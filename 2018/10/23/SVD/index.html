<!DOCTYPE HTML>
<html class="no-js" lang="zh-CN">
<head><meta name="generator" content="Hexo 3.8.0">
    <!--[if lte IE 9]>
<meta http-equiv="refresh" content="0;url=http://yoursite.com/warn.html">
<![endif]-->
<meta charset="utf-8">
<meta http-equiv="X-DNS-Prefetch-Control" content="on">
<link rel="dns-prefetch" href="http://yoursite.com">
<link rel="dns-prefetch" href="//www.google-analytics.com">
<link rel="prefetch" href="http://yoursite.com">
<link rel="prefetch" href="//www.google-analytics.com">


<link rel="prerender" href="http://yoursite.com">

<meta http-equiv="X-UA-Compatible" content="IE=Edge">
<meta name="renderer" content="webkit">
<meta name="viewport" content="width=device-width, initial-scale=1.0,user-scalable=no">
<meta http-equiv="mobile-agent" content="format=html5; url=http://yoursite.com">
<meta name="author" content="Louis Hsu">
<link rel="stylesheet" href="/css/JSimple.css">

<link rel="shortcut icon" href="/images/favicon.png">


<title>svd - LOUIS&#39; BLOG</title>

<meta name="keywords" content="">

<meta name="description " content="Inside! Insane!">

    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            tex2jax: {
                inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                processEscapes: true
            }
        });
    </script>


    

    

</head>
<body>
<div id="nav">
    <nav class="nav-menu">
        <a class="site-name current" href="/" title="彬">彬</a>
        <a class="site-index current" href="/"><i class="fa fa-home"></i><span>Home</span></a>
        <a href="/archives" title="Archives"><i class="fa fa-archives"></i><span>Archives</span></a>
        <a href="/tags" title="Tags"><i class="fa fa-tags"></i><span>Tags</span></a>
        <!-- custom single page of menus -->
        
        
        <a href="/help" title="帮助">
            <i class="fa fa-question-circle"></i>
            <span>帮助</span>
        </a>
        
    </nav>
</div>

<div class="nav-user">
    <a class="btn-search" href="#"><i class="fa fa-search"></i></a>
    <a class="btn-read-mode" href="#"><i class="fa fa-sun-o"></i></a>
    <a class="btn-sns-qr" href="javascript:"><i class="fa fa-telegram"></i></a>
</div>

<div id="wrapper" class="clearfix">
    <div id="body">
        <div class="main" id="main">
            <div id="cover">
    <div class="cover-img"></div>
    <div class="cover-info">
        
        <h1 class="cover-siteName">LOUIS&#39; BLOG</h1>
        <h3 class="cover-siteTitle">人生苦短，不如不管，继续任性</h3>
        <p class="cover-siteDesc">技术博客？</p>
        <div class="cover-sns">
            

        </div>
    </div>
</div>

            <div class="page-title">
    <ul>
        <li><a href="/">Recent Posts</a></li>
        
            
                <li class="">
                    <a href="/categories//" data-name="主页">主页</a>
                </li>
            
                <li class="">
                    <a href="/categories/Python" data-name="Python">Python</a>
                </li>
            
                <li class="">
                    <a href="/categories/Machine-Learning" data-name="机器学习">机器学习</a>
                </li>
            
                <li class="">
                    <a href="/categories/Deep-Learning" data-name="深度学习">深度学习</a>
                </li>
            
                <li class="">
                    <a href="/categories/冯唐" data-name="冯唐">冯唐</a>
                </li>
            
                <li class="">
                    <a href="/categories/Others" data-name="其他">其他</a>
                </li>
            
        
        <li class="page-search">
    <form id="search" class="search-form">
        <input type="text" readonly="readonly" id="local-search-input-tip" placeholder="click to search...">
        <button type="button" disabled="disabled" class="search-form-submit"><i class="fa fa-search"></i></button>
    </form>
</li>

    </ul>
</div>
<div class="main-inner">
    <article class="post" itemscope="" itemtype="http://schema.org/BlogPosting">
        <div class="post-header">
            <div class="post-author clearfix">
                <a class="avatar fleft" href="https://louishsu.xyz/" target="_blank">
                    <img width="48" src="/images/favicon.png" alt="avatar">
                </a>
                <p><span class="label">Author</span>
                    <a href="https://louishsu.xyz/" target="_blank">徐耀彬</a>
                    <span title="Last edited at&nbsp;2018-10-23">2018-10-23</span>
                </p>
                <p>有味道的程序员</p>
            </div>
            <h2 class="post-title">SVD</h2>
            <div class="post-meta">
                emm... 11291 words in the article |
                you are the&nbsp;<span id="busuanzi_value_page_pv"><i class="fa fa-spinner fa-spin"></i></span>th friend who reading now
            </div>
        </div>
        <div class="post-content markdown-body">
            <h1 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h1><p>奇异值分解<code>Singular Value Decomposition</code>是线性代数中一种重要的矩阵分解，奇异值分解则是特征分解在任意矩阵上的推广。在信号处理、统计学等领域有重要应用。</p>
<h1 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h1><h2 id="从特征值分解-EVD-讲起"><a href="#从特征值分解-EVD-讲起" class="headerlink" title="从特征值分解(EVD)讲起"></a>从特征值分解(EVD)讲起</h2><p>我们知道对于一个$n$阶方阵$A_{n×n}$，有</p>
<script type="math/tex; mode=display">
A\alpha_i = \lambda_i \alpha_i　i = 1, ..., n</script><p>取</p>
<script type="math/tex; mode=display">
P = \left[\alpha_1, \alpha_2, ..., \alpha_n\right]</script><p>有下式成立</p>
<script type="math/tex; mode=display">
AP = P\Lambda</script><p>其中</p>
<script type="math/tex; mode=display">
\Lambda = \left[
        \begin{matrix}
            \lambda_1 & & \\
            & ... & \\
            & & \lambda_n \\
        \end{matrix}
\right]</script><blockquote>
<p>特征值一般从大到小排列</p>
</blockquote>
<p>利用该式可将方阵$A_{n×n}$化作对角阵$\Lambda_{n×n}$</p>
<script type="math/tex; mode=display">
\Lambda = P^{-1}AP</script><p>或者</p>
<script type="math/tex; mode=display">
A = P \Lambda P^{-1} = \sum_{i=1}^n \lambda_i (P_{,i})(P_{,i})^{-1}</script><blockquote>
<p>“$_{i}$”表示第$i$行，“$_{,i}$”表示第$i$列</p>
</blockquote>
<p>这样我们就可以理解为，矩阵$A$是由$n$个$n$阶矩阵$P_{,i}P^{-1}_{i}$加权组成，特征值$\lambda_i$即为权重。</p>
<blockquote>
<p>以上为个人理解，不妥之处可以指出。</p>
</blockquote>
<h2 id="奇异值分解-SVD"><a href="#奇异值分解-SVD" class="headerlink" title="奇异值分解(SVD)"></a>奇异值分解(SVD)</h2><h3 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h3><p>对于长方阵$A_{m×n}$，不能进行特征值分解，可进行如下分解</p>
<script type="math/tex; mode=display">
A_{m×n} = U_{m×m} \Sigma_{m×n} V_{n×n}^T</script><p>其中$U \in \mathbb{R}^{m×m}, V \in \mathbb{R}^{n×n}$，均为正交矩阵。矩阵$\Sigma_{m×n}$如下</p>
<ul>
<li><p>对于$m&gt;n$</p>
<script type="math/tex; mode=display">
  \Sigma_{m×n} = \left[
          \begin{matrix}
              S_{n×n} \\
              --- \\
              O_{(m-n)×n}
          \end{matrix}
  \right]</script></li>
<li><p>对于$m&lt;n$</p>
<script type="math/tex; mode=display">
  \Sigma_{m×n} = \left[
          \begin{matrix}
              S_{m×m} & | & O_{m×(n-m)}
          \end{matrix}
  \right]</script></li>
</ul>
<p>矩阵$S_{n×n}$为对角阵，对角元素从大到小排列</p>
<script type="math/tex; mode=display">
S_{n×n} = \left[
    \begin{matrix}
        \sigma_1 & & \\
         & ... & \\
         & & \sigma_n\\
    \end{matrix}
\right]</script><p>直观表示<code>SVD</code>分解如下<br><img src="/2018/10/23/SVD/直观表示SVD.jpg" alt="直观表示SVD"></p>
<p>当取$r&lt;n$时，有部分奇异值分解，可用于降维</p>
<script type="math/tex; mode=display">
A_{m×n} = U_{m×r} \Sigma_{r×r} V_{r×n}^T</script><h3 id="计算"><a href="#计算" class="headerlink" title="计算"></a>计算</h3><blockquote>
<p>以下仅考虑$m&gt;n$的情况</p>
</blockquote>
<ol>
<li><p>令矩阵$A^T$与$A$相乘，有</p>
<script type="math/tex; mode=display">
 A^TA = (U \Sigma V^T)^T (U \Sigma V^T)</script><script type="math/tex; mode=display">
 = V \Sigma^T U^T U \Sigma V^T</script><script type="math/tex; mode=display">
 A^TA = V \Sigma^T \Sigma V^T</script><blockquote>
<p>矩阵$U$为正交阵，即满足$U^TU=I$</p>
</blockquote>
<p> 其中</p>
<script type="math/tex; mode=display">
 \Sigma^T \Sigma = 
         \left[
             \begin{matrix}
                 S^T_{n×n} & | & O^T_{n×(m-n)}
             \end{matrix}
         \right]
         \left[
             \begin{matrix}
                 S_{n×n} \\
                 --- \\
                 O_{(m-n)×n}
             \end{matrix}
         \right]</script><script type="math/tex; mode=display">
 = S_{n×n}^2 
 = \left[
     \begin{matrix}
         \sigma_1^2 & & \\
         & ... & \\
         & & \sigma_n^2\\
     \end{matrix}
 \right]</script><p> 则</p>
<script type="math/tex; mode=display">
 A^T A = V S^2  V^T</script><p> 即矩阵$A^T A$相似对角化为$S^2$，对角元素$\sigma_i^2$与矩阵$V$的列向量$v_i(i=1, …, n)$为矩阵$A^T A$的特征对。</p>
<p> 那么对矩阵$A^T A$进行特征值分解，有</p>
<script type="math/tex; mode=display">
 (A^T A) \alpha^{(1)}_i = \lambda^{(1)}_i \alpha^{(1)}_i</script><p> 则</p>
<script type="math/tex; mode=display">
 v_i = \alpha^{(1)}_i　\sigma_i = \sqrt{\lambda^{(1)}_i}</script><blockquote>
<p>注：对于二次型$x^T (A^T A) x$</p>
<script type="math/tex; mode=display">
x^T (A^T A) x = (Ax)^T(Ax) \geq 0</script><p>故矩阵$A^T A$半正定，$\sigma_i = \sqrt{\lambda_i}$有解</p>
</blockquote>
</li>
</ol>
<ol>
<li><p>同理，令矩阵$A$与$A^T$相乘，可证得</p>
<script type="math/tex; mode=display">
 A A^T = U \Sigma \Sigma^T U^T</script><p> 其中</p>
<script type="math/tex; mode=display">
 \Sigma \Sigma^T = 
         \left[
             \begin{matrix}
                 S_{n×n} \\
                 --- \\
                 O_{(m-n)×n}
             \end{matrix}
         \right]
         \left[
             \begin{matrix}
                 S^T_{n×n} & | & O^T_{n×(m-n)}
             \end{matrix}
         \right]</script><script type="math/tex; mode=display">
 = \left[
     \begin{matrix}
         S^2_{n×n} & O_{n×(m-n)} \\
         O_{(m-n)×n} & O_{(m-n)×(m-n)}
     \end{matrix}
 \right]</script><p> 即矩阵$A A^T$相似对角化，对角元素$\sigma_i^2$与矩阵$U$的列向量$u_i(i=1, …, m)$为矩阵$A A^T$的特征对。</p>
<p> 对矩阵$A A^T$进行特征值分解，有</p>
<script type="math/tex; mode=display">
 (A^T A) \alpha^{(2)}_i = \lambda^{(2)}_i \alpha^{(2)}_i</script><p> 则</p>
<script type="math/tex; mode=display">
 u_i = \alpha^{(2)}_i　\sigma_i = \sqrt{\lambda^{(2)}_i}</script><blockquote>
<p>同理可证得$A A^T$半正定，略。</p>
</blockquote>
</li>
</ol>
<p>一般来说，为减少计算量，计算奇异值分解只进行一次特征值分解，如对于矩阵$X_{m×n}(m&gt;n)$，选取$n$阶矩阵$X^T X$进行特征值分解计算$v_i$，计算$u_i$方法下面介绍。</p>
<p>根据前面推导，我们有特征值分解</p>
<script type="math/tex; mode=display">
(A^T A) \alpha^{(1)}_i = \lambda^{(1)}_i \alpha^{(1)}_i</script><script type="math/tex; mode=display">
(A A^T) \alpha^{(2)}_i = \lambda^{(2)}_i \alpha^{(2)}_i</script><p>其中$\lambda^{(1)}_i = \lambda^{(2)}_i = \sigma_i^2$，$v_i = \alpha^{(1)}_i$，$u_i = \alpha^{(2)}_i$，即</p>
<script type="math/tex; mode=display">
A^T A v_i = \sigma_i^2 v_i \tag{1}</script><script type="math/tex; mode=display">
A A^T u_i = \sigma_i^2 u_i \tag{2}</script><p>$(1)$式左右乘$A$，有</p>
<script type="math/tex; mode=display">
A A^T A v_i = \sigma_i^2 A v_i</script><p>发现什么？这是另一个特征值分解的表达式！</p>
<script type="math/tex; mode=display">
(A A^T) (A v_i) = \sigma_i^2 (A v_i)</script><p>故</p>
<script type="math/tex; mode=display">
u_i \propto A v_i　或　
u_i = k · A v_i \tag{3}</script><p>现在求解系数$k$，根据定义</p>
<script type="math/tex; mode=display">
A = U \Sigma V^T　\Rightarrow　AV = U \Sigma</script><p>则</p>
<script type="math/tex; mode=display">
A v_i = \sigma_i u_i　\Rightarrow　u_i = \frac{1}{\sigma_i} A v_i</script><p>或者</p>
<script type="math/tex; mode=display">
U = A V \Sigma^{-1}</script><blockquote>
<p>注：只能求前$n$个$u_i$，之后的需要列写方程求解</p>
</blockquote>
<h1 id="举栗"><a href="#举栗" class="headerlink" title="举栗"></a>举栗</h1><p>将矩阵$A$进行分解</p>
<script type="math/tex; mode=display">
A = \left[
    \begin{matrix}
        0 & 1 \\
        1 & 1 \\
        1 & 0
    \end{matrix}
\right]</script><p>为减少计算量，取$A^T A$计算</p>
<script type="math/tex; mode=display">
A^T A = \left[
    \begin{matrix}
        2 & 1 \\
        1 & 2 
    \end{matrix}
\right]</script><p>特征值分解，有</p>
<script type="math/tex; mode=display">
A\left[
    \begin{matrix}
        \frac{1}{\sqrt{2}} & -\frac{1}{\sqrt{2}} \\
        \frac{1}{\sqrt{2}} & \frac{1}{\sqrt{2}}
    \end{matrix} 
\right]
= \left[
    \begin{matrix}
        \frac{1}{\sqrt{2}} & -\frac{1}{\sqrt{2}} \\
        \frac{1}{\sqrt{2}} & \frac{1}{\sqrt{2}}
    \end{matrix} 
\right]
\left[
    \begin{matrix}
        3 &  \\
          & 1
    \end{matrix} 
\right]</script><p>故</p>
<script type="math/tex; mode=display">
\Sigma = \left[
    \begin{matrix}
        \sqrt{3} &  \\
          & 1
    \end{matrix} 
\right]　
V = \left[
    \begin{matrix}
        \frac{1}{\sqrt{2}} & -\frac{1}{\sqrt{2}} \\
        \frac{1}{\sqrt{2}} & \frac{1}{\sqrt{2}}
    \end{matrix} 
\right]</script><script type="math/tex; mode=display">
U = A V \Sigma^{-1} = \left[
    \begin{matrix}
        \frac{1}{\sqrt{6}} & \frac{1}{\sqrt{2}} \\
        \frac{2}{\sqrt{6}} & 0 \\
        \frac{1}{\sqrt{6}} & -\frac{1}{\sqrt{2}}
    \end{matrix} 
\right]</script><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; import numpy as np</span><br><span class="line">&gt;&gt;&gt; A = np.array([</span><br><span class="line">	[0, 1], [1, 1], [1, 0]</span><br><span class="line">	])</span><br><span class="line">&gt;&gt;&gt; ATA = A.T.dot(A)</span><br><span class="line">&gt;&gt;&gt; eigval, eigvec= np.linalg.eig(ATA)</span><br><span class="line">&gt;&gt;&gt; V = eigvec.copy()</span><br><span class="line">&gt;&gt;&gt; S = np.diag(np.sqrt(eigval))</span><br><span class="line">&gt;&gt;&gt; U = A.dot(V).dot(np.linalg.inv(S))</span><br><span class="line">&gt;&gt;&gt; U</span><br><span class="line">array([[ 0.40824829,  0.70710678],</span><br><span class="line">       [ 0.81649658,  0.        ],</span><br><span class="line">       [ 0.40824829, -0.70710678]])</span><br><span class="line">&gt;&gt;&gt; S</span><br><span class="line">array([[1.73205081, 0.        ],</span><br><span class="line">       [0.        , 1.        ]])</span><br><span class="line">&gt;&gt;&gt; V</span><br><span class="line">array([[ 0.70710678, -0.70710678],</span><br><span class="line">       [ 0.70710678,  0.70710678]])</span><br><span class="line">&gt;&gt;&gt; # 验证</span><br><span class="line">&gt;&gt;&gt; U.dot(S).dot(V.T)</span><br><span class="line">array([[-2.23711432e-17,  1.00000000e+00],</span><br><span class="line">       [ 1.00000000e+00,  1.00000000e+00],</span><br><span class="line">       [ 1.00000000e+00, -2.23711432e-17]])</span><br></pre></td></tr></table></figure>
<h1 id="理解"><a href="#理解" class="headerlink" title="理解"></a>理解</h1><p>展开表达式，取$r \leq n$时，</p>
<script type="math/tex; mode=display">
A = U_{m×r} \Sigma_{r×r} V_{r×n}^T = \sum_{i=1}^r \sigma_i (U_{,i}) (V_{,i})^T</script><p>就得到与<code>PCA</code>相同的结论，矩阵$A$可由$r$个$m×n$的矩阵$(U_{,i}) (V_{,i})^T$加权组成。一般来说，前$10\%$甚至$1\%$的奇异值就占了全部奇异值之和的$99\%$，极大地保留了信息，而大大减少了存储空间。</p>
<blockquote>
<p>以图片为例，若原有<code>24bit</code>图片，其大小为<code>(1024, 768)</code>，则不计图片信息，仅仅数据共占<code>1024×768×3 B</code>，或<code>2.25 MB</code>。用奇异值分解进行压缩，保留$60\%$的奇异值，可达到几乎无损的程度，此时需要保存向量矩阵$U_{1024×60}$，$V_{60×768}$以及$60$个奇异值，以浮点数<code>float32</code>存储，一共占<code>420 KB</code>即可。</p>
<script type="math/tex; mode=display">
(1024 × 60 + 60 × 768 + 60) × 4 / 2^{10} = 420.23</script><p>说句题外话，存储量的压缩必然以计算量的增大为代价，相反亦然，所以需要协调好<code>RAM</code>与<code>ROM</code>容量，考虑计算机的计算速度。换句话说，空间和时间上必然是互补的，哲学的味道hhhh。</p>
</blockquote>
<h1 id="分解结果的信息保留"><a href="#分解结果的信息保留" class="headerlink" title="分解结果的信息保留"></a>分解结果的信息保留</h1><p>分解后各样本间的欧式距离与角度信息应不变，给出证明如下<br>设有$m$组$n$维样本样本</p>
<script type="math/tex; mode=display">
X_{n×m} = [X^{(1)}, X^{(2)}, ..., X^{(m)}]</script><p>经奇异值分解，有</p>
<script type="math/tex; mode=display">
X_{n×m} = U_{n×r} \Sigma_{r×r} V_{r×m}^T</script><p>记</p>
<script type="math/tex; mode=display">
Z_{r×m} = \Sigma V^T = [Z^{(1)}, Z^{(2)}, ..., Z^{(N)}]</script><p>有</p>
<script type="math/tex; mode=display">
X = U Z</script><ul>
<li><p>欧式距离</p>
<script type="math/tex; mode=display">
  || X^{(i)} - X^{(j)} ||_2^2 = || U (Z^{(i)} - Z^{(j)}) ||_2^2</script><script type="math/tex; mode=display">
  = \left[ U (Z^{(i)} - Z^{(j)}) \right]^T \left[ U (Z^{(i)} - Z^{(j)}) \right]</script><script type="math/tex; mode=display">
  = (Z^{(i)} - Z^{(j)})^T U^T U (Z^{(i)} - Z^{(j)})</script><script type="math/tex; mode=display">
  = || Z^{(i)} - Z^{(j)} ||_2^2</script><p>  即</p>
<script type="math/tex; mode=display">
  || X^{(i)} - X^{(j)} ||_2^2 = || Z^{(i)} - Z^{(j)} ||_2^2</script></li>
<li><p>角度信息</p>
<script type="math/tex; mode=display">
  \frac{X^{(i)T}X^{(j)}}{||X^{(i)}||_2||X^{(j)}||_2}</script><script type="math/tex; mode=display">
  = \frac{(UZ^{(i)})^T(UZ^{(j)})}{||UZ^{(i)}||_2||UZ^{(j)}||_2}</script><script type="math/tex; mode=display">
  = \frac{(UZ^{(i)})^T(UZ^{(j)})}{\sqrt{(UZ^{(i)})^T(UZ^{(i)})} \sqrt{(UZ^{(j)})^T(UZ^{(j)})}}</script><script type="math/tex; mode=display">
  = \frac{Z^{(i)T}Z^{(j)}}{||Z^{(i)}||_2||Z^{(j)}||_2}</script><p>  即</p>
<script type="math/tex; mode=display">
  \frac{X^{(i)T}X^{(j)}}{||X^{(i)}||_2||X^{(j)}||_2} = 
  \frac{Z^{(i)T}Z^{(j)}}{||Z^{(i)}||_2||Z^{(j)}||_2}</script></li>
</ul>
<h1 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h1><p><a href="https://github.com/isLouisHsu/Python-Examples-for-Pattern-Recognition-Course/blob/master/examples/p15_svd.py" target="_blank" rel="noopener">@Github: Code of SVD</a><br>对图片进行了分解<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br></pre></td><td class="code"><pre><span class="line">class SVD():</span><br><span class="line">    &quot;&quot;&quot; Singular Value Decomposition</span><br><span class="line">    Attributes:</span><br><span class="line">        m &#123;int&#125;</span><br><span class="line">        n &#123;int&#125;</span><br><span class="line">        r &#123;int&#125;: if r == -1, then r = n</span><br><span class="line">        isTrains &#123;bool&#125;: isTrains = True if input.shape[0] &lt; input.shape[1]</span><br><span class="line">        U &#123;ndarray(m, r)&#125;</span><br><span class="line">        S &#123;ndarray(r, )&#125;</span><br><span class="line">        V &#123;ndarray(n, r)&#125;</span><br><span class="line">    Notes:</span><br><span class="line">        - Transpose input matrix if m &lt; n, and m, n := n, m</span><br><span class="line">        - Reassign r if eigvals contains zero</span><br><span class="line">        - Singular values are stored in a 1-dim array `S`</span><br><span class="line">        - X&apos; = U S V^T</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    def __init__(self, r=-1):</span><br><span class="line">        self.m = None</span><br><span class="line">        self.n = None</span><br><span class="line">        self.r = r</span><br><span class="line">        self.isTrans = False</span><br><span class="line">        self.U = None</span><br><span class="line">        self.S = None</span><br><span class="line">        self.V = None</span><br><span class="line">    def fit(self, X):</span><br><span class="line">        &quot;&quot;&quot; calculate components</span><br><span class="line">        Notes:</span><br><span class="line">            - Transpose input matrix if m &lt; n, and m, n := n, m</span><br><span class="line">            - reassign self.r if eigvals contains zero</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        (self.m, self.n) = X.shape</span><br><span class="line">        if self.m &lt; self.n:</span><br><span class="line">            X = X.T</span><br><span class="line">            self.m, self.n = self.n, self.m</span><br><span class="line">            self.isTrans = True</span><br><span class="line">        self.r = self.n if (self.r == -1) else self.r</span><br><span class="line"></span><br><span class="line">        XTX = X.T.dot(X)</span><br><span class="line">        eigval, eigvec = np.linalg.eig(X.T.dot(X))</span><br><span class="line">        eigval, eigvec = np.real(eigval), np.real(eigvec)</span><br><span class="line">        </span><br><span class="line">        self.S = np.sqrt(np.clip(eigval, 0, float(&apos;inf&apos;)))</span><br><span class="line">        self.S = self.S[self.S &gt; 0]</span><br><span class="line">        self.r = min(self.r, self.S.shape[0])               # reassign self.r</span><br><span class="line">        order = np.argsort(eigval)[::-1][: self.r]          # sort eigval from large to small</span><br><span class="line">        eigval = eigval[order]; eigvec = eigvec[:, order]</span><br><span class="line">        self.V = eigvec.copy()</span><br><span class="line">        self.U = X.dot(self.V).dot(</span><br><span class="line">                    np.linalg.inv(np.diag(self.S)))</span><br><span class="line">        return self.U, self.S, self.V</span><br><span class="line">    def compose(self, r=-1):</span><br><span class="line">        &quot;&quot;&quot; merge first r components</span><br><span class="line">        Parameters:</span><br><span class="line">            r &#123;int&#125;: if r==-1, merge all components</span><br><span class="line">        Returns:</span><br><span class="line">            X &#123;ndarray(m, n)&#125;</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        if r == -1:</span><br><span class="line">            X = self.U.dot(np.diag(self.S)).dot(self.V.T)</span><br><span class="line">            X = X.T if self.isTrans else X</span><br><span class="line">        else:</span><br><span class="line">            (m, n) = (self.n, self.m) if self.isTrans else (self.m, self.n)</span><br><span class="line">            X = np.zeros(shape=(m, n))</span><br><span class="line">            for i in range(r):</span><br><span class="line">                X += self.__getitem__(i)</span><br><span class="line">        return X</span><br><span class="line">    def __getitem__(self, idx):</span><br><span class="line">        &quot;&quot;&quot; get a component</span><br><span class="line">        Parameters:</span><br><span class="line">            index &#123;int&#125;: range from (0, self.r)</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        u = self.U[:, idx]</span><br><span class="line">        v = self.V[:, idx]</span><br><span class="line">        s = self.S[idx]</span><br><span class="line">        x = s * u.reshape(self.m, 1).\</span><br><span class="line">                    dot(v.reshape(1, self.n))</span><br><span class="line">        x = x.T if self.isTrans else x</span><br><span class="line">        return x</span><br><span class="line">    def showComponets(self, r=-1):</span><br><span class="line">        &quot;&quot;&quot; display components</span><br><span class="line">        Notes:</span><br><span class="line">            - Resize components&apos; shape into (40, 30)</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        m, n = self.m, self.n</span><br><span class="line">        r = self.r if r==-1 else r</span><br><span class="line">        n_images = 10; m_images = r // n_images + 1</span><br><span class="line">        m_size, n_size = 40, 30</span><br><span class="line">        showfig = np.zeros(shape=(m_images*m_size, n_images*n_size))</span><br><span class="line">        for i in range(r):</span><br><span class="line">            m_pos = i // n_images</span><br><span class="line">            n_pos = i %  n_images</span><br><span class="line">            component = self.__getitem__(i)</span><br><span class="line">            component = component.T if self.isTrans else component</span><br><span class="line">            component = cv2.resize(component, (30, 40))</span><br><span class="line">            showfig[m_pos*m_size: (m_pos+1)*m_size, n_pos*n_size: (n_pos+1)*n_size] = component</span><br><span class="line">        plt.figure(&apos;components&apos;)</span><br><span class="line">        plt.imshow(showfig)</span><br><span class="line">        plt.show()</span><br></pre></td></tr></table></figure></p>
<p>用上面的代码进行实验<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"># 读取一张图片</span><br><span class="line">X = load_images()[0].reshape((32, 32))</span><br><span class="line">showmat2d(X)</span><br><span class="line"># 对图片进行奇异值分解</span><br><span class="line">decomposer = SVD(r=-1)</span><br><span class="line">decomposer.fit(X)</span><br><span class="line"># 显示一下分量</span><br><span class="line">decomposer.showComponets(r=-1)</span><br><span class="line"># 将全部分量组合，并显示</span><br><span class="line">X_ = decomposer.compose(r=-1)</span><br><span class="line">showmat2d(X_)</span><br><span class="line"># 将前5个分量组合，并显示</span><br><span class="line">X_ = decomposer.compose(r=5)</span><br><span class="line">showmat2d(X_)</span><br></pre></td></tr></table></figure></p>
<ul>
<li><p>载入原图如下<br><img src="/2018/10/23/SVD/source.png" alt="source"></p>
</li>
<li><p>分量显示如下<br><img src="/2018/10/23/SVD/components.png" alt="components"></p>
</li>
<li><p>组合分量显示如下</p>
<ul>
<li>组合全部<br>  <img src="/2018/10/23/SVD/merge_all.png" alt="merge_all"></li>
<li>组合前5个分量<br>  <img src="/2018/10/23/SVD/merge_5.png" alt="merge_5"></li>
</ul>
</li>
</ul>

        </div>
        <div class="post-tool">
            <a class="btn-thumbs-up" href="javascript:void(0);" data-cid="52" title="95">
                <i class="fa fa-thumbs-up" aria-hidden="true"></i> Donate
            </a>
        </div>
        
        <div class="post-tags">Tags：
            
        </div>
        
    </article>
    
    <p style="text-align: center">This article just represents my own viewpoint. If there is something wrong, please correct me.</p>
    
    

    

</div>
<script src="/js/busuanzi.pure.mini.js"></script>


        </div><!-- end #main-->
    </div><!-- end #body -->
    <footer class="footer">
    <div class="footer-inner" style="text-align: center">
        <p>
            <a href="/about" title="About">About</a>&nbsp;&nbsp<em>·</em>&nbsp;&nbsp
            <!-- 自定义链接 -->
            <a href="/help" title="Help">Help</a>&nbsp;&nbsp<em>·</em>&nbsp;&nbsp
            <a href="/links" title="Links">Links</a>&nbsp;&nbsp<em>·</em>&nbsp;&nbsp
            <a href="/sitemap.xml" title="SiteMap">SiteMap</a>
        </p>
        <p>
            Has been established&nbsp<a href="/timeline" id="siteBuildingTime"></a>&nbspDays，<a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank" rel="licence">Based on Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0)</a><br>
            ©2017-<span id="cpYear"></span> Based on&nbsp<a href="http://hexo.io" target="_blank" rel="nofollow">Hexo</a>
            ，Theme by&nbsp&nbsp<a href="https://github.com/tangkunyin/hexo-theme-jsimple" target="_blank" rel="bookmark">JSimple</a>
            ，Author&nbsp<a href="https://louishsu.xyz/" target="_blank" rel="friend">徐耀彬</a>
            ，Hosted by <a href="https://pages.github.com/" target="_blank" rel="nofollow">GitHub Pages</a>
        </p>
    </div>
</footer>
<script src="/js/SimpleCore.js"></script>

</div>
<!-- search pop -->
<div class="popup search-popup local-search-popup">
    <div class="local-search-header clearfix">
        <span class="search-icon">
            <i class="fa fa-search"></i>
        </span>
        <span class="popup-btn-close">
            <i class="fa fa-times-circle"></i>
        </span>
        <div class="local-search-input-wrapper">
            <input id="local-search-input" spellcheck="false" type="text" autocomplete="off" placeholder="Input query keywords here...">
        </div>
    </div>
    <div id="local-search-result"></div>
</div>
<div class="fixed-btn">
    <a class="btn-gotop" href="javascript:"> <i class="fa fa-angle-up"></i></a>
</div>
<script>
    $(function () {
        var jsi_config = {
            buildingTime: '10/20/2018',
            current: $('.post-tags').length > 0 ? 'post' : 'archive',
            snsQRCode: '/images/sns-qrcode.png',
            donateImg: '/images/donate-qr.png',
            localSearch: { dbPath: '' },
            readMode: 'day'
        };
        
            jsi_config.localSearch = {
                dbPath: '/search.json',
                trigger: 'auto',
                topN: '1',
                unescape: 'false'
            }
        
        SimpleCore.init(jsi_config);
        
    });
</script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>
</html>
