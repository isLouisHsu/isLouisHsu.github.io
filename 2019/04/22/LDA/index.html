<!DOCTYPE HTML>
<html class="no-js" lang="zh-CN">
<head><meta name="generator" content="Hexo 3.8.0">
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><!--[if lte IE 9]>
<meta http-equiv="refresh" content="0;url=http://yoursite.com/warn.html">
<![endif]-->
<meta charset="utf-8">
<meta http-equiv="X-DNS-Prefetch-Control" content="on">
<link rel="dns-prefetch" href="http://yoursite.com">
<link rel="dns-prefetch" href="//www.google-analytics.com">
<link rel="prefetch" href="http://yoursite.com">
<link rel="prefetch" href="//www.google-analytics.com">


<link rel="prerender" href="http://yoursite.com">

<meta http-equiv="X-UA-Compatible" content="IE=Edge">
<meta name="renderer" content="webkit">
<meta name="viewport" content="width=device-width, initial-scale=1.0,user-scalable=no">
<meta http-equiv="mobile-agent" content="format=html5; url=http://yoursite.com">
<meta name="author" content="Louis Hsu">
<link rel="stylesheet" href="/css/JSimple.css">

<link rel="shortcut icon" href="/images/favicon.png">


<title>lda - LOUIS&#39; BLOG</title>

<meta name="keywords" content="">

<meta name="description " content="Inside! Insane!">

    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            tex2jax: {
                inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                processEscapes: true
            }
        });
    </script><!-- hexo-inject:begin --><!-- hexo-inject:end -->


    

    

</head>
<body>
<!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="nav">
    <nav class="nav-menu">
        <a class="site-name current" href="/" title="彬">彬</a>
        <a class="site-index current" href="/"><i class="fa fa-home"></i><span>Home</span></a>
        <a href="/archives" title="Archives"><i class="fa fa-archives"></i><span>Archives</span></a>
        <a href="/tags" title="Tags"><i class="fa fa-tags"></i><span>Tags</span></a>
        <!-- custom single page of menus -->
        
        
        <a href="/help" title="帮助">
            <i class="fa fa-question-circle"></i>
            <span>帮助</span>
        </a>
        
    </nav>
</div>

<div class="nav-user">
    <a class="btn-search" href="#"><i class="fa fa-search"></i></a>
    <a class="btn-read-mode" href="#"><i class="fa fa-sun-o"></i></a>
    <a class="btn-sns-qr" href="javascript:"><i class="fa fa-telegram"></i></a>
</div>

<div id="wrapper" class="clearfix">
    <div id="body">
        <div class="main" id="main">
            <div id="cover">
    <div class="cover-img"></div>
    <div class="cover-info">
        
        <img class="avatar" width="72" src="/images/favicon.png" alt="avatar">
        
        <h1 class="cover-siteName">LOUIS&#39; BLOG</h1>
        <h3 class="cover-siteTitle">人生苦短，不如不管，继续任性</h3>
        <p class="cover-siteDesc">技术博客？</p>
        <div class="cover-sns">
            

        </div>
    </div>
</div>

            <div class="page-title">
    <ul>
        <li><a href="/">Recent Posts</a></li>
        
            
                <li class="">
                    <a href="/categories//" data-name="主页">主页</a>
                </li>
            
                <li class="">
                    <a href="/categories/Python" data-name="Python">Python</a>
                </li>
            
                <li class="">
                    <a href="/categories/Machine-Learning" data-name="机器学习">机器学习</a>
                </li>
            
                <li class="">
                    <a href="/categories/Deep-Learning" data-name="深度学习">深度学习</a>
                </li>
            
                <li class="">
                    <a href="/categories/冯唐" data-name="冯唐">冯唐</a>
                </li>
            
                <li class="">
                    <a href="/categories/Others" data-name="其他">其他</a>
                </li>
            
        
        <li class="page-search">
    <form id="search" class="search-form">
        <input type="text" readonly="readonly" id="local-search-input-tip" placeholder="click to search...">
        <button type="button" disabled="disabled" class="search-form-submit"><i class="fa fa-search"></i></button>
    </form>
</li>

    </ul>
</div>
<div class="main-inner">
    <article class="post" itemscope="" itemtype="http://schema.org/BlogPosting">
        <div class="post-header">
            <div class="post-author clearfix">
                <a class="avatar fleft" href="https://louishsu.xyz/" target="_blank">
                    <img width="48" src="/images/favicon.png" alt="avatar">
                </a>
                <p><span class="label">Author</span>
                    <a href="https://louishsu.xyz/" target="_blank">徐耀彬</a>
                    <span title="Last edited at&nbsp;2019-04-22">2019-04-22</span>
                </p>
                <p>有味道的程序员</p>
            </div>
            <h2 class="post-title">LDA</h2>
            <div class="post-meta">
                emm... 6879 words in the article |
                you are the&nbsp;<span id="busuanzi_value_page_pv"><i class="fa fa-spinner fa-spin"></i></span>th friend who reading now
            </div>
        </div>
        <div class="post-content markdown-body">
            <h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>在<a href="https://louishsu.xyz/2018/10/22/PCA/" target="_blank" rel="noopener">PCA</a>中，介绍了无监督降维方法，主成分分析(Principal Components Analysis)。从投影后数据方差最大的角度出发，选取主轴。下面介绍一种有监督的降维方法，线性判别分析(Linear Discriminant Analysis)。</p>
<h1 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h1><p>设有$n$维样本集$D=\{x^{(1)}, …, x^{(i)}, …, x^{(m)}\}$，所属类别数目为$C$，现求其第一投影轴$u_1$，即</p>
<script type="math/tex; mode=display">
\tilde{x}^{(i)}_1 = u_1^Tx^{(i)}</script><p>现希望投影后，<strong>类内距离越小越好，类间距离越大越好</strong>，定义衡量指标</p>
<ol>
<li><p>类内离差阵</p>
<script type="math/tex; mode=display">
 S_W = \sum_{j=1}^C \frac{m_j}{m} \left[ \frac{1}{m_j} \sum_{i=1}^{m_j} (x^{(i)} - \mu^{(j)}) (x^{(i)} - \mu^{(j)})^T \right] \tag{1}</script><p> 即</p>
<script type="math/tex; mode=display">
 S_W = \frac{1}{m} \sum_{j=1}^C \sum_{i=1}^{m_j} (x^{(i)} - \mu^{(j)}) (x^{(i)} - \mu^{(j)})^T \tag{1}</script></li>
<li><p>类间离差阵</p>
<script type="math/tex; mode=display">
 S_B = \sum_{j=1}^C \frac{m_j}{m} (\mu^{(j)} - \mu) (\mu^{(j)} - \mu)^T \tag{2}</script></li>
</ol>
<p>则投影到第一主轴$u_1$后数据的类内离差阵和类间离差阵为</p>
<script type="math/tex; mode=display">
\tilde{S_W} = \sum_{j=1}^C \frac{m_j}{m} \left[ \frac{1}{m_j} \sum_{i=1}^{m_j} 
(\tilde{x}^{(i)}_1 - \tilde{\mu}^{(j)}_1) (\tilde{x}^{(i)}_1 - \tilde{\mu}^{(j)}_1)^T \right]</script><script type="math/tex; mode=display">
\tilde{S_B} = \sum_{j=1}^C \frac{m_j}{m} 
(\tilde{\mu}^{(j)}_1 - \tilde{\mu}_1) (\tilde{\mu}^{(j)}_1 - \tilde{\mu}_1)^T</script><p>其中</p>
<script type="math/tex; mode=display">
\tilde{x}^{(i)}_1 = u_1^T x^{(i)}</script><script type="math/tex; mode=display">
\tilde{\mu}^{(j)}_1 = u_1^T \mu^{(j)}</script><script type="math/tex; mode=display">
\tilde{\mu}_1 = u_1^T \mu</script><p>带入后得到</p>
<script type="math/tex; mode=display">
\tilde{S_W} = \frac{1}{m} \sum_{j=1}^C \sum_{i=1}^{m_j} 
(u_1^T x^{(i)} - u_1^T \mu^{(j)}) (u_1^T x^{(i)} - u_1^T \mu^{(j)})^T</script><script type="math/tex; mode=display">
= \frac{1}{m} \sum_{j=1}^C \sum_{i=1}^{m_j} 
u_1^T(x^{(i)} - \mu^{(j)}) (x^{(i)} - \mu^{(j)})^T u_1</script><script type="math/tex; mode=display">
= u_1^T S_W u_1</script><p>同理</p>
<script type="math/tex; mode=display">
\tilde{S_B} = u_1^T S_B u_1</script><p>定义优化目标</p>
<script type="math/tex; mode=display">
J = \min \left\{ \frac{\tilde{S_W}}{\tilde{S_B}} \right\}
= \min \left\{ \frac{u_1^T S_W u_1}{u_1^T S_B u_1} \right\} \tag{3}</script><p>取</p>
<script type="math/tex; mode=display">
L(u_1) = \frac{u_1^T S_W u_1}{u_1^T S_B u_1} \tag{4}</script><p>则其极值为</p>
<script type="math/tex; mode=display">
\frac{∂L}{∂u_1} = \frac{2(u_1^T S_B u_1) S_W u_1 - 2(u_1^T S_W u_1) S_B u_1}{(u_1^T S_B u_1)^2} = 0</script><p>得到</p>
<script type="math/tex; mode=display">
(u_1^T S_B u_1) S_W u_1 = (u_1^T S_W u_1) S_B u_1</script><p>令$\lambda_1 = \frac{u_1^T S_B u_1}{u_1^T S_W u_1}$，有</p>
<script type="math/tex; mode=display">
S_B u_1 = \lambda_1 S_W u_1 \tag{5}</script><p>当$m$较大时，$S_W$一般非奇异，故</p>
<script type="math/tex; mode=display">
S_W^{-1} S_B u_1 = \lambda_1 u_1 \tag{6}</script><p>即$\{\lambda_1, u_1\}$为矩阵$S_W^{-1} S_B$的特征对。</p>
<p>更进一步，对于而分类问题，我们有</p>
<script type="math/tex; mode=display">
S_B = \sum_{j=1}^C \frac{m_j}{m} (\mu^{(j)} - \mu) (\mu^{(j)} - \mu)^T</script><script type="math/tex; mode=display">
= \frac{m_1}{m} (\mu^{(1)} - \mu) (\mu^{(1)} - \mu)^T + \frac{m_2}{m} (\mu^{(2)} - \mu) (\mu^{(2)} - \mu)^T</script><script type="math/tex; mode=display">
= \frac{m_1}{m} \mu^{(1)} \mu^{(1)T} + \frac{m_2}{m} \mu^{(2)} \mu^{(2)T} - 2 \mu \left( \frac{m_1}{m} \mu^{(1)T} + \frac{m_2}{m} \mu^{(2)T} \right) + \mu \mu^T</script><p>其中</p>
<script type="math/tex; mode=display">
\frac{m_1}{m} \mu^{(1)} + \frac{m_2}{m} \mu^{(2)} = \mu \tag{*1}</script><p>所以$(7)$带入$S_B$化简得</p>
<script type="math/tex; mode=display">
S_B = \frac{m_1}{m} \mu^{(1)} \mu^{(1)T} + \frac{m_2}{m} \mu^{(2)} \mu^{(2)T} - \mu \mu^T</script><script type="math/tex; mode=display">
= \frac{m_1}{m} \mu^{(1)} \mu^{(1)T} + \frac{m_2}{m} \mu^{(2)} \mu^{(2)T} - (\frac{m_1}{m} \mu^{(1)} + \frac{m_2}{m} \mu^{(2)}) (\frac{m_1}{m} \mu^{(1)} + \frac{m_2}{m} \mu^{(2)})^T</script><script type="math/tex; mode=display">
= \frac{m_1}{m} \left(1-\frac{m_1}{m}\right) \mu^{(1)} \mu^{(1)T} + \frac{m_2}{m} \left(1-\frac{m_2}{m}\right) \mu^{(2)} \mu^{(2)T} - \frac{m_1}{m} \frac{m_2}{m} \mu^{(2)} \mu^{(1)T} - \frac{m_1}{m} \frac{m_2}{m} \mu^{(1)} \mu^{(2)T}</script><script type="math/tex; mode=display">
= \left( \frac{m_1}{m} \mu^{(1)} - \frac{m_2}{m} \mu^{(2)} \right) \left( \frac{m_1}{m} \mu^{(1)} - \frac{m_2}{m} \mu^{(2)} \right)^T</script><p>$S_B$带入式$(*)$，得</p>
<script type="math/tex; mode=display">
左边 = S_W^{-1} \left( \frac{m_1}{m} \mu^{(1)} - \frac{m_2}{m} \mu^{(2)} \right) \left( \frac{m_1}{m} \mu^{(1)} - \frac{m_2}{m} \mu^{(2)} \right)^T u_1</script><p>其中$\left( \frac{m_1}{m} \mu^{(1)} - \frac{m_2}{m} \mu^{(2)} \right)^T u_1$为常数，记作$\alpha$，所以</p>
<script type="math/tex; mode=display">
u_1 = \frac{\alpha}{\lambda_1} S_W^{-1} \left( \frac{m_1}{m} \mu^{(1)} - \frac{m_2}{m} \mu^{(2)} \right) \tag{*2}</script><p>其中常数$\frac{\alpha}{\lambda_1}$不影响投影结果，如取$1$，则得到</p>
<script type="math/tex; mode=display">
u_1 = S_W^{-1} \left( \frac{m_1}{m} \mu^{(1)} - \frac{m_2}{m} \mu^{(2)} \right)</script><p>同理，可求得第二、三主成分轴</p>
<h1 id="计算步骤"><a href="#计算步骤" class="headerlink" title="计算步骤"></a>计算步骤</h1><p>给定数据集矩阵</p>
<script type="math/tex; mode=display">
X = \left[ \begin{matrix}
    ... \\
    x^{(i)T} \\
    ... 
\end{matrix} \right]</script><p>其中$x^{(i)} = \left[ x^{(i)}_1, …, x^{(i)}_j, … x^{(i)}_n \right]^T$</p>
<ol>
<li>计算类内离差阵$S_W$与类间离差阵$S_B$；</li>
<li>计算矩阵$S_W^{-1}S_B$的特征对$(\lambda_i, u_i)$；</li>
<li>按特征值从大到小排序，选取最大的特征值作为第一主轴；</li>
<li>将数据投影到主轴上；</li>
</ol>
<h1 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h1><p>LDA可用于分类，以二分类为例，在求取主轴$u_1$后，将各类中心投影到主轴上，即</p>
<script type="math/tex; mode=display">
\begin{cases}
    \tilde{\mu}^{(1)}_1 = u_1^T \mu^{(1)} \\
    \tilde{\mu}^{(2)}_1 = u_1^T \mu^{(2)}
\end{cases}</script><p>选取阈值，如</p>
<script type="math/tex; mode=display">
\tilde{x}_1 = \frac{\tilde{\mu}^{(1)}_1 + \tilde{\mu}^{(2)}_1}{2}</script><p>则预测时，判决方程为</p>
<script type="math/tex; mode=display">
\begin{cases}
    u_1^T x^{(i)} < \tilde{x}_1 \Rightarrow x^{(i)} \in \omega_1 \\
    u_1^T x^{(i)} > \tilde{x}_1 \Rightarrow x^{(i)} \in \omega_2
\end{cases}</script><h1 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h1><p>详情查看<a href="https://github.com/isLouisHsu/Basic-Machine-Learning-Algorithm/blob/master/algorithm/lda.py" target="_blank" rel="noopener">Github</a></p>
<details>
<summary>展开</summary>
<pre><code>
class LDA(object):
    """ 先行判别分析

    Attributes:
        n_components:   {int} 主成分个数
        axis:           {ndarray(n_features, n_component)}
    Notes:
        S_W = \frac{1}{m} \sum_{j=1}^C \sum_{i=1}^m_j (x^{(i)} - \mu^{(j)}) (x^{(i)} - \mu^{(j)})^T
        S_B = \sum_{j=1}^C \frac{m_j}{m} (\mu^{(j)} - \mu) (\mu^{(j)} - \mu)^T
    Example:

    """

    def __init__(self, n_components=-1):
        self.n_components = n_components
        self.axis = None

    def fit(self, X, y, prop=0.99):
        """ train the model
        Params:
            X:      {ndarray(n_samples, n_features)}
            y:      {ndarray(n_samples)}
            prop:   {float}:  在[0, 1]范围内，表示取特征值之和占所有特征值的比重
        Notes:
            - `prop`参数仅在`n_components=-1`时生效
        """
        labels = list(set(list(y)))
        n_class = len(labels)
        n_samples, n_feats = X.shape

        ## 计算 S_W, S_B
        S_W = np.zeros(shape=(n_feats, n_feats))
        S_B = np.zeros(shape=(n_feats, n_feats))
        mean_ = np.mean(X, axis=0)
        for i_class in range(n_class):
            X_ = X[y==labels[i_class]]
            weight = X_.shape[0] / n_samples
            means_ = np.mean(X_, axis=0)
            S_W += ((X_ - means_).T).dot(X_ - means_) / X_.shape[0] * weight
            S_B += (means_ - mean_).dot((means_ - mean_).T) * weight

        ## 计算特征对
        eigVal, eigVec = np.linalg.eig(np.linalg.inv(S_W).dot(S_B))
        order = np.argsort(eigVal)[::-1]
        eigVal = eigVal[order]
        eigVec = eigVec.T[order].T

        ## 选取主轴
        if self.n_components == -1:
            sumOfEigVal = np.sum(eigVal)
            sum_tmp = 0
            for k in range(eigVal.shape[0]):
                sum_tmp += eigVal[k]
                if sum_tmp > prop * sumOfEigVal:
                    self.n_components = k + 1
                    break
        self.axis = eigVec[:, :self.n_components]

    def transform(self, X):
        """
        Params:
            X:  {ndarray(n_samples, n_features)}
        Returns:
            X:  {ndarray(n_samples, n_components)}
        """
        X = X.dot(self.axis)
        return X

    def fit_transform(self, X, y, prop=0.99):
        """
        Params:
            X:  {ndarray(n_samples, n_features)}
        Returns:
            X:  {ndarray(n_samples, n_components)}
        """
        self.fit(X, y, prop=prop)
        X = self.transform(X)
        return X

    def transform_inv(self, X):
        """
        Params:
            X:  {ndarray(n_samples, n_components)}
        Returns:
            X:  {ndarray(n_samples, n_features)}
        """
        X = X.dot(self.axis.T)
        return X
</code></pre>
</details>

<p>与PCA投影结果对比如下</p>
<ul>
<li>PCA<br>  <img src="/2019/04/22/LDA/PCA.png" alt="PCA"></li>
<li>LDA<br>  <img src="/2019/04/22/LDA/LDA.png" alt="LDA"></li>
</ul>
<h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol>
<li><a href="https://www.cnblogs.com/LeftNotEasy/archive/2011/01/08/lda-and-pca-machine-learning.html" target="_blank" rel="noopener">机器学习中的数学(4)-线性判别分析（LDA）, 主成分分析(PCA)</a></li>
</ol>

        </div>
        <div class="post-tool">
            <a class="btn-thumbs-up" href="javascript:void(0);" data-cid="52" title="95">
                <i class="fa fa-thumbs-up" aria-hidden="true"></i> Donate
            </a>
        </div>
        
        <div class="post-tags">Tags：
            
        </div>
        
    </article>
    
    <p style="text-align: center">This article just represents my own viewpoint. If there is something wrong, please correct me.</p>
    
    

    

</div>
<script src="/js/busuanzi.pure.mini.js"></script>


        </div><!-- end #main-->
    </div><!-- end #body -->
    <footer class="footer">
    <div class="footer-inner" style="text-align: center">
        <p>
            <a href="/about" title="About">About</a>&nbsp;&nbsp<em>·</em>&nbsp;&nbsp
            <!-- 自定义链接 -->
            <a href="/help" title="Help">Help</a>&nbsp;&nbsp<em>·</em>&nbsp;&nbsp
            <a href="/links" title="Links">Links</a>&nbsp;&nbsp<em>·</em>&nbsp;&nbsp
            <a href="/sitemap.xml" title="SiteMap">SiteMap</a>
        </p>
        <p>
            Has been established&nbsp<a href="/timeline" id="siteBuildingTime"></a>&nbspDays，<a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank" rel="licence">Based on Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0)</a><br>
            ©2017-<span id="cpYear"></span> Based on&nbsp<a href="http://hexo.io" target="_blank" rel="nofollow">Hexo</a>
            ，Theme by&nbsp&nbsp<a href="https://github.com/tangkunyin/hexo-theme-jsimple" target="_blank" rel="bookmark">JSimple</a>
            ，Author&nbsp<a href="https://louishsu.xyz/" target="_blank" rel="friend">徐耀彬</a>
            ，Hosted by <a href="https://pages.github.com/" target="_blank" rel="nofollow">GitHub Pages</a>
        </p>
    </div>
</footer>
<script src="/js/SimpleCore.js"></script>

</div>
<!-- search pop -->
<div class="popup search-popup local-search-popup">
    <div class="local-search-header clearfix">
        <span class="search-icon">
            <i class="fa fa-search"></i>
        </span>
        <span class="popup-btn-close">
            <i class="fa fa-times-circle"></i>
        </span>
        <div class="local-search-input-wrapper">
            <input id="local-search-input" spellcheck="false" type="text" autocomplete="off" placeholder="Input query keywords here...">
        </div>
    </div>
    <div id="local-search-result"></div>
</div>
<div class="fixed-btn">
    <a class="btn-gotop" href="javascript:"> <i class="fa fa-angle-up"></i></a>
</div>
<script>
    $(function () {
        var jsi_config = {
            buildingTime: '10/20/2018',
            current: $('.post-tags').length > 0 ? 'post' : 'archive',
            snsQRCode: '/images/sns-qrcode.png',
            donateImg: '/images/donate-qr.png',
            localSearch: { dbPath: '' },
            readMode: 'day'
        };
        
            jsi_config.localSearch = {
                dbPath: '/search.json',
                trigger: 'auto',
                topN: '1',
                unescape: 'false'
            }
        
        SimpleCore.init(jsi_config);
        
    });
</script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</body>
</html>
