<h1 id="Contents"><a href="#Contents" class="headerlink" title="Contents"></a>Contents</h1><ul>
<li><a href="#contents">Contents</a></li>
<li><a href="#introduction-of-dataset">Introduction of Dataset</a></li>
<li><a href="#introduction-of-methods">Introduction of Methods</a><ul>
<li><a href="#eigenface">Eigenface</a></li>
<li><a href="#fisherface">Fisherface</a></li>
</ul>
</li>
<li><a href="#implementation">Implementation</a><ul>
<li><a href="#import-modules">Import modules</a></li>
<li><a href="#pca">PCA</a></li>
<li><a href="#lda">LDA</a></li>
<li><a href="#functions">Functions</a></li>
</ul>
</li>
<li><a href="#experiments">Experiments</a><ul>
<li><a href="#load-data">Load data</a></li>
<li><a href="#eigenface-1">Eigenface</a></li>
<li><a href="#fisherface-1">Fisherface</a></li>
</ul>
</li>
<li><p><a href="#reference">Reference</a></p>
</li>
<li><p><a href="#Implementation">Implementation</a></p>
<ul>
<li><a href="#Import-modules">Import modules</a></li>
<li><a href="#PCA">PCA</a></li>
<li><a href="#LDA">LDA</a></li>
<li><a href="#Functions">Functions</a></li>
</ul>
</li>
<li><a href="#Experiment">Experiment</a></li>
</ul>
<h1 id="Introduction-of-Dataset"><a href="#Introduction-of-Dataset" class="headerlink" title="Introduction of Dataset"></a>Introduction of Dataset</h1><p><a href="https://www.cl.cam.ac.uk/research/dtg/attarchive/facedatabase.html">The ORL Database of Faces</a> contains a set of face images taken between April 1992 and April 1994 at the lab. The database was used in the context of a face recognition project carried out in collaboration with the Speech, Vision and Robotics Group of the Cambridge University Engineering Department.</p>
<p>There are ten different images of each of 40 distinct subjects. For some subjects, the images were taken at different times, varying the lighting, facial expressions (open / closed eyes, smiling / not smiling) and facial details (glasses / no glasses). All the images were taken against a dark homogeneous background with the subjects in an upright, frontal position (with tolerance for some side movement). </p>
<p>The files are in PGM format, and can conveniently be viewed on UNIX (TM) systems using the ‘xv’ program. The size of each image is 92x112 pixels, with 256 grey levels per pixel. The images are organised in 40 directories (one for each subject), which have names of the form sX, where X indicates the subject number (between 1 and 40). In each of these directories, there are ten different images of that subject, which have names of the form Y.pgm, where Y is the image number for that subject (between 1 and 10).</p>
<p>The database can be retrieved from <a href="http://www.cl.cam.ac.uk/Research/DTG/attarchive:pub/data/att_faces.tar.Z">http://www.cl.cam.ac.uk/Research/DTG/attarchive:pub/data/att_faces.tar.Z</a> as a 4.5Mbyte compressed tar file or from <a href="http://www.cl.cam.ac.uk/Research/DTG/attarchive:pub/data/att_faces.zip">http://www.cl.cam.ac.uk/Research/DTG/attarchive:pub/data/att_faces.zip</a> as a ZIP file of similar size.</p>
<p>The ORL database comes in such a hierarchy</p>
<pre><code>att_faces
├─ README
├─ s1
│  ├─ 1.pgm
│  ...
│  └─ 10.pgm
├─ s2
│  ├─ 1.pgm
│  ...
│  └─ 10.pgm
...
└─ s40
   ├─ 1.pgm
   ...
   └─ 10.pgm
</code></pre><p>A preview image of the Database of Faces is as follows<br><img src="attachment:faces.gif" alt="faces.gif"></p>
<h1 id="Introduction-of-Methods"><a href="#Introduction-of-Methods" class="headerlink" title="Introduction of Methods"></a>Introduction of Methods</h1><h2 id="Eigenface"><a href="#Eigenface" class="headerlink" title="Eigenface"></a>Eigenface</h2><p>The Eigenface approach began with a search for a low-dimensional representation of face images. Sirovich and Kirby (1987) showed that principal component analysis could be used on a collection of face images to form a set of basis features. These basis images, known as eigenpictures, could be linearly combined to reconstruct images in the original training set.</p>
<p>A set of eigenfaces can be generated by performing PCA on a large set of images depicting defferent human faces. Informally, eigenfaces can be considered a set of “standardized face ingredients”, derived from statistical analysis of many pictures of faces. Any human face can be considered to be a combination of these standard faces.</p>
<p>Prepare a data set of face images. The images should have been resampled to a common pixel resolution $(H, W)$. Each image is treated as a vector $x^{(i)}$ by concatenating the rows of pixels, resulting in a single column with $H \times W$ elements. And all images of the data set are stored in a single matrix $X$</p>
<script type="math/tex; mode=display">X_{N \times (H \times W)} = \left[ \begin{matrix} x^{(1)} & x^{(2)} & \cdots  & x^{(N)} \end{matrix} \right]</script><p>Perform PCA on the matrix $X$</p>
<ol>
<li><p>Compute the mean $\mu$</p>
<script type="math/tex; mode=display">\mu = \frac{1}{N} \sum_{i=1}^{N} x^{(i)}</script></li>
<li><p>Compute the convariance matrix $C$</p>
<script type="math/tex; mode=display">C = \frac{1}{N} XX^T</script></li>
<li><p>Perform Eigen-Decomposition on matrix $C$</p>
<script type="math/tex; mode=display">C v_i = \lambda_i v_i</script></li>
</ol>
<p>Sort the eigenvalues in desending order and arrange eigenvectors accordingly. Then choose a subset of the eigenvectors, i.e. principal components, as Eigenfaces. </p>
<script type="math/tex; mode=display">E_{K \times (H \times W)} = \left[ \begin{matrix} v^{(1)} & v^{(2)} & \cdots  & v^{(K)} \end{matrix} \right]</script><p>These eigenfaces can be used to represent both existing and new faces. For instance, a new vector $x$ can be projected on the Eigenfaces</p>
<script type="math/tex; mode=display">x = E \cdot w</script><p>where</p>
<script type="math/tex; mode=display">w = \left[ \begin{matrix} w_1 & w_2 & \cdots  & w_K \end{matrix} \right]^T</script><p>Elements in the vector $w$ are the scalar multipliers which can be used to characterize the new face.</p>
<p>Notice that the images are sized $(H \times W)$ pixels. The PCA solves the convariance matrix $C = XX^T$, which is a matrix of size $(H \times W) \times (H \times W)$. Performing ED on the matrix $C$ is not feasible, so some trick will be apply.. </p>
<p>It’s possible to perform ED on matrix $X^TX$</p>
<script type="math/tex; mode=display">X^TX u_i = \lambda_i u_i</script><p>So</p>
<script type="math/tex; mode=display">X X^T (X u_i) = \lambda_i (X u_i)</script><p>which means $(\lambda_i, X u_i)$ is the eigenpair of matrix $X X^T$.</p>
<script type="math/tex; mode=display">v_i = X u_i</script><p>The Eigenfaces can be visualized when reshaped into the resolution $(H, W)$ .</p>
<h2 id="Fisherface"><a href="#Fisherface" class="headerlink" title="Fisherface"></a>Fisherface</h2><p>Fisherfaces can be generated by performing LDA, which was invented by Sir R.A.Fisher. The idea of LDA is simple: same classes should cluster tightly together, while different classes are far away as possible from each other. This was recognized by Belhumeur, Hespanha and Kriegman and so they applied a Discriminant Analysis to face recognition.</p>
<p>Similarly, theimages of a data set are stored in a single matrix $X$</p>
<script type="math/tex; mode=display">X_{N \times (H \times W)} = \left[ \begin{matrix} x^{(1)} & x^{(2)} & \cdots  & x^{(N)} \end{matrix} \right]</script><p>The scatter matrices $S_W$ and $S_B$ are calculated as:</p>
<script type="math/tex; mode=display">S_W = \frac{1}{N} \sum_{j=1}^{C} \sum_{i=1}^{N_j} (x^{(i)} - \mu_j) (x^{(i)} - \mu_j)^T</script><script type="math/tex; mode=display">S_B = \sum_{j=1}^C \frac{N_j}{N} (\mu_j - \mu) (\mu_j - \mu)^T</script><p>where </p>
<ul>
<li>$C$ is the number of classes;</li>
<li>$N_j$ is the number of samples belonging to class $j$;</li>
<li><p>$\mu$ is the center of all samples, $\mu_j$ is the center of class $j$;</p>
<script type="math/tex; mode=display">\mu = \frac{1}{N} \sum_{i=1}^N x^{(i)}</script><script type="math/tex; mode=display">\mu_j = \frac{1}{N_j} \sum_{i=1}^N x^{(i)}, x^{(i)} \in C_j</script></li>
</ul>
<p>Perform Eigen-Decomposition on matrix $S_W^{-1} S_B$</p>
<script type="math/tex; mode=display">S_W^{-1} S_B v_i = \lambda_i v_i</script><p>Sort the eigenvalues in desending order and arrange eigenvectors accordingly. Then choose a subset of the eigenvectors as Fisherfaces. </p>
<script type="math/tex; mode=display">F_{K \times (H \times W)} = \left[ \begin{matrix} v^{(1)} & v^{(2)} & \cdots  & v^{(K)} \end{matrix} \right]</script><p>However, when performing ED on matrix $S_W^{-1} S_B$ using <code>numpy.linalg.eig()</code>, complex numbers are contained in eigenvalues and eigenvectors. So there are some tricks.</p>
<p>$S_W$ is a real symmetric matrix, which can be performed ED using <code>numpy.linalg.eigh()</code>:</p>
<script type="math/tex; mode=display">S_W = U \Lambda U^T</script><p>So</p>
<script type="math/tex; mode=display">S_W^{-1} S_B = (U \Lambda^{-1} U^T) S_B = (U \Lambda^{-\frac{1}{2}} \Lambda^{-\frac{1}{2}} U^T) S_B (U \Lambda^{-\frac{1}{2}} \Lambda^{\frac{1}{2}} U^T)</script><p>Substituting $S_W^{-1} S_B$ into the equation $S_W^{-1} S_B v_i = \lambda_i v_i$ gives:</p>
<script type="math/tex; mode=display">\Lambda^{-\frac{1}{2}} U^T S_B U \Lambda^{-\frac{1}{2}} (\Lambda^{\frac{1}{2}} U^T v_i) = \lambda_i (\Lambda^{\frac{1}{2}} U^T v_i)</script><p>which means $(\lambda_i, \Lambda^{\frac{1}{2}} U^T v_i)$ is the eigenpair of matrix $\Lambda^{-\frac{1}{2}} U^T S_B U \Lambda^{-\frac{1}{2}}$</p>
<p>Notice that $\Lambda^{-\frac{1}{2}} U^T S_B U \Lambda^{-\frac{1}{2}}$ is a real symmetric matrix, so it can be decomposed using <code>numpy.linalg.eigh()</code>:</p>
<script type="math/tex; mode=display">\Lambda^{-\frac{1}{2}} U^T S_B U \Lambda^{-\frac{1}{2}} = P \Lambda P^T</script><p>where</p>
<script type="math/tex; mode=display">P = \left[ \begin{matrix} \alpha^{(1)} & \alpha^{(2)} & \cdots \end{matrix} \right]</script><p>So</p>
<script type="math/tex; mode=display">\alpha_i = \Lambda^{\frac{1}{2}} U^T v_i \Rightarrow v_i = U \Lambda^{-\frac{1}{2}} \alpha_i</script><h1 id="Implementation"><a href="#Implementation" class="headerlink" title="Implementation"></a>Implementation</h1><h2 id="Import-modules"><a href="#Import-modules" class="headerlink" title="Import modules"></a>Import modules</h2><pre><code class="lang-python">import os
import cv2
import numpy as np
from matplotlib import pyplot as plt
</code></pre>
<h2 id="PCA"><a href="#PCA" class="headerlink" title="PCA"></a>PCA</h2><pre><code class="lang-python">class PCA():
    &quot;&quot;&quot; Principal Components Analysis

    Attributes:
        components_: {ndarray(n_components, n_features)}
        means_:      {ndarray(n_components)}
    &quot;&quot;&quot;

    def __init__(self, n_components):

        self.n_components = n_components
        self.components_  = None
        self.means_       = None

    def fit(self, X):
        &#39;&#39;&#39; train the model
        Params:
            X: {ndarray(n_samples, n_features)}
        &#39;&#39;&#39;
        n_samples, n_features = X.shape

        self.means_ = np.mean(X, axis=0)
        X_ = X - self.means_
        eigval, eigvec = None, None

        if n_samples &lt; n_features:
            eigval, u = np.linalg.eig(X_.dot(X_.T))
            eigvec = X_.T.dot(u).dot(np.diag(1 / eigval))
        else:
            covar_ = X_.T.dot(X_)
            eigval, eigvec = np.linalg.eig(covar_)

        order = np.argsort(eigval)[::-1]
        eigval = eigval[order]
        eigvec = eigvec.T[order].T

        self.components_ = eigvec[:, :self.n_components].T

    def transform(self, X):
        &quot;&quot;&quot;
        Params:
            X: {ndarray(n_samples, n_features)}
        Returns:
            X_:{ndarray(n_samples, n_components)}
        Notes:
            X&#39;_{nxk&#39;} · V_{kxk&#39;}^T = X&#39;&#39;_{nxk}
        &quot;&quot;&quot;
        X_ = X - self.means_
        X_ = X_.dot(self.components_.T)
        return X_

    def fit_transform(self, X):
        self.fit(X)
        return self.transform(X)

    def transform_inv(self, X):
        &quot;&quot;&quot; 
        Params:
            X: {ndarray(n_samples, n_components)}
        Returns:
            X_:{ndarray(n_samples, n_features)}
        &quot;&quot;&quot;
        X_ = X.dot(self.components_) + self.means_
        return X_
</code></pre>
<h2 id="LDA"><a href="#LDA" class="headerlink" title="LDA"></a>LDA</h2><pre><code class="lang-python">class LDA(object):
    &quot;&quot;&quot; 

    Attributes:
        n_components: {int}
        components_:  {ndarray(n_components, n_features)}
    &quot;&quot;&quot;

    def __init__(self, n_components=-1):
        self.n_components = n_components
        self.components_ = None

    def fit(self, X, y):
        &quot;&quot;&quot; train the model
        Params:
            X:      {ndarray(n_samples, n_features)}
            y:      {ndarray(n_samples)}
        &quot;&quot;&quot;
        labels = list(set(list(y)))
        n_class = len(labels)
        n_samples, n_feats = X.shape

        S_W = np.zeros(shape=(n_feats, n_feats))
        S_B = np.zeros(shape=(n_feats, n_feats))
        mean_ = np.mean(X, axis=0)
        for i_class in range(n_class):
            X_ = X[y==labels[i_class]]
            means_ = np.mean(X_, axis=0)

            X_ = X_ - means_
            means_ = (means_ - mean_).reshape(1, -1)

            S_W += (X_.T).dot(X_) * (1 / n_samples)
            S_B += (means_.T).dot(means_) * (X_.shape[0] / n_samples)

        s, u = np.linalg.eigh(S_W)
        s_sqrt = np.diag(np.sqrt(s))
        s_sqrt_inv = np.linalg.inv(s_sqrt)

        A = s_sqrt_inv.dot(u.T).dot(S_B).dot(u).dot(s_sqrt_inv)
        eigval, P = np.linalg.eigh(A)
        eigvec = u.dot(s_sqrt_inv).dot(P)

        order = np.argsort(eigval)[::-1]
        eigval = eigval[order]
        eigvec = eigvec[:, order]

        self.components_ = eigvec[:, :self.n_components].T

    def transform(self, X):
        &quot;&quot;&quot;
        Params:
            X:  {ndarray(n_samples, n_features)}
        Returns:
            X:  {ndarray(n_samples, n_components)}
        &quot;&quot;&quot;
        X_ = X.dot(self.components_.T)
        return X_

    def fit_transform(self, X, y):
        &quot;&quot;&quot;
        Params:
            X:  {ndarray(n_samples, n_features)}
        Returns:
            X:  {ndarray(n_samples, n_components)}
        &quot;&quot;&quot;
        self.fit(X, y)
        X_ = self.transform(X)
        return X_

    def transform_inv(self, X):
        &quot;&quot;&quot;
        Params:
            X:  {ndarray(n_samples, n_components)}
        Returns:
            X:  {ndarray(n_samples, n_features)}
        &quot;&quot;&quot;
        X_ = X.dot(self.components_)
        return X_
</code></pre>
<h2 id="Functions"><a href="#Functions" class="headerlink" title="Functions"></a>Functions</h2><pre><code class="lang-python">def load_ORL(dsize=None):
    &quot;&quot;&quot; Load ORL

    Params:
        dsize: {tuple(H, W)}
    Returns:
        images: {list[ndarray(H, W)]}
        labels: {list[int]}
    Notes:
        Download from https://www.cl.cam.ac.uk/research/dtg/attarchive/facedatabase.html
    &quot;&quot;&quot;
    DIR = &#39;att_faces&#39;
    SUBJECTS = 40; IMAGES = 10
    FILENAME = &#39;{}/s{}/{}.pgm&#39;

    images = []; labels = []

    for i in range(SUBJECTS):
        for j in range(IMAGES):
            filename = FILENAME.format(DIR, i + 1, j + 1)
            image = cv2.imread(filename, cv2.IMREAD_GRAYSCALE)
            if dsize is not None:
                image = cv2.resize(image, dsize[::-1])
            images += [image]
            labels += [i + 1]

    return images, labels
</code></pre>
<pre><code class="lang-python">def load(dsize=None):
    &quot;&quot;&quot; Concatenate images to vectors 

    Params:
        dsize: {tuple(H, W)}
    Returns:
        X: {ndarray(n_samples, n_features)}
        y: {ndarray(n_samples)}
    &quot;&quot;&quot;
    images, labels = load_ORL(dsize=dsize)

    X = np.concatenate(list(map(lambda x: x.reshape(-1)[np.newaxis], images)), axis=0) / 255.
    y = np.array(labels)

    return X, y
</code></pre>
<pre><code class="lang-python">def show_features(X, dsize, title=&quot;features&quot;):
    &quot;&quot;&quot; Show features

    Params:
        X: {ndarray(N, n_features)}
        dsize: {tuple(H, W)}
        title: {str}
    &quot;&quot;&quot;
    SUBPLOT = &quot;19{}&quot;

    plt.figure(figsize=(18, 2))
    plt.title(title)
    for i in range(9):
        plt.subplot(int(SUBPLOT.format(i+1)))
        plt.imshow(X[i].reshape(dsize), cmap=&quot;gray&quot;)
    plt.show()
</code></pre>
<h1 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h1><h2 id="Load-data"><a href="#Load-data" class="headerlink" title="Load data"></a>Load data</h2><pre><code class="lang-python">DSIZE = (112, 92)
X, y = load(DSIZE)
n_samples, n_features = X.shape
n_classes = len(set(y))
</code></pre>
<p>First 9 faces of subject 1 in the database are as follows.</p>
<pre><code class="lang-python">show_features(X[: 10], DSIZE, title=&quot;origin {}&quot;.format(repr(DSIZE)))
</code></pre>
<p><img src="output_25_0.png" alt="png"></p>
<p>Faces of first 9 subjects are as follows. </p>
<pre><code class="lang-python">show_features(X[::10], DSIZE, title=&quot;origin {}&quot;.format(repr(DSIZE)))
</code></pre>
<p><img src="output_27_0.png" alt="png"></p>
<h2 id="Eigenface-1"><a href="#Eigenface-1" class="headerlink" title="Eigenface"></a>Eigenface</h2><p>The first 9 components are as follows.</p>
<pre><code class="lang-python">pca = PCA(n_components=n_features)
pca.fit(X)
show_features(pca.components_, DSIZE, title=&quot;Eigenface {}&quot;.format(repr(DSIZE)))
</code></pre>
<p><img src="output_30_0.png" alt="png"></p>
<h2 id="Fisherface-1"><a href="#Fisherface-1" class="headerlink" title="Fisherface"></a>Fisherface</h2><p>In order to reduce the number of dimensions, we perform PCA on the origin data. Chooing different numbers of dimensions will result in differet outputs.</p>
<pre><code class="lang-python">n_decomposed = n_samples - n_classes - 1

for n_decomposed in range(199 , n_samples - n_classes, 40):
    pca = PCA(n_components=n_decomposed)
    X_decomposed = pca.fit_transform(X)

    lda = LDA(n_components=n_classes - 1)
    lda.fit(X_decomposed, y)

    components_ = pca.transform_inv(lda.components_)
    show_features(components_, DSIZE, title=&quot;Fisherface {} {}&quot;.format(repr(DSIZE), n_decomposed))
</code></pre>
<p><img src="output_33_0.png" alt="png"></p>
<p><img src="output_33_1.png" alt="png"></p>
<p><img src="output_33_2.png" alt="png"></p>
<p><img src="output_33_3.png" alt="png"></p>
<p><img src="output_33_4.png" alt="png"></p>
<h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol>
<li><a href="https://www.cl.cam.ac.uk/research/dtg/attarchive/facedatabase.html">The Database of Faces</a></li>
<li><a href="https://www.xuebuyuan.com/3231919.html">人脸识别之—-FisherFace - 学步园</a></li>
<li><a href="https://bytefish.de/pdf/facerec_python.pdf">Face Recognition with Python, by Philipp Wagner</a></li>
</ol>
