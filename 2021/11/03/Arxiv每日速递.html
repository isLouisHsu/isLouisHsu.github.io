<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Arxiv每日速递(2021-11-03) | LOUIS' BLOG</title><meta name="author" content="徐耀彬"><meta name="copyright" content="徐耀彬"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="本篇博文主要展示每日从Arxiv论文网站获取的最新论文列表，以计算机视觉、自然语言处理、机器学习、人工智能等大方向进行划分。 统计 今日共更新495篇论文，其中：  117篇计算机视觉（cs.CV） 50篇自然语言处理（cs.CL） 191篇机器学习（cs.LG） 108篇人工智能（cs.AI）  计算机视觉    1. 标题：When Does Contrastive Learning Pres">
<meta property="og:type" content="article">
<meta property="og:title" content="Arxiv每日速递(2021-11-03)">
<meta property="og:url" content="http://louishsu.xyz/2021/11/03/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html">
<meta property="og:site_name" content="LOUIS&#39; BLOG">
<meta property="og:description" content="本篇博文主要展示每日从Arxiv论文网站获取的最新论文列表，以计算机视觉、自然语言处理、机器学习、人工智能等大方向进行划分。 统计 今日共更新495篇论文，其中：  117篇计算机视觉（cs.CV） 50篇自然语言处理（cs.CL） 191篇机器学习（cs.LG） 108篇人工智能（cs.AI）  计算机视觉    1. 标题：When Does Contrastive Learning Pres">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png">
<meta property="article:published_time" content="2021-11-03T00:26:11.862Z">
<meta property="article:modified_time" content="2021-11-03T00:27:36.699Z">
<meta property="article:author" content="徐耀彬">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://louishsu.xyz/2021/11/03/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2021-11-03 08:27:36'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const fontSizeVal = saveToLocal.get('global-font-size')
    if (fontSizeVal !== undefined) {
      document.documentElement.style.setProperty('--global-font-size', fontSizeVal + 'px')
    }
    })(window)</script><link rel="stylesheet" href="/css/background.css"><script src="https://cdn.jsdelivr.net/npm/echarts@4.7.0/dist/echarts.min.js"></script><!-- hexo injector head_end start --><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Zfour/hexo-electric-clock@1.0.6/clock.css"><!-- hexo injector head_end end --><meta name="generator" content="Hexo 5.4.0"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="author-avatar"><img class="avatar-img" src="/img/touxiang.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">10</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">标签</div><div class="length-num">3</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">分类</div><div class="length-num">7</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/message/"><i class="fa-fw far fa-comment-dots"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa-fw fa fa-book"></i><span> 找文章</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></li><li><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></li><li><a class="site-page" href="/charts/"><i class="fa-fw fa fa-archive"></i><span> 统计</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-tools"></i><span> 工具</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/md_editor/"><i class="fa-fw fas fa-pen"></i><span> 在线markdown</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/isLouisHsu/blog/tree/master/source/_posts"><i class="fa-fw fa fa-star"></i><span> 在线push</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">LOUIS' BLOG</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/message/"><i class="fa-fw far fa-comment-dots"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa-fw fa fa-book"></i><span> 找文章</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></li><li><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></li><li><a class="site-page" href="/charts/"><i class="fa-fw fa fa-archive"></i><span> 统计</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-tools"></i><span> 工具</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/md_editor/"><i class="fa-fw fas fa-pen"></i><span> 在线markdown</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/isLouisHsu/blog/tree/master/source/_posts"><i class="fa-fw fa fa-star"></i><span> 在线push</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Arxiv每日速递(2021-11-03)<a class="post-edit-link" href="https://github.com/isLouisHsu/blog/tree/master/source_posts/Arxiv每日速递.md" title="编辑" target="_blank"><i class="fas fa-pencil-square"></i></a></h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2021-11-03T00:26:11.862Z" title="发表于 2021-11-03 08:26:11">2021-11-03</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2021-11-03T00:27:36.699Z" title="更新于 2021-11-03 08:27:36">2021-11-03</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">阅读笔记</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">30.2k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>181分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span><span class="post-meta-separator">|</span><span class="post-meta-commentcount"><i class="far fa-comments fa-fw post-meta-icon"></i><span class="post-meta-label">评论数:</span><a href="/2021/11/03/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html#post-comment"><span id="twikoo-count"></span></a></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><p>本篇博文主要展示每日从Arxiv论文网站获取的最新论文列表，以计算机视觉、自然语言处理、机器学习、人工智能等大方向进行划分。</p>
<h1>统计</h1>
<p>今日共更新495篇论文，其中：</p>
<ul>
<li>117篇计算机视觉（<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>）</li>
<li>50篇自然语言处理（<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>）</li>
<li>191篇机器学习（cs.LG）</li>
<li>108篇人工智能（<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>）</li>
</ul>
<h1>计算机视觉</h1>
<details>
  <summary>1. <b>标题：When Does Contrastive Learning Preserve Adversarial Robustness from  Pretraining to Finetuning?</b></summary>
  <p><b>编号</b>：[1]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.01124</p>
  <p><b>作者</b>：Lijie Fan,  Sijia Liu,  Pin-Yu Chen,  Gaoyuan Zhang,  Chuang Gan</p>
  <p><b>备注</b>：NeurIPS 2021. Code is available at this https URL</p>
  <p><b>关键词</b>：supervised robust learning methods across multiple datasets, task robustness transferability without loss, helps preserve robustness without forgetting, novel adversarial contrastive pretraining framework, task robustness transferability '.</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Contrastive learning (CL) can learn generalizable feature representations and
achieve the state-of-the-art performance of downstream tasks by finetuning a
linear classifier on top of it. However, as adversarial robustness becomes
vital in image classification, it remains unclear whether or not CL is able to
preserve robustness to downstream tasks. The main challenge is that in the
self-supervised pretraining + supervised finetuning paradigm, adversarial
robustness is easily forgotten due to a learning task mismatch from pretraining
to finetuning. We call such a challenge 'cross-task robustness
transferability'. To address the above problem, in this paper we revisit and
advance CL principles through the lens of robustness enhancement. We show that
(1) the design of contrastive views matters: High-frequency components of
images are beneficial to improving model robustness; (2) Augmenting CL with
pseudo-supervision stimulus (e.g., resorting to feature clustering) helps
preserve robustness without forgetting. Equipped with our new designs, we
propose AdvCL, a novel adversarial contrastive pretraining framework. We show
that AdvCL is able to enhance cross-task robustness transferability without
loss of model accuracy and finetuning efficiency. With a thorough experimental
study, we demonstrate that AdvCL outperforms the state-of-the-art
self-supervised robust learning methods across multiple datasets (CIFAR-10,
CIFAR-100, and STL-10) and finetuning schemes (linear evaluation and full model
finetuning).</p>
  </details>
</details>
<details>
  <summary>2. <b>标题：Rebooting ACGAN: Auxiliary Classifier GANs with Stable Training</b></summary>
  <p><b>编号</b>：[3]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.01118</p>
  <p><b>作者</b>：Minguk Kang,  Woohyeon Shim,  Minsu Cho,  Jaesik Park</p>
  <p><b>备注</b>：34 pages, 26 figures, 35th Conference on Neural Information Processing Systems (NeurIPS 2021)</p>
  <p><b>关键词</b>：rebooted auxiliary classifier generative adversarial network, conditional generative adversarial networks, projecting input vectors onto, generate easily classifiable samples, auxiliary classifier gan</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Conditional Generative Adversarial Networks (cGAN) generate realistic images
by incorporating class information into GAN. While one of the most popular
cGANs is an auxiliary classifier GAN with softmax cross-entropy loss (ACGAN),
it is widely known that training ACGAN is challenging as the number of classes
in the dataset increases. ACGAN also tends to generate easily classifiable
samples with a lack of diversity. In this paper, we introduce two cures for
ACGAN. First, we identify that gradient exploding in the classifier can cause
an undesirable collapse in early training, and projecting input vectors onto a
unit hypersphere can resolve the problem. Second, we propose the Data-to-Data
Cross-Entropy loss (D2D-CE) to exploit relational information in the
class-labeled dataset. On this foundation, we propose the Rebooted Auxiliary
Classifier Generative Adversarial Network (ReACGAN). The experimental results
show that ReACGAN achieves state-of-the-art generation results on CIFAR10,
Tiny-ImageNet, CUB200, and ImageNet datasets. We also verify that ReACGAN
benefits from differentiable augmentations and that D2D-CE harmonizes with
StyleGAN2 architecture. Model weights and a software package that provides
implementations of representative cGANs and all experiments in our paper are
available at this https URL.</p>
  </details>
</details>
<details>
  <summary>3. <b>标题：FREGAN : an application of generative adversarial networks in enhancing  the frame rate of videos</b></summary>
  <p><b>编号</b>：[5]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.01105</p>
  <p><b>作者</b>：Rishik Mishra,  Neeraj Gupta,  Nitya Shukla</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：frame rate enhancement generative adversarial network, high refresh rate, high refresh rate, frame rate enhancement, structural similarity index</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A digital video is a collection of individual frames, while streaming the
video the scene utilized the time slice for each frame. High refresh rate and
high frame rate is the demand of all high technology applications. The action
tracking in videos becomes easier and motion becomes smoother in gaming
applications due to the high refresh rate. It provides a faster response
because of less time in between each frame that is displayed on the screen.
FREGAN (Frame Rate Enhancement Generative Adversarial Network) model has been
proposed, which predicts future frames of a video sequence based on a sequence
of past frames. In this paper, we investigated the GAN model and proposed
FREGAN for the enhancement of frame rate in videos. We have utilized Huber loss
as a loss function in the proposed FREGAN. It provided excellent results in
super-resolution and we have tried to reciprocate that performance in the
application of frame rate enhancement. We have validated the effectiveness of
the proposed model on the standard datasets (UCF101 and RFree500). The
experimental outcomes illustrate that the proposed model has a Peak
signal-to-noise ratio (PSNR) of 34.94 and a Structural Similarity Index (SSIM)
of 0.95.</p>
  </details>
</details>
<details>
  <summary>4. <b>标题：FaceScape: 3D Facial Dataset and Benchmark for Single-View 3D Face  Reconstruction</b></summary>
  <p><b>编号</b>：[13]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.01082</p>
  <p><b>作者</b>：Hao Zhu,  Haotian Yang,  Longwei Guo,  Yidi Zhang,  Yanru Wang,  Mingkai Huang,  Qiu Shen,  Ruigang Yang,  Xun Cao</p>
  <p><b>备注</b>：14 pages, 13 figures, journal extension of FaceScape(CVPR 2020). arXiv admin note: substantial text overlap with arXiv:2003.13989</p>
  <p><b>关键词</b>：predict elaborate riggable 3d face models, scale detailed 3d face dataset, 3d face prediction system, 760 textured 3d faces, fine 3d facial models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we present a large-scale detailed 3D face dataset, FaceScape,
and the corresponding benchmark to evaluate single-view facial 3D
reconstruction. By training on FaceScape data, a novel algorithm is proposed to
predict elaborate riggable 3D face models from a single image input. FaceScape
dataset provides 18,760 textured 3D faces, captured from 938 subjects and each
with 20 specific expressions. The 3D models contain the pore-level facial
geometry that is also processed to be topologically uniformed. These fine 3D
facial models can be represented as a 3D morphable model for rough shapes and
displacement maps for detailed geometry. Taking advantage of the large-scale
and high-accuracy dataset, a novel algorithm is further proposed to learn the
expression-specific dynamic details using a deep neural network. The learned
relationship serves as the foundation of our 3D face prediction system from a
single image input. Different than the previous methods, our predicted 3D
models are riggable with highly detailed geometry under different expressions.
We also use FaceScape data to generate the in-the-wild and in-the-lab benchmark
to evaluate recent methods of single-view face reconstruction. The accuracy is
reported and analyzed on the dimensions of camera pose and focal length, which
provides a faithful and comprehensive evaluation and reveals new challenges.
The unprecedented dataset, benchmark, and code have been released to the public
for research purpose.</p>
  </details>
</details>
<details>
  <summary>5. <b>标题：OctField: Hierarchical Implicit Functions for 3D Modeling</b></summary>
  <p><b>编号</b>：[19]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.01067</p>
  <p><b>作者</b>：Jia-Heng Tang,  Weikai Chen,  Jie Yang,  Bo Wang,  Songrun Liu,  Bo Yang,  Lin Gao</p>
  <p><b>备注</b>：13 pages, 9 figures, NeurIPS 2021</p>
  <p><b>关键词</b>：distributes local implicit functions around, enabled neural implicit representation, learnable hierarchical implicit representation, prohibitive computational cost even, memory footprint grows cubically</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent advances in localized implicit functions have enabled neural implicit
representation to be scalable to large scenes. However, the regular subdivision
of 3D space employed by these approaches fails to take into account the
sparsity of the surface occupancy and the varying granularities of geometric
details. As a result, its memory footprint grows cubically with the input
volume, leading to a prohibitive computational cost even at a moderately dense
decomposition. In this work, we present a learnable hierarchical implicit
representation for 3D surfaces, coded OctField, that allows high-precision
encoding of intricate surfaces with low memory and computational budget. The
key to our approach is an adaptive decomposition of 3D scenes that only
distributes local implicit functions around the surface of interest. We achieve
this goal by introducing a hierarchical octree structure to adaptively
subdivide the 3D space according to the surface occupancy and the richness of
part geometry. As octree is discrete and non-differentiable, we further propose
a novel hierarchical network that models the subdivision of octree cells as a
probabilistic process and recursively encodes and decodes both octree structure
and surface geometry in a differentiable manner. We demonstrate the value of
OctField for a range of shape modeling and reconstruction tasks, showing
superiority over alternative approaches.</p>
  </details>
</details>
<details>
  <summary>6. <b>标题：MOST-GAN: 3D Morphable StyleGAN for Disentangled Face Image Manipulation</b></summary>
  <p><b>编号</b>：[22]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.01048</p>
  <p><b>作者</b>：Safa C. Medin,  Bernhard Egger,  Anoop Cherian,  Ye Wang,  Joshua B. Tenenbaum,  Xiaoming Liu,  Tim K. Marks</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：art 2d hair manipulation network, generate strikingly photorealistic face images, nonlinear 3d morphable models, gan achieves photorealistic manipulation, priori models physical attributes</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent advances in generative adversarial networks (GANs) have led to
remarkable achievements in face image synthesis. While methods that use
style-based GANs can generate strikingly photorealistic face images, it is
often difficult to control the characteristics of the generated faces in a
meaningful and disentangled way. Prior approaches aim to achieve such semantic
control and disentanglement within the latent space of a previously trained
GAN. In contrast, we propose a framework that a priori models physical
attributes of the face such as 3D shape, albedo, pose, and lighting explicitly,
thus providing disentanglement by design. Our method, MOST-GAN, integrates the
expressive power and photorealism of style-based GANs with the physical
disentanglement and flexibility of nonlinear 3D morphable models, which we
couple with a state-of-the-art 2D hair manipulation network. MOST-GAN achieves
photorealistic manipulation of portrait images with fully disentangled 3D
control over their physical attributes, enabling extreme manipulation of
lighting, facial expression, and pose variations up to full profile view.</p>
  </details>
</details>
<details>
  <summary>7. <b>标题：A Unified View of cGANs with and without Classifiers</b></summary>
  <p><b>编号</b>：[25]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.01035</p>
  <p><b>作者</b>：Si-An Chen,  Chun-Liang Li,  Hsuan-Tien Lin</p>
  <p><b>备注</b>：Accepted by NeurIPS 2021</p>
  <p><b>关键词</b>：explains several popular cgan variants, help eliminate samples generated, conditional generative adversarial networks, proposed framework outperforms state, one popular design</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Conditional Generative Adversarial Networks (cGANs) are implicit generative
models which allow to sample from class-conditional distributions. Existing
cGANs are based on a wide range of different discriminator designs and training
objectives. One popular design in earlier works is to include a classifier
during training with the assumption that good classifiers can help eliminate
samples generated with wrong classes. Nevertheless, including classifiers in
cGANs often comes with a side effect of only generating easy-to-classify
samples. Recently, some representative cGANs avoid the shortcoming and reach
state-of-the-art performance without having classifiers. Somehow it remains
unanswered whether the classifiers can be resurrected to design better cGANs.
In this work, we demonstrate that classifiers can be properly leveraged to
improve cGANs. We start by using the decomposition of the joint probability
distribution to connect the goals of cGANs and classification as a unified
framework. The framework, along with a classic energy model to parameterize
distributions, justifies the use of classifiers for cGANs in a principled
manner. It explains several popular cGAN variants, such as ACGAN, ProjGAN, and
ContraGAN, as special cases with different levels of approximations, which
provides a unified view and brings new insights to understanding cGANs.
Experimental results demonstrate that the design inspired by the proposed
framework outperforms state-of-the-art cGANs on multiple benchmark datasets,
especially on the most challenging ImageNet. The code is available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>8. <b>标题：Render In-between: Motion Guided Video Synthesis for Action  Interpolation</b></summary>
  <p><b>编号</b>：[26]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.01029</p>
  <p><b>作者</b>：Hsuan-I Ho,  Xu Chen,  Jie Song,  Otmar Hilliges</p>
  <p><b>备注</b>：12 pages</p>
  <p><b>关键词</b>：many potential applications ranging, interesting yet challenging task, art video interpolation techniques, producing realistic human motion, unpaired human motion data</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Upsampling videos of human activity is an interesting yet challenging task
with many potential applications ranging from gaming to entertainment and
sports broadcasting. The main difficulty in synthesizing video frames in this
setting stems from the highly complex and non-linear nature of human motion and
the complex appearance and texture of the body. We propose to address these
issues in a motion-guided frame-upsampling framework that is capable of
producing realistic human motion and appearance. A novel motion model is
trained to inference the non-linear skeletal motion between frames by
leveraging a large-scale motion-capture dataset (AMASS). The high-frame-rate
pose predictions are then used by a neural rendering pipeline to produce the
full-frame output, taking the pose and background consistency into
consideration. Our pipeline only requires low-frame-rate videos and unpaired
human motion data but does not require high-frame-rate videos for training.
Furthermore, we contribute the first evaluation dataset that consists of
high-quality and high-frame-rate videos of human activities for this task.
Compared with state-of-the-art video interpolation techniques, our method
produces in-between frames with better quality and accuracy, which is evident
by state-of-the-art results on pixel-level, distributional metrics and
comparative user evaluations. Our code and the collected dataset are available
at this https URL.</p>
  </details>
</details>
<details>
  <summary>9. <b>标题：Introspective Distillation for Robust Question Answering</b></summary>
  <p><b>编号</b>：[28]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.01026</p>
  <p><b>作者</b>：Yulei Niu,  Hanwang Zhang</p>
  <p><b>备注</b>：Accepted by NeurIPS 2021</p>
  <p><b>关键词</b>：novel debiasing method called introspective distillation, even achieving better id performance compared, recent debiasing methods achieve good, reading comprehension dataset squad demonstrate, visual qa datasets vqa v2</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Question answering (QA) models are well-known to exploit data bias, e.g., the
language prior in visual QA and the position bias in reading comprehension.
Recent debiasing methods achieve good out-of-distribution (OOD)
generalizability with a considerable sacrifice of the in-distribution (ID)
performance. Therefore, they are only applicable in domains where the test
distribution is known in advance. In this paper, we present a novel debiasing
method called Introspective Distillation (IntroD) to make the best of both
worlds for QA. Our key technical contribution is to blend the inductive bias of
OOD and ID by introspecting whether a training sample fits in the factual ID
world or the counterfactual OOD one. Experiments on visual QA datasets VQA v2,
VQA-CP, and reading comprehension dataset SQuAD demonstrate that our proposed
IntroD maintains the competitive OOD performance compared to other debiasing
methods, while sacrificing little or even achieving better ID performance
compared to the non-debiasing ones.</p>
  </details>
</details>
<details>
  <summary>10. <b>标题：With a Little Help from my Temporal Context: Multimodal Egocentric  Action Recognition</b></summary>
  <p><b>编号</b>：[29]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.01024</p>
  <p><b>作者</b>：Evangelos Kazakos,  Jaesung Huh,  Arsha Nagrani,  Andrew Zisserman,  Dima Damen</p>
  <p><b>备注</b>：Accepted at BMVC 2021</p>
  <p><b>关键词</b>：explicit language model providing action sequence context, egtea datasets reporting state, incorporating audio input modality, based multimodal model, utilising temporal context</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In egocentric videos, actions occur in quick succession. We capitalise on the
action's temporal context and propose a method that learns to attend to
surrounding actions in order to improve recognition performance. To incorporate
the temporal context, we propose a transformer-based multimodal model that
ingests video and audio as input modalities, with an explicit language model
providing action sequence context to enhance the predictions. We test our
approach on EPIC-KITCHENS and EGTEA datasets reporting state-of-the-art
performance. Our ablations showcase the advantage of utilising temporal context
as well as incorporating audio input modality and language model to rescore
predictions. Code and models at: this https URL.</p>
  </details>
</details>
<details>
  <summary>11. <b>标题：Projected GANs Converge Faster</b></summary>
  <p><b>编号</b>：[36]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.01007</p>
  <p><b>作者</b>：Axel Sauer,  Kashyap Chitta,  Jens Müller,  Andreas Geiger</p>
  <p><b>备注</b>：To appear in NeurIPS 2021. Project Page: this https URL</p>
  <p><b>关键词</b>：discriminator cannot fully exploit features, projected gan improves image quality, mixes features across channels, art fréchet inception distance, two benchmark datasets</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Generative Adversarial Networks (GANs) produce high-quality images but are
challenging to train. They need careful regularization, vast amounts of
compute, and expensive hyper-parameter sweeps. We make significant headway on
these issues by projecting generated and real samples into a fixed, pretrained
feature space. Motivated by the finding that the discriminator cannot fully
exploit features from deeper layers of the pretrained model, we propose a more
effective strategy that mixes features across channels and resolutions. Our
Projected GAN improves image quality, sample efficiency, and convergence speed.
It is further compatible with resolutions of up to one Megapixel and advances
the state-of-the-art Fréchet Inception Distance (FID) on twenty-two benchmark
datasets. Importantly, Projected GANs match the previously lowest FIDs up to 40
times faster, cutting the wall-clock time from 5 days to less than 3 hours
given the same computational resources.</p>
  </details>
</details>
<details>
  <summary>12. <b>标题：Improving Contrastive Learning on Imbalanced Seed Data via Open-World  Sampling</b></summary>
  <p><b>编号</b>：[37]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.01004</p>
  <p><b>作者</b>：Ziyu Jiang,  Tianlong Chen,  Ting Chen,  Zhangyang Wang</p>
  <p><b>备注</b>：Neurips 2021</p>
  <p><b>关键词</b>：world unlabeled data sampling framework called model, evaluated via linear classifier evaluation, world unlabeled data usually follows, follows three simple principles, empirical contrastive loss expectation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Contrastive learning approaches have achieved great success in learning
visual representations with few labels of the target classes. That implies a
tantalizing possibility of scaling them up beyond a curated "seed" benchmark,
to incorporating more unlabeled images from the internet-scale external sources
to enhance its performance. However, in practice, larger amount of unlabeled
data will require more computing resources due to the bigger model size and
longer training needed. Moreover, open-world unlabeled data usually follows an
implicit long-tail class or attribute distribution, many of which also do not
belong to the target classes. Blindly leveraging all unlabeled data hence can
lead to the data imbalance as well as distraction issues. This motivates us to
seek a principled approach to strategically select unlabeled data from an
external source, in order to learn generalizable, balanced and diverse
representations for relevant classes. In this work, we present an open-world
unlabeled data sampling framework called Model-Aware K-center (MAK), which
follows three simple principles: (1) tailness, which encourages sampling of
examples from tail classes, by sorting the empirical contrastive loss
expectation (ECLE) of samples over random data augmentations; (2) proximity,
which rejects the out-of-distribution outliers that may distract training; and
(3) diversity, which ensures diversity in the set of sampled examples.
Empirically, using ImageNet-100-LT (without labels) as the seed dataset and two
"noisy" external data sources, we demonstrate that MAK can consistently improve
both the overall representation quality and the class balancedness of the
learned features, as evaluated via linear classifier evaluation on full-shot
and few-shot settings. The code is available at:
\url{this https URL</p>
  </details>
</details>
<details>
  <summary>13. <b>标题：Sign-to-Speech Model for Sign Language Understanding: A Case Study of  Nigerian Sign Language</b></summary>
  <p><b>编号</b>：[39]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00995</p>
  <p><b>作者</b>：Steven Kolawole,  Opeyemi Osakuade,  Nayan Saxena,  Babatunde Kazeem Olorisade</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：achieves impressive results converting sign words, two different object detection models, employed diverse evaluation metrics, predicted sign texts, gauge model performance</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Through this paper, we seek to reduce the communication barrier between the
hearing-impaired community and the larger society who are usually not familiar
with sign language in the sub-Saharan region of Africa with the largest
occurrences of hearing disability cases, while using Nigeria as a case study.
The dataset is a pioneer dataset for the Nigerian Sign Language and was created
in collaboration with relevant stakeholders. We pre-processed the data in
readiness for two different object detection models and a classification model
and employed diverse evaluation metrics to gauge model performance on
sign-language to text conversion tasks. Finally, we convert the predicted sign
texts to speech and deploy the best performing model in a lightweight
application that works in real-time and achieves impressive results converting
sign words/phrases to text and subsequently, into speech.</p>
  </details>
</details>
<details>
  <summary>14. <b>标题：Egocentric Human Trajectory Forecasting with a Wearable Camera and  Multi-Modal Fusion</b></summary>
  <p><b>编号</b>：[40]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00993</p>
  <p><b>作者</b>：Jianing Qiu,  Lipeng Chen,  Xiao Gu,  Frank P.-W. Lo,  Ya-Yen Tsai,  Jiankai Sun,  Jiaqi Liu,  Benny Lo</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：novel egocentric human trajectory forecasting dataset, different camera wearers walking around, utilize three different modalities, egocentric human trajectory forecasting, decoder neural network model</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we address the problem of forecasting the trajectory of an
egocentric camera wearer (ego-person) in crowded spaces. The trajectory
forecasting ability learned from the data of different camera wearers walking
around in the real world can be transferred to assist visually impaired people
in navigation, as well as to instill human navigation behaviours in mobile
robots, enabling better human-robot interactions. To this end, a novel
egocentric human trajectory forecasting dataset was constructed, containing
real trajectories of people navigating in crowded spaces wearing a camera, as
well as extracted rich contextual data. We extract and utilize three different
modalities to forecast the trajectory of the camera wearer, i.e., his/her past
trajectory, the past trajectories of nearby people, and the environment such as
the scene semantics or the depth of the scene. A Transformer-based
encoder-decoder neural network model, integrated with a novel cascaded
cross-attention mechanism that fuses multiple modalities, has been designed to
predict the future trajectory of the camera wearer. Extensive experiments have
been conducted, and the results have shown that our model outperforms the
state-of-the-art methods in egocentric human trajectory forecasting.</p>
  </details>
</details>
<details>
  <summary>15. <b>标题：Generative Occupancy Fields for 3D Surface-Aware Image Synthesis</b></summary>
  <p><b>编号</b>：[50]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00969</p>
  <p><b>作者</b>：Xudong Xu,  Xingang Pan,  Dahua Lin,  Bo Dai</p>
  <p><b>备注</b>：Accepted to NeurIPS2021. We propose Generative Occupancy Fields(GOF), a 3D-aware generative model which could synthesize realistic images with 3D consistency and simultaneously learn compact object surfaces</p>
  <p><b>关键词</b>：radiance fields occupancy representations could inherently ensure deterministic surfaces, generative models much easier since gradients, learn compact object surfaces without impeding, receive sparse gradients located, directly apply occupancy representations</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The advent of generative radiance fields has significantly promoted the
development of 3D-aware image synthesis. The cumulative rendering process in
radiance fields makes training these generative models much easier since
gradients are distributed over the entire volume, but leads to diffused object
surfaces. In the meantime, compared to radiance fields occupancy
representations could inherently ensure deterministic surfaces. However, if we
directly apply occupancy representations to generative models, during training
they will only receive sparse gradients located on object surfaces and
eventually suffer from the convergence problem. In this paper, we propose
Generative Occupancy Fields (GOF), a novel model based on generative radiance
fields that can learn compact object surfaces without impeding its training
convergence. The key insight of GOF is a dedicated transition from the
cumulative rendering in radiance fields to rendering with only the surface
points as the learned surface gets more and more accurate. In this way, GOF
combines the merits of two representations in a unified framework. In practice,
the training-time transition of start from radiance fields and march to
occupancy representations is achieved in GOF by gradually shrinking the
sampling region in its rendering process from the entire volume to a minimal
neighboring region around the surface. Through comprehensive experiments on
multiple datasets, we demonstrate that GOF can synthesize high-quality images
with 3D consistency and simultaneously learn compact and smooth object
surfaces. Code, models, and demo videos are available at
this https URL</p>
  </details>
</details>
<details>
  <summary>16. <b>标题：VPFNet: Voxel-Pixel Fusion Network for Multi-class 3D Object Detection</b></summary>
  <p><b>编号</b>：[52]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00966</p>
  <p><b>作者</b>：Chia-Hung Wang,  Hsueh-Wei Chen,  Li-Chen Fu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：class 3d object detection task, class 3d object detection network, camera sensor data streams, dl )- embedded fusion, class object detection</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Many LiDAR-based methods for detecting large objects, single-class object
detection, or under easy situations were claimed to perform quite well.
However, their performances of detecting small objects or under hard situations
did not surpass those of the fusion-based ones due to failure to leverage the
image semantics. In order to elevate the detection performance in a complicated
environment, this paper proposes a deep learning (DL)-embedded fusion-based
multi-class 3D object detection network which admits both LiDAR and camera
sensor data streams, named Voxel-Pixel Fusion Network (VPFNet). Inside this
network, a key novel component is called Voxel-Pixel Fusion (VPF) layer, which
takes advantage of the geometric relation of a voxel-pixel pair and fuses the
voxel features and the pixel features with proper mechanisms. Moreover, several
parameters are particularly designed to guide and enhance the fusion effect
after considering the characteristics of a voxel-pixel pair. Finally, the
proposed method is evaluated on the KITTI benchmark for multi-class 3D object
detection task under multilevel difficulty, and is shown to outperform all
state-of-the-art methods in mean average precision (mAP). It is also noteworthy
that our approach here ranks the first on the KITTI leaderboard for the
challenging pedestrian class.</p>
  </details>
</details>
<details>
  <summary>17. <b>标题：Higher-Order Implicit Fairing Networks for 3D Human Pose Estimation</b></summary>
  <p><b>编号</b>：[58]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00950</p>
  <p><b>作者</b>：Jianning Quan,  A. Ben Hamza</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：learned feature representations retain important information, two standard benchmarks demonstrate, order graph convolutional framework, approach leverages residual connections, 3d human pose estimation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Estimating a 3D human pose has proven to be a challenging task, primarily
because of the complexity of the human body joints, occlusions, and variability
in lighting conditions. In this paper, we introduce a higher-order graph
convolutional framework with initial residual connections for 2D-to-3D pose
estimation. Using multi-hop neighborhoods for node feature aggregation, our
model is able to capture the long-range dependencies between body joints.
Moreover, our approach leverages residual connections, which are integrated by
design in our network architecture, ensuring that the learned feature
representations retain important information from the initial features of the
input layer as the network depth increases. Experiments and ablations studies
conducted on two standard benchmarks demonstrate the effectiveness of our
model, achieving superior performance over strong baseline methods for 3D human
pose estimation.</p>
  </details>
</details>
<details>
  <summary>18. <b>标题：Nested Multiple Instance Learning with Attention Mechanisms</b></summary>
  <p><b>编号</b>：[59]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00947</p>
  <p><b>作者</b>：Saul Fuster,  Trygve Eftestøl,  Kjersti Engan</p>
  <p><b>备注</b>：Submitted to ICASSP 2022</p>
  <p><b>关键词</b>：proposed model provides high accuracy performance, nested mil considers labelled bags within bags, method fits diverse applications, like finding relevant regions, classical image datasets show</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Multiple instance learning (MIL) is a type of weakly supervised learning
where multiple instances of data with unknown labels are sorted into bags.
Since knowledge about the individual instances is incomplete, labels are
assigned to the bags containing the instances. While this method fits diverse
applications were labelled data is scarce, it lacks depth for solving more
complex scenarios where associations between sets of instances have to be made,
like finding relevant regions of interest in an image or detecting events in a
set of time-series signals. Nested MIL considers labelled bags within bags,
where only the outermost bag is labelled and inner-bags and instances are
represented as latent labels. In addition, we propose using an attention
mechanism to add interpretability, providing awareness into the impact of each
instance to the weak bag label. Experiments in classical image datasets show
that our proposed model provides high accuracy performance as well as spotting
relevant instances on image regions.</p>
  </details>
</details>
<details>
  <summary>19. <b>标题：SVBRDF Recovery From a Single Image With Highlights using a Pretrained  Generative Adversarial Network</b></summary>
  <p><b>编号</b>：[63]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00943</p>
  <p><b>作者</b>：Tao Wen,  Beibei Wang,  Lei Zhang,  Jie Guo,  Nicolas Holzschuch</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：stage training boosts runtime performance, unsupervised generative adversarial neural network, single image contains incomplete information, vivid rendering results compared, existing methods either rely</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Spatially-varying bi-directional reflectance distribution functions (SVBRDFs)
are crucial for designers to incorporate new materials in virtual scenes,
making them look more realistic. Reconstruction of SVBRDFs is a long-standing
problem. Existing methods either rely on extensive acquisition system or
require huge datasets which are nontrivial to acquire. We aim to recover
SVBRDFs from a single image, without any datasets. A single image contains
incomplete information about the SVBRDF, making the reconstruction task highly
ill-posed. It is also difficult to separate between the changes in color that
are caused by the material and those caused by the illumination, without the
prior knowledge learned from the dataset. In this paper, we use an unsupervised
generative adversarial neural network (GAN) to recover SVBRDFs maps with a
single image as input. To better separate the effects due to illumination from
the effects due to the material, we add the hypothesis that the material is
stationary and introduce a new loss function based on Fourier coefficients to
enforce this stationarity. For efficiency, we train the network in two stages:
reusing a trained model to initialize the SVBRDFs and fine-tune it based on the
input image. Our method generates high-quality SVBRDFs maps from a single input
photograph, and provides more vivid rendering results compared to previous
work. The two-stage training boosts runtime performance, making it 8 times
faster than previous work.</p>
  </details>
</details>
<details>
  <summary>20. <b>标题：Turning Traffic Monitoring Cameras into Intelligent Sensors for Traffic  Density Estimation</b></summary>
  <p><b>编号</b>：[64]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00941</p>
  <p><b>作者</b>：Zijian Hu,  William H.K. Lam,  S.C. Wong,  Andy H.F. Chow,  Wei Ma</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：estimating traffic density using uncalibrated traffic monitoring cameras, time traffic information without installing additional sensors, providing useful traffic state information, accurate traffic state information plays, traffic density estimation problem</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Accurate traffic state information plays a pivotal role in the Intelligent
Transportation Systems (ITS), and it is an essential input to various smart
mobility applications such as signal coordination and traffic flow prediction.
The current practice to obtain the traffic state information is through
specialized sensors such as loop detectors and speed cameras. In most
metropolitan areas, traffic monitoring cameras have been installed to monitor
the traffic conditions on arterial roads and expressways, and the collected
videos or images are mainly used for visual inspection by traffic engineers.
Unfortunately, the data collected from traffic monitoring cameras are affected
by the 4L characteristics: Low frame rate, Low resolution, Lack of annotated
data, and Located in complex road environments. Therefore, despite the great
potentials of the traffic monitoring cameras, the 4L characteristics hinder
them from providing useful traffic state information (e.g., speed, flow,
density). This paper focuses on the traffic density estimation problem as it is
widely applicable to various traffic surveillance systems. To the best of our
knowledge, there is a lack of the holistic framework for addressing the 4L
characteristics and extracting the traffic density information from traffic
monitoring camera data. In view of this, this paper proposes a framework for
estimating traffic density using uncalibrated traffic monitoring cameras with
4L characteristics. The proposed framework consists of two major components:
camera calibration and vehicle detection. The camera calibration method
estimates the actual length between pixels in the images and videos, and the
vehicle counts are extracted from the deep-learning-based vehicle detection
method. Combining the two components, high-granular traffic density can be
estimated. To validate the proposed framework, two case studies were conducted
in Hong Kong and Sacramento. The results show that the Mean Absolute Error
(MAE) in camera calibration is less than 0.2 meters out of 6 meters, and the
accuracy of vehicle detection under various conditions is approximately 90%.
Overall, the MAE for the estimated density is 9.04 veh/km/lane in Hong Kong and
1.30 veh/km/lane in Sacramento. The research outcomes can be used to calibrate
the speed-density fundamental diagrams, and the proposed framework can provide
accurate and real-time traffic information without installing additional
sensors.</p>
  </details>
</details>
<details>
  <summary>21. <b>标题：Structure Information is the Key: Self-Attention RoI Feature Extractor  in 3D Object Detection</b></summary>
  <p><b>编号</b>：[66]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00931</p>
  <p><b>作者</b>：Diankun Zhang,  Zhijie Zheng,  Xueting Bi,  Xiaojun Liu,</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：3d point cloud object detection, unlike 2d object detection, attention roi feature extractor, 3d object detection, whole point cloud</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Unlike 2D object detection where all RoI features come from grid pixels, the
RoI feature extraction of 3D point cloud object detection is more diverse. In
this paper, we first compare and analyze the differences in structure and
performance between the two state-of-the-art models PV-RCNN and Voxel-RCNN.
Then, we find that the performance gap between the two models does not come
from point information, but structural information. The voxel features contain
more structural information because they do quantization instead of
downsampling to point cloud so that they can contain basically the complete
information of the whole point cloud. The stronger structural information in
voxel features makes the detector have higher performance in our experiments
even if the voxel features don't have accurate location information. Then, we
propose that structural information is the key to 3D object detection. Based on
the above conclusion, we propose a Self-Attention RoI Feature Extractor (SARFE)
to enhance structural information of the feature extracted from 3D proposals.
SARFE is a plug-and-play module that can be easily used on existing 3D
detectors. Our SARFE is evaluated on both KITTI dataset and Waymo Open dataset.
With the newly introduced SARFE, we improve the performance of the
state-of-the-art 3D detectors by a large margin in cyclist on KITTI dataset
while keeping real-time capability.</p>
  </details>
</details>
<details>
  <summary>22. <b>标题：Combating Noise: Semi-supervised Learning by Region Uncertainty  Quantification</b></summary>
  <p><b>编号</b>：[68]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00928</p>
  <p><b>作者</b>：Zhenyu Wang,  Yali Li,  Ye Guo,  Shengjin Wang</p>
  <p><b>备注</b>：Accepted by NeurIPS 2021</p>
  <p><b>关键词</b>：promoting multipeak probability distribution output, existing works primarily focus, ms coco demonstrate, adverse effects brought, supervised learning aims</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Semi-supervised learning aims to leverage a large amount of unlabeled data
for performance boosting. Existing works primarily focus on image
classification. In this paper, we delve into semi-supervised learning for
object detection, where labeled data are more labor-intensive to collect.
Current methods are easily distracted by noisy regions generated by pseudo
labels. To combat the noisy labeling, we propose noise-resistant
semi-supervised learning by quantifying the region uncertainty. We first
investigate the adverse effects brought by different forms of noise associated
with pseudo labels. Then we propose to quantify the uncertainty of regions by
identifying the noise-resistant properties of regions over different strengths.
By importing the region uncertainty quantification and promoting multipeak
probability distribution output, we introduce uncertainty into training and
further achieve noise-resistant learning. Experiments on both PASCAL VOC and MS
COCO demonstrate the extraordinary performance of our method.</p>
  </details>
</details>
<details>
  <summary>23. <b>标题：DFCANet: Dense Feature Calibration-Attention Guided Network for Cross  Domain Iris Presentation Attack Detection</b></summary>
  <p><b>编号</b>：[70]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00919</p>
  <p><b>作者</b>：Gaurav Jaswal,  Aman Verma,  Sumantra Dutta Roy,  Raghavendra Ramachandra</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：domain scenarios highlights consistent outperforming results, high visual correlation amongst bonafide, widely used iris recognition systems, capitalize discriminative feature learning across, normalized ocular iris images</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>An iris presentation attack detection (IPAD) is essential for securing
personal identity is widely used iris recognition systems. However, the
existing IPAD algorithms do not generalize well to unseen and cross-domain
scenarios because of capture in unconstrained environments and high visual
correlation amongst bonafide and attack samples. These similarities in
intricate textural and morphological patterns of iris ocular images contribute
further to performance degradation. To alleviate these shortcomings, this paper
proposes DFCANet: Dense Feature Calibration and Attention Guided Network which
calibrates the locally spread iris patterns with the globally located ones.
Uplifting advantages from feature calibration convolution and residual
learning, DFCANet generates domain-specific iris feature representations. Since
some channels in the calibrated feature maps contain more prominent
information, we capitalize discriminative feature learning across the channels
through the channel attention mechanism. In order to intensify the challenge
for our proposed model, we make DFCANet operate over nonsegmented and
non-normalized ocular iris images. Extensive experimentation conducted over
challenging cross-domain and intra-domain scenarios highlights consistent
outperforming results. Compared to state-of-the-art methods, DFCANet achieves
significant gains in performance for the benchmark IIITD CLI, IIIT CSD and
NDCLD13 databases respectively. Further, a novel incremental learning-based
methodology has been introduced so as to overcome disentangled iris-data
characteristics and data scarcity. This paper also pursues the challenging
scenario that considers soft-lens under the attack category with evaluation
performed under various cross-domain protocols. The code will be made publicly
available.</p>
  </details>
</details>
<details>
  <summary>24. <b>标题：Multi-Attribute Balanced Sampling for Disentangled GAN Controls</b></summary>
  <p><b>编号</b>：[74]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00909</p>
  <p><b>作者</b>：Perla Doubinsky (CEDRIC - VERTIGO, CNAM),  Nicolas Audebert (CEDRIC - VERTIGO, CNAM),  Michel Crucianu (CEDRIC - VERTIGO, CNAM),  Hervé Le Borgne (LIST)</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：supervised approaches typically sample, extracting disentangled linear directions, occuring attributes thus balancing, two popular gan architectures, vary semantic attributes</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Various controls over the generated data can be extracted from the latent
space of a pre-trained GAN, as it implicitly encodes the semantics of the
training data. The discovered controls allow to vary semantic attributes in the
generated images but usually lead to entangled edits that affect multiple
attributes at the same time. Supervised approaches typically sample and
annotate a collection of latent codes, then train classifiers in the latent
space to identify the controls. Since the data generated by GANs reflects the
biases of the original dataset, so do the resulting semantic controls. We
propose to address disentanglement by subsampling the generated data to remove
over-represented co-occuring attributes thus balancing the semantics of the
dataset before training the classifiers. We demonstrate the effectiveness of
this approach by extracting disentangled linear directions for face
manipulation on two popular GAN architectures, PGGAN and StyleGAN, and two
datasets, CelebAHQ and FFHQ. We show that this approach outperforms
state-of-the-art classifier-based methods while avoiding the need for
disentanglement-enforcing post-processing.</p>
  </details>
</details>
<details>
  <summary>25. <b>标题：Smart Fashion: A Review of AI Applications in the Fashion & Apparel  Industry</b></summary>
  <p><b>编号</b>：[75]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00905</p>
  <p><b>作者</b>：Seyed Omid Mohammadi,  Ahmad Kalhor (University of Tehran, College of Engineering, School of Electrical and Computer Engineering, Tehran, Iran)</p>
  <p><b>备注</b>：99 Pages, 79 Figures, 24 Tables, Full length manuscript</p>
  <p><b>关键词</b>：86 public fashion datasets accompanied, fashion research articles provides researchers, explicit research directions, 580 related articles, paper provides</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The fashion industry is on the verge of an unprecedented change. The
implementation of machine learning, computer vision, and artificial
intelligence (AI) in fashion applications is opening lots of new opportunities
for this industry. This paper provides a comprehensive survey on this matter,
categorizing more than 580 related articles into 22 well-defined
fashion-related tasks. Such structured task-based multi-label classification of
fashion research articles provides researchers with explicit research
directions and facilitates their access to the related studies, improving the
visibility of studies simultaneously. For each task, a time chart is provided
to analyze the progress through the years. Furthermore, we provide a list of 86
public fashion datasets accompanied by a list of suggested applications and
additional information for each.</p>
  </details>
</details>
<details>
  <summary>26. <b>标题：PP-PicoDet: A Better Real-Time Object Detector on Mobile Devices</b></summary>
  <p><b>编号</b>：[77]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00902</p>
  <p><b>作者</b>：Guanghua Yu,  Qinyao Chang,  Wenyu Lv,  Chang Xu,  Cheng Cui,  Wei Ji,  Qingqing Dang,  Kaipeng Deng,  Guanzhong Wang,  Yuning Du,  Baohua Lai,  Qiwen Liu,  Xiaoguang Hu,  Dianhai Yu,  Yanjun Ma</p>
  <p><b>备注</b>：9 pages, 3 figures, 5 tables</p>
  <p><b>关键词</b>：150 fps using paddle lite, reducing mobile cpu inference latency, 99m parameters achieves 30, 3m parameters achieves 40, neural network architecture choices</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The better accuracy and efficiency trade-off has been a challenging problem
in object detection. In this work, we are dedicated to studying key
optimizations and neural network architecture choices for object detection to
improve accuracy and efficiency. We investigate the applicability of the
anchor-free strategy on lightweight object detection models. We enhance the
backbone structure and design the lightweight structure of the neck, which
improves the feature extraction ability of the network. We improve label
assignment strategy and loss function to make training more stable and
efficient. Through these optimizations, we create a new family of real-time
object detectors, named PP-PicoDet, which achieves superior performance on
object detection for mobile devices. Our models achieve better trade-offs
between accuracy and latency compared to other popular models. PicoDet-S with
only 0.99M parameters achieves 30.6% mAP, which is an absolute 4.8% improvement
in mAP while reducing mobile CPU inference latency by 55% compared to
YOLOX-Nano, and is an absolute 7.1% improvement in mAP compared to NanoDet. It
reaches 123 FPS (150 FPS using Paddle Lite) on mobile ARM CPU when the input
size is 320. PicoDet-L with only 3.3M parameters achieves 40.9% mAP, which is
an absolute 3.7% improvement in mAP and 44% faster than YOLOv5s. As shown in
Figure 1, our models far outperform the state-of-the-art results for
lightweight object detection. Code and pre-trained models are available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>27. <b>标题：Equivariant Contrastive Learning</b></summary>
  <p><b>编号</b>：[80]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00899</p>
  <p><b>作者</b>：Rumen Dangovski,  Li Jing,  Charlotte Loh,  Seungwook Han,  Akash Srivastava,  Brian Cheung,  Pulkit Agrawal,  Marin Soljačić</p>
  <p><b>备注</b>：17 pages, 5 figures</p>
  <p><b>关键词</b>：several popular computer vision benchmarks, training produces semantically good representations, applications beyond computer vision, broader class called equivariance, extend popular ssl methods</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In state-of-the-art self-supervised learning (SSL) pre-training produces
semantically good representations by encouraging them to be invariant under
meaningful transformations prescribed from human knowledge. In fact, the
property of invariance is a trivial instance of a broader class called
equivariance, which can be intuitively understood as the property that
representations transform according to the way the inputs transform. Here, we
show that rather than using only invariance, pre-training that encourages
non-trivial equivariance to some transformations, while maintaining invariance
to other transformations, can be used to improve the semantic quality of
representations. Specifically, we extend popular SSL methods to a more general
framework which we name Equivariant Self-Supervised Learning (E-SSL). In E-SSL,
a simple additional pre-training objective encourages equivariance by
predicting the transformations applied to the input. We demonstrate E-SSL's
effectiveness empirically on several popular computer vision benchmarks.
Furthermore, we demonstrate usefulness of E-SSL for applications beyond
computer vision; in particular, we show its utility on regression problems in
photonics science. We will release our code.</p>
  </details>
</details>
<details>
  <summary>28. <b>标题：Hierarchical Image Classification with A Literally Toy Dataset</b></summary>
  <p><b>编号</b>：[82]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00892</p>
  <p><b>作者</b>：Long He,  Dandan Song,  Liang Zheng</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：g ., two easily confusing classes may belong, 15 dataset contains 15 classes, variant studies provide insights, train feature extractors supervised, entirely different base classes</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Unsupervised domain adaptation (UDA) in image classification remains a big
challenge. In existing UDA image dataset, classes are usually organized in a
flattened way, where a plain classifier can be trained. Yet in some scenarios,
the flat categories originate from some base classes. For example, buggies
belong to the class bird. We define the classification task where classes have
characteristics above and the flat classes and the base classes are organized
hierarchically as hierarchical image classification. Intuitively, leveraging
such hierarchical structure will benefit hierarchical image classification,
e.g., two easily confusing classes may belong to entirely different base
classes. In this paper, we improve the performance of classification by fusing
features learned from a hierarchy of labels. Specifically, we train feature
extractors supervised by hierarchical labels and with UDA technology, which
will output multiple features for an input image. The features are subsequently
concatenated to predict the finest-grained class. This study is conducted with
a new dataset named Lego-15. Consisting of synthetic images and real images of
the Lego bricks, the Lego-15 dataset contains 15 classes of bricks. Each class
originates from a coarse-level label and a middle-level label. For example,
class "85080" is associated with bricks (coarse) and bricks round (middle). In
this dataset, we demonstrate that our method brings about consistent
improvement over the baseline in UDA in hierarchical image classification.
Extensive ablation and variant studies provide insights into the new dataset
and the investigated algorithm.</p>
  </details>
</details>
<details>
  <summary>29. <b>标题：Benchmarks for Corruption Invariant Person Re-identification</b></summary>
  <p><b>编号</b>：[88]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00880</p>
  <p><b>作者</b>：Minghui Chen,  Zhiqiang Wang,  Feng Zheng</p>
  <p><b>备注</b>：Accepted by NeurIPS 2021 Track on Datasets and Benchmarks. Project page: this https URL</p>
  <p><b>关键词</b>：comprehensively establish six reid benchmarks, commonly used augmentation method, 21 recent reid methods, robust towards corrupted images, learning corruption invariant representation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>When deploying person re-identification (ReID) model in safety-critical
applications, it is pivotal to understanding the robustness of the model
against a diverse array of image corruptions. However, current evaluations of
person ReID only consider the performance on clean datasets and ignore images
in various corrupted scenarios. In this work, we comprehensively establish six
ReID benchmarks for learning corruption invariant representation. In the field
of ReID, we are the first to conduct an exhaustive study on corruption
invariant learning in single- and cross-modality datasets, including
Market-1501, CUHK03, MSMT17, RegDB, SYSU-MM01. After reproducing and examining
the robustness performance of 21 recent ReID methods, we have some
observations: 1) transformer-based models are more robust towards corrupted
images, compared with CNN-based models, 2) increasing the probability of random
erasing (a commonly used augmentation method) hurts model corruption
robustness, 3) cross-dataset generalization improves with corruption robustness
increases. By analyzing the above observations, we propose a strong baseline on
both single- and cross-modality ReID datasets which achieves improved
robustness against diverse corruptions. Our codes are available on
this https URL.</p>
  </details>
</details>
<details>
  <summary>30. <b>标题：DetectorNet: Transformer-enhanced Spatial Temporal Graph Neural Network  for Traffic Prediction</b></summary>
  <p><b>编号</b>：[94]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00869</p>
  <p><b>作者</b>：He Li,  Shiyu Zhang,  Xuejiao Li,  Liangcai Su,  Hongjie Huang,  Duo Jin,  Linghao Chen,  Jianbing Huang,  Jaesoo Yoo</p>
  <p><b>备注</b>：The 29th ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems (ACM SIGSPATIAL 2021)</p>
  <p><b>关键词</b>：eventually loses much valuable potential information, data presents unique challenges including, four ablation experiments proves, static road network structure, view temporal attention module</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Detectors with high coverage have direct and far-reaching benefits for road
users in route planning and avoiding traffic congestion, but utilizing these
data presents unique challenges including: the dynamic temporal correlation,
and the dynamic spatial correlation caused by changes in road conditions.
Although the existing work considers the significance of modeling with
spatial-temporal correlation, what it has learned is still a static road
network structure, which cannot reflect the dynamic changes of roads, and
eventually loses much valuable potential information. To address these
challenges, we propose DetectorNet enhanced by Transformer. Differs from
previous studies, our model contains a Multi-view Temporal Attention module and
a Dynamic Attention module, which focus on the long-distance and short-distance
temporal correlation, and dynamic spatial correlation by dynamically updating
the learned knowledge respectively, so as to make accurate prediction. In
addition, the experimental results on two public datasets and the comparison
results of four ablation experiments proves that the performance of DetectorNet
is better than the eleven advanced baselines.</p>
  </details>
</details>
<details>
  <summary>31. <b>标题：MEmoBERT: Pre-training Model with Prompt-based Learning for Multimodal  Emotion Recognition</b></summary>
  <p><b>编号</b>：[97]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00865</p>
  <p><b>作者</b>：Jinming Zhao,  Ruichen Li,  Qin Jin,  Xinchao Wang,  Haizhou Li</p>
  <p><b>备注</b>：4 papges, 2 figures</p>
  <p><b>关键词</b>：proposed memobert significantly enhances emotion recognition performance, multimodal emotion recognition study, masked text prediction one, learns multimodal joint representations, downstream emotion classification task</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Multimodal emotion recognition study is hindered by the lack of labelled
corpora in terms of scale and diversity, due to the high annotation cost and
label ambiguity. In this paper, we propose a pre-training model
\textbf{MEmoBERT} for multimodal emotion recognition, which learns multimodal
joint representations through self-supervised learning from large-scale
unlabeled video data that come in sheer volume. Furthermore, unlike the
conventional "pre-train, finetune" paradigm, we propose a prompt-based method
that reformulates the downstream emotion classification task as a masked text
prediction one, bringing the downstream task closer to the pre-training.
Extensive experiments on two benchmark datasets, IEMOCAP and MSP-IMPROV, show
that our proposed MEmoBERT significantly enhances emotion recognition
performance.</p>
  </details>
</details>
<details>
  <summary>32. <b>标题：A Frequency Perspective of Adversarial Robustness</b></summary>
  <p><b>编号</b>：[99]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00861</p>
  <p><b>作者</b>：Shishira R Maiya,  Max Ehrlich,  Vatsal Agarwal,  Ser-Nam Lim,  Tom Goldstein,  Abhinav Shrivastava</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：provide new insights towards, commonly observed accuracy vs, analyze many intriguing properties, simply dataset dependent, despite recent advances</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Adversarial examples pose a unique challenge for deep learning systems.
Despite recent advances in both attacks and defenses, there is still a lack of
clarity and consensus in the community about the true nature and underlying
properties of adversarial examples. A deep understanding of these examples can
provide new insights towards the development of more effective attacks and
defenses. Driven by the common misconception that adversarial examples are
high-frequency noise, we present a frequency-based understanding of adversarial
examples, supported by theoretical and empirical findings. Our analysis shows
that adversarial examples are neither in high-frequency nor in low-frequency
components, but are simply dataset dependent. Particularly, we highlight the
glaring disparities between models trained on CIFAR-10 and ImageNet-derived
datasets. Utilizing this framework, we analyze many intriguing properties of
training robust models with frequency constraints, and propose a
frequency-based explanation for the commonly observed accuracy vs. robustness
trade-off.</p>
  </details>
</details>
<details>
  <summary>33. <b>标题：LSTA-Net: Long short-term Spatio-Temporal Aggregation Network for  Skeleton-based Action Recognition</b></summary>
  <p><b>编号</b>：[109]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00823</p>
  <p><b>作者</b>：Tailin Chen,  Shidong Wang,  Desen Zhou,  Yu Guan</p>
  <p><b>备注</b>：Accepted by BMVC 2021</p>
  <p><b>关键词</b>：alternately perform spatial feature aggregation, three public benchmark datasets, existing methods excessively relied, distant yet important joints, feature aggregation effect</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Modelling various spatio-temporal dependencies is the key to recognising
human actions in skeleton sequences. Most existing methods excessively relied
on the design of traversal rules or graph topologies to draw the dependencies
of the dynamic joints, which is inadequate to reflect the relationships of the
distant yet important joints. Furthermore, due to the locally adopted
operations, the important long-range temporal information is therefore not well
explored in existing works. To address this issue, in this work we propose
LSTA-Net: a novel Long short-term Spatio-Temporal Aggregation Network, which
can effectively capture the long/short-range dependencies in a spatio-temporal
manner. We devise our model into a pure factorised architecture which can
alternately perform spatial feature aggregation and temporal feature
aggregation. To improve the feature aggregation effect, a channel-wise
attention mechanism is also designed and employed. Extensive experiments were
conducted on three public benchmark datasets, and the results suggest that our
approach can capture both long-and-short range dependencies in the space and
time domain, yielding higher results than other state-of-the-art methods. Code
available at this https URL.</p>
  </details>
</details>
<details>
  <summary>34. <b>标题：Livestock Monitoring with Transformer</b></summary>
  <p><b>编号</b>：[114]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00801</p>
  <p><b>作者</b>：Bhavesh Tangirala,  Ishan Bhandari,  Daniel Laszlo,  Deepak K. Gupta,  Rajat M. Thomas,  Devanshu Arya</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：carefully curated dataset comprising video sequences, starformer outperforms popular baseline models trained, computer vision algorithms perform poorly, could use standard video cameras, perform simultaneous instance level segmentation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Tracking the behaviour of livestock enables early detection and thus
prevention of contagious diseases in modern animal farms. Apart from economic
gains, this would reduce the amount of antibiotics used in livestock farming
which otherwise enters the human diet exasperating the epidemic of antibiotic
resistance - a leading cause of death. We could use standard video cameras,
available in most modern farms, to monitor livestock. However, most computer
vision algorithms perform poorly on this task, primarily because, (i) animals
bred in farms look identical, lacking any obvious spatial signature, (ii) none
of the existing trackers are robust for long duration, and (iii) real-world
conditions such as changing illumination, frequent occlusion, varying camera
angles, and sizes of the animals make it hard for models to generalize. Given
these challenges, we develop an end-to-end behaviour monitoring system for
group-housed pigs to perform simultaneous instance level segmentation,
tracking, action recognition and re-identification (STAR) tasks. We present
starformer, the first end-to-end multiple-object livestock monitoring framework
that learns instance-level embeddings for grouped pigs through the use of
transformer architecture. For benchmarking, we present Pigtrace, a carefully
curated dataset comprising video sequences with instance level bounding box,
segmentation, tracking and activity classification of pigs in real indoor
farming environment. Using simultaneous optimization on STAR tasks we show that
starformer outperforms popular baseline models trained for individual tasks.</p>
  </details>
</details>
<details>
  <summary>35. <b>标题：Geodesic Models with Convexity Shape Prior</b></summary>
  <p><b>编号</b>：[116]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00794</p>
  <p><b>作者</b>：Da Chen,  Jean-Marie Mirebeau,  Minglei Shu,  Xuecheng Tai,  Laurent D. Cohen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：based segmentation approaches usually exploit image features, efficient interactive image segmentation algorithms, art hamiltonian fast marching method, establish new geodesic models relying, various image segmentation scenarios</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The minimal geodesic models based on the Eikonal equations are capable of
finding suitable solutions in various image segmentation scenarios. Existing
geodesic-based segmentation approaches usually exploit image features in
conjunction with geometric regularization terms, such as Euclidean curve length
or curvature-penalized length, for computing geodesic curves. In this paper, we
take into account a more complicated problem: finding curvature-penalized
geodesic paths with a convexity shape prior. We establish new geodesic models
relying on the strategy of orientation-lifting, by which a planar curve can be
mapped to an high-dimensional orientation-dependent space. The convexity shape
prior serves as a constraint for the construction of local geodesic metrics
encoding a particular curvature constraint. Then the geodesic distances and the
corresponding closed geodesic paths in the orientation-lifted space can be
efficiently computed through state-of-the-art Hamiltonian fast marching method.
In addition, we apply the proposed geodesic models to the active contours,
leading to efficient interactive image segmentation algorithms that preserve
the advantages of convexity shape prior and curvature penalization.</p>
  </details>
</details>
<details>
  <summary>36. <b>标题：Learning Event-based Spatio-Temporal Feature Descriptors via Local  Synaptic Plasticity: A Biologically-realistic Perspective of Computer Vision</b></summary>
  <p><b>编号</b>：[117]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00791</p>
  <p><b>作者</b>：Ali Safa,  Hichem Sahli,  André Bourdoux,  Ilja Ocket,  Francky Catthoor,  Georges Gielen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：based theory describing spiking cortical ensembles equipped, based feature descriptors (+ 8, report significant accuracy improvements compared, based systems (+ 10, ibm dvs128 gesture dataset</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present an optimization-based theory describing spiking cortical ensembles
equipped with Spike-Timing-Dependent Plasticity (STDP) learning, as empirically
observed in the visual cortex. Using our methods, we build a class of
fully-connected, convolutional and action-based feature descriptors for
event-based camera that we respectively assess on N-MNIST, challenging
CIFAR10-DVS and on the IBM DVS128 gesture dataset. We report significant
accuracy improvements compared to conventional state-of-the-art event-based
feature descriptors (+8% on CIFAR10-DVS). We report large improvements in
accuracy compared to state-of-the-art STDP-based systems (+10% on N-MNIST,
+7.74% on IBM DVS128 Gesture). In addition to ultra-low-power learning in
neuromorphic edge devices, our work helps paving the way towards a
biologically-realistic, optimization-based theory of cortical vision.</p>
  </details>
</details>
<details>
  <summary>37. <b>标题：PP-ShiTu: A Practical Lightweight Image Recognition System</b></summary>
  <p><b>编号</b>：[124]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00775</p>
  <p><b>作者</b>：Shengyu Wei,  Ruoyu Guo,  Cheng Cui,  Bin Lu,  Shuilong Dong,  Tingquan Gao,  Yuning Du,  Ying Zhou,  Xueying Lyu,  Qiwen Liu,  Xiaoguang Hu,  Dianhai Yu,  Yanjun Ma</p>
  <p><b>备注</b>：9 pages, 5 figures, 8 tables. arXiv admin note: text overlap with arXiv:2109.03144</p>
  <p><b>关键词</b>：introduce popular strategies including metric learning, practical lightweight image recognition system, image recognition applications, github repository paddleclas, following 3 modules</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In recent years, image recognition applications have developed rapidly. A
large number of studies and techniques have emerged in different fields, such
as face recognition, pedestrian and vehicle re-identification, landmark
retrieval, and product recognition. In this paper, we propose a practical
lightweight image recognition system, named PP-ShiTu, consisting of the
following 3 modules, mainbody detection, feature extraction and vector search.
We introduce popular strategies including metric learning, deep hash, knowledge
distillation and model quantization to improve accuracy and inference speed.
With strategies above, PP-ShiTu works well in different scenarios with a set of
models trained on a mixed dataset. Experiments on different datasets and
benchmarks show that the system is widely effective in different domains of
image recognition. All the above mentioned models are open-sourced and the code
is available in the GitHub repository PaddleClas on PaddlePaddle.</p>
  </details>
</details>
<details>
  <summary>38. <b>标题：AdaPool: Exponential Adaptive Pooling for Information-Retaining  Downsampling</b></summary>
  <p><b>编号</b>：[126]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00772</p>
  <p><b>作者</b>：Alexandros Stergiou,  Ronald Poppe</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：adapool systematically achieves better results across tasks, exponentially weighted pooling method named adapool, frame interpolation tasks, proposed method uses, tasks including image</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Pooling layers are essential building blocks of Convolutional Neural Networks
(CNNs) that reduce computational overhead and increase the receptive fields of
proceeding convolutional operations. They aim to produce downsampled volumes
that closely resemble the input volume while, ideally, also being
computationally and memory efficient. It is a challenge to meet both
requirements jointly. To this end, we propose an adaptive and exponentially
weighted pooling method named adaPool. Our proposed method uses a parameterized
fusion of two sets of pooling kernels that are based on the exponent of the
Dice-Sorensen coefficient and the exponential maximum, respectively. A key
property of adaPool is its bidirectional nature. In contrast to common pooling
methods, weights can be used to upsample a downsampled activation map. We term
this method adaUnPool. We demonstrate how adaPool improves the preservation of
detail through a range of tasks including image and video classification and
object detection. We then evaluate adaUnPool on image and video frame
super-resolution and frame interpolation tasks. For benchmarking, we introduce
Inter4K, a novel high-quality, high frame-rate video dataset. Our combined
experiments demonstrate that adaPool systematically achieves better results
across tasks and backbone architectures, while introducing a minor additional
computational and memory overhead.</p>
  </details>
</details>
<details>
  <summary>39. <b>标题：Dense Prediction with Attentive Feature Aggregation</b></summary>
  <p><b>编号</b>：[128]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00770</p>
  <p><b>作者</b>：Yung-Hsu Yang,  Thomas E. Huang,  Samuel Rota Bulò,  Peter Kontschieder,  Fisher Yu</p>
  <p><b>备注</b>：18 pages, 16 figures</p>
  <p><b>关键词</b>：progressively refine segmentation maps, features across different layers, fuse different network layers, challenging semantic segmentation benchmarks, introduce attentive feature aggregation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Aggregating information from features across different layers is an essential
operation for dense prediction models. Despite its limited expressiveness,
feature concatenation dominates the choice of aggregation operations. In this
paper, we introduce Attentive Feature Aggregation (AFA) to fuse different
network layers with more expressive non-linear operations. AFA exploits both
spatial and channel attention to compute weighted average of the layer
activations. Inspired by neural volume rendering, we extend AFA with
Scale-Space Rendering (SSR) to perform late fusion of multi-scale predictions.
AFA is applicable to a wide range of existing network designs. Our experiments
show consistent and significant improvements on challenging semantic
segmentation benchmarks, including Cityscapes, BDD100K, and Mapillary Vistas,
at negligible computational and parameter overhead. In particular, AFA improves
the performance of the Deep Layer Aggregation (DLA) model by nearly 6% mIoU on
Cityscapes. Our experimental analyses show that AFA learns to progressively
refine segmentation maps and to improve boundary details, leading to new
state-of-the-art results on boundary detection benchmarks on BSDS500 and
NYUDv2. Code and video resources are available at http://vis.xyz/pub/dla-afa.</p>
  </details>
</details>
<details>
  <summary>40. <b>标题：Monocular 3D Reconstruction of Interacting Hands via Collision-Aware  Factorized Refinements</b></summary>
  <p><b>编号</b>：[131]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00763</p>
  <p><b>作者</b>：Yu Rong,  Jingbo Wang,  Ziwei Liu,  Chen Change Loy</p>
  <p><b>备注</b>：Accepted to 3DV 2021. Code and demo is available at this https URL</p>
  <p><b>关键词</b>：carefully investigate potential implementations, second stage progressively ameliorates, generate collided hand meshes, reconstruct 3d interacting hands, 3d interacting hand reconstruction</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>3D interacting hand reconstruction is essential to facilitate human-machine
interaction and human behaviors understanding. Previous works in this field
either rely on auxiliary inputs such as depth images or they can only handle a
single hand if monocular single RGB images are used. Single-hand methods tend
to generate collided hand meshes, when applied to closely interacting hands,
since they cannot model the interactions between two hands explicitly. In this
paper, we make the first attempt to reconstruct 3D interacting hands from
monocular single RGB images. Our method can generate 3D hand meshes with both
precise 3D poses and minimal collisions. This is made possible via a two-stage
framework. Specifically, the first stage adopts a convolutional neural network
to generate coarse predictions that tolerate collisions but encourage
pose-accurate hand meshes. The second stage progressively ameliorates the
collisions through a series of factorized refinements while retaining the
preciseness of 3D poses. We carefully investigate potential implementations for
the factorized refinement, considering the trade-off between efficiency and
accuracy. Extensive quantitative and qualitative results on large-scale
datasets such as InterHand2.6M demonstrate the effectiveness of the proposed
approach.</p>
  </details>
</details>
<details>
  <summary>41. <b>标题：Single-Item Fashion Recommender: Towards Cross-Domain Recommendations</b></summary>
  <p><b>编号</b>：[133]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00758</p>
  <p><b>作者</b>：Seyed Omid Mohammadi,  Hossein Bodaghi,  Ahmad Kalhor (University of Tehran, College of Engineering, School of Electrical and Computer Engineering, Tehran, Iran)</p>
  <p><b>备注</b>：16 Pages, 14 Figures, 2 Tables</p>
  <p><b>关键词</b>：single fashion item shop image, recommendation tasks called objective, many challenges lie ahead, listing similar items available, based fashion recommender system</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Nowadays, recommender systems and search engines play an integral role in
fashion e-commerce. Still, many challenges lie ahead, and this study tries to
tackle some. This article first suggests a content-based fashion recommender
system that uses a parallel neural network to take a single fashion item shop
image as input and make in-shop recommendations by listing similar items
available in the store. Next, the same structure is enhanced to personalize the
results based on user preferences. This work then introduces a background
augmentation technique that makes the system more robust to out-of-domain
queries, enabling it to make street-to-shop recommendations using only a
training set of catalog shop images. Moreover, the last contribution of this
paper is a new evaluation metric for recommendation tasks called
objective-guided human score. This method is an entirely customizable framework
that produces interpretable, comparable scores from subjective evaluations of
human scorers.</p>
  </details>
</details>
<details>
  <summary>42. <b>标题：Few-shot learning with improved local representations via bias rectify  module</b></summary>
  <p><b>编号</b>：[135]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00754</p>
  <p><b>作者</b>：Chao Dong,  Qi Ye,  Wenchao Meng,  Kaixiang Yang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：thus produce undesirable performance, deep bias rectify network, bias rectify module, bias rectify module, recent approaches based</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent approaches based on metric learning have achieved great progress in
few-shot learning. However, most of them are limited to image-level
representation manners, which fail to properly deal with the intra-class
variations and spatial knowledge and thus produce undesirable performance. In
this paper we propose a Deep Bias Rectify Network (DBRN) to fully exploit the
spatial information that exists in the structure of the feature
representations. We first employ a bias rectify module to alleviate the adverse
impact caused by the intra-class variations. bias rectify module is able to
focus on the features that are more discriminative for classification by given
different weights. To make full use of the training data, we design a prototype
augment mechanism that can make the prototypes generated from the support set
to be more representative. To validate the effectiveness of our method, we
conducted extensive experiments on various popular few-shot classification
benchmarks and our methods can outperform state-of-the-art methods.</p>
  </details>
</details>
<details>
  <summary>43. <b>标题：Towards the Generalization of Contrastive Self-Supervised Learning</b></summary>
  <p><b>编号</b>：[138]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00743</p>
  <p><b>作者</b>：Weiran Huang,  Mingyang Yi,  Xuyang Zhao</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：attracted great attention since, two canonical contrastive self, trained models generalize, requires unlabeled data, embeds input data</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recently, self-supervised learning has attracted great attention since it
only requires unlabeled data for training. Contrastive learning is a popular
approach for self-supervised learning and empirically performs well in
practice. However, the theoretical understanding of its generalization ability
on downstream tasks is not well studied. To this end, we present a theoretical
explanation of how contrastive self-supervised pre-trained models generalize to
downstream tasks. Concretely, we quantitatively show that the self-supervised
model has generalization ability on downstream classification tasks if it
embeds input data into a feature space with distinguishing centers of classes
and closely clustered intra-class samples. With the above conclusion, we
further explore SimCLR and Barlow Twins, which are two canonical contrastive
self-supervised methods. We prove that the aforementioned feature space can be
obtained via any of the methods, and thus explain their success on the
generalization on downstream classification tasks. Finally, various experiments
are also conducted to verify our theoretical findings.</p>
  </details>
</details>
<details>
  <summary>44. <b>标题：Learning Iterative Robust Transformation Synchronization</b></summary>
  <p><b>编号</b>：[143]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00728</p>
  <p><b>作者</b>：Zi Jian Yew,  Gim Hee Lee</p>
  <p><b>备注</b>：To appear in 3DV2021</p>
  <p><b>关键词</b>：avoid handcrafting robust loss functions, shared message passing layer, use graph neural networks, problem remains challenging due, pairwise relative motions</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Transformation Synchronization is the problem of recovering absolute
transformations from a given set of pairwise relative motions. Despite its
usefulness, the problem remains challenging due to the influences from noisy
and outlier relative motions, and the difficulty to model analytically and
suppress them with high fidelity. In this work, we avoid handcrafting robust
loss functions, and propose to use graph neural networks (GNNs) to learn
transformation synchronization. Unlike previous works which use complicated
multi-stage pipelines, we use an iterative approach where each step consists of
a single weight-shared message passing layer that refines the absolute poses
from the previous iteration by predicting an incremental update in the tangent
space. To reduce the influence of outliers, the messages are weighted before
aggregation. Our iterative approach alleviates the need for an explicit
initialization step and performs well with identity initial poses. Although our
approach is simple, we show that it performs favorably against existing
handcrafted and learned synchronization methods through experiments on both
SO(3) and SE(3) synchronization.</p>
  </details>
</details>
<details>
  <summary>45. <b>标题：RMNet: Equivalently Removing Residual Connection from Networks</b></summary>
  <p><b>编号</b>：[158]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00687</p>
  <p><b>作者</b>：Fanxu Meng,  Hao Cheng,  Jiaxin Zhuang,  Ke Li,  Xing Sun</p>
  <p><b>备注</b>：Equivalently removing residual connection from ResBlock with non-linear layer inside it, towards an efficient plain model</p>
  <p><b>关键词</b>：rm operation allows input feature maps, designing dnns without residual connections, remove residual connections without changing, although residual connection enables training, high ratio network pruning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Although residual connection enables training very deep neural networks, it
is not friendly for online inference due to its multi-branch topology. This
encourages many researchers to work on designing DNNs without residual
connections at inference. For example, RepVGG re-parameterizes multi-branch
topology to a VGG-like (single-branch) model when deploying, showing great
performance when the network is relatively shallow. However, RepVGG can not
transform ResNet to VGG equivalently because re-parameterizing methods can only
be applied to linear blocks and the non-linear layers (ReLU) have to be put
outside of the residual connection which results in limited representation
ability, especially for deeper networks. In this paper, we aim to remedy this
problem and propose to remove the residual connection in a vanilla ResNet
equivalently by a reserving and merging (RM) operation on ResBlock.
Specifically, the RM operation allows input feature maps to pass through the
block while reserving their information and merges all the information at the
end of each block, which can remove residual connections without changing the
original output. As a plug-in method, RM Operation basically has three
advantages: 1) its implementation makes it naturally friendly for high ratio
network pruning. 2) it helps break the depth limitation of RepVGG. 3) it leads
to better accuracy-speed trade-off network (RMNet) compared to ResNet and
RepVGG. We believe the ideology of RM Operation can inspire many insights on
model design for the community in the future. Code is available at:
this https URL.</p>
  </details>
</details>
<details>
  <summary>46. <b>标题：Distilling Object Detectors with Feature Richness</b></summary>
  <p><b>编号</b>：[163]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00674</p>
  <p><b>作者</b>：Zhixing Du,  Rui Zhang,  Ming Chang,  Xishan Zhang,  Shaoli Liu,  Tianshi Chen,  Yunji Chen</p>
  <p><b>备注</b>：Accepted in NeurIPS 2021</p>
  <p><b>关键词</b>：based detection methods mainly imitating features near bounding boxes, 101 based teacher detector 38, massive storage requirements make, methods achieve excellent performance, proposed method effectively retrieves</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In recent years, large-scale deep models have achieved great success, but the
huge computational complexity and massive storage requirements make it a great
challenge to deploy them in resource-limited devices. As a model compression
and acceleration method, knowledge distillation effectively improves the
performance of small models by transferring the dark knowledge from the teacher
detector. However, most of the existing distillation-based detection methods
mainly imitating features near bounding boxes, which suffer from two
limitations. First, they ignore the beneficial features outside the bounding
boxes. Second, these methods imitate some features which are mistakenly
regarded as the background by the teacher detector. To address the above
issues, we propose a novel Feature-Richness Score (FRS) method to choose
important features that improve generalized detectability during distilling.
The proposed method effectively retrieves the important features outside the
bounding boxes and removes the detrimental features within the bounding boxes.
Extensive experiments show that our methods achieve excellent performance on
both anchor-based and anchor-free detectors. For example, RetinaNet with
ResNet-50 achieves 39.7% in mAP on the COCO2017 dataset, which even surpasses
the ResNet-101 based teacher detector 38.9% by 0.8%.</p>
  </details>
</details>
<details>
  <summary>47. <b>标题：Evaluation of Human and Machine Face Detection using a Novel Distinctive  Human Appearance Dataset</b></summary>
  <p><b>编号</b>：[169]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00660</p>
  <p><b>作者</b>：Necdet Gurkan,  Jordan W. Suchow</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：every human appearance reflects something unique, distinctive human appearance dataset, accurately localize human faces, development towards creating fairer, significant technical hurdles</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Face detection is a long-standing challenge in the field of computer vision,
with the ultimate goal being to accurately localize human faces in an
unconstrained environment. There are significant technical hurdles in making
these systems accurate due to confounding factors related to pose, image
resolution, illumination, occlusion, and viewpoint [44]. That being said, with
recent developments in machine learning, face-detection systems have achieved
extraordinary accuracy, largely built on data-driven deep-learning models [70].
Though encouraging, a critical aspect that limits face-detection performance
and social responsibility of deployed systems is the inherent diversity of
human appearance. Every human appearance reflects something unique about a
person, including their heritage, identity, experiences, and visible
manifestations of self-expression. However, there are questions about how well
face-detection systems perform when faced with varying face size and shape,
skin color, body modification, and body ornamentation. Towards this goal, we
collected the Distinctive Human Appearance dataset, an image set that
represents appearances with low frequency and that tend to be undersampled in
face datasets. Then, we evaluated current state-of-the-art face-detection
models in their ability to detect faces in these images. The evaluation results
show that face-detection algorithms do not generalize well to these diverse
appearances. Evaluating and characterizing the state of current face-detection
models will accelerate research and development towards creating fairer and
more accurate face-detection systems.</p>
  </details>
</details>
<details>
  <summary>48. <b>标题：Feature Aggregation and Refinement Network for 2D AnatomicalLandmark  Detection</b></summary>
  <p><b>编号</b>：[170]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00659</p>
  <p><b>作者</b>：Yueyuan Ao,  Hong Wu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：novel loss function named exponential weighted center loss, three publicly available anatomical landmark detection datasets, scale feature aggregation module, named feature aggregation, novel deep network</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Localization of anatomical landmarks is essential for clinical diagnosis,
treatment planning, and research. In this paper, we propose a novel deep
network, named feature aggregation and refinement network (FARNet), for the
automatic detection of anatomical landmarks. To alleviate the problem of
limited training data in the medical domain, our network adopts a deep network
pre-trained on natural images as the backbone network and several popular
networks have been compared. Our FARNet also includes a multi-scale feature
aggregation module for multi-scale feature fusion and a feature refinement
module for high-resolution heatmap regression. Coarse-to-fine supervisions are
applied to the two modules to facilitate the end-to-end training. We further
propose a novel loss function named Exponential Weighted Center loss for
accurate heatmap regression, which focuses on the losses from the pixels near
landmarks and suppresses the ones from far away. Our network has been evaluated
on three publicly available anatomical landmark detection datasets, including
cephalometric radiographs, hand radiographs, and spine radiographs, and
achieves state-of-art performances on all three datasets. Code is available at:
\url{this https URL}</p>
  </details>
</details>
<details>
  <summary>49. <b>标题：TriVoC: Efficient Voting-based Consensus Maximization for Robust Point  Cloud Registration with Extreme Outlier Ratios</b></summary>
  <p><b>编号</b>：[172]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00657</p>
  <p><b>作者</b>：Lei Sun,  Lu Deng</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：best rigid transformation aligning two point clouds, makes robust registration methods imperative, 3d keypoint matching approaches, based point cloud registration, reduced correspondence sets according</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Correspondence-based point cloud registration is a cornerstone in robotics
perception and computer vision, which seeks to estimate the best rigid
transformation aligning two point clouds from the putative correspondences.
However, due to the limited robustness of 3D keypoint matching approaches,
outliers, probably in large numbers, are prone to exist among the
correspondences, which makes robust registration methods imperative.
Unfortunately, existing robust methods have their own limitations (e.g. high
computational cost or limited robustness) when facing high or extreme outlier
ratios, probably unsuitable for practical use. In this paper, we present a
novel, fast, deterministic and guaranteed robust solver, named TriVoC
(Triple-layered Voting with Consensus maximization), for the robust
registration problem. We decompose the selecting of the minimal 3-point sets
into 3 consecutive layers, and in each layer we design an efficient voting and
correspondence sorting framework on the basis of the pairwise equal-length
constraint. In this manner, the 3-point sets can be selected independently from
the reduced correspondence sets according to the sorted sequence, which can
significantly lower the computational cost and meanwhile provide a strong
guarantee to achieve the largest consensus set (as the final inlier set) as
long as a probabilistic termination condition is fulfilled. Varied experiments
show that our solver TriVoC is robust against up to 99% outliers, highly
accurate, time-efficient even with extreme outlier ratios, and also practical
for real-world applications, showing performance superior to other
state-of-the-art competitors.</p>
  </details>
</details>
<details>
  <summary>50. <b>标题：Accurate Point Cloud Registration with Robust Optimal Transport</b></summary>
  <p><b>编号</b>：[176]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00648</p>
  <p><b>作者</b>：Zhengyang Shen,  Jean Feydy,  Peirong Liu,  Ariel Hernán Curiale,  Ruben San Jose Estepar,  Raul San Jose Estepar,  Marc Niethammer</p>
  <p><b>备注</b>：Accepted in NeurIPS 2021</p>
  <p><b>关键词</b>：robust ot enables fast pre, recent ot solvers improve, based methods achieve state, point cloud registration algorithms, challenging lung registration task</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This work investigates the use of robust optimal transport (OT) for shape
matching. Specifically, we show that recent OT solvers improve both
optimization-based and deep learning methods for point cloud registration,
boosting accuracy at an affordable computational cost. This manuscript starts
with a practical overview of modern OT theory. We then provide solutions to the
main difficulties in using this framework for shape matching. Finally, we
showcase the performance of transport-enhanced registration models on a wide
range of challenging tasks: rigid registration for partial shapes; scene flow
estimation on the Kitti dataset; and nonparametric registration of lung
vascular trees between inspiration and expiration. Our OT-based methods achieve
state-of-the-art results on Kitti and for the challenging lung registration
task, both in terms of accuracy and scalability. We also release PVT1010, a new
public dataset of 1,010 pairs of lung vascular trees with densely sampled
points. This dataset provides a challenging use case for point cloud
registration algorithms with highly complex shapes and deformations. Our work
demonstrates that robust OT enables fast pre-alignment and fine-tuning for a
wide range of registration models, thereby providing a new key method for the
computer vision toolbox. Our code and dataset are available online at:
this https URL.</p>
  </details>
</details>
<details>
  <summary>51. <b>标题：Learning Distilled Collaboration Graph for Multi-Agent Perception</b></summary>
  <p><b>编号</b>：[177]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00643</p>
  <p><b>作者</b>：Yiming Li,  Shunli Ren,  Pengxiang Wu,  Siheng Chen,  Chen Feng,  Wenjun Zhang</p>
  <p><b>备注</b>：Accepted to 35th Conference on Neural Information Processing Systems (NeurIPS 2021)</p>
  <p><b>关键词</b>：agent 3d object detection show, train discograph via knowledge distillation, shared disconet could collaboratively approach, art collaborative perception methods, novel distilled collaboration graph</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>To promote better performance-bandwidth trade-off for multi-agent perception,
we propose a novel distilled collaboration graph (DiscoGraph) to model
trainable, pose-aware, and adaptive collaboration among agents. Our key
novelties lie in two aspects. First, we propose a teacher-student framework to
train DiscoGraph via knowledge distillation. The teacher model employs an early
collaboration with holistic-view inputs; the student model is based on
intermediate collaboration with single-view inputs. Our framework trains
DiscoGraph by constraining post-collaboration feature maps in the student model
to match the correspondences in the teacher model. Second, we propose a
matrix-valued edge weight in DiscoGraph. In such a matrix, each element
reflects the inter-agent attention at a specific spatial region, allowing an
agent to adaptively highlight the informative regions. During inference, we
only need to use the student model named as the distilled collaboration network
(DiscoNet). Attributed to the teacher-student framework, multiple agents with
the shared DiscoNet could collaboratively approach the performance of a
hypothetical teacher model with a holistic view. Our approach is validated on
V2X-Sim 1.0, a large-scale multi-agent perception dataset that we synthesized
using CARLA and SUMO co-simulation. Our quantitative and qualitative
experiments in multi-agent 3D object detection show that DiscoNet could not
only achieve a better performance-bandwidth trade-off than the state-of-the-art
collaborative perception methods, but also bring more straightforward design
rationale. Our code is available on this https URL.</p>
  </details>
</details>
<details>
  <summary>52. <b>标题：Distantly Supervised Semantic Text Detection and Recognition for  Broadcast Sports Videos Understanding</b></summary>
  <p><b>编号</b>：[182]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00629</p>
  <p><b>作者</b>：Avijit Shah,  Topojoy Biswas,  Sathish Ramadoss,  Deven Santosh Shah</p>
  <p><b>备注</b>：9 pages, 7 figures and 6 tables. To be published in the proceedings of ACM Multimedia 21, Industrial Track, held from October 20-24 in China</p>
  <p><b>关键词</b>：study extremely accurate semantic text detection, extract extremely accurate semantic text, video frames still remains one, automatically build sports clock datasets, novel distant supervision technique</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Comprehensive understanding of key players and actions in multiplayer sports
broadcast videos is a challenging problem. Unlike in news or finance videos,
sports videos have limited text. While both action recognition for multiplayer
sports and detection of players has seen robust research, understanding
contextual text in video frames still remains one of the most impactful avenues
of sports video understanding. In this work we study extremely accurate
semantic text detection and recognition in sports clocks, and challenges
therein. We observe unique properties of sports clocks, which makes it hard to
utilize general-purpose pre-trained detectors and recognizers, so that text can
be accurately understood to the degree of being used to align to external
knowledge. We propose a novel distant supervision technique to automatically
build sports clock datasets. Along with suitable data augmentations, combined
with any state-of-the-art text detection and recognition model architectures,
we extract extremely accurate semantic text. Finally, we share our
computational architecture pipeline to scale this system in industrial setting
and proposed a robust dataset for the same to validate our results.</p>
  </details>
</details>
<details>
  <summary>53. <b>标题：PIE: Pseudo-Invertible Encoder</b></summary>
  <p><b>编号</b>：[186]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00619</p>
  <p><b>作者</b>：Jan Jetze Beitler,  Ivan Sosnovik,  Arnold Smeulders</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：evaluate gaussian pseudo invertible encoder, call pseudo invertible encoders, pseudo bijective architecture, model outperforms wae, introduce new class</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We consider the problem of information compression from high dimensional
data. Where many studies consider the problem of compression by non-invertible
transformations, we emphasize the importance of invertible compression. We
introduce new class of likelihood-based autoencoders with pseudo bijective
architecture, which we call Pseudo Invertible Encoders. We provide the
theoretical explanation of their principles. We evaluate Gaussian Pseudo
Invertible Encoder on MNIST, where our model outperforms WAE and VAE in
sharpness of the generated images.</p>
  </details>
</details>
<details>
  <summary>54. <b>标题：Recognizing Families In the Wild (RFIW): The 5th Edition</b></summary>
  <p><b>编号</b>：[199]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00598</p>
  <p><b>作者</b>：Joseph P. Robinson,  Can Qin,  Ming Shao,  Matthew A. Turk,  Rama Chellappa,  Yun Fu</p>
  <p><b>备注</b>：2021 Conference on Automatic Face and Gesture Recognition</p>
  <p><b>关键词</b>：track visual kinship recognition evaluation, 16th ieee international conference, share current efforts, publish new work, promising future directions</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recognizing Families In the Wild (RFIW), held as a data challenge in
conjunction with the 16th IEEE International Conference on Automatic Face and
Gesture Recognition (FG), is a large-scale, multi-track visual kinship
recognition evaluation. This is our fifth edition of RFIW, for which we
continue the effort to attract scholars, bring together professionals, publish
new work, and discuss prospects. In this paper, we summarize submissions for
the three tasks of this year's RFIW: specifically, we review the results for
kinship verification, tri-subject verification, and family member search and
retrieval. We take a look at the RFIW problem, as well as share current efforts
and make recommendations for promising future directions.</p>
  </details>
</details>
<details>
  <summary>55. <b>标题：From Face to Gait: Weakly-Supervised Learning of Gender Information from  Walking Patterns</b></summary>
  <p><b>编号</b>：[219]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00538</p>
  <p><b>作者</b>：Andy Catruna,  Adrian Cosma,  Ion Emilian Radoi</p>
  <p><b>备注</b>：Accepted at Face & Gesture Recognition 2021</p>
  <p><b>关键词</b>：art facial analysis models, facial analysis models, obtaining demographics information, leverage facial features, automatically annotate front</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Obtaining demographics information from video is valuable for a range of
real-world applications. While approaches that leverage facial features for
gender inference are very successful in restrained environments, they do not
work in most real-world scenarios when the subject is not facing the camera,
has the face obstructed or the face is not clear due to distance from the
camera or poor resolution. We propose a weakly-supervised method for learning
gender information of people based on their manner of walking. We make use of
state-of-the art facial analysis models to automatically annotate front-view
walking sequences and generalise to unseen angles by leveraging gait-based
label propagation. Our results show on par or higher performance with facial
analysis models with an F1 score of 91% and the ability to successfully
generalise to scenarios in which facial analysis is unfeasible due to subjects
not facing the camera or having the face obstructed.</p>
  </details>
</details>
<details>
  <summary>56. <b>标题：Learning Debiased and Disentangled Representations for Semantic  Segmentation</b></summary>
  <p><b>编号</b>：[221]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00531</p>
  <p><b>作者</b>：Sanghyeok Chu,  Dongwan Kim,  Bohyung Han</p>
  <p><b>备注</b>：Accepted by NeurIPS 2021</p>
  <p><b>关键词</b>：complex dense prediction problems including semantic segmentation, effectively reduce feature dependencies among classes, randomly eliminating certain class information, multiple semantic segmentation benchmarks, especially notable performance gains</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep neural networks are susceptible to learn biased models with entangled
feature representations, which may lead to subpar performances on various
downstream tasks. This is particularly true for under-represented classes,
where a lack of diversity in the data exacerbates the tendency. This limitation
has been addressed mostly in classification tasks, but there is little study on
additional challenges that may appear in more complex dense prediction problems
including semantic segmentation. To this end, we propose a model-agnostic and
stochastic training scheme for semantic segmentation, which facilitates the
learning of debiased and disentangled representations. For each class, we first
extract class-specific information from the highly entangled feature map. Then,
information related to a randomly sampled class is suppressed by a feature
selection process in the feature space. By randomly eliminating certain class
information in each training iteration, we effectively reduce feature
dependencies among classes, and the model is able to learn more debiased and
disentangled feature representations. Models trained with our approach
demonstrate strong results on multiple semantic segmentation benchmarks, with
especially notable performance gains on under-represented classes.</p>
  </details>
</details>
<details>
  <summary>57. <b>标题：DRBANET: A Lightweight Dual-Resolution Network for Semantic Segmentation  with Boundary Auxiliary</b></summary>
  <p><b>编号</b>：[228]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00509</p>
  <p><b>作者</b>：Linjie Wang,  Quan Zhou,  Chenfeng Jiang,  Xiaofu Wu,  Longin Jan Latecki</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：extremely lightweight pyramid pooling module, drbanet adopts dual parallel architecture, method achieves promising trade, efficient inverted bottleneck modules, refine semantic segmentation results</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Due to the powerful ability to encode image details and semantics, many
lightweight dual-resolution networks have been proposed in recent years.
However, most of them ignore the benefit of boundary information. This paper
introduces a lightweight dual-resolution network, called DRBANet, aiming to
refine semantic segmentation results with the aid of boundary information.
DRBANet adopts dual parallel architecture, including: high resolution branch
(HRB) and low resolution branch (LRB). Specifically, HRB mainly consists of a
set of Efficient Inverted Bottleneck Modules (EIBMs), which learn feature
representations with larger receptive fields. LRB is composed of a series of
EIBMs and an Extremely Lightweight Pyramid Pooling Module (ELPPM), where ELPPM
is utilized to capture multi-scale context through hierarchical residual
connections. Finally, a boundary supervision head is designed to capture object
boundaries in HRB. Extensive experiments on Cityscapes and CamVid datasets
demonstrate that our method achieves promising trade-off between segmentation
accuracy and running efficiency.</p>
  </details>
</details>
<details>
  <summary>58. <b>标题：Fully convolutional Siamese neural networks for buildings damage  assessment from satellite images</b></summary>
  <p><b>编号</b>：[229]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00508</p>
  <p><b>作者</b>：Eugene Khvedchenya,  Tatiana Gabruseva</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：means processing many square kilometers, process involves acquiring satellite imagery, building damage assessment competition, siamese neural networks, extensive ablation study</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Damage assessment after natural disasters is needed to distribute aid and
forces to recovery from damage dealt optimally. This process involves acquiring
satellite imagery for the region of interest, localization of buildings, and
classification of the amount of damage caused by nature or urban factors to
buildings. In case of natural disasters, this means processing many square
kilometers of the area to judge whether a particular building had suffered from
the damaging factors.
In this work, we develop a computational approach for an automated comparison
of the same region's satellite images before and after the disaster, and
classify different levels of damage in buildings. Our solution is based on
Siamese neural networks with encoder-decoder architecture. We include an
extensive ablation study and compare different encoders, decoders, loss
functions, augmentations, and several methods to combine two images. The
solution achieved one of the best results in the Computer Vision for Building
Damage Assessment competition.</p>
  </details>
</details>
<details>
  <summary>59. <b>标题：DPNET: Dual-Path Network for Efficient Object Detectioj with Lightweight  Self-Attention</b></summary>
  <p><b>编号</b>：[232]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00500</p>
  <p><b>作者</b>：Huimin Shi,  Quan Zhou,  Yinghao Ni,  Xiaofu Wu,  Longin Jan Latecki</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：object detection often costs, efficient object detection, method achieves state, get satisfied performance, feature pyramid network</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Object detection often costs a considerable amount of computation to get
satisfied performance, which is unfriendly to be deployed in edge devices. To
address the trade-off between computational cost and detection accuracy, this
paper presents a dual path network, named DPNet, for efficient object detection
with lightweight self-attention. In backbone, a single input/output lightweight
self-attention module (LSAM) is designed to encode global interactions between
different positions. LSAM is also extended into a multiple-inputs version in
feature pyramid network (FPN), which is employed to capture cross-resolution
dependencies in two paths. Extensive experiments on the COCO dataset
demonstrate that our method achieves state-of-the-art detection results. More
specifically, DPNet obtains 29.0% AP on COCO test-dev, with only 1.14 GFLOPs
and 2.27M model size for a 320x320 image.</p>
  </details>
</details>
<details>
  <summary>60. <b>标题：Smart(Sampling)Augment: Optimal and Efficient Data Augmentation for  Semantic Segmentation</b></summary>
  <p><b>编号</b>：[238]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00487</p>
  <p><b>作者</b>：Misgana Negassi,  Diane Wagner,  Alexander Reiterer</p>
  <p><b>备注</b>：Negassi and Wagner provided an equal contribution</p>
  <p><b>关键词</b>：data augmentation methods enrich datasets, fixed augmentation strategy competes, automated data augmentation methods, smartaugment uses bayesian optimization, design choices behind smartaugment</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Data augmentation methods enrich datasets with augmented data to improve the
performance of neural networks. Recently, automated data augmentation methods
have emerged, which automatically design augmentation strategies. Existing work
focuses on image classification and object detection, whereas we provide the
first study on semantic image segmentation and introduce two new approaches:
\textit{SmartAugment} and \textit{SmartSamplingAugment}. SmartAugment uses
Bayesian Optimization to search over a rich space of augmentation strategies
and achieves a new state-of-the-art performance in all semantic segmentation
tasks we consider. SmartSamplingAugment, a simple parameter-free approach with
a fixed augmentation strategy competes in performance with the existing
resource-intensive approaches and outperforms cheap state-of-the-art data
augmentation methods. Further, we analyze the impact, interaction, and
importance of data augmentation hyperparameters and perform ablation studies,
which confirm our design choices behind SmartAugment and SmartSamplingAugment.
Lastly, we will provide our source code for reproducibility and to facilitate
further research.</p>
  </details>
</details>
<details>
  <summary>61. <b>标题：Learned Image Compression with Separate Hyperprior Decoders</b></summary>
  <p><b>编号</b>：[240]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00485</p>
  <p><b>作者</b>：Zhao Zan,  Chao Liu,  Heming Sun,  Xiaoyang Zeng,  Yibo Fan</p>
  <p><b>备注</b>：This paper has been accepted by IEEE Open Journal of Circuits and Systems</p>
  <p><b>关键词</b>：ternary gaussian model collapses, learned image compression techniques, discrete gaussian mixture likelihoods, use three hyperprior decoders, single hyperprior decoder</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Learned image compression techniques have achieved considerable development
in recent years. In this paper, we find that the performance bottleneck lies in
the use of a single hyperprior decoder, in which case the ternary Gaussian
model collapses to a binary one. To solve this, we propose to use three
hyperprior decoders to separate the decoding process of the mixed parameters in
discrete Gaussian mixture likelihoods, achieving more accurate parameters
estimation. Experimental results demonstrate the proposed method optimized by
MS-SSIM achieves on average 3.36% BD-rate reduction compared with
state-of-the-art approach. The contribution of the proposed method to the
coding time and FLOPs is negligible.</p>
  </details>
</details>
<details>
  <summary>62. <b>标题：Gaussian Kernel Mixture Network for Single Image Defocus Deblurring</b></summary>
  <p><b>编号</b>：[250]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00454</p>
  <p><b>作者</b>：Yuhui Quan,  Zicong Wu,  Hui Ji</p>
  <p><b>备注</b>：Accepted by NeurIPS 2021</p>
  <p><b>关键词</b>：noticeably outperforms existing defocus deblurring methods, representing spatially variant defocus blur kernels, deep neural network called gkmnet, wise gaussian kernel mixture, efficient linear parametric form</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Defocus blur is one kind of blur effects often seen in images, which is
challenging to remove due to its spatially variant amount. This paper presents
an end-to-end deep learning approach for removing defocus blur from a single
image, so as to have an all-in-focus image for consequent vision tasks. First,
a pixel-wise Gaussian kernel mixture (GKM) model is proposed for representing
spatially variant defocus blur kernels in an efficient linear parametric form,
with higher accuracy than existing models. Then, a deep neural network called
GKMNet is developed by unrolling a fixed-point iteration of the GKM-based
deblurring. The GKMNet is built on a lightweight scale-recurrent architecture,
with a scale-recurrent attention module for estimating the mixing coefficients
in GKM for defocus deblurring. Extensive experiments show that the GKMNet not
only noticeably outperforms existing defocus deblurring methods, but also has
its advantages in terms of model complexity and computational efficiency.</p>
  </details>
</details>
<details>
  <summary>63. <b>标题：Loop closure detection using local 3D deep descriptors</b></summary>
  <p><b>编号</b>：[253]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00440</p>
  <p><b>作者</b>：Youjie Zhou,  Yiming Wang,  Fabio Poiesi,  Qi Qin,  Yi Wan</p>
  <p><b>备注</b>：This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible</p>
  <p><b>关键词</b>：mapping using local 3d deep descriptors, art loop closure detection accuracy, simple yet effective method, original loop closure strategy, better localisation accuracy compared</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present a simple yet effective method to address loop closure detection in
simultaneous localisation and mapping using local 3D deep descriptors (L3Ds).
L3Ds are emerging compact representations of patches extracted from point
clouds that are learned from data using a deep learning algorithm. We propose a
novel overlap measure for loop detection by computing the metric error between
points that correspond to mutually-nearest-neighbour descriptors after
registering the loop candidate point cloud by its estimated relative pose. This
novel approach enables us to accurately detect loops and estimate six
degrees-of-freedom poses in the case of small overlaps. We compare our
L3D-based loop closure approach with recent approaches on LiDAR data and
achieve state-of-the-art loop closure detection accuracy. Additionally, we
embed our loop closure approach in RESLAM, a recent edge-based SLAM system, and
perform the evaluation on real-world RGBD-TUM and synthetic ICL datasets. Our
approach enables RESLAM to achieve a better localisation accuracy compared to
its original loop closure strategy.</p>
  </details>
</details>
<details>
  <summary>64. <b>标题：Hierarchical Deep Residual Reasoning for Temporal Moment Localization</b></summary>
  <p><b>编号</b>：[265]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00417</p>
  <p><b>作者</b>：Ziyang Ma,  Xianjing Han,  Xuemeng Song,  Yiran Cui,  Liqiang Nie</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：simple yet effective res, hierarchical deep residual reasoning, existing methods mainly focus, works mainly understand, extensive experiments conducted</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Temporal Moment Localization (TML) in untrimmed videos is a challenging task
in the field of multimedia, which aims at localizing the start and end points
of the activity in the video, described by a sentence query. Existing methods
mainly focus on mining the correlation between video and sentence
representations or investigating the fusion manner of the two modalities. These
works mainly understand the video and sentence coarsely, ignoring the fact that
a sentence can be understood from various semantics, and the dominant words
affecting the moment localization in the semantics are the action and object
reference. Toward this end, we propose a Hierarchical Deep Residual Reasoning
(HDRR) model, which decomposes the video and sentence into multi-level
representations with different semantics to achieve a finer-grained
localization. Furthermore, considering that videos with different resolution
and sentences with different length have different difficulty in understanding,
we design the simple yet effective Res-BiGRUs for feature fusion, which is able
to grasp the useful information in a self-adapting manner. Extensive
experiments conducted on Charades-STA and ActivityNet-Captions datasets
demonstrate the superiority of our HDRR model compared with other
state-of-the-art methods.</p>
  </details>
</details>
<details>
  <summary>65. <b>标题：PANet: Perspective-Aware Network with Dynamic Receptive Fields and  Self-Distilling Supervision for Crowd Counting</b></summary>
  <p><b>编号</b>：[270]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00406</p>
  <p><b>作者</b>：Xiaoshuang Chen,  Yiru Zhao,  Yu Qin,  Fei Jiang,  Mingyuan Tao,  Xiansheng Hua,  Hongtao Lu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：dilated convolution parameters according, aware approach called panet, proposed panet outperforms, use gaussian kernels, ucf_cc_50 datasets demonstrate</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Crowd counting aims to learn the crowd density distributions and estimate the
number of objects (e.g. persons) in images. The perspective effect, which
significantly influences the distribution of data points, plays an important
role in crowd counting. In this paper, we propose a novel perspective-aware
approach called PANet to address the perspective problem. Based on the
observation that the size of the objects varies greatly in one image due to the
perspective effect, we propose the dynamic receptive fields (DRF) framework.
The framework is able to adjust the receptive field by the dilated convolution
parameters according to the input image, which helps the model to extract more
discriminative features for each local region. Different from most previous
works which use Gaussian kernels to generate the density map as the supervised
information, we propose the self-distilling supervision (SDS) training method.
The ground-truth density maps are refined from the first training stage and the
perspective information is distilled to the model in the second stage. The
experimental results on ShanghaiTech Part_A and Part_B, UCF_QNRF, and UCF_CC_50
datasets demonstrate that our proposed PANet outperforms the state-of-the-art
methods by a large margin.</p>
  </details>
</details>
<details>
  <summary>66. <b>标题：A Simple Approach to Image Tilt Correction with Self-Attention MobileNet  for Smartphones</b></summary>
  <p><b>编号</b>：[274]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00398</p>
  <p><b>作者</b>：Siddhant Garg,  Debi Prasanna Mohanty,  Siva Prasad Thota,  Sukumar Moharana</p>
  <p><b>备注</b>：Accepted - British Machine vision Conference 2021</p>
  <p><b>关键词</b>：standard convolutional kernels, snapdragon 750 octa, predict multiple angles, least 4 milliseconds, inverted bottleneck blocks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The main contributions of our work are two-fold. First, we present a
Self-Attention MobileNet, called SA-MobileNet Network that can model long-range
dependencies between the image features instead of processing the local region
as done by standard convolutional kernels. SA-MobileNet contains self-attention
modules integrated with the inverted bottleneck blocks of the MobileNetV3 model
which results in modeling of both channel-wise attention and spatial attention
of the image features and at the same time introduce a novel self-attention
architecture for low-resource devices. Secondly, we propose a novel training
pipeline for the task of image tilt detection. We treat this problem in a
multi-label scenario where we predict multiple angles for a tilted input image
in a narrow interval of range 1-2 degrees, depending on the dataset used. This
process induces an implicit correlation between labels without any
computational overhead of the second or higher-order methods in multi-label
learning. With the combination of our novel approach and the architecture, we
present state-of-the-art results on detecting the image tilt angle on mobile
devices as compared to the MobileNetV3 model. Finally, we establish that
SA-MobileNet is more accurate than MobileNetV3 on SUN397, NYU-V1, and ADE20K
datasets by 6.42%, 10.51%, and 9.09% points respectively, and faster by at
least 4 milliseconds on Snapdragon 750 Octa-core.</p>
  </details>
</details>
<details>
  <summary>67. <b>标题：3DP3: 3D Scene Perception via Probabilistic Programming</b></summary>
  <p><b>编号</b>：[298]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00312</p>
  <p><b>作者</b>：Nishad Gothoskar,  Marco Cusumano-Towner,  Ben Zinberg,  Matin Ghavamizadeh,  Falk Pollok,  Austin Garrett,  Joshua B. Tenenbaum,  Dan Gutfreund,  Vikash K. Mansinghka</p>
  <p><b>备注</b>：NeurIPS 2021</p>
  <p><b>关键词</b>：novel involutive mcmc updates, depth image likelihoods based, underlying latent 3d scene, 6dof object pose estimation, 3dp3 enables scene understanding</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present 3DP3, a framework for inverse graphics that uses inference in a
structured generative model of objects, scenes, and images. 3DP3 uses (i) voxel
models to represent the 3D shape of objects, (ii) hierarchical scene graphs to
decompose scenes into objects and the contacts between them, and (iii) depth
image likelihoods based on real-time graphics. Given an observed RGB-D image,
3DP3's inference algorithm infers the underlying latent 3D scene, including the
object poses and a parsimonious joint parametrization of these poses, using
fast bottom-up pose proposals, novel involutive MCMC updates of the scene graph
structure, and, optionally, neural object detectors and pose estimators. We
show that 3DP3 enables scene understanding that is aware of 3D shape,
occlusion, and contact structure. Our results demonstrate that 3DP3 is more
accurate at 6DoF object pose estimation from real images than deep learning
baselines and shows better generalization to challenging scenes with novel
viewpoints, contact, and partial observability.</p>
  </details>
</details>
<details>
  <summary>68. <b>标题：A fast accurate fine-grain object detection model based on YOLOv4 deep  neural network</b></summary>
  <p><b>编号</b>：[305]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00298</p>
  <p><b>作者</b>：Arunabha M. Roy,  Rikhi Bose,  Jayabrata Bhaduri</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：mean average precision ($ map $) value, various automated agricultural detection processes, two new residual blocks, modified path aggregation network, modified network architecture maximizes</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Early identification and prevention of various plant diseases in commercial
farms and orchards is a key feature of precision agriculture technology. This
paper presents a high-performance real-time fine-grain object detection
framework that addresses several obstacles in plant disease detection that
hinder the performance of traditional methods, such as, dense distribution,
irregular morphology, multi-scale object classes, textural similarity, etc. The
proposed model is built on an improved version of the You Only Look Once
(YOLOv4) algorithm. The modified network architecture maximizes both detection
accuracy and speed by including the DenseNet in the back-bone to optimize
feature transfer and reuse, two new residual blocks in the backbone and neck
enhance feature extraction and reduce computing cost; the Spatial Pyramid
Pooling (SPP) enhances receptive field, and a modified Path Aggregation Network
(PANet) preserves fine-grain localized information and improve feature fusion.
Additionally, the use of the Hard-Swish function as the primary activation
improved the model's accuracy due to better nonlinear feature extraction. The
proposed model is tested in detecting four different diseases in tomato plants
under various challenging environments. The model outperforms the existing
state-of-the-art detection models in detection accuracy and speed. At a
detection rate of 70.19 FPS, the proposed model obtained a precision value of
$90.33 \%$, F1-score of $93.64 \%$, and a mean average precision ($mAP$) value
of $96.29 \%$. Current work provides an effective and efficient method for
detecting different plant diseases in complex scenarios that can be extended to
different fruit and crop detection, generic disease detection, and various
automated agricultural detection processes.</p>
  </details>
</details>
<details>
  <summary>69. <b>标题：Get Fooled for the Right Reason: Improving Adversarial Robustness  through a Teacher-guided Curriculum Learning Approach</b></summary>
  <p><b>编号</b>：[306]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00295</p>
  <p><b>作者</b>：Anindya Sarkar,  Anirban Sarkar,  Sowrya Gali,  Vineeth N Balasubramanian</p>
  <p><b>备注</b>：16 pages, 9 figures, Accepted at NeurIPS 2021, Code at this https URL</p>
  <p><b>关键词</b>：many popular strong adversarial attacks, method achieves significant performance gains, current sota adversarially robust models, adversarially robust models compared, naturally trained models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Current SOTA adversarially robust models are mostly based on adversarial
training (AT) and differ only by some regularizers either at inner maximization
or outer minimization steps. Being repetitive in nature during the inner
maximization step, they take a huge time to train. We propose a non-iterative
method that enforces the following ideas during training. Attribution maps are
more aligned to the actual object in the image for adversarially robust models
compared to naturally trained models. Also, the allowed set of pixels to
perturb an image (that changes model decision) should be restricted to the
object pixels only, which reduces the attack strength by limiting the attack
space. Our method achieves significant performance gains with a little extra
effort (10-20%) over existing AT models and outperforms all other methods in
terms of adversarial as well as natural accuracy. We have performed extensive
experimentation with CIFAR-10, CIFAR-100, and TinyImageNet datasets and
reported results against many popular strong adversarial attacks to prove the
effectiveness of our method.</p>
  </details>
</details>
<details>
  <summary>70. <b>标题：MFNet: Multi-class Few-shot Segmentation Network with Pixel-wise Metric  Learning</b></summary>
  <p><b>编号</b>：[326]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00232</p>
  <p><b>作者</b>：Miao Zhang,  Miaojing Shi,  Li Li</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：wise metric learning module, deep learning development, visual recognition tasks, triplet loss formulated, standard benchmarks pascal</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In visual recognition tasks, few-shot learning requires the ability to learn
object categories with few support examples. Its recent resurgence in light of
the deep learning development is mainly in image classification. This work
focuses on few-shot semantic segmentation, which is still a largely unexplored
field. A few recent advances are often restricted to single-class few-shot
segmentation. In this paper, we first present a novel multi-way encoding and
decoding architecture which effectively fuses multi-scale query information and
multi-class support information into one query-support embedding; multi-class
segmentation is directly decoded upon this embedding. In order for better
feature fusion, a multi-level attention mechanism is proposed within the
architecture, which includes the attention for support feature modulation and
attention for multi-scale combination. Last, to enhance the embedding space
learning, an additional pixel-wise metric learning module is devised with
triplet loss formulated on the pixel-level embedding of the input image.
Extensive experiments on standard benchmarks PASCAL-5^i and COCO-20^i show
clear benefits of our method over the state of the art in few-shot
segmentation.</p>
  </details>
</details>
<details>
  <summary>71. <b>标题：Two Heads are Better than One: Geometric-Latent Attention for Point  Cloud Classification and Segmentation</b></summary>
  <p><b>编号</b>：[327]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00231</p>
  <p><b>作者</b>：Hanz Cuevas-Velasquez,  Antonio Javier Gallego,  Robert B. Fisher</p>
  <p><b>备注</b>：Accepted in BMVC 2021</p>
  <p><b>关键词</b>：learn better local relationships, overall accuracy using k, local attention layer, simple yet robust, semantically meaningful subsets</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present an innovative two-headed attention layer that combines geometric
and latent features to segment a 3D scene into semantically meaningful subsets.
Each head combines local and global information, using either the geometric or
latent features, of a neighborhood of points and uses this information to learn
better local relationships. This Geometric-Latent attention layer (Ge-Latto) is
combined with a sub-sampling strategy to capture global features. Our method is
invariant to permutation thanks to the use of shared-MLP layers, and it can
also be used with point clouds with varying densities because the local
attention layer does not depend on the neighbor order. Our proposal is simple
yet robust, which allows it to achieve competitive results in the ShapeNetPart
and ModelNet40 datasets, and the state-of-the-art when segmenting the complex
dataset S3DIS, with 69.2% IoU on Area 5, and 89.7% overall accuracy using
K-fold cross-validation on the 6 areas.</p>
  </details>
</details>
<details>
  <summary>72. <b>标题：A Spatio-Temporal Identity Verification Method for Person-Action  Instance Search in Movies</b></summary>
  <p><b>编号</b>：[330]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00228</p>
  <p><b>作者</b>：Jingyao Yang,  Chao Liang,  Yanrui Niu,  Baojin Huang,  Zhongyuan Wang</p>
  <p><b>备注</b>：13 pages, 12 figures</p>
  <p><b>关键词</b>：existing methods mainly include two steps, two individual ins scores cannot guarantee, large scale trecvid ins dataset, face detection results usually locate, two individual ins branches</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As one of the challenging problems in video search, Person-Action Instance
Search (INS) aims to retrieve shots with specific person carrying out specific
action from massive video shots. Existing methods mainly include two steps:
First, two individual INS branches, i.e., person INS and action INS, are
separately conducted to compute the initial person and action ranking scores;
Second, both scores are directly fused to generate the final ranking list.
However, direct aggregation of two individual INS scores cannot guarantee the
identity consistency between person and action. For example, a shot with "Pat
is standing" and "Ian is sitting on couch" may be erroneously understood as
"Pat is sitting on couch" or "Ian is standing". To address the above identity
inconsistency problem (IIP), we study a spatio-temporal identity verification
method. Specifically, in the spatial dimension, we propose an identity
consistency verification scheme to optimize the direct fusion score of person
INS and action INS. The motivation originates from an observation that face
detection results usually locate in the identity-consistent action bounding
boxes. Moreover, in the temporal dimension, considering the complex filming
condition, we propose an inter-frame detection extension operation to
interpolate missing face/action detection results in successive video frames.
The proposed method is evaluated on the large scale TRECVID INS dataset, and
the experimental results show that our method can effectively mitigate the IIP
and surpass the existing second places in both TRECVID 2019 and 2020 INS tasks.</p>
  </details>
</details>
<details>
  <summary>73. <b>标题：Mastering Atari Games with Limited Data</b></summary>
  <p><b>编号</b>：[337]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00210</p>
  <p><b>作者</b>：Weirui Ye,  Shaohuai Liu,  Thanard Kurutach,  Pieter Abbeel,  Yang Gao</p>
  <p><b>备注</b>：Published at NeurIPS 2021</p>
  <p><b>关键词</b>：consume 500 times less data, based visual rl algorithm built, prominent methods requiring millions, atari game benchmark remains, based rl algorithms</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Reinforcement learning has achieved great success in many applications.
However, sample efficiency remains a key challenge, with prominent methods
requiring millions (or even billions) of environment steps to train. Recently,
there has been significant progress in sample efficient image-based RL
algorithms; however, consistent human-level performance on the Atari game
benchmark remains an elusive goal. We propose a sample efficient model-based
visual RL algorithm built on MuZero, which we name EfficientZero. Our method
achieves 190.4% mean human performance and 116.0% median performance on the
Atari 100k benchmark with only two hours of real-time game experience and
outperforms the state SAC in some tasks on the DMControl 100k benchmark. This
is the first time an algorithm achieves super-human performance on Atari games
with such little data. EfficientZero's performance is also close to DQN's
performance at 200 million frames while we consume 500 times less data.
EfficientZero's low sample complexity and high performance can bring RL closer
to real-world applicability. We implement our algorithm in an
easy-to-understand manner and it is available at
this https URL. We hope it will accelerate the research
of MCTS-based RL algorithms in the wider community.</p>
  </details>
</details>
<details>
  <summary>74. <b>标题：PatchFormer: A Versatile 3D Transformer Based on Patch Attention</b></summary>
  <p><b>编号</b>：[338]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00207</p>
  <p><b>作者</b>：Zhang Cheng,  Haocheng Wan,  Xinyi Shen,  Zizhao Wu</p>
  <p><b>备注</b>：10 pages, 5 figures</p>
  <p><b>关键词</b>：neural architecture called patchformer, major 3d learning benchmarks, general 3d recognition tasks, network achieves strong accuracy, build attentions among features</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The 3D vision community is witnesses a modeling shift from CNNs to
Transformers, where pure Transformer architectures have attained top accuracy
on the major 3D learning benchmarks. However, existing 3D Transformers need to
generate a large attention map, which has quadratic complexity (both in space
and time) with respect to input size. To solve this shortcoming, we introduce
patch-attention to adaptively learn a much smaller set of bases upon which the
attention maps are computed. By a weighted summation upon these bases,
patch-attention not only captures the global shape context but also achieves
linear complexity to input size. In addition, we propose a lightweight
Multi-scale Attention (MSA) block to build attentions among features of
different scales, providing the model with multi-scale features. Based on these
proposed modules, we construct our neural architecture called PatchFormer.
Extensive experiments demonstrate that our network achieves strong accuracy on
general 3D recognition tasks with 7.3x speed-up than previous 3D Transformers.</p>
  </details>
</details>
<details>
  <summary>75. <b>标题：Imitating Arbitrary Talking Style for Realistic Audio-DrivenTalking Face  Synthesis</b></summary>
  <p><b>编号</b>：[340]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00203</p>
  <p><b>作者</b>：Haozhe Wu,  Jia Jia,  Haoyu Wang,  Yishun Dou,  Chao Duan,  Qingshan Deng</p>
  <p><b>备注</b>：Accepted by MM2021, code available at this https URL</p>
  <p><b>关键词</b>：different talking styles exhibit significant differences, 3d morphable model ~( 3dmm, driven talking face synthesis framework, seldomly exhibits exaggerated motions, talking face synthesis framework</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>People talk with diversified styles. For one piece of speech, different
talking styles exhibit significant differences in the facial and head pose
movements. For example, the "excited" style usually talks with the mouth wide
open, while the "solemn" style is more standardized and seldomly exhibits
exaggerated motions. Due to such huge differences between different styles, it
is necessary to incorporate the talking style into audio-driven talking face
synthesis framework. In this paper, we propose to inject style into the talking
face synthesis framework through imitating arbitrary talking style of the
particular reference video. Specifically, we systematically investigate talking
styles with our collected \textit{Ted-HD} dataset and construct style codes as
several statistics of 3D morphable model~(3DMM) parameters. Afterwards, we
devise a latent-style-fusion~(LSF) model to synthesize stylized talking faces
by imitating talking styles from the style codes. We emphasize the following
novel characteristics of our framework: (1) It doesn't require any annotation
of the style, the talking style is learned in an unsupervised manner from
talking videos in the wild. (2) It can imitate arbitrary styles from arbitrary
videos, and the style codes can also be interpolated to generate new styles.
Extensive experiments demonstrate that the proposed framework has the ability
to synthesize more natural and expressive talking styles compared with baseline
methods.</p>
  </details>
</details>
<details>
  <summary>76. <b>标题：A Comparative Review of Recent Few-Shot Object Detection Algorithms</b></summary>
  <p><b>编号</b>：[342]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00201</p>
  <p><b>作者</b>：Leng Jiaxu,  Chen Taiyue,  Gao Xinbo,  Yu Yongtao,  Wang Ye,  Gao Feng,  Wang Yue</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：shot detectors refine robust task notions, extra datasets without target, shot object detection, shot object detection, shot object detection</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Few-shot object detection, learning to adapt to the novel classes with a few
labeled data, is an imperative and long-lasting problem due to the inherent
long-tail distribution of real-world data and the urgent demands to cut costs
of data collection and annotation. Recently, some studies have explored how to
use implicit cues in extra datasets without target-domain supervision to help
few-shot detectors refine robust task notions. This survey provides a
comprehensive overview from current classic and latest achievements for
few-shot object detection to future research expectations from manifold
perspectives. In particular, we first propose a data-based taxonomy of the
training data and the form of corresponding supervision which are accessed
during the training stage. Following this taxonomy, we present a significant
review of the formal definition, main challenges, benchmark datasets,
evaluation metrics, and learning strategies. In addition, we present a detailed
investigation of how to interplay the object detection methods to develop this
issue systematically. Finally, we conclude with the current status of few-shot
object detection, along with potential research directions for this field.</p>
  </details>
</details>
<details>
  <summary>77. <b>标题：Leveraging SE(3) Equivariance for Self-Supervised Category-Level Object  Pose Estimation</b></summary>
  <p><b>编号</b>：[349]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00190</p>
  <p><b>作者</b>：Xiaolong Li,  Yijia Weng,  Li Yi,  Leonidas Guibas,  A. Lynn Abbott,  Shuran Song,  He Wang</p>
  <p><b>备注</b>：20 pages, 11 figures</p>
  <p><b>关键词</b>：equivariant pose estimation module achieves category, level reference frame without using, invariant shape reconstruction module learns, level object pose estimation aims, equivariant pose estimation module</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Category-level object pose estimation aims to find 6D object poses of
previously unseen object instances from known categories without access to
object CAD models. To reduce the huge amount of pose annotations needed for
category-level learning, we propose for the first time a self-supervised
learning framework to estimate category-level 6D object pose from single 3D
point clouds.During training, our method assumes no ground-truth pose
annotations, no CAD models, and no multi-view supervision. The key to our
method is to disentangle shape and pose through an invariant shape
reconstruction module and an equivariant pose estimation module, empowered by
SE(3) equivariant point cloud networks.The invariant shape reconstruction
module learns to perform aligned reconstructions, yielding a category-level
reference frame without using any annotations. In addition, the equivariant
pose estimation module achieves category-level pose estimation accuracy that is
comparable to some fully supervised methods. Extensive experiments demonstrate
the effectiveness of our approach on both complete and partial depth point
clouds from the ModelNet40 benchmark, and on real depth point clouds from the
NOCS-REAL 275 dataset. The project page with code and visualizations can be
found at: this https URL.</p>
  </details>
</details>
<details>
  <summary>78. <b>标题：Geometry-Aware Hierarchical Bayesian Learning on Manifolds</b></summary>
  <p><b>编号</b>：[351]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00184</p>
  <p><b>作者</b>：Yonghui Fan,  Yalin Wang</p>
  <p><b>备注</b>：Published in WACV 2022</p>
  <p><b>关键词</b>：gaussian processes demonstrates encouraging regression, method outperforms existing bayesian methods, enables geometrically reasonable inferences, efficiently aggregate geometric features, solving computer vision tasks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Bayesian learning with Gaussian processes demonstrates encouraging regression
and classification performances in solving computer vision tasks. However,
Bayesian methods on 3D manifold-valued vision data, such as meshes and point
clouds, are seldom studied. One of the primary challenges is how to effectively
and efficiently aggregate geometric features from the irregular inputs. In this
paper, we propose a hierarchical Bayesian learning model to address this
challenge. We initially introduce a kernel with the properties of
geometry-awareness and intra-kernel convolution. This enables geometrically
reasonable inferences on manifolds without using any specific hand-crafted
feature descriptors. Then, we use a Gaussian process regression to organize the
inputs and finally implement a hierarchical Bayesian network for the feature
aggregation. Furthermore, we incorporate the feature learning of neural
networks with the feature aggregation of Bayesian models to investigate the
feasibility of jointly learning on manifolds. Experimental results not only
show that our method outperforms existing Bayesian methods on manifolds but
also demonstrate the prospect of coupling neural networks with Bayesian
networks.</p>
  </details>
</details>
<details>
  <summary>79. <b>标题：Direct attacks using fake images in iris verification</b></summary>
  <p><b>编号</b>：[353]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00178</p>
  <p><b>作者</b>：Virginia Ruiz-Albacete,  Pedro Tome-Gonzalez,  Fernando Alonso-Fernandez,  Javier Galbally,  Julian Fierrez,  Javier Ortega-Garcia</p>
  <p><b>备注</b>：Published at European Workshop on Biometrics and Identity Management (BIOID)</p>
  <p><b>关键词</b>：publicly available iris recognition system, different operational scenarios, based recognition systems, iris segmentation step, fake iris images</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this contribution, the vulnerabilities of iris-based recognition systems
to direct attacks are studied. A database of fake iris images has been created
from real iris of the BioSec baseline database. Iris images are printed using a
commercial printer and then, presented at the iris sensor. We use for our
experiments a publicly available iris recognition system, which some
modifications to improve the iris segmentation step. Based on results achieved
on different operational scenarios, we show that the system is vulnerable to
direct attacks, pointing out the importance of having countermeasures against
this type of fraudulent actions.</p>
  </details>
</details>
<details>
  <summary>80. <b>标题：Iris Recognition Based on SIFT Features</b></summary>
  <p><b>编号</b>：[355]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00176</p>
  <p><b>作者</b>：Fernando Alonso-Fernandez,  Pedro Tome-Gonzalez,  Virginia Ruiz-Albacete,  Javier Ortega-Garcia</p>
  <p><b>备注</b>：Published at IEEE International Conference on Biometrics, Identity and Security (BIdS)</p>
  <p><b>关键词</b>：allowing less constrained image acquisition conditions, two approaches achieves significantly better performance, extract characteristic sift feature points, traditional iris recognition systems, popular matching approach based</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Biometric methods based on iris images are believed to allow very high
accuracy, and there has been an explosion of interest in iris biometrics in
recent years. In this paper, we use the Scale Invariant Feature Transformation
(SIFT) for recognition using iris images. Contrarily to traditional iris
recognition systems, the SIFT approach does not rely on the transformation of
the iris pattern to polar coordinates or on highly accurate segmentation,
allowing less constrained image acquisition conditions. We extract
characteristic SIFT feature points in scale space and perform matching based on
the texture information around the feature points using the SIFT operator.
Experiments are done using the BioSec multimodal database, which includes 3,200
iris images from 200 individuals acquired in two different sessions. We
contribute with the analysis of the influence of different SIFT parameters on
the recognition performance. We also show the complementarity between the SIFT
approach and a popular matching approach based on transformation to polar
coordinates and Log-Gabor wavelets. The combination of the two approaches
achieves significantly better performance than either of the individual
schemes, with a performance improvement of 24% in the Equal Error Rate.</p>
  </details>
</details>
<details>
  <summary>81. <b>标题：HIERMATCH: Leveraging Label Hierarchies for Improving Semi-Supervised  Learning</b></summary>
  <p><b>编号</b>：[362]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00164</p>
  <p><b>作者</b>：Ashima Garg,  Shaurya Bagga,  Yashvardhan Singh,  Saket Anand</p>
  <p><b>备注</b>：10 pages, 1 figure, Accepted in WACV 2022</p>
  <p><b>关键词</b>：supervision using coarse category labels, uses coarse class labels, g ., downy woodpeckers, g ., woodpeckers, fronted woodpeckers ).</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Semi-supervised learning approaches have emerged as an active area of
research to combat the challenge of obtaining large amounts of annotated data.
Towards the goal of improving the performance of semi-supervised learning
methods, we propose a novel framework, HIERMATCH, a semi-supervised approach
that leverages hierarchical information to reduce labeling costs and performs
as well as a vanilla semi-supervised learning method. Hierarchical information
is often available as prior knowledge in the form of coarse labels (e.g.,
woodpeckers) for images with fine-grained labels (e.g., downy woodpeckers or
golden-fronted woodpeckers). However, the use of supervision using coarse
category labels to improve semi-supervised techniques has not been explored. In
the absence of fine-grained labels, HIERMATCH exploits the label hierarchy and
uses coarse class labels as a weak supervisory signal. Additionally, HIERMATCH
is a generic-approach to improve any semisupervised learning framework, we
demonstrate this using our results on recent state-of-the-art techniques
MixMatch and FixMatch. We evaluate the efficacy of HIERMATCH on two benchmark
datasets, namely CIFAR-100 and NABirds. HIERMATCH can reduce the usage of
fine-grained labels by 50% on CIFAR-100 with only a marginal drop of 0.59% in
top-1 accuracy as compared to MixMatch.</p>
  </details>
</details>
<details>
  <summary>82. <b>标题：DIB-R++: Learning to Predict Lighting and Material with a Hybrid  Differentiable Renderer</b></summary>
  <p><b>编号</b>：[374]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00140</p>
  <p><b>作者</b>：Wenzheng Chen,  Joey Litalien,  Jun Gao,  Zian Wang,  Clement Fuji Tsang,  Sameh Khamis,  Or Litany,  Sanja Fidler</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：showcase several artistic applications including material editing, based differentiable renderers leveraging path tracing, via spherical basis functions, specular reflections commonly observed, respective strengths -- speed</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We consider the challenging problem of predicting intrinsic object properties
from a single image by exploiting differentiable renderers. Many previous
learning-based approaches for inverse graphics adopt rasterization-based
renderers and assume naive lighting and material models, which often fail to
account for non-Lambertian, specular reflections commonly observed in the wild.
In this work, we propose DIBR++, a hybrid differentiable renderer which
supports these photorealistic effects by combining rasterization and
ray-tracing, taking the advantage of their respective strengths -- speed and
realism. Our renderer incorporates environmental lighting and spatially-varying
material models to efficiently approximate light transport, either through
direct estimation or via spherical basis functions. Compared to more advanced
physics-based differentiable renderers leveraging path tracing, DIBR++ is
highly performant due to its compact and expressive shading model, which
enables easy integration with learning frameworks for geometry, reflectance and
lighting prediction from a single image without requiring any ground-truth. We
experimentally demonstrate that our approach achieves superior material and
lighting disentanglement on synthetic and real data compared to existing
rasterization-based approaches and showcase several artistic applications
including material editing and relighting.</p>
  </details>
</details>
<details>
  <summary>83. <b>标题：Three approaches to facilitate DNN generalization to objects in  out-of-distribution orientations and illuminations: late-stopping, tuning  batch normalization and invariance loss</b></summary>
  <p><b>编号</b>：[376]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00131</p>
  <p><b>作者</b>：Akira Sakai,  Taro Sunagawa,  Spandan Madan,  Kanata Suzuki,  Takashi Katoh,  Hiromichi Kobashi,  Hanspeter Pfister,  Pawan Sinha,  Xavier Boix,  Tomotake Sasaki</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：enable ood accuracy gains -- individual neurons, often biased towards objects, investigate three different approaches, three approaches focus, approaches substantially improves</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The training data distribution is often biased towards objects in certain
orientations and illumination conditions. While humans have a remarkable
capability of recognizing objects in out-of-distribution (OoD) orientations and
illuminations, Deep Neural Networks (DNNs) severely suffer in this case, even
when large amounts of training examples are available. In this paper, we
investigate three different approaches to improve DNNs in recognizing objects
in OoD orientations and illuminations. Namely, these are (i) training much
longer after convergence of the in-distribution (InD) validation accuracy,
i.e., late-stopping, (ii) tuning the momentum parameter of the batch
normalization layers, and (iii) enforcing invariance of the neural activity in
an intermediate layer to orientation and illumination conditions. Each of these
approaches substantially improves the DNN's OoD accuracy (more than 20% in some
cases). We report results in four datasets: two datasets are modified from the
MNIST and iLab datasets, and the other two are novel (one of 3D rendered cars
and another of objects taken from various controlled orientations and
illumination conditions). These datasets allow to study the effects of
different amounts of bias and are challenging as DNNs perform poorly in OoD
conditions. Finally, we demonstrate that even though the three approaches focus
on different aspects of DNNs, they all tend to lead to the same underlying
neural mechanism to enable OoD accuracy gains -- individual neurons in the
intermediate layers become more selective to a category and also invariant to
OoD orientations and illuminations.</p>
  </details>
</details>
<details>
  <summary>84. <b>标题：Predicting Atlantic Multidecadal Variability</b></summary>
  <p><b>编号</b>：[379]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00124</p>
  <p><b>作者</b>：Glenn Liu,  Peidong Wang,  Matthew Beveridge,  Young-Oh Kwon,  Iddo Drori</p>
  <p><b>备注</b>：7 pages, 3 figures</p>
  <p><b>关键词</b>：community earth system model 1 large ensemble project, work tests multiple machine learning models, amv strongly impacts local climate, north atlantic sea surface temperature, traditional persistence forecast baseline</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Atlantic Multidecadal Variability (AMV) describes variations of North
Atlantic sea surface temperature with a typical cycle of between 60 and 70
years. AMV strongly impacts local climate over North America and Europe,
therefore prediction of AMV, especially the extreme values, is of great
societal utility for understanding and responding to regional climate change.
This work tests multiple machine learning models to improve the state of AMV
prediction from maps of sea surface temperature, salinity, and sea level
pressure in the North Atlantic region. We use data from the Community Earth
System Model 1 Large Ensemble Project, a state-of-the-art climate model with
3,440 years of data. Our results demonstrate that all of the models we use
outperform the traditional persistence forecast baseline. Predicting the AMV is
important for identifying future extreme temperatures and precipitation, as
well as hurricane activity, in Europe and North America up to 25 years in
advance.</p>
  </details>
</details>
<details>
  <summary>85. <b>标题：Longitudinal Analysis of Mask and No-Mask on Child Face Recognition</b></summary>
  <p><b>编号</b>：[382]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00121</p>
  <p><b>作者</b>：Praveen Kumar Chandaliya,  Zahid Akhtar,  Neeta Nain</p>
  <p><b>备注</b>：6 Pages, 3 Figure</p>
  <p><b>关键词</b>：e ., extended indian child longitudinal face dataset, three top performing publicly available face matchers, mask longitudinal child face dataset, child longitudinal impact together, still face obstacles caused</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Face is one of the most widely employed traits for person recognition, even
in many large-scale applications. Despite technological advancements in face
recognition systems, they still face obstacles caused by pose, expression,
occlusion, and aging variations. Owing to the COVID-19 pandemic, contactless
identity verification has become exceedingly vital. To constrain the pandemic,
people have started using face mask. Recently, few studies have been conducted
on the effect of face mask on adult face recognition systems. However, the
impact of aging with face mask on child subject recognition has not been
adequately explored. Thus, the main objective of this study is analyzing the
child longitudinal impact together with face mask and other covariates on face
recognition systems. Specifically, we performed a comparative investigation of
three top performing publicly available face matchers and a post-COVID-19
commercial-off-the-shelf (COTS) system under child cross-age verification and
identification settings using our generated synthetic mask and no-mask samples.
Furthermore, we investigated the longitudinal consequence of eyeglasses with
mask and no-mask. The study exploited no-mask longitudinal child face dataset
(i.e., extended Indian Child Longitudinal Face Dataset) that contains $26,258$
face images of $7,473$ subjects in the age group of $[2, 18]$ over an average
time span of $3.35$ years. Experimental results showed that problem of face
mask on automated face recognition is compounded by aging variate.</p>
  </details>
</details>
<details>
  <summary>86. <b>标题：Visual Explanations for Convolutional Neural Networks via Latent  Traversal of Generative Adversarial Networks</b></summary>
  <p><b>编号</b>：[384]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00116</p>
  <p><b>作者</b>：Amil Dravid,  Aggelos K. Katsaggelos</p>
  <p><b>备注</b>：2 pages, 2 figures, to appear as extended abstract at AAAI-22</p>
  <p><b>关键词</b>：gan framework disentangles lung structure, weighted class activation mapping, utilizing generative adversarial networks, specifically deep neural networks, convolutional neural network</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Lack of explainability in artificial intelligence, specifically deep neural
networks, remains a bottleneck for implementing models in practice. Popular
techniques such as Gradient-weighted Class Activation Mapping (Grad-CAM)
provide a coarse map of salient features in an image, which rarely tells the
whole story of what a convolutional neural network (CNN) learned. Using
COVID-19 chest X-rays, we present a method for interpreting what a CNN has
learned by utilizing Generative Adversarial Networks (GANs). Our GAN framework
disentangles lung structure from COVID-19 features. Using this GAN, we can
visualize the transition of a pair of COVID negative lungs in a chest
radiograph to a COVID positive pair by interpolating in the latent space of the
GAN, which provides fine-grained visualization of how the CNN responds to
varying features within the lungs.</p>
  </details>
</details>
<details>
  <summary>87. <b>标题：Classification of jujube fruit based on several pricing factors using  machine learning methods</b></summary>
  <p><b>编号</b>：[387]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00112</p>
  <p><b>作者</b>：Abdollah Zakeri,  Ruhollah Hedayati,  Mohammad Khedmati,  Mehran Taghipour-Gorjikolaie</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：useful features using feature selection algorithms like pca, grading jujube fruits using machine learning techniques, first acquire several images, machine learning methods, using decision tree</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Jujube is a fruit mainly cultivated in India, China and Iran and has many
health benefits. It is sold both fresh and dried. There are several factors in
jujube pricing such as weight, wrinkles and defections. Some jujube farmers
sell their product all at once, without any proper sorting or classification,
for an average price. Our studies and experiences show that their profit can
increase significantly if their product is sold after the sorting process.
There are some traditional sorting methods for dried jujube fruit but they are
costly, time consuming and can be inaccurate due to human error. Nowadays,
computer vision combined with machine learning methods, is used increasingly in
food industry for sorting and classification purposes and solve many of the
traditional sorting methods' problems. In this paper we are proposing a
computer vision-based method for grading jujube fruits using machine learning
techniques which will take most of the important pricing factors into account
and can be used to increase the profit of farmers. In this method we first
acquire several images from different samples and then extract their visual
features such as color features, shape and size features, texture features,
defection and wrinkle features and then we select the most useful features
using feature selection algorithms like PCA and CFS. A feature vector is
obtained for each sample and we use these vectors to train our classifiers to
be able to specify the corresponding pre-defined group for each of the samples.
We used different classifiers and training methods in order to obtain the best
result and by using decision tree we could reach 98.8% accuracy of the
classification.</p>
  </details>
</details>
<details>
  <summary>88. <b>标题：FC2T2: The Fast Continuous Convolutional Taylor Transform with  Applications in Vision and Graphics</b></summary>
  <p><b>编号</b>：[388]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00110</p>
  <p><b>作者</b>：Henning Lange,  J. Nathan Kutz</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：fast continuous convolutional taylor transform, low dimensional convolutional operators, require repeated function evaluations, unlike regular neural networks, modern machine learning perspective</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Series expansions have been a cornerstone of applied mathematics and
engineering for centuries. In this paper, we revisit the Taylor series
expansion from a modern Machine Learning perspective. Specifically, we
introduce the Fast Continuous Convolutional Taylor Transform (FC2T2), a variant
of the Fast Multipole Method (FMM), that allows for the efficient approximation
of low dimensional convolutional operators in continuous space. We build upon
the FMM which is an approximate algorithm that reduces the computational
complexity of N-body problems from O(NM) to O(N+M) and finds application in
e.g. particle simulations. As an intermediary step, the FMM produces a series
expansion for every cell on a grid and we introduce algorithms that act
directly upon this representation. These algorithms analytically but
approximately compute the quantities required for the forward and backward pass
of the backpropagation algorithm and can therefore be employed as (implicit)
layers in Neural Networks. Specifically, we introduce a root-implicit layer
that outputs surface normals and object distances as well as an
integral-implicit layer that outputs a rendering of a radiance field given a 3D
pose. In the context of Machine Learning, $N$ and $M$ can be understood as the
number of model parameters and model evaluations respectively which entails
that, for applications that require repeated function evaluations which are
prevalent in Computer Vision and Graphics, unlike regular Neural Networks, the
techniques introduce in this paper scale gracefully with parameters. For some
applications, this results in a 200x reduction in FLOPs compared to
state-of-the-art approaches at a reasonable or non-existent loss in accuracy.</p>
  </details>
</details>
<details>
  <summary>89. <b>标题：Deep Deterministic Uncertainty for Semantic Segmentation</b></summary>
  <p><b>编号</b>：[403]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00079</p>
  <p><b>作者</b>：Jishnu Mukhoti,  Joost van Amersfoort,  Philip H.S. Torr,  Yarin Gal</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：uncertainty estimation using feature space densities, ddu improves upon mc dropout, apply ddu location independently, extend deep deterministic uncertainty, pixel dependent ddu</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We extend Deep Deterministic Uncertainty (DDU), a method for uncertainty
estimation using feature space densities, to semantic segmentation. DDU enables
quantifying and disentangling epistemic and aleatoric uncertainty in a single
forward pass through the model. We study the similarity of feature
representations of pixels at different locations for the same class and
conclude that it is feasible to apply DDU location independently, which leads
to a significant reduction in memory consumption compared to pixel dependent
DDU. Using the DeepLab-v3+ architecture on Pascal VOC 2012, we show that DDU
improves upon MC Dropout and Deep Ensembles while being significantly faster to
compute.</p>
  </details>
</details>
<details>
  <summary>90. <b>标题：Polyline Based Generative Navigable Space Segmentation for Autonomous  Visual Navigation</b></summary>
  <p><b>编号</b>：[411]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00063</p>
  <p><b>作者</b>：Zheng Chen,  Zhengming Ding,  David Crandall,  Lantao Liu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：propose polyline segmentation variational autoencoder networks, current segmentation techniques heavily rely, visual receding horizon planning method, scaled euclidean distance field, achieve autonomous navigation without</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Detecting navigable space is a fundamental capability for mobile robots
navigating in unknown or unmapped environments. In this work, we treat the
visual navigable space segmentation as a scene decomposition problem and
propose Polyline Segmentation Variational AutoEncoder Networks (PSV-Nets), a
representation-learning-based framework to enable robots to learn the navigable
space segmentation in an unsupervised manner. Current segmentation techniques
heavily rely on supervised learning strategies which demand a large amount of
pixel-level annotated images. In contrast, the proposed framework leverages a
generative model - Variational AutoEncoder (VAE) and an AutoEncoder (AE) to
learn a polyline representation that compactly outlines the desired navigable
space boundary in an unsupervised way. We also propose a visual receding
horizon planning method that uses the learned navigable space and a Scaled
Euclidean Distance Field (SEDF) to achieve autonomous navigation without an
explicit map. Through extensive experiments, we have validated that the
proposed PSV-Nets can learn the visual navigable space with high accuracy, even
without any single label. We also show that the prediction of the PSV-Nets can
be further improved with a small number of labels (if available) and can
significantly outperform the state-of-the-art fully supervised-learning-based
segmentation methods.</p>
  </details>
</details>
<details>
  <summary>91. <b>标题：Generalized Data Weighting via Class-level Gradient Manipulation</b></summary>
  <p><b>编号</b>：[414]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00056</p>
  <p><b>作者</b>：Can Chen,  Shuhao Zheng,  Xi Chen,  Erqun Dong,  Xue Liu,  Hao Liu,  Dejing Dou</p>
  <p><b>备注</b>：17 pages, 8 figures, accepted by NeurIPS 2021 for a poster session, camera-ready version, initial submission to arXiv</p>
  <p><b>关键词</b>：60 \%$ uniform noise setting, gdw achieves remarkable performance improvement, extra computational cost compared, simultaneously mitigate label noise, propose generalized data weighting</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Label noise and class imbalance are two major issues coexisting in real-world
datasets. To alleviate the two issues, state-of-the-art methods reweight each
instance by leveraging a small amount of clean and unbiased data. Yet, these
methods overlook class-level information within each instance, which can be
further utilized to improve performance. To this end, in this paper, we propose
Generalized Data Weighting (GDW) to simultaneously mitigate label noise and
class imbalance by manipulating gradients at the class level. To be specific,
GDW unrolls the loss gradient to class-level gradients by the chain rule and
reweights the flow of each gradient separately. In this way, GDW achieves
remarkable performance improvement on both issues. Aside from the performance
gain, GDW efficiently obtains class-level weights without introducing any extra
computational cost compared with instance weighting methods. Specifically, GDW
performs a gradient descent step on class-level weights, which only relies on
intermediate gradients. Extensive experiments in various settings verify the
effectiveness of GDW. For example, GDW outperforms state-of-the-art methods by
$2.56\%$ under the $60\%$ uniform noise setting in CIFAR10. Our code is
available at this https URL.</p>
  </details>
</details>
<details>
  <summary>92. <b>标题：CvS: Classification via Segmentation For Small Datasets</b></summary>
  <p><b>编号</b>：[418]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00042</p>
  <p><b>作者</b>：Nooshin Mojab,  Philip S. Yu,  Joelle A. Hallak,  Darvin Yi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：computer vision applications across various domains, achieve much higher classification results compared, deep learning methods relies heavily, deep learning models, shown promising results</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep learning models have shown promising results in a wide range of computer
vision applications across various domains. The success of deep learning
methods relies heavily on the availability of a large amount of data. Deep
neural networks are prone to overfitting when data is scarce. This problem
becomes even more severe for neural network with classification head with
access to only a few data points. However, acquiring large-scale datasets is
very challenging, laborious, or even infeasible in some domains. Hence,
developing classifiers that are able to perform well in small data regimes is
crucial for applications with limited data. This paper presents CvS, a
cost-effective classifier for small datasets that derives the classification
labels from predicting the segmentation maps. We employ the label propagation
method to achieve a fully segmented dataset with only a handful of manually
segmented data. We evaluate the effectiveness of our framework on diverse
problems showing that CvS is able to achieve much higher classification results
compared to previous methods when given only a handful of examples.</p>
  </details>
</details>
<details>
  <summary>93. <b>标题：On-device Real-time Hand Gesture Recognition</b></summary>
  <p><b>编号</b>：[419]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00038</p>
  <p><b>作者</b>：George Sung,  Kanstantsin Sokal,  Esha Uboweja,  Valentin Bazarevsky,  Jonathan Baccash,  Eduard Gabriel Bazavan,  Chuo-Ling Chang,  Matthias Grundmann</p>
  <p><b>备注</b>：5 pages, 6 figures; ICCV Workshop on Computer Vision for Augmented and Virtual Reality, Montreal, Canada, 2021</p>
  <p><b>关键词</b>：create two different gesture classifiers, time hand gesture recognition, hand skeleton tracker, hand skeleton tracker, world metric space</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present an on-device real-time hand gesture recognition (HGR) system,
which detects a set of predefined static gestures from a single RGB camera. The
system consists of two parts: a hand skeleton tracker and a gesture classifier.
We use MediaPipe Hands as the basis of the hand skeleton tracker, improve the
keypoint accuracy, and add the estimation of 3D keypoints in a world metric
space. We create two different gesture classifiers, one based on heuristics and
the other using neural networks (NN).</p>
  </details>
</details>
<details>
  <summary>94. <b>标题：Domain Agnostic Few-Shot Learning For Document Intelligence</b></summary>
  <p><b>编号</b>：[423]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00007</p>
  <p><b>作者</b>：Jaya Krishna Mandivarapu,  Eric bunch,  Glenn fung</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：proposed method shows consistent improvements, shot document image classification, experimental results demonstrate, methods also aim, collecting large samples</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Few-shot learning aims to generalize to novel classes with only a few samples
with class labels. Research in few-shot learning has borrowed techniques from
transfer learning, metric learning, meta-learning, and Bayesian methods. These
methods also aim to train models from limited training samples, and while
encouraging performance has been achieved, they often fail to generalize to
novel domains. Many of the existing meta-learning methods rely on training data
for which the base classes are sampled from the same domain as the novel
classes used for meta-testing. However, in many applications in the industry,
such as document classification, collecting large samples of data for
meta-learning is infeasible or impossible. While research in the field of the
cross-domain few-shot learning exists, it is mostly limited to computer vision.
To our knowledge, no work yet exists that examines the use of few-shot learning
for classification of semi-structured documents (scans of paper documents)
generated as part of a business workflow (forms, letters, bills, etc.). Here
the domain shift is significant, going from natural images to the
semi-structured documents of interest. In this work, we address the problem of
few-shot document image classification under domain shift. We evaluate our work
by extensive comparisons with existing methods. Experimental results
demonstrate that the proposed method shows consistent improvements on the
few-shot classification performance under domain shift.</p>
  </details>
</details>
<details>
  <summary>95. <b>标题：Adaptive Hierarchical Similarity Metric Learning with Noisy Labels</b></summary>
  <p><b>编号</b>：[424]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00006</p>
  <p><b>作者</b>：Jiexi Yan,  Lei Luo,  Cheng Deng,  Heng Huang</p>
  <p><b>备注</b>：11 pages, 5 figures</p>
  <p><b>关键词</b>：noisy labels often cause severe performance degradation, effectively excavate richer similarity information beyond binary, adaptive hierarchical similarity metric learning method, existing deep metric learning methods, current deep metric learning approaches</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep Metric Learning (DML) plays a critical role in various machine learning
tasks. However, most existing deep metric learning methods with binary
similarity are sensitive to noisy labels, which are widely present in
real-world data. Since these noisy labels often cause severe performance
degradation, it is crucial to enhance the robustness and generalization ability
of DML. In this paper, we propose an Adaptive Hierarchical Similarity Metric
Learning method. It considers two noise-insensitive information, \textit{i.e.},
class-wise divergence and sample-wise consistency. Specifically, class-wise
divergence can effectively excavate richer similarity information beyond binary
in modeling by taking advantage of Hyperbolic metric learning, while
sample-wise consistency can further improve the generalization ability of the
model using contrastive augmentation. More importantly, we design an adaptive
strategy to integrate this information in a unified view. It is noteworthy that
the new method can be extended to any pair-based metric loss. Extensive
experimental results on benchmark datasets demonstrate that our method achieves
state-of-the-art performance compared with current deep metric learning
approaches.</p>
  </details>
</details>
<details>
  <summary>96. <b>标题：Correlation between image quality metrics of magnetic resonance images  and the neural network segmentation accuracy</b></summary>
  <p><b>编号</b>：[430]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.01093</p>
  <p><b>作者</b>：Rajarajeswari Muthusivarajan,  Adrian Celaya,  Joshua P. Yung,  Satish Viswanath,  Daniel S. Marcus,  Caroline Chung,  David Fuentes</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：iqm based training inputs shed light, multilevel connections process input data, magnetic resonance images enables learning, training data set based, networks learning efficiency depends</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep neural networks with multilevel connections process input data in
complex ways to learn the information.A networks learning efficiency depends
not only on the complex neural network architecture but also on the input
training images.Medical image segmentation with deep neural networks for skull
stripping or tumor segmentation from magnetic resonance images enables learning
both global and local features of the images.Though medical images are
collected in a controlled environment,there may be artifacts or equipment based
variance that cause inherent bias in the input this http URL this study, we
investigated the correlation between the image quality metrics of MR images
with the neural network segmentation accuracy.For that we have used the 3D
DenseNet architecture and let the network trained on the same input but
applying different methodologies to select the training data set based on the
IQM values.The difference in the segmentation accuracy between models based on
the random training inputs with IQM based training inputs shed light on the
role of image quality metrics on segmentation this http URL running the image
quality metrics to choose the training inputs,further we may tune the learning
efficiency of the network and the segmentation accuracy.</p>
  </details>
</details>
<details>
  <summary>97. <b>标题：Robustness of deep learning algorithms in astronomy -- galaxy morphology  studies</b></summary>
  <p><b>编号</b>：[440]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00961</p>
  <p><b>作者</b>：A. Ćiprijanović,  D. Kafkes,  G. N. Perdue,  K. Pedro,  G. Snyder,  F. J. Sánchez,  S. Madireddy,  S. M. Wild,  B. Nord</p>
  <p><b>备注</b>：Accepted in: Fourth Workshop on Machine Learning and the Physical Sciences (35th Conference on Neural Information Processing Systems; NeurIPS2021); final version</p>
  <p><b>关键词</b>：help improve model robustness, help scientists build, naturally occurring attacks, domain adaptation techniques, common image processing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep learning models are being increasingly adopted in wide array of
scientific domains, especially to handle high-dimensionality and volume of the
scientific data. However, these models tend to be brittle due to their
complexity and overparametrization, especially to the inadvertent adversarial
perturbations that can appear due to common image processing such as
compression or blurring that are often seen with real scientific data. It is
crucial to understand this brittleness and develop models robust to these
adversarial perturbations. To this end, we study the effect of observational
noise from the exposure time, as well as the worst case scenario of a one-pixel
attack as a proxy for compression or telescope errors on performance of
ResNet18 trained to distinguish between galaxies of different morphologies in
LSST mock data. We also explore how domain adaptation techniques can help
improve model robustness in case of this type of naturally occurring attacks
and help scientists build more trustworthy and stable models.</p>
  </details>
</details>
<details>
  <summary>98. <b>标题：IRA: A shape matching approach for recognition and comparison of generic  atomic patterns</b></summary>
  <p><b>编号</b>：[441]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00939</p>
  <p><b>作者</b>：Miha Gunde,  Nicolas Salles,  Anne Hémeryck,  Layla Martin-Samos</p>
  <p><b>备注</b>：18 pages, 19 figures</p>
  <p><b>关键词</b>：algorithm iteratively suggests rotated atom, standard singular value decomposition, including distorted structural fragments, constrained shortest distance assignments, returns minimal value</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose a versatile, parameter-less approach for solving the shape
matching problem, specifically in the context of atomic structures when atomic
assignments are not known a priori. The algorithm Iteratively suggests Rotated
atom-centered reference frames and Assignments (Iterative Rotations and
Assignments, IRA). The frame for which a permutationally invariant set-set
distance, namely the Hausdorff distance, returns minimal value is chosen as the
solution of the matching problem. IRA is able to find rigid rotations,
reflections, translations, and permutations between structures with different
numbers of atoms, for any atomic arrangement and pattern, periodic or not. When
distortions are present between the structures, optimal rotation and
translation are found by further applying a standard Singular Value
Decomposition-based method. To compute the atomic assignments under the
one-to-one assignment constraint, we develop our own algorithm, Constrained
Shortest Distance Assignments (CShDA). The overall approach is extensively
tested on several structures, including distorted structural fragments.
Efficiency of the proposed algorithm is shown as a benchmark comparison against
two other shape matching algorithms. We discuss the use of our approach for the
identification and comparison of structures and structural fragments through
two examples: a replica exchange trajectory of a cyanine molecule, in which we
show how our approach could aid the exploration of relevant collective
coordinates for clustering the data; and an SiO$_2$ amorphous model, in which
we compute distortion scores and compare them with a classical strain-based
potential. The source code and benchmark data are available at
\url{this https URL}.</p>
  </details>
</details>
<details>
  <summary>99. <b>标题：Simulating Realistic MRI variations to Improve Deep Learning model and  visual explanations using GradCAM</b></summary>
  <p><b>编号</b>：[446]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00837</p>
  <p><b>作者</b>：Muhammad Ilyas Patel,  Shrey Singla,  Razeem Ahmad Ali Mattathodi,  Sumit Sharma,  Deepam Gautam,  Srinivasa Rao Kundeti</p>
  <p><b>备注</b>：8 pages, 9 figures, IEEE-CCEM 2021 conference</p>
  <p><b>关键词</b>：solving brain mri volumetric landmark detection problem, three respective views -- sagittal, proposed method shows favorable results, generate synthetic 3d volumetric data, weighted class activation mapping</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In the medical field, landmark detection in MRI plays an important role in
reducing medical technician efforts in tasks like scan planning, image
registration, etc. First, 88 landmarks spread across the brain anatomy in the
three respective views -- sagittal, coronal, and axial are manually annotated,
later guidelines from the expert clinical technicians are taken
sub-anatomy-wise, for better localization of the existing landmarks, in order
to identify and locate the important atlas landmarks even in oblique scans. To
overcome limited data availability, we implement realistic data augmentation to
generate synthetic 3D volumetric data. We use a modified HighRes3DNet model for
solving brain MRI volumetric landmark detection problem. In order to visually
explain our trained model on unseen data, and discern a stronger model from a
weaker model, we implement Gradient-weighted Class Activation Mapping
(Grad-CAM) which produces a coarse localization map highlighting the regions
the model is focusing. Our experiments show that the proposed method shows
favorable results, and the overall pipeline can be extended to a variable
number of landmarks and other anatomies.</p>
  </details>
</details>
<details>
  <summary>100. <b>标题：Redundancy Reduction in Semantic Segmentation of 3D Brain Tumor MRIs</b></summary>
  <p><b>编号</b>：[453]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00742</p>
  <p><b>作者</b>：Md Mahfuzur Rahman Siddiquee,  Andriy Myronenko</p>
  <p><b>备注</b>：BraTS 2021, BrainLes, MICCAI 2021</p>
  <p><b>关键词</b>：within top 10 performing teams, multimodal brain tumor segmentation challenge, brain tumor segmentation methods, confidence based ensembling techniques, decoder based segmentation network</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Another year of the multimodal brain tumor segmentation challenge (BraTS)
2021 provides an even larger dataset to facilitate collaboration and research
of brain tumor segmentation methods, which are necessary for disease analysis
and treatment planning. A large dataset size of BraTS 2021 and the advent of
modern GPUs provide a better opportunity for deep-learning based approaches to
learn tumor representation from the data. In this work, we maintained an
encoder-decoder based segmentation network, but focused on a modification of
network training process that minimizes redundancy under perturbations. Given a
set trained networks, we further introduce a confidence based ensembling
techniques to further improve the performance. We evaluated the method on BraTS
2021 validation board, and achieved 0.8600, 0.8868 and 0.9265 average dice for
enhanced tumor core, tumor core and whole tumor, respectively. Our team
(NVAUTO) submission was the top performing in terms of ET and TC scores and
within top 10 performing teams in terms of WT scores.</p>
  </details>
</details>
<details>
  <summary>101. <b>标题：Influential Prototypical Networks for Few Shot Learning: A  Dermatological Case Study</b></summary>
  <p><b>编号</b>：[455]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00698</p>
  <p><b>作者</b>：Ranjana Roy Chowdhury,  Deepti R. Bathula</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：three different benchmark dermatological datasets, conventional pn attributes equal importance, support sample embeddings belonging, support sample distribution, simple yet effective</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Prototypical network (PN) is a simple yet effective few shot learning
strategy. It is a metric-based meta-learning technique where classification is
performed by computing Euclidean distances to prototypical representations of
each class. Conventional PN attributes equal importance to all samples and
generates prototypes by simply averaging the support sample embeddings
belonging to each class. In this work, we propose a novel version of PN that
attributes weights to support samples corresponding to their influence on the
support sample distribution. Influence weights of samples are calculated based
on maximum mean discrepancy (MMD) between the mean embeddings of sample
distributions including and excluding the sample. Comprehensive evaluation of
our proposed influential PN (IPNet) is performed by comparing its performance
with other baseline PNs on three different benchmark dermatological datasets.
IPNet outperforms all baseline models with compelling results across all three
datasets and various N-way, K-shot classification tasks. Findings from
cross-domain adaptation experiments further establish the robustness and
generalizability of IPNet.</p>
  </details>
</details>
<details>
  <summary>102. <b>标题：Self-Verification in Image Denoising</b></summary>
  <p><b>编号</b>：[456]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00666</p>
  <p><b>作者</b>：Huangxing Lin,  Yihong Zhuang,  Delu Zeng,  Yue Huang,  Xinghao Ding,  John Paisley</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：level image statistics needed, various denoising tasks using, deep image prior learned, observed corrupted data, denoising performance close</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We devise a new regularization, called self-verification, for image
denoising. This regularization is formulated using a deep image prior learned
by the network, rather than a traditional predefined prior. Specifically, we
treat the output of the network as a ``prior'' that we denoise again after
``re-noising''. The comparison between the again denoised image and its prior
can be interpreted as a self-verification of the network's denoising ability.
We demonstrate that self-verification encourages the network to capture
low-level image statistics needed to restore the image. Based on this
self-verification regularization, we further show that the network can learn to
denoise even if it has not seen any clean images. This learning strategy is
self-supervised, and we refer to it as Self-Verification Image Denoising
(SVID). SVID can be seen as a mixture of learning-based methods and traditional
model-based denoising methods, in which regularization is adaptively formulated
using the output of the network. We show the application of SVID to various
denoising tasks using only observed corrupted data. It can achieve the
denoising performance close to supervised CNNs.</p>
  </details>
</details>
<details>
  <summary>103. <b>标题：TorchXRayVision: A library of chest X-ray datasets and models</b></summary>
  <p><b>编号</b>：[459]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00595</p>
  <p><b>作者</b>：Joseph Paul Cohen,  Joseph D. Viviano,  Paul Bertin,  Paul Morrison,  Parsa Torabian,  Matteo Guarrera,  Matthew P Lungren,  Akshay Chaudhari,  Rupert Brooks,  Mohammad Hashir,  Hadrien Bertrand</p>
  <p><b>备注</b>：Library source code: this https URL</p>
  <p><b>关键词</b>：open source software library, publicly available chest x, representation learning models, deep learning models, different data combinations</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>TorchXRayVision is an open source software library for working with chest
X-ray datasets and deep learning models. It provides a common interface and
common pre-processing chain for a wide set of publicly available chest X-ray
datasets. In addition, a number of classification and representation learning
models with different architectures, trained on different data combinations,
are available through the library to serve as baselines or feature extractors.</p>
  </details>
</details>
<details>
  <summary>104. <b>标题：Learning to Detect Open Carry and Concealed Object with 77GHz Radar</b></summary>
  <p><b>编号</b>：[462]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00551</p>
  <p><b>作者</b>：Xiangyu Gao,  Hui Liu,  Sumit Roy,  Guanbin Xing,  Ali Alansari,  Youchen Luo</p>
  <p><b>备注</b>：12 pages</p>
  <p><b>关键词</b>：detect carried objects using 77ghz radar, detecting harmful carried objects plays, cost 77ghz mmwave radar, carried objects detection problem, time detecting three classes</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Detecting harmful carried objects plays a key role in intelligent
surveillance systems and has widespread applications, for example, in airport
security. In this paper, we focus on the relatively unexplored area of using
low-cost 77GHz mmWave radar for the carried objects detection problem. The
proposed system is capable of real-time detecting three classes of objects -
laptop, phone, and knife - under open carry and concealed cases where objects
are hidden with clothes or bags. This capability is achieved by initial signal
processing for localization and generating range-azimuth-elevation image cubes,
followed by a deep learning-based prediction network and a multi-shot
post-processing module for detecting objects. Extensive experiments for
validating the system performance on detecting open carry and concealed objects
have been presented with a self-built radar-camera testbed and dataset.
Additionally, the influence of different input, factors, and parameters on
system performance is analyzed, providing an intuitive understanding of the
system. This system would be the very first baseline for other future works
aiming to detect carried objects using 77GHz radar.</p>
  </details>
</details>
<details>
  <summary>105. <b>标题：Focal Attention Networks: optimising attention for biomedical image  segmentation</b></summary>
  <p><b>编号</b>：[463]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00534</p>
  <p><b>作者</b>：Michael Yeung,  Leonardo Rundo,  Evis Sala,  Carola-Bibiane Schönlieb,  Guang Yang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：attention mechanisms enables flexible integration, validated biomedical imaging datasets, focal distance penalty term, unified focal loss framework, convolutional neural network architectures</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In recent years, there has been increasing interest to incorporate attention
into deep learning architectures for biomedical image segmentation. The modular
design of attention mechanisms enables flexible integration into convolutional
neural network architectures, such as the U-Net. Whether attention is
appropriate to use, what type of attention to use, and where in the network to
incorporate attention modules, are all important considerations that are
currently overlooked. In this paper, we investigate the role of the Focal
parameter in modulating attention, revealing a link between attention in loss
functions and networks. By incorporating a Focal distance penalty term, we
extend the Unified Focal loss framework to include boundary-based losses.
Furthermore, we develop a simple and interpretable, dataset and model-specific
heuristic to integrate the Focal parameter into the Squeeze-and-Excitation
block and Attention Gate, achieving optimal performance with fewer number of
attention modules on three well-validated biomedical imaging datasets,
suggesting judicious use of attention modules results in better performance and
efficiency.</p>
  </details>
</details>
<details>
  <summary>106. <b>标题：Incorporating Boundary Uncertainty into loss functions for biomedical  image segmentation</b></summary>
  <p><b>编号</b>：[464]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00533</p>
  <p><b>作者</b>：Michael Yeung,  Guang Yang,  Evis Sala,  Carola-Bibiane Schönlieb,  Leonardo Rundo</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：achieving consistently improved performance across three well, validated biomedical imaging datasets compared, automated image segmentation tasks, enable robust model training, neither approach accurately reflects</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Manual segmentation is used as the gold-standard for evaluating neural
networks on automated image segmentation tasks. Due to considerable
heterogeneity in shapes, colours and textures, demarcating object boundaries is
particularly difficult in biomedical images, resulting in significant inter and
intra-rater variability. Approaches, such as soft labelling and distance
penalty term, apply a global transformation to the ground truth, redefining the
loss function with respect to uncertainty. However, global operations are
computationally expensive, and neither approach accurately reflects the
uncertainty underlying manual annotation. In this paper, we propose the
Boundary Uncertainty, which uses morphological operations to restrict soft
labelling to object boundaries, providing an appropriate representation of
uncertainty in ground truth labels, and may be adapted to enable robust model
training where systematic manual segmentation errors are present. We
incorporate Boundary Uncertainty with the Dice loss, achieving consistently
improved performance across three well-validated biomedical imaging datasets
compared to soft labelling and distance-weighted penalty. Boundary Uncertainty
not only more accurately reflects the segmentation process, but it is also
efficient, robust to segmentation errors and exhibits better generalisation.</p>
  </details>
</details>
<details>
  <summary>107. <b>标题：Calibrating the Dice loss to handle neural network overconfidence for  biomedical image segmentation</b></summary>
  <p><b>编号</b>：[465]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00528</p>
  <p><b>作者</b>：Michael Yeung,  Leonardo Rundo,  Yang Nan,  Evis Sala,  Carola-Bibiane Schönlieb,  Guang Yang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：dsc ++ loss achieves significantly improved calibration, conventional dsc loss across five well, deep learning based biomedical image segmentation, training deep learning segmentation models, well calibrated outputs enable tailoring</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The Dice similarity coefficient (DSC) is both a widely used metric and loss
function for biomedical image segmentation due to its robustness to class
imbalance. However, it is well known that the DSC loss is poorly calibrated,
resulting in overconfident predictions that cannot be usefully interpreted in
biomedical and clinical practice. Performance is often the only metric used to
evaluate segmentations produced by deep neural networks, and calibration is
often neglected. However, calibration is important for translation into
biomedical and clinical practice, providing crucial contextual information to
model predictions for interpretation by scientists and clinicians. In this
study, we identify poor calibration as an emerging challenge of deep learning
based biomedical image segmentation. We provide a simple yet effective
extension of the DSC loss, named the DSC++ loss, that selectively modulates the
penalty associated with overconfident, incorrect predictions. As a standalone
loss function, the DSC++ loss achieves significantly improved calibration over
the conventional DSC loss across five well-validated open-source biomedical
imaging datasets. Similarly, we observe significantly improved when integrating
the DSC++ loss into four DSC-based loss functions. Finally, we use softmax
thresholding to illustrate that well calibrated outputs enable tailoring of
precision-recall bias, an important post-processing technique to adapt the
model predictions to suit the biomedical or clinical task. The DSC++ loss
overcomes the major limitation of the DSC, providing a suitable loss function
for training deep learning segmentation models for use in biomedical and
clinical practice.</p>
  </details>
</details>
<details>
  <summary>108. <b>标题：IGCN: Image-to-graph Convolutional Network for 2D/3D Deformable  Registration</b></summary>
  <p><b>编号</b>：[468]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00484</p>
  <p><b>作者</b>：Megumi Nakao,  Mitsuhiro Nakamura,  Tetsuya Matsuda</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：experimental results show shape prediction considering relationships among multiple organs, organ shape reconstruction based, multiple abdominal organs, framework enables simultaneous training, 3d deformable registration performance</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Organ shape reconstruction based on a single-projection image during
treatment has wide clinical scope, e.g., in image-guided radiotherapy and
surgical guidance. We propose an image-to-graph convolutional network that
achieves deformable registration of a 3D organ mesh for a single-viewpoint 2D
projection image. This framework enables simultaneous training of two types of
transformation: from the 2D projection image to a displacement map, and from
the sampled per-vertex feature to a 3D displacement that satisfies the
geometrical constraint of the mesh structure. Assuming application to radiation
therapy, the 2D/3D deformable registration performance is verified for multiple
abdominal organs that have not been targeted to date, i.e., the liver, stomach,
duodenum, and kidney, and for pancreatic cancer. The experimental results show
shape prediction considering relationships among multiple organs can be used to
predict respiratory motion and deformation from digitally reconstructed
radiographs with clinically acceptable accuracy.</p>
  </details>
</details>
<details>
  <summary>109. <b>标题：A robust single-pixel particle image velocimetry based on fully  convolutional networks with cross-correlation embedded</b></summary>
  <p><b>编号</b>：[471]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00395</p>
  <p><b>作者</b>：Qi Gao,  Hongtao Lin,  Han Tu,  Haoran Zhu,  Runjie Wei,  Guoping Zhang,  Xueming Shao</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：proposed model could therefore provide competitive, initial velocity field calculated using cross, new velocity field estimation paradigm, synthetic data sets including ground, real experimental piv data sets</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Particle image velocimetry (PIV) is essential in experimental fluid dynamics.
In the current work, we propose a new velocity field estimation paradigm, which
achieves a synergetic combination of the deep learning method and the
traditional cross-correlation method. Specifically, the deep learning method is
used to optimize and correct a coarse velocity guess to achieve a
super-resolution calculation. And the cross-correlation method provides the
initial velocity field based on a coarse correlation with a large interrogation
window. As a reference, the coarse velocity guess helps with improving the
robustness of the proposed algorithm. This fully convolutional network with
embedded cross-correlation is named as CC-FCN. CC-FCN has two types of input
layers, one is for the particle images, and the other is for the initial
velocity field calculated using cross-correlation with a coarse resolution.
Firstly, two pyramidal modules extract features of particle images and initial
velocity field respectively. Then the fusion module appropriately fuses these
features. Finally, CC-FCN achieves the super-resolution calculation through a
series of deconvolution layers to obtain the single-pixel velocity field. As
the supervised learning strategy is considered, synthetic data sets including
ground-truth fluid motions are generated to train the network parameters.
Synthetic and real experimental PIV data sets are used to test the trained
neural network in terms of accuracy, precision, spatial resolution and
robustness. The test results show that these attributes of CC-FCN are further
improved compared with those of other tested PIV algorithms. The proposed model
could therefore provide competitive and robust estimations for PIV experiments.</p>
  </details>
</details>
<details>
  <summary>110. <b>标题：Dual Attention Network for Heart Rate and Respiratory Rate Estimation</b></summary>
  <p><b>编号</b>：[472]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00390</p>
  <p><b>作者</b>：Yuzhuo Ren,  Braeden Syrnyk,  Niranjan Avadhanam</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：proposed system significantly improves heart rate, contact camera based physiological measurement, remote physiological signal measurement, contact methods reduce risk, fingertip oximeters since non</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Heart rate and respiratory rate measurement is a vital step for diagnosing
many diseases. Non-contact camera based physiological measurement is more
accessible and convenient in Telehealth nowadays than contact instruments such
as fingertip oximeters since non-contact methods reduce risk of infection.
However, remote physiological signal measurement is challenging due to
environment illumination variations, head motion, facial expression, etc. It's
also desirable to have a unified network which could estimate both heart rate
and respiratory rate to reduce system complexity and latency. We propose a
convolutional neural network which leverages spatial attention and channel
attention, which we call it dual attention network (DAN) to jointly estimate
heart rate and respiratory rate with camera video as input. Extensive
experiments demonstrate that our proposed system significantly improves heart
rate and respiratory rate measurement accuracy.</p>
  </details>
</details>
<details>
  <summary>111. <b>标题：Functional Neural Networks for Parametric Image Restoration Problems</b></summary>
  <p><b>编号</b>：[473]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00361</p>
  <p><b>作者</b>：Fangzhou Luo,  Xiaolin Wu,  Yanhui Guo</p>
  <p><b>备注</b>：NeurIPS 2021</p>
  <p><b>关键词</b>：novel system called functional neural network, almost every single image restoration problem, previous researchers either treat problems, three parametric image restoration tasks, achieved great success due</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Almost every single image restoration problem has a closely related
parameter, such as the scale factor in super-resolution, the noise level in
image denoising, and the quality factor in JPEG deblocking. Although recent
studies on image restoration problems have achieved great success due to the
development of deep neural networks, they handle the parameter involved in an
unsophisticated way. Most previous researchers either treat problems with
different parameter levels as independent tasks, and train a specific model for
each parameter level; or simply ignore the parameter, and train a single model
for all parameter levels. The two popular approaches have their own
shortcomings. The former is inefficient in computing and the latter is
ineffective in performance. In this work, we propose a novel system called
functional neural network (FuncNet) to solve a parametric image restoration
problem with a single model. Unlike a plain neural network, the smallest
conceptual element of our FuncNet is no longer a floating-point variable, but a
function of the parameter of the problem. This feature makes it both efficient
and effective for a parametric problem. We apply FuncNet to super-resolution,
image denoising, and JPEG deblocking. The experimental results show the
superiority of our FuncNet on all three parametric image restoration tasks over
the state of the arts.</p>
  </details>
</details>
<details>
  <summary>112. <b>标题：Cross-Modality Fusion Transformer for Multispectral Object Detection</b></summary>
  <p><b>编号</b>：[477]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00273</p>
  <p><b>作者</b>：Fang Qingyun,  Han Dapeng,  Wang Zhaokui</p>
  <p><b>备注</b>：5 pages,3 figures, 4 tables</p>
  <p><b>关键词</b>：integrates global contextual information, making object detection applications, simple yet effective cross, modality feature fusion approach, multispectral object detection</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Multispectral image pairs can provide the combined information, making object
detection applications more reliable and robust in the open world. To fully
exploit the different modalities, we present a simple yet effective
cross-modality feature fusion approach, named Cross-Modality Fusion Transformer
(CFT) in this paper. Unlike prior CNNs-based works, guided by the transformer
scheme, our network learns long-range dependencies and integrates global
contextual information in the feature extraction stage. More importantly, by
leveraging the self attention of the transformer, the network can naturally
carry out simultaneous intra-modality and inter-modality fusion, and robustly
capture the latent interactions between RGB and Thermal domains, thereby
significantly improving the performance of multispectral object detection.
Extensive experiments and ablation studies on multiple datasets demonstrate
that our approach is effective and achieves state-of-the-art detection
performance. Our code and models will be released soon at
this https URL.</p>
  </details>
</details>
<details>
  <summary>113. <b>标题：Unpaired Learning for High Dynamic Range Image Tone Mapping</b></summary>
  <p><b>编号</b>：[480]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00219</p>
  <p><b>作者</b>：Yael Vinker,  Inbar Huberman-Spiegelglas,  Raanan Fattal</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：level attributes native ldr possess, unpaired adversarial training based, different image fidelity indices, producing low dynamic range, producing training data</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>High dynamic range (HDR) photography is becoming increasingly popular and
available by DSLR and mobile-phone cameras. While deep neural networks (DNN)
have greatly impacted other domains of image manipulation, their use for HDR
tone-mapping is limited due to the lack of a definite notion of ground-truth
solution, which is needed for producing training data.
In this paper we describe a new tone-mapping approach guided by the distinct
goal of producing low dynamic range (LDR) renditions that best reproduce the
visual characteristics of native LDR images. This goal enables the use of an
unpaired adversarial training based on unrelated sets of HDR and LDR images,
both of which are widely available and easy to acquire.
In order to achieve an effective training under this minimal requirements, we
introduce the following new steps and components: (i) a range-normalizing
pre-process which estimates and applies a different level of curve-based
compression, (ii) a loss that preserves the input content while allowing the
network to achieve its goal, and (iii) the use of a more concise discriminator
network, designed to promote the reproduction of low-level attributes native
LDR possess.
Evaluation of the resulting network demonstrates its ability to produce
photo-realistic artifact-free tone-mapped images, and state-of-the-art
performance on different image fidelity indices and visual distances.</p>
  </details>
</details>
<details>
  <summary>114. <b>标题：M2MRF: Many-to-Many Reassembly of Features for Tiny Lesion Segmentation  in Fundus Images</b></summary>
  <p><b>编号</b>：[481]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00193</p>
  <p><b>作者</b>：Qing Liu,  Haotian Liu,  Yixiong Liang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：existing feature reassembly operators reassemble multiple features, m2mrf outperforms existing feature reassembly operators, simultaneously aggregates multiple features inside, two lesion segmentation benchmarks, long range spatial dependencies</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Feature reassembly is an essential component in modern CNNs-based
segmentation approaches, which includes feature downsampling and upsampling
operators. Existing feature reassembly operators reassemble multiple features
from a small predefined region into one for each target location independently.
This may result in loss of spatial information, which could vanish activations
of tiny lesions particularly when they cluster together. In this paper, we
propose a many-to-many reassembly of features (M2MRF). It reassembles features
in a dimension-reduced feature space and simultaneously aggregates multiple
features inside a large predefined region into multiple target features. In
this way, long range spatial dependencies are captured to maintain activations
on tiny lesions, particularly when multiple lesions coexist. Experimental
results on two lesion segmentation benchmarks, i.e. DDR and IDRiD, show that
our M2MRF outperforms existing feature reassembly operators.</p>
  </details>
</details>
<details>
  <summary>115. <b>标题：Fetal MRI by robust deep generative prior reconstruction and  diffeomorphic registration: application to gestational age prediction</b></summary>
  <p><b>编号</b>：[486]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00102</p>
  <p><b>作者</b>：Lucilio Cordero-Grande,  Juan Enrique Ortuño-Fisac,  Alena Uus,  Maria Deprez,  Andrés Santos,  Joseph V. Hajnal,  María Jesús Ledesma-Carbayo</p>
  <p><b>备注</b>：23 pages, 15 figures, 1 table</p>
  <p><b>关键词</b>：usual scanning techniques employ single, results suggest improved image resolution, robust volumetric reconstructions integrated, volumetric reconstructions compare favourably, gestational age prediction results</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Magnetic resonance imaging of whole fetal body and placenta is limited by
different sources of motion affecting the womb. Usual scanning techniques
employ single-shot multi-slice sequences where anatomical information in
different slices may be subject to different deformations, contrast variations
or artifacts. Volumetric reconstruction formulations have been proposed to
correct for these factors, but they must accommodate a non-homogeneous and
non-isotropic sampling, so regularization becomes necessary. Thus, in this
paper we propose a deep generative prior for robust volumetric reconstructions
integrated with a diffeomorphic volume to slice registration method.
Experiments are performed to validate our contributions and compare with a
state of the art method in a cohort of $72$ fetal datasets in the range of
$20-36$ weeks gestational age. Results suggest improved image resolution and
more accurate prediction of gestational age at scan when comparing to a state
of the art reconstruction method. In addition, gestational age prediction
results from our volumetric reconstructions compare favourably with existing
brain-based approaches, with boosted accuracy when integrating information of
organs other than the brain. Namely, a mean absolute error of $0.618$ weeks
($R^2=0.958$) is achieved when combining fetal brain and trunk information.</p>
  </details>
</details>
<details>
  <summary>116. <b>标题：DeepDoseNet: A Deep Learning model for 3D Dose Prediction in Radiation  Therapy</b></summary>
  <p><b>编号</b>：[487]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00077</p>
  <p><b>作者</b>：Mumtaz Hussain Soomro,  Victor Gabriel Leandro Alves,  Hamidreza Nourzadeh,  Jeffrey V. Siebers</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：d99 %, d95 %, d1, d99 %, d95 %, d1, deepdosenet 3d dose prediction model based, predicted 3d dose distributions, 2020 aapm openkbp challenge</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The DeepDoseNet 3D dose prediction model based on ResNet and Dilated DenseNet
is proposed. The 340 head-and-neck datasets from the 2020 AAPM OpenKBP
challenge were utilized, with 200 for training, 40 for validation, and 100 for
testing. Structures include 56Gy, 63Gy, 70Gy PTVs, and brainstem, spinal cord,
right parotid, left parotid, larynx, esophagus, and mandible OARs. Mean squared
error (MSE) loss, mean absolute error (MAE) loss, and MAE plus dose-volume
histogram (DVH) based loss functions were investigated. Each model's
performance was compared using a 3D dose score, $\bar{S_{D}}$, (mean absolute
difference between ground truth and predicted 3D dose distributions) and a DVH
score, $\bar{S_{DVH}}$ (mean absolute difference between ground truth and
predicted dose-volume metrics).Furthermore, DVH metrics Mean[Gy] and D0.1cc
[Gy] for OARs and D99%, D95%, D1% for PTVs were computed. DeepDoseNet with the
MAE plus DVH-based loss function had the best dose score performance of the
OpenKBP entries. MAE+DVH model had the lowest prediction error (P<0.0001, wilcoxon test) on validation and test datasets (validation: $\bar{s_{d}}$="2.3Gy," $\bar{s_{dvh}}$="1.9Gy;" test: followed by the mae model mse had highest prediction error no significant difference was found among models in terms of mean [gy], but mae+dvh significantly outperformed d0.1cc[gy], particularly for mandible parotids both (p<0.01) (p<0.0001) datasets. d99%, d95%, d1% targets. reduced ~60% ~70%.< p>
  </0.0001,></p></details>
</details>
<details>
  <summary>117. <b>标题：Multiple Sclerosis Lesions Identification/Segmentation in Magnetic  Resonance Imaging using Ensemble CNN and Uncertainty Classification</b></summary>
  <p><b>编号</b>：[495]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2108.11791</p>
  <p><b>作者</b>：Giuseppe Placidi,  Luigi Cinque,  Filippo Mignosi,  Matteo Polsinelli</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：2016 msseg benchmark public data set, better emulate human reasoning, three pivotal concepts, single imaging modality, physicians partially manage</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>To date, several automated strategies for identification/segmentation of
Multiple Sclerosis (MS) lesions with the use of Magnetic Resonance Imaging
(MRI) have been presented but they are either outperformed by human experts or
perform differently from them. This is mainly due to the ambiguity originated
by MRI instabilities, peculiar variability of MS and unspecific nature of MRI
with respect to MS. Physicians partially manage the uncertainty generated by
ambiguity relying on their personal radiological/clinical/anatomical background
and experience. We present an automated framework based on three pivotal
concepts to better emulate human reasoning: 1. the modelling of uncertainty; 2.
the proposal of two, separately trained, CNN, one optimized with respect to
lesions themselves and the other to the environment surrounding lesions,
respectively repeated for axial, coronal and sagittal directions; 3. the
definition of an ensemble classifier to merge the information collected by all
CNN. The proposed framework is trained, validated and tested on the 2016 MSSEG
benchmark public data set from a single imaging modality, the FLuid-Attenuated
Inversion Recovery (FLAIR). The comparison, made with the consensus (the
ground-truth) between 7 human raters and with each of the 7 human raters,
proves that there is no significant difference between the automated and the
human raters. The results of our framework concerning the uncertainty are also
reported, even if a comparison with the raters is impossible because they don't
recognize this class.</p>
  </details>
</details>
<h1>自然语言处理</h1>
<details>
  <summary>1. <b>标题：Introspective Distillation for Robust Question Answering</b></summary>
  <p><b>编号</b>：[28]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.01026</p>
  <p><b>作者</b>：Yulei Niu,  Hanwang Zhang</p>
  <p><b>备注</b>：Accepted by NeurIPS 2021</p>
  <p><b>关键词</b>：novel debiasing method called introspective distillation, even achieving better id performance compared, recent debiasing methods achieve good, reading comprehension dataset squad demonstrate, visual qa datasets vqa v2</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Question answering (QA) models are well-known to exploit data bias, e.g., the
language prior in visual QA and the position bias in reading comprehension.
Recent debiasing methods achieve good out-of-distribution (OOD)
generalizability with a considerable sacrifice of the in-distribution (ID)
performance. Therefore, they are only applicable in domains where the test
distribution is known in advance. In this paper, we present a novel debiasing
method called Introspective Distillation (IntroD) to make the best of both
worlds for QA. Our key technical contribution is to blend the inductive bias of
OOD and ID by introspecting whether a training sample fits in the factual ID
world or the counterfactual OOD one. Experiments on visual QA datasets VQA v2,
VQA-CP, and reading comprehension dataset SQuAD demonstrate that our proposed
IntroD maintains the competitive OOD performance compared to other debiasing
methods, while sacrificing little or even achieving better ID performance
compared to the non-debiasing ones.</p>
  </details>
</details>
<details>
  <summary>2. <b>标题：Interpretable contrastive word mover's embedding</b></summary>
  <p><b>编号</b>：[30]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.01023</p>
  <p><b>作者</b>：Ruijie Jiang,  Julia Gouvea,  Eric Miller,  David Hammer,  Shuchin Aeron</p>
  <p><b>备注</b>：8 pages, 4 figures</p>
  <p><b>关键词</b>：method improves significantly upon existing baselines, help ls researchers gain insights, develop natural language processing, several public datasets, clusters via identifying</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper shows that a popular approach to the supervised embedding of
documents for classification, namely, contrastive Word Mover's Embedding, can
be significantly enhanced by adding interpretability. This interpretability is
achieved by incorporating a clustering promoting mechanism into the contrastive
loss. On several public datasets, we show that our method improves
significantly upon existing baselines while providing interpretation to the
clusters via identifying a set of keywords that are the most representative of
a particular class. Our approach was motivated in part by the need to develop
Natural Language Processing (NLP) methods for the \textit{novel problem of
assessing student work for scientific writing and thinking} - a problem that is
central to the area of (educational) Learning Sciences (LS). In this context,
we show that our approach leads to a meaningful assessment of the student work
related to lab reports from a biology class and can help LS researchers gain
insights into student understanding and assess evidence of scientific thought
processes.</p>
  </details>
</details>
<details>
  <summary>3. <b>标题：Cross-lingual Hate Speech Detection using Transformer Models</b></summary>
  <p><b>编号</b>：[43]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00981</p>
  <p><b>作者</b>：Teodor Tiţa,  Arkaitz Zubiaga</p>
  <p><b>备注</b>：7 pages</p>
  <p><b>关键词</b>：crucial social data science task, hate speech detection within, tuned altered multi, morally questionable real, comparative error analysis</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Hate speech detection within a cross-lingual setting represents a paramount
area of interest for all medium and large-scale online platforms. Failing to
properly address this issue on a global scale has already led over time to
morally questionable real-life events, human deaths, and the perpetuation of
hate itself. This paper illustrates the capabilities of fine-tuned altered
multi-lingual Transformer models (mBERT, XLM-RoBERTa) regarding this crucial
social data science task with cross-lingual training from English to French,
vice-versa and each language on its own, including sections about iterative
improvement and comparative error analysis.</p>
  </details>
</details>
<details>
  <summary>4. <b>标题：A transfer learning based approach for pronunciation scoring</b></summary>
  <p><b>编号</b>：[47]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00976</p>
  <p><b>作者</b>：Marcelo Sancinetti,  Jazmin Vidal,  Cyntia Bonomi,  Luciana Ferrer</p>
  <p><b>备注</b>：ICASSP 2022</p>
  <p><b>关键词</b>：phrase using models trained, several design choices, prioritizes low rates, automatic speech recognition, standard systems generate</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Phone-level pronunciation scoring is a challenging task, with performance far
from that of human annotators. Standard systems generate a score for each phone
in a phrase using models trained for automatic speech recognition (ASR) with
native data only. Better performance has been shown when using systems that are
trained specifically for the task using non-native data. Yet, such systems face
the challenge that datasets labelled for this task are scarce and usually
small. In this paper, we present a transfer learning-based approach that
leverages a model trained for ASR, adapting it for the task of pronunciation
scoring. We analyze the effect of several design choices and compare the
performance with a state-of-the-art goodness of pronunciation (GOP) system. Our
final system is 20% better than the GOP system on EpaDB, a database for
pronunciation scoring research, for a cost function that prioritizes low rates
of unnecessary corrections.</p>
  </details>
</details>
<details>
  <summary>5. <b>标题：Transductive Data Augmentation with Relational Path Rule Mining for  Knowledge Graph Embedding</b></summary>
  <p><b>编号</b>：[48]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00974</p>
  <p><b>作者</b>：Yushi Hirose,  Masashi Shimbo,  Taro Watanabe</p>
  <p><b>备注</b>：8 pages, 0 figures, accepted by 2021 IEEE International Conference on Big Knowledge. The copyright of this paper has been transferred to the IEEE, please comply with the copyright of the IEEE</p>
  <p><b>关键词</b>：proposed method effectively improves, propose transductive data augmentation, alternately augments training data, relation path rule induction, relation path rules</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>For knowledge graph completion, two major types of prediction models exist:
one based on graph embeddings, and the other based on relation path rule
induction. They have different advantages and disadvantages. To take advantage
of both types, hybrid models have been proposed recently. One of the hybrid
models, UniKER, alternately augments training data by relation path rules and
trains an embedding model. Despite its high prediction accuracy, it does not
take full advantage of relation path rules, as it disregards low-confidence
rules in order to maintain the quality of augmented data. To mitigate this
limitation, we propose transductive data augmentation by relation path rules
and confidence-based weighting of augmented data. The results and analysis show
that our proposed method effectively improves the performance of the embedding
model by augmenting data that include true answers or entities similar to them.</p>
  </details>
</details>
<details>
  <summary>6. <b>标题：Enhanced Language Representation with Label Knowledge for Span  Extraction</b></summary>
  <p><b>编号</b>：[86]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00884</p>
  <p><b>作者</b>：Pan Yang,  Xin Cong,  Zhenyun Sun,  Xingwu Liu</p>
  <p><b>备注</b>：Accepted to the main conference of EMNLP 2021 (long paper)</p>
  <p><b>关键词</b>：three typical span extraction tasks, designed semantics fusion module, efficiently integrate label knowledge, span extraction task, integrate label knowledge</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Span extraction, aiming to extract text spans (such as words or phrases) from
plain texts, is a fundamental process in Information Extraction. Recent works
introduce the label knowledge to enhance the text representation by formalizing
the span extraction task into a question answering problem (QA Formalization),
which achieves state-of-the-art performance. However, QA Formalization does not
fully exploit the label knowledge and suffers from low efficiency in
training/inference. To address those problems, we introduce a new paradigm to
integrate label knowledge and further propose a novel model to explicitly and
efficiently integrate label knowledge into text representations. Specifically,
it encodes texts and label annotations independently and then integrates label
knowledge into text representation with an elaborate-designed semantics fusion
module. We conduct extensive experiments on three typical span extraction
tasks: flat NER, nested NER, and event detection. The empirical results show
that 1) our method achieves state-of-the-art performance on four benchmarks,
and 2) reduces training time and inference time by 76% and 77% on average,
respectively, compared with the QA Formalization paradigm. Our code and data
are available at this https URL.</p>
  </details>
</details>
<details>
  <summary>7. <b>标题：Interpretive Blindness</b></summary>
  <p><b>编号</b>：[96]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00867</p>
  <p><b>作者</b>：Nicholas Asher,  Julie Hunter</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：promote good epistemic practices, particular characteristic contemporary testimony, one acquires information, argumentative completeness },, hierarchical bayesian settings</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We model here an epistemic bias we call \textit{interpretive blindness} (IB).
IB is a special problem for learning from testimony, in which one acquires
information only from text or conversation. We show that IB follows from a
co-dependence between background beliefs and interpretation in a Bayesian
setting and the nature of contemporary testimony. We argue that a particular
characteristic contemporary testimony, \textit{argumentative completeness}, can
preclude learning in hierarchical Bayesian settings, even in the presence of
constraints that are designed to promote good epistemic practices.</p>
  </details>
</details>
<details>
  <summary>8. <b>标题：Exploring Non-Autoregressive End-To-End Neural Modeling For English  Mispronunciation Detection And Diagnosis</b></summary>
  <p><b>编号</b>：[102]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00844</p>
  <p><b>作者</b>：Hsin-Wei Wang,  Bi-Cheng Yan,  Hsuan-Sheng Chiu,  Yung-Chang Hsu,  Berlin Chen</p>
  <p><b>备注</b>：Preprint. Under review 5 pages, 2 figures</p>
  <p><b>关键词</b>：nonnative training data would often reduce, least two pivotal challenges, arctic english dataset seems, pronunciation modeling network stacked, current e2e neural methods</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>End-to-end (E2E) neural modeling has emerged as one predominant school of
thought to develop computer-assisted language training (CAPT) systems, showing
competitive performance to conventional pronunciation-scoring based methods.
However, current E2E neural methods for CAPT are faced with at least two
pivotal challenges. On one hand, most of the E2E methods operate in an
autoregressive manner with left-to-right beam search to dictate the
pronunciations of an L2 learners. This however leads to very slow inference
speed, which inevitably hinders their practical use. On the other hand, E2E
neural methods are normally data greedy and meanwhile an insufficient amount of
nonnative training data would often reduce their efficacy on mispronunciation
detection and diagnosis (MD&D). In response, we put forward a novel MD&D method
that leverages non-autoregressive (NAR) E2E neural modeling to dramatically
speed up the inference time while maintaining performance in line with the
conventional E2E neural methods. In addition, we design and develop a
pronunciation modeling network stacked on top of the NAR E2E models of our
method to further boost the effectiveness of MD&D. Empirical experiments
conducted on the L2-ARCTIC English dataset seems to validate the feasibility of
our method, in comparison to some top-of-the-line E2E models and an iconic
pronunciation-scoring based method built on a DNN-HMM acoustic model.</p>
  </details>
</details>
<details>
  <summary>9. <b>标题：Deep Learning Transformer Architecture for Named Entity Recognition on  Low Resourced Languages: State of the art results</b></summary>
  <p><b>编号</b>：[106]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00830</p>
  <p><b>作者</b>：Ridewaan Hanslo</p>
  <p><b>备注</b>：8 pages, 6 tables, and 3 figures</p>
  <p><b>关键词</b>：conditional random fields ml model, transformer models significantly improve performance, tuning parameters per language, natural language processing tasks, additional research could evaluate</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper reports on the evaluation of Deep Learning (DL) transformer
architecture models for Named-Entity Recognition (NER) on ten low-resourced
South African (SA) languages. In addition, these DL transformer models were
compared to other Neural Network and Machine Learning (ML) NER models. The
findings show that transformer models significantly improve performance when
applying discrete fine-tuning parameters per language. Furthermore, fine-tuned
transformer models outperform other neural network and machine learning models
with NER on the low-resourced SA languages. For example, the transformer models
generated the highest F-scores for six of the ten SA languages, including the
highest average F-score surpassing the Conditional Random Fields ML model.
Additional research could evaluate the more recent transformer architecture
models on other Natural Language Processing tasks and applications, such as
Phrase chunking, Machine Translation, and Part-of-Speech tagging.</p>
  </details>
</details>
<details>
  <summary>10. <b>标题：Unsupervised Discovery of Unaccusative and Unergative Verbs</b></summary>
  <p><b>编号</b>：[112]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00808</p>
  <p><b>作者</b>：Sharid Loáiciga,  Luca Bevacqua,  Christian Hardmeier</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：inchoative alternation without knowing, intransitive sentence variants, detect english unergative, categories allow us, identify verbs participating</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present an unsupervised method to detect English unergative and
unaccusative verbs. These categories allow us to identify verbs participating
in the causative-inchoative alternation without knowing the semantic roles of
the verb. The method is based on the generation of intransitive sentence
variants of candidate verbs and probing a language model. We obtained results
on par with similar approaches, with the added benefit of not relying on
annotated resources.</p>
  </details>
</details>
<details>
  <summary>11. <b>标题：A New Tool for Efficiently Generating Quality Estimation Datasets</b></summary>
  <p><b>编号</b>：[129]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00767</p>
  <p><b>作者</b>：Sugyeong Eo,  Chanjun Park,  Jaehyung Seo,  Hyeonseok Moon,  Heuiseok Lim</p>
  <p><b>备注</b>：Accepted for Data-centric AI workshop at NeurIPS 2021</p>
  <p><b>关键词</b>：user friendly qe dataset generation tool, qe dataset generation tool, requires significant human labor, encouraging multiple language pairs, fully automatic pseudo</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Building of data for quality estimation (QE) training is expensive and
requires significant human labor. In this study, we focus on a data-centric
approach while performing QE, and subsequently propose a fully automatic
pseudo-QE dataset generation tool that generates QE datasets by receiving only
monolingual or parallel corpus as the input. Consequently, the QE performance
is enhanced either by data augmentation or by encouraging multiple language
pairs to exploit the applicability of QE. Further, we intend to publicly
release this user friendly QE dataset generation tool as we believe this tool
provides a new, inexpensive method to the community for developing QE datasets.</p>
  </details>
</details>
<details>
  <summary>12. <b>标题：Outlining and Filling: Hierarchical Query Graph Generation for Answering  Complex Questions over Knowledge Graph</b></summary>
  <p><b>编号</b>：[142]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00732</p>
  <p><b>作者</b>：Yongrui Chen,  Huiying Li,  Guilin Qi,  Tianxing Wu,  Tenggou Wang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：graph generation model performs hierarchical generation, complex questions bring three new challenges, although recent approaches perform well, regard common complicated sparql syntax, new unified query graph grammar</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Query graph building aims to build correct executable SPARQL over the
knowledge graph for answering natural language questions. Although recent
approaches perform well by NN-based query graph ranking, more complex questions
bring three new challenges: complicated SPARQL syntax, huge search space for
ranking, and noisy query graphs with local ambiguity. This paper handles these
challenges. Initially, we regard common complicated SPARQL syntax as the
sub-graphs comprising of vertices and edges and propose a new unified query
graph grammar to adapt them. Subsequently, we propose a new two-stage approach
to build query graphs. In the first stage, the top-$k$ related instances
(entities, relations, etc.) are collected by simple strategies, as the
candidate instances. In the second stage, a graph generation model performs
hierarchical generation. It first outlines a graph structure whose vertices and
edges are empty slots, and then fills the appropriate instances into the slots,
thereby completing the query graph. Our approach decomposes the unbearable
search space of entire query graphs into affordable sub-spaces of operations,
meanwhile, leverages the global structural information to eliminate local
ambiguity. The experimental results demonstrate that our approach greatly
improves state-of-the-art on the hardest KGQA benchmarks and has an excellent
performance on complex questions.</p>
  </details>
</details>
<details>
  <summary>13. <b>标题：Comparative Study of Long Document Classification</b></summary>
  <p><b>编号</b>：[153]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00702</p>
  <p><b>作者</b>：Vedangi Wagh,  Snehal Khandve,  Isha Joshi,  Apurva Wani,  Geetanjali Kale,  Raviraj Joshi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：revisit long document classification using standard machine learning approaches, six standard text classification datasets, even basic algorithms perform competitively, based models perform consistently well, different data sets thus making</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The amount of information stored in the form of documents on the internet has
been increasing rapidly. Thus it has become a necessity to organize and
maintain these documents in an optimum manner. Text classification algorithms
study the complex relationships between words in a text and try to interpret
the semantics of the document. These algorithms have evolved significantly in
the past few years. There has been a lot of progress from simple machine
learning algorithms to transformer-based architectures. However, existing
literature has analyzed different approaches on different data sets thus making
it difficult to compare the performance of machine learning algorithms. In this
work, we revisit long document classification using standard machine learning
approaches. We benchmark approaches ranging from simple Naive Bayes to complex
BERT on six standard text classification datasets. We present an exhaustive
comparison of different algorithms on a range of long document datasets. We
re-iterate that long document classification is a simpler task and even basic
algorithms perform competitively with BERT-based approaches on most of the
datasets. The BERT-based models perform consistently well on all the datasets
and can be blindly used for the document classification task when the
computations cost is not a concern. In the shallow model's category, we suggest
the usage of raw BiLSTM + Max architecture which performs decently across all
the datasets. Even simpler Glove + Attention bag of words model can be utilized
for simpler use cases. The importance of using sophisticated models is clearly
visible in the IMDB sentiment dataset which is a comparatively harder task.</p>
  </details>
</details>
<details>
  <summary>14. <b>标题：Discourse Comprehension: A Question Answering Framework to Represent  Sentence Connections</b></summary>
  <p><b>编号</b>：[154]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00701</p>
  <p><b>作者</b>：Wei-Jen Ko,  Cutter Dalton,  Mark Simmons,  Eliza Fisher,  Greg Durrett,  Junyi Jessy Li</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：answer pairs across 607 english documents, training methods utilizing existing question, enables scalable data collection targeting, requires high cognitive load, especially since finding answers</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>While there has been substantial progress in text comprehension through
simple factoid question answering, more holistic comprehension of a discourse
still presents a major challenge. Someone critically reflecting on a text as
they read it will pose curiosity-driven, often open-ended questions, which
reflect deep understanding of the content and require complex reasoning to
answer. A key challenge in building and evaluating models for this type of
discourse comprehension is the lack of annotated data, especially since finding
answers to such questions (which may not be answered at all) requires high
cognitive load for annotators over long documents. This paper presents a novel
paradigm that enables scalable data collection targeting the comprehension of
news documents, viewing these questions through the lens of discourse. The
resulting corpus, DCQA (Discourse Comprehension by Question Answering),
consists of 22,430 question-answer pairs across 607 English documents. DCQA
captures both discourse and semantic links between sentences in the form of
free-form, open-ended questions. On an evaluation set that we annotated on
questions from the INQUISITIVE dataset, we show that DCQA provides valuable
supervision for answering open-ended questions. We additionally design
pre-training methods utilizing existing question-answering resources, and use
synthetic data to accommodate unanswerable questions.</p>
  </details>
</details>
<details>
  <summary>15. <b>标题：Domain-adaptation of spherical embeddings</b></summary>
  <p><b>编号</b>：[162]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00677</p>
  <p><b>作者</b>：Mihalis Gongolidis,  Jeremy Minton,  Ronin Wu,  Valentin Stauber,  Jason Hoelscher-Obermaier,  Viktor Botev</p>
  <p><b>备注</b>：SciNLP 2021 poster abstract</p>
  <p><b>关键词</b>：two new document classification data, 01196 jointly learns word, recent spherical embedding model, proposed update training strategies, word correlation tasks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Domain adaptation of embedding models, updating a generic embedding to the
language of a specific domain, is a proven technique for domains that have
insufficient data to train an effective model from scratch. Chemistry
publications is one such domain, where scientific jargon and overloaded
terminology inhibit the performance of a general language model. The recent
spherical embedding model (JoSE) proposed in arXiv:1911.01196 jointly learns
word and document embeddings during training on the multi-dimensional unit
sphere, which performs well for document classification and word correlation
tasks. But, we show a non-convergence caused by global rotations during its
training prevents it from domain adaptation. In this work, we develop methods
to counter the global rotation of the embedding space and propose strategies to
update words and documents during domain specific training. Two new document
classification data-sets are collated from general and chemistry scientific
journals to compare the proposed update training strategies with benchmark
models. We show that our strategies are able to reduce the performance cost of
domain adaptation to a level similar to Word2Vec.</p>
  </details>
</details>
<details>
  <summary>16. <b>标题：Comparative Explanations of Recommendations</b></summary>
  <p><b>编号</b>：[165]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00670</p>
  <p><b>作者</b>：Aobo Yang,  Nan Wang,  Renqin Cai,  Hongbo Deng,  Hongning Wang</p>
  <p><b>备注</b>：17 pages, 4 figures</p>
  <p><b>关键词</b>：two large recommendation benchmark datasets, art explainable recommendation algorithms demonstrate, new explanation quality metric based, first extract one sentence, e ., comparative explanations</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As recommendation is essentially a comparative (or ranking) process, a good
explanation should illustrate to users why an item is believed to be better
than another, i.e., comparative explanations about the recommended items.
Ideally, after reading the explanations, a user should reach the same ranking
of items as the system's. Unfortunately, little research attention has yet been
paid on such comparative explanations.
In this work, we develop an extract-and-refine architecture to explain the
relative comparisons among a set of ranked items from a recommender system. For
each recommended item, we first extract one sentence from its associated
reviews that best suits the desired comparison against a set of reference
items. Then this extracted sentence is further articulated with respect to the
target user through a generative model to better explain why the item is
recommended. We design a new explanation quality metric based on BLEU to guide
the end-to-end training of the extraction and refinement components, which
avoids generation of generic content. Extensive offline evaluations on two
large recommendation benchmark datasets and serious user studies against an
array of state-of-the-art explainable recommendation algorithms demonstrate the
necessity of comparative explanations and the effectiveness of our solution.</p>
  </details>
</details>
<details>
  <summary>17. <b>标题：Unsupervised Domain Adaptation with Adapter</b></summary>
  <p><b>编号</b>：[167]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00667</p>
  <p><b>作者</b>：Rongsheng Zhang,  Yinhe Zheng,  Xiaoxi Mao,  Minlie Huang</p>
  <p><b>备注</b>：Accepted by NeurIPS2021 workshop</p>
  <p><b>关键词</b>：trained models embed generic knowledge learned, better capture transferable features, achieved promising results since, several trainable adapter modules, learned generic knowledge</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Unsupervised domain adaptation (UDA) with pre-trained language models (PrLM)
has achieved promising results since these pre-trained models embed generic
knowledge learned from various domains. However, fine-tuning all the parameters
of the PrLM on a small domain-specific corpus distort the learned generic
knowledge, and it is also expensive to deployment a whole fine-tuned PrLM for
each domain. This paper explores an adapter-based fine-tuning approach for
unsupervised domain adaptation. Specifically, several trainable adapter modules
are inserted in a PrLM, and the embedded generic knowledge is preserved by
fixing the parameters of the original PrLM at fine-tuning. A domain-fusion
scheme is introduced to train these adapters using a mix-domain corpus to
better capture transferable features. Elaborated experiments on two benchmark
datasets are carried out, and the results demonstrate that our approach is
effective with different tasks, dataset sizes, and domain similarities.</p>
  </details>
</details>
<details>
  <summary>18. <b>标题：SADGA: Structure-Aware Dual Graph Aggregation Network for Text-to-SQL</b></summary>
  <p><b>编号</b>：[174]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00653</p>
  <p><b>作者</b>：Ruichu Cai,  Jinjie Yuan,  Boyan Xu,  Zhifeng Hao</p>
  <p><b>备注</b>：Paper accepted at the 35th Conference on Neural Information Processing Systems(NeurIPS 2021)</p>
  <p><b>关键词</b>：aware dual graph aggregation network, drawn much attention recently, also achieved 3rd place, aware aggregation method, aware aggregation method</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The Text-to-SQL task, aiming to translate the natural language of the
questions into SQL queries, has drawn much attention recently. One of the most
challenging problems of Text-to-SQL is how to generalize the trained model to
the unseen database schemas, also known as the cross-domain Text-to-SQL task.
The key lies in the generalizability of (i) the encoding method to model the
question and the database schema and (ii) the question-schema linking method to
learn the mapping between words in the question and tables/columns in the
database schema. Focusing on the above two key issues, we propose a
Structure-Aware Dual Graph Aggregation Network (SADGA) for cross-domain
Text-to-SQL. In SADGA, we adopt the graph structure to provide a unified
encoding model for both the natural language question and database schema.
Based on the proposed unified modeling, we further devise a structure-aware
aggregation method to learn the mapping between the question-graph and
schema-graph. The structure-aware aggregation method is featured with Global
Graph Linking, Local Graph Linking, and Dual-Graph Aggregation Mechanism. We
not only study the performance of our proposal empirically but also achieved
3rd place on the challenging Text-to-SQL benchmark Spider at the time of
writing.</p>
  </details>
</details>
<details>
  <summary>19. <b>标题：VSEC: Transformer-based Model for Vietnamese Spelling Correction</b></summary>
  <p><b>编号</b>：[178]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00640</p>
  <p><b>作者</b>：Dinh-Truong Do,  Ha Thanh Nguyen,  Thang Ngoc Bui,  Dinh Hieu Vo</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：byte pair encoding technique, spelling mistakes stand near, randomly introduced spelling errors, 341 different vietnamese sentences, correct vietnamese spelling errors</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Spelling error correction is one of topics which have a long history in
natural language processing. Although previous studies have achieved remarkable
results, challenges still exist. In the Vietnamese language, a state-of-the-art
method for the task infers a syllable's context from its adjacent syllables.
The method's accuracy can be unsatisfactory, however, because the model may
lose the context if two (or more) spelling mistakes stand near each other. In
this paper, we propose a novel method to correct Vietnamese spelling errors. We
tackle the problems of mistyped errors and misspelled errors by using a deep
learning model. The embedding layer, in particular, is powered by the byte pair
encoding technique. The sequence to sequence model based on the Transformer
architecture makes our approach different from the previous works on the same
problem. In the experiment, we train the model with a large synthetic dataset,
which is randomly introduced spelling errors. We test the performance of the
proposed method using a realistic dataset. This dataset contains 11,202
human-made misspellings in 9,341 different Vietnamese sentences. The
experimental results show that our method achieves encouraging performance with
86.8% errors detected and 81.5% errors corrected, which improves the
state-of-the-art approach 5.6% and 2.2%, respectively.</p>
  </details>
</details>
<details>
  <summary>20. <b>标题：R-BERT-CNN: Drug-target interactions extraction from biomedical  literature</b></summary>
  <p><b>编号</b>：[188]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00611</p>
  <p><b>作者</b>：Jehad Aldahdooh,  Ziaurrehman Tanoli,  Jing Tang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：biocreative vi chemprot test corpus )., biocreative vii drugprot test corpus, biocreative vii challenge, often manually extracted, micro f1 score</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this research, we present our work participation for the DrugProt task of
BioCreative VII challenge. Drug-target interactions (DTIs) are critical for
drug discovery and repurposing, which are often manually extracted from the
experimental articles. There are >32M biomedical articles on PubMed and
manually extracting DTIs from such a huge knowledge base is challenging. To
solve this issue, we provide a solution for Track 1, which aims to extract 10
types of interactions between drug and protein entities. We applied an Ensemble
Classifier model that combines BioMed-RoBERTa, a state of art language model,
with Convolutional Neural Networks (CNN) to extract these relations. Despite
the class imbalances in the BioCreative VII DrugProt test corpus, our model
achieves a good performance compared to the average of other submissions in the
challenge, with the micro F1 score of 55.67% (and 63% on BioCreative VI
ChemProt test corpus). The results show the potential of deep learning in
extracting various types of DTIs.</p>
  </details>
</details>
<details>
  <summary>21. <b>标题：Towards Language Modelling in the Speech Domain Using Sub-word  Linguistic Units</b></summary>
  <p><b>编号</b>：[189]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00610</p>
  <p><b>作者</b>：Anurag Katakkar,  Alan W Black</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：traditional text language modelling metrics like perplexity, offers better acoustic consistency across utterances, traditional speech lms often depending, model closely approximates babbling speech, based generative speech lm</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Language models (LMs) for text data have been studied extensively for their
usefulness in language generation and other downstream tasks. However, language
modelling purely in the speech domain is still a relatively unexplored topic,
with traditional speech LMs often depending on auxiliary text LMs for learning
distributional aspects of the language. For the English language, these LMs
treat words as atomic units, which presents inherent challenges to language
modelling in the speech domain. In this paper, we propose a novel LSTM-based
generative speech LM that is inspired by the CBOW model and built on linguistic
units including syllables and phonemes. This offers better acoustic consistency
across utterances in the dataset, as opposed to single melspectrogram frames,
or whole words. With a limited dataset, orders of magnitude smaller than that
required by contemporary generative models, our model closely approximates
babbling speech. We show the effect of training with auxiliary text LMs,
multitask learning objectives, and auxiliary articulatory features. Through our
experiments, we also highlight some well known, but poorly documented
challenges in training generative speech LMs, including the mismatch between
the supervised learning objective with which these models are trained such as
Mean Squared Error (MSE), and the true objective, which is speech quality. Our
experiments provide an early indication that while validation loss and Mel
Cepstral Distortion (MCD) are not strongly correlated with generated speech
quality, traditional text language modelling metrics like perplexity and
next-token-prediction accuracy might be.</p>
  </details>
</details>
<details>
  <summary>22. <b>标题：A Systematic Investigation of Commonsense Understanding in Large  Language Models</b></summary>
  <p><b>编号</b>：[191]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00607</p>
  <p><b>作者</b>：Xiang Lorraine Li,  Adhi Kuncoro,  Cyprien de Masson d'Autume,  Phil Blunsom,  Aida Nematzadeh</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：models exhibit commonsense understanding --, leveraging explicit commonsense knowledge, many natural language processing, large language models, large language models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large language models have shown impressive performance on many natural
language processing (NLP) tasks in a zero-shot setting. We ask whether these
models exhibit commonsense understanding -- a critical component of NLP
applications -- by evaluating models against four commonsense benchmarks. We
find that the impressive zero-shot performance of large language models is
mostly due to existence of dataset bias in our benchmarks. We also show that
the zero-shot performance is sensitive to the choice of hyper-parameters and
similarity of the benchmark to the pre-training datasets. Moreover, we did not
observe substantial improvements when evaluating models in a few-shot setting.
Finally, in contrast to previous work, we find that leveraging explicit
commonsense knowledge does not yield substantial improvement.</p>
  </details>
</details>
<details>
  <summary>23. <b>标题：Minimum Description Length Recurrent Neural Networks</b></summary>
  <p><b>编号</b>：[197]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00600</p>
  <p><b>作者</b>：Nur Lan,  Michal Geyer,  Emmanuel Chemla,  Roni Katzir</p>
  <p><b>备注</b>：14 pages</p>
  <p><b>关键词</b>：objective function master tasks involving memory challenges, thus provide formal proofs, minimum description length score, nb ^{ 2n }$,, learners master grammars</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We train neural networks to optimize a Minimum Description Length score,
i.e., to balance between the complexity of the network and its accuracy at a
task. We show that networks trained with this objective function master tasks
involving memory challenges such as counting, including cases that go beyond
context-free languages. These learners master grammars for, e.g., $a^nb^n$,
$a^nb^nc^n$, $a^nb^{2n}$, and $a^nb^mc^{n+m}$, and they perform addition. They
do so with 100% accuracy, sometimes also with 100% confidence. The networks are
also small and their inner workings are transparent. We thus provide formal
proofs that their perfect accuracy holds not only on a given test set, but for
any input sequence.</p>
  </details>
</details>
<details>
  <summary>24. <b>标题：Text Classification for Task-based Source Code Related Questions</b></summary>
  <p><b>编号</b>：[207]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00580</p>
  <p><b>作者</b>：Sairamvinay Vijayaraghavan,  Jinxiao Song,  David Tomassi,  Siddhartha Punj,  Jailan Sabet</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：simple binary neural network classifier model, using hidden state context vectors, fold deep learning model, embeddings perform slightly better, hidden state layer</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>There is a key demand to automatically generate code for small tasks for
developers. Websites such as StackOverflow provide a simplistic way by offering
solutions in small snippets which provide a complete answer to whatever task
question the developer wants to code. Natural Language Processing and
particularly Question-Answering Systems are very helpful in resolving and
working on these tasks. In this paper, we develop a two-fold deep learning
model: Seq2Seq and a binary classifier that takes in the intent (which is in
natural language) and code snippets in Python. We train both the intent and the
code utterances in the Seq2Seq model, where we decided to compare the effect of
the hidden layer embedding from the encoder for representing the intent and
similarly, using the decoder's hidden layer embeddings for the code sequence.
Then we combine both these embeddings and then train a simple binary neural
network classifier model for predicting if the intent is correctly answered by
the predicted code sequence from the seq2seq model. We find that the hidden
state layer's embeddings perform slightly better than regular standard
embeddings from a constructed vocabulary. We experimented with our tests on the
CoNaLa dataset in addition to the StaQC database consisting of simple task-code
snippet-based pairs. We empirically establish that using additional pre-trained
embeddings for code snippets in Python is less context-based in comparison to
using hidden state context vectors from seq2seq models.</p>
  </details>
</details>
<details>
  <summary>25. <b>标题：What Went Wrong? Explaining Overall Dialogue Quality through  Utterance-Level Impacts</b></summary>
  <p><b>编号</b>：[209]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00572</p>
  <p><b>作者</b>：James D. Finch,  Sarah E. Finch,  Jinho D. Choi</p>
  <p><b>备注</b>：Accepted at the 3rd Workshop on NLP for ConvAI</p>
  <p><b>关键词</b>：dialogue system often requires intensive developer effort, overall user rating without utterance, allowing resultant model conclusions, overall dialogue quality, overall dialogue quality</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Improving user experience of a dialogue system often requires intensive
developer effort to read conversation logs, run statistical analyses, and
intuit the relative importance of system shortcomings. This paper presents a
novel approach to automated analysis of conversation logs that learns the
relationship between user-system interactions and overall dialogue quality.
Unlike prior work on utterance-level quality prediction, our approach learns
the impact of each interaction from the overall user rating without
utterance-level annotation, allowing resultant model conclusions to be derived
on the basis of empirical evidence and at low cost. Our model identifies
interactions that have a strong correlation with the overall dialogue quality
in a chatbot setting. Experiments show that the automated analysis from our
model agrees with expert judgments, making this work the first to show that
such weakly-supervised learning of utterance-level quality prediction is highly
achievable.</p>
  </details>
</details>
<details>
  <summary>26. <b>标题：An Approach to Inference-Driven Dialogue Management within a Social  Chatbot</b></summary>
  <p><b>编号</b>：[210]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00570</p>
  <p><b>作者</b>：Sarah E. Finch,  James D. Finch,  Daniil Huryn,  William Hutsell,  Xiaoyuan Huang,  Han He,  Jinho D. Choi</p>
  <p><b>备注</b>：Published in 4th Proceedings of Alexa Prize (Alexa Prize 2020)</p>
  <p><b>关键词</b>：synthesize new predicates using efficient graph matching, novel dialogue management approach based, first stage translates user utterances, synthesize new knowledge, understanding latent semantics</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present a chatbot implementing a novel dialogue management approach based
on logical inference. Instead of framing conversation a sequence of response
generation tasks, we model conversation as a collaborative inference process in
which speakers share information to synthesize new knowledge in real time. Our
chatbot pipeline accomplishes this modelling in three broad stages. The first
stage translates user utterances into a symbolic predicate representation. The
second stage then uses this structured representation in conjunction with a
larger knowledge base to synthesize new predicates using efficient graph
matching. In the third and final stage, our bot selects a small subset of
predicates and translates them into an English response. This approach lends
itself to understanding latent semantics of user inputs, flexible initiative
taking, and responses that are novel and coherent with the dialogue context.</p>
  </details>
</details>
<details>
  <summary>27. <b>标题：Revealing and Protecting Labels in Distributed Training</b></summary>
  <p><b>编号</b>：[214]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00556</p>
  <p><b>作者</b>：Trung Dang,  Om Thakkar,  Swaroop Ramaswamy,  Rajiv Mathews,  Peter Chin,  Françoise Beaufays</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：federated learning often involve transmission, model architectures across multiple domains, g ., resnet ),, existing reconstruction techniques improve, thereby avoiding transmission</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Distributed learning paradigms such as federated learning often involve
transmission of model updates, or gradients, over a network, thereby avoiding
transmission of private data. However, it is possible for sensitive information
about the training data to be revealed from such gradients. Prior works have
demonstrated that labels can be revealed analytically from the last layer of
certain models (e.g., ResNet), or they can be reconstructed jointly with model
inputs by using Gradients Matching [Zhu et al'19] with additional knowledge
about the current state of the model. In this work, we propose a method to
discover the set of labels of training samples from only the gradient of the
last layer and the id to label mapping. Our method is applicable to a wide
variety of model architectures across multiple domains. We demonstrate the
effectiveness of our method for model training in two domains - image
classification, and automatic speech recognition. Furthermore, we show that
existing reconstruction techniques improve their efficacy when used in
conjunction with our method. Conversely, we demonstrate that gradient
quantization and sparsification can significantly reduce the success of the
attack.</p>
  </details>
</details>
<details>
  <summary>28. <b>标题：Quality Estimation Using Round-trip Translation with Sentence Embeddings</b></summary>
  <p><b>编号</b>：[215]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00554</p>
  <p><b>作者</b>：Nathan Crone,  Adam Power,  John Weldon</p>
  <p><b>备注</b>：10 pages, 5 figures</p>
  <p><b>关键词</b>：previous pitfalls found, many previous attempts, method makes use, language representation learning, trip translated sentences</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Estimating the quality of machine translation systems has been an ongoing
challenge for researchers in this field. Many previous attempts at using
round-trip translation as a measure of quality have failed, and there is much
disagreement as to whether it can be a viable method of quality estimation. In
this paper, we revisit round-trip translation, proposing a system which aims to
solve the previous pitfalls found with the approach. Our method makes use of
recent advances in language representation learning to more accurately gauge
the similarity between the original and round-trip translated sentences.
Experiments show that while our approach does not reach the performance of
current state of the art methods, it may still be an effective approach for
some language pairs.</p>
  </details>
</details>
<details>
  <summary>29. <b>标题：Cross-Domain Reasoning via Template Filling</b></summary>
  <p><b>编号</b>：[218]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00539</p>
  <p><b>作者</b>：Dheeraj Rajagopal,  Vivek Khetan,  Bogdan Sacaleanu,  Anatole Gershman,  Andrew Fano,  Eduard Hovy</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：experiments across several pretrained encoder, filling enables pretrained sequence, sequence models across domains, depth error analysis, reasoning across domains</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we explore the ability of sequence to sequence models to
perform cross-domain reasoning. Towards this, we present a
prompt-template-filling approach to enable sequence to sequence models to
perform cross-domain reasoning. We also present a case-study with commonsense
and health and well-being domains, where we study how prompt-template-filling
enables pretrained sequence to sequence models across domains. Our experiments
across several pretrained encoder-decoder models show that cross-domain
reasoning is challenging for current models. We also show an in-depth error
analysis and avenues for future research for reasoning across domains</p>
  </details>
</details>
<details>
  <summary>30. <b>标题：FinEAS: Financial Embedding Analysis of Sentiment</b></summary>
  <p><b>编号</b>：[222]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00526</p>
  <p><b>作者</b>：Asier Gutiérrez-Fandiño,  Miquel Noguer i Alonso,  Petter Kolm,  Jordi Armengol-Estapé</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：including sentiment analysis using labelled datasets, finance called financial embedding analysis, based language models like bert, financial sentiment analysis based, approach achieves significant improvements</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We introduce a new language representation model in finance called Financial
Embedding Analysis of Sentiment (FinEAS). In financial markets, news and
investor sentiment are significant drivers of security prices. Thus, leveraging
the capabilities of modern NLP approaches for financial sentiment analysis is a
crucial component in identifying patterns and trends that are useful for market
participants and regulators. In recent years, methods that use transfer
learning from large Transformer-based language models like BERT, have achieved
state-of-the-art results in text classification tasks, including sentiment
analysis using labelled datasets. Researchers have quickly adopted these
approaches to financial texts, but best practices in this domain are not
well-established. In this work, we propose a new model for financial sentiment
analysis based on supervised fine-tuned sentence embeddings from a standard
BERT model. We demonstrate our approach achieves significant improvements in
comparison to vanilla BERT, LSTM, and FinBERT, a financial domain specific
BERT.</p>
  </details>
</details>
<details>
  <summary>31. <b>标题：Visualization: the missing factor in Simultaneous Speech Translation</b></summary>
  <p><b>编号</b>：[225]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00514</p>
  <p><b>作者</b>：Sara Papi,  Matteo Negri,  Marco Turchi</p>
  <p><b>备注</b>：Accepted at CLIC-it 2021</p>
  <p><b>关键词</b>：like international live conferences, visualization strategy adopted, user experience standpoint, simultaneous speech translation, oriented metrics accounting</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Simultaneous speech translation (SimulST) is the task in which output
generation has to be performed on partial, incremental speech input. In recent
years, SimulST has become popular due to the spread of cross-lingual
application scenarios, like international live conferences and streaming
lectures, in which on-the-fly speech translation can facilitate users' access
to audio-visual content. In this paper, we analyze the characteristics of the
SimulST systems developed so far, discussing their strengths and weaknesses. We
then concentrate on the evaluation framework required to properly assess
systems' effectiveness. To this end, we raise the need for a broader
performance analysis, also including the user experience standpoint. SimulST
systems, indeed, should be evaluated not only in terms of quality/latency
measures, but also via task-oriented metrics accounting, for instance, for the
visualization strategy adopted. In light of this, we highlight which are the
goals achieved by the community and what is still missing.</p>
  </details>
</details>
<details>
  <summary>32. <b>标题：DSC-IITISM at FinCausal 2021: Combining POS tagging with Attention-based  Contextual Representations for Identifying Causal Relationships in Financial  Documents</b></summary>
  <p><b>编号</b>：[235]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00490</p>
  <p><b>作者</b>：Gunjan Haldar,  Aman Mittal,  Pradyumna Gupta</p>
  <p><b>备注</b>：5 pages, 5 tables</p>
  <p><b>关键词</b>：financial documents using transformers, causality detection draws plenty, natural language processing, modern transformer models, explore several methods</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Causality detection draws plenty of attention in the field of Natural
Language Processing and linguistics research. It has essential applications in
information retrieval, event prediction, question answering, financial
analysis, and market research. In this study, we explore several methods to
identify and extract cause-effect pairs in financial documents using
transformers. For this purpose, we propose an approach that combines POS
tagging with the BIO scheme, which can be integrated with modern transformer
models to address this challenge of identifying causality in a given text. Our
best methodology achieves an F1-Score of 0.9551, and an Exact Match Score of
0.8777 on the blind test in the FinCausal-2021 Shared Task at the FinCausal
2021 Workshop.</p>
  </details>
</details>
<details>
  <summary>33. <b>标题：Hierarchical Deep Residual Reasoning for Temporal Moment Localization</b></summary>
  <p><b>编号</b>：[265]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00417</p>
  <p><b>作者</b>：Ziyang Ma,  Xianjing Han,  Xuemeng Song,  Yiran Cui,  Liqiang Nie</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：simple yet effective res, hierarchical deep residual reasoning, existing methods mainly focus, works mainly understand, extensive experiments conducted</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Temporal Moment Localization (TML) in untrimmed videos is a challenging task
in the field of multimedia, which aims at localizing the start and end points
of the activity in the video, described by a sentence query. Existing methods
mainly focus on mining the correlation between video and sentence
representations or investigating the fusion manner of the two modalities. These
works mainly understand the video and sentence coarsely, ignoring the fact that
a sentence can be understood from various semantics, and the dominant words
affecting the moment localization in the semantics are the action and object
reference. Toward this end, we propose a Hierarchical Deep Residual Reasoning
(HDRR) model, which decomposes the video and sentence into multi-level
representations with different semantics to achieve a finer-grained
localization. Furthermore, considering that videos with different resolution
and sentences with different length have different difficulty in understanding,
we design the simple yet effective Res-BiGRUs for feature fusion, which is able
to grasp the useful information in a self-adapting manner. Extensive
experiments conducted on Charades-STA and ActivityNet-Captions datasets
demonstrate the superiority of our HDRR model compared with other
state-of-the-art methods.</p>
  </details>
</details>
<details>
  <summary>34. <b>标题：Speech Emotion Recognition Using Quaternion Convolutional Neural  Networks</b></summary>
  <p><b>编号</b>：[271]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00404</p>
  <p><b>作者</b>：Aneesh Muppidi,  Martin Radfar</p>
  <p><b>备注</b>：Published in ICASSP 2021</p>
  <p><b>关键词</b>：interactive emotional dyadic motion capture, qcnn also achieves comparable results, qcnn based ser model outperforms, quaternion convolutional neural network, model size significantly compared</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Although speech recognition has become a widespread technology, inferring
emotion from speech signals still remains a challenge. To address this problem,
this paper proposes a quaternion convolutional neural network (QCNN) based
speech emotion recognition (SER) model in which Mel-spectrogram features of
speech signals are encoded in an RGB quaternion domain. We show that our QCNN
based SER model outperforms other real-valued methods in the Ryerson
Audio-Visual Database of Emotional Speech and Song (RAVDESS, 8-classes)
dataset, achieving, to the best of our knowledge, state-of-the-art results. The
QCNN also achieves comparable results with the state-of-the-art methods in the
Interactive Emotional Dyadic Motion Capture (IEMOCAP 4-classes) and Berlin
EMO-DB (7-classes) datasets. Specifically, the model achieves an accuracy of
77.87\%, 70.46\%, and 88.78\% for the RAVDESS, IEMOCAP, and EMO-DB datasets,
respectively. In addition, our results show that the quaternion unit structure
is better able to encode internal dependencies to reduce its model size
significantly compared to other methods.</p>
  </details>
</details>
<details>
  <summary>35. <b>标题：FANS: Fusing ASR and NLU for on-device SLU</b></summary>
  <p><b>编号</b>：[273]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00400</p>
  <p><b>作者</b>：Martin Radfar,  Athanasios Mouchtaris,  Siegfried Kunzmann,  Ariya Rastrow</p>
  <p><b>备注</b>：Published in Interspeech 2021</p>
  <p><b>关键词</b>：systems translate voice input commands, predict non null slot tags, current slu systems deploy, given input audio, spoken language understanding</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Spoken language understanding (SLU) systems translate voice input commands to
semantics which are encoded as an intent and pairs of slot tags and values.
Most current SLU systems deploy a cascade of two neural models where the first
one maps the input audio to a transcript (ASR) and the second predicts the
intent and slots from the transcript (NLU). In this paper, we introduce FANS, a
new end-to-end SLU model that fuses an ASR audio encoder to a multi-task NLU
decoder to infer the intent, slot tags, and slot values directly from a given
input audio, obviating the need for transcription. FANS consists of a shared
audio encoder and three decoders, two of which are seq-to-seq decoders that
predict non null slot tags and slot values in parallel and in an
auto-regressive manner. FANS neural encoder and decoders architectures are
flexible which allows us to leverage different combinations of LSTM,
self-attention, and attenders. Our experiments show compared to the
state-of-the-art end-to-end SLU models, FANS reduces ICER and IRER errors
relatively by 30 % and 7 %, respectively, when tested on an in-house SLU
dataset and by 0.86 % and 2 % absolute when tested on a public SLU dataset.</p>
  </details>
</details>
<details>
  <summary>36. <b>标题：EfficientWord-Net: An Open Source Hotword Detection Engine based on  One-shot Learning</b></summary>
  <p><b>编号</b>：[280]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00379</p>
  <p><b>作者</b>：Chidhambararajan R,  Aman Rangaur,  Sibi Chakkaravarthy Sethuraman</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：existing systems requires enormous amounts, special phrases also known, voice assistants like siri, time engines whose purpose, hotword detection engine based</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Voice assistants like Siri, Google Assistant, Alexa etc. are used widely
across the globe for home automation, these require the use of special phrases
also known as hotwords to wake it up and perform an action like "Hey Alexa!",
"Ok Google!" and "Hey Siri!" etc. These hotwords are detected with lightweight
real-time engines whose purpose is to detect the hotwords uttered by the user.
This paper presents the design and implementation of a hotword detection engine
based on one-shot learning which detects the hotword uttered by the user in
real-time with just one or few training samples of the hotword. This approach
is efficient when compared to existing implementations because the process of
adding a new hotword in the existing systems requires enormous amounts of
positive and negative training samples and the model needs to retrain for every
hotword. This makes the existing implementations inefficient in terms of
computation and cost. The architecture proposed in this paper has achieved an
accuracy of 94.51%.</p>
  </details>
</details>
<details>
  <summary>37. <b>标题：AdvCodeMix: Adversarial Attack on Code-Mixed Data</b></summary>
  <p><b>编号</b>：[287]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00350</p>
  <p><b>作者</b>：Sourya Dipta Das,  Ayan Basak,  Soumil Mandal,  Dipankar Das</p>
  <p><b>备注</b>：Accepted to CODS-COMAD 2022</p>
  <p><b>关键词</b>：various sentiment classification models trained, employing various perturbation strategies, mixed classification models, various perturbation techniques, first generalized framework</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Research on adversarial attacks are becoming widely popular in the recent
years. One of the unexplored areas where prior research is lacking is the
effect of adversarial attacks on code-mixed data. Therefore, in the present
work, we have explained the first generalized framework on text perturbation to
attack code-mixed classification models in a black-box setting. We rely on
various perturbation techniques that preserve the semantic structures of the
sentences and also obscure the attacks from the perception of a human user. The
present methodology leverages the importance of a token to decide where to
attack by employing various perturbation strategies. We test our strategies on
various sentiment classification models trained on Bengali-English and
Hindi-English code-mixed datasets, and reduce their F1-scores by nearly 51 %
and 53 % respectively, which can be further reduced if a larger number of
tokens are perturbed in a given sentence.</p>
  </details>
</details>
<details>
  <summary>38. <b>标题：EmpBot: A T5-based Empathetic Chatbot focusing on Sentiments</b></summary>
  <p><b>编号</b>：[299]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00310</p>
  <p><b>作者</b>：Emmanouil Zaranis,  Georgios Paraskevopoulos,  Athanasios Katsamanis,  Alexandros Potamianos</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：empathy forcing auxiliary losses favor empathetic responses, transformer pretrained language model, human evaluation results indicate, favoring empathetic responses, response language modeling</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we introduce EmpBot: an end-to-end empathetic chatbot.
Empathetic conversational agents should not only understand what is being
discussed, but also acknowledge the implied feelings of the conversation
partner and respond appropriately. To this end, we propose a method based on a
transformer pretrained language model (T5). Specifically, during finetuning we
propose to use three objectives: response language modeling, sentiment
understanding, and empathy forcing. The first objective is crucial for
generating relevant and coherent responses, while the next ones are significant
for acknowledging the sentimental state of the conversational partner and for
favoring empathetic responses. We evaluate our model on the EmpatheticDialogues
dataset using both automated metrics and human evaluation. The inclusion of the
sentiment understanding and empathy forcing auxiliary losses favor empathetic
responses, as human evaluation results indicate, comparing with the current
state-of-the-art.</p>
  </details>
</details>
<details>
  <summary>39. <b>标题：EventNarrative: A large-scale Event-centric Dataset for Knowledge  Graph-to-Text Generation</b></summary>
  <p><b>编号</b>：[311]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00276</p>
  <p><b>作者</b>：Anthony Colas,  Ali Sadeghian,  Yue Wang,  Daisy Zhe Wang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：datasets contain many unlinked entities, help break new ground, current largest parallel dataset, corresponding natural language text, also evaluate two types</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We introduce EventNarrative, a knowledge graph-to-text dataset from publicly
available open-world knowledge graphs. Given the recent advances in
event-driven Information Extraction (IE), and that prior research on
graph-to-text only focused on entity-driven KGs, this paper focuses on
event-centric data. However, our data generation system can still be adapted to
other other types of KG data. Existing large-scale datasets in the
graph-to-text area are non-parallel, meaning there is a large disconnect
between the KGs and text. The datasets that have a paired KG and text, are
small scale and manually generated or generated without a rich ontology, making
the corresponding graphs sparse. Furthermore, these datasets contain many
unlinked entities between their KG and text pairs. EventNarrative consists of
approximately 230,000 graphs and their corresponding natural language text, 6
times larger than the current largest parallel dataset. It makes use of a rich
ontology, all of the KGs entities are linked to the text, and our manual
annotations confirm a high data quality. Our aim is two-fold: help break new
ground in event-centric research where data is lacking, and to give researchers
a well-defined, large-scale dataset in order to better evaluate existing and
future knowledge graph-to-text models. We also evaluate two types of baseline
on EventNarrative: a graph-to-text specific model and two state-of-the-art
language models, which previous work has shown to be adaptable to the knowledge
graph-to-text domain.</p>
  </details>
</details>
<details>
  <summary>40. <b>标题：Magic Pyramid: Accelerating Inference with Early Exiting and Token  Pruning</b></summary>
  <p><b>编号</b>：[328]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00230</p>
  <p><b>作者</b>：Xuanli He,  Iman Keivanloo,  Yi Xu,  Xiang He,  Belinda Zeng,  Santosh Rajagopalan,  Trishul Chilimbi</p>
  <p><b>备注</b>：8 pages</p>
  <p><b>关键词</b>：two popular text classification tasks, early exiting express distinctive preferences, wise computation via token pruning, giga floating point operations, computation via removing non</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Pre-training and then fine-tuning large language models is commonly used to
achieve state-of-the-art performance in natural language processing (NLP)
tasks. However, most pre-trained models suffer from low inference speed.
Deploying such large models to applications with latency constraints is
challenging. In this work, we focus on accelerating the inference via
conditional computations. To achieve this, we propose a novel idea, Magic
Pyramid (MP), to reduce both width-wise and depth-wise computation via token
pruning and early exiting for Transformer-based models, particularly BERT. The
former manages to save the computation via removing non-salient tokens, while
the latter can fulfill the computation reduction by terminating the inference
early before reaching the final layer, if the exiting condition is met. Our
empirical studies demonstrate that compared to previous state of arts, MP is
not only able to achieve a speed-adjustable inference but also to surpass token
pruning and early exiting by reducing up to 70% giga floating point operations
(GFLOPs) with less than 0.5% accuracy drop. Token pruning and early exiting
express distinctive preferences to sequences with different lengths. However,
MP is capable of achieving an average of 8.06x speedup on two popular text
classification tasks, regardless of the sizes of the inputs.</p>
  </details>
</details>
<details>
  <summary>41. <b>标题：Backdoor Pre-trained Models Can Transfer to All</b></summary>
  <p><b>编号</b>：[345]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00197</p>
  <p><b>作者</b>：Lujia Shen,  Shouling Ji,  Xuhong Zhang,  Jinfeng Li,  Jing Chen,  Jie Shi,  Chengfang Fang,  Jianwei Yin,  Ting Wang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：popular online model repository hugging face, world natural language processing, inputs containing triggers directly, propose two new metrics, purpose language models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Pre-trained general-purpose language models have been a dominating component
in enabling real-world natural language processing (NLP) applications. However,
a pre-trained model with backdoor can be a severe threat to the applications.
Most existing backdoor attacks in NLP are conducted in the fine-tuning phase by
introducing malicious triggers in the targeted class, thus relying greatly on
the prior knowledge of the fine-tuning task. In this paper, we propose a new
approach to map the inputs containing triggers directly to a predefined output
representation of the pre-trained NLP models, e.g., a predefined output
representation for the classification token in BERT, instead of a target label.
It can thus introduce backdoor to a wide range of downstream tasks without any
prior knowledge. Additionally, in light of the unique properties of triggers in
NLP, we propose two new metrics to measure the performance of backdoor attacks
in terms of both effectiveness and stealthiness. Our experiments with various
types of triggers show that our method is widely applicable to different
fine-tuning tasks (classification and named entity recognition) and to
different models (such as BERT, XLNet, BART), which poses a severe threat.
Furthermore, by collaborating with the popular online model repository Hugging
Face, the threat brought by our method has been confirmed. Finally, we analyze
the factors that may affect the attack performance and share insights on the
causes of the success of our backdoor attack.</p>
  </details>
</details>
<details>
  <summary>42. <b>标题：Automatic Knowledge Augmentation for Generative Commonsense Reasoning</b></summary>
  <p><b>编号</b>：[347]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00192</p>
  <p><b>作者</b>：Jaehyung Seo,  Chanjun Park,  Sugyeong Eo,  Hyeonseok Moon,  Heuiseok Lim</p>
  <p><b>备注</b>：Accepted for Data-centric AI workshop at NeurIPS 2021</p>
  <p><b>关键词</b>：generative language models still struggle, language model without architecture modifications, uses automatic knowledge augmentation, extend commonsense knowledge using, generative commonsense reasoning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Generative commonsense reasoning is the capability of a language model to
generate a sentence with a given concept-set that is based on commonsense
knowledge. However, generative language models still struggle to provide
outputs, and the training set does not contain patterns that are sufficient for
generative commonsense reasoning. In this paper, we propose a data-centric
method that uses automatic knowledge augmentation to extend commonsense
knowledge using a machine knowledge generator. This method can generate
semi-golden sentences that improve the generative commonsense reasoning of a
language model without architecture modifications. Furthermore, this approach
is a model-agnostic method and does not require human effort for data
construction.</p>
  </details>
</details>
<details>
  <summary>43. <b>标题：How should human translation coexist with NMT? Efficient tool for  building high quality parallel corpus</b></summary>
  <p><b>编号</b>：[348]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00191</p>
  <p><b>作者</b>：Chanjun Park,  Seolhwa Lee,  Hyeonseok Moon,  Sugyeong Eo,  Jaehyung Seo,  Heuiseok Lim</p>
  <p><b>备注</b>：Accepted for Data-centric AI workshop at NeurIPS 2021</p>
  <p><b>关键词</b>：combining data quality control, quality parallel corpora, proposed construction process, efficiently constructing high, neural machine translation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper proposes a tool for efficiently constructing high-quality parallel
corpora with minimizing human labor and making this tool publicly available.
Our proposed construction process is based on neural machine translation (NMT)
to allow for it to not only coexist with human translation, but also improve
its efficiency by combining data quality control with human translation in a
data-centric approach.</p>
  </details>
</details>
<details>
  <summary>44. <b>标题：Hierarchical Heterogeneous Graph Representation Learning for Short Text  Classification</b></summary>
  <p><b>编号</b>：[352]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00180</p>
  <p><b>作者</b>：Yaqing Wang,  Song Wang,  Quanming Yao,  Dejing Dou</p>
  <p><b>备注</b>：Accepted to EMNLP 2021</p>
  <p><b>关键词</b>：facilitates effective label propagation among similar short texts, various benchmark short text datasets show, hierarchical heterogeneous graph consisting, shine consistently outperforms state, new method called shine</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Short text classification is a fundamental task in natural language
processing. It is hard due to the lack of context information and labeled data
in practice. In this paper, we propose a new method called SHINE, which is
based on graph neural network (GNN), for short text classification. First, we
model the short text dataset as a hierarchical heterogeneous graph consisting
of word-level component graphs which introduce more semantic and syntactic
information. Then, we dynamically learn a short document graph that facilitates
effective label propagation among similar short texts. Thus, compared with
existing GNN-based methods, SHINE can better exploit interactions between nodes
of the same types and capture similarities between short texts. Extensive
experiments on various benchmark short text datasets show that SHINE
consistently outperforms state-of-the-art methods, especially with fewer
labels.</p>
  </details>
</details>
<details>
  <summary>45. <b>标题：Pseudo-Labeling for Massively Multilingual Speech Recognition</b></summary>
  <p><b>编号</b>：[365]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00161</p>
  <p><b>作者</b>：Loren Lugosch,  Tatiana Likhomanenko,  Gabriel Synnaeve,  Ronan Collobert</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：art monolingual speech recognition systems, massively multilingual speech recognition, unlabeled voxpopuli datasets show, final model using pseudo, works well even</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Semi-supervised learning through pseudo-labeling has become a staple of
state-of-the-art monolingual speech recognition systems. In this work, we
extend pseudo-labeling to massively multilingual speech recognition with 60
languages. We propose a simple pseudo-labeling recipe that works well even with
low-resource languages: train a supervised multilingual model, fine-tune it
with semi-supervised learning on a target language, generate pseudo-labels for
that language, and train a final model using pseudo-labels for all languages,
either from scratch or by fine-tuning. Experiments on the labeled Common Voice
and unlabeled VoxPopuli datasets show that our recipe can yield a model with
better performance for many languages that also transfers well to LibriSpeech.</p>
  </details>
</details>
<details>
  <summary>46. <b>标题：DSEE: Dually Sparsity-embedded Efficient Tuning of Pre-trained Language  Models</b></summary>
  <p><b>编号</b>：[366]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00160</p>
  <p><b>作者</b>：Xuxi Chen,  Tianlong Chen,  Yu Cheng,  Weizhu Chen,  Zhangyang Wang,  Ahmed Hassan Awadallah</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：consistently demonstrate highly impressive parameter -/ training -/ inference, 35 \%$ inference flops savings, maintaining competitive downstream transfer performance, trained language models via magnitude, achieve two key objectives</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Gigantic pre-trained models have become central to natural language
processing (NLP), serving as the starting point for fine-tuning towards a range
of downstream tasks. However, two pain points persist for this paradigm: (a) as
the pre-trained models grow bigger (e.g., 175B parameters for GPT-3), even the
fine-tuning process can be time-consuming and computationally expensive; (b)
the fine-tuned model has the same size as its starting point by default, which
is neither sensible due to its more specialized functionality, nor practical
since many fine-tuned models will be deployed in resource-constrained
environments. To address these pain points, we propose a framework for
resource- and parameter-efficient fine-tuning by leveraging the sparsity prior
in both weight updates and the final model weights. Our proposed framework,
dubbed Dually Sparsity-Embedded Efficient Tuning (DSEE), aims to achieve two
key objectives: (i) parameter efficient fine-tuning - by enforcing
sparsity-aware weight updates on top of the pre-trained weights; and (ii)
resource-efficient inference - by encouraging a sparse weight structure towards
the final fine-tuned model. We leverage sparsity in these two directions by
exploiting both unstructured and structured sparse patterns in pre-trained
language models via magnitude-based pruning and $\ell_1$ sparse regularization.
Extensive experiments and in-depth investigations, with diverse network
backbones (i.e., BERT, GPT-2, and DeBERTa) on dozens of datasets, consistently
demonstrate highly impressive parameter-/training-/inference-efficiency, while
maintaining competitive downstream transfer performance. For instance, our
DSEE-BERT obtains about $35\%$ inference FLOPs savings with <1% trainable parameters and comparable performance to conventional fine-tuning. codes are available in this https url.< p>
  </1%></p></details>
</details>
<details>
  <summary>47. <b>标题：TransAug: Translate as Augmentation for Sentence Embeddings</b></summary>
  <p><b>编号</b>：[367]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00157</p>
  <p><b>作者</b>：Jue Wang,  Haofan Wang,  Xing Wu,  Chaochen Gao,  Debing Zhang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：standard semantic textual similarity, utilizing translated sentence pairs, english encoder via cross, contrastive learning greatly advances, lingual contrastive learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>While contrastive learning greatly advances the representation of sentence
embeddings, it is still limited by the size of the existing sentence datasets.
In this paper, we present TransAug (Translate as Augmentation), which provide
the first exploration of utilizing translated sentence pairs as data
augmentation for text, and introduce a two-stage paradigm to advances the
state-of-the-art sentence embeddings. Instead of adopting an encoder trained in
other languages setting, we first distill a Chinese encoder from a SimCSE
encoder (pretrained in English), so that their embeddings are close in semantic
space, which can be regraded as implicit data augmentation. Then, we only
update the English encoder via cross-lingual contrastive learning and frozen
the distilled Chinese encoder. Our approach achieves a new state-of-art on
standard semantic textual similarity (STS), outperforming both SimCSE and
Sentence-T5, and the best performance in corresponding tracks on transfer tasks
evaluated by SentEval.</p>
  </details>
</details>
<details>
  <summary>48. <b>标题：The Golden Rule as a Heuristic to Measure the Fairness of Texts Using  Machine Learning</b></summary>
  <p><b>编号</b>：[389]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00107</p>
  <p><b>作者</b>：A. Izzidien,  J. Watson,  B. Loe,  P. Romero,  S. Fitz,  D. Stillwell</p>
  <p><b>备注</b>：32 pages, 4 figures</p>
  <p><b>关键词</b>：moral philosophy exists, individuals would typically, implementing two approaches, find f1 scores, axiom throughout history</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>To treat others as one would wish to be treated is a common formulation of
the Golden Rule (GR). Yet, despite its prevalence as an axiom throughout
history, no digitisation of the moral philosophy exists. In this paper we
consider how to digitise it so that it may be used to measure sentences such
as: the boy harmed the girl, and categorise them as fair or unfair. A review
and reply to criticisms of the GR is made. We share the code for the
digitisation of the GR, and test it with a list of sentences. Implementing two
approaches, one using the USE, and a second using ALBERT. We find F1 scores of
78.0, 85.0, respectively. A suggestion of how the technology may be implemented
to avoid unfair biases in word embeddings is made - given that individuals
would typically not wish to be on the receiving end of an unfair act, such as
racism, irrespective of whether the corpus being used deems such discrimination
as praiseworthy.</p>
  </details>
</details>
<details>
  <summary>49. <b>标题：Measuring a Texts Fairness Dimensions Using Machine Learning Based on  Social Psychological Factors</b></summary>
  <p><b>编号</b>：[398]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00086</p>
  <p><b>作者</b>：A. Izzidien,  J. Watson,  B. Loe,  P. Romero,  S. Fitz,  D. Stillwell</p>
  <p><b>备注</b>：38 pages, 9 figures</p>
  <p><b>关键词</b>：dimensioned sentence level fairness perceptions vector, social bias within word embeddings, said fairness approximation vector produces, utilise social psychology literature, social act remains wanting</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Fairness is a principal social value that can be observed in civilisations
around the world. A manifestations of this is in social agreements, often
described in texts, such as contracts. Yet, despite the prevalence of such, a
fairness metric for texts describing a social act remains wanting. To address
this, we take a step back to consider the problem based on first principals.
Instead of using rules or templates, we utilise social psychology literature to
determine the principal factors that humans use when making a fairness
assessment. We then attempt to digitise these using word embeddings into a
multi-dimensioned sentence level fairness perceptions vector to serve as an
approximation for these fairness perceptions. The method leverages a pro-social
bias within word embeddings, for which we obtain an F1= 81.0. A second
approach, using PCA and ML based on the said fairness approximation vector
produces an F1 score of 86.2. We details improvements that can be made in the
methodology to incorporate the projection of sentence embedding on to a
subspace representation of fairness.</p>
  </details>
</details>
<details>
  <summary>50. <b>标题：Skyformer: Remodel Self-Attention with Gaussian Kernel and Nyström  Method</b></summary>
  <p><b>编号</b>：[420]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00035</p>
  <p><b>作者</b>：Yifan Chen,  Qi Zeng,  Heng Ji,  Yun Yang</p>
  <p><b>备注</b>：To appear in NeurIPS 2021</p>
  <p><b>关键词</b>：long range arena benchmark show, computational cost without sacrificing, requiring fewer computation resources, although kernel machines suffer, high computational cost</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Transformers are expensive to train due to the quadratic time and space
complexity in the self-attention mechanism. On the other hand, although kernel
machines suffer from the same computation bottleneck in pairwise dot products,
several approximation schemes have been successfully incorporated to
considerably reduce their computational cost without sacrificing too much
accuracy. In this work, we leverage the computation methods for kernel machines
to alleviate the high computational cost and introduce Skyformer, which
replaces the softmax structure with a Gaussian kernel to stabilize the model
training and adapts the Nyström method to a non-positive semidefinite matrix
to accelerate the computation. We further conduct theoretical analysis by
showing that the matrix approximation error of our proposed method is small in
the spectral norm. Experiments on Long Range Arena benchmark show that the
proposed method is sufficient in getting comparable or even better performance
than the full self-attention while requiring fewer computation resources.</p>
  </details>
</details>
<h1>机器学习</h1>
<details>
  <summary>1. <b>标题：When Does Contrastive Learning Preserve Adversarial Robustness from  Pretraining to Finetuning?</b></summary>
  <p><b>编号</b>：[1]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.01124</p>
  <p><b>作者</b>：Lijie Fan,  Sijia Liu,  Pin-Yu Chen,  Gaoyuan Zhang,  Chuang Gan</p>
  <p><b>备注</b>：NeurIPS 2021. Code is available at this https URL</p>
  <p><b>关键词</b>：supervised robust learning methods across multiple datasets, task robustness transferability without loss, helps preserve robustness without forgetting, novel adversarial contrastive pretraining framework, task robustness transferability '.</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Contrastive learning (CL) can learn generalizable feature representations and
achieve the state-of-the-art performance of downstream tasks by finetuning a
linear classifier on top of it. However, as adversarial robustness becomes
vital in image classification, it remains unclear whether or not CL is able to
preserve robustness to downstream tasks. The main challenge is that in the
self-supervised pretraining + supervised finetuning paradigm, adversarial
robustness is easily forgotten due to a learning task mismatch from pretraining
to finetuning. We call such a challenge 'cross-task robustness
transferability'. To address the above problem, in this paper we revisit and
advance CL principles through the lens of robustness enhancement. We show that
(1) the design of contrastive views matters: High-frequency components of
images are beneficial to improving model robustness; (2) Augmenting CL with
pseudo-supervision stimulus (e.g., resorting to feature clustering) helps
preserve robustness without forgetting. Equipped with our new designs, we
propose AdvCL, a novel adversarial contrastive pretraining framework. We show
that AdvCL is able to enhance cross-task robustness transferability without
loss of model accuracy and finetuning efficiency. With a thorough experimental
study, we demonstrate that AdvCL outperforms the state-of-the-art
self-supervised robust learning methods across multiple datasets (CIFAR-10,
CIFAR-100, and STL-10) and finetuning schemes (linear evaluation and full model
finetuning).</p>
  </details>
</details>
<details>
  <summary>2. <b>标题：Rebooting ACGAN: Auxiliary Classifier GANs with Stable Training</b></summary>
  <p><b>编号</b>：[3]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.01118</p>
  <p><b>作者</b>：Minguk Kang,  Woohyeon Shim,  Minsu Cho,  Jaesik Park</p>
  <p><b>备注</b>：34 pages, 26 figures, 35th Conference on Neural Information Processing Systems (NeurIPS 2021)</p>
  <p><b>关键词</b>：rebooted auxiliary classifier generative adversarial network, conditional generative adversarial networks, projecting input vectors onto, generate easily classifiable samples, auxiliary classifier gan</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Conditional Generative Adversarial Networks (cGAN) generate realistic images
by incorporating class information into GAN. While one of the most popular
cGANs is an auxiliary classifier GAN with softmax cross-entropy loss (ACGAN),
it is widely known that training ACGAN is challenging as the number of classes
in the dataset increases. ACGAN also tends to generate easily classifiable
samples with a lack of diversity. In this paper, we introduce two cures for
ACGAN. First, we identify that gradient exploding in the classifier can cause
an undesirable collapse in early training, and projecting input vectors onto a
unit hypersphere can resolve the problem. Second, we propose the Data-to-Data
Cross-Entropy loss (D2D-CE) to exploit relational information in the
class-labeled dataset. On this foundation, we propose the Rebooted Auxiliary
Classifier Generative Adversarial Network (ReACGAN). The experimental results
show that ReACGAN achieves state-of-the-art generation results on CIFAR10,
Tiny-ImageNet, CUB200, and ImageNet datasets. We also verify that ReACGAN
benefits from differentiable augmentations and that D2D-CE harmonizes with
StyleGAN2 architecture. Model weights and a software package that provides
implementations of representative cGANs and all experiments in our paper are
available at this https URL.</p>
  </details>
</details>
<details>
  <summary>3. <b>标题：Resource-Efficient Federated Learning</b></summary>
  <p><b>编号</b>：[4]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.01108</p>
  <p><b>作者</b>：Ahmed M. Abdelmoniem,  Atal Narayan Sahu,  Marco Canini,  Suhaib A. Fahmy</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：existing fl schemes use random participant selection, also improving trained model quality, presents numerous challenges relating, learners using local data, factors enable resource efficiency</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Federated Learning (FL) enables distributed training by learners using local
data, thereby enhancing privacy and reducing communication. However, it
presents numerous challenges relating to the heterogeneity of the data
distribution, device capabilities, and participant availability as deployments
scale, which can impact both model convergence and bias. Existing FL schemes
use random participant selection to improve fairness; however, this can result
in inefficient use of resources and lower quality training. In this work, we
systematically address the question of resource efficiency in FL, showing the
benefits of intelligent participant selection, and incorporation of updates
from straggling participants. We demonstrate how these factors enable resource
efficiency while also improving trained model quality.</p>
  </details>
</details>
<details>
  <summary>4. <b>标题：FREGAN : an application of generative adversarial networks in enhancing  the frame rate of videos</b></summary>
  <p><b>编号</b>：[5]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.01105</p>
  <p><b>作者</b>：Rishik Mishra,  Neeraj Gupta,  Nitya Shukla</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：frame rate enhancement generative adversarial network, high refresh rate, high refresh rate, frame rate enhancement, structural similarity index</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A digital video is a collection of individual frames, while streaming the
video the scene utilized the time slice for each frame. High refresh rate and
high frame rate is the demand of all high technology applications. The action
tracking in videos becomes easier and motion becomes smoother in gaming
applications due to the high refresh rate. It provides a faster response
because of less time in between each frame that is displayed on the screen.
FREGAN (Frame Rate Enhancement Generative Adversarial Network) model has been
proposed, which predicts future frames of a video sequence based on a sequence
of past frames. In this paper, we investigated the GAN model and proposed
FREGAN for the enhancement of frame rate in videos. We have utilized Huber loss
as a loss function in the proposed FREGAN. It provided excellent results in
super-resolution and we have tried to reciprocate that performance in the
application of frame rate enhancement. We have validated the effectiveness of
the proposed model on the standard datasets (UCF101 and RFree500). The
experimental outcomes illustrate that the proposed model has a Peak
signal-to-noise ratio (PSNR) of 34.94 and a Structural Similarity Index (SSIM)
of 0.95.</p>
  </details>
</details>
<details>
  <summary>5. <b>标题：Investigation of Independent Reinforcement Learning Algorithms in  Multi-Agent Environments</b></summary>
  <p><b>编号</b>：[7]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.01100</p>
  <p><b>作者</b>：Ken Ming Lee,  Sriram Ganapathi Subramanian,  Mark Crowley</p>
  <p><b>备注</b>：15 pages, 7 figures, Accepted for NeurIPS 2021 Deep Reinforcement Learning Workshop</p>
  <p><b>关键词</b>：agents trained via independent algorithms learn, cooperative partially observable environments, independent reinforcement learning algorithms, three main categories, adding recurrence improves</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Independent reinforcement learning algorithms have no theoretical guarantees
for finding the best policy in multi-agent settings. However, in practice,
prior works have reported good performance with independent algorithms in some
domains and bad performance in others. Moreover, a comprehensive study of the
strengths and weaknesses of independent algorithms is lacking in the
literature. In this paper, we carry out an empirical comparison of the
performance of independent algorithms on four PettingZoo environments that span
the three main categories of multi-agent environments, i.e., cooperative,
competitive, and mixed. We show that in fully-observable environments,
independent algorithms can perform on par with multi-agent algorithms in
cooperative and competitive settings. For the mixed environments, we show that
agents trained via independent algorithms learn to perform well individually,
but fail to learn to cooperate with allies and compete with enemies. We also
show that adding recurrence improves the learning of independent algorithms in
cooperative partially observable environments.</p>
  </details>
</details>
<details>
  <summary>6. <b>标题：Encoding Program as Image: Evaluating Visual Representation of Source  Code</b></summary>
  <p><b>编号</b>：[8]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.01097</p>
  <p><b>作者</b>：Md Rafiqul Islam Rabin,  Mohammad Amin Alipour</p>
  <p><b>备注</b>：8 pages, 2 figures, 1 table</p>
  <p><b>关键词</b>：neural models may provide high performance, code summarization task suggests, include various syntactic, evaluate several variations, encode source code</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>There are several approaches to encode source code in the input vectors of
neural models. These approaches attempt to include various syntactic and
semantic features of input programs in their encoding. In this paper, we
investigate Code2Snapshot, a novel representation of the source code that is
based on the snapshots of input programs. We evaluate several variations of
this representation and compare its performance with state-of-the-art
representations that utilize the rich syntactic and semantic features of input
programs. Our preliminary study on the utility of Code2Snapshot in the code
summarization task suggests that simple snapshots of input programs have
comparable performance to the state-of-the-art representations. Interestingly,
obscuring the input programs have insignificant impacts on the Code2Snapshot
performance, suggesting that, for some tasks, neural models may provide high
performance by relying merely on the structure of input programs.</p>
  </details>
</details>
<details>
  <summary>7. <b>标题：ZeBRA: Precisely Destroying Neural Networks with Zero-Data Based  Repeated Bit Flip Attack</b></summary>
  <p><b>编号</b>：[14]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.01080</p>
  <p><b>作者</b>：Dahoon Park,  Kon-Woo Kwon,  Sunghoon Im,  Jaeha Kung</p>
  <p><b>备注</b>：14 pages, 3 figures, 5 tables, Accepted at British Machine Vision Conference (BMVC) 2021</p>
  <p><b>关键词</b>：data based repeated bit flip attack, precisely destroys deep neural networks, named distilled target data, model without accessing training, adversarial weight attack require</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we present Zero-data Based Repeated bit flip Attack (ZeBRA)
that precisely destroys deep neural networks (DNNs) by synthesizing its own
attack datasets. Many prior works on adversarial weight attack require not only
the weight parameters, but also the training or test dataset in searching
vulnerable bits to be attacked. We propose to synthesize the attack dataset,
named distilled target data, by utilizing the statistics of batch normalization
layers in the victim DNN model. Equipped with the distilled target data, our
ZeBRA algorithm can search vulnerable bits in the model without accessing
training or test dataset. Thus, our approach makes the adversarial weight
attack more fatal to the security of DNNs. Our experimental results show that
2.0x (CIFAR-10) and 1.6x (ImageNet) less number of bit flips are required on
average to destroy DNNs compared to the previous attack method. Our code is
available at https://github. com/pdh930105/ZeBRA.</p>
  </details>
</details>
<details>
  <summary>8. <b>标题：SmartSplit: Latency-Energy-Memory Optimisation for CNN Splitting on  Smartphone Environment</b></summary>
  <p><b>编号</b>：[15]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.01077</p>
  <p><b>作者</b>：Ishan Prakash,  Aniruddh Bansal,  Rohit Verma,  Rajeev Shorey</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：although new generation smartphones come, decision analysis based approach, multiple cnn models show, taken centre stage, convolution neural networks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Artificial Intelligence has now taken centre stage in the smartphone industry
owing to the need of bringing all processing close to the user and addressing
privacy concerns. Convolution Neural Networks (CNNs), which are used by several
AI applications, are highly resource and computation intensive. Although new
generation smartphones come with AI-enabled chips, minimal memory and energy
utilisation is essential as many applications are run concurrently on a
smartphone. In light of this, optimising the workload on the smartphone by
offloading a part of the processing to a cloud server is an important direction
of research. In this paper, we analyse the feasibility of splitting CNNs
between smartphones and cloud server by formulating a multi-objective
optimisation problem that optimises the end-to-end latency, memory utilisation,
and energy consumption. We design SmartSplit, a Genetic Algorithm with decision
analysis based approach to solve the optimisation problem. Our experiments run
with multiple CNN models show that splitting a CNN between a smartphone and a
cloud server is feasible. The proposed approach, SmartSplit fares better when
compared to other state-of-the-art approaches.</p>
  </details>
</details>
<details>
  <summary>9. <b>标题：FedFm: Towards a Robust Federated Learning Approach For Fault Mitigation  at the Edge Nodes</b></summary>
  <p><b>编号</b>：[16]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.01074</p>
  <p><b>作者</b>：Manupriya Gupta,  Pavas Goyal,  Rohit Verma,  Rajeev Shorey,  Huzur Saran</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：numerous heterogeneous edge devices collecting data, different network channels get involved, robust federated learning technique, federated learning deviates, selected devices fail</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Federated Learning deviates from the norm of "send data to model" to "send
model to data". When used in an edge ecosystem, numerous heterogeneous edge
devices collecting data through different means and connected through different
network channels get involved in the training process. Failure of edge devices
in such an ecosystem due to device fault or network issues is highly likely. In
this paper, we first analyse the impact of the number of edge devices on an FL
model and provide a strategy to select an optimal number of devices that would
contribute to the model. We observe how the edge ecosystem behaves when the
selected devices fail and provide a mitigation strategy to ensure a robust
Federated Learning technique.</p>
  </details>
</details>
<details>
  <summary>10. <b>标题：Learning to Assimilate in Chaotic Dynamical Systems</b></summary>
  <p><b>编号</b>：[21]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.01058</p>
  <p><b>作者</b>：Michael McCabe,  Jed Brown</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：experimental results across several benchmark systems highlight, produce effective estimation schemes, used data assimilation methods, extending powerful results, data assimilation methods</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The accuracy of simulation-based forecasting in chaotic systems is heavily
dependent on high-quality estimates of the system state at the time the
forecast is initialized. Data assimilation methods are used to infer these
initial conditions by systematically combining noisy, incomplete observations
and numerical models of system dynamics to produce effective estimation
schemes. We introduce amortized assimilation, a framework for learning to
assimilate in dynamical systems from sequences of noisy observations with no
need for ground truth data. We motivate the framework by extending powerful
results from self-supervised denoising to the dynamical systems setting through
the use of differentiable simulation. Experimental results across several
benchmark systems highlight the improved effectiveness of our approach over
widely-used data assimilation methods.</p>
  </details>
</details>
<details>
  <summary>11. <b>标题：MOST-GAN: 3D Morphable StyleGAN for Disentangled Face Image Manipulation</b></summary>
  <p><b>编号</b>：[22]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.01048</p>
  <p><b>作者</b>：Safa C. Medin,  Bernhard Egger,  Anoop Cherian,  Ye Wang,  Joshua B. Tenenbaum,  Xiaoming Liu,  Tim K. Marks</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：art 2d hair manipulation network, generate strikingly photorealistic face images, nonlinear 3d morphable models, gan achieves photorealistic manipulation, priori models physical attributes</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent advances in generative adversarial networks (GANs) have led to
remarkable achievements in face image synthesis. While methods that use
style-based GANs can generate strikingly photorealistic face images, it is
often difficult to control the characteristics of the generated faces in a
meaningful and disentangled way. Prior approaches aim to achieve such semantic
control and disentanglement within the latent space of a previously trained
GAN. In contrast, we propose a framework that a priori models physical
attributes of the face such as 3D shape, albedo, pose, and lighting explicitly,
thus providing disentanglement by design. Our method, MOST-GAN, integrates the
expressive power and photorealism of style-based GANs with the physical
disentanglement and flexibility of nonlinear 3D morphable models, which we
couple with a state-of-the-art 2D hair manipulation network. MOST-GAN achieves
photorealistic manipulation of portrait images with fully disentangled 3D
control over their physical attributes, enabling extreme manipulation of
lighting, facial expression, and pose variations up to full profile view.</p>
  </details>
</details>
<details>
  <summary>12. <b>标题：A Unified View of cGANs with and without Classifiers</b></summary>
  <p><b>编号</b>：[25]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.01035</p>
  <p><b>作者</b>：Si-An Chen,  Chun-Liang Li,  Hsuan-Tien Lin</p>
  <p><b>备注</b>：Accepted by NeurIPS 2021</p>
  <p><b>关键词</b>：explains several popular cgan variants, help eliminate samples generated, conditional generative adversarial networks, proposed framework outperforms state, one popular design</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Conditional Generative Adversarial Networks (cGANs) are implicit generative
models which allow to sample from class-conditional distributions. Existing
cGANs are based on a wide range of different discriminator designs and training
objectives. One popular design in earlier works is to include a classifier
during training with the assumption that good classifiers can help eliminate
samples generated with wrong classes. Nevertheless, including classifiers in
cGANs often comes with a side effect of only generating easy-to-classify
samples. Recently, some representative cGANs avoid the shortcoming and reach
state-of-the-art performance without having classifiers. Somehow it remains
unanswered whether the classifiers can be resurrected to design better cGANs.
In this work, we demonstrate that classifiers can be properly leveraged to
improve cGANs. We start by using the decomposition of the joint probability
distribution to connect the goals of cGANs and classification as a unified
framework. The framework, along with a classic energy model to parameterize
distributions, justifies the use of classifiers for cGANs in a principled
manner. It explains several popular cGAN variants, such as ACGAN, ProjGAN, and
ContraGAN, as special cases with different levels of approximations, which
provides a unified view and brings new insights to understanding cGANs.
Experimental results demonstrate that the design inspired by the proposed
framework outperforms state-of-the-art cGANs on multiple benchmark datasets,
especially on the most challenging ImageNet. The code is available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>13. <b>标题：Interpretable contrastive word mover's embedding</b></summary>
  <p><b>编号</b>：[30]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.01023</p>
  <p><b>作者</b>：Ruijie Jiang,  Julia Gouvea,  Eric Miller,  David Hammer,  Shuchin Aeron</p>
  <p><b>备注</b>：8 pages, 4 figures</p>
  <p><b>关键词</b>：method improves significantly upon existing baselines, help ls researchers gain insights, develop natural language processing, several public datasets, clusters via identifying</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper shows that a popular approach to the supervised embedding of
documents for classification, namely, contrastive Word Mover's Embedding, can
be significantly enhanced by adding interpretability. This interpretability is
achieved by incorporating a clustering promoting mechanism into the contrastive
loss. On several public datasets, we show that our method improves
significantly upon existing baselines while providing interpretation to the
clusters via identifying a set of keywords that are the most representative of
a particular class. Our approach was motivated in part by the need to develop
Natural Language Processing (NLP) methods for the \textit{novel problem of
assessing student work for scientific writing and thinking} - a problem that is
central to the area of (educational) Learning Sciences (LS). In this context,
we show that our approach leads to a meaningful assessment of the student work
related to lab reports from a biology class and can help LS researchers gain
insights into student understanding and assess evidence of scientific thought
processes.</p>
  </details>
</details>
<details>
  <summary>14. <b>标题：A variance principle explains why dropout finds flatter minima</b></summary>
  <p><b>编号</b>：[31]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.01022</p>
  <p><b>作者</b>：Zhongwang Zhang,  Hanxu Zhou,  Zhi-Qin John Xu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：standard gradient descent training, dropout finds flatter minima, dropout finds flatter minima, flatter minimum compared, obtain good generalization</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Although dropout has achieved great success in deep learning, little is known
about how it helps the training find a good generalization solution in the
high-dimensional parameter space. In this work, we show that the training with
dropout finds the neural network with a flatter minimum compared with standard
gradient descent training. We further study the underlying mechanism of why
dropout finds flatter minima through experiments. We propose a {\it Variance
Principle} that the variance of a noise is larger at the sharper direction of
the loss landscape. Existing works show that SGD satisfies the variance
principle, which leads the training to flatter minima. Our work show that the
noise induced by the dropout also satisfies the variance principle that
explains why dropout finds flatter minima. In general, our work points out that
the variance principle is an important similarity between dropout and SGD that
lead the training to find flatter minima and obtain good generalization.</p>
  </details>
</details>
<details>
  <summary>15. <b>标题：HyperPINN: Learning parameterized differential equations with  physics-informed hypernetworks</b></summary>
  <p><b>编号</b>：[35]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.01008</p>
  <p><b>作者</b>：Filipe de Avila Belbute-Peres,  Yi-fan Chen,  Fei Sha</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：particular task requires solving, informed neural network models, generate neural networks, neural network solutions, requires either</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Many types of physics-informed neural network models have been proposed in
recent years as approaches for learning solutions to differential equations.
When a particular task requires solving a differential equation at multiple
parameterizations, this requires either re-training the model, or expanding its
representation capacity to include the parameterization -- both solution that
increase its computational cost. We propose the HyperPINN, which uses
hypernetworks to learn to generate neural networks that can solve a
differential equation from a given parameterization. We demonstrate with
experiments on both a PDE and an ODE that this type of model can lead to neural
network solutions to differential equations that maintain a small size, even
when learning a family of solutions over a parameter space.</p>
  </details>
</details>
<details>
  <summary>16. <b>标题：Projected GANs Converge Faster</b></summary>
  <p><b>编号</b>：[36]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.01007</p>
  <p><b>作者</b>：Axel Sauer,  Kashyap Chitta,  Jens Müller,  Andreas Geiger</p>
  <p><b>备注</b>：To appear in NeurIPS 2021. Project Page: this https URL</p>
  <p><b>关键词</b>：discriminator cannot fully exploit features, projected gan improves image quality, mixes features across channels, art fréchet inception distance, two benchmark datasets</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Generative Adversarial Networks (GANs) produce high-quality images but are
challenging to train. They need careful regularization, vast amounts of
compute, and expensive hyper-parameter sweeps. We make significant headway on
these issues by projecting generated and real samples into a fixed, pretrained
feature space. Motivated by the finding that the discriminator cannot fully
exploit features from deeper layers of the pretrained model, we propose a more
effective strategy that mixes features across channels and resolutions. Our
Projected GAN improves image quality, sample efficiency, and convergence speed.
It is further compatible with resolutions of up to one Megapixel and advances
the state-of-the-art Fréchet Inception Distance (FID) on twenty-two benchmark
datasets. Importantly, Projected GANs match the previously lowest FIDs up to 40
times faster, cutting the wall-clock time from 5 days to less than 3 hours
given the same computational resources.</p>
  </details>
</details>
<details>
  <summary>17. <b>标题：PDE-READ: Human-readable Partial Differential Equation Discovery using  Deep Learning</b></summary>
  <p><b>编号</b>：[38]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00998</p>
  <p><b>作者</b>：Robert Stephany,  Christopher Earls</p>
  <p><b>备注</b>：32 pages, 14 figures</p>
  <p><b>关键词</b>：uses two rational neural networks, principled sparse regression algorithm, free sparse regression algorithm, source library called pde, pde discovery shows promise</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>PDE discovery shows promise for uncovering predictive models for complex
physical systems but has difficulty when measurements are sparse and noisy. We
introduce a new approach for PDE discovery that uses two Rational Neural
Networks and a principled sparse regression algorithm to identify the hidden
dynamics that govern a system's response. The first network learns the system
response function, while the second learns a hidden PDE which drives the
system's evolution. We then use a parameter-free sparse regression algorithm to
extract a human-readable form of the hidden PDE from the second network. We
implement our approach in an open-source library called PDE-READ. Our approach
successfully identifies the Heat, Burgers, and Korteweg-De Vries equations with
remarkable consistency. We demonstrate that our approach is unprecedentedly
robust to both sparsity and noise and is, therefore, applicable to real-world
observational data.</p>
  </details>
</details>
<details>
  <summary>18. <b>标题：Transfer Learning Approach to Bicycle-sharing Systems' Station Location  Planning using OpenStreetMap Data</b></summary>
  <p><b>编号</b>：[41]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00990</p>
  <p><b>作者</b>：Kamil Raczycki,  Piotr Szymański</p>
  <p><b>备注</b>：Accepted to 4th ACM SIGSPATIAL International Workshop on Advances in Resilient and Intelligent Cities</p>
  <p><b>关键词</b>：sharing stations usually requires expensive data gathering, uber h3 discrete global grid system, include citizens leaving public transport, different cities using transfer learning, bike sharing system quickly</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Bicycle-sharing systems (BSS) have become a daily reality for many citizens
of larger, wealthier cities in developed regions. However, planning the layout
of bicycle-sharing stations usually requires expensive data gathering,
surveying travel behavior and trip modelling followed by station layout
optimization. Many smaller cities and towns, especially in developing areas,
may have difficulty financing such projects. Planning a BSS also takes a
considerable amount of time. Yet as the pandemic has shown us, municipalities
will face the need to adapt rapidly to mobility shifts, which include citizens
leaving public transport for bicycles. Laying out a bike sharing system quickly
will become critical in addressing the increase in bike demand. This paper
addresses the problem of cost and time in BSS layout design and proposes a new
solution to streamline and facilitate the process of such planning by using
spatial embedding methods. Based only on publicly available data from
OpenStreetMap, and station layouts from 34 cities in Europe, a method has been
developed to divide cities into micro-regions using the Uber H3 discrete global
grid system and to indicate regions where it is worth placing a station based
on existing systems in different cities using transfer learning. The result of
the work is a mechanism to support planners in their decision making when
planning a station layout with a choice of reference cities.</p>
  </details>
</details>
<details>
  <summary>19. <b>标题：Partial-Adaptive Submodular Maximization</b></summary>
  <p><b>编号</b>：[42]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00986</p>
  <p><b>作者</b>：Shaojie Tang,  Jing Yuan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：typical adaptive sequential decision making problem, e ., one must wait, monotone adaptive submodular maximization problem, adaptive submodular maximization focus, adaptive submodular maximization</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The goal of a typical adaptive sequential decision making problem is to
design an interactive policy that selects a group of items sequentially, based
on some partial observations, to maximize the expected utility. It has been
shown that the utility functions of many real-world applications, including
pooled-based active learning and adaptive influence maximization, satisfy the
property of adaptive submodularity. However, most of existing studies on
adaptive submodular maximization focus on the fully adaptive setting, i.e., one
must wait for the feedback from \emph{all} past selections before making the
next selection. Although this approach can take full advantage of feedback from
the past to make informed decisions, it may take a longer time to complete the
selection process as compared with the non-adaptive solution where all
selections are made in advance before any observations take place. In this
paper, we explore the problem of partial-adaptive submodular maximization where
one is allowed to make multiple selections in a batch simultaneously and
observe their realizations together. Our approach enjoys the benefits of
adaptivity while reducing the time spent on waiting for the observations from
past selections. To the best of our knowledge, no results are known for
partial-adaptive policies for the non-monotone adaptive submodular maximization
problem. We study this problem under both cardinality constraint and knapsack
constraints, and develop effective and efficient solutions for both cases. We
also analyze the batch query complexity, i.e., the number of batches a policy
takes to complete the selection process, of our policy under some additional
assumptions.</p>
  </details>
</details>
<details>
  <summary>20. <b>标题：Mixture Proportion Estimation and PU Learning: A Modern Approach</b></summary>
  <p><b>编号</b>：[44]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00980</p>
  <p><b>作者</b>：Saurabh Garg,  Yifan Wu,  Alex Smola,  Sivaraman Balakrishnan,  Zachary C. Lipton</p>
  <p><b>备注</b>：Spotlight at NeurIPS 2021</p>
  <p><b>关键词</b>：recently proposed heuristics lack theoretical coherence, ted )$^ n $, alternates, methods dominate previous approaches empirically, conditional value ignoring risk, propose two simple techniques</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Given only positive examples and unlabeled examples (from both positive and
negative classes), we might hope nevertheless to estimate an accurate
positive-versus-negative classifier. Formally, this task is broken down into
two subtasks: (i) Mixture Proportion Estimation (MPE) -- determining the
fraction of positive examples in the unlabeled data; and (ii) PU-learning --
given such an estimate, learning the desired positive-versus-negative
classifier. Unfortunately, classical methods for both problems break down in
high-dimensional settings. Meanwhile, recently proposed heuristics lack
theoretical coherence and depend precariously on hyperparameter tuning. In this
paper, we propose two simple techniques: Best Bin Estimation (BBE) (for MPE);
and Conditional Value Ignoring Risk (CVIR), a simple objective for PU-learning.
Both methods dominate previous approaches empirically, and for BBE, we
establish formal guarantees that hold whenever we can train a model to cleanly
separate out a small subset of positive examples. Our final algorithm
(TED)$^n$, alternates between the two procedures, significantly improving both
our mixture proportion estimator and classifier</p>
  </details>
</details>
<details>
  <summary>21. <b>标题：Transductive Data Augmentation with Relational Path Rule Mining for  Knowledge Graph Embedding</b></summary>
  <p><b>编号</b>：[48]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00974</p>
  <p><b>作者</b>：Yushi Hirose,  Masashi Shimbo,  Taro Watanabe</p>
  <p><b>备注</b>：8 pages, 0 figures, accepted by 2021 IEEE International Conference on Big Knowledge. The copyright of this paper has been transferred to the IEEE, please comply with the copyright of the IEEE</p>
  <p><b>关键词</b>：proposed method effectively improves, propose transductive data augmentation, alternately augments training data, relation path rule induction, relation path rules</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>For knowledge graph completion, two major types of prediction models exist:
one based on graph embeddings, and the other based on relation path rule
induction. They have different advantages and disadvantages. To take advantage
of both types, hybrid models have been proposed recently. One of the hybrid
models, UniKER, alternately augments training data by relation path rules and
trains an embedding model. Despite its high prediction accuracy, it does not
take full advantage of relation path rules, as it disregards low-confidence
rules in order to maintain the quality of augmented data. To mitigate this
limitation, we propose transductive data augmentation by relation path rules
and confidence-based weighting of augmented data. The results and analysis show
that our proposed method effectively improves the performance of the embedding
model by augmenting data that include true answers or entities similar to them.</p>
  </details>
</details>
<details>
  <summary>22. <b>标题：Hex2vec -- Context-Aware Embedding H3 Hexagons with OpenStreetMap Tags</b></summary>
  <p><b>编号</b>：[49]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00970</p>
  <p><b>作者</b>：Szymon Woźniak,  Piotr Szymański</p>
  <p><b>备注</b>：Accepted at 4th ACM SIGSPATIAL International Workshop on AI for Geographic Knowledge Discovery (GEOAI '21)</p>
  <p><b>关键词</b>：quality inference using deep neural networks, resulting vector representations showcase semantic structures, satellite photos ), mobility data, past approaches however concentrated, learning vector representations</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Representation learning of spatial and geographic data is a rapidly
developing field which allows for similarity detection between areas and
high-quality inference using deep neural networks. Past approaches however
concentrated on embedding raster imagery (maps, street or satellite photos),
mobility data or road networks. In this paper we propose the first approach to
learning vector representations of OpenStreetMap regions with respect to urban
functions and land-use in a micro-region grid. We identify a subset of OSM tags
related to major characteristics of land-use, building and urban region
functions, types of water, green or other natural areas. Through manual
verification of tagging quality, we selected 36 cities were for training region
representations. Uber's H3 index was used to divide the cities into hexagons,
and OSM tags were aggregated for each hexagon. We propose the hex2vec method
based on the Skip-gram model with negative sampling. The resulting vector
representations showcase semantic structures of the map characteristics,
similar to ones found in vector-based language models. We also present insights
from region similarity detection in six Polish cities and propose a region
typology obtained through agglomerative clustering.</p>
  </details>
</details>
<details>
  <summary>23. <b>标题：VPFNet: Voxel-Pixel Fusion Network for Multi-class 3D Object Detection</b></summary>
  <p><b>编号</b>：[52]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00966</p>
  <p><b>作者</b>：Chia-Hung Wang,  Hsueh-Wei Chen,  Li-Chen Fu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：class 3d object detection task, class 3d object detection network, camera sensor data streams, dl )- embedded fusion, class object detection</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Many LiDAR-based methods for detecting large objects, single-class object
detection, or under easy situations were claimed to perform quite well.
However, their performances of detecting small objects or under hard situations
did not surpass those of the fusion-based ones due to failure to leverage the
image semantics. In order to elevate the detection performance in a complicated
environment, this paper proposes a deep learning (DL)-embedded fusion-based
multi-class 3D object detection network which admits both LiDAR and camera
sensor data streams, named Voxel-Pixel Fusion Network (VPFNet). Inside this
network, a key novel component is called Voxel-Pixel Fusion (VPF) layer, which
takes advantage of the geometric relation of a voxel-pixel pair and fuses the
voxel features and the pixel features with proper mechanisms. Moreover, several
parameters are particularly designed to guide and enhance the fusion effect
after considering the characteristics of a voxel-pixel pair. Finally, the
proposed method is evaluated on the KITTI benchmark for multi-class 3D object
detection task under multilevel difficulty, and is shown to outperform all
state-of-the-art methods in mean average precision (mAP). It is also noteworthy
that our approach here ranks the first on the KITTI leaderboard for the
challenging pedestrian class.</p>
  </details>
</details>
<details>
  <summary>24. <b>标题：iFlow: Numerically Invertible Flows for Efficient Lossless Compression  via a Uniform Coder</b></summary>
  <p><b>编号</b>：[53]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00965</p>
  <p><b>作者</b>：Shifeng Zhang,  Ning Kang,  Tom Ryder,  Zhenguo Li</p>
  <p><b>备注</b>：Accepted for NeurIPS 2021 Spotlight</p>
  <p><b>关键词</b>：neural compression garners little commercial interest due, discuss lossless compression using normalizing flows, first propose modular scale transform, numerically invertible flow transformations based, achieving efficient lossless compression</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>It was estimated that the world produced $59 ZB$ ($5.9 \times 10^{13} GB$) of
data in 2020, resulting in the enormous costs of both data storage and
transmission. Fortunately, recent advances in deep generative models have
spearheaded a new class of so-called "neural compression" algorithms, which
significantly outperform traditional codecs in terms of compression ratio.
Unfortunately, the application of neural compression garners little commercial
interest due to its limited bandwidth; therefore, developing highly efficient
frameworks is of critical practical importance. In this paper, we discuss
lossless compression using normalizing flows which have demonstrated a great
capacity for achieving high compression ratios. As such, we introduce iFlow, a
new method for achieving efficient lossless compression. We first propose
Modular Scale Transform (MST) and a novel family of numerically invertible flow
transformations based on MST. Then we introduce the Uniform Base Conversion
System (UBCS), a fast uniform-distribution codec incorporated into iFlow,
enabling efficient compression. iFlow achieves state-of-the-art compression
ratios and is $5\times$ quicker than other high-performance schemes.
Furthermore, the techniques presented in this paper can be used to accelerate
coding time for a broad class of flow-based algorithms.</p>
  </details>
</details>
<details>
  <summary>25. <b>标题：Machine Learning aided Crop Yield Optimization</b></summary>
  <p><b>编号</b>：[54]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00963</p>
  <p><b>作者</b>：Chace Ashcraft,  Kiran Karra</p>
  <p><b>备注</b>：4 pages, 2 figures</p>
  <p><b>关键词</b>：optimize crop yield may help address upcoming global food demands due, apply modern deep reinforcement learning, help optimize crop yield, simultaneously minimizing constraining factors, crop simulation environment</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present a crop simulation environment with an OpenAI Gym interface, and
apply modern deep reinforcement learning (DRL) algorithms to optimize yield. We
empirically show that DRL algorithms may be useful in discovering new policies
and approaches to help optimize crop yield, while simultaneously minimizing
constraining factors such as water and fertilizer usage. We propose that this
hybrid plant modeling and data-driven approach for discovering new strategies
to optimize crop yield may help address upcoming global food demands due to
population expansion and climate change.</p>
  </details>
</details>
<details>
  <summary>26. <b>标题：gtfs2vec -- Learning GTFS Embeddings for comparing Public Transport  Offer in Microregions</b></summary>
  <p><b>编号</b>：[56]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00960</p>
  <p><b>作者</b>：Piotr Gramacki,  Szymon Woźniak,  Piotr Szymański</p>
  <p><b>备注</b>：Accepted at 4th ACM SIGSPATIAL International Workshop on AI for Geographic Knowledge Discovery GEOAI'21</p>
  <p><b>关键词</b>：qualitatively describe public transport availability, similar public transport schedule characteristics, created certain features describing, associative deep neural network, selected 48 european cities</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We selected 48 European cities and gathered their public transport timetables
in the GTFS format. We utilized Uber's H3 spatial index to divide each city
into hexagonal micro-regions. Based on the timetables data we created certain
features describing the quantity and variety of public transport availability
in each region. Next, we trained an auto-associative deep neural network to
embed each of the regions. Having such prepared representations, we then used a
hierarchical clustering approach to identify similar regions. To do so, we
utilized an agglomerative clustering algorithm with a euclidean distance
between regions and Ward's method to minimize in-cluster variance. Finally, we
analyzed the obtained clusters at different levels to identify some number of
clusters that qualitatively describe public transport availability. We showed
that our typology matches the characteristics of analyzed cities and allows
succesful searching for areas with similar public transport schedule
characteristics.</p>
  </details>
</details>
<details>
  <summary>27. <b>标题：Robot Learning from Randomized Simulations: A Review</b></summary>
  <p><b>编号</b>：[57]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00956</p>
  <p><b>作者</b>：Fabio Muratore,  Fabio Ramos,  Greg Turk,  Wenhao Yu,  Michael Gienger,  Jan Peters</p>
  <p><b>备注</b>：submitted to Frontiers in Robotics and AI</p>
  <p><b>关键词</b>：facilitate learning robot control policies, despite becoming increasingly realistic, require large amounts, hence inevitably imperfect, art approaches learn</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The rise of deep learning has caused a paradigm shift in robotics research,
favoring methods that require large amounts of data. It is prohibitively
expensive to generate such data sets on a physical platform. Therefore,
state-of-the-art approaches learn in simulation where data generation is fast
as well as inexpensive and subsequently transfer the knowledge to the real
robot (sim-to-real). Despite becoming increasingly realistic, all simulators
are by construction based on models, hence inevitably imperfect. This raises
the question of how simulators can be modified to facilitate learning robot
control policies and overcome the mismatch between simulation and reality,
often called the 'reality gap'. We provide a comprehensive review of
sim-to-real research for robotics, focusing on a technique named 'domain
randomization' which is a method for learning from randomized simulations.</p>
  </details>
</details>
<details>
  <summary>28. <b>标题：Nested Multiple Instance Learning with Attention Mechanisms</b></summary>
  <p><b>编号</b>：[59]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00947</p>
  <p><b>作者</b>：Saul Fuster,  Trygve Eftestøl,  Kjersti Engan</p>
  <p><b>备注</b>：Submitted to ICASSP 2022</p>
  <p><b>关键词</b>：proposed model provides high accuracy performance, nested mil considers labelled bags within bags, method fits diverse applications, like finding relevant regions, classical image datasets show</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Multiple instance learning (MIL) is a type of weakly supervised learning
where multiple instances of data with unknown labels are sorted into bags.
Since knowledge about the individual instances is incomplete, labels are
assigned to the bags containing the instances. While this method fits diverse
applications were labelled data is scarce, it lacks depth for solving more
complex scenarios where associations between sets of instances have to be made,
like finding relevant regions of interest in an image or detecting events in a
set of time-series signals. Nested MIL considers labelled bags within bags,
where only the outermost bag is labelled and inner-bags and instances are
represented as latent labels. In addition, we propose using an attention
mechanism to add interpretability, providing awareness into the impact of each
instance to the weak bag label. Experiments in classical image datasets show
that our proposed model provides high accuracy performance as well as spotting
relevant instances on image regions.</p>
  </details>
</details>
<details>
  <summary>29. <b>标题：Bounds all around: training energy-based models with bidirectional  bounds</b></summary>
  <p><b>编号</b>：[67]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00929</p>
  <p><b>作者</b>：Cong Geng,  Jia Wang,  Zhiyong Gao,  Jes Frellsen,  Søren Hauberg</p>
  <p><b>备注</b>：This paper has been accepted by NeurIPS 2021</p>
  <p><b>关键词</b>：developments significantly stabilize training, variational value function, thereby providing grounding, generative adversarial networks, best engineering practice</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Energy-based models (EBMs) provide an elegant framework for density
estimation, but they are notoriously difficult to train. Recent work has
established links to generative adversarial networks, where the EBM is trained
through a minimax game with a variational value function. We propose a
bidirectional bound on the EBM log-likelihood, such that we maximize a lower
bound and minimize an upper bound when solving the minimax game. We link one
bound to a gradient penalty that stabilizes training, thereby providing
grounding for best engineering practice. To evaluate the bounds we develop a
new and efficient estimator of the Jacobi-determinant of the EBM generator. We
demonstrate that these developments significantly stabilize training and yield
high-quality density estimation and sample generation.</p>
  </details>
</details>
<details>
  <summary>30. <b>标题：Combining expert knowledge and neural networks to model environmental  stresses in agriculture</b></summary>
  <p><b>编号</b>：[71]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00918</p>
  <p><b>作者</b>：Kostadin Cvejoski,  Jannis Schuecker,  Anne-Katrin Mahlein,  Bogdan Georgiev</p>
  <p><b>备注</b>：19 pages, Winners of the 2019 Syngenta Crop Challenge</p>
  <p><b>关键词</b>：first design deterministic expert models, combine representation learning capabilities, model environmental heat, sensitivity analysis, resistant ones</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this work we combine representation learning capabilities of neural
network with agricultural knowledge from experts to model environmental heat
and drought stresses. We first design deterministic expert models which serve
as a benchmark and inform the design of flexible neural-network architectures.
Finally, a sensitivity analysis of the latter allows a clustering of hybrids
into susceptible and resistant ones.</p>
  </details>
</details>
<details>
  <summary>31. <b>标题：Adaptive Modeling Powers Fast Multi-parameter Fitting of CARS Spectra</b></summary>
  <p><b>编号</b>：[72]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00917</p>
  <p><b>作者</b>：Gregory J. Hunt,  Cody R. Ground,  Andrew D. Cutler</p>
  <p><b>备注</b>：14 pages, 6 figures</p>
  <p><b>关键词</b>：based measurement technique widely applied across many science, simultaneously recover multiple flow parameters, h_2 /$ air flame, recover multiple flow parameters, pump cars experiment probing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Coherent anti-Stokes Raman Spectroscopy (CARS) is a laser-based measurement
technique widely applied across many science and engineering disciplines to
perform non-intrusive gas diagnostics. CARS is often used to study combustion,
where the measured spectra can be used to simultaneously recover multiple flow
parameters from the reacting gas such as temperature and relative species mole
fractions. This is typically done by using numerical optimization to find the
flow parameters for which a theoretical model of the CARS spectra best matches
the actual measurements. The most commonly used theoretical model is the CARSFT
spectrum calculator. Unfortunately, this CARSFT spectrum generator is
computationally expensive and using it to recover multiple flow parameters can
be prohibitively time-consuming, especially when experiments have hundreds or
thousands of measurements distributed over time or space. To overcome these
issues, several methods have been developed to approximate CARSFT using a
library of pre-computed theoretical spectra. In this work we present a new
approach that leverages ideas from the machine learning literature to build an
adaptively smoothed kernel-based approximator. In application on a simulated
dual-pump CARS experiment probing a $H_2/$air flame, we show that the approach
can use a small number library spectra to quickly and accurately recover
temperature and four gas species' mole fractions. The method's flexibility
allows fine-tuned navigation of the trade-off between speed and accuracy, and
makes the approach suitable for a wide range of problems and flow regimes.</p>
  </details>
</details>
<details>
  <summary>32. <b>标题：Multi-Attribute Balanced Sampling for Disentangled GAN Controls</b></summary>
  <p><b>编号</b>：[74]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00909</p>
  <p><b>作者</b>：Perla Doubinsky (CEDRIC - VERTIGO, CNAM),  Nicolas Audebert (CEDRIC - VERTIGO, CNAM),  Michel Crucianu (CEDRIC - VERTIGO, CNAM),  Hervé Le Borgne (LIST)</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：supervised approaches typically sample, extracting disentangled linear directions, occuring attributes thus balancing, two popular gan architectures, vary semantic attributes</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Various controls over the generated data can be extracted from the latent
space of a pre-trained GAN, as it implicitly encodes the semantics of the
training data. The discovered controls allow to vary semantic attributes in the
generated images but usually lead to entangled edits that affect multiple
attributes at the same time. Supervised approaches typically sample and
annotate a collection of latent codes, then train classifiers in the latent
space to identify the controls. Since the data generated by GANs reflects the
biases of the original dataset, so do the resulting semantic controls. We
propose to address disentanglement by subsampling the generated data to remove
over-represented co-occuring attributes thus balancing the semantics of the
dataset before training the classifiers. We demonstrate the effectiveness of
this approach by extracting disentangled linear directions for face
manipulation on two popular GAN architectures, PGGAN and StyleGAN, and two
datasets, CelebAHQ and FFHQ. We show that this approach outperforms
state-of-the-art classifier-based methods while avoiding the need for
disentanglement-enforcing post-processing.</p>
  </details>
</details>
<details>
  <summary>33. <b>标题：Smart Fashion: A Review of AI Applications in the Fashion & Apparel  Industry</b></summary>
  <p><b>编号</b>：[75]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00905</p>
  <p><b>作者</b>：Seyed Omid Mohammadi,  Ahmad Kalhor (University of Tehran, College of Engineering, School of Electrical and Computer Engineering, Tehran, Iran)</p>
  <p><b>备注</b>：99 Pages, 79 Figures, 24 Tables, Full length manuscript</p>
  <p><b>关键词</b>：86 public fashion datasets accompanied, fashion research articles provides researchers, explicit research directions, 580 related articles, paper provides</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The fashion industry is on the verge of an unprecedented change. The
implementation of machine learning, computer vision, and artificial
intelligence (AI) in fashion applications is opening lots of new opportunities
for this industry. This paper provides a comprehensive survey on this matter,
categorizing more than 580 related articles into 22 well-defined
fashion-related tasks. Such structured task-based multi-label classification of
fashion research articles provides researchers with explicit research
directions and facilitates their access to the related studies, improving the
visibility of studies simultaneously. For each task, a time chart is provided
to analyze the progress through the years. Furthermore, we provide a list of 86
public fashion datasets accompanied by a list of suggested applications and
additional information for each.</p>
  </details>
</details>
<details>
  <summary>34. <b>标题：Towards a theory of quantum gravity from neural networks</b></summary>
  <p><b>编号</b>：[76]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00903</p>
  <p><b>作者</b>：Vitaly Vanchurin</p>
  <p><b>备注</b>：19 pages</p>
  <p><b>关键词</b>：provide alternative macroscopic descriptions, two different types, stochastic entropy production, entropy destruction due, dynamical system described</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Neural network is a dynamical system described by two different types of
degrees of freedom: fast-changing non-trainable variables (e.g. state of
neurons) and slow-changing trainable variables (e.g. weights and biases). We
show that the non-equilibrium dynamics of trainable variables can be described
by the Madelung equations, if the number of neurons is fixed, and by the
Schrodinger equation, if the learning system is capable of adjusting its own
parameters such as the number of neurons, step size and mini-batch size. We
argue that the Lorentz symmetries and curved space-time can emerge from the
interplay between stochastic entropy production and entropy destruction due to
learning. We show that the non-equilibrium dynamics of non-trainable variables
can be described by the geodesic equation (in the emergent space-time) for
localized states of neurons, and by the Einstein equations (with cosmological
constant) for the entire network. We conclude that the quantum description of
trainable variables and the gravitational description of non-trainable
variables are dual in the sense that they provide alternative macroscopic
descriptions of the same learning system, defined microscopically as a neural
network.</p>
  </details>
</details>
<details>
  <summary>35. <b>标题：Click-Based Student Performance Prediction: A Clustering Guided  Meta-Learning Approach</b></summary>
  <p><b>编号</b>：[78]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00901</p>
  <p><b>作者</b>：Yun-Wei Chu,  Elizabeth Tenorio,  Laura Cruz,  Kerrie Douglas,  Andrew S. Lan,  Christopher G. Brinton</p>
  <p><b>备注</b>：10 pages, IEEE BigData 2021</p>
  <p><b>关键词</b>：may lose important information embedded within, method obtains substantial improvements, clicking behavior via time, series learning architectures operating, predicting student knowledge acquisition</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We study the problem of predicting student knowledge acquisition in online
courses from clickstream behavior. Motivated by the proliferation of eLearning
lecture delivery, we specifically focus on student in-video activity in
lectures videos, which consist of content and in-video quizzes. Our methodology
for predicting in-video quiz performance is based on three key ideas we
develop. First, we model students' clicking behavior via time-series learning
architectures operating on raw event data, rather than defining hand-crafted
features as in existing approaches that may lose important information embedded
within the click sequences. Second, we develop a self-supervised clickstream
pre-training to learn informative representations of clickstream events that
can initialize the prediction model effectively. Third, we propose a clustering
guided meta-learning-based training that optimizes the prediction model to
exploit clusters of frequent patterns in student clickstream sequences. Through
experiments on three real-world datasets, we demonstrate that our method
obtains substantial improvements over two baseline models in predicting
students' in-video quiz performance. Further, we validate the importance of the
pre-training and meta-learning components of our framework through ablation
studies. Finally, we show how our methodology reveals insights on
video-watching behavior associated with knowledge acquisition for useful
learning analytics.</p>
  </details>
</details>
<details>
  <summary>36. <b>标题：Equivariant Contrastive Learning</b></summary>
  <p><b>编号</b>：[80]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00899</p>
  <p><b>作者</b>：Rumen Dangovski,  Li Jing,  Charlotte Loh,  Seungwook Han,  Akash Srivastava,  Brian Cheung,  Pulkit Agrawal,  Marin Soljačić</p>
  <p><b>备注</b>：17 pages, 5 figures</p>
  <p><b>关键词</b>：several popular computer vision benchmarks, training produces semantically good representations, applications beyond computer vision, broader class called equivariance, extend popular ssl methods</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In state-of-the-art self-supervised learning (SSL) pre-training produces
semantically good representations by encouraging them to be invariant under
meaningful transformations prescribed from human knowledge. In fact, the
property of invariance is a trivial instance of a broader class called
equivariance, which can be intuitively understood as the property that
representations transform according to the way the inputs transform. Here, we
show that rather than using only invariance, pre-training that encourages
non-trivial equivariance to some transformations, while maintaining invariance
to other transformations, can be used to improve the semantic quality of
representations. Specifically, we extend popular SSL methods to a more general
framework which we name Equivariant Self-Supervised Learning (E-SSL). In E-SSL,
a simple additional pre-training objective encourages equivariance by
predicting the transformations applied to the input. We demonstrate E-SSL's
effectiveness empirically on several popular computer vision benchmarks.
Furthermore, we demonstrate usefulness of E-SSL for applications beyond
computer vision; in particular, we show its utility on regression problems in
photonics science. We will release our code.</p>
  </details>
</details>
<details>
  <summary>37. <b>标题：Indiscriminate Poisoning Attacks Are Shortcuts</b></summary>
  <p><b>编号</b>：[81]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00898</p>
  <p><b>作者</b>：Da Yu,  Huishuai Zhang,  Wei Chen,  Jian Yin,  Tie-Yan Liu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：trained feature extractors would disable, deep learning heavily relies, indiscriminate data poisoning attacks, synthesize linear separable data, preventing unauthorized use</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Indiscriminate data poisoning attacks, which add imperceptible perturbations
to training data to maximize the test error of trained models, have become a
trendy topic because they are thought to be capable of preventing unauthorized
use of data. In this work, we investigate why these perturbations work in
principle. We find that the perturbations of advanced poisoning attacks are
almost \textbf{linear separable} when assigned with the target labels of the
corresponding samples, which hence can work as \emph{shortcuts} for the
learning objective. This important population property has not been unveiled
before. Moreover, we further verify that linear separability is indeed the
workhorse for poisoning attacks. We synthesize linear separable data as
perturbations and show that such synthetic perturbations are as powerful as the
deliberately crafted attacks. Our finding suggests that the \emph{shortcut
learning} problem is more serious than previously believed as deep learning
heavily relies on shortcuts even if they are of an imperceptible scale and
mixed together with the normal features. This finding also suggests that
pre-trained feature extractors would disable these poisoning attacks
effectively.</p>
  </details>
</details>
<details>
  <summary>38. <b>标题：Intervention Efficient Algorithm for Two-Stage Causal MDPs</b></summary>
  <p><b>编号</b>：[84]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00886</p>
  <p><b>作者</b>：Rahul Madhavan,  Aurghya Maiti,  Gaurav Sinha,  Siddharth Barman</p>
  <p><b>备注</b>：29 pages</p>
  <p><b>关键词</b>：study markov decision processes, instance dependent regret bound, utilizes convex optimization, regret minimization guarantees, current work develops</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We study Markov Decision Processes (MDP) wherein states correspond to causal
graphs that stochastically generate rewards. In this setup, the learner's goal
is to identify atomic interventions that lead to high rewards by intervening on
variables at each state. Generalizing the recent causal-bandit framework, the
current work develops (simple) regret minimization guarantees for two-stage
causal MDPs, with parallel causal graph at each state. We propose an algorithm
that achieves an instance dependent regret bound. A key feature of our
algorithm is that it utilizes convex optimization to address the exploration
problem. We identify classes of instances wherein our regret guarantee is
essentially tight, and experimentally validate our theoretical results.</p>
  </details>
</details>
<details>
  <summary>39. <b>标题：Artificial Intelligence in the Low-Level Realm -- A Survey</b></summary>
  <p><b>编号</b>：[87]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00881</p>
  <p><b>作者</b>：Vahid Mohammadi Safarzadeh,  Hamed Ghasr Loghmani</p>
  <p><b>备注</b>：7 pages</p>
  <p><b>关键词</b>：traditional os kernel main tasks, practically related area concentrated, making ml computational aspects, specifically machine learning, aware machine learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Resource-aware machine learning has been a trending topic in recent years,
focusing on making ML computational aspects more exploitable by the edge
devices in the Internet of Things. This paper attempts to review a conceptually
and practically related area concentrated on efforts and challenges for
applying ML in the operating systems' main tasks in a low-resource environment.
Artificial Intelligence has been integrated into the operating system with
applications such as voice or image recognition. However, this integration is
only in user space. Here, we seek methods and efforts that exploit AI
approaches, specifically machine learning, in the OSes' primary
responsibilities. We provide the improvements that ML can bring to OS to make
them more trustworthy. In other words, the main question to be answered is how
AI has played/can play a role directly in improving the traditional OS kernel
main tasks. Also, the challenges and limitations in the way of this combination
are provided.</p>
  </details>
</details>
<details>
  <summary>40. <b>标题：On the Expressivity of Markov Reward</b></summary>
  <p><b>编号</b>：[89]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00876</p>
  <p><b>作者</b>：David Abel,  Will Dabney,  Anna Harutyunyan,  Mark K. Ho,  Michael L. Littman,  Doina Precup,  Satinder Singh</p>
  <p><b>备注</b>：Accepted to NeurIPS 2021</p>
  <p><b>关键词</b>：study around three new abstract notions, main results prove, reward function exists, markov reward function, markov reward function</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Reward is the driving force for reinforcement-learning agents. This paper is
dedicated to understanding the expressivity of reward as a way to capture tasks
that we would want an agent to perform. We frame this study around three new
abstract notions of "task" that might be desirable: (1) a set of acceptable
behaviors, (2) a partial ordering over behaviors, or (3) a partial ordering
over trajectories. Our main results prove that while reward can express many of
these tasks, there exist instances of each task type that no Markov reward
function can capture. We then provide a set of polynomial-time algorithms that
construct a Markov reward function that allows an agent to optimize tasks of
each of these three types, and correctly determine when no such reward function
exists. We conclude with an empirical study that corroborates and illustrates
our theoretical findings.</p>
  </details>
</details>
<details>
  <summary>41. <b>标题：A moment-matching metric for latent variable generative models</b></summary>
  <p><b>编号</b>：[90]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00875</p>
  <p><b>作者</b>：Cédric Beaulac</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：facing unsupervised learning problems, evaluating latent variable models, latent variable models, discuss future work, gaussian mixture models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>It can be difficult to assess the quality of a fitted model when facing
unsupervised learning problems. Latent variable models, such as variation
autoencoders and Gaussian mixture models, are often trained with
likelihood-based approaches. In scope of Goodhart's law, when a metric becomes
a target it ceases to be a good metric and therefore we should not use
likelihood to assess the quality of the fit of these models. The solution we
propose is a new metric for model comparison or regularization that relies on
moments. The concept is to study the difference between the data moments and
the model moments using a matrix norm, such as the Frobenius norm. We show how
to use this new metric for model comparison and then for regularization. It is
common to draw samples from the fitted distribution when evaluating latent
variable models and we show that our proposed metric is faster to compute and
has a smaller variance that this alternative. We conclude this article with a
proof of concept of both applications and we discuss future work.</p>
  </details>
</details>
<details>
  <summary>42. <b>标题：An Uncertainty-Informed Framework for Trustworthy Fault Diagnosis in  Safety-Critical Applications</b></summary>
  <p><b>编号</b>：[91]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00874</p>
  <p><b>作者</b>：Taotao Zhou,  Enrique Lopez Droguett,  Ali Mosleh,  Felix T.S. Chan</p>
  <p><b>备注</b>：49 pages</p>
  <p><b>关键词</b>：thus potentially avoiding undesirable consequences, probabilistic bayesian convolutional neural network, end maintenance decision support systems, four common sensor faults, three ood datasets attributed</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>There has been a growing interest in deep learning-based prognostic and
health management (PHM) for building end-to-end maintenance decision support
systems, especially due to the rapid development of autonomous systems.
However, the low trustworthiness of PHM hinders its applications in
safety-critical assets when handling data from an unknown distribution that
differs from the training dataset, referred to as the out-of-distribution (OOD)
dataset. To bridge this gap, we propose an uncertainty-informed framework to
diagnose faults and meanwhile detect the OOD dataset, enabling the capability
of learning unknowns and achieving trustworthy fault diagnosis. Particularly,
we develop a probabilistic Bayesian convolutional neural network (CNN) to
quantify both epistemic and aleatory uncertainties in fault diagnosis. The
fault diagnosis model flags the OOD dataset with large predictive uncertainty
for expert intervention and is confident in providing predictions for the data
within tolerable uncertainty. This results in trustworthy fault diagnosis and
reduces the risk of erroneous decision-making, thus potentially avoiding
undesirable consequences. The proposed framework is demonstrated by the fault
diagnosis of bearings with three OOD datasets attributed to random number
generation, an unknown fault mode, and four common sensor faults, respectively.
The results show that the proposed framework is of particular advantage in
tackling unknowns and enhancing the trustworthiness of fault diagnosis in
safety-critical applications.</p>
  </details>
</details>
<details>
  <summary>43. <b>标题：Probabilistic prediction of the heave motions of a semi-submersible by a  deep learning problem model</b></summary>
  <p><b>编号</b>：[92]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00873</p>
  <p><b>作者</b>：Xiaoxian Guo,  Xiantao Zhang,  Xinliang Tian,  Wenyue Lu,  Xin Li</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：provides useful early warning information, wide noise level range, floating offshore platform refers, training data could help, time motion prediction</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The real-time motion prediction of a floating offshore platform refers to
forecasting its motions in the following one- or two-wave cycles, which helps
improve the performance of a motion compensation system and provides useful
early warning information. In this study, we extend a deep learning (DL) model,
which could predict the heave and surge motions of a floating semi-submersible
20 to 50 seconds ahead with good accuracy, to quantify its uncertainty of the
predictive time series with the help of the dropout technique. By repeating the
inference several times, it is found that the collection of the predictive time
series is a Gaussian process (GP). The DL model with dropout learned a kernel
inside, and the learning procedure was similar to GP regression. Adding noise
into training data could help the model to learn more robust features from the
training data, thereby leading to a better performance on test data with a wide
noise level range. This study extends the understanding of the DL model to
predict the wave excited motions of an offshore platform.</p>
  </details>
</details>
<details>
  <summary>44. <b>标题：Statistical Consequences of Dueling Bandits</b></summary>
  <p><b>编号</b>：[93]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00870</p>
  <p><b>作者</b>：Nayan Saxena,  Pan Chen,  Emmy Liu</p>
  <p><b>备注</b>：In Workshop on Reinforcement Learning for Education, 14th International Conference on Educational Data Mining , Paris, France, 2021</p>
  <p><b>关键词</b>：dueling bandit algorithms perform well, comparing traditional uniform sampling, using dueling bandit algorithms, dueling bandit algorithm, run adaptive experiments</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Multi-Armed-Bandit frameworks have often been used by researchers to assess
educational interventions, however, recent work has shown that it is more
beneficial for a student to provide qualitative feedback through preference
elicitation between different alternatives, making a dueling bandits framework
more appropriate. In this paper, we explore the statistical quality of data
under this framework by comparing traditional uniform sampling to a dueling
bandit algorithm and find that dueling bandit algorithms perform well at
cumulative regret minimisation, but lead to inflated Type-I error rates and
reduced power under certain circumstances. Through these results we provide
insight into the challenges and opportunities in using dueling bandit
algorithms to run adaptive experiments.</p>
  </details>
</details>
<details>
  <summary>45. <b>标题：DetectorNet: Transformer-enhanced Spatial Temporal Graph Neural Network  for Traffic Prediction</b></summary>
  <p><b>编号</b>：[94]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00869</p>
  <p><b>作者</b>：He Li,  Shiyu Zhang,  Xuejiao Li,  Liangcai Su,  Hongjie Huang,  Duo Jin,  Linghao Chen,  Jianbing Huang,  Jaesoo Yoo</p>
  <p><b>备注</b>：The 29th ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems (ACM SIGSPATIAL 2021)</p>
  <p><b>关键词</b>：eventually loses much valuable potential information, data presents unique challenges including, four ablation experiments proves, static road network structure, view temporal attention module</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Detectors with high coverage have direct and far-reaching benefits for road
users in route planning and avoiding traffic congestion, but utilizing these
data presents unique challenges including: the dynamic temporal correlation,
and the dynamic spatial correlation caused by changes in road conditions.
Although the existing work considers the significance of modeling with
spatial-temporal correlation, what it has learned is still a static road
network structure, which cannot reflect the dynamic changes of roads, and
eventually loses much valuable potential information. To address these
challenges, we propose DetectorNet enhanced by Transformer. Differs from
previous studies, our model contains a Multi-view Temporal Attention module and
a Dynamic Attention module, which focus on the long-distance and short-distance
temporal correlation, and dynamic spatial correlation by dynamically updating
the learned knowledge respectively, so as to make accurate prediction. In
addition, the experimental results on two public datasets and the comparison
results of four ablation experiments proves that the performance of DetectorNet
is better than the eleven advanced baselines.</p>
  </details>
</details>
<details>
  <summary>46. <b>标题：Surreal Decisions</b></summary>
  <p><b>编号</b>：[98]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00862</p>
  <p><b>作者</b>：Eddy Keming Chen,  Daniel Rubio</p>
  <p><b>备注</b>：First published online: 05 June 2018</p>
  <p><b>关键词</b>：surreal decision theory respects dominance reasoning even, pascalian decision problem depends, surreal numbers shall provide, pure pascalian strategy beats, although expected utility theory</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Although expected utility theory has proven a fruitful and elegant theory in
the finite realm, attempts to generalize it to infinite values have resulted in
many paradoxes. In this paper, we argue that the use of John Conway's surreal
numbers shall provide a firm mathematical foundation for transfinite decision
theory. To that end, we prove a surreal representation theorem and show that
our surreal decision theory respects dominance reasoning even in the case of
infinite values. We then bring our theory to bear on one of the more venerable
decision problems in the literature: Pascal's Wager. Analyzing the wager
showcases our theory's virtues and advantages. To that end, we analyze two
objections against the wager: Mixed Strategies and Many Gods. After formulating
the two objections in the framework of surreal utilities and probabilities, our
theory correctly predicts that (1) the pure Pascalian strategy beats all mixed
strategies, and (2) what one should do in a Pascalian decision problem depends
on what one's credence function is like. Our analysis therefore suggests that
although Pascal's Wager is mathematically coherent, it does not deliver what it
purports to, a rationally compelling argument that people should lead a
religious life regardless of how confident they are in theism and its
alternatives.</p>
  </details>
</details>
<details>
  <summary>47. <b>标题：A Frequency Perspective of Adversarial Robustness</b></summary>
  <p><b>编号</b>：[99]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00861</p>
  <p><b>作者</b>：Shishira R Maiya,  Max Ehrlich,  Vatsal Agarwal,  Ser-Nam Lim,  Tom Goldstein,  Abhinav Shrivastava</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：provide new insights towards, commonly observed accuracy vs, analyze many intriguing properties, simply dataset dependent, despite recent advances</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Adversarial examples pose a unique challenge for deep learning systems.
Despite recent advances in both attacks and defenses, there is still a lack of
clarity and consensus in the community about the true nature and underlying
properties of adversarial examples. A deep understanding of these examples can
provide new insights towards the development of more effective attacks and
defenses. Driven by the common misconception that adversarial examples are
high-frequency noise, we present a frequency-based understanding of adversarial
examples, supported by theoretical and empirical findings. Our analysis shows
that adversarial examples are neither in high-frequency nor in low-frequency
components, but are simply dataset dependent. Particularly, we highlight the
glaring disparities between models trained on CIFAR-10 and ImageNet-derived
datasets. Utilizing this framework, we analyze many intriguing properties of
training robust models with frequency constraints, and propose a
frequency-based explanation for the commonly observed accuracy vs. robustness
trade-off.</p>
  </details>
</details>
<details>
  <summary>48. <b>标题：Large-Scale Deep Learning Optimizations: A Comprehensive Survey</b></summary>
  <p><b>编号</b>：[101]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00856</p>
  <p><b>作者</b>：Xiaoxin He,  Fuzhao Xue,  Xiaozhe Ren,  Yang You</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：models consistently yield better performance, generally spend longer training time, generalization gap arises, achieved promising results, scale deep learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep learning have achieved promising results on a wide spectrum of AI
applications. Larger datasets and models consistently yield better performance.
However, we generally spend longer training time on more computation and
communication. In this survey, we aim to provide a clear sketch about the
optimizations for large-scale deep learning with regard to the model accuracy
and model efficiency. We investigate algorithms that are most commonly used for
optimizing, elaborate the debatable topic of generalization gap arises in
large-batch training, and review the SOTA strategies in addressing the
communication overhead and reducing the memory footprints.</p>
  </details>
</details>
<details>
  <summary>49. <b>标题：Back to Basics: Efficient Network Compression via IMP</b></summary>
  <p><b>编号</b>：[103]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00843</p>
  <p><b>作者</b>：Max Zimmer,  Christoph Spiegel,  Sebastian Pokutta</p>
  <p><b>备注</b>：10 pages main text, 11 pages appendix, 4 tables, 12 figures</p>
  <p><b>关键词</b>：realistic yet easily realisable baseline, effectively compressing deep neural networks, total training time actually required, properly determine optimal layer, global selection criterion fails</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Network pruning is a widely used technique for effectively compressing Deep
Neural Networks with little to no degradation in performance during inference.
Iterative Magnitude Pruning (IMP) is one of the most established approaches for
network pruning, consisting of several iterative training and pruning steps,
where a significant amount of the network's performance is lost after pruning
and then recovered in the subsequent retraining phase. While commonly used as a
benchmark reference, it is often argued that a) it reaches suboptimal states by
not incorporating sparsification into the training phase, b) its global
selection criterion fails to properly determine optimal layer-wise pruning
rates and c) its iterative nature makes it slow and non-competitive. In light
of recently proposed retraining techniques, we investigate these claims through
rigorous and consistent experiments where we compare IMP to
pruning-during-training algorithms, evaluate proposed modifications of its
selection criterion and study the number of iterations and total training time
actually required. We find that IMP with SLR for retraining can outperform
state-of-the-art pruning-during-training approaches without or with only little
computational overhead, that the global magnitude selection criterion is
largely competitive with more complex approaches and that only few retraining
epochs are needed in practice to achieve most of the sparsity-vs.-performance
tradeoff of IMP. Our goals are both to demonstrate that basic IMP can already
provide state-of-the-art pruning results on par with or even outperforming more
complex or heavily parameterized approaches and also to establish a more
realistic yet easily realisable baseline for future research.</p>
  </details>
</details>
<details>
  <summary>50. <b>标题：Statistical quantification of confounding bias in predictive modelling</b></summary>
  <p><b>编号</b>：[111]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00814</p>
  <p><b>作者</b>：Tamas Spisak</p>
  <p><b>备注</b>：20 pages, 7 figures. The manuscript is associated with the the python package `mlconfound`: this https URL See manuscript repository, including fully reproducible analysis code, here: this https URL</p>
  <p><b>关键词</b>：autism brain imaging data exchange dataset reveals confounders, clinically useful machine learning biomarkers, functional brain connectivity data, confounding bias significantly hampers, art confound mitigation approaches</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The lack of non-parametric statistical tests for confounding bias
significantly hampers the development of robust, valid and generalizable
predictive models in many fields of research. Here I propose the partial and
full confounder tests, which, for a given confounder variable, probe the null
hypotheses of unconfounded and fully confounded models, respectively. The tests
provide a strict control for Type I errors and high statistical power, even for
non-normally and non-linearly dependent predictions, often seen in machine
learning. Applying the proposed tests on models trained on functional brain
connectivity data from the Human Connectome Project and the Autism Brain
Imaging Data Exchange dataset reveals confounders that were previously
unreported or found to be hard to correct for with state-of-the-art confound
mitigation approaches. The tests, implemented in the package mlconfound
(this https URL), can aid the assessment and improvement of
the generalizability and neurobiological validity of predictive models and,
thereby, foster the development of clinically useful machine learning
biomarkers.</p>
  </details>
</details>
<details>
  <summary>51. <b>标题：Decentralized Cooperative Reinforcement Learning with Hierarchical  Information Structure</b></summary>
  <p><b>编号</b>：[122]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00781</p>
  <p><b>作者</b>：Hsu Kao,  Chen-Yu Wei,  Vijay Subramanian</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：existing methods often require high level, obtain $\ widetilde {\ mathcal, $\ widetilde {\ mathcal, hierarchical information structure arising, existing lower bound</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Multi-agent reinforcement learning (MARL) problems are challenging due to
information asymmetry. To overcome this challenge, existing methods often
require high level of coordination or communication between the agents. We
consider two-agent multi-armed bandits (MABs) and Markov decision processes
(MDPs) with a hierarchical information structure arising in applications, which
we exploit to propose simpler and more efficient algorithms that require no
coordination or communication. In the structure, in each step the ``leader"
chooses her action first, and then the ``follower" decides his action after
observing the leader's action. The two agents observe the same reward (and the
same state transition in the MDP setting) that depends on their joint action.
For the bandit setting, we propose a hierarchical bandit algorithm that
achieves a near-optimal gap-independent regret of
$\widetilde{\mathcal{O}}(\sqrt{ABT})$ and a near-optimal gap-dependent regret
of $\mathcal{O}(\log(T))$, where $A$ and $B$ are the numbers of actions of the
leader and the follower, respectively, and $T$ is the number of steps. We
further extend to the case of multiple followers and the case with a deep
hierarchy, where we both obtain near-optimal regret bounds. For the MDP
setting, we obtain $\widetilde{\mathcal{O}}(\sqrt{H^7S^2ABT})$ regret, where
$H$ is the number of steps per episode, $S$ is the number of states, $T$ is the
number of episodes. This matches the existing lower bound in terms of $A, B$,
and $T$.</p>
  </details>
</details>
<details>
  <summary>52. <b>标题：Pseudo-Spherical Contrastive Divergence</b></summary>
  <p><b>编号</b>：[123]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00780</p>
  <p><b>作者</b>：Lantao Yu,  Jiaming Song,  Yang Song,  Stefano Ermon</p>
  <p><b>备注</b>：NeurIPS 2021</p>
  <p><b>关键词</b>：train ebms without additional computational cost, strictly proper homogeneous scoring rules, commonly used image datasets demonstrate, typically trained via contrastive divergence, flexibly choose various learning objectives</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Energy-based models (EBMs) offer flexible distribution parametrization.
However, due to the intractable partition function, they are typically trained
via contrastive divergence for maximum likelihood estimation. In this paper, we
propose pseudo-spherical contrastive divergence (PS-CD) to generalize maximum
likelihood learning of EBMs. PS-CD is derived from the maximization of a family
of strictly proper homogeneous scoring rules, which avoids the computation of
the intractable partition function and provides a generalized family of
learning objectives that include contrastive divergence as a special case.
Moreover, PS-CD allows us to flexibly choose various learning objectives to
train EBMs without additional computational cost or variational minimax
optimization. Theoretical analysis on the proposed method and extensive
experiments on both synthetic data and commonly used image datasets demonstrate
the effectiveness and modeling flexibility of PS-CD, as well as its robustness
to data contamination, thus showing its superiority over maximum likelihood and
$f$-EBMs.</p>
  </details>
</details>
<details>
  <summary>53. <b>标题：Validate on Sim, Detect on Real -- Model Selection for Domain  Randomization</b></summary>
  <p><b>编号</b>：[130]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00765</p>
  <p><b>作者</b>：Gal Leibovich,  Guy Jacob,  Shadi Endrawis,  Gal Novik,  Aviv Tamar</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：policy ranking without requiring additional real world data, uses significantly less data compared, method achieves significantly better ranking, vsdr improves policy selection across, extensively evaluate different dr parameters</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A practical approach to learning robot skills, often termed sim2real, is to
train control policies in simulation and then deploy them on a real robot.
Popular techniques to improve the sim2real transfer build on domain
randomization (DR): Training the policy on a diverse set of randomly generated
domains with the hope of better generalization to the real world. Due to the
large number of hyper-parameters in both the policy learning and DR algorithms,
one often ends up with a large number of trained models, where choosing the
best model among them demands costly evaluation on the real robot. In this work
we ask: Can we rank the policies without running them in the real world? Our
main idea is that a predefined set of real world data can be used to evaluate
all policies, using out-of-distribution detection (OOD) techniques. In a sense,
this approach can be seen as a "unit test" to evaluate policies before any real
world execution. However, we find that by itself, the OOD score can be
inaccurate and very sensitive to the particular OOD method. Our main
contribution is a simple-yet-effective policy score that combines OOD with an
evaluation in simulation. We show that our score - VSDR - can significantly
improve the accuracy of policy ranking without requiring additional real world
data. We evaluate the effectiveness of VSDR on sim2real transfer in a robotic
grasping task with image inputs. We extensively evaluate different DR
parameters and OOD methods, and show that VSDR improves policy selection across
the board. More importantly, our method achieves significantly better ranking,
and uses significantly less data compared to baselines.</p>
  </details>
</details>
<details>
  <summary>54. <b>标题：Single-Item Fashion Recommender: Towards Cross-Domain Recommendations</b></summary>
  <p><b>编号</b>：[133]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00758</p>
  <p><b>作者</b>：Seyed Omid Mohammadi,  Hossein Bodaghi,  Ahmad Kalhor (University of Tehran, College of Engineering, School of Electrical and Computer Engineering, Tehran, Iran)</p>
  <p><b>备注</b>：16 Pages, 14 Figures, 2 Tables</p>
  <p><b>关键词</b>：single fashion item shop image, recommendation tasks called objective, many challenges lie ahead, listing similar items available, based fashion recommender system</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Nowadays, recommender systems and search engines play an integral role in
fashion e-commerce. Still, many challenges lie ahead, and this study tries to
tackle some. This article first suggests a content-based fashion recommender
system that uses a parallel neural network to take a single fashion item shop
image as input and make in-shop recommendations by listing similar items
available in the store. Next, the same structure is enhanced to personalize the
results based on user preferences. This work then introduces a background
augmentation technique that makes the system more robust to out-of-domain
queries, enabling it to make street-to-shop recommendations using only a
training set of catalog shop images. Moreover, the last contribution of this
paper is a new evaluation metric for recommendation tasks called
objective-guided human score. This method is an entirely customizable framework
that produces interpretable, comparable scores from subjective evaluations of
human scorers.</p>
  </details>
</details>
<details>
  <summary>55. <b>标题：Towards the Generalization of Contrastive Self-Supervised Learning</b></summary>
  <p><b>编号</b>：[138]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00743</p>
  <p><b>作者</b>：Weiran Huang,  Mingyang Yi,  Xuyang Zhao</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：attracted great attention since, two canonical contrastive self, trained models generalize, requires unlabeled data, embeds input data</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recently, self-supervised learning has attracted great attention since it
only requires unlabeled data for training. Contrastive learning is a popular
approach for self-supervised learning and empirically performs well in
practice. However, the theoretical understanding of its generalization ability
on downstream tasks is not well studied. To this end, we present a theoretical
explanation of how contrastive self-supervised pre-trained models generalize to
downstream tasks. Concretely, we quantitatively show that the self-supervised
model has generalization ability on downstream classification tasks if it
embeds input data into a feature space with distinguishing centers of classes
and closely clustered intra-class samples. With the above conclusion, we
further explore SimCLR and Barlow Twins, which are two canonical contrastive
self-supervised methods. We prove that the aforementioned feature space can be
obtained via any of the methods, and thus explain their success on the
generalization on downstream classification tasks. Finally, various experiments
are also conducted to verify our theoretical findings.</p>
  </details>
</details>
<details>
  <summary>56. <b>标题：Calibrating Explore-Exploit Trade-off for Fair Online Learning to Rank</b></summary>
  <p><b>编号</b>：[140]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00735</p>
  <p><b>作者</b>：Yiling Jia,  Hongning Wang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：g ., intentionally present selected results, existing fair ranking solutions usually require, items might receive differential treatments, offline supervised ranking model learning, existing fair ol2r solutions</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Online learning to rank (OL2R) has attracted great research interests in
recent years, thanks to its advantages in avoiding expensive relevance labeling
as required in offline supervised ranking model learning. Such a solution
explores the unknowns (e.g., intentionally present selected results on top
positions) to improve its relevance estimation. This however triggers concerns
on its ranking fairness: different groups of items might receive differential
treatments during the course of OL2R. But existing fair ranking solutions
usually require the knowledge of result relevance or a performing ranker
beforehand, which contradicts with the setting of OL2R and thus cannot be
directly applied to guarantee fairness.
In this work, we propose a general framework to achieve fairness defined by
group exposure in OL2R. The key idea is to calibrate exploration and
exploitation for fairness control, relevance learning and online ranking
quality. In particular, when the model is exploring a set of results for
relevance feedback, we confine the exploration within a subset of random
permutations, where fairness across groups is maintained while the feedback is
still unbiased. Theoretically we prove such a strategy introduces minimum
distortion in OL2R's regret to obtain fairness. Extensive empirical analysis is
performed on two public learning to rank benchmark datasets to demonstrate the
effectiveness of the proposed solution compared to existing fair OL2R
solutions.</p>
  </details>
</details>
<details>
  <summary>57. <b>标题：Robust Deep Learning from Crowds with Belief Propagation</b></summary>
  <p><b>编号</b>：[141]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00734</p>
  <p><b>作者</b>：Hoyoung Kim,  Seunghyuk Cho,  Dongwoo Kim,  Jungseul Ok</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：em framework alternating variational inference, graphical model representing local dependencies, crowdsourcing systems enable us, based em algorithm, predictive model working</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Crowdsourcing systems enable us to collect noisy labels from crowd workers. A
graphical model representing local dependencies between workers and tasks
provides a principled way of reasoning over the true labels from the noisy
answers. However, one needs a predictive model working on unseen data directly
from crowdsourced datasets instead of the true labels in many cases. To infer
true labels and learn a predictive model simultaneously, we propose a new
data-generating process, where a neural network generates the true labels from
task features. We devise an EM framework alternating variational inference and
deep learning to infer the true labels and to update the neural network,
respectively. Experimental results with synthetic and real datasets show a
belief-propagation-based EM algorithm is robust to i) corruption in task
features, ii) multi-modal or mismatched worker prior, and iii) few spammers
submitting noises to many tasks.</p>
  </details>
</details>
<details>
  <summary>58. <b>标题：Adaptive Multi-receptive Field Spatial-Temporal Graph Convolutional  Network for Traffic Forecasting</b></summary>
  <p><b>编号</b>：[144]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00724</p>
  <p><b>作者</b>：Xing Wang (1),  Juan Zhao (1),  Lin Zhu (1),  Xu Zhou (2),  Zhao Li (2),  Junlan Feng (1),  Chao Deng (1),  Yong Zhang (2) ((1) China Mobile Research Institute, Beijing, China, (2) Electronic Engineering, Beijing University of Posts and Telecommunications, Beijing, China)</p>
  <p><b>备注</b>：To be published in IEEE GLOBECOM</p>
  <p><b>关键词</b>：intrinsic features make mobile network traffic forecasting far, two different domains consistently show amf, novel deep learning network architecture, mobile network traffic forecasting, fully connected deep network</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Mobile network traffic forecasting is one of the key functions in daily
network operation. A commercial mobile network is large, heterogeneous, complex
and dynamic. These intrinsic features make mobile network traffic forecasting
far from being solved even with recent advanced algorithms such as graph
convolutional network-based prediction approaches and various attention
mechanisms, which have been proved successful in vehicle traffic forecasting.
In this paper, we cast the problem as a spatial-temporal sequence prediction
task. We propose a novel deep learning network architecture, Adaptive
Multi-receptive Field Spatial-Temporal Graph Convolutional Networks
(AMF-STGCN), to model the traffic dynamics of mobile base stations. AMF-STGCN
extends GCN by (1) jointly modeling the complex spatial-temporal dependencies
in mobile networks, (2) applying attention mechanisms to capture various
Receptive Fields of heterogeneous base stations, and (3) introducing an extra
decoder based on a fully connected deep network to conquer the error
propagation challenge with multi-step forecasting. Experiments on four
real-world datasets from two different domains consistently show AMF-STGCN
outperforms the state-of-the-art methods.</p>
  </details>
</details>
<details>
  <summary>59. <b>标题：Edge-Level Explanations for Graph Neural Networks by Extending  Explainability Methods for Convolutional Neural Networks</b></summary>
  <p><b>编号</b>：[145]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00722</p>
  <p><b>作者</b>：Tetsu Kasanishi,  Xueting Wang,  Toshihiko Yamasaki</p>
  <p><b>备注</b>：4 pages, accepted at 23rd IEEE International Symposium on Multimedia (ISM), short paper, 2021</p>
  <p><b>关键词</b>：weighted class activation mapping, take graph data, graph neural networks, experimental results indicate, deep learning models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Graph Neural Networks (GNNs) are deep learning models that take graph data as
inputs, and they are applied to various tasks such as traffic prediction and
molecular property prediction. However, owing to the complexity of the GNNs, it
has been difficult to analyze which parts of inputs affect the GNN model's
outputs. In this study, we extend explainability methods for Convolutional
Neural Networks (CNNs), such as Local Interpretable Model-Agnostic Explanations
(LIME), Gradient-Based Saliency Maps, and Gradient-Weighted Class Activation
Mapping (Grad-CAM) to GNNs, and predict which edges in the input graphs are
important for GNN decisions. The experimental results indicate that the
LIME-based approach is the most efficient explainability method for multiple
tasks in the real-world situation, outperforming even the state-of-the-art
method in GNN explainability.</p>
  </details>
</details>
<details>
  <summary>60. <b>标题：Communication-Compressed Adaptive Gradient Method for Distributed  Nonconvex Optimization</b></summary>
  <p><b>编号</b>：[150]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00705</p>
  <p><b>作者</b>：Yujia Wang,  Lu Lin,  Jinghui Chen</p>
  <p><b>备注</b>：34 pages, 10 figures</p>
  <p><b>关键词</b>：efficient distributed adaptive gradient method converges, proposed distributed learning framework features, efficient adaptive gradient methods, distributed nonconvex optimization problem, side model update design</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Due to the explosion in the size of the training datasets, distributed
learning has received growing interest in recent years. One of the major
bottlenecks is the large communication cost between the central server and the
local workers. While error feedback compression has been proven to be
successful in reducing communication costs with stochastic gradient descent
(SGD), there are much fewer attempts in building communication-efficient
adaptive gradient methods with provable guarantees, which are widely used in
training large-scale machine learning models. In this paper, we propose a new
communication-compressed AMSGrad for distributed nonconvex optimization
problem, which is provably efficient. Our proposed distributed learning
framework features an effective gradient compression strategy and a worker-side
model update design. We prove that the proposed communication-efficient
distributed adaptive gradient method converges to the first-order stationary
point with the same iteration complexity as uncompressed vanilla AMSGrad in the
stochastic nonconvex optimization setting. Experiments on various benchmarks
back up our theory.</p>
  </details>
</details>
<details>
  <summary>61. <b>标题：Comparative Study of Long Document Classification</b></summary>
  <p><b>编号</b>：[153]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00702</p>
  <p><b>作者</b>：Vedangi Wagh,  Snehal Khandve,  Isha Joshi,  Apurva Wani,  Geetanjali Kale,  Raviraj Joshi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：revisit long document classification using standard machine learning approaches, six standard text classification datasets, even basic algorithms perform competitively, based models perform consistently well, different data sets thus making</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The amount of information stored in the form of documents on the internet has
been increasing rapidly. Thus it has become a necessity to organize and
maintain these documents in an optimum manner. Text classification algorithms
study the complex relationships between words in a text and try to interpret
the semantics of the document. These algorithms have evolved significantly in
the past few years. There has been a lot of progress from simple machine
learning algorithms to transformer-based architectures. However, existing
literature has analyzed different approaches on different data sets thus making
it difficult to compare the performance of machine learning algorithms. In this
work, we revisit long document classification using standard machine learning
approaches. We benchmark approaches ranging from simple Naive Bayes to complex
BERT on six standard text classification datasets. We present an exhaustive
comparison of different algorithms on a range of long document datasets. We
re-iterate that long document classification is a simpler task and even basic
algorithms perform competitively with BERT-based approaches on most of the
datasets. The BERT-based models perform consistently well on all the datasets
and can be blindly used for the document classification task when the
computations cost is not a concern. In the shallow model's category, we suggest
the usage of raw BiLSTM + Max architecture which performs decently across all
the datasets. Even simpler Glove + Attention bag of words model can be utilized
for simpler use cases. The importance of using sophisticated models is clearly
visible in the IMDB sentiment dataset which is a comparatively harder task.</p>
  </details>
</details>
<details>
  <summary>62. <b>标题：RMNet: Equivalently Removing Residual Connection from Networks</b></summary>
  <p><b>编号</b>：[158]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00687</p>
  <p><b>作者</b>：Fanxu Meng,  Hao Cheng,  Jiaxin Zhuang,  Ke Li,  Xing Sun</p>
  <p><b>备注</b>：Equivalently removing residual connection from ResBlock with non-linear layer inside it, towards an efficient plain model</p>
  <p><b>关键词</b>：rm operation allows input feature maps, designing dnns without residual connections, remove residual connections without changing, although residual connection enables training, high ratio network pruning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Although residual connection enables training very deep neural networks, it
is not friendly for online inference due to its multi-branch topology. This
encourages many researchers to work on designing DNNs without residual
connections at inference. For example, RepVGG re-parameterizes multi-branch
topology to a VGG-like (single-branch) model when deploying, showing great
performance when the network is relatively shallow. However, RepVGG can not
transform ResNet to VGG equivalently because re-parameterizing methods can only
be applied to linear blocks and the non-linear layers (ReLU) have to be put
outside of the residual connection which results in limited representation
ability, especially for deeper networks. In this paper, we aim to remedy this
problem and propose to remove the residual connection in a vanilla ResNet
equivalently by a reserving and merging (RM) operation on ResBlock.
Specifically, the RM operation allows input feature maps to pass through the
block while reserving their information and merges all the information at the
end of each block, which can remove residual connections without changing the
original output. As a plug-in method, RM Operation basically has three
advantages: 1) its implementation makes it naturally friendly for high ratio
network pruning. 2) it helps break the depth limitation of RepVGG. 3) it leads
to better accuracy-speed trade-off network (RMNet) compared to ResNet and
RepVGG. We believe the ideology of RM Operation can inspire many insights on
model design for the community in the future. Code is available at:
this https URL.</p>
  </details>
</details>
<details>
  <summary>63. <b>标题：Graph Structural Attack by Spectral Distanc</b></summary>
  <p><b>编号</b>：[159]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00684</p>
  <p><b>作者</b>：Lu Lin,  Ethan Blaser,  Hongning Wang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：experiments demonstrate remarkable effectiveness, disrupt graph spectral filters, effective graph structural attack, graph learning tasks, graph convolutional networks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Graph Convolutional Networks (GCNs) have fueled a surge of interest due to
their superior performance on graph learning tasks, but are also shown
vulnerability to adversarial attacks. In this paper, an effective graph
structural attack is investigated to disrupt graph spectral filters in the
Fourier domain. We define the spectral distance based on the eigenvalues of
graph Laplacian to measure the disruption of spectral filters. We then generate
edge perturbations by simultaneously maximizing a task-specific attack
objective and the proposed spectral distance. The experiments demonstrate
remarkable effectiveness of the proposed attack in the white-box setting at
both training and test time. Our qualitative analysis shows the connection
between the attack behavior and the imposed changes on the spectral
distribution, which provides empirical evidence that maximizing spectral
distance is an effective manner to change the structural property of graphs in
the spatial domain and perturb the frequency components in the Fourier domain.</p>
  </details>
</details>
<details>
  <summary>64. <b>标题：GCNear: A Hybrid Architecture for Efficient GCN Training with  Near-Memory Processing</b></summary>
  <p><b>编号</b>：[160]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00680</p>
  <p><b>作者</b>：Zhe Zhou,  Cong Li,  Xuechao Wei,  Guangyu Sun</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：complex training dataflow jointly increase, large graphs even requires hundreds, heterogeneous nature challenges current cpu, high aggregated local bandwidth, propose several optimization strategies</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recently, Graph Convolutional Networks (GCNs) have become state-of-the-art
algorithms for analyzing non-euclidean graph data. However, it is challenging
to realize efficient GCN training, especially on large graphs. The reasons are
many-folded: 1) GCN training incurs a substantial memory footprint. Full-batch
training on large graphs even requires hundreds to thousands of gigabytes of
memory to buffer the intermediate data for back-propagation. 2) GCN training
involves both memory-intensive data reduction and computation-intensive
features/gradients update operations. Such a heterogeneous nature challenges
current CPU/GPU platforms. 3) The irregularity of graphs and the complex
training dataflow jointly increase the difficulty of improving a GCN training
system's efficiency.
This paper presents GCNear, a hybrid architecture to tackle these challenges.
Specifically, GCNear adopts a DIMM-based memory system to provide easy-to-scale
memory capacity. To match the heterogeneous nature, we categorize GCN training
operations as memory-intensive Reduce and computation-intensive Update
operations. We then offload Reduce operations to on-DIMM NMEs, making full use
of the high aggregated local bandwidth. We adopt a CAE with sufficient
computation capacity to process Update operations. We further propose several
optimization strategies to deal with the irregularity of GCN tasks and improve
GCNear's performance. We also propose a Multi-GCNear system to evaluate the
scalability of GCNear.</p>
  </details>
</details>
<details>
  <summary>65. <b>标题：Latent Structures Mining with Contrastive Modality Fusion for Multimedia  Recommendation</b></summary>
  <p><b>编号</b>：[161]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00678</p>
  <p><b>作者</b>：Jinghao Zhang,  Yanqiao Zhu,  Qiang Liu,  Mengqi Zhang,  Shu Wu,  Liang Wang</p>
  <p><b>备注</b>：12 pages; in submission to IEEE TKDE. arXiv admin note: substantial text overlap with arXiv:2104.09036</p>
  <p><b>关键词</b>：multiple modalities might allow us, comprehensively discover candidate items, aware structure learning module, fully understand content information, existing collaborative filtering methods</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent years have witnessed growing interests in multimedia recommendation,
which aims to predict whether a user will interact with an item with multimodal
contents. Previous studies focus on modeling user-item interactions with
multimodal features included as side information. However, this scheme is not
well-designed for multimedia recommendation. Firstly, only collaborative
item-item relationships are implicitly modeled through high-order
item-user-item co-occurrences. We argue that the latent semantic item-item
structures underlying these multimodal contents could be beneficial for
learning better item representations and assist the recommender models to
comprehensively discover candidate items. Secondly, previous studies disregard
the fine-grained multimodal fusion. Although having access to multiple
modalities might allow us to capture rich information, we argue that the simple
coarse-grained fusion by linear combination or concatenation in previous work
is insufficient to fully understand content information and item
this http URL this end, we propose a latent structure MIning with
ContRastive mOdality fusion method (MICRO for brevity). To be specific, we
devise a novel modality-aware structure learning module, which learns item-item
relationships for each modality. Based on the learned modality-aware latent
item relationships, we perform graph convolutions that explicitly inject item
affinities to modality-aware item representations. Then, we design a novel
contrastive method to fuse multimodal features. These enriched item
representations can be plugged into existing collaborative filtering methods to
make more accurate recommendations. Extensive experiments on real-world
datasets demonstrate the superiority of our method over state-of-the-art
baselines.</p>
  </details>
</details>
<details>
  <summary>66. <b>标题：RMNA: A Neighbor Aggregation-Based Knowledge Graph Representation  Learning Model Using Rule Mining</b></summary>
  <p><b>编号</b>：[171]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00658</p>
  <p><b>作者</b>：Ling Chen,  Jun Cui,  Xing Tang,  Chaodu Song,  Yuntao Qian,  Yansheng Li,  Yongjun Zhang</p>
  <p><b>备注</b>：22 pages, 2 figures</p>
  <p><b>关键词</b>：uses selected horn rules, art traditional representation learning, existing narl models either, narl model named rmna, models show competitive performance</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Although the state-of-the-art traditional representation learning (TRL)
models show competitive performance on knowledge graph completion, there is no
parameter sharing between the embeddings of entities, and the connections
between entities are weak. Therefore, neighbor aggregation-based representation
learning (NARL) models are proposed, which encode the information in the
neighbors of an entity into its embeddings. However, existing NARL models
either only utilize one-hop neighbors, ignoring the information in multi-hop
neighbors, or utilize multi-hop neighbors by hierarchical neighbor aggregation,
destroying the completeness of multi-hop neighbors. In this paper, we propose a
NARL model named RMNA, which obtains and filters horn rules through a rule
mining algorithm, and uses selected horn rules to transform valuable multi-hop
neighbors into one-hop neighbors, therefore, the information in valuable
multi-hop neighbors can be completely utilized by aggregating these one-hop
neighbors. In experiments, we compare RMNA with the state-of-the-art TRL models
and NARL models. The results show that RMNA has a competitive performance.</p>
  </details>
</details>
<details>
  <summary>67. <b>标题：Collage: Automated Integration of Deep Learning Backends</b></summary>
  <p><b>编号</b>：[173]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00655</p>
  <p><b>作者</b>：Byungsoo Jeon,  Sunghyun Park,  Peiyuan Liao,  Sheng Xu,  Tianqi Chen,  Zhihao Jia</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：collage automatically integrates multiple backends together without manual intervention, current dl frameworks require significant manual effort, two different nvidia gpus, outperforms existing frameworks, integrating dl backends</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Strong demands for efficient deployment of Deep Learning (DL) applications
prompt the rapid development of a rich DL ecosystem. To keep up with its fast
advancement, it is crucial for DL frameworks to efficiently integrate a variety
of optimized libraries and runtimes as their backends and generate the fastest
possible executable by using them properly. However, current DL frameworks
require significant manual effort to integrate diverse backends and often fail
to deliver high performance. In this paper, we propose Collage, an automatic
framework for integrating DL backends. Collage provides a backend registration
interface that allows users to precisely specify the capability of various
backends. By leveraging the specifications of available backends, Collage
searches for an optimized backend placement for a given workload and execution
environment. Our evaluation shows that Collage automatically integrates
multiple backends together without manual intervention, and outperforms
existing frameworks by 1.21x, 1.39x, 1.40x on two different NVIDIA GPUs and an
Intel CPU respectively.</p>
  </details>
</details>
<details>
  <summary>68. <b>标题：To Talk or to Work: Delay Efficient Federated Learning over Mobile Edge  Devices</b></summary>
  <p><b>编号</b>：[179]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00637</p>
  <p><b>作者</b>：Pavana Prakash,  Jiahao Ding,  Maoqiang Wu,  Minglei Shu,  Rong Yu,  Miao Pan</p>
  <p><b>备注</b>：Accepted for publication in Globecom'21</p>
  <p><b>关键词</b>：unreliable network connections may obstruct, emerging distributed machine learning paradigm, create local model updates along, since mobile devices collaborate, mobile edge devices</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Federated learning (FL), an emerging distributed machine learning paradigm,
in conflux with edge computing is a promising area with novel applications over
mobile edge devices. In FL, since mobile devices collaborate to train a model
based on their own data under the coordination of a central server by sharing
just the model updates, training data is maintained private. However, without
the central availability of data, computing nodes need to communicate the model
updates often to attain convergence. Hence, the local computation time to
create local model updates along with the time taken for transmitting them to
and from the server result in a delay in the overall time. Furthermore,
unreliable network connections may obstruct an efficient communication of these
updates. To address these, in this paper, we propose a delay-efficient FL
mechanism that reduces the overall time (consisting of both the computation and
communication latencies) and communication rounds required for the model to
converge. Exploring the impact of various parameters contributing to delay, we
seek to balance the trade-off between wireless communication (to talk) and
local computation (to work). We formulate a relation with overall time as an
optimization problem and demonstrate the efficacy of our approach through
extensive simulations.</p>
  </details>
</details>
<details>
  <summary>69. <b>标题：Settling the Horizon-Dependence of Sample Complexity in Reinforcement  Learning</b></summary>
  <p><b>编号</b>：[180]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00633</p>
  <p><b>作者</b>：Yuanzhi Li,  Ruosong Wang,  Lin F. Yang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：1 )$- optimal policy using $\ mathrm, polylog }( h )$ episodes, polylog }( h )$ dependence, h $, previous work, horizon markov decision processes</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recently there is a surge of interest in understanding the horizon-dependence
of the sample complexity in reinforcement learning (RL). Notably, for an RL
environment with horizon length $H$, previous work have shown that there is a
probably approximately correct (PAC) algorithm that learns an $O(1)$-optimal
policy using $\mathrm{polylog}(H)$ episodes of environment interactions when
the number of states and actions is fixed. It is yet unknown whether the
$\mathrm{polylog}(H)$ dependence is necessary or not. In this work, we resolve
this question by developing an algorithm that achieves the same PAC guarantee
while using only $O(1)$ episodes of environment interactions, completely
settling the horizon-dependence of the sample complexity in RL. We achieve this
bound by (i) establishing a connection between value functions in discounted
and finite-horizon Markov decision processes (MDPs) and (ii) a novel
perturbation analysis in MDPs. We believe our new techniques are of independent
interest and could be applied in related questions in RL.</p>
  </details>
</details>
<details>
  <summary>70. <b>标题：Safe Learning of Linear Time-Invariant Systems</b></summary>
  <p><b>编号</b>：[181]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00631</p>
  <p><b>作者</b>：Farhad Farokhi,  Alex S. Leong,  Mohammad Zamani,  Iman Shames</p>
  <p><b>备注</b>：Accepted in NeurIPS 2021 Workshop on Safe and Robust Control of Uncertain Systems</p>
  <p><b>关键词</b>：provide rigorous confidence bounds, constrained optimization exists, time linear time, tightening becomes negligible, modify control inputs</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We consider safety in simultaneous learning and control of discrete-time
linear time-invariant systems. We provide rigorous confidence bounds on the
learned model of the system based on the number of utilized state measurements.
These bounds are used to modify control inputs to the system via an
optimization problem with potentially time-varying safety constraints. We prove
that the state can only exit the safe set with small probability, provided a
feasible solution to the safety-constrained optimization exists. This
optimization problem is then reformulated in a more computationally-friendly
format by tightening the safety constraints to account for model uncertainty
during learning. The tightening decreases as the confidence in the learned
model improves. We finally prove that, under persistence of excitation, the
tightening becomes negligible as more measurements are gathered.</p>
  </details>
</details>
<details>
  <summary>71. <b>标题：Distantly Supervised Semantic Text Detection and Recognition for  Broadcast Sports Videos Understanding</b></summary>
  <p><b>编号</b>：[182]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00629</p>
  <p><b>作者</b>：Avijit Shah,  Topojoy Biswas,  Sathish Ramadoss,  Deven Santosh Shah</p>
  <p><b>备注</b>：9 pages, 7 figures and 6 tables. To be published in the proceedings of ACM Multimedia 21, Industrial Track, held from October 20-24 in China</p>
  <p><b>关键词</b>：study extremely accurate semantic text detection, extract extremely accurate semantic text, video frames still remains one, automatically build sports clock datasets, novel distant supervision technique</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Comprehensive understanding of key players and actions in multiplayer sports
broadcast videos is a challenging problem. Unlike in news or finance videos,
sports videos have limited text. While both action recognition for multiplayer
sports and detection of players has seen robust research, understanding
contextual text in video frames still remains one of the most impactful avenues
of sports video understanding. In this work we study extremely accurate
semantic text detection and recognition in sports clocks, and challenges
therein. We observe unique properties of sports clocks, which makes it hard to
utilize general-purpose pre-trained detectors and recognizers, so that text can
be accurately understood to the degree of being used to align to external
knowledge. We propose a novel distant supervision technique to automatically
build sports clock datasets. Along with suitable data augmentations, combined
with any state-of-the-art text detection and recognition model architectures,
we extract extremely accurate semantic text. Finally, we share our
computational architecture pipeline to scale this system in industrial setting
and proposed a robust dataset for the same to validate our results.</p>
  </details>
</details>
<details>
  <summary>72. <b>标题：Intrusion Detection using Spatial-Temporal features based on Riemannian  Manifold</b></summary>
  <p><b>编号</b>：[183]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00626</p>
  <p><b>作者</b>：Amardeep Singh,  Julian Jang-Jaccard</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：new novel feature extraction method based, often requires high computational cost, detecting malicious network traffic behavior, using hybrid classification techniques, detecting malicious network traffic</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Network traffic data is a combination of different data bytes packets under
different network protocols. These traffic packets have complex time-varying
non-linear relationships. Existing state-of-the-art methods rise up to this
challenge by fusing features into multiple subsets based on correlations and
using hybrid classification techniques that extract spatial and temporal
characteristics. This often requires high computational cost and manual support
that limit them for real-time processing of network traffic. To address this,
we propose a new novel feature extraction method based on covariance matrices
that extract spatial-temporal characteristics of network traffic data for
detecting malicious network traffic behavior. The covariance matrices in our
proposed method not just naturally encode the mutual relationships between
different network traffic values but also have well-defined geometry that falls
in the Riemannian manifold. Riemannian manifold is embedded with distance
metrics that facilitate extracting discriminative features for detecting
malicious network traffic. We evaluated our model on NSL-KDD and UNSW-NB15
datasets and showed our proposed method significantly outperforms the
conventional method and other existing studies on the dataset.</p>
  </details>
</details>
<details>
  <summary>73. <b>标题：Deep Recursive Embedding for High-Dimensional Data</b></summary>
  <p><b>编号</b>：[184]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00622</p>
  <p><b>作者</b>：Zixia Zhou,  Xinrui Zu,  Yuanyuan Wang,  Boudewijn P.F. Lelieveldt,  Qian Tao</p>
  <p><b>备注</b>：arXiv admin note: substantial text overlap with arXiv:2104.05171</p>
  <p><b>关键词</b>：public datasets demonstrated improved embedding performance, combine deep neural networks, generic deep embedding network, distributed stochastic neighbor embedding, called deep recursive embedding</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Embedding high-dimensional data onto a low-dimensional manifold is of both
theoretical and practical value. In this paper, we propose to combine deep
neural networks (DNN) with mathematics-guided embedding rules for
high-dimensional data embedding. We introduce a generic deep embedding network
(DEN) framework, which is able to learn a parametric mapping from
high-dimensional space to low-dimensional space, guided by well-established
objectives such as Kullback-Leibler (KL) divergence minimization. We further
propose a recursive strategy, called deep recursive embedding (DRE), to make
use of the latent data representations for boosted embedding performance. We
exemplify the flexibility of DRE by different architectures and loss functions,
and benchmarked our method against the two most popular embedding methods,
namely, t-distributed stochastic neighbor embedding (t-SNE) and uniform
manifold approximation and projection (UMAP). The proposed DRE method can map
out-of-sample data and scale to extremely large datasets. Experiments on a
range of public datasets demonstrated improved embedding performance in terms
of local and global structure preservation, compared with other
state-of-the-art embedding methods.</p>
  </details>
</details>
<details>
  <summary>74. <b>标题：PIE: Pseudo-Invertible Encoder</b></summary>
  <p><b>编号</b>：[186]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00619</p>
  <p><b>作者</b>：Jan Jetze Beitler,  Ivan Sosnovik,  Arnold Smeulders</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：evaluate gaussian pseudo invertible encoder, call pseudo invertible encoders, pseudo bijective architecture, model outperforms wae, introduce new class</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We consider the problem of information compression from high dimensional
data. Where many studies consider the problem of compression by non-invertible
transformations, we emphasize the importance of invertible compression. We
introduce new class of likelihood-based autoencoders with pseudo bijective
architecture, which we call Pseudo Invertible Encoders. We provide the
theoretical explanation of their principles. We evaluate Gaussian Pseudo
Invertible Encoder on MNIST, where our model outperforms WAE and VAE in
sharpness of the generated images.</p>
  </details>
</details>
<details>
  <summary>75. <b>标题：Towards Language Modelling in the Speech Domain Using Sub-word  Linguistic Units</b></summary>
  <p><b>编号</b>：[189]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00610</p>
  <p><b>作者</b>：Anurag Katakkar,  Alan W Black</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：traditional text language modelling metrics like perplexity, offers better acoustic consistency across utterances, traditional speech lms often depending, model closely approximates babbling speech, based generative speech lm</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Language models (LMs) for text data have been studied extensively for their
usefulness in language generation and other downstream tasks. However, language
modelling purely in the speech domain is still a relatively unexplored topic,
with traditional speech LMs often depending on auxiliary text LMs for learning
distributional aspects of the language. For the English language, these LMs
treat words as atomic units, which presents inherent challenges to language
modelling in the speech domain. In this paper, we propose a novel LSTM-based
generative speech LM that is inspired by the CBOW model and built on linguistic
units including syllables and phonemes. This offers better acoustic consistency
across utterances in the dataset, as opposed to single melspectrogram frames,
or whole words. With a limited dataset, orders of magnitude smaller than that
required by contemporary generative models, our model closely approximates
babbling speech. We show the effect of training with auxiliary text LMs,
multitask learning objectives, and auxiliary articulatory features. Through our
experiments, we also highlight some well known, but poorly documented
challenges in training generative speech LMs, including the mismatch between
the supervised learning objective with which these models are trained such as
Mean Squared Error (MSE), and the true objective, which is speech quality. Our
experiments provide an early indication that while validation loss and Mel
Cepstral Distortion (MCD) are not strongly correlated with generated speech
quality, traditional text language modelling metrics like perplexity and
next-token-prediction accuracy might be.</p>
  </details>
</details>
<details>
  <summary>76. <b>标题：Explainable Artificial Intelligence for Smart City Application: A Secure  and Trusted Platform</b></summary>
  <p><b>编号</b>：[196]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00601</p>
  <p><b>作者</b>：M. Humayn Kabir,  Khondokar Fida Hasan,  Mohammad Kamrul Hasan,  Keyvan Ansari</p>
  <p><b>备注</b>：Book_Chapter, Springer Nature</p>
  <p><b>关键词</b>：g ., deep learning, applying different autonomous systems, protecting critical cyber infrastructure, major smart city solutions, seemingly unpredictable outputs</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Artificial Intelligence (AI) is one of the disruptive technologies that is
shaping the future. It has growing applications for data-driven decisions in
major smart city solutions, including transportation, education, healthcare,
public governance, and power systems. At the same time, it is gaining
popularity in protecting critical cyber infrastructure from cyber threats,
attacks, damages, or unauthorized access. However, one of the significant
issues of those traditional AI technologies (e.g., deep learning) is that the
rapid progress in complexity and sophistication propelled and turned out to be
uninterpretable black boxes. On many occasions, it is very challenging to
understand the decision and bias to control and trust systems' unexpected or
seemingly unpredictable outputs. It is acknowledged that the loss of control
over interpretability of decision-making becomes a critical issue for many
data-driven automated applications. But how may it affect the system's security
and trustworthiness? This chapter conducts a comprehensive study of machine
learning applications in cybersecurity to indicate the need for explainability
to address this question. While doing that, this chapter first discusses the
black-box problems of AI technologies for Cybersecurity applications in smart
city-based solutions. Later, considering the new technological paradigm,
Explainable Artificial Intelligence (XAI), this chapter discusses the
transition from black-box to white-box. This chapter also discusses the
transition requirements concerning the interpretability, transparency,
understandability, and Explainability of AI-based technologies in applying
different autonomous systems in smart cities. Finally, it has presented some
commercial XAI platforms that offer explainability over traditional AI
technologies before presenting future challenges and opportunities.</p>
  </details>
</details>
<details>
  <summary>77. <b>标题：Bayesian optimization of distributed neurodynamical controller models  for spatial navigation</b></summary>
  <p><b>编号</b>：[198]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00599</p>
  <p><b>作者</b>：Armin Hadzic,  Grace M. Hwang,  Kechen Zhang,  Kevin M. Schultz,  Joseph D. Monaco</p>
  <p><b>备注</b>：29 pages, 10 figures</p>
  <p><b>关键词</b>：generalized task performance across environments, operate within hippocampal place, demonstrated advances toward resilient, capture spatially distributed rewards, study conventional swarm models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Dynamical systems models for controlling multi-agent swarms have demonstrated
advances toward resilient, decentralized navigation algorithms. We previously
introduced the NeuroSwarms controller, in which agent-based interactions were
modeled by analogy to neuronal network interactions, including attractor
dynamics and phase synchrony, that have been theorized to operate within
hippocampal place-cell circuits in navigating rodents. This complexity
precludes linear analyses of stability, controllability, and performance
typically used to study conventional swarm models. Further, tuning dynamical
controllers by hand or grid search is often inadequate due to the complexity of
objectives, dimensionality of model parameters, and computational costs of
simulation-based sampling. Here, we present a framework for tuning dynamical
controller models of autonomous multi-agent systems based on Bayesian
Optimization (BayesOpt). Our approach utilizes a task-dependent objective
function to train Gaussian Processes (GPs) as surrogate models to achieve
adaptive and efficient exploration of a dynamical controller model's parameter
space. We demonstrate this approach by studying an objective function selecting
for NeuroSwarms behaviors that cooperatively localize and capture spatially
distributed rewards under time pressure. We generalized task performance across
environments by combining scores for simulations in distinct geometries. To
validate search performance, we compared high-dimensional clustering for high-
vs. low-likelihood parameter points by visualizing sample trajectories in
Uniform Manifold Approximation and Projection (UMAP) embeddings. Our findings
show that adaptive, sample-efficient evaluation of the self-organizing
behavioral capacities of complex systems, including dynamical swarm
controllers, can accelerate the translation of neuroscientific theory to
applied domains.</p>
  </details>
</details>
<details>
  <summary>78. <b>标题：Unsupervised Learning to Subphenotype Delirium Patients from Electronic  Health Records</b></summary>
  <p><b>编号</b>：[201]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00592</p>
  <p><b>作者</b>：Yiqing Zhao,  Yuan Luo</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：work could recalibrate existing delirium prediction models, detect delirium using medical information mart, common acute onset brain dysfunction, highly heterogeneous medical conditions, underlying medical condition</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Delirium is a common acute onset brain dysfunction in the emergency setting
and is associated with higher mortality. It is difficult to detect and monitor
since its presentations and risk factors can be different depending on the
underlying medical condition of patients. In our study, we aimed to identify
subtypes within the delirium population and build subgroup-specific predictive
models to detect delirium using Medical Information Mart for Intensive Care IV
(MIMIC-IV) data. We showed that clusters exist within the delirium population.
Differences in feature importance were also observed for subgroup-specific
predictive models. Our work could recalibrate existing delirium prediction
models for each delirium subgroup and improve the precision of delirium
detection and monitoring for ICU or emergency department patients who had
highly heterogeneous medical conditions.</p>
  </details>
</details>
<details>
  <summary>79. <b>标题：A Tensor SVD-based Classification Algorithm Applied to fMRI Data</b></summary>
  <p><b>编号</b>：[204]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00587</p>
  <p><b>作者</b>：Katherine Keegan,  Tanvi Vishwanath,  Yihua Xu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：facilitate efficient multidimensional feature extraction, matrix singular value decomposition, best possible equivalent matrix, based classification algorithm using, vectorization causes us</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>To analyze the abundance of multidimensional data, tensor-based frameworks
have been developed. Traditionally, the matrix singular value decomposition
(SVD) is used to extract the most dominant features from a matrix containing
the vectorized data. While the SVD is highly useful for data that can be
appropriately represented as a matrix, this step of vectorization causes us to
lose the high-dimensional relationships intrinsic to the data. To facilitate
efficient multidimensional feature extraction, we utilize a projection-based
classification algorithm using the t-SVDM, a tensor analog of the matrix SVD.
Our work extends the t-SVDM framework and the classification algorithm, both
initially proposed for tensors of order 3, to any number of dimensions. We then
apply this algorithm to a classification task using the StarPlus fMRI dataset.
Our numerical experiments demonstrate that there exists a superior tensor-based
approach to fMRI classification than the best possible equivalent matrix-based
approach. Our results illustrate the advantages of our chosen tensor framework,
provide insight into beneficial choices of parameters, and could be further
developed for classification of more complex imaging data. We provide our
Python implementation at this https URL.</p>
  </details>
</details>
<details>
  <summary>80. <b>标题：Text Classification for Task-based Source Code Related Questions</b></summary>
  <p><b>编号</b>：[207]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00580</p>
  <p><b>作者</b>：Sairamvinay Vijayaraghavan,  Jinxiao Song,  David Tomassi,  Siddhartha Punj,  Jailan Sabet</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：simple binary neural network classifier model, using hidden state context vectors, fold deep learning model, embeddings perform slightly better, hidden state layer</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>There is a key demand to automatically generate code for small tasks for
developers. Websites such as StackOverflow provide a simplistic way by offering
solutions in small snippets which provide a complete answer to whatever task
question the developer wants to code. Natural Language Processing and
particularly Question-Answering Systems are very helpful in resolving and
working on these tasks. In this paper, we develop a two-fold deep learning
model: Seq2Seq and a binary classifier that takes in the intent (which is in
natural language) and code snippets in Python. We train both the intent and the
code utterances in the Seq2Seq model, where we decided to compare the effect of
the hidden layer embedding from the encoder for representing the intent and
similarly, using the decoder's hidden layer embeddings for the code sequence.
Then we combine both these embeddings and then train a simple binary neural
network classifier model for predicting if the intent is correctly answered by
the predicted code sequence from the seq2seq model. We find that the hidden
state layer's embeddings perform slightly better than regular standard
embeddings from a constructed vocabulary. We experimented with our tests on the
CoNaLa dataset in addition to the StaQC database consisting of simple task-code
snippet-based pairs. We empirically establish that using additional pre-trained
embeddings for code snippets in Python is less context-based in comparison to
using hidden state context vectors from seq2seq models.</p>
  </details>
</details>
<details>
  <summary>81. <b>标题：Can we learn gradients by Hamiltonian Neural Networks?</b></summary>
  <p><b>编号</b>：[211]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00565</p>
  <p><b>作者</b>：Aleksandr Timofeev,  Andrei Afonin,  Yehao Liu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：simplest hamiltonian neural network, ode neural networks, classic optimization methods, automatic inductive bias, achieves comparable results</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this work, we propose a meta-learner based on ODE neural networks that
learns gradients. This approach makes the optimizer is more flexible inducing
an automatic inductive bias to the given task. Using the simplest Hamiltonian
Neural Network we demonstrate that our method outperforms a meta-learner based
on LSTM for an artificial task and the MNIST dataset with ReLU activations in
the optimizee. Furthermore, it also surpasses the classic optimization methods
for the artificial task and achieves comparable results for MNIST.</p>
  </details>
</details>
<details>
  <summary>82. <b>标题：Revealing and Protecting Labels in Distributed Training</b></summary>
  <p><b>编号</b>：[214]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00556</p>
  <p><b>作者</b>：Trung Dang,  Om Thakkar,  Swaroop Ramaswamy,  Rajiv Mathews,  Peter Chin,  Françoise Beaufays</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：federated learning often involve transmission, model architectures across multiple domains, g ., resnet ),, existing reconstruction techniques improve, thereby avoiding transmission</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Distributed learning paradigms such as federated learning often involve
transmission of model updates, or gradients, over a network, thereby avoiding
transmission of private data. However, it is possible for sensitive information
about the training data to be revealed from such gradients. Prior works have
demonstrated that labels can be revealed analytically from the last layer of
certain models (e.g., ResNet), or they can be reconstructed jointly with model
inputs by using Gradients Matching [Zhu et al'19] with additional knowledge
about the current state of the model. In this work, we propose a method to
discover the set of labels of training samples from only the gradient of the
last layer and the id to label mapping. Our method is applicable to a wide
variety of model architectures across multiple domains. We demonstrate the
effectiveness of our method for model training in two domains - image
classification, and automatic speech recognition. Furthermore, we show that
existing reconstruction techniques improve their efficacy when used in
conjunction with our method. Conversely, we demonstrate that gradient
quantization and sparsification can significantly reduce the success of the
attack.</p>
  </details>
</details>
<details>
  <summary>83. <b>标题：Quality Estimation Using Round-trip Translation with Sentence Embeddings</b></summary>
  <p><b>编号</b>：[215]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00554</p>
  <p><b>作者</b>：Nathan Crone,  Adam Power,  John Weldon</p>
  <p><b>备注</b>：10 pages, 5 figures</p>
  <p><b>关键词</b>：previous pitfalls found, many previous attempts, method makes use, language representation learning, trip translated sentences</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Estimating the quality of machine translation systems has been an ongoing
challenge for researchers in this field. Many previous attempts at using
round-trip translation as a measure of quality have failed, and there is much
disagreement as to whether it can be a viable method of quality estimation. In
this paper, we revisit round-trip translation, proposing a system which aims to
solve the previous pitfalls found with the approach. Our method makes use of
recent advances in language representation learning to more accurately gauge
the similarity between the original and round-trip translated sentences.
Experiments show that while our approach does not reach the performance of
current state of the art methods, it may still be an effective approach for
some language pairs.</p>
  </details>
</details>
<details>
  <summary>84. <b>标题：Fast Global Convergence of Policy Optimization for Constrained MDPs</b></summary>
  <p><b>编号</b>：[216]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00552</p>
  <p><b>作者</b>：Tao Liu,  Ruida Zhou,  Dileep Kalathil,  P. R. Kumar,  Chao Tian</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：horizon constrained markov decision process framework, faster convergence rate $\ mathcal, }( 1 /\ sqrt, })$ global convergence rate, natural policy gradient</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We address the issue of safety in reinforcement learning. We pose the problem
in a discounted infinite-horizon constrained Markov decision process framework.
Existing results have shown that gradient-based methods are able to achieve an
$\mathcal{O}(1/\sqrt{T})$ global convergence rate both for the optimality gap
and the constraint violation. We exhibit a natural policy gradient-based
algorithm that has a faster convergence rate $\mathcal{O}(\log(T)/T)$ for both
the optimality gap and the constraint violation. When Slater's condition is
satisfied and known a priori, zero constraint violation can be further
guaranteed for a sufficiently large $T$ while maintaining the same convergence
rate.</p>
  </details>
</details>
<details>
  <summary>85. <b>标题：Learning Debiased and Disentangled Representations for Semantic  Segmentation</b></summary>
  <p><b>编号</b>：[221]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00531</p>
  <p><b>作者</b>：Sanghyeok Chu,  Dongwan Kim,  Bohyung Han</p>
  <p><b>备注</b>：Accepted by NeurIPS 2021</p>
  <p><b>关键词</b>：complex dense prediction problems including semantic segmentation, effectively reduce feature dependencies among classes, randomly eliminating certain class information, multiple semantic segmentation benchmarks, especially notable performance gains</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep neural networks are susceptible to learn biased models with entangled
feature representations, which may lead to subpar performances on various
downstream tasks. This is particularly true for under-represented classes,
where a lack of diversity in the data exacerbates the tendency. This limitation
has been addressed mostly in classification tasks, but there is little study on
additional challenges that may appear in more complex dense prediction problems
including semantic segmentation. To this end, we propose a model-agnostic and
stochastic training scheme for semantic segmentation, which facilitates the
learning of debiased and disentangled representations. For each class, we first
extract class-specific information from the highly entangled feature map. Then,
information related to a randomly sampled class is suppressed by a feature
selection process in the feature space. By randomly eliminating certain class
information in each training iteration, we effectively reduce feature
dependencies among classes, and the model is able to learn more debiased and
disentangled feature representations. Models trained with our approach
demonstrate strong results on multiple semantic segmentation benchmarks, with
especially notable performance gains on under-represented classes.</p>
  </details>
</details>
<details>
  <summary>86. <b>标题：Classification of fetal compromise during labour: signal processing and  feature engineering of the cardiotocograph</b></summary>
  <p><b>编号</b>：[224]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00517</p>
  <p><b>作者</b>：M. O'Sullivan,  T. Gabruseva,  G. Boylan,  M. O'Riordan,  G. Lightbody,  W. Marnane</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：ctg requires dynamic pattern recognition, viable path towards objective, system control theory using, signal quality measure improved, arma features ranked amongst</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Cardiotocography (CTG) is the main tool used for fetal monitoring during
labour. Interpretation of CTG requires dynamic pattern recognition in real
time. It is recognised as a difficult task with high inter- and intra-observer
disagreement. Machine learning has provided a viable path towards objective and
reliable CTG assessment. In this study, novel CTG features are developed based
on clinical expertise and system control theory using an autoregressive
moving-average (ARMA) model to characterise the response of the fetal heart
rate to contractions. The features are evaluated in a machine learning model to
assess their efficacy in identifying fetal compromise. ARMA features ranked
amongst the top features for detecting fetal compromise. Additionally,
including clinical factors in the machine learning model and pruning data based
on a signal quality measure improved the performance of the classifier.</p>
  </details>
</details>
<details>
  <summary>87. <b>标题：Automated Hyperparameter Optimization Challenge at CIKM 2021 AnalyticCup</b></summary>
  <p><b>编号</b>：[226]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00513</p>
  <p><b>作者</b>：Huaijun Jiang,  Yu Shen,  Yang Li</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：competition organizers provide anonymized realistic industrial tasks, acm cikm 2021 analyticcup track 2 )., qq browser 2021 ai algorithm competiton, heuristic early stopping strategy, automated hyperparameter optimization challenge</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we describe our method for tackling the automated
hyperparameter optimization challenge in QQ Browser 2021 AI Algorithm
Competiton (ACM CIKM 2021 AnalyticCup Track 2). The competition organizers
provide anonymized realistic industrial tasks and datasets for black-box
optimization. Based on our open-sourced package OpenBox, we adopt the Bayesian
optimization framework for configuration sampling and a heuristic early
stopping strategy. We won first place in both the preliminary and final
contests with the results of 0.938291 and 0.918753, respectively.</p>
  </details>
</details>
<details>
  <summary>88. <b>标题：Smart(Sampling)Augment: Optimal and Efficient Data Augmentation for  Semantic Segmentation</b></summary>
  <p><b>编号</b>：[238]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00487</p>
  <p><b>作者</b>：Misgana Negassi,  Diane Wagner,  Alexander Reiterer</p>
  <p><b>备注</b>：Negassi and Wagner provided an equal contribution</p>
  <p><b>关键词</b>：data augmentation methods enrich datasets, fixed augmentation strategy competes, automated data augmentation methods, smartaugment uses bayesian optimization, design choices behind smartaugment</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Data augmentation methods enrich datasets with augmented data to improve the
performance of neural networks. Recently, automated data augmentation methods
have emerged, which automatically design augmentation strategies. Existing work
focuses on image classification and object detection, whereas we provide the
first study on semantic image segmentation and introduce two new approaches:
\textit{SmartAugment} and \textit{SmartSamplingAugment}. SmartAugment uses
Bayesian Optimization to search over a rich space of augmentation strategies
and achieves a new state-of-the-art performance in all semantic segmentation
tasks we consider. SmartSamplingAugment, a simple parameter-free approach with
a fixed augmentation strategy competes in performance with the existing
resource-intensive approaches and outperforms cheap state-of-the-art data
augmentation methods. Further, we analyze the impact, interaction, and
importance of data augmentation hyperparameters and perform ablation studies,
which confirm our design choices behind SmartAugment and SmartSamplingAugment.
Lastly, we will provide our source code for reproducibility and to facilitate
further research.</p>
  </details>
</details>
<details>
  <summary>89. <b>标题：Efficient, Anytime Algorithms for Calibration with Isotonic Regression  under Strictly Convex Losses</b></summary>
  <p><b>编号</b>：[244]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00468</p>
  <p><b>作者</b>：Kaan Gokcesu,  Hakan Gokcesu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：general strictly convex loss functions, traditional square error setting, specific loss settings, single staircase transform, optimal monotone transform</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We investigate the calibration of estimations to increase performance with an
optimal monotone transform on the estimator outputs. We start by studying the
traditional square error setting with its weighted variant and show that the
optimal monotone transform is in the form of a unique staircase function. We
further show that this staircase behavior is preserved for general strictly
convex loss functions. Their optimal monotone transforms are also unique, i.e.,
there exist a single staircase transform that achieves the minimum loss. We
propose a linear time and space algorithm that can find such optimal transforms
for specific loss settings. Our algorithm has an online implementation where
the optimal transform for the samples observed so far are found in linear space
and amortized time when the samples arrive in an ordered fashion. We also
extend our results to cases where the functions are not trivial to individually
optimize and propose an anytime algorithm, which has linear space and
pseudo-linearithmic time complexity.</p>
  </details>
</details>
<details>
  <summary>90. <b>标题：DAdaQuant: Doubly-adaptive quantization for communication-efficient  Federated Learning</b></summary>
  <p><b>编号</b>：[246]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00465</p>
  <p><b>作者</b>：Robert Hönig,  Yiren Zhao,  Robert Mullins</p>
  <p><b>备注</b>：10 pages, 5 figures, submitted to ICLR 2022</p>
  <p><b>关键词</b>：dadaquant consistently improves client $\ rightarrow, boost compression without sacrificing model quality, fl incurs significant communication costs, efficiently compress fl communication, recently proposed algorithms quantize</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Federated Learning (FL) is a powerful technique for training a model on a
server with data from several clients in a privacy-preserving manner. In FL, a
server sends the model to every client, who then train the model locally and
send it back to the server. The server aggregates the updated models and
repeats the process for several rounds. FL incurs significant communication
costs, in particular when transmitting the updated local models from the
clients back to the server. Recently proposed algorithms quantize the model
parameters to efficiently compress FL communication. These algorithms typically
have a quantization level that controls the compression factor. We find that
dynamic adaptations of the quantization level can boost compression without
sacrificing model quality. First, we introduce a time-adaptive quantization
algorithm that increases the quantization level as training progresses. Second,
we introduce a client-adaptive quantization algorithm that assigns each
individual client the optimal quantization level at every round. Finally, we
combine both algorithms into DAdaQuant, the doubly-adaptive quantization
algorithm. Our experiments show that DAdaQuant consistently improves
client$\rightarrow$server compression, outperforming the strongest non-adaptive
baselines by up to $2.8\times$.</p>
  </details>
</details>
<details>
  <summary>91. <b>标题：FastCover: An Unsupervised Learning Framework for Multi-Hop Influence  Maximization in Social Networks</b></summary>
  <p><b>编号</b>：[247]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00463</p>
  <p><b>作者</b>：Runbo Ni,  Xueyan Li,  Fangqi Li,  Xiaofeng Gao,  Guihai Chen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：many possible useful applications, diffusion process among neighbors, world social networks demonstrate, novel graph neural network, graph reversed attention network</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Finding influential users in social networks is a fundamental problem with
many possible useful applications. Viewing the social network as a graph, the
influence of a set of users can be measured by the number of neighbors located
within a given number of hops in the network, where each hop marks a step of
influence diffusion. In this paper, we reduce the problem of IM to a
budget-constrained d-hop dominating set problem (kdDSP). We propose a unified
machine learning (ML) framework, FastCover, to solve kdDSP by learning an
efficient greedy strategy in an unsupervised way. As one critical component of
the framework, we devise a novel graph neural network (GNN) architecture, graph
reversed attention network (GRAT), that captures the diffusion process among
neighbors. Unlike most heuristic algorithms and concurrent ML frameworks for
combinatorial optimization problems, FastCover determines the entire seed set
from the nodes' scores computed with only one forward propagation of the GNN
and has a time complexity quasi-linear in the graph size. Experiments on
synthetic graphs and real-world social networks demonstrate that FastCover
finds solutions with better or comparable quality rendered by the concurrent
algorithms while achieving a speedup of over 1000x.</p>
  </details>
</details>
<details>
  <summary>92. <b>标题：Graph Neural Network based scheduling : Improved throughput under a  generalized interference model</b></summary>
  <p><b>编号</b>：[249]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00459</p>
  <p><b>作者</b>：S. Ramakrishnan,  Jaswanthi Mandalapu,  Subrahmanya Swamy Peruru,  Bhavesh Jain,  Eitan Altman</p>
  <p><b>备注</b>：10 pages, Accepted at EAI VALUETOOLS 2021 - 14th EAI International Conference on Performance Evaluation Methodologies and Tools</p>
  <p><b>关键词</b>：k $- tolerant conflict graph model, significantly ($ 4 $-$ 20, generalized interference model called, require labelled data set, extensive numerical experiments illustrate</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this work, we propose a Graph Convolutional Neural Networks (GCN) based
scheduling algorithm for adhoc networks. In particular, we consider a
generalized interference model called the $k$-tolerant conflict graph model and
design an efficient approximation for the well-known Max-Weight scheduling
algorithm. A notable feature of this work is that the proposed method do not
require labelled data set (NP-hard to compute) for training the neural network.
Instead, we design a loss function that utilises the existing greedy approaches
and trains a GCN that improves the performance of greedy approaches. Our
extensive numerical experiments illustrate that using our GCN approach, we can
significantly ($4$-$20$ percent) improve the performance of the conventional
greedy approach.</p>
  </details>
</details>
<details>
  <summary>93. <b>标题：Decentralized Multi-Agent Reinforcement Learning: An Off-Policy Method</b></summary>
  <p><b>编号</b>：[254]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00438</p>
  <p><b>作者</b>：Kuo Li,  Qing-Shan Jia</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：space markov decision process, agents make individual decisions, g ., q, data efficiency compared, higher accumulated reward</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We discuss the problem of decentralized multi-agent reinforcement learning
(MARL) in this work. In our setting, the global state, action, and reward are
assumed to be fully observable, while the local policy is protected as privacy
by each agent, and thus cannot be shared with others. There is a communication
graph, among which the agents can exchange information with their neighbors.
The agents make individual decisions and cooperate to reach a higher
accumulated reward.
Towards this end, we first propose a decentralized actor-critic (AC) setting.
Then, the policy evaluation and policy improvement algorithms are designed for
discrete and continuous state-action-space Markov Decision Process (MDP)
respectively. Furthermore, convergence analysis is given under the
discrete-space case, which guarantees that the policy will be reinforced by
alternating between the processes of policy evaluation and policy improvement.
In order to validate the effectiveness of algorithms, we design experiments and
compare them with previous algorithms, e.g., Q-learning \cite{watkins1992q} and
MADDPG \cite{lowe2017multi}. The results show that our algorithms perform
better from the aspects of both learning speed and final performance. Moreover,
the algorithms can be executed in an off-policy manner, which greatly improves
the data efficiency compared with on-policy algorithms.</p>
  </details>
</details>
<details>
  <summary>94. <b>标题：An Actor-Critic Method for Simulation-Based Optimization</b></summary>
  <p><b>编号</b>：[256]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00435</p>
  <p><b>作者</b>：Kuo Li,  Qing-Shan Jia,  Jiaqi Yan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：e ., adversarial attack task, existing works commonly optimize, internal processing rule cannot, including two toy examples, based optimization problem</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We focus on a simulation-based optimization problem of choosing the best
design from the feasible space. Although the simulation model can be queried
with finite samples, its internal processing rule cannot be utilized in the
optimization process. We formulate the sampling process as a policy searching
problem and give a solution from the perspective of Reinforcement Learning
(RL). Concretely, Actor-Critic (AC) framework is applied, where the Actor
serves as a surrogate model to predict the performance on unknown designs,
whereas the actor encodes the sampling policy to be optimized. We design the
updating rule and propose two algorithms for the cases where the feasible
spaces are continuous and discrete respectively. Some experiments are designed
to validate the effectiveness of proposed algorithms, including two toy
examples, which intuitively explain the algorithms, and two more complex tasks,
i.e., adversarial attack task and RL task, which validate the effectiveness in
large-scale problems. The results show that the proposed algorithms can
successfully deal with these problems. Especially note that in the RL task, our
methods give a new perspective to robot control by treating the task as a
simulation model and solving it by optimizing the policy generating process,
while existing works commonly optimize the policy itself directly.</p>
  </details>
</details>
<details>
  <summary>95. <b>标题：Efficient passive membership inference attack in federated learning</b></summary>
  <p><b>编号</b>：[258]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00430</p>
  <p><b>作者</b>：Oualid Zari,  Chuan Xu,  Giovanni Neglia</p>
  <p><b>备注</b>：Accepted as a poster in NeurIPS 2021 PriML workshop</p>
  <p><b>关键词</b>：requires much less computation power, global machine learning model, passive membership inference attack, new passive inference attack, magnitude less memory space</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In cross-device federated learning (FL) setting, clients such as mobiles
cooperate with the server to train a global machine learning model, while
maintaining their data locally. However, recent work shows that client's
private information can still be disclosed to an adversary who just eavesdrops
the messages exchanged between the client and the server. For example, the
adversary can infer whether the client owns a specific data instance, which is
called a passive membership inference attack. In this paper, we propose a new
passive inference attack that requires much less computation power and memory
than existing methods. Our empirical results show that our attack achieves a
higher accuracy on CIFAR100 dataset (more than $4$ percentage points) with
three orders of magnitude less memory space and five orders of magnitude less
calculations.</p>
  </details>
</details>
<details>
  <summary>96. <b>标题：Using Google Trends as a proxy for occupant behavior to predict building  energy consumption</b></summary>
  <p><b>编号</b>：[260]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00426</p>
  <p><b>作者</b>：Chun Fu,  Clayton Miller</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：ashrae great energy predictor iii, highly correlated google trends data, top five winning teams, advanced machine learning algorithms, building energy prediction research</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In recent years, the availability of larger amounts of energy data and
advanced machine learning algorithms has created a surge in building energy
prediction research. However, one of the variables in energy prediction models,
occupant behavior, is crucial for prediction performance but hard-to-measure or
time-consuming to collect from each building. This study proposes an approach
that utilizes the search volume of topics (e.g., education} or Microsoft Excel)
on the Google Trends platform as a proxy of occupant behavior and use of
buildings. Linear correlations were first examined to explore the relationship
between energy meter data and Google Trends search terms to infer building
occupancy. Prediction errors before and after the inclusion of the trends of
these terms were compared and analyzed based on the ASHRAE Great Energy
Predictor III (GEPIII) competition dataset. The results show that highly
correlated Google Trends data can effectively reduce the overall RMSLE error
for a subset of the buildings to the level of the GEPIII competition's top five
winning teams' performance. In particular, the RMSLE error reduction during
public holidays and days with site-specific schedules are respectively reduced
by 20-30% and 2-5%. These results show the potential of using Google Trends to
improve energy prediction for a portion of the building stock by automatically
identifying site-specific and holiday schedules.</p>
  </details>
</details>
<details>
  <summary>97. <b>标题：Deep Learning in Human Activity Recognition with Wearable Sensors: A  Review on Advances</b></summary>
  <p><b>编号</b>：[264]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00418</p>
  <p><b>作者</b>：Shibo Zhang,  Yaxuan Li,  Shen Zhang,  Farzad Shahabi,  Stephen Xia,  Yu Deng,  Nabil Alshurafa</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：deep learning -- based har, introduces deep learning methods, perform human activity recognition, including activity tracking, summarizes existing work</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Mobile and wearable devices have enabled numerous applications, including
activity tracking, wellness monitoring, and human-computer interaction, that
measure and improve our daily lives. Many of these applications are made
possible by leveraging the rich collection of low-power sensors found in many
mobile and wearable devices to perform human activity recognition (HAR).
Recently, deep learning has greatly pushed the boundaries of HAR on mobile and
wearable devices. This paper systematically categorizes and summarizes existing
work that introduces deep learning methods for wearables-based HAR and provides
a comprehensive analysis of the current advancements, developing trends, and
major challenges. We also present cutting-edge frontiers and future directions
for deep learning--based HAR.</p>
  </details>
</details>
<details>
  <summary>98. <b>标题：Safe Adaptive Learning-based Control for Constrained Linear Quadratic  Regulators with Regret Guarantees</b></summary>
  <p><b>编号</b>：[267]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00411</p>
  <p><b>作者</b>：Yingying Li,  Subhro Das,  Jeff Shamma,  Na Li</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：quadratic cost function subject, (\ cdot )$ absorbs, optimal safe linear controller, unknown linear system, require system restarts</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We study the adaptive control of an unknown linear system with a quadratic
cost function subject to safety constraints on both the states and actions. The
challenges of this problem arise from the tension among safety, exploration,
performance, and computation. To address these challenges, we propose a
polynomial-time algorithm that guarantees feasibility and constraint
satisfaction with high probability under proper conditions. Our algorithm is
implemented on a single trajectory and does not require system restarts.
Further, we analyze the regret of our learning algorithm compared to the
optimal safe linear controller with known model information. The proposed
algorithm can achieve a $\tilde O(T^{2/3})$ regret, where $T$ is the number of
stages and $\tilde O(\cdot)$ absorbs some logarithmic terms of $T$.</p>
  </details>
</details>
<details>
  <summary>99. <b>标题：Efficiently Modeling Long Sequences with Structured State Spaces</b></summary>
  <p><b>编号</b>：[276]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00396</p>
  <p><b>作者</b>：Albert Gu,  Karan Goel,  Christopher Ré</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：s4 achieves strong empirical results across, promising recent approach proposed modeling sequences, although conventional models including rnns, technique involves conditioning \(, address sequence data across</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A central goal of sequence modeling is designing a single principled model
that can address sequence data across a range of modalities and tasks,
particularly on long-range dependencies. Although conventional models including
RNNs, CNNs, and Transformers have specialized variants for capturing long
dependencies, they still struggle to scale to very long sequences of $10000$ or
more steps. A promising recent approach proposed modeling sequences by
simulating the fundamental state space model (SSM) \( x'(t) = Ax(t) + Bu(t),
y(t) = Cx(t) + Du(t) \), and showed that for appropriate choices of the state
matrix \( A \), this system could handle long-range dependencies mathematically
and empirically. However, this method has prohibitive computation and memory
requirements, rendering it infeasible as a general sequence modeling solution.
We propose the Structured State Space (S4) sequence model based on a new
parameterization for the SSM, and show that it can be computed much more
efficiently than prior approaches while preserving their theoretical strengths.
Our technique involves conditioning \( A \) with a low-rank correction,
allowing it to be diagonalized stably and reducing the SSM to the well-studied
computation of a Cauchy kernel. S4 achieves strong empirical results across a
diverse range of established benchmarks, including (i) 91\% accuracy on
sequential CIFAR-10 with no data augmentation or auxiliary losses, on par with
a larger 2-D ResNet, (ii) substantially closing the gap to Transformers on
image and language modeling tasks, while performing generation $60\times$
faster (iii) SoTA on every task from the Long Range Arena benchmark, including
solving the challenging Path-X task of length 16k that all prior work fails on,
while being as efficient as all competitors.</p>
  </details>
</details>
<details>
  <summary>100. <b>标题：EfficientWord-Net: An Open Source Hotword Detection Engine based on  One-shot Learning</b></summary>
  <p><b>编号</b>：[280]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00379</p>
  <p><b>作者</b>：Chidhambararajan R,  Aman Rangaur,  Sibi Chakkaravarthy Sethuraman</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：existing systems requires enormous amounts, special phrases also known, voice assistants like siri, time engines whose purpose, hotword detection engine based</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Voice assistants like Siri, Google Assistant, Alexa etc. are used widely
across the globe for home automation, these require the use of special phrases
also known as hotwords to wake it up and perform an action like "Hey Alexa!",
"Ok Google!" and "Hey Siri!" etc. These hotwords are detected with lightweight
real-time engines whose purpose is to detect the hotwords uttered by the user.
This paper presents the design and implementation of a hotword detection engine
based on one-shot learning which detects the hotword uttered by the user in
real-time with just one or few training samples of the hotword. This approach
is efficient when compared to existing implementations because the process of
adding a new hotword in the existing systems requires enormous amounts of
positive and negative training samples and the model needs to retrain for every
hotword. This makes the existing implementations inefficient in terms of
computation and cost. The architecture proposed in this paper has achieved an
accuracy of 94.51%.</p>
  </details>
</details>
<details>
  <summary>101. <b>标题：Sustainable AI: Environmental Implications, Challenges and Opportunities</b></summary>
  <p><b>编号</b>：[283]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00364</p>
  <p><b>作者</b>：Carole-Jean Wu,  Ramya Raghavendra,  Udit Gupta,  Bilge Acun,  Newsha Ardalani,  Kiwan Maeng,  Gloria Chang,  Fiona Aga Behram,  James Huang,  Charles Bai,  Michael Gschwind,  Anurag Gupta,  Myle Ott,  Anastasia Melnikov,  Salvatore Candido,  David Brooks,  Geeta Chauhan,  Benjamin Lee,  Hsien-Hsin S. Lee,  Bugra Akyildiz,  Maximilian Balandat,  Joe Spisak,  Ravi Jain,  Mike Rabbat,  Kim Hazelwood</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：scale machine learning use cases, model development cycle across industry, important development directions across, linear growth trends, overall carbon footprint</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper explores the environmental impact of the super-linear growth
trends for AI from a holistic perspective, spanning Data, Algorithms, and
System Hardware. We characterize the carbon footprint of AI computing by
examining the model development cycle across industry-scale machine learning
use cases and, at the same time, considering the life cycle of system hardware.
Taking a step further, we capture the operational and manufacturing carbon
footprint of AI computing and present an end-to-end analysis for what and how
hardware-software design and at-scale optimization can help reduce the overall
carbon footprint of AI. Based on the industry experience and lessons learned,
we share the key challenges and chart out important development directions
across the many dimensions of AI. We hope the key messages and insights
presented in this paper can inspire the community to advance the field of AI in
an environmentally-responsible manner.</p>
  </details>
</details>
<details>
  <summary>102. <b>标题：A Survey on the Robustness of Feature Importance and Counterfactual  Explanations</b></summary>
  <p><b>编号</b>：[285]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00358</p>
  <p><b>作者</b>：Saumitra Mishra,  Sanghamitra Dutta,  Jason Long,  Daniele Magazzeni</p>
  <p><b>备注</b>：4 pages plus references. Accepted at the workshop on Explainable AI in Finance (XAI-FIN21). Camera-ready version</p>
  <p><b>关键词</b>：extending current robustness analysis approaches, classify different robustness approaches, identify reliable explainability methods, unify existing definitions, relatively lesser effort</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>There exist several methods that aim to address the crucial task of
understanding the behaviour of AI/ML models. Arguably, the most popular among
them are local explanations that focus on investigating model behaviour for
individual instances. Several methods have been proposed for local analysis,
but relatively lesser effort has gone into understanding if the explanations
are robust and accurately reflect the behaviour of underlying models. In this
work, we present a survey of the works that analysed the robustness of two
classes of local explanations (feature importance and counterfactual
explanations) that are popularly used in analysing AI/ML models in finance. The
survey aims to unify existing definitions of robustness, introduces a taxonomy
to classify different robustness approaches, and discusses some interesting
results. Finally, the survey introduces some pointers about extending current
robustness analysis approaches so as to identify reliable explainability
methods.</p>
  </details>
</details>
<details>
  <summary>103. <b>标题：Optimizing Sparse Matrix Multiplications for Graph Neural Networks</b></summary>
  <p><b>编号</b>：[286]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00352</p>
  <p><b>作者</b>：Shenghao Qiu,  You Liang,  Zheng Wang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：right sparse matrix storage format varies across input data, first trained offline using training matrix samples, sparse matrix storage formats affect, suitable sparse matrix storage format, existing deep learning frameworks employ</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Graph neural networks (GNNs) are emerging as a powerful technique for
modeling graph structures. Due to the sparsity of real-world graph data, GNN
performance is limited by extensive sparse matrix multiplication (SpMM)
operations involved in computation. While the right sparse matrix storage
format varies across input data, existing deep learning frameworks employ a
single, static storage format, leaving much room for improvement. This paper
investigates how the choice of sparse matrix storage formats affect the GNN
performance. We observe that choosing a suitable sparse matrix storage format
can significantly improve the GNN training performance, but the right format
depends on the input workloads and can change as the GNN iterates over the
input graph. We then develop a predictive model to dynamically choose a sparse
matrix storage format to be used by a GNN layer based on the input matrices.
Our model is first trained offline using training matrix samples, and the
trained model can be applied to any input matrix and GNN kernels with SpMM
computation. We implement our approach on top of PyTorch and apply it to 5
representative GNN models running on a multi-core CPU using real-life and
synthetic datasets. Experimental results show that our approach gives an
average speedup of 1.17x (up to 3x) for GNN running time.</p>
  </details>
</details>
<details>
  <summary>104. <b>标题：AdvCodeMix: Adversarial Attack on Code-Mixed Data</b></summary>
  <p><b>编号</b>：[287]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00350</p>
  <p><b>作者</b>：Sourya Dipta Das,  Ayan Basak,  Soumil Mandal,  Dipankar Das</p>
  <p><b>备注</b>：Accepted to CODS-COMAD 2022</p>
  <p><b>关键词</b>：various sentiment classification models trained, employing various perturbation strategies, mixed classification models, various perturbation techniques, first generalized framework</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Research on adversarial attacks are becoming widely popular in the recent
years. One of the unexplored areas where prior research is lacking is the
effect of adversarial attacks on code-mixed data. Therefore, in the present
work, we have explained the first generalized framework on text perturbation to
attack code-mixed classification models in a black-box setting. We rely on
various perturbation techniques that preserve the semantic structures of the
sentences and also obscure the attacks from the perception of a human user. The
present methodology leverages the importance of a token to decide where to
attack by employing various perturbation strategies. We test our strategies on
various sentiment classification models trained on Bengali-English and
Hindi-English code-mixed datasets, and reduce their F1-scores by nearly 51 %
and 53 % respectively, which can be further reduced if a larger number of
tokens are perturbed in a given sentence.</p>
  </details>
</details>
<details>
  <summary>105. <b>标题：Continuous Convolutional Neural Networks: Coupled Neural PDE and ODE</b></summary>
  <p><b>编号</b>：[290]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00343</p>
  <p><b>作者</b>：Mansura Habiba,  Barak A. Pearlmutter</p>
  <p><b>备注</b>：Proc. of the International Conference on Electrical, Computer and Energy Technologies (ICECET)</p>
  <p><b>关键词</b>：physical system using ordinary differential equation, partial differential equation systems, ordinary differential equation, partial differential equation, solving physical systems</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent work in deep learning focuses on solving physical systems in the
Ordinary Differential Equation or Partial Differential Equation. This current
work proposed a variant of Convolutional Neural Networks (CNNs) that can learn
the hidden dynamics of a physical system using ordinary differential equation
(ODEs) systems (ODEs) and Partial Differential Equation systems (PDEs). Instead
of considering the physical system such as image, time -series as a system of
multiple layers, this new technique can model a system in the form of
Differential Equation (DEs). The proposed method has been assessed by solving
several steady-state PDEs on irregular domains, including heat equations,
Navier-Stokes equations.</p>
  </details>
</details>
<details>
  <summary>106. <b>标题：Causal Discovery in Linear Structural Causal Models with Deterministic  Relations</b></summary>
  <p><b>编号</b>：[291]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00341</p>
  <p><b>作者</b>：Yuqin Yang,  Mohamed Nafea,  AmirEmad Ghassami,  Negar Kiyavash</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：causal discovery form observational data generated, existing work almost exclusively focus, linear structural causal models, e ., models, underlying causal structure</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Linear structural causal models (SCMs) -- in which each observed variable is
generated by a subset of the other observed variables as well as a subset of
the exogenous sources -- are pervasive in causal inference and casual
discovery. However, for the task of causal discovery, existing work almost
exclusively focus on the submodel where each observed variable is associated
with a distinct source with non-zero variance. This results in the restriction
that no observed variable can deterministically depend on other observed
variables or latent confounders. In this paper, we extend the results on
structure learning by focusing on a subclass of linear SCMs which do not have
this property, i.e., models in which observed variables can be causally
affected by any subset of the sources, and are allowed to be a deterministic
function of other observed variables or latent confounders. This allows for a
more realistic modeling of influence or information propagation in systems. We
focus on the task of causal discovery form observational data generated from a
member of this subclass. We derive a set of necessary and sufficient conditions
for unique identifiability of the causal structure. To the best of our
knowledge, this is the first work that gives identifiability results for causal
discovery under both latent confounding and deterministic relationships.
Further, we propose an algorithm for recovering the underlying causal structure
when the aforementioned conditions are satisfied. We validate our theoretical
results both on synthetic and real datasets.</p>
  </details>
</details>
<details>
  <summary>107. <b>标题：Identifying and mitigating bias in algorithms used to manage patients in  a pandemic</b></summary>
  <p><b>编号</b>：[292]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00340</p>
  <p><b>作者</b>：Yifan Li,  Garrett Yoon,  Mustafa Nasir-Moin,  David Rosenberg,  Sean Neifert,  Douglas Kondziolka,  Eric Karl Oermann</p>
  <p><b>备注</b>：4 pages, 1 tables</p>
  <p><b>关键词</b>：methodological shortcomings including algorithmic bias, 19 clinical decision support systems, auc ), remained unchanged, methods logistic regression models, deploying machine learning models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Numerous COVID-19 clinical decision support systems have been developed.
However many of these systems do not have the merit for validity due to
methodological shortcomings including algorithmic bias. Methods Logistic
regression models were created to predict COVID-19 mortality, ventilator status
and inpatient status using a real-world dataset consisting of four hospitals in
New York City and analyzed for biases against race, gender and age. Simple
thresholding adjustments were applied in the training process to establish more
equitable models. Results Compared to the naively trained models, the
calibrated models showed a 57% decrease in the number of biased trials, while
predictive performance, measured by area under the receiver/operating curve
(AUC), remained unchanged. After calibration, the average sensitivity of the
predictive models increased from 0.527 to 0.955. Conclusion We demonstrate that
naively training and deploying machine learning models on real world data for
predictive analytics of COVID-19 has a high risk of bias. Simple implemented
adjustments or calibrations during model training can lead to substantial and
sustained gains in fairness on subsequent deployment.</p>
  </details>
</details>
<details>
  <summary>108. <b>标题：Neural Network based on Automatic Differentiation Transformation of  Numeric Iterate-to-Fixedpoint</b></summary>
  <p><b>编号</b>：[295]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00326</p>
  <p><b>作者</b>：Mansura Habiba,  Barak A. Pearlmutter</p>
  <p><b>备注</b>：Proc. of the International Conference on Electrical, Computer and Energy Technologies (ICECET)</p>
  <p><b>关键词</b>：`` temporal wormhole '' connections create, `` easy '' input cases, overcoming traditional deep learning models, `` wormhole '' connections, `` difficult '' ones</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This work proposes a Neural Network model that can control its depth using an
iterate-to-fixed-point operator. The architecture starts with a standard
layered Network but with added connections from current later to earlier
layers, along with a gate to make them inactive under most circumstances. These
``temporal wormhole'' connections create a shortcut that allows the Neural
Network to use the information available at deeper layers and re-do earlier
computations with modulated inputs. End-to-end training is accomplished by
using appropriate calculations for a numeric iterate-to-fixed-point operator.
In a typical case, where the ``wormhole'' connections are inactive, this is
inexpensive; but when they are active, the network takes a longer time to
settle down, and the gradient calculation is also more laborious, with an
effect similar to making the network deeper. In contrast to the existing
skip-connection concept, this proposed technique enables information to flow up
and down in the network. Furthermore, the flow of information follows a fashion
that seems analogous to the afferent and efferent flow of information through
layers of processing in the brain. We evaluate models that use this novel
mechanism on different long-term dependency tasks. The results are competitive
with other studies, showing that the proposed model contributes significantly
to overcoming traditional deep learning models' vanishing gradient descent
problem. At the same time, the training time is significantly reduced, as the
``easy'' input cases are processed more quickly than ``difficult'' ones.</p>
  </details>
</details>
<details>
  <summary>109. <b>标题：ECG synthesis with Neural ODE and GAN models</b></summary>
  <p><b>编号</b>：[297]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00314</p>
  <p><b>作者</b>：Mansura Habiba,  Eoin Borphy,  Barak A. Pearlmutter,  Tomas Ward</p>
  <p><b>备注</b>：Proc. of the International Conference on Electrical, Computer and Energy Technologies (ICECET), 9-10 December 2021, Cape Town-South Africa</p>
  <p><b>关键词</b>：generate synthetic continuous medical time series data, several research works already showed, generating continuous medical time series, continuous medical time series generation, continuous medical time series data</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Continuous medical time series data such as ECG is one of the most complex
time series due to its dynamic and high dimensional characteristics. In
addition, due to its sensitive nature, privacy concerns and legal restrictions,
it is often even complex to use actual data for different medical research. As
a result, generating continuous medical time series is a very critical research
area. Several research works already showed that the ability of generative
adversarial networks (GANs) in the case of continuous medical time series
generation is promising. Most medical data generation works, such as ECG
synthesis, are mainly driven by the GAN model and its variation. On the other
hand, Some recent work on Neural Ordinary Differential Equation (Neural ODE)
demonstrates its strength against informative missingness, high dimension as
well as dynamic nature of continuous time series. Instead of considering
continuous-time series as a discrete-time sequence, Neural ODE can train
continuous time series in real-time continuously. In this work, we used Neural
ODE based model to generate synthetic sine waves and synthetic ECG. We
introduced a new technique to design the generative adversarial network with
Neural ODE based Generator and Discriminator. We developed three new models to
synthesise continuous medical data. Different evaluation metrics are then used
to quantitatively assess the quality of generated synthetic data for real-world
applications and data analysis. Another goal of this work is to combine the
strength of GAN and Neural ODE to generate synthetic continuous medical time
series data such as ECG. We also evaluated both the GAN model and the Neural
ODE model to understand the comparative efficiency of models from the GAN and
Neural ODE family in medical data synthesis.</p>
  </details>
</details>
<details>
  <summary>110. <b>标题：Optimizing Binary Symptom Checkers via Approximate Message Passing</b></summary>
  <p><b>编号</b>：[303]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00303</p>
  <p><b>作者</b>：Mohamed Akrout,  Faouzi Bellili,  Amine Mezghani,  Hayet Amdouni</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：generalized vector approximate message passing, ongoing pandemic crisis, data collection process, convex optimization problems, convex optimization problem</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Symptom checkers have been widely adopted as an intelligent e-healthcare
application during the ongoing pandemic crisis. Their performance have been
limited by the fine-grained quality of the collected medical knowledge between
symptom and diseases. While the binarization of the relationships between
symptoms and diseases simplifies the data collection process, it also leads to
non-convex optimization problems during the inference step. In this paper, we
formulate the symptom checking problem as an underdertermined non-convex
optimization problem, thereby justifying the use of the compressive sensing
framework to solve it. We show that the generalized vector approximate message
passing (G-VAMP) algorithm provides the best performance for binary symptom
checkers.</p>
  </details>
</details>
<details>
  <summary>111. <b>标题：Throughput and Latency in the Distributed Q-Learning Random Access mMTC  Networks</b></summary>
  <p><b>编号</b>：[304]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00299</p>
  <p><b>作者</b>：Giovanni Maciel Ferreira Silva,  Taufik Abrao</p>
  <p><b>备注</b>：8 pages</p>
  <p><b>关键词</b>：access network resources sporadically, resources becomes crucial, numerical results indicated, use learning mechanisms, learning method attains</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In mMTC mode, with thousands of devices trying to access network resources
sporadically, the problem of random access (RA) and collisions between devices
that select the same resources becomes crucial. A promising approach to solve
such an RA problem is to use learning mechanisms, especially the Q-learning
algorithm, where the devices learn about the best time-slot periods to transmit
through rewards sent by the central node. In this work, we propose a
distributed packet-based learning method by varying the reward from the central
node that favors devices having a larger number of remaining packets to
transmit. Our numerical results indicated that the proposed distributed
packet-based Q-learning method attains a much better throughput-latency
trade-off than the alternative independent and collaborative techniques in
practical scenarios of interest. In contrast, the number of payload bits of the
packet-based technique is reduced regarding the collaborative Q-learning RA
technique for achieving the same normalized throughput.</p>
  </details>
</details>
<details>
  <summary>112. <b>标题：A fast accurate fine-grain object detection model based on YOLOv4 deep  neural network</b></summary>
  <p><b>编号</b>：[305]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00298</p>
  <p><b>作者</b>：Arunabha M. Roy,  Rikhi Bose,  Jayabrata Bhaduri</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：mean average precision ($ map $) value, various automated agricultural detection processes, two new residual blocks, modified path aggregation network, modified network architecture maximizes</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Early identification and prevention of various plant diseases in commercial
farms and orchards is a key feature of precision agriculture technology. This
paper presents a high-performance real-time fine-grain object detection
framework that addresses several obstacles in plant disease detection that
hinder the performance of traditional methods, such as, dense distribution,
irregular morphology, multi-scale object classes, textural similarity, etc. The
proposed model is built on an improved version of the You Only Look Once
(YOLOv4) algorithm. The modified network architecture maximizes both detection
accuracy and speed by including the DenseNet in the back-bone to optimize
feature transfer and reuse, two new residual blocks in the backbone and neck
enhance feature extraction and reduce computing cost; the Spatial Pyramid
Pooling (SPP) enhances receptive field, and a modified Path Aggregation Network
(PANet) preserves fine-grain localized information and improve feature fusion.
Additionally, the use of the Hard-Swish function as the primary activation
improved the model's accuracy due to better nonlinear feature extraction. The
proposed model is tested in detecting four different diseases in tomato plants
under various challenging environments. The model outperforms the existing
state-of-the-art detection models in detection accuracy and speed. At a
detection rate of 70.19 FPS, the proposed model obtained a precision value of
$90.33 \%$, F1-score of $93.64 \%$, and a mean average precision ($mAP$) value
of $96.29 \%$. Current work provides an effective and efficient method for
detecting different plant diseases in complex scenarios that can be extended to
different fruit and crop detection, generic disease detection, and various
automated agricultural detection processes.</p>
  </details>
</details>
<details>
  <summary>113. <b>标题：Get Fooled for the Right Reason: Improving Adversarial Robustness  through a Teacher-guided Curriculum Learning Approach</b></summary>
  <p><b>编号</b>：[306]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00295</p>
  <p><b>作者</b>：Anindya Sarkar,  Anirban Sarkar,  Sowrya Gali,  Vineeth N Balasubramanian</p>
  <p><b>备注</b>：16 pages, 9 figures, Accepted at NeurIPS 2021, Code at this https URL</p>
  <p><b>关键词</b>：many popular strong adversarial attacks, method achieves significant performance gains, current sota adversarially robust models, adversarially robust models compared, naturally trained models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Current SOTA adversarially robust models are mostly based on adversarial
training (AT) and differ only by some regularizers either at inner maximization
or outer minimization steps. Being repetitive in nature during the inner
maximization step, they take a huge time to train. We propose a non-iterative
method that enforces the following ideas during training. Attribution maps are
more aligned to the actual object in the image for adversarially robust models
compared to naturally trained models. Also, the allowed set of pixels to
perturb an image (that changes model decision) should be restricted to the
object pixels only, which reduces the attack strength by limiting the attack
space. Our method achieves significant performance gains with a little extra
effort (10-20%) over existing AT models and outperforms all other methods in
terms of adversarial as well as natural accuracy. We have performed extensive
experimentation with CIFAR-10, CIFAR-100, and TinyImageNet datasets and
reported results against many popular strong adversarial attacks to prove the
effectiveness of our method.</p>
  </details>
</details>
<details>
  <summary>114. <b>标题：Intrusion Prevention through Optimal Stopping</b></summary>
  <p><b>编号</b>：[308]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00289</p>
  <p><b>作者</b>：Kim Hammar,  Rolf Stadler</p>
  <p><b>备注</b>：Preprint; Submitted to IEEE for review. arXiv admin note: substantial text overlap with arXiv:2106.07160</p>
  <p><b>关键词</b>：study automated intrusion prevention using reinforcement learning, optimal defender policy using dynamic programming, validating policies includes two systems, formulation gives us insight, produce effective defender policies</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We study automated intrusion prevention using reinforcement learning.
Following a novel approach, we formulate the problem of intrusion prevention as
an (optimal) multiple stopping problem. This formulation gives us insight into
the structure of optimal policies, which we show to have threshold properties.
For most practical cases, it is not feasible to obtain an optimal defender
policy using dynamic programming. We therefore develop a reinforcement learning
approach to approximate an optimal policy. Our method for learning and
validating policies includes two systems: a simulation system where defender
policies are incrementally learned and an emulation system where statistics are
produced that drive simulation runs and where learned policies are evaluated.
We show that our approach can produce effective defender policies for a
practical IT infrastructure of limited size. Inspection of the learned policies
confirms that they exhibit threshold properties.</p>
  </details>
</details>
<details>
  <summary>115. <b>标题：Higher-Order Relations Skew Link Prediction in Graphs</b></summary>
  <p><b>编号</b>：[313]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00271</p>
  <p><b>作者</b>：Govind Sharma,  Aditya Challa,  Paarth Gupta,  M. Narasimha Murty</p>
  <p><b>备注</b>：12 pages, 1 table, 5 figures, under review</p>
  <p><b>关键词</b>：similar link prediction algorithms, random graph would, best auc score, adjustment factor allows, link prediction problem</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The problem of link prediction is of active interest. The main approach to
solving the link prediction problem is based on heuristics such as Common
Neighbors (CN) -- more number of common neighbors of a pair of nodes implies a
higher chance of them getting linked. In this article, we investigate this
problem in the presence of higher-order relations. Surprisingly, it is found
that CN works very well, and even better in the presence of higher-order
relations. However, as we prove in the current work, this is due to the
CN-heuristic overestimating its prediction abilities in the presence of
higher-order relations. This statement is proved by considering a theoretical
model for higher-order relations and by showing that AUC scores of CN are
higher than can be achieved from the model. Theoretical justification in simple
cases is also provided. Further, we extend our observations to other similar
link prediction algorithms such as Adamic Adar. Finally, these insights are
used to propose an adjustment factor by taking into conscience that a random
graph would only have a best AUC score of 0.5. This adjustment factor allows
for a better estimation of generalization scores.</p>
  </details>
</details>
<details>
  <summary>116. <b>标题：Learning Coordinated Terrain-Adaptive Locomotion by Imitating a  Centroidal Dynamics Planner</b></summary>
  <p><b>编号</b>：[315]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00262</p>
  <p><b>作者</b>：Philemon Brakel,  Steven Bohez,  Leonard Hasenclever,  Nicolas Heess,  Konstantinos Bousmalis</p>
  <p><b>备注</b>：A shorter version without appendix was submitted to ICRA 2022</p>
  <p><b>关键词</b>：trouble discovering precise coordinated movements, produce coordinated constraint satisfying motions, require carefully tuned shaping rewards, require precise foot placements, learn dynamic reactive controllers</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Dynamic quadruped locomotion over challenging terrains with precise foot
placements is a hard problem for both optimal control methods and Reinforcement
Learning (RL). Non-linear solvers can produce coordinated constraint satisfying
motions, but often take too long to converge for online application. RL methods
can learn dynamic reactive controllers but require carefully tuned shaping
rewards to produce good gaits and can have trouble discovering precise
coordinated movements. Imitation learning circumvents this problem and has been
used with motion capture data to extract quadruped gaits for flat terrains.
However, it would be costly to acquire motion capture data for a very large
variety of terrains with height differences. In this work, we combine the
advantages of trajectory optimization and learning methods and show that
terrain adaptive controllers can be obtained by training policies to imitate
trajectories that have been planned over procedural terrains by a non-linear
solver. We show that the learned policies transfer to unseen terrains and can
be fine-tuned to dynamically traverse challenging terrains that require precise
foot placements and are very hard to solve with standard RL.</p>
  </details>
</details>
<details>
  <summary>117. <b>标题：Love tHy Neighbour: Remeasuring Local Structural Node Similarity in  Hypergraph-Derived Networks</b></summary>
  <p><b>编号</b>：[319]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00256</p>
  <p><b>作者</b>：Govind Sharma,  Paarth Gupta,  M. Narasihma Murty</p>
  <p><b>备注</b>：15 pages, 2 figures, 9 tables, under review</p>
  <p><b>关键词</b>：classifier predicts links much better, thereby providing novel solutions, provide theoretical formulations, order relations cannot, extensions thereof viz</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The problem of node-similarity in networks has motivated a plethora of such
measures between node-pairs, which make use of the underlying graph structure.
However, higher-order relations cannot be losslessly captured by mere graphs
and hence, extensions thereof viz. hypergraphs are used instead. Measuring
proximity between node pairs in such a setting calls for a revision in the
topological measures of similarity, lest the hypergraph structure remains
under-exploited. We, in this work, propose a multitude of hypergraph-oriented
similarity scores between node-pairs, thereby providing novel solutions to the
link prediction problem. As a part of our proposition, we provide theoretical
formulations to extend graph-topology based scores to hypergraphs. We compare
our scores with graph-based scores (over clique-expansions of hypergraphs into
graphs) from the state-of-the-art. Using a combination of the existing
graph-based and the proposed hypergraph-based similarity scores as features for
a classifier predicts links much better than using the former solely.
Experiments on several real-world datasets and both quantitative as well as
qualitative analyses on the same exhibit the superiority of the proposed
similarity scores over the existing ones.</p>
  </details>
</details>
<details>
  <summary>118. <b>标题：Equinox: neural networks in JAX via callable PyTrees and filtered  transformations</b></summary>
  <p><b>编号</b>：[320]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00254</p>
  <p><b>作者</b>：Patrick Kidger,  Cristian Garcia</p>
  <p><b>备注</b>：Accepted at the Differentiable Programming workshop at NeurIPS 2021</p>
  <p><b>关键词</b>：small neural network library showing, two popular python autodifferentiation frameworks, fundamental difference means current libraries, provide two main ideas, transforming (` jit ',</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>JAX and PyTorch are two popular Python autodifferentiation frameworks. JAX is
based around pure functions and functional programming. PyTorch has popularised
the use of an object-oriented (OO) class-based syntax for defining
parameterised functions, such as neural networks. That this seems like a
fundamental difference means current libraries for building parameterised
functions in JAX have either rejected the OO approach entirely (Stax) or have
introduced OO-to-functional transformations, multiple new abstractions, and
been limited in the extent to which they integrate with JAX (Flax, Haiku,
Objax). Either way this OO/functional difference has been a source of tension.
Here, we introduce `Equinox', a small neural network library showing how a
PyTorch-like class-based approach may be admitted without sacrificing JAX-like
functional programming. We provide two main ideas. One: parameterised functions
are themselves represented as `PyTrees', which means that the parameterisation
of a function is transparent to the JAX framework. Two: we filter a PyTree to
isolate just those components that should be treated when transforming (`jit',
`grad' or `vmap'-ing) a higher-order function of a parameterised function --
such as a loss function applied to a model. Overall Equinox resolves the above
tension without introducing any new programmatic abstractions: only PyTrees and
transformations, just as with regular JAX. Equinox is available at
\url{this https URL}.</p>
  </details>
</details>
<details>
  <summary>119. <b>标题：The CAT SET on the MAT: Cross Attention for Set Matching in Bipartite  Hypergraphs</b></summary>
  <p><b>编号</b>：[322]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00243</p>
  <p><b>作者</b>：Govind Sharma,  Swyam Prakash Singh,  V. Susheela Devi,  M. Narasimha Murty</p>
  <p><b>备注</b>：18 pages, 9 figures, under review</p>
  <p><b>关键词</b>：novel neural network architecture called catsetmat, results also elucidate information flow, right ") -- calls, bipartite hyperedge link prediction, multiple bipartite hypergraph datasets</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Usual relations between entities could be captured using graphs; but those of
a higher-order -- more so between two different types of entities (which we
term "left" and "right") -- calls for a "bipartite hypergraph". For example,
given a left set of symptoms and right set of diseases, the relation between a
set subset of symptoms (that a patient experiences at a given point of time)
and a subset of diseases (that he/she might be diagnosed with) could be
well-represented using a bipartite hyperedge. The state-of-the-art in embedding
nodes of a hypergraph is based on learning the self-attention structure between
node-pairs from a hyperedge. In the present work, given a bipartite hypergraph,
we aim at capturing relations between node pairs from the cross-product between
the left and right hyperedges, and term it a "cross-attention" (CAT) based
model. More precisely, we pose "bipartite hyperedge link prediction" as a
set-matching (SETMAT) problem and propose a novel neural network architecture
called CATSETMAT for the same. We perform extensive experiments on multiple
bipartite hypergraph datasets to show the superior performance of CATSETMAT,
which we compare with multiple techniques from the state-of-the-art. Our
results also elucidate information flow in self- and cross-attention scenarios.</p>
  </details>
</details>
<details>
  <summary>120. <b>标题：On Joint Learning for Solving Placement and Routing in Chip Design</b></summary>
  <p><b>编号</b>：[325]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00234</p>
  <p><b>作者</b>：Ruoyu Cheng,  Junchi Yan</p>
  <p><b>备注</b>：accepted for 35th Conference on Neural Information Processing Systems (NeurIPS 2021)</p>
  <p><b>关键词</b>：joint learning approach via reinforcement learning, public chip design benchmarks show, modern chip design flow, gradient based optimization scheme, local node level information</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>For its advantage in GPU acceleration and less dependency on human experts,
machine learning has been an emerging tool for solving the placement and
routing problems, as two critical steps in modern chip design flow. Being still
in its early stage, there are fundamental issues: scalability, reward design,
and end-to-end learning paradigm etc. To achieve end-to-end placement learning,
we first propose a joint learning method termed by DeepPlace for the placement
of macros and standard cells, by the integration of reinforcement learning with
a gradient based optimization scheme. To further bridge the placement with the
subsequent routing task, we also develop a joint learning approach via
reinforcement learning to fulfill both macro placement and routing, which is
called DeepPR. One key design in our (reinforcement) learning paradigm involves
a multi-view embedding model to encode both global graph level and local node
level information of the input macros. Moreover, the random network
distillation is devised to encourage exploration. Experiments on public chip
design benchmarks show that our method can effectively learn from experience
and also provides intermediate placement for the post standard cell placement,
within few hours for training.</p>
  </details>
</details>
<details>
  <summary>121. <b>标题：Two Heads are Better than One: Geometric-Latent Attention for Point  Cloud Classification and Segmentation</b></summary>
  <p><b>编号</b>：[327]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00231</p>
  <p><b>作者</b>：Hanz Cuevas-Velasquez,  Antonio Javier Gallego,  Robert B. Fisher</p>
  <p><b>备注</b>：Accepted in BMVC 2021</p>
  <p><b>关键词</b>：learn better local relationships, overall accuracy using k, local attention layer, simple yet robust, semantically meaningful subsets</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present an innovative two-headed attention layer that combines geometric
and latent features to segment a 3D scene into semantically meaningful subsets.
Each head combines local and global information, using either the geometric or
latent features, of a neighborhood of points and uses this information to learn
better local relationships. This Geometric-Latent attention layer (Ge-Latto) is
combined with a sub-sampling strategy to capture global features. Our method is
invariant to permutation thanks to the use of shared-MLP layers, and it can
also be used with point clouds with varying densities because the local
attention layer does not depend on the neighbor order. Our proposal is simple
yet robust, which allows it to achieve competitive results in the ShapeNetPart
and ModelNet40 datasets, and the state-of-the-art when segmenting the complex
dataset S3DIS, with 69.2% IoU on Area 5, and 89.7% overall accuracy using
K-fold cross-validation on the 6 areas.</p>
  </details>
</details>
<details>
  <summary>122. <b>标题：Approximation properties of Residual Neural Networks for Kolmogorov PDEs</b></summary>
  <p><b>编号</b>：[335]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00215</p>
  <p><b>作者</b>：Jonas Baggenstos,  Diyora Salimova</p>
  <p><b>备注</b>：24 pages, 2 figures</p>
  <p><b>关键词</b>：possibly nonlinear drift coefficients without suffering, deep neural networks without suffering, recent years residual neural networks, kolmogorov partial differential equations, approximation accuracy $\ varepsilon</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In recent years residual neural networks (ResNets) as introduced by [He, K.,
Zhang, X., Ren, S., and Sun, J., Proceedings of the IEEE conference on computer
vision and pattern recognition (2016), 770-778] have become very popular in a
large number of applications, including in image classification and
segmentation. They provide a new perspective in training very deep neural
networks without suffering the vanishing gradient problem. In this article we
show that ResNets are able to approximate solutions of Kolmogorov partial
differential equations (PDEs) with constant diffusion and possibly nonlinear
drift coefficients without suffering the curse of dimensionality, which is to
say the number of parameters of the approximating ResNets grows at most
polynomially in the reciprocal of the approximation accuracy $\varepsilon > 0$
and the dimension of the considered PDE $d\in\mathbb{N}$. We adapt a proof in
[Jentzen, A., Salimova, D., and Welti, T., Commun. Math. Sci. 19, 5 (2021),
1167-1205] - who showed a similar result for feedforward neural networks (FNNs)
- to ResNets. In contrast to FNNs, the Euler-Maruyama approximation structure
of ResNets simplifies the construction of the approximating ResNets
substantially. Moreover, contrary to the above work, in our proof using ResNets
does not require the existence of an FNN (or a ResNet) representing the
identity map, which enlarges the set of applicable activation functions.</p>
  </details>
</details>
<details>
  <summary>123. <b>标题：Adjacency constraint for efficient hierarchical reinforcement learning</b></summary>
  <p><b>编号</b>：[336]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00213</p>
  <p><b>作者</b>：Tianren Zhang,  Shangqi Guo,  Tian Tan,  Xiaolin Hu,  Feng Chen</p>
  <p><b>备注</b>：arXiv admin note: substantial text overlap with arXiv:2006.11485</p>
  <p><b>关键词</b>：continuous control tasks including challenging simulated robot locomotion, k $- step adjacent region, large goal space poses difficulty, deterministic markov decision process, proposed adjacency constraint preserves</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Goal-conditioned Hierarchical Reinforcement Learning (HRL) is a promising
approach for scaling up reinforcement learning (RL) techniques. However, it
often suffers from training inefficiency as the action space of the high-level,
i.e., the goal space, is large. Searching in a large goal space poses
difficulty for both high-level subgoal generation and low-level policy
learning. In this paper, we show that this problem can be effectively
alleviated by restricting the high-level action space from the whole goal space
to a $k$-step adjacent region of the current state using an adjacency
constraint. We theoretically prove that in a deterministic Markov Decision
Process (MDP), the proposed adjacency constraint preserves the optimal
hierarchical policy, while in a stochastic MDP the adjacency constraint induces
a bounded state-value suboptimality determined by the MDP's transition
structure. We further show that this constraint can be practically implemented
by training an adjacency network that can discriminate between adjacent and
non-adjacent subgoals. Experimental results on discrete and continuous control
tasks including challenging simulated robot locomotion and manipulation tasks
show that incorporating the adjacency constraint significantly boosts the
performance of state-of-the-art goal-conditioned HRL approaches.</p>
  </details>
</details>
<details>
  <summary>124. <b>标题：Mastering Atari Games with Limited Data</b></summary>
  <p><b>编号</b>：[337]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00210</p>
  <p><b>作者</b>：Weirui Ye,  Shaohuai Liu,  Thanard Kurutach,  Pieter Abbeel,  Yang Gao</p>
  <p><b>备注</b>：Published at NeurIPS 2021</p>
  <p><b>关键词</b>：consume 500 times less data, based visual rl algorithm built, prominent methods requiring millions, atari game benchmark remains, based rl algorithms</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Reinforcement learning has achieved great success in many applications.
However, sample efficiency remains a key challenge, with prominent methods
requiring millions (or even billions) of environment steps to train. Recently,
there has been significant progress in sample efficient image-based RL
algorithms; however, consistent human-level performance on the Atari game
benchmark remains an elusive goal. We propose a sample efficient model-based
visual RL algorithm built on MuZero, which we name EfficientZero. Our method
achieves 190.4% mean human performance and 116.0% median performance on the
Atari 100k benchmark with only two hours of real-time game experience and
outperforms the state SAC in some tasks on the DMControl 100k benchmark. This
is the first time an algorithm achieves super-human performance on Atari games
with such little data. EfficientZero's performance is also close to DQN's
performance at 200 million frames while we consume 500 times less data.
EfficientZero's low sample complexity and high performance can bring RL closer
to real-world applicability. We implement our algorithm in an
easy-to-understand manner and it is available at
this https URL. We hope it will accelerate the research
of MCTS-based RL algorithms in the wider community.</p>
  </details>
</details>
<details>
  <summary>125. <b>标题：One Step at a Time: Pros and Cons of Multi-Step Meta-Gradient  Reinforcement Learning</b></summary>
  <p><b>编号</b>：[339]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00206</p>
  <p><b>作者</b>：Clément Bonnet,  Paul Caron,  Thomas Barrett,  Ian Davies,  Alexandre Laterre</p>
  <p><b>备注</b>：14 pages, 6 figures, 2 tables</p>
  <p><b>关键词</b>：novel method mixing multiple inner steps, learning process online encourage, multiple learning steps, avoid myopic updates, better learning signal</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Self-tuning algorithms that adapt the learning process online encourage more
effective and robust learning. Among all the methods available, meta-gradients
have emerged as a promising approach. They leverage the differentiability of
the learning rule with respect to some hyper-parameters to adapt them in an
online fashion. Although meta-gradients can be accumulated over multiple
learning steps to avoid myopic updates, this is rarely used in practice. In
this work, we demonstrate that whilst multi-step meta-gradients do provide a
better learning signal in expectation, this comes at the cost of a significant
increase in variance, hindering performance. In the light of this analysis, we
introduce a novel method mixing multiple inner steps that enjoys a more
accurate and robust meta-gradient signal, essentially trading off bias and
variance in meta-gradient estimation. When applied to the Snake game, the
mixing meta-gradient algorithm can cut the variance by a factor of 3 while
achieving similar or higher performance.</p>
  </details>
</details>
<details>
  <summary>126. <b>标题：Personal thermal comfort models using digital twins: Preference  prediction with BIM-extracted spatial-temporal proximity data from Build2Vec</b></summary>
  <p><b>编号</b>：[344]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00199</p>
  <p><b>作者</b>：Mahmoud Abdelrahman,  Adrian Chong,  Clayton Miller</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：framework uses longitudinal intensive thermal comfort subjective feedback, use conventional thermal preference prediction input variables, conventional thermal preference prediction, predict occupant thermal preference, test implementation show 14</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Conventional thermal preference prediction in buildings has limitations due
to the difficulty in capturing all environmental and personal factors. New
model features can improve the ability of a machine learning model to classify
a person's thermal preference. The spatial context of a building can provide
information to models about the windows, walls, heating and cooling sources,
air diffusers, and other factors that create micro-environments that influence
thermal comfort. Due to spatial heterogeneity, it is impractical to position
sensors at a high enough resolution to capture all conditions. This research
aims to build upon an existing vector-based spatial model, called Build2Vec,
for predicting spatial-temporal occupants' indoor environmental preferences.
Build2Vec utilizes the spatial data from the Building Information Model (BIM)
and indoor localization in a real-world setting. This framework uses
longitudinal intensive thermal comfort subjective feedback from smart
watch-based ecological momentary assessments (EMA). The aggregation of these
data is combined into a graph network structure (i.e., objects and relations)
and used as input for a classification model to predict occupant thermal
preference. The results of a test implementation show 14-28% accuracy
improvement over a set of baselines that use conventional thermal preference
prediction input variables.</p>
  </details>
</details>
<details>
  <summary>127. <b>标题：Backdoor Pre-trained Models Can Transfer to All</b></summary>
  <p><b>编号</b>：[345]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00197</p>
  <p><b>作者</b>：Lujia Shen,  Shouling Ji,  Xuhong Zhang,  Jinfeng Li,  Jing Chen,  Jie Shi,  Chengfang Fang,  Jianwei Yin,  Ting Wang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：popular online model repository hugging face, world natural language processing, inputs containing triggers directly, propose two new metrics, purpose language models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Pre-trained general-purpose language models have been a dominating component
in enabling real-world natural language processing (NLP) applications. However,
a pre-trained model with backdoor can be a severe threat to the applications.
Most existing backdoor attacks in NLP are conducted in the fine-tuning phase by
introducing malicious triggers in the targeted class, thus relying greatly on
the prior knowledge of the fine-tuning task. In this paper, we propose a new
approach to map the inputs containing triggers directly to a predefined output
representation of the pre-trained NLP models, e.g., a predefined output
representation for the classification token in BERT, instead of a target label.
It can thus introduce backdoor to a wide range of downstream tasks without any
prior knowledge. Additionally, in light of the unique properties of triggers in
NLP, we propose two new metrics to measure the performance of backdoor attacks
in terms of both effectiveness and stealthiness. Our experiments with various
types of triggers show that our method is widely applicable to different
fine-tuning tasks (classification and named entity recognition) and to
different models (such as BERT, XLNet, BART), which poses a severe threat.
Furthermore, by collaborating with the popular online model repository Hugging
Face, the threat brought by our method has been confirmed. Finally, we analyze
the factors that may affect the attack performance and share insights on the
causes of the success of our backdoor attack.</p>
  </details>
</details>
<details>
  <summary>128. <b>标题：Learning Continuous Representation of Audio for Arbitrary Scale Super  Resolution</b></summary>
  <p><b>编号</b>：[346]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00195</p>
  <p><b>作者</b>：Jaechang Kim,  Yunjoo Lee,  Seunghoon Hong,  Jungseul Ok</p>
  <p><b>备注</b>：submitted to ICASSP 2022</p>
  <p><b>关键词</b>：arbitrary scale super resolution even beyond, missing high resolution components, practice super resolution tasks, change output resolution )., coined local implicit representation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Audio super resolution aims to predict the missing high resolution components
of the low resolution audio signals. While audio in nature is continuous
signal, current approaches treat it as discrete data (i.e., input is defined on
discrete time domain), and consider the super resolution over fixed scale
factor (i.e., it is required to train a new neural network to change output
resolution). To obtain a continuous representation of audio and enable super
resolution for arbitrary scale factor, we propose a method of neural implicit
representation, coined Local Implicit representation for Super resolution of
Arbitrary scale (LISA). Our method locally parameterizes a chunk of audio as a
function of continuous time, and represents each chunk with the local latent
codes of neighboring chunks so that the function can extrapolate the signal at
any time coordinate, i.e., infinite resolution. To learn a continuous
representation for audio, we design a self-supervised learning strategy to
practice super resolution tasks up to the original resolution by stochastic
selection. Our numerical evaluation shows that LISA outperforms the previous
fixed-scale methods with a fraction of parameters, but also is capable of
arbitrary scale super resolution even beyond the resolution of training data.</p>
  </details>
</details>
<details>
  <summary>129. <b>标题：Convergence and Optimality of Policy Gradient Methods in Weakly Smooth  Settings</b></summary>
  <p><b>编号</b>：[350]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00185</p>
  <p><b>作者</b>：Matthew Shunshi Zhang,  Murat Erdogdu,  Animesh Garg</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：yet existing convergence analysis still relies, policy gradient methods without relying, weakly smooth policy classes, natural policy gradient algorithms, establish explicit convergence rates</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Policy gradient methods have been frequently applied to problems in control
and reinforcement learning with great success, yet existing convergence
analysis still relies on non-intuitive, impractical and often opaque
conditions. In particular, existing rates are achieved in limited settings,
under strict smoothness and bounded conditions. In this work, we establish
explicit convergence rates of policy gradient methods without relying on these
conditions, instead extending the convergence regime to weakly smooth policy
classes with $L_2$ integrable gradient. We provide intuitive examples to
illustrate the insight behind these new conditions. We also characterize the
sufficiency conditions for the ergodicity of near-linear MDPs, which represent
an important class of problems. Notably, our analysis also shows that fast
convergence rates are achievable for both the standard policy gradient and the
natural policy gradient algorithms under these assumptions. Lastly we provide
conditions and analysis for optimality of the converged policies.</p>
  </details>
</details>
<details>
  <summary>130. <b>标题：On Quantitative Evaluations of Counterfactuals</b></summary>
  <p><b>编号</b>：[354]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00177</p>
  <p><b>作者</b>：Frederik Hvilshøj,  Alexandros Iosifidis,  Ira Assent</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：counterfactual examples become increasingly popular, propose two new metrics, evaluating visual counterfactual examples, properties quantitative evaluation metrics, metrics give good scores</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As counterfactual examples become increasingly popular for explaining
decisions of deep learning models, it is essential to understand what
properties quantitative evaluation metrics do capture and equally important
what they do not capture. Currently, such understanding is lacking, potentially
slowing down scientific progress. In this paper, we consolidate the work on
evaluating visual counterfactual examples through an analysis and experiments.
We find that while most metrics behave as intended for sufficiently simple
datasets, some fail to tell the difference between good and bad counterfactuals
when the complexity increases. We observe experimentally that metrics give good
scores to tiny adversarial-like changes, wrongly identifying such changes as
superior counterfactual examples. To mitigate this issue, we propose two new
metrics, the Label Variation Score and the Oracle score, which are both less
vulnerable to such tiny changes. We conclude that a proper quantitative
evaluation of visual counterfactual examples should combine metrics to ensure
that all aspects of good counterfactuals are quantified.</p>
  </details>
</details>
<details>
  <summary>131. <b>标题：Dynamic Differential-Privacy Preserving SGD</b></summary>
  <p><b>编号</b>：[358]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00173</p>
  <p><b>作者</b>：Jian Du,  Song Li,  Moran Feng,  Siheng Chen</p>
  <p><b>备注</b>：15 pages</p>
  <p><b>关键词</b>：additive noise across training steps results, improves model accuracy without sacrificing privacy, gaussian dp central limit theorem, strong privacy protection region, significantly improves model accuracy</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Differentially-Private Stochastic Gradient Descent (DP-SGD) prevents
training-data privacy breaches by adding noise to the clipped gradient during
SGD training to satisfy the differential privacy (DP) definition. On the other
hand, the same clipping operation and additive noise across training steps
results in unstable updates and even a ramp-up period, which significantly
reduces the model's accuracy. In this paper, we extend the Gaussian DP central
limit theorem to calibrate the clipping value and the noise power for each
individual step separately. We, therefore, are able to propose the dynamic
DP-SGD, which has a lower privacy cost than the DP-SGD during updates until
they achieve the same target privacy budget at a target number of updates.
Dynamic DP-SGD, in particular, improves model accuracy without sacrificing
privacy by gradually lowering both clipping value and noise power while
adhering to a total privacy budget constraint. Extensive experiments on a
variety of deep learning tasks, including image classification, natural
language processing, and federated learning, show that the proposed dynamic
DP-SGD algorithm stabilizes updates and, as a result, significantly improves
model accuracy in the strong privacy protection region when compared to DP-SGD.</p>
  </details>
</details>
<details>
  <summary>132. <b>标题：You are caught stealing my winning lottery ticket! Making a lottery  ticket claim its ownership</b></summary>
  <p><b>编号</b>：[364]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00162</p>
  <p><b>作者</b>：Xuxi Chen,  Tianlong Chen,  Zhenyu Zhang,  Zhangyang Wang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：existing methods explored encrypted weights, found winning ticket become, e ., winning ticket, leverage sparse topological information, special sparse subnetwork</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Despite tremendous success in many application scenarios, the training and
inference costs of using deep learning are also rapidly increasing over time.
The lottery ticket hypothesis (LTH) emerges as a promising framework to
leverage a special sparse subnetwork (i.e., winning ticket) instead of a full
model for both training and inference, that can lower both costs without
sacrificing the performance. The main resource bottleneck of LTH is however the
extraordinary cost to find the sparse mask of the winning ticket. That makes
the found winning ticket become a valuable asset to the owners, highlighting
the necessity of protecting its copyright. Our setting adds a new dimension to
the recently soaring interest in protecting against the intellectual property
(IP) infringement of deep models and verifying their ownerships, since they
take owners' massive/unique resources to develop or train. While existing
methods explored encrypted weights or predictions, we investigate a unique way
to leverage sparse topological information to perform lottery verification, by
developing several graph-based signatures that can be embedded as credentials.
By further combining trigger set-based methods, our proposal can work in both
white-box and black-box verification scenarios. Through extensive experiments,
we demonstrate the effectiveness of lottery verification in diverse models
(ResNet-20, ResNet-18, ResNet-50) on CIFAR-10 and CIFAR-100. Specifically, our
verification is shown to be robust to removal attacks such as model fine-tuning
and pruning, as well as several ambiguity attacks. Our codes are available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>133. <b>标题：DSEE: Dually Sparsity-embedded Efficient Tuning of Pre-trained Language  Models</b></summary>
  <p><b>编号</b>：[366]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00160</p>
  <p><b>作者</b>：Xuxi Chen,  Tianlong Chen,  Yu Cheng,  Weizhu Chen,  Zhangyang Wang,  Ahmed Hassan Awadallah</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：consistently demonstrate highly impressive parameter -/ training -/ inference, 35 \%$ inference flops savings, maintaining competitive downstream transfer performance, trained language models via magnitude, achieve two key objectives</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Gigantic pre-trained models have become central to natural language
processing (NLP), serving as the starting point for fine-tuning towards a range
of downstream tasks. However, two pain points persist for this paradigm: (a) as
the pre-trained models grow bigger (e.g., 175B parameters for GPT-3), even the
fine-tuning process can be time-consuming and computationally expensive; (b)
the fine-tuned model has the same size as its starting point by default, which
is neither sensible due to its more specialized functionality, nor practical
since many fine-tuned models will be deployed in resource-constrained
environments. To address these pain points, we propose a framework for
resource- and parameter-efficient fine-tuning by leveraging the sparsity prior
in both weight updates and the final model weights. Our proposed framework,
dubbed Dually Sparsity-Embedded Efficient Tuning (DSEE), aims to achieve two
key objectives: (i) parameter efficient fine-tuning - by enforcing
sparsity-aware weight updates on top of the pre-trained weights; and (ii)
resource-efficient inference - by encouraging a sparse weight structure towards
the final fine-tuned model. We leverage sparsity in these two directions by
exploiting both unstructured and structured sparse patterns in pre-trained
language models via magnitude-based pruning and $\ell_1$ sparse regularization.
Extensive experiments and in-depth investigations, with diverse network
backbones (i.e., BERT, GPT-2, and DeBERTa) on dozens of datasets, consistently
demonstrate highly impressive parameter-/training-/inference-efficiency, while
maintaining competitive downstream transfer performance. For instance, our
DSEE-BERT obtains about $35\%$ inference FLOPs savings with <1% trainable parameters and comparable performance to conventional fine-tuning. codes are available in this https url.< p>
  </1%></p></details>
</details>
<details>
  <summary>134. <b>标题：ILMPQ : An Intra-Layer Multi-Precision Deep Neural Network Quantization  framework for FPGA</b></summary>
  <p><b>编号</b>：[368]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00155</p>
  <p><b>作者</b>：Sung-En Chang,  Yanyu Li,  Mengshu Sun,  Yanzhi Wang,  Xue Lin</p>
  <p><b>备注</b>：Accepted by CogArch 2021: 5th Workshop on Cognitive Architectures</p>
  <p><b>关键词</b>：proposed ilmpq dnn quantization framework achieves 70, existing quantization methods apply multi, e ., xilinx xc7z020, supports multiple precisions along, main model compression technique</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This work targets the commonly used FPGA (field-programmable gate array)
devices as the hardware platform for DNN edge computing. We focus on DNN
quantization as the main model compression technique. The novelty of this work
is: We use a quantization method that supports multiple precisions along the
intra-layer dimension, while the existing quantization methods apply
multi-precision quantization along the inter-layer dimension. The intra-layer
multi-precision method can uniform the hardware configurations for different
layers to reduce computation overhead and at the same time preserve the model
accuracy as the inter-layer approach. Our proposed ILMPQ DNN quantization
framework achieves 70.73 Top1 accuracy in ResNet-18 on the ImageNet dataset. We
also validate the proposed MSP framework on two FPGA devices i.e., Xilinx
XC7Z020 and XC7Z045. We achieve 3.65x speedup in end-to-end inference time on
the ImageNet, compared with the fixed-point quantization method.</p>
  </details>
</details>
<details>
  <summary>135. <b>标题：RMSMP: A Novel Deep Neural Network Quantization Framework with Row-wise  Mixed Schemes and Multiple Precisions</b></summary>
  <p><b>编号</b>：[370]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00153</p>
  <p><b>作者</b>：Sung-En Chang,  Yanyu Li,  Mengshu Sun,  Weiwen Jiang,  Sijia Liu,  Yanzhi Wang,  Xue Lin</p>
  <p><b>备注</b>：Accepted by International Conference on Computer Vision 2021 (ICCV 2021)</p>
  <p><b>关键词</b>：multiple precisions within layers -- among rows, hardware implementation towards guaranteed inference acceleration, best accuracy performance among state, novel deep neural network, rmsmp quantization algorithm uses</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This work proposes a novel Deep Neural Network (DNN) quantization framework,
namely RMSMP, with a Row-wise Mixed-Scheme and Multi-Precision approach.
Specifically, this is the first effort to assign mixed quantization schemes and
multiple precisions within layers -- among rows of the DNN weight matrix, for
simplified operations in hardware inference, while preserving accuracy.
Furthermore, this paper makes a different observation from the prior work that
the quantization error does not necessarily exhibit the layer-wise sensitivity,
and actually can be mitigated as long as a certain portion of the weights in
every layer are in higher precisions. This observation enables layer-wise
uniformality in the hardware implementation towards guaranteed inference
acceleration, while still enjoying row-wise flexibility of mixed schemes and
multiple precisions to boost accuracy. The candidates of schemes and precisions
are derived practically and effectively with a highly hardware-informative
strategy to reduce the problem search space. With the offline determined ratio
of different quantization schemes and precisions for all the layers, the RMSMP
quantization algorithm uses the Hessian and variance-based method to
effectively assign schemes and precisions for each row. The proposed RMSMP is
tested for the image classification and natural language processing (BERT)
applications and achieves the best accuracy performance among state-of-the-arts
under the same equivalent precisions. The RMSMP is implemented on FPGA devices,
achieving 3.65x speedup in the end-to-end inference time for ResNet-18 on
ImageNet, compared with the 4-bit Fixed-point baseline.</p>
  </details>
</details>
<details>
  <summary>136. <b>标题：Temporal-Spatial Feature Extraction Based on Convolutional Neural  Networks for Travel Time Prediction</b></summary>
  <p><b>编号</b>：[371]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00149</p>
  <p><b>作者</b>：Chi-Hua Chen</p>
  <p><b>备注</b>：22 pages, 15 figures, and 3 tables</p>
  <p><b>关键词</b>：travel time prediction method based, mean absolute percentage error, traffic information prediction methods, travel time prediction, traffic information prediction</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In recent years, some traffic information prediction methods have been
proposed to provide the precise information of travel time, vehicle speed, and
traffic flow for highways. However, big errors may be obtained by these methods
for urban roads or the alternative roads of highways. Therefore, this study
proposes a travel time prediction method based on convolutional neural networks
to extract important factors for the improvement of traffic information
prediction. In practical experimental environments, the travel time records of
No. 5 Highway and the alternative roads of its were collected and used to
evaluate the proposed method. The results showed that the mean absolute
percentage error of the proposed method was about 5.69%. Therefore, the
proposed method based on deep learning techniques can improve the accuracy of
travel time prediction.</p>
  </details>
</details>
<details>
  <summary>137. <b>标题：Uncovering IP Address Hosting Types Behind Malicious Websites</b></summary>
  <p><b>编号</b>：[373]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00142</p>
  <p><b>作者</b>：Nimesha Wickramasinghe,  Mohamed Nabeel,  Kenneth Thilakaratne,  Chamath Keppitiyagama,  Kasun De Zoysa</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：single entity ), one may blacklist, attackers utilize bullet proof hosting services, hosting providers may take measures, moving towards utilizing ips, regular hosting providers</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Hundreds of thousands of malicious domains are created everyday. These
malicious domains are hosted on a wide variety of network infrastructures.
Traditionally, attackers utilize bullet proof hosting services (e.g. MaxiDed,
Cyber Bunker) to take advantage of relatively lenient policies on what content
they can host. However, these IP ranges are increasingly being blocked or the
services are taken down by law enforcement. Hence, attackers are moving towards
utilizing IPs from regular hosting providers while staying under the radar of
these hosting providers. There are several practical advantages of accurately
knowing the type of IP used to host malicious domains. If the IP is a dedicated
IP (i.e. it is leased to a single entity), one may blacklist the IP to block
domains hosted on those IPs as welll as use as a way to identify other
malicious domains hosted the same IP. If the IP is a shared hosting IP, hosting
providers may take measures to clean up such domains and maintain a high
reputation for their users.</p>
  </details>
</details>
<details>
  <summary>138. <b>标题：Context Meta-Reinforcement Learning via Neuromodulation</b></summary>
  <p><b>编号</b>：[375]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00134</p>
  <p><b>作者</b>：Eseoghene Ben-Iwhiwhu,  Jeffery Dick,  Nicholas A. Ketz,  Praveen K. Pilly,  Andrea Soltoggio</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：fast adaptation beyond simple benchmark problems, neuromodulation produces significantly better result, evaluated across multiple discrete, produce efficient dynamic representations, obtaining rich dynamic representations</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Meta-reinforcement learning (meta-RL) algorithms enable agents to adapt
quickly to tasks from few samples in dynamic environments. Such a feat is
achieved through dynamic representations in an agent's policy network (obtained
via reasoning about task context, model parameter updates, or both). However,
obtaining rich dynamic representations for fast adaptation beyond simple
benchmark problems is challenging due to the burden placed on the policy
network to accommodate different policies. This paper addresses the challenge
by introducing neuromodulation as a modular component to augment a standard
policy network that regulates neuronal activities in order to produce efficient
dynamic representations for task adaptation. The proposed extension to the
policy network is evaluated across multiple discrete and continuous control
environments of increasing complexity. To prove the generality and benefits of
the extension in meta-RL, the neuromodulated network was applied to two
state-of-the-art meta-RL algorithms (CAVIA and PEARL). The result demonstrates
that meta-RL augmented with neuromodulation produces significantly better
result and richer dynamic representations in comparison to the baselines.</p>
  </details>
</details>
<details>
  <summary>139. <b>标题：Three approaches to facilitate DNN generalization to objects in  out-of-distribution orientations and illuminations: late-stopping, tuning  batch normalization and invariance loss</b></summary>
  <p><b>编号</b>：[376]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00131</p>
  <p><b>作者</b>：Akira Sakai,  Taro Sunagawa,  Spandan Madan,  Kanata Suzuki,  Takashi Katoh,  Hiromichi Kobashi,  Hanspeter Pfister,  Pawan Sinha,  Xavier Boix,  Tomotake Sasaki</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：enable ood accuracy gains -- individual neurons, often biased towards objects, investigate three different approaches, three approaches focus, approaches substantially improves</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The training data distribution is often biased towards objects in certain
orientations and illumination conditions. While humans have a remarkable
capability of recognizing objects in out-of-distribution (OoD) orientations and
illuminations, Deep Neural Networks (DNNs) severely suffer in this case, even
when large amounts of training examples are available. In this paper, we
investigate three different approaches to improve DNNs in recognizing objects
in OoD orientations and illuminations. Namely, these are (i) training much
longer after convergence of the in-distribution (InD) validation accuracy,
i.e., late-stopping, (ii) tuning the momentum parameter of the batch
normalization layers, and (iii) enforcing invariance of the neural activity in
an intermediate layer to orientation and illumination conditions. Each of these
approaches substantially improves the DNN's OoD accuracy (more than 20% in some
cases). We report results in four datasets: two datasets are modified from the
MNIST and iLab datasets, and the other two are novel (one of 3D rendered cars
and another of objects taken from various controlled orientations and
illumination conditions). These datasets allow to study the effects of
different amounts of bias and are challenging as DNNs perform poorly in OoD
conditions. Finally, we demonstrate that even though the three approaches focus
on different aspects of DNNs, they all tend to lead to the same underlying
neural mechanism to enable OoD accuracy gains -- individual neurons in the
intermediate layers become more selective to a category and also invariant to
OoD orientations and illuminations.</p>
  </details>
</details>
<details>
  <summary>140. <b>标题：Predicting Critical Biogeochemistry of the Southern Ocean for Climate  Monitoring</b></summary>
  <p><b>编号</b>：[378]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00126</p>
  <p><b>作者</b>：Ellen Park,  Jae Deok Kim,  Nadege Aoki,  Yumeng Melody Cao,  Yamin Arefeen,  Matthew Beveridge,  David Nicholson,  Iddo Drori</p>
  <p><b>备注</b>：6 pages, 4 figures</p>
  <p><b>关键词</b>：neural network significantly improves upon linear regression, calculate uncertainty bounds around estimates advance, provide uncertainty bounds around, equipped robotic profiling floats, based hydrographic investigations program</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The Biogeochemical-Argo (BGC-Argo) program is building a network of globally
distributed, sensor-equipped robotic profiling floats, improving our
understanding of the climate system and how it is changing. These floats,
however, are limited in the number of variables measured. In this study, we
train neural networks to predict silicate and phosphate values in the Southern
Ocean from temperature, pressure, salinity, oxygen, nitrate, and location and
apply these models to earth system model (ESM) and BGC-Argo data to expand the
utility of this ocean observation network. We trained our neural networks on
observations from the Global Ocean Ship-Based Hydrographic Investigations
Program (GO-SHIP) and use dropout regularization to provide uncertainty bounds
around our predicted values. Our neural network significantly improves upon
linear regression but shows variable levels of uncertainty across the ranges of
predicted variables. We explore the generalization of our estimators to test
data outside our training distribution from both ESM and BGC-Argo data. Our use
of out-of-distribution test data to examine shifts in biogeochemical parameters
and calculate uncertainty bounds around estimates advance the state-of-the-art
in oceanographic data and climate monitoring. We make our data and code
publicly available.</p>
  </details>
</details>
<details>
  <summary>141. <b>标题：Predicting Atlantic Multidecadal Variability</b></summary>
  <p><b>编号</b>：[379]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00124</p>
  <p><b>作者</b>：Glenn Liu,  Peidong Wang,  Matthew Beveridge,  Young-Oh Kwon,  Iddo Drori</p>
  <p><b>备注</b>：7 pages, 3 figures</p>
  <p><b>关键词</b>：community earth system model 1 large ensemble project, work tests multiple machine learning models, amv strongly impacts local climate, north atlantic sea surface temperature, traditional persistence forecast baseline</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Atlantic Multidecadal Variability (AMV) describes variations of North
Atlantic sea surface temperature with a typical cycle of between 60 and 70
years. AMV strongly impacts local climate over North America and Europe,
therefore prediction of AMV, especially the extreme values, is of great
societal utility for understanding and responding to regional climate change.
This work tests multiple machine learning models to improve the state of AMV
prediction from maps of sea surface temperature, salinity, and sea level
pressure in the North Atlantic region. We use data from the Community Earth
System Model 1 Large Ensemble Project, a state-of-the-art climate model with
3,440 years of data. Our results demonstrate that all of the models we use
outperform the traditional persistence forecast baseline. Predicting the AMV is
important for identifying future extreme temperatures and precipitation, as
well as hurricane activity, in Europe and North America up to 25 years in
advance.</p>
  </details>
</details>
<details>
  <summary>142. <b>标题：Visual Explanations for Convolutional Neural Networks via Latent  Traversal of Generative Adversarial Networks</b></summary>
  <p><b>编号</b>：[384]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00116</p>
  <p><b>作者</b>：Amil Dravid,  Aggelos K. Katsaggelos</p>
  <p><b>备注</b>：2 pages, 2 figures, to appear as extended abstract at AAAI-22</p>
  <p><b>关键词</b>：gan framework disentangles lung structure, weighted class activation mapping, utilizing generative adversarial networks, specifically deep neural networks, convolutional neural network</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Lack of explainability in artificial intelligence, specifically deep neural
networks, remains a bottleneck for implementing models in practice. Popular
techniques such as Gradient-weighted Class Activation Mapping (Grad-CAM)
provide a coarse map of salient features in an image, which rarely tells the
whole story of what a convolutional neural network (CNN) learned. Using
COVID-19 chest X-rays, we present a method for interpreting what a CNN has
learned by utilizing Generative Adversarial Networks (GANs). Our GAN framework
disentangles lung structure from COVID-19 features. Using this GAN, we can
visualize the transition of a pair of COVID negative lungs in a chest
radiograph to a COVID positive pair by interpolating in the latent space of the
GAN, which provides fine-grained visualization of how the CNN responds to
varying features within the lungs.</p>
  </details>
</details>
<details>
  <summary>143. <b>标题：Combining Public and Private Data</b></summary>
  <p><b>编号</b>：[385]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00115</p>
  <p><b>作者</b>：Cecilia Ferrando,  Jennifer Gillenwater,  Alex Kulesza</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：experiments provide empirical evidence, provide provable privacy guarantees, mixed median estimator based, jorgensen et al, estimating aggregate statistics</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Differential privacy is widely adopted to provide provable privacy guarantees
in data analysis. We consider the problem of combining public and private data
(and, more generally, data with heterogeneous privacy needs) for estimating
aggregate statistics. We introduce a mixed estimator of the mean optimized to
minimize the variance. We argue that our mechanism is preferable to techniques
that preserve the privacy of individuals by subsampling data proportionally to
the privacy needs of users. Similarly, we present a mixed median estimator
based on the exponential mechanism. We compare our mechanisms to the methods
proposed in Jorgensen et al. [2015]. Our experiments provide empirical evidence
that our mechanisms often outperform the baseline methods.</p>
  </details>
</details>
<details>
  <summary>144. <b>标题：FC2T2: The Fast Continuous Convolutional Taylor Transform with  Applications in Vision and Graphics</b></summary>
  <p><b>编号</b>：[388]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00110</p>
  <p><b>作者</b>：Henning Lange,  J. Nathan Kutz</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：fast continuous convolutional taylor transform, low dimensional convolutional operators, require repeated function evaluations, unlike regular neural networks, modern machine learning perspective</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Series expansions have been a cornerstone of applied mathematics and
engineering for centuries. In this paper, we revisit the Taylor series
expansion from a modern Machine Learning perspective. Specifically, we
introduce the Fast Continuous Convolutional Taylor Transform (FC2T2), a variant
of the Fast Multipole Method (FMM), that allows for the efficient approximation
of low dimensional convolutional operators in continuous space. We build upon
the FMM which is an approximate algorithm that reduces the computational
complexity of N-body problems from O(NM) to O(N+M) and finds application in
e.g. particle simulations. As an intermediary step, the FMM produces a series
expansion for every cell on a grid and we introduce algorithms that act
directly upon this representation. These algorithms analytically but
approximately compute the quantities required for the forward and backward pass
of the backpropagation algorithm and can therefore be employed as (implicit)
layers in Neural Networks. Specifically, we introduce a root-implicit layer
that outputs surface normals and object distances as well as an
integral-implicit layer that outputs a rendering of a radiance field given a 3D
pose. In the context of Machine Learning, $N$ and $M$ can be understood as the
number of model parameters and model evaluations respectively which entails
that, for applications that require repeated function evaluations which are
prevalent in Computer Vision and Graphics, unlike regular Neural Networks, the
techniques introduce in this paper scale gracefully with parameters. For some
applications, this results in a 200x reduction in FLOPs compared to
state-of-the-art approaches at a reasonable or non-existent loss in accuracy.</p>
  </details>
</details>
<details>
  <summary>145. <b>标题：Evaluation of an Anomaly Detector for Routers using Parameterizable  Malware in an IoT Ecosystem</b></summary>
  <p><b>编号</b>：[392]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00097</p>
  <p><b>作者</b>：John Carter,  Spiros Mancoridis</p>
  <p><b>备注</b>：To appear in Proceedings of the 17th International Conference on Ubiquitous Security (UbiSec 2021)</p>
  <p><b>关键词</b>：anomaly detector uses feature sets crafted, machine learning anomaly detector using custom, malware samples multiple degrees, based anomaly detector, support vector machine</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This work explores the evaluation of a machine learning anomaly detector
using custom-made parameterizable malware in an Internet of Things (IoT)
Ecosystem. It is assumed that the malware has infected, and resides on, the
Linux router that serves other devices on the network, as depicted in Figure 1.
This IoT Ecosystem was developed as a testbed to evaluate the efficacy of a
behavior-based anomaly detector. The malware consists of three types of
custom-made malware: ransomware, cryptominer, and keylogger, which all have
exfiltration capabilities to the network. The parameterization of the malware
gives the malware samples multiple degrees of freedom, specifically relating to
the rate and size of data exfiltration. The anomaly detector uses feature sets
crafted from system calls and network traffic, and uses a Support Vector
Machine (SVM) for behavioral-based anomaly detection. The custom-made malware
is used to evaluate the situations where the SVM is effective, as well as the
situations where it is not effective.</p>
  </details>
</details>
<details>
  <summary>146. <b>标题：Online Optimization with Feedback Delay and Nonlinear Switching Cost</b></summary>
  <p><b>编号</b>：[393]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00095</p>
  <p><b>作者</b>：Weici Pan,  Guanya Shi,  Yiheng Lin,  Adam Wierman</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：novel iterative regularized online balanced descent, k $- round $\ textit, e ., costs depend, l ^{ 2k })$,, irobd directly offers constant</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We study a variant of online optimization in which the learner receives
$k$-round $\textit{delayed feedback}$ about hitting cost and there is a
multi-step nonlinear switching cost, i.e., costs depend on multiple previous
actions in a nonlinear manner. Our main result shows that a novel Iterative
Regularized Online Balanced Descent (iROBD) algorithm has a constant,
dimension-free competitive ratio that is $O(L^{2k})$, where $L$ is the
Lipschitz constant of the switching cost. Additionally, we provide lower bounds
that illustrate the Lipschitz condition is required and the dependencies on $k$
and $L$ are tight. Finally, via reductions, we show that this setting is
closely related to online control problems with delay, nonlinear dynamics, and
adversarial disturbances, where iROBD directly offers constant-competitive
online policies.</p>
  </details>
</details>
<details>
  <summary>147. <b>标题：Optimal Compression of Locally Differentially Private Mechanisms</b></summary>
  <p><b>编号</b>：[395]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00092</p>
  <p><b>作者</b>：Abhin Shah,  Wei-Ning Chen,  Johannes Balle,  Peter Kairouz,  Lucas Theis</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：ye et al ., 2018 ),, bhowmick et al ., 2018, havasi et al ., 2019, data using shared randomness, best known ldp algorithms</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Compressing the output of \epsilon-locally differentially private (LDP)
randomizers naively leads to suboptimal utility. In this work, we demonstrate
the benefits of using schemes that jointly compress and privatize the data
using shared randomness. In particular, we investigate a family of schemes
based on Minimal Random Coding (Havasi et al., 2019) and prove that they offer
optimal privacy-accuracy-communication tradeoffs. Our theoretical and empirical
findings show that our approach can compress PrivUnit (Bhowmick et al., 2018)
and Subset Selection (Ye et al., 2018), the best known LDP algorithms for mean
and frequency estimation, to to the order of \epsilon-bits of communication
while preserving their privacy and accuracy guarantees.</p>
  </details>
</details>
<details>
  <summary>148. <b>标题：A Scalable AutoML Approach Based on Graph Neural Networks</b></summary>
  <p><b>编号</b>：[400]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00083</p>
  <p><b>作者</b>：Mossad Helali,  Essam Mansour,  Ibrahim Abdelaziz,  Julian Dolby,  Kavitha Srinivas</p>
  <p><b>备注</b>：15 pages, 10 figures</p>
  <p><b>关键词</b>：corresponding historically used pipelines using effective static analysis instead, automl systems build machine learning models automatically, models automl pipeline creation, ability via integrating kgpip, diverse pipelines seen</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>AutoML systems build machine learning models automatically by performing a
search over valid data transformations and learners, along with hyper-parameter
optimization for each learner. We present a system called KGpip for the
selection of transformations and learners, which (1) builds a database of
datasets and corresponding historically used pipelines using effective static
analysis instead of the typical use of actual runtime information, (2) uses
dataset embeddings to find similar datasets in the database based on its
content instead of metadata-based features, (3) models AutoML pipeline creation
as a graph generation problem, to succinctly characterize the diverse pipelines
seen for a single dataset. KGpip is designed as a sub-component for AutoML
systems. We demonstrate this ability via integrating KGpip with two AutoML
systems and show that it does significantly enhance the performance of existing
state-of-the-art systems.</p>
  </details>
</details>
<details>
  <summary>149. <b>标题：Deep Deterministic Uncertainty for Semantic Segmentation</b></summary>
  <p><b>编号</b>：[403]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00079</p>
  <p><b>作者</b>：Jishnu Mukhoti,  Joost van Amersfoort,  Philip H.S. Torr,  Yarin Gal</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：uncertainty estimation using feature space densities, ddu improves upon mc dropout, apply ddu location independently, extend deep deterministic uncertainty, pixel dependent ddu</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We extend Deep Deterministic Uncertainty (DDU), a method for uncertainty
estimation using feature space densities, to semantic segmentation. DDU enables
quantifying and disentangling epistemic and aleatoric uncertainty in a single
forward pass through the model. We study the similarity of feature
representations of pixels at different locations for the same class and
conclude that it is feasible to apply DDU location independently, which leads
to a significant reduction in memory consumption compared to pixel dependent
DDU. Using the DeepLab-v3+ architecture on Pascal VOC 2012, we show that DDU
improves upon MC Dropout and Deep Ensembles while being significantly faster to
compute.</p>
  </details>
</details>
<details>
  <summary>150. <b>标题：Generalized Proximal Policy Optimization with Sample Reuse</b></summary>
  <p><b>编号</b>：[406]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00072</p>
  <p><b>作者</b>：James Queeney,  Ioannis Ch. Paschalidis,  Christos G. Cassandras</p>
  <p><b>备注</b>：To appear in 35th Conference on Neural Information Processing Systems (NeurIPS 2021)</p>
  <p><b>关键词</b>：policy methods typically generate reliable policy improvement throughout training, call generalized proximal policy optimization, develop policy improvement guarantees, driven reinforcement learning methods, world decision making tasks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In real-world decision making tasks, it is critical for data-driven
reinforcement learning methods to be both stable and sample efficient.
On-policy methods typically generate reliable policy improvement throughout
training, while off-policy methods make more efficient use of data through
sample reuse. In this work, we combine the theoretically supported stability
benefits of on-policy algorithms with the sample efficiency of off-policy
algorithms. We develop policy improvement guarantees that are suitable for the
off-policy setting, and connect these bounds to the clipping mechanism used in
Proximal Policy Optimization. This motivates an off-policy version of the
popular algorithm that we call Generalized Proximal Policy Optimization with
Sample Reuse. We demonstrate both theoretically and empirically that our
algorithm delivers improved performance by effectively balancing the competing
goals of stability and sample efficiency.</p>
  </details>
</details>
<details>
  <summary>151. <b>标题：Deep inference of latent dynamics with spatio-temporal super-resolution  using selective backpropagation through time</b></summary>
  <p><b>编号</b>：[408]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00070</p>
  <p><b>作者</b>：Feng Zhu,  Andrew R. Sedler,  Harrison A. Grier,  Nauman Ahad,  Mark A. Davenport,  Matthew T. Kaufman,  Andrea Giovannucci,  Chethan Pandarinath</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：frequency temporal structure underlying neural population activity, novel neural network training strategy, million neurons within brain circuits, modern neural interfaces allow access, exploiting relationships among neurons</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Modern neural interfaces allow access to the activity of up to a million
neurons within brain circuits. However, bandwidth limits often create a
trade-off between greater spatial sampling (more channels or pixels) and the
temporal frequency of sampling. Here we demonstrate that it is possible to
obtain spatio-temporal super-resolution in neuronal time series by exploiting
relationships among neurons, embedded in latent low-dimensional population
dynamics. Our novel neural network training strategy, selective backpropagation
through time (SBTT), enables learning of deep generative models of latent
dynamics from data in which the set of observed variables changes at each time
step. The resulting models are able to infer activity for missing samples by
combining observations with learned latent dynamics. We test SBTT applied to
sequential autoencoders and demonstrate more efficient and higher-fidelity
characterization of neural population dynamics in electrophysiological and
calcium imaging data. In electrophysiology, SBTT enables accurate inference of
neuronal population dynamics with lower interface bandwidths, providing an
avenue to significant power savings for implanted neuroelectronic interfaces.
In applications to two-photon calcium imaging, SBTT accurately uncovers
high-frequency temporal structure underlying neural population activity,
substantially outperforming the current state-of-the-art. Finally, we
demonstrate that performance could be further improved by using limited,
high-bandwidth sampling to pretrain dynamics models, and then using SBTT to
adapt these models for sparsely-sampled data.</p>
  </details>
</details>
<details>
  <summary>152. <b>标题：Node Feature Extraction by Self-Supervised Multi-scale Neighborhood  Prediction</b></summary>
  <p><b>编号</b>：[410]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00064</p>
  <p><b>作者</b>：Eli Chien,  Wei-Cheng Chang,  Cho-Jui Hsieh,  Hsiang-Fu Yu,  Jiong Zhang,  Olgica Milenkovic,  Inderjit S Dhillon</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：graph information aided node feature extraction, agnostic within standard gnn pipelines, fully utilizing potential correlations, take numerical node features, extracting numerical node features</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Learning on graphs has attracted significant attention in the learning
community due to numerous real-world applications. In particular, graph neural
networks (GNNs), which take numerical node features and graph structure as
inputs, have been shown to achieve state-of-the-art performance on various
graph-related learning tasks. Recent works exploring the correlation between
numerical node features and graph structure via self-supervised learning have
paved the way for further performance improvements of GNNs. However, methods
used for extracting numerical node features from raw data are still
graph-agnostic within standard GNN pipelines. This practice is sub-optimal as
it prevents one from fully utilizing potential correlations between graph
topology and node attributes. To mitigate this issue, we propose a new
self-supervised learning framework, Graph Information Aided Node feature
exTraction (GIANT). GIANT makes use of the eXtreme Multi-label Classification
(XMC) formalism, which is crucial for fine-tuning the language model based on
graph information, and scales to large datasets. We also provide a theoretical
analysis that justifies the use of XMC over link prediction and motivates
integrating XR-Transformers, a powerful method for solving XMC problems, into
the GIANT framework. We demonstrate the superior performance of GIANT over the
standard GNN pipeline on Open Graph Benchmark datasets: For example, we improve
the accuracy of the top-ranked method GAMLP from $68.25\%$ to $69.67\%$, SGC
from $63.29\%$ to $66.10\%$ and MLP from $47.24\%$ to $61.10\%$ on the
ogbn-papers100M dataset by leveraging GIANT.</p>
  </details>
</details>
<details>
  <summary>153. <b>标题：Improving Generalization Bounds for VC Classes Using the Hypergeometric  Tail Inversion</b></summary>
  <p><b>编号</b>：[412]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00062</p>
  <p><b>作者</b>：Jean-Samuel Leboeuf,  Frédéric LeBlanc,  Mario Marchand</p>
  <p><b>备注</b>：15 pages (body), 36 pages (appendices), 54 pages (total), 13 figures</p>
  <p><b>关键词</b>：using two main ideas, reasonable data set sizes, independent risk upper bound, numerical comparisons show, nearly never vacuous</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We significantly improve the generalization bounds for VC classes by using
two main ideas. First, we consider the hypergeometric tail inversion to obtain
a very tight non-uniform distribution-independent risk upper bound for VC
classes. Second, we optimize the ghost sample trick to obtain a further
non-negligible gain. These improvements are then used to derive a relative
deviation bound, a multiclass margin bound, as well as a lower bound. Numerical
comparisons show that the new bound is nearly never vacuous, and is tighter
than other VC bounds for all reasonable data set sizes.</p>
  </details>
</details>
<details>
  <summary>154. <b>标题：Word embeddings for topic modeling: an application to the estimation of  the economic policy uncertainty index</b></summary>
  <p><b>编号</b>：[413]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00057</p>
  <p><b>作者</b>：Hairo U. Miranda Belmonte,  Victor Muñiz-Sánchez,  Francisco Corona</p>
  <p><b>备注</b>：Preprint version</p>
  <p><b>关键词</b>：use computationally intensive methods, proper way based solely, proposal allow us, new document assignation, latent dirichlet allocation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Quantification of economic uncertainty is a key concept for the prediction of
macro economic variables such as gross domestic product (GDP), and it becomes
particularly relevant on real-time or short-time predictions methodologies,
such as nowcasting, where it is required a large amount of time series data,
commonly with different structures and frequencies. Most of the data comes from
the official agencies statistics and non-public institutions, however, relying
our estimates in just the traditional data mentioned before, have some
disadvantages. One of them is that economic uncertainty could not be
represented or measured in a proper way based solely in financial or
macroeconomic data, another one, is that they are susceptible to lack of
information due to extraordinary events, such as the current COVID-19 pandemic.
For these reasons, it is very common nowadays to use some non-traditional data
from different sources, such as social networks or digital newspapers, in
addition to the traditional data from official sources. The economic policy
uncertainty (EPU) index, is the most used newspaper-based indicator to quantify
the uncertainty, and is based on topic modeling of newspapers. In this paper,
we propose a methodology to estimate the EPU index, which incorporates a fast
and efficient method for topic modeling of digital news based on semantic
clustering with word embeddings, allowing to update the index in real-time,
which is a drawback with another proposals that use computationally intensive
methods for topic modeling, such as Latent Dirichlet Allocation (LDA). We show
that our proposal allow us to update the index and significantly reduces the
time required for new document assignation into topics.</p>
  </details>
</details>
<details>
  <summary>155. <b>标题：Generalized Data Weighting via Class-level Gradient Manipulation</b></summary>
  <p><b>编号</b>：[414]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00056</p>
  <p><b>作者</b>：Can Chen,  Shuhao Zheng,  Xi Chen,  Erqun Dong,  Xue Liu,  Hao Liu,  Dejing Dou</p>
  <p><b>备注</b>：17 pages, 8 figures, accepted by NeurIPS 2021 for a poster session, camera-ready version, initial submission to arXiv</p>
  <p><b>关键词</b>：60 \%$ uniform noise setting, gdw achieves remarkable performance improvement, extra computational cost compared, simultaneously mitigate label noise, propose generalized data weighting</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Label noise and class imbalance are two major issues coexisting in real-world
datasets. To alleviate the two issues, state-of-the-art methods reweight each
instance by leveraging a small amount of clean and unbiased data. Yet, these
methods overlook class-level information within each instance, which can be
further utilized to improve performance. To this end, in this paper, we propose
Generalized Data Weighting (GDW) to simultaneously mitigate label noise and
class imbalance by manipulating gradients at the class level. To be specific,
GDW unrolls the loss gradient to class-level gradients by the chain rule and
reweights the flow of each gradient separately. In this way, GDW achieves
remarkable performance improvement on both issues. Aside from the performance
gain, GDW efficiently obtains class-level weights without introducing any extra
computational cost compared with instance weighting methods. Specifically, GDW
performs a gradient descent step on class-level weights, which only relies on
intermediate gradients. Extensive experiments in various settings verify the
effectiveness of GDW. For example, GDW outperforms state-of-the-art methods by
$2.56\%$ under the $60\%$ uniform noise setting in CIFAR10. Our code is
available at this https URL.</p>
  </details>
</details>
<details>
  <summary>156. <b>标题：Symbolic Regression via Neural-Guided Genetic Programming Population  Seeding</b></summary>
  <p><b>编号</b>：[415]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00053</p>
  <p><b>作者</b>：T. Nathan Mundhenk,  Mikel Landajuela,  Ruben Glatt,  Claudio P. Santiago,  Daniel M. Faissol,  Brenden K. Petersen</p>
  <p><b>备注</b>：Accepted at the 35th Conference on Neural Information Processing Systems (NeurIPS 2021)</p>
  <p><b>关键词</b>：running many genetic programming generations without interdependence, discrete optimization problem generally believed, random restart genetic programming component, gradually learning better starting populations, 22 symbolic regression benchmark problems</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Symbolic regression is the process of identifying mathematical expressions
that fit observed output from a black-box process. It is a discrete
optimization problem generally believed to be NP-hard. Prior approaches to
solving the problem include neural-guided search (e.g. using reinforcement
learning) and genetic programming. In this work, we introduce a hybrid
neural-guided/genetic programming approach to symbolic regression and other
combinatorial optimization problems. We propose a neural-guided component used
to seed the starting population of a random restart genetic programming
component, gradually learning better starting populations. On a number of
common benchmark tasks to recover underlying expressions from a dataset, our
method recovers 65% more expressions than a recently published top-performing
model using the same experimental setup. We demonstrate that running many
genetic programming generations without interdependence on the neural-guided
component performs better for symbolic regression than alternative formulations
where the two are more strongly coupled. Finally, we introduce a new set of 22
symbolic regression benchmark problems with increased difficulty over existing
benchmarks. Source code is provided at
this http URL.</p>
  </details>
</details>
<details>
  <summary>157. <b>标题：On the Power of Edge Independent Graph Models</b></summary>
  <p><b>编号</b>：[417]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00048</p>
  <p><b>作者</b>：Sudhanshu Chanpuriya,  Cameron Musco,  Konstantinos Sotiropoulos,  Charalampos E. Tsourakakis</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：based graph generative models fail, edge independent random graph models, reconstructing many graph statistics, edge independent models, modern generative models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Why do many modern neural-network-based graph generative models fail to
reproduce typical real-world network characteristics, such as high triangle
density? In this work we study the limitations of edge independent random graph
models, in which each edge is added to the graph independently with some
probability. Such models include both the classic Erdös-Rényi and
stochastic block models, as well as modern generative models such as NetGAN,
variational graph autoencoders, and CELL. We prove that subject to a bounded
overlap condition, which ensures that the model does not simply memorize a
single graph, edge independent models are inherently limited in their ability
to generate graphs with high triangle and other subgraph densities. Notably,
such high densities are known to appear in real-world social networks and other
graphs. We complement our negative results with a simple generative model that
balances overlap and accuracy, performing comparably to more complex models in
reconstructing many graph statistics.</p>
  </details>
</details>
<details>
  <summary>158. <b>标题：Skyformer: Remodel Self-Attention with Gaussian Kernel and Nyström  Method</b></summary>
  <p><b>编号</b>：[420]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00035</p>
  <p><b>作者</b>：Yifan Chen,  Qi Zeng,  Heng Ji,  Yun Yang</p>
  <p><b>备注</b>：To appear in NeurIPS 2021</p>
  <p><b>关键词</b>：long range arena benchmark show, computational cost without sacrificing, requiring fewer computation resources, although kernel machines suffer, high computational cost</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Transformers are expensive to train due to the quadratic time and space
complexity in the self-attention mechanism. On the other hand, although kernel
machines suffer from the same computation bottleneck in pairwise dot products,
several approximation schemes have been successfully incorporated to
considerably reduce their computational cost without sacrificing too much
accuracy. In this work, we leverage the computation methods for kernel machines
to alleviate the high computational cost and introduce Skyformer, which
replaces the softmax structure with a Gaussian kernel to stabilize the model
training and adapts the Nyström method to a non-positive semidefinite matrix
to accelerate the computation. We further conduct theoretical analysis by
showing that the matrix approximation error of our proposed method is small in
the spectral norm. Experiments on Long Range Arena benchmark show that the
proposed method is sufficient in getting comparable or even better performance
than the full self-attention while requiring fewer computation resources.</p>
  </details>
</details>
<details>
  <summary>159. <b>标题：Federated Semi-Supervised Learning with Class Distribution Mismatch</b></summary>
  <p><b>编号</b>：[421]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00010</p>
  <p><b>作者</b>：Zhiguo Wang,  Xintong Wang,  Ruoyu Sun,  Tsung-Hui Chang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：introduce two proper regularization terms, }( 1 /\ sqrt, first formal convergence result, acquire complete data labels, many existing federated learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Many existing federated learning (FL) algorithms are designed for supervised
learning tasks, assuming that the local data owned by the clients are well
labeled. However, in many practical situations, it could be difficult and
expensive to acquire complete data labels. Federated semi-supervised learning
(Fed-SSL) is an attractive solution for fully utilizing both labeled and
unlabeled data. Similar to that encountered in federated supervised learning,
class distribution of labeled/unlabeled data could be non-i.i.d. among clients.
Besides, in each client, the class distribution of labeled data may be distinct
from that of unlabeled data. Unfortunately, both can severely jeopardize the FL
performance. To address such challenging issues, we introduce two proper
regularization terms that can effectively alleviate the class distribution
mismatch problem in Fed-SSL. In addition, to overcome the non-i.i.d. data, we
leverage the variance reduction and normalized averaging techniques to develop
a novel Fed-SSL algorithm. Theoretically, we prove that the proposed method has
a convergence rate of $\mathcal{O}(1/\sqrt{T})$, where $T$ is the number of
communication rounds, even when the data distribution are non-i.i.d. among
clients. To the best of our knowledge, it is the first formal convergence
result for Fed-SSL problems. Numerical experiments based on MNIST data and
CIFAR-10 data show that the proposed method can greatly improve the
classification accuracy compared to baselines.</p>
  </details>
</details>
<details>
  <summary>160. <b>标题：Domain Agnostic Few-Shot Learning For Document Intelligence</b></summary>
  <p><b>编号</b>：[423]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00007</p>
  <p><b>作者</b>：Jaya Krishna Mandivarapu,  Eric bunch,  Glenn fung</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：proposed method shows consistent improvements, shot document image classification, experimental results demonstrate, methods also aim, collecting large samples</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Few-shot learning aims to generalize to novel classes with only a few samples
with class labels. Research in few-shot learning has borrowed techniques from
transfer learning, metric learning, meta-learning, and Bayesian methods. These
methods also aim to train models from limited training samples, and while
encouraging performance has been achieved, they often fail to generalize to
novel domains. Many of the existing meta-learning methods rely on training data
for which the base classes are sampled from the same domain as the novel
classes used for meta-testing. However, in many applications in the industry,
such as document classification, collecting large samples of data for
meta-learning is infeasible or impossible. While research in the field of the
cross-domain few-shot learning exists, it is mostly limited to computer vision.
To our knowledge, no work yet exists that examines the use of few-shot learning
for classification of semi-structured documents (scans of paper documents)
generated as part of a business workflow (forms, letters, bills, etc.). Here
the domain shift is significant, going from natural images to the
semi-structured documents of interest. In this work, we address the problem of
few-shot document image classification under domain shift. We evaluate our work
by extensive comparisons with existing methods. Experimental results
demonstrate that the proposed method shows consistent improvements on the
few-shot classification performance under domain shift.</p>
  </details>
</details>
<details>
  <summary>161. <b>标题：Adaptive Hierarchical Similarity Metric Learning with Noisy Labels</b></summary>
  <p><b>编号</b>：[424]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00006</p>
  <p><b>作者</b>：Jiexi Yan,  Lei Luo,  Cheng Deng,  Heng Huang</p>
  <p><b>备注</b>：11 pages, 5 figures</p>
  <p><b>关键词</b>：noisy labels often cause severe performance degradation, effectively excavate richer similarity information beyond binary, adaptive hierarchical similarity metric learning method, existing deep metric learning methods, current deep metric learning approaches</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep Metric Learning (DML) plays a critical role in various machine learning
tasks. However, most existing deep metric learning methods with binary
similarity are sensitive to noisy labels, which are widely present in
real-world data. Since these noisy labels often cause severe performance
degradation, it is crucial to enhance the robustness and generalization ability
of DML. In this paper, we propose an Adaptive Hierarchical Similarity Metric
Learning method. It considers two noise-insensitive information, \textit{i.e.},
class-wise divergence and sample-wise consistency. Specifically, class-wise
divergence can effectively excavate richer similarity information beyond binary
in modeling by taking advantage of Hyperbolic metric learning, while
sample-wise consistency can further improve the generalization ability of the
model using contrastive augmentation. More importantly, we design an adaptive
strategy to integrate this information in a unified view. It is noteworthy that
the new method can be extended to any pair-based metric loss. Extensive
experimental results on benchmark datasets demonstrate that our method achieves
state-of-the-art performance compared with current deep metric learning
approaches.</p>
  </details>
</details>
<details>
  <summary>162. <b>标题：Earning Sans Learning: Noisy Decision-Making and Labor Supply on Gig  Economy Platforms</b></summary>
  <p><b>编号</b>：[428]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00002</p>
  <p><b>作者</b>：Daniel Freund,  Chamsi Hssaine</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：complex stochastic optimization problem whose natural fluid relaxation, consider captures two key, finding optimal compensation schemes, driven observations suggest may, asymptotically optimal amongst</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We study a gig economy platform's problem of finding optimal compensation
schemes when faced with workers who myopically base their participation
decisions on limited information with respect to their earnings. The stylized
model we consider captures two key, related features absent from prior work on
the operations of on-demand service platforms: (i) workers' lack of information
regarding the distribution from which their earnings are drawn and (ii) worker
decisions that are sensitive to variability in earnings. Despite its stylized
nature, our model induces a complex stochastic optimization problem whose
natural fluid relaxation is also a priori intractable. Nevertheless, we uncover
a surprising structural property of the relaxation that allows us to design a
tractable, fast-converging heuristic policy that is asymptotically optimal
amongst the space of all policies that fulfill a fairness property. In doing
so, via both theory and extensive simulations, we uncover phenomena that may
arise when earnings are volatile and hard to predict, as both the empirical
literature and our own data-driven observations suggest may be prevalent on gig
economy platforms.</p>
  </details>
</details>
<details>
  <summary>163. <b>标题：NOTMAD: Estimating Bayesian Networks with Sample-Specific Structures and  Parameters</b></summary>
  <p><b>编号</b>：[429]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.01104</p>
  <p><b>作者</b>：Ben Lengerich,  Caleb Ellington,  Bryon Aragam,  Eric P. Xing,  Manolis Kellis</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：graph generator functions )., specific gene expression networks, mix archetypal networks according, smooth regularization loss, limiting statistical power</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Context-specific Bayesian networks (i.e. directed acyclic graphs, DAGs)
identify context-dependent relationships between variables, but the
non-convexity induced by the acyclicity requirement makes it difficult to share
information between context-specific estimators (e.g. with graph generator
functions). For this reason, existing methods for inferring context-specific
Bayesian networks have favored breaking datasets into subsamples, limiting
statistical power and resolution, and preventing the use of multidimensional
and latent contexts. To overcome this challenge, we propose NOTEARS-optimized
Mixtures of Archetypal DAGs (NOTMAD). NOTMAD models context-specific Bayesian
networks as the output of a function which learns to mix archetypal networks
according to sample context. The archetypal networks are estimated jointly with
the context-specific networks and do not require any prior knowledge. We encode
the acyclicity constraint as a smooth regularization loss which is
back-propagated to the mixing function; in this way, NOTMAD shares information
between context-specific acyclic graphs, enabling the estimation of Bayesian
network structures and parameters at even single-sample resolution. We
demonstrate the utility of NOTMAD and sample-specific network inference through
analysis and experiments, including patient-specific gene expression networks
which correspond to morphological variation in cancer.</p>
  </details>
</details>
<details>
  <summary>164. <b>标题：STORM+: Fully Adaptive SGD with Momentum for Nonconvex Optimization</b></summary>
  <p><b>编号</b>：[433]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.01040</p>
  <p><b>作者</b>：Kfir Y. Levy,  Ali Kavis,  Volkan Cevher</p>
  <p><b>备注</b>：25 pages, 1 figure, accepted to NeurIPS 2021</p>
  <p><b>关键词</b>：method called storm crucially relies, challenging hyperparameter tuning problem, obtain tight convergence rates, propose storm +,, smooth loss functions</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this work we investigate stochastic non-convex optimization problems where
the objective is an expectation over smooth loss functions, and the goal is to
find an approximate stationary point. The most popular approach to handling
such problems is variance reduction techniques, which are also known to obtain
tight convergence rates, matching the lower bounds in this case. Nevertheless,
these techniques require a careful maintenance of anchor points in conjunction
with appropriately selected "mega-batchsizes". This leads to a challenging
hyperparameter tuning problem, that weakens their practicality. Recently,
[Cutkosky and Orabona, 2019] have shown that one can employ recursive momentum
in order to avoid the use of anchor points and large batchsizes, and still
obtain the optimal rate for this setting. Yet, their method called STORM
crucially relies on the knowledge of the smoothness, as well a bound on the
gradient norms. In this work we propose STORM+, a new method that is completely
parameter-free, does not require large batch-sizes, and obtains the optimal
$O(1/T^{1/3})$ rate for finding an approximate stationary point. Our work
builds on the STORM algorithm, in conjunction with a novel approach to
adaptively set the learning rate and momentum parameters.</p>
  </details>
</details>
<details>
  <summary>165. <b>标题：Interpretable and Explainable Machine Learning for Materials Science and  Chemistry</b></summary>
  <p><b>编号</b>：[434]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.01037</p>
  <p><b>作者</b>：Felipe Oviedo,  Juan Lavista Ferres,  Tonio Buonassisi,  Keith Butler</p>
  <p><b>备注</b>：Under review Accounts of Material Research</p>
  <p><b>关键词</b>：qualities beyond purely predictive power, unveiling unexpected correlations, successful scientific discovery, potential model issues, machine learning models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>While the uptake of data-driven approaches for materials science is at an
exciting, early stage, to realise the true potential of machine learning models
for successful scientific discovery, they must have qualities beyond purely
predictive power. The predictions and inner workings of models should provide a
certain degree of explainability by human experts, permitting the
identification of potential model issues or limitations, building trust on
model predictions and unveiling unexpected correlations that may lead to
scientific insights. In this work, we summarize applications of
interpretability and explainability techniques for materials science and
chemistry and discuss how these techniques can improve the outcome of
scientific studies.</p>
  </details>
</details>
<details>
  <summary>166. <b>标题：Fragment-based Sequential Translation for Molecular Optimization</b></summary>
  <p><b>编号</b>：[436]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.01009</p>
  <p><b>作者</b>：Benson Chen,  Xiang Fu,  Regina Barzilay,  Tommi Jaakkola</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：generates molecules using learned molecular fragments -- meaningful substructures, many existing frameworks generate molecules one atom, objective molecular optimization tasks, complex chemical property space, encode molecular fragments</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Searching for novel molecular compounds with desired properties is an
important problem in drug discovery. Many existing frameworks generate
molecules one atom at a time. We instead propose a flexible editing paradigm
that generates molecules using learned molecular fragments--meaningful
substructures of molecules. To do so, we train a variational autoencoder (VAE)
to encode molecular fragments in a coherent latent space, which we then utilize
as a vocabulary for editing molecules to explore the complex chemical property
space. Equipped with the learned fragment vocabulary, we propose Fragment-based
Sequential Translation (FaST), which learns a reinforcement learning (RL)
policy to iteratively translate model-discovered molecules into increasingly
novel molecules while satisfying desired properties. Empirical evaluation shows
that FaST significantly improves over state-of-the-art methods on benchmark
single/multi-objective molecular optimization tasks.</p>
  </details>
</details>
<details>
  <summary>167. <b>标题：Modelling the transition to a low-carbon energy supply</b></summary>
  <p><b>编号</b>：[438]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00987</p>
  <p><b>作者</b>：Alexander Kell</p>
  <p><b>备注</b>：PhD thesis</p>
  <p><b>关键词</b>：reducing carbon emissions could help prevent, runaway emissions could lead, whole electricity market reacts, different factors using state, reliable energy supply</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A transition to a low-carbon electricity supply is crucial to limit the
impacts of climate change. Reducing carbon emissions could help prevent the
world from reaching a tipping point, where runaway emissions are likely.
Runaway emissions could lead to extremes in weather conditions around the world
-- especially in problematic regions unable to cope with these conditions.
However, the movement to a low-carbon energy supply can not happen
instantaneously due to the existing fossil-fuel infrastructure and the
requirement to maintain a reliable energy supply. Therefore, a low-carbon
transition is required, however, the decisions various stakeholders should make
over the coming decades to reduce these carbon emissions are not obvious. This
is due to many long-term uncertainties, such as electricity, fuel and
generation costs, human behaviour and the size of electricity demand. A well
choreographed low-carbon transition is, therefore, required between all of the
heterogenous actors in the system, as opposed to changing the behaviour of a
single, centralised actor. The objective of this thesis is to create a novel,
open-source agent-based model to better understand the manner in which the
whole electricity market reacts to different factors using state-of-the-art
machine learning and artificial intelligence methods. In contrast to other
works, this thesis looks at both the long-term and short-term impact that
different behaviours have on the electricity market by using these
state-of-the-art methods.</p>
  </details>
</details>
<details>
  <summary>168. <b>标题：Robustness of deep learning algorithms in astronomy -- galaxy morphology  studies</b></summary>
  <p><b>编号</b>：[440]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00961</p>
  <p><b>作者</b>：A. Ćiprijanović,  D. Kafkes,  G. N. Perdue,  K. Pedro,  G. Snyder,  F. J. Sánchez,  S. Madireddy,  S. M. Wild,  B. Nord</p>
  <p><b>备注</b>：Accepted in: Fourth Workshop on Machine Learning and the Physical Sciences (35th Conference on Neural Information Processing Systems; NeurIPS2021); final version</p>
  <p><b>关键词</b>：help improve model robustness, help scientists build, naturally occurring attacks, domain adaptation techniques, common image processing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep learning models are being increasingly adopted in wide array of
scientific domains, especially to handle high-dimensionality and volume of the
scientific data. However, these models tend to be brittle due to their
complexity and overparametrization, especially to the inadvertent adversarial
perturbations that can appear due to common image processing such as
compression or blurring that are often seen with real scientific data. It is
crucial to understand this brittleness and develop models robust to these
adversarial perturbations. To this end, we study the effect of observational
noise from the exposure time, as well as the worst case scenario of a one-pixel
attack as a proxy for compression or telescope errors on performance of
ResNet18 trained to distinguish between galaxies of different morphologies in
LSST mock data. We also explore how domain adaptation techniques can help
improve model robustness in case of this type of naturally occurring attacks
and help scientists build more trustworthy and stable models.</p>
  </details>
</details>
<details>
  <summary>169. <b>标题：PCA-based Multi Task Learning: a Random Matrix Approach</b></summary>
  <p><b>编号</b>：[442]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00924</p>
  <p><b>作者</b>：Malik Tiomoko,  Romain Couillet,  Frédéric Pascal</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：pca )- based supervised learning schemes, proposed method achieves comparable performance, default learning may dramatically fail, significantly reduced computational cost }., data labels avert negative transfer</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The article proposes and theoretically analyses a \emph{computationally
efficient} multi-task learning (MTL) extension of popular principal component
analysis (PCA)-based supervised learning schemes
\cite{barshan2011supervised,bair2006prediction}. The analysis reveals that (i)
by default learning may dramatically fail by suffering from \emph{negative
transfer}, but that (ii) simple counter-measures on data labels avert negative
transfer and necessarily result in improved performances.
Supporting experiments on synthetic and real data benchmarks show that the
proposed method achieves comparable performance with state-of-the-art MTL
methods but at a \emph{significantly reduced computational cost}.</p>
  </details>
</details>
<details>
  <summary>170. <b>标题：A multi-task learning-based optimization approach for finding diverse  sets of material microstructures with desired properties and its application  to texture optimization</b></summary>
  <p><b>编号</b>：[443]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00916</p>
  <p><b>作者</b>：Tarek Iraki,  Lukas Morand,  Johannes Dornheim,  Norbert Link,  Dirk Helm</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：rolled steel sheets given desired properties, lower dimensional latent feature space, distance preserving microstructure feature extraction, crystallographic texture optimization problem, given desired properties</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The optimization along the chain processing-structure-properties-performance
is one of the core objectives in data-driven materials science. In this sense,
processes are supposed to manufacture workpieces with targeted material
microstructures. These microstructures are defined by the material properties
of interest and identifying them is a question of materials design. In the
present paper, we addresse this issue and introduce a generic multi-task
learning-based optimization approach. The approach enables the identification
of sets of highly diverse microstructures for given desired properties and
corresponding tolerances. Basically, the approach consists of an optimization
algorithm that interacts with a machine learning model that combines multi-task
learning with siamese neural networks. The resulting model (1) relates
microstructures and properties, (2) estimates the likelihood of a
microstructure of being producible, and (3) performs a distance preserving
microstructure feature extraction in order to generate a lower dimensional
latent feature space to enable efficient optimization. The proposed approach is
applied on a crystallographic texture optimization problem for rolled steel
sheets given desired properties.</p>
  </details>
</details>
<details>
  <summary>171. <b>标题：Free Probability, Newton lilypads and Jacobians of neural networks</b></summary>
  <p><b>编号</b>：[445]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00841</p>
  <p><b>作者</b>：Reda Chhaibi,  Tariq Daouda,  Ezechiel Kahn</p>
  <p><b>备注</b>：22 pages, 4 figures</p>
  <p><b>关键词</b>：newton algorithm finds contiguous lilypad, modeled using free multiplicative convolutions, pennington et al .,, free probability theory, free probability metrics</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Gradient descent during the learning process of a neural network can be
subject to many instabilities. The spectral density of the Jacobian is a key
component for analyzing robustness. Following the works of Pennington et al.,
such Jacobians are modeled using free multiplicative convolutions from Free
Probability Theory. We present a reliable and very fast method for computing
the associated spectral densities. This method has a controlled and proven
convergence.
Our technique is based on an adaptative Newton-Raphson scheme, by finding and
chaining basins of attraction: the Newton algorithm finds contiguous
lilypad-like basins and steps from one to the next, heading towards the
objective.
We demonstrate the applicability of our method by using it to assess how the
learning process is affected by network depth, layer widths and initialization
choices: empirically, final test losses are very correlated to our Free
Probability metrics.</p>
  </details>
</details>
<details>
  <summary>172. <b>标题：Swift sky localization of gravitational waves using deep learning seeded  importance sampling</b></summary>
  <p><b>编号</b>：[447]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00833</p>
  <p><b>作者</b>：Alex Kolmus,  Grégory Baltus,  Justin Janquart,  Twan van Laarhoven,  Sarah Caudill,  Tom Heskes</p>
  <p><b>备注</b>：12 pages, 9 figures, 1 table</p>
  <p><b>关键词</b>：highly resemble predictions generated using bayesian inference, gravitational waves would enable real, given simulated gravitational wave injections, neural network parametrizes von mises, current bayesian inference methodologies</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Fast, highly accurate, and reliable inference of the sky origin of
gravitational waves would enable real-time multi-messenger astronomy. Current
Bayesian inference methodologies, although highly accurate and reliable, are
slow. Deep learning models have shown themselves to be accurate and extremely
fast for inference tasks on gravitational waves, but their output is inherently
questionable due to the blackbox nature of neural networks. In this work, we
join Bayesian inference and deep learning by applying importance sampling on an
approximate posterior generated by a multi-headed convolutional neural network.
The neural network parametrizes Von Mises-Fisher and Gaussian distributions for
the sky coordinates and two masses for given simulated gravitational wave
injections in the LIGO and Virgo detectors. We generate skymaps for unseen
gravitational-wave events that highly resemble predictions generated using
Bayesian inference in a few minutes. Furthermore, we can detect poor
predictions from the neural network, and quickly flag them.</p>
  </details>
</details>
<details>
  <summary>173. <b>标题：Dynamic Pricing and Demand Learning on a Large Network of Products: A  PAC-Bayesian Approach</b></summary>
  <p><b>编号</b>：[449]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00790</p>
  <p><b>作者</b>：Bora Keskin,  David Simchi-Levi,  Prem Talwai</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：policy achieves asymptotically optimal performance, study three different sparsity frameworks, expected revenue loss relative, characterize various connectivity properties, dynamically adjust product prices</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We consider a seller offering a large network of $N$ products over a time
horizon of $T$ periods. The seller does not know the parameters of the
products' linear demand model, and can dynamically adjust product prices to
learn the demand model based on sales observations. The seller aims to minimize
its pseudo-regret, i.e., the expected revenue loss relative to a clairvoyant
who knows the underlying demand model. We consider a sparse set of demand
relationships between products to characterize various connectivity properties
of the product network. In particular, we study three different sparsity
frameworks: (1) $L_0$ sparsity, which constrains the number of connections in
the network, and (2) off-diagonal sparsity, which constrains the magnitude of
cross-product price sensitivities, and (3) a new notion of spectral sparsity,
which constrains the asymptotic decay of a similarity metric on network nodes.
We propose a dynamic pricing-and-learning policy that combines the
optimism-in-the-face-of-uncertainty and PAC-Bayesian approaches, and show that
this policy achieves asymptotically optimal performance in terms of $N$ and
$T$. We also show that in the case of spectral and off-diagonal sparsity, the
seller can have a pseudo-regret linear in $N$, even when the network is dense.</p>
  </details>
</details>
<details>
  <summary>174. <b>标题：Uncertainty quantification for ptychography using normalizing flows</b></summary>
  <p><b>编号</b>：[452]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00745</p>
  <p><b>作者</b>：Agnimitra Dasgupta,  Zichao Wendy Di</p>
  <p><b>备注</b>：Accepted at the Fourth Workshop on Machine Learning for Physical Sciences, NeurIPS 2021</p>
  <p><b>关键词</b>：intrinsic photon statistics create clear opportunities, various physical experimental settings, guiding future experiments using, based deep learning approaches, spotting spurious artifacts</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Ptychography, as an essential tool for high-resolution and nondestructive
material characterization, presents a challenging large-scale nonlinear and
non-convex inverse problem; however, its intrinsic photon statistics create
clear opportunities for statistical-based deep learning approaches to tackle
these challenges, which has been underexplored. In this work, we explore
normalizing flows to obtain a surrogate for the high-dimensional posterior,
which also enables the characterization of the uncertainty associated with the
reconstruction: an extremely desirable capability when judging the
reconstruction quality in the absence of ground truth, spotting spurious
artifacts and guiding future experiments using the returned uncertainty
patterns. We demonstrate the performance of the proposed method on a synthetic
sample with added noise and in various physical experimental settings.</p>
  </details>
</details>
<details>
  <summary>175. <b>标题：Learning linear non-Gaussian directed acyclic graph with diverging  number of nodes</b></summary>
  <p><b>编号</b>：[454]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00740</p>
  <p><b>作者</b>：Ruixuan Zhao,  Xin He,  Junhui Wang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：represent directional causal relations among collected nodes, existing dag learning methods assuming gaussian noise, child relations among nodes, attain exact dag recovery, various simulated examples</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Acyclic model, often depicted as a directed acyclic graph (DAG), has been
widely employed to represent directional causal relations among collected
nodes. In this article, we propose an efficient method to learn linear
non-Gaussian DAG in high dimensional cases, where the noises can be of any
continuous non-Gaussian distribution. This is in sharp contrast to most
existing DAG learning methods assuming Gaussian noise with additional variance
assumptions to attain exact DAG recovery. The proposed method leverages a novel
concept of topological layer to facilitate the DAG learning. Particularly, we
show that the topological layers can be exactly reconstructed in a bottom-up
fashion, and the parent-child relations among nodes in each layer can also be
consistently established. More importantly, the proposed method does not
require the faithfulness or parental faithfulness assumption which has been
widely assumed in the literature of DAG learning. Its advantage is also
supported by the numerical comparison against some popular competitors in
various simulated examples as well as a real application on the global spread
of COVID-19.</p>
  </details>
</details>
<details>
  <summary>176. <b>标题：Influential Prototypical Networks for Few Shot Learning: A  Dermatological Case Study</b></summary>
  <p><b>编号</b>：[455]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00698</p>
  <p><b>作者</b>：Ranjana Roy Chowdhury,  Deepti R. Bathula</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：three different benchmark dermatological datasets, conventional pn attributes equal importance, support sample embeddings belonging, support sample distribution, simple yet effective</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Prototypical network (PN) is a simple yet effective few shot learning
strategy. It is a metric-based meta-learning technique where classification is
performed by computing Euclidean distances to prototypical representations of
each class. Conventional PN attributes equal importance to all samples and
generates prototypes by simply averaging the support sample embeddings
belonging to each class. In this work, we propose a novel version of PN that
attributes weights to support samples corresponding to their influence on the
support sample distribution. Influence weights of samples are calculated based
on maximum mean discrepancy (MMD) between the mean embeddings of sample
distributions including and excluding the sample. Comprehensive evaluation of
our proposed influential PN (IPNet) is performed by comparing its performance
with other baseline PNs on three different benchmark dermatological datasets.
IPNet outperforms all baseline models with compelling results across all three
datasets and various N-way, K-shot classification tasks. Findings from
cross-domain adaptation experiments further establish the robustness and
generalizability of IPNet.</p>
  </details>
</details>
<details>
  <summary>177. <b>标题：End-to-End Learning of Deep Kernel Acquisition Functions for Bayesian  Optimization</b></summary>
  <p><b>编号</b>：[457]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00639</p>
  <p><b>作者</b>：Tomoharu Iwata</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：experiments using three text document datasets, proposed method achieves better bo performance, existing methods train neural networks, learn flexible surrogate functions, shared across different tasks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>For Bayesian optimization (BO) on high-dimensional data with complex
structure, neural network-based kernels for Gaussian processes (GPs) have been
used to learn flexible surrogate functions by the high representation power of
deep learning. However, existing methods train neural networks by maximizing
the marginal likelihood, which do not directly improve the BO performance. In
this paper, we propose a meta-learning method for BO with neural network-based
kernels that minimizes the expected gap between the true optimum value and the
best value found by BO. We model a policy, which takes the current evaluated
data points as input and outputs the next data point to be evaluated, by a
neural network, where neural network-based kernels, GPs, and mutual
information-based acquisition functions are used as its layers. With our model,
the neural network-based kernel is trained to be appropriate for the
acquisition function by backpropagating the gap through the acquisition
function and GP. Our model is trained by a reinforcement learning framework
from multiple tasks. Since the neural network is shared across different tasks,
we can gather knowledge on BO from multiple training tasks, and use the
knowledge for unseen test tasks. In experiments using three text document
datasets, we demonstrate that the proposed method achieves better BO
performance than the existing methods.</p>
  </details>
</details>
<details>
  <summary>178. <b>标题：Laplacian Constrained Precision Matrix Estimation: Existence and High  Dimensional Consistency</b></summary>
  <p><b>编号</b>：[460]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00590</p>
  <p><b>作者</b>：Eduardo Pavez</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：estimating high dimensional laplacian constrained precision matrices, certain data dependent graph, high dimensional setting, high dimensional consistency, proofs exploit properties</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper considers the problem of estimating high dimensional Laplacian
constrained precision matrices by minimizing Stein's loss. We obtain a
necessary and sufficient condition for existence of this estimator, that boils
down to checking whether a certain data dependent graph is connected. We also
prove consistency in the high dimensional setting under the symmetryzed Stein
loss. We show that the error rate does not depend on the graph sparsity, or
other type of structure, and that Laplacian constraints are sufficient for high
dimensional consistency. Our proofs exploit properties of graph Laplacians, and
a characterization of the proposed estimator based on effective graph
resistances. We validate our theoretical claims with numerical experiments.</p>
  </details>
</details>
<details>
  <summary>179. <b>标题：IGCN: Image-to-graph Convolutional Network for 2D/3D Deformable  Registration</b></summary>
  <p><b>编号</b>：[468]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00484</p>
  <p><b>作者</b>：Megumi Nakao,  Mitsuhiro Nakamura,  Tetsuya Matsuda</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：experimental results show shape prediction considering relationships among multiple organs, organ shape reconstruction based, multiple abdominal organs, framework enables simultaneous training, 3d deformable registration performance</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Organ shape reconstruction based on a single-projection image during
treatment has wide clinical scope, e.g., in image-guided radiotherapy and
surgical guidance. We propose an image-to-graph convolutional network that
achieves deformable registration of a 3D organ mesh for a single-viewpoint 2D
projection image. This framework enables simultaneous training of two types of
transformation: from the 2D projection image to a displacement map, and from
the sampled per-vertex feature to a 3D displacement that satisfies the
geometrical constraint of the mesh structure. Assuming application to radiation
therapy, the 2D/3D deformable registration performance is verified for multiple
abdominal organs that have not been targeted to date, i.e., the liver, stomach,
duodenum, and kidney, and for pancreatic cancer. The experimental results show
shape prediction considering relationships among multiple organs can be used to
predict respiratory motion and deformation from digitally reconstructed
radiographs with clinically acceptable accuracy.</p>
  </details>
</details>
<details>
  <summary>180. <b>标题：Multi-Task Learning based Convolutional Models with Curriculum Learning  for the Anisotropic Reynolds Stress Tensor in Turbulent Duct Flow</b></summary>
  <p><b>编号</b>：[474]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00328</p>
  <p><b>作者</b>：Haitz Sáez de Ocáriz Borde,  David Sondak,  Pavlos Protopapas</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：build upon recent convolutional neural network architectures used, task learning based fully convolutional neural network, started using machine learning approaches, normalized anisotropic reynolds stress tensor, anisotropic reynolds stress tensor</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The Reynolds-averaged Navier-Stokes (RANS) equations require accurate
modeling of the anisotropic Reynolds stress tensor, for which traditional
closure models only give good results in certain flow configurations.
Researchers have started using machine learning approaches to address this
problem. In this work we build upon recent convolutional neural network
architectures used for turbulence modeling and propose a multi-task learning
based fully convolutional neural network that is able to accurately predict the
normalized anisotropic Reynolds stress tensor for turbulent duct flow.
Furthermore, we also explore the application of curriculum learning to
data-driven turbulence modeling.</p>
  </details>
</details>
<details>
  <summary>181. <b>标题：Speaker conditioning of acoustic models using affine transformation for  multi-speaker speech recognition</b></summary>
  <p><b>编号</b>：[475]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00320</p>
  <p><b>作者</b>：Midia Yousefi,  John H.L. Hanse</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：original resnet acoustic model baseline, speaker conditioning process allows, channel automatic speech recognition, fuse speaker auxiliary information, proposed speaker conditioning method</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This study addresses the problem of single-channel Automatic Speech
Recognition of a target speaker within an overlap speech scenario. In the
proposed method, the hidden representations in the acoustic model are modulated
by speaker auxiliary information to recognize only the desired speaker. Affine
transformation layers are inserted into the acoustic model network to integrate
speaker information with the acoustic features. The speaker conditioning
process allows the acoustic model to perform computation in the context of
target-speaker auxiliary information. The proposed speaker conditioning method
is a general approach and can be applied to any acoustic model architecture.
Here, we employ speaker conditioning on a ResNet acoustic model. Experiments on
the WSJ corpus show that the proposed speaker conditioning method is an
effective solution to fuse speaker auxiliary information with acoustic features
for multi-speaker speech recognition, achieving +9% and +20% relative WER
reduction for clean and overlap speech scenarios, respectively, compared to the
original ResNet acoustic model baseline.</p>
  </details>
</details>
<details>
  <summary>182. <b>标题：Real-time Speaker counting in a cocktail party scenario using  Attention-guided Convolutional Neural Network</b></summary>
  <p><b>编号</b>：[476]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00316</p>
  <p><b>作者</b>：Midia Yousefi,  John H.L. Hansen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：compact feature vector without losing critical information, simulated overlapping speech using wsj corpus show, e ., 200 ms )., e ., 1s )., speech spectral content using</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Most current speech technology systems are designed to operate well even in
the presence of multiple active speakers. However, most solutions assume that
the number of co-current speakers is known. Unfortunately, this information
might not always be available in real-world applications. In this study, we
propose a real-time, single-channel attention-guided Convolutional Neural
Network (CNN) to estimate the number of active speakers in overlapping speech.
The proposed system extracts higher-level information from the speech spectral
content using a CNN model. Next, the attention mechanism summarizes the
extracted information into a compact feature vector without losing critical
information. Finally, the active speakers are classified using a fully
connected network. Experiments on simulated overlapping speech using WSJ corpus
show that the attention solution is shown to improve the performance by almost
3% absolute over conventional temporal average pooling. The proposed
Attention-guided CNN achieves 76.15% for both Weighted Accuracy and average
Recall, and 75.80% Precision on speech segments as short as 20 frames (i.e.,
200 ms). All the classification metrics exceed 92% for the attention-guided
model in offline scenarios where the input signal is more than 100 frames long
(i.e., 1s).</p>
  </details>
</details>
<details>
  <summary>183. <b>标题：Unpaired Learning for High Dynamic Range Image Tone Mapping</b></summary>
  <p><b>编号</b>：[480]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00219</p>
  <p><b>作者</b>：Yael Vinker,  Inbar Huberman-Spiegelglas,  Raanan Fattal</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：level attributes native ldr possess, unpaired adversarial training based, different image fidelity indices, producing low dynamic range, producing training data</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>High dynamic range (HDR) photography is becoming increasingly popular and
available by DSLR and mobile-phone cameras. While deep neural networks (DNN)
have greatly impacted other domains of image manipulation, their use for HDR
tone-mapping is limited due to the lack of a definite notion of ground-truth
solution, which is needed for producing training data.
In this paper we describe a new tone-mapping approach guided by the distinct
goal of producing low dynamic range (LDR) renditions that best reproduce the
visual characteristics of native LDR images. This goal enables the use of an
unpaired adversarial training based on unrelated sets of HDR and LDR images,
both of which are widely available and easy to acquire.
In order to achieve an effective training under this minimal requirements, we
introduce the following new steps and components: (i) a range-normalizing
pre-process which estimates and applies a different level of curve-based
compression, (ii) a loss that preserves the input content while allowing the
network to achieve its goal, and (iii) the use of a more concise discriminator
network, designed to promote the reproduction of low-level attributes native
LDR possess.
Evaluation of the resulting network demonstrates its ability to produce
photo-realistic artifact-free tone-mapped images, and state-of-the-art
performance on different image fidelity indices and visual distances.</p>
  </details>
</details>
<details>
  <summary>184. <b>标题：Efficient Inference Without Trading-off Regret in Bandits: An Allocation  Probability Test for Thompson Sampling</b></summary>
  <p><b>编号</b>：[483]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00137</p>
  <p><b>作者</b>：Nina Deliu,  Joseph J. Williams,  Sofia S. Villar</p>
  <p><b>备注</b>：32 pages including supplementary material</p>
  <p><b>关键词</b>：g ., biased estimators, large experiments generally follow, require large sample sizes, challenges typically impose restrictions, conduct adaptive randomised experiments</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Using bandit algorithms to conduct adaptive randomised experiments can
minimise regret, but it poses major challenges for statistical inference (e.g.,
biased estimators, inflated type-I error and reduced power). Recent attempts to
address these challenges typically impose restrictions on the exploitative
nature of the bandit algorithm$-$trading off regret$-$and require large sample
sizes to ensure asymptotic guarantees. However, large experiments generally
follow a successful pilot study, which is tightly constrained in its size or
duration. Increasing power in such small pilot experiments, without limiting
the adaptive nature of the algorithm, can allow promising interventions to
reach a larger experimental phase. In this work we introduce a novel hypothesis
test, uniquely based on the allocation probabilities of the bandit algorithm,
and without constraining its exploitative nature or requiring a minimum
experimental size. We characterise our $Allocation\ Probability\ Test$ when
applied to $Thompson\ Sampling$, presenting its asymptotic theoretical
properties, and illustrating its finite-sample performances compared to
state-of-the-art approaches. We demonstrate the regret and inferential
advantages of our approach, particularly in small samples, in both extensive
simulations and in a real-world experiment on mental health aspects.</p>
  </details>
</details>
<details>
  <summary>185. <b>标题：High-dimensional multi-trait GWAS by reverse prediction of genotypes</b></summary>
  <p><b>编号</b>：[485]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00108</p>
  <p><b>作者</b>：Muhammad Ammar Malik,  Adriaan-Alexander Ludl,  Tom Michoel</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：analyzed different machine learning methods, root mean squared error, model feature coefficients correlated, truth transcriptional regulatory networks, complementary findings across methods</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Multi-trait genome-wide association studies (GWAS) use multi-variate
statistical methods to identify associations between genetic variants and
multiple correlated traits simultaneously, and have higher statistical power
than independent univariate analysis of traits. Reverse regression, where
genotypes of genetic variants are regressed on multiple traits simultaneously,
has emerged as a promising approach to perform multi-trait GWAS in
high-dimensional settings where the number of traits exceeds the number of
samples. We extended this approach and analyzed different machine learning
methods (ridge regression, random forests and support vector machines)for
reverse regression in multi-trait GWAS, using genotypes, gene expression data
and ground-truth transcriptional regulatory networks from the DREAM5 SysGen
Challenge and from a cross between two yeast strains to evaluate methods. We
found that genotype prediction performance, in terms of root mean squared error
(RMSE), allowed to distinguish between genomic regions with high and low
transcriptional activity. Moreover, model feature coefficients correlated with
the strength of association between variants and individual traits, and were
predictive of true trans-eQTL target genes, with complementary findings across
methods.</p>
  </details>
</details>
<details>
  <summary>186. <b>标题：DeepDoseNet: A Deep Learning model for 3D Dose Prediction in Radiation  Therapy</b></summary>
  <p><b>编号</b>：[487]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00077</p>
  <p><b>作者</b>：Mumtaz Hussain Soomro,  Victor Gabriel Leandro Alves,  Hamidreza Nourzadeh,  Jeffrey V. Siebers</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：d99 %, d95 %, d1, d99 %, d95 %, d1, deepdosenet 3d dose prediction model based, predicted 3d dose distributions, 2020 aapm openkbp challenge</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The DeepDoseNet 3D dose prediction model based on ResNet and Dilated DenseNet
is proposed. The 340 head-and-neck datasets from the 2020 AAPM OpenKBP
challenge were utilized, with 200 for training, 40 for validation, and 100 for
testing. Structures include 56Gy, 63Gy, 70Gy PTVs, and brainstem, spinal cord,
right parotid, left parotid, larynx, esophagus, and mandible OARs. Mean squared
error (MSE) loss, mean absolute error (MAE) loss, and MAE plus dose-volume
histogram (DVH) based loss functions were investigated. Each model's
performance was compared using a 3D dose score, $\bar{S_{D}}$, (mean absolute
difference between ground truth and predicted 3D dose distributions) and a DVH
score, $\bar{S_{DVH}}$ (mean absolute difference between ground truth and
predicted dose-volume metrics).Furthermore, DVH metrics Mean[Gy] and D0.1cc
[Gy] for OARs and D99%, D95%, D1% for PTVs were computed. DeepDoseNet with the
MAE plus DVH-based loss function had the best dose score performance of the
OpenKBP entries. MAE+DVH model had the lowest prediction error (P<0.0001, wilcoxon test) on validation and test datasets (validation: $\bar{s_{d}}$="2.3Gy," $\bar{s_{dvh}}$="1.9Gy;" test: followed by the mae model mse had highest prediction error no significant difference was found among models in terms of mean [gy], but mae+dvh significantly outperformed d0.1cc[gy], particularly for mandible parotids both (p<0.01) (p<0.0001) datasets. d99%, d95%, d1% targets. reduced ~60% ~70%.< p>
  </0.0001,></p></details>
</details>
<details>
  <summary>187. <b>标题：Robust and efficient change point detection using novel multivariate  rank-energy GoF test</b></summary>
  <p><b>编号</b>：[488]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00047</p>
  <p><b>作者</b>：Shoaib Bin Masud,  Shuchin Aeron</p>
  <p><b>备注</b>：6 pages, 1 figure</p>
  <p><b>关键词</b>：new gof test statistic called, proposed sre based cpd outperforms, unsupervised change point detection, requires large sample complexity, multivariate time series data</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we use and further develop upon a recently proposed
multivariate, distribution-free Goodness-of-Fit (GoF) test based on the theory
of Optimal Transport (OT) called the Rank Energy (RE) [1], for non-parametric
and unsupervised Change Point Detection (CPD) in multivariate time series data.
We show that directly using RE leads to high sensitivity to very small changes
in distributions (causing high false alarms) and it requires large sample
complexity and huge computational cost. To alleviate these drawbacks, we
propose a new GoF test statistic called as soft-Rank Energy (sRE) that is based
on entropy regularized OT and employ it towards CPD. We discuss the advantages
of using sRE over RE and demonstrate that the proposed sRE based CPD
outperforms all the existing methods in terms of Area Under the Curve (AUC) and
F1-score on real and synthetic data sets.</p>
  </details>
</details>
<details>
  <summary>188. <b>标题：Learning generative models for valid knockoffs using novel  multivariate-rank based statistics</b></summary>
  <p><b>编号</b>：[489]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00043</p>
  <p><b>作者</b>：Shoaib Bin Masud,  Shuchin Aeron</p>
  <p><b>备注</b>：23 pages, 9 figures</p>
  <p><b>关键词</b>：provides provable false discovery rate guarantees, detection power vs false discoveries, derived using theoretical results characterizing, soft rank maximum mean discrepancy, show via extensive evaluation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We consider the problem of generating valid knockoffs for knockoff filtering
which is a statistical method that provides provable false discovery rate
guarantees for any model selection procedure. To this end, we are motivated by
recent advances in multivariate distribution-free goodness-of-fit tests namely,
the rank energy (RE), that is derived using theoretical results characterizing
the optimal maps in the Monge's Optimal Transport (OT) problem. However, direct
use of use RE for learning generative models is not feasible because of its
high computational and sample complexity, saturation under large support
discrepancy between distributions, and non-differentiability in generative
parameters. To alleviate these, we begin by proposing a variant of the RE,
dubbed as soft rank energy (sRE), and its kernel variant called as soft rank
maximum mean discrepancy (sRMMD) using entropic regularization of Monge's OT
problem. We then use sRMMD to generate deep knockoffs and show via extensive
evaluation that it is a novel and effective method to produce valid knockoffs,
achieving comparable, or in some cases improved tradeoffs between detection
power Vs false discoveries.</p>
  </details>
</details>
<details>
  <summary>189. <b>标题：Real-time detection of anomalies in large-scale transient surveys</b></summary>
  <p><b>编号</b>：[490]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00036</p>
  <p><b>作者</b>：Daniel Muthukrishna,  Kaisey S. Mandel,  Michelle Lochner,  Sara Webb,  Gautham Narayan</p>
  <p><b>备注</b>：25 pages, 21 figures, submitted to MNRAS</p>
  <p><b>关键词</b>：probabilistic neural network built using temporal convolutional networks, high true anomaly rates achieving area, automatically detecting anomalous transient light curves, low false anomaly rates, rubin observatory legacy survey</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>New time-domain surveys, such as the Rubin Observatory Legacy Survey of Space
and Time (LSST), will observe millions of transient alerts each night, making
standard approaches of visually identifying new and interesting transients
infeasible. We present two novel methods of automatically detecting anomalous
transient light curves in real-time. Both methods are based on the simple idea
that if the light curves from a known population of transients can be
accurately modelled, any deviations from model predictions are likely
anomalies. The first modelling approach is a probabilistic neural network built
using Temporal Convolutional Networks (TCNs) and the second is an interpretable
Bayesian parametric model of a transient. We demonstrate our methods' ability
to provide anomaly scores as a function of time on light curves from the Zwicky
Transient Facility. We show that the flexibility of neural networks, the
attribute that makes them such a powerful tool for many regression tasks, is
what makes them less suitable for anomaly detection when compared with our
parametric model. The parametric model is able to identify anomalies with
respect to common supernova classes with low false anomaly rates and high true
anomaly rates achieving Area Under the Receive Operating Characteristic (ROC)
Curve (AUC) scores above 0.8 for most rare classes such as kilonovae, tidal
disruption events, intermediate luminosity transients, and pair-instability
supernovae. Our ability to identify anomalies improves over the lifetime of the
light curves. Our framework, used in conjunction with transient classifiers,
will enable fast and prioritised follow-up of unusual transients from new
large-scale surveys.</p>
  </details>
</details>
<details>
  <summary>190. <b>标题：Neural Networks as Kernel Learners: The Silent Alignment Effect</b></summary>
  <p><b>编号</b>：[491]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00034</p>
  <p><b>作者</b>：Alexander Atanasov,  Blake Bordelon,  Cengiz Pehlevan</p>
  <p><b>备注</b>：24 pages, 13 figures</p>
  <p><b>关键词</b>：rich feature learning regime learn, lazy training regime converge, relative learning rates, early spectral learning, term silent alignment</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Neural networks in the lazy training regime converge to kernel machines. Can
neural networks in the rich feature learning regime learn a kernel machine with
a data-dependent kernel? We demonstrate that this can indeed happen due to a
phenomenon we term silent alignment, which requires that the tangent kernel of
a network evolves in eigenstructure while small and before the loss appreciably
decreases, and grows only in overall scale afterwards. We show that such an
effect takes place in homogenous neural networks with small initialization and
whitened data. We provide an analytical treatment of this effect in the linear
network case. In general, we find that the kernel develops a low-rank
contribution in the early phase of training, and then evolves in overall scale,
yielding a function equivalent to a kernel regression solution with the final
network's tangent kernel. The early spectral learning of the kernel depends on
both depth and on relative learning rates in each layer. We also demonstrate
that non-whitened data can weaken the silent alignment effect.</p>
  </details>
</details>
<details>
  <summary>191. <b>标题：Revisiting joint decoding based multi-talker speech recognition with DNN  acoustic model</b></summary>
  <p><b>编号</b>：[493]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00009</p>
  <p><b>作者</b>：Martin Kocour,  Kateřina Žmolíková,  Lucas Ondel,  Ján Švec,  Marc Delcroix,  Tsubasa Ochiai,  Lukáš Burget,  Jan Černocký</p>
  <p><b>备注</b>：submitted to ICASSP 2022</p>
  <p><b>关键词</b>：based acoustic model predicts senone state posteriors, predict joint state posteriors, specific output stream separately, provides greater modeling power, talker speech recognition systems</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In typical multi-talker speech recognition systems, a neural network-based
acoustic model predicts senone state posteriors for each speaker. These are
later used by a single-talker decoder which is applied on each speaker-specific
output stream separately. In this work, we argue that such a scheme is
sub-optimal and propose a principled solution that decodes all speakers
jointly. We modify the acoustic model to predict joint state posteriors for all
speakers, enabling the network to express uncertainty about the attribution of
parts of the speech signal to the speakers. We employ a joint decoder that can
make use of this uncertainty together with higher-level language information.
For this, we revisit decoding algorithms used in factorial generative models in
early multi-talker speech recognition systems. In contrast with these early
works, we replace the GMM acoustic model with DNN, which provides greater
modeling power and simplifies part of the inference. We demonstrate the
advantage of joint decoding in proof of concept experiments on a mixed-TIDIGITS
dataset.</p>
  </details>
</details>
<h1>人工智能</h1>
<details>
  <summary>1. <b>标题：When Does Contrastive Learning Preserve Adversarial Robustness from  Pretraining to Finetuning?</b></summary>
  <p><b>编号</b>：[1]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.01124</p>
  <p><b>作者</b>：Lijie Fan,  Sijia Liu,  Pin-Yu Chen,  Gaoyuan Zhang,  Chuang Gan</p>
  <p><b>备注</b>：NeurIPS 2021. Code is available at this https URL</p>
  <p><b>关键词</b>：supervised robust learning methods across multiple datasets, task robustness transferability without loss, helps preserve robustness without forgetting, novel adversarial contrastive pretraining framework, task robustness transferability '.</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Contrastive learning (CL) can learn generalizable feature representations and
achieve the state-of-the-art performance of downstream tasks by finetuning a
linear classifier on top of it. However, as adversarial robustness becomes
vital in image classification, it remains unclear whether or not CL is able to
preserve robustness to downstream tasks. The main challenge is that in the
self-supervised pretraining + supervised finetuning paradigm, adversarial
robustness is easily forgotten due to a learning task mismatch from pretraining
to finetuning. We call such a challenge 'cross-task robustness
transferability'. To address the above problem, in this paper we revisit and
advance CL principles through the lens of robustness enhancement. We show that
(1) the design of contrastive views matters: High-frequency components of
images are beneficial to improving model robustness; (2) Augmenting CL with
pseudo-supervision stimulus (e.g., resorting to feature clustering) helps
preserve robustness without forgetting. Equipped with our new designs, we
propose AdvCL, a novel adversarial contrastive pretraining framework. We show
that AdvCL is able to enhance cross-task robustness transferability without
loss of model accuracy and finetuning efficiency. With a thorough experimental
study, we demonstrate that AdvCL outperforms the state-of-the-art
self-supervised robust learning methods across multiple datasets (CIFAR-10,
CIFAR-100, and STL-10) and finetuning schemes (linear evaluation and full model
finetuning).</p>
  </details>
</details>
<details>
  <summary>2. <b>标题：Stakeholder Participation in AI: Beyond "Add Diverse Stakeholders and  Stir"</b></summary>
  <p><b>编号</b>：[2]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.01122</p>
  <p><b>作者</b>：Fernando Delgado,  Stephen Yang,  Michael Madaio,  Qian Yang</p>
  <p><b>备注</b>：Pre-print of an accepted paper at the Human-Centered AI workshop at NeurIPS 2021</p>
  <p><b>关键词</b>：move forward across ai, current practices via, workshop paper aims, synthesizing existing literature, analyzing participatory approaches</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>There is a growing consensus in HCI and AI research that the design of AI
systems needs to engage and empower stakeholders who will be affected by AI.
However, the manner in which stakeholders should participate in AI design is
unclear. This workshop paper aims to ground what we dub a 'participatory turn'
in AI design by synthesizing existing literature on participation and through
empirical analysis of its current practices via a survey of recent published
research and a dozen semi-structured interviews with AI researchers and
practitioners. Based on our literature synthesis and empirical research, this
paper presents a conceptual framework for analyzing participatory approaches to
AI design and articulates a set of empirical findings that in ensemble detail
out the contemporary landscape of participatory practice in AI design. These
findings can help bootstrap a more principled discussion on how PD of AI should
move forward across AI, HCI, and other research communities.</p>
  </details>
</details>
<details>
  <summary>3. <b>标题：Rebooting ACGAN: Auxiliary Classifier GANs with Stable Training</b></summary>
  <p><b>编号</b>：[3]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.01118</p>
  <p><b>作者</b>：Minguk Kang,  Woohyeon Shim,  Minsu Cho,  Jaesik Park</p>
  <p><b>备注</b>：34 pages, 26 figures, 35th Conference on Neural Information Processing Systems (NeurIPS 2021)</p>
  <p><b>关键词</b>：rebooted auxiliary classifier generative adversarial network, conditional generative adversarial networks, projecting input vectors onto, generate easily classifiable samples, auxiliary classifier gan</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Conditional Generative Adversarial Networks (cGAN) generate realistic images
by incorporating class information into GAN. While one of the most popular
cGANs is an auxiliary classifier GAN with softmax cross-entropy loss (ACGAN),
it is widely known that training ACGAN is challenging as the number of classes
in the dataset increases. ACGAN also tends to generate easily classifiable
samples with a lack of diversity. In this paper, we introduce two cures for
ACGAN. First, we identify that gradient exploding in the classifier can cause
an undesirable collapse in early training, and projecting input vectors onto a
unit hypersphere can resolve the problem. Second, we propose the Data-to-Data
Cross-Entropy loss (D2D-CE) to exploit relational information in the
class-labeled dataset. On this foundation, we propose the Rebooted Auxiliary
Classifier Generative Adversarial Network (ReACGAN). The experimental results
show that ReACGAN achieves state-of-the-art generation results on CIFAR10,
Tiny-ImageNet, CUB200, and ImageNet datasets. We also verify that ReACGAN
benefits from differentiable augmentations and that D2D-CE harmonizes with
StyleGAN2 architecture. Model weights and a software package that provides
implementations of representative cGANs and all experiments in our paper are
available at this https URL.</p>
  </details>
</details>
<details>
  <summary>4. <b>标题：Investigation of Independent Reinforcement Learning Algorithms in  Multi-Agent Environments</b></summary>
  <p><b>编号</b>：[7]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.01100</p>
  <p><b>作者</b>：Ken Ming Lee,  Sriram Ganapathi Subramanian,  Mark Crowley</p>
  <p><b>备注</b>：15 pages, 7 figures, Accepted for NeurIPS 2021 Deep Reinforcement Learning Workshop</p>
  <p><b>关键词</b>：agents trained via independent algorithms learn, cooperative partially observable environments, independent reinforcement learning algorithms, three main categories, adding recurrence improves</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Independent reinforcement learning algorithms have no theoretical guarantees
for finding the best policy in multi-agent settings. However, in practice,
prior works have reported good performance with independent algorithms in some
domains and bad performance in others. Moreover, a comprehensive study of the
strengths and weaknesses of independent algorithms is lacking in the
literature. In this paper, we carry out an empirical comparison of the
performance of independent algorithms on four PettingZoo environments that span
the three main categories of multi-agent environments, i.e., cooperative,
competitive, and mixed. We show that in fully-observable environments,
independent algorithms can perform on par with multi-agent algorithms in
cooperative and competitive settings. For the mixed environments, we show that
agents trained via independent algorithms learn to perform well individually,
but fail to learn to cooperate with allies and compete with enemies. We also
show that adding recurrence improves the learning of independent algorithms in
cooperative partially observable environments.</p>
  </details>
</details>
<details>
  <summary>5. <b>标题：MOST-GAN: 3D Morphable StyleGAN for Disentangled Face Image Manipulation</b></summary>
  <p><b>编号</b>：[22]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.01048</p>
  <p><b>作者</b>：Safa C. Medin,  Bernhard Egger,  Anoop Cherian,  Ye Wang,  Joshua B. Tenenbaum,  Xiaoming Liu,  Tim K. Marks</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：art 2d hair manipulation network, generate strikingly photorealistic face images, nonlinear 3d morphable models, gan achieves photorealistic manipulation, priori models physical attributes</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent advances in generative adversarial networks (GANs) have led to
remarkable achievements in face image synthesis. While methods that use
style-based GANs can generate strikingly photorealistic face images, it is
often difficult to control the characteristics of the generated faces in a
meaningful and disentangled way. Prior approaches aim to achieve such semantic
control and disentanglement within the latent space of a previously trained
GAN. In contrast, we propose a framework that a priori models physical
attributes of the face such as 3D shape, albedo, pose, and lighting explicitly,
thus providing disentanglement by design. Our method, MOST-GAN, integrates the
expressive power and photorealism of style-based GANs with the physical
disentanglement and flexibility of nonlinear 3D morphable models, which we
couple with a state-of-the-art 2D hair manipulation network. MOST-GAN achieves
photorealistic manipulation of portrait images with fully disentangled 3D
control over their physical attributes, enabling extreme manipulation of
lighting, facial expression, and pose variations up to full profile view.</p>
  </details>
</details>
<details>
  <summary>6. <b>标题：Logic Rules Meet Deep Learning: A Novel Approach for Ship Type  Classification</b></summary>
  <p><b>编号</b>：[23]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.01042</p>
  <p><b>作者</b>：Manolis Pitsikalis,  Thanh-Toan Do,  Alexei Lisitsa,  Shan Luo</p>
  <p><b>备注</b>：Accepted and presented in RuleML+RR 2021</p>
  <p><b>关键词</b>：novel ship type classification model, model using real world data, common black box approaches, cnn deep neural network, combines vessel transmitted data</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The shipping industry is an important component of the global trade and
economy, however in order to ensure law compliance and safety it needs to be
monitored. In this paper, we present a novel Ship Type classification model
that combines vessel transmitted data from the Automatic Identification System,
with vessel imagery. The main components of our approach are the Faster R-CNN
Deep Neural Network and a Neuro-Fuzzy system with IF-THEN rules. We evaluate
our model using real world data and showcase the advantages of this combination
while also compare it with other methods. Results show that our model can
increase prediction scores by up to 15.4\% when compared with the next best
model we considered, while also maintaining a level of explainability as
opposed to common black box approaches.</p>
  </details>
</details>
<details>
  <summary>7. <b>标题：Introspective Distillation for Robust Question Answering</b></summary>
  <p><b>编号</b>：[28]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.01026</p>
  <p><b>作者</b>：Yulei Niu,  Hanwang Zhang</p>
  <p><b>备注</b>：Accepted by NeurIPS 2021</p>
  <p><b>关键词</b>：novel debiasing method called introspective distillation, even achieving better id performance compared, recent debiasing methods achieve good, reading comprehension dataset squad demonstrate, visual qa datasets vqa v2</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Question answering (QA) models are well-known to exploit data bias, e.g., the
language prior in visual QA and the position bias in reading comprehension.
Recent debiasing methods achieve good out-of-distribution (OOD)
generalizability with a considerable sacrifice of the in-distribution (ID)
performance. Therefore, they are only applicable in domains where the test
distribution is known in advance. In this paper, we present a novel debiasing
method called Introspective Distillation (IntroD) to make the best of both
worlds for QA. Our key technical contribution is to blend the inductive bias of
OOD and ID by introspecting whether a training sample fits in the factual ID
world or the counterfactual OOD one. Experiments on visual QA datasets VQA v2,
VQA-CP, and reading comprehension dataset SQuAD demonstrate that our proposed
IntroD maintains the competitive OOD performance compared to other debiasing
methods, while sacrificing little or even achieving better ID performance
compared to the non-debiasing ones.</p>
  </details>
</details>
<details>
  <summary>8. <b>标题：Gomoku: analysis of the game and of the player Wine</b></summary>
  <p><b>编号</b>：[33]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.01016</p>
  <p><b>作者</b>：Lorenzo Piazzo,  Michele Scarpiniti,  Enzo Baccarelli</p>
  <p><b>备注</b>：32 pages, 1 figure</p>
  <p><b>关键词</b>：quickly testing novel artificial intelligence, main game concepts, classical board game, strong gomoku player, new gomoku player</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Gomoku, also known as five in a row, is a classical board game, ideally
suited for quickly testing novel Artificial Intelligence (AI) techniques. With
the aim of facilitating a developer willing to write a new Gomoku player, in
this report we present an analysis of the main game concepts and strategies,
which is wider and deeper than existing ones. Moreover, after discussing the
general structure of an artificial player, we present and analyse a strong
Gomoku player, named Wine, the code of which is freely available on the
Internet and which is an excelent example of how a modern player is organised.</p>
  </details>
</details>
<details>
  <summary>9. <b>标题：Transfer Learning Approach to Bicycle-sharing Systems' Station Location  Planning using OpenStreetMap Data</b></summary>
  <p><b>编号</b>：[41]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00990</p>
  <p><b>作者</b>：Kamil Raczycki,  Piotr Szymański</p>
  <p><b>备注</b>：Accepted to 4th ACM SIGSPATIAL International Workshop on Advances in Resilient and Intelligent Cities</p>
  <p><b>关键词</b>：sharing stations usually requires expensive data gathering, uber h3 discrete global grid system, include citizens leaving public transport, different cities using transfer learning, bike sharing system quickly</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Bicycle-sharing systems (BSS) have become a daily reality for many citizens
of larger, wealthier cities in developed regions. However, planning the layout
of bicycle-sharing stations usually requires expensive data gathering,
surveying travel behavior and trip modelling followed by station layout
optimization. Many smaller cities and towns, especially in developing areas,
may have difficulty financing such projects. Planning a BSS also takes a
considerable amount of time. Yet as the pandemic has shown us, municipalities
will face the need to adapt rapidly to mobility shifts, which include citizens
leaving public transport for bicycles. Laying out a bike sharing system quickly
will become critical in addressing the increase in bike demand. This paper
addresses the problem of cost and time in BSS layout design and proposes a new
solution to streamline and facilitate the process of such planning by using
spatial embedding methods. Based only on publicly available data from
OpenStreetMap, and station layouts from 34 cities in Europe, a method has been
developed to divide cities into micro-regions using the Uber H3 discrete global
grid system and to indicate regions where it is worth placing a station based
on existing systems in different cities using transfer learning. The result of
the work is a mechanism to support planners in their decision making when
planning a station layout with a choice of reference cities.</p>
  </details>
</details>
<details>
  <summary>10. <b>标题：Fast Convolution based on Winograd Minimum Filtering: Introduction and  Development</b></summary>
  <p><b>编号</b>：[46]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00977</p>
  <p><b>作者</b>：Gan Tong,  Libo Huang</p>
  <p><b>备注</b>：15 pages, 1 figure</p>
  <p><b>关键词</b>：proposed several fast convolution algorithms including fft, fast convolution implementation within, winograd convolution significantly reduces, provide detailed references, possible future directions</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Convolutional Neural Network (CNN) has been widely used in various fields and
played an important role. Convolution operators are the fundamental component
of convolutional neural networks, and it is also the most time-consuming part
of network training and inference. In recent years, researchers have proposed
several fast convolution algorithms including FFT and Winograd. Among them,
Winograd convolution significantly reduces the multiplication operations in
convolution, and it also takes up less memory space than FFT convolution.
Therefore, Winograd convolution has quickly become the first choice for fast
convolution implementation within a few years. At present, there is no
systematic summary of the convolution algorithm. This article aims to fill this
gap and provide detailed references for follow-up researchers. This article
summarizes the development of Winograd convolution from the three aspects of
algorithm expansion, algorithm optimization, implementation, and application,
and finally makes a simple outlook on the possible future directions.</p>
  </details>
</details>
<details>
  <summary>11. <b>标题：Hex2vec -- Context-Aware Embedding H3 Hexagons with OpenStreetMap Tags</b></summary>
  <p><b>编号</b>：[49]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00970</p>
  <p><b>作者</b>：Szymon Woźniak,  Piotr Szymański</p>
  <p><b>备注</b>：Accepted at 4th ACM SIGSPATIAL International Workshop on AI for Geographic Knowledge Discovery (GEOAI '21)</p>
  <p><b>关键词</b>：quality inference using deep neural networks, resulting vector representations showcase semantic structures, satellite photos ), mobility data, past approaches however concentrated, learning vector representations</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Representation learning of spatial and geographic data is a rapidly
developing field which allows for similarity detection between areas and
high-quality inference using deep neural networks. Past approaches however
concentrated on embedding raster imagery (maps, street or satellite photos),
mobility data or road networks. In this paper we propose the first approach to
learning vector representations of OpenStreetMap regions with respect to urban
functions and land-use in a micro-region grid. We identify a subset of OSM tags
related to major characteristics of land-use, building and urban region
functions, types of water, green or other natural areas. Through manual
verification of tagging quality, we selected 36 cities were for training region
representations. Uber's H3 index was used to divide the cities into hexagons,
and OSM tags were aggregated for each hexagon. We propose the hex2vec method
based on the Skip-gram model with negative sampling. The resulting vector
representations showcase semantic structures of the map characteristics,
similar to ones found in vector-based language models. We also present insights
from region similarity detection in six Polish cities and propose a region
typology obtained through agglomerative clustering.</p>
  </details>
</details>
<details>
  <summary>12. <b>标题：Generative Occupancy Fields for 3D Surface-Aware Image Synthesis</b></summary>
  <p><b>编号</b>：[50]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00969</p>
  <p><b>作者</b>：Xudong Xu,  Xingang Pan,  Dahua Lin,  Bo Dai</p>
  <p><b>备注</b>：Accepted to NeurIPS2021. We propose Generative Occupancy Fields(GOF), a 3D-aware generative model which could synthesize realistic images with 3D consistency and simultaneously learn compact object surfaces</p>
  <p><b>关键词</b>：radiance fields occupancy representations could inherently ensure deterministic surfaces, generative models much easier since gradients, learn compact object surfaces without impeding, receive sparse gradients located, directly apply occupancy representations</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The advent of generative radiance fields has significantly promoted the
development of 3D-aware image synthesis. The cumulative rendering process in
radiance fields makes training these generative models much easier since
gradients are distributed over the entire volume, but leads to diffused object
surfaces. In the meantime, compared to radiance fields occupancy
representations could inherently ensure deterministic surfaces. However, if we
directly apply occupancy representations to generative models, during training
they will only receive sparse gradients located on object surfaces and
eventually suffer from the convergence problem. In this paper, we propose
Generative Occupancy Fields (GOF), a novel model based on generative radiance
fields that can learn compact object surfaces without impeding its training
convergence. The key insight of GOF is a dedicated transition from the
cumulative rendering in radiance fields to rendering with only the surface
points as the learned surface gets more and more accurate. In this way, GOF
combines the merits of two representations in a unified framework. In practice,
the training-time transition of start from radiance fields and march to
occupancy representations is achieved in GOF by gradually shrinking the
sampling region in its rendering process from the entire volume to a minimal
neighboring region around the surface. Through comprehensive experiments on
multiple datasets, we demonstrate that GOF can synthesize high-quality images
with 3D consistency and simultaneously learn compact and smooth object
surfaces. Code, models, and demo videos are available at
this https URL</p>
  </details>
</details>
<details>
  <summary>13. <b>标题：VPFNet: Voxel-Pixel Fusion Network for Multi-class 3D Object Detection</b></summary>
  <p><b>编号</b>：[52]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00966</p>
  <p><b>作者</b>：Chia-Hung Wang,  Hsueh-Wei Chen,  Li-Chen Fu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：class 3d object detection task, class 3d object detection network, camera sensor data streams, dl )- embedded fusion, class object detection</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Many LiDAR-based methods for detecting large objects, single-class object
detection, or under easy situations were claimed to perform quite well.
However, their performances of detecting small objects or under hard situations
did not surpass those of the fusion-based ones due to failure to leverage the
image semantics. In order to elevate the detection performance in a complicated
environment, this paper proposes a deep learning (DL)-embedded fusion-based
multi-class 3D object detection network which admits both LiDAR and camera
sensor data streams, named Voxel-Pixel Fusion Network (VPFNet). Inside this
network, a key novel component is called Voxel-Pixel Fusion (VPF) layer, which
takes advantage of the geometric relation of a voxel-pixel pair and fuses the
voxel features and the pixel features with proper mechanisms. Moreover, several
parameters are particularly designed to guide and enhance the fusion effect
after considering the characteristics of a voxel-pixel pair. Finally, the
proposed method is evaluated on the KITTI benchmark for multi-class 3D object
detection task under multilevel difficulty, and is shown to outperform all
state-of-the-art methods in mean average precision (mAP). It is also noteworthy
that our approach here ranks the first on the KITTI leaderboard for the
challenging pedestrian class.</p>
  </details>
</details>
<details>
  <summary>14. <b>标题：RefineGAN: Universally Generating Waveform Better than Ground Truth with  Highly Accurate Pitch and Intensity Responses</b></summary>
  <p><b>编号</b>：[55]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00962</p>
  <p><b>作者</b>：Shengyuan Xu,  Wenxiao Zhao,  Jing Guo</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：generative adversarial network )- based approaches towards high, gan method introduces much uncertainty, fidelity waveform generation heavily rely, unseen speaker identically well, based loss function</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Most GAN(Generative Adversarial Network)-based approaches towards
high-fidelity waveform generation heavily rely on discriminators to improve
their performance. However, the over-use of this GAN method introduces much
uncertainty into the generation process and often result in mismatches of pitch
and intensity, which is fatal when it comes to sensitive using cases such as
singing voice synthesis(SVS). To address this problem, we propose RefineGAN, a
high-fidelity neural vocoder with faster-than-real-time generation capability,
and focused on the robustness, pitch and intensity accuracy, and full-band
audio generation. We employed a pitch-guided refine architecture with a
multi-scale spectrogram-based loss function to help stabilize the training
process and maintain the robustness of the neural vocoder while using the
GAN-based training method. Audio generated using this method shows a better
performance in subjective tests when compared with the ground-truth audio. This
result shows that the fidelity is even improved during the waveform
reconstruction by eliminating defects produced by the speaker and the recording
procedure. Moreover, a further study shows that models trained on a specified
type of data can perform on totally unseen language and unseen speaker
identically well. Generated sample pairs are provided on
this https URL.</p>
  </details>
</details>
<details>
  <summary>15. <b>标题：gtfs2vec -- Learning GTFS Embeddings for comparing Public Transport  Offer in Microregions</b></summary>
  <p><b>编号</b>：[56]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00960</p>
  <p><b>作者</b>：Piotr Gramacki,  Szymon Woźniak,  Piotr Szymański</p>
  <p><b>备注</b>：Accepted at 4th ACM SIGSPATIAL International Workshop on AI for Geographic Knowledge Discovery GEOAI'21</p>
  <p><b>关键词</b>：qualitatively describe public transport availability, similar public transport schedule characteristics, created certain features describing, associative deep neural network, selected 48 european cities</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We selected 48 European cities and gathered their public transport timetables
in the GTFS format. We utilized Uber's H3 spatial index to divide each city
into hexagonal micro-regions. Based on the timetables data we created certain
features describing the quantity and variety of public transport availability
in each region. Next, we trained an auto-associative deep neural network to
embed each of the regions. Having such prepared representations, we then used a
hierarchical clustering approach to identify similar regions. To do so, we
utilized an agglomerative clustering algorithm with a euclidean distance
between regions and Ward's method to minimize in-cluster variance. Finally, we
analyzed the obtained clusters at different levels to identify some number of
clusters that qualitatively describe public transport availability. We showed
that our typology matches the characteristics of analyzed cities and allows
succesful searching for areas with similar public transport schedule
characteristics.</p>
  </details>
</details>
<details>
  <summary>16. <b>标题：Turning Traffic Monitoring Cameras into Intelligent Sensors for Traffic  Density Estimation</b></summary>
  <p><b>编号</b>：[64]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00941</p>
  <p><b>作者</b>：Zijian Hu,  William H.K. Lam,  S.C. Wong,  Andy H.F. Chow,  Wei Ma</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：estimating traffic density using uncalibrated traffic monitoring cameras, time traffic information without installing additional sensors, providing useful traffic state information, accurate traffic state information plays, traffic density estimation problem</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Accurate traffic state information plays a pivotal role in the Intelligent
Transportation Systems (ITS), and it is an essential input to various smart
mobility applications such as signal coordination and traffic flow prediction.
The current practice to obtain the traffic state information is through
specialized sensors such as loop detectors and speed cameras. In most
metropolitan areas, traffic monitoring cameras have been installed to monitor
the traffic conditions on arterial roads and expressways, and the collected
videos or images are mainly used for visual inspection by traffic engineers.
Unfortunately, the data collected from traffic monitoring cameras are affected
by the 4L characteristics: Low frame rate, Low resolution, Lack of annotated
data, and Located in complex road environments. Therefore, despite the great
potentials of the traffic monitoring cameras, the 4L characteristics hinder
them from providing useful traffic state information (e.g., speed, flow,
density). This paper focuses on the traffic density estimation problem as it is
widely applicable to various traffic surveillance systems. To the best of our
knowledge, there is a lack of the holistic framework for addressing the 4L
characteristics and extracting the traffic density information from traffic
monitoring camera data. In view of this, this paper proposes a framework for
estimating traffic density using uncalibrated traffic monitoring cameras with
4L characteristics. The proposed framework consists of two major components:
camera calibration and vehicle detection. The camera calibration method
estimates the actual length between pixels in the images and videos, and the
vehicle counts are extracted from the deep-learning-based vehicle detection
method. Combining the two components, high-granular traffic density can be
estimated. To validate the proposed framework, two case studies were conducted
in Hong Kong and Sacramento. The results show that the Mean Absolute Error
(MAE) in camera calibration is less than 0.2 meters out of 6 meters, and the
accuracy of vehicle detection under various conditions is approximately 90%.
Overall, the MAE for the estimated density is 9.04 veh/km/lane in Hong Kong and
1.30 veh/km/lane in Sacramento. The research outcomes can be used to calibrate
the speed-density fundamental diagrams, and the proposed framework can provide
accurate and real-time traffic information without installing additional
sensors.</p>
  </details>
</details>
<details>
  <summary>17. <b>标题：Combining expert knowledge and neural networks to model environmental  stresses in agriculture</b></summary>
  <p><b>编号</b>：[71]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00918</p>
  <p><b>作者</b>：Kostadin Cvejoski,  Jannis Schuecker,  Anne-Katrin Mahlein,  Bogdan Georgiev</p>
  <p><b>备注</b>：19 pages, Winners of the 2019 Syngenta Crop Challenge</p>
  <p><b>关键词</b>：first design deterministic expert models, combine representation learning capabilities, model environmental heat, sensitivity analysis, resistant ones</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this work we combine representation learning capabilities of neural
network with agricultural knowledge from experts to model environmental heat
and drought stresses. We first design deterministic expert models which serve
as a benchmark and inform the design of flexible neural-network architectures.
Finally, a sensitivity analysis of the latter allows a clustering of hybrids
into susceptible and resistant ones.</p>
  </details>
</details>
<details>
  <summary>18. <b>标题：Smart Fashion: A Review of AI Applications in the Fashion & Apparel  Industry</b></summary>
  <p><b>编号</b>：[75]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00905</p>
  <p><b>作者</b>：Seyed Omid Mohammadi,  Ahmad Kalhor (University of Tehran, College of Engineering, School of Electrical and Computer Engineering, Tehran, Iran)</p>
  <p><b>备注</b>：99 Pages, 79 Figures, 24 Tables, Full length manuscript</p>
  <p><b>关键词</b>：86 public fashion datasets accompanied, fashion research articles provides researchers, explicit research directions, 580 related articles, paper provides</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The fashion industry is on the verge of an unprecedented change. The
implementation of machine learning, computer vision, and artificial
intelligence (AI) in fashion applications is opening lots of new opportunities
for this industry. This paper provides a comprehensive survey on this matter,
categorizing more than 580 related articles into 22 well-defined
fashion-related tasks. Such structured task-based multi-label classification of
fashion research articles provides researchers with explicit research
directions and facilitates their access to the related studies, improving the
visibility of studies simultaneously. For each task, a time chart is provided
to analyze the progress through the years. Furthermore, we provide a list of 86
public fashion datasets accompanied by a list of suggested applications and
additional information for each.</p>
  </details>
</details>
<details>
  <summary>19. <b>标题：Intervention Efficient Algorithm for Two-Stage Causal MDPs</b></summary>
  <p><b>编号</b>：[84]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00886</p>
  <p><b>作者</b>：Rahul Madhavan,  Aurghya Maiti,  Gaurav Sinha,  Siddharth Barman</p>
  <p><b>备注</b>：29 pages</p>
  <p><b>关键词</b>：study markov decision processes, instance dependent regret bound, utilizes convex optimization, regret minimization guarantees, current work develops</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We study Markov Decision Processes (MDP) wherein states correspond to causal
graphs that stochastically generate rewards. In this setup, the learner's goal
is to identify atomic interventions that lead to high rewards by intervening on
variables at each state. Generalizing the recent causal-bandit framework, the
current work develops (simple) regret minimization guarantees for two-stage
causal MDPs, with parallel causal graph at each state. We propose an algorithm
that achieves an instance dependent regret bound. A key feature of our
algorithm is that it utilizes convex optimization to address the exploration
problem. We identify classes of instances wherein our regret guarantee is
essentially tight, and experimentally validate our theoretical results.</p>
  </details>
</details>
<details>
  <summary>20. <b>标题：On the Expressivity of Markov Reward</b></summary>
  <p><b>编号</b>：[89]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00876</p>
  <p><b>作者</b>：David Abel,  Will Dabney,  Anna Harutyunyan,  Mark K. Ho,  Michael L. Littman,  Doina Precup,  Satinder Singh</p>
  <p><b>备注</b>：Accepted to NeurIPS 2021</p>
  <p><b>关键词</b>：study around three new abstract notions, main results prove, reward function exists, markov reward function, markov reward function</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Reward is the driving force for reinforcement-learning agents. This paper is
dedicated to understanding the expressivity of reward as a way to capture tasks
that we would want an agent to perform. We frame this study around three new
abstract notions of "task" that might be desirable: (1) a set of acceptable
behaviors, (2) a partial ordering over behaviors, or (3) a partial ordering
over trajectories. Our main results prove that while reward can express many of
these tasks, there exist instances of each task type that no Markov reward
function can capture. We then provide a set of polynomial-time algorithms that
construct a Markov reward function that allows an agent to optimize tasks of
each of these three types, and correctly determine when no such reward function
exists. We conclude with an empirical study that corroborates and illustrates
our theoretical findings.</p>
  </details>
</details>
<details>
  <summary>21. <b>标题：DetectorNet: Transformer-enhanced Spatial Temporal Graph Neural Network  for Traffic Prediction</b></summary>
  <p><b>编号</b>：[94]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00869</p>
  <p><b>作者</b>：He Li,  Shiyu Zhang,  Xuejiao Li,  Liangcai Su,  Hongjie Huang,  Duo Jin,  Linghao Chen,  Jianbing Huang,  Jaesoo Yoo</p>
  <p><b>备注</b>：The 29th ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems (ACM SIGSPATIAL 2021)</p>
  <p><b>关键词</b>：eventually loses much valuable potential information, data presents unique challenges including, four ablation experiments proves, static road network structure, view temporal attention module</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Detectors with high coverage have direct and far-reaching benefits for road
users in route planning and avoiding traffic congestion, but utilizing these
data presents unique challenges including: the dynamic temporal correlation,
and the dynamic spatial correlation caused by changes in road conditions.
Although the existing work considers the significance of modeling with
spatial-temporal correlation, what it has learned is still a static road
network structure, which cannot reflect the dynamic changes of roads, and
eventually loses much valuable potential information. To address these
challenges, we propose DetectorNet enhanced by Transformer. Differs from
previous studies, our model contains a Multi-view Temporal Attention module and
a Dynamic Attention module, which focus on the long-distance and short-distance
temporal correlation, and dynamic spatial correlation by dynamically updating
the learned knowledge respectively, so as to make accurate prediction. In
addition, the experimental results on two public datasets and the comparison
results of four ablation experiments proves that the performance of DetectorNet
is better than the eleven advanced baselines.</p>
  </details>
</details>
<details>
  <summary>22. <b>标题：Interpretive Blindness</b></summary>
  <p><b>编号</b>：[96]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00867</p>
  <p><b>作者</b>：Nicholas Asher,  Julie Hunter</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：promote good epistemic practices, particular characteristic contemporary testimony, one acquires information, argumentative completeness },, hierarchical bayesian settings</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We model here an epistemic bias we call \textit{interpretive blindness} (IB).
IB is a special problem for learning from testimony, in which one acquires
information only from text or conversation. We show that IB follows from a
co-dependence between background beliefs and interpretation in a Bayesian
setting and the nature of contemporary testimony. We argue that a particular
characteristic contemporary testimony, \textit{argumentative completeness}, can
preclude learning in hierarchical Bayesian settings, even in the presence of
constraints that are designed to promote good epistemic practices.</p>
  </details>
</details>
<details>
  <summary>23. <b>标题：Surreal Decisions</b></summary>
  <p><b>编号</b>：[98]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00862</p>
  <p><b>作者</b>：Eddy Keming Chen,  Daniel Rubio</p>
  <p><b>备注</b>：First published online: 05 June 2018</p>
  <p><b>关键词</b>：surreal decision theory respects dominance reasoning even, pascalian decision problem depends, surreal numbers shall provide, pure pascalian strategy beats, although expected utility theory</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Although expected utility theory has proven a fruitful and elegant theory in
the finite realm, attempts to generalize it to infinite values have resulted in
many paradoxes. In this paper, we argue that the use of John Conway's surreal
numbers shall provide a firm mathematical foundation for transfinite decision
theory. To that end, we prove a surreal representation theorem and show that
our surreal decision theory respects dominance reasoning even in the case of
infinite values. We then bring our theory to bear on one of the more venerable
decision problems in the literature: Pascal's Wager. Analyzing the wager
showcases our theory's virtues and advantages. To that end, we analyze two
objections against the wager: Mixed Strategies and Many Gods. After formulating
the two objections in the framework of surreal utilities and probabilities, our
theory correctly predicts that (1) the pure Pascalian strategy beats all mixed
strategies, and (2) what one should do in a Pascalian decision problem depends
on what one's credence function is like. Our analysis therefore suggests that
although Pascal's Wager is mathematically coherent, it does not deliver what it
purports to, a rationally compelling argument that people should lead a
religious life regardless of how confident they are in theism and its
alternatives.</p>
  </details>
</details>
<details>
  <summary>24. <b>标题：Deep Learning Transformer Architecture for Named Entity Recognition on  Low Resourced Languages: State of the art results</b></summary>
  <p><b>编号</b>：[106]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00830</p>
  <p><b>作者</b>：Ridewaan Hanslo</p>
  <p><b>备注</b>：8 pages, 6 tables, and 3 figures</p>
  <p><b>关键词</b>：conditional random fields ml model, transformer models significantly improve performance, tuning parameters per language, natural language processing tasks, additional research could evaluate</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper reports on the evaluation of Deep Learning (DL) transformer
architecture models for Named-Entity Recognition (NER) on ten low-resourced
South African (SA) languages. In addition, these DL transformer models were
compared to other Neural Network and Machine Learning (ML) NER models. The
findings show that transformer models significantly improve performance when
applying discrete fine-tuning parameters per language. Furthermore, fine-tuned
transformer models outperform other neural network and machine learning models
with NER on the low-resourced SA languages. For example, the transformer models
generated the highest F-scores for six of the ten SA languages, including the
highest average F-score surpassing the Conditional Random Fields ML model.
Additional research could evaluate the more recent transformer architecture
models on other Natural Language Processing tasks and applications, such as
Phrase chunking, Machine Translation, and Part-of-Speech tagging.</p>
  </details>
</details>
<details>
  <summary>25. <b>标题：Teaching Fairness, Accountability, Confidentiality, and Transparency in  Artificial Intelligence through the Lens of Reproducibility</b></summary>
  <p><b>编号</b>：[107]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00826</p>
  <p><b>作者</b>：Ana Lucic,  Maurits Bleeker,  Sami Jullien,  Samarth Bhargav,  Maarten de Rijke</p>
  <p><b>备注</b>：Preprint</p>
  <p><b>关键词</b>：machine learning reproducibility challenge, two academic years, open source repository, one year coincided, group project based</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this work we explain the setup for a technical, graduate-level course on
Fairness, Accountability, Confidentiality and Transparency in Artificial
Intelligence (FACT-AI) at the University of Amsterdam, which teaches FACT-AI
concepts through the lens of reproducibility. The focal point of the course is
a group project based on reproducing existing FACT-AI algorithms from top AI
conferences, and writing a report about their experiences. In the first
iteration of the course, we created an open source repository with the code
implementations from the group projects. In the second iteration, we encouraged
students to submit their group projects to the Machine Learning Reproducibility
Challenge, which resulted in 9 reports from our course being accepted to the
challenge. We reflect on our experience teaching the course over two academic
years, where one year coincided with a global pandemic, and propose guidelines
for teaching FACT-AI through reproducibility in graduate-level AI programs. We
hope this can be a useful resource for instructors to set up similar courses at
their universities in the future.</p>
  </details>
</details>
<details>
  <summary>26. <b>标题：Towards Reformulating Essence Specifications for Robustness</b></summary>
  <p><b>编号</b>：[110]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00821</p>
  <p><b>作者</b>：Özgür Akgün,  Alan M. Frisch,  Ian P. Gent,  Christopher Jefferson,  Ian Miguel,  Peter Nightingale,  András Z. Salamon</p>
  <p><b>备注</b>：12 pages, 6 figures, presented at ModRef 2021</p>
  <p><b>关键词</b>：conjure automated modelling tool, user may therefore omit, constraint modelling decisions, transformed specification compared, many equivalent ways</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The Essence language allows a user to specify a constraint problem at a level
of abstraction above that at which constraint modelling decisions are made.
Essence specifications are refined into constraint models using the Conjure
automated modelling tool, which employs a suite of refinement rules. However,
Essence is a rich language in which there are many equivalent ways to specify a
given problem. A user may therefore omit the use of domain attributes or
abstract types, resulting in fewer refinement rules being applicable and
therefore a reduced set of output models from which to select. This paper
addresses the problem of recovering this information automatically to increase
the robustness of the quality of the output constraint models in the face of
variation in the input Essence specification. We present reformulation rules
that can change the type of a decision variable or add attributes that shrink
its domain. We demonstrate the efficacy of this approach in terms of the
quantity and quality of models Conjure can produce from the transformed
specification compared with the original.</p>
  </details>
</details>
<details>
  <summary>27. <b>标题：Livestock Monitoring with Transformer</b></summary>
  <p><b>编号</b>：[114]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00801</p>
  <p><b>作者</b>：Bhavesh Tangirala,  Ishan Bhandari,  Daniel Laszlo,  Deepak K. Gupta,  Rajat M. Thomas,  Devanshu Arya</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：carefully curated dataset comprising video sequences, starformer outperforms popular baseline models trained, computer vision algorithms perform poorly, could use standard video cameras, perform simultaneous instance level segmentation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Tracking the behaviour of livestock enables early detection and thus
prevention of contagious diseases in modern animal farms. Apart from economic
gains, this would reduce the amount of antibiotics used in livestock farming
which otherwise enters the human diet exasperating the epidemic of antibiotic
resistance - a leading cause of death. We could use standard video cameras,
available in most modern farms, to monitor livestock. However, most computer
vision algorithms perform poorly on this task, primarily because, (i) animals
bred in farms look identical, lacking any obvious spatial signature, (ii) none
of the existing trackers are robust for long duration, and (iii) real-world
conditions such as changing illumination, frequent occlusion, varying camera
angles, and sizes of the animals make it hard for models to generalize. Given
these challenges, we develop an end-to-end behaviour monitoring system for
group-housed pigs to perform simultaneous instance level segmentation,
tracking, action recognition and re-identification (STAR) tasks. We present
starformer, the first end-to-end multiple-object livestock monitoring framework
that learns instance-level embeddings for grouped pigs through the use of
transformer architecture. For benchmarking, we present Pigtrace, a carefully
curated dataset comprising video sequences with instance level bounding box,
segmentation, tracking and activity classification of pigs in real indoor
farming environment. Using simultaneous optimization on STAR tasks we show that
starformer outperforms popular baseline models trained for individual tasks.</p>
  </details>
</details>
<details>
  <summary>28. <b>标题：Knowledge-driven Site Selection via Urban Knowledge Graph</b></summary>
  <p><b>编号</b>：[120]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00787</p>
  <p><b>作者</b>：Yu Liu,  Jingtao Ding,  Yong Li</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：source urban data makes intelligent site selection promising, site selection determines optimal locations, driven methods heavily rely, knowsite outperforms representative baselines, based attention mechanism developed</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Site selection determines optimal locations for new stores, which is of
crucial importance to business success. Especially, the wide application of
artificial intelligence with multi-source urban data makes intelligent site
selection promising. However, existing data-driven methods heavily rely on
feature engineering, facing the issues of business generalization and complex
relationship modeling. To get rid of the dilemma, in this work, we borrow ideas
from knowledge graph (KG), and propose a knowledge-driven model for site
selection, short for KnowSite. Specifically, motivated by distilled knowledge
and rich semantics in KG, we firstly construct an urban KG (UrbanKG) with
cities' key elements and semantic relationships captured. Based on UrbanKG, we
employ pre-training techniques for semantic representations, which are fed into
an encoder-decoder structure for site decisions. With multi-relational message
passing and relation path-based attention mechanism developed, KnowSite
successfully reveals the relationship between various businesses and site
selection criteria. Extensive experiments on two datasets demonstrate that
KnowSite outperforms representative baselines with both effectiveness and
explainability achieved.</p>
  </details>
</details>
<details>
  <summary>29. <b>标题：An AI-powered Smart Routing Solution for Payment Systems</b></summary>
  <p><b>编号</b>：[121]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00783</p>
  <p><b>作者</b>：Ramya Bygari,  Aayush Gupta,  Shashwat Raghuvanshi,  Aakanksha Bapna,  Birendra Sahu</p>
  <p><b>备注</b>：9 pages, 10 figures, Accepted at IEEE Big Data Conference - this https URL</p>
  <p><b>关键词</b>：adaptive time decay rate algorithm, terminals using static rules, random forest classifier, net banking )., multiple terminals associated</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In the current era of digitization, online payment systems are attracting
considerable interest. Improving the efficiency of a payment system is
important since it has a substantial impact on revenues for businesses. A
gateway is an integral component of a payment system through which every
transaction is routed. In an online payment system, payment processors
integrate with these gateways by means of various configurations such as
pricing, methods, risk checks, etc. These configurations are called terminals.
Each gateway can have multiple terminals associated with it. Routing a payment
transaction through the best terminal is crucial to increase the probability of
a payment transaction being successful. Machine learning (ML) and artificial
intelligence (AI) techniques can be used to accurately predict the best
terminals based on their previous performance and various payment-related
attributes. We have devised a pipeline consisting of static and dynamic
modules. The static module does the initial filtering of the terminals using
static rules and a logistic regression model that predicts gateway downtimes.
Subsequently, the dynamic module computes a lot of novel features based on
success rate, payment attributes, time lag, etc. to model the terminal
behaviour accurately. These features are updated using an adaptive time decay
rate algorithm in real-time using a feedback loop and passed to a random forest
classifier to predict the success probabilities for every terminal. This
pipeline is currently in production at Razorpay routing millions of
transactions through it in real-time and has given a 4-6\% improvement in
success rate across all payment methods (credit card, debit card, UPI, net
banking). This has made our payment system more resilient to performance drops,
which has improved the user experience, instilled more trust in the merchants,
and boosted the revenue of the business.</p>
  </details>
</details>
<details>
  <summary>30. <b>标题：Validate on Sim, Detect on Real -- Model Selection for Domain  Randomization</b></summary>
  <p><b>编号</b>：[130]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00765</p>
  <p><b>作者</b>：Gal Leibovich,  Guy Jacob,  Shadi Endrawis,  Gal Novik,  Aviv Tamar</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：policy ranking without requiring additional real world data, uses significantly less data compared, method achieves significantly better ranking, vsdr improves policy selection across, extensively evaluate different dr parameters</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A practical approach to learning robot skills, often termed sim2real, is to
train control policies in simulation and then deploy them on a real robot.
Popular techniques to improve the sim2real transfer build on domain
randomization (DR): Training the policy on a diverse set of randomly generated
domains with the hope of better generalization to the real world. Due to the
large number of hyper-parameters in both the policy learning and DR algorithms,
one often ends up with a large number of trained models, where choosing the
best model among them demands costly evaluation on the real robot. In this work
we ask: Can we rank the policies without running them in the real world? Our
main idea is that a predefined set of real world data can be used to evaluate
all policies, using out-of-distribution detection (OOD) techniques. In a sense,
this approach can be seen as a "unit test" to evaluate policies before any real
world execution. However, we find that by itself, the OOD score can be
inaccurate and very sensitive to the particular OOD method. Our main
contribution is a simple-yet-effective policy score that combines OOD with an
evaluation in simulation. We show that our score - VSDR - can significantly
improve the accuracy of policy ranking without requiring additional real world
data. We evaluate the effectiveness of VSDR on sim2real transfer in a robotic
grasping task with image inputs. We extensively evaluate different DR
parameters and OOD methods, and show that VSDR improves policy selection across
the board. More importantly, our method achieves significantly better ranking,
and uses significantly less data compared to baselines.</p>
  </details>
</details>
<details>
  <summary>31. <b>标题：Towards the Generalization of Contrastive Self-Supervised Learning</b></summary>
  <p><b>编号</b>：[138]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00743</p>
  <p><b>作者</b>：Weiran Huang,  Mingyang Yi,  Xuyang Zhao</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：attracted great attention since, two canonical contrastive self, trained models generalize, requires unlabeled data, embeds input data</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recently, self-supervised learning has attracted great attention since it
only requires unlabeled data for training. Contrastive learning is a popular
approach for self-supervised learning and empirically performs well in
practice. However, the theoretical understanding of its generalization ability
on downstream tasks is not well studied. To this end, we present a theoretical
explanation of how contrastive self-supervised pre-trained models generalize to
downstream tasks. Concretely, we quantitatively show that the self-supervised
model has generalization ability on downstream classification tasks if it
embeds input data into a feature space with distinguishing centers of classes
and closely clustered intra-class samples. With the above conclusion, we
further explore SimCLR and Barlow Twins, which are two canonical contrastive
self-supervised methods. We prove that the aforementioned feature space can be
obtained via any of the methods, and thus explain their success on the
generalization on downstream classification tasks. Finally, various experiments
are also conducted to verify our theoretical findings.</p>
  </details>
</details>
<details>
  <summary>32. <b>标题：URIR: Recommendation algorithm of user RNN encoder and item encoder  based on knowledge graph</b></summary>
  <p><b>编号</b>：[139]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00739</p>
  <p><b>作者</b>：Na zhao,  Zhen Long,  Zhi-Dan Zhao,  Jian Wang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：thereby obtaining better recommendation results, item encoder recommendation algorithm based, user recurrent neural network, perform inner product operation, obtain better user codes</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Due to a large amount of information, it is difficult for users to find what
they are interested in among the many choices. In order to improve users'
experience, recommendation systems have been widely used in music
recommendations, movie recommendations, online shopping, and other scenarios.
Recently, Knowledge Graph (KG) has been proven to be an effective tool to
improve the performance of recommendation systems. However, a huge challenge in
applying knowledge graphs for recommendation is how to use knowledge graphs to
obtain better user codes and item codes. In response to this problem, this
research proposes a user Recurrent Neural Network (RNN) encoder and item
encoder recommendation algorithm based on Knowledge Graph (URIR). This study
encodes items by capturing high-level neighbor information to generate items'
representation vectors and applies an RNN and items' representation vectors to
encode users to generate users' representation vectors, and then perform inner
product operation on users' representation vectors and items' representation
vectors to get probabilities of users interaction with items. Numerical
experiments on three real-world datasets demonstrate that URIR is superior
performance to state-of-the-art algorithms in indicators such as AUC,
Precision, Recall, and MRR. This implies that URIR can effectively use
knowledge graph to obtain better user codes and item codes, thereby obtaining
better recommendation results.</p>
  </details>
</details>
<details>
  <summary>33. <b>标题：Robust Deep Learning from Crowds with Belief Propagation</b></summary>
  <p><b>编号</b>：[141]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00734</p>
  <p><b>作者</b>：Hoyoung Kim,  Seunghyuk Cho,  Dongwoo Kim,  Jungseul Ok</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：em framework alternating variational inference, graphical model representing local dependencies, crowdsourcing systems enable us, based em algorithm, predictive model working</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Crowdsourcing systems enable us to collect noisy labels from crowd workers. A
graphical model representing local dependencies between workers and tasks
provides a principled way of reasoning over the true labels from the noisy
answers. However, one needs a predictive model working on unseen data directly
from crowdsourced datasets instead of the true labels in many cases. To infer
true labels and learn a predictive model simultaneously, we propose a new
data-generating process, where a neural network generates the true labels from
task features. We devise an EM framework alternating variational inference and
deep learning to infer the true labels and to update the neural network,
respectively. Experimental results with synthetic and real datasets show a
belief-propagation-based EM algorithm is robust to i) corruption in task
features, ii) multi-modal or mismatched worker prior, and iii) few spammers
submitting noises to many tasks.</p>
  </details>
</details>
<details>
  <summary>34. <b>标题：Outlining and Filling: Hierarchical Query Graph Generation for Answering  Complex Questions over Knowledge Graph</b></summary>
  <p><b>编号</b>：[142]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00732</p>
  <p><b>作者</b>：Yongrui Chen,  Huiying Li,  Guilin Qi,  Tianxing Wu,  Tenggou Wang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：graph generation model performs hierarchical generation, complex questions bring three new challenges, although recent approaches perform well, regard common complicated sparql syntax, new unified query graph grammar</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Query graph building aims to build correct executable SPARQL over the
knowledge graph for answering natural language questions. Although recent
approaches perform well by NN-based query graph ranking, more complex questions
bring three new challenges: complicated SPARQL syntax, huge search space for
ranking, and noisy query graphs with local ambiguity. This paper handles these
challenges. Initially, we regard common complicated SPARQL syntax as the
sub-graphs comprising of vertices and edges and propose a new unified query
graph grammar to adapt them. Subsequently, we propose a new two-stage approach
to build query graphs. In the first stage, the top-$k$ related instances
(entities, relations, etc.) are collected by simple strategies, as the
candidate instances. In the second stage, a graph generation model performs
hierarchical generation. It first outlines a graph structure whose vertices and
edges are empty slots, and then fills the appropriate instances into the slots,
thereby completing the query graph. Our approach decomposes the unbearable
search space of entire query graphs into affordable sub-spaces of operations,
meanwhile, leverages the global structural information to eliminate local
ambiguity. The experimental results demonstrate that our approach greatly
improves state-of-the-art on the hardest KGQA benchmarks and has an excellent
performance on complex questions.</p>
  </details>
</details>
<details>
  <summary>35. <b>标题：Adaptive Multi-receptive Field Spatial-Temporal Graph Convolutional  Network for Traffic Forecasting</b></summary>
  <p><b>编号</b>：[144]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00724</p>
  <p><b>作者</b>：Xing Wang (1),  Juan Zhao (1),  Lin Zhu (1),  Xu Zhou (2),  Zhao Li (2),  Junlan Feng (1),  Chao Deng (1),  Yong Zhang (2) ((1) China Mobile Research Institute, Beijing, China, (2) Electronic Engineering, Beijing University of Posts and Telecommunications, Beijing, China)</p>
  <p><b>备注</b>：To be published in IEEE GLOBECOM</p>
  <p><b>关键词</b>：intrinsic features make mobile network traffic forecasting far, two different domains consistently show amf, novel deep learning network architecture, mobile network traffic forecasting, fully connected deep network</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Mobile network traffic forecasting is one of the key functions in daily
network operation. A commercial mobile network is large, heterogeneous, complex
and dynamic. These intrinsic features make mobile network traffic forecasting
far from being solved even with recent advanced algorithms such as graph
convolutional network-based prediction approaches and various attention
mechanisms, which have been proved successful in vehicle traffic forecasting.
In this paper, we cast the problem as a spatial-temporal sequence prediction
task. We propose a novel deep learning network architecture, Adaptive
Multi-receptive Field Spatial-Temporal Graph Convolutional Networks
(AMF-STGCN), to model the traffic dynamics of mobile base stations. AMF-STGCN
extends GCN by (1) jointly modeling the complex spatial-temporal dependencies
in mobile networks, (2) applying attention mechanisms to capture various
Receptive Fields of heterogeneous base stations, and (3) introducing an extra
decoder based on a fully connected deep network to conquer the error
propagation challenge with multi-step forecasting. Experiments on four
real-world datasets from two different domains consistently show AMF-STGCN
outperforms the state-of-the-art methods.</p>
  </details>
</details>
<details>
  <summary>36. <b>标题：Edge-Level Explanations for Graph Neural Networks by Extending  Explainability Methods for Convolutional Neural Networks</b></summary>
  <p><b>编号</b>：[145]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00722</p>
  <p><b>作者</b>：Tetsu Kasanishi,  Xueting Wang,  Toshihiko Yamasaki</p>
  <p><b>备注</b>：4 pages, accepted at 23rd IEEE International Symposium on Multimedia (ISM), short paper, 2021</p>
  <p><b>关键词</b>：weighted class activation mapping, take graph data, graph neural networks, experimental results indicate, deep learning models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Graph Neural Networks (GNNs) are deep learning models that take graph data as
inputs, and they are applied to various tasks such as traffic prediction and
molecular property prediction. However, owing to the complexity of the GNNs, it
has been difficult to analyze which parts of inputs affect the GNN model's
outputs. In this study, we extend explainability methods for Convolutional
Neural Networks (CNNs), such as Local Interpretable Model-Agnostic Explanations
(LIME), Gradient-Based Saliency Maps, and Gradient-Weighted Class Activation
Mapping (Grad-CAM) to GNNs, and predict which edges in the input graphs are
important for GNN decisions. The experimental results indicate that the
LIME-based approach is the most efficient explainability method for multiple
tasks in the real-world situation, outperforming even the state-of-the-art
method in GNN explainability.</p>
  </details>
</details>
<details>
  <summary>37. <b>标题：Communication-Compressed Adaptive Gradient Method for Distributed  Nonconvex Optimization</b></summary>
  <p><b>编号</b>：[150]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00705</p>
  <p><b>作者</b>：Yujia Wang,  Lu Lin,  Jinghui Chen</p>
  <p><b>备注</b>：34 pages, 10 figures</p>
  <p><b>关键词</b>：efficient distributed adaptive gradient method converges, proposed distributed learning framework features, efficient adaptive gradient methods, distributed nonconvex optimization problem, side model update design</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Due to the explosion in the size of the training datasets, distributed
learning has received growing interest in recent years. One of the major
bottlenecks is the large communication cost between the central server and the
local workers. While error feedback compression has been proven to be
successful in reducing communication costs with stochastic gradient descent
(SGD), there are much fewer attempts in building communication-efficient
adaptive gradient methods with provable guarantees, which are widely used in
training large-scale machine learning models. In this paper, we propose a new
communication-compressed AMSGrad for distributed nonconvex optimization
problem, which is provably efficient. Our proposed distributed learning
framework features an effective gradient compression strategy and a worker-side
model update design. We prove that the proposed communication-efficient
distributed adaptive gradient method converges to the first-order stationary
point with the same iteration complexity as uncompressed vanilla AMSGrad in the
stochastic nonconvex optimization setting. Experiments on various benchmarks
back up our theory.</p>
  </details>
</details>
<details>
  <summary>38. <b>标题：Graph Structural Attack by Spectral Distanc</b></summary>
  <p><b>编号</b>：[159]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00684</p>
  <p><b>作者</b>：Lu Lin,  Ethan Blaser,  Hongning Wang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：experiments demonstrate remarkable effectiveness, disrupt graph spectral filters, effective graph structural attack, graph learning tasks, graph convolutional networks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Graph Convolutional Networks (GCNs) have fueled a surge of interest due to
their superior performance on graph learning tasks, but are also shown
vulnerability to adversarial attacks. In this paper, an effective graph
structural attack is investigated to disrupt graph spectral filters in the
Fourier domain. We define the spectral distance based on the eigenvalues of
graph Laplacian to measure the disruption of spectral filters. We then generate
edge perturbations by simultaneously maximizing a task-specific attack
objective and the proposed spectral distance. The experiments demonstrate
remarkable effectiveness of the proposed attack in the white-box setting at
both training and test time. Our qualitative analysis shows the connection
between the attack behavior and the imposed changes on the spectral
distribution, which provides empirical evidence that maximizing spectral
distance is an effective manner to change the structural property of graphs in
the spatial domain and perturb the frequency components in the Fourier domain.</p>
  </details>
</details>
<details>
  <summary>39. <b>标题：Comparative Explanations of Recommendations</b></summary>
  <p><b>编号</b>：[165]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00670</p>
  <p><b>作者</b>：Aobo Yang,  Nan Wang,  Renqin Cai,  Hongbo Deng,  Hongning Wang</p>
  <p><b>备注</b>：17 pages, 4 figures</p>
  <p><b>关键词</b>：two large recommendation benchmark datasets, art explainable recommendation algorithms demonstrate, new explanation quality metric based, first extract one sentence, e ., comparative explanations</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As recommendation is essentially a comparative (or ranking) process, a good
explanation should illustrate to users why an item is believed to be better
than another, i.e., comparative explanations about the recommended items.
Ideally, after reading the explanations, a user should reach the same ranking
of items as the system's. Unfortunately, little research attention has yet been
paid on such comparative explanations.
In this work, we develop an extract-and-refine architecture to explain the
relative comparisons among a set of ranked items from a recommender system. For
each recommended item, we first extract one sentence from its associated
reviews that best suits the desired comparison against a set of reference
items. Then this extracted sentence is further articulated with respect to the
target user through a generative model to better explain why the item is
recommended. We design a new explanation quality metric based on BLEU to guide
the end-to-end training of the extraction and refinement components, which
avoids generation of generic content. Extensive offline evaluations on two
large recommendation benchmark datasets and serious user studies against an
array of state-of-the-art explainable recommendation algorithms demonstrate the
necessity of comparative explanations and the effectiveness of our solution.</p>
  </details>
</details>
<details>
  <summary>40. <b>标题：RMNA: A Neighbor Aggregation-Based Knowledge Graph Representation  Learning Model Using Rule Mining</b></summary>
  <p><b>编号</b>：[171]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00658</p>
  <p><b>作者</b>：Ling Chen,  Jun Cui,  Xing Tang,  Chaodu Song,  Yuntao Qian,  Yansheng Li,  Yongjun Zhang</p>
  <p><b>备注</b>：22 pages, 2 figures</p>
  <p><b>关键词</b>：uses selected horn rules, art traditional representation learning, existing narl models either, narl model named rmna, models show competitive performance</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Although the state-of-the-art traditional representation learning (TRL)
models show competitive performance on knowledge graph completion, there is no
parameter sharing between the embeddings of entities, and the connections
between entities are weak. Therefore, neighbor aggregation-based representation
learning (NARL) models are proposed, which encode the information in the
neighbors of an entity into its embeddings. However, existing NARL models
either only utilize one-hop neighbors, ignoring the information in multi-hop
neighbors, or utilize multi-hop neighbors by hierarchical neighbor aggregation,
destroying the completeness of multi-hop neighbors. In this paper, we propose a
NARL model named RMNA, which obtains and filters horn rules through a rule
mining algorithm, and uses selected horn rules to transform valuable multi-hop
neighbors into one-hop neighbors, therefore, the information in valuable
multi-hop neighbors can be completely utilized by aggregating these one-hop
neighbors. In experiments, we compare RMNA with the state-of-the-art TRL models
and NARL models. The results show that RMNA has a competitive performance.</p>
  </details>
</details>
<details>
  <summary>41. <b>标题：Collage: Automated Integration of Deep Learning Backends</b></summary>
  <p><b>编号</b>：[173]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00655</p>
  <p><b>作者</b>：Byungsoo Jeon,  Sunghyun Park,  Peiyuan Liao,  Sheng Xu,  Tianqi Chen,  Zhihao Jia</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：collage automatically integrates multiple backends together without manual intervention, current dl frameworks require significant manual effort, two different nvidia gpus, outperforms existing frameworks, integrating dl backends</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Strong demands for efficient deployment of Deep Learning (DL) applications
prompt the rapid development of a rich DL ecosystem. To keep up with its fast
advancement, it is crucial for DL frameworks to efficiently integrate a variety
of optimized libraries and runtimes as their backends and generate the fastest
possible executable by using them properly. However, current DL frameworks
require significant manual effort to integrate diverse backends and often fail
to deliver high performance. In this paper, we propose Collage, an automatic
framework for integrating DL backends. Collage provides a backend registration
interface that allows users to precisely specify the capability of various
backends. By leveraging the specifications of available backends, Collage
searches for an optimized backend placement for a given workload and execution
environment. Our evaluation shows that Collage automatically integrates
multiple backends together without manual intervention, and outperforms
existing frameworks by 1.21x, 1.39x, 1.40x on two different NVIDIA GPUs and an
Intel CPU respectively.</p>
  </details>
</details>
<details>
  <summary>42. <b>标题：Settling the Horizon-Dependence of Sample Complexity in Reinforcement  Learning</b></summary>
  <p><b>编号</b>：[180]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00633</p>
  <p><b>作者</b>：Yuanzhi Li,  Ruosong Wang,  Lin F. Yang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：1 )$- optimal policy using $\ mathrm, polylog }( h )$ episodes, polylog }( h )$ dependence, h $, previous work, horizon markov decision processes</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recently there is a surge of interest in understanding the horizon-dependence
of the sample complexity in reinforcement learning (RL). Notably, for an RL
environment with horizon length $H$, previous work have shown that there is a
probably approximately correct (PAC) algorithm that learns an $O(1)$-optimal
policy using $\mathrm{polylog}(H)$ episodes of environment interactions when
the number of states and actions is fixed. It is yet unknown whether the
$\mathrm{polylog}(H)$ dependence is necessary or not. In this work, we resolve
this question by developing an algorithm that achieves the same PAC guarantee
while using only $O(1)$ episodes of environment interactions, completely
settling the horizon-dependence of the sample complexity in RL. We achieve this
bound by (i) establishing a connection between value functions in discounted
and finite-horizon Markov decision processes (MDPs) and (ii) a novel
perturbation analysis in MDPs. We believe our new techniques are of independent
interest and could be applied in related questions in RL.</p>
  </details>
</details>
<details>
  <summary>43. <b>标题：Clinical Evidence Engine: Proof-of-Concept For A  Clinical-Domain-Agnostic Decision Support Infrastructure</b></summary>
  <p><b>编号</b>：[185]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00621</p>
  <p><b>作者</b>：Bojian Hou,  Hao Zhang,  Gur Ladizhinsky,  Gur Ladizhinsky,  Stephen Yang,  Volodymyr Kuleshov,  Fei Wang,  Qian Yang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：complex datasets increasingly characterize modern clinical decision support systems, effectively identify clinical trial reports based, illustrating two example use scenarios, catheter infection among adult patients, require arterial catheters ), intervention</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Abstruse learning algorithms and complex datasets increasingly characterize
modern clinical decision support systems (CDSS). As a result, clinicians cannot
easily or rapidly scrutinize the CDSS recommendation when facing a difficult
diagnosis or treatment decision in practice. Over-trust or under-trust are
frequent. Prior research has explored supporting such assessments by explaining
DST data inputs and algorithmic mechanisms. This paper explores a different
approach: Providing precisely relevant, scientific evidence from biomedical
literature. We present a proof-of-concept system, Clinical Evidence Engine, to
demonstrate the technical and design feasibility of this approach across three
domains (cardiovascular diseases, autism, cancer). Leveraging Clinical BioBERT,
the system can effectively identify clinical trial reports based on lengthy
clinical questions (e.g., "risks of catheter infection among adult patients in
intensive care unit who require arterial catheters, if treated with povidone
iodine-alcohol"). This capability enables the system to identify clinical
trials relevant to diagnostic/treatment hypotheses -- a clinician's or a
CDSS's. Further, Clinical Evidence Engine can identify key parts of a clinical
trial abstract, including patient population (e.g., adult patients in intensive
care unit who require arterial catheters), intervention (povidone
iodine-alcohol), and outcome (risks of catheter infection). This capability
opens up the possibility of enabling clinicians to 1) rapidly determine the
match between a clinical trial and a clinical question, and 2) understand the
result and contexts of the trial without extensive reading. We demonstrate this
potential by illustrating two example use scenarios of the system. We discuss
the idea of designing DST explanations not as specific to a DST or an
algorithm, but as a domain-agnostic decision support infrastructure.</p>
  </details>
</details>
<details>
  <summary>44. <b>标题：R-BERT-CNN: Drug-target interactions extraction from biomedical  literature</b></summary>
  <p><b>编号</b>：[188]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00611</p>
  <p><b>作者</b>：Jehad Aldahdooh,  Ziaurrehman Tanoli,  Jing Tang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：biocreative vi chemprot test corpus )., biocreative vii drugprot test corpus, biocreative vii challenge, often manually extracted, micro f1 score</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this research, we present our work participation for the DrugProt task of
BioCreative VII challenge. Drug-target interactions (DTIs) are critical for
drug discovery and repurposing, which are often manually extracted from the
experimental articles. There are >32M biomedical articles on PubMed and
manually extracting DTIs from such a huge knowledge base is challenging. To
solve this issue, we provide a solution for Track 1, which aims to extract 10
types of interactions between drug and protein entities. We applied an Ensemble
Classifier model that combines BioMed-RoBERTa, a state of art language model,
with Convolutional Neural Networks (CNN) to extract these relations. Despite
the class imbalances in the BioCreative VII DrugProt test corpus, our model
achieves a good performance compared to the average of other submissions in the
challenge, with the micro F1 score of 55.67% (and 63% on BioCreative VI
ChemProt test corpus). The results show the potential of deep learning in
extracting various types of DTIs.</p>
  </details>
</details>
<details>
  <summary>45. <b>标题：Graph Embedding with Hierarchical Attentive Membership</b></summary>
  <p><b>编号</b>：[193]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00604</p>
  <p><b>作者</b>：Lu Lin,  Ethan Blaser,  Hongning Wang</p>
  <p><b>备注</b>：to be published in WSDM 2022</p>
  <p><b>关键词</b>：novel hierarchical attentive membership model, enables explainable embedding learning, defined hierarchical grouping structure, learned node embeddings along, art graph embedding solutions</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The exploitation of graph structures is the key to effectively learning
representations of nodes that preserve useful information in graphs. A
remarkable property of graph is that a latent hierarchical grouping of nodes
exists in a global perspective, where each node manifests its membership to a
specific group based on the context composed by its neighboring nodes. Most
prior works ignore such latent groups and nodes' membership to different
groups, not to mention the hierarchy, when modeling the neighborhood structure.
Thus, they fall short of delivering a comprehensive understanding of the nodes
under different contexts in a graph. In this paper, we propose a novel
hierarchical attentive membership model for graph embedding, where the latent
memberships for each node are dynamically discovered based on its neighboring
context. Both group-level and individual-level attentions are performed when
aggregating neighboring states to generate node embeddings. We introduce
structural constraints to explicitly regularize the inferred memberships of
each node, such that a well-defined hierarchical grouping structure is
captured. The proposed model outperformed a set of state-of-the-art graph
embedding solutions on node classification and link prediction tasks in a
variety of graphs including citation networks and social networks. Qualitative
evaluations visualize the learned node embeddings along with the inferred
memberships, which proved the concept of membership hierarchy and enables
explainable embedding learning in graphs.</p>
  </details>
</details>
<details>
  <summary>46. <b>标题：Unsupervised Learning to Subphenotype Delirium Patients from Electronic  Health Records</b></summary>
  <p><b>编号</b>：[201]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00592</p>
  <p><b>作者</b>：Yiqing Zhao,  Yuan Luo</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：work could recalibrate existing delirium prediction models, detect delirium using medical information mart, common acute onset brain dysfunction, highly heterogeneous medical conditions, underlying medical condition</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Delirium is a common acute onset brain dysfunction in the emergency setting
and is associated with higher mortality. It is difficult to detect and monitor
since its presentations and risk factors can be different depending on the
underlying medical condition of patients. In our study, we aimed to identify
subtypes within the delirium population and build subgroup-specific predictive
models to detect delirium using Medical Information Mart for Intensive Care IV
(MIMIC-IV) data. We showed that clusters exist within the delirium population.
Differences in feature importance were also observed for subgroup-specific
predictive models. Our work could recalibrate existing delirium prediction
models for each delirium subgroup and improve the precision of delirium
detection and monitoring for ICU or emergency department patients who had
highly heterogeneous medical conditions.</p>
  </details>
</details>
<details>
  <summary>47. <b>标题：JEDAI Explains Decision-Making AI</b></summary>
  <p><b>编号</b>：[205]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00585</p>
  <p><b>作者</b>：Trevor Angle,  Naman Shah,  Pulkit Verma,  Siddharth Srivastava</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：also provides users customized explanations, jedai helps users create high, paper presents jedai, educational efforts aimed, ai system designed</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper presents JEDAI, an AI system designed for outreach and educational
efforts aimed at non-AI experts. JEDAI features a novel synthesis of research
ideas from integrated task and motion planning and explainable AI. JEDAI helps
users create high-level, intuitive plans while ensuring that they will be
executable by the robot. It also provides users customized explanations about
errors and helps improve their understanding of AI planning as well as the
limits and capabilities of the underlying robot system.</p>
  </details>
</details>
<details>
  <summary>48. <b>标题：What Went Wrong? Explaining Overall Dialogue Quality through  Utterance-Level Impacts</b></summary>
  <p><b>编号</b>：[209]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00572</p>
  <p><b>作者</b>：James D. Finch,  Sarah E. Finch,  Jinho D. Choi</p>
  <p><b>备注</b>：Accepted at the 3rd Workshop on NLP for ConvAI</p>
  <p><b>关键词</b>：dialogue system often requires intensive developer effort, overall user rating without utterance, allowing resultant model conclusions, overall dialogue quality, overall dialogue quality</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Improving user experience of a dialogue system often requires intensive
developer effort to read conversation logs, run statistical analyses, and
intuit the relative importance of system shortcomings. This paper presents a
novel approach to automated analysis of conversation logs that learns the
relationship between user-system interactions and overall dialogue quality.
Unlike prior work on utterance-level quality prediction, our approach learns
the impact of each interaction from the overall user rating without
utterance-level annotation, allowing resultant model conclusions to be derived
on the basis of empirical evidence and at low cost. Our model identifies
interactions that have a strong correlation with the overall dialogue quality
in a chatbot setting. Experiments show that the automated analysis from our
model agrees with expert judgments, making this work the first to show that
such weakly-supervised learning of utterance-level quality prediction is highly
achievable.</p>
  </details>
</details>
<details>
  <summary>49. <b>标题：An Approach to Inference-Driven Dialogue Management within a Social  Chatbot</b></summary>
  <p><b>编号</b>：[210]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00570</p>
  <p><b>作者</b>：Sarah E. Finch,  James D. Finch,  Daniil Huryn,  William Hutsell,  Xiaoyuan Huang,  Han He,  Jinho D. Choi</p>
  <p><b>备注</b>：Published in 4th Proceedings of Alexa Prize (Alexa Prize 2020)</p>
  <p><b>关键词</b>：synthesize new predicates using efficient graph matching, novel dialogue management approach based, first stage translates user utterances, synthesize new knowledge, understanding latent semantics</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present a chatbot implementing a novel dialogue management approach based
on logical inference. Instead of framing conversation a sequence of response
generation tasks, we model conversation as a collaborative inference process in
which speakers share information to synthesize new knowledge in real time. Our
chatbot pipeline accomplishes this modelling in three broad stages. The first
stage translates user utterances into a symbolic predicate representation. The
second stage then uses this structured representation in conjunction with a
larger knowledge base to synthesize new predicates using efficient graph
matching. In the third and final stage, our bot selects a small subset of
predicates and translates them into an English response. This approach lends
itself to understanding latent semantics of user inputs, flexible initiative
taking, and responses that are novel and coherent with the dialogue context.</p>
  </details>
</details>
<details>
  <summary>50. <b>标题：Fast Global Convergence of Policy Optimization for Constrained MDPs</b></summary>
  <p><b>编号</b>：[216]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00552</p>
  <p><b>作者</b>：Tao Liu,  Ruida Zhou,  Dileep Kalathil,  P. R. Kumar,  Chao Tian</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：horizon constrained markov decision process framework, faster convergence rate $\ mathcal, }( 1 /\ sqrt, })$ global convergence rate, natural policy gradient</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We address the issue of safety in reinforcement learning. We pose the problem
in a discounted infinite-horizon constrained Markov decision process framework.
Existing results have shown that gradient-based methods are able to achieve an
$\mathcal{O}(1/\sqrt{T})$ global convergence rate both for the optimality gap
and the constraint violation. We exhibit a natural policy gradient-based
algorithm that has a faster convergence rate $\mathcal{O}(\log(T)/T)$ for both
the optimality gap and the constraint violation. When Slater's condition is
satisfied and known a priori, zero constraint violation can be further
guaranteed for a sufficiently large $T$ while maintaining the same convergence
rate.</p>
  </details>
</details>
<details>
  <summary>51. <b>标题：Cross-Domain Reasoning via Template Filling</b></summary>
  <p><b>编号</b>：[218]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00539</p>
  <p><b>作者</b>：Dheeraj Rajagopal,  Vivek Khetan,  Bogdan Sacaleanu,  Anatole Gershman,  Andrew Fano,  Eduard Hovy</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：experiments across several pretrained encoder, filling enables pretrained sequence, sequence models across domains, depth error analysis, reasoning across domains</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we explore the ability of sequence to sequence models to
perform cross-domain reasoning. Towards this, we present a
prompt-template-filling approach to enable sequence to sequence models to
perform cross-domain reasoning. We also present a case-study with commonsense
and health and well-being domains, where we study how prompt-template-filling
enables pretrained sequence to sequence models across domains. Our experiments
across several pretrained encoder-decoder models show that cross-domain
reasoning is challenging for current models. We also show an in-depth error
analysis and avenues for future research for reasoning across domains</p>
  </details>
</details>
<details>
  <summary>52. <b>标题：PnPOOD : Out-Of-Distribution Detection for Text Classification via Plug  andPlay Data Augmentation</b></summary>
  <p><b>编号</b>：[231]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00506</p>
  <p><b>作者</b>：Mrinal Rawat,  Ramya Hebbalaguppe,  Lovekesh Vig</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：method generates high quality discriminative samples close, dathathri et al ., 2020 )., socheret al ., 2013 )., domain sample generation using, stanford sentiment treebank dataset</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>While Out-of-distribution (OOD) detection has been well explored in computer
vision, there have been relatively few prior attempts in OOD detection for NLP
classification. In this paper we argue that these prior attempts do not fully
address the OOD problem and may suffer from data leakage and poor calibration
of the resulting models. We present PnPOOD, a data augmentation technique to
perform OOD detection via out-of-domain sample generation using the recently
proposed Plug and Play Language Model (Dathathri et al., 2020). Our method
generates high quality discriminative samples close to the class boundaries,
resulting in accurate OOD detection at test time. We demonstrate that our model
outperforms prior models on OOD sample detection, and exhibits lower
calibration error on the 20 newsgroup text and Stanford Sentiment Treebank
dataset (Lang, 1995; Socheret al., 2013). We further highlight an important
data leakage issue with datasets used in prior attempts at OOD detection, and
share results on a new dataset for OOD detection that does not suffer from the
same problem.</p>
  </details>
</details>
<details>
  <summary>53. <b>标题：DSC-IITISM at FinCausal 2021: Combining POS tagging with Attention-based  Contextual Representations for Identifying Causal Relationships in Financial  Documents</b></summary>
  <p><b>编号</b>：[235]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00490</p>
  <p><b>作者</b>：Gunjan Haldar,  Aman Mittal,  Pradyumna Gupta</p>
  <p><b>备注</b>：5 pages, 5 tables</p>
  <p><b>关键词</b>：financial documents using transformers, causality detection draws plenty, natural language processing, modern transformer models, explore several methods</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Causality detection draws plenty of attention in the field of Natural
Language Processing and linguistics research. It has essential applications in
information retrieval, event prediction, question answering, financial
analysis, and market research. In this study, we explore several methods to
identify and extract cause-effect pairs in financial documents using
transformers. For this purpose, we propose an approach that combines POS
tagging with the BIO scheme, which can be integrated with modern transformer
models to address this challenge of identifying causality in a given text. Our
best methodology achieves an F1-Score of 0.9551, and an Exact Match Score of
0.8777 on the blind test in the FinCausal-2021 Shared Task at the FinCausal
2021 Workshop.</p>
  </details>
</details>
<details>
  <summary>54. <b>标题：Graph Tree Neural Networks</b></summary>
  <p><b>编号</b>：[261]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00424</p>
  <p><b>作者</b>：Seokjun Kim,  Jaeeun Jang,  Hee-seok Jung,  Hyeoncheol Kim</p>
  <p><b>备注</b>：This paper was submitted as a simple experiment. It has been slightly modified from the original</p>
  <p><b>关键词</b>：supervised learning using graph tree recursive neural network, graph tree recursive attention networks, propose graph tree neural networks, graph tree recursive autoencoders, recently shown good performance</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Graph neural networks (GNNs) have recently shown good performance in various
fields. In this paper, we propose graph tree neural networks (GTNNs) designed
to solve the problems of existing networks by analyzing the structure of human
neural networks. In GTNNs, information units are related to the form of a graph
and then they become a bigger unit of information again and have a relationship
with other information units. At this point, the unit of information is a set
of neurons, and we can express it as a vector with GTNN. Defining the starting
and ending points in a single graph is difficult, and a tree cannot express the
relationship among sibling nodes. However, a graph tree can be expressed using
leaf and root nodes as its starting and ending points and the relationship
among sibling nodes. Depth-first convolution (DFC) encodes the interaction
result from leaf nodes to the root node in a bottom-up approach, and
depth-first deconvolution (DFD) decodes the interaction result from the root
node to the leaf nodes in a top-down approach. GTNN is data-driven learning in
which the number of convolutions varies according to the depth of the tree.
Moreover, learning features of different types together is possible.
Supervised, unsupervised, and semi-supervised learning using graph tree
recursive neural network (GTR) , graph tree recursive attention networks
(GTRAs), and graph tree recursive autoencoders (GTRAEs) are introduced in this
paper. We experimented with a simple toy test with source code dataset.</p>
  </details>
</details>
<details>
  <summary>55. <b>标题：Interpreting Deep Knowledge Tracing Model on EdNet Dataset</b></summary>
  <p><b>编号</b>：[263]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00419</p>
  <p><b>作者</b>：Deliang Wang,  Yu Lu,  Qinggang Meng,  Penghe Chen</p>
  <p><b>备注</b>：This paper has been accepted and presented in AAAI 2021 Workshop on AI Education</p>
  <p><b>关键词</b>：koedinger 2009 ),, whose size, preliminary experiment results show, kt model mainly adopts, lu et al, knowledge tracing models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>With more deep learning techniques being introduced into the knowledge
tracing domain, the interpretability issue of the knowledge tracing models has
aroused researchers' attention. Our previous study(Lu et al. 2020) on building
and interpreting the KT model mainly adopts the ASSISTment dataset(Feng,
Heffernan, and Koedinger 2009),, whose size is relatively small. In this work,
we perform the similar tasks but on a large and newly available dataset, called
EdNet(Choi et al. 2020). The preliminary experiment results show the
effectiveness of the interpreting techniques, while more questions and tasks
are worthy to be further explored and accomplished.</p>
  </details>
</details>
<details>
  <summary>56. <b>标题：A Simple Approach to Image Tilt Correction with Self-Attention MobileNet  for Smartphones</b></summary>
  <p><b>编号</b>：[274]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00398</p>
  <p><b>作者</b>：Siddhant Garg,  Debi Prasanna Mohanty,  Siva Prasad Thota,  Sukumar Moharana</p>
  <p><b>备注</b>：Accepted - British Machine vision Conference 2021</p>
  <p><b>关键词</b>：standard convolutional kernels, snapdragon 750 octa, predict multiple angles, least 4 milliseconds, inverted bottleneck blocks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The main contributions of our work are two-fold. First, we present a
Self-Attention MobileNet, called SA-MobileNet Network that can model long-range
dependencies between the image features instead of processing the local region
as done by standard convolutional kernels. SA-MobileNet contains self-attention
modules integrated with the inverted bottleneck blocks of the MobileNetV3 model
which results in modeling of both channel-wise attention and spatial attention
of the image features and at the same time introduce a novel self-attention
architecture for low-resource devices. Secondly, we propose a novel training
pipeline for the task of image tilt detection. We treat this problem in a
multi-label scenario where we predict multiple angles for a tilted input image
in a narrow interval of range 1-2 degrees, depending on the dataset used. This
process induces an implicit correlation between labels without any
computational overhead of the second or higher-order methods in multi-label
learning. With the combination of our novel approach and the architecture, we
present state-of-the-art results on detecting the image tilt angle on mobile
devices as compared to the MobileNetV3 model. Finally, we establish that
SA-MobileNet is more accurate than MobileNetV3 on SUN397, NYU-V1, and ADE20K
datasets by 6.42%, 10.51%, and 9.09% points respectively, and faster by at
least 4 milliseconds on Snapdragon 750 Octa-core.</p>
  </details>
</details>
<details>
  <summary>57. <b>标题：Conical Classification For Computationally Efficient One-Class Topic  Determination</b></summary>
  <p><b>编号</b>：[282]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00375</p>
  <p><b>作者</b>：Sameer Khanna</p>
  <p><b>备注</b>：Findings in Empirical Methods in Natural Language Processing 2021</p>
  <p><b>关键词</b>：vector space model representing, research regarding efficient approaches, also propose normal exclusion, propose conical classification, computationally efficient manner</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As the Internet grows in size, so does the amount of text based information
that exists. For many application spaces it is paramount to isolate and
identify texts that relate to a particular topic. While one-class
classification would be ideal for such analysis, there is a relative lack of
research regarding efficient approaches with high predictive power. By noting
that the range of documents we wish to identify can be represented as positive
linear combinations of the Vector Space Model representing our text, we propose
Conical classification, an approach that allows us to identify if a document is
of a particular topic in a computationally efficient manner. We also propose
Normal Exclusion, a modified version of Bi-Normal Separation that makes it more
suitable within the one-class classification context. We show in our analysis
that our approach not only has higher predictive power on our datasets, but is
also faster to compute.</p>
  </details>
</details>
<details>
  <summary>58. <b>标题：Sustainable AI: Environmental Implications, Challenges and Opportunities</b></summary>
  <p><b>编号</b>：[283]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00364</p>
  <p><b>作者</b>：Carole-Jean Wu,  Ramya Raghavendra,  Udit Gupta,  Bilge Acun,  Newsha Ardalani,  Kiwan Maeng,  Gloria Chang,  Fiona Aga Behram,  James Huang,  Charles Bai,  Michael Gschwind,  Anurag Gupta,  Myle Ott,  Anastasia Melnikov,  Salvatore Candido,  David Brooks,  Geeta Chauhan,  Benjamin Lee,  Hsien-Hsin S. Lee,  Bugra Akyildiz,  Maximilian Balandat,  Joe Spisak,  Ravi Jain,  Mike Rabbat,  Kim Hazelwood</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：scale machine learning use cases, model development cycle across industry, important development directions across, linear growth trends, overall carbon footprint</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper explores the environmental impact of the super-linear growth
trends for AI from a holistic perspective, spanning Data, Algorithms, and
System Hardware. We characterize the carbon footprint of AI computing by
examining the model development cycle across industry-scale machine learning
use cases and, at the same time, considering the life cycle of system hardware.
Taking a step further, we capture the operational and manufacturing carbon
footprint of AI computing and present an end-to-end analysis for what and how
hardware-software design and at-scale optimization can help reduce the overall
carbon footprint of AI. Based on the industry experience and lessons learned,
we share the key challenges and chart out important development directions
across the many dimensions of AI. We hope the key messages and insights
presented in this paper can inspire the community to advance the field of AI in
an environmentally-responsible manner.</p>
  </details>
</details>
<details>
  <summary>59. <b>标题：A Survey on the Robustness of Feature Importance and Counterfactual  Explanations</b></summary>
  <p><b>编号</b>：[285]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00358</p>
  <p><b>作者</b>：Saumitra Mishra,  Sanghamitra Dutta,  Jason Long,  Daniele Magazzeni</p>
  <p><b>备注</b>：4 pages plus references. Accepted at the workshop on Explainable AI in Finance (XAI-FIN21). Camera-ready version</p>
  <p><b>关键词</b>：extending current robustness analysis approaches, classify different robustness approaches, identify reliable explainability methods, unify existing definitions, relatively lesser effort</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>There exist several methods that aim to address the crucial task of
understanding the behaviour of AI/ML models. Arguably, the most popular among
them are local explanations that focus on investigating model behaviour for
individual instances. Several methods have been proposed for local analysis,
but relatively lesser effort has gone into understanding if the explanations
are robust and accurately reflect the behaviour of underlying models. In this
work, we present a survey of the works that analysed the robustness of two
classes of local explanations (feature importance and counterfactual
explanations) that are popularly used in analysing AI/ML models in finance. The
survey aims to unify existing definitions of robustness, introduces a taxonomy
to classify different robustness approaches, and discusses some interesting
results. Finally, the survey introduces some pointers about extending current
robustness analysis approaches so as to identify reliable explainability
methods.</p>
  </details>
</details>
<details>
  <summary>60. <b>标题：Multi-Agent Advisor Q-Learning</b></summary>
  <p><b>编号</b>：[288]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00345</p>
  <p><b>作者</b>：Sriram Ganapathi Subramanian,  Matthew E. Taylor,  Kate Larson,  Mark Crowley</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：advising multiple intelligent reinforcement agents, present two novel q, sum stochastic game environments, help improve reinforcement learning, sum stochastic games</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In the last decade, there have been significant advances in multi-agent
reinforcement learning (MARL) but there are still numerous challenges, such as
high sample complexity and slow convergence to stable policies, that need to be
overcome before wide-spread deployment is possible. However, many real-world
environments already, in practice, deploy sub-optimal or heuristic approaches
for generating policies. An interesting question which arises is how to best
use such approaches as advisors to help improve reinforcement learning in
multi-agent domains. In this paper, we provide a principled framework for
incorporating action recommendations from online sub-optimal advisors in
multi-agent settings. We describe the problem of ADvising Multiple Intelligent
Reinforcement Agents (ADMIRAL) in nonrestrictive general-sum stochastic game
environments and present two novel Q-learning based algorithms: ADMIRAL -
Decision Making (ADMIRAL-DM) and ADMIRAL - Advisor Evaluation (ADMIRAL-AE),
which allow us to improve learning by appropriately incorporating advice from
an advisor (ADMIRAL-DM), and evaluate the effectiveness of an advisor
(ADMIRAL-AE). We analyze the algorithms theoretically and provide fixed-point
guarantees regarding their learning in general-sum stochastic games.
Furthermore, extensive experiments illustrate that these algorithms: can be
used in a variety of environments, have performances that compare favourably to
other related baselines, can scale to large state-action spaces, and are robust
to poor advice from advisors.</p>
  </details>
</details>
<details>
  <summary>61. <b>标题：Causal Discovery in Linear Structural Causal Models with Deterministic  Relations</b></summary>
  <p><b>编号</b>：[291]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00341</p>
  <p><b>作者</b>：Yuqin Yang,  Mohamed Nafea,  AmirEmad Ghassami,  Negar Kiyavash</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：causal discovery form observational data generated, existing work almost exclusively focus, linear structural causal models, e ., models, underlying causal structure</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Linear structural causal models (SCMs) -- in which each observed variable is
generated by a subset of the other observed variables as well as a subset of
the exogenous sources -- are pervasive in causal inference and casual
discovery. However, for the task of causal discovery, existing work almost
exclusively focus on the submodel where each observed variable is associated
with a distinct source with non-zero variance. This results in the restriction
that no observed variable can deterministically depend on other observed
variables or latent confounders. In this paper, we extend the results on
structure learning by focusing on a subclass of linear SCMs which do not have
this property, i.e., models in which observed variables can be causally
affected by any subset of the sources, and are allowed to be a deterministic
function of other observed variables or latent confounders. This allows for a
more realistic modeling of influence or information propagation in systems. We
focus on the task of causal discovery form observational data generated from a
member of this subclass. We derive a set of necessary and sufficient conditions
for unique identifiability of the causal structure. To the best of our
knowledge, this is the first work that gives identifiability results for causal
discovery under both latent confounding and deterministic relationships.
Further, we propose an algorithm for recovering the underlying causal structure
when the aforementioned conditions are satisfied. We validate our theoretical
results both on synthetic and real datasets.</p>
  </details>
</details>
<details>
  <summary>62. <b>标题：3DP3: 3D Scene Perception via Probabilistic Programming</b></summary>
  <p><b>编号</b>：[298]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00312</p>
  <p><b>作者</b>：Nishad Gothoskar,  Marco Cusumano-Towner,  Ben Zinberg,  Matin Ghavamizadeh,  Falk Pollok,  Austin Garrett,  Joshua B. Tenenbaum,  Dan Gutfreund,  Vikash K. Mansinghka</p>
  <p><b>备注</b>：NeurIPS 2021</p>
  <p><b>关键词</b>：novel involutive mcmc updates, depth image likelihoods based, underlying latent 3d scene, 6dof object pose estimation, 3dp3 enables scene understanding</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present 3DP3, a framework for inverse graphics that uses inference in a
structured generative model of objects, scenes, and images. 3DP3 uses (i) voxel
models to represent the 3D shape of objects, (ii) hierarchical scene graphs to
decompose scenes into objects and the contacts between them, and (iii) depth
image likelihoods based on real-time graphics. Given an observed RGB-D image,
3DP3's inference algorithm infers the underlying latent 3D scene, including the
object poses and a parsimonious joint parametrization of these poses, using
fast bottom-up pose proposals, novel involutive MCMC updates of the scene graph
structure, and, optionally, neural object detectors and pose estimators. We
show that 3DP3 enables scene understanding that is aware of 3D shape,
occlusion, and contact structure. Our results demonstrate that 3DP3 is more
accurate at 6DoF object pose estimation from real images than deep learning
baselines and shows better generalization to challenging scenes with novel
viewpoints, contact, and partial observability.</p>
  </details>
</details>
<details>
  <summary>63. <b>标题：EmpBot: A T5-based Empathetic Chatbot focusing on Sentiments</b></summary>
  <p><b>编号</b>：[299]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00310</p>
  <p><b>作者</b>：Emmanouil Zaranis,  Georgios Paraskevopoulos,  Athanasios Katsamanis,  Alexandros Potamianos</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：empathy forcing auxiliary losses favor empathetic responses, transformer pretrained language model, human evaluation results indicate, favoring empathetic responses, response language modeling</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we introduce EmpBot: an end-to-end empathetic chatbot.
Empathetic conversational agents should not only understand what is being
discussed, but also acknowledge the implied feelings of the conversation
partner and respond appropriately. To this end, we propose a method based on a
transformer pretrained language model (T5). Specifically, during finetuning we
propose to use three objectives: response language modeling, sentiment
understanding, and empathy forcing. The first objective is crucial for
generating relevant and coherent responses, while the next ones are significant
for acknowledging the sentimental state of the conversational partner and for
favoring empathetic responses. We evaluate our model on the EmpatheticDialogues
dataset using both automated metrics and human evaluation. The inclusion of the
sentiment understanding and empathy forcing auxiliary losses favor empathetic
responses, as human evaluation results indicate, comparing with the current
state-of-the-art.</p>
  </details>
</details>
<details>
  <summary>64. <b>标题：TargetUM: Targeted High-Utility Itemset Querying</b></summary>
  <p><b>编号</b>：[300]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00309</p>
  <p><b>作者</b>：Jinbao Miao,  Shicheng Wan,  Wensheng Gan,  Jiayi Sun,  Jiahui Chen</p>
  <p><b>备注</b>：Preprint. 7 figures, 9 tables</p>
  <p><b>关键词</b>：minimum utility threshold (\ textit, three effective pruning strategies, utility itemset querying using, targeted utility mining task, utility itemset mining</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Traditional high-utility itemset mining (HUIM) aims to determine all
high-utility itemsets (HUIs) that satisfy the minimum utility threshold
(\textit{minUtil}) in transaction databases. However, in most applications, not
all HUIs are interesting because only specific parts are required. Thus,
targeted mining based on user preferences is more important than traditional
mining tasks. This paper is the first to propose a target-based HUIM problem
and to provide a clear formulation of the targeted utility mining task in a
quantitative transaction database. A tree-based algorithm known as Target-based
high-Utility iteMset querying using (TargetUM) is proposed. The algorithm uses
a lexicographic querying tree and three effective pruning strategies to improve
the mining efficiency. We implemented experimental validation on several real
and synthetic databases, and the results demonstrate that the performance of
\textbf{TargetUM} is satisfactory, complete, and correct. Finally, owing to the
lexicographic querying tree, the database no longer needs to be scanned
repeatedly for multiple queries.</p>
  </details>
</details>
<details>
  <summary>65. <b>标题：Long-Range Route-planning for Autonomous Vehicles in the Polar Oceans</b></summary>
  <p><b>编号</b>：[307]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00293</p>
  <p><b>作者</b>：Maria Fox,  Michael Meredith,  J. Alexander Brearley,  Dan Jones,  Derek Long</p>
  <p><b>备注</b>：Submitted to the AMS Journal of Atmospheric and Oceanic Technology</p>
  <p><b>关键词</b>：piloted autonomous underwater vehicles, range route planning capability, term autonomous missions, high carbon cost, polar ice conditions</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>There is an increasing demand for piloted autonomous underwater vehicles
(AUVs) to operate in polar ice conditions. At present, AUVs are deployed from
ships and directly human-piloted in these regions, entailing a high carbon cost
and limiting the scope of operations. A key requirement for long-term
autonomous missions is a long-range route planning capability that is aware of
the changing ice conditions. In this paper we address the problem of automating
long-range route-planning for AUVs operating in the Southern Ocean. We present
the route-planning method and results showing that efficient, ice-avoiding,
long-distance traverses can be planned.</p>
  </details>
</details>
<details>
  <summary>66. <b>标题：Intrusion Prevention through Optimal Stopping</b></summary>
  <p><b>编号</b>：[308]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00289</p>
  <p><b>作者</b>：Kim Hammar,  Rolf Stadler</p>
  <p><b>备注</b>：Preprint; Submitted to IEEE for review. arXiv admin note: substantial text overlap with arXiv:2106.07160</p>
  <p><b>关键词</b>：study automated intrusion prevention using reinforcement learning, optimal defender policy using dynamic programming, validating policies includes two systems, formulation gives us insight, produce effective defender policies</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We study automated intrusion prevention using reinforcement learning.
Following a novel approach, we formulate the problem of intrusion prevention as
an (optimal) multiple stopping problem. This formulation gives us insight into
the structure of optimal policies, which we show to have threshold properties.
For most practical cases, it is not feasible to obtain an optimal defender
policy using dynamic programming. We therefore develop a reinforcement learning
approach to approximate an optimal policy. Our method for learning and
validating policies includes two systems: a simulation system where defender
policies are incrementally learned and an emulation system where statistics are
produced that drive simulation runs and where learned policies are evaluated.
We show that our approach can produce effective defender policies for a
practical IT infrastructure of limited size. Inspection of the learned policies
confirms that they exhibit threshold properties.</p>
  </details>
</details>
<details>
  <summary>67. <b>标题：A Decentralized Reinforcement Learning Framework for Efficient Passage  of Emergency Vehicles</b></summary>
  <p><b>编号</b>：[310]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00278</p>
  <p><b>作者</b>：Haoran Su,  Yaofeng Desmond Zhong,  Dey Biswadip,  Amit Chakraborty</p>
  <p><b>备注</b>：Artificial Intelligence and Humanitarian Assistance and Disaster Recovery (AI + HADR) workshop, NeurIPS 2021. arXiv admin note: substantial text overlap with arXiv:2109.05429</p>
  <p><b>关键词</b>：reduce emv travel time employ route optimization, emvlight outperforms benchmark transportation engineering techniques, level cooperative traffic signal phase strategies, planned route often becomes suboptimal, based traffic signal control methods</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Emergency vehicles (EMVs) play a critical role in a city's response to
time-critical events such as medical emergencies and fire outbreaks. The
existing approaches to reduce EMV travel time employ route optimization and
traffic signal pre-emption without accounting for the coupling between route
these two subproblems. As a result, the planned route often becomes suboptimal.
In addition, these approaches also do not focus on minimizing disruption to the
overall traffic flow. To address these issues, we introduce EMVLight in this
paper. This is a decentralized reinforcement learning (RL) framework for
simultaneous dynamic routing and traffic signal control. EMVLight extends
Dijkstra's algorithm to efficiently update the optimal route for an EMV in
real-time as it travels through the traffic network. Consequently, the
decentralized RL agents learn network-level cooperative traffic signal phase
strategies that reduce EMV travel time and the average travel time of non-EMVs
in the network. We have carried out comprehensive experiments with synthetic
and real-world maps to demonstrate this benefit. Our results show that EMVLight
outperforms benchmark transportation engineering techniques as well as existing
RL-based traffic signal control methods.</p>
  </details>
</details>
<details>
  <summary>68. <b>标题：On Joint Learning for Solving Placement and Routing in Chip Design</b></summary>
  <p><b>编号</b>：[325]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00234</p>
  <p><b>作者</b>：Ruoyu Cheng,  Junchi Yan</p>
  <p><b>备注</b>：accepted for 35th Conference on Neural Information Processing Systems (NeurIPS 2021)</p>
  <p><b>关键词</b>：joint learning approach via reinforcement learning, public chip design benchmarks show, modern chip design flow, gradient based optimization scheme, local node level information</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>For its advantage in GPU acceleration and less dependency on human experts,
machine learning has been an emerging tool for solving the placement and
routing problems, as two critical steps in modern chip design flow. Being still
in its early stage, there are fundamental issues: scalability, reward design,
and end-to-end learning paradigm etc. To achieve end-to-end placement learning,
we first propose a joint learning method termed by DeepPlace for the placement
of macros and standard cells, by the integration of reinforcement learning with
a gradient based optimization scheme. To further bridge the placement with the
subsequent routing task, we also develop a joint learning approach via
reinforcement learning to fulfill both macro placement and routing, which is
called DeepPR. One key design in our (reinforcement) learning paradigm involves
a multi-view embedding model to encode both global graph level and local node
level information of the input macros. Moreover, the random network
distillation is devised to encourage exploration. Experiments on public chip
design benchmarks show that our method can effectively learn from experience
and also provides intermediate placement for the post standard cell placement,
within few hours for training.</p>
  </details>
</details>
<details>
  <summary>69. <b>标题：Fuzzy Conceptual Graphs: a comparative discussion</b></summary>
  <p><b>编号</b>：[329]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00229</p>
  <p><b>作者</b>：Adam Faci (LFI, TRT),  Marie-Jeanne Lesot (LFI),  Claire Laudy (TRT)</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：discussion revolves around three axes, fuzzy set theory, based knowledge representation, many possible interpretations, fuzzy conceptual graphs</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Conceptual Graphs (CG) are a graph-based knowledge representation and
reasoning formalism; fuzzy Conceptual Graphs (fCG) constitute an extension that
enriches their expressiveness, exploiting the fuzzy set theory so as to relax
their constraints at various levels. This paper proposes a comparative study of
existing approaches over their respective advantages and possible limitations.
The discussion revolves around three axes: (a) Critical view of each approach
and comparison with previous propositions from the state of the art; (b)
Presentation of the many possible interpretations of each definition to
illustrate its potential and its limits; (c) Clarification of the part of CG
impacted by the definition as well as the relaxed constraint.</p>
  </details>
</details>
<details>
  <summary>70. <b>标题：Mastering Atari Games with Limited Data</b></summary>
  <p><b>编号</b>：[337]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00210</p>
  <p><b>作者</b>：Weirui Ye,  Shaohuai Liu,  Thanard Kurutach,  Pieter Abbeel,  Yang Gao</p>
  <p><b>备注</b>：Published at NeurIPS 2021</p>
  <p><b>关键词</b>：consume 500 times less data, based visual rl algorithm built, prominent methods requiring millions, atari game benchmark remains, based rl algorithms</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Reinforcement learning has achieved great success in many applications.
However, sample efficiency remains a key challenge, with prominent methods
requiring millions (or even billions) of environment steps to train. Recently,
there has been significant progress in sample efficient image-based RL
algorithms; however, consistent human-level performance on the Atari game
benchmark remains an elusive goal. We propose a sample efficient model-based
visual RL algorithm built on MuZero, which we name EfficientZero. Our method
achieves 190.4% mean human performance and 116.0% median performance on the
Atari 100k benchmark with only two hours of real-time game experience and
outperforms the state SAC in some tasks on the DMControl 100k benchmark. This
is the first time an algorithm achieves super-human performance on Atari games
with such little data. EfficientZero's performance is also close to DQN's
performance at 200 million frames while we consume 500 times less data.
EfficientZero's low sample complexity and high performance can bring RL closer
to real-world applicability. We implement our algorithm in an
easy-to-understand manner and it is available at
this https URL. We hope it will accelerate the research
of MCTS-based RL algorithms in the wider community.</p>
  </details>
</details>
<details>
  <summary>71. <b>标题：One Step at a Time: Pros and Cons of Multi-Step Meta-Gradient  Reinforcement Learning</b></summary>
  <p><b>编号</b>：[339]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00206</p>
  <p><b>作者</b>：Clément Bonnet,  Paul Caron,  Thomas Barrett,  Ian Davies,  Alexandre Laterre</p>
  <p><b>备注</b>：14 pages, 6 figures, 2 tables</p>
  <p><b>关键词</b>：novel method mixing multiple inner steps, learning process online encourage, multiple learning steps, avoid myopic updates, better learning signal</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Self-tuning algorithms that adapt the learning process online encourage more
effective and robust learning. Among all the methods available, meta-gradients
have emerged as a promising approach. They leverage the differentiability of
the learning rule with respect to some hyper-parameters to adapt them in an
online fashion. Although meta-gradients can be accumulated over multiple
learning steps to avoid myopic updates, this is rarely used in practice. In
this work, we demonstrate that whilst multi-step meta-gradients do provide a
better learning signal in expectation, this comes at the cost of a significant
increase in variance, hindering performance. In the light of this analysis, we
introduce a novel method mixing multiple inner steps that enjoys a more
accurate and robust meta-gradient signal, essentially trading off bias and
variance in meta-gradient estimation. When applied to the Snake game, the
mixing meta-gradient algorithm can cut the variance by a factor of 3 while
achieving similar or higher performance.</p>
  </details>
</details>
<details>
  <summary>72. <b>标题：A Comparative Review of Recent Few-Shot Object Detection Algorithms</b></summary>
  <p><b>编号</b>：[342]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00201</p>
  <p><b>作者</b>：Leng Jiaxu,  Chen Taiyue,  Gao Xinbo,  Yu Yongtao,  Wang Ye,  Gao Feng,  Wang Yue</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：shot detectors refine robust task notions, extra datasets without target, shot object detection, shot object detection, shot object detection</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Few-shot object detection, learning to adapt to the novel classes with a few
labeled data, is an imperative and long-lasting problem due to the inherent
long-tail distribution of real-world data and the urgent demands to cut costs
of data collection and annotation. Recently, some studies have explored how to
use implicit cues in extra datasets without target-domain supervision to help
few-shot detectors refine robust task notions. This survey provides a
comprehensive overview from current classic and latest achievements for
few-shot object detection to future research expectations from manifold
perspectives. In particular, we first propose a data-based taxonomy of the
training data and the form of corresponding supervision which are accessed
during the training stage. Following this taxonomy, we present a significant
review of the formal definition, main challenges, benchmark datasets,
evaluation metrics, and learning strategies. In addition, we present a detailed
investigation of how to interplay the object detection methods to develop this
issue systematically. Finally, we conclude with the current status of few-shot
object detection, along with potential research directions for this field.</p>
  </details>
</details>
<details>
  <summary>73. <b>标题：AutoDrone: Shortest Optimized Obstacle-Free Path Planning for Autonomous  Drones</b></summary>
  <p><b>编号</b>：[343]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00200</p>
  <p><b>作者</b>：Prithwish Jana,  Debasish Jana</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：work shows different scenarios, shortest feasible path computed, wreckage site affected, unmanned aerial vehicle, planned smart city</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>With technological advancement, drone has emerged as unmanned aerial vehicle
that can be controlled by humans to fly or reach a destination. This may be
autonomous as well, where the drone itself is intelligent enough to find a
shortest obstacle-free path to reach the destination from a designated source.
Be it a planned smart city or even a wreckage site affected by natural
calamity, we may imagine the buildings, any surface-erected structure or other
blockage as obstacles for the drone to fly in a direct line-of-sight path. So,
the whole bird's eye-view of the landscape can be transformed to a graph of
grid-cells, where some are occupied to indicate the obstacles and some are free
to indicate the free path. The autonomous drone (AutoDrone) will be able to
find out the shortest hindrance-free path while travelling in two-dimensional
space and move from one place to another. In this paper, we propose a method to
find out an obstacle-free shortest path in the coordinate system guided by GPS.
This can be especially beneficial in rescue operations and fast delivery or
pick-up in an energy-efficient way, where our algorithm will help in finding
out the shortest path and angle along which it should fly. Our work shows
different scenarios to path-tracing, through the shortest feasible path
computed by the autonomous drone.</p>
  </details>
</details>
<details>
  <summary>74. <b>标题：How should human translation coexist with NMT? Efficient tool for  building high quality parallel corpus</b></summary>
  <p><b>编号</b>：[348]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00191</p>
  <p><b>作者</b>：Chanjun Park,  Seolhwa Lee,  Hyeonseok Moon,  Sugyeong Eo,  Jaehyung Seo,  Heuiseok Lim</p>
  <p><b>备注</b>：Accepted for Data-centric AI workshop at NeurIPS 2021</p>
  <p><b>关键词</b>：combining data quality control, quality parallel corpora, proposed construction process, efficiently constructing high, neural machine translation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper proposes a tool for efficiently constructing high-quality parallel
corpora with minimizing human labor and making this tool publicly available.
Our proposed construction process is based on neural machine translation (NMT)
to allow for it to not only coexist with human translation, but also improve
its efficiency by combining data quality control with human translation in a
data-centric approach.</p>
  </details>
</details>
<details>
  <summary>75. <b>标题：Convergence and Optimality of Policy Gradient Methods in Weakly Smooth  Settings</b></summary>
  <p><b>编号</b>：[350]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00185</p>
  <p><b>作者</b>：Matthew Shunshi Zhang,  Murat Erdogdu,  Animesh Garg</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：yet existing convergence analysis still relies, policy gradient methods without relying, weakly smooth policy classes, natural policy gradient algorithms, establish explicit convergence rates</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Policy gradient methods have been frequently applied to problems in control
and reinforcement learning with great success, yet existing convergence
analysis still relies on non-intuitive, impractical and often opaque
conditions. In particular, existing rates are achieved in limited settings,
under strict smoothness and bounded conditions. In this work, we establish
explicit convergence rates of policy gradient methods without relying on these
conditions, instead extending the convergence regime to weakly smooth policy
classes with $L_2$ integrable gradient. We provide intuitive examples to
illustrate the insight behind these new conditions. We also characterize the
sufficiency conditions for the ergodicity of near-linear MDPs, which represent
an important class of problems. Notably, our analysis also shows that fast
convergence rates are achievable for both the standard policy gradient and the
natural policy gradient algorithms under these assumptions. Lastly we provide
conditions and analysis for optimality of the converged policies.</p>
  </details>
</details>
<details>
  <summary>76. <b>标题：Hierarchical Heterogeneous Graph Representation Learning for Short Text  Classification</b></summary>
  <p><b>编号</b>：[352]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00180</p>
  <p><b>作者</b>：Yaqing Wang,  Song Wang,  Quanming Yao,  Dejing Dou</p>
  <p><b>备注</b>：Accepted to EMNLP 2021</p>
  <p><b>关键词</b>：facilitates effective label propagation among similar short texts, various benchmark short text datasets show, hierarchical heterogeneous graph consisting, shine consistently outperforms state, new method called shine</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Short text classification is a fundamental task in natural language
processing. It is hard due to the lack of context information and labeled data
in practice. In this paper, we propose a new method called SHINE, which is
based on graph neural network (GNN), for short text classification. First, we
model the short text dataset as a hierarchical heterogeneous graph consisting
of word-level component graphs which introduce more semantic and syntactic
information. Then, we dynamically learn a short document graph that facilitates
effective label propagation among similar short texts. Thus, compared with
existing GNN-based methods, SHINE can better exploit interactions between nodes
of the same types and capture similarities between short texts. Extensive
experiments on various benchmark short text datasets show that SHINE
consistently outperforms state-of-the-art methods, especially with fewer
labels.</p>
  </details>
</details>
<details>
  <summary>77. <b>标题：Advanced Algorithms of Collision Free Navigation and Flocking for  Autonomous UAVs</b></summary>
  <p><b>编号</b>：[361]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00166</p>
  <p><b>作者</b>：Taha Elmokadem</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：produce quick reactions around obstacles, methods offer good computational cost, advanced 3d reactive control strategies, also investigated considering uav dynamics, general 3d kinematic models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Unmanned aerial vehicles (UAVs) have become very popular for many military
and civilian applications including in agriculture, construction, mining,
environmental monitoring, etc. A desirable feature for UAVs is the ability to
navigate and perform tasks autonomously with least human interaction. This is a
very challenging problem due to several factors such as the high complexity of
UAV applications, operation in harsh environments, limited payload and onboard
computing power and highly nonlinear dynamics. The work presented in this
report contributes towards the state-of-the-art in UAV control for safe
autonomous navigation and motion coordination of multi-UAV systems. The first
part of this report deals with single-UAV systems. The complex problem of
three-dimensional (3D) collision-free navigation in unknown/dynamic
environments is addressed. To that end, advanced 3D reactive control strategies
are developed adopting the sense-and-avoid paradigm to produce quick reactions
around obstacles. A special case of navigation in 3D unknown confined
environments (i.e. tunnel-like) is also addressed. General 3D kinematic models
are considered in the design which makes these methods applicable to different
UAV types in addition to underwater vehicles. Moreover, different
implementation methods for these strategies with quadrotor-type UAVs are also
investigated considering UAV dynamics in the control design. Practical
experiments and simulations were carried out to analyze the performance of the
developed methods. The second part of this report addresses safe navigation for
multi-UAV systems. Distributed motion coordination methods of multi-UAV systems
for flocking and 3D area coverage are developed. These methods offer good
computational cost for large-scale systems. Simulations were performed to
verify the performance of these methods considering systems with different
sizes.</p>
  </details>
</details>
<details>
  <summary>78. <b>标题：Temporal-Spatial Feature Extraction Based on Convolutional Neural  Networks for Travel Time Prediction</b></summary>
  <p><b>编号</b>：[371]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00149</p>
  <p><b>作者</b>：Chi-Hua Chen</p>
  <p><b>备注</b>：22 pages, 15 figures, and 3 tables</p>
  <p><b>关键词</b>：travel time prediction method based, mean absolute percentage error, traffic information prediction methods, travel time prediction, traffic information prediction</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In recent years, some traffic information prediction methods have been
proposed to provide the precise information of travel time, vehicle speed, and
traffic flow for highways. However, big errors may be obtained by these methods
for urban roads or the alternative roads of highways. Therefore, this study
proposes a travel time prediction method based on convolutional neural networks
to extract important factors for the improvement of traffic information
prediction. In practical experimental environments, the travel time records of
No. 5 Highway and the alternative roads of its were collected and used to
evaluate the proposed method. The results showed that the mean absolute
percentage error of the proposed method was about 5.69%. Therefore, the
proposed method based on deep learning techniques can improve the accuracy of
travel time prediction.</p>
  </details>
</details>
<details>
  <summary>79. <b>标题：Context Meta-Reinforcement Learning via Neuromodulation</b></summary>
  <p><b>编号</b>：[375]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00134</p>
  <p><b>作者</b>：Eseoghene Ben-Iwhiwhu,  Jeffery Dick,  Nicholas A. Ketz,  Praveen K. Pilly,  Andrea Soltoggio</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：fast adaptation beyond simple benchmark problems, neuromodulation produces significantly better result, evaluated across multiple discrete, produce efficient dynamic representations, obtaining rich dynamic representations</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Meta-reinforcement learning (meta-RL) algorithms enable agents to adapt
quickly to tasks from few samples in dynamic environments. Such a feat is
achieved through dynamic representations in an agent's policy network (obtained
via reasoning about task context, model parameter updates, or both). However,
obtaining rich dynamic representations for fast adaptation beyond simple
benchmark problems is challenging due to the burden placed on the policy
network to accommodate different policies. This paper addresses the challenge
by introducing neuromodulation as a modular component to augment a standard
policy network that regulates neuronal activities in order to produce efficient
dynamic representations for task adaptation. The proposed extension to the
policy network is evaluated across multiple discrete and continuous control
environments of increasing complexity. To prove the generality and benefits of
the extension in meta-RL, the neuromodulated network was applied to two
state-of-the-art meta-RL algorithms (CAVIA and PEARL). The result demonstrates
that meta-RL augmented with neuromodulation produces significantly better
result and richer dynamic representations in comparison to the baselines.</p>
  </details>
</details>
<details>
  <summary>80. <b>标题：Three approaches to facilitate DNN generalization to objects in  out-of-distribution orientations and illuminations: late-stopping, tuning  batch normalization and invariance loss</b></summary>
  <p><b>编号</b>：[376]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00131</p>
  <p><b>作者</b>：Akira Sakai,  Taro Sunagawa,  Spandan Madan,  Kanata Suzuki,  Takashi Katoh,  Hiromichi Kobashi,  Hanspeter Pfister,  Pawan Sinha,  Xavier Boix,  Tomotake Sasaki</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：enable ood accuracy gains -- individual neurons, often biased towards objects, investigate three different approaches, three approaches focus, approaches substantially improves</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The training data distribution is often biased towards objects in certain
orientations and illumination conditions. While humans have a remarkable
capability of recognizing objects in out-of-distribution (OoD) orientations and
illuminations, Deep Neural Networks (DNNs) severely suffer in this case, even
when large amounts of training examples are available. In this paper, we
investigate three different approaches to improve DNNs in recognizing objects
in OoD orientations and illuminations. Namely, these are (i) training much
longer after convergence of the in-distribution (InD) validation accuracy,
i.e., late-stopping, (ii) tuning the momentum parameter of the batch
normalization layers, and (iii) enforcing invariance of the neural activity in
an intermediate layer to orientation and illumination conditions. Each of these
approaches substantially improves the DNN's OoD accuracy (more than 20% in some
cases). We report results in four datasets: two datasets are modified from the
MNIST and iLab datasets, and the other two are novel (one of 3D rendered cars
and another of objects taken from various controlled orientations and
illumination conditions). These datasets allow to study the effects of
different amounts of bias and are challenging as DNNs perform poorly in OoD
conditions. Finally, we demonstrate that even though the three approaches focus
on different aspects of DNNs, they all tend to lead to the same underlying
neural mechanism to enable OoD accuracy gains -- individual neurons in the
intermediate layers become more selective to a category and also invariant to
OoD orientations and illuminations.</p>
  </details>
</details>
<details>
  <summary>81. <b>标题：Visual Explanations for Convolutional Neural Networks via Latent  Traversal of Generative Adversarial Networks</b></summary>
  <p><b>编号</b>：[384]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00116</p>
  <p><b>作者</b>：Amil Dravid,  Aggelos K. Katsaggelos</p>
  <p><b>备注</b>：2 pages, 2 figures, to appear as extended abstract at AAAI-22</p>
  <p><b>关键词</b>：gan framework disentangles lung structure, weighted class activation mapping, utilizing generative adversarial networks, specifically deep neural networks, convolutional neural network</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Lack of explainability in artificial intelligence, specifically deep neural
networks, remains a bottleneck for implementing models in practice. Popular
techniques such as Gradient-weighted Class Activation Mapping (Grad-CAM)
provide a coarse map of salient features in an image, which rarely tells the
whole story of what a convolutional neural network (CNN) learned. Using
COVID-19 chest X-rays, we present a method for interpreting what a CNN has
learned by utilizing Generative Adversarial Networks (GANs). Our GAN framework
disentangles lung structure from COVID-19 features. Using this GAN, we can
visualize the transition of a pair of COVID negative lungs in a chest
radiograph to a COVID positive pair by interpolating in the latent space of the
GAN, which provides fine-grained visualization of how the CNN responds to
varying features within the lungs.</p>
  </details>
</details>
<details>
  <summary>82. <b>标题：FC2T2: The Fast Continuous Convolutional Taylor Transform with  Applications in Vision and Graphics</b></summary>
  <p><b>编号</b>：[388]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00110</p>
  <p><b>作者</b>：Henning Lange,  J. Nathan Kutz</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：fast continuous convolutional taylor transform, low dimensional convolutional operators, require repeated function evaluations, unlike regular neural networks, modern machine learning perspective</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Series expansions have been a cornerstone of applied mathematics and
engineering for centuries. In this paper, we revisit the Taylor series
expansion from a modern Machine Learning perspective. Specifically, we
introduce the Fast Continuous Convolutional Taylor Transform (FC2T2), a variant
of the Fast Multipole Method (FMM), that allows for the efficient approximation
of low dimensional convolutional operators in continuous space. We build upon
the FMM which is an approximate algorithm that reduces the computational
complexity of N-body problems from O(NM) to O(N+M) and finds application in
e.g. particle simulations. As an intermediary step, the FMM produces a series
expansion for every cell on a grid and we introduce algorithms that act
directly upon this representation. These algorithms analytically but
approximately compute the quantities required for the forward and backward pass
of the backpropagation algorithm and can therefore be employed as (implicit)
layers in Neural Networks. Specifically, we introduce a root-implicit layer
that outputs surface normals and object distances as well as an
integral-implicit layer that outputs a rendering of a radiance field given a 3D
pose. In the context of Machine Learning, $N$ and $M$ can be understood as the
number of model parameters and model evaluations respectively which entails
that, for applications that require repeated function evaluations which are
prevalent in Computer Vision and Graphics, unlike regular Neural Networks, the
techniques introduce in this paper scale gracefully with parameters. For some
applications, this results in a 200x reduction in FLOPs compared to
state-of-the-art approaches at a reasonable or non-existent loss in accuracy.</p>
  </details>
</details>
<details>
  <summary>83. <b>标题：The Golden Rule as a Heuristic to Measure the Fairness of Texts Using  Machine Learning</b></summary>
  <p><b>编号</b>：[389]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00107</p>
  <p><b>作者</b>：A. Izzidien,  J. Watson,  B. Loe,  P. Romero,  S. Fitz,  D. Stillwell</p>
  <p><b>备注</b>：32 pages, 4 figures</p>
  <p><b>关键词</b>：moral philosophy exists, individuals would typically, implementing two approaches, find f1 scores, axiom throughout history</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>To treat others as one would wish to be treated is a common formulation of
the Golden Rule (GR). Yet, despite its prevalence as an axiom throughout
history, no digitisation of the moral philosophy exists. In this paper we
consider how to digitise it so that it may be used to measure sentences such
as: the boy harmed the girl, and categorise them as fair or unfair. A review
and reply to criticisms of the GR is made. We share the code for the
digitisation of the GR, and test it with a list of sentences. Implementing two
approaches, one using the USE, and a second using ALBERT. We find F1 scores of
78.0, 85.0, respectively. A suggestion of how the technology may be implemented
to avoid unfair biases in word embeddings is made - given that individuals
would typically not wish to be on the receiving end of an unfair act, such as
racism, irrespective of whether the corpus being used deems such discrimination
as praiseworthy.</p>
  </details>
</details>
<details>
  <summary>84. <b>标题：Measuring a Texts Fairness Dimensions Using Machine Learning Based on  Social Psychological Factors</b></summary>
  <p><b>编号</b>：[398]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00086</p>
  <p><b>作者</b>：A. Izzidien,  J. Watson,  B. Loe,  P. Romero,  S. Fitz,  D. Stillwell</p>
  <p><b>备注</b>：38 pages, 9 figures</p>
  <p><b>关键词</b>：dimensioned sentence level fairness perceptions vector, social bias within word embeddings, said fairness approximation vector produces, utilise social psychology literature, social act remains wanting</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Fairness is a principal social value that can be observed in civilisations
around the world. A manifestations of this is in social agreements, often
described in texts, such as contracts. Yet, despite the prevalence of such, a
fairness metric for texts describing a social act remains wanting. To address
this, we take a step back to consider the problem based on first principals.
Instead of using rules or templates, we utilise social psychology literature to
determine the principal factors that humans use when making a fairness
assessment. We then attempt to digitise these using word embeddings into a
multi-dimensioned sentence level fairness perceptions vector to serve as an
approximation for these fairness perceptions. The method leverages a pro-social
bias within word embeddings, for which we obtain an F1= 81.0. A second
approach, using PCA and ML based on the said fairness approximation vector
produces an F1 score of 86.2. We details improvements that can be made in the
methodology to incorporate the projection of sentence embedding on to a
subspace representation of fairness.</p>
  </details>
</details>
<details>
  <summary>85. <b>标题：Generalized Proximal Policy Optimization with Sample Reuse</b></summary>
  <p><b>编号</b>：[406]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00072</p>
  <p><b>作者</b>：James Queeney,  Ioannis Ch. Paschalidis,  Christos G. Cassandras</p>
  <p><b>备注</b>：To appear in 35th Conference on Neural Information Processing Systems (NeurIPS 2021)</p>
  <p><b>关键词</b>：policy methods typically generate reliable policy improvement throughout training, call generalized proximal policy optimization, develop policy improvement guarantees, driven reinforcement learning methods, world decision making tasks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In real-world decision making tasks, it is critical for data-driven
reinforcement learning methods to be both stable and sample efficient.
On-policy methods typically generate reliable policy improvement throughout
training, while off-policy methods make more efficient use of data through
sample reuse. In this work, we combine the theoretically supported stability
benefits of on-policy algorithms with the sample efficiency of off-policy
algorithms. We develop policy improvement guarantees that are suitable for the
off-policy setting, and connect these bounds to the clipping mechanism used in
Proximal Policy Optimization. This motivates an off-policy version of the
popular algorithm that we call Generalized Proximal Policy Optimization with
Sample Reuse. We demonstrate both theoretically and empirically that our
algorithm delivers improved performance by effectively balancing the competing
goals of stability and sample efficiency.</p>
  </details>
</details>
<details>
  <summary>86. <b>标题：ReSkin: versatile, replaceable, lasting tactile skins</b></summary>
  <p><b>编号</b>：[407]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00071</p>
  <p><b>作者</b>：Raunaq Bhirangi,  Tess Hellebrekers,  Carmel Majidi,  Abhinav Gupta</p>
  <p><b>备注</b>：CoRL 2021. Project Website: this https URL . First two authors contributed equally</p>
  <p><b>关键词</b>：supervised learning algorithm enables finer performance enhancement, machine learning allows us, inexpensive tactile sensation modules, inexpensive data collection procedures, learn sensor response models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Soft sensors have continued growing interest in robotics, due to their
ability to enable both passive conformal contact from the material properties
and active contact data from the sensor properties. However, the same
properties of conformal contact result in faster deterioration of soft sensors
and larger variations in their response characteristics over time and across
samples, inhibiting their ability to be long-lasting and replaceable. ReSkin is
a tactile soft sensor that leverages machine learning and magnetic sensing to
offer a low-cost, diverse and compact solution for long-term use. Magnetic
sensing separates the electronic circuitry from the passive interface, making
it easier to replace interfaces as they wear out while allowing for a wide
variety of form factors. Machine learning allows us to learn sensor response
models that are robust to variations across fabrication and time, and our
self-supervised learning algorithm enables finer performance enhancement with
small, inexpensive data collection procedures. We believe that ReSkin opens the
door to more versatile, scalable and inexpensive tactile sensation modules than
existing alternatives.</p>
  </details>
</details>
<details>
  <summary>87. <b>标题：Symbolic Regression via Neural-Guided Genetic Programming Population  Seeding</b></summary>
  <p><b>编号</b>：[415]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00053</p>
  <p><b>作者</b>：T. Nathan Mundhenk,  Mikel Landajuela,  Ruben Glatt,  Claudio P. Santiago,  Daniel M. Faissol,  Brenden K. Petersen</p>
  <p><b>备注</b>：Accepted at the 35th Conference on Neural Information Processing Systems (NeurIPS 2021)</p>
  <p><b>关键词</b>：running many genetic programming generations without interdependence, discrete optimization problem generally believed, random restart genetic programming component, gradually learning better starting populations, 22 symbolic regression benchmark problems</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Symbolic regression is the process of identifying mathematical expressions
that fit observed output from a black-box process. It is a discrete
optimization problem generally believed to be NP-hard. Prior approaches to
solving the problem include neural-guided search (e.g. using reinforcement
learning) and genetic programming. In this work, we introduce a hybrid
neural-guided/genetic programming approach to symbolic regression and other
combinatorial optimization problems. We propose a neural-guided component used
to seed the starting population of a random restart genetic programming
component, gradually learning better starting populations. On a number of
common benchmark tasks to recover underlying expressions from a dataset, our
method recovers 65% more expressions than a recently published top-performing
model using the same experimental setup. We demonstrate that running many
genetic programming generations without interdependence on the neural-guided
component performs better for symbolic regression than alternative formulations
where the two are more strongly coupled. Finally, we introduce a new set of 22
symbolic regression benchmark problems with increased difficulty over existing
benchmarks. Source code is provided at
this http URL.</p>
  </details>
</details>
<details>
  <summary>88. <b>标题：Diagnosing Web Data of ICTs to Provide Focused Assistance in  Agricultural Adoptions</b></summary>
  <p><b>编号</b>：[416]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00052</p>
  <p><b>作者</b>：Ashwin Singh,  Mallika Subramanian,  Anmol Agarwal,  Pratyush Priyadarshi,  Shrey Gupta,  Kiran Garimella,  Sanjeev Kumar,  Ritesh Kumar,  Lokesh Garg,  Erica Arya,  Ponnurangam Kumaraguru</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：3 million farmers across three continents, digital green disseminates instructional agricultural videos, technology ownership across rural areas, demographic features across five states, smallholder farmers via human mediators</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The past decade has witnessed a rapid increase in technology ownership across
rural areas of India, signifying the potential for ICT initiatives to empower
rural households. In our work, we focus on the web infrastructure of one such
ICT - Digital Green that started in 2008. Following a participatory approach
for content production, Digital Green disseminates instructional agricultural
videos to smallholder farmers via human mediators to improve the adoption of
farming practices. Their web-based data tracker, CoCo, captures data related to
these processes, storing the attendance and adoption logs of over 2.3 million
farmers across three continents and twelve countries. Using this data, we model
the components of the Digital Green ecosystem involving the past
attendance-adoption behaviours of farmers, the content of the videos screened
to them and their demographic features across five states in India. We use
statistical tests to identify different factors which distinguish farmers with
higher adoption rates to understand why they adopt more than others. Our
research finds that farmers with higher adoption rates adopt videos of shorter
duration and belong to smaller villages. The co-attendance and co-adoption
networks of farmers indicate that they greatly benefit from past adopters of a
video from their village and group when it comes to adopting practices from the
same video. Following our analysis, we model the adoption of practices from a
video as a prediction problem to identify and assist farmers who might face
challenges in adoption in each of the five states. We experiment with different
model architectures and achieve macro-f1 scores ranging from 79% to 89% using a
Random Forest classifier. Finally, we measure the importance of different
features using SHAP values and provide implications for improving the adoption
rates of nearly a million farmers across five states in India.</p>
  </details>
</details>
<details>
  <summary>89. <b>标题：Skyformer: Remodel Self-Attention with Gaussian Kernel and Nyström  Method</b></summary>
  <p><b>编号</b>：[420]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00035</p>
  <p><b>作者</b>：Yifan Chen,  Qi Zeng,  Heng Ji,  Yun Yang</p>
  <p><b>备注</b>：To appear in NeurIPS 2021</p>
  <p><b>关键词</b>：long range arena benchmark show, computational cost without sacrificing, requiring fewer computation resources, although kernel machines suffer, high computational cost</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Transformers are expensive to train due to the quadratic time and space
complexity in the self-attention mechanism. On the other hand, although kernel
machines suffer from the same computation bottleneck in pairwise dot products,
several approximation schemes have been successfully incorporated to
considerably reduce their computational cost without sacrificing too much
accuracy. In this work, we leverage the computation methods for kernel machines
to alleviate the high computational cost and introduce Skyformer, which
replaces the softmax structure with a Gaussian kernel to stabilize the model
training and adapts the Nyström method to a non-positive semidefinite matrix
to accelerate the computation. We further conduct theoretical analysis by
showing that the matrix approximation error of our proposed method is small in
the spectral norm. Experiments on Long Range Arena benchmark show that the
proposed method is sufficient in getting comparable or even better performance
than the full self-attention while requiring fewer computation resources.</p>
  </details>
</details>
<details>
  <summary>90. <b>标题：Reinforced Workload Distribution Fairness</b></summary>
  <p><b>编号</b>：[422]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00008</p>
  <p><b>作者</b>：Zhiyuan Yao,  Zihan Ding,  Thomas Heide Clausen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：distributes workloads across multiple servers, distributed asynchronous reinforcement learning mechanism, active load balancer state monitoring, preliminary results show promise, including reward function design</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Network load balancers are central components in data centers, that
distributes workloads across multiple servers and thereby contribute to
offering scalable services. However, when load balancers operate in dynamic
environments with limited monitoring of application server loads, they rely on
heuristic algorithms that require manual configurations for fairness and
performance. To alleviate that, this paper proposes a distributed asynchronous
reinforcement learning mechanism to-with no active load balancer state
monitoring and limited network observations-improve the fairness of the
workload distribution achieved by a load balancer. The performance of proposed
mechanism is evaluated and compared with stateof-the-art load balancing
algorithms in a simulator, under configurations with progressively increasing
complexities. Preliminary results show promise in RLbased load balancing
algorithms, and identify additional challenges and future research directions,
including reward function design and model scalability.</p>
  </details>
</details>
<details>
  <summary>91. <b>标题：Adaptive Hierarchical Similarity Metric Learning with Noisy Labels</b></summary>
  <p><b>编号</b>：[424]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00006</p>
  <p><b>作者</b>：Jiexi Yan,  Lei Luo,  Cheng Deng,  Heng Huang</p>
  <p><b>备注</b>：11 pages, 5 figures</p>
  <p><b>关键词</b>：noisy labels often cause severe performance degradation, effectively excavate richer similarity information beyond binary, adaptive hierarchical similarity metric learning method, existing deep metric learning methods, current deep metric learning approaches</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep Metric Learning (DML) plays a critical role in various machine learning
tasks. However, most existing deep metric learning methods with binary
similarity are sensitive to noisy labels, which are widely present in
real-world data. Since these noisy labels often cause severe performance
degradation, it is crucial to enhance the robustness and generalization ability
of DML. In this paper, we propose an Adaptive Hierarchical Similarity Metric
Learning method. It considers two noise-insensitive information, \textit{i.e.},
class-wise divergence and sample-wise consistency. Specifically, class-wise
divergence can effectively excavate richer similarity information beyond binary
in modeling by taking advantage of Hyperbolic metric learning, while
sample-wise consistency can further improve the generalization ability of the
model using contrastive augmentation. More importantly, we design an adaptive
strategy to integrate this information in a unified view. It is noteworthy that
the new method can be extended to any pair-based metric loss. Extensive
experimental results on benchmark datasets demonstrate that our method achieves
state-of-the-art performance compared with current deep metric learning
approaches.</p>
  </details>
</details>
<details>
  <summary>92. <b>标题：Concept and Attribute Reduction Based on Rectangle Theory of Formal  Concept</b></summary>
  <p><b>编号</b>：[425]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00005</p>
  <p><b>作者</b>：Jianqin Zhou,  Sichun Yang,  Xifeng Wang,  Wanquan Liu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：concept reduction preserving binary relations, concept reduction preserving binary relations, allows multiple context cells, new algorithm could store, new judgment results</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Based on rectangle theory of formal concept and set covering theory, the
concept reduction preserving binary relations is investigated in this paper. It
is known that there are three types of formal concepts: core concepts, relative
necessary concepts and unnecessary concepts. First, we present the new judgment
results for relative necessary concepts and unnecessary concepts. Second, we
derive the bounds for both the maximum number of relative necessary concepts
and the maximum number of unnecessary concepts and it is a difficult problem as
either in concept reduction preserving binary relations or attribute reduction
of decision formal contexts, the computation of formal contexts from formal
concepts is a challenging problem. Third, based on rectangle theory of formal
concept, a fast algorithm for reducing attributes while preserving the
extensions for a set of formal concepts is proposed using the extension
bit-array technique, which allows multiple context cells to be processed by a
single 32-bit or 64-bit operator. Technically, the new algorithm could store
both formal context and extent of a concept as bit-arrays, and we can use
bit-operations to process set operations "or" as well as "and". One more merit
is that the new algorithm does not need to consider other concepts in the
concept lattice, thus the algorithm is explicit to understand and fast.
Experiments demonstrate that the new algorithm is effective in the computation
of attribute reductions.</p>
  </details>
</details>
<details>
  <summary>93. <b>标题：Granule Description based on Compound Concepts</b></summary>
  <p><b>编号</b>：[426]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00004</p>
  <p><b>作者</b>：Jianqin Zhou,  Sichun Yang,  Xifeng Wang,  Wanquan Liu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：logical relationship among various concepts, propose two new types, unified equivalent conditions, approaching description methods, approaching description methods</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Concise granule descriptions for describable granules and approaching
description methods for indescribable granules are challenging and important
issues in granular computing. The concept with only common attributes has been
frequently studied. To investigate the granules with some special needs, we
propose two new types of compound concepts in this paper: bipolar concept and
common-and-necessary concept. Based on the definitions of concept-forming
operations, the logical formulas are derived for each of the following types of
concepts: formal concept, three-way concept, object oriented concept, bipolar
concept and common-and-necessary concept. Furthermore, by utilizing the logical
relationship among various concepts, we have derived concise and unified
equivalent conditions for describable granules and approaching description
methods for indescribable granules for all five kinds of concepts.</p>
  </details>
</details>
<details>
  <summary>94. <b>标题：A New Algorithm based on Extent Bit-array for Computing Formal Concepts</b></summary>
  <p><b>编号</b>：[427]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00003</p>
  <p><b>作者</b>：Jianqin Zhou,  Sichun Yang,  Xifeng Wang,  Wanquan Liu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：compute formal concepts quickly, experimental results demonstrate, data analysis technique, formal concept analysis, computing formal concept</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The emergence of Formal Concept Analysis (FCA) as a data analysis technique
has increased the need for developing algorithms which can compute formal
concepts quickly. The current efficient algorithms for FCA are variants of the
Close-By-One (CbO) algorithm, such as In-Close2, In-Close3 and In-Close4, which
are all based on horizontal storage of contexts. In this paper, based on
algorithm In-Close4, a new algorithm based on the vertical storage of contexts,
called In-Close5, is proposed, which can significantly reduce both the time
complexity and space complexity of algorithm In-Close4. Technically, the new
algorithm stores both context and extent of a concept as a vertical bit-array,
while within In-Close4 algorithm the context is stored only as a horizontal
bit-array, which is very slow in finding the intersection of two extent sets.
Experimental results demonstrate that the proposed algorithm is much more
effective than In-Close4 algorithm, and it also has a broader scope of
applicability in computing formal concept in which one can solve the problems
that cannot be solved by the In-Close4 algorithm.</p>
  </details>
</details>
<details>
  <summary>95. <b>标题：NOTMAD: Estimating Bayesian Networks with Sample-Specific Structures and  Parameters</b></summary>
  <p><b>编号</b>：[429]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.01104</p>
  <p><b>作者</b>：Ben Lengerich,  Caleb Ellington,  Bryon Aragam,  Eric P. Xing,  Manolis Kellis</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：graph generator functions )., specific gene expression networks, mix archetypal networks according, smooth regularization loss, limiting statistical power</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Context-specific Bayesian networks (i.e. directed acyclic graphs, DAGs)
identify context-dependent relationships between variables, but the
non-convexity induced by the acyclicity requirement makes it difficult to share
information between context-specific estimators (e.g. with graph generator
functions). For this reason, existing methods for inferring context-specific
Bayesian networks have favored breaking datasets into subsamples, limiting
statistical power and resolution, and preventing the use of multidimensional
and latent contexts. To overcome this challenge, we propose NOTEARS-optimized
Mixtures of Archetypal DAGs (NOTMAD). NOTMAD models context-specific Bayesian
networks as the output of a function which learns to mix archetypal networks
according to sample context. The archetypal networks are estimated jointly with
the context-specific networks and do not require any prior knowledge. We encode
the acyclicity constraint as a smooth regularization loss which is
back-propagated to the mixing function; in this way, NOTMAD shares information
between context-specific acyclic graphs, enabling the estimation of Bayesian
network structures and parameters at even single-sample resolution. We
demonstrate the utility of NOTMAD and sample-specific network inference through
analysis and experiments, including patient-specific gene expression networks
which correspond to morphological variation in cancer.</p>
  </details>
</details>
<details>
  <summary>96. <b>标题：Modelling the transition to a low-carbon energy supply</b></summary>
  <p><b>编号</b>：[438]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00987</p>
  <p><b>作者</b>：Alexander Kell</p>
  <p><b>备注</b>：PhD thesis</p>
  <p><b>关键词</b>：reducing carbon emissions could help prevent, runaway emissions could lead, whole electricity market reacts, different factors using state, reliable energy supply</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A transition to a low-carbon electricity supply is crucial to limit the
impacts of climate change. Reducing carbon emissions could help prevent the
world from reaching a tipping point, where runaway emissions are likely.
Runaway emissions could lead to extremes in weather conditions around the world
-- especially in problematic regions unable to cope with these conditions.
However, the movement to a low-carbon energy supply can not happen
instantaneously due to the existing fossil-fuel infrastructure and the
requirement to maintain a reliable energy supply. Therefore, a low-carbon
transition is required, however, the decisions various stakeholders should make
over the coming decades to reduce these carbon emissions are not obvious. This
is due to many long-term uncertainties, such as electricity, fuel and
generation costs, human behaviour and the size of electricity demand. A well
choreographed low-carbon transition is, therefore, required between all of the
heterogenous actors in the system, as opposed to changing the behaviour of a
single, centralised actor. The objective of this thesis is to create a novel,
open-source agent-based model to better understand the manner in which the
whole electricity market reacts to different factors using state-of-the-art
machine learning and artificial intelligence methods. In contrast to other
works, this thesis looks at both the long-term and short-term impact that
different behaviours have on the electricity market by using these
state-of-the-art methods.</p>
  </details>
</details>
<details>
  <summary>97. <b>标题：Free Probability, Newton lilypads and Jacobians of neural networks</b></summary>
  <p><b>编号</b>：[445]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00841</p>
  <p><b>作者</b>：Reda Chhaibi,  Tariq Daouda,  Ezechiel Kahn</p>
  <p><b>备注</b>：22 pages, 4 figures</p>
  <p><b>关键词</b>：newton algorithm finds contiguous lilypad, modeled using free multiplicative convolutions, pennington et al .,, free probability theory, free probability metrics</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Gradient descent during the learning process of a neural network can be
subject to many instabilities. The spectral density of the Jacobian is a key
component for analyzing robustness. Following the works of Pennington et al.,
such Jacobians are modeled using free multiplicative convolutions from Free
Probability Theory. We present a reliable and very fast method for computing
the associated spectral densities. This method has a controlled and proven
convergence.
Our technique is based on an adaptative Newton-Raphson scheme, by finding and
chaining basins of attraction: the Newton algorithm finds contiguous
lilypad-like basins and steps from one to the next, heading towards the
objective.
We demonstrate the applicability of our method by using it to assess how the
learning process is affected by network depth, layer widths and initialization
choices: empirically, final test losses are very correlated to our Free
Probability metrics.</p>
  </details>
</details>
<details>
  <summary>98. <b>标题：Simulating Realistic MRI variations to Improve Deep Learning model and  visual explanations using GradCAM</b></summary>
  <p><b>编号</b>：[446]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00837</p>
  <p><b>作者</b>：Muhammad Ilyas Patel,  Shrey Singla,  Razeem Ahmad Ali Mattathodi,  Sumit Sharma,  Deepam Gautam,  Srinivasa Rao Kundeti</p>
  <p><b>备注</b>：8 pages, 9 figures, IEEE-CCEM 2021 conference</p>
  <p><b>关键词</b>：solving brain mri volumetric landmark detection problem, three respective views -- sagittal, proposed method shows favorable results, generate synthetic 3d volumetric data, weighted class activation mapping</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In the medical field, landmark detection in MRI plays an important role in
reducing medical technician efforts in tasks like scan planning, image
registration, etc. First, 88 landmarks spread across the brain anatomy in the
three respective views -- sagittal, coronal, and axial are manually annotated,
later guidelines from the expert clinical technicians are taken
sub-anatomy-wise, for better localization of the existing landmarks, in order
to identify and locate the important atlas landmarks even in oblique scans. To
overcome limited data availability, we implement realistic data augmentation to
generate synthetic 3D volumetric data. We use a modified HighRes3DNet model for
solving brain MRI volumetric landmark detection problem. In order to visually
explain our trained model on unseen data, and discern a stronger model from a
weaker model, we implement Gradient-weighted Class Activation Mapping
(Grad-CAM) which produces a coarse localization map highlighting the regions
the model is focusing. Our experiments show that the proposed method shows
favorable results, and the overall pipeline can be extended to a variable
number of landmarks and other anatomies.</p>
  </details>
</details>
<details>
  <summary>99. <b>标题：End-to-End Learning of Deep Kernel Acquisition Functions for Bayesian  Optimization</b></summary>
  <p><b>编号</b>：[457]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00639</p>
  <p><b>作者</b>：Tomoharu Iwata</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：experiments using three text document datasets, proposed method achieves better bo performance, existing methods train neural networks, learn flexible surrogate functions, shared across different tasks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>For Bayesian optimization (BO) on high-dimensional data with complex
structure, neural network-based kernels for Gaussian processes (GPs) have been
used to learn flexible surrogate functions by the high representation power of
deep learning. However, existing methods train neural networks by maximizing
the marginal likelihood, which do not directly improve the BO performance. In
this paper, we propose a meta-learning method for BO with neural network-based
kernels that minimizes the expected gap between the true optimum value and the
best value found by BO. We model a policy, which takes the current evaluated
data points as input and outputs the next data point to be evaluated, by a
neural network, where neural network-based kernels, GPs, and mutual
information-based acquisition functions are used as its layers. With our model,
the neural network-based kernel is trained to be appropriate for the
acquisition function by backpropagating the gap through the acquisition
function and GP. Our model is trained by a reinforcement learning framework
from multiple tasks. Since the neural network is shared across different tasks,
we can gather knowledge on BO from multiple training tasks, and use the
knowledge for unseen test tasks. In experiments using three text document
datasets, we demonstrate that the proposed method achieves better BO
performance than the existing methods.</p>
  </details>
</details>
<details>
  <summary>100. <b>标题：TorchXRayVision: A library of chest X-ray datasets and models</b></summary>
  <p><b>编号</b>：[459]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00595</p>
  <p><b>作者</b>：Joseph Paul Cohen,  Joseph D. Viviano,  Paul Bertin,  Paul Morrison,  Parsa Torabian,  Matteo Guarrera,  Matthew P Lungren,  Akshay Chaudhari,  Rupert Brooks,  Mohammad Hashir,  Hadrien Bertrand</p>
  <p><b>备注</b>：Library source code: this https URL</p>
  <p><b>关键词</b>：open source software library, publicly available chest x, representation learning models, deep learning models, different data combinations</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>TorchXRayVision is an open source software library for working with chest
X-ray datasets and deep learning models. It provides a common interface and
common pre-processing chain for a wide set of publicly available chest X-ray
datasets. In addition, a number of classification and representation learning
models with different architectures, trained on different data combinations,
are available through the library to serve as baselines or feature extractors.</p>
  </details>
</details>
<details>
  <summary>101. <b>标题：Focal Attention Networks: optimising attention for biomedical image  segmentation</b></summary>
  <p><b>编号</b>：[463]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00534</p>
  <p><b>作者</b>：Michael Yeung,  Leonardo Rundo,  Evis Sala,  Carola-Bibiane Schönlieb,  Guang Yang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：attention mechanisms enables flexible integration, validated biomedical imaging datasets, focal distance penalty term, unified focal loss framework, convolutional neural network architectures</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In recent years, there has been increasing interest to incorporate attention
into deep learning architectures for biomedical image segmentation. The modular
design of attention mechanisms enables flexible integration into convolutional
neural network architectures, such as the U-Net. Whether attention is
appropriate to use, what type of attention to use, and where in the network to
incorporate attention modules, are all important considerations that are
currently overlooked. In this paper, we investigate the role of the Focal
parameter in modulating attention, revealing a link between attention in loss
functions and networks. By incorporating a Focal distance penalty term, we
extend the Unified Focal loss framework to include boundary-based losses.
Furthermore, we develop a simple and interpretable, dataset and model-specific
heuristic to integrate the Focal parameter into the Squeeze-and-Excitation
block and Attention Gate, achieving optimal performance with fewer number of
attention modules on three well-validated biomedical imaging datasets,
suggesting judicious use of attention modules results in better performance and
efficiency.</p>
  </details>
</details>
<details>
  <summary>102. <b>标题：Incorporating Boundary Uncertainty into loss functions for biomedical  image segmentation</b></summary>
  <p><b>编号</b>：[464]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00533</p>
  <p><b>作者</b>：Michael Yeung,  Guang Yang,  Evis Sala,  Carola-Bibiane Schönlieb,  Leonardo Rundo</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：achieving consistently improved performance across three well, validated biomedical imaging datasets compared, automated image segmentation tasks, enable robust model training, neither approach accurately reflects</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Manual segmentation is used as the gold-standard for evaluating neural
networks on automated image segmentation tasks. Due to considerable
heterogeneity in shapes, colours and textures, demarcating object boundaries is
particularly difficult in biomedical images, resulting in significant inter and
intra-rater variability. Approaches, such as soft labelling and distance
penalty term, apply a global transformation to the ground truth, redefining the
loss function with respect to uncertainty. However, global operations are
computationally expensive, and neither approach accurately reflects the
uncertainty underlying manual annotation. In this paper, we propose the
Boundary Uncertainty, which uses morphological operations to restrict soft
labelling to object boundaries, providing an appropriate representation of
uncertainty in ground truth labels, and may be adapted to enable robust model
training where systematic manual segmentation errors are present. We
incorporate Boundary Uncertainty with the Dice loss, achieving consistently
improved performance across three well-validated biomedical imaging datasets
compared to soft labelling and distance-weighted penalty. Boundary Uncertainty
not only more accurately reflects the segmentation process, but it is also
efficient, robust to segmentation errors and exhibits better generalisation.</p>
  </details>
</details>
<details>
  <summary>103. <b>标题：Calibrating the Dice loss to handle neural network overconfidence for  biomedical image segmentation</b></summary>
  <p><b>编号</b>：[465]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00528</p>
  <p><b>作者</b>：Michael Yeung,  Leonardo Rundo,  Yang Nan,  Evis Sala,  Carola-Bibiane Schönlieb,  Guang Yang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：dsc ++ loss achieves significantly improved calibration, conventional dsc loss across five well, deep learning based biomedical image segmentation, training deep learning segmentation models, well calibrated outputs enable tailoring</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The Dice similarity coefficient (DSC) is both a widely used metric and loss
function for biomedical image segmentation due to its robustness to class
imbalance. However, it is well known that the DSC loss is poorly calibrated,
resulting in overconfident predictions that cannot be usefully interpreted in
biomedical and clinical practice. Performance is often the only metric used to
evaluate segmentations produced by deep neural networks, and calibration is
often neglected. However, calibration is important for translation into
biomedical and clinical practice, providing crucial contextual information to
model predictions for interpretation by scientists and clinicians. In this
study, we identify poor calibration as an emerging challenge of deep learning
based biomedical image segmentation. We provide a simple yet effective
extension of the DSC loss, named the DSC++ loss, that selectively modulates the
penalty associated with overconfident, incorrect predictions. As a standalone
loss function, the DSC++ loss achieves significantly improved calibration over
the conventional DSC loss across five well-validated open-source biomedical
imaging datasets. Similarly, we observe significantly improved when integrating
the DSC++ loss into four DSC-based loss functions. Finally, we use softmax
thresholding to illustrate that well calibrated outputs enable tailoring of
precision-recall bias, an important post-processing technique to adapt the
model predictions to suit the biomedical or clinical task. The DSC++ loss
overcomes the major limitation of the DSC, providing a suitable loss function
for training deep learning segmentation models for use in biomedical and
clinical practice.</p>
  </details>
</details>
<details>
  <summary>104. <b>标题：A robust single-pixel particle image velocimetry based on fully  convolutional networks with cross-correlation embedded</b></summary>
  <p><b>编号</b>：[471]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00395</p>
  <p><b>作者</b>：Qi Gao,  Hongtao Lin,  Han Tu,  Haoran Zhu,  Runjie Wei,  Guoping Zhang,  Xueming Shao</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：proposed model could therefore provide competitive, initial velocity field calculated using cross, new velocity field estimation paradigm, synthetic data sets including ground, real experimental piv data sets</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Particle image velocimetry (PIV) is essential in experimental fluid dynamics.
In the current work, we propose a new velocity field estimation paradigm, which
achieves a synergetic combination of the deep learning method and the
traditional cross-correlation method. Specifically, the deep learning method is
used to optimize and correct a coarse velocity guess to achieve a
super-resolution calculation. And the cross-correlation method provides the
initial velocity field based on a coarse correlation with a large interrogation
window. As a reference, the coarse velocity guess helps with improving the
robustness of the proposed algorithm. This fully convolutional network with
embedded cross-correlation is named as CC-FCN. CC-FCN has two types of input
layers, one is for the particle images, and the other is for the initial
velocity field calculated using cross-correlation with a coarse resolution.
Firstly, two pyramidal modules extract features of particle images and initial
velocity field respectively. Then the fusion module appropriately fuses these
features. Finally, CC-FCN achieves the super-resolution calculation through a
series of deconvolution layers to obtain the single-pixel velocity field. As
the supervised learning strategy is considered, synthetic data sets including
ground-truth fluid motions are generated to train the network parameters.
Synthetic and real experimental PIV data sets are used to test the trained
neural network in terms of accuracy, precision, spatial resolution and
robustness. The test results show that these attributes of CC-FCN are further
improved compared with those of other tested PIV algorithms. The proposed model
could therefore provide competitive and robust estimations for PIV experiments.</p>
  </details>
</details>
<details>
  <summary>105. <b>标题：Speaker conditioning of acoustic models using affine transformation for  multi-speaker speech recognition</b></summary>
  <p><b>编号</b>：[475]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00320</p>
  <p><b>作者</b>：Midia Yousefi,  John H.L. Hanse</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：original resnet acoustic model baseline, speaker conditioning process allows, channel automatic speech recognition, fuse speaker auxiliary information, proposed speaker conditioning method</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This study addresses the problem of single-channel Automatic Speech
Recognition of a target speaker within an overlap speech scenario. In the
proposed method, the hidden representations in the acoustic model are modulated
by speaker auxiliary information to recognize only the desired speaker. Affine
transformation layers are inserted into the acoustic model network to integrate
speaker information with the acoustic features. The speaker conditioning
process allows the acoustic model to perform computation in the context of
target-speaker auxiliary information. The proposed speaker conditioning method
is a general approach and can be applied to any acoustic model architecture.
Here, we employ speaker conditioning on a ResNet acoustic model. Experiments on
the WSJ corpus show that the proposed speaker conditioning method is an
effective solution to fuse speaker auxiliary information with acoustic features
for multi-speaker speech recognition, achieving +9% and +20% relative WER
reduction for clean and overlap speech scenarios, respectively, compared to the
original ResNet acoustic model baseline.</p>
  </details>
</details>
<details>
  <summary>106. <b>标题：DeepDoseNet: A Deep Learning model for 3D Dose Prediction in Radiation  Therapy</b></summary>
  <p><b>编号</b>：[487]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.00077</p>
  <p><b>作者</b>：Mumtaz Hussain Soomro,  Victor Gabriel Leandro Alves,  Hamidreza Nourzadeh,  Jeffrey V. Siebers</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：d99 %, d95 %, d1, d99 %, d95 %, d1, deepdosenet 3d dose prediction model based, predicted 3d dose distributions, 2020 aapm openkbp challenge</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The DeepDoseNet 3D dose prediction model based on ResNet and Dilated DenseNet
is proposed. The 340 head-and-neck datasets from the 2020 AAPM OpenKBP
challenge were utilized, with 200 for training, 40 for validation, and 100 for
testing. Structures include 56Gy, 63Gy, 70Gy PTVs, and brainstem, spinal cord,
right parotid, left parotid, larynx, esophagus, and mandible OARs. Mean squared
error (MSE) loss, mean absolute error (MAE) loss, and MAE plus dose-volume
histogram (DVH) based loss functions were investigated. Each model's
performance was compared using a 3D dose score, $\bar{S_{D}}$, (mean absolute
difference between ground truth and predicted 3D dose distributions) and a DVH
score, $\bar{S_{DVH}}$ (mean absolute difference between ground truth and
predicted dose-volume metrics).Furthermore, DVH metrics Mean[Gy] and D0.1cc
[Gy] for OARs and D99%, D95%, D1% for PTVs were computed. DeepDoseNet with the
MAE plus DVH-based loss function had the best dose score performance of the
OpenKBP entries. MAE+DVH model had the lowest prediction error (P<0.0001, wilcoxon test) on validation and test datasets (validation: $\bar{s_{d}}$="2.3Gy," $\bar{s_{dvh}}$="1.9Gy;" test: followed by the mae model mse had highest prediction error no significant difference was found among models in terms of mean [gy], but mae+dvh significantly outperformed d0.1cc[gy], particularly for mandible parotids both (p<0.01) (p<0.0001) datasets. d99%, d95%, d1% targets. reduced ~60% ~70%.< p>
  </0.0001,></p></details>
</details>
<details>
  <summary>107. <b>标题：Sampling-Based Robust Control of Autonomous Systems with Non-Gaussian  Noise</b></summary>
  <p><b>编号</b>：[494]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2110.12662</p>
  <p><b>作者</b>：Thom S. Badings,  Alessandro Abate,  Nils Jansen,  David Parker,  Hasan A. Poonawala,  Marielle Stoelinga</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：called interval markov decision process, critical settings must account, compute probably approximately correct, realistic benchmarks show, art verification techniques</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Controllers for autonomous systems that operate in safety-critical settings
must account for stochastic disturbances. Such disturbances are often modelled
as process noise, and common assumptions are that the underlying distributions
are known and/or Gaussian. In practice, however, these assumptions may be
unrealistic and can lead to poor approximations of the true noise distribution.
We present a novel planning method that does not rely on any explicit
representation of the noise distributions. In particular, we address the
problem of computing a controller that provides probabilistic guarantees on
safely reaching a target. First, we abstract the continuous system into a
discrete-state model that captures noise by probabilistic transitions between
states. As a key contribution, we adapt tools from the scenario approach to
compute probably approximately correct (PAC) bounds on these transition
probabilities, based on a finite number of samples of the noise. We capture
these bounds in the transition probability intervals of a so-called interval
Markov decision process (iMDP). This iMDP is robust against uncertainty in the
transition probabilities, and the tightness of the probability intervals can be
controlled through the number of samples. We use state-of-the-art verification
techniques to provide guarantees on the iMDP, and compute a controller for
which these guarantees carry over to the autonomous system. Realistic
benchmarks show the practical applicability of our method, even when the iMDP
has millions of states or transitions.</p>
  </details>
</details>
<details>
  <summary>108. <b>标题：Multiple Sclerosis Lesions Identification/Segmentation in Magnetic  Resonance Imaging using Ensemble CNN and Uncertainty Classification</b></summary>
  <p><b>编号</b>：[495]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2108.11791</p>
  <p><b>作者</b>：Giuseppe Placidi,  Luigi Cinque,  Filippo Mignosi,  Matteo Polsinelli</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：2016 msseg benchmark public data set, better emulate human reasoning, three pivotal concepts, single imaging modality, physicians partially manage</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>To date, several automated strategies for identification/segmentation of
Multiple Sclerosis (MS) lesions with the use of Magnetic Resonance Imaging
(MRI) have been presented but they are either outperformed by human experts or
perform differently from them. This is mainly due to the ambiguity originated
by MRI instabilities, peculiar variability of MS and unspecific nature of MRI
with respect to MS. Physicians partially manage the uncertainty generated by
ambiguity relying on their personal radiological/clinical/anatomical background
and experience. We present an automated framework based on three pivotal
concepts to better emulate human reasoning: 1. the modelling of uncertainty; 2.
the proposal of two, separately trained, CNN, one optimized with respect to
lesions themselves and the other to the environment surrounding lesions,
respectively repeated for axial, coronal and sagittal directions; 3. the
definition of an ensemble classifier to merge the information collected by all
CNN. The proposed framework is trained, validated and tested on the 2016 MSSEG
benchmark public data set from a single imaging modality, the FLuid-Attenuated
Inversion Recovery (FLAIR). The comparison, made with the consensus (the
ground-truth) between 7 human raters and with each of the 7 human raters,
proves that there is no significant difference between the automated and the
human raters. The results of our framework concerning the uncertainty are also
reported, even if a comparison with the raters is impossible because they don't
recognize this class.</p>
  </details>
</details>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">徐耀彬</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://louishsu.xyz/2021/11/03/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html">http://louishsu.xyz/2021/11/03/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://louishsu.xyz" target="_blank">LOUIS' BLOG</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"></div><div class="post_share"><div class="social-share" data-image="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="next-post pull-full"><a href="/2021/05/19/%E5%85%A8%E7%90%83%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%8A%80%E6%9C%AF%E5%88%9B%E6%96%B0%E5%A4%A7%E8%B5%9B%E3%80%90%E8%B5%9B%E9%81%93%E4%B8%80%E3%80%91%EF%BC%9A%E5%8C%BB%E5%AD%A6%E5%BD%B1%E5%83%8F%E6%8A%A5%E5%91%8A%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B.html"><img class="next-cover" src="https://tianchi-public.oss-cn-hangzhou.aliyuncs.com/public/files/forum/161037709574435991610377095138.jpeg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">全球人工智能技术创新大赛【赛道一】：医学影像报告异常检测</div></div></a></div></nav><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="twikoo-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="card-info-avatar is-center"><img class="avatar-img" src="/img/touxiang.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/><div class="author-info__name">徐耀彬</div><div class="author-info__description">ᵕ᷄ ≀ ̠˘᷅ 永远年轻，永远热泪盈眶</div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">10</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">标签</div><div class="length-num">3</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">分类</div><div class="length-num">7</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/isLouisHsu"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/isLouisHsu" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:is.louishsu@foxmail.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>公告</span></div><div class="announcement_content">记录和分享一些学习和开源内容，若有问题可通过邮箱is.louishsu@foxmail.com联系，欢迎交流！！</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">1.</span> <span class="toc-text">统计</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">2.</span> <span class="toc-text">计算机视觉</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">3.</span> <span class="toc-text">自然语言处理</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">4.</span> <span class="toc-text">机器学习</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">5.</span> <span class="toc-text">人工智能</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2021/11/03/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html" title="Arxiv每日速递(2021-11-03)"><img src="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Arxiv每日速递(2021-11-03)"/></a><div class="content"><a class="title" href="/2021/11/03/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html" title="Arxiv每日速递(2021-11-03)">Arxiv每日速递(2021-11-03)</a><time datetime="2021-11-03T00:26:11.862Z" title="发表于 2021-11-03 08:26:11">2021-11-03</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/05/19/%E5%85%A8%E7%90%83%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%8A%80%E6%9C%AF%E5%88%9B%E6%96%B0%E5%A4%A7%E8%B5%9B%E3%80%90%E8%B5%9B%E9%81%93%E4%B8%80%E3%80%91%EF%BC%9A%E5%8C%BB%E5%AD%A6%E5%BD%B1%E5%83%8F%E6%8A%A5%E5%91%8A%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B.html" title="全球人工智能技术创新大赛【赛道一】：医学影像报告异常检测"><img src="https://tianchi-public.oss-cn-hangzhou.aliyuncs.com/public/files/forum/161037709574435991610377095138.jpeg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="全球人工智能技术创新大赛【赛道一】：医学影像报告异常检测"/></a><div class="content"><a class="title" href="/2021/05/19/%E5%85%A8%E7%90%83%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%8A%80%E6%9C%AF%E5%88%9B%E6%96%B0%E5%A4%A7%E8%B5%9B%E3%80%90%E8%B5%9B%E9%81%93%E4%B8%80%E3%80%91%EF%BC%9A%E5%8C%BB%E5%AD%A6%E5%BD%B1%E5%83%8F%E6%8A%A5%E5%91%8A%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B.html" title="全球人工智能技术创新大赛【赛道一】：医学影像报告异常检测">全球人工智能技术创新大赛【赛道一】：医学影像报告异常检测</a><time datetime="2021-05-19T09:57:06.000Z" title="发表于 2021-05-19 17:57:06">2021-05-19</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2020/09/16/%E8%AF%A6%E8%A7%A3%E5%91%BD%E5%90%8D%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB%E6%A8%A1%E5%9E%8B%EF%BC%9ALSTM-CRF.html" title="详解命名实体识别模型：LSTM-CRF"><img src="https://gimg2.baidu.com/image_search/src=http%3A%2F%2Fpic1.zhimg.com%2Fv2-1ed6a10dbb239a148e42df088c5870a6_1440w.jpg%3Fsource%3D172ae18b&amp;refer=http%3A%2F%2Fpic1.zhimg.com&amp;app=2002&amp;size=f9999,10000&amp;q=a80&amp;n=0&amp;g=0n&amp;fmt=jpeg?sec=1638183974&amp;t=4632f13fd487ed1cfcb12d67a6b71e52" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="详解命名实体识别模型：LSTM-CRF"/></a><div class="content"><a class="title" href="/2020/09/16/%E8%AF%A6%E8%A7%A3%E5%91%BD%E5%90%8D%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB%E6%A8%A1%E5%9E%8B%EF%BC%9ALSTM-CRF.html" title="详解命名实体识别模型：LSTM-CRF">详解命名实体识别模型：LSTM-CRF</a><time datetime="2020-09-16T09:26:44.000Z" title="发表于 2020-09-16 17:26:44">2020-09-16</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2020/06/14/%E8%AE%B0%E4%B8%80%E6%AC%A1MySQL%E8%A7%A3%E5%86%B3%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E6%97%B6%E7%9A%84%E5%88%86%E8%A1%A8%E9%97%AE%E9%A2%98.html" title="记一次MySQL解决大数据存储时的分表问题"><img src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="记一次MySQL解决大数据存储时的分表问题"/></a><div class="content"><a class="title" href="/2020/06/14/%E8%AE%B0%E4%B8%80%E6%AC%A1MySQL%E8%A7%A3%E5%86%B3%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E6%97%B6%E7%9A%84%E5%88%86%E8%A1%A8%E9%97%AE%E9%A2%98.html" title="记一次MySQL解决大数据存储时的分表问题">记一次MySQL解决大数据存储时的分表问题</a><time datetime="2020-06-14T15:24:27.000Z" title="发表于 2020-06-14 23:24:27">2020-06-14</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2020/05/05/grep-sed-awk.html" title="grep, sed, awk"><img src="https://img2.baidu.com/it/u=2210698206,229004679&amp;fm=15&amp;fmt=auto" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="grep, sed, awk"/></a><div class="content"><a class="title" href="/2020/05/05/grep-sed-awk.html" title="grep, sed, awk">grep, sed, awk</a><time datetime="2020-05-05T10:47:36.000Z" title="发表于 2020-05-05 18:47:36">2020-05-05</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2021 By 徐耀彬</div><div class="footer_custom_text"><p><a style="margin-inline:5px"target="_blank"href="https://hexo.io/"><img src="https://img.shields.io/badge/Frame-Hexo-blue?style=flat&logo=hexo"title="博客框架为Hexo"alt="img"></a><a style="margin-inline:5px"target="_blank"href="https://butterfly.js.org/"><img src="https://img.shields.io/badge/Theme-Butterfly-6513df?style=flat&logo=bitdefender"title="主题采用butterfly"alt="img"></a><a style="margin-inline:5px"target="_blank"href="https://www.jsdelivr.com/"><img src="https://img.shields.io/badge/CDN-jsDelivr-orange?style=flat&logo=jsDelivr"title="本站使用JsDelivr为静态资源提供CDN加速"alt="img"></a><a style="margin-inline:5px"target="_blank"href="https://github.com/"><img src="https://img.shields.io/badge/Source-Github-d021d6?style=flat&logo=GitHub"title="本站项目由Gtihub托管"alt="img"></a><a style="margin-inline:5px"target="_blank"href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img src="https://img.shields.io/badge/Copyright-BY--NC--SA%204.0-d42328?style=flat&logo=Claris"alt="img"title="本站采用知识共享署名-非商业性使用-相同方式共享4.0国际许可协议进行许可"></a></br></p></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="font-plus" type="button" title="放大字体"><i class="fas fa-plus"></i></button><button id="font-minus" type="button" title="缩小字体"><i class="fas fa-minus"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div></div><hr/><div id="local-search-results"></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.css"><script>(() => {
  document.querySelectorAll('#article-container span.katex-display').forEach(item => {
    btf.wrap(item, 'div', '', 'katex-wrap')
  })
})()</script><script>(()=>{
  const $countDom = document.getElementById('twikoo-count')
  const init = () => {
    let initData = {
      el: '#twikoo-wrap',
      envId: 'blog-',
      region: ''
    }

    if (false) {
      const otherData = false
      initData = Object.assign(initData, otherData)
    }
    
    twikoo.init(initData)
  }

  const getCount = () => {
    twikoo.getCommentsCount({
      envId: 'blog-',
      region: '',
      urls: [window.location.pathname],
      includeReply: false
    }).then(function (res) {
      $countDom.innerText = res[0].count
    }).catch(function (err) {
      console.error(err);
    });
  }

  const loadTwikoo = (bool = false) => {
    if (typeof twikoo === 'object') {
      init()
      bool && $countDom && setTimeout(getCount,0)
    } else {
      getScript('https://cdn.jsdelivr.net/npm/twikoo/dist/twikoo.all.min.js').then(()=> {
        init()
        bool && $countDom && setTimeout(getCount,0)
      })
    }
  }

  if ('Twikoo' === 'Twikoo' || !false) {
    if (false) btf.loadComment(document.getElementById('twikoo-wrap'), loadTwikoo)
    else loadTwikoo(true)
  } else {
    window.loadOtherComment = () => {
      loadTwikoo()
    }
  }
})()</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><!-- hexo injector body_end start --> <script data-pjax>if(document.getElementById('recent-posts') && (location.pathname ==='/'|| '/' ==='all')){
    var parent = document.getElementById('recent-posts');
    var child = '<div class="recent-post-item" style="width:100%;height: auto"><div id="catalog_magnet"><div class="magnet_item"><a class="magnet_link" href="http://louishsu.xyz/categories/机器学习/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🐱 机器学习 (1)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://louishsu.xyz/categories/自然语言处理/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">📚 自然语言处理 (1)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://louishsu.xyz/categories/竞赛相关/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🎮 竞赛相关 (1)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://louishsu.xyz/categories/阅读笔记/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🎮 阅读笔记 (1)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><a class="magnet_link_more"  href="http://louishsu.xyz/categories" style="flex:1;text-align: center;margin-bottom: 10px;">查看更多...</a></div></div>';
    console.log('已挂载magnet')
    parent.insertAdjacentHTML("afterbegin",child)}
     </script><style>#catalog_magnet{flex-wrap: wrap;display: flex;width:100%;justify-content:space-between;padding: 10px 10px 0 10px;align-content: flex-start;}.magnet_item{flex-basis: calc(50% - 5px);background: #f2f2f2;margin-bottom: 10px;border-radius: 8px;transition: all 0.2s ease-in-out;}.magnet_item:hover{background: #b30070}.magnet_link_more{color:#555}.magnet_link{color:black}.magnet_link:hover{color:white}@media screen and (max-width: 600px) {.magnet_item {flex-basis: 100%;}}.magnet_link_context{display:flex;padding: 10px;font-size:16px;transition: all 0.2s ease-in-out;}.magnet_link_context:hover{padding: 10px 20px;}</style>
    <style></style>
  <script data-pjax src="https://cdn.jsdelivr.net/gh/Zfour/hexo-github-calendar@1.21/hexo_githubcalendar.js"></script>
  <script data-pjax>
        function GithubCalendarConfig(){
            var git_githubapiurl ="https://python-github-calendar-api.vercel.app/api?isLouisHsu";
            var git_color =['#ebedf0', '#fdcdec', '#fc9bd9', '#fa6ac5', '#f838b2', '#f5089f', '#c4067e', '#92055e', '#540336', '#48022f', '#30021f'];
            var git_user ="isLouisHsu";
            var parent_div_git = document.getElementById('recent-posts');
            var git_div_html = '<div class="recent-post-item" style="width:100%;height:auto;padding:10px;"><div id="github_loading" style="width:10%;height:100%;margin:0 auto;display: block"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"  viewBox="0 0 50 50" style="enable-background:new 0 0 50 50" xml:space="preserve"><path fill="#d0d0d0" d="M25.251,6.461c-10.318,0-18.683,8.365-18.683,18.683h4.068c0-8.071,6.543-14.615,14.615-14.615V6.461z" transform="rotate(275.098 25 25)"><animateTransform attributeType="xml" attributeName="transform" type="rotate" from="0 25 25" to="360 25 25" dur="0.6s" repeatCount="indefinite"></animateTransform></path></svg></div><div id="github_container"></div></div>';
            if(parent_div_git && location.pathname =='/'){
                console.log('已挂载github calendar')
                // parent_div_git.innerHTML=git_div_html+parent_div_git.innerHTML // 无报错，但不影响使用(支持pjax跳转)
                parent_div_git.insertAdjacentHTML("afterbegin",git_div_html) // 有报错，但不影响使用(支持pjax跳转)
            };
            GithubCalendar(git_githubapiurl,git_color,git_user)
        }
        if(document.getElementById('recent-posts')){
            GithubCalendarConfig()
        }
    </script>
    <style>#github_container{min-height:280px}@media screen and (max-width:650px) {#github_container{background-image:;min-height:0px}}</style>
    <style></style><script data-pjax>function electric_clock_injector_config(){
                var parent_div_git = document.getElementsByClassName('sticky_layout')[0];
                var item_html = '<div class="card-widget card-clock"><div class="card-glass"><div class="card-background"><div class="card-content"><div id="hexo_electric_clock"><img id="card-clock-loading" src="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-clock/clock/images/weather/loading.gif" style="height: 120px; width: 100%;" data-ll-status="loading" class="entered loading"></div></div></div></div></div>';
                console.log('已挂载electric_clock')
                // parent_div_git.innerHTML=item_html+parent_div_git.innerHTML // 无报错，但不影响使用(支持pjax跳转)
                parent_div_git.insertAdjacentHTML("afterbegin",item_html) // 有报错，但不影响使用(支持pjax跳转)
            }if( document.getElementsByClassName('sticky_layout')[0] && (location.pathname ==='all'|| 'all' ==='all')){

            electric_clock_injector_config()
        } </script><script src="https://pv.sohu.com/cityjson?ie=utf-8"></script><script data-pjax  src="https://cdn.jsdelivr.net/gh/Zfour/hexo-electric-clock@1.0.6/clock.js"></script><!-- hexo injector body_end end --><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"model":{"jsonPath":"/live2dw/assets/hijiki.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":false},"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body></html>