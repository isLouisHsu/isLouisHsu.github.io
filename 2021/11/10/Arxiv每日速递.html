<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Arxiv每日速递(2021-11-10) | LOUIS' BLOG</title><meta name="author" content="徐耀彬"><meta name="copyright" content="徐耀彬"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="本篇博文主要展示每日从Arxiv论文网站获取的最新论文列表，以计算机视觉、自然语言处理、机器学习、人工智能等大方向进行划分。 统计 今日共更新454篇论文，其中：  84篇计算机视觉（cs.CV） 33篇自然语言处理（cs.CL） 164篇机器学习（cs.LG） 80篇人工智能（cs.AI）  计算机视觉    1. 标题：SustainBench: Benchmarks for Monitori">
<meta property="og:type" content="article">
<meta property="og:title" content="Arxiv每日速递(2021-11-10)">
<meta property="og:url" content="http://louishsu.xyz/2021/11/10/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html">
<meta property="og:site_name" content="LOUIS&#39; BLOG">
<meta property="og:description" content="本篇博文主要展示每日从Arxiv论文网站获取的最新论文列表，以计算机视觉、自然语言处理、机器学习、人工智能等大方向进行划分。 统计 今日共更新454篇论文，其中：  84篇计算机视觉（cs.CV） 33篇自然语言处理（cs.CL） 164篇机器学习（cs.LG） 80篇人工智能（cs.AI）  计算机视觉    1. 标题：SustainBench: Benchmarks for Monitori">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png">
<meta property="article:published_time" content="2021-11-10T00:26:44.000Z">
<meta property="article:modified_time" content="2021-11-10T00:28:45.909Z">
<meta property="article:author" content="徐耀彬">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://louishsu.xyz/2021/11/10/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2021-11-10 08:28:45'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const fontSizeVal = saveToLocal.get('global-font-size')
    if (fontSizeVal !== undefined) {
      document.documentElement.style.setProperty('--global-font-size', fontSizeVal + 'px')
    }
    })(window)</script><link rel="stylesheet" href="/css/background.css"><script src="https://cdn.jsdelivr.net/npm/echarts@4.7.0/dist/echarts.min.js"></script><!-- hexo injector head_end start --><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Zfour/hexo-electric-clock@1.0.6/clock.css"><!-- hexo injector head_end end --><meta name="generator" content="Hexo 5.4.0"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="author-avatar"><img class="avatar-img" src="/img/touxiang.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">10</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">标签</div><div class="length-num">3</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">分类</div><div class="length-num">7</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/message/"><i class="fa-fw far fa-comment-dots"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa-fw fa fa-book"></i><span> 找文章</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></li><li><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></li><li><a class="site-page" href="/charts/"><i class="fa-fw fa fa-archive"></i><span> 统计</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-tools"></i><span> 工具</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/md_editor/"><i class="fa-fw fas fa-pen"></i><span> 在线markdown</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/isLouisHsu/blog/tree/master/source/_posts"><i class="fa-fw fa fa-star"></i><span> 在线push</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">LOUIS' BLOG</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/message/"><i class="fa-fw far fa-comment-dots"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa-fw fa fa-book"></i><span> 找文章</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></li><li><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></li><li><a class="site-page" href="/charts/"><i class="fa-fw fa fa-archive"></i><span> 统计</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-tools"></i><span> 工具</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/md_editor/"><i class="fa-fw fas fa-pen"></i><span> 在线markdown</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/isLouisHsu/blog/tree/master/source/_posts"><i class="fa-fw fa fa-star"></i><span> 在线push</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Arxiv每日速递(2021-11-10)<a class="post-edit-link" href="https://github.com/isLouisHsu/blog/tree/master/source_posts/Arxiv每日速递.md" title="编辑" target="_blank"><i class="fas fa-pencil-square"></i></a></h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2021-11-10T00:26:44.000Z" title="发表于 2021-11-10 08:26:44">2021-11-10</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2021-11-10T00:28:45.909Z" title="更新于 2021-11-10 08:28:45">2021-11-10</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">阅读笔记</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">91.2k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>546分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span><span class="post-meta-separator">|</span><span class="post-meta-commentcount"><i class="far fa-comments fa-fw post-meta-icon"></i><span class="post-meta-label">评论数:</span><a href="/2021/11/10/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html#post-comment"><span id="twikoo-count"></span></a></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><p>本篇博文主要展示每日从Arxiv论文网站获取的最新论文列表，以计算机视觉、自然语言处理、机器学习、人工智能等大方向进行划分。</p>
<h1>统计</h1>
<p>今日共更新454篇论文，其中：</p>
<ul>
<li>84篇计算机视觉（<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>）</li>
<li>33篇自然语言处理（<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>）</li>
<li>164篇机器学习（cs.LG）</li>
<li>80篇人工智能（<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>）</li>
</ul>
<h1>计算机视觉</h1>
<details>
  <summary>1. <b>标题：SustainBench: Benchmarks for Monitoring the Sustainable Development  Goals with Machine Learning</b></summary>
  <p><b>编号</b>：[3]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04724</p>
  <p><b>作者</b>：Christopher Yeh,  Chenlin Meng,  Sherrie Wang,  Anne Driscoll,  Erik Rozi,  Patrick Liu,  Jihyeon Lee,  Marshall Burke,  David B. Lobell,  Stefano Ermon</p>
  <p><b>备注</b>：NeurIPS 2021 (Track on Datasets and Benchmarks)</p>
  <p><b>关键词</b>：improved model performance facilitates progress towards, ground survey data requires domain knowledge, 15 benchmark tasks across 7 sdgs, united nations sustainable development goals, used inconsistent evaluation metrics</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Progress toward the United Nations Sustainable Development Goals (SDGs) has
been hindered by a lack of data on key environmental and socioeconomic
indicators, which historically have come from ground surveys with sparse
temporal and spatial coverage. Recent advances in machine learning have made it
possible to utilize abundant, frequently-updated, and globally available data,
such as from satellites or social media, to provide insights into progress
toward SDGs. Despite promising early results, approaches to using such data for
SDG measurement thus far have largely evaluated on different datasets or used
inconsistent evaluation metrics, making it hard to understand whether
performance is improving and where additional research would be most fruitful.
Furthermore, processing satellite and ground survey data requires domain
knowledge that many in the machine learning community lack. In this paper, we
introduce SustainBench, a collection of 15 benchmark tasks across 7 SDGs,
including tasks related to economic development, agriculture, health,
education, water and sanitation, climate action, and life on land. Datasets for
11 of the 15 tasks are released publicly for the first time. Our goals for
SustainBench are to (1) lower the barriers to entry for the machine learning
community to contribute to measuring and achieving the SDGs; (2) provide
standard benchmarks for evaluating machine learning models on tasks across a
variety of SDGs; and (3) encourage the development of novel machine learning
methods where improved model performance facilitates progress towards the SDGs.</p>
  </details>
</details>
<details>
  <summary>2. <b>标题：OMD: Orthogonal Malware Detection Using Audio, Image, and Static  Features</b></summary>
  <p><b>编号</b>：[7]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04710</p>
  <p><b>作者</b>：Lakshmanan Nataraj,  Tajuddin Manhar Mohammed,  Tejaswi Nanjundaswamy,  Satish Chikkagoudar,  Shivkumar Chandrasekaran,  B.S. Manjunath</p>
  <p><b>备注</b>：Submitted version - MILCOM 2021 IEEE Military Communications Conference</p>
  <p><b>关键词</b>：detecting unique malware samples, identify malware using, classifying malware families, new feature set, cyber defense approaches</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>With the growing number of malware and cyber attacks, there is a need for
"orthogonal" cyber defense approaches, which are complementary to existing
methods by detecting unique malware samples that are not predicted by other
methods. In this paper, we propose a novel and orthogonal malware detection
(OMD) approach to identify malware using a combination of audio descriptors,
image similarity descriptors and other static/statistical features. First, we
show how audio descriptors are effective in classifying malware families when
the malware binaries are represented as audio signals. Then, we show that the
predictions made on the audio descriptors are orthogonal to the predictions
made on image similarity descriptors and other static features. Further, we
develop a framework for error analysis and a metric to quantify how orthogonal
a new feature set (or type) is with respect to other feature sets. This allows
us to add new features and detection methods to our overall framework.
Experimental results on malware datasets show that our approach provides a
robust framework for orthogonal malware detection.</p>
  </details>
</details>
<details>
  <summary>3. <b>标题：SMU: smooth activation function for deep networks using smoothing  maximum technique</b></summary>
  <p><b>编号</b>：[16]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04682</p>
  <p><b>作者</b>：Koushik Biswas,  Sandeep Kumar,  Shilpak Banerjee,  Ashish Kumar Pandey</p>
  <p><b>备注</b>：7 pages</p>
  <p><b>关键词</b>：proposing two new novel activation functions, known activation functions like leaky relu, new novel activation function based, function smooth maximum unit, deep learning community due</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep learning researchers have a keen interest in proposing two new novel
activation functions which can boost network performance. A good choice of
activation function can have significant consequences in improving network
performance. A handcrafted activation is the most common choice in neural
network models. ReLU is the most common choice in the deep learning community
due to its simplicity though ReLU has some serious drawbacks. In this paper, we
have proposed a new novel activation function based on approximation of known
activation functions like Leaky ReLU, and we call this function Smooth Maximum
Unit (SMU). Replacing ReLU by SMU, we have got 6.22% improvement in the
CIFAR100 dataset with the ShuffleNet V2 model.</p>
  </details>
</details>
<details>
  <summary>4. <b>标题：Information-Theoretic Bias Assessment Of Learned Representations Of  Pretrained Face Recognition</b></summary>
  <p><b>编号</b>：[18]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04673</p>
  <p><b>作者</b>：Jiazhi Li,  Wael Abd-Almageed</p>
  <p><b>备注</b>：FG2021</p>
  <p><b>关键词</b>：explain bias since predictors based, pretrained facial recognition systems, debiased deep learning models, protected attributes predicted using, independent bias assessment metric</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As equality issues in the use of face recognition have garnered a lot of
attention lately, greater efforts have been made to debiased deep learning
models to improve fairness to minorities. However, there is still no clear
definition nor sufficient analysis for bias assessment metrics. We propose an
information-theoretic, independent bias assessment metric to identify degree of
bias against protected demographic attributes from learned representations of
pretrained facial recognition systems. Our metric differs from other methods
that rely on classification accuracy or examine the differences between ground
truth and predicted labels of protected attributes predicted using a shallow
network. Also, we argue, theoretically and experimentally, that logits-level
loss is not adequate to explain bias since predictors based on neural networks
will always find correlations. Further, we present a synthetic dataset that
mitigates the issue of insufficient samples in certain cohorts. Lastly, we
establish a benchmark metric by presenting advantages in clear discrimination
and small variation comparing with other metrics, and evaluate the performance
of different debiased models with the proposed metric.</p>
  </details>
</details>
<details>
  <summary>5. <b>标题：Approximate Neural Architecture Search via Operation Distribution  Learning</b></summary>
  <p><b>编号</b>：[20]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04670</p>
  <p><b>作者</b>：Xingchen Wan,  Binxin Ru,  Pedro M. Esperança,  Fabio M. Carlucci</p>
  <p><b>备注</b>：WACV 2022. 10 pages, 3 figures and 5 tables (15 pages, 7 figures and 6 tables including appendices)</p>
  <p><b>关键词</b>：holds enough discriminating power, simple intuition significantly reduces, fully deterministic architecture, specific connection pattern, typical search spaces</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The standard paradigm in Neural Architecture Search (NAS) is to search for a
fully deterministic architecture with specific operations and connections. In
this work, we instead propose to search for the optimal operation distribution,
thus providing a stochastic and approximate solution, which can be used to
sample architectures of arbitrary length. We propose and show, that given an
architectural cell, its performance largely depends on the ratio of used
operations, rather than any specific connection pattern in typical search
spaces; that is, small changes in the ordering of the operations are often
irrelevant. This intuition is orthogonal to any specific search strategy and
can be applied to a diverse set of NAS algorithms. Through extensive validation
on 4 data-sets and 4 NAS techniques (Bayesian optimisation, differentiable
search, local search and random search), we show that the operation
distribution (1) holds enough discriminating power to reliably identify a
solution and (2) is significantly easier to optimise than traditional
encodings, leading to large speed-ups at little to no cost in performance.
Indeed, this simple intuition significantly reduces the cost of current
approaches and potentially enable NAS to be used in a broader range of
applications.</p>
  </details>
</details>
<details>
  <summary>6. <b>标题：Composition and Style Attributes Guided Image Aesthetic Assessment</b></summary>
  <p><b>编号</b>：[25]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04647</p>
  <p><b>作者</b>：Luigi Celona,  Marco Leonardi,  Paolo Napoletano,  Alessandro Rozza</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：three benchmark datasets demonstrate, photographic setup used, ablation study gives, multi layer perceptron, aesthetic score distribution</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The aesthetic quality of an image is defined as the measure or appreciation
of the beauty of an image. Aesthetics is inherently a subjective property but
there are certain factors that influence it such as, the semantic content of
the image, the attributes describing the artistic aspect, the photographic
setup used for the shot, etc. In this paper we propose a method for the
automatic prediction of the aesthetics of an image that is based on the
analysis of the semantic content, the artistic style and the composition of the
image. The proposed network includes: a pre-trained network for semantic
features extraction (the Backbone); a Multi Layer Perceptron (MLP) network that
relies on the Backbone features for the prediction of image attributes (the
AttributeNet); a self-adaptive Hypernetwork that exploits the attributes prior
encoded into the embedding generated by the AttributeNet to predict the
parameters of the target network dedicated to aesthetic estimation (the
AestheticNet). Given an image, the proposed multi-network is able to predict:
style and composition attributes, and aesthetic score distribution. Results on
three benchmark datasets demonstrate the effectiveness of the proposed method,
while the ablation study gives a better understanding of the proposed network.</p>
  </details>
</details>
<details>
  <summary>7. <b>标题：S3RP: Self-Supervised Super-Resolution and Prediction for  Advection-Diffusion Process</b></summary>
  <p><b>编号</b>：[28]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04639</p>
  <p><b>作者</b>：Chulin Wang,  Kyongmin Yeo,  Xiao Jin,  Andres Codas,  Levente J. Klein,  Bruce Elmegreen</p>
  <p><b>备注</b>：9 pages, 8 figures</p>
  <p><b>关键词</b>：recurrent convolutional network trained, resolution models assume high, recurrent wasserstein autoencoder, hr information without, limited information</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present a super-resolution model for an advection-diffusion process with
limited information. While most of the super-resolution models assume
high-resolution (HR) ground-truth data in the training, in many cases such HR
dataset is not readily accessible. Here, we show that a Recurrent Convolutional
Network trained with physics-based regularizations is able to reconstruct the
HR information without having the HR ground-truth data. Moreover, considering
the ill-posed nature of a super-resolution problem, we employ the Recurrent
Wasserstein Autoencoder to model the uncertainty.</p>
  </details>
</details>
<details>
  <summary>8. <b>标题：DeepSteal: Advanced Model Extractions Leveraging Efficient Weight  Stealing in Memories</b></summary>
  <p><b>编号</b>：[33]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04625</p>
  <p><b>作者</b>：Adnan Siraj Rakin,  Md Hafizul Islam Chowdhuryy,  Fan Yao,  Deliang Fan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：extracted substitute model could also generate effective adversarial input samples, existing attacks cannot extract detailed model parameters, proposed deepsteal comprises two key stages, advanced model extraction attack framework deepsteal, new weight bit information extraction method</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent advancements of Deep Neural Networks (DNNs) have seen widespread
deployment in multiple security-sensitive domains. The need of
resource-intensive training and use of valuable domain-specific training data
have made these models a top intellectual property (IP) for model owners. One
of the major threats to the DNN privacy is model extraction attacks where
adversaries attempt to steal sensitive information in DNN models. Recent
studies show hardware-based side channel attacks can reveal internal knowledge
about DNN models (e.g., model architectures) However, to date, existing attacks
cannot extract detailed model parameters (e.g., weights/biases). In this work,
for the first time, we propose an advanced model extraction attack framework
DeepSteal that effectively steals DNN weights with the aid of memory
side-channel attack. Our proposed DeepSteal comprises two key stages. Firstly,
we develop a new weight bit information extraction method, called HammerLeak,
through adopting the rowhammer based hardware fault technique as the
information leakage vector. HammerLeak leverages several novel system-level
techniques tailed for DNN applications to enable fast and efficient weight
stealing. Secondly, we propose a novel substitute model training algorithm with
Mean Clustering weight penalty, which leverages the partial leaked bit
information effectively and generates a substitute prototype of the target
victim model. We evaluate this substitute model extraction method on three
popular image datasets (e.g., CIFAR-10/100/GTSRB) and four DNN architectures
(e.g., ResNet-18/34/Wide-ResNet/VGG-11). The extracted substitute model has
successfully achieved more than 90 % test accuracy on deep residual networks
for the CIFAR-10 dataset. Moreover, our extracted substitute model could also
generate effective adversarial input samples to fool the victim model.</p>
  </details>
</details>
<details>
  <summary>9. <b>标题：Improved Regularization and Robustness for Fine-tuning in Neural  Networks</b></summary>
  <p><b>编号</b>：[48]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04578</p>
  <p><b>作者</b>：Dongyue Li,  Hongyang R. Zhang</p>
  <p><b>备注</b>：22 pages, 6 figures, 11 tables</p>
  <p><b>关键词</b>：text data sets using multiple pre, target data set includes noisy labels, reweight less confident data points, correct mislabeled data points, approach outperforms baseline methods</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A widely used algorithm for transfer learning is fine-tuning, where a
pre-trained model is fine-tuned on a target task with a small amount of labeled
data. When the capacity of the pre-trained model is much larger than the size
of the target data set, fine-tuning is prone to overfitting and "memorizing"
the training labels. Hence, an important question is to regularize fine-tuning
and ensure its robustness to noise. To address this question, we begin by
analyzing the generalization properties of fine-tuning. We present a PAC-Bayes
generalization bound that depends on the distance traveled in each layer during
fine-tuning and the noise stability of the fine-tuned model. We empirically
measure these quantities. Based on the analysis, we propose regularized
self-labeling -- the interpolation between regularization and self-labeling
methods, including (i) layer-wise regularization to constrain the distance
traveled in each layer; (ii) self label-correction and label-reweighting to
correct mislabeled data points (that the model is confident) and reweight less
confident data points. We validate our approach on an extensive collection of
image and text data sets using multiple pre-trained model architectures. Our
approach improves baseline methods by 1.76% (on average) for seven image
classification tasks and 0.75% for a few-shot classification task. When the
target data set includes noisy labels, our approach outperforms baseline
methods by 3.56% on average in two noisy settings.</p>
  </details>
</details>
<details>
  <summary>10. <b>标题：Tensor-based Subspace Factorization for StyleGAN</b></summary>
  <p><b>编号</b>：[54]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04554</p>
  <p><b>作者</b>：René Haas,  Stella Graßhof,  Sami Sebastian Brandt</p>
  <p><b>备注</b>：Accepted for FG2021</p>
  <p><b>关键词</b>：structured facial expression database, structured facial expression database, expression trajectories meet, two competing approaches, several experiments comparing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we propose $\tau$GAN a tensor-based method for modeling the
latent space of generative models. The objective is to identify semantic
directions in latent space. To this end, we propose to fit a multilinear tensor
model on a structured facial expression database, which is initially embedded
into latent space. We validate our approach on StyleGAN trained on FFHQ using
BU-3DFE as a structured facial expression database. We show how the parameters
of the multilinear tensor model can be approximated by Alternating Least
Squares. Further, we introduce a tacked style-separated tensor model, defined
as an ensemble of style-specific models to integrate our approach with the
extended latent space of StyleGAN. We show that taking the individual styles of
the extended latent space into account leads to higher model flexibility and
lower reconstruction error. Finally, we do several experiments comparing our
approach to former work on both GANs and multilinear models. Concretely, we
analyze the expression subspace and find that the expression trajectories meet
at an apathetic face that is consistent with earlier work. We also show that by
changing the pose of a person, the generated image from our approach is closer
to the ground truth than results from two competing approaches.</p>
  </details>
</details>
<details>
  <summary>11. <b>标题：Self-Supervised Intrinsic Image Decomposition Network Considering  Reflectance Consistency</b></summary>
  <p><b>编号</b>：[65]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04506</p>
  <p><b>作者</b>：Yuma Kinoshita,  Hitoshi Kiya</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：novel intrinsic image decomposition network considering reflectance consistency, intrinsic image decomposition aims, `` shading ,'' respectively, illuminant decomposition model, `` reflectance ''</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose a novel intrinsic image decomposition network considering
reflectance consistency. Intrinsic image decomposition aims to decompose an
image into illumination-invariant and illumination-variant components, referred
to as ``reflectance'' and ``shading,'' respectively. Although there are three
consistencies that the reflectance and shading should satisfy, most
conventional work does not sufficiently account for consistency with respect to
reflectance, owing to the use of a white-illuminant decomposition model and the
lack of training images capturing the same objects under various
illumination-brightness and -color conditions. For this reason, the three
consistencies are considered in the proposed network by using a
color-illuminant model and training the network with losses calculated from
images taken under various illumination conditions. In addition, the proposed
network can be trained in a self-supervised manner because various illumination
conditions can easily be simulated. Experimental results show that our network
can decompose images into reflectance and shading components.</p>
  </details>
</details>
<details>
  <summary>12. <b>标题：3D Siamese Voxel-to-BEV Tracker for Sparse Point Clouds</b></summary>
  <p><b>编号</b>：[102]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04426</p>
  <p><b>作者</b>：Le Hui,  Lingpeng Wang,  Mingmei Cheng,  Jin Xie,  Jian Yang</p>
  <p><b>备注</b>：Accepted by NeurIPS 2021</p>
  <p><b>关键词</b>：first perform template feature embedding, bev target localization network regresses, aware feature learning network, aware feature learning network, voxelized point cloud along</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>3D object tracking in point clouds is still a challenging problem due to the
sparsity of LiDAR points in dynamic environments. In this work, we propose a
Siamese voxel-to-BEV tracker, which can significantly improve the tracking
performance in sparse 3D point clouds. Specifically, it consists of a Siamese
shape-aware feature learning network and a voxel-to-BEV target localization
network. The Siamese shape-aware feature learning network can capture 3D shape
information of the object to learn the discriminative features of the object so
that the potential target from the background in sparse point clouds can be
identified. To this end, we first perform template feature embedding to embed
the template's feature into the potential target and then generate a dense 3D
shape to characterize the shape information of the potential target. For
localizing the tracked target, the voxel-to-BEV target localization network
regresses the target's 2D center and the $z$-axis center from the dense bird's
eye view (BEV) feature map in an anchor-free manner. Concretely, we compress
the voxelized point cloud along $z$-axis through max pooling to obtain a dense
BEV feature map, where the regression of the 2D center and the $z$-axis center
can be performed more effectively. Extensive evaluation on the KITTI and
nuScenes datasets shows that our method significantly outperforms the current
state-of-the-art methods by a large margin.</p>
  </details>
</details>
<details>
  <summary>13. <b>标题：GROWL: Group Detection With Link Prediction</b></summary>
  <p><b>编号</b>：[116]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04397</p>
  <p><b>作者</b>：Viktor Schmuck,  Oya Celiktutan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：significantly improve accuracy across different camera views, shallow binary classification method, art group detection approaches, pairwise affinity matrices, interaction group detection</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Interaction group detection has been previously addressed with bottom-up
approaches which relied on the position and orientation information of
individuals. These approaches were primarily based on pairwise affinity
matrices and were limited to static, third-person views. This problem can
greatly benefit from a holistic approach based on Graph Neural Networks (GNNs)
beyond pairwise relationships, due to the inherent spatial configuration that
exists between individuals who form interaction groups. Our proposed method,
GROup detection With Link prediction (GROWL), demonstrates the effectiveness of
a GNN based approach. GROWL predicts the link between two individuals by
generating a feature embedding based on their neighbourhood in the graph and
determines whether they are connected with a shallow binary classification
method such as Multi-layer Perceptrons (MLPs). We test our method against other
state-of-the-art group detection approaches on both a third-person view dataset
and a robocentric (i.e., egocentric) dataset. In addition, we propose a
multimodal approach based on RGB and depth data to calculate a representation
GROWL can utilise as input. Our results show that a GNN based approach can
significantly improve accuracy across different camera views, i.e.,
third-person and egocentric views.</p>
  </details>
</details>
<details>
  <summary>14. <b>标题：Get a Model! Model Hijacking Attack Against Machine Learning Models</b></summary>
  <p><b>编号</b>：[118]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04394</p>
  <p><b>作者</b>：Ahmed Salem,  Michael Backes,  Yang Zhang</p>
  <p><b>备注</b>：To Appear in NDSS 2022</p>
  <p><b>关键词</b>：computer vision based machine learning models, propose two different model hijacking attacks, various critical applications ranging, existing data poisoning attacks, high attack success rate</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Machine learning (ML) has established itself as a cornerstone for various
critical applications ranging from autonomous driving to authentication
systems. However, with this increasing adoption rate of machine learning
models, multiple attacks have emerged. One class of such attacks is training
time attack, whereby an adversary executes their attack before or during the
machine learning model training. In this work, we propose a new training time
attack against computer vision based machine learning models, namely model
hijacking attack. The adversary aims to hijack a target model to execute a
different task than its original one without the model owner noticing. Model
hijacking can cause accountability and security risks since a hijacked model
owner can be framed for having their model offering illegal or unethical
services. Model hijacking attacks are launched in the same way as existing data
poisoning attacks. However, one requirement of the model hijacking attack is to
be stealthy, i.e., the data samples used to hijack the target model should look
similar to the model's original training dataset. To this end, we propose two
different model hijacking attacks, namely Chameleon and Adverse Chameleon,
based on a novel encoder-decoder style ML model, namely the Camouflager. Our
evaluation shows that both of our model hijacking attacks achieve a high attack
success rate, with a negligible drop in model utility.</p>
  </details>
</details>
<details>
  <summary>15. <b>标题：Geometrically Adaptive Dictionary Attack on Face Recognition</b></summary>
  <p><b>编号</b>：[121]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04371</p>
  <p><b>作者</b>：Junyoung Byun,  Hyojun Go,  Changick Kim</p>
  <p><b>备注</b>：Accepted at WACV 2022</p>
  <p><b>关键词</b>：face recognition named geometrically adaptive dictionary attack, show overwhelming performance improvement, exploit 3d face alignment, brought remarkable performance improvement, effectively recycling previous perturbations</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>CNN-based face recognition models have brought remarkable performance
improvement, but they are vulnerable to adversarial perturbations. Recent
studies have shown that adversaries can fool the models even if they can only
access the models' hard-label output. However, since many queries are needed to
find imperceptible adversarial noise, reducing the number of queries is crucial
for these attacks. In this paper, we point out two limitations of existing
decision-based black-box attacks. We observe that they waste queries for
background noise optimization, and they do not take advantage of adversarial
perturbations generated for other images. We exploit 3D face alignment to
overcome these limitations and propose a general strategy for query-efficient
black-box attacks on face recognition named Geometrically Adaptive Dictionary
Attack (GADA). Our core idea is to create an adversarial perturbation in the UV
texture map and project it onto the face in the image. It greatly improves
query efficiency by limiting the perturbation search space to the facial area
and effectively recycling previous perturbations. We apply the GADA strategy to
two existing attack methods and show overwhelming performance improvement in
the experiments on the LFW and CPLFW datasets. Furthermore, we also present a
novel attack strategy that can circumvent query similarity-based stateful
detection that identifies the process of query-based black-box attacks.</p>
  </details>
</details>
<details>
  <summary>16. <b>标题：Grassmannian learning mutual subspace method for image set recognition</b></summary>
  <p><b>编号</b>：[126]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04352</p>
  <p><b>作者</b>：Lincon S. Souza,  Naoya Sogi,  Bernardo B. Gatto,  Takumi Kobayashi,  Kazuhiro Fukui</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：g ., multiple camera sources, grassmannian learning mutual subspace method, riemannian stochastic gradient descent, cnn )- based frameworks, video frames ).</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper addresses the problem of object recognition given a set of images
as input (e.g., multiple camera sources and video frames). Convolutional neural
network (CNN)-based frameworks do not exploit these sets effectively,
processing a pattern as observed, not capturing the underlying feature
distribution as it does not consider the variance of images in the set. To
address this issue, we propose the Grassmannian learning mutual subspace method
(G-LMSM), a NN layer embedded on top of CNNs as a classifier, that can process
image sets more effectively and can be trained in an end-to-end manner. The
image set is represented by a low-dimensional input subspace; and this input
subspace is matched with reference subspaces by a similarity of their canonical
angles, an interpretable and easy to compute metric. The key idea of G-LMSM is
that the reference subspaces are learned as points on the Grassmann manifold,
optimized with Riemannian stochastic gradient descent. This learning is stable,
efficient and theoretically well-grounded. We demonstrate the effectiveness of
our proposed method on hand shape recognition, face identification, and facial
emotion recognition.</p>
  </details>
</details>
<details>
  <summary>17. <b>标题：Off-policy Imitation Learning from Visual Inputs</b></summary>
  <p><b>编号</b>：[128]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04345</p>
  <p><b>作者</b>：Zhihao Cheng,  Li Shen,  Dacheng Tao</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：provided via extensive experiments using deepmind control suite, various successful applications utilizing expert states, another il setting -- il, utilizing online visual resources, opifvi employs data augmentation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recently, various successful applications utilizing expert states in
imitation learning (IL) have been witnessed. However, another IL setting -- IL
from visual inputs (ILfVI), which has a greater promise to be applied in
reality by utilizing online visual resources, suffers from low data-efficiency
and poor performance resulted from an on-policy learning manner and
high-dimensional visual inputs. We propose OPIfVI (Off-Policy Imitation from
Visual Inputs), which is composed of an off-policy learning manner, data
augmentation, and encoder techniques, to tackle the mentioned challenges,
respectively. More specifically, to improve data-efficiency, OPIfVI conducts IL
in an off-policy manner, with which sampled data can be used multiple times. In
addition, we enhance the stability of OPIfVI with spectral normalization to
mitigate the side-effect of off-policy training. The core factor, contributing
to the poor performance of ILfVI, that we think is the agent could not extract
meaningful features from visual inputs. Hence, OPIfVI employs data augmentation
from computer vision to help train encoders that can better extract features
from visual inputs. In addition, a specific structure of gradient
backpropagation for the encoder is designed to stabilize the encoder training.
At last, we demonstrate that OPIfVI is able to achieve expert-level performance
and outperform existing baselines no matter visual demonstrations or visual
observations are provided via extensive experiments using DeepMind Control
Suite.</p>
  </details>
</details>
<details>
  <summary>18. <b>标题：Partial Attack Supervision and Regional Weighted Inference for Masked  Face Presentation Attack Detection</b></summary>
  <p><b>编号</b>：[131]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04336</p>
  <p><b>作者</b>：Meiling Fang,  Fadi Boutros,  Arjan Kuijper,  Naser Damer</p>
  <p><b>备注</b>：Accepted at the 16th IEEE International Conference on Automatic Face and Gesture Recognition, FG 2021</p>
  <p><b>关键词</b>：wrongly classified bona fide masked faces, proposed method outperforms established pad methods, wrongly classified partial attacks, wise ablation study pointing, masked face presentation detection</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Wearing a mask has proven to be one of the most effective ways to prevent the
transmission of SARS-CoV-2 coronavirus. However, wearing a mask poses
challenges for different face recognition tasks and raises concerns about the
performance of masked face presentation detection (PAD). The main issues facing
the mask face PAD are the wrongly classified bona fide masked faces and the
wrongly classified partial attacks (covered by real masks). This work addresses
these issues by proposing a method that considers partial attack labels to
supervise the PAD model training, as well as regional weighted inference to
further improve the PAD performance by varying the focus on different facial
areas. Our proposed method is not directly linked to specific network
architecture and thus can be directly incorporated into any common or
custom-designed network. In our work, two neural networks (DeepPixBis and
MixFaceNet) are selected as backbones. The experiments are demonstrated on the
collaborative real mask attack (CRMA) database. Our proposed method outperforms
established PAD methods in the CRMA database by reducing the mentioned
shortcomings when facing masked faces. Moreover, we present a detailed
step-wise ablation study pointing out the individual and joint benefits of the
proposed concepts on the overall PAD performance.</p>
  </details>
</details>
<details>
  <summary>19. <b>标题：Enhancing Prototypical Few-Shot Learning by Leveraging the Local-Level  Strategy</b></summary>
  <p><b>编号</b>：[135]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04331</p>
  <p><b>作者</b>：Junying Huang,  Fan Chen,  Keze Wang,  Liang Lin,  Dongyu Zhang</p>
  <p><b>备注</b>：5 pages, 4 figures, submitted to ICASSP 2022</p>
  <p><b>关键词</b>：baseline across different benchmark datasets, existing works often build, synthesize different knowledge transfers, different location features, extensive experiments justify</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Aiming at recognizing the samples from novel categories with few reference
samples, few-shot learning (FSL) is a challenging problem. We found that the
existing works often build their few-shot model based on the image-level
feature by mixing all local-level features, which leads to the discriminative
location bias and information loss in local details. To tackle the problem,
this paper returns the perspective to the local-level feature and proposes a
series of local-level strategies. Specifically, we present (a) a local-agnostic
training strategy to avoid the discriminative location bias between the base
and novel categories, (b) a novel local-level similarity measure to capture the
accurate comparison between local-level features, and (c) a local-level
knowledge transfer that can synthesize different knowledge transfers from the
base category according to different location features. Extensive experiments
justify that our proposed local-level strategies can significantly boost the
performance and achieve 2.8%-7.2% improvements over the baseline across
different benchmark datasets, which also achieves state-of-the-art accuracy.</p>
  </details>
</details>
<details>
  <summary>20. <b>标题：Towards Debiasing Temporal Sentence Grounding in Video</b></summary>
  <p><b>编号</b>：[139]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04321</p>
  <p><b>作者</b>：Hao Zhang,  Aixin Sun,  Wei Jing,  Joey Tianyi Zhou</p>
  <p><b>备注</b>：13 pages, 6 figures, 11 tables</p>
  <p><b>关键词</b>：data debiasing performs data oversampling, video ), many models tend, improving model generalization capability, vslnet achieves best results, balance moment temporal distribution</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The temporal sentence grounding in video (TSGV) task is to locate a temporal
moment from an untrimmed video, to match a language query, i.e., a sentence.
Without considering bias in moment annotations (e.g., start and end positions
in a video), many models tend to capture statistical regularities of the moment
annotations, and do not well learn cross-modal reasoning between video and
language query. In this paper, we propose two debiasing strategies, data
debiasing and model debiasing, to "force" a TSGV model to capture cross-modal
interactions. Data debiasing performs data oversampling through video
truncation to balance moment temporal distribution in train set. Model
debiasing leverages video-only and query-only models to capture the
distribution bias, and forces the model to learn cross-modal interactions.
Using VSLNet as the base model, we evaluate impact of the two strategies on two
datasets that contain out-of-distribution test instances. Results show that
both strategies are effective in improving model generalization capability.
Equipped with both debiasing strategies, VSLNet achieves best results on both
datasets.</p>
  </details>
</details>
<details>
  <summary>21. <b>标题：Auto-Encoding Knowledge Graph for Unsupervised Medical Report Generation</b></summary>
  <p><b>编号</b>：[140]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04318</p>
  <p><b>作者</b>：Fenglin Liu,  Chenyu You,  Xian Wu,  Shen Ge,  Sheng Wang,  Xu Sun</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：unsupervised kgae generates desirable medical reports without using, unsupervised model knowledge graph auto, driven encoder projects medical images, receiving growing research interests, existing approaches mainly adopt</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Medical report generation, which aims to automatically generate a long and
coherent report of a given medical image, has been receiving growing research
interests. Existing approaches mainly adopt a supervised manner and heavily
rely on coupled image-report pairs. However, in the medical domain, building a
large-scale image-report paired dataset is both time-consuming and expensive.
To relax the dependency on paired data, we propose an unsupervised model
Knowledge Graph Auto-Encoder (KGAE) which accepts independent sets of images
and reports in training. KGAE consists of a pre-constructed knowledge graph, a
knowledge-driven encoder and a knowledge-driven decoder. The knowledge graph
works as the shared latent space to bridge the visual and textual domains; The
knowledge-driven encoder projects medical images and reports to the
corresponding coordinates in this latent space and the knowledge-driven decoder
generates a medical report given a coordinate in this space. Since the
knowledge-driven encoder and decoder can be trained with independent sets of
images and reports, KGAE is unsupervised. The experiments show that the
unsupervised KGAE generates desirable medical reports without using any
image-report training pairs. Moreover, KGAE can also work in both
semi-supervised and supervised settings, and accept paired images and reports
in training. By further fine-tuning with image-report pairs, KGAE consistently
outperforms the current state-of-the-art models on two datasets.</p>
  </details>
</details>
<details>
  <summary>22. <b>标题：SEGA: Semantic Guided Attention on Visual Prototype for Few-Shot  Learning</b></summary>
  <p><b>编号</b>：[142]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04316</p>
  <p><b>作者</b>：Fengyuan Yang,  Ruiping Wang,  Xilin Chen</p>
  <p><b>备注</b>：11 pages, 7 figures, 4 tables. Accepted by WACV2022</p>
  <p><b>关键词</b>：semantic guided attention realizes anticipated function, learn new classes quickly even given, one remains challenging owing, transferring visual prior knowledge, semantic guided attention</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Teaching machines to recognize a new category based on few training samples
especially only one remains challenging owing to the incomprehensive
understanding of the novel category caused by the lack of data. However, human
can learn new classes quickly even given few samples since human can tell what
discriminative features should be focused on about each category based on both
the visual and semantic prior knowledge. To better utilize those prior
knowledge, we propose the SEmantic Guided Attention (SEGA) mechanism where the
semantic knowledge is used to guide the visual perception in a top-down manner
about what visual features should be paid attention to when distinguishing a
category from the others. As a result, the embedding of the novel class even
with few samples can be more discriminative. Concretely, a feature extractor is
trained to embed few images of each novel class into a visual prototype with
the help of transferring visual prior knowledge from base classes. Then we
learn a network that maps semantic knowledge to category-specific attention
vectors which will be used to perform feature selection to enhance the visual
prototypes. Extensive experiments on miniImageNet, tieredImageNet, CIFAR-FS,
and CUB indicate that our semantic guided attention realizes anticipated
function and outperforms state-of-the-art results.</p>
  </details>
</details>
<details>
  <summary>23. <b>标题：A Relational Model for One-Shot Classification</b></summary>
  <p><b>编号</b>：[145]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04313</p>
  <p><b>作者</b>：Arturs Polis,  Alexander Ilin</p>
  <p><b>备注</b>：Published at ESANN 2021</p>
  <p><b>关键词</b>：shot classification model performs relational matching, shot image classification omniglot challenge, model exceeds human level accuracy, relational inductive bias, deep learning model</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We show that a deep learning model with built-in relational inductive bias
can bring benefits to sample-efficient learning, without relying on extensive
data augmentation. The proposed one-shot classification model performs
relational matching of a pair of inputs in the form of local and pairwise
attention. Our approach solves perfectly the one-shot image classification
Omniglot challenge. Our model exceeds human level accuracy, as well as the
previous state of the art, with no data augmentation.</p>
  </details>
</details>
<details>
  <summary>24. <b>标题：Residual-Guided Learning Representation for Self-Supervised Monocular  Depth Estimation</b></summary>
  <p><b>编号</b>：[146]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04310</p>
  <p><b>作者</b>：Byeongjun Park,  Taekyung Kim,  Hyojun Go,  Changick Kim</p>
  <p><b>备注</b>：5 pages, 2 figures</p>
  <p><b>关键词</b>：loss often causes unstable depth predictions, representative objective functions commonly used, utilizing feature representations explicitly learned, supervised learning approaches tackle, supervised monocular depth estimation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Photometric consistency loss is one of the representative objective functions
commonly used for self-supervised monocular depth estimation. However, this
loss often causes unstable depth predictions in textureless or occluded regions
due to incorrect guidance. Recent self-supervised learning approaches tackle
this issue by utilizing feature representations explicitly learned from
auto-encoders, expecting better discriminability than the input image. Despite
the use of auto-encoded features, we observe that the method does not embed
features as discriminative as auto-encoded features. In this paper, we propose
residual guidance loss that enables the depth estimation network to embed the
discriminative feature by transferring the discriminability of auto-encoded
features. We conducted experiments on the KITTI benchmark and verified our
method's superiority and orthogonality on other state-of-the-art methods.</p>
  </details>
</details>
<details>
  <summary>25. <b>标题：Deep Marching Tetrahedra: a Hybrid Representation for High-Resolution 3D  Shape Synthesis</b></summary>
  <p><b>编号</b>：[159]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04276</p>
  <p><b>作者</b>：Tianchang Shen,  Jun Gao,  Kangxue Yin,  Ming-Yu Liu,  Sanja Fidler</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：resolution 3d shapes using simple user guides, approach significantly outperforms existing work, unlike deep 3d generative models, deep 3d conditional generative model, complex 3d animal shapes</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We introduce DMTet, a deep 3D conditional generative model that can
synthesize high-resolution 3D shapes using simple user guides such as coarse
voxels. It marries the merits of implicit and explicit 3D representations by
leveraging a novel hybrid 3D representation. Compared to the current implicit
approaches, which are trained to regress the signed distance values, DMTet
directly optimizes for the reconstructed surface, which enables us to
synthesize finer geometric details with fewer artifacts. Unlike deep 3D
generative models that directly generate explicit representations such as
meshes, our model can synthesize shapes with arbitrary topology. The core of
DMTet includes a deformable tetrahedral grid that encodes a discretized signed
distance function and a differentiable marching tetrahedra layer that converts
the implicit signed distance representation to the explicit surface mesh
representation. This combination allows joint optimization of the surface
geometry and topology as well as generation of the hierarchy of subdivisions
using reconstruction and adversarial losses defined explicitly on the surface
mesh. Our approach significantly outperforms existing work on conditional shape
synthesis from coarse voxel inputs, trained on a dataset of complex 3D animal
shapes. Project page: this https URL.</p>
  </details>
</details>
<details>
  <summary>26. <b>标题：Generative Dynamic Patch Attack</b></summary>
  <p><b>编号</b>：[163]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04266</p>
  <p><b>作者</b>：Xiang Li,  Shihao Ji</p>
  <p><b>备注</b>：Published as a conference paper at BMVC 2021</p>
  <p><b>关键词</b>：existing patch attacks mostly consider injecting adversarial patches, existing patch attacks cannot effectively defend, gdpa achieves higher attack success rates, deep neural network model, gdpa demonstrates superior robustness</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Adversarial patch attack is a family of attack algorithms that perturb a part
of image to fool a deep neural network model. Existing patch attacks mostly
consider injecting adversarial patches at input-agnostic locations: either a
predefined location or a random location. This attack setup may be sufficient
for attack but has considerable limitations when using it for adversarial
training. Thus, robust models trained with existing patch attacks cannot
effectively defend other adversarial attacks. In this paper, we first propose
an end-to-end patch attack algorithm, Generative Dynamic Patch Attack (GDPA),
which generates both patch pattern and patch location adversarially for each
input image. We show that GDPA is a generic attack framework that can produce
dynamic/static and visible/invisible patches with a few configuration changes.
Secondly, GDPA can be readily integrated for adversarial training to improve
model robustness to various adversarial attacks. Extensive experiments on
VGGFace, Traffic Sign and ImageNet show that GDPA achieves higher attack
success rates than state-of-the-art patch attacks, while adversarially trained
model with GDPA demonstrates superior robustness to adversarial patch attacks
than competing methods. Our source code can be found at
this https URL.</p>
  </details>
</details>
<details>
  <summary>27. <b>标题：Adaptive area-preserving parameterization of open and closed anatomical  surfaces</b></summary>
  <p><b>编号</b>：[164]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04265</p>
  <p><b>作者</b>：Gary P. T. Choi,  Amita Giri,  Lalan Kumar</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：adaptive parameter domain allows easy handling, also exhibiting low conformal distortion, entire unit sphere may induce, like basis functions defined, optimal spherical cap region</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The parameterization of open and closed anatomical surfaces is of fundamental
importance in many biomedical applications. Spherical harmonics, a set of basis
functions defined on the unit sphere, are widely used for anatomical shape
description. However, establishing a one-to-one correspondence between the
object surface and the entire unit sphere may induce a large geometric
distortion in case the shape of the surface is too different from a perfect
sphere. In this work, we propose adaptive area-preserving parameterization
methods for simply-connected open and closed surfaces with the target of the
parameterization being a spherical cap. Our methods optimize the shape of the
parameter domain along with the mapping from the object surface to the
parameter domain. The object surface will be globally mapped to an optimal
spherical cap region of the unit sphere in an area-preserving manner while also
exhibiting low conformal distortion. We further develop a set of spherical
harmonics-like basis functions defined over the adaptive spherical cap domain,
which we call the adaptive harmonics. Experimental results show that the
proposed parameterization methods outperform the existing methods for both open
and closed anatomical surfaces in terms of area and angle distortion. Surface
description of the object surfaces can be effectively achieved using a novel
combination of the adaptive parameterization and the adaptive harmonics. Our
work provides a novel way of mapping anatomical surfaces with improved accuracy
and greater flexibility. More broadly, the idea of using an adaptive parameter
domain allows easy handling of a wide range of biomedical shapes.</p>
  </details>
</details>
<details>
  <summary>28. <b>标题：Cross-Modal Object Tracking: Modality-Aware Representations and A  Unified Benchmark</b></summary>
  <p><b>编号</b>：[165]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04264</p>
  <p><b>作者</b>：Chenglong Li,  Tianhao Zhu,  Lei Liu,  Xiaonan Si Zilin Fan,  Sulan Zhai</p>
  <p><b>备注</b>：In Submission</p>
  <p><b>关键词</b>：modal imaging platforms usually require elaborate designs, thus bring big challenges, visual tracking often bases, modal object tracking problem, two representative tracking frameworks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In many visual systems, visual tracking often bases on RGB image sequences,
in which some targets are invalid in low-light conditions, and tracking
performance is thus affected significantly. Introducing other modalities such
as depth and infrared data is an effective way to handle imaging limitations of
individual sources, but multi-modal imaging platforms usually require elaborate
designs and cannot be applied in many real-world applications at present.
Near-infrared (NIR) imaging becomes an essential part of many surveillance
cameras, whose imaging is switchable between RGB and NIR based on the light
intensity. These two modalities are heterogeneous with very different visual
properties and thus bring big challenges for visual tracking. However, existing
works have not studied this challenging problem. In this work, we address the
cross-modal object tracking problem and contribute a new video dataset,
including 654 cross-modal image sequences with over 481K frames in total, and
the average video length is more than 735 frames. To promote the research and
development of cross-modal object tracking, we propose a new algorithm, which
learns the modality-aware target representation to mitigate the appearance gap
between RGB and NIR modalities in the tracking process. It is plug-and-play and
could thus be flexibly embedded into different tracking frameworks. Extensive
experiments on the dataset are conducted, and we demonstrate the effectiveness
of the proposed algorithm in two representative tracking frameworks against 17
state-of-the-art tracking methods. We will release the dataset for free
academic usage, dataset download link and code will be released soon.</p>
  </details>
</details>
<details>
  <summary>29. <b>标题：Template NeRF: Towards Modeling Dense Shape Correspondences from  Category-Specific Object Images</b></summary>
  <p><b>编号</b>：[176]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04237</p>
  <p><b>作者</b>：Jianfei Guo,  Zhiyuan Yang,  Xi Lin,  Qingfu Zhang</p>
  <p><b>备注</b>：10 pages, 8 figures</p>
  <p><b>关键词</b>：generating dense shape correspondences simultaneously among objects, previously require specific model designs, achieve dense shape correspondences reasoning, aware image synthesis pipeline nerf, present neural radiance fields</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present neural radiance fields (NeRF) with templates, dubbed
Template-NeRF, for modeling appearance and geometry and generating dense shape
correspondences simultaneously among objects of the same category from only
multi-view posed images, without the need of either 3D supervision or
ground-truth correspondence knowledge. The learned dense correspondences can be
readily used for various image-based tasks such as keypoint detection, part
segmentation, and texture transfer that previously require specific model
designs. Our method can also accommodate annotation transfer in a one or
few-shot manner, given only one or a few instances of the category. Using
periodic activation and feature-wise linear modulation (FiLM) conditioning, we
introduce deep implicit templates on 3D data into the 3D-aware image synthesis
pipeline NeRF. By representing object instances within the same category as
shape and appearance variation of a shared NeRF template, our proposed method
can achieve dense shape correspondences reasoning on images for a wide range of
object classes. We demonstrate the results and applications on both synthetic
and real-world data with competitive results compared with other methods based
on 3D information.</p>
  </details>
</details>
<details>
  <summary>30. <b>标题：A Study of the Human Perception of Synthetic Faces</b></summary>
  <p><b>编号</b>：[177]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04230</p>
  <p><b>作者</b>：Bingyu Shen,  Brandon RichardWebster,  Alice O'Toole,  Kevin Bowyer,  Walter J. Scheirer</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：synthetic faces generated using different strategies including, synthetic face generation techniques grounded, based techniques confuse human observers, scale crowdsourced behavioral experiments, distinguish synthetic faces</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Advances in face synthesis have raised alarms about the deceptive use of
synthetic faces. Can synthetic identities be effectively used to fool human
observers? In this paper, we introduce a study of the human perception of
synthetic faces generated using different strategies including a
state-of-the-art deep learning-based GAN model. This is the first rigorous
study of the effectiveness of synthetic face generation techniques grounded in
experimental techniques from psychology. We answer important questions such as
how often do GAN-based and more traditional image processing-based techniques
confuse human observers, and are there subtle cues within a synthetic face
image that cause humans to perceive it as a fake without having to search for
obvious clues? To answer these questions, we conducted a series of large-scale
crowdsourced behavioral experiments with different sources of face imagery.
Results show that humans are unable to distinguish synthetic faces from real
faces under several different circumstances. This finding has serious
implications for many different applications where face images are presented to
human users.</p>
  </details>
</details>
<details>
  <summary>31. <b>标题：Practical, Fast and Robust Point Cloud Registration for 3D Scene  Stitching and Object Localization</b></summary>
  <p><b>编号</b>：[178]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04228</p>
  <p><b>作者</b>：Lei Sun</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：since existing robust solvers may encounter high computational cost, 3d point cloud registration ranks among, efficient consensus maximization paradigm based, point cloud registration problem, 3d feature matching techniques</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>3D point cloud registration ranks among the most fundamental problems in
remote sensing, photogrammetry, robotics and geometric computer vision. Due to
the limited accuracy of 3D feature matching techniques, outliers may exist,
sometimes even in very large numbers, among the correspondences. Since existing
robust solvers may encounter high computational cost or restricted robustness,
we propose a novel, fast and highly robust solution, named VOCRA (VOting with
Cost function and Rotating Averaging), for the point cloud registration problem
with extreme outlier rates. Our first contribution is to employ the Tukey's
Biweight robust cost to introduce a new voting and correspondence sorting
technique, which proves to be rather effective in distinguishing true inliers
from outliers even with extreme (99%) outlier rates. Our second contribution
consists in designing a time-efficient consensus maximization paradigm based on
robust rotation averaging, serving to seek inlier candidates among the
correspondences. Finally, we apply Graduated Non-Convexity with Tukey's
Biweight (GNC-TB) to estimate the correct transformation with the inlier
candidates obtained, which is then used to find the complete inlier set. Both
standard benchmarking and realistic experiments with application to two
real-data problems are conducted, and we show that our solver VOCRA is robust
against over 99% outliers and more time-efficient than the state-of-the-art
competitors.</p>
  </details>
</details>
<details>
  <summary>32. <b>标题：Rethinking Deconvolution for 2D Human Pose Estimation Light yet Accurate  Model for Real-time Edge Computing</b></summary>
  <p><b>编号</b>：[179]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04226</p>
  <p><b>作者</b>：Masayuki Yamazaki,  Eigo Mori</p>
  <p><b>备注</b>：IEEE International Conference on Automatic Face and Gesture Recognition 2021</p>
  <p><b>关键词</b>：reducing computational resource consumption without degrading, also incorporated recent model agnostic techniques, pragmatic lightweight pose estimation model, time predictions using low, sota hrnet 256x192 using</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this study, we present a pragmatic lightweight pose estimation model. Our
model can achieve real-time predictions using low-power embedded devices. This
system was found to be very accurate and achieved a 94.5% accuracy of SOTA
HRNet 256x192 using a computational cost of only 3.8% on COCO test dataset. Our
model adopts an encoder-decoder architecture and is carefully downsized to
improve its efficiency. We especially focused on optimizing the deconvolution
layers and observed that the channel reduction of the deconvolution layers
contributes significantly to reducing computational resource consumption
without degrading the accuracy of this system. We also incorporated recent
model agnostic techniques such as DarkPose and distillation training to
maximize the efficiency of our model. Furthermore, we applied model
quantization to exploit multi/mixed precision features. Our FP16'ed model (COCO
AP 70.0) operates at ~60-fps on NVIDIA Jetson AGX Xavier and ~200 fps on NVIDIA
Quadro RTX6000.</p>
  </details>
</details>
<details>
  <summary>33. <b>标题：Natural Adversarial Objects</b></summary>
  <p><b>编号</b>：[186]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04204</p>
  <p><b>作者</b>：Felix Lau,  Nishant Subramani,  Sasha Harrison,  Aerin Kim,  Elliot Branson,  Rosanne Liu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：shuffling image patches reveal, standard mscoco validation set, art object detection methods, mscoco validation set, object detection architectures</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Although state-of-the-art object detection methods have shown compelling
performance, models often are not robust to adversarial attacks and
out-of-distribution data. We introduce a new dataset, Natural Adversarial
Objects (NAO), to evaluate the robustness of object detection models. NAO
contains 7,934 images and 9,943 objects that are unmodified and representative
of real-world scenarios, but cause state-of-the-art detection models to
misclassify with high confidence. The mean average precision (mAP) of
EfficientDet-D7 drops 74.5% when evaluated on NAO compared to the standard
MSCOCO validation set.
Moreover, by comparing a variety of object detection architectures, we find
that better performance on MSCOCO validation set does not necessarily translate
to better performance on NAO, suggesting that robustness cannot be simply
achieved by training a more accurate model.
We further investigate why examples in NAO are difficult to detect and
classify. Experiments of shuffling image patches reveal that models are overly
sensitive to local texture. Additionally, using integrated gradients and
background replacement, we find that the detection model is reliant on pixel
information within the bounding box, and insensitive to the background context
when predicting class labels. NAO can be downloaded at
this https URL.</p>
  </details>
</details>
<details>
  <summary>34. <b>标题：Look at the Variance! Efficient Black-box Explanations with Sobol-based  Sensitivity Analysis</b></summary>
  <p><b>编号</b>：[206]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04138</p>
  <p><b>作者</b>：Thomas Fel,  Remi Cadene,  Mathieu Chalvidal,  Matthieu Cord,  David Vigouroux,  Thomas Serre</p>
  <p><b>备注</b>：NeurIPS2021</p>
  <p><b>关键词</b>：box methods -- even surpassing, using perturbation masks coupled, proposed method leads, novel attribution method, computing time compared</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We describe a novel attribution method which is grounded in Sensitivity
Analysis and uses Sobol indices. Beyond modeling the individual contributions
of image regions, Sobol indices provide an efficient way to capture
higher-order interactions between image regions and their contributions to a
neural network's prediction through the lens of variance. We describe an
approach that makes the computation of these indices efficient for
high-dimensional problems by using perturbation masks coupled with efficient
estimators to handle the high dimensionality of images. Importantly, we show
that the proposed method leads to favorable scores on standard benchmarks for
vision (and language models) while drastically reducing the computing time
compared to other black-box methods -- even surpassing the accuracy of
state-of-the-art white-box methods which require access to internal
representations. Our code is freely available:
this https URL</p>
  </details>
</details>
<details>
  <summary>35. <b>标题：Global-Local Attention for Emotion Recognition</b></summary>
  <p><b>编号</b>：[211]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04129</p>
  <p><b>作者</b>：Nhat Le,  Khanh Nguyen,  Anh Nguyen,  Bac Le</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：many recent works mainly focus, effectively recognize human emotions using, infer human emotions, recent emotion datasets, infer human affection</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Human emotion recognition is an active research area in artificial
intelligence and has made substantial progress over the past few years. Many
recent works mainly focus on facial regions to infer human affection, while the
surrounding context information is not effectively utilized. In this paper, we
proposed a new deep network to effectively recognize human emotions using a
novel global-local attention mechanism. Our network is designed to extract
features from both facial and context regions independently, then learn them
together using the attention module. In this way, both the facial and
contextual information is used to infer human emotions, therefore enhancing the
discrimination of the classifier. The intensive experiments show that our
method surpasses the current state-of-the-art methods on recent emotion
datasets by a fair margin. Qualitatively, our global-local attention module can
extract more meaningful attention maps than previous methods. The source code
and trained model of our network are available at
this https URL</p>
  </details>
</details>
<details>
  <summary>36. <b>标题：NeurInt : Learning to Interpolate through Neural ODEs</b></summary>
  <p><b>编号</b>：[212]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04123</p>
  <p><b>作者</b>：Avinandan Bose,  Aniket Das,  Yatin Dandi,  Piyush Rai</p>
  <p><b>备注</b>：Accepted (Spotlight paper) at the NeurIPS 2021 Workshop on the Symbiosis of Deep Learning and Differential Equations (DLDE)</p>
  <p><b>关键词</b>：applications require learning image generation models whose latent space effectively captures, two given images using latent second, order neural ordinary differential equations, latent space ),, interpolation trajectories lacking smoothness</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A wide range of applications require learning image generation models whose
latent space effectively captures the high-level factors of variation present
in the data distribution. The extent to which a model represents such
variations through its latent space can be judged by its ability to interpolate
between images smoothly. However, most generative models mapping a fixed prior
to the generated images lead to interpolation trajectories lacking smoothness
and containing images of reduced quality. In this work, we propose a novel
generative model that learns a flexible non-parametric prior over interpolation
trajectories, conditioned on a pair of source and target images. Instead of
relying on deterministic interpolation methods (such as linear or spherical
interpolation in latent space), we devise a framework that learns a
distribution of trajectories between two given images using Latent Second-Order
Neural Ordinary Differential Equations. Through a hybrid combination of
reconstruction and adversarial losses, the generator is trained to map the
sampled points from these trajectories to sequences of realistic images that
smoothly transition from the source to the target image. Through comprehensive
qualitative and quantitative experiments, we demonstrate our approach's
effectiveness in generating images of improved quality as well as its ability
to learn a diverse distribution over smooth interpolation trajectories for any
pair of real source and target images.</p>
  </details>
</details>
<details>
  <summary>37. <b>标题：Hierarchical Segment-based Optimization for SLAM</b></summary>
  <p><b>编号</b>：[220]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04101</p>
  <p><b>作者</b>：Yuxin Tian,  Yujie Wang,  Ming Ouyang,  Xuesong Shi</p>
  <p><b>备注</b>：IROS 2021</p>
  <p><b>关键词</b>：reliable trajectory segmentation method, method greatly improves, use global information, outperforms existing high, based optimization method</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper presents a hierarchical segment-based optimization method for
Simultaneous Localization and Mapping (SLAM) system. First we propose a
reliable trajectory segmentation method that can be used to increase efficiency
in the back-end optimization. Then we propose a buffer mechanism for the first
time to improve the robustness of the segmentation. During the optimization, we
use global information to optimize the frames with large error, and
interpolation instead of optimization to update well-estimated frames to
hierarchically allocate the amount of computation according to error of each
frame. Comparative experiments on the benchmark show that our method greatly
improves the efficiency of optimization with almost no drop in accuracy, and
outperforms existing high-efficiency optimization method by a large margin.</p>
  </details>
</details>
<details>
  <summary>38. <b>标题：Online Adaptation of Monocular Depth Prediction with Visual SLAM</b></summary>
  <p><b>编号</b>：[222]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04096</p>
  <p><b>作者</b>：Shing Yan Loo,  Moein Shakeri,  Sai Hong Tang,  Syamsiah Mashohor,  Hong Zhang</p>
  <p><b>备注</b>：9 pages, 8 figures</p>
  <p><b>关键词</b>：perform global photometric bundle adjustment, online adapted depth prediction cnn outperforms, novel online adaptation framework consisting, potential noisy map points, practical visual slam applications</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The ability of accurate depth prediction by a CNN is a major challenge for
its wide use in practical visual SLAM applications, such as enhanced camera
tracking and dense mapping. This paper is set out to answer the following
question: Can we tune a depth prediction CNN with the help of a visual SLAM
algorithm even if the CNN is not trained for the current operating environment
in order to benefit the SLAM performance? To this end, we propose a novel
online adaptation framework consisting of two complementary processes: a SLAM
algorithm that is used to generate keyframes to fine-tune the depth prediction
and another algorithm that uses the online adapted depth to improve map
quality. Once the potential noisy map points are removed, we perform global
photometric bundle adjustment (BA) to improve the overall SLAM performance.
Experimental results on both benchmark datasets and a real robot in our own
experimental environments show that our proposed method improves the SLAM
reconstruction accuracy. We demonstrate the use of regularization in the
training loss as an effective means to prevent catastrophic forgetting. In
addition, we compare our online adaptation framework against the
state-of-the-art pre-trained depth prediction CNNs to show that our online
adapted depth prediction CNN outperforms the depth prediction CNNs that have
been trained on a large collection of datasets.</p>
  </details>
</details>
<details>
  <summary>39. <b>标题：Cross-modal Zero-shot Hashing by Label Attributes Embedding</b></summary>
  <p><b>编号</b>：[231]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04080</p>
  <p><b>作者</b>：Runmin Wang,  Guoxian Yu,  Lei Liu,  Lizhen Cui,  Carlotta Domeniconi,  Xiangliang Zhang</p>
  <p><b>备注</b>：7 pages, 2 figures</p>
  <p><b>关键词</b>：modal approximate nearest neighbor search, unseen ones using label attributes, laeh outperforms related representative zero, cmh solutions ideally assume, initial semantic attribute vectors</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Cross-modal hashing (CMH) is one of the most promising methods in cross-modal
approximate nearest neighbor search. Most CMH solutions ideally assume the
labels of training and testing set are identical. However, the assumption is
often violated, causing a zero-shot CMH problem. Recent efforts to address this
issue focus on transferring knowledge from the seen classes to the unseen ones
using label attributes. However, the attributes are isolated from the features
of multi-modal data. To reduce the information gap, we introduce an approach
called LAEH (Label Attributes Embedding for zero-shot cross-modal Hashing).
LAEH first gets the initial semantic attribute vectors of labels by word2vec
model and then uses a transformation network to transform them into a common
subspace. Next, it leverages the hash vectors and the feature similarity matrix
to guide the feature extraction network of different modalities. At the same
time, LAEH uses the attribute similarity as the supplement of label similarity
to rectify the label embedding and common subspace. Experiments show that LAEH
outperforms related representative zero-shot and cross-modal hashing methods.</p>
  </details>
</details>
<details>
  <summary>40. <b>标题：Direct Multi-view Multi-person 3D Pose Estimation</b></summary>
  <p><b>编号</b>：[234]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04076</p>
  <p><b>作者</b>：Tao Wang,  Jianfeng Zhang,  Yujun Cai,  Shuicheng Yan,  Jiashi Feng</p>
  <p><b>备注</b>：NeurIPS-2021</p>
  <p><b>关键词</b>：novel geometrically guided attention mechanism, recovering human mesh represented, multiple detected 2d poses, concisely represent query embeddings, dependent query adaptation approach</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present Multi-view Pose transformer (MvP) for estimating multi-person 3D
poses from multi-view images. Instead of estimating 3D joint locations from
costly volumetric representation or reconstructing the per-person 3D pose from
multiple detected 2D poses as in previous methods, MvP directly regresses the
multi-person 3D poses in a clean and efficient way, without relying on
intermediate tasks. Specifically, MvP represents skeleton joints as learnable
query embeddings and let them progressively attend to and reason over the
multi-view information from the input images to directly regress the actual 3D
joint locations. To improve the accuracy of such a simple pipeline, MvP
presents a hierarchical scheme to concisely represent query embeddings of
multi-person skeleton joints and introduces an input-dependent query adaptation
approach. Further, MvP designs a novel geometrically guided attention
mechanism, called projective attention, to more precisely fuse the cross-view
information for each joint. MvP also introduces a RayConv operation to
integrate the view-dependent camera geometry into the feature representations
for augmenting the projective attention. We show experimentally that our MvP
model outperforms the state-of-the-art methods on several benchmarks while
being much more efficient. Notably, it achieves 92.3% AP25 on the challenging
Panoptic dataset, improving upon the previous best approach [36] by 9.8%. MvP
is general and also extendable to recovering human mesh represented by the SMPL
model, thus useful for modeling multi-person body shapes. Code and models are
available at this https URL.</p>
  </details>
</details>
<details>
  <summary>41. <b>标题：Can viewer proximity be a behavioural marker for Autism Spectrum  Disorder?</b></summary>
  <p><b>编号</b>：[241]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04064</p>
  <p><b>作者</b>：Rahul Bishain,  Sharat Chandran</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：analyse videos generated using one, process requires trained clinicians, complicated process often involving, questionnaire based tests, children aged 2</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Screening for any of the Autism Spectrum Disorders is a complicated process
often involving a hybrid of behavioural observations and questionnaire based
tests. Typically carried out in a controlled setting, this process requires
trained clinicians or psychiatrists for such assessments. Riding on the wave of
technical advancement in mobile platforms, several attempts have been made at
incorporating such assessments on mobile and tablet devices.
In this paper we analyse videos generated using one such screening test. This
paper reports the first use of the efficacy of using the observer's distance
from the display screen while administering a sensory sensitivity test as a
behavioural marker for autism for children aged 2-7 years The potential for
using a test such as this in casual home settings is promising.</p>
  </details>
</details>
<details>
  <summary>42. <b>标题：Are we ready for a new paradigm shift? A Survey on Visual Deep MLP</b></summary>
  <p><b>编号</b>：[242]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04060</p>
  <p><b>作者</b>：Ruiyang Liu,  Yinghui Li,  Dun Liang,  Linmi Tao,  Shimin Hu,  Hai-Tao Zheng</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：artificial visual guidance remains important, encourage better visual tailored design, computational densities remain unresolved, gradually evolving towards cnn, new computer vision paradigm</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Multilayer perceptron (MLP), as the first neural network structure to appear,
was a big hit. But constrained by the hardware computing power and the size of
the datasets, it once sank for tens of years. During this period, we have
witnessed a paradigm shift from manual feature extraction to the CNN with local
receptive fields, and further to the Transform with global receptive fields
based on self-attention mechanism. And this year (2021), with the introduction
of MLP-Mixer, MLP has re-entered the limelight and has attracted extensive
research from the computer vision community. Compare to the conventional MLP,
it gets deeper but changes the input from full flattening to patch flattening.
Given its high performance and less need for vision-specific inductive bias,
the community can't help but wonder, Will MLP, the simplest structure with
global receptive fields but no attention, become a new computer vision
paradigm? To answer this question, this survey aims to provide a comprehensive
overview of the recent development of vision deep MLP models. Specifically, we
review these vision deep MLPs detailedly, from the subtle sub-module design to
the global network structure. We compare the receptive field, computational
complexity, and other properties of different network designs in order to have
a clear understanding of the development path of MLPs. The investigation shows
that MLPs' resolution-sensitivity and computational densities remain
unresolved, and pure MLPs are gradually evolving towards CNN-like. We suggest
that the current data volume and computational power are not ready to embrace
pure MLPs, and artificial visual guidance remains important. Finally, we
provide an analysis of open research directions and possible future works. We
hope this effort will ignite further interest in the community and encourage
better visual tailored design for the neural network at the moment.</p>
  </details>
</details>
<details>
  <summary>43. <b>标题：Registration Techniques for Deformable Objects</b></summary>
  <p><b>编号</b>：[244]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04053</p>
  <p><b>作者</b>：Alireza Ahmadi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：consequent scans undergo small deformations, explicit feature point correspondences, matching two different scans, two different points, since new parts</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In general, the problem of non-rigid registration is about matching two
different scans of a dynamic object taken at two different points in time.
These scans can undergo both rigid motions and non-rigid deformations. Since
new parts of the model may come into view and other parts get occluded in
between two scans, the region of overlap is a subset of both scans. In the most
general setting, no prior template shape is given and no markers or explicit
feature point correspondences are available. So, this case is a partial
matching problem that takes into account the assumption that consequent scans
undergo small deformations while having a significant amount of overlapping
area [28]. The problem which this thesis is addressing is mapping deforming
objects and localizing cameras in the environment at the same time.</p>
  </details>
</details>
<details>
  <summary>44. <b>标题：Information Extraction from Visually Rich Documents with Font Style  Embeddings</b></summary>
  <p><b>编号</b>：[248]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04045</p>
  <p><b>作者</b>：Ismail Oussaid,  William Vanhuffel,  Pirashanth Ratnamogan,  Mhamed Hajaiej,  Alexis Mathey,  Thomas Gilles</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：using token style attributes based embedding instead, e native pdf documents )., world complex datasets demonstrate, approaches combining computer vision, raw visual embedding</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Information extraction (IE) from documents is an intensive area of research
with a large set of industrial applications. Current state-of-the-art methods
focus on scanned documents with approaches combining computer vision, natural
language processing and layout representation. We propose to challenge the
usage of computer vision in the case where both token style and visual
representation are available (i.e native PDF documents). Our experiments on
three real-world complex datasets demonstrate that using token style attributes
based embedding instead of a raw visual embedding in LayoutLM model is
beneficial. Depending on the dataset, such an embedding yields an improvement
of 0.18% to 2.29% in the weighted F1-score with a decrease of 30.7% in the
final number of trainable parameters of the model, leading to an improvement in
both efficiency and effectiveness.</p>
  </details>
</details>
<details>
  <summary>45. <b>标题：Style Transfer with Target Feature Palette and Attention Coloring</b></summary>
  <p><b>编号</b>：[253]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04028</p>
  <p><b>作者</b>：Suhyeon Ha,  Guisik Kim,  Junseok Kwon</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：proposed method via exhaustive ablation study, following ac module calculates attention maps, conventional approaches easily lose image details, fpc module captures representative features based, stylized images exhibit state</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Style transfer has attracted a lot of attentions, as it can change a given
image into one with splendid artistic styles while preserving the image
structure. However, conventional approaches easily lose image details and tend
to produce unpleasant artifacts during style transfer. In this paper, to solve
these problems, a novel artistic stylization method with target feature
palettes is proposed, which can transfer key features accurately. Specifically,
our method contains two modules, namely feature palette composition (FPC) and
attention coloring (AC) modules. The FPC module captures representative
features based on K-means clustering and produces a feature target palette. The
following AC module calculates attention maps between content and style images,
and transfers colors and patterns based on the attention map and the target
palette. These modules enable the proposed stylization to focus on key features
and generate plausibly transferred images. Thus, the contributions of the
proposed method are to propose a novel deep learning-based style transfer
method and present target feature palette and attention coloring modules, and
provide in-depth analysis and insight on the proposed method via exhaustive
ablation study. Qualitative and quantitative results show that our stylized
images exhibit state-of-the-art performance, with strength in preserving core
structures and details of the content image.</p>
  </details>
</details>
<details>
  <summary>46. <b>标题：SL-CycleGAN: Blind Motion Deblurring in Cycles using Sparse Learning</b></summary>
  <p><b>编号</b>：[254]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04026</p>
  <p><b>作者</b>：Ali Syed Saqlain,  Li-Yun Wang,  Fang Fang</p>
  <p><b>备注</b>：12 pages</p>
  <p><b>关键词</b>：single image blind motion deblurring, trainable spatial pooler k, end generative adversarial network, based motion deblurring methods, blind motion deblurring</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we introduce an end-to-end generative adversarial network
(GAN) based on sparse learning for single image blind motion deblurring, which
we called SL-CycleGAN. For the first time in blind motion deblurring, we
propose a sparse ResNet-block as a combination of sparse convolution layers and
a trainable spatial pooler k-winner based on HTM (Hierarchical Temporal Memory)
to replace non-linearity such as ReLU in the ResNet-block of SL-CycleGAN
generators. Furthermore, unlike many state-of-the-art GAN-based motion
deblurring methods that treat motion deblurring as a linear end-to-end process,
we take our inspiration from the domain-to-domain translation ability of
CycleGAN, and we show that image deblurring can be cycle-consistent while
achieving the best qualitative results. Finally, we perform extensive
experiments on popular image benchmarks both qualitatively and quantitatively
and achieve the record-breaking PSNR of 38.087 dB on GoPro dataset, which is
5.377 dB better than the most recent deblurring method.</p>
  </details>
</details>
<details>
  <summary>47. <b>标题：Out-of-Domain Human Mesh Reconstruction via Dynamic Bilevel Online  Adaptation</b></summary>
  <p><b>编号</b>：[258]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04017</p>
  <p><b>作者</b>：Shanyan Guan,  Jingwei Xu,  Michelle Z. He,  Yunbo Wang,  Bingbing Ni,  Xiaokang Yang</p>
  <p><b>备注</b>：14 pages, 13 figures; code repositoty: this https URL</p>
  <p><b>关键词</b>：similar source examples retrieved efficiently despite, domain human mesh reconstruction benchmarks, dynaboa provides additional 3d guidance, dynamic bilevel online adaptation algorithm, human mesh reconstruction model</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We consider a new problem of adapting a human mesh reconstruction model to
out-of-domain streaming videos, where performance of existing SMPL-based models
are significantly affected by the distribution shift represented by different
camera parameters, bone lengths, backgrounds, and occlusions. We tackle this
problem through online adaptation, gradually correcting the model bias during
testing. There are two main challenges: First, the lack of 3D annotations
increases the training difficulty and results in 3D ambiguities. Second,
non-stationary data distribution makes it difficult to strike a balance between
fitting regular frames and hard samples with severe occlusions or dramatic
changes. To this end, we propose the Dynamic Bilevel Online Adaptation
algorithm (DynaBOA). It first introduces the temporal constraints to compensate
for the unavailable 3D annotations, and leverages a bilevel optimization
procedure to address the conflicts between multi-objectives. DynaBOA provides
additional 3D guidance by co-training with similar source examples retrieved
efficiently despite the distribution shift. Furthermore, it can adaptively
adjust the number of optimization steps on individual frames to fully fit hard
samples and avoid overfitting regular frames. DynaBOA achieves state-of-the-art
results on three out-of-domain human mesh reconstruction benchmarks.</p>
  </details>
</details>
<details>
  <summary>48. <b>标题：A-PixelHop: A Green, Robust and Explainable Fake-Image Detector</b></summary>
  <p><b>编号</b>：[259]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04012</p>
  <p><b>作者</b>：Yao Zhu,  Xinyu Wang,  Hong-Shuo Chen,  Ronald Salloum,  C.-C. Jay Kuo</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：contains four building modules, applying multiple filter banks, multiple binary classifiers, small model size, low computational complexity</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A novel method for detecting CNN-generated images, called Attentive PixelHop
(or A-PixelHop), is proposed in this work. It has three advantages: 1) low
computational complexity and a small model size, 2) high detection performance
against a wide range of generative models, and 3) mathematical transparency.
A-PixelHop is designed under the assumption that it is difficult to synthesize
high-quality, high-frequency components in local regions. It contains four
building modules: 1) selecting edge/texture blocks that contain significant
high-frequency components, 2) applying multiple filter banks to them to obtain
rich sets of spatial-spectral responses as features, 3) feeding features to
multiple binary classifiers to obtain a set of soft decisions, 4) developing an
effective ensemble scheme to fuse the soft decisions into the final decision.
Experimental results show that A-PixelHop outperforms state-of-the-art methods
in detecting CycleGAN-generated images. Furthermore, it can generalize well to
unseen generative models and datasets.</p>
  </details>
</details>
<details>
  <summary>49. <b>标题：NarrationBot and InfoBot: A Hybrid System for Automated Video  Description</b></summary>
  <p><b>编号</b>：[266]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03994</p>
  <p><b>作者</b>：Shasta Ihorn,  Yue-Ting Siu,  Aditya Bodi,  Lothar Narins,  Jose M. Castanon,  Yash Kant,  Abhishek Das,  Ilmi Yoon,  Pooyan Fazli</p>
  <p><b>备注</b>：14 pages</p>
  <p><b>关键词</b>：system significantly improved user comprehension, low vision individuals show, results demonstrate user enthusiasm, generated descriptions cannot match, autogenerated descriptions versus human</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Video accessibility is crucial for blind and low vision users for equitable
engagements in education, employment, and entertainment. Despite the
availability of professional and amateur services and tools, most
human-generated descriptions are expensive and time consuming. Moreover, the
rate of human-generated descriptions cannot match the speed of video
production. To overcome the increasing gaps in video accessibility, we
developed a hybrid system of two tools to 1) automatically generate
descriptions for videos and 2) provide answers or additional descriptions in
response to user queries on a video. Results from a mixed-methods study with 26
blind and low vision individuals show that our system significantly improved
user comprehension and enjoyment of selected videos when both tools were used
in tandem. In addition, participants reported no significant difference in
their ability to understand videos when presented with autogenerated
descriptions versus human-revised autogenerated descriptions. Our results
demonstrate user enthusiasm about the developed system and its promise for
providing customized access to videos. We discuss the limitations of the
current work and provide recommendations for the future development of
automated video description tools.</p>
  </details>
</details>
<details>
  <summary>50. <b>标题：Multi-Scale Semantics-Guided Neural Networks for Efficient  Skeleton-Based Human Action Recognition</b></summary>
  <p><b>编号</b>：[267]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03993</p>
  <p><b>作者</b>：Pengfei Zhang,  Cuiling Lan,  Wenjun Zeng,  Junliang Xing,  Jianru Xue,  Nanning Zheng</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：complicated feedforward neural networks, simple yet effective multi, magnitude smaller model size, skeleton sequence without considering, feature representation capability</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Skeleton data is of low dimension. However, there is a trend of using very
deep and complicated feedforward neural networks to model the skeleton sequence
without considering the complexity in recent year. In this paper, a simple yet
effective multi-scale semantics-guided neural network (MS-SGN) is proposed for
skeleton-based action recognition. We explicitly introduce the high level
semantics of joints (joint type and frame index) into the network to enhance
the feature representation capability of joints. Moreover, a multi-scale
strategy is proposed to be robust to the temporal scale variations. In
addition, we exploit the relationship of joints hierarchically through two
modules, i.e., a joint-level module for modeling the correlations of joints in
the same frame and a frame-level module for modeling the temporal dependencies
of frames. With an order of magnitude smaller model size than most previous
methods, MSSGN achieves the state-of-the-art performance on the NTU60, NTU120,
and SYSU datasets.</p>
  </details>
</details>
<details>
  <summary>51. <b>标题：V-MAO: Generative Modeling for Multi-Arm Manipulation of Articulated  Objects</b></summary>
  <p><b>编号</b>：[269]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03987</p>
  <p><b>作者</b>：Xingyu Liu,  Kris M. Kitani</p>
  <p><b>备注</b>：CoRL 2021</p>
  <p><b>关键词</b>：manipulating articulated objects requires multiple robot arms, enable multiple robot arms, collaboratively complete manipulation tasks, learns contact point distribution, customized mujoco simulation environment</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Manipulating articulated objects requires multiple robot arms in general. It
is challenging to enable multiple robot arms to collaboratively complete
manipulation tasks on articulated objects. In this paper, we present
$\textbf{V-MAO}$, a framework for learning multi-arm manipulation of
articulated objects. Our framework includes a variational generative model that
learns contact point distribution over object rigid parts for each robot arm.
The training signal is obtained from interaction with the simulation
environment which is enabled by planning and a novel formulation of
object-centric control for articulated objects. We deploy our framework in a
customized MuJoCo simulation environment and demonstrate that our framework
achieves a high success rate on six different objects and two different robots.
We also show that generative modeling can effectively learn the contact point
distribution on articulated objects.</p>
  </details>
</details>
<details>
  <summary>52. <b>标题：CALText: Contextual Attention Localization for Offline Handwritten Text</b></summary>
  <p><b>编号</b>：[285]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03952</p>
  <p><b>作者</b>：Tayaba Anjum,  Nazar Khan</p>
  <p><b>备注</b>：25 pages, 15 figures and 6 tables</p>
  <p><b>关键词</b>：publicly available handwritten urdu dataset, offline handwritten urdu script, contextual attention localization outperforms, novel localization penalty, much research exists</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recognition of Arabic-like scripts such as Persian and Urdu is more
challenging than Latin-based scripts. This is due to the presence of a
two-dimensional structure, context-dependent character shapes, spaces and
overlaps, and placement of diacritics. Not much research exists for offline
handwritten Urdu script which is the 10th most spoken language in the world. We
present an attention based encoder-decoder model that learns to read Urdu in
context. A novel localization penalty is introduced to encourage the model to
attend only one location at a time when recognizing the next character. In
addition, we comprehensively refine the only complete and publicly available
handwritten Urdu dataset in terms of ground-truth annotations. We evaluate the
model on both Urdu and Arabic datasets and show that contextual attention
localization outperforms both simple attention and multi-directional LSTM
models.</p>
  </details>
</details>
<details>
  <summary>53. <b>标题：Convolutional Gated MLP: Combining Convolutions & gMLP</b></summary>
  <p><b>编号</b>：[291]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03940</p>
  <p><b>作者</b>：A.Rajagopal,  V. Nirmala</p>
  <p><b>备注</b>：Conference</p>
  <p><b>关键词</b>：learnt using vast amount, novel deep learning architecture, novel deep learning architecture, spatial gated mlp, google brain introduced</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>To the best of our knowledge, this is the first paper to introduce
Convolutions to Gated MultiLayer Perceptron and contributes an implementation
of this novel Deep Learning architecture. Google Brain introduced the gMLP in
May 2021. Microsoft introduced Convolutions in Vision Transformer in Mar 2021.
Inspired by both gMLP and CvT, we introduce convolutional layers in gMLP. CvT
combined the power of Convolutions and Attention. Our implementation combines
the best of Convolutional learning along with spatial gated MLP. Further, the
paper visualizes how CgMLP learns. Visualizations show how CgMLP learns from
features such as outline of a car. While Attention was the basis of much of
recent progress in Deep Learning, gMLP proposed an approach that doesn't use
Attention computation. In Transformer based approaches, a whole lot of
Attention matrixes need to be learnt using vast amount of training data. In
gMLP, the fine tunning for new tasks can be challenging by transfer learning
with smaller datasets. We implement CgMLP and compares it with gMLP on CIFAR
dataset. Experimental results explore the power of generaliza-tion of CgMLP,
while gMLP tend to drastically overfit the training data.
To summarize, the paper contributes a novel Deep Learning architecture and
demonstrates the learning mechanism of CgMLP through visualizations, for the
first time in literature.</p>
  </details>
</details>
<details>
  <summary>54. <b>标题：Tip-Adapter: Training-free CLIP-Adapter for Better Vision-Language  Modeling</b></summary>
  <p><b>编号</b>：[296]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03930</p>
  <p><b>作者</b>：Renrui Zhang,  Rongyao Fang,  Peng Gao,  Wei Zhang,  Kunchang Li,  Jifeng Dai,  Yu Qiao,  Hongsheng Li</p>
  <p><b>备注</b>：preprints</p>
  <p><b>关键词</b>：process still needs extra training, value cache model constructed, lightweight residual feature adapter, performed adapter weights without, learning visual representations</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Contrastive Vision-Language Pre-training, known as CLIP, has provided a new
paradigm for learning visual representations by using large-scale contrastive
image-text pairs. It shows impressive performance on zero-shot knowledge
transfer to downstream tasks. To further enhance CLIP's few-shot capability,
CLIP-Adapter proposed to fine-tune a lightweight residual feature adapter and
significantly improves the performance for few-shot classification. However,
such a process still needs extra training and computational resources. In this
paper, we propose \textbf{T}raining-Free CL\textbf{IP}-\textbf{Adapter}
(\textbf{Tip-Adapter}), which not only inherits CLIP's training-free advantage
but also performs comparably or even better than CLIP-Adapter. Tip-Adapter does
not require any back propagation for training the adapter, but creates the
weights by a key-value cache model constructed from the few-shot training set.
In this non-parametric manner, Tip-Adapter acquires well-performed adapter
weights without any training, which is both efficient and effective. Moreover,
the performance of Tip-Adapter can be further boosted by fine-tuning such
properly initialized adapter for only a few epochs with super-fast convergence
speed. We conduct extensive experiments of few-shot classification on ImageNet
and other 10 datasets to demonstrate the superiority of proposed Tip-Adapter.
The code will be released at \url{this https URL}.</p>
  </details>
</details>
<details>
  <summary>55. <b>标题：Domain Attention Consistency for Multi-Source Domain Adaptation</b></summary>
  <p><b>编号</b>：[304]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03911</p>
  <p><b>作者</b>：Zhongying Deng,  Kaiyang Zhou,  Yongxin Yang,  Tao Xiang</p>
  <p><b>备注</b>：Accepted to BMVC 2021 as oral presentation</p>
  <p><b>关键词</b>：target domain pairs via feature distribution alignment, drastically different visual appearances, facilitate discriminative feature learning, aligning pairwise feature distributions, net achieves new state</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Most existing multi-source domain adaptation (MSDA) methods minimize the
distance between multiple source-target domain pairs via feature distribution
alignment, an approach borrowed from the single source setting. However, with
diverse source domains, aligning pairwise feature distributions is challenging
and could even be counter-productive for MSDA. In this paper, we introduce a
novel approach: transferable attribute learning. The motivation is simple:
although different domains can have drastically different visual appearances,
they contain the same set of classes characterized by the same set of
attributes; an MSDA model thus should focus on learning the most transferable
attributes for the target domain. Adopting this approach, we propose a domain
attention consistency network, dubbed DAC-Net. The key design is a feature
channel attention module, which aims to identify transferable features
(attributes). Importantly, the attention module is supervised by a consistency
loss, which is imposed on the distributions of channel attention weights
between source and target domains. Moreover, to facilitate discriminative
feature learning on the target data, we combine pseudo-labeling with a class
compactness loss to minimize the distance between the target features and the
classifier's weight vectors. Extensive experiments on three MSDA benchmarks
show that our DAC-Net achieves new state of the art performance on all of them.</p>
  </details>
</details>
<details>
  <summary>56. <b>标题：Action Recognition using Transfer Learning and Majority Voting for CSGO</b></summary>
  <p><b>编号</b>：[315]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03882</p>
  <p><b>作者</b>：Tasnim Sakib Apon,  Abrar Islam,  MD. Golam Rabiul Alam</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：also including major voting later, five different transfer learning models, developed deep neural network, csv formatted file however, presently online video games</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Presently online video games have become a progressively favorite source of
recreation and Counter Strike: Global Offensive (CS: GO) is one of the
top-listed online first-person shooting games. Numerous competitive games are
arranged every year by Esports. Nonetheless, (i) No study has been conducted on
video analysis and action recognition of CS: GO game-play which can play a
substantial role in the gaming industry for prediction model (ii) No work has
been done on the real-time application on the actions and results of a CS: GO
match (iii) Game data of a match is usually available in the HLTV as a CSV
formatted file however it does not have open access and HLTV tends to prevent
users from taking data. This manuscript aims to develop a model for accurate
prediction of 4 different actions and compare the performance among the five
different transfer learning models with our self-developed deep neural network
and identify the best-fitted model and also including major voting later on,
which is qualified to provide real time prediction and the result of this model
aids to the construction of the automated system of gathering and processing
more data alongside solving the issue of collecting data from HLTV.</p>
  </details>
</details>
<details>
  <summary>57. <b>标题：Towards Calibrated Model for Long-Tailed Visual Recognition from Prior  Perspective</b></summary>
  <p><b>编号</b>：[317]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03874</p>
  <p><b>作者</b>：Zhengzhuo Xu,  Zenghao Chai,  Chun Yuan</p>
  <p><b>备注</b>：Accepted at NeurIPS 2021</p>
  <p><b>关键词</b>：oriented data augmentation named uniform mixup, datasets would prefer dominant labels, world data universally confronts, adopts advanced mixing factor, propose two novel methods</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Real-world data universally confronts a severe class-imbalance problem and
exhibits a long-tailed distribution, i.e., most labels are associated with
limited instances. The naïve models supervised by such datasets would prefer
dominant labels, encounter a serious generalization challenge and become poorly
calibrated. We propose two novel methods from the prior perspective to
alleviate this dilemma. First, we deduce a balance-oriented data augmentation
named Uniform Mixup (UniMix) to promote mixup in long-tailed scenarios, which
adopts advanced mixing factor and sampler in favor of the minority. Second,
motivated by the Bayesian theory, we figure out the Bayes Bias (Bayias), an
inherent bias caused by the inconsistency of prior, and compensate it as a
modification on standard cross-entropy loss. We further prove that both the
proposed methods ensure the classification calibration theoretically and
empirically. Extensive experiments verify that our strategies contribute to a
better-calibrated model, and their combination achieves state-of-the-art
performance on CIFAR-LT, ImageNet-LT, and iNaturalist 2018.</p>
  </details>
</details>
<details>
  <summary>58. <b>标题：What augmentations are sensitive to hyper-parameters and why?</b></summary>
  <p><b>编号</b>：[319]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03861</p>
  <p><b>作者</b>：Ch Muhammad Awais,  Imad Eddine Ibrahim Bekkouch</p>
  <p><b>备注</b>：10 pages, 17 figures</p>
  <p><b>关键词</b>：utilized linear regression coefficients, machine learning model, hyper parameters along, question remains, noisy data</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We apply augmentations to our dataset to enhance the quality of our
predictions and make our final models more resilient to noisy data and domain
drifts. Yet the question remains, how are these augmentations going to perform
with different hyper-parameters? In this study we evaluate the sensitivity of
augmentations with regards to the model's hyper parameters along with their
consistency and influence by performing a Local Surrogate (LIME) interpretation
on the impact of hyper-parameters when different augmentations are applied to a
machine learning model. We have utilized Linear regression coefficients for
weighing each augmentation. Our research has proved that there are some
augmentations which are highly sensitive to hyper-parameters and others which
are more resilient and reliable.</p>
  </details>
</details>
<details>
  <summary>59. <b>标题：Multi-modal land cover mapping of remote sensing images using pyramid  attention and gated fusion networks</b></summary>
  <p><b>编号</b>：[322]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03845</p>
  <p><b>作者</b>：Qinghui Liu,  Michael Kampffmeyer,  Robert Jenssen,  Arnt-Børre Salberg</p>
  <p><b>备注</b>：24 pages, 11 figures, submitted to IJRS</p>
  <p><b>关键词</b>：two representative rs benchmark datasets demonstrate, modal remote sensing data based, efficiently obtain rich fine, view attention fusion mechanism, novel pyramid attention fusion</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Multi-modality data is becoming readily available in remote sensing (RS) and
can provide complementary information about the Earth's surface. Effective
fusion of multi-modal information is thus important for various applications in
RS, but also very challenging due to large domain differences, noise, and
redundancies. There is a lack of effective and scalable fusion techniques for
bridging multiple modality encoders and fully exploiting complementary
information. To this end, we propose a new multi-modality network (MultiModNet)
for land cover mapping of multi-modal remote sensing data based on a novel
pyramid attention fusion (PAF) module and a gated fusion unit (GFU). The PAF
module is designed to efficiently obtain rich fine-grained contextual
representations from each modality with a built-in cross-level and cross-view
attention fusion mechanism, and the GFU module utilizes a novel gating
mechanism for early merging of features, thereby diminishing hidden
redundancies and noise. This enables supplementary modalities to effectively
extract the most valuable and complementary information for late feature
fusion. Extensive experiments on two representative RS benchmark datasets
demonstrate the effectiveness, robustness, and superiority of the MultiModNet
for multi-modal land cover classification.</p>
  </details>
</details>
<details>
  <summary>60. <b>标题：Neural Implicit Event Generator for Motion Tracking</b></summary>
  <p><b>编号</b>：[326]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03824</p>
  <p><b>作者</b>：Mana Masuda,  Yusuke Sekikawa,  Ryo Fujii,  Hideo Saito</p>
  <p><b>备注</b>：Submitted to ICRA 2022</p>
  <p><b>关键词</b>：trained event generation mlp named implicit event generator, implicit approach realizes efficient state update directly, event data using implicit expression, ar marker tracking application, conventional explicit approach</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present a novel framework of motion tracking from event data using
implicit expression. Our framework use pre-trained event generation MLP named
implicit event generator (IEG) and does motion tracking by updating its state
(position and velocity) based on the difference between the observed event and
generated event from the current state estimate. The difference is computed
implicitly by the IEG. Unlike the conventional explicit approach, which
requires dense computation to evaluate the difference, our implicit approach
realizes efficient state update directly from sparse event data. Our sparse
algorithm is especially suitable for mobile robotics applications where
computational resources and battery life are limited. To verify the
effectiveness of our method on real-world data, we applied it to the AR marker
tracking application. We have confirmed that our framework works well in
real-world environments in the presence of noise and background clutter.</p>
  </details>
</details>
<details>
  <summary>61. <b>标题：ROFT: Real-Time Optical Flow-Aided 6D Object Pose and Velocity Tracking</b></summary>
  <p><b>编号</b>：[329]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03821</p>
  <p><b>作者</b>：Nicola A. Piga,  Yuriy Onyshchuk,  Giulia Pasquale,  Ugo Pattacini,  Lorenzo Natale</p>
  <p><b>备注</b>：To cite this work, please refer to the journal reference entry. For more information, code, pictures and video please visit this https URL</p>
  <p><b>关键词</b>：low frame rate convolutional neural networks, also providing 6d object velocity tracking, hand pose estimation ho, precise 6d object pose, 6d object pose estimation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>6D object pose tracking has been extensively studied in the robotics and
computer vision communities. The most promising solutions, leveraging on deep
neural networks and/or filtering and optimization, exhibit notable performance
on standard benchmarks. However, to our best knowledge, these have not been
tested thoroughly against fast object motions. Tracking performance in this
scenario degrades significantly, especially for methods that do not achieve
real-time performance and introduce non negligible delays. In this work, we
introduce ROFT, a Kalman filtering approach for 6D object pose and velocity
tracking from a stream of RGB-D images. By leveraging real-time optical flow,
ROFT synchronizes delayed outputs of low frame rate Convolutional Neural
Networks for instance segmentation and 6D object pose estimation with the RGB-D
input stream to achieve fast and precise 6D object pose and velocity tracking.
We test our method on a newly introduced photorealistic dataset, Fast-YCB,
which comprises fast moving objects from the YCB model set, and on the dataset
for object and hand pose estimation HO-3D. Results demonstrate that our
approach outperforms state-of-the-art methods for 6D object pose tracking,
while also providing 6D object velocity tracking. A video showing the
experiments is provided as supplementary material.</p>
  </details>
</details>
<details>
  <summary>62. <b>标题：Will You Ever Become Popular? Learning to Predict Virality of Dance  Clips</b></summary>
  <p><b>编号</b>：[330]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03819</p>
  <p><b>作者</b>：Jiahao Wang,  Yunhong Wang,  Nina Weng,  Tianrui Chai,  Annan Li,  Faxi Zhang,  Sansi Yu</p>
  <p><b>备注</b>：Accepted by TOMM</p>
  <p><b>关键词</b>：video communities like tiktok nowadays, pyramidal skeleton graph convolutional network, short video applications like multi, relational temporal convolutional network, scale viral dance video</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Dance challenges are going viral in video communities like TikTok nowadays.
Once a challenge becomes popular, thousands of short-form videos will be
uploaded in merely a couple of days. Therefore, virality prediction from dance
challenges is of great commercial value and has a wide range of applications,
such as smart recommendation and popularity promotion. In this paper, a novel
multi-modal framework which integrates skeletal, holistic appearance, facial
and scenic cues is proposed for comprehensive dance virality prediction. To
model body movements, we propose a pyramidal skeleton graph convolutional
network (PSGCN) which hierarchically refines spatio-temporal skeleton graphs.
Meanwhile, we introduce a relational temporal convolutional network (RTCN) to
exploit appearance dynamics with non-local temporal relations. An attentive
fusion approach is finally proposed to adaptively aggregate predictions from
different modalities. To validate our method, we introduce a large-scale viral
dance video (VDV) dataset, which contains over 4,000 dance clips of eight viral
dance challenges. Extensive experiments on the VDV dataset demonstrate the
efficacy of our model. Extensive experiments on the VDV dataset well
demonstrate the effectiveness of our approach. Furthermore, we show that short
video applications like multi-dimensional recommendation and action feedback
can be derived from our model.</p>
  </details>
</details>
<details>
  <summary>63. <b>标题：Neural BRDFs: Representation and Operations</b></summary>
  <p><b>编号</b>：[337]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03797</p>
  <p><b>作者</b>：Jiahui Fan,  Beibei Wang,  Miloš Hašan,  Jian Yang,  Ling-Qi Yan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：several works explored using neural networks, expensive monte carlo layering approaches, fit highly complex functions, bidirectional reflectance distribution functions, neural brdf algebra ",</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Bidirectional reflectance distribution functions (BRDFs) are pervasively used
in computer graphics to produce realistic physically-based appearance. In
recent years, several works explored using neural networks to represent BRDFs,
taking advantage of neural networks' high compression rate and their ability to
fit highly complex functions. However, once represented, the BRDFs will be
fixed and therefore lack flexibility to take part in follow-up operations. In
this paper, we present a form of "Neural BRDF algebra", and focus on both
representation and operations of BRDFs at the same time. We propose a
representation neural network to compress BRDFs into latent vectors, which is
able to represent BRDFs accurately. We further propose several operations that
can be applied solely in the latent space, such as layering and interpolation.
Spatial variation is straightforward to achieve by using textures of latent
vectors. Furthermore, our representation can be efficiently evaluated and
sampled, providing a competitive solution to more expensive Monte Carlo
layering approaches.</p>
  </details>
</details>
<details>
  <summary>64. <b>标题：Generation of microbial colonies dataset with deep learning style  transfer</b></summary>
  <p><b>编号</b>：[341]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03789</p>
  <p><b>作者</b>：Jarosław Pawłowski,  Sylwia Majchrowska,  Tomasz Golan</p>
  <p><b>备注</b>：11 pages, 9 figures, 2 tables</p>
  <p><b>关键词</b>：developed generator employs traditional computer vision algorithms together, classifying five different microbial species, method requires significantly fewer resources, several dozen times bigger dataset, neural network model capable</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We introduce an effective strategy to generate a synthetic dataset of
microbiological images of Petri dishes that can be used to train deep learning
models. The developed generator employs traditional computer vision algorithms
together with a neural style transfer method for data augmentation. We show
that the method is able to synthesize a dataset of realistic looking images
that can be used to train a neural network model capable of localising,
segmenting, and classifying five different microbial species. Our method
requires significantly fewer resources to obtain a useful dataset than
collecting and labeling a whole large set of real images with annotations. We
show that starting with only 100 real images, we can generate data to train a
detector that achieves comparable results to the same detector but trained on a
real, several dozen times bigger dataset. We prove the usefulness of the method
in microbe detection and segmentation, but we expect that it is general and
flexible and can also be applicable in other domains of science and industry to
detect various objects.</p>
  </details>
</details>
<details>
  <summary>65. <b>标题：MQBench: Towards Reproducible and Deployable Model Quantization  Benchmark</b></summary>
  <p><b>编号</b>：[352]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03759</p>
  <p><b>作者</b>：Yuhang Li,  Mingzhu Shen,  Jian Ma,  Yan Ren,  Mingxin Zhao,  Qi Zhang,  Ruihao Gong,  Fengwei Yu,  Junjie Yan</p>
  <p><b>备注</b>：Accepted by 35th Conference on Neural Information Processing Systems (NeurIPS 2021) Track on Datasets and Benchmarks</p>
  <p><b>关键词</b>：work could inspire future research directions, existing algorithm wins every challenge, choose multiple different platforms, accelerate deep learning inference, choose consistent training pipelines</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Model quantization has emerged as an indispensable technique to accelerate
deep learning inference. While researchers continue to push the frontier of
quantization algorithms, existing quantization work is often unreproducible and
undeployable. This is because researchers do not choose consistent training
pipelines and ignore the requirements for hardware deployments. In this work,
we propose Model Quantization Benchmark (MQBench), a first attempt to evaluate,
analyze, and benchmark the reproducibility and deployability for model
quantization algorithms. We choose multiple different platforms for real-world
deployments, including CPU, GPU, ASIC, DSP, and evaluate extensive
state-of-the-art quantization algorithms under a unified training pipeline.
MQBench acts like a bridge to connect the algorithm and the hardware. We
conduct a comprehensive analysis and find considerable intuitive or
counter-intuitive insights. By aligning the training settings, we find existing
algorithms have about the same performance on the conventional academic track.
While for the hardware-deployable quantization, there is a huge accuracy gap
which remains unsettled. Surprisingly, no existing algorithm wins every
challenge in MQBench, and we hope this work could inspire future research
directions.</p>
  </details>
</details>
<details>
  <summary>66. <b>标题：Reconstructing Training Data from Diverse ML Models by Ensemble  Inversion</b></summary>
  <p><b>编号</b>：[376]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03702</p>
  <p><b>作者</b>：Qian Wang,  Daniel Kurz</p>
  <p><b>备注</b>：9 pages, 8 figures, WACV 2022</p>
  <p><b>关键词</b>：training data contains personally identifiable information, explore targeting multiple models jointly, achieve high quality results without, attracted increasing research attention, may provide additional information</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Model Inversion (MI), in which an adversary abuses access to a trained
Machine Learning (ML) model attempting to infer sensitive information about its
original training data, has attracted increasing research attention. During MI,
the trained model under attack (MUA) is usually frozen and used to guide the
training of a generator, such as a Generative Adversarial Network (GAN), to
reconstruct the distribution of the original training data of that model. This
might cause leakage of original training samples, and if successful, the
privacy of dataset subjects will be at risk if the training data contains
Personally Identifiable Information (PII). Therefore, an in-depth investigation
of the potentials of MI techniques is crucial for the development of
corresponding defense techniques. High-quality reconstruction of training data
based on a single model is challenging. However, existing MI literature does
not explore targeting multiple models jointly, which may provide additional
information and diverse perspectives to the adversary.
We propose the ensemble inversion technique that estimates the distribution
of original training data by training a generator constrained by an ensemble
(or set) of trained models with shared subjects or entities. This technique
leads to noticeable improvements of the quality of the generated samples with
distinguishable features of the dataset entities compared to MI of a single ML
model. We achieve high quality results without any dataset and show how
utilizing an auxiliary dataset that's similar to the presumed training data
improves the results. The impact of model diversity in the ensemble is
thoroughly investigated and additional constraints are utilized to encourage
sharp predictions and high activations for the reconstructed samples, leading
to more accurate reconstruction of training images.</p>
  </details>
</details>
<details>
  <summary>67. <b>标题：Disaster mapping from satellites: damage detection with crowdsourced  point labels</b></summary>
  <p><b>编号</b>：[380]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03693</p>
  <p><b>作者</b>：Danil Kuzin,  Olga Isupova,  Brooke D. Simmons,  Steven Reece</p>
  <p><b>备注</b>：3rd Workshop on Artificial Intelligence for Humanitarian Assistance and Disaster Response at NeurIPS 2021</p>
  <p><b>关键词</b>：resolution satellite imagery available immediately, aggregating potentially inconsistent damage marks, scale would require hundreds, facilitates broad situational awareness, neural network damage detector</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>High-resolution satellite imagery available immediately after disaster events
is crucial for response planning as it facilitates broad situational awareness
of critical infrastructure status such as building damage, flooding, and
obstructions to access routes. Damage mapping at this scale would require
hundreds of expert person-hours. However, a combination of crowdsourcing and
recent advances in deep learning reduces the effort needed to just a few hours
in real time. Asking volunteers to place point marks, as opposed to shapes of
actual damaged areas, significantly decreases the required analysis time for
response during the disaster. However, different volunteers may be inconsistent
in their marking. This work presents methods for aggregating potentially
inconsistent damage marks to train a neural network damage detector.</p>
  </details>
</details>
<details>
  <summary>68. <b>标题：The Role of Pre-Training in High-Resolution Remote Sensing Scene  Classification</b></summary>
  <p><b>编号</b>：[381]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03690</p>
  <p><b>作者</b>：Vladimir Risojević,  Vladan Stojnić</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：several larger high resolution remote sensing, several newer datasets yields comparable results, hrrs scene classification tasks better, remote sensing scene classification, establishing new benchmarks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Due to the scarcity of labeled data, using models pre-trained on ImageNet is
a de facto standard in remote sensing scene classification. Although, recently,
several larger high resolution remote sensing (HRRS) datasets have appeared
with a goal of establishing new benchmarks, attempts at training models from
scratch on these datasets are sporadic. In this paper, we show that training
models from scratch on several newer datasets yields comparable results to
fine-tuning the models pre-trained on ImageNet. Furthermore, the
representations learned on HRRS datasets transfer to other HRRS scene
classification tasks better or at least similarly as those learned on ImageNet.
Finally, we show that in many cases the best representations are obtained by
using a second round of pre-training using in-domain data, i.e. domain-adaptive
pre-training. The source code and pre-trained models are available at
\url{this https URL.}</p>
  </details>
</details>
<details>
  <summary>69. <b>标题：Automated pharyngeal phase detection and bolus localization in  videofluoroscopic swallowing study: Killing two birds with one stone?</b></summary>
  <p><b>编号</b>：[388]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04699</p>
  <p><b>作者</b>：Andrea Bandini,  Sana Smaoui,  Catriona M. Steele</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：vfss recordings via computer vision approaches, infer whether individual vfss frames belong, jointly tackles pharyngeal phase detection, prominent visual feature upon, multiple convolutional neural networks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The videofluoroscopic swallowing study (VFSS) is a gold-standard imaging
technique for assessing swallowing, but analysis and rating of VFSS recordings
is time consuming and requires specialized training and expertise. Researchers
have demonstrated that it is possible to automatically detect the pharyngeal
phase of swallowing and to localize the bolus in VFSS recordings via computer
vision approaches, fostering the development of novel techniques for automatic
VFSS analysis. However, training of algorithms to perform these tasks requires
large amounts of annotated data that are seldom available. We demonstrate that
the challenges of pharyngeal phase detection and bolus localization can be
solved together using a single approach. We propose a deep-learning framework
that jointly tackles pharyngeal phase detection and bolus localization in a
weakly-supervised manner, requiring only the initial and final frames of the
pharyngeal phase as ground truth annotations for the training. Our approach
stems from the observation that bolus presence in the pharynx is the most
prominent visual feature upon which to infer whether individual VFSS frames
belong to the pharyngeal phase. We conducted extensive experiments with
multiple convolutional neural networks (CNNs) on a dataset of 1245 VFSS clips
from 59 healthy subjects. We demonstrated that the pharyngeal phase can be
detected with an F1-score higher than 0.9. Moreover, by processing the class
activation maps of the CNNs, we were able to localize the bolus with promising
results, obtaining correlations with ground truth trajectories higher than 0.9,
without any manual annotations of bolus location used for training purposes.
Once validated on a larger sample of participants with swallowing disorders,
our framework will pave the way for the development of intelligent tools for
VFSS analysis to support clinicians in swallowing assessment.</p>
  </details>
</details>
<details>
  <summary>70. <b>标题：Machine Learning Guided 3D Image Recognition for Carbonate Pore and  Mineral Volumes Determination</b></summary>
  <p><b>编号</b>：[394]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04612</p>
  <p><b>作者</b>：Omar Alfarisi,  Aikifa Raza,  Hongtao Zhang,  Djamel Ozzane,  Mohamed Sassi,  Tiejun Zhang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：iroga ); advanced image recognition method enabled, pyrite reference values using two methods, image resolution optimized gaussian algorithm, built reference 3d micro models, image analysis methods converge</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Automated image processing algorithms can improve the quality, efficiency,
and consistency of classifying the morphology of heterogeneous carbonate rock
and can deal with a massive amount of data and images seamlessly. Geoscientists
face difficulties in setting the direction of the optimum method for
determining petrophysical properties from rock images, Micro-Computed
Tomography (uCT), or Magnetic Resonance Imaging (MRI). Most of the successful
work is from the homogeneous rocks focusing on 2D images with less focus on 3D
and requiring numerical simulation. Currently, image analysis methods converge
to three approaches: image processing, artificial intelligence, and combined
image processing with artificial intelligence. In this work, we propose two
methods to determine the porosity from 3D uCT and MRI images: an image
processing method with Image Resolution Optimized Gaussian Algorithm (IROGA);
advanced image recognition method enabled by Machine Learning Difference of
Gaussian Random Forest (MLDGRF). We have built reference 3D micro models and
collected images for calibration of IROGA and MLDGRF methods. To evaluate the
predictive capability of these calibrated approaches, we ran them on 3D uCT and
MRI images of natural heterogeneous carbonate rock. We measured the porosity
and lithology of the carbonate rock using three and two industry-standard ways,
respectively, as reference values. Notably, IROGA and MLDGRF have produced
porosity results with an accuracy of 96.2% and 97.1% on the training set and
91.7% and 94.4% on blind test validation, respectively, in comparison with the
three experimental measurements. We measured limestone and pyrite reference
values using two methods, X-ray powder diffraction, and grain density
measurements. MLDGRF has produced lithology (limestone and Pyrite) volumes with
97.7% accuracy.</p>
  </details>
</details>
<details>
  <summary>71. <b>标题：Triple-level Model Inferred Collaborative Network Architecture for Video  Deraining</b></summary>
  <p><b>编号</b>：[413]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04459</p>
  <p><b>作者</b>：Pan Mu,  Zhu Liu,  Yaohua Liu,  Risheng Liu,  Xin Fan</p>
  <p><b>备注</b>：Accepted at IEEE Transactions on Image Processing</p>
  <p><b>关键词</b>：existing methods cannot cover various rain streaks distribution, discover desirable rain streaks removal architectures automatically, structure includes dominant network architecture, level model inferred cooperating searching, various video rain circumstances</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Video deraining is an important issue for outdoor vision systems and has been
investigated extensively. However, designing optimal architectures by the
aggregating model formation and data distribution is a challenging task for
video deraining. In this paper, we develop a model-guided triple-level
optimization framework to deduce network architecture with cooperating
optimization and auto-searching mechanism, named Triple-level Model Inferred
Cooperating Searching (TMICS), for dealing with various video rain
circumstances. In particular, to mitigate the problem that existing methods
cannot cover various rain streaks distribution, we first design a
hyper-parameter optimization model about task variable and hyper-parameter.
Based on the proposed optimization model, we design a collaborative structure
for video deraining. This structure includes Dominant Network Architecture
(DNA) and Companionate Network Architecture (CNA) that is cooperated by
introducing an Attention-based Averaging Scheme (AAS). To better explore
inter-frame information from videos, we introduce a macroscopic structure
searching scheme that searches from Optical Flow Module (OFM) and Temporal
Grouping Module (TGM) to help restore latent frame. In addition, we apply the
differentiable neural architecture searching from a compact candidate set of
task-specific operations to discover desirable rain streaks removal
architectures automatically. Extensive experiments on various datasets
demonstrate that our model shows significant improvements in fidelity and
temporal consistency over the state-of-the-art works. Source code is available
at this https URL.</p>
  </details>
</details>
<details>
  <summary>72. <b>标题：Dense Representative Tooth Landmark/axis Detection Network on 3D Model</b></summary>
  <p><b>编号</b>：[420]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04212</p>
  <p><b>作者</b>：Guangshun Wei,  Zhiming Cui,  Jie Zhu,  Lei Yang,  Yuanfeng Zhou,  Pradeep Singh,  Min Gu,  Wenping Wang</p>
  <p><b>备注</b>：11pages,27figures</p>
  <p><b>关键词</b>：large variations among individual tooth, accurately detect tooth landmarks, given 3d tooth model, sophisticated geometric definitions, predicts various types</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Artificial intelligence (AI) technology is increasingly used for digital
orthodontics, but one of the challenges is to automatically and accurately
detect tooth landmarks and axes. This is partly because of sophisticated
geometric definitions of them, and partly due to large variations among
individual tooth and across different types of tooth. As such, we propose a
deep learning approach with a labeled dataset by professional dentists to the
tooth landmark/axis detection on tooth model that are crucial for orthodontic
treatments. Our method can extract not only tooth landmarks in the form of
point (e.g. cusps), but also axes that measure the tooth angulation and
inclination. The proposed network takes as input a 3D tooth model and predicts
various types of the tooth landmarks and axes. Specifically, we encode the
landmarks and axes as dense fields defined on the surface of the tooth model.
This design choice and a set of added components make the proposed network more
suitable for extracting sparse landmarks from a given 3D tooth model. Extensive
evaluation of the proposed method was conducted on a set of dental models
prepared by experienced dentists. Results show that our method can produce
tooth landmarks with high accuracy. Our method was examined and justified via
comparison with the state-of-the-art methods as well as the ablation studies.</p>
  </details>
</details>
<details>
  <summary>73. <b>标题：Acquisition-invariant brain MRI segmentation with informative  uncertainties</b></summary>
  <p><b>编号</b>：[425]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04094</p>
  <p><b>作者</b>：Pedro Borges,  Richard Shaw,  Thomas Varsavsky,  Kerstin Klaser,  David Thomas,  Ivana Drobnjak,  Sebastien Ourselin,  M Jorge Cardoso</p>
  <p><b>备注</b>：25 pages, 8 figures</p>
  <p><b>关键词</b>：site correction methods exist, simultaneously modelling uncertainty, sequence parameter choices, explicit uncertainty modelling, complete holdout datasets</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Combining multi-site data can strengthen and uncover trends, but is a task
that is marred by the influence of site-specific covariates that can bias the
data and therefore any downstream analyses. Post-hoc multi-site correction
methods exist but have strong assumptions that often do not hold in real-world
scenarios. Algorithms should be designed in a way that can account for
site-specific effects, such as those that arise from sequence parameter
choices, and in instances where generalisation fails, should be able to
identify such a failure by means of explicit uncertainty modelling. This body
of work showcases such an algorithm, that can become robust to the physics of
acquisition in the context of segmentation tasks, while simultaneously
modelling uncertainty. We demonstrate that our method not only generalises to
complete holdout datasets, preserving segmentation quality, but does so while
also accounting for site-specific sequence choices, which also allows it to
perform as a harmonisation tool.</p>
  </details>
</details>
<details>
  <summary>74. <b>标题：Texture-enhanced Light Field Super-resolution with Spatio-Angular  Decomposition Kernels</b></summary>
  <p><b>编号</b>：[428]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04069</p>
  <p><b>作者</b>：Zexi Hu,  Xiaoming Chen,  Henry Wing Fung Yeung,  Yuk Ying Chung,  Zhibo Chen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：generate rich authentic textures, visually pleasing lfsr results, existing lfsr methods resorted, proposed decomposition kernel network, visual quality significantly</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Despite the recent progress in light field super-resolution (LFSR) achieved
by convolutional neural networks, the correlation information of light field
(LF) images has not been sufficiently studied and exploited due to the
complexity of 4D LF data. To cope with such high-dimensional LF data, most of
the existing LFSR methods resorted to decomposing it into lower dimensions and
subsequently performing optimization on the decomposed sub-spaces. However,
these methods are inherently limited as they neglected the characteristics of
the decomposition operations and only utilized a limited set of LF sub-spaces
ending up failing to comprehensively extract spatio-angular features and
leading to a performance bottleneck. To overcome these limitations, in this
paper, we thoroughly discover the potentials of LF decomposition and propose a
novel concept of decomposition kernels. In particular, we systematically unify
the decomposition operations of various sub-spaces into a series of such
decomposition kernels, which are incorporated into our proposed Decomposition
Kernel Network (DKNet) for comprehensive spatio-angular feature extraction. The
proposed DKNet is experimentally verified to achieve substantial improvements
by 1.35 dB, 0.83 dB, and 1.80 dB PSNR in 2x, 3x and 4x LFSR scales,
respectively, when compared with the state-of-the-art methods. To further
improve DKNet in producing more visually pleasing LFSR results, based on the
VGG network, we propose a LFVGG loss to guide the Texture-Enhanced DKNet
(TE-DKNet) to generate rich authentic textures and enhance LF images' visual
quality significantly. We also propose an indirect evaluation metric by taking
advantage of LF material recognition to objectively assess the perceptual
enhancement brought by the LFVGG loss.</p>
  </details>
</details>
<details>
  <summary>75. <b>标题：Multi-Fake Evolutionary Generative Adversarial Networks for Imbalance  Hyperspectral Image Classification</b></summary>
  <p><b>编号</b>：[431]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04019</p>
  <p><b>作者</b>：Tanmoy Dam,  Nidhi Swami,  Sreenatha G. Anavatti,  Hussein A. Abbass</p>
  <p><b>备注</b>：This paper is underreview to IEEE Trans. of GRSL</p>
  <p><b>关键词</b>：handling imbalance hyperspectral image classification, fake evolutionary generative adversarial network, two different gan objectives, different generative objective losses, two hyperspectral spatial</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper presents a novel multi-fake evolutionary generative adversarial
network(MFEGAN) for handling imbalance hyperspectral image classification. It
is an end-to-end approach in which different generative objective losses are
considered in the generator network to improve the classification performance
of the discriminator network. Thus, the same discriminator network has been
used as a standard classifier by embedding the classifier network on top of the
discriminating function. The effectiveness of the proposed method has been
validated through two hyperspectral spatial-spectral data sets. The same
generative and discriminator architectures have been utilized with two
different GAN objectives for a fair performance comparison with the proposed
method. It is observed from the experimental validations that the proposed
method outperforms the state-of-the-art methods with better classification
performance.</p>
  </details>
</details>
<details>
  <summary>76. <b>标题：The Three-Dimensional Structural Configuration of the Central Retinal  Vessel Trunk and Branches as a Glaucoma Biomarker</b></summary>
  <p><b>编号</b>：[432]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03997</p>
  <p><b>作者</b>：Satish K. Panda,  Haris Cheong,  Tin A. Tun,  Thanadet Chuangsuwanich,  Aiste Kadziauskiene,  Vijayalakshmi Senthil,  Ramaswami Krishnadas,  Martin L. Buist,  Shamira Perera,  Ching-Yu Cheng,  Tin Aung,  Alexandre H. Thiery,  Michael J. A. Girard</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：major retinal blood vessels form, efficiently segment retinal blood vessels, b orthographically onto three planes, central retinal vessel trunk, retinal nerve fiber layer</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Purpose: To assess whether the three-dimensional (3D) structural
configuration of the central retinal vessel trunk and its branches (CRVT&B)
could be used as a diagnostic marker for glaucoma. Method: We trained a deep
learning network to automatically segment the CRVT&B from the B-scans of the
optical coherence tomography (OCT) volume of the optic nerve head (ONH).
Subsequently, two different approaches were used for glaucoma diagnosis using
the structural configuration of the CRVT&B as extracted from the OCT volumes.
In the first approach, we aimed to provide a diagnosis using only 3D CNN and
the 3D structure of the CRVT&B. For the second approach, we projected the 3D
structure of the CRVT&B orthographically onto three planes to obtain 2D images,
and then a 2D CNN was used for diagnosis. The segmentation accuracy was
evaluated using the Dice coefficient, whereas the diagnostic accuracy was
assessed using the area under the receiver operating characteristic curves
(AUC). The diagnostic performance of the CRVT&B was also compared with that of
retinal nerve fiber layer (RNFL) thickness. Results: Our segmentation network
was able to efficiently segment retinal blood vessels from OCT scans. On a test
set, we achieved a Dice coefficient of 0.81\pm0.07. The 3D and 2D diagnostic
networks were able to differentiate glaucoma from non-glaucoma subjects with
accuracies of 82.7% and 83.3%, respectively. The corresponding AUCs for CRVT&B
were 0.89 and 0.90, higher than those obtained with RNFL thickness alone.
Conclusions: Our work demonstrated that the diagnostic power of the CRVT&B is
superior to that of a gold-standard glaucoma parameter, i.e., RNFL thickness.
Our work also suggested that the major retinal blood vessels form a skeleton --
the configuration of which may be representative of major ONH structural
changes as typically observed with the development and progression of glaucoma.</p>
  </details>
</details>
<details>
  <summary>77. <b>标题：Demystifying Deep Learning Models for Retinal OCT Disease Classification  using Explainable AI</b></summary>
  <p><b>编号</b>：[437]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03890</p>
  <p><b>作者</b>：Tasnim Sakib Apon,  Mohammad Mahmudul Hasan,  Abrar Islam,  MD. Golam Rabiul Alam</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：retina optical coherence tomography, various deep learning techniques, conventional deep learning models, making final decisions, introduces explainable ai</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In the world of medical diagnostics, the adoption of various deep learning
techniques is quite common as well as effective, and its statement is equally
true when it comes to implementing it into the retina Optical Coherence
Tomography (OCT) sector, but (i)These techniques have the black box
characteristics that prevent the medical professionals to completely trust the
results generated from them (ii)Lack of precision of these methods restricts
their implementation in clinical and complex cases (iii)The existing works and
models on the OCT classification are substantially large and complicated and
they require a considerable amount of memory and computational power, reducing
the quality of classifiers in real-time applications. To meet these problems,
in this paper a self-developed CNN model has been proposed which is
comparatively smaller and simpler along with the use of Lime that introduces
Explainable AI to the study and helps to increase the interpretability of the
model. This addition will be an asset to the medical experts for getting major
and detailed information and will help them in making final decisions and will
also reduce the opacity and vulnerability of the conventional deep learning
models.</p>
  </details>
</details>
<details>
  <summary>78. <b>标题：A new baseline for retinal vessel segmentation: Numerical identification  and correction of methodological inconsistencies affecting 100+ papers</b></summary>
  <p><b>编号</b>：[439]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03853</p>
  <p><b>作者</b>：György Kovács,  Attila Fazekas</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：de facto benchmarking data sets, similar problems may arise, highest accuracy score achieved, perfect accuracy scores reported, biases using numerical techniques</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In the last 15 years, the segmentation of vessels in retinal images has
become an intensively researched problem in medical imaging, with hundreds of
algorithms published. One of the de facto benchmarking data sets of vessel
segmentation techniques is the DRIVE data set. Since DRIVE contains a
predefined split of training and test images, the published performance results
of the various segmentation techniques should provide a reliable ranking of the
algorithms. Including more than 100 papers in the study, we performed a
detailed numerical analysis of the coherence of the published performance
scores. We found inconsistencies in the reported scores related to the use of
the field of view (FoV), which has a significant impact on the performance
scores. We attempted to eliminate the biases using numerical techniques to
provide a more realistic picture of the state of the art. Based on the results,
we have formulated several findings, most notably: despite the well-defined
test set of DRIVE, most rankings in published papers are based on
non-comparable figures; in contrast to the near-perfect accuracy scores
reported in the literature, the highest accuracy score achieved to date is
0.9582 in the FoV region, which is 1% higher than that of human annotators. The
methods we have developed for identifying and eliminating the evaluation biases
can be easily applied to other domains where similar problems may arise.</p>
  </details>
</details>
<details>
  <summary>79. <b>标题：Multimodal PET/CT Tumour Segmentation and Prediction of Progression-Free  Survival using a Full-Scale UNet with Attention</b></summary>
  <p><b>编号</b>：[440]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03848</p>
  <p><b>作者</b>：Emmanuelle Bourigault,  Daniel R. McGowan,  Abolfazl Mehranian,  Bartłomiej W. Papież</p>
  <p><b>备注</b>：13 pages, 3 figures, 2 tables. To appear in Head and Neck Tumor Segmentation in PET/CT: The HECKTOR Challenge,Valentin Oreiller et al., Medical Image Analysis,2021, HECKTOR 2021, Lecture Notes in Computer Science, Springer</p>
  <p><b>关键词</b>：cox proportional hazard regression combining clinical, h \& n oropharyngeal cancer, patient progression free survival task, used conditional random fields, trained multiple neural networks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Segmentation of head and neck (H\&N) tumours and prediction of patient
outcome are crucial for patient's disease diagnosis and treatment monitoring.
Current developments of robust deep learning models are hindered by the lack of
large multi-centre, multi-modal data with quality annotations. The MICCAI 2021
HEad and neCK TumOR (HECKTOR) segmentation and outcome prediction challenge
creates a platform for comparing segmentation methods of the primary gross
target volume on fluoro-deoxyglucose (FDG)-PET and Computed Tomography images
and prediction of progression-free survival in H\&N oropharyngeal cancer.For
the segmentation task, we proposed a new network based on an encoder-decoder
architecture with full inter- and intra-skip connections to take advantage of
low-level and high-level semantics at full scales. Additionally, we used
Conditional Random Fields as a post-processing step to refine the predicted
segmentation maps. We trained multiple neural networks for tumor volume
segmentation, and these segmentations were ensembled achieving an average Dice
Similarity Coefficient of 0.75 in cross-validation, and 0.76 on the challenge
testing data set. For prediction of patient progression free survival task, we
propose a Cox proportional hazard regression combining clinical, radiomic, and
deep learning features. Our survival prediction model achieved a concordance
index of 0.82 in cross-validation, and 0.62 on the challenge testing data set.</p>
  </details>
</details>
<details>
  <summary>80. <b>标题：Order-Guided Disentangled Representation Learning for Ulcerative Colitis  Classification with Limited Labels</b></summary>
  <p><b>编号</b>：[444]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03815</p>
  <p><b>作者</b>：Shota Harada,  Ryoma Bise,  Hideaki Hayashi,  Kiyohito Tanaka,  Seiichi Uchida</p>
  <p><b>备注</b>：Accepted by MICCAI 2021</p>
  <p><b>关键词</b>：proposed method outperforms several existing semi, newly exploiting two additional features, involves two main difficulties, g ., left colon, second difficulty prevents us</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Ulcerative colitis (UC) classification, which is an important task for
endoscopic diagnosis, involves two main difficulties. First, endoscopic images
with the annotation about UC (positive or negative) are usually limited.
Second, they show a large variability in their appearance due to the location
in the colon. Especially, the second difficulty prevents us from using existing
semi-supervised learning techniques, which are the common remedy for the first
difficulty. In this paper, we propose a practical semi-supervised learning
method for UC classification by newly exploiting two additional features, the
location in a colon (e.g., left colon) and image capturing order, both of which
are often attached to individual images in endoscopic image sequences. The
proposed method can extract the essential information of UC classification
efficiently by a disentanglement process with those features. Experimental
results demonstrate that the proposed method outperforms several existing
semi-supervised learning methods in the classification task, even with a small
number of annotated images.</p>
  </details>
</details>
<details>
  <summary>81. <b>标题：Artifact- and content-specific quality assessment for MRI with image  rulers</b></summary>
  <p><b>编号</b>：[445]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03780</p>
  <p><b>作者</b>：Ke Lei,  John M. Pauly,  Shreyas S. Vasanawala</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：image rulers address varying quality standards, clinical practice mr images, best previous method examined, around 90 %, 6, image quality requirements vary</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In clinical practice MR images are often first seen by radiologists long
after the scan. If image quality is inadequate either patients have to return
for an additional scan, or a suboptimal interpretation is rendered. An
automatic image quality assessment (IQA) would enable real-time remediation.
Existing IQA works for MRI give only a general quality score, agnostic to the
cause of and solution to low-quality scans. Furthermore, radiologists' image
quality requirements vary with the scan type and diagnostic task. Therefore,
the same score may have different implications for different scans. We propose
a framework with multi-task CNN model trained with calibrated labels and
inferenced with image rulers. Labels calibrated by human inputs follow a
well-defined and efficient labeling task. Image rulers address varying quality
standards and provide a concrete way of interpreting raw scores from the CNN.
The model supports assessments of two of the most common artifacts in MRI:
noise and motion. It achieves accuracies of around 90%, 6% better than the best
previous method examined, and 3% better than human experts on noise assessment.
Our experiments show that label calibration, image rulers, and multi-task
training improve the model's performance and generalizability.</p>
  </details>
</details>
<details>
  <summary>82. <b>标题：Explaining neural network predictions of material strength</b></summary>
  <p><b>编号</b>：[448]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03729</p>
  <p><b>作者</b>：Ian A. Palmer,  T. Nathan Mundhenk,  Brian Gallagher,  Yong Han</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：explainable ai saliency map, helps us map features, scanning electron microscope, critical peak stress, natural image photographs</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We recently developed a deep learning method that can determine the critical
peak stress of a material by looking at scanning electron microscope (SEM)
images of the material's crystals. However, it has been somewhat unclear what
kind of image features the network is keying off of when it makes its
prediction. It is common in computer vision to employ an explainable AI
saliency map to tell one what parts of an image are important to the network's
decision. One can usually deduce the important features by looking at these
salient locations. However, SEM images of crystals are more abstract to the
human observer than natural image photographs. As a result, it is not easy to
tell what features are important at the locations which are most salient. To
solve this, we developed a method that helps us map features from important
locations in SEM images to non-abstract textures that are easier to interpret.</p>
  </details>
</details>
<details>
  <summary>83. <b>标题：Damage Estimation and Localization from Sparse Aerial Imagery</b></summary>
  <p><b>编号</b>：[449]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03708</p>
  <p><b>作者</b>：Rene Garcia Franceschini,  Jeffrey Liu,  Saurabh Amin</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：aerial images provide important situational awareness, handheld cameras lack imu information, high precision using limited data, using class activation mapping, unmanned aerial systems technology</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Aerial images provide important situational awareness for responding to
natural disasters such as hurricanes. They are well-suited for providing
information for damage estimation and localization (DEL); i.e., characterizing
the type and spatial extent of damage following a disaster. Despite recent
advances in sensing and unmanned aerial systems technology, much of
post-disaster aerial imagery is still taken by handheld DSLR cameras from
small, manned, fixed-wing aircraft. However, these handheld cameras lack IMU
information, and images are taken opportunistically post-event by operators. As
such, DEL from such imagery is still a highly manual and time-consuming
process. We propose an approach to both detect damage in aerial images and
localize it in world coordinates, with specific focus on detecting and
localizing flooding. The approach is based on using structure from motion to
relate image coordinates to world coordinates via a projective transformation,
using class activation mapping to detect the extent of damage in an image, and
applying the projective transformation to localize damage in world coordinates.
We evaluate the performance of our approach on post-event data from the 2016
Louisiana floods, and find that our approach achieves a precision of 88%. Given
this high precision using limited data, we argue that this approach is
currently viable for fast and effective DEL from handheld aerial imagery for
disaster response.</p>
  </details>
</details>
<details>
  <summary>84. <b>标题：First steps on Gamification of Lung Fluid Cells Annotations in the  Flower Domain</b></summary>
  <p><b>编号</b>：[452]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03663</p>
  <p><b>作者</b>：Sonja Kunzmann,  Christian Marzahl,  Felix Denzinger,  Christof A. Bertram,  Robert Klopfleisch,  Katharina Breininger,  Vincent Christlein,  Andreas Maier</p>
  <p><b>备注</b>：6 pages, 4 figures</p>
  <p><b>关键词</b>：transformed lung fluid cells, original lung fluid cells, pathological whole slide images, image classification network trained, annotating lung fluid cells</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Annotating data, especially in the medical domain, requires expert knowledge
and a lot of effort. This limits the amount and/or usefulness of available
medical data sets for experimentation. Therefore, developing strategies to
increase the number of annotations while lowering the needed domain knowledge
is of interest. A possible strategy is the use of gamification, that is i.e.
transforming the annotation task into a game. We propose an approach to gamify
the task of annotating lung fluid cells from pathological whole slide images.
As this domain is unknown to non-expert annotators, we transform images of
cells detected with a RetinaNet architecture to the domain of flower images.
This domain transfer is performed with a CycleGAN architecture for different
cell types. In this more assessable domain, non-expert annotators can be
(t)asked to annotate different kinds of flowers in a playful setting. In order
to provide a proof of concept, this work shows that the domain transfer is
possible by evaluating an image classification network trained on real cell
images and tested on the cell images generated by the CycleGAN network. The
classification network reaches an accuracy of 97.48% and 95.16% on the original
lung fluid cells and transformed lung fluid cells, respectively. With this
study, we lay the foundation for future research on gamification using
CycleGANs.</p>
  </details>
</details>
<h1>自然语言处理</h1>
<details>
  <summary>1. <b>标题：Detecting Depression in Thai Blog Posts: a Dataset and a Baseline</b></summary>
  <p><b>编号</b>：[50]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04574</p>
  <p><b>作者</b>：Mika Hämäläinen,  Pattama Patpong,  Khalid Alnajjar,  Niko Partanen,  Jack Rueter</p>
  <p><b>备注</b>：Workshop on Noisy User-generated Text (at EMNLP)</p>
  <p><b>关键词</b>：two different lstm based models, two different bert based models, first openly available corpus, thai bert model, several online blogs</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present the first openly available corpus for detecting depression in
Thai. Our corpus is compiled by expert verified cases of depression in several
online blogs. We experiment with two different LSTM based models and two
different BERT based models. We achieve a 77.53\% accuracy with a Thai BERT
model in detecting depression. This establishes a good baseline for future
researcher on the same corpus. Furthermore, we identify a need for Thai
embeddings that have been trained on a more varied corpus than Wikipedia. Our
corpus, code and trained models have been released openly on Zenodo.</p>
  </details>
</details>
<details>
  <summary>2. <b>标题：Sexism Prediction in Spanish and English Tweets Using Monolingual and  Multilingual BERT and Ensemble Models</b></summary>
  <p><b>编号</b>：[55]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04551</p>
  <p><b>作者</b>：Angel Felipe Magnossão de Paula,  Roberto Fray da Silva,  Ipek Baris Schlicht</p>
  <p><b>备注</b>：18 pages, presented at IberLEF: this http URL, the best scoring system at EXIST</p>
  <p><b>关键词</b>：ensemble models obtained better results, iberian languages evaluation forum, work obtained first place, best standardized values obtained, system obtained better results</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The popularity of social media has created problems such as hate speech and
sexism. The identification and classification of sexism in social media are
very relevant tasks, as they would allow building a healthier social
environment. Nevertheless, these tasks are considerably challenging. This work
proposes a system to use multilingual and monolingual BERT and data points
translation and ensemble strategies for sexism identification and
classification in English and Spanish. It was conducted in the context of the
sEXism Identification in Social neTworks shared 2021 (EXIST 2021) task,
proposed by the Iberian Languages Evaluation Forum (IberLEF). The proposed
system and its main components are described, and an in-depth hyperparameters
analysis is conducted. The main results observed were: (i) the system obtained
better results than the baseline model (multilingual BERT); (ii) ensemble
models obtained better results than monolingual models; and (iii) an ensemble
model considering all individual models and the best standardized values
obtained the best accuracies and F1-scores for both tasks. This work obtained
first place in both tasks at EXIST, with the highest accuracies (0.780 for task
1 and 0.658 for task 2) and F1-scores (F1-binary of 0.780 for task 1 and
F1-macro of 0.579 for task 2).</p>
  </details>
</details>
<details>
  <summary>3. <b>标题：AI-UPV at IberLEF-2021 DETOXIS task: Toxicity Detection in  Immigration-Related Web News Comments Using Transformers and Statistical  Models</b></summary>
  <p><b>编号</b>：[59]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04530</p>
  <p><b>作者</b>：Angel Felipe Magnossão de Paula,  Ipek Baris Schlicht</p>
  <p><b>备注</b>：20 pages. Presented at IberLEF. See this http URL</p>
  <p><b>关键词</b>：different online news articles related, bert models obtain better results, web news articles within, necessary efforts towards mitigating, iberian languages evaluation forum</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper describes our participation in the DEtection of TOXicity in
comments In Spanish (DETOXIS) shared task 2021 at the 3rd Workshop on Iberian
Languages Evaluation Forum. The shared task is divided into two related
classification tasks: (i) Task 1: toxicity detection and; (ii) Task 2: toxicity
level detection. They focus on the xenophobic problem exacerbated by the spread
of toxic comments posted in different online news articles related to
immigration. One of the necessary efforts towards mitigating this problem is to
detect toxicity in the comments. Our main objective was to implement an
accurate model to detect xenophobia in comments about web news articles within
the DETOXIS shared task 2021, based on the competition's official metrics: the
F1-score for Task 1 and the Closeness Evaluation Metric (CEM) for Task 2. To
solve the tasks, we worked with two types of machine learning models: (i)
statistical models and (ii) Deep Bidirectional Transformers for Language
Understanding (BERT) models. We obtained our best results in both tasks using
BETO, an BERT model trained on a big Spanish corpus. We obtained the 3rd place
in Task 1 official ranking with the F1-score of 0.5996, and we achieved the 6th
place in Task 2 official ranking with the CEM of 0.7142. Our results suggest:
(i) BERT models obtain better results than statistical models for toxicity
detection in text comments; (ii) Monolingual BERT models have an advantage over
multilingual BERT models in toxicity detection in text comments in their
pre-trained language.</p>
  </details>
</details>
<details>
  <summary>4. <b>标题：Ontology-based question answering over corporate structured data</b></summary>
  <p><b>编号</b>：[64]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04507</p>
  <p><b>作者</b>：Sergey Gorshkov,  Constantin Kondratiev,  Roman Shebalov</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：corporate data sources allows extracting facts, improve questions answering quality, graph data population tasks, using question answering engine, engine transforms user input</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Ontology-based approach to the Natural Language Understanding (NLU)
processing allows to improve questions answering quality in dialogue systems.
We describe our NLU engine architecture and evaluate its implementation. The
engine transforms user input into the SPARQL SELECT, ASK or INSERT query to the
knowledge graph provided by the ontology-based data virtualization platform.
The transformation is based on the lexical level of the knowledge graph built
according to the Ontolex ontology. The described approach can be applied for
graph data population tasks and to the question answering systems
implementation, including chat bots. We describe the dialogue engine for a chat
bot which can keep the conversation context and ask clarifying questions,
simulating some aspects of the human logical thinking. Our approach uses
graph-based algorithms to avoid gathering datasets, required in the neural
nets-based approaches, and provide better explainability of our models. Using
question answering engine in conjunction with data virtualization layer over
the corporate data sources allows extracting facts from the structured data to
be used in conversation.</p>
  </details>
</details>
<details>
  <summary>5. <b>标题：Topic Modeling, Clade-assisted Sentiment Analysis, and Vaccine Brand  Reputation Analysis of COVID-19 Vaccine-related Facebook Comments in the  Philippines</b></summary>
  <p><b>编号</b>：[107]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04416</p>
  <p><b>作者</b>：Jasper Kyle Catapang,  Jerome V. Cleofas</p>
  <p><b>备注</b>：Submitted to Applied Soft Computing</p>
  <p><b>关键词</b>：supervised machine learning pipeline, humorous content -- suggest, vaccine brand reputation analysis, vaccine brand reputation, national public opinion</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Vaccine hesitancy and other COVID-19-related concerns and complaints in the
Philippines are evident on social media. It is important to identify these
different topics and sentiments in order to gauge public opinion, use the
insights to develop policies, and make necessary adjustments or actions to
improve public image and reputation of the administering agency and the
COVID-19 vaccines themselves. This paper proposes a semi-supervised machine
learning pipeline to perform topic modeling, sentiment analysis, and an
analysis of vaccine brand reputation to obtain an in-depth understanding of
national public opinion of Filipinos on Facebook. The methodology makes use of
a multilingual version of Bidirectional Encoder Representations from
Transformers or BERT for topic modeling, hierarchical clustering, five
different classifiers for sentiment analysis, and cosine similarity of BERT
topic embeddings for vaccine brand reputation analysis. Results suggest that
any type of COVID-19 misinformation is an emergent property of COVID-19 public
opinion, and that the detection of COVID-19 misinformation can be an
unsupervised task. Sentiment analysis aided by hierarchical clustering reveal
that 21 of the 25 topics extrapolated by topic modeling are negative topics.
Such negative comments spike in count whenever the Department of Health in the
Philippines posts about the COVID-19 situation in other countries.
Additionally, the high numbers of laugh reactions on the Facebook posts by the
same agency -- without any humorous content -- suggest that the reactors of
these posts tend to react the way they do, not because of what the posts are
about but because of who posted them.</p>
  </details>
</details>
<details>
  <summary>6. <b>标题：Sentiment Analysis and Topic Modeling for COVID-19 Vaccine Discussions</b></summary>
  <p><b>编号</b>：[108]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04415</p>
  <p><b>作者</b>：Hui Yin,  Xiangyu Song,  Shuiqiao Yang,  Jianxin Li</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：systematically analyze public opinion towards covid, provide effective data support, exist much research work, corresponding sentimental polarities regarding, novel coronavirus disease 2019</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The outbreak of the novel Coronavirus Disease 2019 (COVID-19) has lasted for
nearly two years and caused unprecedented impacts on people's daily life around
the world. Even worse, the emergence of the COVID-19 Delta variant once again
puts the world in danger. Fortunately, many countries and companies have
started to develop coronavirus vaccines since the beginning of this disaster.
Till now, more than 20 vaccines have been approved by the World Health
Organization (WHO), bringing light to people besieged by the pandemic. The
promotion of COVID-19 vaccination around the world also brings a lot of
discussions on social media about different aspects of vaccines, such as
efficacy and security. However, there does not exist much research work to
systematically analyze public opinion towards COVID-19 vaccines. In this study,
we conduct an in-depth analysis of tweets related to the coronavirus vaccine on
Twitter to understand the trending topics and their corresponding sentimental
polarities regarding the country and vaccine levels. The results show that a
majority of people are confident in the effectiveness of vaccines and are
willing to get vaccinated. In contrast, the negative tweets are often
associated with the complaints of vaccine shortages, side effects after
injections and possible death after being vaccinated. Overall, this study
exploits popular NLP and topic modeling methods to mine people's opinions on
the COVID-19 vaccines on social media and to analyse and visualise them
objectively. Our findings can improve the readability of the noisy information
on social media and provide effective data support for the government and
policy makers.</p>
  </details>
</details>
<details>
  <summary>7. <b>标题：Towards Debiasing Temporal Sentence Grounding in Video</b></summary>
  <p><b>编号</b>：[139]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04321</p>
  <p><b>作者</b>：Hao Zhang,  Aixin Sun,  Wei Jing,  Joey Tianyi Zhou</p>
  <p><b>备注</b>：13 pages, 6 figures, 11 tables</p>
  <p><b>关键词</b>：data debiasing performs data oversampling, video ), many models tend, improving model generalization capability, vslnet achieves best results, balance moment temporal distribution</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The temporal sentence grounding in video (TSGV) task is to locate a temporal
moment from an untrimmed video, to match a language query, i.e., a sentence.
Without considering bias in moment annotations (e.g., start and end positions
in a video), many models tend to capture statistical regularities of the moment
annotations, and do not well learn cross-modal reasoning between video and
language query. In this paper, we propose two debiasing strategies, data
debiasing and model debiasing, to "force" a TSGV model to capture cross-modal
interactions. Data debiasing performs data oversampling through video
truncation to balance moment temporal distribution in train set. Model
debiasing leverages video-only and query-only models to capture the
distribution bias, and forces the model to learn cross-modal interactions.
Using VSLNet as the base model, we evaluate impact of the two strategies on two
datasets that contain out-of-distribution test instances. Results show that
both strategies are effective in improving model generalization capability.
Equipped with both debiasing strategies, VSLNet achieves best results on both
datasets.</p>
  </details>
</details>
<details>
  <summary>8. <b>标题：Auto-Encoding Knowledge Graph for Unsupervised Medical Report Generation</b></summary>
  <p><b>编号</b>：[140]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04318</p>
  <p><b>作者</b>：Fenglin Liu,  Chenyu You,  Xian Wu,  Shen Ge,  Sheng Wang,  Xu Sun</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：unsupervised kgae generates desirable medical reports without using, unsupervised model knowledge graph auto, driven encoder projects medical images, receiving growing research interests, existing approaches mainly adopt</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Medical report generation, which aims to automatically generate a long and
coherent report of a given medical image, has been receiving growing research
interests. Existing approaches mainly adopt a supervised manner and heavily
rely on coupled image-report pairs. However, in the medical domain, building a
large-scale image-report paired dataset is both time-consuming and expensive.
To relax the dependency on paired data, we propose an unsupervised model
Knowledge Graph Auto-Encoder (KGAE) which accepts independent sets of images
and reports in training. KGAE consists of a pre-constructed knowledge graph, a
knowledge-driven encoder and a knowledge-driven decoder. The knowledge graph
works as the shared latent space to bridge the visual and textual domains; The
knowledge-driven encoder projects medical images and reports to the
corresponding coordinates in this latent space and the knowledge-driven decoder
generates a medical report given a coordinate in this space. Since the
knowledge-driven encoder and decoder can be trained with independent sets of
images and reports, KGAE is unsupervised. The experiments show that the
unsupervised KGAE generates desirable medical reports without using any
image-report training pairs. Moreover, KGAE can also work in both
semi-supervised and supervised settings, and accept paired images and reports
in training. By further fine-tuning with image-report pairs, KGAE consistently
outperforms the current state-of-the-art models on two datasets.</p>
  </details>
</details>
<details>
  <summary>9. <b>标题：JaMIE: A Pipeline Japanese Medical Information Extraction System</b></summary>
  <p><b>编号</b>：[167]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04261</p>
  <p><b>作者</b>：Fei Cheng,  Shuntaro Yada,  Ribeka Tanaka,  Eiji Aramaki,  Sadao Kurohashi</p>
  <p><b>备注</b>：8 pages</p>
  <p><b>关键词</b>：empirical results show accurate analyzing performance, access natural language processing toolkit, separately annotating two different types, latest contextual embedding models, novel relation annotation schema</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present an open-access natural language processing toolkit for Japanese
medical information extraction. We first propose a novel relation annotation
schema for investigating the medical and temporal relations between medical
entities in Japanese medical reports. We experiment with the practical
annotation scenarios by separately annotating two different types of reports.
We design a pipeline system with three components for recognizing medical
entities, classifying entity modalities, and extracting relations. The
empirical results show accurate analyzing performance and suggest the
satisfactory annotation quality, the effective annotation strategy for
targeting report types, and the superiority of the latest contextual embedding
models.</p>
  </details>
</details>
<details>
  <summary>10. <b>标题：TaCL: Improving BERT Pre-training with Token-aware Contrastive Learning</b></summary>
  <p><b>编号</b>：[187]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04198</p>
  <p><b>作者</b>：Yixuan Su,  Fangyu Liu,  Zaiqiao Meng,  Lei Shu,  Ehsan Shareghi,  Nigel Collier</p>
  <p><b>备注</b>：Work in progress</p>
  <p><b>关键词</b>：conduct detailed ablation study, aware contrastive learning ),, demand discriminative semantic meanings, trained mlms often output, natural language understanding</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Masked language models (MLMs) such as BERT and RoBERTa have revolutionized
the field of Natural Language Understanding in the past few years. However,
existing pre-trained MLMs often output an anisotropic distribution of token
representations that occupies a narrow subset of the entire representation
space. Such token representations are not ideal, especially for tasks that
demand discriminative semantic meanings of distinct tokens. In this work, we
propose TaCL (Token-aware Contrastive Learning), a novel continual pre-training
approach that encourages BERT to learn an isotropic and discriminative
distribution of token representations. TaCL is fully unsupervised and requires
no additional data. We extensively test our approach on a wide range of English
and Chinese benchmarks. The results show that TaCL brings consistent and
notable improvements over the original BERT model. Furthermore, we conduct
detailed ablation study and careful analysis to reveal the merits and
inner-workings of our approach.</p>
  </details>
</details>
<details>
  <summary>11. <b>标题：Retrieving Speaker Information from Personalized Acoustic Models for  Speech Recognition</b></summary>
  <p><b>编号</b>：[188]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04194</p>
  <p><b>作者</b>：Salima Mdhaffar,  Jean-François Bonastre,  Marc Tommasi,  Natalia Tomashenko,  Yannick Estève</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：build speaker adapted speech recognition system, neural acoustic model locally adapted, powerful personal devices capable, identified almost surely using, speaker verification performs well</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The widespread of powerful personal devices capable of collecting voice of
their users has opened the opportunity to build speaker adapted speech
recognition system (ASR) or to participate to collaborative learning of ASR. In
both cases, personalized acoustic models (AM), i.e. fine-tuned AM with specific
speaker data, can be built. A question that naturally arises is whether the
dissemination of personalized acoustic models can leak personal information. In
this paper, we show that it is possible to retrieve the gender of the speaker,
but also his identity, by just exploiting the weight matrix changes of a neural
acoustic model locally adapted to this speaker. Incidentally we observe
phenomena that may be useful towards explainability of deep neural networks in
the context of speech processing. Gender can be identified almost surely using
only the first layers and speaker verification performs well when using
middle-up layers. Our experimental study on the TED-LIUM 3 dataset with
HMM/TDNN models shows an accuracy of 95% for gender detection, and an Equal
Error Rate of 9.07% for a speaker verification task by only exploiting the
weights from personalized models that could be exchanged instead of user data.</p>
  </details>
</details>
<details>
  <summary>12. <b>标题：Machine-in-the-Loop Rewriting for Creative Image Captioning</b></summary>
  <p><b>编号</b>：[189]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04193</p>
  <p><b>作者</b>：Vishakh Padmakumar,  He He</p>
  <p><b>备注</b>：Novel Ideas in Learning-to-Learn through Interaction - Workshop @ EMNLP 2021</p>
  <p><b>关键词</b>：baseline infilling language model, party evaluation shows, modifies specified spans, limited success since, creative image captioning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Machine-in-the-loop writing aims to enable humans to collaborate with models
to complete their writing tasks more effectively. Prior work has found that
providing humans a machine-written draft or sentence-level continuations has
limited success since the generated text tends to deviate from humans'
intention. To allow the user to retain control over the content, we train a
rewriting model that, when prompted, modifies specified spans of text within
the user's original draft to introduce descriptive and figurative elements
locally in the text. We evaluate the model on its ability to collaborate with
humans on the task of creative image captioning. On a user study through Amazon
Mechanical Turk, our model is rated to be more helpful than a baseline
infilling language model. In addition, third-party evaluation shows that users
write more descriptive and figurative captions when collaborating with our
model compared to completing the task alone.</p>
  </details>
</details>
<details>
  <summary>13. <b>标题：A Word on Machine Ethics: A Response to Jiang et al. (2021)</b></summary>
  <p><b>编号</b>：[199]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04158</p>
  <p><b>作者</b>：Zeerak Talat,  Hagen Blix,  Josef Valvoda,  Maya Indira Ganesh,  Ryan Cotterell,  Adina Williams</p>
  <p><b>备注</b>：11 pages, 2 figures, submitting soon to ACL Rolling Review</p>
  <p><b>关键词</b>：machine ethics could usefully proceed, longest standing intellectual endeavors, recently proposed delphi model, single case study, examine broader issues</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Ethics is one of the longest standing intellectual endeavors of humanity. In
recent years, the fields of AI and NLP have attempted to wrangle with how
learning systems that interact with humans should be constrained to behave
ethically. One proposal in this vein is the construction of morality models
that can take in arbitrary text and output a moral judgment about the situation
described. In this work, we focus on a single case study of the recently
proposed Delphi model and offer a critique of the project's proposed method of
automating morality judgments. Through an audit of Delphi, we examine broader
issues that would be applicable to any similar attempt. We conclude with a
discussion of how machine ethics could usefully proceed, by focusing on current
and near-future uses of technology, in a way that centers around transparency,
democratic values, and allows for straightforward accountability.</p>
  </details>
</details>
<details>
  <summary>14. <b>标题：Look at the Variance! Efficient Black-box Explanations with Sobol-based  Sensitivity Analysis</b></summary>
  <p><b>编号</b>：[206]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04138</p>
  <p><b>作者</b>：Thomas Fel,  Remi Cadene,  Mathieu Chalvidal,  Matthieu Cord,  David Vigouroux,  Thomas Serre</p>
  <p><b>备注</b>：NeurIPS2021</p>
  <p><b>关键词</b>：box methods -- even surpassing, using perturbation masks coupled, proposed method leads, novel attribution method, computing time compared</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We describe a novel attribution method which is grounded in Sensitivity
Analysis and uses Sobol indices. Beyond modeling the individual contributions
of image regions, Sobol indices provide an efficient way to capture
higher-order interactions between image regions and their contributions to a
neural network's prediction through the lens of variance. We describe an
approach that makes the computation of these indices efficient for
high-dimensional problems by using perturbation masks coupled with efficient
estimators to handle the high dimensionality of images. Importantly, we show
that the proposed method leads to favorable scores on standard benchmarks for
vision (and language models) while drastically reducing the computing time
compared to other black-box methods -- even surpassing the accuracy of
state-of-the-art white-box methods which require access to internal
representations. Our code is freely available:
this https URL</p>
  </details>
</details>
<details>
  <summary>15. <b>标题：NLP From Scratch Without Large-Scale Pretraining: A Simple and Efficient  Framework</b></summary>
  <p><b>编号</b>：[210]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04130</p>
  <p><b>作者</b>：Xingcheng Yao,  Yanan Zheng,  Xiaocong Yang,  Zhilin Yang</p>
  <p><b>备注</b>：13 pages, 5 figures</p>
  <p><b>关键词</b>：many nlp tasks due, tlm achieves results better, tlm uses task data, labeled task data, pretrained language models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Pretrained language models have become the standard approach for many NLP
tasks due to strong performance, but they are very expensive to train. We
propose a simple and efficient learning framework, TLM, that does not rely on
large-scale pretraining. Given some labeled task data and a large general
corpus, TLM uses task data as queries to retrieve a tiny subset of the general
corpus and jointly optimizes the task objective and the language modeling
objective from scratch. On eight classification datasets in four domains, TLM
achieves results better than or similar to pretrained language models (e.g.,
RoBERTa-Large) while reducing the training FLOPs by two orders of magnitude.
With high accuracy and efficiency, we hope TLM will contribute to democratizing
NLP and expediting its development.</p>
  </details>
</details>
<details>
  <summary>16. <b>标题：Developing neural machine translation models for Hungarian-English</b></summary>
  <p><b>编号</b>：[221]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04099</p>
  <p><b>作者</b>：Attila Nagy</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：propose 5 different augmentation methods, evaluating different data augmentation methods, detailed exploratory data analysis, proposed data augmentation techniques, detailed literature review</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>I train models for the task of neural machine translation for
English-Hungarian and Hungarian-English, using the Hunglish2 corpus. The main
contribution of this work is evaluating different data augmentation methods
during the training of NMT models. I propose 5 different augmentation methods
that are structure-aware, meaning that instead of randomly selecting words for
blanking or replacement, the dependency tree of sentences is used as a basis
for augmentation. I start my thesis with a detailed literature review on neural
networks, sequential modeling, neural machine translation, dependency parsing
and data augmentation. After a detailed exploratory data analysis and
preprocessing of the Hunglish2 corpus, I perform experiments with the proposed
data augmentation techniques. The best model for Hungarian-English achieves a
BLEU score of 33.9, while the best model for English-Hungarian achieves a BLEU
score of 28.6.</p>
  </details>
</details>
<details>
  <summary>17. <b>标题：Variance-Aware Machine Translation Test Sets</b></summary>
  <p><b>编号</b>：[232]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04079</p>
  <p><b>作者</b>：Runzhe Zhan,  Xuebo Liu,  Derek F. Wong,  Lidia S. Chao</p>
  <p><b>备注</b>：Accepted to NeurIPS 2021 Datasets and Benchmarks Track</p>
  <p><b>关键词</b>：human judgement across mainstream language pairs, vat ), covering 35 translation directions, current mt test sets without, constructing future mt test sets, original wmt test sets</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We release 70 small and discriminative test sets for machine translation (MT)
evaluation called variance-aware test sets (VAT), covering 35 translation
directions from WMT16 to WMT20 competitions. VAT is automatically created by a
novel variance-aware filtering method that filters the indiscriminative test
instances of the current MT test sets without any human labor. Experimental
results show that VAT outperforms the original WMT test sets in terms of the
correlation with human judgement across mainstream language pairs and test
sets. Further analysis on the properties of VAT reveals the challenging
linguistic features (e.g., translation of low-frequency words and proper nouns)
for competitive MT systems, providing guidance for constructing future MT test
sets. The test sets and the code for preparing variance-aware MT test sets are
freely available at this https URL .</p>
  </details>
</details>
<details>
  <summary>18. <b>标题：How does a Pre-Trained Transformer Integrate Contextual Keywords?  Application to Humanitarian Computing</b></summary>
  <p><b>编号</b>：[245]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04052</p>
  <p><b>作者</b>：Barriere Valentin,  Jacquet Guillaume</p>
  <p><b>备注</b>：Oral ISCRAM2021</p>
  <p><b>关键词</b>：semantic information encoded inside, proposed neural network approach, metadata usually requires dealing, still undoubtedly learning, crisis event type</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In a classification task, dealing with text snippets and metadata usually
requires dealing with multimodal approaches. When those metadata are textual,
it is tempting to use them intrinsically with a pre-trained transformer, in
order to leverage the semantic information encoded inside the model. This paper
describes how to improve a humanitarian classification task by adding the
crisis event type to each tweet to be classified. Based on additional
experiments of the model weights and behavior, it identifies how the proposed
neural network approach is partially over-fitting the particularities of the
Crisis Benchmark, to better highlight how the model is still undoubtedly
learning to use and take advantage of the metadata's textual semantics.</p>
  </details>
</details>
<details>
  <summary>19. <b>标题：Information Extraction from Visually Rich Documents with Font Style  Embeddings</b></summary>
  <p><b>编号</b>：[248]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04045</p>
  <p><b>作者</b>：Ismail Oussaid,  William Vanhuffel,  Pirashanth Ratnamogan,  Mhamed Hajaiej,  Alexis Mathey,  Thomas Gilles</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：using token style attributes based embedding instead, e native pdf documents )., world complex datasets demonstrate, approaches combining computer vision, raw visual embedding</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Information extraction (IE) from documents is an intensive area of research
with a large set of industrial applications. Current state-of-the-art methods
focus on scanned documents with approaches combining computer vision, natural
language processing and layout representation. We propose to challenge the
usage of computer vision in the case where both token style and visual
representation are available (i.e native PDF documents). Our experiments on
three real-world complex datasets demonstrate that using token style attributes
based embedding instead of a raw visual embedding in LayoutLM model is
beneficial. Depending on the dataset, such an embedding yields an improvement
of 0.18% to 2.29% in the weighted F1-score with a decrease of 30.7% in the
final number of trainable parameters of the model, leading to an improvement in
both efficiency and effectiveness.</p>
  </details>
</details>
<details>
  <summary>20. <b>标题：Meta-TTS: Meta-Learning for Few-Shot Speaker Adaptive Text-to-Speech</b></summary>
  <p><b>编号</b>：[250]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04040</p>
  <p><b>作者</b>：Sung-Feng Huang,  Chyi-Jiunn Lin,  Hung-yi Lee</p>
  <p><b>备注</b>：under review</p>
  <p><b>关键词</b>：speaker encoding methods encode enrollment utterances, shot speaker adaptation tasks quickly, speaker adaptation methods fine, speaker encoding method baseline, speaker adaptation method baseline</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Personalizing a speech synthesis system is a highly desired application,
where the system can generate speech with the user's voice with rare enrolled
recordings. There are two main approaches to build such a system in recent
works: speaker adaptation and speaker encoding. On the one hand, speaker
adaptation methods fine-tune a trained multi-speaker text-to-speech (TTS) model
with few enrolled samples. However, they require at least thousands of
fine-tuning steps for high-quality adaptation, making it hard to apply on
devices. On the other hand, speaker encoding methods encode enrollment
utterances into a speaker embedding. The trained TTS model can synthesize the
user's speech conditioned on the corresponding speaker embedding. Nevertheless,
the speaker encoder suffers from the generalization gap between the seen and
unseen speakers.
In this paper, we propose applying a meta-learning algorithm to the speaker
adaptation method. More specifically, we use Model Agnostic Meta-Learning
(MAML) as the training algorithm of a multi-speaker TTS model, which aims to
find a great meta-initialization to adapt the model to any few-shot speaker
adaptation tasks quickly. Therefore, we can also adapt the meta-trained TTS
model to unseen speakers efficiently. Our experiments compare the proposed
method (Meta-TTS) with two baselines: a speaker adaptation method baseline and
a speaker encoding method baseline. The evaluation results show that Meta-TTS
can synthesize high speaker-similarity speech from few enrollment samples with
fewer adaptation steps than the speaker adaptation baseline and outperforms the
speaker encoding baseline under the same training scheme. When the speaker
encoder of the baseline is pre-trained with extra 8371 speakers of data,
Meta-TTS can still outperform the baseline on LibriTTS dataset and achieve
comparable results on VCTK dataset.</p>
  </details>
</details>
<details>
  <summary>21. <b>标题：MotifClass: Weakly Supervised Text Classification with Higher-order  Metadata Information</b></summary>
  <p><b>编号</b>：[255]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04022</p>
  <p><b>作者</b>：Yu Zhang,  Shweta Garg,  Yu Meng,  Xiusi Chen,  Jiawei Han</p>
  <p><b>备注</b>：9 pages; Accepted to WSDM 2022</p>
  <p><b>关键词</b>：existing weakly supervised text classification approaches, help weakly supervised text classification, existing approaches leverage textual information, weakly supervised text classification, labeled training samples based</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We study the problem of weakly supervised text classification, which aims to
classify text documents into a set of pre-defined categories with category
surface names only and without any annotated training document provided. Most
existing approaches leverage textual information in each document. However, in
many domains, documents are accompanied by various types of metadata (e.g.,
authors, venue, and year of a research paper). These metadata and their
combinations may serve as strong category indicators in addition to textual
contents. In this paper, we explore the potential of using metadata to help
weakly supervised text classification. To be specific, we model the
relationships between documents and metadata via a heterogeneous information
network. To effectively capture higher-order structures in the network, we use
motifs to describe metadata combinations. We propose a novel framework, named
MotifClass, which (1) selects category-indicative motif instances, (2)
retrieves and generates pseudo-labeled training samples based on category names
and indicative motif instances, and (3) trains a text classifier using the
pseudo training data. Extensive experiments on real-world datasets demonstrate
the superior performance of MotifClass to existing weakly supervised text
classification approaches. Further analysis shows the benefit of considering
higher-order metadata information in our framework.</p>
  </details>
</details>
<details>
  <summary>22. <b>标题：Profitable Trade-Off Between Memory and Performance In Multi-Domain  Chatbot Architectures</b></summary>
  <p><b>编号</b>：[281]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03963</p>
  <p><b>作者</b>：D Emre Tasar,  Sukru Ozan,  M Fatih Akca,  Oguzhan Olmez,  Semih Gulum,  Secilay Kutay,  Ceren Belhan</p>
  <p><b>备注</b>：in Turkish language. ICADA 21 1st International Conference on Artificial Intelligence and Data Science Nov 26-Nov 28 2021 Izmir Katip Celebi University Izmir, Turkey</p>
  <p><b>关键词</b>：three separate data sets covering different fields, bert models trained specifically, natural language processing, natural language processing, masking method applied</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Text classification problem is a very broad field of study in the field of
natural language processing. In short, the text classification problem is to
determine which of the previously determined classes the given text belongs to.
Successful studies have been carried out in this field in the past studies. In
the study, Bidirectional Encoder Representations for Transformers (BERT), which
is a frequently preferred method for solving the classification problem in the
field of natural language processing, is used. By solving classification
problems through a single model to be used in a chatbot architecture, it is
aimed to alleviate the load on the server that will be created by more than one
model used for solving more than one classification problem. At this point,
with the masking method applied during the estimation of a single BERT model,
which was created for classification in more than one subject, the estimation
of the model was provided on a problem-based basis. Three separate data sets
covering different fields from each other are divided by various methods in
order to complicate the problem, and classification problems that are very
close to each other in terms of field are also included in this way. The
dataset used in this way consists of five classification problems with 154
classes. A BERT model containing all classification problems and other BERT
models trained specifically for the problems were compared with each other in
terms of performance and the space they occupied on the server.</p>
  </details>
</details>
<details>
  <summary>23. <b>标题：Towards Building ASR Systems for the Next Billion Users</b></summary>
  <p><b>编号</b>：[287]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03945</p>
  <p><b>作者</b>：Tahir Javed,  Sumanth Doddapaneni,  Abhigyan Raman,  Kaushal Santosh Bhogale,  Gowtham Ramesh,  Anoop Kunchukuttan,  Pratyush Kumar,  Mitesh M. Khapra</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：attention heads often pay attention within small local windows, make multiple contributions towards building asr systems, building asr systems, similar sounding phonemes, representations across layers</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent methods in speech and language technology pretrain very LARGE models
which are fine-tuned for specific tasks. However, the benefits of such LARGE
models are often limited to a few resource rich languages of the world. In this
work, we make multiple contributions towards building ASR systems for low
resource languages from the Indian subcontinent. First, we curate 17,000 hours
of raw speech data for 40 Indian languages from a wide variety of domains
including education, news, technology, and finance. Second, using this raw
speech data we pretrain several variants of wav2vec style models for 40 Indian
languages. Third, we analyze the pretrained models to find key features:
codebook vectors of similar sounding phonemes are shared across languages,
representations across layers are discriminative of the language family, and
attention heads often pay attention within small local windows. Fourth, we
fine-tune this model for downstream ASR for 9 languages and obtain
state-of-the-art results on 3 public datasets, including on very low-resource
languages such as Sinhala and Nepali. Our work establishes that multilingual
pretraining is an effective strategy for building ASR systems for the
linguistically diverse speakers of the Indian subcontinent.</p>
  </details>
</details>
<details>
  <summary>24. <b>标题：Transformer Based Bengali Chatbot Using General Knowledge Dataset</b></summary>
  <p><b>编号</b>：[292]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03937</p>
  <p><b>作者</b>：Abu Kaisar Mohammad Masum,  Sheikh Abujar,  Sharmin Akter,  Nushrat Jahan Ria,  Syed Akhter Hossain</p>
  <p><b>备注</b>：4 pages, 3 figures, supplemental materials</p>
  <p><b>关键词</b>：bengali general knowledge question answer, bengali general knowledge chatbot based, model reduces training time compared, deep neural models superior, rnn model regularly used</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>An AI chatbot provides an impressive response after learning from the trained
dataset. In this decade, most of the research work demonstrates that deep
neural models superior to any other model. RNN model regularly used for
determining the sequence-related problem like a question and it answers. This
approach acquainted with everyone as seq2seq learning. In a seq2seq model
mechanism, it has encoder and decoder. The encoder embedded any input sequence,
and the decoder embedded output sequence. For reinforcing the seq2seq model
performance, attention mechanism added into the encoder and decoder. After
that, the transformer model has introduced itself as a high-performance model
with multiple attention mechanism for solving the sequence-related dilemma.
This model reduces training time compared with RNN based model and also
achieved state-of-the-art performance for sequence transduction. In this
research, we applied the transformer model for Bengali general knowledge
chatbot based on the Bengali general knowledge Question Answer (QA) dataset. It
scores 85.0 BLEU on the applied QA data. To check the comparison of the
transformer model performance, we trained the seq2seq model with attention on
our dataset that scores 23.5 BLEU.</p>
  </details>
</details>
<details>
  <summary>25. <b>标题：Tip-Adapter: Training-free CLIP-Adapter for Better Vision-Language  Modeling</b></summary>
  <p><b>编号</b>：[296]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03930</p>
  <p><b>作者</b>：Renrui Zhang,  Rongyao Fang,  Peng Gao,  Wei Zhang,  Kunchang Li,  Jifeng Dai,  Yu Qiao,  Hongsheng Li</p>
  <p><b>备注</b>：preprints</p>
  <p><b>关键词</b>：process still needs extra training, value cache model constructed, lightweight residual feature adapter, performed adapter weights without, learning visual representations</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Contrastive Vision-Language Pre-training, known as CLIP, has provided a new
paradigm for learning visual representations by using large-scale contrastive
image-text pairs. It shows impressive performance on zero-shot knowledge
transfer to downstream tasks. To further enhance CLIP's few-shot capability,
CLIP-Adapter proposed to fine-tune a lightweight residual feature adapter and
significantly improves the performance for few-shot classification. However,
such a process still needs extra training and computational resources. In this
paper, we propose \textbf{T}raining-Free CL\textbf{IP}-\textbf{Adapter}
(\textbf{Tip-Adapter}), which not only inherits CLIP's training-free advantage
but also performs comparably or even better than CLIP-Adapter. Tip-Adapter does
not require any back propagation for training the adapter, but creates the
weights by a key-value cache model constructed from the few-shot training set.
In this non-parametric manner, Tip-Adapter acquires well-performed adapter
weights without any training, which is both efficient and effective. Moreover,
the performance of Tip-Adapter can be further boosted by fine-tuning such
properly initialized adapter for only a few epochs with super-fast convergence
speed. We conduct extensive experiments of few-shot classification on ImageNet
and other 10 datasets to demonstrate the superiority of proposed Tip-Adapter.
The code will be released at \url{this https URL}.</p>
  </details>
</details>
<details>
  <summary>26. <b>标题：Distinguishing Commercial from Editorial Content in News</b></summary>
  <p><b>编号</b>：[301]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03916</p>
  <p><b>作者</b>：Timo Kats,  Peter van der Putten,  Jasper Schelling</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：four different dutch news sources, also analyzed model coefficients, successful machine learning model, machine learning model, generate additional insights</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>How can we distinguish commercial from editorial content in news, or more
specifically, differentiate between advertorials and regular news articles? An
advertorial is a commercial message written and formatted as an article, making
it harder for readers to recognize these as advertising, despite the use of
disclaimers. In our research we aim to differentiate the two using a machine
learning model, and a lexicon derived from it. This was accomplished by
scraping 1.000 articles and 1.000 advertorials from four different Dutch news
sources and classifying these based on textual features. With this setup our
most successful machine learning model had an accuracy of just over $90\%$. To
generate additional insights into differences between news and advertorial
language, we also analyzed model coefficients and explored the corpus through
co-occurrence networks and t-SNE graphs.</p>
  </details>
</details>
<details>
  <summary>27. <b>标题：Linguistic Cues of Deception in a Multilingual April Fools' Day Context</b></summary>
  <p><b>编号</b>：[303]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03913</p>
  <p><b>作者</b>：Katerina Papantoniou,  Panagiotis Papadakos,  Giorgos Flouris,  Dimitris Plexousakis</p>
  <p><b>备注</b>：accepted for publication in Eighth Italian Conference on Computational Linguistics (CLIC-it 2021)</p>
  <p><b>关键词</b>：rich linguistic feature set, afd collection currently available, testing various monolingual, established ground truth, deceptive april fools</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this work we consider the collection of deceptive April Fools' Day(AFD)
news articles as a useful addition in existing datasets for deception detection
tasks. Such collections have an established ground truth and are relatively
easy to construct across languages. As a result, we introduce a corpus that
includes diachronic AFD and normal articles from Greek newspapers and news
websites. On top of that, we build a rich linguistic feature set, and analyze
and compare its deception cues with the only AFD collection currently
available, which is in English. Following a current research thread, we also
discuss the individualism/collectivism dimension in deception with respect to
these two datasets. Lastly, we build classifiers by testing various monolingual
and crosslingual settings. The results showcase that AFD datasets can be
helpful in deception detection studies, and are in alignment with the
observations of other deception detection works.</p>
  </details>
</details>
<details>
  <summary>28. <b>标题：Focusing on Possible Named Entities in Active Named Entity Label  Acquisition</b></summary>
  <p><b>编号</b>：[324]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03837</p>
  <p><b>作者</b>：Ali Osman Berk Sapci,  Oznur Tastan,  Reyyan Yeniterzi</p>
  <p><b>备注</b>：20 pages, 8 figures</p>
  <p><b>关键词</b>：trained language models achieve good predictive performances, annotation cost without sacrificing model performance, propose al sentence query evaluation functions, designing effective al querying methods, based cost evaluation strategies</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Named entity recognition (NER) aims to identify mentions of named entities in
an unstructured text and classify them into the predefined named entity
classes. Even though deep learning-based pre-trained language models achieve
good predictive performances, many domain-specific NERtasks still require a
sufficient amount of labeled data. Active learning (AL), a general framework
for the label acquisition problem, has been used for the NER tasks to minimize
the annotation cost without sacrificing model performance. However, heavily
imbalanced class distribution of tokens introduces challenges in designing
effective AL querying methods for NER. We propose AL sentence query evaluation
functions which pay more attention to possible positive tokens, and evaluate
these proposed functions with both sentence-based and token-based cost
evaluation strategies. We also propose a better data-driven normalization
approach to penalize too long or too short sentences. Our experiments on three
datasets from different domains reveal that the proposed approaches reduce the
number of annotated tokens while achieving better or comparable prediction
performance with conventional methods.</p>
  </details>
</details>
<details>
  <summary>29. <b>标题：Analyzing Architectures for Neural Machine Translation Using Low  Computational Resources</b></summary>
  <p><b>编号</b>：[333]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03813</p>
  <p><b>作者</b>：Aditya Mandke,  Onkar Litake,  Dipali Kadam</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：took comparatively less time, neural machine translation, natural language processing, lstm performed well, fewer bleu scores</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>With the recent developments in the field of Natural Language Processing,
there has been a rise in the use of different architectures for Neural Machine
Translation. Transformer architectures are used to achieve state-of-the-art
accuracy, but they are very computationally expensive to train. Everyone cannot
have such setups consisting of high-end GPUs and other resources. We train our
models on low computational resources and investigate the results. As expected,
transformers outperformed other architectures, but there were some surprising
results. Transformers consisting of more encoders and decoders took more time
to train but had fewer BLEU scores. LSTM performed well in the experiment and
took comparatively less time to train than transformers, making it suitable to
use in situations having time constraints.</p>
  </details>
</details>
<details>
  <summary>30. <b>标题：Finnish Dialect Identification: The Effect of Audio and Text</b></summary>
  <p><b>编号</b>：[336]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03800</p>
  <p><b>作者</b>：Mika Hämäläinen,  Khalid Alnajjar,  Niko Partanen,  Jack Rueter</p>
  <p><b>备注</b>：EMNLP 2021</p>
  <p><b>关键词</b>：23 different dialects, multiple dialects, speaker based, results show, released openly</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Finnish is a language with multiple dialects that not only differ from each
other in terms of accent (pronunciation) but also in terms of morphological
forms and lexical choice. We present the first approach to automatically detect
the dialect of a speaker based on a dialect transcript and transcript with
audio recording in a dataset consisting of 23 different dialects. Our results
show that the best accuracy is received by combining both of the modalities, as
text only reaches to an overall accuracy of 57\%, where as text and audio reach
to 85\%. Our code, models and data have been released openly on Github and
Zenodo.</p>
  </details>
</details>
<details>
  <summary>31. <b>标题：Privacy attacks for automatic speech recognition acoustic models in a  federated learning framework</b></summary>
  <p><b>编号</b>：[348]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03777</p>
  <p><b>作者</b>：Natalia Tomashenko,  Salima Mdhaffar,  Marc Tommasi,  Yannick Estève,  Jean-François Bonastre</p>
  <p><b>备注</b>：Submitted to ICASSP 2022</p>
  <p><b>关键词</b>：personalized speaker adapted neural network acoustic models, updated personalized models without access, develop two attack models, provide equal error rate, lium 3 corpus demonstrate</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper investigates methods to effectively retrieve speaker information
from the personalized speaker adapted neural network acoustic models (AMs) in
automatic speech recognition (ASR). This problem is especially important in the
context of federated learning of ASR acoustic models where a global model is
learnt on the server based on the updates received from multiple clients. We
propose an approach to analyze information in neural network AMs based on a
neural network footprint on the so-called Indicator dataset. Using this method,
we develop two attack models that aim to infer speaker identity from the
updated personalized models without access to the actual users' speech data.
Experiments on the TED-LIUM 3 corpus demonstrate that the proposed approaches
are very effective and can provide equal error rate (EER) of 1-2%.</p>
  </details>
</details>
<details>
  <summary>32. <b>标题：Leveraging Sentiment Analysis Knowledge to Solve Emotion Detection Tasks</b></summary>
  <p><b>编号</b>：[370]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03715</p>
  <p><b>作者</b>：Maude Nguyen-The,  Guillaume-Alexandre Bilodeau,  Jan Rockemann</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：multiple natural language processing applications, simple sentiment analysis tasks, simple polarity sentiment analysis, understanding underlying sentiment, large scale dataset</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Identifying and understanding underlying sentiment or emotions in text is a
key component of multiple natural language processing applications. While
simple polarity sentiment analysis is a well-studied subject, fewer advances
have been made in identifying more complex, finer-grained emotions using only
textual data. In this paper, we present a Transformer-based model with a Fusion
of Adapter layers which leverages knowledge from more simple sentiment analysis
tasks to improve the emotion detection task on large scale dataset, such as
CMU-MOSEI, using the textual modality only. Results show that our proposed
method is competitive with other approaches. We obtained state-of-the-art
results for emotion recognition on CMU-MOSEI even while using only the textual
modality.</p>
  </details>
</details>
<details>
  <summary>33. <b>标题：Anagrammatic quotients of free groups</b></summary>
  <p><b>编号</b>：[407]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04517</p>
  <p><b>作者</b>：Eric Stubley</p>
  <p><b>备注</b>：14 pages, 7 of which are a long table of anagrams. Comments very welcome!</p>
  <p><b>关键词</b>：24 missing commutators involve, sowpods scrabble dictionary witnessing, possible 325 commutators, surprisingly simple presentation, english language anagrams</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We determine the structure of the quotient of the free group on 26 generators
by English language anagrams. This group admits a surprisingly simple
presentation as a quotient of the free group by 301 of the possible 325
commutators of pairs of generators; all of the 24 missing commutators involve
at least one of the letters j, q, x, z. We describe the algorithm which can be
used to determine this group given any dictionary, and provide examples from
the SOWPODS scrabble dictionary witnessing the 301 commutators found.</p>
  </details>
</details>
<h1>机器学习</h1>
<details>
  <summary>1. <b>标题：Efficiently Learning Any One Hidden Layer ReLU Network From Queries</b></summary>
  <p><b>编号</b>：[1]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04727</p>
  <p><b>作者</b>：Sitan Chen,  Adam R Klivans,  Raghu Meka</p>
  <p><b>备注</b>：To appear in Advances in Neural Information Processing Systems (NeurIPS 2021)</p>
  <p><b>关键词</b>：learning arbitrary one hidden layer neural networks activations provided black, f '$ achieving low square loss relative, arbitrary one hidden layer neural network, learning neural networks, overparameterized setting ).</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Model extraction attacks have renewed interest in the classic problem of
learning neural networks from queries. In this work we give the first
polynomial-time algorithm for learning arbitrary one hidden layer neural
networks activations provided black-box access to the network. Formally, we
show that if $F$ is an arbitrary one hidden layer neural network with ReLU
activations, there is an algorithm with query complexity and running time that
is polynomial in all parameters that outputs a network $F'$ achieving low
square loss relative to $F$ with respect to the Gaussian measure. While a
number of works in the security literature have proposed and empirically
demonstrated the effectiveness of certain algorithms for this problem, ours is
the first with fully polynomial-time guarantees of efficiency even for
worst-case networks (in particular our algorithm succeeds in the
overparameterized setting).</p>
  </details>
</details>
<details>
  <summary>2. <b>标题：Estimating High Order Gradients of the Data Distribution by Denoising</b></summary>
  <p><b>编号</b>：[2]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04726</p>
  <p><b>作者</b>：Chenlin Meng,  Yang Song,  Wenzhe Li,  Stefano Ermon</p>
  <p><b>备注</b>：NeurIPS 2021</p>
  <p><b>关键词</b>：higher order derivatives provide additional local information, langevin dynamics via ozaki discretization, directly estimate high order derivatives, estimate higher order derivatives, approximate second order derivatives</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The first order derivative of a data density can be estimated efficiently by
denoising score matching, and has become an important component in many
applications, such as image generation and audio synthesis. Higher order
derivatives provide additional local information about the data distribution
and enable new applications. Although they can be estimated via automatic
differentiation of a learned density model, this can amplify estimation errors
and is expensive in high dimensional settings. To overcome these limitations,
we propose a method to directly estimate high order derivatives (scores) of a
data density from samples. We first show that denoising score matching can be
interpreted as a particular case of Tweedie's formula. By leveraging Tweedie's
formula on higher order moments, we generalize denoising score matching to
estimate higher order derivatives. We demonstrate empirically that models
trained with the proposed method can approximate second order derivatives more
efficiently and accurately than via automatic differentiation. We show that our
models can be used to quantify uncertainty in denoising and to improve the
mixing speed of Langevin dynamics via Ozaki discretization for sampling
synthetic data and natural images.</p>
  </details>
</details>
<details>
  <summary>3. <b>标题：SustainBench: Benchmarks for Monitoring the Sustainable Development  Goals with Machine Learning</b></summary>
  <p><b>编号</b>：[3]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04724</p>
  <p><b>作者</b>：Christopher Yeh,  Chenlin Meng,  Sherrie Wang,  Anne Driscoll,  Erik Rozi,  Patrick Liu,  Jihyeon Lee,  Marshall Burke,  David B. Lobell,  Stefano Ermon</p>
  <p><b>备注</b>：NeurIPS 2021 (Track on Datasets and Benchmarks)</p>
  <p><b>关键词</b>：improved model performance facilitates progress towards, ground survey data requires domain knowledge, 15 benchmark tasks across 7 sdgs, united nations sustainable development goals, used inconsistent evaluation metrics</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Progress toward the United Nations Sustainable Development Goals (SDGs) has
been hindered by a lack of data on key environmental and socioeconomic
indicators, which historically have come from ground surveys with sparse
temporal and spatial coverage. Recent advances in machine learning have made it
possible to utilize abundant, frequently-updated, and globally available data,
such as from satellites or social media, to provide insights into progress
toward SDGs. Despite promising early results, approaches to using such data for
SDG measurement thus far have largely evaluated on different datasets or used
inconsistent evaluation metrics, making it hard to understand whether
performance is improving and where additional research would be most fruitful.
Furthermore, processing satellite and ground survey data requires domain
knowledge that many in the machine learning community lack. In this paper, we
introduce SustainBench, a collection of 15 benchmark tasks across 7 SDGs,
including tasks related to economic development, agriculture, health,
education, water and sanitation, climate action, and life on land. Datasets for
11 of the 15 tasks are released publicly for the first time. Our goals for
SustainBench are to (1) lower the barriers to entry for the machine learning
community to contribute to measuring and achieving the SDGs; (2) provide
standard benchmarks for evaluating machine learning models on tasks across a
variety of SDGs; and (3) encourage the development of novel machine learning
methods where improved model performance facilitates progress towards the SDGs.</p>
  </details>
</details>
<details>
  <summary>4. <b>标题：Directional Message Passing on Molecular Graphs via Synthetic  Coordinates</b></summary>
  <p><b>编号</b>：[5]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04718</p>
  <p><b>作者</b>：Johannes Klicpera,  Chandan Yeshwanth,  Stephan Günnemann</p>
  <p><b>备注</b>：Published as a conference paper at NeurIPS 2021</p>
  <p><b>关键词</b>：leverage coordinates via directional message passing, multiple molecular property prediction tasks, transforming normal graph neural networks, advanced gnns without requiring, normal graph neural network</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Graph neural networks that leverage coordinates via directional message
passing have recently set the state of the art on multiple molecular property
prediction tasks. However, they rely on atom position information that is often
unavailable, and obtaining it is usually prohibitively expensive or even
impossible. In this paper we propose synthetic coordinates that enable the use
of advanced GNNs without requiring the true molecular configuration. We propose
two distances as synthetic coordinates: Distance bounds that specify the rough
range of molecular configurations, and graph-based distances using a symmetric
variant of personalized PageRank. To leverage both distance and angular
information we propose a method of transforming normal graph neural networks
into directional MPNNs. We show that with this transformation we can reduce the
error of a normal graph neural network by 55% on the ZINC benchmark. We
furthermore set the state of the art on ZINC and coordinate-free QM9 by
incorporating synthetic coordinates in the SMP and DimeNet++ models. Our
implementation is available online.</p>
  </details>
</details>
<details>
  <summary>5. <b>标题：Understanding the Effects of Dataset Characteristics on Offline  Reinforcement Learning</b></summary>
  <p><b>编号</b>：[6]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04714</p>
  <p><b>作者</b>：Kajetan Schweighofer,  Markus Hofmarcher,  Marius-Constantin Dinu,  Philipp Renz,  Angela Bitto-Nemling,  Vihang Patil,  Sepp Hochreiter</p>
  <p><b>备注</b>：Code: this https URL</p>
  <p><b>关键词</b>：dataset characteristics influence different offline rl algorithms, therefore hampers real world applications, given dataset without interacting, best offline rl algorithms, average dataset return measured</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In real world, affecting the environment by a weak policy can be expensive or
very risky, therefore hampers real world applications of reinforcement
learning. Offline Reinforcement Learning (RL) can learn policies from a given
dataset without interacting with the environment. However, the dataset is the
only source of information for an Offline RL algorithm and determines the
performance of the learned policy. We still lack studies on how dataset
characteristics influence different Offline RL algorithms. Therefore, we
conducted a comprehensive empirical analysis of how dataset characteristics
effect the performance of Offline RL algorithms for discrete action
environments. A dataset is characterized by two metrics: (1) the average
dataset return measured by the Trajectory Quality (TQ) and (2) the coverage
measured by the State-Action Coverage (SACo). We found that variants of the
off-policy Deep Q-Network family require datasets with high SACo to perform
well. Algorithms that constrain the learned policy towards the given dataset
perform well for datasets with high TQ or SACo. For datasets with high TQ,
Behavior Cloning outperforms or performs similarly to the best Offline RL
algorithms.</p>
  </details>
</details>
<details>
  <summary>6. <b>标题：OMD: Orthogonal Malware Detection Using Audio, Image, and Static  Features</b></summary>
  <p><b>编号</b>：[7]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04710</p>
  <p><b>作者</b>：Lakshmanan Nataraj,  Tajuddin Manhar Mohammed,  Tejaswi Nanjundaswamy,  Satish Chikkagoudar,  Shivkumar Chandrasekaran,  B.S. Manjunath</p>
  <p><b>备注</b>：Submitted version - MILCOM 2021 IEEE Military Communications Conference</p>
  <p><b>关键词</b>：detecting unique malware samples, identify malware using, classifying malware families, new feature set, cyber defense approaches</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>With the growing number of malware and cyber attacks, there is a need for
"orthogonal" cyber defense approaches, which are complementary to existing
methods by detecting unique malware samples that are not predicted by other
methods. In this paper, we propose a novel and orthogonal malware detection
(OMD) approach to identify malware using a combination of audio descriptors,
image similarity descriptors and other static/statistical features. First, we
show how audio descriptors are effective in classifying malware families when
the malware binaries are represented as audio signals. Then, we show that the
predictions made on the audio descriptors are orthogonal to the predictions
made on image similarity descriptors and other static features. Further, we
develop a framework for error analysis and a metric to quantify how orthogonal
a new feature set (or type) is with respect to other feature sets. This allows
us to add new features and detection methods to our overall framework.
Experimental results on malware datasets show that our approach provides a
robust framework for orthogonal malware detection.</p>
  </details>
</details>
<details>
  <summary>7. <b>标题：Bayesian Framework for Gradient Leakage</b></summary>
  <p><b>编号</b>：[8]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04706</p>
  <p><b>作者</b>：Mislav Balunović,  Dimitar I. Dimitrov,  Robin Staab,  Martin Vechev</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：training machine learning models without sharing training data, cannot guarantee data privacy, still leak sensitive information, several existing heuristic defenses, bayes optimal adversary phrased</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Federated learning is an established method for training machine learning
models without sharing training data. However, recent work has shown that it
cannot guarantee data privacy as shared gradients can still leak sensitive
information. To formalize the problem of gradient leakage, we propose a
theoretical framework that enables, for the first time, analysis of the Bayes
optimal adversary phrased as an optimization problem. We demonstrate that
existing leakage attacks can be seen as approximations of this optimal
adversary with different assumptions on the probability distributions of the
input data and gradients. Our experiments confirm the effectiveness of the
Bayes optimal adversary when it has knowledge of the underlying distribution.
Further, our experimental evaluation shows that several existing heuristic
defenses are not effective against stronger attacks, especially early in the
training process. Thus, our findings indicate that the construction of more
effective defenses and their evaluation remains an open problem.</p>
  </details>
</details>
<details>
  <summary>8. <b>标题：Data-driven Set-based Estimation of Polynomial Systems with Application  to SIR Epidemics</b></summary>
  <p><b>编号</b>：[9]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04704</p>
  <p><b>作者</b>：Amr Alanwar,  Muhammad Umar B. Niazi,  Karl H. Johansson</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：offline phase utilizes past input, online phase provides, based estimation algorithm, proposed method computes, exact polynomial functions</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper proposes a data-driven set-based estimation algorithm for a class
of nonlinear systems with polynomial nonlinearities. Using the system's
input-output data, the proposed method computes in real-time a set that
guarantees the inclusion of the system's state. Although the system is assumed
to be polynomial type, the exact polynomial functions and their coefficients
need not be known. To this end, the estimator relies on offline and online
phases. The offline phase utilizes past input-output data to estimate a set of
possible coefficients of the polynomial system. Then, using this estimated set
of coefficients and the side information about the system, the online phase
provides a set estimate of the state. Finally, the proposed methodology is
evaluated through its application on SIR (Susceptible, Infected, Recovered)
epidemic model.</p>
  </details>
</details>
<details>
  <summary>9. <b>标题：HAPSSA: Holistic Approach to PDF Malware Detection Using Signal and  Statistical Analysis</b></summary>
  <p><b>编号</b>：[10]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04703</p>
  <p><b>作者</b>：Tajuddin Manhar Mohammed,  Lakshmanan Nataraj,  Satish Chikkagoudar,  Shivkumar Chandrasekaran,  B.S. Manjunath</p>
  <p><b>备注</b>：Submitted version - MILCOM 2021 IEEE Military Communications Conference</p>
  <p><b>关键词</b>：includes combining orthogonal feature space models, even detects new malicious files created, art approaches use machine learning, require modern threat intelligence platforms, simple yet effective holistic approach</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Malicious PDF documents present a serious threat to various security
organizations that require modern threat intelligence platforms to effectively
analyze and characterize the identity and behavior of PDF malware.
State-of-the-art approaches use machine learning (ML) to learn features that
characterize PDF malware. However, ML models are often susceptible to evasion
attacks, in which an adversary obfuscates the malware code to avoid being
detected by an Antivirus. In this paper, we derive a simple yet effective
holistic approach to PDF malware detection that leverages signal and
statistical analysis of malware binaries. This includes combining orthogonal
feature space models from various static and dynamic malware detection methods
to enable generalized robustness when faced with code obfuscations. Using a
dataset of nearly 30,000 PDF files containing both malware and benign samples,
we show that our holistic approach maintains a high detection rate (99.92%) of
PDF malware and even detects new malicious files created by simple methods that
remove the obfuscation conducted by malware authors to hide their malware,
which are undetected by most antiviruses.</p>
  </details>
</details>
<details>
  <summary>10. <b>标题：Interactive Inverse Reinforcement Learning for Cooperative Games</b></summary>
  <p><b>编号</b>：[11]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04698</p>
  <p><b>作者</b>：Thomas Kleine Buening,  Anne-Marie George,  Christos Dimitrakakis</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：maximise expected utility given, agent markov decision process, potentially suboptimal partner, designing ai agents, cooperative episodic two</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We study the problem of designing AI agents that can learn to cooperate
effectively with a potentially suboptimal partner while having no access to the
joint reward function. This problem is modeled as a cooperative episodic
two-agent Markov decision process. We assume control over only the first of the
two agents in a Stackelberg formulation of the game, where the second agent is
acting so as to maximise expected utility given the first agent's policy. How
should the first agent act in order to learn the joint reward function as
quickly as possible, and so that the joint policy is as close to optimal as
possible? In this paper, we analyse how knowledge about the reward function can
be gained in this interactive two-agent scenario. We show that when the
learning agent's policies have a significant effect on the transition function,
the reward function can be learned efficiently.</p>
  </details>
</details>
<details>
  <summary>11. <b>标题：Universal and data-adaptive algorithms for model selection in linear  contextual bandits</b></summary>
  <p><b>编号</b>：[13]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04688</p>
  <p><b>作者</b>：Vidya Muthukumar,  Akshay Krishnamurthy</p>
  <p><b>备注</b>：27 pages</p>
  <p><b>关键词</b>：model selection among nested linear contextual bandits, second removes distributional assumptions altogether, recovering two prior results, linear contextual bandit problem, provide model selection guarantees</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Model selection in contextual bandits is an important complementary problem
to regret minimization with respect to a fixed model class. We consider the
simplest non-trivial instance of model-selection: distinguishing a simple
multi-armed bandit problem from a linear contextual bandit problem. Even in
this instance, current state-of-the-art methods explore in a suboptimal manner
and require strong "feature-diversity" conditions. In this paper, we introduce
new algorithms that a) explore in a data-adaptive manner, and b) provide model
selection guarantees of the form $\mathcal{O}(d^{\alpha} T^{1- \alpha})$ with
no feature diversity conditions whatsoever, where $d$ denotes the dimension of
the linear model and $T$ denotes the total number of rounds. The first
algorithm enjoys a "best-of-both-worlds" property, recovering two prior results
that hold under distinct distributional assumptions, simultaneously. The second
removes distributional assumptions altogether, expanding the scope for
tractable model selection. Our approach extends to model selection among nested
linear contextual bandits under some additional assumptions.</p>
  </details>
</details>
<details>
  <summary>12. <b>标题：Reinforcement Learning for Mixed Autonomy Intersections</b></summary>
  <p><b>编号</b>：[14]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04686</p>
  <p><b>作者</b>：Zhongxia Yan,  Cathy Wu</p>
  <p><b>备注</b>：7 pages, 6 figures, ITSC 2021, 2021 IEEE International Conference on Intelligent Transportation Systems (ITSC)</p>
  <p><b>关键词</b>：behavior generalizes across inflow rates, even without reward shaping, allows decentralized control based, controlling mixed autonomy traffic, free reinforcement learning method</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose a model-free reinforcement learning method for controlling mixed
autonomy traffic in simulated traffic networks with through-traffic-only
two-way and four-way intersections. Our method utilizes multi-agent policy
decomposition which allows decentralized control based on local observations
for an arbitrary number of controlled vehicles. We demonstrate that, even
without reward shaping, reinforcement learning learns to coordinate the
vehicles to exhibit traffic signal-like behaviors, achieving near-optimal
throughput with 33-50% controlled vehicles. With the help of multi-task
learning and transfer learning, we show that this behavior generalizes across
inflow rates and size of the traffic network. Our code, models, and videos of
results are available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>13. <b>标题：Revisiting Methods for Finding Influential Examples</b></summary>
  <p><b>编号</b>：[15]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04683</p>
  <p><b>作者</b>：Karthikeyan K,  Anders Søgaard</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：e ., extremely sensitive, finding influential training examples, evaluated using loo influence, yet effective baseline, representer point selection</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Several instance-based explainability methods for finding influential
training examples for test-time decisions have been proposed recently,
including Influence Functions, TraceIn, Representer Point Selection, Grad-Dot,
and Grad-Cos. Typically these methods are evaluated using LOO influence (Cook's
distance) as a gold standard, or using various heuristics. In this paper, we
show that all of the above methods are unstable, i.e., extremely sensitive to
initialization, ordering of the training data, and batch size. We suggest that
this is a natural consequence of how in the literature, the influence of
examples is assumed to be independent of model state and other examples -- and
argue it is not. We show that LOO influence and heuristics are, as a result,
poor metrics to measure the quality of instance-based explanations, and instead
propose to evaluate such explanations by their ability to detect poisoning
attacks. Further, we provide a simple, yet effective baseline to improve all of
the above methods and show how it leads to very significant improvements on
downstream tasks.</p>
  </details>
</details>
<details>
  <summary>14. <b>标题：SMU: smooth activation function for deep networks using smoothing  maximum technique</b></summary>
  <p><b>编号</b>：[16]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04682</p>
  <p><b>作者</b>：Koushik Biswas,  Sandeep Kumar,  Shilpak Banerjee,  Ashish Kumar Pandey</p>
  <p><b>备注</b>：7 pages</p>
  <p><b>关键词</b>：proposing two new novel activation functions, known activation functions like leaky relu, new novel activation function based, function smooth maximum unit, deep learning community due</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep learning researchers have a keen interest in proposing two new novel
activation functions which can boost network performance. A good choice of
activation function can have significant consequences in improving network
performance. A handcrafted activation is the most common choice in neural
network models. ReLU is the most common choice in the deep learning community
due to its simplicity though ReLU has some serious drawbacks. In this paper, we
have proposed a new novel activation function based on approximation of known
activation functions like Leaky ReLU, and we call this function Smooth Maximum
Unit (SMU). Replacing ReLU by SMU, we have got 6.22% improvement in the
CIFAR100 dataset with the ShuffleNet V2 model.</p>
  </details>
</details>
<details>
  <summary>15. <b>标题：Approximate Neural Architecture Search via Operation Distribution  Learning</b></summary>
  <p><b>编号</b>：[20]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04670</p>
  <p><b>作者</b>：Xingchen Wan,  Binxin Ru,  Pedro M. Esperança,  Fabio M. Carlucci</p>
  <p><b>备注</b>：WACV 2022. 10 pages, 3 figures and 5 tables (15 pages, 7 figures and 6 tables including appendices)</p>
  <p><b>关键词</b>：holds enough discriminating power, simple intuition significantly reduces, fully deterministic architecture, specific connection pattern, typical search spaces</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The standard paradigm in Neural Architecture Search (NAS) is to search for a
fully deterministic architecture with specific operations and connections. In
this work, we instead propose to search for the optimal operation distribution,
thus providing a stochastic and approximate solution, which can be used to
sample architectures of arbitrary length. We propose and show, that given an
architectural cell, its performance largely depends on the ratio of used
operations, rather than any specific connection pattern in typical search
spaces; that is, small changes in the ordering of the operations are often
irrelevant. This intuition is orthogonal to any specific search strategy and
can be applied to a diverse set of NAS algorithms. Through extensive validation
on 4 data-sets and 4 NAS techniques (Bayesian optimisation, differentiable
search, local search and random search), we show that the operation
distribution (1) holds enough discriminating power to reliably identify a
solution and (2) is significantly easier to optimise than traditional
encodings, leading to large speed-ups at little to no cost in performance.
Indeed, this simple intuition significantly reduces the cost of current
approaches and potentially enable NAS to be used in a broader range of
applications.</p>
  </details>
</details>
<details>
  <summary>16. <b>标题：Evaluating Predictive Uncertainty and Robustness to Distributional Shift  Using Real World Data</b></summary>
  <p><b>编号</b>：[22]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04665</p>
  <p><b>作者</b>：Kumud Lakara,  Akshat Bhandari,  Pratinav Seth,  Ujjwal Verma</p>
  <p><b>备注</b>：6 pages, 3 figures, 4 tables</p>
  <p><b>关键词</b>：machine learning models operate, general regression tasks using, shifts weather prediction dataset, generally hold true, baseline methods using</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Most machine learning models operate under the assumption that the training,
testing and deployment data is independent and identically distributed
(i.i.d.). This assumption doesn't generally hold true in a natural setting.
Usually, the deployment data is subject to various types of distributional
shifts. The magnitude of a model's performance is proportional to this shift in
the distribution of the dataset. Thus it becomes necessary to evaluate a
model's uncertainty and robustness to distributional shifts to get a realistic
estimate of its expected performance on real-world data. Present methods to
evaluate uncertainty and model's robustness are lacking and often fail to paint
the full picture. Moreover, most analysis so far has primarily focused on
classification tasks. In this paper, we propose more insightful metrics for
general regression tasks using the Shifts Weather Prediction Dataset. We also
present an evaluation of the baseline methods using these metrics.</p>
  </details>
</details>
<details>
  <summary>17. <b>标题：S3RP: Self-Supervised Super-Resolution and Prediction for  Advection-Diffusion Process</b></summary>
  <p><b>编号</b>：[28]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04639</p>
  <p><b>作者</b>：Chulin Wang,  Kyongmin Yeo,  Xiao Jin,  Andres Codas,  Levente J. Klein,  Bruce Elmegreen</p>
  <p><b>备注</b>：9 pages, 8 figures</p>
  <p><b>关键词</b>：recurrent convolutional network trained, resolution models assume high, recurrent wasserstein autoencoder, hr information without, limited information</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present a super-resolution model for an advection-diffusion process with
limited information. While most of the super-resolution models assume
high-resolution (HR) ground-truth data in the training, in many cases such HR
dataset is not readily accessible. Here, we show that a Recurrent Convolutional
Network trained with physics-based regularizations is able to reconstruct the
HR information without having the HR ground-truth data. Moreover, considering
the ill-posed nature of a super-resolution problem, we employ the Recurrent
Wasserstein Autoencoder to model the uncertainty.</p>
  </details>
</details>
<details>
  <summary>18. <b>标题：Accelerating GAN training using highly parallel hardware on public cloud</b></summary>
  <p><b>编号</b>：[32]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04628</p>
  <p><b>作者</b>：Renato Cardoso,  Dejan Golubovic,  Ignacio Peluaga Lozada,  Ricardo Rocha,  João Fernandes,  Sofia Vallecorsa</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：using tensorflow data parallel strategy, work explores different types, google tensor processing units, different public cloud providers, monte carlo simulation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>With the increasing number of Machine and Deep Learning applications in High
Energy Physics, easy access to dedicated infrastructure represents a
requirement for fast and efficient R&D. This work explores different types of
cloud services to train a Generative Adversarial Network (GAN) in a parallel
environment, using Tensorflow data parallel strategy. More specifically, we
parallelize the training process on multiple GPUs and Google Tensor Processing
Units (TPU) and we compare two algorithms: the TensorFlow built-in logic and a
custom loop, optimised to have higher control of the elements assigned to each
GPU worker or TPU core. The quality of the generated data is compared to Monte
Carlo simulation. Linear speed-up of the training process is obtained, while
retaining most of the performance in terms of physics results. Additionally, we
benchmark the aforementioned approaches, at scale, over multiple GPU nodes,
deploying the training process on different public cloud providers, seeking for
overall efficiency and cost-effectiveness. The combination of data science,
cloud deployment options and associated economics allows to burst out
heterogeneously, exploring the full potential of cloud-based services.</p>
  </details>
</details>
<details>
  <summary>19. <b>标题：DeepSteal: Advanced Model Extractions Leveraging Efficient Weight  Stealing in Memories</b></summary>
  <p><b>编号</b>：[33]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04625</p>
  <p><b>作者</b>：Adnan Siraj Rakin,  Md Hafizul Islam Chowdhuryy,  Fan Yao,  Deliang Fan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：extracted substitute model could also generate effective adversarial input samples, existing attacks cannot extract detailed model parameters, proposed deepsteal comprises two key stages, advanced model extraction attack framework deepsteal, new weight bit information extraction method</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent advancements of Deep Neural Networks (DNNs) have seen widespread
deployment in multiple security-sensitive domains. The need of
resource-intensive training and use of valuable domain-specific training data
have made these models a top intellectual property (IP) for model owners. One
of the major threats to the DNN privacy is model extraction attacks where
adversaries attempt to steal sensitive information in DNN models. Recent
studies show hardware-based side channel attacks can reveal internal knowledge
about DNN models (e.g., model architectures) However, to date, existing attacks
cannot extract detailed model parameters (e.g., weights/biases). In this work,
for the first time, we propose an advanced model extraction attack framework
DeepSteal that effectively steals DNN weights with the aid of memory
side-channel attack. Our proposed DeepSteal comprises two key stages. Firstly,
we develop a new weight bit information extraction method, called HammerLeak,
through adopting the rowhammer based hardware fault technique as the
information leakage vector. HammerLeak leverages several novel system-level
techniques tailed for DNN applications to enable fast and efficient weight
stealing. Secondly, we propose a novel substitute model training algorithm with
Mean Clustering weight penalty, which leverages the partial leaked bit
information effectively and generates a substitute prototype of the target
victim model. We evaluate this substitute model extraction method on three
popular image datasets (e.g., CIFAR-10/100/GTSRB) and four DNN architectures
(e.g., ResNet-18/34/Wide-ResNet/VGG-11). The extracted substitute model has
successfully achieved more than 90 % test accuracy on deep residual networks
for the CIFAR-10 dataset. Moreover, our extracted substitute model could also
generate effective adversarial input samples to fool the victim model.</p>
  </details>
</details>
<details>
  <summary>20. <b>标题：Variational Automatic Curriculum Learning for Sparse-Reward Cooperative  Multi-Agent Problems</b></summary>
  <p><b>编号</b>：[38]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04613</p>
  <p><b>作者</b>：Jiayu Chen,  Yuanxin Zhang,  Yuanfan Xu,  Huimin Ma,  Huazhong Yang,  Jiaming Song,  Yu Wang,  Yi Wu</p>
  <p><b>备注</b>：In NeurIPS 2021</p>
  <p><b>关键词</b>：use behavior originally shown, agent reinforcement learning problems, variational automatic curriculum learning, solving challenging goal, single desktop machine</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We introduce a curriculum learning algorithm, Variational Automatic
Curriculum Learning (VACL), for solving challenging goal-conditioned
cooperative multi-agent reinforcement learning problems. We motivate our
paradigm through a variational perspective, where the learning objective can be
decomposed into two terms: task learning on the current task distribution, and
curriculum update to a new task distribution. Local optimization over the
second term suggests that the curriculum should gradually expand the training
tasks from easy to hard. Our VACL algorithm implements this variational
paradigm with two practical components, task expansion and entity progression,
which produces training curricula over both the task configurations as well as
the number of entities in the task. Experiment results show that VACL solves a
collection of sparse-reward problems with a large number of agents.
Particularly, using a single desktop machine, VACL achieves 98% coverage rate
with 100 agents in the simple-spread benchmark and reproduces the ramp-use
behavior originally shown in OpenAI's hide-and-seek project. Our project
website is at this https URL.</p>
  </details>
</details>
<details>
  <summary>21. <b>标题：On the Stochastic Stability of Deep Markov Models</b></summary>
  <p><b>编号</b>：[40]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04601</p>
  <p><b>作者</b>：Ján Drgoňa,  Sayak Mukherjee,  Jiaxin Zhang,  Frank Liu,  Mahantesh Halappanavar</p>
  <p><b>备注</b>：35th Conference on Neural Information Processing Systems (NeurIPS 2021), Sydney, Australia</p>
  <p><b>关键词</b>：theoretical results via intuitive numerical experiments using, fundamental stochastic stability guarantees, stability analysis method based, used activation functions, provide sufficient conditions</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep Markov models (DMM) are generative models that are scalable and
expressive generalization of Markov models for representation, learning, and
inference problems. However, the fundamental stochastic stability guarantees of
such models have not been thoroughly investigated. In this paper, we provide
sufficient conditions of DMM's stochastic stability as defined in the context
of dynamical systems and propose a stability analysis method based on the
contraction of probabilistic maps modeled by deep neural networks. We make
connections between the spectral properties of neural network's weights and
different types of used activation functions on the stability and overall
dynamic behavior of DMMs with Gaussian distributions. Based on the theory, we
propose a few practical methods for designing constrained DMMs with guaranteed
stability. We empirically substantiate our theoretical results via intuitive
numerical experiments using the proposed stability constraints.</p>
  </details>
</details>
<details>
  <summary>22. <b>标题：Nonnegative Tensor Completion via Integer Optimization</b></summary>
  <p><b>编号</b>：[46]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04580</p>
  <p><b>作者</b>：Caleb Bugg,  Chen Chen,  Anil Aswani</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：use integer linear programming, solve linear separation problems, theoretic sample complexity rate, unlike matrix completion, tensor completion problem</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Unlike matrix completion, no algorithm for the tensor completion problem has
so far been shown to achieve the information-theoretic sample complexity rate.
This paper develops a new algorithm for the special case of completion for
nonnegative tensors. We prove that our algorithm converges in a linear (in
numerical tolerance) number of oracle steps, while achieving the
information-theoretic rate. Our approach is to define a new norm for
nonnegative tensors using the gauge of a specific 0-1 polytope that we
construct. Because the norm is defined using a 0-1 polytope, this means we can
use integer linear programming to solve linear separation problems over the
polytope. We combine this insight with a variant of the Frank-Wolfe algorithm
to construct our numerical algorithm, and we demonstrate its effectiveness and
scalability through experiments.</p>
  </details>
</details>
<details>
  <summary>23. <b>标题：Information-Theoretic Bayes Risk Lower Bounds for Realizable Models</b></summary>
  <p><b>编号</b>：[47]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04579</p>
  <p><b>作者</b>：Matthew Nokleby,  Ahmad Beirami</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：matches known outer bounds, vc }/ n )$,, mutual information admit expressions, realizable machine learning models, vc }\ log</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We derive information-theoretic lower bounds on the Bayes risk and
generalization error of realizable machine learning models. In particular, we
employ an analysis in which the rate-distortion function of the model
parameters bounds the required mutual information between the training samples
and the model parameters in order to learn a model up to a Bayes risk
constraint. For realizable models, we show that both the rate distortion
function and mutual information admit expressions that are convenient for
analysis. For models that are (roughly) lower Lipschitz in their parameters, we
bound the rate distortion function from below, whereas for VC classes, the
mutual information is bounded above by $d_\mathrm{vc}\log(n)$. When these
conditions match, the Bayes risk with respect to the zero-one loss scales no
faster than $\Omega(d_\mathrm{vc}/n)$, which matches known outer bounds and
minimax lower bounds up to logarithmic factors. We also consider the impact of
label noise, providing lower bounds when training and/or test samples are
corrupted.</p>
  </details>
</details>
<details>
  <summary>24. <b>标题：Improved Regularization and Robustness for Fine-tuning in Neural  Networks</b></summary>
  <p><b>编号</b>：[48]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04578</p>
  <p><b>作者</b>：Dongyue Li,  Hongyang R. Zhang</p>
  <p><b>备注</b>：22 pages, 6 figures, 11 tables</p>
  <p><b>关键词</b>：text data sets using multiple pre, target data set includes noisy labels, reweight less confident data points, correct mislabeled data points, approach outperforms baseline methods</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A widely used algorithm for transfer learning is fine-tuning, where a
pre-trained model is fine-tuned on a target task with a small amount of labeled
data. When the capacity of the pre-trained model is much larger than the size
of the target data set, fine-tuning is prone to overfitting and "memorizing"
the training labels. Hence, an important question is to regularize fine-tuning
and ensure its robustness to noise. To address this question, we begin by
analyzing the generalization properties of fine-tuning. We present a PAC-Bayes
generalization bound that depends on the distance traveled in each layer during
fine-tuning and the noise stability of the fine-tuned model. We empirically
measure these quantities. Based on the analysis, we propose regularized
self-labeling -- the interpolation between regularization and self-labeling
methods, including (i) layer-wise regularization to constrain the distance
traveled in each layer; (ii) self label-correction and label-reweighting to
correct mislabeled data points (that the model is confident) and reweight less
confident data points. We validate our approach on an extensive collection of
image and text data sets using multiple pre-trained model architectures. Our
approach improves baseline methods by 1.76% (on average) for seven image
classification tasks and 0.75% for a few-shot classification task. When the
target data set includes noisy labels, our approach outperforms baseline
methods by 3.56% on average in two noisy settings.</p>
  </details>
</details>
<details>
  <summary>25. <b>标题：Sexism Prediction in Spanish and English Tweets Using Monolingual and  Multilingual BERT and Ensemble Models</b></summary>
  <p><b>编号</b>：[55]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04551</p>
  <p><b>作者</b>：Angel Felipe Magnossão de Paula,  Roberto Fray da Silva,  Ipek Baris Schlicht</p>
  <p><b>备注</b>：18 pages, presented at IberLEF: this http URL, the best scoring system at EXIST</p>
  <p><b>关键词</b>：ensemble models obtained better results, iberian languages evaluation forum, work obtained first place, best standardized values obtained, system obtained better results</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The popularity of social media has created problems such as hate speech and
sexism. The identification and classification of sexism in social media are
very relevant tasks, as they would allow building a healthier social
environment. Nevertheless, these tasks are considerably challenging. This work
proposes a system to use multilingual and monolingual BERT and data points
translation and ensemble strategies for sexism identification and
classification in English and Spanish. It was conducted in the context of the
sEXism Identification in Social neTworks shared 2021 (EXIST 2021) task,
proposed by the Iberian Languages Evaluation Forum (IberLEF). The proposed
system and its main components are described, and an in-depth hyperparameters
analysis is conducted. The main results observed were: (i) the system obtained
better results than the baseline model (multilingual BERT); (ii) ensemble
models obtained better results than monolingual models; and (iii) an ensemble
model considering all individual models and the best standardized values
obtained the best accuracies and F1-scores for both tasks. This work obtained
first place in both tasks at EXIST, with the highest accuracies (0.780 for task
1 and 0.658 for task 2) and F1-scores (F1-binary of 0.780 for task 1 and
F1-macro of 0.579 for task 2).</p>
  </details>
</details>
<details>
  <summary>26. <b>标题：BARFED: Byzantine Attack-Resistant Federated Averaging Based on Outlier  Elimination</b></summary>
  <p><b>编号</b>：[56]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04550</p>
  <p><b>作者</b>：Ece Isik-Polat,  Gorkem Polat,  Altan Kocyigit</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：mostly lack comprehensive experimental analyses, defense algorithm called barfed, although many defense algorithms, aggregating model updates coming, global model becomes vulnerable</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In federated learning, each participant trains its local model with its own
data and a global model is formed at a trusted server by aggregating model
updates coming from these participants. Since the server has no effect and
visibility on the training procedure of the participants to ensure privacy, the
global model becomes vulnerable to attacks such as data poisoning and model
poisoning. Although many defense algorithms have recently been proposed to
address these attacks, they often make strong assumptions that do not agree
with the nature of federated learning, such as Non-IID datasets. Moreover, they
mostly lack comprehensive experimental analyses. In this work, we propose a
defense algorithm called BARFED that does not make any assumptions about data
distribution, update similarity of participants, or the ratio of the malicious
participants. BARFED mainly considers the outlier status of participant updates
for each layer of the model architecture based on the distance to the global
model. Hence, the participants that do not have any outlier layer are involved
in model aggregation. We perform extensive experiments on many grounds and show
that the proposed approach provides a robust defense against different attacks.</p>
  </details>
</details>
<details>
  <summary>27. <b>标题：AI-UPV at IberLEF-2021 DETOXIS task: Toxicity Detection in  Immigration-Related Web News Comments Using Transformers and Statistical  Models</b></summary>
  <p><b>编号</b>：[59]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04530</p>
  <p><b>作者</b>：Angel Felipe Magnossão de Paula,  Ipek Baris Schlicht</p>
  <p><b>备注</b>：20 pages. Presented at IberLEF. See this http URL</p>
  <p><b>关键词</b>：different online news articles related, bert models obtain better results, web news articles within, necessary efforts towards mitigating, iberian languages evaluation forum</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper describes our participation in the DEtection of TOXicity in
comments In Spanish (DETOXIS) shared task 2021 at the 3rd Workshop on Iberian
Languages Evaluation Forum. The shared task is divided into two related
classification tasks: (i) Task 1: toxicity detection and; (ii) Task 2: toxicity
level detection. They focus on the xenophobic problem exacerbated by the spread
of toxic comments posted in different online news articles related to
immigration. One of the necessary efforts towards mitigating this problem is to
detect toxicity in the comments. Our main objective was to implement an
accurate model to detect xenophobia in comments about web news articles within
the DETOXIS shared task 2021, based on the competition's official metrics: the
F1-score for Task 1 and the Closeness Evaluation Metric (CEM) for Task 2. To
solve the tasks, we worked with two types of machine learning models: (i)
statistical models and (ii) Deep Bidirectional Transformers for Language
Understanding (BERT) models. We obtained our best results in both tasks using
BETO, an BERT model trained on a big Spanish corpus. We obtained the 3rd place
in Task 1 official ranking with the F1-score of 0.5996, and we achieved the 6th
place in Task 2 official ranking with the CEM of 0.7142. Our results suggest:
(i) BERT models obtain better results than statistical models for toxicity
detection in text comments; (ii) Monolingual BERT models have an advantage over
multilingual BERT models in toxicity detection in text comments in their
pre-trained language.</p>
  </details>
</details>
<details>
  <summary>28. <b>标题：Feature Concepts for Data Federative Innovations</b></summary>
  <p><b>编号</b>：[66]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04505</p>
  <p><b>作者</b>：Yukio Ohsawa,  Sae Kondo,  Teruaki Hayashi</p>
  <p><b>备注</b>：13 pages, 7 figures</p>
  <p><b>关键词</b>：far via creative communication among stakeholders, federative innovation process, decision tree learning, useful feature concepts, creative communication</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A feature concept, the essence of the data-federative innovation process, is
presented as a model of the concept to be acquired from data. A feature concept
may be a simple feature, such as a single variable, but is more likely to be a
conceptual illustration of the abstract information to be obtained from the
data. For example, trees and clusters are feature concepts for decision tree
learning and clustering, respectively. Useful feature concepts for satis-fying
the requirements of users of data have been elicited so far via creative
communication among stakeholders in the market of data. In this short paper,
such a creative communication is reviewed, showing a couple of appli-cations,
for example, change explanation in markets and earthquakes, and highlight the
feature concepts elicited in these cases.</p>
  </details>
</details>
<details>
  <summary>29. <b>标题：Improving RNA Secondary Structure Design using Deep Reinforcement  Learning</b></summary>
  <p><b>编号</b>：[67]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04504</p>
  <p><b>作者</b>：Alexander Whatley,  Zhekun Luo,  Xiangru Tang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：future experiments involving machine learning, applying reinforcement learning, widely used approach, performance across batches, simulates biological evolution</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Rising costs in recent years of developing new drugs and treatments have led
to extensive research in optimization techniques in biomolecular design.
Currently, the most widely used approach in biomolecular design is directed
evolution, which is a greedy hill-climbing algorithm that simulates biological
evolution. In this paper, we propose a new benchmark of applying reinforcement
learning to RNA sequence design, in which the objective function is defined to
be the free energy in the sequence's secondary structure. In addition to
experimenting with the vanilla implementations of each reinforcement learning
algorithm from standard libraries, we analyze variants of each algorithm in
which we modify the algorithm's reward function and tune the model's
hyperparameters. We show results of the ablation analysis that we do for these
algorithms, as well as graphs indicating the algorithm's performance across
batches and its ability to search the possible space of RNA sequences. We find
that our DQN algorithm performs by far the best in this setting, contrasting
with, in which PPO performs the best among all tested algorithms. Our results
should be of interest to those in the biomolecular design community and should
serve as a baseline for future experiments involving machine learning in
molecule design.</p>
  </details>
</details>
<details>
  <summary>30. <b>标题：An Approach for Combining Multimodal Fusion and Neural Architecture  Search Applied to Knowledge Tracing</b></summary>
  <p><b>编号</b>：[68]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04497</p>
  <p><b>作者</b>：Xinyi Ding,  Tao Han,  Yili Fang,  Eric Larson</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：existing deep learning based knowledge tracing models either, commonly used neural architecture search technique could, neural architecture search within one framework, two public real datasets showing, seen researchers take similar approaches</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Knowledge Tracing is the process of tracking mastery level of different
skills of students for a given learning domain. It is one of the key components
for building adaptive learning systems and has been investigated for decades.
In parallel with the success of deep neural networks in other fields, we have
seen researchers take similar approaches in the learning science community.
However, most existing deep learning based knowledge tracing models either: (1)
only use the correct/incorrect response (ignoring useful information from other
modalities) or (2) design their network architectures through domain expertise
via trial and error. In this paper, we propose a sequential model based
optimization approach that combines multimodal fusion and neural architecture
search within one framework. The commonly used neural architecture search
technique could be considered as a special case of our proposed approach when
there is only one modality involved. We further propose to use a new metric
called time-weighted Area Under the Curve (weighted AUC) to measure how a
sequence model performs with time. We evaluate our methods on two public real
datasets showing the discovered model is able to achieve superior performance.
Unlike most existing works, we conduct McNemar's test on the model predictions
and the results are statistically significant.</p>
  </details>
</details>
<details>
  <summary>31. <b>标题：Multi-Airport Delay Prediction with Transformers</b></summary>
  <p><b>编号</b>：[69]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04494</p>
  <p><b>作者</b>：Liya Wang,  Alex Tien,  Jason Chou</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：based delay prediction model achieves satisfactory performance measured, forecast selected delay metrics, decision makers gain insights, capture complex temporal dynamics, help air traffic managers</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Airport performance prediction with a reasonable look-ahead time is a
challenging task and has been attempted by various prior research. Traffic,
demand, weather, and traffic management actions are all critical inputs to any
prediction model. In this paper, a novel approach based on Temporal Fusion
Transformer (TFT) was proposed to predict departure and arrival delays
simultaneously for multiple airports at once. This approach can capture complex
temporal dynamics of the inputs known at the time of prediction and then
forecast selected delay metrics up to four hours into the future. When dealing
with weather inputs, a self-supervised learning (SSL) model was developed to
encode high-dimensional weather data into a much lower-dimensional
representation to make the training of TFT more efficiently and effectively.
The initial results show that the TFT-based delay prediction model achieves
satisfactory performance measured by smaller prediction errors on a testing
dataset. In addition, the interpretability analysis of the model outputs
identifies the important input factors for delay prediction. The proposed
approach is expected to help air traffic managers or decision makers gain
insights about traffic management actions on delay mitigation and once
operationalized, provide enough lead time to plan for predicted performance
degradation.</p>
  </details>
</details>
<details>
  <summary>32. <b>标题：Identifying the Leading Factors of Significant Weight Gains Using a New  Rule Discovery Method</b></summary>
  <p><b>编号</b>：[74]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04475</p>
  <p><b>作者</b>：Mina Samizadeh,  Jessica C Jones-Smith,  Bethany Sheridan,  Rahmatollah Beheshti</p>
  <p><b>备注</b>：The code for this project is available on: this https URL</p>
  <p><b>关键词</b>：major global public health concern, patterns across 22 strata determined, indicates significant weight gains, future dangerous weight gains, future weight gains</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Overweight and obesity remain a major global public health concern and
identifying the individualized patterns that increase the risk of future weight
gains has a crucial role in preventing obesity and numerous sub-sequent
diseases associated with obesity. In this work, we use a rule discovery method
to study this problem, by presenting an approach that offers genuine
interpretability and concurrently optimizes the accuracy(being correct often)
and support (applying to many samples) of the identified patterns.
Specifically, we extend an established subgroup-discovery method to generate
the desired rules of type X -> Y and show how top features can be extracted
from the X side, functioning as the best predictors of Y. In our obesity
problem, X refers to the extracted features from very large and multi-site EHR
data, and Y indicates significant weight gains. Using our method, we also
extensively compare the differences and inequities in patterns across 22 strata
determined by the individual's gender, age, race, insurance type, neighborhood
type, and income level. Through extensive series of experiments, we show new
and complementary findings regarding the predictors of future dangerous weight
gains.</p>
  </details>
</details>
<details>
  <summary>33. <b>标题：Weapon Engagement Zone Maximum Launch Range Estimation Using a Deep  Neural Network</b></summary>
  <p><b>编号</b>：[75]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04474</p>
  <p><b>作者</b>：Joao P. A. Dantas,  Andre N. Costa,  Diego Geraldo,  Marcos R. O. A. Maximo,  Takashi Yoneyama</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：provides another procedure concerning preceding research since, providing faster model training, given missile using 50, weapon engagement zone, proposed method uses</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This work investigates the use of a Deep Neural Network (DNN) to perform an
estimation of the Weapon Engagement Zone (WEZ) maximum launch range. The WEZ
allows the pilot to identify an airspace in which the available missile has a
more significant probability of successfully engaging a particular target,
i.e., a hypothetical area surrounding an aircraft in which an adversary is
vulnerable to a shot. We propose an approach to determine the WEZ of a given
missile using 50,000 simulated launches in variate conditions. These
simulations are used to train a DNN that can predict the WEZ when the aircraft
finds itself on different firing conditions, with a coefficient of
determination of 0.99. It provides another procedure concerning preceding
research since it employs a non-discretized model, i.e., it considers all
directions of the WEZ at once, which has not been done previously.
Additionally, the proposed method uses an experimental design that allows for
fewer simulation runs, providing faster model training.</p>
  </details>
</details>
<details>
  <summary>34. <b>标题：Flight Demand Forecasting with Transformers</b></summary>
  <p><b>编号</b>：[78]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04471</p>
  <p><b>作者</b>：Liya Wang,  Amy Mykityshyn,  Craig Johnson,  Jillian Cheng</p>
  <p><b>备注</b>：arXiv admin note: substantial text overlap with arXiv:2011.04476</p>
  <p><b>关键词</b>：predict strategic flight departure demand, better prediction across diverse airports, system wide information management, displays predicted departure demand, based prediction method showed</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Transformers have become the de-facto standard in the natural language
processing (NLP) field. They have also gained momentum in computer vision and
other domains. Transformers can enable artificial intelligence (AI) models to
dynamically focus on certain parts of their input and thus reason more
effectively. Inspired by the success of transformers, we adopted this technique
to predict strategic flight departure demand in multiple horizons. This work
was conducted in support of a MITRE-developed mobile application, Pacer, which
displays predicted departure demand to general aviation (GA) flight operators
so they can have better situation awareness of the potential for departure
delays during busy periods. Field demonstrations involving Pacer's previously
designed rule-based prediction method showed that the prediction accuracy of
departure demand still has room for improvement. This research strives to
improve prediction accuracy from two key aspects: better data sources and
robust forecasting algorithms. We leveraged two data sources, Aviation System
Performance Metrics (ASPM) and System Wide Information Management (SWIM), as
our input. We then trained forecasting models with temporal fusion transformer
(TFT) for five different airports. Case studies show that TFTs can perform
better than traditional forecasting methods by large margins, and they can
result in better prediction across diverse airports and with better
interpretability.</p>
  </details>
</details>
<details>
  <summary>35. <b>标题：The Invisible COVID-19 Crisis: Post-Traumatic Stress Disorder Risk Among  Frontline Physicians Treating COVID-19 Patients</b></summary>
  <p><b>编号</b>：[93]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04441</p>
  <p><b>作者</b>：Sayanti Mukherjee,  Lance Rintamaki,  Janet L. Shucard,  Zhiyuan Wei,  Lindsey E. Carlasare,  Christine A. Sinsky</p>
  <p><b>备注</b>：34 pages, 5 Tables, 2 Figues, Under review with Journal of Psychiatric Research</p>
  <p><b>关键词</b>：study evaluated post traumatic stress disorder, final ml model random forest, uncover nonlinear relationships among protective, key damaging factors included depression, seven nonlinear machine learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This study evaluated post traumatic stress disorder (PTSD) among frontline US
physicians (treating COVID-19 patients) in comparison with second-line
physicians (not treating COVID-19 patients), and identified the significance
and patterns of factors associated with higher PTSD risk. A cross-sectional,
web-based survey was deployed during August and September, 2020, to practicing
physicians in the 18 states with the largest COVID-19 cases. Among 1,478
responding physicians, 1,017 completed the PTSD Checklist (PCL-5). First, the
PCL-5 was used to compare symptom endorsement between the two physician groups.
A greater percentage of frontline than second-line physicians had clinically
significant endorsement of PCL-5 symptoms and higher PCL-5 scores. Second,
logistic regression and seven nonlinear machine learning (ML) algorithms were
leveraged to identify potential predictors of PTSD risk by analyzing variable
importance and partial dependence plots. Predictors of PTSD risk included
cognitive/psychological measures, occupational characteristics, work
experiences, social support, demographics, and workplace characteristics.
Importantly, the final ML model random forest, identified patterns of both
damaging and protective predictors of PTSD risk among frontline physicians. Key
damaging factors included depression, burnout, negative coping, fears of
contracting/transmitting COVID-19, perceived stigma, and insufficient resources
to treat COVID-19 patients. Protective factors included resilience and support
from employers/friends/family/significant others. This study underscores the
value of ML algorithms to uncover nonlinear relationships among
protective/damaging risk factors for PTSD in frontline physicians, which may
better inform interventions to prepare healthcare systems for future
epidemics/pandemics.</p>
  </details>
</details>
<details>
  <summary>36. <b>标题：Addressing Privacy Threats from Machine Learning</b></summary>
  <p><b>编号</b>：[94]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04439</p>
  <p><b>作者</b>：Mary Anne Smart</p>
  <p><b>备注</b>：3 pages. Human Centered AI Workshop @ NeurIPS 2021 accepted submission</p>
  <p><b>关键词</b>：nanayakkara et al ., 2021 )., machine learning researchers gather, expressing growing concern, computer interaction researchers, discuss exciting applications</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Every year at NeurIPS, machine learning researchers gather and discuss
exciting applications of machine learning in areas such as public health,
disaster response, climate change, education, and more. However, many of these
same researchers are expressing growing concern about applications of machine
learning for surveillance (Nanayakkara et al., 2021). This paper presents a
brief overview of strategies for resisting these surveillance technologies and
calls for greater collaboration between machine learning and human-computer
interaction researchers to address the threats that these technologies pose.</p>
  </details>
</details>
<details>
  <summary>37. <b>标题：SEOFP-NET: Compression and Acceleration of Deep Neural Networks for  Speech Enhancement Using Sign-Exponent-Only Floating-Points</b></summary>
  <p><b>编号</b>：[96]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04436</p>
  <p><b>作者</b>：Yu-Chen Lin,  Cheng Yu,  Yi-Te Hsu,  Szu-Wei Fu,  Yu Tsao,  Tei-Wei Kuo</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：dnn )- based speech enhancement models, listeners cannot facilely differentiate, enhanced speech signals processed, different speech enhancement tasks, speech enhancement performance</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Numerous compression and acceleration strategies have achieved outstanding
results on classification tasks in various fields, such as computer vision and
speech signal processing. Nevertheless, the same strategies have yielded
ungratified performance on regression tasks because the nature between these
and classification tasks differs. In this paper, a novel sign-exponent-only
floating-point network (SEOFP-NET) technique is proposed to compress the model
size and accelerate the inference time for speech enhancement, a regression
task of speech signal processing. The proposed method compressed the sizes of
deep neural network (DNN)-based speech enhancement models by quantizing the
fraction bits of single-precision floating-point parameters during training.
Before inference implementation, all parameters in the trained SEOFP-NET model
are slightly adjusted to accelerate the inference time by replacing the
floating-point multiplier with an integer-adder. For generalization, the
SEOFP-NET technique is introduced to different speech enhancement tasks in
speech signal processing with different model architectures under various
corpora. The experimental results indicate that the size of SEOFP-NET models
can be significantly compressed by up to 81.249% without noticeably downgrading
their speech enhancement performance, and the inference time can be accelerated
to 1.212x compared with the baseline models. The results also verify that the
proposed SEOFP-NET can cooperate with other efficiency strategies to achieve a
synergy effect for model compression. In addition, the just noticeable
difference (JND) was applied to the user study experiment to statistically
analyze the effect of speech enhancement on listening. The results indicate
that the listeners cannot facilely differentiate between the enhanced speech
signals processed by the baseline model and the proposed SEOFP-NET.</p>
  </details>
</details>
<details>
  <summary>38. <b>标题：A Survey of Human Activity Recognition in Smart Homes Based on IoT  Sensors Algorithms: Taxonomies, Challenges, and Opportunities with Deep  Learning</b></summary>
  <p><b>编号</b>：[105]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04418</p>
  <p><b>作者</b>：Damien Bouchabou (1),  Sao Mai Nguyen (1),  Christophe Lohr (1),  Benoit Leduc,  Ioannis Kanellos (1) ((1) Lab-STICC_RAMBO, IMT Atlantique - INFO)</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：offer home assistance services, since activity recognition, recognizing human activity, raise specific problems, human activity recognition</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent advances in Internet of Things (IoT) technologies and the reduction in
the cost of sensors have encouraged the development of smart environments, such
as smart homes. Smart homes can offer home assistance services to improve the
quality of life, autonomy and health of their residents, especially for the
elderly and dependent. To provide such services, a smart home must be able to
understand the daily activities of its residents. Techniques for recognizing
human activity in smart homes are advancing daily. But new challenges are
emerging every day. In this paper, we present recent algorithms, works,
challenges and taxonomy of the field of human activity recognition in a smart
home through ambient sensors. Moreover, since activity recognition in smart
homes is a young field, we raise specific problems, missing and needed
contributions. But also propose directions, research opportunities and
solutions to accelerate advances in this field.</p>
  </details>
</details>
<details>
  <summary>39. <b>标题：There is no Double-Descent in Random Forests</b></summary>
  <p><b>编号</b>：[110]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04409</p>
  <p><b>作者</b>：Sebastian Buschjäger,  Katharina Morik</p>
  <p><b>备注</b>：11 pages, 3 figures, 3 algorithms</p>
  <p><b>关键词</b>：nearly zero parameter tuning, introduce negative correlation forest, produce correct outputs anymore, broadly received study argued, overfitting even though</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Random Forests (RFs) are among the state-of-the-art in machine learning and
offer excellent performance with nearly zero parameter tuning. Remarkably, RFs
seem to be impervious to overfitting even though their basic building blocks
are well-known to overfit. Recently, a broadly received study argued that a RF
exhibits a so-called double-descent curve: First, the model overfits the data
in a u-shaped curve and then, once a certain model complexity is reached, it
suddenly improves its performance again. In this paper, we challenge the notion
that model capacity is the correct tool to explain the success of RF and argue
that the algorithm which trains the model plays a more important role than
previously thought. We show that a RF does not exhibit a double-descent curve
but rather has a single descent. Hence, it does not overfit in the classic
sense. We further present a RF variation that also does not overfit although
its decision boundary approximates that of an overfitted DT. Similar, we show
that a DT which approximates the decision boundary of a RF will still overfit.
Last, we study the diversity of an ensemble as a tool the estimate its
performance. To do so, we introduce Negative Correlation Forest (NCForest)
which allows for precise control over the diversity in the ensemble. We show,
that the diversity and the bias indeed have a crucial impact on the performance
of the RF. Having too low diversity collapses the performance of the RF into a
a single tree, whereas having too much diversity means that most trees do not
produce correct outputs anymore. However, in-between these two extremes we find
a large range of different trade-offs with all roughly equal performance.
Hence, the specific trade-off between bias and diversity does not matter as
long as the algorithm reaches this good trade-off regime.</p>
  </details>
</details>
<details>
  <summary>40. <b>标题：Robust and Information-theoretically Safe Bias Classifier against  Adversarial Attacks</b></summary>
  <p><b>编号</b>：[112]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04404</p>
  <p><b>作者</b>：Lijia Yu,  Xiao-Shan Gao</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：totally random direction, effective training method, proper random first, piecewise constant function, theoretically safe classifier</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, the bias classifier is introduced, that is, the bias part of a
DNN with Relu as the activation function is used as a classifier. The work is
motivated by the fact that the bias part is a piecewise constant function with
zero gradient and hence cannot be directly attacked by gradient-based methods
to generate adversaries such as FGSM. The existence of the bias classifier is
proved an effective training method for the bias classifier is proposed. It is
proved that by adding a proper random first-degree part to the bias classifier,
an information-theoretically safe classifier against the original-model
gradient-based attack is obtained in the sense that the attack generates a
totally random direction for generating adversaries. This seems to be the first
time that the concept of information-theoretically safe classifier is proposed.
Several attack methods for the bias classifier are proposed and numerical
experiments are used to show that the bias classifier is more robust than DNNs
against these attacks in most cases.</p>
  </details>
</details>
<details>
  <summary>41. <b>标题：Get a Model! Model Hijacking Attack Against Machine Learning Models</b></summary>
  <p><b>编号</b>：[118]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04394</p>
  <p><b>作者</b>：Ahmed Salem,  Michael Backes,  Yang Zhang</p>
  <p><b>备注</b>：To Appear in NDSS 2022</p>
  <p><b>关键词</b>：computer vision based machine learning models, propose two different model hijacking attacks, various critical applications ranging, existing data poisoning attacks, high attack success rate</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Machine learning (ML) has established itself as a cornerstone for various
critical applications ranging from autonomous driving to authentication
systems. However, with this increasing adoption rate of machine learning
models, multiple attacks have emerged. One class of such attacks is training
time attack, whereby an adversary executes their attack before or during the
machine learning model training. In this work, we propose a new training time
attack against computer vision based machine learning models, namely model
hijacking attack. The adversary aims to hijack a target model to execute a
different task than its original one without the model owner noticing. Model
hijacking can cause accountability and security risks since a hijacked model
owner can be framed for having their model offering illegal or unethical
services. Model hijacking attacks are launched in the same way as existing data
poisoning attacks. However, one requirement of the model hijacking attack is to
be stealthy, i.e., the data samples used to hijack the target model should look
similar to the model's original training dataset. To this end, we propose two
different model hijacking attacks, namely Chameleon and Adverse Chameleon,
based on a novel encoder-decoder style ML model, namely the Camouflager. Our
evaluation shows that both of our model hijacking attacks achieve a high attack
success rate, with a negligible drop in model utility.</p>
  </details>
</details>
<details>
  <summary>42. <b>标题：Geometrically Adaptive Dictionary Attack on Face Recognition</b></summary>
  <p><b>编号</b>：[121]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04371</p>
  <p><b>作者</b>：Junyoung Byun,  Hyojun Go,  Changick Kim</p>
  <p><b>备注</b>：Accepted at WACV 2022</p>
  <p><b>关键词</b>：face recognition named geometrically adaptive dictionary attack, show overwhelming performance improvement, exploit 3d face alignment, brought remarkable performance improvement, effectively recycling previous perturbations</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>CNN-based face recognition models have brought remarkable performance
improvement, but they are vulnerable to adversarial perturbations. Recent
studies have shown that adversaries can fool the models even if they can only
access the models' hard-label output. However, since many queries are needed to
find imperceptible adversarial noise, reducing the number of queries is crucial
for these attacks. In this paper, we point out two limitations of existing
decision-based black-box attacks. We observe that they waste queries for
background noise optimization, and they do not take advantage of adversarial
perturbations generated for other images. We exploit 3D face alignment to
overcome these limitations and propose a general strategy for query-efficient
black-box attacks on face recognition named Geometrically Adaptive Dictionary
Attack (GADA). Our core idea is to create an adversarial perturbation in the UV
texture map and project it onto the face in the image. It greatly improves
query efficiency by limiting the perturbation search space to the facial area
and effectively recycling previous perturbations. We apply the GADA strategy to
two existing attack methods and show overwhelming performance improvement in
the experiments on the LFW and CPLFW datasets. Furthermore, we also present a
novel attack strategy that can circumvent query similarity-based stateful
detection that identifies the process of query-based black-box attacks.</p>
  </details>
</details>
<details>
  <summary>43. <b>标题：A Comparison of Deep Learning Architectures for Optical Galaxy  Morphology Classification</b></summary>
  <p><b>编号</b>：[125]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04353</p>
  <p><b>作者</b>：Ezra Fielding,  Clement N. Nyirenda,  Mattia Vaccari</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：predict galaxy zoo decals decision tree responses, generate accuracy metrics per decision tree question, deep learning architectures could prove beneficial, model training method proposed, optical galaxy morphology classification</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The classification of galaxy morphology plays a crucial role in understanding
galaxy formation and evolution. Traditionally, this process is done manually.
The emergence of deep learning techniques has given room for the automation of
this process. As such, this paper offers a comparison of deep learning
architectures to determine which is best suited for optical galaxy morphology
classification. Adapting the model training method proposed by Walmsley et al
in 2021, the Zoobot Python library is used to train models to predict Galaxy
Zoo DECaLS decision tree responses, made by volunteers, using EfficientNet B0,
DenseNet121 and ResNet50 as core model architectures. The predicted results are
then used to generate accuracy metrics per decision tree question to determine
architecture performance. DenseNet121 was found to produce the best results, in
terms of accuracy, with a reasonable training time. In future, further testing
with more deep learning architectures could prove beneficial.</p>
  </details>
</details>
<details>
  <summary>44. <b>标题：Off-policy Imitation Learning from Visual Inputs</b></summary>
  <p><b>编号</b>：[128]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04345</p>
  <p><b>作者</b>：Zhihao Cheng,  Li Shen,  Dacheng Tao</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：provided via extensive experiments using deepmind control suite, various successful applications utilizing expert states, another il setting -- il, utilizing online visual resources, opifvi employs data augmentation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recently, various successful applications utilizing expert states in
imitation learning (IL) have been witnessed. However, another IL setting -- IL
from visual inputs (ILfVI), which has a greater promise to be applied in
reality by utilizing online visual resources, suffers from low data-efficiency
and poor performance resulted from an on-policy learning manner and
high-dimensional visual inputs. We propose OPIfVI (Off-Policy Imitation from
Visual Inputs), which is composed of an off-policy learning manner, data
augmentation, and encoder techniques, to tackle the mentioned challenges,
respectively. More specifically, to improve data-efficiency, OPIfVI conducts IL
in an off-policy manner, with which sampled data can be used multiple times. In
addition, we enhance the stability of OPIfVI with spectral normalization to
mitigate the side-effect of off-policy training. The core factor, contributing
to the poor performance of ILfVI, that we think is the agent could not extract
meaningful features from visual inputs. Hence, OPIfVI employs data augmentation
from computer vision to help train encoders that can better extract features
from visual inputs. In addition, a specific structure of gradient
backpropagation for the encoder is designed to stabilize the encoder training.
At last, we demonstrate that OPIfVI is able to achieve expert-level performance
and outperform existing baselines no matter visual demonstrations or visual
observations are provided via extensive experiments using DeepMind Control
Suite.</p>
  </details>
</details>
<details>
  <summary>45. <b>标题：threaTrace: Detecting and Tracing Host-based Threats in Node Level  Through Provenance Graph Learning</b></summary>
  <p><b>编号</b>：[133]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04333</p>
  <p><b>作者</b>：Su Wang,  Zhiliang Wang,  Tao Zhou,  Xia Yin,  Dongqi Han,  Han Zhang,  Hongbin Sun,  Xingang Shi,  Jiahai Yang</p>
  <p><b>备注</b>：13 pages, 6 figures</p>
  <p><b>关键词</b>：system entity level without prior knowledge, art host intrusion detection systems, provenance graph represent system entities, learn every benign entity, edges represent system calls</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Host-based threats such as Program Attack, Malware Implantation, and Advanced
Persistent Threats (APT), are commonly adopted by modern attackers. Recent
studies propose leveraging the rich contextual information in data provenance
to detect threats in a host. Data provenance is a directed acyclic graph
constructed from system audit data. Nodes in a provenance graph represent
system entities (e.g., $processes$ and $files$) and edges represent system
calls in the direction of information flow. However, previous studies, which
extract features of the whole provenance graph, are not sensitive to the small
number of threat-related entities and thus result in low performance when
hunting stealthy threats.
We present threaTrace, an anomaly-based detector that detects host-based
threats at system entity level without prior knowledge of attack patterns. We
tailor GraphSAGE, an inductive graph neural network, to learn every benign
entity's role in a provenance graph. threaTrace is a real-time system, which is
scalable of monitoring a long-term running host and capable of detecting
host-based intrusion in their early phase. We evaluate threaTrace on three
public datasets. The results show that threaTrace outperforms three
state-of-the-art host intrusion detection systems.</p>
  </details>
</details>
<details>
  <summary>46. <b>标题：Characterizing the adversarial vulnerability of speech self-supervised  learning</b></summary>
  <p><b>编号</b>：[136]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04330</p>
  <p><b>作者</b>：Haibin Wu,  Bo Zheng,  Xu Li,  Xixin Wu,  Hung-yi Lee,  Helen Meng</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：leaderboard named speech processing universal performance benchmark, superb demonstrates speech ssl upstream models improve, speech model across various downstream speech tasks, supervised learning upstream model followed, various downstream tasks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A leaderboard named Speech processing Universal PERformance Benchmark
(SUPERB), which aims at benchmarking the performance of a shared
self-supervised learning (SSL) speech model across various downstream speech
tasks with minimal modification of architectures and small amount of data, has
fueled the research for speech representation learning. The SUPERB demonstrates
speech SSL upstream models improve the performance of various downstream tasks
through just minimal adaptation. As the paradigm of the self-supervised
learning upstream model followed by downstream tasks arouses more attention in
the speech community, characterizing the adversarial robustness of such
paradigm is of high priority. In this paper, we make the first attempt to
investigate the adversarial vulnerability of such paradigm under the attacks
from both zero-knowledge adversaries and limited-knowledge adversaries. The
experimental results illustrate that the paradigm proposed by SUPERB is
seriously vulnerable to limited-knowledge adversaries, and the attacks
generated by zero-knowledge adversaries are with transferability. The XAB test
verifies the imperceptibility of crafted adversarial attacks.</p>
  </details>
</details>
<details>
  <summary>47. <b>标题：Auto-Encoding Knowledge Graph for Unsupervised Medical Report Generation</b></summary>
  <p><b>编号</b>：[140]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04318</p>
  <p><b>作者</b>：Fenglin Liu,  Chenyu You,  Xian Wu,  Shen Ge,  Sheng Wang,  Xu Sun</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：unsupervised kgae generates desirable medical reports without using, unsupervised model knowledge graph auto, driven encoder projects medical images, receiving growing research interests, existing approaches mainly adopt</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Medical report generation, which aims to automatically generate a long and
coherent report of a given medical image, has been receiving growing research
interests. Existing approaches mainly adopt a supervised manner and heavily
rely on coupled image-report pairs. However, in the medical domain, building a
large-scale image-report paired dataset is both time-consuming and expensive.
To relax the dependency on paired data, we propose an unsupervised model
Knowledge Graph Auto-Encoder (KGAE) which accepts independent sets of images
and reports in training. KGAE consists of a pre-constructed knowledge graph, a
knowledge-driven encoder and a knowledge-driven decoder. The knowledge graph
works as the shared latent space to bridge the visual and textual domains; The
knowledge-driven encoder projects medical images and reports to the
corresponding coordinates in this latent space and the knowledge-driven decoder
generates a medical report given a coordinate in this space. Since the
knowledge-driven encoder and decoder can be trained with independent sets of
images and reports, KGAE is unsupervised. The experiments show that the
unsupervised KGAE generates desirable medical reports without using any
image-report training pairs. Moreover, KGAE can also work in both
semi-supervised and supervised settings, and accept paired images and reports
in training. By further fine-tuning with image-report pairs, KGAE consistently
outperforms the current state-of-the-art models on two datasets.</p>
  </details>
</details>
<details>
  <summary>48. <b>标题：Spirometry-based airways disease simulation and recognition using  Machine Learning approaches</b></summary>
  <p><b>编号</b>：[143]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04315</p>
  <p><b>作者</b>：Riccardo Dio (AROMATH, UCA),  André Galligo (AROMATH, UCA),  Angelos Mantzaflaris (AROMATH, UCA),  Benjamin Mauroy (UCA)</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：naive bias classifier show accuracy, accurately differentiate diseases based, different machine learning models, realized simulating healthy, least 99 %.</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The purpose of this study is to provide means to physicians for automated and
fast recognition of airways diseases. In this work, we mainly focus on measures
that can be easily recorded using a spirometer. The signals used in this
framework are simulated using the linear bi-compartment model of the lungs.
This allows us to simulate ventilation under the hypothesis of ventilation at
rest (tidal breathing). By changing the resistive and elastic parameters, data
samples are realized simulating healthy, fibrosis and asthma breathing. On this
synthetic data, different machine learning models are tested and their
performance is assessed. All but the Naive bias classifier show accuracy of at
least 99%. This represents a proof of concept that Machine Learning can
accurately differentiate diseases based on manufactured spirometry data. This
paves the way for further developments on the topic, notably testing the model
on real data.</p>
  </details>
</details>
<details>
  <summary>49. <b>标题：Graph Robustness Benchmark: Benchmarking the Adversarial Robustness of  Graph Machine Learning</b></summary>
  <p><b>编号</b>：[144]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04314</p>
  <p><b>作者</b>：Qinkai Zheng,  Xu Zou,  Yuxiao Dong,  Yukuo Cen,  Da Yin,  Jiarong Xu,  Yang Yang,  Jie Tang</p>
  <p><b>备注</b>：21 pages, 12 figures, NeurIPS 2021 Datasets and Benchmarks Track</p>
  <p><b>关键词</b>：grb also hosts public leaderboards across different scenarios, graph machine learning, escalating arms race, conduct extensive experiments, benchmark baseline techniques</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Adversarial attacks on graphs have posed a major threat to the robustness of
graph machine learning (GML) models. Naturally, there is an ever-escalating
arms race between attackers and defenders. However, the strategies behind both
sides are often not fairly compared under the same and realistic conditions. To
bridge this gap, we present the Graph Robustness Benchmark (GRB) with the goal
of providing a scalable, unified, modular, and reproducible evaluation for the
adversarial robustness of GML models. GRB standardizes the process of attacks
and defenses by 1) developing scalable and diverse datasets, 2) modularizing
the attack and defense implementations, and 3) unifying the evaluation protocol
in refined scenarios. By leveraging the GRB pipeline, the end-users can focus
on the development of robust GML models with automated data processing and
experimental evaluations. To support open and reproducible research on graph
adversarial learning, GRB also hosts public leaderboards across different
scenarios. As a starting point, we conduct extensive experiments to benchmark
baseline techniques. GRB is open-source and welcomes contributions from the
community. Datasets, codes, leaderboards are available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>50. <b>标题：A Relational Model for One-Shot Classification</b></summary>
  <p><b>编号</b>：[145]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04313</p>
  <p><b>作者</b>：Arturs Polis,  Alexander Ilin</p>
  <p><b>备注</b>：Published at ESANN 2021</p>
  <p><b>关键词</b>：shot classification model performs relational matching, shot image classification omniglot challenge, model exceeds human level accuracy, relational inductive bias, deep learning model</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We show that a deep learning model with built-in relational inductive bias
can bring benefits to sample-efficient learning, without relying on extensive
data augmentation. The proposed one-shot classification model performs
relational matching of a pair of inputs in the form of local and pairwise
attention. Our approach solves perfectly the one-shot image classification
Omniglot challenge. Our model exceeds human level accuracy, as well as the
previous state of the art, with no data augmentation.</p>
  </details>
</details>
<details>
  <summary>51. <b>标题：Assessing learned features of Deep Learning applied to EEG</b></summary>
  <p><b>编号</b>：[147]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04309</p>
  <p><b>作者</b>：Dung Truong,  Scott Makeig,  Arnaud Delorme</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：possibly identifying new class relevant biomarkers, many computer vision related tasks, eeg researchers using deep learning, reveal interesting eeg results, performing eeg classification tasks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Convolutional Neural Networks (CNNs) have achieved impressive performance on
many computer vision related tasks, such as object detection, image
recognition, image retrieval, etc. These achievements benefit from the CNNs'
outstanding capability to learn discriminative features with deep layers of
neuron structures and iterative training process. This has inspired the EEG
research community to adopt CNN in performing EEG classification tasks.
However, CNNs learned features are not immediately interpretable, causing a
lack of understanding of the CNNs' internal working mechanism. To improve CNN
interpretability, CNN visualization methods are applied to translate the
internal features into visually perceptible patterns for qualitative analysis
of CNN layers. Many CNN visualization methods have been proposed in the
Computer Vision literature to interpret the CNN network structure, operation,
and semantic concept, yet applications to EEG data analysis have been limited.
In this work we use 3 different methods to extract EEG-relevant features from a
CNN trained on raw EEG data: optimal samples for each classification category,
activation maximization, and reverse convolution. We applied these methods to a
high-performing Deep Learning model with state-of-the-art performance for an
EEG sex classification task, and show that the model features a difference in
the theta frequency band. We show that visualization of a CNN model can reveal
interesting EEG results. Using these tools, EEG researchers using Deep Learning
can better identify the learned EEG features, possibly identifying new class
relevant biomarkers.</p>
  </details>
</details>
<details>
  <summary>52. <b>标题：Learning Context-Aware Representations of Subtrees</b></summary>
  <p><b>编号</b>：[148]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04308</p>
  <p><b>作者</b>：Cedric Cook</p>
  <p><b>备注</b>：36 pages, 12 Figures. This work was carried out as a Master Thesis at Klarna Bank AB, under supervision of Stefan Magureanu</p>
  <p><b>关键词</b>：discuss current expert knowledge systems, model generates better representations, class web classification task, learning efficient representations, new model achieves</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This thesis tackles the problem of learning efficient representations of
complex, structured data with a natural application to web page and element
classification. We hypothesise that the context around the element inside the
web page is of high value to the problem and is currently under exploited. This
thesis aims to solve the problem of classifying web elements as subtrees of a
DOM tree by also considering their context.
To achieve this, first we discuss current expert knowledge systems that work
on structures, such as Tree-LSTM. Then, we propose context-aware extensions to
this model. We show that the new model achieves an average F1-score of 0.7973
on a multi-class web classification task. This model generates better
representations for various subtrees and may be used for applications such
element classification, state estimators in reinforcement learning over the Web
and more.</p>
  </details>
</details>
<details>
  <summary>53. <b>标题：Defense Against Explanation Manipulation</b></summary>
  <p><b>编号</b>：[150]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04303</p>
  <p><b>作者</b>：Ruixiang Tang,  Ninghao Liu,  Fan Yang,  Na Zou,  Xia Hu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：also brings additional benefits including smoothing explanations, explainable machine learning attracts increasing attention, new training scheme called adversarial training, directly specifying explanation values, atex improves model robustness</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Explainable machine learning attracts increasing attention as it improves
transparency of models, which is helpful for machine learning to be trusted in
real applications. However, explanation methods have recently been demonstrated
to be vulnerable to manipulation, where we can easily change a model's
explanation while keeping its prediction constant. To tackle this problem, some
efforts have been paid to use more stable explanation methods or to change
model configurations. In this work, we tackle the problem from the training
perspective, and propose a new training scheme called Adversarial Training on
EXplanations (ATEX) to improve the internal explanation stability of a model
regardless of the specific explanation method being applied. Instead of
directly specifying explanation values over data instances, ATEX only puts
requirement on model predictions which avoids involving second-order
derivatives in optimization. As a further discussion, we also find that
explanation stability is closely related to another property of the model,
i.e., the risk of being exposed to adversarial attack. Through experiments,
besides showing that ATEX improves model robustness against manipulation
targeting explanation, it also brings additional benefits including smoothing
explanations and improving the efficacy of adversarial training if applied to
the model.</p>
  </details>
</details>
<details>
  <summary>54. <b>标题：The Hardness Analysis of Thompson Sampling for Combinatorial  Semi-bandits with Greedy Oracle</b></summary>
  <p><b>编号</b>：[153]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04295</p>
  <p><b>作者</b>：Fang Kong,  Yueran Yang,  Wei Chen,  Shuai Li</p>
  <p><b>备注</b>：Accepted in NeurIPS, 2021</p>
  <p><b>关键词</b>：feasible since many combinatorial optimization problems, almost matching regret upper bound, order $\ omega (\ log, dependent regret lower bound, combinatorial optimization problems</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Thompson sampling (TS) has attracted a lot of interest in the bandit area. It
was introduced in the 1930s but has not been theoretically proven until recent
years. All of its analysis in the combinatorial multi-armed bandit (CMAB)
setting requires an exact oracle to provide optimal solutions with any input.
However, such an oracle is usually not feasible since many combinatorial
optimization problems are NP-hard and only approximation oracles are available.
An example (Wang and Chen, 2018) has shown the failure of TS to learn with an
approximation oracle. However, this oracle is uncommon and is designed only for
a specific problem instance. It is still an open question whether the
convergence analysis of TS can be extended beyond the exact oracle in CMAB. In
this paper, we study this question under the greedy oracle, which is a common
(approximation) oracle with theoretical guarantees to solve many (offline)
combinatorial optimization problems. We provide a problem-dependent regret
lower bound of order $\Omega(\log T/\Delta^2)$ to quantify the hardness of TS
to solve CMAB problems with greedy oracle, where $T$ is the time horizon and
$\Delta$ is some reward gap. We also provide an almost matching regret upper
bound. These are the first theoretical results for TS to solve CMAB with a
common approximation oracle and break the misconception that TS cannot work
with approximation oracles.</p>
  </details>
</details>
<details>
  <summary>55. <b>标题：BlueFog: Make Decentralized Algorithms Practical for Optimization and  Deep Learning</b></summary>
  <p><b>编号</b>：[155]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04287</p>
  <p><b>作者</b>：Bicheng Ying,  Kun Yuan,  Hanbin Hu,  Yiming Chen,  Wotao Yin</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：scale optimization tasks involving distributed datasets, art distributed deep learning package based, bluefog also adopts several system, mainstream dnn training tasks, bluefog offers intuitive interfaces</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Decentralized algorithm is a form of computation that achieves a global goal
through local dynamics that relies on low-cost communication between
directly-connected agents. On large-scale optimization tasks involving
distributed datasets, decentralized algorithms have shown strong, sometimes
superior, performance over distributed algorithms with a central node.
Recently, developing decentralized algorithms for deep learning has attracted
great attention. They are considered as low-communication-overhead alternatives
to those using a parameter server or the Ring-Allreduce protocol. However, the
lack of an easy-to-use and efficient software package has kept most
decentralized algorithms merely on paper. To fill the gap, we introduce
BlueFog, a python library for straightforward, high-performance implementations
of diverse decentralized algorithms. Based on a unified abstraction of various
communication operations, BlueFog offers intuitive interfaces to implement a
spectrum of decentralized algorithms, from those using a static, undirected
graph for synchronous operations to those using dynamic and directed graphs for
asynchronous operations. BlueFog also adopts several system-level acceleration
techniques to further optimize the performance on the deep learning tasks. On
mainstream DNN training tasks, BlueFog reaches a much higher throughput and
achieves an overall $1.2\times \sim 1.8\times$ speedup over Horovod, a
state-of-the-art distributed deep learning package based on Ring-Allreduce.
BlueFog is open source at this https URL.</p>
  </details>
</details>
<details>
  <summary>56. <b>标题：Deep Unsupervised Active Learning on Learnable Graphs</b></summary>
  <p><b>编号</b>：[156]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04286</p>
  <p><b>作者</b>：Handong Ma,  Changsheng Li,  Xinchu Shi,  Ye Yuan,  Guoren Wang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：novel deep unsupervised active learning model via learnable graphs, also incorporate shortcut connections among different layers, k $- nearest neighbor graph, learning optimal graph structures, leverage graph structure learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recently deep learning has been successfully applied to unsupervised active
learning. However, current method attempts to learn a nonlinear transformation
via an auto-encoder while ignoring the sample relation, leaving huge room to
design more effective representation learning mechanisms for unsupervised
active learning. In this paper, we propose a novel deep unsupervised Active
Learning model via Learnable Graphs, named ALLG. ALLG benefits from learning
optimal graph structures to acquire better sample representation and select
representative samples. To make the learnt graph structure more stable and
effective, we take into account $k$-nearest neighbor graph as a priori, and
learn a relation propagation graph structure. We also incorporate shortcut
connections among different layers, which can alleviate the well-known
over-smoothing problem to some extent. To the best of our knowledge, this is
the first attempt to leverage graph structure learning for unsupervised active
learning. Extensive experiments performed on six datasets demonstrate the
efficacy of our method.</p>
  </details>
</details>
<details>
  <summary>57. <b>标题：Batch Reinforcement Learning from Crowds</b></summary>
  <p><b>编号</b>：[158]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04279</p>
  <p><b>作者</b>：Guoxi Zhang,  Hisashi Kashima</p>
  <p><b>备注</b>：16 pages</p>
  <p><b>关键词</b>：batch reinforcement learning setting, expert humans using crowdsourcing, tasks without reward functions, batch reinforcement learning, atari datasets demonstrates</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A shortcoming of batch reinforcement learning is its requirement for rewards
in data, thus not applicable to tasks without reward functions. Existing
settings for lack of reward, such as behavioral cloning, rely on optimal
demonstrations collected from humans. Unfortunately, extensive expertise is
required for ensuring optimality, which hinder the acquisition of large-scale
data for complex tasks. This paper addresses the lack of reward in a batch
reinforcement learning setting by learning a reward function from preferences.
Generating preferences only requires a basic understanding of a task. Being a
mental process, generating preferences is faster than performing
demonstrations. So preferences can be collected at scale from non-expert humans
using crowdsourcing. This paper tackles a critical challenge that emerged when
collecting data from non-expert humans: the noise in preferences. A novel
probabilistic model is proposed for modelling the reliability of labels, which
utilizes labels collaboratively. Moreover, the proposed model smooths the
estimation with a learned reward function. Evaluation on Atari datasets
demonstrates the effectiveness of the proposed model, followed by an ablation
study to analyze the relative importance of the proposed ideas.</p>
  </details>
</details>
<details>
  <summary>58. <b>标题：Deep Marching Tetrahedra: a Hybrid Representation for High-Resolution 3D  Shape Synthesis</b></summary>
  <p><b>编号</b>：[159]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04276</p>
  <p><b>作者</b>：Tianchang Shen,  Jun Gao,  Kangxue Yin,  Ming-Yu Liu,  Sanja Fidler</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：resolution 3d shapes using simple user guides, approach significantly outperforms existing work, unlike deep 3d generative models, deep 3d conditional generative model, complex 3d animal shapes</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We introduce DMTet, a deep 3D conditional generative model that can
synthesize high-resolution 3D shapes using simple user guides such as coarse
voxels. It marries the merits of implicit and explicit 3D representations by
leveraging a novel hybrid 3D representation. Compared to the current implicit
approaches, which are trained to regress the signed distance values, DMTet
directly optimizes for the reconstructed surface, which enables us to
synthesize finer geometric details with fewer artifacts. Unlike deep 3D
generative models that directly generate explicit representations such as
meshes, our model can synthesize shapes with arbitrary topology. The core of
DMTet includes a deformable tetrahedral grid that encodes a discretized signed
distance function and a differentiable marching tetrahedra layer that converts
the implicit signed distance representation to the explicit surface mesh
representation. This combination allows joint optimization of the surface
geometry and topology as well as generation of the hierarchy of subdivisions
using reconstruction and adversarial losses defined explicitly on the surface
mesh. Our approach significantly outperforms existing work on conditional shape
synthesis from coarse voxel inputs, trained on a dataset of complex 3D animal
shapes. Project page: this https URL.</p>
  </details>
</details>
<details>
  <summary>59. <b>标题：Mimic: An adaptive algorithm for multivariate time series classification</b></summary>
  <p><b>编号</b>：[160]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04273</p>
  <p><b>作者</b>：Yuhui Wang,  Diane J. Cook</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：26 time series datasets support mimic, existing multivariate time series classifier, critical applications may rely, time series classifiers visually, time series data</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Time series data are valuable but are often inscrutable. Gaining trust in
time series classifiers for finance, healthcare, and other critical
applications may rely on creating interpretable models. Researchers have
previously been forced to decide between interpretable methods that lack
predictive power and deep learning methods that lack transparency. In this
paper, we propose a novel Mimic algorithm that retains the predictive accuracy
of the strongest classifiers while introducing interpretability. Mimic mirrors
the learning method of an existing multivariate time series classifier while
simultaneously producing a visual representation that enhances user
understanding of the learned model. Experiments on 26 time series datasets
support Mimic's ability to imitate a variety of time series classifiers
visually and accurately.</p>
  </details>
</details>
<details>
  <summary>60. <b>标题：Identifying Best Fair Intervention</b></summary>
  <p><b>编号</b>：[161]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04272</p>
  <p><b>作者</b>：Ruijiang Gao,  Han Feng</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：provide theoretical guarantees, best arm identification, given causal model, causal model, given node</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We study the problem of best arm identification with a fairness constraint in
a given causal model. The goal is to find a soft intervention on a given node
to maximize the outcome while meeting a fairness constraint by counterfactual
estimation with only partial knowledge of the causal model. The problem is
motivated by ensuring fairness on an online marketplace. We provide theoretical
guarantees on the probability of error and empirically examine the
effectiveness of our algorithm with a two-stage baseline.</p>
  </details>
</details>
<details>
  <summary>61. <b>标题：Group-Aware Threshold Adaptation for Fair Classification</b></summary>
  <p><b>编号</b>：[162]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04271</p>
  <p><b>作者</b>：Taeuk Jang,  Pengyi Shi,  Xiaoqian Wang</p>
  <p><b>备注</b>：19 pages 1 figures</p>
  <p><b>关键词</b>：provide rigorous theoretical analysis, learn adaptive classification thresholds, process existing fairness methods, low computational cost, getting increasing attention</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The fairness in machine learning is getting increasing attention, as its
applications in different fields continue to expand and diversify. To mitigate
the discriminated model behaviors between different demographic groups, we
introduce a novel post-processing method to optimize over multiple fairness
constraints through group-aware threshold adaptation. We propose to learn
adaptive classification thresholds for each demographic group by optimizing the
confusion matrix estimated from the probability distribution of a
classification model output. As we only need an estimated probability
distribution of model output instead of the classification model structure, our
post-processing model can be applied to a wide range of classification models
and improve fairness in a model-agnostic manner and ensure privacy. This even
allows us to post-process existing fairness methods to further improve the
trade-off between accuracy and fairness. Moreover, our model has low
computational cost. We provide rigorous theoretical analysis on the convergence
of our optimization algorithm and the trade-off between accuracy and fairness
of our method. Our method theoretically enables a better upper bound in near
optimality than existing method under same condition. Experimental results
demonstrate that our method outperforms state-of-the-art methods and obtains
the result that is closest to the theoretical accuracy-fairness trade-off
boundary.</p>
  </details>
</details>
<details>
  <summary>62. <b>标题：Federated Learning Based on Dynamic Regularization</b></summary>
  <p><b>编号</b>：[166]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04263</p>
  <p><b>作者</b>：Durmus Alp Emre Acar,  Yue Zhao,  Ramon Matas Navarro,  Matthew Mattina,  Paul N. Whatmough,  Venkatesh Saligrama</p>
  <p><b>备注</b>：Slightly extended version of ICLR 2021 Paper</p>
  <p><b>关键词</b>：view federated learning problem primarily, distributively training neural network models, novel federated learning method, either attempt inexact minimization, device level empirical loss</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose a novel federated learning method for distributively training
neural network models, where the server orchestrates cooperation between a
subset of randomly chosen devices in each round. We view Federated Learning
problem primarily from a communication perspective and allow more device level
computations to save transmission costs. We point out a fundamental dilemma, in
that the minima of the local-device level empirical loss are inconsistent with
those of the global empirical loss. Different from recent prior works, that
either attempt inexact minimization or utilize devices for parallelizing
gradient computation, we propose a dynamic regularizer for each device at each
round, so that in the limit the global and device solutions are aligned. We
demonstrate both through empirical results on real and synthetic data as well
as analytical results that our scheme leads to efficient training, in both
convex and non-convex settings, while being fully agnostic to device
heterogeneity and robust to large number of devices, partial participation and
unbalanced data.</p>
  </details>
</details>
<details>
  <summary>63. <b>标题：Personalized Benchmarking with the Ludwig Benchmarking Toolkit</b></summary>
  <p><b>编号</b>：[168]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04260</p>
  <p><b>作者</b>：Avanika Narayan,  Piero Molino,  Karan Goel,  Willie Neiswanger,  Christopher Ré (Department of Computer Science, Stanford University)</p>
  <p><b>备注</b>：14 pages, 14 figures, 35th Conference on Neural Information Processing Systems (NeurIPS 2021) Track on Datasets and Benchmarks</p>
  <p><b>关键词</b>：computational budget ), making fair comparisons difficult, users cannot use standard benchmark results, text classification across 7 models, machine learning models across domains, traditional benchmarks evaluate models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The rapid proliferation of machine learning models across domains and
deployment settings has given rise to various communities (e.g. industry
practitioners) which seek to benchmark models across tasks and objectives of
personal value. Unfortunately, these users cannot use standard benchmark
results to perform such value-driven comparisons as traditional benchmarks
evaluate models on a single objective (e.g. average accuracy) and fail to
facilitate a standardized training framework that controls for confounding
variables (e.g. computational budget), making fair comparisons difficult. To
address these challenges, we introduce the open-source Ludwig Benchmarking
Toolkit (LBT), a personalized benchmarking toolkit for running end-to-end
benchmark studies (from hyperparameter optimization to evaluation) across an
easily extensible set of tasks, deep learning models, datasets and evaluation
metrics. LBT provides a configurable interface for controlling training and
customizing evaluation, a standardized training framework for eliminating
confounding variables, and support for multi-objective evaluation. We
demonstrate how LBT can be used to create personalized benchmark studies with a
large-scale comparative analysis for text classification across 7 models and 9
datasets. We explore the trade-offs between inference latency and performance,
relationships between dataset attributes and performance, and the effects of
pretraining on convergence and robustness, showing how LBT can be used to
satisfy various benchmarking objectives.</p>
  </details>
</details>
<details>
  <summary>64. <b>标题：A Novel Data Pre-processing Technique: Making Data Mining Robust to  Different Units and Scales of Measurement</b></summary>
  <p><b>编号</b>：[172]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04253</p>
  <p><b>作者</b>：Arbind Agrahari Baniya,  Sunil Aryal,  Santosh KC</p>
  <p><b>备注</b>：This paper is published in a special issue of the Australian Journal of Intelligent Information Processing Systems as part of the proceedings of the International Conference on Neural Information Processing (ICONIP) 2019</p>
  <p><b>关键词</b>：many existing data mining algorithms use feature values directly, widely used data mining algorithms, many data mining applications, outcome across various algorithms, widely used min</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Many existing data mining algorithms use feature values directly in their
model, making them sensitive to units/scales used to measure/represent data.
Pre-processing of data based on rank transformation has been suggested as a
potential solution to overcome this issue. However, the resulting data after
pre-processing with rank transformation is uniformly distributed, which may not
be very useful in many data mining applications. In this paper, we present a
better and effective alternative based on ranks over multiple sub-samples of
data. We call the proposed pre-processing technique as ARES | Average Rank over
an Ensemble of Sub-samples. Our empirical results of widely used data mining
algorithms for classification and anomaly detection in a wide range of data
sets suggest that ARES results in more consistent task specific? outcome across
various algorithms and data sets. In addition to this, it results in better or
competitive outcome most of the time compared to the most widely used min-max
normalisation and the traditional rank transformation.</p>
  </details>
</details>
<details>
  <summary>65. <b>标题：Learning to Rectify for Robust Learning with Noisy Labels</b></summary>
  <p><b>编号</b>：[175]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04239</p>
  <p><b>作者</b>：Haoliang Sun,  Chenhui Guo,  Qi Wei,  Zhongyi Han,  Yilong Yin</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：leveraging sufficient information lying, existing works usually rely, directly generating weight values, propose warped probabilistic inference, existing approximated weighting function</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Label noise significantly degrades the generalization ability of deep models
in applications. Effective strategies and approaches, \textit{e.g.}
re-weighting, or loss correction, are designed to alleviate the negative impact
of label noise when training a neural network. Those existing works usually
rely on the pre-specified architecture and manually tuning the additional
hyper-parameters. In this paper, we propose warped probabilistic inference
(WarPI) to achieve adaptively rectifying the training procedure for the
classification network within the meta-learning scenario. In contrast to the
deterministic models, WarPI is formulated as a hierarchical probabilistic model
by learning an amortization meta-network, which can resolve sample ambiguity
and be therefore more robust to serious label noise. Unlike the existing
approximated weighting function of directly generating weight values from
losses, our meta-network is learned to estimate a rectifying vector from the
input of the logits and labels, which has the capability of leveraging
sufficient information lying in them. This provides an effective way to rectify
the learning procedure for the classification network, demonstrating a
significant improvement of the generalization ability. Besides, modeling the
rectifying vector as a latent variable and learning the meta-network can be
seamlessly integrated into the SGD optimization of the classification network.
We evaluate WarPI on four benchmarks of robust learning with noisy labels and
achieve the new state-of-the-art under variant noise types. Extensive study and
analysis also demonstrate the effectiveness of our model.</p>
  </details>
</details>
<details>
  <summary>66. <b>标题：Uncertainty Quantification in Neural Differential Equations</b></summary>
  <p><b>编号</b>：[184]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04207</p>
  <p><b>作者</b>：Olga Graf,  Pablo Flores,  Pavlos Protopapas,  Karim Pichara</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：deep learning based differential equation, make trustworthy predictions based, four different de types, make deep models, uncertain domain knowledge</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Uncertainty quantification (UQ) helps to make trustworthy predictions based
on collected observations and uncertain domain knowledge. With increased usage
of deep learning in various applications, the need for efficient UQ methods
that can make deep models more reliable has increased as well. Among
applications that can benefit from effective handling of uncertainty are the
deep learning based differential equation (DE) solvers. We adapt several
state-of-the-art UQ methods to get the predictive uncertainty for DE solutions
and show the results on four different DE types.</p>
  </details>
</details>
<details>
  <summary>67. <b>标题：VizAI : Selecting Accurate Visualizations of Numerical Data</b></summary>
  <p><b>编号</b>：[190]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04190</p>
  <p><b>作者</b>：Ritvik Vij,  Rohit Raj,  Madhur Singhal,  Manish Tanwar,  Srikanta Bedathur</p>
  <p><b>备注</b>：Proc. of the ACM India Joint International Conference on Data Sciences and Management of Data (CODS-COMAD) 2022 (9th ACM IKDD CODS and 27th COMAD) - To Appear</p>
  <p><b>关键词</b>：manual process involving many iterations, first generates various statistical properties, common use across various stages, reveal underlying statistical properties, require large training samples</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A good data visualization is not only a distortion-free graphical
representation of data but also a way to reveal underlying statistical
properties of the data. Despite its common use across various stages of data
analysis, selecting a good visualization often is a manual process involving
many iterations. Recently there has been interest in reducing this effort by
developing models that can recommend visualizations, but they are of limited
use since they require large training samples (data and visualization pairs)
and focus primarily on the design aspects rather than on assessing the
effectiveness of the selected visualization.
In this paper, we present VizAI, a generative-discriminative framework that
first generates various statistical properties of the data from a number of
alternative visualizations of the data. It is linked to a discriminative model
that selects the visualization that best matches the true statistics of the
data being visualized. VizAI can easily be trained with minimal supervision and
adapts to settings with varying degrees of supervision easily. Using
crowd-sourced judgements and a large repository of publicly available
visualizations, we demonstrate that VizAI outperforms the state of the art
methods that learn to recommend visualizations.</p>
  </details>
</details>
<details>
  <summary>68. <b>标题：CoughTrigger: Earbuds IMU Based Cough Detection Activator Using An  Energy-efficient Sensitivity-prioritized Time Series Classifier</b></summary>
  <p><b>编号</b>：[192]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04185</p>
  <p><b>作者</b>：Shibo Zhang,  Ebrahim Nemati,  Minh Dinh,  Nathan Folkman,  Tousif Ahmed,  Mahbubur Rahman,  Jilong Kuang,  Nabil Alshurafa,  Alex Gao</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：process audio signals hinders continuous audio, limited commercial wearable products, based model achieved 0, detecting coughs using wearables, intense power consumption needed</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Persistent coughs are a major symptom of respiratory-related diseases.
Increasing research attention has been paid to detecting coughs using
wearables, especially during the COVID-19 pandemic. Among all types of sensors
utilized, microphone is most widely used to detect coughs. However, the intense
power consumption needed to process audio signals hinders continuous
audio-based cough detection on battery-limited commercial wearable products,
such as earbuds. We present CoughTrigger, which utilizes a lower-power sensor,
an inertial measurement unit (IMU), in earbuds as a cough detection activator
to trigger a higher-power sensor for audio processing and classification. It is
able to run all-the-time as a standby service with minimal battery consumption
and trigger the audio-based cough detection when a candidate cough is detected
from IMU. Besides, the use of IMU brings the benefit of improved specificity of
cough detection. Experiments are conducted on 45 subjects and our IMU-based
model achieved 0.77 AUC score under leave one subject out evaluation. We also
validated its effectiveness on free-living data and through on-device
implementation.</p>
  </details>
</details>
<details>
  <summary>69. <b>标题：Teamwork makes von Neumann work: Min-Max Optimization in Two-Team  Zero-Sum Games</b></summary>
  <p><b>编号</b>：[196]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04178</p>
  <p><b>作者</b>：Fivos Kalogiannis,  Emmanouil-Vasileios Vlatakis-Gkaragkounis,  Ioannis Panageas</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：possible using gradient descent ascent, team games whose induced utility, team competition structure like multi, even asymptotic last iterate, agent generative adversarial networks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Motivated by recent advances in both theoretical and applied aspects of
multiplayer games, spanning from e-sports to multi-agent generative adversarial
networks, we focus on min-max optimization in team zero-sum games. In this
class of games, players are split in two teams with payoffs equal within the
same team and of opposite sign across the opponent team. Unlike the textbook
two-player zero-sum games, finding a Nash equilibrium in our class can be shown
to be CLS-hard, i.e., it is unlikely to have a polynomial time algorithm for
computing Nash equilibria. Moreover in this generalized framework, we establish
that even asymptotic last iterate or time average convergence to a Nash
Equilibrium is not possible using Gradient Descent Ascent (GDA), its optimistic
variant and extra gradient. Specifically, we present a family of team games
whose induced utility is \emph{non} multi-linear with \emph{non} attractive
\emph{per-se} mixed Nash Equilibria, as strict saddle points of the underlying
optimization landscape. Leveraging techniques from control theory, we
complement these negative results by designing a modified GDA that converges
locally to Nash equilibria. Finally, we discuss connections of our framework
with AI architectures with team competition structure like multi-agent
generative adversarial networks.</p>
  </details>
</details>
<details>
  <summary>70. <b>标题：Data-Efficient Deep Reinforcement Learning for Attitude Control of  Fixed-Wing UAVs: Field Experiments</b></summary>
  <p><b>编号</b>：[201]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04153</p>
  <p><b>作者</b>：Eivind Bøhn,  Erlend M. Coates,  Dirk Reinhardt,  Tor Arne Johansen</p>
  <p><b>备注</b>：This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible</p>
  <p><b>关键词</b>：automatically discover optimal control laws, wing unmanned aerial vehicles, handle complex nonlinear dynamics, wing uav operating directly, uncertain nonlinear dynamics</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Attitude control of fixed-wing unmanned aerial vehicles (UAVs)is a difficult
control problem in part due to uncertain nonlinear dynamics, actuator
constraints, and coupled longitudinal and lateral motions. Current
state-of-the-art autopilots are based on linear control and are thus limited in
their effectiveness and performance. Deep reinforcement learning (DRL) is a
machine learning method to automatically discover optimal control laws through
interaction with the controlled system, that can handle complex nonlinear
dynamics. We show in this paper that DRL can successfully learn to perform
attitude control of a fixed-wing UAV operating directly on the original
nonlinear dynamics, requiring as little as three minutes of flight data. We
initially train our model in a simulation environment and then deploy the
learned controller on the UAV in flight tests, demonstrating comparable
performance to the state-of-the-art ArduPlaneproportional-integral-derivative
(PID) attitude controller with no further online learning required. To better
understand the operation of the learned controller we present an analysis of
its behaviour, including a comparison to the existing well-tuned PID
controller.</p>
  </details>
</details>
<details>
  <summary>71. <b>标题：Optimization of the Model Predictive Control Meta-Parameters Through  Reinforcement Learning</b></summary>
  <p><b>编号</b>：[205]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04146</p>
  <p><b>作者</b>：Eivind Bøhn,  Sebastien Gros,  Signe Moe,  Tor Arne Johansen</p>
  <p><b>备注</b>：This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible</p>
  <p><b>关键词</b>：linear state feedback control law applied, jointly tuned using reinforcement learning, inverted pendulum control task, high computational complexity results, total computation time</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Model predictive control (MPC) is increasingly being considered for control
of fast systems and embedded applications. However, the MPC has some
significant challenges for such systems. Its high computational complexity
results in high power consumption from the control algorithm, which could
account for a significant share of the energy resources in battery-powered
embedded systems. The MPC parameters must be tuned, which is largely a
trial-and-error process that affects the control performance, the robustness
and the computational complexity of the controller to a high degree. In this
paper, we propose a novel framework in which any parameter of the control
algorithm can be jointly tuned using reinforcement learning(RL), with the goal
of simultaneously optimizing the control performance and the power usage of the
control algorithm. We propose the novel idea of optimizing the meta-parameters
of MPCwith RL, i.e. parameters affecting the structure of the MPCproblem as
opposed to the solution to a given problem. Our control algorithm is based on
an event-triggered MPC where we learn when the MPC should be re-computed, and a
dual mode MPC and linear state feedback control law applied in between MPC
computations. We formulate a novel mixture-distribution policy and show that
with joint optimization we achieve improvements that do not present themselves
when optimizing the same parameters in isolation. We demonstrate our framework
on the inverted pendulum control task, reducing the total computation time of
the control system by 36% while also improving the control performance by 18.4%
over the best-performing MPC baseline.</p>
  </details>
</details>
<details>
  <summary>72. <b>标题：Look at the Variance! Efficient Black-box Explanations with Sobol-based  Sensitivity Analysis</b></summary>
  <p><b>编号</b>：[206]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04138</p>
  <p><b>作者</b>：Thomas Fel,  Remi Cadene,  Mathieu Chalvidal,  Matthieu Cord,  David Vigouroux,  Thomas Serre</p>
  <p><b>备注</b>：NeurIPS2021</p>
  <p><b>关键词</b>：box methods -- even surpassing, using perturbation masks coupled, proposed method leads, novel attribution method, computing time compared</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We describe a novel attribution method which is grounded in Sensitivity
Analysis and uses Sobol indices. Beyond modeling the individual contributions
of image regions, Sobol indices provide an efficient way to capture
higher-order interactions between image regions and their contributions to a
neural network's prediction through the lens of variance. We describe an
approach that makes the computation of these indices efficient for
high-dimensional problems by using perturbation masks coupled with efficient
estimators to handle the high dimensionality of images. Importantly, we show
that the proposed method leads to favorable scores on standard benchmarks for
vision (and language models) while drastically reducing the computing time
compared to other black-box methods -- even surpassing the accuracy of
state-of-the-art white-box methods which require access to internal
representations. Our code is freely available:
this https URL</p>
  </details>
</details>
<details>
  <summary>73. <b>标题：Plumber: Diagnosing and Removing Performance Bottlenecks in Machine  Learning Data Pipelines</b></summary>
  <p><b>编号</b>：[209]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04131</p>
  <p><b>作者</b>：Michael Kuchnik,  Ana Klimovic,  Jiri Simsa,  George Amvrosiadis,  Virginia Smith</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：interprettable operational analysis analytical model, model training jobs could benefit, across five representative ml pipelines, 2 million ml jobs, implement efficient input pipelines</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Input pipelines, which ingest and transform input data, are an essential part
of training Machine Learning (ML) models. However, it is challenging to
implement efficient input pipelines, as it requires reasoning about
parallelism, asynchrony, and variability in fine-grained profiling information.
Our analysis of over 2 million ML jobs in Google datacenters reveals that a
significant fraction of model training jobs could benefit from faster input
data pipelines. At the same time, our analysis reveals that most jobs do not
saturate host hardware, pointing in the direction of software-based
bottlenecks. Motivated by these findings, we propose Plumber, a tool for
finding bottlenecks in ML input pipelines. Plumber uses an extensible and
interprettable operational analysis analytical model to automatically tune
parallelism, prefetching, and caching under host resource constraints. Across
five representative ML pipelines, Plumber obtains speedups of up to 46x for
misconfigured pipelines. By automating caching, Plumber obtains end-to-end
speedups of over 40% compared to state-of-the-art tuners.</p>
  </details>
</details>
<details>
  <summary>74. <b>标题：NLP From Scratch Without Large-Scale Pretraining: A Simple and Efficient  Framework</b></summary>
  <p><b>编号</b>：[210]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04130</p>
  <p><b>作者</b>：Xingcheng Yao,  Yanan Zheng,  Xiaocong Yang,  Zhilin Yang</p>
  <p><b>备注</b>：13 pages, 5 figures</p>
  <p><b>关键词</b>：many nlp tasks due, tlm achieves results better, tlm uses task data, labeled task data, pretrained language models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Pretrained language models have become the standard approach for many NLP
tasks due to strong performance, but they are very expensive to train. We
propose a simple and efficient learning framework, TLM, that does not rely on
large-scale pretraining. Given some labeled task data and a large general
corpus, TLM uses task data as queries to retrieve a tiny subset of the general
corpus and jointly optimizes the task objective and the language modeling
objective from scratch. On eight classification datasets in four domains, TLM
achieves results better than or similar to pretrained language models (e.g.,
RoBERTa-Large) while reducing the training FLOPs by two orders of magnitude.
With high accuracy and efficiency, we hope TLM will contribute to democratizing
NLP and expediting its development.</p>
  </details>
</details>
<details>
  <summary>75. <b>标题：NeurInt : Learning to Interpolate through Neural ODEs</b></summary>
  <p><b>编号</b>：[212]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04123</p>
  <p><b>作者</b>：Avinandan Bose,  Aniket Das,  Yatin Dandi,  Piyush Rai</p>
  <p><b>备注</b>：Accepted (Spotlight paper) at the NeurIPS 2021 Workshop on the Symbiosis of Deep Learning and Differential Equations (DLDE)</p>
  <p><b>关键词</b>：applications require learning image generation models whose latent space effectively captures, two given images using latent second, order neural ordinary differential equations, latent space ),, interpolation trajectories lacking smoothness</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A wide range of applications require learning image generation models whose
latent space effectively captures the high-level factors of variation present
in the data distribution. The extent to which a model represents such
variations through its latent space can be judged by its ability to interpolate
between images smoothly. However, most generative models mapping a fixed prior
to the generated images lead to interpolation trajectories lacking smoothness
and containing images of reduced quality. In this work, we propose a novel
generative model that learns a flexible non-parametric prior over interpolation
trajectories, conditioned on a pair of source and target images. Instead of
relying on deterministic interpolation methods (such as linear or spherical
interpolation in latent space), we devise a framework that learns a
distribution of trajectories between two given images using Latent Second-Order
Neural Ordinary Differential Equations. Through a hybrid combination of
reconstruction and adversarial losses, the generator is trained to map the
sampled points from these trajectories to sequences of realistic images that
smoothly transition from the source to the target image. Through comprehensive
qualitative and quantitative experiments, we demonstrate our approach's
effectiveness in generating images of improved quality as well as its ability
to learn a diverse distribution over smooth interpolation trajectories for any
pair of real source and target images.</p>
  </details>
</details>
<details>
  <summary>76. <b>标题：MetaMIML: Meta Multi-Instance Multi-Label Learning</b></summary>
  <p><b>编号</b>：[217]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04112</p>
  <p><b>作者</b>：Yuanlin Yang,  Guoxian Yu,  Jun Wang,  Lei Liu,  Carlotta Domeniconi,  Maozu Guo</p>
  <p><b>备注</b>：10 pages, 2 figures</p>
  <p><b>关键词</b>：generally need abundant labeled data, current miml solutions still focus, effectively mine interdependent miml objects, meta learning based approach, data level improving</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Multi-Instance Multi-Label learning (MIML) models complex objects (bags),
each of which is associated with a set of interrelated labels and composed with
a set of instances. Current MIML solutions still focus on a single-type of
objects and assumes an IID distribution of training data. But these objects are
linked with objects of other types, %(i.e., pictures in Facebook link with
various users), which also encode the semantics of target objects. In addition,
they generally need abundant labeled data for training. To effectively mine
interdependent MIML objects of different types, we propose a network embedding
and meta learning based approach (MetaMIML). MetaMIML introduces the context
learner with network embedding to capture semantic information of objects of
different types, and the task learner to extract the meta knowledge for fast
adapting to new tasks. In this way, MetaMIML can naturally deal with MIML
objects at data level improving, but also exploit the power of meta-learning at
the model enhancing. Experiments on benchmark datasets demonstrate that
MetaMIML achieves a significantly better performance than state-of-the-art
algorithms.</p>
  </details>
</details>
<details>
  <summary>77. <b>标题：DQRE-SCnet: A novel hybrid approach for selecting users in Federated  Learning with Deep-Q-Reinforcement Learning based on Spectral Clustering</b></summary>
  <p><b>编号</b>：[218]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04105</p>
  <p><b>作者</b>：Mohsen Ahmadi,  Ali Taghavirashidizadeh,  Danial Javaheri,  Armin Masoumian,  Saeid Jafarzadeh Ghoushchi,  Yaghoub Pourasad</p>
  <p><b>备注</b>：14 pages, Accepted, Elsevier (Journal of King Saud University - Computer and Information Sciences)</p>
  <p><b>关键词</b>：learning applications require decentralized learning based, learning participant communication rounds benefit, teaching detailed machine learning models, federated learning allows various parties, people avoid sensitive data sharing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Machine learning models based on sensitive data in the real-world promise
advances in areas ranging from medical screening to disease outbreaks,
agriculture, industry, defense science, and more. In many applications,
learning participant communication rounds benefit from collecting their own
private data sets, teaching detailed machine learning models on the real data,
and sharing the benefits of using these models. Due to existing privacy and
security concerns, most people avoid sensitive data sharing for training.
Without each user demonstrating their local data to a central server, Federated
Learning allows various parties to train a machine learning algorithm on their
shared data jointly. This method of collective privacy learning results in the
expense of important communication during training. Most large-scale
machine-learning applications require decentralized learning based on data sets
generated on various devices and places. Such datasets represent an essential
obstacle to decentralized learning, as their diverse contexts contribute to
significant differences in the delivery of data across devices and locations.
Researchers have proposed several ways to achieve data privacy in Federated
Learning systems. However, there are still challenges with homogeneous local
data. This research approach is to select nodes (users) to share their data in
Federated Learning for independent data-based equilibrium to improve accuracy,
reduce training time, and increase convergence. Therefore, this research
presents a combined Deep-QReinforcement Learning Ensemble based on Spectral
Clustering called DQRE-SCnet to choose a subset of devices in each
communication round. Based on the results, it has been displayed that it is
possible to decrease the number of communication rounds needed in Federated
Learning.</p>
  </details>
</details>
<details>
  <summary>78. <b>标题：Uncertainty Calibration for Ensemble-Based Debiasing Methods</b></summary>
  <p><b>编号</b>：[219]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04104</p>
  <p><b>作者</b>：Ruibin Xiong,  Yimeng Chen,  Liang Pang,  Xueqi Chen,  Yanyan Lan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：stage debiasing framework consistently outperforms, producing accurate uncertainty estimations, fact verification tasks show, inaccurate uncertainty estimations, based debiasing framework</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Ensemble-based debiasing methods have been shown effective in mitigating the
reliance of classifiers on specific dataset bias, by exploiting the output of a
bias-only model to adjust the learning target. In this paper, we focus on the
bias-only model in these ensemble-based methods, which plays an important role
but has not gained much attention in the existing literature. Theoretically, we
prove that the debiasing performance can be damaged by inaccurate uncertainty
estimations of the bias-only model. Empirically, we show that existing
bias-only models fall short in producing accurate uncertainty estimations.
Motivated by these findings, we propose to conduct calibration on the bias-only
model, thus achieving a three-stage ensemble-based debiasing framework,
including bias modeling, model calibrating, and debiasing. Experimental results
on NLI and fact verification tasks show that our proposed three-stage debiasing
framework consistently outperforms the traditional two-stage one in
out-of-distribution accuracy.</p>
  </details>
</details>
<details>
  <summary>79. <b>标题：Developing neural machine translation models for Hungarian-English</b></summary>
  <p><b>编号</b>：[221]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04099</p>
  <p><b>作者</b>：Attila Nagy</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：propose 5 different augmentation methods, evaluating different data augmentation methods, detailed exploratory data analysis, proposed data augmentation techniques, detailed literature review</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>I train models for the task of neural machine translation for
English-Hungarian and Hungarian-English, using the Hunglish2 corpus. The main
contribution of this work is evaluating different data augmentation methods
during the training of NMT models. I propose 5 different augmentation methods
that are structure-aware, meaning that instead of randomly selecting words for
blanking or replacement, the dependency tree of sentences is used as a basis
for augmentation. I start my thesis with a detailed literature review on neural
networks, sequential modeling, neural machine translation, dependency parsing
and data augmentation. After a detailed exploratory data analysis and
preprocessing of the Hunglish2 corpus, I perform experiments with the proposed
data augmentation techniques. The best model for Hungarian-English achieves a
BLEU score of 33.9, while the best model for English-Hungarian achieves a BLEU
score of 28.6.</p>
  </details>
</details>
<details>
  <summary>80. <b>标题：Iterative Causal Discovery in the Possible Presence of Latent  Confounders and Selection Bias</b></summary>
  <p><b>编号</b>：[223]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04095</p>
  <p><b>作者</b>：Raanan Y. Rohekar,  Shami Nisimov,  Yaniv Gurwicz,  Gal Novik</p>
  <p><b>备注</b>：35th Conference on Neural Information Processing Systems (NeurIPS 2021). arXiv admin note: text overlap with arXiv:2012.07513</p>
  <p><b>关键词</b>：icd requires significantly fewer ci tests, higher statistical power --, smaller conditioning sets --, called iterative causal discovery, accurate causal graphs compared</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present a sound and complete algorithm, called iterative causal discovery
(ICD), for recovering causal graphs in the presence of latent confounders and
selection bias. ICD relies on the causal Markov and faithfulness assumptions
and recovers the equivalence class of the underlying causal graph. It starts
with a complete graph, and consists of a single iterative stage that gradually
refines this graph by identifying conditional independence (CI) between
connected nodes. Independence and causal relations entailed after any iteration
are correct, rendering ICD anytime. Essentially, we tie the size of the CI
conditioning set to its distance on the graph from the tested nodes, and
increase this value in the successive iteration. Thus, each iteration refines a
graph that was recovered by previous iterations having smaller conditioning
sets -- a higher statistical power -- which contributes to stability. We
demonstrate empirically that ICD requires significantly fewer CI tests and
learns more accurate causal graphs compared to FCI, FCI+, and RFCI algorithms.</p>
  </details>
</details>
<details>
  <summary>81. <b>标题：Sampling from Log-Concave Distributions with Infinity-Distance  Guarantees and Applications to Differentially Private Optimization</b></summary>
  <p><b>编号</b>：[226]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04089</p>
  <p><b>作者</b>：Oren Mangoubi,  Nisheeth K. Vishnoi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：concave distribution $\ pi (\ theta )\ propto e ^{- f (\ theta )}$, frac {\ nu (\ theta )}{\ pi (\ theta )}|$, lrd }{\ varepsilon r }))\ times md ^{\ omega, $\ varepsilon $- pure differentially private algorithms, distance $\ sup_ {\ theta</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>For a $d$-dimensional log-concave distribution $\pi(\theta)\propto
e^{-f(\theta)}$ on a polytope $K$, we consider the problem of outputting
samples from a distribution $\nu$ which is $O(\varepsilon)$-close in
infinity-distance $\sup_{\theta\in K}|\log\frac{\nu(\theta)}{\pi(\theta)}|$ to
$\pi$. Such samplers with infinity-distance guarantees are specifically desired
for differentially private optimization as traditional sampling algorithms
which come with total-variation distance or KL divergence bounds are
insufficient to guarantee differential privacy. Our main result is an algorithm
that outputs a point from a distribution $O(\varepsilon)$-close to $\pi$ in
infinity-distance and requires
$O((md+dL^2R^2)\times(LR+d\log(\frac{Rd+LRd}{\varepsilon r}))\times
md^{\omega-1})$ arithmetic operations, where $f$ is $L$-Lipschitz, $K$ is
defined by $m$ inequalities, is contained in a ball of radius $R$ and contains
a ball of smaller radius $r$, and $\omega$ is the matrix-multiplication
constant. In particular this runtime is logarithmic in $\frac{1}{\varepsilon}$
and significantly improves on prior works. Technically, we depart from the
prior works that construct Markov chains on a
$\frac{1}{\varepsilon^2}$-discretization of $K$ to achieve a sample with
$O(\varepsilon)$ infinity-distance error, and present a method to convert
continuous samples from $K$ with total-variation bounds to samples with
infinity bounds. To achieve improved dependence on $d$, we present a
"soft-threshold" version of the Dikin walk which may be of independent
interest. Plugging our algorithm into the framework of the exponential
mechanism yields similar improvements in the running time of $\varepsilon$-pure
differentially private algorithms for optimization problems such as empirical
risk minimization of Lipschitz-convex functions and low-rank approximation,
while still achieving the tightest known utility bounds.</p>
  </details>
</details>
<details>
  <summary>82. <b>标题：Meta Cross-Modal Hashing on Long-Tailed Data</b></summary>
  <p><b>编号</b>：[227]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04086</p>
  <p><b>作者</b>：Runmin Wang,  Guoxian Yu,  Carlotta Domeniconi,  Xiangliang Zhang</p>
  <p><b>备注</b>：10 pages, 4 figures</p>
  <p><b>关键词</b>：metacmh first learns direct features, approximate nearest neighbor search, metacmh performs significantly better, real world data often, learns hash functions</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Due to the advantage of reducing storage while speeding up query time on big
heterogeneous data, cross-modal hashing has been extensively studied for
approximate nearest neighbor search of multi-modal data. Most hashing methods
assume that training data is class-balanced.However, in practice, real world
data often have a long-tailed distribution. In this paper, we introduce a
meta-learning based cross-modal hashing method (MetaCMH) to handle long-tailed
data. Due to the lack of training samples in the tail classes, MetaCMH first
learns direct features from data in different modalities, and then introduces
an associative memory module to learn the memory features of samples of the
tail classes. It then combines the direct and memory features to obtain meta
features for each sample. For samples of the head classes of the long tail
distribution, the weight of the direct features is larger, because there are
enough training data to learn them well; while for rare classes, the weight of
the memory features is larger. Finally, MetaCMH uses a likelihood loss function
to preserve the similarity in different modalities and learns hash functions in
an end-to-end fashion. Experiments on long-tailed datasets show that MetaCMH
performs significantly better than state-of-the-art methods, especially on the
tail classes.</p>
  </details>
</details>
<details>
  <summary>83. <b>标题：Cross-modal Zero-shot Hashing by Label Attributes Embedding</b></summary>
  <p><b>编号</b>：[231]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04080</p>
  <p><b>作者</b>：Runmin Wang,  Guoxian Yu,  Lei Liu,  Lizhen Cui,  Carlotta Domeniconi,  Xiangliang Zhang</p>
  <p><b>备注</b>：7 pages, 2 figures</p>
  <p><b>关键词</b>：modal approximate nearest neighbor search, unseen ones using label attributes, laeh outperforms related representative zero, cmh solutions ideally assume, initial semantic attribute vectors</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Cross-modal hashing (CMH) is one of the most promising methods in cross-modal
approximate nearest neighbor search. Most CMH solutions ideally assume the
labels of training and testing set are identical. However, the assumption is
often violated, causing a zero-shot CMH problem. Recent efforts to address this
issue focus on transferring knowledge from the seen classes to the unseen ones
using label attributes. However, the attributes are isolated from the features
of multi-modal data. To reduce the information gap, we introduce an approach
called LAEH (Label Attributes Embedding for zero-shot cross-modal Hashing).
LAEH first gets the initial semantic attribute vectors of labels by word2vec
model and then uses a transformation network to transform them into a common
subspace. Next, it leverages the hash vectors and the feature similarity matrix
to guide the feature extraction network of different modalities. At the same
time, LAEH uses the attribute similarity as the supplement of label similarity
to rectify the label embedding and common subspace. Experiments show that LAEH
outperforms related representative zero-shot and cross-modal hashing methods.</p>
  </details>
</details>
<details>
  <summary>84. <b>标题：Open-Set Crowdsourcing using Multiple-Source Transfer Learning</b></summary>
  <p><b>编号</b>：[235]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04073</p>
  <p><b>作者</b>：Guangyang Han,  Guoxian Yu,  Lei Liu,  Lizhen Cui,  Carlotta Domeniconi,  Xiangliang Zhang</p>
  <p><b>备注</b>：8 pages, 1 figures</p>
  <p><b>关键词</b>：oscrowd integrates crowd theme related datasets, source open set transfer learning, facilitate partial transfer learning, open set crowdsourcing problem, related crowdsourcing solutions</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We raise and define a new crowdsourcing scenario, open set crowdsourcing,
where we only know the general theme of an unfamiliar crowdsourcing project,
and we don't know its label space, that is, the set of possible labels. This is
still a task annotating problem, but the unfamiliarity with the tasks and the
label space hampers the modelling of the task and of workers, and also the
truth inference. We propose an intuitive solution, OSCrowd. First, OSCrowd
integrates crowd theme related datasets into a large source domain to
facilitate partial transfer learning to approximate the label space inference
of these tasks. Next, it assigns weights to each source domain based on
category correlation. After this, it uses multiple-source open set transfer
learning to model crowd tasks and assign possible annotations. The label space
and annotations given by transfer learning will be used to guide and
standardize crowd workers' annotations. We validate OSCrowd in an online
scenario, and prove that OSCrowd solves the open set crowdsourcing problem,
works better than related crowdsourcing solutions.</p>
  </details>
</details>
<details>
  <summary>85. <b>标题：DVS: Deep Visibility Series and its Application in Construction Cost  Index Forecasting</b></summary>
  <p><b>编号</b>：[236]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04071</p>
  <p><b>作者</b>：Tianxiang Zhan,  Yuanpeng He,  Hanwen Li,  Fuyuan Xiao</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：ann ), convolutional neural network, new time series forecasting methods, obtained superior forecast accuracy, construction cost index forecast, obtained better forecasting effects</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Time series forecasting has always been a hot spot in scientific research.
With the development of artificial intelligence, new time series forecasting
methods have obtained better forecasting effects and forecasting performance
through bionic research and improvements to the past methods. Visibility Graph
(VG) algorithm is often used for time series prediction in previous research,
but the prediction effect is not as good as deep learning prediction methods
such as Artificial Neural Network (ANN), Convolutional Neural Network (CNN) and
Long Short-Term Memory Network (LSTM) prediction. The VG algorithm contains a
wealth of network information, but previous studies did not effectively use the
network information to make predictions, resulting in relatively large
prediction errors. In order to solve this problem, this paper proposes the Deep
Visibility Series (DVS) module through the bionic design of VG and the
expansion of the past research, which is the first time to combine VG with
bionic design and deep network. By applying the bionic design of biological
vision to VG, the time series of DVS has obtained superior forecast accuracy,
which has made a contribution to time series forecasting. At the same time,
this paper applies the DVS forecasting method to the construction cost index
forecast, which has practical significance.</p>
  </details>
</details>
<details>
  <summary>86. <b>标题：Crowdsourcing with Meta-Workers: A New Way to Save the Budget</b></summary>
  <p><b>编号</b>：[238]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04068</p>
  <p><b>作者</b>：Guangyang Han,  Guoxian Yu,  Lizhen Cui,  Carlotta Domeniconi,  Xiangliang Zhang</p>
  <p><b>备注</b>：11 pages, 6 figures</p>
  <p><b>关键词</b>：workers using different meta learning algorithms, e ., image classification, art task assignment methods, unlike regular crowd workers, first cluster unlabeled data</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Due to the unreliability of Internet workers, it's difficult to complete a
crowdsourcing project satisfactorily, especially when the tasks are multiple
and the budget is limited. Recently, meta learning has brought new vitality to
few-shot learning, making it possible to obtain a classifier with a fair
performance using only a few training samples. Here we introduce the concept of
\emph{meta-worker}, a machine annotator trained by meta learning for types of
tasks (i.e., image classification) that are well-fit for AI. Unlike regular
crowd workers, meta-workers can be reliable, stable, and more importantly,
tireless and free. We first cluster unlabeled data and ask crowd workers to
repeatedly annotate the instances nearby the cluster centers; we then leverage
the annotated data and meta-training datasets to build a cluster of
meta-workers using different meta learning algorithms. Subsequently,
meta-workers are asked to annotate the remaining crowdsourced tasks. The
Jensen-Shannon divergence is used to measure the disagreement among the
annotations provided by the meta-workers, which determines whether or not crowd
workers should be invited for further annotation of the same task. Finally, we
model meta-workers' preferences and compute the consensus annotation by
weighted majority voting. Our empirical study confirms that, by combining
machine and human intelligence, we can accomplish a crowdsourcing project with
a lower budget than state-of-the-art task assignment methods, while achieving a
superior or comparable quality.</p>
  </details>
</details>
<details>
  <summary>87. <b>标题：High Performance Out-of-sample Embedding Techniques for Multidimensional  Scaling</b></summary>
  <p><b>编号</b>：[239]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04067</p>
  <p><b>作者</b>：Samudra Herath,  Matthew Roughan,  Gary Glonek</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：make data analysis feasible, neural network model outperforms, present two ose techniques, many traditional dr techniques, truly large data sets</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The recent rapid growth of the dimension of many datasets means that many
approaches to dimension reduction (DR) have gained significant attention.
High-performance DR algorithms are required to make data analysis feasible for
big and fast data sets. However, many traditional DR techniques are challenged
by truly large data sets. In particular multidimensional scaling (MDS) does not
scale well. MDS is a popular group of DR techniques because it can perform DR
on data where the only input is a dissimilarity function. However, common
approaches are at least quadratic in memory and computation and, hence,
prohibitive for large-scale data.
We propose an out-of-sample embedding (OSE) solution to extend the MDS
algorithm for large-scale data utilising the embedding of only a subset of the
given data. We present two OSE techniques: the first based on an optimisation
approach and the second based on a neural network model. With a minor trade-off
in the approximation, the out-of-sample techniques can process large-scale data
with reasonable computation and memory requirements. While both methods perform
well, the neural network model outperforms the optimisation approach of the OSE
solution in terms of efficiency. OSE has the dual benefit that it allows fast
DR on streaming datasets as well as static databases.</p>
  </details>
</details>
<details>
  <summary>88. <b>标题：Positivity Validation Detection and Explainability via Zero Fraction  Multi-Hypothesis Testing and Asymmetrically Pruned Decision Trees</b></summary>
  <p><b>编号</b>：[251]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04033</p>
  <p><b>作者</b>：Guy Wolf,  Gil Shabat,  Hanan Shteingart</p>
  <p><b>备注</b>：Talk accepted to Causal Data Science Meeting, 2021</p>
  <p><b>关键词</b>：second step uses asymmetrically pruned decision trees, latter distribution using multiple hypothesis testing, create positivity violation labels, two steps process, large software enterprise</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Positivity is one of the three conditions for causal inference from
observational data. The standard way to validate positivity is to analyze the
distribution of propensity. However, to democratize the ability to do causal
inference by non-experts, it is required to design an algorithm to (i) test
positivity and (ii) explain where in the covariate space positivity is lacking.
The latter could be used to either suggest the limitation of further causal
analysis and/or encourage experimentation where positivity is violated. The
contribution of this paper is first present the problem of automatic positivity
analysis and secondly to propose an algorithm based on a two steps process. The
first step, models the propensity condition on the covariates and then analyze
the latter distribution using multiple hypothesis testing to create positivity
violation labels. The second step uses asymmetrically pruned decision trees for
explainability. The latter is further converted into readable text a non-expert
can understand. We demonstrate our method on a proprietary data-set of a large
software enterprise.</p>
  </details>
</details>
<details>
  <summary>89. <b>标题：A-PixelHop: A Green, Robust and Explainable Fake-Image Detector</b></summary>
  <p><b>编号</b>：[259]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04012</p>
  <p><b>作者</b>：Yao Zhu,  Xinyu Wang,  Hong-Shuo Chen,  Ronald Salloum,  C.-C. Jay Kuo</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：contains four building modules, applying multiple filter banks, multiple binary classifiers, small model size, low computational complexity</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A novel method for detecting CNN-generated images, called Attentive PixelHop
(or A-PixelHop), is proposed in this work. It has three advantages: 1) low
computational complexity and a small model size, 2) high detection performance
against a wide range of generative models, and 3) mathematical transparency.
A-PixelHop is designed under the assumption that it is difficult to synthesize
high-quality, high-frequency components in local regions. It contains four
building modules: 1) selecting edge/texture blocks that contain significant
high-frequency components, 2) applying multiple filter banks to them to obtain
rich sets of spatial-spectral responses as features, 3) feeding features to
multiple binary classifiers to obtain a set of soft decisions, 4) developing an
effective ensemble scheme to fuse the soft decisions into the final decision.
Experimental results show that A-PixelHop outperforms state-of-the-art methods
in detecting CycleGAN-generated images. Furthermore, it can generalize well to
unseen generative models and datasets.</p>
  </details>
</details>
<details>
  <summary>90. <b>标题：A Review of Location Encoding for GeoAI: Methods and Applications</b></summary>
  <p><b>编号</b>：[262]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04006</p>
  <p><b>作者</b>：Gengchen Mai,  Krzysztof Janowicz,  Yingjie Hu,  Song Gao,  Bo Yan,  Rui Zhu,  Ling Cai,  Ni Lao</p>
  <p><b>备注</b>：32 Pages, 5 Figures, Accepted to International Journal of Geographical Information Science, 2021</p>
  <p><b>关键词</b>：g ., remote sensing images ),, g ., administrative regions ), graphs, g ., trajectories ), polygons, g ., transportation networks ),, downstream machine learning models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A common need for artificial intelligence models in the broader geoscience is
to represent and encode various types of spatial data, such as points (e.g.,
points of interest), polylines (e.g., trajectories), polygons (e.g.,
administrative regions), graphs (e.g., transportation networks), or rasters
(e.g., remote sensing images), in a hidden embedding space so that they can be
readily incorporated into deep learning models. One fundamental step is to
encode a single point location into an embedding space, such that this
embedding is learning-friendly for downstream machine learning models such as
support vector machines and neural networks. We call this process location
encoding. However, there lacks a systematic review on the concept of location
encoding, its potential applications, and key challenges that need to be
addressed. This paper aims to fill this gap. We first provide a formal
definition of location encoding, and discuss the necessity of location encoding
for GeoAI research from a machine learning perspective. Next, we provide a
comprehensive survey and discussion about the current landscape of location
encoding research. We classify location encoding models into different
categories based on their inputs and encoding methods, and compare them based
on whether they are parametric, multi-scale, distance preserving, and direction
aware. We demonstrate that existing location encoding models can be unified
under a shared formulation framework. We also discuss the application of
location encoding for different types of spatial data. Finally, we point out
several challenges in location encoding research that need to be solved in the
future.</p>
  </details>
</details>
<details>
  <summary>91. <b>标题：Quasi-potential theory for escape problem: Quantitative sharpness effect  on SGD's escape from local minima</b></summary>
  <p><b>编号</b>：[264]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04004</p>
  <p><b>作者</b>：Hikaru Ibayashi,  Masaaki Imaizumi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：theory using neural networks trained, various theoretical open questions, theoretical results imply, stochastic dynamical systems, also conduct experiments</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We develop a quantitative theory on an escape problem of a stochastic
gradient descent (SGD) algorithm and investigate the effect of sharpness of
loss surfaces on the escape. Deep learning has achieved tremendous success in
various domains, however, it has opened up various theoretical open questions.
One of the typical questions is why an SGD can find parameters that generalize
well over non-convex loss surfaces. An escape problem is an approach to tackle
this question, which investigates how efficiently an SGD escapes from local
minima. In this paper, we develop a quasi-potential theory for the escape
problem, by applying a theory of stochastic dynamical systems. We show that the
quasi-potential theory can handle both geometric properties of loss surfaces
and a covariance structure of gradient noise in a unified manner, while they
have been separately studied in previous works. Our theoretical results imply
that (i) the sharpness of loss surfaces contributes to the slow escape of an
SGD, and (ii) the SGD's noise structure cancels the effect and exponentially
accelerates the escape. We also conduct experiments to empirically validate our
theory using neural networks trained with real data.</p>
  </details>
</details>
<details>
  <summary>92. <b>标题：Predictive Model for Gross Community Production Rate of Coral Reefs  using Ensemble Learning Methodologies</b></summary>
  <p><b>编号</b>：[265]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04003</p>
  <p><b>作者</b>：Umanandini S,  Aouthithiye Barathwaj SR Y,  Jasline Augusta J,  Shrirang Sapate,  Reenasree S,  Vigneash M</p>
  <p><b>备注</b>：8 pages, 18 figures</p>
  <p><b>关键词</b>：various marine organisms depend, various exotic species, provide better rates, ensemble machine learning, calcium carbonate compounds</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Coral reefs play a vital role in maintaining the ecological balance of the
marine ecosystem. Various marine organisms depend on coral reefs for their
existence and their natural processes. Coral reefs provide the necessary
habitat for reproduction and growth for various exotic species of the marine
ecosystem. In this article, we discuss the most important parameters which
influence the lifecycle of coral and coral reefs such as ocean acidification,
deoxygenation and other physical parameters such as flow rate and surface area.
Ocean acidification depends on the amount of dissolved Carbon dioxide (CO2).
This is due to the release of H+ ions upon the reaction of the dissolved CO2
gases with the calcium carbonate compounds in the ocean. Deoxygenation is
another problem that leads to hypoxia which is characterized by a lesser amount
of dissolved oxygen in water than the required amount for the existence of
marine organisms. In this article, we highlight the importance of physical
parameters such as flow rate which influence gas exchange, heat dissipation,
bleaching sensitivity, nutrient supply, feeding, waste and sediment removal,
growth and reproduction. In this paper, we also bring out these important
parameters and propose an ensemble machine learning-based model for analyzing
these parameters and provide better rates that can help us to understand and
suitably improve the ocean composition which in turn can eminently improve the
sustainability of the marine ecosystem, mainly the coral reefs</p>
  </details>
</details>
<details>
  <summary>93. <b>标题：NarrationBot and InfoBot: A Hybrid System for Automated Video  Description</b></summary>
  <p><b>编号</b>：[266]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03994</p>
  <p><b>作者</b>：Shasta Ihorn,  Yue-Ting Siu,  Aditya Bodi,  Lothar Narins,  Jose M. Castanon,  Yash Kant,  Abhishek Das,  Ilmi Yoon,  Pooyan Fazli</p>
  <p><b>备注</b>：14 pages</p>
  <p><b>关键词</b>：system significantly improved user comprehension, low vision individuals show, results demonstrate user enthusiasm, generated descriptions cannot match, autogenerated descriptions versus human</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Video accessibility is crucial for blind and low vision users for equitable
engagements in education, employment, and entertainment. Despite the
availability of professional and amateur services and tools, most
human-generated descriptions are expensive and time consuming. Moreover, the
rate of human-generated descriptions cannot match the speed of video
production. To overcome the increasing gaps in video accessibility, we
developed a hybrid system of two tools to 1) automatically generate
descriptions for videos and 2) provide answers or additional descriptions in
response to user queries on a video. Results from a mixed-methods study with 26
blind and low vision individuals show that our system significantly improved
user comprehension and enjoyment of selected videos when both tools were used
in tandem. In addition, participants reported no significant difference in
their ability to understand videos when presented with autogenerated
descriptions versus human-revised autogenerated descriptions. Our results
demonstrate user enthusiasm about the developed system and its promise for
providing customized access to videos. We discuss the limitations of the
current work and provide recommendations for the future development of
automated video description tools.</p>
  </details>
</details>
<details>
  <summary>94. <b>标题：V-MAO: Generative Modeling for Multi-Arm Manipulation of Articulated  Objects</b></summary>
  <p><b>编号</b>：[269]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03987</p>
  <p><b>作者</b>：Xingyu Liu,  Kris M. Kitani</p>
  <p><b>备注</b>：CoRL 2021</p>
  <p><b>关键词</b>：manipulating articulated objects requires multiple robot arms, enable multiple robot arms, collaboratively complete manipulation tasks, learns contact point distribution, customized mujoco simulation environment</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Manipulating articulated objects requires multiple robot arms in general. It
is challenging to enable multiple robot arms to collaboratively complete
manipulation tasks on articulated objects. In this paper, we present
$\textbf{V-MAO}$, a framework for learning multi-arm manipulation of
articulated objects. Our framework includes a variational generative model that
learns contact point distribution over object rigid parts for each robot arm.
The training signal is obtained from interaction with the simulation
environment which is enabled by planning and a novel formulation of
object-centric control for articulated objects. We deploy our framework in a
customized MuJoCo simulation environment and demonstrate that our framework
achieves a high success rate on six different objects and two different robots.
We also show that generative modeling can effectively learn the contact point
distribution on articulated objects.</p>
  </details>
</details>
<details>
  <summary>95. <b>标题：Machine Learning-Assisted E-jet Printing of Organic Flexible Biosensors</b></summary>
  <p><b>编号</b>：[271]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03985</p>
  <p><b>作者</b>：Mehran Abbasi Shirsavar,  Mehrnoosh Taghavimehr,  Lionel J. Ouedraogo,  Mojan Javaheripi,  Nicole N. Hashemi,  Farinaz Koushanfar,  Reza Montazami</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：since decision tree methods could, complex soft electronic devices, printing soft electronic devices, supervised classification models, machine learning algorithm</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Electrohydrodynamic-jet (e-jet) printing technique enables the
high-resolution printing of complex soft electronic devices. As such, it has an
unmatched potential for becoming the conventional technique for printing soft
electronic devices. In this study, the electrical conductivity of the e-jet
printed circuits was studied as a function of key printing parameters (nozzle
speed, ink flow rate, and voltage). The collected experimental dataset was then
used to train a machine learning algorithm to establish models capable of
predicting the characteristics of the printed circuits in real-time. Precision
parameters were compared to evaluate the supervised classification models.
Since decision tree methods could not increase the accuracy higher than 71%,
more advanced algorithms are performed on our dataset to improve the precision
of model. According to F-measure values, the K-NN model (k=10) and random
forest are the best methods to classify the conductivity of electrodes. The
highest accuracy of AdaBoost ensemble learning has resulted in the range of
10-15 trees (87%).</p>
  </details>
</details>
<details>
  <summary>96. <b>标题：Proposing an Interactive Audit Pipeline for Visual Privacy Research</b></summary>
  <p><b>编号</b>：[272]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03984</p>
  <p><b>作者</b>：Jasmine DeHart,  Chenguang Xu,  Lisa Egede,  Christan Grant</p>
  <p><b>备注</b>：Extended version of IEEE BigData 2021 Short Paper, 15 pages</p>
  <p><b>关键词</b>：various machine learning phases, examine visual privacy research, deployed machine learning models, machine learning pipeline, g ., researchers</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In an ideal world, deployed machine learning models will enhance our society.
We hope that those models will provide unbiased and ethical decisions that will
benefit everyone. However, this is not always the case; issues arise from the
data curation process to the models' deployment. The continued use of biased
datasets and processes will adversely damage communities and increase the cost
to fix the problem. In this work, we walk through the decision process that a
researcher will need to make before, during, and after their project to
consider the broader impacts of research and the community. Throughout this
paper, we observe the critical decisions that are often overlooked when
deploying AI, argue for the use of fairness forensics to discover bias and
fairness issues in systems, assert the need for a responsible
human-over-the-loop to bring accountability into the deployed system, and
finally, reflect on the need to explore research agendas that have harmful
societal impacts. We examine visual privacy research and draw lessons that can
apply broadly to Artificial Intelligence. Our goal is to provide a systematic
analysis of the machine learning pipeline for visual privacy and bias issues.
With this pipeline, we hope to raise stakeholder (e.g., researchers, modelers,
corporations) awareness as these issues propagate in the various machine
learning phases.</p>
  </details>
</details>
<details>
  <summary>97. <b>标题：CubeLearn: End-to-end Learning for Human Motion Recognition from Raw  mmWave Radar Signals</b></summary>
  <p><b>编号</b>：[275]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03976</p>
  <p><b>作者</b>：Peijun Zhao,  Chris Xiaoxuan Lu,  Bing Wang,  Niki Trigoni,  Andrew Markham</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：built upon conventional discrete fourier transform, different approaches towards data cube slicing, deep neural network classifier hybrid methods, mmwave fmcw radar motion recognition applications, end deep neural network</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>mmWave FMCW radar has attracted huge amount of research interest for
human-centered applications in recent years, such as human gesture/activity
recognition. Most existing pipelines are built upon conventional Discrete
Fourier Transform (DFT) pre-processing and deep neural network classifier
hybrid methods, with a majority of previous works focusing on designing the
downstream classifier to improve overall accuracy. In this work, we take a step
back and look at the pre-processing module. To avoid the drawbacks of
conventional DFT pre-processing, we propose a learnable pre-processing module,
named CubeLearn, to directly extract features from raw radar signal and build
an end-to-end deep neural network for mmWave FMCW radar motion recognition
applications. Extensive experiments show that our CubeLearn module consistently
improves the classification accuracies of different pipelines, especially
benefiting those previously weaker models. We provide ablation studies on
initialization methods and structure of the proposed module, as well as an
evaluation of the running time on PC and edge devices. This work also serves as
a comparison of different approaches towards data cube slicing. Through our
task agnostic design, we propose a first step towards a generic end-to-end
solution for radar recognition problems.</p>
  </details>
</details>
<details>
  <summary>98. <b>标题：Understanding Layer-wise Contributions in Deep Neural Networks through  Spectral Analysis</b></summary>
  <p><b>编号</b>：[276]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03972</p>
  <p><b>作者</b>：Yatin Dandi,  Arthur Jacot</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：provide empirical results validating, larger bias towards high, high dimensional datasets, wise spectral bias, deep neural networks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Spectral analysis is a powerful tool, decomposing any function into simpler
parts. In machine learning, Mercer's theorem generalizes this idea, providing
for any kernel and input distribution a natural basis of functions of
increasing frequency. More recently, several works have extended this analysis
to deep neural networks through the framework of Neural Tangent Kernel. In this
work, we analyze the layer-wise spectral bias of Deep Neural Networks and
relate it to the contributions of different layers in the reduction of
generalization error for a given target function. We utilize the properties of
Hermite polynomials and spherical harmonics to prove that initial layers
exhibit a larger bias towards high-frequency functions defined on the unit
sphere. We further provide empirical results validating our theory in high
dimensional datasets for Deep Neural Networks.</p>
  </details>
</details>
<details>
  <summary>99. <b>标题：Towards noise robust trigger-word detection with contrastive learning  pre-task for fast on-boarding of new trigger-words</b></summary>
  <p><b>编号</b>：[277]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03971</p>
  <p><b>作者</b>：Sivakumar Balasubramanian,  Aditya Jajodia,  Gowtham Srinivasan</p>
  <p><b>备注</b>：submitted to ICASSP 2022</p>
  <p><b>关键词</b>：supervised technique using chunked words, word involves huge amount, explore supervised contrastive techniques, makes supporting new trigger, time consuming process</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Trigger-word detection plays an important role as the entry point of user's
communication with voice assistants. But supporting a particular word as a
trigger-word involves huge amount of data collection, augmentation and
labelling for that word. This makes supporting new trigger-words a tedious and
time consuming process. To combat this, we explore the use of contrastive
learning as a pre-training task that helps the detection model to generalize to
different words and noise conditions. We explore supervised contrastive
techniques and also propose a self-supervised technique using chunked words
from long sentence audios. We show that the contrastive pre-training techniques
have comparable results to a traditional classification pre-training on new
trigger words with less data availability.</p>
  </details>
</details>
<details>
  <summary>100. <b>标题：A Deep Reinforcement Learning Approach for Composing Moving IoT Services</b></summary>
  <p><b>编号</b>：[279]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03967</p>
  <p><b>作者</b>：Azadeh Ghari Neiat,  Athman Bouguettaya,  Mohammed Bahutair</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：compose moving iot services considering quality parameters, effectively discovering crowdsourced services, moving crowdsourced service model, based service discovery algorithm, world datasets verify</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We develop a novel framework for efficiently and effectively discovering
crowdsourced services that move in close proximity to a user over a period of
time. We introduce a moving crowdsourced service model which is modelled as a
moving region. We propose a deep reinforcement learning-based composition
approach to select and compose moving IoT services considering quality
parameters. Additionally, we develop a parallel flock-based service discovery
algorithm as a ground-truth to measure the accuracy of the proposed approach.
The experiments on two real-world datasets verify the effectiveness and
efficiency of the deep reinforcement learning-based approach.</p>
  </details>
</details>
<details>
  <summary>101. <b>标题：CALText: Contextual Attention Localization for Offline Handwritten Text</b></summary>
  <p><b>编号</b>：[285]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03952</p>
  <p><b>作者</b>：Tayaba Anjum,  Nazar Khan</p>
  <p><b>备注</b>：25 pages, 15 figures and 6 tables</p>
  <p><b>关键词</b>：publicly available handwritten urdu dataset, offline handwritten urdu script, contextual attention localization outperforms, novel localization penalty, much research exists</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recognition of Arabic-like scripts such as Persian and Urdu is more
challenging than Latin-based scripts. This is due to the presence of a
two-dimensional structure, context-dependent character shapes, spaces and
overlaps, and placement of diacritics. Not much research exists for offline
handwritten Urdu script which is the 10th most spoken language in the world. We
present an attention based encoder-decoder model that learns to read Urdu in
context. A novel localization penalty is introduced to encourage the model to
attend only one location at a time when recognizing the next character. In
addition, we comprehensively refine the only complete and publicly available
handwritten Urdu dataset in terms of ground-truth annotations. We evaluate the
model on both Urdu and Arabic datasets and show that contextual attention
localization outperforms both simple attention and multi-directional LSTM
models.</p>
  </details>
</details>
<details>
  <summary>102. <b>标题：Exponential Bellman Equation and Improved Regret Bounds for  Risk-Sensitive Reinforcement Learning</b></summary>
  <p><b>编号</b>：[286]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03947</p>
  <p><b>作者</b>：Yingjie Fei,  Zhuoran Yang,  Yudong Chen,  Zhaoran Wang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：exponential bellman equation inspires us, algorithmic innovations together lead, improved regret upper bounds, exponential bellman equation, sensitive bellman equations</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We study risk-sensitive reinforcement learning (RL) based on the entropic
risk measure. Although existing works have established non-asymptotic regret
guarantees for this problem, they leave open an exponential gap between the
upper and lower bounds. We identify the deficiencies in existing algorithms and
their analysis that result in such a gap. To remedy these deficiencies, we
investigate a simple transformation of the risk-sensitive Bellman equations,
which we call the exponential Bellman equation. The exponential Bellman
equation inspires us to develop a novel analysis of Bellman backup procedures
in risk-sensitive RL algorithms, and further motivates the design of a novel
exploration mechanism. We show that these analytic and algorithmic innovations
together lead to improved regret upper bounds over existing ones.</p>
  </details>
</details>
<details>
  <summary>103. <b>标题：A Probit Tensor Factorization Model For Relational Learning</b></summary>
  <p><b>编号</b>：[288]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03943</p>
  <p><b>作者</b>：Ye Liu,  Rui Song,  Wenbin Lu</p>
  <p><b>备注</b>：30 pages</p>
  <p><b>关键词</b>：e ., predicting whether certain relations exist, classic tensor factorization model, binary tensor factorization model, proposed probit tensor factorization, existing tensor factorization models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>With the proliferation of knowledge graphs, modeling data with complex
multirelational structure has gained increasing attention in the area of
statistical relational learning. One of the most important goals of statistical
relational learning is link prediction, i.e., predicting whether certain
relations exist in the knowledge graph. A large number of models and algorithms
have been proposed to perform link prediction, among which tensor factorization
method has proven to achieve state-of-the-art performance in terms of
computation efficiency and prediction accuracy. However, a common drawback of
the existing tensor factorization models is that the missing relations and
non-existing relations are treated in the same way, which results in a loss of
information. To address this issue, we propose a binary tensor factorization
model with probit link, which not only inherits the computation efficiency from
the classic tensor factorization model but also accounts for the binary nature
of relational data. Our proposed probit tensor factorization (PTF) model shows
advantages in both the prediction accuracy and interpretability</p>
  </details>
</details>
<details>
  <summary>104. <b>标题：Time Discretization-Invariant Safe Action Repetition for Policy Gradient  Methods</b></summary>
  <p><b>编号</b>：[290]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03941</p>
  <p><b>作者</b>：Seohong Park,  Jaekyeom Kim,  Gunhee Kim</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：novel $\ delta $- invariant method named safe action repetition, outperforming previous $\ delta $- invariant approaches, previous action repetition methods cannot immediately react, $\ delta $- invariant algorithm, time scale $\ delta $,</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In reinforcement learning, continuous time is often discretized by a time
scale $\delta$, to which the resulting performance is known to be highly
sensitive. In this work, we seek to find a $\delta$-invariant algorithm for
policy gradient (PG) methods, which performs well regardless of the value of
$\delta$. We first identify the underlying reasons that cause PG methods to
fail as $\delta \to 0$, proving that the variance of the PG estimator can
diverge to infinity in stochastic environments under a certain assumption of
stochasticity. While durative actions or action repetition can be employed to
have $\delta$-invariance, previous action repetition methods cannot immediately
react to unexpected situations in stochastic environments. We thus propose a
novel $\delta$-invariant method named Safe Action Repetition (SAR) applicable
to any existing PG algorithm. SAR can handle the stochasticity of environments
by adaptively reacting to changes in states during action repetition. We
empirically show that our method is not only $\delta$-invariant but also robust
to stochasticity, outperforming previous $\delta$-invariant approaches on eight
MuJoCo environments with both deterministic and stochastic settings. Our code
is available at this https URL.</p>
  </details>
</details>
<details>
  <summary>105. <b>标题：Convolutional Gated MLP: Combining Convolutions & gMLP</b></summary>
  <p><b>编号</b>：[291]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03940</p>
  <p><b>作者</b>：A.Rajagopal,  V. Nirmala</p>
  <p><b>备注</b>：Conference</p>
  <p><b>关键词</b>：learnt using vast amount, novel deep learning architecture, novel deep learning architecture, spatial gated mlp, google brain introduced</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>To the best of our knowledge, this is the first paper to introduce
Convolutions to Gated MultiLayer Perceptron and contributes an implementation
of this novel Deep Learning architecture. Google Brain introduced the gMLP in
May 2021. Microsoft introduced Convolutions in Vision Transformer in Mar 2021.
Inspired by both gMLP and CvT, we introduce convolutional layers in gMLP. CvT
combined the power of Convolutions and Attention. Our implementation combines
the best of Convolutional learning along with spatial gated MLP. Further, the
paper visualizes how CgMLP learns. Visualizations show how CgMLP learns from
features such as outline of a car. While Attention was the basis of much of
recent progress in Deep Learning, gMLP proposed an approach that doesn't use
Attention computation. In Transformer based approaches, a whole lot of
Attention matrixes need to be learnt using vast amount of training data. In
gMLP, the fine tunning for new tasks can be challenging by transfer learning
with smaller datasets. We implement CgMLP and compares it with gMLP on CIFAR
dataset. Experimental results explore the power of generaliza-tion of CgMLP,
while gMLP tend to drastically overfit the training data.
To summarize, the paper contributes a novel Deep Learning architecture and
demonstrates the learning mechanism of CgMLP through visualizations, for the
first time in literature.</p>
  </details>
</details>
<details>
  <summary>106. <b>标题：SOPE: Spectrum of Off-Policy Estimators</b></summary>
  <p><b>编号</b>：[293]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03936</p>
  <p><b>作者</b>：Christina J. Yuan,  Yash Chandak,  Stephen Giguere,  Philip S. Thomas,  Scott Niekum</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：new policy using historical data collected using, many sequential decision making problems, sis often provides lower variance estimates, importance sampling methods based, trajectory based importance sampling</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Many sequential decision making problems are high-stakes and require
off-policy evaluation (OPE) of a new policy using historical data collected
using some other policy. One of the most common OPE techniques that provides
unbiased estimates is trajectory based importance sampling (IS). However, due
to the high variance of trajectory IS estimates, importance sampling methods
based on state-action visitation distributions (SIS) have recently been
adopted. Unfortunately, while SIS often provides lower variance estimates for
long horizons, estimating the state-action distribution ratios can be
challenging and lead to biased estimates. In this paper, we present a new
perspective on this bias-variance trade-off and show the existence of a
spectrum of estimators whose endpoints are SIS and IS. Additionally, we also
establish a spectrum for doubly-robust and weighted version of these
estimators. We provide empirical evidence that estimators in this spectrum can
be used to trade-off between the bias and variance of IS and SIS and can
achieve lower mean-squared error than both IS and SIS.</p>
  </details>
</details>
<details>
  <summary>107. <b>标题：Deep Learning Based Model for Breast Cancer Subtype Classification</b></summary>
  <p><b>编号</b>：[298]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03923</p>
  <p><b>作者</b>：Sheetal Rajpal,  Virendra Kumar,  Manoj Agarwal,  Naveen Kumar</p>
  <p><b>备注</b>：Paper have been accepted for publication in ICACET 2021</p>
  <p><b>关键词</b>：fairly robust throughout 10 different runs, accurately classify four breast cancer subtypes, correctly label breast cancer patients, rna sequencing tools capable, 530 gene expression values</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Breast cancer has long been a prominent cause of mortality among women.
Diagnosis, therapy, and prognosis are now possible, thanks to the availability
of RNA sequencing tools capable of recording gene expression data. Molecular
subtyping being closely related to devising clinical strategy and prognosis,
this paper focuses on the use of gene expression data for the classification of
breast cancer into four subtypes, namely, Basal, Her2, LumA, and LumB. In stage
1, we suggested a deep learning-based model that uses an autoencoder to reduce
dimensionality. The size of the feature set is reduced from 20,530 gene
expression values to 500 by using an autoencoder. This encoded representation
is passed to the deep neural network of the second stage for the classification
of patients into four molecular subtypes of breast cancer. By deploying the
combined network of stages 1 and 2, we have been able to attain a mean 10-fold
test accuracy of 0.907 on the TCGA breast cancer dataset. The proposed
framework is fairly robust throughout 10 different runs, as shown by the
boxplot for classification accuracy. Compared to related work reported in the
literature, we have achieved a competitive outcome. In conclusion, the proposed
two-stage deep learning-based model is able to accurately classify four breast
cancer subtypes, highlighting the autoencoder's capacity to deduce the compact
representation and the neural network classifier's ability to correctly label
breast cancer patients.</p>
  </details>
</details>
<details>
  <summary>108. <b>标题：Optimal and Efficient Dynamic Regret Algorithms for Non-Stationary  Dueling Bandits</b></summary>
  <p><b>编号</b>：[300]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03917</p>
  <p><b>作者</b>：Shubham Gupta,  Aadirupa Saha</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：next use similar algorithmic ideas, k $- armed dueling bandits, proving matching lower bound guarantees, kt })$ high probability regret, ({ v_t ^{ 1</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We study the problem of \emph{dynamic regret minimization} in $K$-armed
Dueling Bandits under non-stationary or time varying preferences. This is an
online learning setup where the agent chooses a pair of items at each round and
observes only a relative binary `win-loss' feedback for this pair, sampled from
an underlying preference matrix at that round. We first study the problem of
static-regret minimization for adversarial preference sequences and design an
efficient algorithm with $O(\sqrt{KT})$ high probability regret. We next use
similar algorithmic ideas to propose an efficient and provably optimal
algorithm for dynamic-regret minimization under two notions of
non-stationarities. In particular, we establish $\tO(\sqrt{SKT})$ and
$\tO({V_T^{1/3}K^{1/3}T^{2/3}})$ dynamic-regret guarantees, $S$ being the total
number of `effective-switches' in the underlying preference relations and $V_T$
being a measure of `continuous-variation' non-stationarity. The complexity of
these problems have not been studied prior to this work despite the
practicability of non-stationary environments in real world systems. We justify
the optimality of our algorithms by proving matching lower bound guarantees
under both the above-mentioned notions of non-stationarities. Finally, we
corroborate our results with extensive simulations and compare the efficacy of
our algorithms over state-of-the-art baselines.</p>
  </details>
</details>
<details>
  <summary>109. <b>标题：Robust Deep Reinforcement Learning for Quadcopter Control</b></summary>
  <p><b>编号</b>：[302]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03915</p>
  <p><b>作者</b>：Aditya M. Deshpande,  Ali A. Minai,  Manish Kumar</p>
  <p><b>备注</b>：6 pages; 3 Figures; Accepted in this https URL</p>
  <p><b>关键词</b>：solve complex robotics problems using neural networks, use robust markov decision processes, added robustness increases generality, handle potential gaps, deep reinforcement learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep reinforcement learning (RL) has made it possible to solve complex
robotics problems using neural networks as function approximators. However, the
policies trained on stationary environments suffer in terms of generalization
when transferred from one environment to another. In this work, we use Robust
Markov Decision Processes (RMDP) to train the drone control policy, which
combines ideas from Robust Control and RL. It opts for pessimistic optimization
to handle potential gaps between policy transfer from one environment to
another. The trained control policy is tested on the task of quadcopter
positional control. RL agents were trained in a MuJoCo simulator. During
testing, different environment parameters (unseen during the training) were
used to validate the robustness of the trained policy for transfer from one
environment to another. The robust policy outperformed the standard agents in
these environments, suggesting that the added robustness increases generality
and can adapt to non-stationary environments.
Codes: this https URL</p>
  </details>
</details>
<details>
  <summary>110. <b>标题：On pseudo-absence generation and machine learning for locust breeding  ground prediction in Africa</b></summary>
  <p><b>编号</b>：[308]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03904</p>
  <p><b>作者</b>：Ibrahim Salihu Yusuf,  Kale-ab Tessera,  Thomas Tumiel,  Sella Nevo,  Arnu Pretorius</p>
  <p><b>备注</b>：AI for Humanitarian Assistance and Disaster Response (AI+HADR) workshop, NeurIPS 2021</p>
  <p><b>关键词</b>：predicting locust breeding grounds across africa, predicting desert locust breeding grounds, logistic model performed significantly better, although background extent limitation combined, optimal background extent limitation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Desert locust outbreaks threaten the food security of a large part of Africa
and have affected the livelihoods of millions of people over the years. Machine
learning (ML) has been demonstrated as an effective approach to locust
distribution modelling which could assist in early warning. ML requires a
significant amount of labelled data to train. Most publicly available labelled
data on locusts are presence-only data, where only the sightings of locusts
being present at a location are recorded. Therefore, prior work using ML have
resorted to pseudo-absence generation methods as a way to circumvent this
issue. The most commonly used approach is to randomly sample points in a region
of interest while ensuring that these sampled pseudo-absence points are at
least a specific distance away from true presence points. In this paper, we
compare this random sampling approach to more advanced pseudo-absence
generation methods, such as environmental profiling and optimal background
extent limitation, specifically for predicting desert locust breeding grounds
in Africa. Interestingly, we find that for the algorithms we tested, namely
logistic regression, gradient boosting, random forests and maximum entropy, all
popular in prior work, the logistic model performed significantly better than
the more sophisticated ensemble methods, both in terms of prediction accuracy
and F1 score. Although background extent limitation combined with random
sampling boosted performance for ensemble methods, for LR this was not the
case, and instead, a significant improvement was obtained when using
environmental profiling. In light of this, we conclude that a simpler ML
approach such as logistic regression combined with more advanced pseudo-absence
generation, specifically environmental profiling, can be a sensible and
effective approach to predicting locust breeding grounds across Africa.</p>
  </details>
</details>
<details>
  <summary>111. <b>标题：TND-NAS: Towards Non-differentiable Objectives in Progressive  Differentiable NAS Framework</b></summary>
  <p><b>编号</b>：[312]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03892</p>
  <p><b>作者</b>：Bo Lyu,  Shiping Wen,  Zheng Yan,  Kaibo Shi,  Ke Li,  Tingwen Huang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：end architecture search framework towards non, representative experiment takes two objectives, architecture parameters ($\ alpha $), recent differentiable nas also aims, neural architecture search</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Differentiable architecture search has gradually become the mainstream
research topic in the field of Neural Architecture Search (NAS) for its
capability to improve efficiency compared with the early NAS (EA-based,
RL-based) methods. Recent differentiable NAS also aims at further improving
search efficiency, reducing the GPU-memory consumption, and addressing the
"depth gap" issue. However, these methods are no longer capable of tackling the
non-differentiable objectives, let alone multi-objectives, e.g., performance,
robustness, efficiency, and other metrics. We propose an end-to-end
architecture search framework towards non-differentiable objectives, TND-NAS,
with the merits of the high efficiency in differentiable NAS framework and the
compatibility among non-differentiable metrics in Multi-objective NAS (MNAS).
Under differentiable NAS framework, with the continuous relaxation of the
search space, TND-NAS has the architecture parameters ($\alpha$) been optimized
in discrete space, while resorting to the search policy of progressively
shrinking the supernetwork by $\alpha$. Our representative experiment takes two
objectives (Parameters, Accuracy) as an example, we achieve a series of
high-performance compact architectures on CIFAR10 (1.09M/3.3%, 2.4M/2.95%,
9.57M/2.54%) and CIFAR100 (2.46M/18.3%, 5.46/16.73%, 12.88/15.20%) datasets.
Favorably, under real-world scenarios (resource-constrained,
platform-specialized), the Pareto-optimal solutions can be conveniently reached
by TND-NAS.</p>
  </details>
</details>
<details>
  <summary>112. <b>标题：Towards Calibrated Model for Long-Tailed Visual Recognition from Prior  Perspective</b></summary>
  <p><b>编号</b>：[317]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03874</p>
  <p><b>作者</b>：Zhengzhuo Xu,  Zenghao Chai,  Chun Yuan</p>
  <p><b>备注</b>：Accepted at NeurIPS 2021</p>
  <p><b>关键词</b>：oriented data augmentation named uniform mixup, datasets would prefer dominant labels, world data universally confronts, adopts advanced mixing factor, propose two novel methods</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Real-world data universally confronts a severe class-imbalance problem and
exhibits a long-tailed distribution, i.e., most labels are associated with
limited instances. The naïve models supervised by such datasets would prefer
dominant labels, encounter a serious generalization challenge and become poorly
calibrated. We propose two novel methods from the prior perspective to
alleviate this dilemma. First, we deduce a balance-oriented data augmentation
named Uniform Mixup (UniMix) to promote mixup in long-tailed scenarios, which
adopts advanced mixing factor and sampler in favor of the minority. Second,
motivated by the Bayesian theory, we figure out the Bayes Bias (Bayias), an
inherent bias caused by the inconsistency of prior, and compensate it as a
modification on standard cross-entropy loss. We further prove that both the
proposed methods ensure the classification calibration theoretically and
empirically. Extensive experiments verify that our strategies contribute to a
better-calibrated model, and their combination achieves state-of-the-art
performance on CIFAR-LT, ImageNet-LT, and iNaturalist 2018.</p>
  </details>
</details>
<details>
  <summary>113. <b>标题：What augmentations are sensitive to hyper-parameters and why?</b></summary>
  <p><b>编号</b>：[319]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03861</p>
  <p><b>作者</b>：Ch Muhammad Awais,  Imad Eddine Ibrahim Bekkouch</p>
  <p><b>备注</b>：10 pages, 17 figures</p>
  <p><b>关键词</b>：utilized linear regression coefficients, machine learning model, hyper parameters along, question remains, noisy data</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We apply augmentations to our dataset to enhance the quality of our
predictions and make our final models more resilient to noisy data and domain
drifts. Yet the question remains, how are these augmentations going to perform
with different hyper-parameters? In this study we evaluate the sensitivity of
augmentations with regards to the model's hyper parameters along with their
consistency and influence by performing a Local Surrogate (LIME) interpretation
on the impact of hyper-parameters when different augmentations are applied to a
machine learning model. We have utilized Linear regression coefficients for
weighing each augmentation. Our research has proved that there are some
augmentations which are highly sensitive to hyper-parameters and others which
are more resilient and reliable.</p>
  </details>
</details>
<details>
  <summary>114. <b>标题：Focusing on Possible Named Entities in Active Named Entity Label  Acquisition</b></summary>
  <p><b>编号</b>：[324]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03837</p>
  <p><b>作者</b>：Ali Osman Berk Sapci,  Oznur Tastan,  Reyyan Yeniterzi</p>
  <p><b>备注</b>：20 pages, 8 figures</p>
  <p><b>关键词</b>：trained language models achieve good predictive performances, annotation cost without sacrificing model performance, propose al sentence query evaluation functions, designing effective al querying methods, based cost evaluation strategies</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Named entity recognition (NER) aims to identify mentions of named entities in
an unstructured text and classify them into the predefined named entity
classes. Even though deep learning-based pre-trained language models achieve
good predictive performances, many domain-specific NERtasks still require a
sufficient amount of labeled data. Active learning (AL), a general framework
for the label acquisition problem, has been used for the NER tasks to minimize
the annotation cost without sacrificing model performance. However, heavily
imbalanced class distribution of tokens introduces challenges in designing
effective AL querying methods for NER. We propose AL sentence query evaluation
functions which pay more attention to possible positive tokens, and evaluate
these proposed functions with both sentence-based and token-based cost
evaluation strategies. We also propose a better data-driven normalization
approach to penalize too long or too short sentences. Our experiments on three
datasets from different domains reveal that the proposed approaches reduce the
number of annotated tokens while achieving better or comparable prediction
performance with conventional methods.</p>
  </details>
</details>
<details>
  <summary>115. <b>标题：Contextual Unsupervised Outlier Detection in Sequences</b></summary>
  <p><b>编号</b>：[335]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03808</p>
  <p><b>作者</b>：Mohamed A. Zahran,  Leonardo Teixeira,  Vinayak Rao,  Bruno Ribeiro</p>
  <p><b>备注</b>：11 pages</p>
  <p><b>关键词</b>：overall framework identifies sequence outliers, desired false positive rate, unsupervised learning framework, simulated datasets based, know ground truth</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This work proposes an unsupervised learning framework for trajectory
(sequence) outlier detection that combines ranking tests with user sequence
models. The overall framework identifies sequence outliers at a desired false
positive rate (FPR), in an otherwise parameter-free manner. We evaluate our
methodology on a collection of real and simulated datasets based on user
actions at the websites this http URL and this http URL, where we know ground truth, and
demonstrate improved accuracy over existing approaches. We also apply our
approach to a large real-world dataset of Pinterest and Facebook users, where
we find that users tend to re-share Pinterest posts of Facebook friends
significantly more than other types of users, pointing to a potential influence
of Facebook friendship on sharing behavior on Pinterest.</p>
  </details>
</details>
<details>
  <summary>116. <b>标题：Physics-Informed Neural Operator for Learning Partial Differential  Equations</b></summary>
  <p><b>编号</b>：[339]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03794</p>
  <p><b>作者</b>：Zongyi Li,  Hongkai Zheng,  Nikola Kovachki,  David Jin,  Haoxuan Chen,  Burigede Liu,  Kamyar Azizzadenesheli,  Anima Anandkumar</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：pino accurately solves challenging long temporal transient flows, experiments show pino outperforms previous ml methods, integrated approach improves convergence rates, baseline ml methods fail, solving partial differential equations</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Machine learning methods have recently shown promise in solving partial
differential equations (PDEs). They can be classified into two broad
categories: approximating the solution function and learning the solution
operator. The Physics-Informed Neural Network (PINN) is an example of the
former while the Fourier neural operator (FNO) is an example of the latter.
Both these approaches have shortcomings. The optimization in PINN is
challenging and prone to failure, especially on multi-scale dynamic systems.
FNO does not suffer from this optimization issue since it carries out
supervised learning on a given dataset, but obtaining such data may be too
expensive or infeasible. In this work, we propose the physics-informed neural
operator (PINO), where we combine the operating-learning and
function-optimization frameworks. This integrated approach improves convergence
rates and accuracy over both PINN and FNO models. In the operator-learning
phase, PINO learns the solution operator over multiple instances of the
parametric PDE family. In the test-time optimization phase, PINO optimizes the
pre-trained operator ansatz for the querying instance of the PDE. Experiments
show PINO outperforms previous ML methods on many popular PDE families while
retaining the extraordinary speed-up of FNO compared to solvers. In particular,
PINO accurately solves challenging long temporal transient flows and Kolmogorov
flows where other baseline ML methods fail to converge.</p>
  </details>
</details>
<details>
  <summary>117. <b>标题：d3rlpy: An Offline Deep Reinforcement Learning Library</b></summary>
  <p><b>编号</b>：[342]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03788</p>
  <p><b>作者</b>：Takuma Seno,  Michita Imai</p>
  <p><b>备注</b>：Accepted at Offline Reinforcement Learning Workshop at Neural Information Processing Systems, 2021</p>
  <p><b>关键词</b>：train offline rl algorithms without coding programs, sourced offline deep reinforcement learning, offline deep rl algorithms, assist deep rl research, online algorithms via</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we introduce d3rlpy, an open-sourced offline deep
reinforcement learning (RL) library for Python. d3rlpy supports a number of
offline deep RL algorithms as well as online algorithms via a user-friendly
API. To assist deep RL research and development projects, d3rlpy provides
practical and unique features such as data collection, exporting policies for
deployment, preprocessing and postprocessing, distributional Q-functions,
multi-step learning and a convenient command-line interface. Furthermore,
d3rlpy additionally provides a novel graphical interface that enables users to
train offline RL algorithms without coding programs. Lastly, the implemented
algorithms are benchmarked with D4RL datasets to ensure the implementation
quality. The d3rlpy source code can be found on GitHub:
\url{this https URL}.</p>
  </details>
</details>
<details>
  <summary>118. <b>标题：Dynamic Regret Minimization for Control of Non-stationary Linear  Dynamical Systems</b></summary>
  <p><b>编号</b>：[350]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03772</p>
  <p><b>作者</b>：Yuwei Luo,  Varun Gupta,  Mladen Kolar</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：$\ tilde {\ mathcal, $\ tilde {\ mathcal, using sliding window learning, 5 }\ right )$., stationary dynamics $\{ a_t</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We consider the problem of controlling a Linear Quadratic Regulator (LQR)
system over a finite horizon $T$ with fixed and known cost matrices $Q,R$, but
unknown and non-stationary dynamics $\{A_t, B_t\}$. The sequence of dynamics
matrices can be arbitrary, but with a total variation, $V_T$, assumed to be
$o(T)$ and unknown to the controller. Under the assumption that a sequence of
stabilizing, but potentially sub-optimal controllers is available for all $t$,
we present an algorithm that achieves the optimal dynamic regret of
$\tilde{\mathcal{O}}\left(V_T^{2/5}T^{3/5}\right)$. With piece-wise constant
dynamics, our algorithm achieves the optimal regret of
$\tilde{\mathcal{O}}(\sqrt{ST})$ where $S$ is the number of switches. The crux
of our algorithm is an adaptive non-stationarity detection strategy, which
builds on an approach recently developed for contextual Multi-armed Bandit
problems. We also argue that non-adaptive forgetting (e.g., restarting or using
sliding window learning with a static window size) may not be regret optimal
for the LQR problem, even when the window size is optimally tuned with the
knowledge of $V_T$. The main technical challenge in the analysis of our
algorithm is to prove that the ordinary least squares (OLS) estimator has a
small bias when the parameter to be estimated is non-stationary. Our analysis
also highlights that the key motif driving the regret is that the LQR problem
is in spirit a bandit problem with linear feedback and locally quadratic cost.
This motif is more universal than the LQR problem itself, and therefore we
believe our results should find wider application.</p>
  </details>
</details>
<details>
  <summary>119. <b>标题：MQBench: Towards Reproducible and Deployable Model Quantization  Benchmark</b></summary>
  <p><b>编号</b>：[352]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03759</p>
  <p><b>作者</b>：Yuhang Li,  Mingzhu Shen,  Jian Ma,  Yan Ren,  Mingxin Zhao,  Qi Zhang,  Ruihao Gong,  Fengwei Yu,  Junjie Yan</p>
  <p><b>备注</b>：Accepted by 35th Conference on Neural Information Processing Systems (NeurIPS 2021) Track on Datasets and Benchmarks</p>
  <p><b>关键词</b>：work could inspire future research directions, existing algorithm wins every challenge, choose multiple different platforms, accelerate deep learning inference, choose consistent training pipelines</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Model quantization has emerged as an indispensable technique to accelerate
deep learning inference. While researchers continue to push the frontier of
quantization algorithms, existing quantization work is often unreproducible and
undeployable. This is because researchers do not choose consistent training
pipelines and ignore the requirements for hardware deployments. In this work,
we propose Model Quantization Benchmark (MQBench), a first attempt to evaluate,
analyze, and benchmark the reproducibility and deployability for model
quantization algorithms. We choose multiple different platforms for real-world
deployments, including CPU, GPU, ASIC, DSP, and evaluate extensive
state-of-the-art quantization algorithms under a unified training pipeline.
MQBench acts like a bridge to connect the algorithm and the hardware. We
conduct a comprehensive analysis and find considerable intuitive or
counter-intuitive insights. By aligning the training settings, we find existing
algorithms have about the same performance on the conventional academic track.
While for the hardware-deployable quantization, there is a huge accuracy gap
which remains unsettled. Surprisingly, no existing algorithm wins every
challenge in MQBench, and we hope this work could inspire future research
directions.</p>
  </details>
</details>
<details>
  <summary>120. <b>标题：CloudRCA: A Root Cause Analysis Framework for Cloud Computing Platforms</b></summary>
  <p><b>编号</b>：[354]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03753</p>
  <p><b>作者</b>：Yingying Zhang,  Zhengxiong Guan,  Huajie Qian,  Leili Xu,  Hengbo Liu,  Qingsong Wen,  Liang Sun,  Junwei Jiang,  Lunting Fan,  Min Ke</p>
  <p><b>备注</b>：Accepted by CIKM 2021; 10 pages, 3 figures, 12 tables</p>
  <p><b>关键词</b>：three typical cloud computing platforms including maxcompute, source data including key performance indicators, root cause analysis framework called cloudrca, big data cloud computing platforms, extracts important features via state</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As business of Alibaba expands across the world among various industries,
higher standards are imposed on the service quality and reliability of big data
cloud computing platforms which constitute the infrastructure of Alibaba Cloud.
However, root cause analysis in these platforms is non-trivial due to the
complicated system architecture. In this paper, we propose a root cause
analysis framework called CloudRCA which makes use of heterogeneous
multi-source data including Key Performance Indicators (KPIs), logs, as well as
topology, and extracts important features via state-of-the-art anomaly
detection and log analysis techniques. The engineered features are then
utilized in a Knowledge-informed Hierarchical Bayesian Network (KHBN) model to
infer root causes with high accuracy and efficiency. Ablation study and
comprehensive experimental comparisons demonstrate that, compared to existing
frameworks, CloudRCA 1) consistently outperforms existing approaches in
f1-score across different cloud systems; 2) can handle novel types of root
causes thanks to the hierarchical structure of KHBN; 3) performs more robustly
with respect to algorithmic configurations; and 4) scales more favorably in the
data and feature sizes. Experiments also show that a cross-platform transfer
learning mechanism can be adopted to further improve the accuracy by more than
10\%. CloudRCA has been integrated into the diagnosis system of Alibaba Cloud
and employed in three typical cloud computing platforms including MaxCompute,
Realtime Compute and Hologres. It saves Site Reliability Engineers (SREs) more
than $20\%$ in the time spent on resolving failures in the past twelve months
and improves service reliability significantly.</p>
  </details>
</details>
<details>
  <summary>121. <b>标题：An Algorithmic Theory of Metacognition in Minds and Machines</b></summary>
  <p><b>编号</b>：[357]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03745</p>
  <p><b>作者</b>：Rylan Schaeffer</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：suboptimal actions without external information, humans sometimes choose actions, machine learning community, proposed theory creates, metacognitive actor critic</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Humans sometimes choose actions that they themselves can identify as
sub-optimal, or wrong, even in the absence of additional information. How is
this possible? We present an algorithmic theory of metacognition based on a
well-understood trade-off in reinforcement learning (RL) between value-based RL
and policy-based RL. To the cognitive (neuro)science community, our theory
answers the outstanding question of why information can be used for error
detection but not for action selection. To the machine learning community, our
proposed theory creates a novel interaction between the Actor and Critic in
Actor-Critic agents and notes a novel connection between RL and Bayesian
Optimization. We call our proposed agent the Metacognitive Actor Critic (MAC).
We conclude with showing how to create metacognition in machines by
implementing a deep MAC and showing that it can detect (some of) its own
suboptimal actions without external information or delay.</p>
  </details>
</details>
<details>
  <summary>122. <b>标题：Increasing Data Diversity with Iterative Sampling to Improve Performance</b></summary>
  <p><b>编号</b>：[359]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03743</p>
  <p><b>作者</b>：Devrim Cavusoglu,  Ogulcan Eryuksel,  Sinan Altinuc</p>
  <p><b>备注</b>：5 pages, 2 (6) figures, to be published in 1st NeurIPS Data-Centric AI Workshop</p>
  <p><b>关键词</b>：difficult classes especially providing closer samples, edge cases potentially, centric ai competition, training samples, augmented samples</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As a part of the Data-Centric AI Competition, we propose a data-centric
approach to improve the diversity of the training samples by iterative
sampling. The method itself relies strongly on the fidelity of augmented
samples and the diversity of the augmentation methods. Moreover, we improve the
performance further by introducing more samples for the difficult classes
especially providing closer samples to edge cases potentially those the model
at hand misclassifies.</p>
  </details>
</details>
<details>
  <summary>123. <b>标题：Sharp Bounds for Federated Averaging (Local SGD) and Continuous  Perspective</b></summary>
  <p><b>编号</b>：[360]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03741</p>
  <p><b>作者</b>：Margalit Glasgow,  Honglin Yuan,  Tengyu Ma</p>
  <p><b>备注</b>：47 pages. First two authors contributed equally</p>
  <p><b>关键词</b>：existing fedavg upper bound analysis, noiseless gradient descent trajectory, prove novel sharp bounds, fedavg ), also known, existing analysis captures</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Federated Averaging (FedAvg), also known as Local SGD, is one of the most
popular algorithms in Federated Learning (FL). Despite its simplicity and
popularity, the convergence rate of FedAvg has thus far been undetermined. Even
under the simplest assumptions (convex, smooth, homogeneous, and bounded
covariance), the best-known upper and lower bounds do not match, and it is not
clear whether the existing analysis captures the capacity of the algorithm. In
this work, we first resolve this question by providing a lower bound for FedAvg
that matches the existing upper bound, which shows the existing FedAvg upper
bound analysis is not improvable. Additionally, we establish a lower bound in a
heterogeneous setting that nearly matches the existing upper bound. While our
lower bounds show the limitations of FedAvg, under an additional assumption of
third-order smoothness, we prove more optimistic state-of-the-art convergence
results in both convex and non-convex settings. Our analysis stems from a
notion we call iterate bias, which is defined by the deviation of the
expectation of the SGD trajectory from the noiseless gradient descent
trajectory with the same initialization. We prove novel sharp bounds on this
quantity, and show intuitively how to analyze this quantity from a Stochastic
Differential Equation (SDE) perspective.</p>
  </details>
</details>
<details>
  <summary>124. <b>标题：Toward Learning Human-aligned Cross-domain Robust Models by Countering  Misaligned Features</b></summary>
  <p><b>编号</b>：[361]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03740</p>
  <p><b>作者</b>：Haohan Wang,  Zeyi Huang,  Hanlin Zhang,  Eric Xing</p>
  <p><b>备注</b>：10 pages of main contents</p>
  <p><b>关键词</b>：data annotator considers similar across, conventional generalization error bound, robust machine learning literature, demonstrated remarkable prediction accuracy, accuracy often drops</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Machine learning has demonstrated remarkable prediction accuracy over i.i.d
data, but the accuracy often drops when tested with data from another
distribution. In this paper, we aim to offer another view of this problem in a
perspective assuming the reason behind this accuracy drop is the reliance of
models on the features that are not aligned well with how a data annotator
considers similar across these two datasets. We refer to these features as
misaligned features. We extend the conventional generalization error bound to a
new one for this setup with the knowledge of how the misaligned features are
associated with the label. Our analysis offers a set of techniques for this
problem, and these techniques are naturally linked to many previous methods in
robust machine learning literature. We also compared the empirical strength of
these methods demonstrated the performance when these previous techniques are
combined.</p>
  </details>
</details>
<details>
  <summary>125. <b>标题：Frugal Machine Learning</b></summary>
  <p><b>编号</b>：[363]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03731</p>
  <p><b>作者</b>：Mikhail Evchenko,  Joaquin Vanschoren,  Holger H. Hoos,  Marc Schoenauer,  Michèle Sebag</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：g ., prediction accuracy ),, paper thus investigates frugal learning, raises major computational limitations, privacy issues may inhibit, learn activity recognition models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Machine learning, already at the core of increasingly many systems and
applications, is set to become even more ubiquitous with the rapid rise of
wearable devices and the Internet of Things. In most machine learning
applications, the main focus is on the quality of the results achieved (e.g.,
prediction accuracy), and hence vast amounts of data are being collected,
requiring significant computational resources to build models. In many
scenarios, however, it is infeasible or impractical to set up large centralized
data repositories. In personal health, for instance, privacy issues may inhibit
the sharing of detailed personal data. In such cases, machine learning should
ideally be performed on wearable devices themselves, which raises major
computational limitations such as the battery capacity of smartwatches. This
paper thus investigates frugal learning, aimed to build the most accurate
possible models using the least amount of resources. A wide range of learning
algorithms is examined through a frugal lens, analyzing their accuracy/runtime
performance on a wide range of data sets. The most promising algorithms are
thereafter assessed in a real-world scenario by implementing them in a
smartwatch and letting them learn activity recognition models on the watch
itself.</p>
  </details>
</details>
<details>
  <summary>126. <b>标题：Defect Detection on Semiconductor Wafers by Distribution Analysis</b></summary>
  <p><b>编号</b>：[365]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03727</p>
  <p><b>作者</b>：Thomas Olschewski</p>
  <p><b>备注</b>：40 pages, 10 figures</p>
  <p><b>关键词</b>：presented algorithm prefers finding, world measurement data, several product types, hundred thousand chips, dimensional search space</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A method for object classification that is based on distribution analysis is
proposed. In addition, a method for finding relevant features and the
unification of this algorithm with another classification algorithm is
proposed. The presented classification algorithm has been applied successfully
to real-world measurement data from wafer fabrication of close to hundred
thousand chips of several product types. The presented algorithm prefers
finding the best rater in a low-dimensional search space over finding a good
rater in a high-dimensional search space. Our approach is interesting in that
it is fast (quasi-linear) and reached good to excellent prediction or detection
quality for real-world wafer data.</p>
  </details>
</details>
<details>
  <summary>127. <b>标题：Leveraging Sentiment Analysis Knowledge to Solve Emotion Detection Tasks</b></summary>
  <p><b>编号</b>：[370]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03715</p>
  <p><b>作者</b>：Maude Nguyen-The,  Guillaume-Alexandre Bilodeau,  Jan Rockemann</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：multiple natural language processing applications, simple sentiment analysis tasks, simple polarity sentiment analysis, understanding underlying sentiment, large scale dataset</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Identifying and understanding underlying sentiment or emotions in text is a
key component of multiple natural language processing applications. While
simple polarity sentiment analysis is a well-studied subject, fewer advances
have been made in identifying more complex, finer-grained emotions using only
textual data. In this paper, we present a Transformer-based model with a Fusion
of Adapter layers which leverages knowledge from more simple sentiment analysis
tasks to improve the emotion detection task on large scale dataset, such as
CMU-MOSEI, using the textual modality only. Results show that our proposed
method is competitive with other approaches. We obtained state-of-the-art
results for emotion recognition on CMU-MOSEI even while using only the textual
modality.</p>
  </details>
</details>
<details>
  <summary>128. <b>标题：Feature-Level Fusion of Super-App and Telecommunication Alternative Data  Sources for Credit Card Fraud Detection</b></summary>
  <p><b>编号</b>：[374]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03707</p>
  <p><b>作者</b>：Jaime D. Acevedo-Viloria,  Sebastián Soriano Pérez,  Jesus Solano,  David Zarruk-Valencia,  Fernando G. Paulin,  Alejandro Correa-Bahnsen</p>
  <p><b>备注</b>：Accepted for IEEE ISI 2021</p>
  <p><b>关键词</b>：identity theft credit card fraud, apps large digital platforms, traditional credit risk variables, mobile phone line data, encompass many different services</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Identity theft is a major problem for credit lenders when there's not enough
data to corroborate a customer's identity. Among super-apps large digital
platforms that encompass many different services this problem is even more
relevant; losing a client in one branch can often mean losing them in other
services. In this paper, we review the effectiveness of a feature-level fusion
of super-app customer information, mobile phone line data, and traditional
credit risk variables for the early detection of identity theft credit card
fraud. Through the proposed framework, we achieved better performance when
using a model whose input is a fusion of alternative data and traditional
credit bureau data, achieving a ROC AUC score of 0.81. We evaluate our approach
over approximately 90,000 users from a credit lender's digital platform
database. The evaluation was performed using not only traditional ML metrics
but the financial costs as well.</p>
  </details>
</details>
<details>
  <summary>129. <b>标题：Inferring untrained complex dynamics of delay systems using an adapted  echo state network</b></summary>
  <p><b>编号</b>：[375]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03706</p>
  <p><b>作者</b>：Mirko Goldmann,  Claudio R. Mirasso,  Ingo Fischer,  Miguel C. Soriano</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：many complex systems feature time delays, finite signal propagation velocities, driven machine learning yields, echo state network adaptable, unprecedented prediction accuracy</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Caused by finite signal propagation velocities, many complex systems feature
time delays that may induce high-dimensional chaotic behavior and make
forecasting intricate. Here, we propose an echo state network adaptable to the
physics of systems with arbitrary delays. After training the network to
forecast a system with a unique and sufficiently long delay, it already learned
to predict the system dynamics for all other delays. A simple adaptation of the
network's topology allows us to infer untrained features such as
high-dimensional chaotic attractors, bifurcations, and even multistabilities,
that emerge with shorter and longer delays. Thus, the fusion of physical
knowledge of the delay system and data-driven machine learning yields a model
with high generalization capabilities and unprecedented prediction accuracy.</p>
  </details>
</details>
<details>
  <summary>130. <b>标题：Reconstructing Training Data from Diverse ML Models by Ensemble  Inversion</b></summary>
  <p><b>编号</b>：[376]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03702</p>
  <p><b>作者</b>：Qian Wang,  Daniel Kurz</p>
  <p><b>备注</b>：9 pages, 8 figures, WACV 2022</p>
  <p><b>关键词</b>：training data contains personally identifiable information, explore targeting multiple models jointly, achieve high quality results without, attracted increasing research attention, may provide additional information</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Model Inversion (MI), in which an adversary abuses access to a trained
Machine Learning (ML) model attempting to infer sensitive information about its
original training data, has attracted increasing research attention. During MI,
the trained model under attack (MUA) is usually frozen and used to guide the
training of a generator, such as a Generative Adversarial Network (GAN), to
reconstruct the distribution of the original training data of that model. This
might cause leakage of original training samples, and if successful, the
privacy of dataset subjects will be at risk if the training data contains
Personally Identifiable Information (PII). Therefore, an in-depth investigation
of the potentials of MI techniques is crucial for the development of
corresponding defense techniques. High-quality reconstruction of training data
based on a single model is challenging. However, existing MI literature does
not explore targeting multiple models jointly, which may provide additional
information and diverse perspectives to the adversary.
We propose the ensemble inversion technique that estimates the distribution
of original training data by training a generator constrained by an ensemble
(or set) of trained models with shared subjects or entities. This technique
leads to noticeable improvements of the quality of the generated samples with
distinguishable features of the dataset entities compared to MI of a single ML
model. We achieve high quality results without any dataset and show how
utilizing an auxiliary dataset that's similar to the presumed training data
improves the results. The impact of model diversity in the ensemble is
thoroughly investigated and additional constraints are utilized to encourage
sharp predictions and high activations for the reconstructed samples, leading
to more accurate reconstruction of training images.</p>
  </details>
</details>
<details>
  <summary>131. <b>标题：Disaster mapping from satellites: damage detection with crowdsourced  point labels</b></summary>
  <p><b>编号</b>：[380]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03693</p>
  <p><b>作者</b>：Danil Kuzin,  Olga Isupova,  Brooke D. Simmons,  Steven Reece</p>
  <p><b>备注</b>：3rd Workshop on Artificial Intelligence for Humanitarian Assistance and Disaster Response at NeurIPS 2021</p>
  <p><b>关键词</b>：resolution satellite imagery available immediately, aggregating potentially inconsistent damage marks, scale would require hundreds, facilitates broad situational awareness, neural network damage detector</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>High-resolution satellite imagery available immediately after disaster events
is crucial for response planning as it facilitates broad situational awareness
of critical infrastructure status such as building damage, flooding, and
obstructions to access routes. Damage mapping at this scale would require
hundreds of expert person-hours. However, a combination of crowdsourcing and
recent advances in deep learning reduces the effort needed to just a few hours
in real time. Asking volunteers to place point marks, as opposed to shapes of
actual damaged areas, significantly decreases the required analysis time for
response during the disaster. However, different volunteers may be inconsistent
in their marking. This work presents methods for aggregating potentially
inconsistent damage marks to train a neural network damage detector.</p>
  </details>
</details>
<details>
  <summary>132. <b>标题：Oracle Teacher: Towards Better Knowledge Distillation</b></summary>
  <p><b>编号</b>：[384]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03664</p>
  <p><b>作者</b>：Ji Won Yoon,  Hyung Yong Kim,  Hyeonseung Lee,  Sunghwan Ahn,  Nam Soo Kim</p>
  <p><b>备注</b>：This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible</p>
  <p><b>关键词</b>：conventional kd methods usually employ, three different sequence learning tasks, kd ), best known, decoder attention structure, scene text recognition</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Knowledge distillation (KD), best known as an effective method for model
compression, aims at transferring the knowledge of a bigger network (teacher)
to a much smaller network (student). Conventional KD methods usually employ the
teacher model trained in a supervised manner, where output labels are treated
only as targets. Extending this supervised scheme further, we introduce a new
type of teacher model for KD, namely Oracle Teacher, that utilizes the
embeddings of both the source inputs and the output labels to extract a more
accurate knowledge to be transferred to the student. The proposed model follows
the encoder-decoder attention structure of the Transformer network, which
allows the model to attend to related information from the output labels.
Extensive experiments are conducted on three different sequence learning tasks:
speech recognition, scene text recognition, and machine translation. From the
experimental results, we empirically show that the proposed model improves the
students across these tasks while achieving a considerable speed-up in the
teacher model's training time.</p>
  </details>
</details>
<details>
  <summary>133. <b>标题：Stock Portfolio Optimization Using a Deep Learning LSTM Model</b></summary>
  <p><b>编号</b>：[387]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04709</p>
  <p><b>作者</b>：Jaydip Sen,  Abhishek Dutta,  Sidra Mehtab</p>
  <p><b>备注</b>：This is the accepted version of our paper in the international conference, IEEE Mysurucon'21, which was organized in Hassan, Karnataka, India from October 24, 2021 to October 25, 2021. The paper is 9 pages long, and it contains 19 figures and 19 tables. This is the preprint of the conference paper</p>
  <p><b>关键词</b>：predicting future stock prices, predicting future stock prices, indian stock market, capital assets using, top five stocks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Predicting future stock prices and their movement patterns is a complex
problem. Hence, building a portfolio of capital assets using the predicted
prices to achieve the optimization between its return and risk is an even more
difficult task. This work has carried out an analysis of the time series of the
historical prices of the top five stocks from the nine different sectors of the
Indian stock market from January 1, 2016, to December 31, 2020. Optimum
portfolios are built for each of these sectors. For predicting future stock
prices, a long-and-short-term memory (LSTM) model is also designed and
fine-tuned. After five months of the portfolio construction, the actual and the
predicted returns and risks of each portfolio are computed. The predicted and
the actual returns of each portfolio are found to be high, indicating the high
precision of the LSTM model.</p>
  </details>
</details>
<details>
  <summary>134. <b>标题：Smooth tensor estimation with unknown permutations</b></summary>
  <p><b>编号</b>：[390]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04681</p>
  <p><b>作者</b>：Chanwoo Lee,  Miaoyan Wang</p>
  <p><b>备注</b>：37 pages, 10 figures, 10 tables</p>
  <p><b>关键词</b>：time borda count algorithm, data problems arise commonly, chicago crime data analysis, smooth tensor estimation problems, provably achieves optimal rate</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We consider the problem of structured tensor denoising in the presence of
unknown permutations. Such data problems arise commonly in recommendation
system, neuroimaging, community detection, and multiway comparison
applications. Here, we develop a general family of smooth tensor models up to
arbitrary index permutations; the model incorporates the popular tensor block
models and Lipschitz hypergraphon models as special cases. We show that a
constrained least-squares estimator in the block-wise polynomial family
achieves the minimax error bound. A phase transition phenomenon is revealed
with respect to the smoothness threshold needed for optimal recovery. In
particular, we find that a polynomial of degree up to $(m-2)(m+1)/2$ is
sufficient for accurate recovery of order-$m$ tensors, whereas higher degree
exhibits no further benefits. This phenomenon reveals the intrinsic distinction
for smooth tensor estimation problems with and without unknown permutations.
Furthermore, we provide an efficient polynomial-time Borda count algorithm that
provably achieves optimal rate under monotonicity assumptions. The efficacy of
our procedure is demonstrated through both simulations and Chicago crime data
analysis.</p>
  </details>
</details>
<details>
  <summary>135. <b>标题：Consistent Sufficient Explanations and Minimal Local Rules for  explaining regression and classification models</b></summary>
  <p><b>编号</b>：[391]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04658</p>
  <p><b>作者</b>：Salim I. Amoukou,  Nicolas J.B Brunel</p>
  <p><b>备注</b>：8 pages, 2 figures, 1 table</p>
  <p><b>关键词</b>：probability via random forests, data $(\ boldsymbol, introduce local rule, http url }., explainable ai methods</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>To explain the decision of any model, we extend the notion of probabilistic
Sufficient Explanations (P-SE). For each instance, this approach selects the
minimal subset of features that is sufficient to yield the same prediction with
high probability, while removing other features. The crux of P-SE is to compute
the conditional probability of maintaining the same prediction. Therefore, we
introduce an accurate and fast estimator of this probability via random Forests
for any data $(\boldsymbol{X}, Y)$ and show its efficiency through a
theoretical analysis of its consistency. As a consequence, we extend the P-SE
to regression problems. In addition, we deal with non-binary features, without
learning the distribution of $X$ nor having the model for making predictions.
Finally, we introduce local rule-based explanations for
regression/classification based on the P-SE and compare our approaches w.r.t
other explainable AI methods. These methods are publicly available as a Python
package at \url{this http URL}.</p>
  </details>
</details>
<details>
  <summary>136. <b>标题：Learning Filterbanks for End-to-End Acoustic Beamforming</b></summary>
  <p><b>编号</b>：[393]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04614</p>
  <p><b>作者</b>：Samuele Cornell,  Manuel Pariente,  François Grondin,  Stefano Squartini</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：hybrid neural beamforming methods, recent clarity challenge data, end hybrid neural beamforming, explore two different types, using fully learned filterbanks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent work on monaural source separation has shown that performance can be
increased by using fully learned filterbanks with short windows. On the other
hand it is widely known that, for conventional beamforming techniques,
performance increases with long analysis windows. This applies also to most
hybrid neural beamforming methods which rely on a deep neural network (DNN) to
estimate the spatial covariance matrices. In this work we try to bridge the gap
between these two worlds and explore fully end-to-end hybrid neural beamforming
in which, instead of using the Short-Time-Fourier Transform, also the analysis
and synthesis filterbanks are learnt jointly with the DNN. In detail, we
explore two different types of learned filterbanks: fully learned and analytic.
We perform a detailed analysis using the recent Clarity Challenge data and show
that by using learnt filterbanks is possible to surpass oracle-mask based
beamforming for short windows.</p>
  </details>
</details>
<details>
  <summary>137. <b>标题：A Private and Computationally-Efficient Estimator for Unbounded  Gaussians</b></summary>
  <p><b>编号</b>：[395]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04609</p>
  <p><b>作者</b>：Gautam Kamath,  Argyris Mouzakis,  Vikrant Singhal,  Thomas Steinke,  Jonathan Ullman</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：n }( 0 ,\ sigma )$, n }(\ mu ,\ sigma )$, arbitrary gaussian distribution $\ mathcal, arbitrary gaussian $\ mathcal, primary new technical tool</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We give the first polynomial-time, polynomial-sample, differentially private
estimator for the mean and covariance of an arbitrary Gaussian distribution
$\mathcal{N}(\mu,\Sigma)$ in $\mathbb{R}^d$. All previous estimators are either
nonconstructive, with unbounded running time, or require the user to specify a
priori bounds on the parameters $\mu$ and $\Sigma$. The primary new technical
tool in our algorithm is a new differentially private preconditioner that takes
samples from an arbitrary Gaussian $\mathcal{N}(0,\Sigma)$ and returns a matrix
$A$ such that $A \Sigma A^T$ has constant condition number.</p>
  </details>
</details>
<details>
  <summary>138. <b>标题：Neyman-Pearson Multi-class Classification via Cost-sensitive Learning</b></summary>
  <p><b>编号</b>：[397]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04597</p>
  <p><b>作者</b>：Ye Tian,  Yang Feng</p>
  <p><b>备注</b>：44 pages, 6 figures</p>
  <p><b>关键词</b>：class np problem via cost, real data studies demonstrate, overall misclassification error rate, existing classification methods aim, class np problem</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Most existing classification methods aim to minimize the overall
misclassification error rate, however, in applications, different types of
errors can have different consequences. To take into account this asymmetry
issue, two popular paradigms have been developed, namely the Neyman-Pearson
(NP) paradigm and cost-sensitive (CS) paradigm. Compared to CS paradigm, NP
paradigm does not require a specification of costs. Most previous works on NP
paradigm focused on the binary case. In this work, we study the multi-class NP
problem by connecting it to the CS problem, and propose two algorithms. We
extend the NP oracle inequalities and consistency from the binary case to the
multi-class case, and show that our two algorithms enjoy these properties under
certain conditions. The simulation and real data studies demonstrate the
effectiveness of our algorithms. To our knowledge, this is the first work to
solve the multi-class NP problem via cost-sensitive learning techniques with
theoretical guarantees. The proposed algorithms are implemented in the R
package "npcs" on CRAN.</p>
  </details>
</details>
<details>
  <summary>139. <b>标题：Inertial Newton Algorithms Avoiding Strict Saddle Points</b></summary>
  <p><b>编号</b>：[398]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04596</p>
  <p><b>作者</b>：Camille Castera</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：almost always escape strict saddle points, qualitative behavior near critical points, order algorithms mixing newton, inertial gradient descent, newtonian behavior</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We study the asymptotic behavior of second-order algorithms mixing Newton's
method and inertial gradient descent in non-convex landscapes. We show that,
despite the Newtonian behavior of these methods, they almost always escape
strict saddle points. We also evidence the role played by the hyper-parameters
of these methods in their qualitative behavior near critical points. The
theoretical results are supported by numerical illustrations.</p>
  </details>
</details>
<details>
  <summary>140. <b>标题：Simultaneous estimation of wall and object parameters in TWR using deep  neural network</b></summary>
  <p><b>编号</b>：[400]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04568</p>
  <p><b>作者</b>：Fardin Ghorbani,  Hossein Soleimani</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：deep neural network model, using deep neural networks, estimate eight values simultaneously, included two wall parameters, deep learning model</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper presents a deep learning model for simultaneously estimating
target and wall parameters in Through-the-Wall Radar. In this work, we consider
two modes: single-target and two-targets. In both cases, we consider the
permittivity and thickness for the wall, as well as the two-dimensional
coordinates of the target's center and permittivity. This means that in the
case of a single target, we estimate five values, whereas, in the case of two
targets, we estimate eight values simultaneously, each of which represents the
mentioned parameters. We discovered that when using deep neural networks to
solve the target locating problem, giving the model more parameters of the
problem increases the location accuracy. As a result, we included two wall
parameters in the problem and discovered that the accuracy of target locating
improves while the wall parameters are estimated. We were able to estimate the
parameters of wall permittivity and thickness, as well as two-dimensional
coordinates and permittivity of targets in single-target and two-target modes
with 99\% accuracy by using a deep neural network model.</p>
  </details>
</details>
<details>
  <summary>141. <b>标题：RF-Net: a Unified Meta-learning Framework for RF-enabled One-shot Human  Activity Recognition</b></summary>
  <p><b>编号</b>：[401]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04566</p>
  <p><b>作者</b>：Shuya Ding,  Zhe Chen,  Tianyue Zheng,  Jun Luo</p>
  <p><b>备注</b>：14 pages</p>
  <p><b>关键词</b>：first examine three representative rf sensing techniques, learning powerful rf features including spatial, three rf sensing techniques, rf datasets strictly require, conduct extensive experiments based</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Radio-Frequency (RF) based device-free Human Activity Recognition (HAR) rises
as a promising solution for many applications. However, device-free (or
contactless) sensing is often more sensitive to environment changes than
device-based (or wearable) sensing. Also, RF datasets strictly require on-line
labeling during collection, starkly different from image and text data
collections where human interpretations can be leveraged to perform off-line
labeling. Therefore, existing solutions to RF-HAR entail a laborious data
collection process for adapting to new environments. To this end, we propose
RF-Net as a meta-learning based approach to one-shot RF-HAR; it reduces the
labeling efforts for environment adaptation to the minimum level. In
particular, we first examine three representative RF sensing techniques and two
major meta-learning approaches. The results motivate us to innovate in two
designs: i) a dual-path base HAR network, where both time and frequency domains
are dedicated to learning powerful RF features including spatial and
attention-based temporal ones, and ii) a metric-based meta-learning framework
to enhance the fast adaption capability of the base network, including an
RF-specific metric module along with a residual classification module. We
conduct extensive experiments based on all three RF sensing techniques in
multiple real-world indoor environments; all results strongly demonstrate the
efficacy of RF-Net compared with state-of-the-art baselines.</p>
  </details>
</details>
<details>
  <summary>142. <b>标题：Human Activity Recognition using Attribute-Based Neural Networks and  Context Information</b></summary>
  <p><b>编号</b>：[402]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04564</p>
  <p><b>作者</b>：Stefan Lüdtke,  Fernando Moya Rueda,  Waqas Ahmed,  Gernot A. Fink,  Thomas Kirste</p>
  <p><b>备注</b>：3rd International Workshop on Deep Learning for Human Activity Recognition</p>
  <p><b>关键词</b>：proposed architecture increases har performance, consider human activity recognition, currently executed process step, level movement descriptors, g ., standing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We consider human activity recognition (HAR) from wearable sensor data in
manual-work processes, like warehouse order-picking. Such structured domains
can often be partitioned into distinct process steps, e.g., packaging or
transporting. Each process step can have a different prior distribution over
activity classes, e.g., standing or walking, and different system dynamics.
Here, we show how such context information can be integrated systematically
into a deep neural network-based HAR system. Specifically, we propose a hybrid
architecture that combines a deep neural network-that estimates high-level
movement descriptors, attributes, from the raw-sensor data-and a shallow
classifier, which predicts activity classes from the estimated attributes and
(optional) context information, like the currently executed process step. We
empirically show that our proposed architecture increases HAR performance,
compared to state-of-the-art methods. Additionally, we show that HAR
performance can be further increased when information about process steps is
incorporated, even when that information is only partially correct.</p>
  </details>
</details>
<details>
  <summary>143. <b>标题：Fast and Scalable Spike and Slab Variable Selection in High-Dimensional  Gaussian Processes</b></summary>
  <p><b>编号</b>：[403]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04558</p>
  <p><b>作者</b>：Hugh Dance,  Brooks Paige</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：achieve substantial speed ups using zero temperature posterior restrictions, sparse variational gps whilst retaining similar runtimes, slab gp using mcmc, scalable variational inference algorithm, method consistently outperforms vanilla</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Variable selection in Gaussian processes (GPs) is typically undertaken by
thresholding the inverse lengthscales of `automatic relevance determination'
kernels, but in high-dimensional datasets this approach can be unreliable. A
more probabilistically principled alternative is to use spike and slab priors
and infer a posterior probability of variable inclusion. However, existing
implementations in GPs are extremely costly to run in both high-dimensional and
large-$n$ datasets, or are intractable for most kernels. As such, we develop a
fast and scalable variational inference algorithm for the spike and slab GP
that is tractable with arbitrary differentiable kernels. We improve our
algorithm's ability to adapt to the sparsity of relevant variables by Bayesian
model averaging over hyperparameters, and achieve substantial speed ups using
zero temperature posterior restrictions, dropout pruning and nearest neighbour
minibatching. In experiments our method consistently outperforms vanilla and
sparse variational GPs whilst retaining similar runtimes (even when $n=10^6$)
and performs competitively with a spike and slab GP using MCMC but runs up to
$1000$ times faster.</p>
  </details>
</details>
<details>
  <summary>144. <b>标题：Clustering and Structural Robustness in Causal Diagrams</b></summary>
  <p><b>编号</b>：[408]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04513</p>
  <p><b>作者</b>：Santtu Tikka,  Jouni Helske,  Juha Karvanen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：graphical approach may become impractical, causal effects remain unchanged, may erroneously change, visualize causal relations, called transit cluster</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Graphs are commonly used to represent and visualize causal relations. For a
small number of variables, this approach provides a succinct and clear view of
the scenario at hand. As the number of variables under study increases, the
graphical approach may become impractical, and the clarity of the
representation is lost. Clustering of variables is a natural way to reduce the
size of the causal diagram but it may erroneously change the essential
properties of the causal relations if implemented arbitrarily. We define a
specific type of cluster, called transit cluster, that is guaranteed to
preserve the identifiability properties of causal effects under certain
conditions. We provide a sound and complete algorithm for finding all transit
clusters in a given graph and demonstrate how clustering can simplify the
identification of causal effects. We also study the inverse problem, where one
starts with a clustered graph and looks for extended graphs where the
identifiability properties of causal effects remain unchanged. We show that
this kind of structural robustness is closely related to transit clusters.</p>
  </details>
</details>
<details>
  <summary>145. <b>标题：Mixed-Integer Optimization with Constraint Learning</b></summary>
  <p><b>编号</b>：[412]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04469</p>
  <p><b>作者</b>：Donato Maragno,  Holly Wiberg,  Dimitris Bertsimas,  S. Ilker Birbil,  Dick den Hertog,  Adejuyigbe Fajemisin</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：world food programme planning, many machine learning methods, capture various underlying relationships, multiple methods allows us, multiple machine learning methods</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We establish a broad methodological foundation for mixed-integer optimization
with learned constraints. We propose an end-to-end pipeline for data-driven
decision making in which constraints and objectives are directly learned from
data using machine learning, and the trained models are embedded in an
optimization formulation. We exploit the mixed-integer
optimization-representability of many machine learning methods, including
linear models, decision trees, ensembles, and multi-layer perceptrons. The
consideration of multiple methods allows us to capture various underlying
relationships between decisions, contextual variables, and outcomes. We also
characterize a decision trust region using the convex hull of the observations,
to ensure credible recommendations and avoid extrapolation. We efficiently
incorporate this representation using column generation and clustering. In
combination with domain-driven constraints and objective terms, the embedded
models and trust region define a mixed-integer optimization problem for
prescription generation. We implement this framework as a Python package
(OptiCL) for practitioners. We demonstrate the method in both chemotherapy
optimization and World Food Programme planning. The case studies illustrate the
benefit of the framework in generating high-quality prescriptions, the value
added by the trust region, the incorporation of multiple machine learning
methods, and the inclusion of multiple learned constraints.</p>
  </details>
</details>
<details>
  <summary>146. <b>标题：Lattice gauge symmetry in neural networks</b></summary>
  <p><b>编号</b>：[415]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04389</p>
  <p><b>作者</b>：Matteo Favoni,  Andreas Ipp,  David I. Müller,  Daniel Schuh</p>
  <p><b>备注</b>：10 pages, 3 figures, proceedings for the 38th International Symposium on Lattice Field Theory (LATTICE21)</p>
  <p><b>关键词</b>：novel neural network architecture called lattice gauge equivariant convolutional neural networks, compared using seemingly simple non, gauge equivariant convolutional layer, exactly preserving gauge symmetry, generic machine learning problems</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We review a novel neural network architecture called lattice gauge
equivariant convolutional neural networks (L-CNNs), which can be applied to
generic machine learning problems in lattice gauge theory while exactly
preserving gauge symmetry. We discuss the concept of gauge equivariance which
we use to explicitly construct a gauge equivariant convolutional layer and a
bilinear layer. The performance of L-CNNs and non-equivariant CNNs is compared
using seemingly simple non-linear regression tasks, where L-CNNs demonstrate
generalizability and achieve a high degree of accuracy in their predictions
compared to their non-equivariant counterparts.</p>
  </details>
</details>
<details>
  <summary>147. <b>标题：Can semi-supervised learning reduce the amount of manual labelling  required for effective radio galaxy morphology classification?</b></summary>
  <p><b>编号</b>：[417]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04357</p>
  <p><b>作者</b>：Inigo V. Slijepcevic,  Anna M. M. Scaife</p>
  <p><b>备注</b>：Accepted in: Fourth Workshop on Machine Learning and the Physical Sciences (35th Conference on Neural Information Processing Systems; NeurIPS2021); final version</p>
  <p><b>关键词</b>：using many fewer labelled data points, using truly unlabelled data leads, although ssl provides additional regularisation, using truly unlabelled data, test whether ssl</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this work, we examine the robustness of state-of-the-art semi-supervised
learning (SSL) algorithms when applied to morphological classification in
modern radio astronomy. We test whether SSL can achieve performance comparable
to the current supervised state of the art when using many fewer labelled data
points and if these results generalise to using truly unlabelled data. We find
that although SSL provides additional regularisation, its performance degrades
rapidly when using very few labels, and that using truly unlabelled data leads
to a significant drop in performance.</p>
  </details>
</details>
<details>
  <summary>148. <b>标题：Representation Learning via Quantum Neural Tangent Kernels</b></summary>
  <p><b>编号</b>：[419]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04225</p>
  <p><b>作者</b>：Junyu Liu,  Francesco Tacchino,  Jennifer R. Glick,  Liang Jiang,  Antonio Mezzacapo</p>
  <p><b>备注</b>：40=11+29 pages, many figures</p>
  <p><b>关键词</b>：analyzing variational quantum circuits using, define quantum neural tangent kernels, variational angles change slowly, designing good variational circuits, variational quantum simulation tasks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Variational quantum circuits are used in quantum machine learning and
variational quantum simulation tasks. Designing good variational circuits or
predicting how well they perform for given learning or optimization tasks is
still unclear. Here we discuss these problems, analyzing variational quantum
circuits using the theory of neural tangent kernels. We define quantum neural
tangent kernels, and derive dynamical equations for their associated loss
function in optimization and learning tasks. We analytically solve the dynamics
in the frozen limit, or lazy training regime, where variational angles change
slowly and a linear perturbation is good enough. We extend the analysis to a
dynamical setting, including quadratic corrections in the variational angles.
We then consider hybrid quantum-classical architecture and define a large width
limit for hybrid kernels, showing that a hybrid quantum-classical neural
network can be approximately Gaussian. The results presented here show limits
for which analytical understandings of the training dynamics for variational
quantum circuits, used for quantum machine learning and optimization problems,
are possible. These analytical results are supported by numerical simulations
of quantum machine learning experiments.</p>
  </details>
</details>
<details>
  <summary>149. <b>标题：AI challenges for predicting the impact of mutations on protein  stability</b></summary>
  <p><b>编号</b>：[421]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04208</p>
  <p><b>作者</b>：Fabrizio Pucci,  Martin Schwersensky,  Marianne Rooman</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：recurrent biases towards, reach improved performance, deleterious variant interpretation, around 1 kcal, independent test set</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Stability is a key ingredient of protein fitness and its modification through
targeted mutations has applications in various fields such as protein
engineering, drug design and deleterious variant interpretation. Many studies
have been devoted over the past decades to building new, more effective methods
for predicting the impact of mutations on protein stability, based on the
latest developments in artificial intelligence (AI). We discuss their features,
algorithms, computational efficiency, and accuracy estimated on an independent
test set. We focus on a critical analysis of their limitations, the recurrent
biases towards the training set, their generalizability and interpretability.
We found that the accuracy of the predictors has stagnated at around 1 kcal/mol
for over 15 years. We conclude by discussing the challenges that need to be
addressed to reach improved performance.</p>
  </details>
</details>
<details>
  <summary>150. <b>标题：Structure-aware generation of drug-like molecules</b></summary>
  <p><b>编号</b>：[424]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04107</p>
  <p><b>作者</b>：Pavol Drotár,  Arian Rokkum Jamasb,  Ben Day,  Cătălina Cangea,  Pietro Liò</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：novo design ), avoiding exhaustive virtual screening, based drug design involves finding ligand molecules, guided generation improves predicted binding affinities, generates molecular graphs jointly, novo models fail</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Structure-based drug design involves finding ligand molecules that exhibit
structural and chemical complementarity to protein pockets. Deep generative
methods have shown promise in proposing novel molecules from scratch (de-novo
design), avoiding exhaustive virtual screening of chemical space. Most
generative de-novo models fail to incorporate detailed ligand-protein
interactions and 3D pocket structures. We propose a novel supervised model that
generates molecular graphs jointly with 3D pose in a discretised molecular
space. Molecules are built atom-by-atom inside pockets, guided by structural
information from crystallographic data. We evaluate our model using a docking
benchmark and find that guided generation improves predicted binding affinities
by 8% and drug-likeness scores by 10% over the baseline. Furthermore, our model
proposes molecules with binding scores exceeding some known ligands, which
could be useful in future wet-lab studies.</p>
  </details>
</details>
<details>
  <summary>151. <b>标题：Acquisition-invariant brain MRI segmentation with informative  uncertainties</b></summary>
  <p><b>编号</b>：[425]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04094</p>
  <p><b>作者</b>：Pedro Borges,  Richard Shaw,  Thomas Varsavsky,  Kerstin Klaser,  David Thomas,  Ivana Drobnjak,  Sebastien Ourselin,  M Jorge Cardoso</p>
  <p><b>备注</b>：25 pages, 8 figures</p>
  <p><b>关键词</b>：site correction methods exist, simultaneously modelling uncertainty, sequence parameter choices, explicit uncertainty modelling, complete holdout datasets</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Combining multi-site data can strengthen and uncover trends, but is a task
that is marred by the influence of site-specific covariates that can bias the
data and therefore any downstream analyses. Post-hoc multi-site correction
methods exist but have strong assumptions that often do not hold in real-world
scenarios. Algorithms should be designed in a way that can account for
site-specific effects, such as those that arise from sequence parameter
choices, and in instances where generalisation fails, should be able to
identify such a failure by means of explicit uncertainty modelling. This body
of work showcases such an algorithm, that can become robust to the physics of
acquisition in the context of segmentation tasks, while simultaneously
modelling uncertainty. We demonstrate that our method not only generalises to
complete holdout datasets, preserving segmentation quality, but does so while
also accounting for site-specific sequence choices, which also allows it to
perform as a harmonisation tool.</p>
  </details>
</details>
<details>
  <summary>152. <b>标题：Learn-Morph-Infer: a new way of solving the inverse problem for brain  tumor modeling</b></summary>
  <p><b>编号</b>：[426]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04090</p>
  <p><b>作者</b>：Ivan Ezhov,  Kevin Scibilia,  Katharina Franitza,  Felix Steinbauer,  Suprosanna Shit,  Lucas Zimmer,  Jana Lipkova,  Florian Kofler,  Johannes Paetzold,  Luca Canalini,  Diana Waldmannstetter,  Martin Menten,  Marie Metz,  Benedikt Wiestler,  Bjoern Menze</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：mri ), contrast sufficiently well areas, tumor growth could complement imaging information, includes different mathematical formalisms describing, brain tumor could significantly benefit, various parametric inference schemes</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Current treatment planning of patients diagnosed with brain tumor could
significantly benefit by accessing the spatial distribution of tumor cell
concentration. Existing diagnostic modalities, such as magnetic-resonance
imaging (MRI), contrast sufficiently well areas of high cell density. However,
they do not portray areas of low concentration, which can often serve as a
source for the secondary appearance of the tumor after treatment. Numerical
simulations of tumor growth could complement imaging information by providing
estimates of full spatial distributions of tumor cells. Over recent years a
corpus of literature on medical image-based tumor modeling was published. It
includes different mathematical formalisms describing the forward tumor growth
model. Alongside, various parametric inference schemes were developed to
perform an efficient tumor model personalization, i.e. solving the inverse
problem. However, the unifying drawback of all existing approaches is the time
complexity of the model personalization that prohibits a potential integration
of the modeling into clinical settings. In this work, we introduce a
methodology for inferring patient-specific spatial distribution of brain tumor
from T1Gd and FLAIR MRI medical scans. Coined as \textit{Learn-Morph-Infer} the
method achieves real-time performance in the order of minutes on widely
available hardware and the compute time is stable across tumor models of
different complexity, such as reaction-diffusion and
reaction-advection-diffusion models. We believe the proposed inverse solution
approach not only bridges the way for clinical translation of brain tumor
personalization but can also be adopted to other scientific and engineering
domains.</p>
  </details>
</details>
<details>
  <summary>153. <b>标题：Kernel Methods for Multistage Causal Inference: Mediation Analysis and  Dynamic Treatment Effects</b></summary>
  <p><b>编号</b>：[434]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03950</p>
  <p><b>作者</b>：Rahul Singh,  Liyuan Xu,  Arthur Gretton</p>
  <p><b>备注</b>：66 pages. Material in this draft previously appeared in a working paper presented at the 2020 NeurIPS Workshop on ML for Economic Policy (arXiv:2010.04855v1). We have divided the original working paper (arXiv:2010.04855v1) into two projects: one paper focusing on static settings (arXiv:2010.04855) and this paper focusing on dynamic settings</p>
  <p><b>关键词</b>：propose kernel ridge regression estimators, us job corps program, kernel matrix operations, finite sample rates, dynamic treatment effects</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose kernel ridge regression estimators for mediation analysis and
dynamic treatment effects over short horizons. We allow treatments, covariates,
and mediators to be discrete or continuous, and low, high, or infinite
dimensional. We propose estimators of means, increments, and distributions of
counterfactual outcomes with closed form solutions in terms of kernel matrix
operations. For the continuous treatment case, we prove uniform consistency
with finite sample rates. For the discrete treatment case, we prove root-n
consistency, Gaussian approximation, and semiparametric efficiency. We conduct
simulations then estimate mediated and dynamic treatment effects of the US Job
Corps program for disadvantaged youth.</p>
  </details>
</details>
<details>
  <summary>154. <b>标题：Deep Neyman-Scott Processes</b></summary>
  <p><b>编号</b>：[435]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03949</p>
  <p><b>作者</b>：Chengkuan Hong,  Christian R. Shelton</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：efficient posterior sampling via markov chain monte carlo, hidden poisson processes brings better performance, using far fewer parameters, sophisticated hierarchical point processes, observable stochastic processes</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A Neyman-Scott process is a special case of a Cox process. The latent and
observable stochastic processes are both Poisson processes. We consider a deep
Neyman-Scott process in this paper, for which the building components of a
network are all Poisson processes. We develop an efficient posterior sampling
via Markov chain Monte Carlo and use it for likelihood-based inference. Our
method opens up room for the inference in sophisticated hierarchical point
processes. We show in the experiments that more hidden Poisson processes brings
better performance for likelihood fitting and events types prediction. We also
compare our method with state-of-the-art models for temporal real-world
datasets and demonstrate competitive abilities for both data fitting and
prediction, using far fewer parameters.</p>
  </details>
</details>
<details>
  <summary>155. <b>标题：AGGLIO: Global Optimization for Locally Convex Functions</b></summary>
  <p><b>编号</b>：[436]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03932</p>
  <p><b>作者</b>：Debojyoti Dey,  Bhaskar Mukhoty,  Purushottam Kar</p>
  <p><b>备注</b>：33 pages, 7 figures, to appear at 9th ACM IKDD Conference on Data Science (CODS) 2022. Code for AGGLIO is available at this https URL</p>
  <p><b>关键词</b>：agglio outperformed several recently proposed optimization techniques, convex optimization problems whose objectives offer, utilize popular activation functions, readily implemented using point, accelerated graduated generalized linear</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper presents AGGLIO (Accelerated Graduated Generalized LInear-model
Optimization), a stage-wise, graduated optimization technique that offers
global convergence guarantees for non-convex optimization problems whose
objectives offer only local convexity and may fail to be even quasi-convex at a
global scale. In particular, this includes learning problems that utilize
popular activation functions such as sigmoid, softplus and SiLU that yield
non-convex training objectives. AGGLIO can be readily implemented using point
as well as mini-batch SGD updates and offers provable convergence to the global
optimum in general conditions. In experiments, AGGLIO outperformed several
recently proposed optimization techniques for non-convex and locally convex
objectives in terms of convergence rate as well as convergent accuracy. AGGLIO
relies on a graduation technique for generalized linear models, as well as a
novel proof strategy, both of which may be of independent interest.</p>
  </details>
</details>
<details>
  <summary>156. <b>标题：Learning equilibria with personalized incentives in a class of  nonmonotone games</b></summary>
  <p><b>编号</b>：[438]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03854</p>
  <p><b>作者</b>：Filippo Fabiani,  Andrea Simonetto,  Paul J. Goulart</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：nonmonotone generalized nash equilibrium problems, layer nash equilibrium seeking algorithm, symmetric interactions among, standard learning policies, underlying potential function</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We consider quadratic, nonmonotone generalized Nash equilibrium problems with
symmetric interactions among the agents, which are known to be potential. As
may happen in practical cases, we envision a scenario in which an explicit
expression of the underlying potential function is not available, and we design
a two-layer Nash equilibrium seeking algorithm. In the proposed scheme, a
coordinator iteratively integrates the noisy agents' feedback to learn the
pseudo-gradients of the agents, and then design personalized incentives for
them. On their side, the agents receive those personalized incentives, compute
a solution to an extended game, and then return feedback measures to the
coordinator. We show that our algorithm returns an equilibrium in case the
coordinator is endowed with standard learning policies, and corroborate our
results on a numerical instance of a hypomonotone game.</p>
  </details>
</details>
<details>
  <summary>157. <b>标题：A new baseline for retinal vessel segmentation: Numerical identification  and correction of methodological inconsistencies affecting 100+ papers</b></summary>
  <p><b>编号</b>：[439]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03853</p>
  <p><b>作者</b>：György Kovács,  Attila Fazekas</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：de facto benchmarking data sets, similar problems may arise, highest accuracy score achieved, perfect accuracy scores reported, biases using numerical techniques</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In the last 15 years, the segmentation of vessels in retinal images has
become an intensively researched problem in medical imaging, with hundreds of
algorithms published. One of the de facto benchmarking data sets of vessel
segmentation techniques is the DRIVE data set. Since DRIVE contains a
predefined split of training and test images, the published performance results
of the various segmentation techniques should provide a reliable ranking of the
algorithms. Including more than 100 papers in the study, we performed a
detailed numerical analysis of the coherence of the published performance
scores. We found inconsistencies in the reported scores related to the use of
the field of view (FoV), which has a significant impact on the performance
scores. We attempted to eliminate the biases using numerical techniques to
provide a more realistic picture of the state of the art. Based on the results,
we have formulated several findings, most notably: despite the well-defined
test set of DRIVE, most rankings in published papers are based on
non-comparable figures; in contrast to the near-perfect accuracy scores
reported in the literature, the highest accuracy score achieved to date is
0.9582 in the FoV region, which is 1% higher than that of human annotators. The
methods we have developed for identifying and eliminating the evaluation biases
can be easily applied to other domains where similar problems may arise.</p>
  </details>
</details>
<details>
  <summary>158. <b>标题：Class Token and Knowledge Distillation for Multi-head Self-Attention  Speaker Verification Systems</b></summary>
  <p><b>编号</b>：[442]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03842</p>
  <p><b>作者</b>：Victoria Mingote,  Antonio Miguel,  Alfonso Ortega,  Eduardo Lleida</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：paper explores three novel approaches, learnable vector called class token, providing competitive results compared, unlike global average pooling, average global pooling mechanism</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper explores three novel approaches to improve the performance of
speaker verification (SV) systems based on deep neural networks (DNN) using
Multi-head Self-Attention (MSA) mechanisms and memory layers. Firstly, we
propose the use of a learnable vector called Class token to replace the average
global pooling mechanism to extract the embeddings. Unlike global average
pooling, our proposal takes into account the temporal structure of the input
what is relevant for the text-dependent SV task. The class token is
concatenated to the input before the first MSA layer, and its state at the
output is used to predict the classes. To gain additional robustness, we
introduce two approaches. First, we have developed a Bayesian estimation of the
class token. Second, we have added a distilled representation token for
training a teacher-student pair of networks using the Knowledge Distillation
(KD) philosophy, which is combined with the class token. This distillation
token is trained to mimic the predictions from the teacher network, while the
class token replicates the true label. All the strategies have been tested on
the RSR2015-Part II and DeepMine-Part 1 databases for text-dependent SV,
providing competitive results compared to the same architecture using the
average pooling mechanism to extract average embeddings.</p>
  </details>
</details>
<details>
  <summary>159. <b>标题：Distributed stochastic proximal algorithm with random reshuffling for  non-smooth finite-sum optimization</b></summary>
  <p><b>编号</b>：[443]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03820</p>
  <p><b>作者</b>：Xia Jiang,  Xianlin Zeng,  Jian Sun,  Jie Chen,  Lihua Xie</p>
  <p><b>备注</b>：15 pages, 7 figures</p>
  <p><b>关键词</b>：network updates local variables, local variable estimates generated, choosing small enough step, proposed algorithm achieve consensus, distributed stochastic proximal</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The non-smooth finite-sum minimization is a fundamental problem in machine
learning. This paper develops a distributed stochastic proximal-gradient
algorithm with random reshuffling to solve the finite-sum minimization over
time-varying multi-agent networks. The objective function is a sum of
differentiable convex functions and non-smooth regularization. Each agent in
the network updates local variables with a constant step-size by local
information and cooperates to seek an optimal solution. We prove that local
variable estimates generated by the proposed algorithm achieve consensus and
are attracted to a neighborhood of the optimal solution in expectation with an
$\mathcal{O}(\frac{1}{T}+\frac{1}{\sqrt{T}})$ convergence rate. In addition,
this paper shows that the steady-state error of the objective function can be
arbitrarily small by choosing small enough step-sizes. Finally, some
comparative simulations are provided to verify the convergence performance of
the proposed algorithm.</p>
  </details>
</details>
<details>
  <summary>160. <b>标题：Tradeoffs of Linear Mixed Models in Genome-wide Association Studies</b></summary>
  <p><b>编号</b>：[447]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03739</p>
  <p><b>作者</b>：Haohan Wang,  Bryon Aragam,  Eric Xing</p>
  <p><b>备注</b>：in final revision of Journal of Computational Biology</p>
  <p><b>关键词</b>：two confounding factors differently, consider two sources, wide association studies, results shed light, environmental confounding factors</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Motivated by empirical arguments that are well-known from the genome-wide
association studies (GWAS) literature, we study the statistical properties of
linear mixed models (LMMs) applied to GWAS. First, we study the sensitivity of
LMMs to the inclusion of a candidate SNP in the kinship matrix, which is often
done in practice to speed up computations. Our results shed light on the size
of the error incurred by including a candidate SNP, providing a justification
to this technique in order to trade-off velocity against veracity. Second, we
investigate how mixed models can correct confounders in GWAS, which is widely
accepted as an advantage of LMMs over traditional methods. We consider two
sources of confounding factors, population stratification and environmental
confounding factors, and study how different methods that are commonly used in
practice trade-off these two confounding factors differently.</p>
  </details>
</details>
<details>
  <summary>161. <b>标题：Explaining neural network predictions of material strength</b></summary>
  <p><b>编号</b>：[448]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03729</p>
  <p><b>作者</b>：Ian A. Palmer,  T. Nathan Mundhenk,  Brian Gallagher,  Yong Han</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：explainable ai saliency map, helps us map features, scanning electron microscope, critical peak stress, natural image photographs</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We recently developed a deep learning method that can determine the critical
peak stress of a material by looking at scanning electron microscope (SEM)
images of the material's crystals. However, it has been somewhat unclear what
kind of image features the network is keying off of when it makes its
prediction. It is common in computer vision to employ an explainable AI
saliency map to tell one what parts of an image are important to the network's
decision. One can usually deduce the important features by looking at these
salient locations. However, SEM images of crystals are more abstract to the
human observer than natural image photographs. As a result, it is not easy to
tell what features are important at the locations which are most salient. To
solve this, we developed a method that helps us map features from important
locations in SEM images to non-abstract textures that are easier to interpret.</p>
  </details>
</details>
<details>
  <summary>162. <b>标题：Damage Estimation and Localization from Sparse Aerial Imagery</b></summary>
  <p><b>编号</b>：[449]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03708</p>
  <p><b>作者</b>：Rene Garcia Franceschini,  Jeffrey Liu,  Saurabh Amin</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：aerial images provide important situational awareness, handheld cameras lack imu information, high precision using limited data, using class activation mapping, unmanned aerial systems technology</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Aerial images provide important situational awareness for responding to
natural disasters such as hurricanes. They are well-suited for providing
information for damage estimation and localization (DEL); i.e., characterizing
the type and spatial extent of damage following a disaster. Despite recent
advances in sensing and unmanned aerial systems technology, much of
post-disaster aerial imagery is still taken by handheld DSLR cameras from
small, manned, fixed-wing aircraft. However, these handheld cameras lack IMU
information, and images are taken opportunistically post-event by operators. As
such, DEL from such imagery is still a highly manual and time-consuming
process. We propose an approach to both detect damage in aerial images and
localize it in world coordinates, with specific focus on detecting and
localizing flooding. The approach is based on using structure from motion to
relate image coordinates to world coordinates via a projective transformation,
using class activation mapping to detect the extent of damage in an image, and
applying the projective transformation to localize damage in world coordinates.
We evaluate the performance of our approach on post-event data from the 2016
Louisiana floods, and find that our approach achieves a precision of 88%. Given
this high precision using limited data, we argue that this approach is
currently viable for fast and effective DEL from handheld aerial imagery for
disaster response.</p>
  </details>
</details>
<details>
  <summary>163. <b>标题：First steps on Gamification of Lung Fluid Cells Annotations in the  Flower Domain</b></summary>
  <p><b>编号</b>：[452]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03663</p>
  <p><b>作者</b>：Sonja Kunzmann,  Christian Marzahl,  Felix Denzinger,  Christof A. Bertram,  Robert Klopfleisch,  Katharina Breininger,  Vincent Christlein,  Andreas Maier</p>
  <p><b>备注</b>：6 pages, 4 figures</p>
  <p><b>关键词</b>：transformed lung fluid cells, original lung fluid cells, pathological whole slide images, image classification network trained, annotating lung fluid cells</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Annotating data, especially in the medical domain, requires expert knowledge
and a lot of effort. This limits the amount and/or usefulness of available
medical data sets for experimentation. Therefore, developing strategies to
increase the number of annotations while lowering the needed domain knowledge
is of interest. A possible strategy is the use of gamification, that is i.e.
transforming the annotation task into a game. We propose an approach to gamify
the task of annotating lung fluid cells from pathological whole slide images.
As this domain is unknown to non-expert annotators, we transform images of
cells detected with a RetinaNet architecture to the domain of flower images.
This domain transfer is performed with a CycleGAN architecture for different
cell types. In this more assessable domain, non-expert annotators can be
(t)asked to annotate different kinds of flowers in a playful setting. In order
to provide a proof of concept, this work shows that the domain transfer is
possible by evaluating an image classification network trained on real cell
images and tested on the cell images generated by the CycleGAN network. The
classification network reaches an accuracy of 97.48% and 95.16% on the original
lung fluid cells and transformed lung fluid cells, respectively. With this
study, we lay the foundation for future research on gamification using
CycleGANs.</p>
  </details>
</details>
<details>
  <summary>164. <b>标题：Predicting Mortality from Credit Reports</b></summary>
  <p><b>编号</b>：[453]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03662</p>
  <p><b>作者</b>：Giacomo De Giorgi,  Matthew Harding,  Gabriel Vasconcelos</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：may also raise privacy concerns, carry significant predictive power, also significant thus indicating, improved mortality predictions based, individual consumer finance behavior</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Data on hundreds of variables related to individual consumer finance behavior
(such as credit card and loan activity) is routinely collected in many
countries and plays an important role in lending decisions. We postulate that
the detailed nature of this data may be used to predict outcomes in seemingly
unrelated domains such as individual health. We build a series of machine
learning models to demonstrate that credit report data can be used to predict
individual mortality. Variable groups related to credit cards and various
loans, mostly unsecured loans, are shown to carry significant predictive power.
Lags of these variables are also significant thus indicating that dynamics also
matters. Improved mortality predictions based on consumer finance data can have
important economic implications in insurance markets but may also raise privacy
concerns.</p>
  </details>
</details>
<h1>人工智能</h1>
<details>
  <summary>1. <b>标题：Understanding the Effects of Dataset Characteristics on Offline  Reinforcement Learning</b></summary>
  <p><b>编号</b>：[6]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04714</p>
  <p><b>作者</b>：Kajetan Schweighofer,  Markus Hofmarcher,  Marius-Constantin Dinu,  Philipp Renz,  Angela Bitto-Nemling,  Vihang Patil,  Sepp Hochreiter</p>
  <p><b>备注</b>：Code: this https URL</p>
  <p><b>关键词</b>：dataset characteristics influence different offline rl algorithms, therefore hampers real world applications, given dataset without interacting, best offline rl algorithms, average dataset return measured</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In real world, affecting the environment by a weak policy can be expensive or
very risky, therefore hampers real world applications of reinforcement
learning. Offline Reinforcement Learning (RL) can learn policies from a given
dataset without interacting with the environment. However, the dataset is the
only source of information for an Offline RL algorithm and determines the
performance of the learned policy. We still lack studies on how dataset
characteristics influence different Offline RL algorithms. Therefore, we
conducted a comprehensive empirical analysis of how dataset characteristics
effect the performance of Offline RL algorithms for discrete action
environments. A dataset is characterized by two metrics: (1) the average
dataset return measured by the Trajectory Quality (TQ) and (2) the coverage
measured by the State-Action Coverage (SACo). We found that variants of the
off-policy Deep Q-Network family require datasets with high SACo to perform
well. Algorithms that constrain the learned policy towards the given dataset
perform well for datasets with high TQ or SACo. For datasets with high TQ,
Behavior Cloning outperforms or performs similarly to the best Offline RL
algorithms.</p>
  </details>
</details>
<details>
  <summary>2. <b>标题：A Comparison of Model-Free and Model Predictive Control for Price  Responsive Water Heaters</b></summary>
  <p><b>编号</b>：[12]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04689</p>
  <p><b>作者</b>：David J. Biagioni,  Xiangyu Zhang,  Peter Graf,  Devon Sigler,  Wesley Jones</p>
  <p><b>备注</b>：All authors are with the Computational Science Center at the National Renewable Energy Laboratory. Corresponding author: David Biagioni (dave.biagioni@nrel.gov)</p>
  <p><b>关键词</b>：stage stochastic programming controller using historical scenarios, 90 seconds using 1150 cpu cores, ppo learn good general purpose policies, receding horizon model predictive control, perfect forecasting yielding optimal control</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present a careful comparison of two model-free control algorithms,
Evolution Strategies (ES) and Proximal Policy Optimization (PPO), with receding
horizon model predictive control (MPC) for operating simulated, price
responsive water heaters. Four MPC variants are considered: a one-shot
controller with perfect forecasting yielding optimal control; a limited-horizon
controller with perfect forecasting; a mean forecasting-based controller; and a
two-stage stochastic programming controller using historical scenarios. In all
cases, the MPC model for water temperature and electricity price are exact;
only water demand is uncertain. For comparison, both ES and PPO learn neural
network-based policies by directly interacting with the simulated environment
under the same scenarios used by MPC. All methods are then evaluated on a
separate one-week continuation of the demand time series. We demonstrate that
optimal control for this problem is challenging, requiring more than 8-hour
lookahead for MPC with perfect forecasting to attain the minimum cost. Despite
this challenge, both ES and PPO learn good general purpose policies that
outperform mean forecast and two-stage stochastic MPC controllers in terms of
average cost and are more than two orders of magnitude faster at computing
actions. We show that ES in particular can leverage parallelism to learn a
policy in under 90 seconds using 1150 CPU cores.</p>
  </details>
</details>
<details>
  <summary>3. <b>标题：Reinforcement Learning for Mixed Autonomy Intersections</b></summary>
  <p><b>编号</b>：[14]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04686</p>
  <p><b>作者</b>：Zhongxia Yan,  Cathy Wu</p>
  <p><b>备注</b>：7 pages, 6 figures, ITSC 2021, 2021 IEEE International Conference on Intelligent Transportation Systems (ITSC)</p>
  <p><b>关键词</b>：behavior generalizes across inflow rates, even without reward shaping, allows decentralized control based, controlling mixed autonomy traffic, free reinforcement learning method</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose a model-free reinforcement learning method for controlling mixed
autonomy traffic in simulated traffic networks with through-traffic-only
two-way and four-way intersections. Our method utilizes multi-agent policy
decomposition which allows decentralized control based on local observations
for an arbitrary number of controlled vehicles. We demonstrate that, even
without reward shaping, reinforcement learning learns to coordinate the
vehicles to exhibit traffic signal-like behaviors, achieving near-optimal
throughput with 33-50% controlled vehicles. With the help of multi-task
learning and transfer learning, we show that this behavior generalizes across
inflow rates and size of the traffic network. Our code, models, and videos of
results are available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>4. <b>标题：Revisiting Methods for Finding Influential Examples</b></summary>
  <p><b>编号</b>：[15]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04683</p>
  <p><b>作者</b>：Karthikeyan K,  Anders Søgaard</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：e ., extremely sensitive, finding influential training examples, evaluated using loo influence, yet effective baseline, representer point selection</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Several instance-based explainability methods for finding influential
training examples for test-time decisions have been proposed recently,
including Influence Functions, TraceIn, Representer Point Selection, Grad-Dot,
and Grad-Cos. Typically these methods are evaluated using LOO influence (Cook's
distance) as a gold standard, or using various heuristics. In this paper, we
show that all of the above methods are unstable, i.e., extremely sensitive to
initialization, ordering of the training data, and batch size. We suggest that
this is a natural consequence of how in the literature, the influence of
examples is assumed to be independent of model state and other examples -- and
argue it is not. We show that LOO influence and heuristics are, as a result,
poor metrics to measure the quality of instance-based explanations, and instead
propose to evaluate such explanations by their ability to detect poisoning
attacks. Further, we provide a simple, yet effective baseline to improve all of
the above methods and show how it leads to very significant improvements on
downstream tasks.</p>
  </details>
</details>
<details>
  <summary>5. <b>标题：SMU: smooth activation function for deep networks using smoothing  maximum technique</b></summary>
  <p><b>编号</b>：[16]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04682</p>
  <p><b>作者</b>：Koushik Biswas,  Sandeep Kumar,  Shilpak Banerjee,  Ashish Kumar Pandey</p>
  <p><b>备注</b>：7 pages</p>
  <p><b>关键词</b>：proposing two new novel activation functions, known activation functions like leaky relu, new novel activation function based, function smooth maximum unit, deep learning community due</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep learning researchers have a keen interest in proposing two new novel
activation functions which can boost network performance. A good choice of
activation function can have significant consequences in improving network
performance. A handcrafted activation is the most common choice in neural
network models. ReLU is the most common choice in the deep learning community
due to its simplicity though ReLU has some serious drawbacks. In this paper, we
have proposed a new novel activation function based on approximation of known
activation functions like Leaky ReLU, and we call this function Smooth Maximum
Unit (SMU). Replacing ReLU by SMU, we have got 6.22% improvement in the
CIFAR100 dataset with the ShuffleNet V2 model.</p>
  </details>
</details>
<details>
  <summary>6. <b>标题：Evaluating Predictive Uncertainty and Robustness to Distributional Shift  Using Real World Data</b></summary>
  <p><b>编号</b>：[22]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04665</p>
  <p><b>作者</b>：Kumud Lakara,  Akshat Bhandari,  Pratinav Seth,  Ujjwal Verma</p>
  <p><b>备注</b>：6 pages, 3 figures, 4 tables</p>
  <p><b>关键词</b>：machine learning models operate, general regression tasks using, shifts weather prediction dataset, generally hold true, baseline methods using</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Most machine learning models operate under the assumption that the training,
testing and deployment data is independent and identically distributed
(i.i.d.). This assumption doesn't generally hold true in a natural setting.
Usually, the deployment data is subject to various types of distributional
shifts. The magnitude of a model's performance is proportional to this shift in
the distribution of the dataset. Thus it becomes necessary to evaluate a
model's uncertainty and robustness to distributional shifts to get a realistic
estimate of its expected performance on real-world data. Present methods to
evaluate uncertainty and model's robustness are lacking and often fail to paint
the full picture. Moreover, most analysis so far has primarily focused on
classification tasks. In this paper, we propose more insightful metrics for
general regression tasks using the Shifts Weather Prediction Dataset. We also
present an evaluation of the baseline methods using these metrics.</p>
  </details>
</details>
<details>
  <summary>7. <b>标题：Intelligent Reflecting Surfaces for Enhanced NOMA-based Visible Light  Communications</b></summary>
  <p><b>编号</b>：[26]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04646</p>
  <p><b>作者</b>：Hanaa Abumarshoud,  Bassant Selim,  Mallik Tatipamula,  Harald Haas</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：achieve specific key performance indicators, emerging intelligent reflecting surface, vlc systems employing non, visible light communication, random device orientation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The emerging intelligent reflecting surface (IRS) technology introduces the
potential of controlled light propagation in visible light communication (VLC)
systems. This concept opens the door for new applications in which the channel
itself can be altered to achieve specific key performance indicators. In this
paper, for the first time in the open literature, we investigate the role that
IRSs can play in enhancing the link reliability in VLC systems employing
non-orthogonal multiple access (NOMA). We propose a framework for the joint
optimisation of the NOMA and IRS parameters and show that it provides
significant enhancements in link reliability. The enhancement is even more
pronounced when the VLC channel is subject to blockage and random device
orientation.</p>
  </details>
</details>
<details>
  <summary>8. <b>标题：DeepSteal: Advanced Model Extractions Leveraging Efficient Weight  Stealing in Memories</b></summary>
  <p><b>编号</b>：[33]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04625</p>
  <p><b>作者</b>：Adnan Siraj Rakin,  Md Hafizul Islam Chowdhuryy,  Fan Yao,  Deliang Fan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：extracted substitute model could also generate effective adversarial input samples, existing attacks cannot extract detailed model parameters, proposed deepsteal comprises two key stages, advanced model extraction attack framework deepsteal, new weight bit information extraction method</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent advancements of Deep Neural Networks (DNNs) have seen widespread
deployment in multiple security-sensitive domains. The need of
resource-intensive training and use of valuable domain-specific training data
have made these models a top intellectual property (IP) for model owners. One
of the major threats to the DNN privacy is model extraction attacks where
adversaries attempt to steal sensitive information in DNN models. Recent
studies show hardware-based side channel attacks can reveal internal knowledge
about DNN models (e.g., model architectures) However, to date, existing attacks
cannot extract detailed model parameters (e.g., weights/biases). In this work,
for the first time, we propose an advanced model extraction attack framework
DeepSteal that effectively steals DNN weights with the aid of memory
side-channel attack. Our proposed DeepSteal comprises two key stages. Firstly,
we develop a new weight bit information extraction method, called HammerLeak,
through adopting the rowhammer based hardware fault technique as the
information leakage vector. HammerLeak leverages several novel system-level
techniques tailed for DNN applications to enable fast and efficient weight
stealing. Secondly, we propose a novel substitute model training algorithm with
Mean Clustering weight penalty, which leverages the partial leaked bit
information effectively and generates a substitute prototype of the target
victim model. We evaluate this substitute model extraction method on three
popular image datasets (e.g., CIFAR-10/100/GTSRB) and four DNN architectures
(e.g., ResNet-18/34/Wide-ResNet/VGG-11). The extracted substitute model has
successfully achieved more than 90 % test accuracy on deep residual networks
for the CIFAR-10 dataset. Moreover, our extracted substitute model could also
generate effective adversarial input samples to fool the victim model.</p>
  </details>
</details>
<details>
  <summary>9. <b>标题：CoCo Games: Graphical Game-Theoretic Swarm Control for  Communication-Aware Coverage</b></summary>
  <p><b>编号</b>：[49]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04576</p>
  <p><b>作者</b>：Malintha Fernando,  Ransalu Senanayake,  Martin Swany</p>
  <p><b>备注</b>：8 pages, 7 figures</p>
  <p><b>关键词</b>：hoc wireless network scenario using unmanned aerial vehicles, underlying network topology, realistic network conditions, scale geographical regions, employ variational inference</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present a novel approach to maximize the communication-aware coverage for
robots operating over large-scale geographical regions of interest (ROIs). Our
approach complements the underlying network topology in neighborhood selection
and control, rendering it highly robust in dynamic environments. We formulate
the coverage as a multi-stage, cooperative graphical game and employ
Variational Inference (VI) to reach the equilibrium. We experimentally validate
our approach in an mobile ad-hoc wireless network scenario using Unmanned
Aerial Vehicles (UAV) and User Equipment (UE) robots. We show that it can cater
to ROIs defined by stationary and moving User Equipment (UE) robots under
realistic network conditions.</p>
  </details>
</details>
<details>
  <summary>10. <b>标题：Sexism Prediction in Spanish and English Tweets Using Monolingual and  Multilingual BERT and Ensemble Models</b></summary>
  <p><b>编号</b>：[55]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04551</p>
  <p><b>作者</b>：Angel Felipe Magnossão de Paula,  Roberto Fray da Silva,  Ipek Baris Schlicht</p>
  <p><b>备注</b>：18 pages, presented at IberLEF: this http URL, the best scoring system at EXIST</p>
  <p><b>关键词</b>：ensemble models obtained better results, iberian languages evaluation forum, work obtained first place, best standardized values obtained, system obtained better results</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The popularity of social media has created problems such as hate speech and
sexism. The identification and classification of sexism in social media are
very relevant tasks, as they would allow building a healthier social
environment. Nevertheless, these tasks are considerably challenging. This work
proposes a system to use multilingual and monolingual BERT and data points
translation and ensemble strategies for sexism identification and
classification in English and Spanish. It was conducted in the context of the
sEXism Identification in Social neTworks shared 2021 (EXIST 2021) task,
proposed by the Iberian Languages Evaluation Forum (IberLEF). The proposed
system and its main components are described, and an in-depth hyperparameters
analysis is conducted. The main results observed were: (i) the system obtained
better results than the baseline model (multilingual BERT); (ii) ensemble
models obtained better results than monolingual models; and (iii) an ensemble
model considering all individual models and the best standardized values
obtained the best accuracies and F1-scores for both tasks. This work obtained
first place in both tasks at EXIST, with the highest accuracies (0.780 for task
1 and 0.658 for task 2) and F1-scores (F1-binary of 0.780 for task 1 and
F1-macro of 0.579 for task 2).</p>
  </details>
</details>
<details>
  <summary>11. <b>标题：Improving RNA Secondary Structure Design using Deep Reinforcement  Learning</b></summary>
  <p><b>编号</b>：[67]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04504</p>
  <p><b>作者</b>：Alexander Whatley,  Zhekun Luo,  Xiangru Tang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：future experiments involving machine learning, applying reinforcement learning, widely used approach, performance across batches, simulates biological evolution</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Rising costs in recent years of developing new drugs and treatments have led
to extensive research in optimization techniques in biomolecular design.
Currently, the most widely used approach in biomolecular design is directed
evolution, which is a greedy hill-climbing algorithm that simulates biological
evolution. In this paper, we propose a new benchmark of applying reinforcement
learning to RNA sequence design, in which the objective function is defined to
be the free energy in the sequence's secondary structure. In addition to
experimenting with the vanilla implementations of each reinforcement learning
algorithm from standard libraries, we analyze variants of each algorithm in
which we modify the algorithm's reward function and tune the model's
hyperparameters. We show results of the ablation analysis that we do for these
algorithms, as well as graphs indicating the algorithm's performance across
batches and its ability to search the possible space of RNA sequences. We find
that our DQN algorithm performs by far the best in this setting, contrasting
with, in which PPO performs the best among all tested algorithms. Our results
should be of interest to those in the biomolecular design community and should
serve as a baseline for future experiments involving machine learning in
molecule design.</p>
  </details>
</details>
<details>
  <summary>12. <b>标题：Multi-Airport Delay Prediction with Transformers</b></summary>
  <p><b>编号</b>：[69]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04494</p>
  <p><b>作者</b>：Liya Wang,  Alex Tien,  Jason Chou</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：based delay prediction model achieves satisfactory performance measured, forecast selected delay metrics, decision makers gain insights, capture complex temporal dynamics, help air traffic managers</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Airport performance prediction with a reasonable look-ahead time is a
challenging task and has been attempted by various prior research. Traffic,
demand, weather, and traffic management actions are all critical inputs to any
prediction model. In this paper, a novel approach based on Temporal Fusion
Transformer (TFT) was proposed to predict departure and arrival delays
simultaneously for multiple airports at once. This approach can capture complex
temporal dynamics of the inputs known at the time of prediction and then
forecast selected delay metrics up to four hours into the future. When dealing
with weather inputs, a self-supervised learning (SSL) model was developed to
encode high-dimensional weather data into a much lower-dimensional
representation to make the training of TFT more efficiently and effectively.
The initial results show that the TFT-based delay prediction model achieves
satisfactory performance measured by smaller prediction errors on a testing
dataset. In addition, the interpretability analysis of the model outputs
identifies the important input factors for delay prediction. The proposed
approach is expected to help air traffic managers or decision makers gain
insights about traffic management actions on delay mitigation and once
operationalized, provide enough lead time to plan for predicted performance
degradation.</p>
  </details>
</details>
<details>
  <summary>13. <b>标题：Identifying the Leading Factors of Significant Weight Gains Using a New  Rule Discovery Method</b></summary>
  <p><b>编号</b>：[74]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04475</p>
  <p><b>作者</b>：Mina Samizadeh,  Jessica C Jones-Smith,  Bethany Sheridan,  Rahmatollah Beheshti</p>
  <p><b>备注</b>：The code for this project is available on: this https URL</p>
  <p><b>关键词</b>：major global public health concern, patterns across 22 strata determined, indicates significant weight gains, future dangerous weight gains, future weight gains</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Overweight and obesity remain a major global public health concern and
identifying the individualized patterns that increase the risk of future weight
gains has a crucial role in preventing obesity and numerous sub-sequent
diseases associated with obesity. In this work, we use a rule discovery method
to study this problem, by presenting an approach that offers genuine
interpretability and concurrently optimizes the accuracy(being correct often)
and support (applying to many samples) of the identified patterns.
Specifically, we extend an established subgroup-discovery method to generate
the desired rules of type X -> Y and show how top features can be extracted
from the X side, functioning as the best predictors of Y. In our obesity
problem, X refers to the extracted features from very large and multi-site EHR
data, and Y indicates significant weight gains. Using our method, we also
extensively compare the differences and inequities in patterns across 22 strata
determined by the individual's gender, age, race, insurance type, neighborhood
type, and income level. Through extensive series of experiments, we show new
and complementary findings regarding the predictors of future dangerous weight
gains.</p>
  </details>
</details>
<details>
  <summary>14. <b>标题：Weapon Engagement Zone Maximum Launch Range Estimation Using a Deep  Neural Network</b></summary>
  <p><b>编号</b>：[75]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04474</p>
  <p><b>作者</b>：Joao P. A. Dantas,  Andre N. Costa,  Diego Geraldo,  Marcos R. O. A. Maximo,  Takashi Yoneyama</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：provides another procedure concerning preceding research since, providing faster model training, given missile using 50, weapon engagement zone, proposed method uses</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This work investigates the use of a Deep Neural Network (DNN) to perform an
estimation of the Weapon Engagement Zone (WEZ) maximum launch range. The WEZ
allows the pilot to identify an airspace in which the available missile has a
more significant probability of successfully engaging a particular target,
i.e., a hypothetical area surrounding an aircraft in which an adversary is
vulnerable to a shot. We propose an approach to determine the WEZ of a given
missile using 50,000 simulated launches in variate conditions. These
simulations are used to train a DNN that can predict the WEZ when the aircraft
finds itself on different firing conditions, with a coefficient of
determination of 0.99. It provides another procedure concerning preceding
research since it employs a non-discretized model, i.e., it considers all
directions of the WEZ at once, which has not been done previously.
Additionally, the proposed method uses an experimental design that allows for
fewer simulation runs, providing faster model training.</p>
  </details>
</details>
<details>
  <summary>15. <b>标题：DeSkew-LSH based Code-to-Code Recommendation Engine</b></summary>
  <p><b>编号</b>：[76]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04473</p>
  <p><b>作者</b>：Fran Silavong,  Sean Moran,  Antonios Georgiadis,  Rohan Saphal,  Robert Otter</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：snippet length distribution using novel abstract syntax tree, evaluate senatus via automatic evaluation, new locality sensitive hashing, expert developer user study, code recommendation engines hold</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Machine learning on source code (MLOnCode) is a popular research field that
has been driven by the availability of large-scale code repositories and the
development of powerful probabilistic and deep learning models for mining
source code. Code-to-code recommendation is a task in MLOnCode that aims to
recommend relevant, diverse and concise code snippets that usefully extend the
code currently being written by a developer in their development environment
(IDE). Code-to-code recommendation engines hold the promise of increasing
developer productivity by reducing context switching from the IDE and
increasing code-reuse. Existing code-to-code recommendation engines do not
scale gracefully to large codebases, exhibiting a linear growth in query time
as the code repository increases in size. In addition, existing code-to-code
recommendation engines fail to account for the global statistics of code
repositories in the ranking function, such as the distribution of code snippet
lengths, leading to sub-optimal retrieval results. We address both of these
weaknesses with \emph{Senatus}, a new code-to-code recommendation engine. At
the core of Senatus is \emph{De-Skew} LSH a new locality sensitive hashing
(LSH) algorithm that indexes the data for fast (sub-linear time) retrieval
while also counteracting the skewness in the snippet length distribution using
novel abstract syntax tree-based feature scoring and selection algorithms. We
evaluate Senatus via automatic evaluation and with an expert developer user
study and find the recommendations to be of higher quality than competing
baselines, while achieving faster search. For example, on the CodeSearchNet
dataset we show that Senatus improves performance by 6.7\% F1 and query time
16x is faster compared to Facebook Aroma on the task of code-to-code
recommendation.</p>
  </details>
</details>
<details>
  <summary>16. <b>标题：Ten Conceptual Dimensions of Context</b></summary>
  <p><b>编号</b>：[77]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04472</p>
  <p><b>作者</b>：Hashai Papneja</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：context thus emerge -- location, synthesize various conceptualizations, ten conceptual dimensions, ten dimensions, systematic examination</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper attempts to synthesize various conceptualizations of the term
"context" as found in computing literature. Ten conceptual dimensions of
context thus emerge -- location; user, task, and system characteristics;
physical, social, organizational, and cultural environments; time-related
aspects, and historical information. Together, the ten dimensions of context
provide a comprehensive view of the notion of context, and allow for a more
systematic examination of the influence of context and contextual information
on human-system or human-AI interactions.</p>
  </details>
</details>
<details>
  <summary>17. <b>标题：Flight Demand Forecasting with Transformers</b></summary>
  <p><b>编号</b>：[78]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04471</p>
  <p><b>作者</b>：Liya Wang,  Amy Mykityshyn,  Craig Johnson,  Jillian Cheng</p>
  <p><b>备注</b>：arXiv admin note: substantial text overlap with arXiv:2011.04476</p>
  <p><b>关键词</b>：predict strategic flight departure demand, better prediction across diverse airports, system wide information management, displays predicted departure demand, based prediction method showed</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Transformers have become the de-facto standard in the natural language
processing (NLP) field. They have also gained momentum in computer vision and
other domains. Transformers can enable artificial intelligence (AI) models to
dynamically focus on certain parts of their input and thus reason more
effectively. Inspired by the success of transformers, we adopted this technique
to predict strategic flight departure demand in multiple horizons. This work
was conducted in support of a MITRE-developed mobile application, Pacer, which
displays predicted departure demand to general aviation (GA) flight operators
so they can have better situation awareness of the potential for departure
delays during busy periods. Field demonstrations involving Pacer's previously
designed rule-based prediction method showed that the prediction accuracy of
departure demand still has room for improvement. This research strives to
improve prediction accuracy from two key aspects: better data sources and
robust forecasting algorithms. We leveraged two data sources, Aviation System
Performance Metrics (ASPM) and System Wide Information Management (SWIM), as
our input. We then trained forecasting models with temporal fusion transformer
(TFT) for five different airports. Case studies show that TFTs can perform
better than traditional forecasting methods by large margins, and they can
result in better prediction across diverse airports and with better
interpretability.</p>
  </details>
</details>
<details>
  <summary>18. <b>标题：Improving Peer Assessment with Graph Convolutional Networks</b></summary>
  <p><b>编号</b>：[80]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04466</p>
  <p><b>作者</b>：Alireza A. Namanloo,  Julie Thorpe,  Amirali Salehi-Abari</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：g ., peer evaluating group work, outperforms existing peer assessment methods, first model peer assessment, peer assessment network model, accurately predict expert evaluations</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Peer assessment systems are emerging in many social and multi-agent settings,
such as peer grading in large (online) classes, peer review in conferences,
peer art evaluation, etc. However, peer assessments might not be as accurate as
expert evaluations, thus rendering these systems unreliable. The reliability of
peer assessment systems is influenced by various factors such as assessment
ability of peers, their strategic assessment behaviors, and the peer assessment
setup (e.g., peer evaluating group work or individual work of others). In this
work, we first model peer assessment as multi-relational weighted networks that
can express a variety of peer assessment setups, plus capture conflicts of
interest and strategic behaviors. Leveraging our peer assessment network model,
we introduce a graph convolutional network which can learn assessment patterns
and user behaviors to more accurately predict expert evaluations. Our extensive
experiments on real and synthetic datasets demonstrate the efficacy of our
proposed approach, which outperforms existing peer assessment methods.</p>
  </details>
</details>
<details>
  <summary>19. <b>标题：IoT to monitor people flow in areas of public interest</b></summary>
  <p><b>编号</b>：[81]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04465</p>
  <p><b>作者</b>：Damiano Perri,  Marco Simonetti,  Alex Bordini,  Simone Cimarelli,  Osvaldo Gervasi</p>
  <p><b>备注</b>：International Conference on Computational Science and Its Applications, ICCSA 2021</p>
  <p><b>关键词</b>：things gives almost unlimited tools, people inside public places, monitoring without personal identification, things tools might, without collecting personal</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The unexpected historical period we are living has abruptly pushed us to
loosen any sort of interaction between individuals, gradually forcing us to
deal with new ways to allow compliance with safety distances; indeed the
present situation has demonstrated more than ever how critical it is to be able
to properly organize our travel plans, put people in safe conditions, and avoid
harmful circumstances. The aim of this research is to set up a system to
monitor the flow of people inside public places and facilities of interest
(museums, theatres, cinemas, etc.) without collecting personal or sensitive
data. Weak monitoring of people flows (i.e. monitoring without personal
identification of the monitored subjects) through Internet of Things tools
might be a viable solution to minimize lineups and overcrowding. Our study,
which began as an experiment in the Umbria region of Italy, aims to be one of
several answers to automated planning of people's flows in order to make our
land more liveable. We intend to show that the Internet of Things gives almost
unlimited tools and possibilities, from developing a basic information process
to implementing a true portal which enables business people to connect with
interested consumers.</p>
  </details>
</details>
<details>
  <summary>20. <b>标题：Creating A Coefficient of Change in the Built Environment After a  Natural Disaster</b></summary>
  <p><b>编号</b>：[82]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04462</p>
  <p><b>作者</b>：Karla Saldana Ochoa</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：000 aerial image database, net algorithm used reached, general cnn architectures, deep learning workflow, 50 epicenters worldwide</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This study proposes a novel method to assess damages in the built environment
using a deep learning workflow to quantify it. Thanks to an automated crawler,
aerial images from before and after a natural disaster of 50 epicenters
worldwide were obtained from Google Earth, generating a 10,000 aerial image
database with a spatial resolution of 2 m per pixel. The study utilizes the
algorithm Seg-Net to perform semantic segmentation of the built environment
from the satellite images in both instances (prior and post-natural disasters).
For image segmentation, Seg-Net is one of the most popular and general CNN
architectures. The Seg-Net algorithm used reached an accuracy of 92% in the
segmentation. After the segmentation, we compared the disparity between both
cases represented as a percentage of change. Such coefficient of change
represents the damage numerically an urban environment had to quantify the
overall damage in the built environment. Such an index can give the government
an estimate of the number of affected households and perhaps the extent of
housing damage.</p>
  </details>
</details>
<details>
  <summary>21. <b>标题：Systematic Review for AI-based Language Learning Tools</b></summary>
  <p><b>编号</b>：[86]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04455</p>
  <p><b>作者</b>：Jin Ha Woo,  Heeyoul Choi</p>
  <p><b>备注</b>：10 pages, 6 figures</p>
  <p><b>关键词</b>：although increasingly adaptive language learning tools, computer assisted language learning field, second language acquisition field, concerns regarding insufficient information, tools utilized machine learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The Second Language Acquisition field has been significantly impacted by a
greater emphasis on individualized learning and rapid developments in
artificial intelligence (AI). Although increasingly adaptive language learning
tools are being developed with the application of AI to the Computer Assisted
Language Learning field, there have been concerns regarding insufficient
information and teacher preparation. To effectively utilize these tools,
teachers need an in-depth overview on recently developed AI-based language
learning tools. Therefore, this review synthesized information on AI tools that
were developed between 2017 and 2020. A majority of these tools utilized
machine learning and natural language processing, and were used to identify
errors, provide feedback, and assess language abilities. After using these
tools, learners demonstrated gains in their language abilities and knowledge.
This review concludes by presenting pedagogical implications and emerging
themes in the future research of AI-based language learning tools.</p>
  </details>
</details>
<details>
  <summary>22. <b>标题：The Problem of Zombie Datasets:A Framework For Deprecating Datasets</b></summary>
  <p><b>编号</b>：[103]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04424</p>
  <p><b>作者</b>：Frances Corry,  Hamsini Sridharan,  Alexandra Sasha Luccioni,  Mike Ananny,  Jason Schultz,  Kate Crawford</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：offer two sample dataset deprecation sheets, 80 million tiny images, including concerns around bias, machine learning dataset, accountable dataset deprecation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>What happens when a machine learning dataset is deprecated for legal,
ethical, or technical reasons, but continues to be widely used? In this paper,
we examine the public afterlives of several prominent deprecated or redacted
datasets, including ImageNet, 80 Million Tiny Images, MS-Celeb-1M, Duke MTMC,
Brainwash, and HRT Transgender, in order to inform a framework for more
consistent, ethical, and accountable dataset deprecation. Building on prior
research, we find that there is a lack of consistency, transparency, and
centralized sourcing of information on the deprecation of datasets, and as
such, these datasets and their derivatives continue to be cited in papers and
circulate online. These datasets that never die -- which we term "zombie
datasets" -- continue to inform the design of production-level systems, causing
technical, legal, and ethical challenges; in so doing, they risk perpetuating
the harms that prompted their supposed withdrawal, including concerns around
bias, discrimination, and privacy. Based on this analysis, we propose a Dataset
Deprecation Framework that includes considerations of risk, mitigation of
impact, appeal mechanisms, timeline, post-deprecation protocol, and publication
checks that can be adapted and implemented by the machine learning community.
Drawing on work on datasheets and checklists, we further offer two sample
dataset deprecation sheets and propose a centralized repository that tracks
which datasets have been deprecated and could be incorporated into the
publication protocols of venues like NeurIPS.</p>
  </details>
</details>
<details>
  <summary>23. <b>标题：A Survey of Human Activity Recognition in Smart Homes Based on IoT  Sensors Algorithms: Taxonomies, Challenges, and Opportunities with Deep  Learning</b></summary>
  <p><b>编号</b>：[105]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04418</p>
  <p><b>作者</b>：Damien Bouchabou (1),  Sao Mai Nguyen (1),  Christophe Lohr (1),  Benoit Leduc,  Ioannis Kanellos (1) ((1) Lab-STICC_RAMBO, IMT Atlantique - INFO)</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：offer home assistance services, since activity recognition, recognizing human activity, raise specific problems, human activity recognition</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent advances in Internet of Things (IoT) technologies and the reduction in
the cost of sensors have encouraged the development of smart environments, such
as smart homes. Smart homes can offer home assistance services to improve the
quality of life, autonomy and health of their residents, especially for the
elderly and dependent. To provide such services, a smart home must be able to
understand the daily activities of its residents. Techniques for recognizing
human activity in smart homes are advancing daily. But new challenges are
emerging every day. In this paper, we present recent algorithms, works,
challenges and taxonomy of the field of human activity recognition in a smart
home through ambient sensors. Moreover, since activity recognition in smart
homes is a young field, we raise specific problems, missing and needed
contributions. But also propose directions, research opportunities and
solutions to accelerate advances in this field.</p>
  </details>
</details>
<details>
  <summary>24. <b>标题：Get a Model! Model Hijacking Attack Against Machine Learning Models</b></summary>
  <p><b>编号</b>：[118]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04394</p>
  <p><b>作者</b>：Ahmed Salem,  Michael Backes,  Yang Zhang</p>
  <p><b>备注</b>：To Appear in NDSS 2022</p>
  <p><b>关键词</b>：computer vision based machine learning models, propose two different model hijacking attacks, various critical applications ranging, existing data poisoning attacks, high attack success rate</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Machine learning (ML) has established itself as a cornerstone for various
critical applications ranging from autonomous driving to authentication
systems. However, with this increasing adoption rate of machine learning
models, multiple attacks have emerged. One class of such attacks is training
time attack, whereby an adversary executes their attack before or during the
machine learning model training. In this work, we propose a new training time
attack against computer vision based machine learning models, namely model
hijacking attack. The adversary aims to hijack a target model to execute a
different task than its original one without the model owner noticing. Model
hijacking can cause accountability and security risks since a hijacked model
owner can be framed for having their model offering illegal or unethical
services. Model hijacking attacks are launched in the same way as existing data
poisoning attacks. However, one requirement of the model hijacking attack is to
be stealthy, i.e., the data samples used to hijack the target model should look
similar to the model's original training dataset. To this end, we propose two
different model hijacking attacks, namely Chameleon and Adverse Chameleon,
based on a novel encoder-decoder style ML model, namely the Camouflager. Our
evaluation shows that both of our model hijacking attacks achieve a high attack
success rate, with a negligible drop in model utility.</p>
  </details>
</details>
<details>
  <summary>25. <b>标题：Auto-Encoding Knowledge Graph for Unsupervised Medical Report Generation</b></summary>
  <p><b>编号</b>：[140]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04318</p>
  <p><b>作者</b>：Fenglin Liu,  Chenyu You,  Xian Wu,  Shen Ge,  Sheng Wang,  Xu Sun</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：unsupervised kgae generates desirable medical reports without using, unsupervised model knowledge graph auto, driven encoder projects medical images, receiving growing research interests, existing approaches mainly adopt</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Medical report generation, which aims to automatically generate a long and
coherent report of a given medical image, has been receiving growing research
interests. Existing approaches mainly adopt a supervised manner and heavily
rely on coupled image-report pairs. However, in the medical domain, building a
large-scale image-report paired dataset is both time-consuming and expensive.
To relax the dependency on paired data, we propose an unsupervised model
Knowledge Graph Auto-Encoder (KGAE) which accepts independent sets of images
and reports in training. KGAE consists of a pre-constructed knowledge graph, a
knowledge-driven encoder and a knowledge-driven decoder. The knowledge graph
works as the shared latent space to bridge the visual and textual domains; The
knowledge-driven encoder projects medical images and reports to the
corresponding coordinates in this latent space and the knowledge-driven decoder
generates a medical report given a coordinate in this space. Since the
knowledge-driven encoder and decoder can be trained with independent sets of
images and reports, KGAE is unsupervised. The experiments show that the
unsupervised KGAE generates desirable medical reports without using any
image-report training pairs. Moreover, KGAE can also work in both
semi-supervised and supervised settings, and accept paired images and reports
in training. By further fine-tuning with image-report pairs, KGAE consistently
outperforms the current state-of-the-art models on two datasets.</p>
  </details>
</details>
<details>
  <summary>26. <b>标题：Graph Robustness Benchmark: Benchmarking the Adversarial Robustness of  Graph Machine Learning</b></summary>
  <p><b>编号</b>：[144]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04314</p>
  <p><b>作者</b>：Qinkai Zheng,  Xu Zou,  Yuxiao Dong,  Yukuo Cen,  Da Yin,  Jiarong Xu,  Yang Yang,  Jie Tang</p>
  <p><b>备注</b>：21 pages, 12 figures, NeurIPS 2021 Datasets and Benchmarks Track</p>
  <p><b>关键词</b>：grb also hosts public leaderboards across different scenarios, graph machine learning, escalating arms race, conduct extensive experiments, benchmark baseline techniques</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Adversarial attacks on graphs have posed a major threat to the robustness of
graph machine learning (GML) models. Naturally, there is an ever-escalating
arms race between attackers and defenders. However, the strategies behind both
sides are often not fairly compared under the same and realistic conditions. To
bridge this gap, we present the Graph Robustness Benchmark (GRB) with the goal
of providing a scalable, unified, modular, and reproducible evaluation for the
adversarial robustness of GML models. GRB standardizes the process of attacks
and defenses by 1) developing scalable and diverse datasets, 2) modularizing
the attack and defense implementations, and 3) unifying the evaluation protocol
in refined scenarios. By leveraging the GRB pipeline, the end-users can focus
on the development of robust GML models with automated data processing and
experimental evaluations. To support open and reproducible research on graph
adversarial learning, GRB also hosts public leaderboards across different
scenarios. As a starting point, we conduct extensive experiments to benchmark
baseline techniques. GRB is open-source and welcomes contributions from the
community. Datasets, codes, leaderboards are available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>27. <b>标题：A Relational Model for One-Shot Classification</b></summary>
  <p><b>编号</b>：[145]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04313</p>
  <p><b>作者</b>：Arturs Polis,  Alexander Ilin</p>
  <p><b>备注</b>：Published at ESANN 2021</p>
  <p><b>关键词</b>：shot classification model performs relational matching, shot image classification omniglot challenge, model exceeds human level accuracy, relational inductive bias, deep learning model</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We show that a deep learning model with built-in relational inductive bias
can bring benefits to sample-efficient learning, without relying on extensive
data augmentation. The proposed one-shot classification model performs
relational matching of a pair of inputs in the form of local and pairwise
attention. Our approach solves perfectly the one-shot image classification
Omniglot challenge. Our model exceeds human level accuracy, as well as the
previous state of the art, with no data augmentation.</p>
  </details>
</details>
<details>
  <summary>28. <b>标题：Defense Against Explanation Manipulation</b></summary>
  <p><b>编号</b>：[150]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04303</p>
  <p><b>作者</b>：Ruixiang Tang,  Ninghao Liu,  Fan Yang,  Na Zou,  Xia Hu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：also brings additional benefits including smoothing explanations, explainable machine learning attracts increasing attention, new training scheme called adversarial training, directly specifying explanation values, atex improves model robustness</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Explainable machine learning attracts increasing attention as it improves
transparency of models, which is helpful for machine learning to be trusted in
real applications. However, explanation methods have recently been demonstrated
to be vulnerable to manipulation, where we can easily change a model's
explanation while keeping its prediction constant. To tackle this problem, some
efforts have been paid to use more stable explanation methods or to change
model configurations. In this work, we tackle the problem from the training
perspective, and propose a new training scheme called Adversarial Training on
EXplanations (ATEX) to improve the internal explanation stability of a model
regardless of the specific explanation method being applied. Instead of
directly specifying explanation values over data instances, ATEX only puts
requirement on model predictions which avoids involving second-order
derivatives in optimization. As a further discussion, we also find that
explanation stability is closely related to another property of the model,
i.e., the risk of being exposed to adversarial attack. Through experiments,
besides showing that ATEX improves model robustness against manipulation
targeting explanation, it also brings additional benefits including smoothing
explanations and improving the efficacy of adversarial training if applied to
the model.</p>
  </details>
</details>
<details>
  <summary>29. <b>标题：Deep Unsupervised Active Learning on Learnable Graphs</b></summary>
  <p><b>编号</b>：[156]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04286</p>
  <p><b>作者</b>：Handong Ma,  Changsheng Li,  Xinchu Shi,  Ye Yuan,  Guoren Wang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：novel deep unsupervised active learning model via learnable graphs, also incorporate shortcut connections among different layers, k $- nearest neighbor graph, learning optimal graph structures, leverage graph structure learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recently deep learning has been successfully applied to unsupervised active
learning. However, current method attempts to learn a nonlinear transformation
via an auto-encoder while ignoring the sample relation, leaving huge room to
design more effective representation learning mechanisms for unsupervised
active learning. In this paper, we propose a novel deep unsupervised Active
Learning model via Learnable Graphs, named ALLG. ALLG benefits from learning
optimal graph structures to acquire better sample representation and select
representative samples. To make the learnt graph structure more stable and
effective, we take into account $k$-nearest neighbor graph as a priori, and
learn a relation propagation graph structure. We also incorporate shortcut
connections among different layers, which can alleviate the well-known
over-smoothing problem to some extent. To the best of our knowledge, this is
the first attempt to leverage graph structure learning for unsupervised active
learning. Extensive experiments performed on six datasets demonstrate the
efficacy of our method.</p>
  </details>
</details>
<details>
  <summary>30. <b>标题：Batch Reinforcement Learning from Crowds</b></summary>
  <p><b>编号</b>：[158]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04279</p>
  <p><b>作者</b>：Guoxi Zhang,  Hisashi Kashima</p>
  <p><b>备注</b>：16 pages</p>
  <p><b>关键词</b>：batch reinforcement learning setting, expert humans using crowdsourcing, tasks without reward functions, batch reinforcement learning, atari datasets demonstrates</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A shortcoming of batch reinforcement learning is its requirement for rewards
in data, thus not applicable to tasks without reward functions. Existing
settings for lack of reward, such as behavioral cloning, rely on optimal
demonstrations collected from humans. Unfortunately, extensive expertise is
required for ensuring optimality, which hinder the acquisition of large-scale
data for complex tasks. This paper addresses the lack of reward in a batch
reinforcement learning setting by learning a reward function from preferences.
Generating preferences only requires a basic understanding of a task. Being a
mental process, generating preferences is faster than performing
demonstrations. So preferences can be collected at scale from non-expert humans
using crowdsourcing. This paper tackles a critical challenge that emerged when
collecting data from non-expert humans: the noise in preferences. A novel
probabilistic model is proposed for modelling the reliability of labels, which
utilizes labels collaboratively. Moreover, the proposed model smooths the
estimation with a learned reward function. Evaluation on Atari datasets
demonstrates the effectiveness of the proposed model, followed by an ablation
study to analyze the relative importance of the proposed ideas.</p>
  </details>
</details>
<details>
  <summary>31. <b>标题：Mimic: An adaptive algorithm for multivariate time series classification</b></summary>
  <p><b>编号</b>：[160]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04273</p>
  <p><b>作者</b>：Yuhui Wang,  Diane J. Cook</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：26 time series datasets support mimic, existing multivariate time series classifier, critical applications may rely, time series classifiers visually, time series data</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Time series data are valuable but are often inscrutable. Gaining trust in
time series classifiers for finance, healthcare, and other critical
applications may rely on creating interpretable models. Researchers have
previously been forced to decide between interpretable methods that lack
predictive power and deep learning methods that lack transparency. In this
paper, we propose a novel Mimic algorithm that retains the predictive accuracy
of the strongest classifiers while introducing interpretability. Mimic mirrors
the learning method of an existing multivariate time series classifier while
simultaneously producing a visual representation that enhances user
understanding of the learned model. Experiments on 26 time series datasets
support Mimic's ability to imitate a variety of time series classifiers
visually and accurately.</p>
  </details>
</details>
<details>
  <summary>32. <b>标题：Group-Aware Threshold Adaptation for Fair Classification</b></summary>
  <p><b>编号</b>：[162]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04271</p>
  <p><b>作者</b>：Taeuk Jang,  Pengyi Shi,  Xiaoqian Wang</p>
  <p><b>备注</b>：19 pages 1 figures</p>
  <p><b>关键词</b>：provide rigorous theoretical analysis, learn adaptive classification thresholds, process existing fairness methods, low computational cost, getting increasing attention</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The fairness in machine learning is getting increasing attention, as its
applications in different fields continue to expand and diversify. To mitigate
the discriminated model behaviors between different demographic groups, we
introduce a novel post-processing method to optimize over multiple fairness
constraints through group-aware threshold adaptation. We propose to learn
adaptive classification thresholds for each demographic group by optimizing the
confusion matrix estimated from the probability distribution of a
classification model output. As we only need an estimated probability
distribution of model output instead of the classification model structure, our
post-processing model can be applied to a wide range of classification models
and improve fairness in a model-agnostic manner and ensure privacy. This even
allows us to post-process existing fairness methods to further improve the
trade-off between accuracy and fairness. Moreover, our model has low
computational cost. We provide rigorous theoretical analysis on the convergence
of our optimization algorithm and the trade-off between accuracy and fairness
of our method. Our method theoretically enables a better upper bound in near
optimality than existing method under same condition. Experimental results
demonstrate that our method outperforms state-of-the-art methods and obtains
the result that is closest to the theoretical accuracy-fairness trade-off
boundary.</p>
  </details>
</details>
<details>
  <summary>33. <b>标题：JaMIE: A Pipeline Japanese Medical Information Extraction System</b></summary>
  <p><b>编号</b>：[167]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04261</p>
  <p><b>作者</b>：Fei Cheng,  Shuntaro Yada,  Ribeka Tanaka,  Eiji Aramaki,  Sadao Kurohashi</p>
  <p><b>备注</b>：8 pages</p>
  <p><b>关键词</b>：empirical results show accurate analyzing performance, access natural language processing toolkit, separately annotating two different types, latest contextual embedding models, novel relation annotation schema</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present an open-access natural language processing toolkit for Japanese
medical information extraction. We first propose a novel relation annotation
schema for investigating the medical and temporal relations between medical
entities in Japanese medical reports. We experiment with the practical
annotation scenarios by separately annotating two different types of reports.
We design a pipeline system with three components for recognizing medical
entities, classifying entity modalities, and extracting relations. The
empirical results show accurate analyzing performance and suggest the
satisfactory annotation quality, the effective annotation strategy for
targeting report types, and the superiority of the latest contextual embedding
models.</p>
  </details>
</details>
<details>
  <summary>34. <b>标题：Personalized Benchmarking with the Ludwig Benchmarking Toolkit</b></summary>
  <p><b>编号</b>：[168]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04260</p>
  <p><b>作者</b>：Avanika Narayan,  Piero Molino,  Karan Goel,  Willie Neiswanger,  Christopher Ré (Department of Computer Science, Stanford University)</p>
  <p><b>备注</b>：14 pages, 14 figures, 35th Conference on Neural Information Processing Systems (NeurIPS 2021) Track on Datasets and Benchmarks</p>
  <p><b>关键词</b>：computational budget ), making fair comparisons difficult, users cannot use standard benchmark results, text classification across 7 models, machine learning models across domains, traditional benchmarks evaluate models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The rapid proliferation of machine learning models across domains and
deployment settings has given rise to various communities (e.g. industry
practitioners) which seek to benchmark models across tasks and objectives of
personal value. Unfortunately, these users cannot use standard benchmark
results to perform such value-driven comparisons as traditional benchmarks
evaluate models on a single objective (e.g. average accuracy) and fail to
facilitate a standardized training framework that controls for confounding
variables (e.g. computational budget), making fair comparisons difficult. To
address these challenges, we introduce the open-source Ludwig Benchmarking
Toolkit (LBT), a personalized benchmarking toolkit for running end-to-end
benchmark studies (from hyperparameter optimization to evaluation) across an
easily extensible set of tasks, deep learning models, datasets and evaluation
metrics. LBT provides a configurable interface for controlling training and
customizing evaluation, a standardized training framework for eliminating
confounding variables, and support for multi-objective evaluation. We
demonstrate how LBT can be used to create personalized benchmark studies with a
large-scale comparative analysis for text classification across 7 models and 9
datasets. We explore the trade-offs between inference latency and performance,
relationships between dataset attributes and performance, and the effects of
pretraining on convergence and robustness, showing how LBT can be used to
satisfy various benchmarking objectives.</p>
  </details>
</details>
<details>
  <summary>35. <b>标题：Trust-aware Control for Intelligent Transportation Systems</b></summary>
  <p><b>编号</b>：[173]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04248</p>
  <p><b>作者</b>：Mingxi Cheng,  Junyao Zhang,  Shahin Nazarian,  Jyotirmoy Deshmukh,  Paul Bogdan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：many intelligent transportation systems, aware version called aim, provide greater safety, lower accident rates, increased autonomy makes</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Many intelligent transportation systems are multi-agent systems, i.e., both
the traffic participants and the subsystems within the transportation
infrastructure can be modeled as interacting agents. The use of AI-based
methods to achieve coordination among the different agents systems can provide
greater safety over transportation systems containing only human-operated
vehicles, and also improve the system efficiency in terms of traffic
throughput, sensing range, and enabling collaborative tasks. However, increased
autonomy makes the transportation infrastructure vulnerable to compromised
vehicular agents or infrastructure. This paper proposes a new framework by
embedding the trust authority into transportation infrastructure to
systematically quantify the trustworthiness of agents using an epistemic logic
known as subjective logic. In this paper, we make the following novel
contributions: (i) We propose a framework for using the quantified
trustworthiness of agents to enable trust-aware coordination and control. (ii)
We demonstrate how to synthesize trust-aware controllers using an approach
based on reinforcement learning. (iii) We comprehensively analyze an autonomous
intersection management (AIM) case study and develop a trust-aware version
called AIM-Trust that leads to lower accident rates in scenarios consisting of
a mixture of trusted and untrusted agents.</p>
  </details>
</details>
<details>
  <summary>36. <b>标题：Automated Detection of GDPR Disclosure Requirements in Privacy Policies  using Deep Active Learning</b></summary>
  <p><b>编号</b>：[180]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04224</p>
  <p><b>作者</b>：Tamjid Al Rahat,  Tu Le,  Yuan Tian</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：websites still fail, least one requirement, essential communication channel, convolutional neural network, 080 websites labeled</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Since GDPR came into force in May 2018, companies have worked on their data
practices to comply with this privacy law. In particular, since the privacy
policy is the essential communication channel for users to understand and
control their privacy, many companies updated their privacy policies after GDPR
was enforced. However, most privacy policies are verbose, full of jargon, and
vaguely describe companies' data practices and users' rights. Therefore, it is
unclear if they comply with GDPR. In this paper, we create a privacy policy
dataset of 1,080 websites labeled with the 18 GDPR requirements and develop a
Convolutional Neural Network (CNN) based model which can classify the privacy
policies with an accuracy of 89.2%. We apply our model to perform a measurement
on the compliance in the privacy policies. Our results show that even after
GDPR went into effect, 97% of websites still fail to comply with at least one
requirement of GDPR.</p>
  </details>
</details>
<details>
  <summary>37. <b>标题：VizAI : Selecting Accurate Visualizations of Numerical Data</b></summary>
  <p><b>编号</b>：[190]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04190</p>
  <p><b>作者</b>：Ritvik Vij,  Rohit Raj,  Madhur Singhal,  Manish Tanwar,  Srikanta Bedathur</p>
  <p><b>备注</b>：Proc. of the ACM India Joint International Conference on Data Sciences and Management of Data (CODS-COMAD) 2022 (9th ACM IKDD CODS and 27th COMAD) - To Appear</p>
  <p><b>关键词</b>：manual process involving many iterations, first generates various statistical properties, common use across various stages, reveal underlying statistical properties, require large training samples</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A good data visualization is not only a distortion-free graphical
representation of data but also a way to reveal underlying statistical
properties of the data. Despite its common use across various stages of data
analysis, selecting a good visualization often is a manual process involving
many iterations. Recently there has been interest in reducing this effort by
developing models that can recommend visualizations, but they are of limited
use since they require large training samples (data and visualization pairs)
and focus primarily on the design aspects rather than on assessing the
effectiveness of the selected visualization.
In this paper, we present VizAI, a generative-discriminative framework that
first generates various statistical properties of the data from a number of
alternative visualizations of the data. It is linked to a discriminative model
that selects the visualization that best matches the true statistics of the
data being visualized. VizAI can easily be trained with minimal supervision and
adapts to settings with varying degrees of supervision easily. Using
crowd-sourced judgements and a large repository of publicly available
visualizations, we demonstrate that VizAI outperforms the state of the art
methods that learn to recommend visualizations.</p>
  </details>
</details>
<details>
  <summary>38. <b>标题：A Word on Machine Ethics: A Response to Jiang et al. (2021)</b></summary>
  <p><b>编号</b>：[199]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04158</p>
  <p><b>作者</b>：Zeerak Talat,  Hagen Blix,  Josef Valvoda,  Maya Indira Ganesh,  Ryan Cotterell,  Adina Williams</p>
  <p><b>备注</b>：11 pages, 2 figures, submitting soon to ACL Rolling Review</p>
  <p><b>关键词</b>：machine ethics could usefully proceed, longest standing intellectual endeavors, recently proposed delphi model, single case study, examine broader issues</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Ethics is one of the longest standing intellectual endeavors of humanity. In
recent years, the fields of AI and NLP have attempted to wrangle with how
learning systems that interact with humans should be constrained to behave
ethically. One proposal in this vein is the construction of morality models
that can take in arbitrary text and output a moral judgment about the situation
described. In this work, we focus on a single case study of the recently
proposed Delphi model and offer a critique of the project's proposed method of
automating morality judgments. Through an audit of Delphi, we examine broader
issues that would be applicable to any similar attempt. We conclude with a
discussion of how machine ethics could usefully proceed, by focusing on current
and near-future uses of technology, in a way that centers around transparency,
democratic values, and allows for straightforward accountability.</p>
  </details>
</details>
<details>
  <summary>39. <b>标题：Learning Finite Linear Temporal Logic Specifications with a Specialized  Neural Operator</b></summary>
  <p><b>编号</b>：[204]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04147</p>
  <p><b>作者</b>：Homer Walke,  Daniel Ritter,  Carl Trimbach,  Michael Littman</p>
  <p><b>备注</b>：10 pages, 5 figures</p>
  <p><b>关键词</b>：finite linear temporal logic ($\ mathsf, formulas show neural $\ mathsf, novel neural network operator, maintains high accuracy even, randomly generated $\ mathsf</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Finite linear temporal logic ($\mathsf{LTL}_f$) is a powerful formal
representation for modeling temporal sequences. We address the problem of
learning a compact $\mathsf{LTL}_f$ formula from labeled traces of system
behavior. We propose a novel neural network operator and evaluate the resulting
architecture, Neural$\mathsf{LTL}_f$. Our approach includes a specialized
recurrent filter, designed to subsume $\mathsf{LTL}_f$ temporal operators, to
learn a highly accurate classifier for traces. Then, it discretizes the
activations and extracts the truth table represented by the learned weights.
This truth table is converted to symbolic form and returned as the learned
formula. Experiments on randomly generated $\mathsf{LTL}_f$ formulas show
Neural$\mathsf{LTL}_f$ scales to larger formula sizes than existing approaches
and maintains high accuracy even in the presence of noise.</p>
  </details>
</details>
<details>
  <summary>40. <b>标题：Look at the Variance! Efficient Black-box Explanations with Sobol-based  Sensitivity Analysis</b></summary>
  <p><b>编号</b>：[206]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04138</p>
  <p><b>作者</b>：Thomas Fel,  Remi Cadene,  Mathieu Chalvidal,  Matthieu Cord,  David Vigouroux,  Thomas Serre</p>
  <p><b>备注</b>：NeurIPS2021</p>
  <p><b>关键词</b>：box methods -- even surpassing, using perturbation masks coupled, proposed method leads, novel attribution method, computing time compared</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We describe a novel attribution method which is grounded in Sensitivity
Analysis and uses Sobol indices. Beyond modeling the individual contributions
of image regions, Sobol indices provide an efficient way to capture
higher-order interactions between image regions and their contributions to a
neural network's prediction through the lens of variance. We describe an
approach that makes the computation of these indices efficient for
high-dimensional problems by using perturbation masks coupled with efficient
estimators to handle the high dimensionality of images. Importantly, we show
that the proposed method leads to favorable scores on standard benchmarks for
vision (and language models) while drastically reducing the computing time
compared to other black-box methods -- even surpassing the accuracy of
state-of-the-art white-box methods which require access to internal
representations. Our code is freely available:
this https URL</p>
  </details>
</details>
<details>
  <summary>41. <b>标题：NeurInt : Learning to Interpolate through Neural ODEs</b></summary>
  <p><b>编号</b>：[212]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04123</p>
  <p><b>作者</b>：Avinandan Bose,  Aniket Das,  Yatin Dandi,  Piyush Rai</p>
  <p><b>备注</b>：Accepted (Spotlight paper) at the NeurIPS 2021 Workshop on the Symbiosis of Deep Learning and Differential Equations (DLDE)</p>
  <p><b>关键词</b>：applications require learning image generation models whose latent space effectively captures, two given images using latent second, order neural ordinary differential equations, latent space ),, interpolation trajectories lacking smoothness</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A wide range of applications require learning image generation models whose
latent space effectively captures the high-level factors of variation present
in the data distribution. The extent to which a model represents such
variations through its latent space can be judged by its ability to interpolate
between images smoothly. However, most generative models mapping a fixed prior
to the generated images lead to interpolation trajectories lacking smoothness
and containing images of reduced quality. In this work, we propose a novel
generative model that learns a flexible non-parametric prior over interpolation
trajectories, conditioned on a pair of source and target images. Instead of
relying on deterministic interpolation methods (such as linear or spherical
interpolation in latent space), we devise a framework that learns a
distribution of trajectories between two given images using Latent Second-Order
Neural Ordinary Differential Equations. Through a hybrid combination of
reconstruction and adversarial losses, the generator is trained to map the
sampled points from these trajectories to sequences of realistic images that
smoothly transition from the source to the target image. Through comprehensive
qualitative and quantitative experiments, we demonstrate our approach's
effectiveness in generating images of improved quality as well as its ability
to learn a diverse distribution over smooth interpolation trajectories for any
pair of real source and target images.</p>
  </details>
</details>
<details>
  <summary>42. <b>标题：Automatic Goal Generation using Dynamical Distance Learning</b></summary>
  <p><b>编号</b>：[213]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04120</p>
  <p><b>作者</b>：Bharat Prakash,  Nicholas Waytowich,  Tinoosh Mohsenin,  Tim Oates</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：solve complex sequential decision making tasks, uses random goal sampling, automatic goal generation using, facilitate efficient learning throughout, solve complex tasks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Reinforcement Learning (RL) agents can learn to solve complex sequential
decision making tasks by interacting with the environment. However, sample
efficiency remains a major challenge. In the field of multi-goal RL, where
agents are required to reach multiple goals to solve complex tasks, improving
sample efficiency can be especially challenging. On the other hand, humans or
other biological agents learn such tasks in a much more strategic way,
following a curriculum where tasks are sampled with increasing difficulty level
in order to make gradual and efficient learning progress. In this work, we
propose a method for automatic goal generation using a dynamical distance
function (DDF) in a self-supervised fashion. DDF is a function which predicts
the dynamical distance between any two states within a markov decision process
(MDP). With this, we generate a curriculum of goals at the appropriate
difficulty level to facilitate efficient learning throughout the training
process. We evaluate this approach on several goal-conditioned robotic
manipulation and navigation tasks, and show improvements in sample efficiency
over a baseline method which only uses random goal sampling.</p>
  </details>
</details>
<details>
  <summary>43. <b>标题：MetaMIML: Meta Multi-Instance Multi-Label Learning</b></summary>
  <p><b>编号</b>：[217]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04112</p>
  <p><b>作者</b>：Yuanlin Yang,  Guoxian Yu,  Jun Wang,  Lei Liu,  Carlotta Domeniconi,  Maozu Guo</p>
  <p><b>备注</b>：10 pages, 2 figures</p>
  <p><b>关键词</b>：generally need abundant labeled data, current miml solutions still focus, effectively mine interdependent miml objects, meta learning based approach, data level improving</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Multi-Instance Multi-Label learning (MIML) models complex objects (bags),
each of which is associated with a set of interrelated labels and composed with
a set of instances. Current MIML solutions still focus on a single-type of
objects and assumes an IID distribution of training data. But these objects are
linked with objects of other types, %(i.e., pictures in Facebook link with
various users), which also encode the semantics of target objects. In addition,
they generally need abundant labeled data for training. To effectively mine
interdependent MIML objects of different types, we propose a network embedding
and meta learning based approach (MetaMIML). MetaMIML introduces the context
learner with network embedding to capture semantic information of objects of
different types, and the task learner to extract the meta knowledge for fast
adapting to new tasks. In this way, MetaMIML can naturally deal with MIML
objects at data level improving, but also exploit the power of meta-learning at
the model enhancing. Experiments on benchmark datasets demonstrate that
MetaMIML achieves a significantly better performance than state-of-the-art
algorithms.</p>
  </details>
</details>
<details>
  <summary>44. <b>标题：Iterative Causal Discovery in the Possible Presence of Latent  Confounders and Selection Bias</b></summary>
  <p><b>编号</b>：[223]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04095</p>
  <p><b>作者</b>：Raanan Y. Rohekar,  Shami Nisimov,  Yaniv Gurwicz,  Gal Novik</p>
  <p><b>备注</b>：35th Conference on Neural Information Processing Systems (NeurIPS 2021). arXiv admin note: text overlap with arXiv:2012.07513</p>
  <p><b>关键词</b>：icd requires significantly fewer ci tests, higher statistical power --, smaller conditioning sets --, called iterative causal discovery, accurate causal graphs compared</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present a sound and complete algorithm, called iterative causal discovery
(ICD), for recovering causal graphs in the presence of latent confounders and
selection bias. ICD relies on the causal Markov and faithfulness assumptions
and recovers the equivalence class of the underlying causal graph. It starts
with a complete graph, and consists of a single iterative stage that gradually
refines this graph by identifying conditional independence (CI) between
connected nodes. Independence and causal relations entailed after any iteration
are correct, rendering ICD anytime. Essentially, we tie the size of the CI
conditioning set to its distance on the graph from the tested nodes, and
increase this value in the successive iteration. Thus, each iteration refines a
graph that was recovered by previous iterations having smaller conditioning
sets -- a higher statistical power -- which contributes to stability. We
demonstrate empirically that ICD requires significantly fewer CI tests and
learns more accurate causal graphs compared to FCI, FCI+, and RFCI algorithms.</p>
  </details>
</details>
<details>
  <summary>45. <b>标题：Consistency and Consensus Driven for Hesitant Fuzzy Linguistic Decision  Making with Pairwise Comparisons</b></summary>
  <p><b>编号</b>：[225]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04092</p>
  <p><b>作者</b>：Peijia Ren,  Zixu Liu,  Wei-Guo Zhang,  Xilan Wu</p>
  <p><b>备注</b>：Submitted to Expert Systems with Applications (ISSN: 0957-4174)</p>
  <p><b>关键词</b>：hesitant fuzzy linguistic geometric consistency index, hesitant fuzzy linguistic preference relation, venture capital guiding funds, consensus ensuring including, original individual hflprs</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Hesitant fuzzy linguistic preference relation (HFLPR) is of interest because
it provides an efficient way for opinion expression under uncertainty. For
enhancing the theory of decision making with HFLPR, the paper introduces an
algorithm for group decision making with HFLPRs based on the acceptable
consistency and consensus measurements, which involves (1) defining a hesitant
fuzzy linguistic geometric consistency index (HFLGCI) and proposing a procedure
for consistency checking and inconsistency improving for HFLPR; (2) measuring
the group consensus based on the similarity between the original individual
HFLPRs and the overall perfect HFLPR, then establishing a procedure for
consensus ensuring including the determination of decision-makers weights. The
convergence and monotonicity of the proposed two procedures have been proved.
Some experiments are furtherly performed to investigate the critical values of
the defined HFLGCI, and comparative analyses are conducted to show the
effectiveness of the proposed algorithm. A case concerning the performance
evaluation of venture capital guiding funds is given to illustrate the
availability of the proposed algorithm. As an application of our work, an
online decision-making portal is finally provided for decision-makers to
utilize the proposed algorithms to solve decision-making problems.</p>
  </details>
</details>
<details>
  <summary>46. <b>标题：Meta Cross-Modal Hashing on Long-Tailed Data</b></summary>
  <p><b>编号</b>：[227]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04086</p>
  <p><b>作者</b>：Runmin Wang,  Guoxian Yu,  Carlotta Domeniconi,  Xiangliang Zhang</p>
  <p><b>备注</b>：10 pages, 4 figures</p>
  <p><b>关键词</b>：metacmh first learns direct features, approximate nearest neighbor search, metacmh performs significantly better, real world data often, learns hash functions</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Due to the advantage of reducing storage while speeding up query time on big
heterogeneous data, cross-modal hashing has been extensively studied for
approximate nearest neighbor search of multi-modal data. Most hashing methods
assume that training data is class-balanced.However, in practice, real world
data often have a long-tailed distribution. In this paper, we introduce a
meta-learning based cross-modal hashing method (MetaCMH) to handle long-tailed
data. Due to the lack of training samples in the tail classes, MetaCMH first
learns direct features from data in different modalities, and then introduces
an associative memory module to learn the memory features of samples of the
tail classes. It then combines the direct and memory features to obtain meta
features for each sample. For samples of the head classes of the long tail
distribution, the weight of the direct features is larger, because there are
enough training data to learn them well; while for rare classes, the weight of
the memory features is larger. Finally, MetaCMH uses a likelihood loss function
to preserve the similarity in different modalities and learns hash functions in
an end-to-end fashion. Experiments on long-tailed datasets show that MetaCMH
performs significantly better than state-of-the-art methods, especially on the
tail classes.</p>
  </details>
</details>
<details>
  <summary>47. <b>标题：Modelling and Optimisation of Resource Usage in an IoT Enabled Smart  Campus</b></summary>
  <p><b>编号</b>：[228]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04085</p>
  <p><b>作者</b>：Thanchanok Sutjarittham</p>
  <p><b>备注</b>：Doctoral thesis</p>
  <p><b>关键词</b>：various stakeholders including students, experimentation using unsw sydney, public transport stops, predict usage patterns, opportunity via theory</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>University campuses are essentially a microcosm of a city. They comprise
diverse facilities such as residences, sport centres, lecture theatres, parking
spaces, and public transport stops. Universities are under constant pressure to
improve efficiencies while offering a better experience to various stakeholders
including students, staff, and visitors. Nonetheless, anecdotal evidence
indicates that campus assets are not being utilised efficiently, often due to
the lack of data collection and analysis, thereby limiting the ability to make
informed decisions on the allocation and management of resources. Advances in
the Internet of Things (IoT) technologies that can sense and communicate data
from the physical world, coupled with data analytics and Artificial
intelligence (AI) that can predict usage patterns, have opened up new
opportunities for organisations to lower cost and improve user experience. This
thesis explores this opportunity via theory and experimentation using UNSW
Sydney as a living laboratory.</p>
  </details>
</details>
<details>
  <summary>48. <b>标题：Cross-modal Zero-shot Hashing by Label Attributes Embedding</b></summary>
  <p><b>编号</b>：[231]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04080</p>
  <p><b>作者</b>：Runmin Wang,  Guoxian Yu,  Lei Liu,  Lizhen Cui,  Carlotta Domeniconi,  Xiangliang Zhang</p>
  <p><b>备注</b>：7 pages, 2 figures</p>
  <p><b>关键词</b>：modal approximate nearest neighbor search, unseen ones using label attributes, laeh outperforms related representative zero, cmh solutions ideally assume, initial semantic attribute vectors</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Cross-modal hashing (CMH) is one of the most promising methods in cross-modal
approximate nearest neighbor search. Most CMH solutions ideally assume the
labels of training and testing set are identical. However, the assumption is
often violated, causing a zero-shot CMH problem. Recent efforts to address this
issue focus on transferring knowledge from the seen classes to the unseen ones
using label attributes. However, the attributes are isolated from the features
of multi-modal data. To reduce the information gap, we introduce an approach
called LAEH (Label Attributes Embedding for zero-shot cross-modal Hashing).
LAEH first gets the initial semantic attribute vectors of labels by word2vec
model and then uses a transformation network to transform them into a common
subspace. Next, it leverages the hash vectors and the feature similarity matrix
to guide the feature extraction network of different modalities. At the same
time, LAEH uses the attribute similarity as the supplement of label similarity
to rectify the label embedding and common subspace. Experiments show that LAEH
outperforms related representative zero-shot and cross-modal hashing methods.</p>
  </details>
</details>
<details>
  <summary>49. <b>标题：DVS: Deep Visibility Series and its Application in Construction Cost  Index Forecasting</b></summary>
  <p><b>编号</b>：[236]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04071</p>
  <p><b>作者</b>：Tianxiang Zhan,  Yuanpeng He,  Hanwen Li,  Fuyuan Xiao</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：ann ), convolutional neural network, new time series forecasting methods, obtained superior forecast accuracy, construction cost index forecast, obtained better forecasting effects</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Time series forecasting has always been a hot spot in scientific research.
With the development of artificial intelligence, new time series forecasting
methods have obtained better forecasting effects and forecasting performance
through bionic research and improvements to the past methods. Visibility Graph
(VG) algorithm is often used for time series prediction in previous research,
but the prediction effect is not as good as deep learning prediction methods
such as Artificial Neural Network (ANN), Convolutional Neural Network (CNN) and
Long Short-Term Memory Network (LSTM) prediction. The VG algorithm contains a
wealth of network information, but previous studies did not effectively use the
network information to make predictions, resulting in relatively large
prediction errors. In order to solve this problem, this paper proposes the Deep
Visibility Series (DVS) module through the bionic design of VG and the
expansion of the past research, which is the first time to combine VG with
bionic design and deep network. By applying the bionic design of biological
vision to VG, the time series of DVS has obtained superior forecast accuracy,
which has made a contribution to time series forecasting. At the same time,
this paper applies the DVS forecasting method to the construction cost index
forecast, which has practical significance.</p>
  </details>
</details>
<details>
  <summary>50. <b>标题：Crowdsourcing with Meta-Workers: A New Way to Save the Budget</b></summary>
  <p><b>编号</b>：[238]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04068</p>
  <p><b>作者</b>：Guangyang Han,  Guoxian Yu,  Lizhen Cui,  Carlotta Domeniconi,  Xiangliang Zhang</p>
  <p><b>备注</b>：11 pages, 6 figures</p>
  <p><b>关键词</b>：workers using different meta learning algorithms, e ., image classification, art task assignment methods, unlike regular crowd workers, first cluster unlabeled data</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Due to the unreliability of Internet workers, it's difficult to complete a
crowdsourcing project satisfactorily, especially when the tasks are multiple
and the budget is limited. Recently, meta learning has brought new vitality to
few-shot learning, making it possible to obtain a classifier with a fair
performance using only a few training samples. Here we introduce the concept of
\emph{meta-worker}, a machine annotator trained by meta learning for types of
tasks (i.e., image classification) that are well-fit for AI. Unlike regular
crowd workers, meta-workers can be reliable, stable, and more importantly,
tireless and free. We first cluster unlabeled data and ask crowd workers to
repeatedly annotate the instances nearby the cluster centers; we then leverage
the annotated data and meta-training datasets to build a cluster of
meta-workers using different meta learning algorithms. Subsequently,
meta-workers are asked to annotate the remaining crowdsourced tasks. The
Jensen-Shannon divergence is used to measure the disagreement among the
annotations provided by the meta-workers, which determines whether or not crowd
workers should be invited for further annotation of the same task. Finally, we
model meta-workers' preferences and compute the consensus annotation by
weighted majority voting. Our empirical study confirms that, by combining
machine and human intelligence, we can accomplish a crowdsourcing project with
a lower budget than state-of-the-art task assignment methods, while achieving a
superior or comparable quality.</p>
  </details>
</details>
<details>
  <summary>51. <b>标题：Coordinated Proximal Policy Optimization</b></summary>
  <p><b>编号</b>：[246]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04051</p>
  <p><b>作者</b>：Zifan Wu,  Chao Yu,  Deheng Ye,  Junge Zhang,  Haiyin Piao,  Hankz Hankui Zhuo</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：achieve dynamic credit assignment among agents, policy update process among multiple agents, coppo outperforms several strong baselines, present coordinated proximal policy optimization, original proximal policy optimization</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present Coordinated Proximal Policy Optimization (CoPPO), an algorithm
that extends the original Proximal Policy Optimization (PPO) to the multi-agent
setting. The key idea lies in the coordinated adaptation of step size during
the policy update process among multiple agents. We prove the monotonicity of
policy improvement when optimizing a theoretically-grounded joint objective,
and derive a simplified optimization objective based on a set of
approximations. We then interpret that such an objective in CoPPO can achieve
dynamic credit assignment among agents, thereby alleviating the high variance
issue during the concurrent update of agent policies. Finally, we demonstrate
that CoPPO outperforms several strong baselines and is competitive with the
latest multi-agent PPO method (i.e. MAPPO) under typical multi-agent settings,
including cooperative matrix games and the StarCraft II micromanagement tasks.</p>
  </details>
</details>
<details>
  <summary>52. <b>标题：V-MAO: Generative Modeling for Multi-Arm Manipulation of Articulated  Objects</b></summary>
  <p><b>编号</b>：[269]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03987</p>
  <p><b>作者</b>：Xingyu Liu,  Kris M. Kitani</p>
  <p><b>备注</b>：CoRL 2021</p>
  <p><b>关键词</b>：manipulating articulated objects requires multiple robot arms, enable multiple robot arms, collaboratively complete manipulation tasks, learns contact point distribution, customized mujoco simulation environment</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Manipulating articulated objects requires multiple robot arms in general. It
is challenging to enable multiple robot arms to collaboratively complete
manipulation tasks on articulated objects. In this paper, we present
$\textbf{V-MAO}$, a framework for learning multi-arm manipulation of
articulated objects. Our framework includes a variational generative model that
learns contact point distribution over object rigid parts for each robot arm.
The training signal is obtained from interaction with the simulation
environment which is enabled by planning and a novel formulation of
object-centric control for articulated objects. We deploy our framework in a
customized MuJoCo simulation environment and demonstrate that our framework
achieves a high success rate on six different objects and two different robots.
We also show that generative modeling can effectively learn the contact point
distribution on articulated objects.</p>
  </details>
</details>
<details>
  <summary>53. <b>标题：Profitable Trade-Off Between Memory and Performance In Multi-Domain  Chatbot Architectures</b></summary>
  <p><b>编号</b>：[281]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03963</p>
  <p><b>作者</b>：D Emre Tasar,  Sukru Ozan,  M Fatih Akca,  Oguzhan Olmez,  Semih Gulum,  Secilay Kutay,  Ceren Belhan</p>
  <p><b>备注</b>：in Turkish language. ICADA 21 1st International Conference on Artificial Intelligence and Data Science Nov 26-Nov 28 2021 Izmir Katip Celebi University Izmir, Turkey</p>
  <p><b>关键词</b>：three separate data sets covering different fields, bert models trained specifically, natural language processing, natural language processing, masking method applied</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Text classification problem is a very broad field of study in the field of
natural language processing. In short, the text classification problem is to
determine which of the previously determined classes the given text belongs to.
Successful studies have been carried out in this field in the past studies. In
the study, Bidirectional Encoder Representations for Transformers (BERT), which
is a frequently preferred method for solving the classification problem in the
field of natural language processing, is used. By solving classification
problems through a single model to be used in a chatbot architecture, it is
aimed to alleviate the load on the server that will be created by more than one
model used for solving more than one classification problem. At this point,
with the masking method applied during the estimation of a single BERT model,
which was created for classification in more than one subject, the estimation
of the model was provided on a problem-based basis. Three separate data sets
covering different fields from each other are divided by various methods in
order to complicate the problem, and classification problems that are very
close to each other in terms of field are also included in this way. The
dataset used in this way consists of five classification problems with 154
classes. A BERT model containing all classification problems and other BERT
models trained specifically for the problems were compared with each other in
terms of performance and the space they occupied on the server.</p>
  </details>
</details>
<details>
  <summary>54. <b>标题：Time Discretization-Invariant Safe Action Repetition for Policy Gradient  Methods</b></summary>
  <p><b>编号</b>：[290]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03941</p>
  <p><b>作者</b>：Seohong Park,  Jaekyeom Kim,  Gunhee Kim</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：novel $\ delta $- invariant method named safe action repetition, outperforming previous $\ delta $- invariant approaches, previous action repetition methods cannot immediately react, $\ delta $- invariant algorithm, time scale $\ delta $,</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In reinforcement learning, continuous time is often discretized by a time
scale $\delta$, to which the resulting performance is known to be highly
sensitive. In this work, we seek to find a $\delta$-invariant algorithm for
policy gradient (PG) methods, which performs well regardless of the value of
$\delta$. We first identify the underlying reasons that cause PG methods to
fail as $\delta \to 0$, proving that the variance of the PG estimator can
diverge to infinity in stochastic environments under a certain assumption of
stochasticity. While durative actions or action repetition can be employed to
have $\delta$-invariance, previous action repetition methods cannot immediately
react to unexpected situations in stochastic environments. We thus propose a
novel $\delta$-invariant method named Safe Action Repetition (SAR) applicable
to any existing PG algorithm. SAR can handle the stochasticity of environments
by adaptively reacting to changes in states during action repetition. We
empirically show that our method is not only $\delta$-invariant but also robust
to stochasticity, outperforming previous $\delta$-invariant approaches on eight
MuJoCo environments with both deterministic and stochastic settings. Our code
is available at this https URL.</p>
  </details>
</details>
<details>
  <summary>55. <b>标题：Convolutional Gated MLP: Combining Convolutions & gMLP</b></summary>
  <p><b>编号</b>：[291]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03940</p>
  <p><b>作者</b>：A.Rajagopal,  V. Nirmala</p>
  <p><b>备注</b>：Conference</p>
  <p><b>关键词</b>：learnt using vast amount, novel deep learning architecture, novel deep learning architecture, spatial gated mlp, google brain introduced</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>To the best of our knowledge, this is the first paper to introduce
Convolutions to Gated MultiLayer Perceptron and contributes an implementation
of this novel Deep Learning architecture. Google Brain introduced the gMLP in
May 2021. Microsoft introduced Convolutions in Vision Transformer in Mar 2021.
Inspired by both gMLP and CvT, we introduce convolutional layers in gMLP. CvT
combined the power of Convolutions and Attention. Our implementation combines
the best of Convolutional learning along with spatial gated MLP. Further, the
paper visualizes how CgMLP learns. Visualizations show how CgMLP learns from
features such as outline of a car. While Attention was the basis of much of
recent progress in Deep Learning, gMLP proposed an approach that doesn't use
Attention computation. In Transformer based approaches, a whole lot of
Attention matrixes need to be learnt using vast amount of training data. In
gMLP, the fine tunning for new tasks can be challenging by transfer learning
with smaller datasets. We implement CgMLP and compares it with gMLP on CIFAR
dataset. Experimental results explore the power of generaliza-tion of CgMLP,
while gMLP tend to drastically overfit the training data.
To summarize, the paper contributes a novel Deep Learning architecture and
demonstrates the learning mechanism of CgMLP through visualizations, for the
first time in literature.</p>
  </details>
</details>
<details>
  <summary>56. <b>标题：Transformer Based Bengali Chatbot Using General Knowledge Dataset</b></summary>
  <p><b>编号</b>：[292]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03937</p>
  <p><b>作者</b>：Abu Kaisar Mohammad Masum,  Sheikh Abujar,  Sharmin Akter,  Nushrat Jahan Ria,  Syed Akhter Hossain</p>
  <p><b>备注</b>：4 pages, 3 figures, supplemental materials</p>
  <p><b>关键词</b>：bengali general knowledge question answer, bengali general knowledge chatbot based, model reduces training time compared, deep neural models superior, rnn model regularly used</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>An AI chatbot provides an impressive response after learning from the trained
dataset. In this decade, most of the research work demonstrates that deep
neural models superior to any other model. RNN model regularly used for
determining the sequence-related problem like a question and it answers. This
approach acquainted with everyone as seq2seq learning. In a seq2seq model
mechanism, it has encoder and decoder. The encoder embedded any input sequence,
and the decoder embedded output sequence. For reinforcing the seq2seq model
performance, attention mechanism added into the encoder and decoder. After
that, the transformer model has introduced itself as a high-performance model
with multiple attention mechanism for solving the sequence-related dilemma.
This model reduces training time compared with RNN based model and also
achieved state-of-the-art performance for sequence transduction. In this
research, we applied the transformer model for Bengali general knowledge
chatbot based on the Bengali general knowledge Question Answer (QA) dataset. It
scores 85.0 BLEU on the applied QA data. To check the comparison of the
transformer model performance, we trained the seq2seq model with attention on
our dataset that scores 23.5 BLEU.</p>
  </details>
</details>
<details>
  <summary>57. <b>标题：Optimal and Efficient Dynamic Regret Algorithms for Non-Stationary  Dueling Bandits</b></summary>
  <p><b>编号</b>：[300]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03917</p>
  <p><b>作者</b>：Shubham Gupta,  Aadirupa Saha</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：next use similar algorithmic ideas, k $- armed dueling bandits, proving matching lower bound guarantees, kt })$ high probability regret, ({ v_t ^{ 1</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We study the problem of \emph{dynamic regret minimization} in $K$-armed
Dueling Bandits under non-stationary or time varying preferences. This is an
online learning setup where the agent chooses a pair of items at each round and
observes only a relative binary `win-loss' feedback for this pair, sampled from
an underlying preference matrix at that round. We first study the problem of
static-regret minimization for adversarial preference sequences and design an
efficient algorithm with $O(\sqrt{KT})$ high probability regret. We next use
similar algorithmic ideas to propose an efficient and provably optimal
algorithm for dynamic-regret minimization under two notions of
non-stationarities. In particular, we establish $\tO(\sqrt{SKT})$ and
$\tO({V_T^{1/3}K^{1/3}T^{2/3}})$ dynamic-regret guarantees, $S$ being the total
number of `effective-switches' in the underlying preference relations and $V_T$
being a measure of `continuous-variation' non-stationarity. The complexity of
these problems have not been studied prior to this work despite the
practicability of non-stationary environments in real world systems. We justify
the optimality of our algorithms by proving matching lower bound guarantees
under both the above-mentioned notions of non-stationarities. Finally, we
corroborate our results with extensive simulations and compare the efficacy of
our algorithms over state-of-the-art baselines.</p>
  </details>
</details>
<details>
  <summary>58. <b>标题：Robust Deep Reinforcement Learning for Quadcopter Control</b></summary>
  <p><b>编号</b>：[302]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03915</p>
  <p><b>作者</b>：Aditya M. Deshpande,  Ali A. Minai,  Manish Kumar</p>
  <p><b>备注</b>：6 pages; 3 Figures; Accepted in this https URL</p>
  <p><b>关键词</b>：solve complex robotics problems using neural networks, use robust markov decision processes, added robustness increases generality, handle potential gaps, deep reinforcement learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep reinforcement learning (RL) has made it possible to solve complex
robotics problems using neural networks as function approximators. However, the
policies trained on stationary environments suffer in terms of generalization
when transferred from one environment to another. In this work, we use Robust
Markov Decision Processes (RMDP) to train the drone control policy, which
combines ideas from Robust Control and RL. It opts for pessimistic optimization
to handle potential gaps between policy transfer from one environment to
another. The trained control policy is tested on the task of quadcopter
positional control. RL agents were trained in a MuJoCo simulator. During
testing, different environment parameters (unseen during the training) were
used to validate the robustness of the trained policy for transfer from one
environment to another. The robust policy outperformed the standard agents in
these environments, suggesting that the added robustness increases generality
and can adapt to non-stationary environments.
Codes: this https URL</p>
  </details>
</details>
<details>
  <summary>59. <b>标题：TND-NAS: Towards Non-differentiable Objectives in Progressive  Differentiable NAS Framework</b></summary>
  <p><b>编号</b>：[312]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03892</p>
  <p><b>作者</b>：Bo Lyu,  Shiping Wen,  Zheng Yan,  Kaibo Shi,  Ke Li,  Tingwen Huang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：end architecture search framework towards non, representative experiment takes two objectives, architecture parameters ($\ alpha $), recent differentiable nas also aims, neural architecture search</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Differentiable architecture search has gradually become the mainstream
research topic in the field of Neural Architecture Search (NAS) for its
capability to improve efficiency compared with the early NAS (EA-based,
RL-based) methods. Recent differentiable NAS also aims at further improving
search efficiency, reducing the GPU-memory consumption, and addressing the
"depth gap" issue. However, these methods are no longer capable of tackling the
non-differentiable objectives, let alone multi-objectives, e.g., performance,
robustness, efficiency, and other metrics. We propose an end-to-end
architecture search framework towards non-differentiable objectives, TND-NAS,
with the merits of the high efficiency in differentiable NAS framework and the
compatibility among non-differentiable metrics in Multi-objective NAS (MNAS).
Under differentiable NAS framework, with the continuous relaxation of the
search space, TND-NAS has the architecture parameters ($\alpha$) been optimized
in discrete space, while resorting to the search policy of progressively
shrinking the supernetwork by $\alpha$. Our representative experiment takes two
objectives (Parameters, Accuracy) as an example, we achieve a series of
high-performance compact architectures on CIFAR10 (1.09M/3.3%, 2.4M/2.95%,
9.57M/2.54%) and CIFAR100 (2.46M/18.3%, 5.46/16.73%, 12.88/15.20%) datasets.
Favorably, under real-world scenarios (resource-constrained,
platform-specialized), the Pareto-optimal solutions can be conveniently reached
by TND-NAS.</p>
  </details>
</details>
<details>
  <summary>60. <b>标题：What augmentations are sensitive to hyper-parameters and why?</b></summary>
  <p><b>编号</b>：[319]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03861</p>
  <p><b>作者</b>：Ch Muhammad Awais,  Imad Eddine Ibrahim Bekkouch</p>
  <p><b>备注</b>：10 pages, 17 figures</p>
  <p><b>关键词</b>：utilized linear regression coefficients, machine learning model, hyper parameters along, question remains, noisy data</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We apply augmentations to our dataset to enhance the quality of our
predictions and make our final models more resilient to noisy data and domain
drifts. Yet the question remains, how are these augmentations going to perform
with different hyper-parameters? In this study we evaluate the sensitivity of
augmentations with regards to the model's hyper parameters along with their
consistency and influence by performing a Local Surrogate (LIME) interpretation
on the impact of hyper-parameters when different augmentations are applied to a
machine learning model. We have utilized Linear regression coefficients for
weighing each augmentation. Our research has proved that there are some
augmentations which are highly sensitive to hyper-parameters and others which
are more resilient and reliable.</p>
  </details>
</details>
<details>
  <summary>61. <b>标题：SIG-VC: A Speaker Information Guided Zero-shot Voice Conversion System  for Both Human Beings and Machines</b></summary>
  <p><b>编号</b>：[334]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03811</p>
  <p><b>作者</b>：Zhang Haozhe,  Cai Zexin,  Qin Xiaoyi,  Li Ming</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：systems achieve good performance, get pure content information, better remove speaker information, proposed system significantly reduces, voice cloning performance</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Nowadays, as more and more systems achieve good performance in traditional
voice conversion (VC) tasks, people's attention gradually turns to VC tasks
under extreme conditions. In this paper, we propose a novel method for
zero-shot voice conversion. We aim to obtain intermediate representations for
speaker-content disentanglement of speech to better remove speaker information
and get pure content information. Accordingly, our proposed framework contains
a module that removes the speaker information from the acoustic feature of the
source speaker. Moreover, speaker information control is added to our system to
maintain the voice cloning performance. The proposed system is evaluated by
subjective and objective metrics. Results show that our proposed system
significantly reduces the trade-off problem in zero-shot voice conversion,
while it also manages to have high spoofing power to the speaker verification
system.</p>
  </details>
</details>
<details>
  <summary>62. <b>标题：Development of collective behavior in newborn artificial agents</b></summary>
  <p><b>编号</b>：[338]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03796</p>
  <p><b>作者</b>：Donsuk Lee,  Samantha M. W. Wood,  Justin N. Wood</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：driven learning -- two learning mechanisms deeply rooted, two generic learning mechanisms -- deep reinforcement learning, agents also learn collective behavior without external rewards, used deep reinforcement learning, driven learning --</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Collective behavior is widespread across the animal kingdom. To date,
however, the developmental and mechanistic foundations of collective behavior
have not been formally established. What learning mechanisms drive the
development of collective behavior in newborn animals? Here, we used deep
reinforcement learning and curiosity-driven learning -- two learning mechanisms
deeply rooted in psychological and neuroscientific research -- to build newborn
artificial agents that develop collective behavior. Like newborn animals, our
agents learn collective behavior from raw sensory inputs in naturalistic
environments. Our agents also learn collective behavior without external
rewards, using only intrinsic motivation (curiosity) to drive learning.
Specifically, when we raise our artificial agents in natural visual
environments with groupmates, the agents spontaneously develop ego-motion,
object recognition, and a preference for groupmates, rapidly learning all of
the core skills required for collective behavior. This work bridges the divide
between high-dimensional sensory inputs and collective action, resulting in a
pixels-to-actions model of collective animal behavior. More generally, we show
that two generic learning mechanisms -- deep reinforcement learning and
curiosity-driven learning -- are sufficient to learn collective behavior from
unsupervised natural experience.</p>
  </details>
</details>
<details>
  <summary>63. <b>标题：Generation of microbial colonies dataset with deep learning style  transfer</b></summary>
  <p><b>编号</b>：[341]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03789</p>
  <p><b>作者</b>：Jarosław Pawłowski,  Sylwia Majchrowska,  Tomasz Golan</p>
  <p><b>备注</b>：11 pages, 9 figures, 2 tables</p>
  <p><b>关键词</b>：developed generator employs traditional computer vision algorithms together, classifying five different microbial species, method requires significantly fewer resources, several dozen times bigger dataset, neural network model capable</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We introduce an effective strategy to generate a synthetic dataset of
microbiological images of Petri dishes that can be used to train deep learning
models. The developed generator employs traditional computer vision algorithms
together with a neural style transfer method for data augmentation. We show
that the method is able to synthesize a dataset of realistic looking images
that can be used to train a neural network model capable of localising,
segmenting, and classifying five different microbial species. Our method
requires significantly fewer resources to obtain a useful dataset than
collecting and labeling a whole large set of real images with annotations. We
show that starting with only 100 real images, we can generate data to train a
detector that achieves comparable results to the same detector but trained on a
real, several dozen times bigger dataset. We prove the usefulness of the method
in microbe detection and segmentation, but we expect that it is general and
flexible and can also be applicable in other domains of science and industry to
detect various objects.</p>
  </details>
</details>
<details>
  <summary>64. <b>标题：d3rlpy: An Offline Deep Reinforcement Learning Library</b></summary>
  <p><b>编号</b>：[342]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03788</p>
  <p><b>作者</b>：Takuma Seno,  Michita Imai</p>
  <p><b>备注</b>：Accepted at Offline Reinforcement Learning Workshop at Neural Information Processing Systems, 2021</p>
  <p><b>关键词</b>：train offline rl algorithms without coding programs, sourced offline deep reinforcement learning, offline deep rl algorithms, assist deep rl research, online algorithms via</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we introduce d3rlpy, an open-sourced offline deep
reinforcement learning (RL) library for Python. d3rlpy supports a number of
offline deep RL algorithms as well as online algorithms via a user-friendly
API. To assist deep RL research and development projects, d3rlpy provides
practical and unique features such as data collection, exporting policies for
deployment, preprocessing and postprocessing, distributional Q-functions,
multi-step learning and a convenient command-line interface. Furthermore,
d3rlpy additionally provides a novel graphical interface that enables users to
train offline RL algorithms without coding programs. Lastly, the implemented
algorithms are benchmarked with D4RL datasets to ensure the implementation
quality. The d3rlpy source code can be found on GitHub:
\url{this https URL}.</p>
  </details>
</details>
<details>
  <summary>65. <b>标题：Confidence Composition for Monitors of Verification Assumptions</b></summary>
  <p><b>编号</b>：[345]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03782</p>
  <p><b>作者</b>：Ivan Ruchkin,  Matthew Cleaveland,  Radoslav Ivanov,  Pengyuan Lu,  Taylor Carpenter,  Oleg Sokolsky,  Insup Lee</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：neural network controllers offers strong safety guarantees, successfully predict safety violations, framework provides theoretical bounds, build calibrated confidence monitors, predict safety violations</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Closed-loop verification of cyber-physical systems with neural network
controllers offers strong safety guarantees under certain assumptions. It is,
however, difficult to determine whether these guarantees apply at run time
because verification assumptions may be violated. To predict safety violations
in a verified system, we propose a three-step framework for monitoring the
confidence in verification assumptions. First, we represent the sufficient
condition for verified safety with a propositional logical formula over
assumptions. Second, we build calibrated confidence monitors that evaluate the
probability that each assumption holds. Third, we obtain the confidence in the
verification guarantees by composing the assumption monitors using a
composition function suitable for the logical formula. Our framework provides
theoretical bounds on the calibration and conservatism of compositional
monitors. In two case studies, we demonstrate that the composed monitors
improve over their constituents and successfully predict safety violations.</p>
  </details>
</details>
<details>
  <summary>66. <b>标题：Asynchronous Collaborative Localization by Integrating Spatiotemporal  Graph Learning with Model-Based Estimation</b></summary>
  <p><b>编号</b>：[355]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03751</p>
  <p><b>作者</b>：Peng Gao,  Brian Reily,  Rui Guo,  Hongsheng Lu,  Qingzhao Zhu,  Hao Zhang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：two collaborative object localization scenarios, including modeling complex relationships, four key challenges must, collaboratively estimate object locations, aware spatiotemporal graph learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Collaborative localization is an essential capability for a team of robots
such as connected vehicles to collaboratively estimate object locations from
multiple perspectives with reliant cooperation. To enable collaborative
localization, four key challenges must be addressed, including modeling complex
relationships between observed objects, fusing observations from an arbitrary
number of collaborating robots, quantifying localization uncertainty, and
addressing latency of robot communications. In this paper, we introduce a novel
approach that integrates uncertainty-aware spatiotemporal graph learning and
model-based state estimation for a team of robots to collaboratively localize
objects. Specifically, we introduce a new uncertainty-aware graph learning
model that learns spatiotemporal graphs to represent historical motions of the
objects observed by each robot over time and provides uncertainties in object
localization. Moreover, we propose a novel method for integrated learning and
model-based state estimation, which fuses asynchronous observations obtained
from an arbitrary number of robots for collaborative localization. We evaluate
our approach in two collaborative object localization scenarios in simulations
and on real robots. Experimental results show that our approach outperforms
previous methods and achieves state-of-the-art performance on asynchronous
collaborative localization.</p>
  </details>
</details>
<details>
  <summary>67. <b>标题：An Algorithmic Theory of Metacognition in Minds and Machines</b></summary>
  <p><b>编号</b>：[357]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03745</p>
  <p><b>作者</b>：Rylan Schaeffer</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：suboptimal actions without external information, humans sometimes choose actions, machine learning community, proposed theory creates, metacognitive actor critic</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Humans sometimes choose actions that they themselves can identify as
sub-optimal, or wrong, even in the absence of additional information. How is
this possible? We present an algorithmic theory of metacognition based on a
well-understood trade-off in reinforcement learning (RL) between value-based RL
and policy-based RL. To the cognitive (neuro)science community, our theory
answers the outstanding question of why information can be used for error
detection but not for action selection. To the machine learning community, our
proposed theory creates a novel interaction between the Actor and Critic in
Actor-Critic agents and notes a novel connection between RL and Bayesian
Optimization. We call our proposed agent the Metacognitive Actor Critic (MAC).
We conclude with showing how to create metacognition in machines by
implementing a deep MAC and showing that it can detect (some of) its own
suboptimal actions without external information or delay.</p>
  </details>
</details>
<details>
  <summary>68. <b>标题：Increasing Data Diversity with Iterative Sampling to Improve Performance</b></summary>
  <p><b>编号</b>：[359]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03743</p>
  <p><b>作者</b>：Devrim Cavusoglu,  Ogulcan Eryuksel,  Sinan Altinuc</p>
  <p><b>备注</b>：5 pages, 2 (6) figures, to be published in 1st NeurIPS Data-Centric AI Workshop</p>
  <p><b>关键词</b>：difficult classes especially providing closer samples, edge cases potentially, centric ai competition, training samples, augmented samples</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As a part of the Data-Centric AI Competition, we propose a data-centric
approach to improve the diversity of the training samples by iterative
sampling. The method itself relies strongly on the fidelity of augmented
samples and the diversity of the augmentation methods. Moreover, we improve the
performance further by introducing more samples for the difficult classes
especially providing closer samples to edge cases potentially those the model
at hand misclassifies.</p>
  </details>
</details>
<details>
  <summary>69. <b>标题：Shared Model of Sense-making for Human-Machine Collaboration</b></summary>
  <p><b>编号</b>：[364]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03728</p>
  <p><b>作者</b>：Gheorghe Tecuci,  Dorin Marcu,  Louis Kaiser,  Mihai Boicu</p>
  <p><b>备注</b>：Presented at AAAI FSS-21: Artificial Intelligence in Government and Public Sector, Washington, DC, USA</p>
  <p><b>关键词</b>：g ., chemical warfare agents, stealth fighter aircraft )., g ., possible production, understand situations involving, general model grounded</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present a model of sense-making that greatly facilitates the collaboration
between an intelligent analyst and a knowledge-based agent. It is a general
model grounded in the science of evidence and the scientific method of
hypothesis generation and testing, where sense-making hypotheses that explain
an observation are generated, relevant evidence is then discovered, and the
hypotheses are tested based on the discovered evidence. We illustrate how the
model enables an analyst to directly instruct the agent to understand
situations involving the possible production of weapons (e.g., chemical warfare
agents) and how the agent becomes increasingly more competent in understanding
other situations from that domain (e.g., possible production of
centrifuge-enriched uranium or of stealth fighter aircraft).</p>
  </details>
</details>
<details>
  <summary>70. <b>标题：Reconstructing Training Data from Diverse ML Models by Ensemble  Inversion</b></summary>
  <p><b>编号</b>：[376]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03702</p>
  <p><b>作者</b>：Qian Wang,  Daniel Kurz</p>
  <p><b>备注</b>：9 pages, 8 figures, WACV 2022</p>
  <p><b>关键词</b>：training data contains personally identifiable information, explore targeting multiple models jointly, achieve high quality results without, attracted increasing research attention, may provide additional information</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Model Inversion (MI), in which an adversary abuses access to a trained
Machine Learning (ML) model attempting to infer sensitive information about its
original training data, has attracted increasing research attention. During MI,
the trained model under attack (MUA) is usually frozen and used to guide the
training of a generator, such as a Generative Adversarial Network (GAN), to
reconstruct the distribution of the original training data of that model. This
might cause leakage of original training samples, and if successful, the
privacy of dataset subjects will be at risk if the training data contains
Personally Identifiable Information (PII). Therefore, an in-depth investigation
of the potentials of MI techniques is crucial for the development of
corresponding defense techniques. High-quality reconstruction of training data
based on a single model is challenging. However, existing MI literature does
not explore targeting multiple models jointly, which may provide additional
information and diverse perspectives to the adversary.
We propose the ensemble inversion technique that estimates the distribution
of original training data by training a generator constrained by an ensemble
(or set) of trained models with shared subjects or entities. This technique
leads to noticeable improvements of the quality of the generated samples with
distinguishable features of the dataset entities compared to MI of a single ML
model. We achieve high quality results without any dataset and show how
utilizing an auxiliary dataset that's similar to the presumed training data
improves the results. The impact of model diversity in the ensemble is
thoroughly investigated and additional constraints are utilized to encourage
sharp predictions and high activations for the reconstructed samples, leading
to more accurate reconstruction of training images.</p>
  </details>
</details>
<details>
  <summary>71. <b>标题：A space of goals: the cognitive geometry of informationally bounded  agents</b></summary>
  <p><b>编号</b>：[378]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03699</p>
  <p><b>作者</b>：Karen Archer,  Nicola Catenacci Volpi,  Franziska Bröker,  Daniel Polani</p>
  <p><b>备注</b>：Includes supplementary material, 5 figures in the main document, 1 figure in the supplementary material</p>
  <p><b>关键词</b>：dimensional spaces showing distinct distortions reflecting, information costs become increasingly important, textit {" cognitive geometry "}, additional informational costs invite, incorporating information processing costs</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Traditionally, Euclidean geometry is treated by scientists as a priori and
objective. However, when we take the position of an agent, the problem of
selecting a best route should also factor in the abilities of the agent, its
embodiment and particularly its cognitive effort. In this paper we consider
geometry in terms of travel between states within a world by incorporating
information processing costs with the appropriate spatial distances. This
induces a geometry that increasingly differs from the original geometry of the
given world, as information costs become increasingly important. We visualize
this \textit{"cognitive geometry"} by projecting it onto 2- and 3-dimensional
spaces showing distinct distortions reflecting the emergence of epistemic and
information-saving strategies as well as pivot states. The analogies between
traditional cost-based geometries and those induced by additional informational
costs invite a generalization of the traditional notion of geodesics as
cheapest routes towards the notion of \textit{infodesics}. Crucially, the
concept of infodesics approximates the usual geometric property that,
travelling from a start to a goal along a geodesic, not only the goal, but all
intermediate points are equally visited at optimal cost from the start.</p>
  </details>
</details>
<details>
  <summary>72. <b>标题：AI and Blackness: Towards moving beyond bias and representation</b></summary>
  <p><b>编号</b>：[383]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03687</p>
  <p><b>作者</b>：Christopher L. Dancy,  P. Khalil Saucier</p>
  <p><b>备注</b>：10 pages, 3 figures, 2 tables</p>
  <p><b>关键词</b>：suggest questions one may ask, ai ethics must move beyond, source semantic network, multiple perspectives together, many recent discussions</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we argue that AI ethics must move beyond the concepts of
race-based representation and bias, and towards those that probe the deeper
relations that impact how these systems are designed, developed, and deployed.
Many recent discussions on ethical considerations of bias in AI systems have
centered on racial bias. We contend that antiblackness in AI requires more of
an examination of the ontological space that provides a foundation for the
design, development, and deployment of AI systems. We examine what this
contention means from the perspective of the sociocultural context in which AI
systems are designed, developed, and deployed and focus on intersections with
anti-Black racism (antiblackness). To bring these multiple perspectives
together and show an example of antiblackness in the face of attempts at
de-biasing, we discuss results from auditing an existing open-source semantic
network (ConceptNet). We use this discussion to further contextualize
antiblackness in design, development, and deployment of AI systems and suggest
questions one may ask when attempting to combat antiblackness in AI systems.</p>
  </details>
</details>
<details>
  <summary>73. <b>标题：Human Activity Recognition using Attribute-Based Neural Networks and  Context Information</b></summary>
  <p><b>编号</b>：[402]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04564</p>
  <p><b>作者</b>：Stefan Lüdtke,  Fernando Moya Rueda,  Waqas Ahmed,  Gernot A. Fink,  Thomas Kirste</p>
  <p><b>备注</b>：3rd International Workshop on Deep Learning for Human Activity Recognition</p>
  <p><b>关键词</b>：proposed architecture increases har performance, consider human activity recognition, currently executed process step, level movement descriptors, g ., standing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We consider human activity recognition (HAR) from wearable sensor data in
manual-work processes, like warehouse order-picking. Such structured domains
can often be partitioned into distinct process steps, e.g., packaging or
transporting. Each process step can have a different prior distribution over
activity classes, e.g., standing or walking, and different system dynamics.
Here, we show how such context information can be integrated systematically
into a deep neural network-based HAR system. Specifically, we propose a hybrid
architecture that combines a deep neural network-that estimates high-level
movement descriptors, attributes, from the raw-sensor data-and a shallow
classifier, which predicts activity classes from the estimated attributes and
(optional) context information, like the currently executed process step. We
empirically show that our proposed architecture increases HAR performance,
compared to state-of-the-art methods. Additionally, we show that HAR
performance can be further increased when information about process steps is
incorporated, even when that information is only partially correct.</p>
  </details>
</details>
<details>
  <summary>74. <b>标题：Representation Learning via Quantum Neural Tangent Kernels</b></summary>
  <p><b>编号</b>：[419]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04225</p>
  <p><b>作者</b>：Junyu Liu,  Francesco Tacchino,  Jennifer R. Glick,  Liang Jiang,  Antonio Mezzacapo</p>
  <p><b>备注</b>：40=11+29 pages, many figures</p>
  <p><b>关键词</b>：analyzing variational quantum circuits using, define quantum neural tangent kernels, variational angles change slowly, designing good variational circuits, variational quantum simulation tasks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Variational quantum circuits are used in quantum machine learning and
variational quantum simulation tasks. Designing good variational circuits or
predicting how well they perform for given learning or optimization tasks is
still unclear. Here we discuss these problems, analyzing variational quantum
circuits using the theory of neural tangent kernels. We define quantum neural
tangent kernels, and derive dynamical equations for their associated loss
function in optimization and learning tasks. We analytically solve the dynamics
in the frozen limit, or lazy training regime, where variational angles change
slowly and a linear perturbation is good enough. We extend the analysis to a
dynamical setting, including quadratic corrections in the variational angles.
We then consider hybrid quantum-classical architecture and define a large width
limit for hybrid kernels, showing that a hybrid quantum-classical neural
network can be approximately Gaussian. The results presented here show limits
for which analytical understandings of the training dynamics for variational
quantum circuits, used for quantum machine learning and optimization problems,
are possible. These analytical results are supported by numerical simulations
of quantum machine learning experiments.</p>
  </details>
</details>
<details>
  <summary>75. <b>标题：Dense Representative Tooth Landmark/axis Detection Network on 3D Model</b></summary>
  <p><b>编号</b>：[420]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04212</p>
  <p><b>作者</b>：Guangshun Wei,  Zhiming Cui,  Jie Zhu,  Lei Yang,  Yuanfeng Zhou,  Pradeep Singh,  Min Gu,  Wenping Wang</p>
  <p><b>备注</b>：11pages,27figures</p>
  <p><b>关键词</b>：large variations among individual tooth, accurately detect tooth landmarks, given 3d tooth model, sophisticated geometric definitions, predicts various types</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Artificial intelligence (AI) technology is increasingly used for digital
orthodontics, but one of the challenges is to automatically and accurately
detect tooth landmarks and axes. This is partly because of sophisticated
geometric definitions of them, and partly due to large variations among
individual tooth and across different types of tooth. As such, we propose a
deep learning approach with a labeled dataset by professional dentists to the
tooth landmark/axis detection on tooth model that are crucial for orthodontic
treatments. Our method can extract not only tooth landmarks in the form of
point (e.g. cusps), but also axes that measure the tooth angulation and
inclination. The proposed network takes as input a 3D tooth model and predicts
various types of the tooth landmarks and axes. Specifically, we encode the
landmarks and axes as dense fields defined on the surface of the tooth model.
This design choice and a set of added components make the proposed network more
suitable for extracting sparse landmarks from a given 3D tooth model. Extensive
evaluation of the proposed method was conducted on a set of dental models
prepared by experienced dentists. Results show that our method can produce
tooth landmarks with high accuracy. Our method was examined and justified via
comparison with the state-of-the-art methods as well as the ablation studies.</p>
  </details>
</details>
<details>
  <summary>76. <b>标题：On the Limits of Design: What Are the Conceptual Constraints on  Designing Artificial Intelligence for Social Good?</b></summary>
  <p><b>编号</b>：[423]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.04165</p>
  <p><b>作者</b>：Jakob Mokander</p>
  <p><b>备注</b>：Artificial Intelligence, Design, Infosphere, Philosophy of Information, Governance, Policy</p>
  <p><b>关键词</b>：collective efforts towards designing future societies, designing future societies needs, thought experiment regarding, enable new solutions, bring substantial benefits</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Artificial intelligence AI can bring substantial benefits to society by
helping to reduce costs, increase efficiency and enable new solutions to
complex problems. Using Floridi's notion of how to design the 'infosphere' as a
starting point, in this chapter I consider the question: what are the limits of
design, i.e. what are the conceptual constraints on designing AI for social
good? The main argument of this chapter is that while design is a useful
conceptual tool to shape technologies and societies, collective efforts towards
designing future societies are constrained by both internal and external
factors. Internal constraints on design are discussed by evoking Hardin's
thought experiment regarding 'the Tragedy of the Commons'. Further, Hayek's
classical distinction between 'cosmos' and 'taxis' is used to demarcate
external constraints on design. Finally, five design principles are presented
which are aimed at helping policymakers manage the internal and external
constraints on design. A successful approach to designing future societies
needs to account for the emergent properties of complex systems by allowing
space for serendipity and socio-technological coevolution.</p>
  </details>
</details>
<details>
  <summary>77. <b>标题：The Three-Dimensional Structural Configuration of the Central Retinal  Vessel Trunk and Branches as a Glaucoma Biomarker</b></summary>
  <p><b>编号</b>：[432]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03997</p>
  <p><b>作者</b>：Satish K. Panda,  Haris Cheong,  Tin A. Tun,  Thanadet Chuangsuwanich,  Aiste Kadziauskiene,  Vijayalakshmi Senthil,  Ramaswami Krishnadas,  Martin L. Buist,  Shamira Perera,  Ching-Yu Cheng,  Tin Aung,  Alexandre H. Thiery,  Michael J. A. Girard</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：major retinal blood vessels form, efficiently segment retinal blood vessels, b orthographically onto three planes, central retinal vessel trunk, retinal nerve fiber layer</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Purpose: To assess whether the three-dimensional (3D) structural
configuration of the central retinal vessel trunk and its branches (CRVT&B)
could be used as a diagnostic marker for glaucoma. Method: We trained a deep
learning network to automatically segment the CRVT&B from the B-scans of the
optical coherence tomography (OCT) volume of the optic nerve head (ONH).
Subsequently, two different approaches were used for glaucoma diagnosis using
the structural configuration of the CRVT&B as extracted from the OCT volumes.
In the first approach, we aimed to provide a diagnosis using only 3D CNN and
the 3D structure of the CRVT&B. For the second approach, we projected the 3D
structure of the CRVT&B orthographically onto three planes to obtain 2D images,
and then a 2D CNN was used for diagnosis. The segmentation accuracy was
evaluated using the Dice coefficient, whereas the diagnostic accuracy was
assessed using the area under the receiver operating characteristic curves
(AUC). The diagnostic performance of the CRVT&B was also compared with that of
retinal nerve fiber layer (RNFL) thickness. Results: Our segmentation network
was able to efficiently segment retinal blood vessels from OCT scans. On a test
set, we achieved a Dice coefficient of 0.81\pm0.07. The 3D and 2D diagnostic
networks were able to differentiate glaucoma from non-glaucoma subjects with
accuracies of 82.7% and 83.3%, respectively. The corresponding AUCs for CRVT&B
were 0.89 and 0.90, higher than those obtained with RNFL thickness alone.
Conclusions: Our work demonstrated that the diagnostic power of the CRVT&B is
superior to that of a gold-standard glaucoma parameter, i.e., RNFL thickness.
Our work also suggested that the major retinal blood vessels form a skeleton --
the configuration of which may be representative of major ONH structural
changes as typically observed with the development and progression of glaucoma.</p>
  </details>
</details>
<details>
  <summary>78. <b>标题：Explainable Deep Reinforcement Learning for Portfolio Management: An  Empirical Approach</b></summary>
  <p><b>编号</b>：[433]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03995</p>
  <p><b>作者</b>：Mao Guan,  Xiao-Yang Liu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：dow jones 30 constituent stocks, assuming knowing actual stock returns, portfolio management task, portfolio management task, portfolio management task</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep reinforcement learning (DRL) has been widely studied in the portfolio
management task. However, it is challenging to understand a DRL-based trading
strategy because of the black-box nature of deep neural networks. In this
paper, we propose an empirical approach to explain the strategies of DRL agents
for the portfolio management task. First, we use a linear model in hindsight as
the reference model, which finds the best portfolio weights by assuming knowing
actual stock returns in foresight. In particular, we use the coefficients of a
linear model in hindsight as the reference feature weights. Secondly, for DRL
agents, we use integrated gradients to define the feature weights, which are
the coefficients between reward and features under a linear regression model.
Thirdly, we study the prediction power in two cases, single-step prediction and
multi-step prediction. In particular, we quantify the prediction power by
calculating the linear correlations between the feature weights of a DRL agent
and the reference feature weights, and similarly for machine learning methods.
Finally, we evaluate a portfolio management task on Dow Jones 30 constituent
stocks during 01/01/2009 to 09/01/2021. Our approach empirically reveals that a
DRL agent exhibits a stronger multi-step prediction power than machine learning
methods.</p>
  </details>
</details>
<details>
  <summary>79. <b>标题：Multimodal PET/CT Tumour Segmentation and Prediction of Progression-Free  Survival using a Full-Scale UNet with Attention</b></summary>
  <p><b>编号</b>：[440]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03848</p>
  <p><b>作者</b>：Emmanuelle Bourigault,  Daniel R. McGowan,  Abolfazl Mehranian,  Bartłomiej W. Papież</p>
  <p><b>备注</b>：13 pages, 3 figures, 2 tables. To appear in Head and Neck Tumor Segmentation in PET/CT: The HECKTOR Challenge,Valentin Oreiller et al., Medical Image Analysis,2021, HECKTOR 2021, Lecture Notes in Computer Science, Springer</p>
  <p><b>关键词</b>：cox proportional hazard regression combining clinical, h \& n oropharyngeal cancer, patient progression free survival task, used conditional random fields, trained multiple neural networks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Segmentation of head and neck (H\&N) tumours and prediction of patient
outcome are crucial for patient's disease diagnosis and treatment monitoring.
Current developments of robust deep learning models are hindered by the lack of
large multi-centre, multi-modal data with quality annotations. The MICCAI 2021
HEad and neCK TumOR (HECKTOR) segmentation and outcome prediction challenge
creates a platform for comparing segmentation methods of the primary gross
target volume on fluoro-deoxyglucose (FDG)-PET and Computed Tomography images
and prediction of progression-free survival in H\&N oropharyngeal cancer.For
the segmentation task, we proposed a new network based on an encoder-decoder
architecture with full inter- and intra-skip connections to take advantage of
low-level and high-level semantics at full scales. Additionally, we used
Conditional Random Fields as a post-processing step to refine the predicted
segmentation maps. We trained multiple neural networks for tumor volume
segmentation, and these segmentations were ensembled achieving an average Dice
Similarity Coefficient of 0.75 in cross-validation, and 0.76 on the challenge
testing data set. For prediction of patient progression free survival task, we
propose a Cox proportional hazard regression combining clinical, radiomic, and
deep learning features. Our survival prediction model achieved a concordance
index of 0.82 in cross-validation, and 0.62 on the challenge testing data set.</p>
  </details>
</details>
<details>
  <summary>80. <b>标题：Artifact- and content-specific quality assessment for MRI with image  rulers</b></summary>
  <p><b>编号</b>：[445]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2111.03780</p>
  <p><b>作者</b>：Ke Lei,  John M. Pauly,  Shreyas S. Vasanawala</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：image rulers address varying quality standards, clinical practice mr images, best previous method examined, around 90 %, 6, image quality requirements vary</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In clinical practice MR images are often first seen by radiologists long
after the scan. If image quality is inadequate either patients have to return
for an additional scan, or a suboptimal interpretation is rendered. An
automatic image quality assessment (IQA) would enable real-time remediation.
Existing IQA works for MRI give only a general quality score, agnostic to the
cause of and solution to low-quality scans. Furthermore, radiologists' image
quality requirements vary with the scan type and diagnostic task. Therefore,
the same score may have different implications for different scans. We propose
a framework with multi-task CNN model trained with calibrated labels and
inferenced with image rulers. Labels calibrated by human inputs follow a
well-defined and efficient labeling task. Image rulers address varying quality
standards and provide a concrete way of interpreting raw scores from the CNN.
The model supports assessments of two of the most common artifacts in MRI:
noise and motion. It achieves accuracies of around 90%, 6% better than the best
previous method examined, and 3% better than human experts on noise assessment.
Our experiments show that label calibration, image rulers, and multi-task
training improve the model's performance and generalizability.</p>
  </details>
</details>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">徐耀彬</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://louishsu.xyz/2021/11/10/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html">http://louishsu.xyz/2021/11/10/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://louishsu.xyz" target="_blank">LOUIS' BLOG</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"></div><div class="post_share"><div class="social-share" data-image="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="next-post pull-full"><a href="/2021/05/19/%E5%85%A8%E7%90%83%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%8A%80%E6%9C%AF%E5%88%9B%E6%96%B0%E5%A4%A7%E8%B5%9B%E3%80%90%E8%B5%9B%E9%81%93%E4%B8%80%E3%80%91%EF%BC%9A%E5%8C%BB%E5%AD%A6%E5%BD%B1%E5%83%8F%E6%8A%A5%E5%91%8A%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B.html"><img class="next-cover" src="https://tianchi-public.oss-cn-hangzhou.aliyuncs.com/public/files/forum/161037709574435991610377095138.jpeg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">全球人工智能技术创新大赛【赛道一】：医学影像报告异常检测</div></div></a></div></nav><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="twikoo-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="card-info-avatar is-center"><img class="avatar-img" src="/img/touxiang.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/><div class="author-info__name">徐耀彬</div><div class="author-info__description">ᵕ᷄ ≀ ̠˘᷅ 永远年轻，永远热泪盈眶</div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">10</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">标签</div><div class="length-num">3</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">分类</div><div class="length-num">7</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/isLouisHsu"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/isLouisHsu" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:is.louishsu@foxmail.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>公告</span></div><div class="announcement_content">记录和分享一些学习和开源内容，若有问题可通过邮箱is.louishsu@foxmail.com联系，欢迎交流！！</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">1.</span> <span class="toc-text">统计</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">2.</span> <span class="toc-text">计算机视觉</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">3.</span> <span class="toc-text">自然语言处理</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">4.</span> <span class="toc-text">机器学习</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">5.</span> <span class="toc-text">人工智能</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2021/11/10/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html" title="Arxiv每日速递(2021-11-10)"><img src="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Arxiv每日速递(2021-11-10)"/></a><div class="content"><a class="title" href="/2021/11/10/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html" title="Arxiv每日速递(2021-11-10)">Arxiv每日速递(2021-11-10)</a><time datetime="2021-11-10T00:26:44.000Z" title="发表于 2021-11-10 08:26:44">2021-11-10</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/05/19/%E5%85%A8%E7%90%83%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%8A%80%E6%9C%AF%E5%88%9B%E6%96%B0%E5%A4%A7%E8%B5%9B%E3%80%90%E8%B5%9B%E9%81%93%E4%B8%80%E3%80%91%EF%BC%9A%E5%8C%BB%E5%AD%A6%E5%BD%B1%E5%83%8F%E6%8A%A5%E5%91%8A%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B.html" title="全球人工智能技术创新大赛【赛道一】：医学影像报告异常检测"><img src="https://tianchi-public.oss-cn-hangzhou.aliyuncs.com/public/files/forum/161037709574435991610377095138.jpeg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="全球人工智能技术创新大赛【赛道一】：医学影像报告异常检测"/></a><div class="content"><a class="title" href="/2021/05/19/%E5%85%A8%E7%90%83%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%8A%80%E6%9C%AF%E5%88%9B%E6%96%B0%E5%A4%A7%E8%B5%9B%E3%80%90%E8%B5%9B%E9%81%93%E4%B8%80%E3%80%91%EF%BC%9A%E5%8C%BB%E5%AD%A6%E5%BD%B1%E5%83%8F%E6%8A%A5%E5%91%8A%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B.html" title="全球人工智能技术创新大赛【赛道一】：医学影像报告异常检测">全球人工智能技术创新大赛【赛道一】：医学影像报告异常检测</a><time datetime="2021-05-19T09:57:06.000Z" title="发表于 2021-05-19 17:57:06">2021-05-19</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2020/09/16/%E8%AF%A6%E8%A7%A3%E5%91%BD%E5%90%8D%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB%E6%A8%A1%E5%9E%8B%EF%BC%9ALSTM-CRF.html" title="详解命名实体识别模型：LSTM-CRF"><img src="https://gimg2.baidu.com/image_search/src=http%3A%2F%2Fpic1.zhimg.com%2Fv2-1ed6a10dbb239a148e42df088c5870a6_1440w.jpg%3Fsource%3D172ae18b&amp;refer=http%3A%2F%2Fpic1.zhimg.com&amp;app=2002&amp;size=f9999,10000&amp;q=a80&amp;n=0&amp;g=0n&amp;fmt=jpeg?sec=1638183974&amp;t=4632f13fd487ed1cfcb12d67a6b71e52" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="详解命名实体识别模型：LSTM-CRF"/></a><div class="content"><a class="title" href="/2020/09/16/%E8%AF%A6%E8%A7%A3%E5%91%BD%E5%90%8D%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB%E6%A8%A1%E5%9E%8B%EF%BC%9ALSTM-CRF.html" title="详解命名实体识别模型：LSTM-CRF">详解命名实体识别模型：LSTM-CRF</a><time datetime="2020-09-16T09:26:44.000Z" title="发表于 2020-09-16 17:26:44">2020-09-16</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2020/06/14/%E8%AE%B0%E4%B8%80%E6%AC%A1MySQL%E8%A7%A3%E5%86%B3%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E6%97%B6%E7%9A%84%E5%88%86%E8%A1%A8%E9%97%AE%E9%A2%98.html" title="记一次MySQL解决大数据存储时的分表问题"><img src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="记一次MySQL解决大数据存储时的分表问题"/></a><div class="content"><a class="title" href="/2020/06/14/%E8%AE%B0%E4%B8%80%E6%AC%A1MySQL%E8%A7%A3%E5%86%B3%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E6%97%B6%E7%9A%84%E5%88%86%E8%A1%A8%E9%97%AE%E9%A2%98.html" title="记一次MySQL解决大数据存储时的分表问题">记一次MySQL解决大数据存储时的分表问题</a><time datetime="2020-06-14T15:24:27.000Z" title="发表于 2020-06-14 23:24:27">2020-06-14</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2020/05/05/grep-sed-awk.html" title="grep, sed, awk"><img src="https://img2.baidu.com/it/u=2210698206,229004679&amp;fm=15&amp;fmt=auto" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="grep, sed, awk"/></a><div class="content"><a class="title" href="/2020/05/05/grep-sed-awk.html" title="grep, sed, awk">grep, sed, awk</a><time datetime="2020-05-05T10:47:36.000Z" title="发表于 2020-05-05 18:47:36">2020-05-05</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2021 By 徐耀彬</div><div class="footer_custom_text"><p><a style="margin-inline:5px"target="_blank"href="https://hexo.io/"><img src="https://img.shields.io/badge/Frame-Hexo-blue?style=flat&logo=hexo"title="博客框架为Hexo"alt="img"></a><a style="margin-inline:5px"target="_blank"href="https://butterfly.js.org/"><img src="https://img.shields.io/badge/Theme-Butterfly-6513df?style=flat&logo=bitdefender"title="主题采用butterfly"alt="img"></a><a style="margin-inline:5px"target="_blank"href="https://www.jsdelivr.com/"><img src="https://img.shields.io/badge/CDN-jsDelivr-orange?style=flat&logo=jsDelivr"title="本站使用JsDelivr为静态资源提供CDN加速"alt="img"></a><a style="margin-inline:5px"target="_blank"href="https://github.com/"><img src="https://img.shields.io/badge/Source-Github-d021d6?style=flat&logo=GitHub"title="本站项目由Gtihub托管"alt="img"></a><a style="margin-inline:5px"target="_blank"href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img src="https://img.shields.io/badge/Copyright-BY--NC--SA%204.0-d42328?style=flat&logo=Claris"alt="img"title="本站采用知识共享署名-非商业性使用-相同方式共享4.0国际许可协议进行许可"></a></br></p></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="font-plus" type="button" title="放大字体"><i class="fas fa-plus"></i></button><button id="font-minus" type="button" title="缩小字体"><i class="fas fa-minus"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div></div><hr/><div id="local-search-results"></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.css"><script>(() => {
  document.querySelectorAll('#article-container span.katex-display').forEach(item => {
    btf.wrap(item, 'div', '', 'katex-wrap')
  })
})()</script><script>(()=>{
  const $countDom = document.getElementById('twikoo-count')
  const init = () => {
    let initData = {
      el: '#twikoo-wrap',
      envId: 'blog-',
      region: ''
    }

    if (false) {
      const otherData = false
      initData = Object.assign(initData, otherData)
    }
    
    twikoo.init(initData)
  }

  const getCount = () => {
    twikoo.getCommentsCount({
      envId: 'blog-',
      region: '',
      urls: [window.location.pathname],
      includeReply: false
    }).then(function (res) {
      $countDom.innerText = res[0].count
    }).catch(function (err) {
      console.error(err);
    });
  }

  const loadTwikoo = (bool = false) => {
    if (typeof twikoo === 'object') {
      init()
      bool && $countDom && setTimeout(getCount,0)
    } else {
      getScript('https://cdn.jsdelivr.net/npm/twikoo/dist/twikoo.all.min.js').then(()=> {
        init()
        bool && $countDom && setTimeout(getCount,0)
      })
    }
  }

  if ('Twikoo' === 'Twikoo' || !false) {
    if (false) btf.loadComment(document.getElementById('twikoo-wrap'), loadTwikoo)
    else loadTwikoo(true)
  } else {
    window.loadOtherComment = () => {
      loadTwikoo()
    }
  }
})()</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><!-- hexo injector body_end start --> <script data-pjax>if(document.getElementById('recent-posts') && (location.pathname ==='/'|| '/' ==='all')){
    var parent = document.getElementById('recent-posts');
    var child = '<div class="recent-post-item" style="width:100%;height: auto"><div id="catalog_magnet"><div class="magnet_item"><a class="magnet_link" href="http://louishsu.xyz/categories/机器学习/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🐱 机器学习 (1)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://louishsu.xyz/categories/自然语言处理/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">📚 自然语言处理 (1)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://louishsu.xyz/categories/竞赛相关/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🎮 竞赛相关 (1)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://louishsu.xyz/categories/阅读笔记/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🎮 阅读笔记 (1)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><a class="magnet_link_more"  href="http://louishsu.xyz/categories" style="flex:1;text-align: center;margin-bottom: 10px;">查看更多...</a></div></div>';
    console.log('已挂载magnet')
    parent.insertAdjacentHTML("afterbegin",child)}
     </script><style>#catalog_magnet{flex-wrap: wrap;display: flex;width:100%;justify-content:space-between;padding: 10px 10px 0 10px;align-content: flex-start;}.magnet_item{flex-basis: calc(50% - 5px);background: #f2f2f2;margin-bottom: 10px;border-radius: 8px;transition: all 0.2s ease-in-out;}.magnet_item:hover{background: #b30070}.magnet_link_more{color:#555}.magnet_link{color:black}.magnet_link:hover{color:white}@media screen and (max-width: 600px) {.magnet_item {flex-basis: 100%;}}.magnet_link_context{display:flex;padding: 10px;font-size:16px;transition: all 0.2s ease-in-out;}.magnet_link_context:hover{padding: 10px 20px;}</style>
    <style></style>
  <script data-pjax src="https://cdn.jsdelivr.net/gh/Zfour/hexo-github-calendar@1.21/hexo_githubcalendar.js"></script>
  <script data-pjax>
        function GithubCalendarConfig(){
            var git_githubapiurl ="https://python-github-calendar-api.vercel.app/api?isLouisHsu";
            var git_color =['#ebedf0', '#fdcdec', '#fc9bd9', '#fa6ac5', '#f838b2', '#f5089f', '#c4067e', '#92055e', '#540336', '#48022f', '#30021f'];
            var git_user ="isLouisHsu";
            var parent_div_git = document.getElementById('recent-posts');
            var git_div_html = '<div class="recent-post-item" style="width:100%;height:auto;padding:10px;"><div id="github_loading" style="width:10%;height:100%;margin:0 auto;display: block"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"  viewBox="0 0 50 50" style="enable-background:new 0 0 50 50" xml:space="preserve"><path fill="#d0d0d0" d="M25.251,6.461c-10.318,0-18.683,8.365-18.683,18.683h4.068c0-8.071,6.543-14.615,14.615-14.615V6.461z" transform="rotate(275.098 25 25)"><animateTransform attributeType="xml" attributeName="transform" type="rotate" from="0 25 25" to="360 25 25" dur="0.6s" repeatCount="indefinite"></animateTransform></path></svg></div><div id="github_container"></div></div>';
            if(parent_div_git && location.pathname =='/'){
                console.log('已挂载github calendar')
                // parent_div_git.innerHTML=git_div_html+parent_div_git.innerHTML // 无报错，但不影响使用(支持pjax跳转)
                parent_div_git.insertAdjacentHTML("afterbegin",git_div_html) // 有报错，但不影响使用(支持pjax跳转)
            };
            GithubCalendar(git_githubapiurl,git_color,git_user)
        }
        if(document.getElementById('recent-posts')){
            GithubCalendarConfig()
        }
    </script>
    <style>#github_container{min-height:280px}@media screen and (max-width:650px) {#github_container{background-image:;min-height:0px}}</style>
    <style></style><script data-pjax>function electric_clock_injector_config(){
                var parent_div_git = document.getElementsByClassName('sticky_layout')[0];
                var item_html = '<div class="card-widget card-clock"><div class="card-glass"><div class="card-background"><div class="card-content"><div id="hexo_electric_clock"><img id="card-clock-loading" src="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-clock/clock/images/weather/loading.gif" style="height: 120px; width: 100%;" data-ll-status="loading" class="entered loading"></div></div></div></div></div>';
                console.log('已挂载electric_clock')
                // parent_div_git.innerHTML=item_html+parent_div_git.innerHTML // 无报错，但不影响使用(支持pjax跳转)
                parent_div_git.insertAdjacentHTML("afterbegin",item_html) // 有报错，但不影响使用(支持pjax跳转)
            }if( document.getElementsByClassName('sticky_layout')[0] && (location.pathname ==='all'|| 'all' ==='all')){

            electric_clock_injector_config()
        } </script><script src="https://pv.sohu.com/cityjson?ie=utf-8"></script><script data-pjax  src="https://cdn.jsdelivr.net/gh/Zfour/hexo-electric-clock@1.0.6/clock.js"></script><!-- hexo injector body_end end --><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"model":{"jsonPath":"/live2dw/assets/hijiki.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":false},"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body></html>