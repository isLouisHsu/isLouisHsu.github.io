<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Arxiv每日速递(2022-01-21) | LOUIS' BLOG</title><meta name="author" content="徐耀彬"><meta name="copyright" content="徐耀彬"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="本篇博文主要展示每日从Arxiv论文网站获取的最新论文列表，以计算机视觉、自然语言处理、机器学习、人工智能等大方向进行划分。 统计 今日共更新244篇论文，其中：  43篇计算机视觉（cs.CV） 18篇自然语言处理（cs.CL） 75篇机器学习（cs.LG） 34篇人工智能（cs.AI）  计算机视觉    1. 标题：ConDor: Self-Supervised Canonicalizati">
<meta property="og:type" content="article">
<meta property="og:title" content="Arxiv每日速递(2022-01-21)">
<meta property="og:url" content="http://louishsu.xyz/2022/01/21/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html">
<meta property="og:site_name" content="LOUIS&#39; BLOG">
<meta property="og:description" content="本篇博文主要展示每日从Arxiv论文网站获取的最新论文列表，以计算机视觉、自然语言处理、机器学习、人工智能等大方向进行划分。 统计 今日共更新244篇论文，其中：  43篇计算机视觉（cs.CV） 18篇自然语言处理（cs.CL） 75篇机器学习（cs.LG） 34篇人工智能（cs.AI）  计算机视觉    1. 标题：ConDor: Self-Supervised Canonicalizati">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png">
<meta property="article:published_time" content="2022-01-21T00:25:01.058Z">
<meta property="article:modified_time" content="2022-01-21T00:26:34.411Z">
<meta property="article:author" content="徐耀彬">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://louishsu.xyz/2022/01/21/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2022-01-21 08:26:34'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const fontSizeVal = saveToLocal.get('global-font-size')
    if (fontSizeVal !== undefined) {
      document.documentElement.style.setProperty('--global-font-size', fontSizeVal + 'px')
    }
    })(window)</script><link rel="stylesheet" href="/css/background.css"><script src="https://cdn.jsdelivr.net/npm/echarts@4.7.0/dist/echarts.min.js"></script><!-- hexo injector head_end start --><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Zfour/hexo-electric-clock@1.0.6/clock.css"><!-- hexo injector head_end end --><meta name="generator" content="Hexo 5.4.0"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="author-avatar"><img class="avatar-img" src="/img/touxiang.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">11</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">标签</div><div class="length-num">3</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">分类</div><div class="length-num">7</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/message/"><i class="fa-fw far fa-comment-dots"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa-fw fa fa-book"></i><span> 找文章</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></li><li><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></li><li><a class="site-page" href="/charts/"><i class="fa-fw fa fa-archive"></i><span> 统计</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-tools"></i><span> 工具</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/md_editor/"><i class="fa-fw fas fa-pen"></i><span> 在线markdown</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/isLouisHsu/blog/tree/master/source/_posts"><i class="fa-fw fa fa-star"></i><span> 在线push</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">LOUIS' BLOG</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/message/"><i class="fa-fw far fa-comment-dots"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa-fw fa fa-book"></i><span> 找文章</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></li><li><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></li><li><a class="site-page" href="/charts/"><i class="fa-fw fa fa-archive"></i><span> 统计</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-tools"></i><span> 工具</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/md_editor/"><i class="fa-fw fas fa-pen"></i><span> 在线markdown</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/isLouisHsu/blog/tree/master/source/_posts"><i class="fa-fw fa fa-star"></i><span> 在线push</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Arxiv每日速递(2022-01-21)<a class="post-edit-link" href="https://github.com/isLouisHsu/blog/tree/master/source_posts/Arxiv每日速递.md" title="编辑" target="_blank"><i class="fas fa-pencil-square"></i></a></h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-01-21T00:25:01.058Z" title="发表于 2022-01-21 08:25:01">2022-01-21</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2022-01-21T00:26:34.411Z" title="更新于 2022-01-21 08:26:34">2022-01-21</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">阅读笔记</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">33k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>197分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span><span class="post-meta-separator">|</span><span class="post-meta-commentcount"><i class="far fa-comments fa-fw post-meta-icon"></i><span class="post-meta-label">评论数:</span><a href="/2022/01/21/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html#post-comment"><span id="twikoo-count"></span></a></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><p>本篇博文主要展示每日从Arxiv论文网站获取的最新论文列表，以计算机视觉、自然语言处理、机器学习、人工智能等大方向进行划分。</p>
<h1>统计</h1>
<p>今日共更新244篇论文，其中：</p>
<ul>
<li>43篇计算机视觉（<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>）</li>
<li>18篇自然语言处理（<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>）</li>
<li>75篇机器学习（cs.LG）</li>
<li>34篇人工智能（<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>）</li>
</ul>
<h1>计算机视觉</h1>
<details>
  <summary>1. <b>标题：ConDor: Self-Supervised Canonicalization of 3D Pose for Partial Shapes</b></summary>
  <p><b>编号</b>：[1]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07788</p>
  <p><b>作者</b>：Rahul Sajnani,  Adrien Poulenard,  Jivitesh Jain,  Radhika Dua,  Leonidas J. Guibas,  Srinath Sridhar</p>
  <p><b>备注</b>：Preprint. For project page and code, see this https URL</p>
  <p><b>关键词</b>：segment object parts without, four new metrics show, partial 3d point clouds, partial 3d point clouds, partial 3d point cloud</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Progress in 3D object understanding has relied on manually canonicalized
shape datasets that contain instances with consistent position and orientation
(3D pose). This has made it hard to generalize these methods to in-the-wild
shapes, eg., from internet model collections or depth sensors. ConDor is a
self-supervised method that learns to Canonicalize the 3D orientation and
position for full and partial 3D point clouds. We build on top of Tensor Field
Networks (TFNs), a class of permutation- and rotation-equivariant, and
translation-invariant 3D networks. During inference, our method takes an unseen
full or partial 3D point cloud at an arbitrary pose and outputs an equivariant
canonical pose. During training, this network uses self-supervision losses to
learn the canonical pose from an un-canonicalized collection of full and
partial 3D point clouds. ConDor can also learn to consistently co-segment
object parts without any supervision. Extensive quantitative results on four
new metrics show that our approach outperforms existing methods while enabling
new applications such as operation on depth images and annotation transfer.</p>
  </details>
</details>
<details>
  <summary>2. <b>标题：Towards a General Deep Feature Extractor for Facial Expression  Recognition</b></summary>
  <p><b>编号</b>：[4]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07781</p>
  <p><b>作者</b>：Liam Schoneveld,  Alice Othmani</p>
  <p><b>备注</b>：Published in: 2021 IEEE International Conference on Image Processing (ICIP). arXiv admin note: text overlap with arXiv:2103.09154</p>
  <p><b>关键词</b>：models often lack generalisation ability across datasets, extracted features also generalise extremely well, visual feature extractor general enough, google facial expression comparison datasets, end trained deep neural networks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The human face conveys a significant amount of information. Through facial
expressions, the face is able to communicate numerous sentiments without the
need for verbalisation. Visual emotion recognition has been extensively
studied. Recently several end-to-end trained deep neural networks have been
proposed for this task. However, such models often lack generalisation ability
across datasets. In this paper, we propose the Deep Facial Expression Vector
ExtractoR (DeepFEVER), a new deep learning-based approach that learns a visual
feature extractor general enough to be applied to any other facial emotion
recognition task or dataset. DeepFEVER outperforms state-of-the-art results on
the AffectNet and Google Facial Expression Comparison datasets. DeepFEVER's
extracted features also generalise extremely well to other datasets -- even
those unseen during training -- namely, the Real-World Affective Faces (RAF)
dataset.</p>
  </details>
</details>
<details>
  <summary>3. <b>标题：Look Closer: Bridging Egocentric and Third-Person Views with  Transformers for Robotic Manipulation</b></summary>
  <p><b>编号</b>：[5]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07779</p>
  <p><b>作者</b>：Rishabh Jangir,  Nicklas Hansen,  Sambaral Ghosal,  Mohit Jain,  Xiaolong Wang</p>
  <p><b>备注</b>：Accepted in Robotics and Automation Letters Journal (RA-L 2022). Website at this https URL 8 Pages</p>
  <p><b>关键词</b>：visual feedback using reinforcement learning, agent receives visual feedback, visual inputs alone, fuse visual information, trials versus 38</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Learning to solve precision-based manipulation tasks from visual feedback
using Reinforcement Learning (RL) could drastically reduce the engineering
efforts required by traditional robot systems. However, performing fine-grained
motor control from visual inputs alone is challenging, especially with a static
third-person camera as often used in previous work. We propose a setting for
robotic manipulation in which the agent receives visual feedback from both a
third-person camera and an egocentric camera mounted on the robot's wrist.
While the third-person camera is static, the egocentric camera enables the
robot to actively control its vision to aid in precise manipulation. To fuse
visual information from both cameras effectively, we additionally propose to
use Transformers with a cross-view attention mechanism that models spatial
attention from one view to another (and vice-versa), and use the learned
features as input to an RL policy. Our method improves learning over strong
single-view and multi-view baselines, and successfully transfers to a set of
challenging manipulation tasks on a real robot with uncalibrated cameras, no
access to state information, and a high degree of task variability. In a hammer
manipulation task, our method succeeds in 75% of trials versus 38% and 13% for
multi-view and single-view baselines, respectively.</p>
  </details>
</details>
<details>
  <summary>4. <b>标题：A pipeline for automated processing of Corona KH-4 (1962-1972) stereo  imagery</b></summary>
  <p><b>编号</b>：[10]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07756</p>
  <p><b>作者</b>：Sajid Ghuffar,  Tobias Bolch,  Ewelina Rupnik,  Atanu Bhattacharya</p>
  <p><b>备注</b>：24 Pages, 16 Figures</p>
  <p><b>关键词</b>：deep learning based feature matcher superglue, compute long term glacier elevation changes, corona dem computed using cosp achieved, time dependent exterior orientation parameters, complex scenes involving high relief</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The Corona KH-4 reconnaissance satellite missions from 1962-1972 acquired
panoramic stereo imagery with high spatial resolution of 1.8-7.5 m. The
potential of 800,000+ declassified Corona images has not been leveraged due to
the complexities arising from handling of panoramic imaging geometry, film
distortions and limited availability of the metadata required for
georeferencing of the Corona imagery. This paper presents Corona Stereo
Pipeline (CoSP): A pipeline for processing of Corona KH-4 stereo panoramic
imagery. CoSP utlizes a deep learning based feature matcher SuperGlue to
automatically match features point between Corona KH-4 images and recent
satellite imagery to generate Ground Control Points (GCPs). To model the
imaging geometry and the scanning motion of the panoramic KH-4 cameras, a
rigorous camera model consisting of modified collinearity equations with time
dependent exterior orientation parameters is employed. The results show that
using the entire frame of the Corona image, bundle adjustment using
well-distributed GCPs results in an average standard deviation (SD) of less
than 2 pixels. The distortion pattern of image residuals of GCPs and y-parallax
in epipolar resampled images suggest that film distortions due to long term
storage as likely cause of systematic deviations. Compared to the SRTM DEM, the
Corona DEM computed using CoSP achieved a Normalized Median Absolute Deviation
(NMAD) of elevation differences of ~4 m over an area of approx. 4000 $km^2$. We
show that the proposed pipeline can be applied to sequence of complex scenes
involving high relief and glacierized terrain and that the resulting DEMs can
be used to compute long term glacier elevation changes over large areas.</p>
  </details>
</details>
<details>
  <summary>5. <b>标题：Towards holistic scene understanding: Semantic segmentation and beyond</b></summary>
  <p><b>编号</b>：[22]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07734</p>
  <p><b>作者</b>：Panagiotis Meletis</p>
  <p><b>备注</b>：PhD Thesis, Eindhoven University of Technology, October 2021</p>
  <p><b>关键词</b>：ecological footprint without sacrificing performance, dissertation addresses visual scene understanding, reasoning towards holistic scene understanding, exploiting various scene understanding datasets, sustainable visual scene understanding</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This dissertation addresses visual scene understanding and enhances
segmentation performance and generalization, training efficiency of networks,
and holistic understanding. First, we investigate semantic segmentation in the
context of street scenes and train semantic segmentation networks on
combinations of various datasets. In Chapter 2 we design a framework of
hierarchical classifiers over a single convolutional backbone, and train it
end-to-end on a combination of pixel-labeled datasets, improving
generalizability and the number of recognizable semantic concepts. Chapter 3
focuses on enriching semantic segmentation with weak supervision and proposes a
weakly-supervised algorithm for training with bounding box-level and
image-level supervision instead of only with per-pixel supervision. The memory
and computational load challenges that arise from simultaneous training on
multiple datasets are addressed in Chapter 4. We propose two methodologies for
selecting informative and diverse samples from datasets with weak supervision
to reduce our networks' ecological footprint without sacrificing performance.
Motivated by memory and computation efficiency requirements, in Chapter 5, we
rethink simultaneous training on heterogeneous datasets and propose a universal
semantic segmentation framework. This framework achieves consistent increases
in performance metrics and semantic knowledgeability by exploiting various
scene understanding datasets. Chapter 6 introduces the novel task of part-aware
panoptic segmentation, which extends our reasoning towards holistic scene
understanding. This task combines scene and parts-level semantics with
instance-level object detection. In conclusion, our contributions span over
convolutional network architectures, weakly-supervised learning, part and
panoptic segmentation, paving the way towards a holistic, rich, and sustainable
visual scene understanding.</p>
  </details>
</details>
<details>
  <summary>6. <b>标题：Object Detection in Autonomous Vehicles: Status and Open Challenges</b></summary>
  <p><b>编号</b>：[35]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07706</p>
  <p><b>作者</b>：Abhishek Balasubramaniam,  Sudeep Pasricha</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：perception system uses object detection algorithms, many consumer applications today, based object detectors play, robust driving performance, mobile text recognition</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Object detection is a computer vision task that has become an integral part
of many consumer applications today such as surveillance and security systems,
mobile text recognition, and diagnosing diseases from MRI/CT scans. Object
detection is also one of the critical components to support autonomous driving.
Autonomous vehicles rely on the perception of their surroundings to ensure safe
and robust driving performance. This perception system uses object detection
algorithms to accurately determine objects such as pedestrians, vehicles,
traffic signs, and barriers in the vehicle's vicinity. Deep learning-based
object detectors play a vital role in finding and localizing these objects in
real-time. This article discusses the state-of-the-art in object detectors and
open challenges for their integration into autonomous vehicles.</p>
  </details>
</details>
<details>
  <summary>7. <b>标题：Q-ViT: Fully Differentiable Quantization for Vision Transformer</b></summary>
  <p><b>编号</b>：[37]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07703</p>
  <p><b>作者</b>：Zhexin Li,  Tong Yang,  Peisong Wang,  Jian Cheng</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：novel technique named switchable scale, bit without heavy performance drop, vit display different quantization robustness, gaussian error linear units, fully differentiable quantization method</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we propose a fully differentiable quantization method for
vision transformer (ViT) named as Q-ViT, in which both of the quantization
scales and bit-widths are learnable parameters. Specifically, based on our
observation that heads in ViT display different quantization robustness, we
leverage head-wise bit-width to squeeze the size of Q-ViT while preserving
performance. In addition, we propose a novel technique named switchable scale
to resolve the convergence problem in the joint training of quantization scales
and bit-widths. In this way, Q-ViT pushes the limits of ViT quantization to
3-bit without heavy performance drop. Moreover, we analyze the quantization
robustness of every architecture component of ViT and show that the Multi-head
Self-Attention (MSA) and the Gaussian Error Linear Units (GELU) are the key
aspects for ViT quantization. This study provides some insights for further
research about ViT quantization. Extensive experiments on different ViT models,
such as DeiT and Swin Transformer show the effectiveness of our quantization
method. In particular, our method outperforms the state-of-the-art uniform
quantization method by 1.5% on DeiT-Tiny.</p>
  </details>
</details>
<details>
  <summary>8. <b>标题：Visualization and Analysis of Wearable Health Data From COVID-19  Patients</b></summary>
  <p><b>编号</b>：[40]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07698</p>
  <p><b>作者</b>：Susanne K. Suter,  Georg R. Spinner,  Bianca Hoelz,  Sofia Rey,  Sujeanthraa Thanabalasingam,  Jens Eckstein,  Sven Hirsch</p>
  <p><b>备注</b>：17 pages, 9 figures, conference</p>
  <p><b>关键词</b>：specifically highlight medically relevant patterns, seven health data science researchers, fluctuating data quality resulting, reveal relevant health patterns, relevant health patterns visible</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Effective visualizations were evaluated to reveal relevant health patterns
from multi-sensor real-time wearable devices that recorded vital signs from
patients admitted to hospital with COVID-19. Furthermore, specific challenges
associated with wearable health data visualizations, such as fluctuating data
quality resulting from compliance problems, time needed to charge the device
and technical problems are described. As a primary use case, we examined the
detection and communication of relevant health patterns visible in the vital
signs acquired by the technology. Customized heat maps and bar charts were used
to specifically highlight medically relevant patterns in vital signs. A survey
of two medical doctors, one clinical project manager and seven health data
science researchers was conducted to evaluate the visualization methods. From a
dataset of 84 hospitalized COVID-19 patients, we extracted one typical COVID-19
patient history and based on the visualizations showcased the health history of
two noteworthy patients. The visualizations were shown to be effective, simple
and intuitive in deducing the health status of patients. For clinical staff who
are time-constrained and responsible for numerous patients, such visualization
methods can be an effective tool to enable continuous acquisition and
monitoring of patients' health statuses even remotely.</p>
  </details>
</details>
<details>
  <summary>9. <b>标题：GroupGazer: A Tool to Compute the Gaze per Participant in Groups with  integrated Calibration to Map the Gaze Online to a Screen or Beamer  Projection</b></summary>
  <p><b>编号</b>：[43]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07692</p>
  <p><b>作者</b>：Wolfgang Fuhl</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：operating system windows, every single person, specific gaze direction, gaze direction, gaze direction</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper we present GroupGaze. It is a tool that can be used to
calculate the gaze direction and the gaze position of whole groups. GroupGazer
calculates the gaze direction of every single person in the image and allows to
map these gaze vectors to a projection like a projector. In addition to the
person-specific gaze direction, the person affiliation of each gaze vector is
stored based on the position in the image. Also, it is possible to save the
group attention after a calibration. The software is free to use and requires a
simple webcam as well as an NVIDIA GPU and the operating system Windows or
Linux.</p>
  </details>
</details>
<details>
  <summary>10. <b>标题：Neighborhood Spatial Aggregation MC Dropout for Efficient  Uncertainty-aware Semantic Segmentation in Point Clouds</b></summary>
  <p><b>编号</b>：[46]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07676</p>
  <p><b>作者</b>：Chao Qi,  Jianqin Yin</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：samples using multiple stochastic forward propagations, framework obtains better segmentation results, point clouds containing massive points, aggregating stochastic inference results, used mc dropout establishes</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Uncertainty-aware semantic segmentation of the point clouds includes the
predictive uncertainty estimation and the uncertainty-guided model
optimization. One key challenge in the task is the efficiency of point-wise
predictive distribution establishment. The widely-used MC dropout establishes
the distribution by computing the standard deviation of samples using multiple
stochastic forward propagations, which is time-consuming for tasks based on
point clouds containing massive points. Hence, a framework embedded with NSA-MC
dropout, a variant of MC dropout, is proposed to establish distributions in
just one forward pass. Specifically, the NSA-MC dropout samples the model many
times through a space-dependent way, outputting point-wise distribution by
aggregating stochastic inference results of neighbors. Based on this, aleatoric
and predictive uncertainties acquire from the predictive distribution. The
aleatoric uncertainty is integrated into the loss function to penalize noisy
points, avoiding the over-fitting of the model to some degree. Besides, the
predictive uncertainty quantifies the confidence degree of predictions.
Experimental results show that our framework obtains better segmentation
results of real-world point clouds and efficiently quantifies the credibility
of results. Our NSA-MC dropout is several times faster than MC dropout, and the
inference time does not establish a coupling relation with the sampling times.
The code will be available if the paper is accepted.</p>
  </details>
</details>
<details>
  <summary>11. <b>标题：Semi-automatic 3D Object Keypoint Annotation and Detection for the  Masses</b></summary>
  <p><b>编号</b>：[51]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07665</p>
  <p><b>作者</b>：Kenneth Blomqvist,  Jen Jen Chung,  Lionel Ott,  Roland Siegwart</p>
  <p><b>备注</b>：Code: this https URL</p>
  <p><b>关键词</b>：creating computer vision datasets requires careful planning, working 3d object keypoint detector, full object keypoint tracking toolkit, based computer vision methods, ycb object set</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Creating computer vision datasets requires careful planning and lots of time
and effort. In robotics research, we often have to use standardized objects,
such as the YCB object set, for tasks such as object tracking, pose estimation,
grasping and manipulation, as there are datasets and pre-learned methods
available for these objects. This limits the impact of our research since
learning-based computer vision methods can only be used in scenarios that are
supported by existing datasets.
In this work, we present a full object keypoint tracking toolkit,
encompassing the entire process from data collection, labeling, model learning
and evaluation. We present a semi-automatic way of collecting and labeling
datasets using a wrist mounted camera on a standard robotic arm. Using our
toolkit and method, we are able to obtain a working 3D object keypoint detector
and go through the whole process of data collection, annotation and learning in
just a couple hours of active time.</p>
  </details>
</details>
<details>
  <summary>12. <b>标题：Open Source Handwritten Text Recognition on Medieval Manuscripts using  Mixed Models and Document-Specific Finetuning</b></summary>
  <p><b>编号</b>：[52]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07661</p>
  <p><b>作者</b>：Christian Reul,  Stefan Tomasek,  Florian Langhanki,  Uwe Springmann</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：two widely used handwriting styles, open source handwritten text recognition, average character error rate, four unseen manuscripts resulted, construct mixed recognition models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper deals with the task of practical and open source Handwritten Text
Recognition (HTR) on German medieval manuscripts. We report on our efforts to
construct mixed recognition models which can be applied out-of-the-box without
any further document-specific training but also serve as a starting point for
finetuning by training a new model on a few pages of transcribed text (ground
truth). To train the mixed models we collected a corpus of 35 manuscripts and
ca. 12.5k text lines for two widely used handwriting styles, Gothic and
Bastarda cursives. Evaluating the mixed models out-of-the-box on four unseen
manuscripts resulted in an average Character Error Rate (CER) of 6.22%. After
training on 2, 4 and eventually 32 pages the CER dropped to 3.27%, 2.58%, and
1.65%, respectively. While the in-domain recognition and training of models
(Bastarda model to Bastarda material, Gothic to Gothic) unsurprisingly yielded
the best results, finetuning out-of-domain models to unseen scripts was still
shown to be superior to training from scratch.
Our new mixed models have been made openly available to the community.</p>
  </details>
</details>
<details>
  <summary>13. <b>标题：A Survey on Training Challenges in Generative Adversarial Networks for  Biomedical Image Analysis</b></summary>
  <p><b>编号</b>：[58]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07646</p>
  <p><b>作者</b>：Muhammad Muneeb Saad,  Ruairi O'Reilly,  Mubashir Husain Rehmani</p>
  <p><b>备注</b>：Submitted to the Journal</p>
  <p><b>关键词</b>：vanishing gradient problem whereby unstable training behavior occurs due, deep learning models requiring large image datasets, discriminator achieving optimal classification performance resulting, mode collapse problem whereby, gradient descent optimizer fails</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In biomedical image analysis, the applicability of deep learning methods is
directly impacted by the quantity of image data available. This is due to deep
learning models requiring large image datasets to provide high-level
performance. Generative Adversarial Networks (GANs) have been widely utilized
to address data limitations through the generation of synthetic biomedical
images. GANs consist of two models. The generator, a model that learns how to
produce synthetic images based on the feedback it receives. The discriminator,
a model that classifies an image as synthetic or real and provides feedback to
the generator. Throughout the training process, a GAN can experience several
technical challenges that impede the generation of suitable synthetic imagery.
First, the mode collapse problem whereby the generator either produces an
identical image or produces a uniform image from distinct input features.
Second, the non-convergence problem whereby the gradient descent optimizer
fails to reach a Nash equilibrium. Thirdly, the vanishing gradient problem
whereby unstable training behavior occurs due to the discriminator achieving
optimal classification performance resulting in no meaningful feedback being
provided to the generator. These problems result in the production of synthetic
imagery that is blurry, unrealistic, and less diverse. To date, there has been
no survey article outlining the impact of these technical challenges in the
context of the biomedical imagery domain. This work presents a review and
taxonomy based on solutions to the training problems of GANs in the biomedical
imaging domain. This survey highlights important challenges and outlines future
research directions about the training of GANs in the domain of biomedical
imagery.</p>
  </details>
</details>
<details>
  <summary>14. <b>标题：CAST: Character labeling in Animation using Self-supervision by Tracking</b></summary>
  <p><b>编号</b>：[65]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07619</p>
  <p><b>作者</b>：Oron Nir,  Gal Rapoport,  Ariel Shamir</p>
  <p><b>备注</b>：Published as a conference paper at EuroGraphics 2022</p>
  <p><b>关键词</b>：refined semantic space allows better clustering, learning solutions often fail, semantic representation suitable, little user effort, different characteristics compared</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Cartoons and animation domain videos have very different characteristics
compared to real-life images and videos. In addition, this domain carries a
large variability in styles. Current computer vision and deep-learning
solutions often fail on animated content because they were trained on natural
images. In this paper we present a method to refine a semantic representation
suitable for specific animated content. We first train a neural network on a
large-scale set of animation videos and use the mapping to deep features as an
embedding space. Next, we use self-supervision to refine the representation for
any specific animation style by gathering many examples of animated characters
in this style, using a multi-object tracking. These examples are used to define
triplets for contrastive loss training. The refined semantic space allows
better clustering of animated characters even when they have diverse
manifestations. Using this space we can build dictionaries of characters in an
animation videos, and define specialized classifiers for specific stylistic
content (e.g., characters in a specific animation series) with very little user
effort. These classifiers are the basis for automatically labeling characters
in animation videos. We present results on a collection of characters in a
variety of animation styles.</p>
  </details>
</details>
<details>
  <summary>15. <b>标题：A Confidence-based Iterative Solver of Depths and Surface Normals for  Deep Multi-view Stereo</b></summary>
  <p><b>编号</b>：[69]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07609</p>
  <p><b>作者</b>：Wang Zhao,  Shaohui Liu,  Yi Wei,  Hengkai Guo,  Yong-Jin Liu</p>
  <p><b>备注</b>：17 pages, 13 figures, 7 tables. ICCV 2021</p>
  <p><b>关键词</b>：view stereo system employs multiple optimization steps, matching pixels within poorly textured regions, deep learning based mvs pipelines, scenes v2 demonstrate state, volume based neural network</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we introduce a deep multi-view stereo (MVS) system that
jointly predicts depths, surface normals and per-view confidence maps. The key
to our approach is a novel solver that iteratively solves for per-view depth
map and normal map by optimizing an energy potential based on the locally
planar assumption. Specifically, the algorithm updates depth map by propagating
from neighboring pixels with slanted planes, and updates normal map with local
probabilistic plane fitting. Both two steps are monitored by a customized
confidence map. This solver is not only effective as a post-processing tool for
plane-based depth refinement and completion, but also differentiable such that
it can be efficiently integrated into deep learning pipelines. Our multi-view
stereo system employs multiple optimization steps of the solver over the
initial prediction of depths and surface normals. The whole system can be
trained end-to-end, decoupling the challenging problem of matching pixels
within poorly textured regions from the cost-volume based neural network.
Experimental results on ScanNet and RGB-D Scenes V2 demonstrate
state-of-the-art performance of the proposed deep MVS system on multi-view
depth estimation, with our proposed solver consistently improving the depth
quality over both conventional and deep learning based MVS pipelines. Code is
available at this https URL.</p>
  </details>
</details>
<details>
  <summary>16. <b>标题：Real-time Recognition of Yoga Poses using computer Vision for Smart  Health Care</b></summary>
  <p><b>编号</b>：[77]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07594</p>
  <p><b>作者</b>：Abhishek Sharma,  Yash Shah,  Yash Agrawal,  Prateek Jain</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：assistance based yoga posture identification technique, also contain 5 mudras, include 10 yoga postures, contains around 500 images, work also presents yoga</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Nowadays, yoga has become a part of life for many people. Exercises and
sports technological assistance is implemented in yoga pose identification. In
this work, a self-assistance based yoga posture identification technique is
developed, which helps users to perform Yoga with the correction feature in
Real-time. The work also presents Yoga-hand mudra (hand gestures)
identification. The YOGI dataset has been developed which include 10 Yoga
postures with around 400-900 images of each pose and also contain 5 mudras for
identification of mudras postures. It contains around 500 images of each mudra.
The feature has been extracted by making a skeleton on the body for yoga poses
and hand for mudra poses. Two different algorithms have been used for creating
a skeleton one for yoga poses and the second for hand mudras. Angles of the
joints have been extracted as a features for different machine learning and
deep learning models. among all the models XGBoost with RandomSearch CV is most
accurate and gives 99.2\% accuracy. The complete design framework is described
in the present paper.</p>
  </details>
</details>
<details>
  <summary>17. <b>标题：DMF-Net: Dual-Branch Multi-Scale Feature Fusion Network for copy forgery  identification of anti-counterfeiting QR code</b></summary>
  <p><b>编号</b>：[80]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07583</p>
  <p><b>作者</b>：Zhongyuan Guo,  Hong Zheng,  Changhui You,  Tianyu Wang,  Chang Liu</p>
  <p><b>备注</b>：17 pages, 6 figures</p>
  <p><b>关键词</b>：scale feature fusion network, scale feature fusion network, counterfeiting qr code based, counterfeiting qr code, counterfeiting qr code</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Anti-counterfeiting QR codes are widely used in people's work and life,
especially in product packaging. However, the anti-counterfeiting QR code has
the risk of being copied and forged in the circulation process. In reality,
copying is usually based on genuine anti-counterfeiting QR codes, but the
brands and models of copiers are diverse, and it is extremely difficult to
determine which individual copier the forged anti-counterfeiting code come
from. In response to the above problems, this paper proposes a method for copy
forgery identification of anti-counterfeiting QR code based on deep learning.
We first analyze the production principle of anti-counterfeiting QR code, and
convert the identification of copy forgery to device category forensics, and
then a Dual-Branch Multi-Scale Feature Fusion network is proposed. During the
design of the network, we conducted a detailed analysis of the data
preprocessing layer, single-branch design, etc., combined with experiments, the
specific structure of the dual-branch multi-scale feature fusion network is
determined. The experimental results show that the proposed method has achieved
a high accuracy of copy forgery identification, which exceeds the current
series of methods in the field of image forensics.</p>
  </details>
</details>
<details>
  <summary>18. <b>标题：Superpixel Pre-Segmentation of HER2 Slides for Efficient Annotation</b></summary>
  <p><b>编号</b>：[83]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07572</p>
  <p><b>作者</b>：Mathias Öttl,  Jana Mönius,  Christian Marzahl,  Matthias Rübner,  Carol I. Geppert,  Arndt Hartmann,  Matthias W. Beckmann,  Peter Fasching,  Andreas Maier,  Ramona Erber,  Katharina Breininger</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：medical image segmentation across different applications, evaluations show encouraging first results, standard simple linear iterative clustering, boundary f1 score increases, efficient manual refinement without</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Supervised deep learning has shown state-of-the-art performance for medical
image segmentation across different applications, including histopathology and
cancer research; however, the manual annotation of such data is extremely
laborious. In this work, we explore the use of superpixel approaches to compute
a pre-segmentation of HER2 stained images for breast cancer diagnosis that
facilitates faster manual annotation and correction in a second step. Four
methods are compared: Standard Simple Linear Iterative Clustering (SLIC) as a
baseline, a domain adapted SLIC, and superpixels based on feature embeddings of
a pretrained ResNet-50 and a denoising autoencoder. To tackle oversegmentation,
we propose to hierarchically merge superpixels, based on their content in the
respective feature space. When evaluating the approaches on fully manually
annotated images, we observe that the autoencoder-based superpixels achieve a
23% increase in boundary F1 score compared to the baseline SLIC superpixels.
Furthermore, the boundary F1 score increases by 73% when hierarchical
clustering is applied on the adapted SLIC and the autoencoder-based
superpixels. These evaluations show encouraging first results for a
pre-segmentation for efficient manual refinement without the need for an
initial set of annotated training data.</p>
  </details>
</details>
<details>
  <summary>19. <b>标题：Simpler is better: spectral regularization and up-sampling techniques  for variational autoencoders</b></summary>
  <p><b>编号</b>：[89]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07544</p>
  <p><b>作者</b>：Sara Björk,  Jonas Nordhaug Myhre,  Thomas Haugland Johansen</p>
  <p><b>备注</b>：Submitted to ICASSP 2022, 2022 IEEE International Conference on Acoustics, Speech and Signal Processing</p>
  <p><b>关键词</b>：simple 2d fourier transform, either replace transposed convolutions, based spectral regularization loss, spectral regularization term, neural networks remains</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Full characterization of the spectral behavior of generative models based on
neural networks remains an open issue. Recent research has focused heavily on
generative adversarial networks and the high-frequency discrepancies between
real and generated images. The current solution to avoid this is to either
replace transposed convolutions with bilinear up-sampling or add a spectral
regularization term in the generator. It is well known that Variational
Autoencoders (VAEs) also suffer from these issues. In this work, we propose a
simple 2D Fourier transform-based spectral regularization loss for the VAE and
show that it can achieve results equal to, or better than, the current
state-of-the-art in frequency-aware losses for generative models. In addition,
we experiment with altering the up-sampling procedure in the generator network
and investigate how it influences the spectral performance of the model. We
include experiments on synthetic and real data sets to demonstrate our results.</p>
  </details>
</details>
<details>
  <summary>20. <b>标题：Virtual Coil Augmentation Technology for MRI via Deep Learning</b></summary>
  <p><b>编号</b>：[90]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07540</p>
  <p><b>作者</b>：Cailian Yang,  Xianghao Liao,  Yuhao Wang,  Minghui Zhang,  Qiegen Liu</p>
  <p><b>备注</b>：arXiv admin note: text overlap with arXiv:2103.15061, arXiv:1907.03063, arXiv:1807.03039 by other authors</p>
  <p><b>关键词</b>：method achieves significantly higher image reconstruction performance, widely used medical imaging modality, utilizing dummy variable technology, variable argumentation provides, namely variable enhancement</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Magnetic resonance imaging (MRI) is a widely used medical imaging modality.
However, due to the limitations in hardware, scan time, and throughput, it is
often clinically challenging to obtain high-quality MR images. In this article,
we propose a method of using artificial intelligence to expand the channel to
achieve the effect of increasing the virtual coil. The main feature of our work
is utilizing dummy variable technology to expand the channel in both the image
and k-space domains. The high-dimensional information formed by channel
expansion is used as the prior information of parallel imaging to improve the
reconstruction effect of parallel imaging. Two features are introduced, namely
variable enhancement and sum of squares (SOS) objective function. Variable
argumentation provides the network with more high-dimensional prior
information, which is helpful for the network to extract the deep feature
in-formation of the image. The SOS objective function is employed to solve the
problem that k-space data is difficult to train while speeding up the
convergence speed. Ablation studies and experimental results demonstrate that
our method achieves significantly higher image reconstruction performance than
current state-of-the-art techniques.</p>
  </details>
</details>
<details>
  <summary>21. <b>标题：Weakly Supervised Semantic Segmentation of Remote Sensing Images for  Tree Species Classification Based on Explanation Methods</b></summary>
  <p><b>编号</b>：[105]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07495</p>
  <p><b>作者</b>：Steve Ahlswede,  Nimisha Thekke-Madam,  Christian Schulz,  Birgit Kleinschmit,  Begüm Demir</p>
  <p><b>备注</b>：4 pages, 1 figure, submitted to IEEE Geosciences and Remote Sensing Symposium (2022)</p>
  <p><b>关键词</b>：performing weakly supervised semantic segmentation using, based labeled training samples, aerial image archive show, operational forestry applications, experimental results obtained</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The collection of a high number of pixel-based labeled training samples for
tree species identification is time consuming and costly in operational
forestry applications. To address this problem, in this paper we investigate
the effectiveness of explanation methods for deep neural networks in performing
weakly supervised semantic segmentation using only image-level labels.
Specifically, we consider four methods:i) class activation maps (CAM); ii)
gradient-based CAM; iii) pixel correlation module; and iv) self-enhancing maps
(SEM). We compare these methods with each other using both quantitative and
qualitative measures of their segmentation accuracy, as well as their
computational requirements. Experimental results obtained on an aerial image
archive show that:i) considered explanation techniques are highly relevant for
the identification of tree species with weak supervision; and ii) the SEM
outperforms the other considered methods. The code for this paper is publicly
available at this https URL.</p>
  </details>
</details>
<details>
  <summary>22. <b>标题：High-fidelity 3D Model Compression based on Key Spheres</b></summary>
  <p><b>编号</b>：[109]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07486</p>
  <p><b>作者</b>：Yuanzhan Li,  Yuqi Liu,  Yujie Lu,  Siyu Zhang,  Shen Cai,  Yanting Zhang</p>
  <p><b>备注</b>：accepted in Data Compression Conference 2022 as a full paper</p>
  <p><b>关键词</b>：sdf prediction network using explicit keyspheres, experiments conductedon three datasets verify, negative signs denote inside, relatively larger sdf values, given query space point</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In recent years, neural signed distance function (SDF) has become one of the
most effectiverepresentation methods for 3D models. By learning continuous SDFs
in 3D space, neuralnetworks can predict the distance from a given query space
point to its closest object surface,whose positive and negative signs denote
inside and outside of the object, respectively.Training a specific network for
each 3D model, which individually embeds its shape, canrealize compressed
representation of objects by storing fewer network (and possibly
latent)parameters. Consequently, reconstruction through network inference and
surface recoverycan be achieved. In this paper, we propose an SDF prediction
network using explicit keyspheres as input. Key spheres are extracted from the
internal space of objects, whosecenters either have relatively larger SDF
values (sphere radii), or are located at essentialpositions. By inputting the
spatial information of multiple spheres which imply differentlocal shapes, the
proposed method can significantly improve the reconstruction accuracywith a
negligible storage cost. Compared to previous works, our method achieves the
high-fidelity and high-compression 3D object coding and reconstruction.
Experiments conductedon three datasets verify the superior performance of our
method.</p>
  </details>
</details>
<details>
  <summary>23. <b>标题：Using Self-Supervised Pretext Tasks for Active Learning</b></summary>
  <p><b>编号</b>：[115]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07459</p>
  <p><b>作者</b>：John Seon Keun Yi,  Minseok Seo,  Jongchan Park,  Dong-Geol Choi</p>
  <p><b>备注</b>：Code available at this https URL</p>
  <p><b>关键词</b>：novel active learning approach, active learning aims, various image classification, supervised pretext tasks, supervised pretext task</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Labeling a large set of data is expensive. Active learning aims to tackle
this problem by asking to annotate only the most informative data from the
unlabeled set. We propose a novel active learning approach that utilizes
self-supervised pretext tasks and a unique data sampler to select data that are
both difficult and representative. We discover that the loss of a simple
self-supervised pretext task, such as rotation prediction, is closely
correlated to the downstream task loss. The pretext task learner is trained on
the unlabeled set, and the unlabeled data are sorted and grouped into batches
by their pretext task losses. In each iteration, the main task model is used to
sample the most uncertain data in a batch to be annotated. We evaluate our
method on various image classification and segmentation benchmarks and achieve
compelling performances on CIFAR10, Caltech-101, ImageNet, and CityScapes.</p>
  </details>
</details>
<details>
  <summary>24. <b>标题：TransFuse: A Unified Transformer-based Image Fusion Framework using  Self-supervised Learning</b></summary>
  <p><b>编号</b>：[118]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07451</p>
  <p><b>作者</b>：Linhao Qu,  Shaolei Liu,  Manning Wang,  Shiman Li,  Siqi Yin,  Qin Qiao,  Zhijian Song</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：end image fusion methods easily fall, focus image fusion tasks demonstrate, decoder based image fusion framework, tedious parameter optimization processes, focus image fusion based</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Image fusion is a technique to integrate information from multiple source
images with complementary information to improve the richness of a single
image. Due to insufficient task-specific training data and corresponding ground
truth, most existing end-to-end image fusion methods easily fall into
overfitting or tedious parameter optimization processes. Two-stage methods
avoid the need of large amount of task-specific training data by training
encoder-decoder network on large natural image datasets and utilizing the
extracted features for fusion, but the domain gap between natural images and
different fusion tasks results in limited performance. In this study, we design
a novel encoder-decoder based image fusion framework and propose a
destruction-reconstruction based self-supervised training scheme to encourage
the network to learn task-specific features. Specifically, we propose three
destruction-reconstruction self-supervised auxiliary tasks for multi-modal
image fusion, multi-exposure image fusion and multi-focus image fusion based on
pixel intensity non-linear transformation, brightness transformation and noise
transformation, respectively. In order to encourage different fusion tasks to
promote each other and increase the generalizability of the trained network, we
integrate the three self-supervised auxiliary tasks by randomly choosing one of
them to destroy a natural image in model training. In addition, we design a new
encoder that combines CNN and Transformer for feature extraction, so that the
trained model can exploit both local and global information. Extensive
experiments on multi-modal image fusion, multi-exposure image fusion and
multi-focus image fusion tasks demonstrate that our proposed method achieves
the state-of-the-art performance in both subjective and objective evaluations.
The code will be publicly available soon.</p>
  </details>
</details>
<details>
  <summary>25. <b>标题：Global-Local Path Networks for Monocular Depth Estimation with Vertical  CutDepth</b></summary>
  <p><b>编号</b>：[124]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07436</p>
  <p><b>作者</b>：Doyeon Kim,  Woonghyun Ga,  Pyungwhan Ahn,  Donggyu Joo,  Sehwan Chun,  Junmo Kim</p>
  <p><b>备注</b>：11pages, 5 figures</p>
  <p><b>关键词</b>：challenging depth dataset nyu depth v2, proposed selective feature fusion module, model shows better generalisation ability, proposed decoder shows better performance, lightweight yet powerful decoder</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Depth estimation from a single image is an important task that can be applied
to various fields in computer vision, and has grown rapidly with the
development of convolutional neural networks. In this paper, we propose a novel
structure and training strategy for monocular depth estimation to further
improve the prediction accuracy of the network. We deploy a hierarchical
transformer encoder to capture and convey the global context, and design a
lightweight yet powerful decoder to generate an estimated depth map while
considering local connectivity. By constructing connected paths between
multi-scale local features and the global decoding stream with our proposed
selective feature fusion module, the network can integrate both representations
and recover fine details. In addition, the proposed decoder shows better
performance than the previously proposed decoders, with considerably less
computational complexity. Furthermore, we improve the depth-specific
augmentation method by utilizing an important observation in depth estimation
to enhance the model. Our network achieves state-of-the-art performance over
the challenging depth dataset NYU Depth V2. Extensive experiments have been
conducted to validate and show the effectiveness of the proposed approach.
Finally, our model shows better generalisation ability and robustness than
other comparative models.</p>
  </details>
</details>
<details>
  <summary>26. <b>标题：Variable Augmented Network for Invertible MR Coil Compression</b></summary>
  <p><b>编号</b>：[129]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07428</p>
  <p><b>作者</b>：Xianghao Liao,  Shanshan Wang,  Lanlan Tu,  Yuhao Wang,  Dong Liang,  Qiegen Liu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：novel variable augmented network, generating fewer virtual coils, icc trains invertible network, utilizes inherent reversibility, qualitative evaluations demonstrated</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A large number of coils are able to provide enhanced signal-to-noise ratio
and improve imaging performance in parallel imaging. As the increasingly grow
of coil number, however, it simultaneously aggravates the drawbacks of data
storage and reconstruction speed, especially in some iterative reconstructions.
Coil compression addresses these issues by generating fewer virtual coils. In
this work, a novel variable augmented network for invertible coil compression
(VAN-ICC) is presented, which utilizes inherent reversibility of
normalizing-flow-based models, for better compression and invertible recovery.
VAN-ICC trains invertible network by finding an invertible and bijective
function, which can map the original image to the compression image. In the
experiments, both fully-sampled images and under-sampled images were used to
verify the effectiveness of the model. Extensive quantitative and qualitative
evaluations demonstrated that, in comparison with SCC and GCC, VAN-ICC can
carry through better compression effect with equal number of virtual coils.
Additionally, its performance is not susceptible to different num-ber of
virtual coils.</p>
  </details>
</details>
<details>
  <summary>27. <b>标题：WebUAV-3M: A Benchmark Unveiling the Power of Million-Scale Deep UAV  Tracking</b></summary>
  <p><b>编号</b>：[130]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07425</p>
  <p><b>作者</b>：Chunhui Zhang,  Guanjie Huang,  Li Liu,  Shan Huang,  Yinan Yang,  Yuxuan Zhang,  Xiang Wan,  Shiming Ge</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：close connections among visual appearance, densely bounding box annotated webuav, robust deep uav tracking improvements, scale deep uav tracking problems, largest public uav tracking benchmark</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this work, we contribute a new million-scale Unmanned Aerial Vehicle (UAV)
tracking benchmark, called WebUAV-3M. Firstly, we collect 4,485 videos with
more than 3M frames from the Internet. Then, an efficient and scalable
Semi-Automatic Target Annotation (SATA) pipeline is devised to label the
tremendous WebUAV-3M in every frame. To the best of our knowledge, the densely
bounding box annotated WebUAV-3M is by far the largest public UAV tracking
benchmark. We expect to pave the way for the follow-up study in the UAV
tracking by establishing a million-scale annotated benchmark covering a wide
range of target categories. Moreover, considering the close connections among
visual appearance, natural language and audio, we enrich WebUAV-3M by providing
natural language specification and audio description, encouraging the
exploration of natural language features and audio cues for UAV tracking.
Equipped with this benchmark, we delve into million-scale deep UAV tracking
problems, aiming to provide the community with a dedicated large-scale
benchmark for training deep UAV trackers and evaluating UAV tracking
approaches. Extensive experiments on WebUAV-3M demonstrate that there is still
a big room for robust deep UAV tracking improvements. The dataset, toolkits and
baseline results will be available at
\url{this https URL}.</p>
  </details>
</details>
<details>
  <summary>28. <b>标题：Self-Supervised Deep Blind Video Super-Resolution</b></summary>
  <p><b>编号</b>：[133]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07422</p>
  <p><b>作者</b>：Haoran Bai,  Jinshan Pan</p>
  <p><b>备注</b>：Project website: this https URL</p>
  <p><b>关键词</b>：optical flow estimation module, g ., bicubic kernel, simultaneously estimates blur kernels, generate auxiliary paired data, blind video sr problem</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Existing deep learning-based video super-resolution (SR) methods usually
depend on the supervised learning approach, where the training data is usually
generated by the blurring operation with known or predefined kernels (e.g.,
Bicubic kernel) followed by a decimation operation. However, this does not hold
for real applications as the degradation process is complex and cannot be
approximated by these idea cases well. Moreover, obtaining high-resolution (HR)
videos and the corresponding low-resolution (LR) ones in real-world scenarios
is difficult. To overcome these problems, we propose a self-supervised learning
method to solve the blind video SR problem, which simultaneously estimates blur
kernels and HR videos from the LR videos. As directly using LR videos as
supervision usually leads to trivial solutions, we develop a simple and
effective method to generate auxiliary paired data from original LR videos
according to the image formation of video SR, so that the networks can be
better constrained by the generated paired data for both blur kernel estimation
and latent HR video restoration. In addition, we introduce an optical flow
estimation module to exploit the information from adjacent frames for HR video
restoration. Experiments show that our method performs favorably against
state-of-the-art ones on benchmarks and real-world videos.</p>
  </details>
</details>
<details>
  <summary>29. <b>标题：Poseur: Direct Human Pose Regression with Transformers</b></summary>
  <p><b>编号</b>：[139]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07412</p>
  <p><b>作者</b>：Weian Mao,  Yongtao Ge,  Chunhua Shen,  Zhi Tian,  Xinlong Wang,  Zhibin Wang,  Anton van den Hengel</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：method significantly improves upon, 2d human pose estimation, based pose estimation methods, two predominant pose, based pose estimation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose a direct, regression-based approach to 2D human pose estimation
from single images. We formulate the problem as a sequence prediction task,
which we solve using a Transformer network. This network directly learns a
regression mapping from images to the keypoint coordinates, without resorting
to intermediate representations such as heatmaps. This approach avoids much of
the complexity associated with heatmap-based approaches. To overcome the
feature misalignment issues of previous regression-based methods, we propose an
attention mechanism that adaptively attends to the features that are most
relevant to the target keypoints, considerably improving the accuracy.
Importantly, our framework is end-to-end differentiable, and naturally learns
to exploit the dependencies between keypoints. Experiments on MS-COCO and MPII,
two predominant pose-estimation datasets, demonstrate that our method
significantly improves upon the state-of-the-art in regression-based pose
estimation. More notably, ours is the first regression-based approach to
perform favorably compared to the best heatmap-based pose estimation methods.</p>
  </details>
</details>
<details>
  <summary>30. <b>标题：KappaFace: Adaptive Additive Angular Margin Loss for Deep Face  Recognition</b></summary>
  <p><b>编号</b>：[146]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07394</p>
  <p><b>作者</b>：Chingis Oinar,  Binh M. Le,  Simon S. Woo</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：methods propose fixed positive margins, proposed method achieves superior performance, developing deep face recognition models, widely used method employed, popular facial benchmarks demonstrate</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Feature learning is a widely used method employed for large-scale face
recognition. Recently, large-margin softmax loss methods have demonstrated
significant enhancements on deep face recognition. These methods propose fixed
positive margins in order to enforce intra-class compactness and inter-class
diversity. However, the majority of the proposed methods do not consider the
class imbalance issue, which is a major challenge in practice for developing
deep face recognition models. We hypothesize that it significantly affects the
generalization ability of the deep face models. Inspired by this observation,
we introduce a novel adaptive strategy, called KappaFace, to modulate the
relative importance based on class difficultness and imbalance. With the
support of the von Mises-Fisher distribution, our proposed KappaFace loss can
intensify the margin's magnitude for hard learning or low concentration classes
while relaxing it for counter classes. Experiments conducted on popular facial
benchmarks demonstrate that our proposed method achieves superior performance
to the state-of-the-art.</p>
  </details>
</details>
<details>
  <summary>31. <b>标题：Swin-Pose: Swin Transformer Based Human Pose Estimation</b></summary>
  <p><b>编号</b>：[152]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07384</p>
  <p><b>作者</b>：Zinan Xiong,  Chenxi Wang,  Ying Li,  Yan Luo,  Yu Cao</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：many computer vision tasks, computer vision applications recently, achieve better performance compared, feature pyramid fusion structure, feature pyramid structure</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Convolutional neural networks (CNNs) have been widely utilized in many
computer vision tasks. However, CNNs have a fixed reception field and lack the
ability of long-range perception, which is crucial to human pose estimation.
Due to its capability to capture long-range dependencies between pixels,
transformer architecture has been adopted to computer vision applications
recently and is proven to be a highly effective architecture. We are interested
in exploring its capability in human pose estimation, and thus propose a novel
model based on transformer architecture, enhanced with a feature pyramid fusion
structure. More specifically, we use pre-trained Swin Transformer as our
backbone and extract features from input images, we leverage a feature pyramid
structure to extract feature maps from different stages. By fusing the features
together, our model predicts the keypoint heatmap. The experiment results of
our study have demonstrated that the proposed transformer-based model can
achieve better performance compared to the state-of-the-art CNN-based models.</p>
  </details>
</details>
<details>
  <summary>32. <b>标题：Online Deep Learning based on Auto-Encoder</b></summary>
  <p><b>编号</b>：[153]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07383</p>
  <p><b>作者</b>：Si-si Zhang,  Jian-wei Liu,  Xin Zuo,  Run-kun Lu,  Si-ming Lian</p>
  <p><b>备注</b>：30 pages</p>
  <p><b>关键词</b>：underlying abstract hierarchical latent information existing, extract abstract hierarchical latent representations, phase online deep learning based, fusion every hidden layer output, abstract hierarchical latent representations</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Online learning is an important technical means for sketching massive
real-time and high-speed data. Although this direction has attracted intensive
attention, most of the literature in this area ignore the following three
issues: (1) they think little of the underlying abstract hierarchical latent
information existing in examples, even if extracting these abstract
hierarchical latent representations is useful to better predict the class
labels of examples; (2) the idea of preassigned model on unseen datapoints is
not suitable for modeling streaming data with evolving probability
distribution. This challenge is referred as model flexibility. And so, with
this in minds, the online deep learning model we need to design should have a
variable underlying structure; (3) moreover, it is of utmost importance to
fusion these abstract hierarchical latent representations to achieve better
classification performance, and we should give different weights to different
levels of implicit representation information when dealing with the data
streaming where the data distribution changes. To address these issues, we
propose a two-phase Online Deep Learning based on Auto-Encoder (ODLAE). Based
on auto-encoder, considering reconstruction loss, we extract abstract
hierarchical latent representations of instances; Based on predictive loss, we
devise two fusion strategies: the output-level fusion strategy, which is
obtained by fusing the classification results of encoder each hidden layer; and
feature-level fusion strategy, which is leveraged self-attention mechanism to
fusion every hidden layer output. Finally, in order to improve the robustness
of the algorithm, we also try to utilize the denoising auto-encoder to yield
hierarchical latent representations. Experimental results on different datasets
are presented to verify the validity of our proposed algorithm (ODLAE)
outperforms several baselines.</p>
  </details>
</details>
<details>
  <summary>33. <b>标题：TriCoLo: Trimodal Contrastive Loss for Fine-grained Text to Shape  Retrieval</b></summary>
  <p><b>编号</b>：[163]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07366</p>
  <p><b>作者</b>：Yue Ruan,  Han-Hung Lee,  Ke Zhang,  Angel X. Chang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：bimodal representation learning using either voxels, shape retrieval without complex attention mechanisms, thus far mostly focused, achieve even higher performance, large batch contrastive learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent work on contrastive losses for learning joint embeddings over
multimodal data has been successful at downstream tasks such as retrieval and
classification. On the other hand, work on joint representation learning for 3D
shapes and text has thus far mostly focused on improving embeddings through
modeling of complex attention between representations , or multi-task learning
. We show that with large batch contrastive learning we achieve SoTA on
text-shape retrieval without complex attention mechanisms or losses. Prior work
in 3D and text representations has also focused on bimodal representation
learning using either voxels or multi-view images with text. To this end, we
propose a trimodal learning scheme to achieve even higher performance and
better representations for all modalities.</p>
  </details>
</details>
<details>
  <summary>34. <b>标题：OSSID: Online Self-Supervised Instance Detection by (and for) Pose  Estimation</b></summary>
  <p><b>编号</b>：[184]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07309</p>
  <p><b>作者</b>：Qiao Gu,  Brian Okorn,  David Held</p>
  <p><b>备注</b>：10 pages, 6 figures. Accepted to RA-L</p>
  <p><b>关键词</b>：two widely used object pose estimation, ossid framework ,} leveraging, many robot manipulation algorithms, significantly faster inference speed, time object pose estimation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Real-time object pose estimation is necessary for many robot manipulation
algorithms. However, state-of-the-art methods for object pose estimation are
trained for a specific set of objects; these methods thus need to be retrained
to estimate the pose of each new object, often requiring tens of GPU-days of
training for optimal performance. \revisef{In this paper, we propose the OSSID
framework,} leveraging a slow zero-shot pose estimator to self-supervise the
training of a fast detection algorithm. This fast detector can then be used to
filter the input to the pose estimator, drastically improving its inference
speed. We show that this self-supervised training exceeds the performance of
existing zero-shot detection methods on two widely used object pose estimation
and detection datasets, without requiring any human annotations. Further, we
show that the resulting method for pose estimation has a significantly faster
inference speed, due to the ability to filter out large parts of the image.
Thus, our method for self-supervised online learning of a detector (trained
using pseudo-labels from a slow pose estimator) leads to accurate pose
estimation at real-time speeds, without requiring human annotations.
Supplementary materials and code can be found at
this https URL</p>
  </details>
</details>
<details>
  <summary>35. <b>标题：Exploring Kervolutional Neural Networks</b></summary>
  <p><b>编号</b>：[200]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07264</p>
  <p><b>作者</b>：Nicolas Perez</p>
  <p><b>备注</b>：5 pages, 8 figures</p>
  <p><b>关键词</b>：cvpr 2019 conference outlines, augmented convolutional neural network, knns achieve faster convergence, kervolutional neural network, rigourous statistical analysis</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A paper published in the CVPR 2019 conference outlines a new technique called
'kervolution' used in a new type of augmented convolutional neural network
(CNN) called a 'kervolutional neural network' (KNN). The paper asserts that
KNNs achieve faster convergence and higher accuracies than CNNs. This "mini
paper" will further examine the findings in the original paper and perform a
more in depth analysis of the KNN architecture. This will be done by analyzing
the impact of hyper parameters (specifically the learning rate) on KNNs versus
CNNs, experimenting with other types of kervolution operations not tested in
the original paper, a more rigourous statistical analysis of accuracies and
convergence times and additional theoretical analysis. The accompanying code is
publicly available.</p>
  </details>
</details>
<details>
  <summary>36. <b>标题：Nonlinear Unknown Input Observability and Unknown Input Reconstruction:  The General Analytical Solution</b></summary>
  <p><b>编号</b>：[223]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07610</p>
  <p><b>作者</b>：Agostino Martinelli</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：matrix rank determination ),, introduce analytical criteria able, new solution exhaustively accounts, unknown input observability problem, unknown input reconstruction</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Observability is a fundamental structural property of any dynamic system and
describes the possibility of reconstructing the state that characterizes the
system from observing its inputs and outputs. Despite the huge effort made to
study this property and to introduce analytical criteria able to check whether
a dynamic system satisfies this property or not, there is no general analytical
criterion to automatically check the state observability when the dynamics are
also driven by unknown inputs. Here, we introduce the general analytical
solution of this fundamental problem, often called the unknown input
observability problem. This paper provides the general analytical solution of
this problem, namely, it provides the systematic procedure, based on automatic
computation (differentiation and matrix rank determination), that allows us to
automatically check the state observability even in the presence of unknown
inputs. A first solution of this problem was presented in the second part of
the book: "Observability: A New Theory Based on the Group of Invariance" [45].
The solution presented by this paper completes the previous solution in [45].
In particular, the new solution exhaustively accounts for the systems that do
not belong to the category of the systems that are canonic with respect to
their unknown inputs. The new solution is also provided in the form of a new
algorithm. A further novelty with respect to the algorithm provided in [45]
consists of a new convergence criterion that holds in all the cases (the
convergence criterion of the algorithm provided in [45] can fail in some
cases). Finally, we also provide the answer to the problem of unknown input
reconstruction which is intimately related to the problem of state
observability. We illustrate the implementation of the new algorithm by
studying a nonlinear system in the framework of visual-inertial sensor fusion.</p>
  </details>
</details>
<details>
  <summary>37. <b>标题：Learned Cone-Beam CT Reconstruction Using Neural Ordinary Differential  Equations</b></summary>
  <p><b>编号</b>：[225]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07562</p>
  <p><b>作者</b>：Mareike Thies,  Fabian Wagner,  Mingxuan Gu,  Lukas Folle,  Lina Felsner,  Andreas Maier</p>
  <p><b>备注</b>：6 pages</p>
  <p><b>关键词</b>：best performing classical iterative reconstruction algorithm, residual formulation via numerical integration, use neural ordinary differential equations, neural ode setting allowing, single consumer graphics card</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Learned iterative reconstruction algorithms for inverse problems offer the
flexibility to combine analytical knowledge about the problem with modules
learned from data. This way, they achieve high reconstruction performance while
ensuring consistency with the measured data. In computed tomography, extending
such approaches from 2D fan-beam to 3D cone-beam data is challenging due to the
prohibitively high GPU memory that would be needed to train such models. This
paper proposes to use neural ordinary differential equations to solve the
reconstruction problem in a residual formulation via numerical integration. For
training, there is no need to backpropagate through several unrolled network
blocks nor through the internals of the solver. Instead, the gradients are
obtained very memory-efficiently in the neural ODE setting allowing for
training on a single consumer graphics card. The method is able to reduce the
root mean squared error by over 30% compared to the best performing classical
iterative reconstruction algorithm and produces high quality cone-beam
reconstructions even in a sparse view scenario.</p>
  </details>
</details>
<details>
  <summary>38. <b>标题：The Role of Pleura and Adipose in Lung Ultrasound AI</b></summary>
  <p><b>编号</b>：[233]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07368</p>
  <p><b>作者</b>：Gautam Rajendrakumar Gare,  Wanwen Chen,  Alex Ling Yu Hung,  Edward Chen,  Hai V. Tran,  Tom Fox,  Pete Lowery,  Kevin Zamora,  Bennett P deBoisblanc,  Ricardo Luis Rodriguez,  John Michael Galeotti</p>
  <p><b>备注</b>：Published in MICCAI 2021 workshop on Lessons Learned from the development and application of medical imaging-based AI technologies for combating COVID-19 (LL-COVID19). The first two authors contributed equally to this work</p>
  <p><b>关键词</b>：showing hfl reveals better pleura detail, lung ultrasound ai analysis, hfl ultrasound probe, curvilinear ultrasound probes, adipose tissue using</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we study the significance of the pleura and adipose tissue in
lung ultrasound AI analysis. We highlight their more prominent appearance when
using high-frequency linear (HFL) instead of curvilinear ultrasound probes,
showing HFL reveals better pleura detail. We compare the diagnostic utility of
the pleura and adipose tissue using an HFL ultrasound probe. Masking the
adipose tissue during training and inference (while retaining the pleural line
and Merlin's space artifacts such as A-lines and B-lines) improved the AI
model's diagnostic accuracy.</p>
  </details>
</details>
<details>
  <summary>39. <b>标题：Weakly Supervised Contrastive Learning for Better Severity Scoring of  Lung Ultrasound</b></summary>
  <p><b>编号</b>：[234]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07357</p>
  <p><b>作者</b>：Gautam Rajendrakumar Gare,  Hai V. Tran,  Bennett P deBoisblanc,  Ricardo Luis Rodriguez,  John Michael Galeotti</p>
  <p><b>备注</b>：Under Review for MIDL 2022 conference</p>
  <p><b>关键词</b>：frame based model achieves comparable performance, based patient severity scoring models, entropy loss based training, contrastive learning method treats, combine frame severity predictions</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>With the onset of the COVID-19 pandemic, ultrasound has emerged as an
effective tool for bedside monitoring of patients. Due to this, a large amount
of lung ultrasound scans have been made available which can be used for AI
based diagnosis and analysis. Several AI-based patient severity scoring models
have been proposed that rely on scoring the appearance of the ultrasound scans.
AI models are trained using ultrasound-appearance severity scores that are
manually labeled based on standardized visual features. We address the
challenge of labeling every ultrasound frame in the video clips. Our
contrastive learning method treats the video clip severity labels as noisy weak
severity labels for individual frames, thus requiring only video-level labels.
We show that it performs better than the conventional cross-entropy loss based
training. We combine frame severity predictions to come up with video severity
predictions and show that the frame based model achieves comparable performance
to a video based TSM model, on a large dataset combining public and private
sources.</p>
  </details>
</details>
<details>
  <summary>40. <b>标题：Lung Swapping Autoencoder: Learning a Disentangled Structure-texture  Representation of Chest Radiographs</b></summary>
  <p><b>编号</b>：[235]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07344</p>
  <p><b>作者</b>：Lei Zhou,  Joseph Bae,  Huidong Liu,  Gagandeep Singh,  Jeremy Green,  Amit Gupta,  Dimitris Samaras,  Prateek Prasanna</p>
  <p><b>备注</b>：Extended version of the MICCAI 2021 paper this https URL The code is available at this https URL</p>
  <p><b>关键词</b>：improve covoc prediction performance, 19 outcome prediction dataset, lung tissue texture rather, generate meaningful hybrid images, unlike natural images</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Well-labeled datasets of chest radiographs (CXRs) are difficult to acquire
due to the high cost of annotation. Thus, it is desirable to learn a robust and
transferable representation in an unsupervised manner to benefit tasks that
lack labeled data. Unlike natural images, medical images have their own domain
prior; e.g., we observe that many pulmonary diseases, such as the COVID-19,
manifest as changes in the lung tissue texture rather than the anatomical
structure. Therefore, we hypothesize that studying only the texture without the
influence of structure variations would be advantageous for downstream
prognostic and predictive modeling tasks. In this paper, we propose a
generative framework, the Lung Swapping Autoencoder (LSAE), that learns
factorized representations of a CXR to disentangle the texture factor from the
structure factor. Specifically, by adversarial training, the LSAE is optimized
to generate a hybrid image that preserves the lung shape in one image but
inherits the lung texture of another. To demonstrate the effectiveness of the
disentangled texture representation, we evaluate the texture encoder $Enc^t$ in
LSAE on ChestX-ray14 (N=112,120), and our own multi-institutional COVID-19
outcome prediction dataset, COVOC (N=340 (Subset-1) + 53 (Subset-2)). On both
datasets, we reach or surpass the state-of-the-art by finetuning $Enc^t$ in
LSAE that is 77% smaller than a baseline Inception v3. Additionally, in
semi-and-self supervised settings with a similar model budget, $Enc^t$ in LSAE
is also competitive with the state-of-the-art MoCo. By "re-mixing" the texture
and shape factors, we generate meaningful hybrid images that can augment the
training set. This data augmentation method can further improve COVOC
prediction performance. The improvement is consistent even when we directly
evaluate the Subset-1 trained model on Subset-2 without any fine-tuning.</p>
  </details>
</details>
<details>
  <summary>41. <b>标题：AI-based Carcinoma Detection and Classification Using Histopathological  Images: A Systematic Review</b></summary>
  <p><b>编号</b>：[238]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07231</p>
  <p><b>作者</b>：Swathi Prabhua,  Keerthana Prasada,  Antonio Robels-Kelly,  Xuequan Lu</p>
  <p><b>备注</b>：accepted to Computers in Biology and Medicine</p>
  <p><b>关键词</b>：carcinoma diagnosis using histopathological images, carcinoma diagnosis also reveals, based carcinoma diagnostic system, histopathological image analysis, automated carcinoma diagnosis</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Histopathological image analysis is the gold standard to diagnose cancer.
Carcinoma is a subtype of cancer that constitutes more than 80% of all cancer
cases. Squamous cell carcinoma and adenocarcinoma are two major subtypes of
carcinoma, diagnosed by microscopic study of biopsy slides. However, manual
microscopic evaluation is a subjective and time-consuming process. Many
researchers have reported methods to automate carcinoma detection and
classification. The increasing use of artificial intelligence (AI) in the
automation of carcinoma diagnosis also reveals a significant rise in the use of
deep network models. In this systematic literature review, we present a
comprehensive review of the state-of-the-art approaches reported in carcinoma
diagnosis using histopathological images. Studies are selected from well-known
databases with strict inclusion/exclusion criteria. We have categorized the
articles and recapitulated their methods based on specific organs of carcinoma
origin. Further, we have summarized pertinent literature on AI methods,
highlighted critical challenges and limitations, and provided insights on
future research direction in automated carcinoma diagnosis. Out of 101 articles
selected, most of the studies experimented on private datasets with varied
image sizes, obtaining accuracy between 63% and 100%. Overall, this review
highlights the need for a generalized AI-based carcinoma diagnostic system.
Additionally, it is desirable to have accountable approaches to extract
microscopic features from images of multiple magnifications that should mimic
pathologists' evaluations.</p>
  </details>
</details>
<details>
  <summary>42. <b>标题：Explainable Ensemble Machine Learning for Breast Cancer Diagnosis based  on Ultrasound Image Texture Features</b></summary>
  <p><b>编号</b>：[239]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07227</p>
  <p><b>作者</b>：Alireza Rezazadeh,  Yasamin Jafarian,  Ali Kord</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：proposed framework achieves high predictive performance, existing approaches overwhelmingly rely, breast cancer diagnosis based, explainable machine learning pipeline, breast cancer diagnosis</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Image classification is widely used to build predictive models for breast
cancer diagnosis. Most existing approaches overwhelmingly rely on deep
convolutional networks to build such diagnosis pipelines. These model
architectures, although remarkable in performance, are black-box systems that
provide minimal insight into the inner logic behind their predictions. This is
a major drawback as the explainability of prediction is vital for applications
such as cancer diagnosis. In this paper, we address this issue by proposing an
explainable machine learning pipeline for breast cancer diagnosis based on
ultrasound images. We extract first- and second-order texture features of the
ultrasound images and use them to build a probabilistic ensemble of decision
tree classifiers. Each decision tree learns to classify the input ultrasound
image by learning a set of robust decision thresholds for texture features of
the image. The decision path of the model predictions can then be interpreted
by decomposing the learned decision trees. Our results show that our proposed
framework achieves high predictive performance while being explainable.</p>
  </details>
</details>
<details>
  <summary>43. <b>标题：Is Contrastive Learning Suitable for Left Ventricular Segmentation in  Echocardiographic Images?</b></summary>
  <p><b>编号</b>：[240]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07219</p>
  <p><b>作者</b>：Mohamed Saeed,  Rand Muhtaseb,  Mohammad Yaqub</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：clinical experts manually annotate large volumes, art fully supervised algorithms, commonly used segmentation network, contrastive pretraining helps improve, solution achieves better results</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Contrastive learning has proven useful in many applications where access to
labelled data is limited. The lack of annotated data is particularly
problematic in medical image segmentation as it is difficult to have clinical
experts manually annotate large volumes of data. One such task is the
segmentation of cardiac structures in ultrasound images of the heart. In this
paper, we argue whether or not contrastive pretraining is helpful for the
segmentation of the left ventricle in echocardiography images. Furthermore, we
study the effect of this on two segmentation networks, DeepLabV3, as well as
the commonly used segmentation network, UNet. Our results show that contrastive
pretraining helps improve the performance on left ventricle segmentation,
particularly when annotated data is scarce. We show how to achieve comparable
results to state-of-the-art fully supervised algorithms when we train our
models in a self-supervised fashion followed by fine-tuning on just 5% of the
data. We also show that our solution achieves better results than what is
currently published on a large public dataset (EchoNet-Dynamic) and we compare
the performance of our solution on another smaller dataset (CAMUS) as well.</p>
  </details>
</details>
<h1>自然语言处理</h1>
<details>
  <summary>1. <b>标题：Improving Biomedical Information Retrieval with Neural Retrievers</b></summary>
  <p><b>编号</b>：[16]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07745</p>
  <p><b>作者</b>：Man Luo,  Arindam Mitra,  Tejas Gokhale,  Chitta Baral</p>
  <p><b>备注</b>：Accepted at AAAI 2022</p>
  <p><b>关键词</b>：scientific knowledge may evolve rapidly, develop two novel pre, natural language processing tasks, train neural retriever models, simple hybrid model leads</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Information retrieval (IR) is essential in search engines and dialogue
systems as well as natural language processing tasks such as open-domain
question answering. IR serve an important function in the biomedical domain,
where content and sources of scientific knowledge may evolve rapidly. Although
neural retrievers have surpassed traditional IR approaches such as TF-IDF and
BM25 in standard open-domain question answering tasks, they are still found
lacking in the biomedical domain. In this paper, we seek to improve information
retrieval (IR) using neural retrievers (NR) in the biomedical domain, and
achieve this goal using a three-pronged approach. First, to tackle the relative
lack of data in the biomedical domain, we propose a template-based question
generation method that can be leveraged to train neural retriever models.
Second, we develop two novel pre-training tasks that are closely aligned to the
downstream task of information retrieval. Third, we introduce the ``Poly-DPR''
model which encodes each context into multiple context vectors. Extensive
experiments and analysis on the BioASQ challenge suggest that our proposed
method leads to large gains over existing neural approaches and beats BM25 in
the small-corpus setting. We show that BM25 and our method can complement each
other, and a simple hybrid model leads to further gains in the large corpus
setting.</p>
  </details>
</details>
<details>
  <summary>2. <b>标题：Data-to-Value: An Evaluation-First Methodology for Natural Language  Projects</b></summary>
  <p><b>编号</b>：[26]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07725</p>
  <p><b>作者</b>：Jochen L. Leidner</p>
  <p><b>备注</b>：9 pages, 6 figures, 4 tables</p>
  <p><b>关键词</b>：level distributed parallel operating systems like hdfs, big data text analytics project team, project managerial aspects )., facing rather abstract box, arrow diagrams commonly associated</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Big data, i.e. collecting, storing and processing of data at scale, has
recently been possible due to the arrival of clusters of commodity computers
powered by application-level distributed parallel operating systems like
HDFS/Hadoop/Spark, and such infrastructures have revolutionized data mining at
scale. For data mining project to succeed more consistently, some methodologies
were developed (e.g. CRISP-DM, SEMMA, KDD), but these do not account for (1)
very large scales of processing, (2) dealing with textual (unstructured) data
(i.e. Natural Language Processing (NLP, "text analytics"), and (3)
non-technical considerations (e.g. legal, ethical, project managerial aspects).
To address these shortcomings, a new methodology, called "Data to Value"
(D2V), is introduced, which is guided by a detailed catalog of questions in
order to avoid a disconnect of big data text analytics project team with the
topic when facing rather abstract box-and-arrow diagrams commonly associated
with methodologies.</p>
  </details>
</details>
<details>
  <summary>3. <b>标题：Top-Down Influence? Predicting CEO Personality and Risk Impact from  Speech Transcripts</b></summary>
  <p><b>编号</b>：[48]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07670</p>
  <p><b>作者</b>：Kilian Theil,  Dirk Hovy,  Heiner Stuckenschmidt</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：sourced myers -- briggs type indicator, based personality regressor using crowd, show empirically --, reported personality data, upper echelons theory</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>How much does a CEO's personality impact the performance of their company?
Management theory posits a great influence, but it is difficult to show
empirically -- there is a lack of publicly available self-reported personality
data of top managers. Instead, we propose a text-based personality regressor
using crowd-sourced Myers--Briggs Type Indicator (MBTI) assessments. The
ratings have a high internal and external validity and can be predicted with
moderate to strong correlations for three out of four dimensions. Providing
evidence for the upper echelons theory, we demonstrate that the predicted CEO
personalities have explanatory power of financial risk.</p>
  </details>
</details>
<details>
  <summary>4. <b>标题：Uncovering More Shallow Heuristics: Probing the Natural Language  Inference Capacities of Transformer-Based Pre-Trained Language Models Using  Syllogistic Patterns</b></summary>
  <p><b>编号</b>：[67]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07614</p>
  <p><b>作者</b>：Reto Gubelmann,  Siegfried Handschuh</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：shallow heuristics used, rather spurious heuristics, natural language inference, certain shallow heuristics, trained language models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this article, we explore the shallow heuristics used by transformer-based
pre-trained language models (PLMs) that are fine-tuned for natural language
inference (NLI). To do so, we construct or own dataset based on syllogistic,
and we evaluate a number of models' performance on our dataset. We find
evidence that the models rely heavily on certain shallow heuristics, picking up
on symmetries and asymmetries between premise and hypothesis. We suggest that
the lack of generalization observable in our study, which is becoming a topic
of lively debate in the field, means that the PLMs are currently not learning
NLI, but rather spurious heuristics.</p>
  </details>
</details>
<details>
  <summary>5. <b>标题：Semi-Supervised Clustering with Contrastive Learning for Discovering New  Intents</b></summary>
  <p><b>编号</b>：[71]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07604</p>
  <p><b>作者</b>：Feng Wei,  Zhenbo Chen,  Zhenghong Hao,  Fengxin Yang,  Hua Wei,  Bing Han,  Sheng Guo</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：results show dcsc achieve best performance across, achieve better text representation, better overall clustering performance, make dcsc fully utilize, propose deep contrastive semi</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Most dialogue systems in real world rely on predefined intents and answers
for QA service, so discovering potential intents from large corpus previously
is really important for building such dialogue services. Considering that most
scenarios have few intents known already and most intents waiting to be
discovered, we focus on semi-supervised text clustering and try to make the
proposed method benefit from labeled samples for better overall clustering
performance. In this paper, we propose Deep Contrastive Semi-supervised
Clustering (DCSC), which aims to cluster text samples in a semi-supervised way
and provide grouped intents to operation staff. To make DCSC fully utilize the
limited known intents, we propose a two-stage training procedure for DCSC, in
which DCSC will be trained on both labeled samples and unlabeled samples, and
achieve better text representation and clustering performance. We conduct
experiments on two public datasets to compare our model with several popular
methods, and the results show DCSC achieve best performance across all datasets
and circumstances, indicating the effect of the improvements in our work.</p>
  </details>
</details>
<details>
  <summary>6. <b>标题：Writing about COVID-19 vaccines: Emotional profiling unravels how  mainstream and alternative press framed AstraZeneca, Pfizer and vaccination  campaigns</b></summary>
  <p><b>编号</b>：[91]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07538</p>
  <p><b>作者</b>：Alfonso Semeraro,  Salvatore Vilella,  Giancarlo Ruffo,  Massimo Stella</p>
  <p><b>备注</b>：16 pages, 5 figures</p>
  <p><b>关键词</b>：even mainstream article titles framed, mainstream media report vaccination news, mainstream news outlets framed covid, alternative news included titles framing, ways alternative sources framed covid</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Since their announcement in November 2020, COVID-19 vaccines were largely
debated by the press and social media. With most studies focusing on COVID-19
disinformation in social media, little attention has been paid to how
mainstream news outlets framed COVID-19 narratives compared to alternative
sources. To fill this gap, we use cognitive network science and natural
language processing to reconstruct time-evolving semantic and emotional frames
of 5745 Italian news, that were massively re-shared on Facebook and Twitter,
about COVID-19 vaccines. We found consistently high levels of
trust/anticipation and less disgust in the way mainstream sources framed the
general idea of "vaccine/vaccino". These emotions were crucially missing in the
ways alternative sources framed COVID-19 vaccines. More differences were found
within specific instances of vaccines. Alternative news included titles framing
the AstraZeneca vaccine with strong levels of sadness, absent in mainstream
titles. Mainstream news initially framed "Pfizer" along more negative
associations with side effects than "AstraZeneca". With the temporary
suspension of the latter, on March 15th 2021, we identified a
semantic/emotional shift: Even mainstream article titles framed "AstraZeneca"
as semantically richer in negative associations with side effects, while
"Pfizer" underwent a positive shift in valence, mostly related to its higher
efficacy. "Thrombosis" entered the frame of vaccines together with fearful
conceptual associations, while "death" underwent an emotional shift, steering
towards fear in alternative titles and losing its hopeful connotation in
mainstream titles. Our findings expose crucial aspects of the emotional
narratives around COVID-19 vaccines adopted by the press, highlighting the need
to understand how alternative and mainstream media report vaccination news.</p>
  </details>
</details>
<details>
  <summary>7. <b>标题：CM3: A Causal Masked Multimodal Model of the Internet</b></summary>
  <p><b>编号</b>：[97]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07520</p>
  <p><b>作者</b>：Armen Aghajanyan,  Bernie Huang,  Candace Ross,  Vladimir Karpukhin,  Hu Xu,  Naman Goyal,  Dmytro Okhonko,  Mandar Joshi,  Gargi Ghosh,  Mike Lewis,  Luke Zettlemoyer</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：new causally masked approach generates tokens left, causally masked generative models trained, train causally masked language, enabling full generative modeling, arbitrary masked document contexts</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We introduce CM3, a family of causally masked generative models trained over
a large corpus of structured multi-modal documents that can contain both text
and image tokens. Our new causally masked approach generates tokens left to
right while also masking out a small number of long token spans that are
generated at the end of the string, instead of their original positions. The
casual masking object provides a type of hybrid of the more common causal and
masked language models, by enabling full generative modeling while also
providing bidirectional context when generating the masked spans. We train
causally masked language-image models on large-scale web and Wikipedia
articles, where each document contains all of the text, hypertext markup,
hyperlinks, and image tokens (from a VQVAE-GAN), provided in the order they
appear in the original HTML source (before masking). The resulting CM3 models
can generate rich structured, multi-modal outputs while conditioning on
arbitrary masked document contexts, and thereby implicitly learn a wide range
of text, image, and cross modal tasks. They can be prompted to recover, in a
zero-shot fashion, the functionality of models such as DALL-E, GENRE, and HTLM.
We set the new state-of-the-art in zero-shot summarization, entity linking, and
entity disambiguation while maintaining competitive performance in the
fine-tuning setting. We can generate images unconditionally, conditioned on
text (like DALL-E) and do captioning all in a zero-shot setting with a single
model.</p>
  </details>
</details>
<details>
  <summary>8. <b>标题：Development of Fake News Model using Machine Learning through Natural  Language Processing</b></summary>
  <p><b>编号</b>：[107]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07489</p>
  <p><b>作者</b>：Sajjad Ahmed,  Knut Hinkelmann,  Flavio Corradini</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：applied three different machine learning classifiers, two publicly available datasets, used machine learning algorithms, build ai systems nowadays, applied three classifiers</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Fake news detection research is still in the early stage as this is a
relatively new phenomenon in the interest raised by society. Machine learning
helps to solve complex problems and to build AI systems nowadays and especially
in those cases where we have tacit knowledge or the knowledge that is not
known. We used machine learning algorithms and for identification of fake news;
we applied three classifiers; Passive Aggressive, Naïve Bayes, and Support
Vector Machine. Simple classification is not completely correct in fake news
detection because classification methods are not specialized for fake news.
With the integration of machine learning and text-based processing, we can
detect fake news and build classifiers that can classify the news data. Text
classification mainly focuses on extracting various features of text and after
that incorporating those features into classification. The big challenge in
this area is the lack of an efficient way to differentiate between fake and
non-fake due to the unavailability of corpora. We applied three different
machine learning classifiers on two publicly available datasets. Experimental
analysis based on the existing dataset indicates a very encouraging and
improved performance.</p>
  </details>
</details>
<details>
  <summary>9. <b>标题：TourBERT: A pretrained language model for the tourism industry</b></summary>
  <p><b>编号</b>：[119]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07449</p>
  <p><b>作者</b>：Veronika Arefieva,  Roman Egger</p>
  <p><b>备注</b>：13 pages, 7 figures, 4 tables</p>
  <p><b>关键词</b>：bidirectional encoder representations, pretrained language model, natural language, specific tasks, specific tasks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The Bidirectional Encoder Representations from Transformers (BERT) is
currently one of the most important and state-of-the-art models for natural
language. However, it has also been shown that for domain-specific tasks it is
helpful to pretrain BERT on a domain-specific corpus. In this paper, we present
TourBERT, a pretrained language model for tourism. We describe how TourBERT was
developed and evaluated. The evaluations show that TourBERT is outperforming
BERT in all tourism-specific tasks.</p>
  </details>
</details>
<details>
  <summary>10. <b>标题：Interpreting Arabic Transformer Models</b></summary>
  <p><b>编号</b>：[126]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07434</p>
  <p><b>作者</b>：Ahmed Abdelali,  Nadir Durrani,  Fahim Dalvi,  Hassan Sajjad</p>
  <p><b>备注</b>：11 pages, 6 figures, 4 tables</p>
  <p><b>关键词</b>：models using three intrinsic tasks, two morphological tagging tasks based, analysis enlightens interesting findings, many transformer models trained, downstream nlp tasks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Arabic is a Semitic language which is widely spoken with many dialects. Given
the success of pre-trained language models, many transformer models trained on
Arabic and its dialects have surfaced. While these models have been compared
with respect to downstream NLP tasks, no evaluation has been carried out to
directly compare the internal representations. We probe how linguistic
information is encoded in Arabic pretrained models, trained on different
varieties of Arabic language. We perform a layer and neuron analysis on the
models using three intrinsic tasks: two morphological tagging tasks based on
MSA (modern standard Arabic) and dialectal POS-tagging and a dialectal
identification task. Our analysis enlightens interesting findings such as: i)
word morphology is learned at the lower and middle layers ii) dialectal
identification necessitate more knowledge and hence preserved even in the final
layers, iii) despite a large overlap in their vocabulary, the MSA-based models
fail to capture the nuances of Arabic dialects, iv) we found that neurons in
embedding layers are polysemous in nature, while the neurons in middle layers
are exclusive to specific properties.</p>
  </details>
</details>
<details>
  <summary>11. <b>标题：Many Ways to be Lonely: Fine-grained Characterization of Loneliness and  its Potential Changes in COVID-19</b></summary>
  <p><b>编号</b>：[132]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07423</p>
  <p><b>作者</b>：Yueyi Jiang,  Yunfan Jiang,  Leqi Liu,  Piotr Winkielman</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：grained loneliness category classification reached, two loneliness related forums consisting, particularly among vulnerable groups, binary loneliness classification archived, young adult related forums</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Loneliness has been associated with negative outcomes for physical and mental
health. Understanding how people express and cope with various forms of
loneliness is critical for early screening and targeted interventions to reduce
loneliness, particularly among vulnerable groups such as young adults. To
examine how different forms of loneliness and coping strategies manifest in
loneliness self-disclosure, we built a dataset, FIG-Loneliness (FIne-Grained
Loneliness) by using Reddit posts in two young adult-focused forums and two
loneliness related forums consisting of a diverse age group. We provide
annotations by trained human annotators for binary and fine-grained loneliness
classifications of the posts. Trained on FIG-Loneliness, two BERT-based models
were used to understand loneliness forms and authors' coping strategies in
these forums. Our binary loneliness classification archived an accuracy above
97%, and fine-grained loneliness category classification reached an average
accuracy of 77% across all labeled categories. With FIG-Loneliness and model
predictions, we found that loneliness expressions in the young adult related
forums are distinct from other forums. Those in young adult-focused forums are
more likely to express concerns pertaining to peer relationship, and are
potentially more sensitive to geographical isolation impacted by the COVID-19
pandemic lockdown. Also, we show that different forms of loneliness have
differential use in coping strategies.</p>
  </details>
</details>
<details>
  <summary>12. <b>标题：Neural Language Models are Effective Plagiarists</b></summary>
  <p><b>编号</b>：[141]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07406</p>
  <p><b>作者</b>：Stella Biderman,  Edward Raff</p>
  <p><b>备注</b>：6 pages of main text, 2 pages of references, 86 pages of appendices</p>
  <p><b>关键词</b>：complete introductory level programming assignments without triggering suspicion, future plagiarism detection techniques may use, solve introductory level programming assignments, widely used plagiarism detection tool, bypassing commonly used ai tools</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As artificial intelligence (AI) technologies become increasingly powerful and
prominent in society, their misuse is a growing concern. In educational
settings, AI technologies could be used by students to cheat on assignments and
exams. In this paper we explore whether transformers can be used to solve
introductory level programming assignments while bypassing commonly used AI
tools to detect plagiarism. We find that a student using GPT-J [Wang and
Komatsuzaki, 2021] can complete introductory level programming assignments
without triggering suspicion from MOSS [Aiken, 2000], a widely used plagiarism
detection tool. This holds despite the fact that GPT-J was not trained on the
problems in question and is not provided with any examples to work from. We
further find that the code written by GPT-J is diverse in structure, lacking
any particular tells that future plagiarism detection techniques may use to try
to identify algorithmically generated code. We conclude with a discussion of
the ethical and educational implications of large language models and
directions for future research.</p>
  </details>
</details>
<details>
  <summary>13. <b>标题：Improving Neural Machine Translation by Denoising Training</b></summary>
  <p><b>编号</b>：[164]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07365</p>
  <p><b>作者</b>：Liang Ding,  Keqin Peng,  Dacheng Tao</p>
  <p><b>备注</b>：arXiv admin note: text overlap with arXiv:2109.07780</p>
  <p><b>关键词</b>：neural machine translation performance across 12 bilingual, dot outperforms costly pretrained model mbart, complement existing data manipulation strategies, neural machine translation, parallel data merely</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present a simple and effective pretraining strategy {D}en{o}ising
{T}raining DoT for neural machine translation. Specifically, we update the
model parameters with source- and target-side denoising tasks at the early
stage and then tune the model normally. Notably, our approach does not increase
any parameters or training steps, requiring the parallel data merely.
Experiments show that DoT consistently improves the neural machine translation
performance across 12 bilingual and 16 multilingual directions (data size
ranges from 80K to 20M). In addition, we show that DoT can complement existing
data manipulation strategies, i.e. curriculum learning, knowledge distillation,
data diversification, bidirectional training, and back-translation.
Encouragingly, we found that DoT outperforms costly pretrained model mBART in
high-resource settings. Analyses show DoT is a novel in-domain cross-lingual
pretraining strategy and could offer further improvements with task-relevant
self-supervisions.</p>
  </details>
</details>
<details>
  <summary>14. <b>标题：Learning grammar with a divide-and-concur neural network</b></summary>
  <p><b>编号</b>：[172]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07341</p>
  <p><b>作者</b>：Sean Deyo,  Veit Elser</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：inferred grammar directly interpretable -- one, infer meaningful grammatical rules, construct grammatically valid sentences, concur iterative projection approach, relatively small number</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We implement a divide-and-concur iterative projection approach to
context-free grammar inference. Unlike most state-of-the-art models of natural
language processing, our method requires a relatively small number of discrete
parameters, making the inferred grammar directly interpretable -- one can read
off from a solution how to construct grammatically valid sentences. Another
advantage of our approach is the ability to infer meaningful grammatical rules
from just a few sentences, compared to the hundreds of gigabytes of training
data many other models employ. We demonstrate several ways of applying our
approach: classifying words and inferring a grammar from scratch, taking an
existing grammar and refining its categories and rules, and taking an existing
grammar and expanding its lexicon as it encounters new words in new data.</p>
  </details>
</details>
<details>
  <summary>15. <b>标题：A Privacy-Preserving Unsupervised Domain Adaptation Framework for  Clinical Text Analysis</b></summary>
  <p><b>编号</b>：[180]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07317</p>
  <p><b>作者</b>：Qiyuan An,  Ruijiang Li,  Lin Gu,  Hao Zhang,  Qingyu Chen,  Zhiyong Lu,  Fei Wang,  Yingying Zhu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：medical report disease label classification task using two noisy challenging clinical text datasets, source data provider could avoid leaking source data privacy, target client resamples differentially private source features, source feature distribution may still suffer, potential data privacy leaking risks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Unsupervised domain adaptation (UDA) generally aligns the unlabeled target
domain data to the distribution of the source domain to mitigate the
distribution shift problem. The standard UDA requires sharing the source data
with the target, having potential data privacy leaking risks. To protect the
source data's privacy, we first propose to share the source feature
distribution instead of the source data. However, sharing only the source
feature distribution may still suffer from the membership inference attack who
can infer an individual's membership by the black-box access to the source
model. To resolve this privacy issue, we further study the under-explored
problem of privacy-preserving domain adaptation and propose a method with a
novel differential privacy training strategy to protect the source data
privacy. We model the source feature distribution by Gaussian Mixture Models
(GMMs) under the differential privacy setting and send it to the target client
for adaptation. The target client resamples differentially private source
features from GMMs and adapts on target data with several state-of-art UDA
backbones. With our proposed method, the source data provider could avoid
leaking source data privacy during domain adaptation as well as reserve the
utility. To evaluate our proposed method's utility and privacy loss, we apply
our model on a medical report disease label classification task using two noisy
challenging clinical text datasets. The results show that our proposed method
can preserve source data's privacy with a minor performance influence on the
text classification task.</p>
  </details>
</details>
<details>
  <summary>16. <b>标题：Datasheet for the Pile</b></summary>
  <p><b>编号</b>：[183]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07311</p>
  <p><b>作者</b>：Stella Biderman,  Kieran Bicheno,  Leo Gao</p>
  <p><b>备注</b>：Accompanies "The Pile: An 800GB Dataset of Diverse Text for Language Modeling" arXiv:2101.00027</p>
  <p><b>关键词</b>：22 different text sources, party scrapes available online, text data made available, authored text compiled, original scrapes done</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This datasheet describes the Pile, a 825 GiB dataset of human-authored text
compiled by EleutherAI for use in large-scale language modeling. The Pile is
comprised of 22 different text sources, ranging from original scrapes done for
this project, to text data made available by the data owners, to third-party
scrapes available online.</p>
  </details>
</details>
<details>
  <summary>17. <b>标题：Extending the Vocabulary of Fictional Languages using Neural Networks</b></summary>
  <p><b>编号</b>：[190]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07288</p>
  <p><b>作者</b>：Thomas Zacharias,  Ashutosh Taklikar,  Raja Giryes</p>
  <p><b>备注</b>：10 pages, 1 figure, NeurIPS Workshop on Machine Learning for Creativity and Design 2021</p>
  <p><b>关键词</b>：given target fictional language, recent years appearing, machine translation tools, generate new words, deep learning solution</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Fictional languages have become increasingly popular over the recent years
appearing in novels, movies, TV shows, comics, and video games. While some of
these fictional languages have a complete vocabulary, most do not. We propose a
deep learning solution to the problem. Using style transfer and machine
translation tools, we generate new words for a given target fictional language,
while maintaining the style of its creator, hence extending this language
vocabulary.</p>
  </details>
</details>
<details>
  <summary>18. <b>标题：Annotating the Tweebank Corpus on Named Entity Recognition and Building  NLP Models for Social Media Analysis</b></summary>
  <p><b>编号</b>：[194]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07281</p>
  <p><b>作者</b>：Hang Jiang,  Yining Hua,  Doug Beeferman,  Deb Roy</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：twitter messages (" tweets ") pose, tb2 using amazon mechanical turk, syntactic parsing require highly domain, first annotate named entities, future tweet nlp research</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Social media data such as Twitter messages ("tweets") pose a particular
challenge to NLP systems because of their short, noisy, and colloquial nature.
Tasks such as Named Entity Recognition (NER) and syntactic parsing require
highly domain-matched training data for good performance. While there are some
publicly available annotated datasets of tweets, they are all purpose-built for
solving one task at a time. As yet there is no complete training corpus for
both syntactic analysis (e.g., part of speech tagging, dependency parsing) and
NER of tweets. In this study, we aim to create Tweebank-NER, an NER corpus
based on Tweebank V2 (TB2), and we use these datasets to train state-of-the-art
NLP models. We first annotate named entities in TB2 using Amazon Mechanical
Turk and measure the quality of our annotations. We train a Stanza NER model on
the new benchmark, achieving competitive performance against other
non-transformer NER systems. Finally, we train other Twitter NLP models (a
tokenizer, lemmatizer, part of speech tagger, and dependency parser) on TB2
based on Stanza, and achieve state-of-the-art or competitive performance on
these tasks. We release the dataset and make the models available to use in an
"off-the-shelf" manner for future Tweet NLP research. Our source code, data,
and pre-trained models are available at:
\url{this https URL}.</p>
  </details>
</details>
<h1>机器学习</h1>
<details>
  <summary>1. <b>标题：ConDor: Self-Supervised Canonicalization of 3D Pose for Partial Shapes</b></summary>
  <p><b>编号</b>：[1]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07788</p>
  <p><b>作者</b>：Rahul Sajnani,  Adrien Poulenard,  Jivitesh Jain,  Radhika Dua,  Leonidas J. Guibas,  Srinath Sridhar</p>
  <p><b>备注</b>：Preprint. For project page and code, see this https URL</p>
  <p><b>关键词</b>：segment object parts without, four new metrics show, partial 3d point clouds, partial 3d point clouds, partial 3d point cloud</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Progress in 3D object understanding has relied on manually canonicalized
shape datasets that contain instances with consistent position and orientation
(3D pose). This has made it hard to generalize these methods to in-the-wild
shapes, eg., from internet model collections or depth sensors. ConDor is a
self-supervised method that learns to Canonicalize the 3D orientation and
position for full and partial 3D point clouds. We build on top of Tensor Field
Networks (TFNs), a class of permutation- and rotation-equivariant, and
translation-invariant 3D networks. During inference, our method takes an unseen
full or partial 3D point cloud at an arbitrary pose and outputs an equivariant
canonical pose. During training, this network uses self-supervision losses to
learn the canonical pose from an un-canonicalized collection of full and
partial 3D point clouds. ConDor can also learn to consistently co-segment
object parts without any supervision. Extensive quantitative results on four
new metrics show that our approach outperforms existing methods while enabling
new applications such as operation on depth images and annotation transfer.</p>
  </details>
</details>
<details>
  <summary>2. <b>标题：Semantic-Aware Implicit Neural Audio-Driven Video Portrait Generation</b></summary>
  <p><b>编号</b>：[2]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07786</p>
  <p><b>作者</b>：Xian Liu,  Yinghao Xu,  Qianyi Wu,  Hang Zhou,  Wayne Wu,  Bolei Zhou</p>
  <p><b>备注</b>：12 pages, 3 figures. Project page: this https URL</p>
  <p><b>关键词</b>：driven portraits using one unified set, one unified neural radiance field, aware dynamic ray sampling module, detailed local facial semantics, accurate explicit structural information</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Animating high-fidelity video portrait with speech audio is crucial for
virtual reality and digital entertainment. While most previous studies rely on
accurate explicit structural information, recent works explore the implicit
scene representation of Neural Radiance Fields (NeRF) for realistic generation.
In order to capture the inconsistent motions as well as the semantic difference
between human head and torso, some work models them via two individual sets of
NeRF, leading to unnatural results. In this work, we propose Semantic-aware
Speaking Portrait NeRF (SSP-NeRF), which creates delicate audio-driven
portraits using one unified set of NeRF. The proposed model can handle the
detailed local facial semantics and the global head-torso relationship through
two semantic-aware modules. Specifically, we first propose a Semantic-Aware
Dynamic Ray Sampling module with an additional parsing branch that facilitates
audio-driven volume rendering. Moreover, to enable portrait rendering in one
unified neural radiance field, a Torso Deformation module is designed to
stabilize the large-scale non-rigid torso motions. Extensive evaluations
demonstrate that our proposed approach renders more realistic video portraits
compared to previous methods. Project page:
this https URL</p>
  </details>
</details>
<details>
  <summary>3. <b>标题：Towards a General Deep Feature Extractor for Facial Expression  Recognition</b></summary>
  <p><b>编号</b>：[4]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07781</p>
  <p><b>作者</b>：Liam Schoneveld,  Alice Othmani</p>
  <p><b>备注</b>：Published in: 2021 IEEE International Conference on Image Processing (ICIP). arXiv admin note: text overlap with arXiv:2103.09154</p>
  <p><b>关键词</b>：models often lack generalisation ability across datasets, extracted features also generalise extremely well, visual feature extractor general enough, google facial expression comparison datasets, end trained deep neural networks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The human face conveys a significant amount of information. Through facial
expressions, the face is able to communicate numerous sentiments without the
need for verbalisation. Visual emotion recognition has been extensively
studied. Recently several end-to-end trained deep neural networks have been
proposed for this task. However, such models often lack generalisation ability
across datasets. In this paper, we propose the Deep Facial Expression Vector
ExtractoR (DeepFEVER), a new deep learning-based approach that learns a visual
feature extractor general enough to be applied to any other facial emotion
recognition task or dataset. DeepFEVER outperforms state-of-the-art results on
the AffectNet and Google Facial Expression Comparison datasets. DeepFEVER's
extracted features also generalise extremely well to other datasets -- even
those unseen during training -- namely, the Real-World Affective Faces (RAF)
dataset.</p>
  </details>
</details>
<details>
  <summary>4. <b>标题：Look Closer: Bridging Egocentric and Third-Person Views with  Transformers for Robotic Manipulation</b></summary>
  <p><b>编号</b>：[5]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07779</p>
  <p><b>作者</b>：Rishabh Jangir,  Nicklas Hansen,  Sambaral Ghosal,  Mohit Jain,  Xiaolong Wang</p>
  <p><b>备注</b>：Accepted in Robotics and Automation Letters Journal (RA-L 2022). Website at this https URL 8 Pages</p>
  <p><b>关键词</b>：visual feedback using reinforcement learning, agent receives visual feedback, visual inputs alone, fuse visual information, trials versus 38</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Learning to solve precision-based manipulation tasks from visual feedback
using Reinforcement Learning (RL) could drastically reduce the engineering
efforts required by traditional robot systems. However, performing fine-grained
motor control from visual inputs alone is challenging, especially with a static
third-person camera as often used in previous work. We propose a setting for
robotic manipulation in which the agent receives visual feedback from both a
third-person camera and an egocentric camera mounted on the robot's wrist.
While the third-person camera is static, the egocentric camera enables the
robot to actively control its vision to aid in precise manipulation. To fuse
visual information from both cameras effectively, we additionally propose to
use Transformers with a cross-view attention mechanism that models spatial
attention from one view to another (and vice-versa), and use the learned
features as input to an RL policy. Our method improves learning over strong
single-view and multi-view baselines, and successfully transfers to a set of
challenging manipulation tasks on a real robot with uncalibrated cameras, no
access to state information, and a high degree of task variability. In a hammer
manipulation task, our method succeeds in 75% of trials versus 38% and 13% for
multi-view and single-view baselines, respectively.</p>
  </details>
</details>
<details>
  <summary>5. <b>标题：Uncertainty Quantification in Scientific Machine Learning: Methods,  Metrics, and Comparisons</b></summary>
  <p><b>编号</b>：[6]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07766</p>
  <p><b>作者</b>：Apostolos F Psaros,  Xuhui Meng,  Zongren Zou,  Ling Guo,  George Em Karniadakis</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：dimensional function spaces using nns, solving partial differential equations, suitable methods towards quantifying, tackling challenging inverse, learning operator mappings</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Neural networks (NNs) are currently changing the computational paradigm on
how to combine data with mathematical laws in physics and engineering in a
profound way, tackling challenging inverse and ill-posed problems not solvable
with traditional methods. However, quantifying errors and uncertainties in
NN-based inference is more complicated than in traditional methods. This is
because in addition to aleatoric uncertainty associated with noisy data, there
is also uncertainty due to limited data, but also due to NN hyperparameters,
overparametrization, optimization and sampling errors as well as model
misspecification. Although there are some recent works on uncertainty
quantification (UQ) in NNs, there is no systematic investigation of suitable
methods towards quantifying the total uncertainty effectively and efficiently
even for function approximation, and there is even less work on solving partial
differential equations and learning operator mappings between
infinite-dimensional function spaces using NNs. In this work, we present a
comprehensive framework that includes uncertainty modeling, new and existing
solution methods, as well as evaluation metrics and post-hoc improvement
approaches. To demonstrate the applicability and reliability of our framework,
we present an extensive comparative study in which various methods are tested
on prototype problems, including problems with mixed input-output data, and
stochastic problems in high dimensions. In the Appendix, we include a
comprehensive description of all the UQ methods employed, which we will make
available as open-source library of all codes included in this framework.</p>
  </details>
</details>
<details>
  <summary>6. <b>标题：Detection of Correlated Alarms Using Graph Embedding</b></summary>
  <p><b>编号</b>：[14]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07748</p>
  <p><b>作者</b>：Hossein Khaleghy,  Iman Izadi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：detecting correlated alarms based, recently progressed considerably, one contributing factor, decrease system efficiency, contain new information</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Industrial alarm systems have recently progressed considerably in terms of
network complexity and the number of alarms. The increase in complexity and
number of alarms presents challenges in these systems that decrease system
efficiency and cause distrust of the operator, which might result in widespread
damages. One contributing factor in alarm inefficiency is the correlated
alarms. These alarms do not contain new information and only confuse the
operator. This paper tries to present a novel method for detecting correlated
alarms based on artificial intelligence methods to help the operator. The
proposed method is based on graph embedding and alarm clustering, resulting in
the detection of correlated alarms. To evaluate the proposed method, a case
study is conducted on the well-known Tennessee-Eastman process.</p>
  </details>
</details>
<details>
  <summary>7. <b>标题：Towards holistic scene understanding: Semantic segmentation and beyond</b></summary>
  <p><b>编号</b>：[22]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07734</p>
  <p><b>作者</b>：Panagiotis Meletis</p>
  <p><b>备注</b>：PhD Thesis, Eindhoven University of Technology, October 2021</p>
  <p><b>关键词</b>：ecological footprint without sacrificing performance, dissertation addresses visual scene understanding, reasoning towards holistic scene understanding, exploiting various scene understanding datasets, sustainable visual scene understanding</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This dissertation addresses visual scene understanding and enhances
segmentation performance and generalization, training efficiency of networks,
and holistic understanding. First, we investigate semantic segmentation in the
context of street scenes and train semantic segmentation networks on
combinations of various datasets. In Chapter 2 we design a framework of
hierarchical classifiers over a single convolutional backbone, and train it
end-to-end on a combination of pixel-labeled datasets, improving
generalizability and the number of recognizable semantic concepts. Chapter 3
focuses on enriching semantic segmentation with weak supervision and proposes a
weakly-supervised algorithm for training with bounding box-level and
image-level supervision instead of only with per-pixel supervision. The memory
and computational load challenges that arise from simultaneous training on
multiple datasets are addressed in Chapter 4. We propose two methodologies for
selecting informative and diverse samples from datasets with weak supervision
to reduce our networks' ecological footprint without sacrificing performance.
Motivated by memory and computation efficiency requirements, in Chapter 5, we
rethink simultaneous training on heterogeneous datasets and propose a universal
semantic segmentation framework. This framework achieves consistent increases
in performance metrics and semantic knowledgeability by exploiting various
scene understanding datasets. Chapter 6 introduces the novel task of part-aware
panoptic segmentation, which extends our reasoning towards holistic scene
understanding. This task combines scene and parts-level semantics with
instance-level object detection. In conclusion, our contributions span over
convolutional network architectures, weakly-supervised learning, part and
panoptic segmentation, paving the way towards a holistic, rich, and sustainable
visual scene understanding.</p>
  </details>
</details>
<details>
  <summary>8. <b>标题：Scotch: An Efficient Secure Computation Framework for Secure Aggregation</b></summary>
  <p><b>编号</b>：[23]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07730</p>
  <p><b>作者</b>：Arup Mondal,  Yash More,  Prashanthi Ramachandran,  Priyam Panda,  Harpreet Virk,  Debayan Gupta</p>
  <p><b>备注</b>：Thirty-Sixth AAAI Conference on Artificial Intelligence (AAAI-22), Third AAAI Privacy-Preserving Artificial Intelligence (PPAI-22) Workshop</p>
  <p><b>关键词</b>：training dataset split amongst 3 participating users, federated learning enables multiple data owners, malicious aggregation server might use, machine learning model without revealing, preserving federated learning frameworks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Federated learning enables multiple data owners to jointly train a machine
learning model without revealing their private datasets. However, a malicious
aggregation server might use the model parameters to derive sensitive
information about the training dataset used. To address such leakage,
differential privacy and cryptographic techniques have been investigated in
prior work, but these often result in large communication overheads or impact
model performance. To mitigate this centralization of power, we propose
\textsc{Scotch}, a decentralized \textit{m-party} secure-computation framework
for federated aggregation that deploys MPC primitives, such as \textit{secret
sharing}. Our protocol is simple, efficient, and provides strict privacy
guarantees against curious aggregators or colluding data-owners with minimal
communication overheads compared to other existing \textit{state-of-the-art}
privacy-preserving federated learning frameworks. We evaluate our framework by
performing extensive experiments on multiple datasets with promising results.
\textsc{Scotch} can train the standard MLP NN with the training dataset split
amongst 3 participating users and 3 aggregating servers with 96.57\% accuracy
on MNIST, and 98.40\% accuracy on the Extended MNIST (digits) dataset, while
providing various optimizations.</p>
  </details>
</details>
<details>
  <summary>9. <b>标题：Visual Exploration of Machine Learning Model Behavior with Hierarchical  Surrogate Rule Sets</b></summary>
  <p><b>编号</b>：[27]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07724</p>
  <p><b>作者</b>：Jun Yuan,  Brian Barr,  Kyle Overton,  Enrico Bertini</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：also discuss many interesting observations, must share ancestor nodes, make inferences across rules, generates hierarchical rules based, interactive surrogate rule visualizations</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>One of the potential solutions for model interpretation is to train a
surrogate model: a more transparent model that approximates the behavior of the
model to be explained. Typically, classification rules or decision trees are
used due to the intelligibility of their logic-based expressions. However,
decision trees can grow too deep and rule sets can become too large to
approximate a complex model. Unlike paths on a decision tree that must share
ancestor nodes (conditions), rules are more flexible. However, the unstructured
visual representation of rules makes it hard to make inferences across rules.
To address these issues, we present a workflow that includes novel algorithmic
and interactive solutions. First, we present Hierarchical Surrogate Rules
(HSR), an algorithm that generates hierarchical rules based on user-defined
parameters. We also contribute SuRE, a visual analytics (VA) system that
integrates HSR and interactive surrogate rule visualizations. Particularly, we
present a novel feature-aligned tree to overcome the shortcomings of existing
rule visualizations. We evaluate the algorithm in terms of parameter
sensitivity, time performance, and comparison with surrogate decision trees and
find that it scales reasonably well and outperforms decision trees in many
respects. We also evaluate the visualization and the VA system by a usability
study with 24 volunteers and an observational study with 7 domain experts. Our
investigation shows that the participants can use feature-aligned trees to
perform non-trivial tasks with very high accuracy. We also discuss many
interesting observations that can be useful for future research on designing
effective rule-based VA systems.</p>
  </details>
</details>
<details>
  <summary>10. <b>标题：Enhancing the Security & Privacy of Wearable Brain-Computer Interfaces</b></summary>
  <p><b>编号</b>：[33]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07711</p>
  <p><b>作者</b>：Zahra Tarkhani,  Lorena Qendro,  Malachy O'Connor Brown,  Oscar Hill,  Cecilia Mascolo,  Anil Madhavapeddy</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：performance overhead (< 15 %)., wearable bci setups typically involve, first information flow control system, six major attack vectors, linux arm platforms suitable</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Brain computing interfaces (BCI) are used in a plethora of
safety/privacy-critical applications, ranging from healthcare to smart
communication and control. Wearable BCI setups typically involve a head-mounted
sensor connected to a mobile device, combined with ML-based data processing.
Consequently, they are susceptible to a multiplicity of attacks across the
hardware, software, and networking stacks used that can leak users' brainwave
data or at worst relinquish control of BCI-assisted devices to remote
attackers. In this paper, we: (i) analyse the whole-system security and privacy
threats to existing wearable BCI products from an operating system and
adversarial machine learning perspective; and (ii) introduce Argus, the first
information flow control system for wearable BCI applications that mitigates
these attacks. Argus' domain-specific design leads to a lightweight
implementation on Linux ARM platforms suitable for existing BCI use-cases. Our
proof of concept attacks on real-world BCI devices (Muse, NeuroSky, and
OpenBCI) led us to discover more than 300 vulnerabilities across the stacks of
six major attack vectors. Our evaluation shows Argus is highly effective in
tracking sensitive dataflows and restricting these attacks with an acceptable
memory and performance overhead (<15%).< p>
  </15%).<></p></details>
</details>
<details>
  <summary>11. <b>标题：Debiased Graph Neural Networks with Agnostic Label Selection Bias</b></summary>
  <p><b>编号</b>：[34]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07708</p>
  <p><b>作者</b>：Shaohua Fan,  Xiao Wang,  Chuan Shi,  Kun Kuang,  Nian Liu,  Bai Wang</p>
  <p><b>备注</b>：Accepted by TNNLS;12 pages</p>
  <p><b>关键词</b>：novel debiased graph neural networks, existing graph neural networks, several challenging graph datasets, biased selected nodes leads, differentiated decorrelation regularizer estimates</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Most existing Graph Neural Networks (GNNs) are proposed without considering
the selection bias in data, i.e., the inconsistent distribution between the
training set with test set. In reality, the test data is not even available
during the training process, making selection bias agnostic. Training GNNs with
biased selected nodes leads to significant parameter estimation bias and
greatly impacts the generalization ability on test nodes. In this paper, we
first present an experimental investigation, which clearly shows that the
selection bias drastically hinders the generalization ability of GNNs, and
theoretically prove that the selection bias will cause the biased estimation on
GNN parameters. Then to remove the bias in GNN estimation, we propose a novel
Debiased Graph Neural Networks (DGNN) with a differentiated decorrelation
regularizer. The differentiated decorrelation regularizer estimates a sample
weight for each labeled node such that the spurious correlation of learned
embeddings could be eliminated. We analyze the regularizer in causal view and
it motivates us to differentiate the weights of the variables based on their
contribution on the confounding bias. Then, these sample weights are used for
reweighting GNNs to eliminate the estimation bias, thus help to improve the
stability of prediction on unknown test nodes. Comprehensive experiments are
conducted on several challenging graph datasets with two kinds of label
selection biases. The results well verify that our proposed model outperforms
the state-of-the-art methods and DGNN is a flexible framework to enhance
existing GNNs.</p>
  </details>
</details>
<details>
  <summary>12. <b>标题：Object Detection in Autonomous Vehicles: Status and Open Challenges</b></summary>
  <p><b>编号</b>：[35]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07706</p>
  <p><b>作者</b>：Abhishek Balasubramaniam,  Sudeep Pasricha</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：perception system uses object detection algorithms, many consumer applications today, based object detectors play, robust driving performance, mobile text recognition</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Object detection is a computer vision task that has become an integral part
of many consumer applications today such as surveillance and security systems,
mobile text recognition, and diagnosing diseases from MRI/CT scans. Object
detection is also one of the critical components to support autonomous driving.
Autonomous vehicles rely on the perception of their surroundings to ensure safe
and robust driving performance. This perception system uses object detection
algorithms to accurately determine objects such as pedestrians, vehicles,
traffic signs, and barriers in the vehicle's vicinity. Deep learning-based
object detectors play a vital role in finding and localizing these objects in
real-time. This article discusses the state-of-the-art in object detectors and
open challenges for their integration into autonomous vehicles.</p>
  </details>
</details>
<details>
  <summary>13. <b>标题：Anytime Optimal PSRO for Two-Player Zero-Sum Games</b></summary>
  <p><b>编号</b>：[39]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07700</p>
  <p><b>作者</b>：Stephen McAleer,  Kevin Wang,  Marc Lanctot,  John Lanier,  Pierre Baldi,  Roy Fox</p>
  <p><b>备注</b>：Published in AAAI Reinforcement Learning in Games Workshop</p>
  <p><b>关键词</b>：calculates best responses via reinforcement learning, empirically found approximate nash equilibria, methods achieve far lower exploitability, propose anytime optimal double oracle, agent reinforcement learning algorithm</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Policy Space Response Oracles (PSRO) is a multi-agent reinforcement learning
algorithm for games that can handle continuous actions and has empirically
found approximate Nash equilibria in large games. PSRO is based on the tabular
Double Oracle (DO) method, an algorithm that is guaranteed to converge to a
Nash equilibrium, but may increase exploitability from one iteration to the
next. We propose Anytime Optimal Double Oracle (AODO), a tabular double oracle
algorithm for 2-player zero-sum games that is guaranteed to converge to a Nash
equilibrium while decreasing exploitability from iteration to iteration. Unlike
DO, in which the meta-strategy is based on the restricted game formed by each
player's strategy sets, AODO finds the meta-strategy for each player that
minimizes its exploitability against any policy in the full, unrestricted game.
We also propose a method of finding this meta-strategy via a no-regret
algorithm updated against a continually-trained best response, called RM-BR DO.
Finally, we propose Anytime Optimal PSRO, a version of AODO that calculates
best responses via reinforcement learning. In experiments on Leduc poker and
random normal form games, we show that our methods achieve far lower
exploitability than DO and PSRO and never increase exploitability.</p>
  </details>
</details>
<details>
  <summary>14. <b>标题：Learning to Rank For Push Notifications Using Pairwise Expected Regret</b></summary>
  <p><b>编号</b>：[44]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07681</p>
  <p><b>作者</b>：Yuguang Yue,  Yuanpu Xie,  Huasen Wu,  Haofeng Jia,  Shaodan Zhai,  Wenzhe Shi,  Jonathan J Hunt</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：content consumption present new challenges, personalized mobile push notifications, novel ranking loss based, traditional ranking problems, major social network</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Listwise ranking losses have been widely studied in recommender systems.
However, new paradigms of content consumption present new challenges for
ranking methods. In this work we contribute an analysis of learning to rank for
personalized mobile push notifications and discuss the unique challenges this
presents compared to traditional ranking problems. To address these challenges,
we introduce a novel ranking loss based on weighting the pairwise loss between
candidates by the expected regret incurred for misordering the pair. We
demonstrate that the proposed method can outperform prior methods both in a
simulated environment and in a production experiment on a major social network.</p>
  </details>
</details>
<details>
  <summary>15. <b>标题：Tiny, always-on and fragile: Bias propagation through design choices in  on-device machine learning workflows</b></summary>
  <p><b>编号</b>：[45]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07677</p>
  <p><b>作者</b>：Wiebke Toussaint,  Akhil Mathur,  Aaron Yi Ding,  Fahim Kawsar</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：resource constrained smart consumer devices deploy, disparate device failures across demographic groups, disparate performance across user groups, audio keyword spotting development workflow, seemingly innocuous design choices</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Billions of distributed, heterogeneous and resource constrained smart
consumer devices deploy on-device machine learning (ML) to deliver private,
fast and offline inference on personal data. On-device ML systems are highly
context dependent, and sensitive to user, usage, hardware and environmental
attributes. Despite this sensitivity and the propensity towards bias in ML,
bias in on-device ML has not been studied. This paper studies the propagation
of bias through design choices in on-device ML development workflows. We
position \emph{reliablity bias}, which arises from disparate device failures
across demographic groups, as a source of unfairness in on-device ML settings
and quantify metrics to evaluate it. We then identify complex and interacting
technical design choices in the on-device ML workflow that can lead to
disparate performance across user groups, and thus \emph{reliability bias}.
Finally, we show with an empirical case study that seemingly innocuous design
choices such as the data sample rate, pre-processing parameters used to
construct input features and pruning hyperparameters propagate
\emph{reliability bias} through an audio keyword spotting development workflow.
We leverage our insights to suggest strategies for developers to develop fairer
on-device ML.</p>
  </details>
</details>
<details>
  <summary>16. <b>标题：Code Sophistication: From Code Recommendation to Logic Recommendation</b></summary>
  <p><b>编号</b>：[47]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07674</p>
  <p><b>作者</b>：Jessie Galasso,  Michalis Famelis,  Houari Sahraoui</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：present early results showing, coding assistants usually focuses, recommending code fragments based, main execution scenario, leveraging code structure</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A typical approach to programming is to first code the main execution
scenario, and then focus on filling out alternative behaviors and corner cases.
But, almost always, there exist unusual conditions that trigger atypical
behaviors, which are hard to predict in program specifications, and are thus
often not coded. In this paper, we consider the problem of detecting and
recommending such missing behaviors, a task that we call code sophistication.
Previous research on coding assistants usually focuses on recommending code
fragments based on specifications of the intended behavior. In contrast, code
sophistication happens in the absence of a specification, aiming to help
developers complete the logic of their programs with missing and unspecified
behaviors. We outline the research challenges to this problem and present early
results showing how program logic can be completed by leveraging code structure
and information about the usage of input parameters.</p>
  </details>
</details>
<details>
  <summary>17. <b>标题：Top-Down Influence? Predicting CEO Personality and Risk Impact from  Speech Transcripts</b></summary>
  <p><b>编号</b>：[48]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07670</p>
  <p><b>作者</b>：Kilian Theil,  Dirk Hovy,  Heiner Stuckenschmidt</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：sourced myers -- briggs type indicator, based personality regressor using crowd, show empirically --, reported personality data, upper echelons theory</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>How much does a CEO's personality impact the performance of their company?
Management theory posits a great influence, but it is difficult to show
empirically -- there is a lack of publicly available self-reported personality
data of top managers. Instead, we propose a text-based personality regressor
using crowd-sourced Myers--Briggs Type Indicator (MBTI) assessments. The
ratings have a high internal and external validity and can be predicted with
moderate to strong correlations for three out of four dimensions. Providing
evidence for the upper echelons theory, we demonstrate that the predicted CEO
personalities have explanatory power of financial risk.</p>
  </details>
</details>
<details>
  <summary>18. <b>标题：DSNet: Dynamic Skin Deformation Prediction by Recurrent Neural Network</b></summary>
  <p><b>编号</b>：[53]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07660</p>
  <p><b>作者</b>：Hyewon Seo (ICube),  Kaifeng Zou (ICube),  Frederic Cordier (IRIMAS)</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：maintaining comparable prediction quality compared, existing mesh deformation sequence data, skin dynamics across different individuals, directly offer practical solutions, recent datadriven methods neither</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Skin dynamics contributes to the enriched realism of human body models in
rendered scenes. Traditional methods rely on physics-based simulations to
accurately reproduce the dynamic behavior of soft tissues. Due to the model
complexity and thus the heavy computation, however, they do not directly offer
practical solutions to domains where real-time performance is desirable. The
quality shapes obtained by physics-based simulations are not fully exploited by
example-based or more recent datadriven methods neither, with most of them
having focused on the modeling of static skin shapes by leveraging quality
data. To address these limitations, we present a learningbased method for
dynamic skin deformation. At the core of our work is a recurrent neural network
that learns to predict the nonlinear, dynamics-dependent shape change over time
from pre-existing mesh deformation sequence data. Our network also learns to
predict the variation of skin dynamics across different individuals with
varying body shapes. After training the network delivers realistic,
high-quality skin dynamics that is specific to a person in a real-time course.
We obtain results that significantly saves the computational time, while
maintaining comparable prediction quality compared to state-of-the-art results.</p>
  </details>
</details>
<details>
  <summary>19. <b>标题：Comprehensive Efficiency Analysis of Machine Learning Algorithms for  Developing Hardware-Based Cybersecurity Countermeasures</b></summary>
  <p><b>编号</b>：[54]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07654</p>
  <p><b>作者</b>：Darren Cobian</p>
  <p><b>备注</b>：54 pages, 17 figures/tables, 43 citations</p>
  <p><b>关键词</b>：new techniques use hardware performance counters, viewed relatively high overhead, comparable hpc values comes, make malware classification understandable, maintaining relatively high accuracy</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Modern computing systems have led cyber adversaries to create more
sophisticated malware than was previously available in the early days of
technology. Dated detection techniques such as Anti-Virus Software (AVS) based
on signature-based methods could no longer keep up with the demand that
computer systems required of them. The complexity of modern malware has led to
the development of contemporary detection techniques that use the machine
learning field and hardware to boost the detection rates of malicious software.
These new techniques use Hardware Performance Counters (HPCs) that form a
digital signature of sorts. After the models are fed training data, they can
reference these HPCs to classify zero-day malware samples. A problem emerges
when malware with no comparable HPC values comes into contact with these new
techniques. We provide an analysis of several machine learning and deep
learning models that run zero-day samples and evaluate the results from the
conversion of C++ algorithms to a hardware description language (HDL) used to
begin a hardware implementation. Our results present a lack of accuracy from
the models when running zero-day malware data as our highest detector, decision
tree, was only able to reach 91.2% accuracy and had an F1-Score of 91.5% in the
form of a decision tree. Next, through the Receiver Operating Curve (ROC) and
area-under-the-curve (AUC), we can also determine that the algorithms did not
present significant robustness as the largest AUC was only 0.819. In addition,
we viewed relatively high overhead for our ensemble learning algorithm while
also only having an 86.3% accuracy and 86% F1-Score. Finally, as an additional
task, we adapted the one rule algorithm to fit many rules to make malware
classification understandable to everyday users by allowing them to view the
regulations while maintaining relatively high accuracy.</p>
  </details>
</details>
<details>
  <summary>20. <b>标题：Malware Classification Using Static Disassembly and Machine Learning</b></summary>
  <p><b>编号</b>：[57]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07649</p>
  <p><b>作者</b>：Zhenshuo Chen,  Eoin Brophy,  Tomas Ward</p>
  <p><b>备注</b>：To be published in 29th AIAI Irish Conference on Artificial Intelligence and Cognitive Science</p>
  <p><b>关键词</b>：proposed features provide macroscopic information, relatively high dimensional feature set, related features like api sequences, novel proposed features together, use automatic machine learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Network and system security are incredibly critical issues now. Due to the
rapid proliferation of malware, traditional analysis methods struggle with
enormous samples.
In this paper, we propose four easy-to-extract and small-scale features,
including sizes and permissions of Windows PE sections, content complexity, and
import libraries, to classify malware families, and use automatic machine
learning to search for the best model and hyper-parameters for each feature and
their combinations. Compared with detailed behavior-related features like API
sequences, proposed features provide macroscopic information about malware. The
analysis is based on static disassembly scripts and hexadecimal machine code.
Unlike dynamic behavior analysis, static analysis is resource-efficient and
offers complete code coverage, but is vulnerable to code obfuscation and
encryption.
The results demonstrate that features which work well in dynamic analysis are
not necessarily effective when applied to static analysis. For instance, API
4-grams only achieve 57.96% accuracy and involve a relatively high dimensional
feature set (5000 dimensions). In contrast, the novel proposed features
together with a classical machine learning algorithm (Random Forest) presents
very good accuracy at 99.40% and the feature vector is of much smaller
dimension (40 dimensions). We demonstrate the effectiveness of this approach
through integration in IDA Pro, which also facilitates the collection of new
training samples and subsequent model retraining.</p>
  </details>
</details>
<details>
  <summary>21. <b>标题：A Survey on Training Challenges in Generative Adversarial Networks for  Biomedical Image Analysis</b></summary>
  <p><b>编号</b>：[58]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07646</p>
  <p><b>作者</b>：Muhammad Muneeb Saad,  Ruairi O'Reilly,  Mubashir Husain Rehmani</p>
  <p><b>备注</b>：Submitted to the Journal</p>
  <p><b>关键词</b>：vanishing gradient problem whereby unstable training behavior occurs due, deep learning models requiring large image datasets, discriminator achieving optimal classification performance resulting, mode collapse problem whereby, gradient descent optimizer fails</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In biomedical image analysis, the applicability of deep learning methods is
directly impacted by the quantity of image data available. This is due to deep
learning models requiring large image datasets to provide high-level
performance. Generative Adversarial Networks (GANs) have been widely utilized
to address data limitations through the generation of synthetic biomedical
images. GANs consist of two models. The generator, a model that learns how to
produce synthetic images based on the feedback it receives. The discriminator,
a model that classifies an image as synthetic or real and provides feedback to
the generator. Throughout the training process, a GAN can experience several
technical challenges that impede the generation of suitable synthetic imagery.
First, the mode collapse problem whereby the generator either produces an
identical image or produces a uniform image from distinct input features.
Second, the non-convergence problem whereby the gradient descent optimizer
fails to reach a Nash equilibrium. Thirdly, the vanishing gradient problem
whereby unstable training behavior occurs due to the discriminator achieving
optimal classification performance resulting in no meaningful feedback being
provided to the generator. These problems result in the production of synthetic
imagery that is blurry, unrealistic, and less diverse. To date, there has been
no survey article outlining the impact of these technical challenges in the
context of the biomedical imagery domain. This work presents a review and
taxonomy based on solutions to the training problems of GANs in the biomedical
imaging domain. This survey highlights important challenges and outlines future
research directions about the training of GANs in the domain of biomedical
imagery.</p>
  </details>
</details>
<details>
  <summary>22. <b>标题：Uncovering More Shallow Heuristics: Probing the Natural Language  Inference Capacities of Transformer-Based Pre-Trained Language Models Using  Syllogistic Patterns</b></summary>
  <p><b>编号</b>：[67]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07614</p>
  <p><b>作者</b>：Reto Gubelmann,  Siegfried Handschuh</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：shallow heuristics used, rather spurious heuristics, natural language inference, certain shallow heuristics, trained language models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this article, we explore the shallow heuristics used by transformer-based
pre-trained language models (PLMs) that are fine-tuned for natural language
inference (NLI). To do so, we construct or own dataset based on syllogistic,
and we evaluate a number of models' performance on our dataset. We find
evidence that the models rely heavily on certain shallow heuristics, picking up
on symmetries and asymmetries between premise and hypothesis. We suggest that
the lack of generalization observable in our study, which is becoming a topic
of lively debate in the field, means that the PLMs are currently not learning
NLI, but rather spurious heuristics.</p>
  </details>
</details>
<details>
  <summary>23. <b>标题：ReGNL: Rapid Prediction of GDP during Disruptive Events using  Nightlights</b></summary>
  <p><b>编号</b>：[68]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07612</p>
  <p><b>作者</b>：Rushabh Musthyala,  Rudrajit Kargupta,  Hritish Jain,  Dipanjan Chakraborty</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：policy makers often make decisions based, regnl outperforms timeseries arima methods, neural network based model, using remote sensing data, present regional gdp nightlight</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Policy makers often make decisions based on parameters such as GDP,
unemployment rate, industrial output, etc. The primary methods to obtain or
even estimate such information are resource intensive and time consuming. In
order to make timely and well-informed decisions, it is imperative to be able
to come up with proxies for these parameters which can be sampled quickly and
efficiently, especially during disruptive events, like the COVID-19 pandemic.
Recently, there has been a lot of focus on using remote sensing data for this
purpose. The data has become cheaper to collect compared to surveys, and can be
available in real time. In this work, we present Regional GDP NightLight
(ReGNL), a neural network based model which is trained on a custom dataset of
historical nightlights and GDP data along with the geographical coordinates of
a place, and estimates the GDP of the place, given the other parameters. Taking
the case of 50 US states, we find that ReGNL is disruption-agnostic and is able
to predict the GDP for both normal years (2019) and for years with a disruptive
event (2020). ReGNL outperforms timeseries ARIMA methods for prediction, even
during the pandemic. Following from our findings, we make a case for building
infrastructures to collect and make available granular data, especially in
resource-poor geographies, so that these can be leveraged for policy making
during disruptive events.</p>
  </details>
</details>
<details>
  <summary>24. <b>标题：Semi-Supervised Clustering with Contrastive Learning for Discovering New  Intents</b></summary>
  <p><b>编号</b>：[71]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07604</p>
  <p><b>作者</b>：Feng Wei,  Zhenbo Chen,  Zhenghong Hao,  Fengxin Yang,  Hua Wei,  Bing Han,  Sheng Guo</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：results show dcsc achieve best performance across, achieve better text representation, better overall clustering performance, make dcsc fully utilize, propose deep contrastive semi</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Most dialogue systems in real world rely on predefined intents and answers
for QA service, so discovering potential intents from large corpus previously
is really important for building such dialogue services. Considering that most
scenarios have few intents known already and most intents waiting to be
discovered, we focus on semi-supervised text clustering and try to make the
proposed method benefit from labeled samples for better overall clustering
performance. In this paper, we propose Deep Contrastive Semi-supervised
Clustering (DCSC), which aims to cluster text samples in a semi-supervised way
and provide grouped intents to operation staff. To make DCSC fully utilize the
limited known intents, we propose a two-stage training procedure for DCSC, in
which DCSC will be trained on both labeled samples and unlabeled samples, and
achieve better text representation and clustering performance. We conduct
experiments on two public datasets to compare our model with several popular
methods, and the results show DCSC achieve best performance across all datasets
and circumstances, indicating the effect of the improvements in our work.</p>
  </details>
</details>
<details>
  <summary>25. <b>标题：Including STDP to eligibility propagation in multi-layer recurrent  spiking neural networks</b></summary>
  <p><b>编号</b>：[72]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07602</p>
  <p><b>作者</b>：Werner van der Veen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：layer recurrent snn consistently outperforms, clear competitive learning algorithm, alif neuron model improves, train competitive recurrent snns, spiking neural networks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Spiking neural networks (SNNs) in neuromorphic systems are more energy
efficient compared to deep learning-based methods, but there is no clear
competitive learning algorithm for training such SNNs. Eligibility propagation
(e-prop) offers an efficient and biologically plausible way to train
competitive recurrent SNNs in low-power neuromorphic hardware. In this report,
previous performance of e-prop on a speech classification task is reproduced,
and the effects of including STDP-like behavior are analyzed. Including STDP to
the ALIF neuron model improves the classification performance, but this is not
the case for the Izhikevich e-prop neuron. Finally, it was found that e-prop
implemented in a single-layer recurrent SNN consistently outperforms a
multi-layer variant.</p>
  </details>
</details>
<details>
  <summary>26. <b>标题：Near-Optimal Sparse Allreduce for Distributed Deep Learning</b></summary>
  <p><b>编号</b>：[75]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07598</p>
  <p><b>作者</b>：Shigang Li,  Torsten Hoefler</p>
  <p><b>备注</b>：Published in Proceedings of the 27th ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming (PPoPP'22), April 2-6, 2022</p>
  <p><b>关键词</b>：decentralized parallel stochastic gradient descent, train large deep learning models, different deep learning domains, achieves similar model accuracy, significantly improves training throughput</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Communication overhead is one of the major obstacles to train large deep
learning models at scale. Gradient sparsification is a promising technique to
reduce the communication volume. However, it is very challenging to obtain real
performance improvement because of (1) the difficulty of achieving an scalable
and efficient sparse allreduce algorithm and (2) the sparsification overhead.
This paper proposes O$k$-Top$k$, a scheme for distributed training with sparse
gradients. O$k$-Top$k$ integrates a novel sparse allreduce algorithm (less than
6$k$ communication volume which is asymptotically optimal) with the
decentralized parallel Stochastic Gradient Descent (SGD) optimizer, and its
convergence is proved. To reduce the sparsification overhead, O$k$-Top$k$
efficiently selects the top-$k$ gradient values according to an estimated
threshold. Evaluations are conducted on the Piz Daint supercomputer with neural
network models from different deep learning domains. Empirical results show
that O$k$-Top$k$ achieves similar model accuracy to dense allreduce. Compared
with the optimized dense and the state-of-the-art sparse allreduces,
O$k$-Top$k$ is more scalable and significantly improves training throughput
(e.g., 3.29x-12.95x improvement for BERT on 256 GPUs).</p>
  </details>
</details>
<details>
  <summary>27. <b>标题：Models for information propagation on graphs</b></summary>
  <p><b>编号</b>：[82]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07577</p>
  <p><b>作者</b>：Oliver R. A. Dunbar,  Charles M. Elliott,  Lisa Maria Kreusser</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：euclidean space mean field limits, information wave front reaches nodes, certain graph models lead, travel time along paths, first arrival time model</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this work we propose and unify classes of different models for information
propagation over graphs. In a first class, propagation is modeled as a wave
which emanates from a set of known nodes at an initial time, to all other
unknown nodes at later times with an ordering determined by the time at which
the information wave front reaches nodes. A second class of models is based on
the notion of a travel time along paths between nodes. The time of information
propagation from an initial known set of nodes to a node is defined as the
minimum of a generalized travel time over subsets of all admissible paths. A
final class is given by imposing a local equation of an eikonal form at each
unknown node, with boundary conditions at the known nodes. The solution value
of the local equation at a node is coupled the neighbouring nodes with smaller
solution values. We provide precise formulations of the model classes in this
graph setting, and prove equivalences between them. Motivated by the connection
between first arrival time model and the eikonal equation in the continuum
setting, we demonstrate that for graphs in the particular form of grids in
Euclidean space mean field limits under grid refinement of certain graph models
lead to Hamilton-Jacobi PDEs. For a specific parameter setting, we demonstrate
that the solution on the grid approximates the Euclidean distance.</p>
  </details>
</details>
<details>
  <summary>28. <b>标题：Superpixel Pre-Segmentation of HER2 Slides for Efficient Annotation</b></summary>
  <p><b>编号</b>：[83]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07572</p>
  <p><b>作者</b>：Mathias Öttl,  Jana Mönius,  Christian Marzahl,  Matthias Rübner,  Carol I. Geppert,  Arndt Hartmann,  Matthias W. Beckmann,  Peter Fasching,  Andreas Maier,  Ramona Erber,  Katharina Breininger</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：medical image segmentation across different applications, evaluations show encouraging first results, standard simple linear iterative clustering, boundary f1 score increases, efficient manual refinement without</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Supervised deep learning has shown state-of-the-art performance for medical
image segmentation across different applications, including histopathology and
cancer research; however, the manual annotation of such data is extremely
laborious. In this work, we explore the use of superpixel approaches to compute
a pre-segmentation of HER2 stained images for breast cancer diagnosis that
facilitates faster manual annotation and correction in a second step. Four
methods are compared: Standard Simple Linear Iterative Clustering (SLIC) as a
baseline, a domain adapted SLIC, and superpixels based on feature embeddings of
a pretrained ResNet-50 and a denoising autoencoder. To tackle oversegmentation,
we propose to hierarchically merge superpixels, based on their content in the
respective feature space. When evaluating the approaches on fully manually
annotated images, we observe that the autoencoder-based superpixels achieve a
23% increase in boundary F1 score compared to the baseline SLIC superpixels.
Furthermore, the boundary F1 score increases by 73% when hierarchical
clustering is applied on the adapted SLIC and the autoencoder-based
superpixels. These evaluations show encouraging first results for a
pre-segmentation for efficient manual refinement without the need for an
initial set of annotated training data.</p>
  </details>
</details>
<details>
  <summary>29. <b>标题：Batch versus Sequential Active Learning for Recommender Systems</b></summary>
  <p><b>编号</b>：[84]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07571</p>
  <p><b>作者</b>：Toon De Pessemier,  Sander Vanhove,  Luc Martens</p>
  <p><b>备注</b>：11 pages, 12 figures, ORSUM@ACM RecSys 2021, 4th Workshop on Online Recommender Systems and User Modeling, in conjunction with the 15th ACM Conference on Recommender Systems</p>
  <p><b>关键词</b>：active learning strategies proactively select items, compare five active learning algorithms, three different predictor algorithms, active learning algorithms, best predictor turned</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recommender systems have been investigated for many years, with the aim of
generating the most accurate recommendations possible. However, available data
about new users is often insufficient, leading to inaccurate recommendations;
an issue that is known as the cold-start problem. A solution can be active
learning. Active learning strategies proactively select items and ask users to
rate these. This way, detailed user preferences can be acquired and as a
result, more accurate recommendations can be offered to the user. In this
study, we compare five active learning algorithms, combined with three
different predictor algorithms, which are used to estimate to what extent the
user would like the item that is asked to rate. In addition, two modes are
tested for selecting the items: batch mode (all items at once), and sequential
mode (the items one by one). Evaluation of the recommender in terms of rating
prediction, decision support, and the ranking of items, showed that sequential
mode produces the most accurate recommendations for dense data sets.
Differences between the active learning algorithms are small. For most active
learners, the best predictor turned out to be FunkSVD in combination with
sequential mode.</p>
  </details>
</details>
<details>
  <summary>30. <b>标题：Stability of Deep Neural Networks via discrete rough paths</b></summary>
  <p><b>编号</b>：[86]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07566</p>
  <p><b>作者</b>：Christian Bayer,  Peter K. Friz,  Nikolas Tapia</p>
  <p><b>备注</b>：21 pages, 2 figures</p>
  <p><b>关键词</b>：weights behaving like brownian motions, deep residual neural networks, estimates remain bounded even, interpret residual neural network, using rough path techniques</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Using rough path techniques, we provide a priori estimates for the output of
Deep Residual Neural Networks in terms of both the input data and the (trained)
network weights. As trained network weights are typically very rough when seen
as functions of the layer, we propose to derive stability bounds in terms of
the total $p$-variation of trained weights for any $p\in[1,3]$. Unlike the
$C^1$-theory underlying the neural ODE literature, our estimates remain bounded
even in the limiting case of weights behaving like Brownian motions, as
suggested in [arXiv:2105.12245]. Mathematically, we interpret residual neural
network as solutions to (rough) difference equations, and analyse them based on
recent results of discrete time signatures and rough path theory.</p>
  </details>
</details>
<details>
  <summary>31. <b>标题：Simpler is better: spectral regularization and up-sampling techniques  for variational autoencoders</b></summary>
  <p><b>编号</b>：[89]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07544</p>
  <p><b>作者</b>：Sara Björk,  Jonas Nordhaug Myhre,  Thomas Haugland Johansen</p>
  <p><b>备注</b>：Submitted to ICASSP 2022, 2022 IEEE International Conference on Acoustics, Speech and Signal Processing</p>
  <p><b>关键词</b>：simple 2d fourier transform, either replace transposed convolutions, based spectral regularization loss, spectral regularization term, neural networks remains</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Full characterization of the spectral behavior of generative models based on
neural networks remains an open issue. Recent research has focused heavily on
generative adversarial networks and the high-frequency discrepancies between
real and generated images. The current solution to avoid this is to either
replace transposed convolutions with bilinear up-sampling or add a spectral
regularization term in the generator. It is well known that Variational
Autoencoders (VAEs) also suffer from these issues. In this work, we propose a
simple 2D Fourier transform-based spectral regularization loss for the VAE and
show that it can achieve results equal to, or better than, the current
state-of-the-art in frequency-aware losses for generative models. In addition,
we experiment with altering the up-sampling procedure in the generator network
and investigate how it influences the spectral performance of the model. We
include experiments on synthetic and real data sets to demonstrate our results.</p>
  </details>
</details>
<details>
  <summary>32. <b>标题：GNN-based Android Malware Detection with Jumping Knowledge</b></summary>
  <p><b>编号</b>：[92]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07537</p>
  <p><b>作者</b>：Wai Weng Lo,  Siamak Layeghy,  Mohanad Sarhan,  Marcus Gallagher,  Marius Portmann</p>
  <p><b>备注</b>：9 pages, 5 figures</p>
  <p><b>关键词</b>：extensively evaluated using two benchmark datasets, new android malware detection method based, android function call graphs, procedural call path patterns, android malware detection</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper presents a new Android malware detection method based on Graph
Neural Networks (GNNs) with Jumping-Knowledge (JK). Android function call
graphs (FCGs) consist of a set of program functions and their inter-procedural
calls. Thus, this paper proposes a GNN-based method for Android malware
detection by capturing meaningful intra-procedural call path patterns. In
addition, a Jumping-Knowledge technique is applied to minimize the effect of
the over-smoothing problem, which is common in GNNs. The proposed method has
been extensively evaluated using two benchmark datasets. The results
demonstrate the superiority of our approach compared to baseline methods in
terms of key classification metrics, which demonstrates the potential of GNNs
in Android malware detection.</p>
  </details>
</details>
<details>
  <summary>33. <b>标题：Privacy-Aware Human Mobility Prediction via Adversarial Networks</b></summary>
  <p><b>编号</b>：[98]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07519</p>
  <p><b>作者</b>：Yuting Zhan,  Alex Kyllo,  Afra Mashhadi,  Hamed Haddadi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：address various societal research questions, four representative mobility datasets demonstrate, lagrangian loss weight parameters, different smart city scenarios, exploring pareto optimal setting</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As various mobile devices and location-based services are increasingly
developed in different smart city scenarios and applications, many unexpected
privacy leakages have arisen due to geolocated data collection and sharing.
While these geolocated data could provide a rich understanding of human
mobility patterns and address various societal research questions, privacy
concerns for users' sensitive information have limited their utilization. In
this paper, we design and implement a novel LSTM-based adversarial mechanism
with representation learning to attain a privacy-preserving feature
representation of the original geolocated data (mobility data) for a sharing
purpose. We quantify the utility-privacy trade-off of mobility datasets in
terms of trajectory reconstruction risk, user re-identification risk, and
mobility predictability. Our proposed architecture reports a Pareto Frontier
analysis that enables the user to assess this trade-off as a function of
Lagrangian loss weight parameters. The extensive comparison results on four
representative mobility datasets demonstrate the superiority of our proposed
architecture and the efficiency of the proposed privacy-preserving features
extractor. Our results show that by exploring Pareto optimal setting, we can
simultaneously increase both privacy (45%) and utility (32%).</p>
  </details>
</details>
<details>
  <summary>34. <b>标题：Can't Steal? Cont-Steal! Contrastive Stealing Attacks Against Image  Encoders</b></summary>
  <p><b>编号</b>：[99]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07513</p>
  <p><b>作者</b>：Zeyang Sha,  Xinlei He,  Ning Yu,  Michael Backes,  Yang Zhang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：computation resources expose image encoders, potential model stealing attacks --, target supervised classifiers given, encoder stealing attacks like, unsupervised representation learning techniques</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Unsupervised representation learning techniques have been developing rapidly
to make full use of unlabeled images. They encode images into rich features
that are oblivious to downstream tasks. Behind its revolutionary representation
power, the requirements for dedicated model designs and a massive amount of
computation resources expose image encoders to the risks of potential model
stealing attacks -- a cheap way to mimic the well-trained encoder performance
while circumventing the demanding requirements. Yet conventional attacks only
target supervised classifiers given their predicted labels and/or posteriors,
which leaves the vulnerability of unsupervised encoders unexplored. In this
paper, we first instantiate the conventional stealing attacks against encoders
and demonstrate their severer vulnerability compared with downstream
classifiers. To better leverage the rich representation of encoders, we further
propose Cont-Steal, a contrastive-learning-based attack, and validate its
improved stealing effectiveness in various experiment settings. As a takeaway,
we appeal to our community's attention to the intellectual property protection
of representation learning techniques, especially to the defenses against
encoder stealing attacks like ours.</p>
  </details>
</details>
<details>
  <summary>35. <b>标题：The Enforcers: Consistent Sparse-Discrete Methods for Constraining  Informative Emergent Communication</b></summary>
  <p><b>编号</b>：[117]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07452</p>
  <p><b>作者</b>：Seth Karten,  Siddharth Agrawal,  Mycal Tucker,  Dana Hughes,  Michael Lewis,  Julie Shah,  Katia Sycara</p>
  <p><b>备注</b>：Submitted to IJCAI 2022</p>
  <p><b>关键词</b>：humans additionally communicate via discrete linguistic tokens, agents must convey information unavailable, agents may hide information, successfully constrain training using, using discrete prototypes</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Communication enables agents to cooperate to achieve their goals. Learning
when to communicate, i.e. sparse communication, is particularly important where
bandwidth is limited, in situations where agents interact with humans, in
partially observable scenarios where agents must convey information unavailable
to others, and in non-cooperative scenarios where agents may hide information
to gain a competitive advantage. Recent work in learning sparse communication,
however, suffers from high variance training where, the price of decreasing
communication is a decrease in reward, particularly in cooperative tasks.
Sparse communications are necessary to match agent communication to limited
human bandwidth. Humans additionally communicate via discrete linguistic
tokens, previously shown to decrease task performance when compared to
continuous communication vectors. This research addresses the above issues by
limiting the loss in reward of decreasing communication and eliminating the
penalty for discretization. In this work, we successfully constrain training
using a learned gate to regulate when to communicate while using discrete
prototypes that reflect what to communicate for cooperative tasks with partial
observability. We provide two types of "Enforcers" for hard and soft budget
constraints and present results of communication under different budgets. We
show that our method satisfies constraints while yielding the same performance
as comparable, unconstrained methods.</p>
  </details>
</details>
<details>
  <summary>36. <b>标题：TourBERT: A pretrained language model for the tourism industry</b></summary>
  <p><b>编号</b>：[119]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07449</p>
  <p><b>作者</b>：Veronika Arefieva,  Roman Egger</p>
  <p><b>备注</b>：13 pages, 7 figures, 4 tables</p>
  <p><b>关键词</b>：bidirectional encoder representations, pretrained language model, natural language, specific tasks, specific tasks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The Bidirectional Encoder Representations from Transformers (BERT) is
currently one of the most important and state-of-the-art models for natural
language. However, it has also been shown that for domain-specific tasks it is
helpful to pretrain BERT on a domain-specific corpus. In this paper, we present
TourBERT, a pretrained language model for tourism. We describe how TourBERT was
developed and evaluated. The evaluations show that TourBERT is outperforming
BERT in all tourism-specific tasks.</p>
  </details>
</details>
<details>
  <summary>37. <b>标题：Dual Space Graph Contrastive Learning</b></summary>
  <p><b>编号</b>：[140]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07409</p>
  <p><b>作者</b>：Haoran Yang,  Hongxu Chen,  Shirui Pan,  Lin Li,  Philip S. Yu,  Guandong Xu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：conduct graph contrastive learning among views generated, ways generating contrasting pairs focus, unsupervised graph representation learning methods, novel graph contrastive learning method, construct proper contrasting pairs</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Unsupervised graph representation learning has emerged as a powerful tool to
address real-world problems and achieves huge success in the graph learning
domain. Graph contrastive learning is one of the unsupervised graph
representation learning methods, which recently attracts attention from
researchers and has achieved state-of-the-art performances on various tasks.
The key to the success of graph contrastive learning is to construct proper
contrasting pairs to acquire the underlying structural semantics of the graph.
However, this key part is not fully explored currently, most of the ways
generating contrasting pairs focus on augmenting or perturbating graph
structures to obtain different views of the input graph. But such strategies
could degrade the performances via adding noise into the graph, which may
narrow down the field of the applications of graph contrastive learning. In
this paper, we propose a novel graph contrastive learning method, namely
\textbf{D}ual \textbf{S}pace \textbf{G}raph \textbf{C}ontrastive (DSGC)
Learning, to conduct graph contrastive learning among views generated in
different spaces including the hyperbolic space and the Euclidean space. Since
both spaces have their own advantages to represent graph data in the embedding
spaces, we hope to utilize graph contrastive learning to bridge the spaces and
leverage advantages from both sides. The comparison experiment results show
that DSGC achieves competitive or better performances among all the datasets.
In addition, we conduct extensive experiments to analyze the impact of
different graph encoders on DSGC, giving insights about how to better leverage
the advantages of contrastive learning between different spaces.</p>
  </details>
</details>
<details>
  <summary>38. <b>标题：Flexible Parallel Learning in Edge Scenarios: Communication,  Computational and Energy Cost</b></summary>
  <p><b>编号</b>：[142]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07402</p>
  <p><b>作者</b>：Francesco Malandrino,  Carla Fabiana Chiasserini</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：based scenarios often require combining, distributed stochastic gradient descent )., distributed machine learning takes, parallelizing learning tasks across, split among multiple nodes</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Traditionally, distributed machine learning takes the guise of (i) different
nodes training the same model (as in federated learning), or (ii) one model
being split among multiple nodes (as in distributed stochastic gradient
descent). In this work, we highlight how fog- and IoT-based scenarios often
require combining both approaches, and we present a framework for flexible
parallel learning (FPL), achieving both data and model parallelism. Further, we
investigate how different ways of distributing and parallelizing learning tasks
across the participating nodes result in different computation, communication,
and energy costs. Our experiments, carried out using state-of-the-art
deep-network architectures and large-scale datasets, confirm that FPL allows
for an excellent trade-off among computational (hence energy) cost,
communication overhead, and learning performance.</p>
  </details>
</details>
<details>
  <summary>39. <b>标题：Overview frequency principle/spectral bias in deep learning</b></summary>
  <p><b>编号</b>：[145]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07395</p>
  <p><b>作者</b>：Zhi-Qin John Xu,  Yaoyu Zhang,  Tao Luo</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：-- dnns often fit functions, fourier analysis sheds lights, explains experimental phenomena emerging, dimensional synthetic data followed, frequency implicit bias reveals</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Understanding deep learning is increasingly emergent as it penetrates more
and more into industry and science. In recent years, a research line from
Fourier analysis sheds lights into this magical "black box" by showing a
Frequency Principle (F-Principle or spectral bias) of the training behavior of
deep neural networks (DNNs) -- DNNs often fit functions from low to high
frequency during the training. The F-Principle is first demonstrated by
one-dimensional synthetic data followed by the verification in high-dimensional
real datasets. A series of works subsequently enhance the validity of the
F-Principle. This low-frequency implicit bias reveals the strength of neural
network in learning low-frequency functions as well as its deficiency in
learning high-frequency functions. Such understanding inspires the design of
DNN-based algorithms in practical problems, explains experimental phenomena
emerging in various scenarios, and further advances the study of deep learning
from the frequency perspective. Although incomplete, we provide an overview of
F-Principle and propose some open problems for future research.</p>
  </details>
</details>
<details>
  <summary>40. <b>标题：Variational Autoencoder Generative Adversarial Network for Synthetic  Data Generation in Smart Home</b></summary>
  <p><b>编号</b>：[149]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07387</p>
  <p><b>作者</b>：Mina Razghandi,  Hao Zhou,  Melike Erol-Kantarci,  Damla Turgut</p>
  <p><b>备注</b>：Accepted by 2022 IEEE International Conference on Communications (ICC) , Copyright belongs to 2022 IEEE</p>
  <p><b>关键词</b>：used five key statistical parameters, proposed synthetic data generative model outperforms, variational autoencoder generative adversarial network, smart grid data generative model, smart grid data distribution</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Data is the fuel of data science and machine learning techniques for smart
grid applications, similar to many other fields. However, the availability of
data can be an issue due to privacy concerns, data size, data quality, and so
on. To this end, in this paper, we propose a Variational AutoEncoder Generative
Adversarial Network (VAE-GAN) as a smart grid data generative model which is
capable of learning various types of data distributions and generating
plausible samples from the same distribution without performing any prior
analysis on the data before the training phase.We compared the Kullback-Leibler
(KL) divergence, maximum mean discrepancy (MMD), and Wasserstein distance
between the synthetic data (electrical load and PV production) distribution
generated by the proposed model, vanilla GAN network, and the real data
distribution, to evaluate the performance of our model. Furthermore, we used
five key statistical parameters to describe the smart grid data distribution
and compared them between synthetic data generated by both models and real
data. Experiments indicate that the proposed synthetic data generative model
outperforms the vanilla GAN network. The distribution of VAE-GAN synthetic data
is the most comparable to that of real data.</p>
  </details>
</details>
<details>
  <summary>41. <b>标题：Online Deep Learning based on Auto-Encoder</b></summary>
  <p><b>编号</b>：[153]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07383</p>
  <p><b>作者</b>：Si-si Zhang,  Jian-wei Liu,  Xin Zuo,  Run-kun Lu,  Si-ming Lian</p>
  <p><b>备注</b>：30 pages</p>
  <p><b>关键词</b>：underlying abstract hierarchical latent information existing, extract abstract hierarchical latent representations, phase online deep learning based, fusion every hidden layer output, abstract hierarchical latent representations</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Online learning is an important technical means for sketching massive
real-time and high-speed data. Although this direction has attracted intensive
attention, most of the literature in this area ignore the following three
issues: (1) they think little of the underlying abstract hierarchical latent
information existing in examples, even if extracting these abstract
hierarchical latent representations is useful to better predict the class
labels of examples; (2) the idea of preassigned model on unseen datapoints is
not suitable for modeling streaming data with evolving probability
distribution. This challenge is referred as model flexibility. And so, with
this in minds, the online deep learning model we need to design should have a
variable underlying structure; (3) moreover, it is of utmost importance to
fusion these abstract hierarchical latent representations to achieve better
classification performance, and we should give different weights to different
levels of implicit representation information when dealing with the data
streaming where the data distribution changes. To address these issues, we
propose a two-phase Online Deep Learning based on Auto-Encoder (ODLAE). Based
on auto-encoder, considering reconstruction loss, we extract abstract
hierarchical latent representations of instances; Based on predictive loss, we
devise two fusion strategies: the output-level fusion strategy, which is
obtained by fusing the classification results of encoder each hidden layer; and
feature-level fusion strategy, which is leveraged self-attention mechanism to
fusion every hidden layer output. Finally, in order to improve the robustness
of the algorithm, we also try to utilize the denoising auto-encoder to yield
hierarchical latent representations. Experimental results on different datasets
are presented to verify the validity of our proposed algorithm (ODLAE)
outperforms several baselines.</p>
  </details>
</details>
<details>
  <summary>42. <b>标题：Prospective Learning: Back to the Future</b></summary>
  <p><b>编号</b>：[159]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07372</p>
  <p><b>作者</b>：Joshua T. Vogelstein,  Timothy Verstynen,  Konrad P. Kording,  Leyla Isik,  John W. Krakauer,  Ralph Etienne-Cummings,  Elizabeth L. Ogburn,  Carey E. Priebe,  Randal Burns,  Kwame Kutten,  James J. Knierim,  James B. Potash,  Thomas Hartung,  Lena Smirnova,  Paul Worley,  Alena Savonenko,  Ian Phillips,  Michael I. Miller,  Rene Vidal,  Jeremias Sulam,  Adam Charles,  Noah J. Cowan,  Maxim Bichuch,  Archana Venkataraman,  Chen Li,  Nitish Thakor,  Justus M Kebschull,  Marilyn Albert,  Jinchong Xu,  Marshall Hussain Shuler,  Brian Caffo,  Tilak Ratnanather,  Ali Geisa,  Seung-Eon Roh,  Eva Yezerets,  Meghana Madhyastha,  Javier J. How,  Tyler M. Tomita,  Jayanta Dey,  Ningyuan (Teresa) Huang,  Jong M. Shin,  Kaleab Alemayehu Kinfu,  Pratik Chaudhari,  Ben Baker,  Anna Schapiro,  Dinesh Jayaraman,  Eric Eaton,  Michael Platt,  Lyle Ungar,  et al. (14 additional authors not shown)</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：retrospective learning intelligence would merely, articulate four relevant factors, causal estimation enables learning, curiosity motivates taking actions, achieve previously unencountered goals</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Research on both natural intelligence (NI) and artificial intelligence (AI)
generally assumes that the future resembles the past: intelligent agents or
systems (what we call 'intelligence') observe and act on the world, then use
this experience to act on future experiences of the same kind. We call this
'retrospective learning'. For example, an intelligence may see a set of
pictures of objects, along with their names, and learn to name them. A
retrospective learning intelligence would merely be able to name more pictures
of the same objects. We argue that this is not what true intelligence is about.
In many real world problems, both NIs and AIs will have to learn for an
uncertain future. Both must update their internal models to be useful for
future tasks, such as naming fundamentally new objects and using these objects
effectively in a new context or to achieve previously unencountered goals. This
ability to learn for the future we call 'prospective learning'. We articulate
four relevant factors that jointly define prospective learning. Continual
learning enables intelligences to remember those aspects of the past which it
believes will be most useful in the future. Prospective constraints (including
biases and priors) facilitate the intelligence finding general solutions that
will be applicable to future problems. Curiosity motivates taking actions that
inform future decision making, including in previously unmet situations. Causal
estimation enables learning the structure of relations that guide choosing
actions for specific outcomes, even when the specific action-outcome
contingencies have never been observed before. We argue that a paradigm shift
from retrospective to prospective learning will enable the communities that
study intelligence to unite and overcome existing bottlenecks to more
effectively explain, augment, and engineer intelligences.</p>
  </details>
</details>
<details>
  <summary>43. <b>标题：Sandbox Sample Classification Using Behavioral Indicators of Compromise</b></summary>
  <p><b>编号</b>：[167]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07359</p>
  <p><b>作者</b>：M. Andrecut</p>
  <p><b>备注</b>：10 pages, 2 figures</p>
  <p><b>关键词</b>：traditional methods like logistic regression, various automated methods used, statistical monte carlo methods, system function calls performed, machine learning approach</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Behavioral Indicators of Compromise are associated with various automated
methods used to extract the sample behavior by observing the system function
calls performed in a virtual execution environment. Thus, every sample is
described by a set of BICs triggered by the sample behavior in the sandbox
environment. Here we discuss a Machine Learning approach to the classification
of the sandbox samples as MALICIOUS or BENIGN, based on the list of triggered
BICs. Besides the more traditional methods like Logistic Regression and Naive
Bayes Classification we also discuss a different approach inspired by the
statistical Monte Carlo methods. The numerical results are illustrated using
ThreatGRID and ReversingLabs data.</p>
  </details>
</details>
<details>
  <summary>44. <b>标题：Learning Tensor Representations for Meta-Learning</b></summary>
  <p><b>编号</b>：[171]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07348</p>
  <p><b>作者</b>：Samuel Deng,  Yilin Guo,  Daniel Hsu,  Debmalya Mandal</p>
  <p><b>备注</b>：Forthcoming at AISTATS-2022</p>
  <p><b>关键词</b>：common shared representation across different tasks, first step allows us estimating, specific observable side information, first method solves, previous linear models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We introduce a tensor-based model of shared representation for meta-learning
from a diverse set of tasks. Prior works on learning linear representations for
meta-learning assume that there is a common shared representation across
different tasks, and do not consider the additional task-specific observable
side information. In this work, we model the meta-parameter through an
order-$3$ tensor, which can adapt to the observed task features of the task. We
propose two methods to estimate the underlying tensor. The first method solves
a tensor regression problem and works under natural assumptions on the data
generating process. The second method uses the method of moments under
additional distributional assumptions and has an improved sample complexity in
terms of the number of tasks.
We also focus on the meta-test phase, and consider estimating task-specific
parameters on a new task. Substituting the estimated tensor from the first step
allows us estimating the task-specific parameters with very few samples of the
new task, thereby showing the benefits of learning tensor representations for
meta-learning. Finally, through simulation and several real-world datasets, we
evaluate our methods and show that it improves over previous linear models of
shared representations for meta-learning.</p>
  </details>
</details>
<details>
  <summary>45. <b>标题：Learning grammar with a divide-and-concur neural network</b></summary>
  <p><b>编号</b>：[172]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07341</p>
  <p><b>作者</b>：Sean Deyo,  Veit Elser</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：inferred grammar directly interpretable -- one, infer meaningful grammatical rules, construct grammatically valid sentences, concur iterative projection approach, relatively small number</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We implement a divide-and-concur iterative projection approach to
context-free grammar inference. Unlike most state-of-the-art models of natural
language processing, our method requires a relatively small number of discrete
parameters, making the inferred grammar directly interpretable -- one can read
off from a solution how to construct grammatically valid sentences. Another
advantage of our approach is the ability to infer meaningful grammatical rules
from just a few sentences, compared to the hundreds of gigabytes of training
data many other models employ. We demonstrate several ways of applying our
approach: classifying words and inferring a grammar from scratch, taking an
existing grammar and refining its categories and rules, and taking an existing
grammar and expanding its lexicon as it encounters new words in new data.</p>
  </details>
</details>
<details>
  <summary>46. <b>标题：Interpretable Single-Cell Set Classification with Kernel Mean Embeddings</b></summary>
  <p><b>编号</b>：[178]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07322</p>
  <p><b>作者</b>：Siyuan Shan,  Vishal Baskaran,  Haidong Yi,  Jolene Ranek,  Natalie Stanley,  Junier Oliva</p>
  <p><b>备注</b>：13 pages</p>
  <p><b>关键词</b>：large set cardinality also limits, method admits rich biological interpretability, using kernel mean embedding, multidimensional cell feature vectors, mass cytometry technologies measure</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Modern single-cell flow and mass cytometry technologies measure the
expression of several proteins of the individual cells within a blood or tissue
sample. Each profiled biological sample is thus represented by a set of
hundreds of thousands of multidimensional cell feature vectors, which incurs a
high computational cost to predict each biological sample's associated
phenotype with machine learning models. Such a large set cardinality also
limits the interpretability of machine learning models due to the difficulty in
tracking how each individual cell influences the ultimate prediction. Using
Kernel Mean Embedding to encode the cellular landscape of each profiled
biological sample, we can train a simple linear classifier and achieve
state-of-the-art classification accuracy on 3 flow and mass cytometry datasets.
Our model contains few parameters but still performs similarly to deep learning
models with millions of parameters. In contrast with deep learning approaches,
the linearity and sub-selection step of our model make it easy to interpret
classification results. Clustering analysis further shows that our method
admits rich biological interpretability for linking cellular heterogeneity to
clinical phenotype.</p>
  </details>
</details>
<details>
  <summary>47. <b>标题：Towards Federated Clustering: A Federated Fuzzy $c$-Means Algorithm  (FFCM)</b></summary>
  <p><b>编号</b>：[181]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07316</p>
  <p><b>作者</b>：Morris Stallmann,  Anna Wilbik</p>
  <p><b>备注</b>：International Workshop on Trustable, Verifiable and Auditable Federated Learning in Conjunction with AAAI 2022 (FL-AAAI-22)</p>
  <p><b>关键词</b>：helps addressing issues like non, identify good global clusters even, calculate global cluster centers, many challenges remain open, c $- means algorithm</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Federated Learning (FL) is a setting where multiple parties with distributed
data collaborate in training a joint Machine Learning (ML) model while keeping
all data local at the parties. Federated clustering is an area of research
within FL that is concerned with grouping together data that is globally
similar while keeping all data local. We describe how this area of research can
be of interest in itself, or how it helps addressing issues like
non-independently-identically-distributed (i.i.d.) data in supervised FL
frameworks. The focus of this work, however, is an extension of the federated
fuzzy $c$-means algorithm to the FL setting (FFCM) as a contribution towards
federated clustering. We propose two methods to calculate global cluster
centers and evaluate their behaviour through challenging numerical experiments.
We observe that one of the methods is able to identify good global clusters
even in challenging scenarios, but also acknowledge that many challenges remain
open.</p>
  </details>
</details>
<details>
  <summary>48. <b>标题：Bregman Deviations of Generic Exponential Families</b></summary>
  <p><b>编号</b>：[187]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07306</p>
  <p><b>作者</b>：Sayak Ray Chowdhury,  Patrick Saux,  Odalric-Ambrym Maillard,  Aditya Gopalan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：novel method yields competitive results, square yielding explicit forms, bregman information gain }., linear contextual multi, g ., gaussian</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We revisit the method of mixture technique, also known as the Laplace method,
to study the concentration phenomenon in generic exponential families.
Combining the properties of Bregman divergence associated with log-partition
function of the family with the method of mixtures for super-martingales, we
establish a generic bound controlling the Bregman divergence between the
parameter of the family and a finite sample estimate of the parameter. Our
bound is time-uniform and makes appear a quantity extending the classical
\textit{information gain} to exponential families, which we call the
\textit{Bregman information gain}. For the practitioner, we instantiate this
novel bound to several classical families, e.g., Gaussian, Bernoulli,
Exponential and Chi-square yielding explicit forms of the confidence sets and
the Bregman information gain. We further numerically compare the resulting
confidence bounds to state-of-the-art alternatives for time-uniform
concentration and show that this novel method yields competitive results.
Finally, we highlight how our results can be applied in a linear contextual
multi-armed bandit problem.</p>
  </details>
</details>
<details>
  <summary>49. <b>标题：Sparsification of Decomposable Submodular Functions</b></summary>
  <p><b>编号</b>：[189]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07289</p>
  <p><b>作者</b>：Akbar Rafiey,  Yuichi Yoshida</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：decomposable submodular functions whose objective, need prohibitively large amount, many data intensive applications, several simple submodular functions, time randomized sparsification algorithm</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Submodular functions are at the core of many machine learning and data mining
tasks. The underlying submodular functions for many of these tasks are
decomposable, i.e., they are sum of several simple submodular functions. In
many data intensive applications, however, the number of underlying submodular
functions in the original function is so large that we need prohibitively large
amount of time to process it and/or it does not even fit in the main memory. To
overcome this issue, we introduce the notion of sparsification for decomposable
submodular functions whose objective is to obtain an accurate approximation of
the original function that is a (weighted) sum of only a few submodular
functions. Our main result is a polynomial-time randomized sparsification
algorithm such that the expected number of functions used in the output is
independent of the number of underlying submodular functions in the original
function. We also study the effectiveness of our algorithm under various
constraints such as matroid and cardinality constraints. We complement our
theoretical analysis with an empirical study of the performance of our
algorithm.</p>
  </details>
</details>
<details>
  <summary>50. <b>标题：Conservative Distributional Reinforcement Learning with Safety  Constraints</b></summary>
  <p><b>编号</b>：[192]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07286</p>
  <p><b>作者</b>：Hengrui Zhang,  Youfang Lin,  Sheng Han,  Shuo Wang,  Kai Lv</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：policy reinforcement learning algorithm called conservative distributional maximum, utilize weighted average proportional integral derivative, cdmpo adapts distributional reinforcement learning method, final test results also illustrate, conservative value function loss</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Safety exploration can be regarded as a constrained Markov decision problem
where the expected long-term cost is constrained. Previous off-policy
algorithms convert the constrained optimization problem into the corresponding
unconstrained dual problem by introducing the Lagrangian relaxation technique.
However, the cost function of the above algorithms provides inaccurate
estimations and causes the instability of the Lagrange multiplier learning. In
this paper, we present a novel off-policy reinforcement learning algorithm
called Conservative Distributional Maximum a Posteriori Policy Optimization
(CDMPO). At first, to accurately judge whether the current situation satisfies
the constraints, CDMPO adapts distributional reinforcement learning method to
estimate the Q-function and C-function. Then, CDMPO uses a conservative value
function loss to reduce the number of violations of constraints during the
exploration process. In addition, we utilize Weighted Average Proportional
Integral Derivative (WAPID) to update the Lagrange multiplier stably. Empirical
results show that the proposed method has fewer violations of constraints in
the early exploration process. The final test results also illustrate that our
method has better risk control.</p>
  </details>
</details>
<details>
  <summary>51. <b>标题：TranAD: Deep Transformer Networks for Anomaly Detection in Multivariate  Time Series Data</b></summary>
  <p><b>编号</b>：[193]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07284</p>
  <p><b>作者</b>：Shreshth Tuli,  Giuliano Casale,  Nicholas R. Jennings</p>
  <p><b>备注</b>：Accepted in VLDB 2022</p>
  <p><b>关键词</b>：deep transformer network based anomaly detection, six publicly available datasets demonstrate, 17 %, reducing training times, accurately pinpoint anomalous observations, tranad increases f1 scores</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Efficient anomaly detection and diagnosis in multivariate time-series data is
of great importance for modern industrial applications. However, building a
system that is able to quickly and accurately pinpoint anomalous observations
is a challenging problem. This is due to the lack of anomaly labels, high data
volatility and the demands of ultra-low inference times in modern applications.
Despite the recent developments of deep learning approaches for anomaly
detection, only a few of them can address all of these challenges. In this
paper, we propose TranAD, a deep transformer network based anomaly detection
and diagnosis model which uses attention-based sequence encoders to swiftly
perform inference with the knowledge of the broader temporal trends in the
data. TranAD uses focus score-based self-conditioning to enable robust
multi-modal feature extraction and adversarial training to gain stability.
Additionally, model-agnostic meta learning (MAML) allows us to train the model
using limited data. Extensive empirical studies on six publicly available
datasets demonstrate that TranAD can outperform state-of-the-art baseline
methods in detection and diagnosis performance with data and time-efficient
training. Specifically, TranAD increases F1 scores by up to 17%, reducing
training times by up to 99% compared to the baselines.</p>
  </details>
</details>
<details>
  <summary>52. <b>标题：EP-PQM: Efficient Parametric Probabilistic Quantum Memory with Fewer  Qubits and Gates</b></summary>
  <p><b>编号</b>：[199]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07265</p>
  <p><b>作者</b>：Mushahid Khan,  Jean Paul Latyr Faye,  Udson C. Mendes,  Andriy Miranskyy</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：pqm also requires fewer gates, ml classification model using ep, pqm brings us closer, pqm requires less space, using probabilistic quantum memory</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Machine learning (ML) classification tasks can be carried out on a quantum
computer (QC) using Probabilistic Quantum Memory (PQM) and its extension,
Parameteric PQM (P-PQM) by calculating the Hamming distance between an input
pattern and a database of $r$ patterns containing $z$ features with $a$
distinct attributes.
For accurate computations, the feature must be encoded using one-hot
encoding, which is memory-intensive for multi-attribute datasets with $a>2$. We
can easily represent multi-attribute data more compactly on a classical
computer by replacing one-hot encoding with label encoding. However, replacing
these encoding schemes on a QC is not straightforward as PQM and P-PQM operate
at the quantum bit level.
We present an enhanced P-PQM, called EP-PQM, that allows label encoding of
data stored in a PQM data structure and reduces the circuit depth of the data
storage and retrieval procedures. We show implementations for an ideal QC and a
noisy intermediate-scale quantum (NISQ) device.
Our complexity analysis shows that the EP-PQM approach requires $O\left(z
\log_2(a)\right)$ qubits as opposed to $O(za)$ qubits for P-PQM. EP-PQM also
requires fewer gates, reducing gate count from $O\left(rza\right)$ to
$O\left(rz\log_2(a)\right)$.
For five datasets, we demonstrate that training an ML classification model
using EP-PQM requires 48% to 77% fewer qubits than P-PQM for datasets with
$a>2$. EP-PQM reduces circuit depth in the range of 60% to 96%, depending on
the dataset. The depth decreases further with a decomposed circuit, ranging
between 94% and 99%.
EP-PQM requires less space; thus, it can train on and classify larger
datasets than previous PQM implementations on NISQ devices. Furthermore,
reducing the number of gates speeds up the classification and reduces the noise
associated with deep quantum circuits. Thus, EP-PQM brings us closer to
scalable ML on a NISQ device.</p>
  </details>
</details>
<details>
  <summary>53. <b>标题：NSGZero: Efficiently Learning Non-Exploitable Policy in Large-Scale  Network Security Games with Neural Monte Carlo Tree Search</b></summary>
  <p><b>编号</b>：[205]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07224</p>
  <p><b>作者</b>：Wanqi Xue,  Bo An,  Chai Kiat Yeo</p>
  <p><b>备注</b>：Published as a conference paper in AAAI 2022</p>
  <p><b>关键词</b>：method achieves significantly better data efficiency, neural monte carlo tree search, nsgzero improves data efficiency, design deep neural networks, perform neural mcts</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>How resources are deployed to secure critical targets in networks can be
modelled by Network Security Games (NSGs). While recent advances in deep
learning (DL) provide a powerful approach to dealing with large-scale NSGs, DL
methods such as NSG-NFSP suffer from the problem of data inefficiency.
Furthermore, due to centralized control, they cannot scale to scenarios with a
large number of resources. In this paper, we propose a novel DL-based method,
NSGZero, to learn a non-exploitable policy in NSGs. NSGZero improves data
efficiency by performing planning with neural Monte Carlo Tree Search (MCTS).
Our main contributions are threefold. First, we design deep neural networks
(DNNs) to perform neural MCTS in NSGs. Second, we enable neural MCTS with
decentralized control, making NSGZero applicable to NSGs with many resources.
Third, we provide an efficient learning paradigm, to achieve joint training of
the DNNs in NSGZero. Compared to state-of-the-art algorithms, our method
achieves significantly better data efficiency and scalability.</p>
  </details>
</details>
<details>
  <summary>54. <b>标题：Do not rug on me: Zero-dimensional Scam Detection</b></summary>
  <p><b>编号</b>：[206]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07220</p>
  <p><b>作者</b>：Bruno Mazorra,  Victor Adan,  Vanesa Daza</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：trade digital assets without trusted third parties, models proposed achieved similar results, execute initial coin offering scams, detect potential rug pulls, new relevant features related</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Uniswap, like other DEXs, has gained much attention this year because it is a
non-custodial and publicly verifiable exchange that allows users to trade
digital assets without trusted third parties. However, its simplicity and lack
of regulation also makes it easy to execute initial coin offering scams by
listing non-valuable tokens. This method of performing scams is known as rug
pull, a phenomenon that already existed in traditional finance but has become
more relevant in DeFi. Various projects such as [34,37] have contributed to
detecting rug pulls in EVM compatible chains. However, the first longitudinal
and academic step to detecting and characterizing scam tokens on Uniswap was
made in [44]. The authors collected all the transactions related to the Uniswap
V2 exchange and proposed a machine learning algorithm to label tokens as scams.
However, the algorithm is only valuable for detecting scams accurately after
they have been executed. This paper increases their data set by 20K tokens and
proposes a new methodology to label tokens as scams. After manually analyzing
the data, we devised a theoretical classification of different malicious
maneuvers in Uniswap protocol. We propose various machine-learning-based
algorithms with new relevant features related to the token propagation and
smart contract heuristics to detect potential rug pulls before they occur. In
general, the models proposed achieved similar results. The best model obtained
an accuracy of 0.9936, recall of 0.9540, and precision of 0.9838 in
distinguishing non-malicious tokens from scams prior to the malicious maneuver.</p>
  </details>
</details>
<details>
  <summary>55. <b>标题：Layerwise Geo-Distributed Computing between Cloud and IoT</b></summary>
  <p><b>编号</b>：[208]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07215</p>
  <p><b>作者</b>：Satoshi Kamo,  Yiqiang Sheng</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：existing deep belief networks, typical deep neural network, distributed computing extends cloud, deep learning system, distributed mnist database</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we propose a novel architecture for a deep learning system,
named k-degree layer-wise network, to realize efficient geo-distributed
computing between Cloud and Internet of Things (IoT). The geo-distributed
computing extends Cloud to the geographical verge of the network in the
neighbor of IoT. The basic ideas of the proposal include a k-degree constraint
and a layer-wise constraint. The k-degree constraint is defined such that the
degree of each vertex on the h-th layer is exactly k(h) to extend the existing
deep belief networks and control the communication cost. The layer-wise
constraint is defined such that the layer-wise degrees are monotonically
decreasing in positive direction to gradually reduce the dimension of data. We
prove the k-degree layer-wise network is sparse, while a typical deep neural
network is dense. In an evaluation on the M-distributed MNIST database, the
proposal is superior to a state-of-the-art model in terms of communication cost
and learning time with scalability.</p>
  </details>
</details>
<details>
  <summary>56. <b>标题：Human-Level Control through Directly-Trained Deep Spiking Q-Networks</b></summary>
  <p><b>编号</b>：[210]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07211</p>
  <p><b>作者</b>：Guisong Liu,  Wenjie Deng,  Xiurui Xie,  Li Huang,  Huajin Tang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：trained deep spiking reinforcement learning architecture based, deep spiking reinforcement learning, direct spiking learning algorithm, deep spiking q, deep spiking q</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As the third-generation neural networks, Spiking Neural Networks (SNNs) have
great potential on neuromorphic hardware because of their high
energy-efficiency. However, Deep Spiking Reinforcement Learning (DSRL), i.e.,
the Reinforcement Learning (RL) based on SNNs, is still in its preliminary
stage due to the binary output and the non-differentiable property of the
spiking function. To address these issues, we propose a Deep Spiking Q-Network
(DSQN) in this paper. Specifically, we propose a directly-trained deep spiking
reinforcement learning architecture based on the Leaky Integrate-and-Fire (LIF)
neurons and Deep Q-Network (DQN). Then, we adapt a direct spiking learning
algorithm for the Deep Spiking Q-Network. We further demonstrate the advantages
of using LIF neurons in DSQN theoretically. Comprehensive experiments have been
conducted on 17 top-performing Atari games to compare our method with the
state-of-the-art conversion method. The experimental results demonstrate the
superiority of our method in terms of performance, stability, robustness and
energy-efficiency. To the best of our knowledge, our work is the first one to
achieve state-of-the-art performance on multiple Atari games with the
directly-trained SNN.</p>
  </details>
</details>
<details>
  <summary>57. <b>标题：Efficient Training of Spiking Neural Networks with Temporally-Truncated  Local Backpropagation through Time</b></summary>
  <p><b>编号</b>：[211]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07210</p>
  <p><b>作者</b>：Wenzhe Guo,  Mohammed E. Fouda,  Ahmed M. Eltawil,  Khaled Nabil Salama</p>
  <p><b>备注</b>：16</p>
  <p><b>关键词</b>：computational cost including gpu memory utilization, design space concerning temporal truncation length, different networks running different types, directly training spiking neural networks, local training block size</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Directly training spiking neural networks (SNNs) has remained challenging due
to complex neural dynamics and intrinsic non-differentiability in firing
functions. The well-known backpropagation through time (BPTT) algorithm
proposed to train SNNs suffers from large memory footprint and prohibits
backward and update unlocking, making it impossible to exploit the potential of
locally-supervised training methods. This work proposes an efficient and direct
training algorithm for SNNs that integrates a locally-supervised training
method with a temporally-truncated BPTT algorithm. The proposed algorithm
explores both temporal and spatial locality in BPTT and contributes to
significant reduction in computational cost including GPU memory utilization,
main memory access and arithmetic operations. We thoroughly explore the design
space concerning temporal truncation length and local training block size and
benchmark their impact on classification accuracy of different networks running
different types of tasks. The results reveal that temporal truncation has a
negative effect on the accuracy of classifying frame-based datasets, but leads
to improvement in accuracy on dynamic-vision-sensor (DVS) recorded datasets. In
spite of resulting information loss, local training is capable of alleviating
overfitting. The combined effect of temporal truncation and local training can
lead to the slowdown of accuracy drop and even improvement in accuracy. In
addition, training deep SNNs models such as AlexNet classifying CIFAR10-DVS
dataset leads to 7.26% increase in accuracy, 89.94% reduction in GPU memory,
10.79% reduction in memory access, and 99.64% reduction in MAC operations
compared to the standard end-to-end BPTT.</p>
  </details>
</details>
<details>
  <summary>58. <b>标题：Enhanced Self-Organizing Map Solution for the Traveling Salesman Problem</b></summary>
  <p><b>编号</b>：[213]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07208</p>
  <p><b>作者</b>：Joao P. A. Dantas,  Andre N. Costa,  Marcos R. O. A. Maximo,  Takashi Yoneyama</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：benchmark work brought consistent results, may inspire future efforts, traveling salesman problem, provided suboptimal solutions, organizing map method</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Using an enhanced Self-Organizing Map method, we provided suboptimal
solutions to the Traveling Salesman Problem. Besides, we employed
hyperparameter tuning to identify the most critical features in the algorithm.
All improvements in the benchmark work brought consistent results and may
inspire future efforts to improve this algorithm and apply it to different
problems.</p>
  </details>
</details>
<details>
  <summary>59. <b>标题：Deep Capsule Encoder-Decoder Network for Surrogate Modeling and  Uncertainty Quantification</b></summary>
  <p><b>编号</b>：[215]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07753</p>
  <p><b>作者</b>：Akshay Thakur,  Souvik Chakraborty</p>
  <p><b>备注</b>：18 pages</p>
  <p><b>关键词</b>：elliptic stochastic partial differential equation, based uncertainty quantification problem, based deep encoder, steady heat conduction, position information related</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose a novel \textit{capsule} based deep encoder-decoder model for
surrogate modeling and uncertainty quantification of systems in mechanics from
sparse data. The proposed framework is developed by adapting Capsule Network
(CapsNet) architecture into image-to-image regression encoder-decoder network.
Specifically, the aim is to exploit the benefits of CapsNet over convolution
neural network (CNN) $-$ retaining pose and position information related to an
entity to name a few. The performance of proposed approach is illustrated by
solving an elliptic stochastic partial differential equation (SPDE), which also
governs systems in mechanics such as steady heat conduction, ground water flow
or other diffusion processes, based uncertainty quantification problem with an
input dimensionality of $1024$. However, the problem definition does not the
restrict the random diffusion field to a particular covariance structure, and
the more strenuous task of response prediction for an arbitrary diffusion field
is solved. The obtained results from performance evaluation indicate that the
proposed approach is accurate, efficient, and robust.</p>
  </details>
</details>
<details>
  <summary>60. <b>标题：On the Complexity of a Practical Primal-Dual Coordinate Method</b></summary>
  <p><b>编号</b>：[218]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07684</p>
  <p><b>作者</b>：Ahmet Alacaoglu,  Volkan Cevher,  Stephen J. Wright</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：strongly )- convex -( strongly )- concave problems, obtain good practical performance, complexity bounds either match, prove complexity bounds, solving convex</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We prove complexity bounds for the primal-dual algorithm with random
extrapolation and coordinate descent (PURE-CD), which has been shown to obtain
good practical performance for solving convex-concave min-max problems with
bilinear coupling. Our complexity bounds either match or improve the best-known
results in the literature for both dense and sparse
(strongly)-convex-(strongly)-concave problems.</p>
  </details>
</details>
<details>
  <summary>61. <b>标题：Coupled Support Tensor Machine Classification for Multimodal  Neuroimaging Data</b></summary>
  <p><b>编号</b>：[219]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07683</p>
  <p><b>作者</b>：Li Peide,  Seyyid Emre Sofuoglu,  Tapabrata Maiti,  Selin Aviyente</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：capturing complementary information among modalities, advanced coupled matrix tensor factorization, multimodal tensor data classification problem, across different imaging modalities, identify complex interdependence among</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Multimodal data arise in various applications where information about the
same phenomenon is acquired from multiple sensors and across different imaging
modalities. Learning from multimodal data is of great interest in machine
learning and statistics research as this offers the possibility of capturing
complementary information among modalities. Multimodal modeling helps to
explain the interdependence between heterogeneous data sources, discovers new
insights that may not be available from a single modality, and improves
decision-making. Recently, coupled matrix-tensor factorization has been
introduced for multimodal data fusion to jointly estimate latent factors and
identify complex interdependence among the latent factors. However, most of the
prior work on coupled matrix-tensor factors focuses on unsupervised learning
and there is little work on supervised learning using the jointly estimated
latent factors. This paper considers the multimodal tensor data classification
problem. A Coupled Support Tensor Machine (C-STM) built upon the latent factors
jointly estimated from the Advanced Coupled Matrix Tensor Factorization (ACMTF)
is proposed. C-STM combines individual and shared latent factors with multiple
kernels and estimates a maximal-margin classifier for coupled matrix tensor
data. The classification risk of C-STM is shown to converge to the optimal
Bayes risk, making it a statistically consistent rule. C-STM is validated
through simulation studies as well as a simultaneous EEG-fMRI analysis. The
empirical evidence shows that C-STM can utilize information from multiple
sources and provide a better classification performance than traditional
single-mode classifiers.</p>
  </details>
</details>
<details>
  <summary>62. <b>标题：Multiblock ADMM for nonsmooth nonconvex optimization with nonlinear  coupling constraints</b></summary>
  <p><b>编号</b>：[220]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07657</p>
  <p><b>作者</b>：Le Thi Khanh Hien,  Dimitri Papadimitriou</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：multiblock nonsmooth nonconvex optimization problem, multiblock alternating direction method, provide preliminary numerical results, also establish iteration complexity, nonlinear coupling constraints</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper considers a multiblock nonsmooth nonconvex optimization problem
with nonlinear coupling constraints. By developing the idea of using the
information zone and adaptive regime proposed in [J. Bolte, S. Sabach and M.
Teboulle, Nonconvex Lagrangian-based optimization: Monitoring schemes and
global convergence, Mathematics of Operations Research, 43: 1210--1232, 2018],
we propose a multiblock alternating direction method of multipliers for solving
this problem. We specify the update of the primal variables by employing a
majorization minimization procedure in each block update. An independent
convergence analysis is conducted to prove subsequential as well as global
convergence of the generated sequence to a critical point of the augmented
Lagrangian. We also establish iteration complexity and provide preliminary
numerical results for the proposed algorithm.</p>
  </details>
</details>
<details>
  <summary>63. <b>标题：Cortical lesions, central vein sign, and paramagnetic rim lesions in  multiple sclerosis: emerging machine learning techniques and future avenues</b></summary>
  <p><b>编号</b>：[229]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07463</p>
  <p><b>作者</b>：Francesco La Rosa,  Maxence Wynen,  Omar Al-Louzi,  Erin S Beck,  Till Huelnhagen,  Pietro Maggi,  Jean-Philippe Thiran,  Tobias Kober,  Russell T Shinohara,  Pascal Sati,  Daniel S Reich,  Cristina Granziera,  Martina Absinta,  Meritxell Bach Cuadra</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：advanced ms lesional imaging biomarkers, white matter lesion segmentation, suggesting future research directions, specialized magnetic resonance imaging, diagnostic criteria lack specificity</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The current multiple sclerosis (MS) diagnostic criteria lack specificity, and
this may lead to misdiagnosis, which remains an issue in present-day clinical
practice. In addition, conventional biomarkers only moderately correlate with
MS disease progression. Recently, advanced MS lesional imaging biomarkers such
as cortical lesions (CL), the central vein sign (CVS), and paramagnetic rim
lesions (PRL), visible in specialized magnetic resonance imaging (MRI)
sequences, have shown higher specificity in differential diagnosis. Moreover,
studies have shown that CL and PRL are potential prognostic biomarkers, the
former correlating with cognitive impairments and the latter with early
disability progression. As machine learning-based methods have achieved
extraordinary performance in the assessment of conventional imaging biomarkers,
such as white matter lesion segmentation, several automated or semi-automated
methods have been proposed for CL, CVS, and PRL as well. In the present review,
we first introduce these advanced MS imaging biomarkers and their imaging
methods. Subsequently, we describe the corresponding machine learning-based
methods that were used to tackle these clinical questions, putting them into
context with respect to the challenges they are still facing, including
non-standardized MRI protocols, limited datasets, and moderate inter-rater
variability. We conclude by presenting the current limitations that prevent
their broader deployment and suggesting future research directions.</p>
  </details>
</details>
<details>
  <summary>64. <b>标题：On the Convergence Rates of Policy Gradient Methods</b></summary>
  <p><b>编号</b>：[230]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07443</p>
  <p><b>作者</b>：Lin Xiao</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：convergence guarantees using arbitrarily large step sizes, using geometrically increasing step sizes, horizon discounted markov decision problems, prove sharper sublinear convergence rate, inexact policy mirror descent method</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We consider infinite-horizon discounted Markov decision problems with finite
state and action spaces. We show that with direct parametrization in the policy
space, the weighted value function, although non-convex in general, is both
quasi-convex and quasi-concave. While quasi-convexity helps explain the
convergence of policy gradient methods to global optima, quasi-concavity hints
at their convergence guarantees using arbitrarily large step sizes that are not
dictated by the Lipschitz constant charactering smoothness of the value
function. In particular, we show that when using geometrically increasing step
sizes, a general class of policy mirror descent methods, including the natural
policy gradient method and a projected Q-descent method, all enjoy a linear
rate of convergence without relying on entropy or other strongly convex
regularization. In addition, we develop a theory of weak gradient-mapping
dominance and use it to prove sharper sublinear convergence rate of the
projected policy gradient method. Finally, we also analyze the convergence rate
of an inexact policy mirror descent method and estimate its sample complexity
under a simple generative model.</p>
  </details>
</details>
<details>
  <summary>65. <b>标题：Lifted Primal-Dual Method for Bilinearly Coupled Smooth Minimax  Optimization</b></summary>
  <p><b>编号</b>：[231]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07427</p>
  <p><b>作者</b>：Kiran Koshy Thekumparampil,  Niao He,  Sewoong Oh</p>
  <p><b>备注</b>：Submitted for review on Oct 15, 2021. Accepted to AISTATS 2022 on Jan 18, 2022</p>
  <p><b>关键词</b>：one gradient oracle call per iteration, log (\ frac1 {\ varepsilon }))$, $\ omega ((\ sqrt {\ frac, l_y ,\ mu_x ,\ mu_y, \|}{\ sqrt {\ mu_x</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We study the bilinearly coupled minimax problem: $\min_{x} \max_{y} f(x) +
y^\top A x - h(y)$, where $f$ and $h$ are both strongly convex smooth functions
and admit first-order gradient oracles. Surprisingly, no known first-order
algorithms have hitherto achieved the lower complexity bound of
$\Omega((\sqrt{\frac{L_x}{\mu_x}} + \frac{\|A\|}{\sqrt{\mu_x \mu_y}} +
\sqrt{\frac{L_y}{\mu_y}}) \log(\frac1{\varepsilon}))$ for solving this problem
up to an $\varepsilon$ primal-dual gap in the general parameter regime, where
$L_x, L_y,\mu_x,\mu_y$ are the corresponding smoothness and strongly convexity
constants.
We close this gap by devising the first optimal algorithm, the Lifted
Primal-Dual (LPD) method. Our method lifts the objective into an extended form
that allows both the smooth terms and the bilinear term to be handled optimally
and seamlessly with the same primal-dual framework. Besides optimality, our
method yields a desirably simple single-loop algorithm that uses only one
gradient oracle call per iteration. Moreover, when $f$ is just convex, the same
algorithm applied to a smoothed objective achieves the nearly optimal iteration
complexity. We also provide a direct single-loop algorithm, using the LPD
method, that achieves the iteration complexity of
$O(\sqrt{\frac{L_x}{\varepsilon}} + \frac{\|A\|}{\sqrt{\mu_y \varepsilon}} +
\sqrt{\frac{L_y}{\varepsilon}})$. Numerical experiments on quadratic minimax
problems and policy evaluation problems further demonstrate the fast
convergence of our algorithm in practice.</p>
  </details>
</details>
<details>
  <summary>66. <b>标题：Compressed Smooth Sparse Decomposition</b></summary>
  <p><b>编号</b>：[232]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07404</p>
  <p><b>作者</b>：Shancong Mou,  Jianjun Shi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：smooth plus sparse signal )., named compressed smooth sparse decomposition, kronecker compressed smooth sparse decomposition, also increases data storage, based image processing techniques</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Image-based anomaly detection systems are of vital importance in various
manufacturing applications. The resolution and acquisition rate of such systems
is increasing significantly in recent years under the fast development of image
sensing technology. This enables the detection of tiny defects in real-time.
However, such a high resolution and acquisition rate of image data not only
slows down the speed of image processing algorithms but also increases data
storage and transmission cost. To tackle this problem, we propose a fast and
data-efficient method with theoretical performance guarantee that is suitable
for sparse anomaly detection in images with a smooth background (smooth plus
sparse signal). The proposed method, named Compressed Smooth Sparse
Decomposition (CSSD), is a one-step method that unifies the compressive image
acquisition and decomposition-based image processing techniques. To further
enhance its performance in a high-dimensional scenario, a Kronecker Compressed
Smooth Sparse Decomposition (KronCSSD) method is proposed. Compared to
traditional smooth and sparse decomposition algorithms, significant
transmission cost reduction and computational speed boost can be achieved with
negligible performance loss. Simulation examples and several case studies in
various applications illustrate the effectiveness of the proposed framework.</p>
  </details>
</details>
<details>
  <summary>67. <b>标题：Weakly Supervised Contrastive Learning for Better Severity Scoring of  Lung Ultrasound</b></summary>
  <p><b>编号</b>：[234]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07357</p>
  <p><b>作者</b>：Gautam Rajendrakumar Gare,  Hai V. Tran,  Bennett P deBoisblanc,  Ricardo Luis Rodriguez,  John Michael Galeotti</p>
  <p><b>备注</b>：Under Review for MIDL 2022 conference</p>
  <p><b>关键词</b>：frame based model achieves comparable performance, based patient severity scoring models, entropy loss based training, contrastive learning method treats, combine frame severity predictions</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>With the onset of the COVID-19 pandemic, ultrasound has emerged as an
effective tool for bedside monitoring of patients. Due to this, a large amount
of lung ultrasound scans have been made available which can be used for AI
based diagnosis and analysis. Several AI-based patient severity scoring models
have been proposed that rely on scoring the appearance of the ultrasound scans.
AI models are trained using ultrasound-appearance severity scores that are
manually labeled based on standardized visual features. We address the
challenge of labeling every ultrasound frame in the video clips. Our
contrastive learning method treats the video clip severity labels as noisy weak
severity labels for individual frames, thus requiring only video-level labels.
We show that it performs better than the conventional cross-entropy loss based
training. We combine frame severity predictions to come up with video severity
predictions and show that the frame based model achieves comparable performance
to a video based TSM model, on a large dataset combining public and private
sources.</p>
  </details>
</details>
<details>
  <summary>68. <b>标题：A Deep Learning Approach for Semantic Segmentation of Unbalanced Data in  Electron Tomography of Catalytic Materials</b></summary>
  <p><b>编号</b>：[236]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07342</p>
  <p><b>作者</b>：Arda Genc,  Libor Kovarik,  Hamish L. Fraser</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：$\ gamma $- alumina support material, results using dice similarity coefficient, heterogeneous catalysts possess complex surface, weighted focal loss function achieved, $\ gamma $- alumina</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Heterogeneous catalysts possess complex surface and bulk structures,
relatively poor intrinsic contrast, and often a sparse distribution of the
catalytic nanoparticles (NPs), posing a significant challenge for image
segmentation, including the current state-of-the-art deep learning methods. To
tackle this problem, we apply a deep learning-based approach for the
multi-class semantic segmentation of a $\gamma$-Alumina/Pt catalytic material
in a class imbalance situation. Specifically, we used the weighted focal loss
as a loss function and attached it to the U-Net's fully convolutional network
architecture. We assessed the accuracy of our results using Dice similarity
coefficient (DSC), recall, precision, and Hausdorff distance (HD) metrics on
the overlap between the ground-truth and predicted segmentations. Our adopted
U-Net model with the weighted focal loss function achieved an average DSC score
of 0.96 $\pm$ 0.003 in the $\gamma$-Alumina support material and 0.84 $\pm$
0.03 in the Pt NPs segmentation tasks. We report an average boundary-overlap
error of less than 2 nm at the 90th percentile of HD for $\gamma$-Alumina and
Pt NPs segmentations. The complex surface morphology of the $\gamma$-Alumina
and its relation to the Pt NPs were visualized in 3D by the deep
learning-assisted automatic segmentation of a large data set of high-angle
annular dark-field (HAADF) scanning transmission electron microscopy (STEM)
tomography reconstructions.</p>
  </details>
</details>
<details>
  <summary>69. <b>标题：Convergence of policy gradient for entropy regularized MDPs with neural  network approximation in the mean-field regime</b></summary>
  <p><b>编号</b>：[237]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07296</p>
  <p><b>作者</b>：Bekzhan Kerimkulov,  James-Michael Leahy,  David Šiška,  Lukasz Szpruch</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：linear fokker -- planck -- kolmogorov equation, gradient flow converges exponentially fast, regularized markov decision processes, neural network approximation, mei et al</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We study the global convergence of policy gradient for infinite-horizon,
continuous state and action space, entropy-regularized Markov decision
processes (MDPs). We consider a softmax policy with (one-hidden layer) neural
network approximation in a mean-field regime. Additional entropic
regularization in the associated mean-field probability measure is added, and
the corresponding gradient flow is studied in the 2-Wasserstein metric. We show
that the objective function is increasing along the gradient flow. Further, we
prove that if the regularization in terms of the mean-field measure is
sufficient, the gradient flow converges exponentially fast to the unique
stationary solution, which is the unique maximizer of the regularized MDP
objective. Lastly, we study the sensitivity of the value function along the
gradient flow with respect to regularization parameters and the initial
condition. Our results rely on the careful analysis of non-linear
Fokker--Planck--Kolmogorov equation and extend the pioneering work of Mei et
al. 2020 and Agarwal et al. 2020, which quantify the global convergence rate of
policy gradient for entropy-regularized MDPs in the tabular setting.</p>
  </details>
</details>
<details>
  <summary>70. <b>标题：AI-based Carcinoma Detection and Classification Using Histopathological  Images: A Systematic Review</b></summary>
  <p><b>编号</b>：[238]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07231</p>
  <p><b>作者</b>：Swathi Prabhua,  Keerthana Prasada,  Antonio Robels-Kelly,  Xuequan Lu</p>
  <p><b>备注</b>：accepted to Computers in Biology and Medicine</p>
  <p><b>关键词</b>：carcinoma diagnosis using histopathological images, carcinoma diagnosis also reveals, based carcinoma diagnostic system, histopathological image analysis, automated carcinoma diagnosis</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Histopathological image analysis is the gold standard to diagnose cancer.
Carcinoma is a subtype of cancer that constitutes more than 80% of all cancer
cases. Squamous cell carcinoma and adenocarcinoma are two major subtypes of
carcinoma, diagnosed by microscopic study of biopsy slides. However, manual
microscopic evaluation is a subjective and time-consuming process. Many
researchers have reported methods to automate carcinoma detection and
classification. The increasing use of artificial intelligence (AI) in the
automation of carcinoma diagnosis also reveals a significant rise in the use of
deep network models. In this systematic literature review, we present a
comprehensive review of the state-of-the-art approaches reported in carcinoma
diagnosis using histopathological images. Studies are selected from well-known
databases with strict inclusion/exclusion criteria. We have categorized the
articles and recapitulated their methods based on specific organs of carcinoma
origin. Further, we have summarized pertinent literature on AI methods,
highlighted critical challenges and limitations, and provided insights on
future research direction in automated carcinoma diagnosis. Out of 101 articles
selected, most of the studies experimented on private datasets with varied
image sizes, obtaining accuracy between 63% and 100%. Overall, this review
highlights the need for a generalized AI-based carcinoma diagnostic system.
Additionally, it is desirable to have accountable approaches to extract
microscopic features from images of multiple magnifications that should mimic
pathologists' evaluations.</p>
  </details>
</details>
<details>
  <summary>71. <b>标题：Explainable Ensemble Machine Learning for Breast Cancer Diagnosis based  on Ultrasound Image Texture Features</b></summary>
  <p><b>编号</b>：[239]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07227</p>
  <p><b>作者</b>：Alireza Rezazadeh,  Yasamin Jafarian,  Ali Kord</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：proposed framework achieves high predictive performance, existing approaches overwhelmingly rely, breast cancer diagnosis based, explainable machine learning pipeline, breast cancer diagnosis</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Image classification is widely used to build predictive models for breast
cancer diagnosis. Most existing approaches overwhelmingly rely on deep
convolutional networks to build such diagnosis pipelines. These model
architectures, although remarkable in performance, are black-box systems that
provide minimal insight into the inner logic behind their predictions. This is
a major drawback as the explainability of prediction is vital for applications
such as cancer diagnosis. In this paper, we address this issue by proposing an
explainable machine learning pipeline for breast cancer diagnosis based on
ultrasound images. We extract first- and second-order texture features of the
ultrasound images and use them to build a probabilistic ensemble of decision
tree classifiers. Each decision tree learns to classify the input ultrasound
image by learning a set of robust decision thresholds for texture features of
the image. The decision path of the model predictions can then be interpreted
by decomposing the learned decision trees. Our results show that our proposed
framework achieves high predictive performance while being explainable.</p>
  </details>
</details>
<details>
  <summary>72. <b>标题：Is Contrastive Learning Suitable for Left Ventricular Segmentation in  Echocardiographic Images?</b></summary>
  <p><b>编号</b>：[240]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07219</p>
  <p><b>作者</b>：Mohamed Saeed,  Rand Muhtaseb,  Mohammad Yaqub</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：clinical experts manually annotate large volumes, art fully supervised algorithms, commonly used segmentation network, contrastive pretraining helps improve, solution achieves better results</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Contrastive learning has proven useful in many applications where access to
labelled data is limited. The lack of annotated data is particularly
problematic in medical image segmentation as it is difficult to have clinical
experts manually annotate large volumes of data. One such task is the
segmentation of cardiac structures in ultrasound images of the heart. In this
paper, we argue whether or not contrastive pretraining is helpful for the
segmentation of the left ventricle in echocardiography images. Furthermore, we
study the effect of this on two segmentation networks, DeepLabV3, as well as
the commonly used segmentation network, UNet. Our results show that contrastive
pretraining helps improve the performance on left ventricle segmentation,
particularly when annotated data is scarce. We show how to achieve comparable
results to state-of-the-art fully supervised algorithms when we train our
models in a self-supervised fashion followed by fine-tuning on just 5% of the
data. We also show that our solution achieves better results than what is
currently published on a large public dataset (EchoNet-Dynamic) and we compare
the performance of our solution on another smaller dataset (CAMUS) as well.</p>
  </details>
</details>
<details>
  <summary>73. <b>标题：Data-Driven Deep Learning Based Hybrid Beamforming for Aerial Massive  MIMO-OFDM Systems with Implicit CSI</b></summary>
  <p><b>编号</b>：[242]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.06778</p>
  <p><b>作者</b>：Zhen Gao,  Minghui Wu,  Chun Hu,  Feifei Gao,  Guanghui Wen,  Dezhi Zheng,  Jun Zhang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：dl )- based unified hybrid beamforming framework, conventional approaches separately processing different modules, downlink hybrid beamforming modules, downlink hybrid beamforming modules, based approach jointly models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In an aerial hybrid massive multiple-input multiple-output (MIMO) and
orthogonal frequency division multiplexing (OFDM) system, how to design a
spectral-efficient broadband multi-user hybrid beamforming with a limited pilot
and feedback overhead is challenging. To this end, by modeling the key
transmission modules as an end-to-end (E2E) neural network, this paper proposes
a data-driven deep learning (DL)-based unified hybrid beamforming framework for
both the time division duplex (TDD) and frequency division duplex (FDD) systems
with implicit channel state information (CSI). For TDD systems, the proposed
DL-based approach jointly models the uplink pilot combining and downlink hybrid
beamforming modules as an E2E neural network. While for FDD systems, we jointly
model the downlink pilot transmission, uplink CSI feedback, and downlink hybrid
beamforming modules as an E2E neural network. Different from conventional
approaches separately processing different modules, the proposed solution
simultaneously optimizes all modules with the sum rate as the optimization
object. Therefore, by perceiving the inherent property of air-to-ground massive
MIMO-OFDM channel samples, the DL-based E2E neural network can establish the
mapping function from the channel to the beamformer, so that the explicit
channel reconstruction can be avoided with reduced pilot and feedback overhead.
Besides, practical low-resolution phase shifters (PSs) introduce the
quantization constraint, leading to the intractable gradient backpropagation
when training the neural network. To mitigate the performance loss caused by
the phase quantization error, we adopt the transfer learning strategy to
further fine-tune the E2E neural network based on a pre-trained network that
assumes the ideal infinite-resolution PSs. Numerical results show that our
DL-based schemes have considerable advantages over state-of-the-art schemes.</p>
  </details>
</details>
<details>
  <summary>74. <b>标题：Using machine learning to parametrize postmerger signals from binary  neutron stars</b></summary>
  <p><b>编号</b>：[243]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.06461</p>
  <p><b>作者</b>：Tim Whittaker,  William E. East,  Stephen R. Green,  Luis Lehner,  Huan Yang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：massive neutron star remnant signals based, ultimately require $\ sim 10, binary neutron star postmerger waveforms, using synthetic training waveforms, interpolate across parameter space</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>There is growing interest in the detection and characterization of
gravitational waves from postmerger oscillations of binary neutron stars. These
signals contain information about the nature of the remnant and the
high-density and out-of-equilibrium physics of the postmerger processes, which
would complement any electromagnetic signal. However, the construction of
binary neutron star postmerger waveforms is much more complicated than for
binary black holes: (i) there are theoretical uncertainties in the neutron-star
equation of state and other aspects of the high-density physics, (ii) numerical
simulations are expensive and available ones only cover a small fraction of the
parameter space with limited numerical accuracy, and (iii) it is unclear how to
parametrize the theoretical uncertainties and interpolate across parameter
space. In this work, we describe the use of a machine-learning method called a
conditional variational autoencoder (CVAE) to construct postmerger models for
hyper/massive neutron star remnant signals based on numerical-relativity
simulations. The CVAE provides a probabilistic model, which encodes
uncertainties in the training data within a set of latent parameters. We
estimate that training such a model will ultimately require $\sim 10^4$
waveforms. However, using synthetic training waveforms as a proof-of-principle,
we show that the CVAE can be used as an accurate generative model and that it
encodes the equation of state in a useful latent representation.</p>
  </details>
</details>
<details>
  <summary>75. <b>标题：A Regularized Limited Memory BFGS method for Large-Scale Unconstrained  Optimization and its Efficient Implementations</b></summary>
  <p><b>编号</b>：[244]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2101.04413</p>
  <p><b>作者</b>：Hardik Tankaria,  Shinji Sugimoto,  Nobuo Yamashita</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：scale unconstrained optimization, certain regularization technique, wolfe line search, limited memory bfgs, bfgs method uses</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The limited memory BFGS (L-BFGS) method is one of the popular methods for
solving large-scale unconstrained optimization. Since the standard L-BFGS
method uses a line search to guarantee its global convergence, it sometimes
requires a large number of function evaluations. To overcome the difficulty, we
propose a new L-BFGS with a certain regularization technique. We show its
global convergence under the usual assumptions. In order to make the method
more robust and efficient, we also extend it with several techniques such as
nonmonotone technique and simultaneous use of the Wolfe line search. Finally,
we present some numerical results for test problems in CUTEst, which show that
the proposed method is robust in terms of solving number of problems.</p>
  </details>
</details>
<h1>人工智能</h1>
<details>
  <summary>1. <b>标题：ConDor: Self-Supervised Canonicalization of 3D Pose for Partial Shapes</b></summary>
  <p><b>编号</b>：[1]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07788</p>
  <p><b>作者</b>：Rahul Sajnani,  Adrien Poulenard,  Jivitesh Jain,  Radhika Dua,  Leonidas J. Guibas,  Srinath Sridhar</p>
  <p><b>备注</b>：Preprint. For project page and code, see this https URL</p>
  <p><b>关键词</b>：segment object parts without, four new metrics show, partial 3d point clouds, partial 3d point clouds, partial 3d point cloud</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Progress in 3D object understanding has relied on manually canonicalized
shape datasets that contain instances with consistent position and orientation
(3D pose). This has made it hard to generalize these methods to in-the-wild
shapes, eg., from internet model collections or depth sensors. ConDor is a
self-supervised method that learns to Canonicalize the 3D orientation and
position for full and partial 3D point clouds. We build on top of Tensor Field
Networks (TFNs), a class of permutation- and rotation-equivariant, and
translation-invariant 3D networks. During inference, our method takes an unseen
full or partial 3D point cloud at an arbitrary pose and outputs an equivariant
canonical pose. During training, this network uses self-supervision losses to
learn the canonical pose from an un-canonicalized collection of full and
partial 3D point clouds. ConDor can also learn to consistently co-segment
object parts without any supervision. Extensive quantitative results on four
new metrics show that our approach outperforms existing methods while enabling
new applications such as operation on depth images and annotation transfer.</p>
  </details>
</details>
<details>
  <summary>2. <b>标题：When Is It Acceptable to Break the Rules? Knowledge Representation of  Moral Judgement Based on Empirical Data</b></summary>
  <p><b>编号</b>：[8]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07763</p>
  <p><b>作者</b>：Edmond Awad,  Sydney Levine,  Andrea Loreggia,  Nicholas Mattei,  Iyad Rahwan,  Francesca Rossi,  Kartik Talamadupula,  Joshua Tenenbaum,  Max Kleiman-Weiner</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：standard `` dual process '' theories, world decision makers, developing ai systems, make moral judgments, human moral mind</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>One of the most remarkable things about the human moral mind is its
flexibility. We can make moral judgments about cases we have never seen before.
We can decide that pre-established rules should be broken. We can invent novel
rules on the fly. Capturing this flexibility is one of the central challenges
in developing AI systems that can interpret and produce human-like moral
judgment. This paper details the results of a study of real-world decision
makers who judge whether it is acceptable to break a well-established norm:
``no cutting in line.'' We gather data on how human participants judge the
acceptability of line-cutting in a range of scenarios. Then, in order to
effectively embed these reasoning capabilities into a machine, we propose a
method for modeling them using a preference-based structure, which captures a
novel modification to standard ``dual process'' theories of moral judgment.</p>
  </details>
</details>
<details>
  <summary>3. <b>标题：Summarising and Comparing Agent Dynamics with Contrastive Spatiotemporal  Abstraction</b></summary>
  <p><b>编号</b>：[13]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07749</p>
  <p><b>作者</b>：Tom Bewley,  Jonathan Lawry,  Arthur Richards</p>
  <p><b>备注</b>：13 pages (6 body, 1 references, 6 appendix). Pre-print; under review</p>
  <p><b>关键词</b>：deep reinforcement learning agents, theoretic divergence measure, textual communication methods, temporal dimensions according, evolving dynamical system</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We introduce a data-driven, model-agnostic technique for generating a
human-interpretable summary of the salient points of contrast within an
evolving dynamical system, such as the learning process of a control agent. It
involves the aggregation of transition data along both spatial and temporal
dimensions according to an information-theoretic divergence measure. A
practical algorithm is outlined for continuous state spaces, and deployed to
summarise the learning histories of deep reinforcement learning agents with the
aid of graphical and textual communication methods. We expect our method to be
complementary to existing techniques in the realm of agent interpretability.</p>
  </details>
</details>
<details>
  <summary>4. <b>标题：Towards holistic scene understanding: Semantic segmentation and beyond</b></summary>
  <p><b>编号</b>：[22]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07734</p>
  <p><b>作者</b>：Panagiotis Meletis</p>
  <p><b>备注</b>：PhD Thesis, Eindhoven University of Technology, October 2021</p>
  <p><b>关键词</b>：ecological footprint without sacrificing performance, dissertation addresses visual scene understanding, reasoning towards holistic scene understanding, exploiting various scene understanding datasets, sustainable visual scene understanding</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This dissertation addresses visual scene understanding and enhances
segmentation performance and generalization, training efficiency of networks,
and holistic understanding. First, we investigate semantic segmentation in the
context of street scenes and train semantic segmentation networks on
combinations of various datasets. In Chapter 2 we design a framework of
hierarchical classifiers over a single convolutional backbone, and train it
end-to-end on a combination of pixel-labeled datasets, improving
generalizability and the number of recognizable semantic concepts. Chapter 3
focuses on enriching semantic segmentation with weak supervision and proposes a
weakly-supervised algorithm for training with bounding box-level and
image-level supervision instead of only with per-pixel supervision. The memory
and computational load challenges that arise from simultaneous training on
multiple datasets are addressed in Chapter 4. We propose two methodologies for
selecting informative and diverse samples from datasets with weak supervision
to reduce our networks' ecological footprint without sacrificing performance.
Motivated by memory and computation efficiency requirements, in Chapter 5, we
rethink simultaneous training on heterogeneous datasets and propose a universal
semantic segmentation framework. This framework achieves consistent increases
in performance metrics and semantic knowledgeability by exploiting various
scene understanding datasets. Chapter 6 introduces the novel task of part-aware
panoptic segmentation, which extends our reasoning towards holistic scene
understanding. This task combines scene and parts-level semantics with
instance-level object detection. In conclusion, our contributions span over
convolutional network architectures, weakly-supervised learning, part and
panoptic segmentation, paving the way towards a holistic, rich, and sustainable
visual scene understanding.</p>
  </details>
</details>
<details>
  <summary>5. <b>标题：Visual Exploration of Machine Learning Model Behavior with Hierarchical  Surrogate Rule Sets</b></summary>
  <p><b>编号</b>：[27]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07724</p>
  <p><b>作者</b>：Jun Yuan,  Brian Barr,  Kyle Overton,  Enrico Bertini</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：also discuss many interesting observations, must share ancestor nodes, make inferences across rules, generates hierarchical rules based, interactive surrogate rule visualizations</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>One of the potential solutions for model interpretation is to train a
surrogate model: a more transparent model that approximates the behavior of the
model to be explained. Typically, classification rules or decision trees are
used due to the intelligibility of their logic-based expressions. However,
decision trees can grow too deep and rule sets can become too large to
approximate a complex model. Unlike paths on a decision tree that must share
ancestor nodes (conditions), rules are more flexible. However, the unstructured
visual representation of rules makes it hard to make inferences across rules.
To address these issues, we present a workflow that includes novel algorithmic
and interactive solutions. First, we present Hierarchical Surrogate Rules
(HSR), an algorithm that generates hierarchical rules based on user-defined
parameters. We also contribute SuRE, a visual analytics (VA) system that
integrates HSR and interactive surrogate rule visualizations. Particularly, we
present a novel feature-aligned tree to overcome the shortcomings of existing
rule visualizations. We evaluate the algorithm in terms of parameter
sensitivity, time performance, and comparison with surrogate decision trees and
find that it scales reasonably well and outperforms decision trees in many
respects. We also evaluate the visualization and the VA system by a usability
study with 24 volunteers and an observational study with 7 domain experts. Our
investigation shows that the participants can use feature-aligned trees to
perform non-trivial tasks with very high accuracy. We also discuss many
interesting observations that can be useful for future research on designing
effective rule-based VA systems.</p>
  </details>
</details>
<details>
  <summary>6. <b>标题：Improving Behavioural Cloning with Human-Driven Dynamic Dataset  Augmentation</b></summary>
  <p><b>编号</b>：[28]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07719</p>
  <p><b>作者</b>：Federico Malato,  Joona Jehkonen,  Ville Hautamäki</p>
  <p><b>备注</b>：6 pages, 5 figures, 2 code snippets, accepted at the AAAI-22 Workshop on Interactive Machine Learning</p>
  <p><b>关键词</b>：teach general behaviours based, supervised learning paradigm, provide optimal solutions, overcome tricky situations, loop training solves</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Behavioural cloning has been extensively used to train agents and is
recognized as a fast and solid approach to teach general behaviours based on
expert trajectories. Such method follows the supervised learning paradigm and
it strongly depends on the distribution of the data. In our paper, we show how
combining behavioural cloning with human-in-the-loop training solves some of
its flaws and provides an agent task-specific corrections to overcome tricky
situations while speeding up the training time and lowering the required
resources. To do this, we introduce a novel approach that allows an expert to
take control of the agent at any moment during a simulation and provide optimal
solutions to its problematic situations. Our experiments show that this
approach leads to better policies both in terms of quantitative evaluation and
in human-likeliness.</p>
  </details>
</details>
<details>
  <summary>7. <b>标题：Debiased Graph Neural Networks with Agnostic Label Selection Bias</b></summary>
  <p><b>编号</b>：[34]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07708</p>
  <p><b>作者</b>：Shaohua Fan,  Xiao Wang,  Chuan Shi,  Kun Kuang,  Nian Liu,  Bai Wang</p>
  <p><b>备注</b>：Accepted by TNNLS;12 pages</p>
  <p><b>关键词</b>：novel debiased graph neural networks, existing graph neural networks, several challenging graph datasets, biased selected nodes leads, differentiated decorrelation regularizer estimates</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Most existing Graph Neural Networks (GNNs) are proposed without considering
the selection bias in data, i.e., the inconsistent distribution between the
training set with test set. In reality, the test data is not even available
during the training process, making selection bias agnostic. Training GNNs with
biased selected nodes leads to significant parameter estimation bias and
greatly impacts the generalization ability on test nodes. In this paper, we
first present an experimental investigation, which clearly shows that the
selection bias drastically hinders the generalization ability of GNNs, and
theoretically prove that the selection bias will cause the biased estimation on
GNN parameters. Then to remove the bias in GNN estimation, we propose a novel
Debiased Graph Neural Networks (DGNN) with a differentiated decorrelation
regularizer. The differentiated decorrelation regularizer estimates a sample
weight for each labeled node such that the spurious correlation of learned
embeddings could be eliminated. We analyze the regularizer in causal view and
it motivates us to differentiate the weights of the variables based on their
contribution on the confounding bias. Then, these sample weights are used for
reweighting GNNs to eliminate the estimation bias, thus help to improve the
stability of prediction on unknown test nodes. Comprehensive experiments are
conducted on several challenging graph datasets with two kinds of label
selection biases. The results well verify that our proposed model outperforms
the state-of-the-art methods and DGNN is a flexible framework to enhance
existing GNNs.</p>
  </details>
</details>
<details>
  <summary>8. <b>标题：Object Detection in Autonomous Vehicles: Status and Open Challenges</b></summary>
  <p><b>编号</b>：[35]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07706</p>
  <p><b>作者</b>：Abhishek Balasubramaniam,  Sudeep Pasricha</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：perception system uses object detection algorithms, many consumer applications today, based object detectors play, robust driving performance, mobile text recognition</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Object detection is a computer vision task that has become an integral part
of many consumer applications today such as surveillance and security systems,
mobile text recognition, and diagnosing diseases from MRI/CT scans. Object
detection is also one of the critical components to support autonomous driving.
Autonomous vehicles rely on the perception of their surroundings to ensure safe
and robust driving performance. This perception system uses object detection
algorithms to accurately determine objects such as pedestrians, vehicles,
traffic signs, and barriers in the vehicle's vicinity. Deep learning-based
object detectors play a vital role in finding and localizing these objects in
real-time. This article discusses the state-of-the-art in object detectors and
open challenges for their integration into autonomous vehicles.</p>
  </details>
</details>
<details>
  <summary>9. <b>标题：GEMEL: Model Merging for Memory-Efficient, Real-Time Video Analytics at  the Edge</b></summary>
  <p><b>编号</b>：[36]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07705</p>
  <p><b>作者</b>：Arthi Padmanabhan,  Neil Agarwal,  Anand Iyer,  Ganesh Ananthanarayanan,  Yuanchao Shu,  Nikolaos Karianakis,  Guoqing Harry Xu,  Ravi Netravali</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：experiments across diverse workloads reveal, leveraging several guiding observations, new memory management technique, reduce workload memory costs, required swapping delays result</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Video analytics pipelines have steadily shifted to edge deployments to reduce
bandwidth overheads and privacy violations, but in doing so, face an
ever-growing resource tension. Most notably, edge-box GPUs lack the memory
needed to concurrently house the growing number of (increasingly complex)
models for real-time inference. Unfortunately, existing solutions that rely on
time/space sharing of GPU resources are insufficient as the required swapping
delays result in unacceptable frame drops and accuracy violations. We present
model merging, a new memory management technique that exploits architectural
similarities between edge vision models by judiciously sharing their layers
(including weights) to reduce workload memory costs and swapping delays. Our
system, GEMEL, efficiently integrates merging into existing pipelines by (1)
leveraging several guiding observations about per-model memory usage and
inter-layer dependencies to quickly identify fruitful and accuracy-preserving
merging configurations, and (2) altering edge inference schedules to maximize
merging benefits. Experiments across diverse workloads reveal that GEMEL
reduces memory usage by up to 60.7%, and improves overall accuracy by 8-39%
relative to time/space sharing alone.</p>
  </details>
</details>
<details>
  <summary>10. <b>标题：DSNet: Dynamic Skin Deformation Prediction by Recurrent Neural Network</b></summary>
  <p><b>编号</b>：[53]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07660</p>
  <p><b>作者</b>：Hyewon Seo (ICube),  Kaifeng Zou (ICube),  Frederic Cordier (IRIMAS)</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：maintaining comparable prediction quality compared, existing mesh deformation sequence data, skin dynamics across different individuals, directly offer practical solutions, recent datadriven methods neither</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Skin dynamics contributes to the enriched realism of human body models in
rendered scenes. Traditional methods rely on physics-based simulations to
accurately reproduce the dynamic behavior of soft tissues. Due to the model
complexity and thus the heavy computation, however, they do not directly offer
practical solutions to domains where real-time performance is desirable. The
quality shapes obtained by physics-based simulations are not fully exploited by
example-based or more recent datadriven methods neither, with most of them
having focused on the modeling of static skin shapes by leveraging quality
data. To address these limitations, we present a learningbased method for
dynamic skin deformation. At the core of our work is a recurrent neural network
that learns to predict the nonlinear, dynamics-dependent shape change over time
from pre-existing mesh deformation sequence data. Our network also learns to
predict the variation of skin dynamics across different individuals with
varying body shapes. After training the network delivers realistic,
high-quality skin dynamics that is specific to a person in a real-time course.
We obtain results that significantly saves the computational time, while
maintaining comparable prediction quality compared to state-of-the-art results.</p>
  </details>
</details>
<details>
  <summary>11. <b>标题：Problem examination for AI methods in product design</b></summary>
  <p><b>编号</b>：[60]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07642</p>
  <p><b>作者</b>：Philipp Rosenthal,  Oliver Niggemann</p>
  <p><b>备注</b>：published at IJCAI 21 Workshop AI and Design</p>
  <p><b>关键词</b>：new ai methods may also support creativity, separate communities fostering different terms, paper first clarifies important terms, verified using design examples, product design needs difficult</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Artificial Intelligence (AI) has significant potential for product design: AI
can check technical and non-technical constraints on products, it can support a
quick design of new product variants and new AI methods may also support
creativity. But currently product design and AI are separate communities
fostering different terms and theories. This makes a mapping of AI approaches
to product design needs difficult and prevents new solutions. As a solution,
this paper first clarifies important terms and concepts for the
interdisciplinary domain of AI methods in product design. A key contribution of
this paper is a new classification of design problems using the four
characteristics decomposability, inter-dependencies, innovation and creativity.
Definitions of these concepts are given where they are lacking. Early mappings
of these concepts to AI solutions are sketched and verified using design
examples. The importance of creativity in product design and a corresponding
gap in AI is pointed out for future research.</p>
  </details>
</details>
<details>
  <summary>12. <b>标题：FAT: An In-Memory Accelerator with Fast Addition for Ternary Weight  Neural Networks</b></summary>
  <p><b>编号</b>：[62]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07634</p>
  <p><b>作者</b>：Shien Zhu,  Luan H.K. Duong,  Hui Chen,  Di Liu,  Weichen Liu</p>
  <p><b>备注</b>：14 pages</p>
  <p><b>关键词</b>：19x energy efficiency compared, 22x area efficiency compared, sparse addition control unit, fast addition scheme based, art imc accelerator parapim</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Convolutional Neural Networks (CNNs) demonstrate great performance in various
applications but have high computational complexity. Quantization is applied to
reduce the latency and storage cost of CNNs. Among the quantization methods,
Binary and Ternary Weight Networks (BWNs and TWNs) have a unique advantage over
8-bit and 4-bit quantization. They replace the multiplication operations in
CNNs with additions, which are favoured on In-Memory-Computing (IMC) devices.
IMC acceleration for BWNs has been widely studied. However, though TWNs have
higher accuracy and better sparsity, IMC acceleration for TWNs has limited
research. TWNs on existing IMC devices are inefficient because the sparsity is
not well utilized, and the addition operation is not efficient.
In this paper, we propose FAT as a novel IMC accelerator for TWNs. First, we
propose a Sparse Addition Control Unit, which utilizes the sparsity of TWNs to
skip the null operations on zero weights. Second, we propose a fast addition
scheme based on the memory Sense Amplifier to avoid the time overhead of both
carry propagation and writing back the carry to the memory cells. Third, we
further propose a Combined-Stationary data mapping to reduce the data movement
of both activations and weights and increase the parallelism of memory columns.
Simulation results show that for addition operations at the Sense Amplifier
level, FAT achieves 2.00X speedup, 1.22X power efficiency and 1.22X area
efficiency compared with State-Of-The-Art IMC accelerator ParaPIM. FAT achieves
10.02X speedup and 12.19X energy efficiency compared with ParaPIM on networks
with 80% sparsity</p>
  </details>
</details>
<details>
  <summary>13. <b>标题：Semi-Supervised Clustering with Contrastive Learning for Discovering New  Intents</b></summary>
  <p><b>编号</b>：[71]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07604</p>
  <p><b>作者</b>：Feng Wei,  Zhenbo Chen,  Zhenghong Hao,  Fengxin Yang,  Hua Wei,  Bing Han,  Sheng Guo</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：results show dcsc achieve best performance across, achieve better text representation, better overall clustering performance, make dcsc fully utilize, propose deep contrastive semi</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Most dialogue systems in real world rely on predefined intents and answers
for QA service, so discovering potential intents from large corpus previously
is really important for building such dialogue services. Considering that most
scenarios have few intents known already and most intents waiting to be
discovered, we focus on semi-supervised text clustering and try to make the
proposed method benefit from labeled samples for better overall clustering
performance. In this paper, we propose Deep Contrastive Semi-supervised
Clustering (DCSC), which aims to cluster text samples in a semi-supervised way
and provide grouped intents to operation staff. To make DCSC fully utilize the
limited known intents, we propose a two-stage training procedure for DCSC, in
which DCSC will be trained on both labeled samples and unlabeled samples, and
achieve better text representation and clustering performance. We conduct
experiments on two public datasets to compare our model with several popular
methods, and the results show DCSC achieve best performance across all datasets
and circumstances, indicating the effect of the improvements in our work.</p>
  </details>
</details>
<details>
  <summary>14. <b>标题：Superpixel Pre-Segmentation of HER2 Slides for Efficient Annotation</b></summary>
  <p><b>编号</b>：[83]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07572</p>
  <p><b>作者</b>：Mathias Öttl,  Jana Mönius,  Christian Marzahl,  Matthias Rübner,  Carol I. Geppert,  Arndt Hartmann,  Matthias W. Beckmann,  Peter Fasching,  Andreas Maier,  Ramona Erber,  Katharina Breininger</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：medical image segmentation across different applications, evaluations show encouraging first results, standard simple linear iterative clustering, boundary f1 score increases, efficient manual refinement without</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Supervised deep learning has shown state-of-the-art performance for medical
image segmentation across different applications, including histopathology and
cancer research; however, the manual annotation of such data is extremely
laborious. In this work, we explore the use of superpixel approaches to compute
a pre-segmentation of HER2 stained images for breast cancer diagnosis that
facilitates faster manual annotation and correction in a second step. Four
methods are compared: Standard Simple Linear Iterative Clustering (SLIC) as a
baseline, a domain adapted SLIC, and superpixels based on feature embeddings of
a pretrained ResNet-50 and a denoising autoencoder. To tackle oversegmentation,
we propose to hierarchically merge superpixels, based on their content in the
respective feature space. When evaluating the approaches on fully manually
annotated images, we observe that the autoencoder-based superpixels achieve a
23% increase in boundary F1 score compared to the baseline SLIC superpixels.
Furthermore, the boundary F1 score increases by 73% when hierarchical
clustering is applied on the adapted SLIC and the autoencoder-based
superpixels. These evaluations show encouraging first results for a
pre-segmentation for efficient manual refinement without the need for an
initial set of annotated training data.</p>
  </details>
</details>
<details>
  <summary>15. <b>标题：Educational Timetabling: Problems, Benchmarks, and State-of-the-Art  Results</b></summary>
  <p><b>编号</b>：[95]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07525</p>
  <p><b>作者</b>：Sara Ceschia,  Luca Di Gaspero,  Andrea Schaerf</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：lower bounds ), search techniques, corresponding benchmark instances, statistical distributions, specific focus, solution quality</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose a survey of the research contributions on the field of Educational
Timetabling with a specific focus on "standard" formulations and the
corresponding benchmark instances. We identify six of such formulations and we
discuss their features, pointing out their relevance and usability. Other
available formulations and datasets are also reviewed and briefly discussed.
Subsequently, we report the main state-of-the-art results on the selected
benchmarks, in terms of solution quality (upper and lower bounds), search
techniques, running times, statistical distributions, and other side settings.</p>
  </details>
</details>
<details>
  <summary>16. <b>标题：POPPINS : A Population-Based Digital Spiking Neuromorphic Processor with  Integer Quadratic Integrate-and-Fire Neurons</b></summary>
  <p><b>编号</b>：[106]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07490</p>
  <p><b>作者</b>：Zuo-Wei Yeh,  Chia-Hua Hsu,  Alexander White,  Chen-Fu Yeh,  Wen-Chieh Wu,  Cheng-Te Wang,  Chung-Chuan Lo,  Kea-Tiong Tang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：biological processing system remain largely, spiking neural networks exhibit low, based digital spiking neuromorphic processor, implement intelligent decision making, bit membrane potential value</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The inner operations of the human brain as a biological processing system
remain largely a mystery. Inspired by the function of the human brain and based
on the analysis of simple neural network systems in other species, such as
Drosophila, neuromorphic computing systems have attracted considerable
interest. In cellular-level connectomics research, we can identify the
characteristics of biological neural network, called population, which
constitute not only recurrent fullyconnection in network, also an
external-stimulus and selfconnection in each neuron. Relying on low data
bandwidth of spike transmission in network and input data, Spiking Neural
Networks exhibit low-latency and low-power design. In this study, we proposed a
configurable population-based digital spiking neuromorphic processor in 180nm
process technology with two configurable hierarchy populations. Also, these
neurons in the processor can be configured as novel models, integer quadratic
integrate-and-fire neuron models, which contain an unsigned 8-bit membrane
potential value. The processor can implement intelligent decision making for
avoidance in real-time. Moreover, the proposed approach enables the
developments of biomimetic neuromorphic system and various low-power, and
low-latency inference processing applications.</p>
  </details>
</details>
<details>
  <summary>17. <b>标题：Development of Fake News Model using Machine Learning through Natural  Language Processing</b></summary>
  <p><b>编号</b>：[107]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07489</p>
  <p><b>作者</b>：Sajjad Ahmed,  Knut Hinkelmann,  Flavio Corradini</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：applied three different machine learning classifiers, two publicly available datasets, used machine learning algorithms, build ai systems nowadays, applied three classifiers</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Fake news detection research is still in the early stage as this is a
relatively new phenomenon in the interest raised by society. Machine learning
helps to solve complex problems and to build AI systems nowadays and especially
in those cases where we have tacit knowledge or the knowledge that is not
known. We used machine learning algorithms and for identification of fake news;
we applied three classifiers; Passive Aggressive, Naïve Bayes, and Support
Vector Machine. Simple classification is not completely correct in fake news
detection because classification methods are not specialized for fake news.
With the integration of machine learning and text-based processing, we can
detect fake news and build classifiers that can classify the news data. Text
classification mainly focuses on extracting various features of text and after
that incorporating those features into classification. The big challenge in
this area is the lack of an efficient way to differentiate between fake and
non-fake due to the unavailability of corpora. We applied three different
machine learning classifiers on two publicly available datasets. Experimental
analysis based on the existing dataset indicates a very encouraging and
improved performance.</p>
  </details>
</details>
<details>
  <summary>18. <b>标题：Mixed Nondeterministic-Probabilistic Automata: Blending graphical  probabilistic models with nondeterminism</b></summary>
  <p><b>编号</b>：[110]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07474</p>
  <p><b>作者</b>：Albert Benveniste,  Jean-Baptiste Raclet</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：support message passing algorithms inherited, graphical models include bayesian networks, graphical probabilistic models, graphical probabilistic models, graphical models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Graphical models in probability and statistics are a core concept in the area
of probabilistic reasoning and probabilistic programming-graphical models
include Bayesian networks and factor graphs. In this paper we develop a new
model of mixed (nondeterministic/probabilistic) automata that subsumes both
nondeterministic automata and graphical probabilistic models. Mixed Automata
are equipped with parallel composition, simulation relation, and support
message passing algorithms inherited from graphical probabilistic models.
Segala's Probabilistic Automatacan be mapped to Mixed Automata.</p>
  </details>
</details>
<details>
  <summary>19. <b>标题：TourBERT: A pretrained language model for the tourism industry</b></summary>
  <p><b>编号</b>：[119]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07449</p>
  <p><b>作者</b>：Veronika Arefieva,  Roman Egger</p>
  <p><b>备注</b>：13 pages, 7 figures, 4 tables</p>
  <p><b>关键词</b>：bidirectional encoder representations, pretrained language model, natural language, specific tasks, specific tasks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The Bidirectional Encoder Representations from Transformers (BERT) is
currently one of the most important and state-of-the-art models for natural
language. However, it has also been shown that for domain-specific tasks it is
helpful to pretrain BERT on a domain-specific corpus. In this paper, we present
TourBERT, a pretrained language model for tourism. We describe how TourBERT was
developed and evaluated. The evaluations show that TourBERT is outperforming
BERT in all tourism-specific tasks.</p>
  </details>
</details>
<details>
  <summary>20. <b>标题：Hiding Data in Colors: Secure and Lossless Deep Image Steganography via  Conditional Invertible Neural Networks</b></summary>
  <p><b>编号</b>：[121]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07444</p>
  <p><b>作者</b>：Yanzhen Ren,  Ting Liu,  Liming Zhai,  Lina Wang</p>
  <p><b>备注</b>：under review</p>
  <p><b>关键词</b>：digital images via deep neural networks, existing deep image steganography methods, conditional invertible neural network, propose deep image steganography, usually hides data limited</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep image steganography is a data hiding technology that conceal data in
digital images via deep neural networks. However, existing deep image
steganography methods only consider the visual similarity of container images
to host images, and neglect the statistical security (stealthiness) of
container images. Besides, they usually hides data limited to image type and
thus relax the constraint of lossless extraction. In this paper, we address the
above issues in a unified manner, and propose deep image steganography that can
embed data with arbitrary types into images for secure data hiding and lossless
data revealing. First, we formulate the data hiding as an image colorization
problem, in which the data is binarized and further mapped into the color
information for a gray-scale host image. Second, we design a conditional
invertible neural network which uses gray-scale image as prior to guide the
color generation and perform data hiding in a secure way. Finally, to achieve
lossless data revealing, we present a multi-stage training scheme to manage the
data loss due to rounding errors between hiding and revealing processes.
Extensive experiments demonstrate that the proposed method can perform secure
data hiding by generating realism color images and successfully resisting the
detection of steganalysis. Moreover, we can achieve 100% revealing accuracy in
different scenarios, indicating the practical utility of our steganography in
the real-world.</p>
  </details>
</details>
<details>
  <summary>21. <b>标题：Cross-Language Binary-Source Code Matching with Intermediate  Representations</b></summary>
  <p><b>编号</b>：[135]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07420</p>
  <p><b>作者</b>：Yi Gui,  Yao Wan,  Hongyu Zhang,  Huifang Huang,  Yulei Sui,  Guandong Xu,  Zhiyuan Shao,  Hai Jin</p>
  <p><b>备注</b>：SANER2022</p>
  <p><b>关键词</b>：source code across programming languages introduces additional challenges, intermediate representations significantly outperforms, source code matching plays, different programming languages, software engineering related tasks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Binary-source code matching plays an important role in many security and
software engineering related tasks such as malware detection, reverse
engineering and vulnerability assessment. Currently, several approaches have
been proposed for binary-source code matching by jointly learning the
embeddings of binary code and source code in a common vector space. Despite
much effort, existing approaches target on matching the binary code and source
code written in a single programming language. However, in practice, software
applications are often written in different programming languages to cater for
different requirements and computing platforms. Matching binary and source code
across programming languages introduces additional challenges when maintaining
multi-language and multi-platform applications. To this end, this paper
formulates the problem of cross-language binary-source code matching, and
develops a new dataset for this new problem. We present a novel approach XLIR,
which is a Transformer-based neural network by learning the intermediate
representations for both binary and source code. To validate the effectiveness
of XLIR, comprehensive experiments are conducted on two tasks of cross-language
binary-source code matching, and cross-language source-source code matching, on
top of our curated dataset. Experimental results and analysis show that our
proposed XLIR with intermediate representations significantly outperforms other
state-of-the-art models in both of the two tasks.</p>
  </details>
</details>
<details>
  <summary>22. <b>标题：Neural Language Models are Effective Plagiarists</b></summary>
  <p><b>编号</b>：[141]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07406</p>
  <p><b>作者</b>：Stella Biderman,  Edward Raff</p>
  <p><b>备注</b>：6 pages of main text, 2 pages of references, 86 pages of appendices</p>
  <p><b>关键词</b>：complete introductory level programming assignments without triggering suspicion, future plagiarism detection techniques may use, solve introductory level programming assignments, widely used plagiarism detection tool, bypassing commonly used ai tools</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As artificial intelligence (AI) technologies become increasingly powerful and
prominent in society, their misuse is a growing concern. In educational
settings, AI technologies could be used by students to cheat on assignments and
exams. In this paper we explore whether transformers can be used to solve
introductory level programming assignments while bypassing commonly used AI
tools to detect plagiarism. We find that a student using GPT-J [Wang and
Komatsuzaki, 2021] can complete introductory level programming assignments
without triggering suspicion from MOSS [Aiken, 2000], a widely used plagiarism
detection tool. This holds despite the fact that GPT-J was not trained on the
problems in question and is not provided with any examples to work from. We
further find that the code written by GPT-J is diverse in structure, lacking
any particular tells that future plagiarism detection techniques may use to try
to identify algorithmically generated code. We conclude with a discussion of
the ethical and educational implications of large language models and
directions for future research.</p>
  </details>
</details>
<details>
  <summary>23. <b>标题：Unveiling Project-Specific Bias in Neural Code Models</b></summary>
  <p><b>编号</b>：[154]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07381</p>
  <p><b>作者</b>：Zhiming Li,  Yanzhou Li,  Tianlin Li,  Mengnan Du,  Bozhi Wu,  Yushi Cao,  Xiaofei Xie,  Yi Li,  Yang Liu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：many software analysis tasks like type inference, leveraging latent logic relations among samples, bias mitigation mechanism batch partition regularization, two deep code benchmarks indicate, ungeneralizable tokens like self</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Neural code models have introduced significant improvements over many
software analysis tasks like type inference, vulnerability detection, etc.
Despite the good performance of such models under the common intra-project
independent and identically distributed (IID) training and validation setting,
we observe that they usually fail to generalize to real-world inter-project
out-of-distribution (OOD) setting. In this work, we show that such phenomenon
is caused by model heavily relying on project-specific, ungeneralizable tokens
like self-defined variable and function names for downstream prediction, and we
formulate it as the project-specific bias learning behavior. We propose a
measurement to interpret such behavior, termed as Cond-Idf, which combines
co-occurrence probability and inverse document frequency to measure the level
of relatedness of token with label and its project-specificness. The
approximation indicates that without proper regularization with prior
knowledge, model tends to leverage spurious statistical cues for prediction.
Equipped with these observations, we propose a bias mitigation mechanism Batch
Partition Regularization (BPR) that regularizes model to infer based on proper
behavior by leveraging latent logic relations among samples. Experimental
results on two deep code benchmarks indicate that BPR can improve both
inter-project OOD generalization and adversarial robustness while not
sacrificing accuracy on IID data.</p>
  </details>
</details>
<details>
  <summary>24. <b>标题：Prospective Learning: Back to the Future</b></summary>
  <p><b>编号</b>：[159]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07372</p>
  <p><b>作者</b>：Joshua T. Vogelstein,  Timothy Verstynen,  Konrad P. Kording,  Leyla Isik,  John W. Krakauer,  Ralph Etienne-Cummings,  Elizabeth L. Ogburn,  Carey E. Priebe,  Randal Burns,  Kwame Kutten,  James J. Knierim,  James B. Potash,  Thomas Hartung,  Lena Smirnova,  Paul Worley,  Alena Savonenko,  Ian Phillips,  Michael I. Miller,  Rene Vidal,  Jeremias Sulam,  Adam Charles,  Noah J. Cowan,  Maxim Bichuch,  Archana Venkataraman,  Chen Li,  Nitish Thakor,  Justus M Kebschull,  Marilyn Albert,  Jinchong Xu,  Marshall Hussain Shuler,  Brian Caffo,  Tilak Ratnanather,  Ali Geisa,  Seung-Eon Roh,  Eva Yezerets,  Meghana Madhyastha,  Javier J. How,  Tyler M. Tomita,  Jayanta Dey,  Ningyuan (Teresa) Huang,  Jong M. Shin,  Kaleab Alemayehu Kinfu,  Pratik Chaudhari,  Ben Baker,  Anna Schapiro,  Dinesh Jayaraman,  Eric Eaton,  Michael Platt,  Lyle Ungar,  et al. (14 additional authors not shown)</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：retrospective learning intelligence would merely, articulate four relevant factors, causal estimation enables learning, curiosity motivates taking actions, achieve previously unencountered goals</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Research on both natural intelligence (NI) and artificial intelligence (AI)
generally assumes that the future resembles the past: intelligent agents or
systems (what we call 'intelligence') observe and act on the world, then use
this experience to act on future experiences of the same kind. We call this
'retrospective learning'. For example, an intelligence may see a set of
pictures of objects, along with their names, and learn to name them. A
retrospective learning intelligence would merely be able to name more pictures
of the same objects. We argue that this is not what true intelligence is about.
In many real world problems, both NIs and AIs will have to learn for an
uncertain future. Both must update their internal models to be useful for
future tasks, such as naming fundamentally new objects and using these objects
effectively in a new context or to achieve previously unencountered goals. This
ability to learn for the future we call 'prospective learning'. We articulate
four relevant factors that jointly define prospective learning. Continual
learning enables intelligences to remember those aspects of the past which it
believes will be most useful in the future. Prospective constraints (including
biases and priors) facilitate the intelligence finding general solutions that
will be applicable to future problems. Curiosity motivates taking actions that
inform future decision making, including in previously unmet situations. Causal
estimation enables learning the structure of relations that guide choosing
actions for specific outcomes, even when the specific action-outcome
contingencies have never been observed before. We argue that a paradigm shift
from retrospective to prospective learning will enable the communities that
study intelligence to unite and overcome existing bottlenecks to more
effectively explain, augment, and engineer intelligences.</p>
  </details>
</details>
<details>
  <summary>25. <b>标题：OSSID: Online Self-Supervised Instance Detection by (and for) Pose  Estimation</b></summary>
  <p><b>编号</b>：[184]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07309</p>
  <p><b>作者</b>：Qiao Gu,  Brian Okorn,  David Held</p>
  <p><b>备注</b>：10 pages, 6 figures. Accepted to RA-L</p>
  <p><b>关键词</b>：two widely used object pose estimation, ossid framework ,} leveraging, many robot manipulation algorithms, significantly faster inference speed, time object pose estimation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Real-time object pose estimation is necessary for many robot manipulation
algorithms. However, state-of-the-art methods for object pose estimation are
trained for a specific set of objects; these methods thus need to be retrained
to estimate the pose of each new object, often requiring tens of GPU-days of
training for optimal performance. \revisef{In this paper, we propose the OSSID
framework,} leveraging a slow zero-shot pose estimator to self-supervise the
training of a fast detection algorithm. This fast detector can then be used to
filter the input to the pose estimator, drastically improving its inference
speed. We show that this self-supervised training exceeds the performance of
existing zero-shot detection methods on two widely used object pose estimation
and detection datasets, without requiring any human annotations. Further, we
show that the resulting method for pose estimation has a significantly faster
inference speed, due to the ability to filter out large parts of the image.
Thus, our method for self-supervised online learning of a detector (trained
using pseudo-labels from a slow pose estimator) leads to accurate pose
estimation at real-time speeds, without requiring human annotations.
Supplementary materials and code can be found at
this https URL</p>
  </details>
</details>
<details>
  <summary>26. <b>标题：Conservative Distributional Reinforcement Learning with Safety  Constraints</b></summary>
  <p><b>编号</b>：[192]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07286</p>
  <p><b>作者</b>：Hengrui Zhang,  Youfang Lin,  Sheng Han,  Shuo Wang,  Kai Lv</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：policy reinforcement learning algorithm called conservative distributional maximum, utilize weighted average proportional integral derivative, cdmpo adapts distributional reinforcement learning method, final test results also illustrate, conservative value function loss</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Safety exploration can be regarded as a constrained Markov decision problem
where the expected long-term cost is constrained. Previous off-policy
algorithms convert the constrained optimization problem into the corresponding
unconstrained dual problem by introducing the Lagrangian relaxation technique.
However, the cost function of the above algorithms provides inaccurate
estimations and causes the instability of the Lagrange multiplier learning. In
this paper, we present a novel off-policy reinforcement learning algorithm
called Conservative Distributional Maximum a Posteriori Policy Optimization
(CDMPO). At first, to accurately judge whether the current situation satisfies
the constraints, CDMPO adapts distributional reinforcement learning method to
estimate the Q-function and C-function. Then, CDMPO uses a conservative value
function loss to reduce the number of violations of constraints during the
exploration process. In addition, we utilize Weighted Average Proportional
Integral Derivative (WAPID) to update the Lagrange multiplier stably. Empirical
results show that the proposed method has fewer violations of constraints in
the early exploration process. The final test results also illustrate that our
method has better risk control.</p>
  </details>
</details>
<details>
  <summary>27. <b>标题：NSGZero: Efficiently Learning Non-Exploitable Policy in Large-Scale  Network Security Games with Neural Monte Carlo Tree Search</b></summary>
  <p><b>编号</b>：[205]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07224</p>
  <p><b>作者</b>：Wanqi Xue,  Bo An,  Chai Kiat Yeo</p>
  <p><b>备注</b>：Published as a conference paper in AAAI 2022</p>
  <p><b>关键词</b>：method achieves significantly better data efficiency, neural monte carlo tree search, nsgzero improves data efficiency, design deep neural networks, perform neural mcts</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>How resources are deployed to secure critical targets in networks can be
modelled by Network Security Games (NSGs). While recent advances in deep
learning (DL) provide a powerful approach to dealing with large-scale NSGs, DL
methods such as NSG-NFSP suffer from the problem of data inefficiency.
Furthermore, due to centralized control, they cannot scale to scenarios with a
large number of resources. In this paper, we propose a novel DL-based method,
NSGZero, to learn a non-exploitable policy in NSGs. NSGZero improves data
efficiency by performing planning with neural Monte Carlo Tree Search (MCTS).
Our main contributions are threefold. First, we design deep neural networks
(DNNs) to perform neural MCTS in NSGs. Second, we enable neural MCTS with
decentralized control, making NSGZero applicable to NSGs with many resources.
Third, we provide an efficient learning paradigm, to achieve joint training of
the DNNs in NSGZero. Compared to state-of-the-art algorithms, our method
achieves significantly better data efficiency and scalability.</p>
  </details>
</details>
<details>
  <summary>28. <b>标题：Wide Area Network Intelligence with Application to Multimedia Service</b></summary>
  <p><b>编号</b>：[207]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07216</p>
  <p><b>作者</b>：Satoshi Kamo,  Yiqiang Sheng</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：latest deep feed forward neural network, evaluation shows scalable improvement, wide area network intelligence, wide area network intelligence, wide area network</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Network intelligence is a discipline that builds on the capabilities of
network systems to act intelligently by the usage of network resources for
delivering high-quality services in a changing environment. Wide area network
intelligence is a class of network intelligence in wide area network which
covers the core and the edge of Internet. In this paper, we propose a system
based on machine learning for wide area network intelligence. The whole system
consists of a core machine for pre-training and many terminal machines to
accomplish faster responses. Each machine is one of dual-hemisphere models
which are made of left and right hemispheres. The left hemisphere is used to
improve latency by terminal response and the right hemisphere is used to
improve communication by data generation. In an application on multimedia
service, the proposed model is superior to the latest deep feed forward neural
network in the data center with respect to the accuracy, latency and
communication. Evaluation shows scalable improvement with regard to the number
of terminal machines. Evaluation also shows the cost of improvement is longer
learning time.</p>
  </details>
</details>
<details>
  <summary>29. <b>标题：Layerwise Geo-Distributed Computing between Cloud and IoT</b></summary>
  <p><b>编号</b>：[208]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07215</p>
  <p><b>作者</b>：Satoshi Kamo,  Yiqiang Sheng</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：existing deep belief networks, typical deep neural network, distributed computing extends cloud, deep learning system, distributed mnist database</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we propose a novel architecture for a deep learning system,
named k-degree layer-wise network, to realize efficient geo-distributed
computing between Cloud and Internet of Things (IoT). The geo-distributed
computing extends Cloud to the geographical verge of the network in the
neighbor of IoT. The basic ideas of the proposal include a k-degree constraint
and a layer-wise constraint. The k-degree constraint is defined such that the
degree of each vertex on the h-th layer is exactly k(h) to extend the existing
deep belief networks and control the communication cost. The layer-wise
constraint is defined such that the layer-wise degrees are monotonically
decreasing in positive direction to gradually reduce the dimension of data. We
prove the k-degree layer-wise network is sparse, while a typical deep neural
network is dense. In an evaluation on the M-distributed MNIST database, the
proposal is superior to a state-of-the-art model in terms of communication cost
and learning time with scalability.</p>
  </details>
</details>
<details>
  <summary>30. <b>标题：Using Particle Swarm Optimization as Pathfinding Strategy in a Space  with Obstacles</b></summary>
  <p><b>编号</b>：[209]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07212</p>
  <p><b>作者</b>：David</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：swarm move faster, many random movements, based adaptive optimization, give solution paths, search algorithm based</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Particle swarm optimization (PSO) is a search algorithm based on stochastic
and population-based adaptive optimization. In this paper, a pathfinding
strategy is proposed to improve the efficiency of path planning for a broad
range of applications. This study aims to investigate the effect of PSO
parameters (numbers of particle, weight constant, particle constant, and global
constant) on algorithm performance to give solution paths. Increasing the PSO
parameters makes the swarm move faster to the target point but takes a long
time to converge because of too many random movements, and vice versa. From a
variety of simulations with different parameters, the PSO algorithm is proven
to be able to provide a solution path in a space with obstacles.</p>
  </details>
</details>
<details>
  <summary>31. <b>标题：Advancing Deep Residual Learning by Solving the Crux of Degradation in  Spiking Neural Networks</b></summary>
  <p><b>编号</b>：[212]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07209</p>
  <p><b>作者</b>：Yifan Hu,  Yujie Wu,  Lei Deng,  Guoqi Li</p>
  <p><b>备注</b>：arXiv admin note: substantial text overlap with arXiv:2112.08954</p>
  <p><b>关键词</b>：resulting insufficient representation power, training deep neural networks, one spike per neuron, spiking neural networks, resulting networks need</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Despite the rapid progress of neuromorphic computing, the inadequate depth
and the resulting insufficient representation power of spiking neural networks
(SNNs) severely restrict their application scope in practice. Residual learning
and shortcuts have been evidenced as an important approach for training deep
neural networks, but rarely did previous work assess their applicability to the
characteristics of spike-based communication and spatiotemporal dynamics. This
negligence leads to impeded information flow and the accompanying degradation
problem. In this paper, we identify the crux and then propose a novel residual
block for SNNs, which is able to significantly extend the depth of directly
trained SNNs, e.g., up to 482 layers on CIFAR-10 and 104 layers on ImageNet,
without observing any slight degradation problem. We validate the effectiveness
of our methods on both frame-based and neuromorphic datasets, and our
SRM-ResNet104 achieves a superior result of 76.02% accuracy on ImageNet, the
first time in the domain of directly trained SNNs. The great energy efficiency
is estimated and the resulting networks need on average only one spike per
neuron for classifying an input sample. We believe our powerful and scalable
modeling will provide a strong support for further exploration of SNNs.</p>
  </details>
</details>
<details>
  <summary>32. <b>标题：Enhanced Self-Organizing Map Solution for the Traveling Salesman Problem</b></summary>
  <p><b>编号</b>：[213]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07208</p>
  <p><b>作者</b>：Joao P. A. Dantas,  Andre N. Costa,  Marcos R. O. A. Maximo,  Takashi Yoneyama</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：benchmark work brought consistent results, may inspire future efforts, traveling salesman problem, provided suboptimal solutions, organizing map method</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Using an enhanced Self-Organizing Map method, we provided suboptimal
solutions to the Traveling Salesman Problem. Besides, we employed
hyperparameter tuning to identify the most critical features in the algorithm.
All improvements in the benchmark work brought consistent results and may
inspire future efforts to improve this algorithm and apply it to different
problems.</p>
  </details>
</details>
<details>
  <summary>33. <b>标题：Convergence of policy gradient for entropy regularized MDPs with neural  network approximation in the mean-field regime</b></summary>
  <p><b>编号</b>：[237]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07296</p>
  <p><b>作者</b>：Bekzhan Kerimkulov,  James-Michael Leahy,  David Šiška,  Lukasz Szpruch</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：linear fokker -- planck -- kolmogorov equation, gradient flow converges exponentially fast, regularized markov decision processes, neural network approximation, mei et al</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We study the global convergence of policy gradient for infinite-horizon,
continuous state and action space, entropy-regularized Markov decision
processes (MDPs). We consider a softmax policy with (one-hidden layer) neural
network approximation in a mean-field regime. Additional entropic
regularization in the associated mean-field probability measure is added, and
the corresponding gradient flow is studied in the 2-Wasserstein metric. We show
that the objective function is increasing along the gradient flow. Further, we
prove that if the regularization in terms of the mean-field measure is
sufficient, the gradient flow converges exponentially fast to the unique
stationary solution, which is the unique maximizer of the regularized MDP
objective. Lastly, we study the sensitivity of the value function along the
gradient flow with respect to regularization parameters and the initial
condition. Our results rely on the careful analysis of non-linear
Fokker--Planck--Kolmogorov equation and extend the pioneering work of Mei et
al. 2020 and Agarwal et al. 2020, which quantify the global convergence rate of
policy gradient for entropy-regularized MDPs in the tabular setting.</p>
  </details>
</details>
<details>
  <summary>34. <b>标题：AI-based Carcinoma Detection and Classification Using Histopathological  Images: A Systematic Review</b></summary>
  <p><b>编号</b>：[238]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2201.07231</p>
  <p><b>作者</b>：Swathi Prabhua,  Keerthana Prasada,  Antonio Robels-Kelly,  Xuequan Lu</p>
  <p><b>备注</b>：accepted to Computers in Biology and Medicine</p>
  <p><b>关键词</b>：carcinoma diagnosis using histopathological images, carcinoma diagnosis also reveals, based carcinoma diagnostic system, histopathological image analysis, automated carcinoma diagnosis</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Histopathological image analysis is the gold standard to diagnose cancer.
Carcinoma is a subtype of cancer that constitutes more than 80% of all cancer
cases. Squamous cell carcinoma and adenocarcinoma are two major subtypes of
carcinoma, diagnosed by microscopic study of biopsy slides. However, manual
microscopic evaluation is a subjective and time-consuming process. Many
researchers have reported methods to automate carcinoma detection and
classification. The increasing use of artificial intelligence (AI) in the
automation of carcinoma diagnosis also reveals a significant rise in the use of
deep network models. In this systematic literature review, we present a
comprehensive review of the state-of-the-art approaches reported in carcinoma
diagnosis using histopathological images. Studies are selected from well-known
databases with strict inclusion/exclusion criteria. We have categorized the
articles and recapitulated their methods based on specific organs of carcinoma
origin. Further, we have summarized pertinent literature on AI methods,
highlighted critical challenges and limitations, and provided insights on
future research direction in automated carcinoma diagnosis. Out of 101 articles
selected, most of the studies experimented on private datasets with varied
image sizes, obtaining accuracy between 63% and 100%. Overall, this review
highlights the need for a generalized AI-based carcinoma diagnostic system.
Additionally, it is desirable to have accountable approaches to extract
microscopic features from images of multiple magnifications that should mimic
pathologists' evaluations.</p>
  </details>
</details>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">徐耀彬</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://louishsu.xyz/2022/01/21/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html">http://louishsu.xyz/2022/01/21/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://louishsu.xyz" target="_blank">LOUIS' BLOG</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"></div><div class="post_share"><div class="social-share" data-image="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="next-post pull-full"><a href="/2021/10/22/%E4%B8%AD%E5%9B%BD%E6%B3%95%E5%BE%8B%E6%99%BA%E8%83%BD%E6%8A%80%E6%9C%AF%E8%AF%84%E6%B5%8B(CAIL2021)%EF%BC%9A%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96(Rank2).html"><img class="next-cover" src="http://cail.cipsc.org.cn/img/index_mainpic.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">中国法律智能技术评测(CAIL2021)：信息抽取(Rank2)</div></div></a></div></nav><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="twikoo-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="card-info-avatar is-center"><img class="avatar-img" src="/img/touxiang.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/><div class="author-info__name">徐耀彬</div><div class="author-info__description">做知识的原创者！</div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">11</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">标签</div><div class="length-num">3</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">分类</div><div class="length-num">7</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/isLouisHsu"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/isLouisHsu" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:is.louishsu@foxmail.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>公告</span></div><div class="announcement_content">记录和分享一些学习和开源内容，若有问题可通过邮箱is.louishsu@foxmail.com联系，欢迎交流！！</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">1.</span> <span class="toc-text">统计</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">2.</span> <span class="toc-text">计算机视觉</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">3.</span> <span class="toc-text">自然语言处理</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">4.</span> <span class="toc-text">机器学习</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">5.</span> <span class="toc-text">人工智能</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2022/01/21/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html" title="Arxiv每日速递(2022-01-21)"><img src="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Arxiv每日速递(2022-01-21)"/></a><div class="content"><a class="title" href="/2022/01/21/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html" title="Arxiv每日速递(2022-01-21)">Arxiv每日速递(2022-01-21)</a><time datetime="2022-01-21T00:25:01.058Z" title="发表于 2022-01-21 08:25:01">2022-01-21</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/10/22/%E4%B8%AD%E5%9B%BD%E6%B3%95%E5%BE%8B%E6%99%BA%E8%83%BD%E6%8A%80%E6%9C%AF%E8%AF%84%E6%B5%8B(CAIL2021)%EF%BC%9A%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96(Rank2).html" title="中国法律智能技术评测(CAIL2021)：信息抽取(Rank2)"><img src="http://cail.cipsc.org.cn/img/index_mainpic.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="中国法律智能技术评测(CAIL2021)：信息抽取(Rank2)"/></a><div class="content"><a class="title" href="/2021/10/22/%E4%B8%AD%E5%9B%BD%E6%B3%95%E5%BE%8B%E6%99%BA%E8%83%BD%E6%8A%80%E6%9C%AF%E8%AF%84%E6%B5%8B(CAIL2021)%EF%BC%9A%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96(Rank2).html" title="中国法律智能技术评测(CAIL2021)：信息抽取(Rank2)">中国法律智能技术评测(CAIL2021)：信息抽取(Rank2)</a><time datetime="2021-10-22T14:29:06.000Z" title="发表于 2021-10-22 22:29:06">2021-10-22</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/05/19/%E5%85%A8%E7%90%83%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%8A%80%E6%9C%AF%E5%88%9B%E6%96%B0%E5%A4%A7%E8%B5%9B%E3%80%90%E8%B5%9B%E9%81%93%E4%B8%80%E3%80%91%EF%BC%9A%E5%8C%BB%E5%AD%A6%E5%BD%B1%E5%83%8F%E6%8A%A5%E5%91%8A%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B.html" title="全球人工智能技术创新大赛【赛道一】：医学影像报告异常检测"><img src="https://tianchi-public.oss-cn-hangzhou.aliyuncs.com/public/files/forum/161037709574435991610377095138.jpeg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="全球人工智能技术创新大赛【赛道一】：医学影像报告异常检测"/></a><div class="content"><a class="title" href="/2021/05/19/%E5%85%A8%E7%90%83%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%8A%80%E6%9C%AF%E5%88%9B%E6%96%B0%E5%A4%A7%E8%B5%9B%E3%80%90%E8%B5%9B%E9%81%93%E4%B8%80%E3%80%91%EF%BC%9A%E5%8C%BB%E5%AD%A6%E5%BD%B1%E5%83%8F%E6%8A%A5%E5%91%8A%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B.html" title="全球人工智能技术创新大赛【赛道一】：医学影像报告异常检测">全球人工智能技术创新大赛【赛道一】：医学影像报告异常检测</a><time datetime="2021-05-19T09:57:06.000Z" title="发表于 2021-05-19 17:57:06">2021-05-19</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2020/09/16/%E8%AF%A6%E8%A7%A3%E5%91%BD%E5%90%8D%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB%E6%A8%A1%E5%9E%8B%EF%BC%9ALSTM-CRF.html" title="详解命名实体识别模型：LSTM-CRF"><img src="https://gimg2.baidu.com/image_search/src=http%3A%2F%2Fpic1.zhimg.com%2Fv2-1ed6a10dbb239a148e42df088c5870a6_1440w.jpg%3Fsource%3D172ae18b&amp;refer=http%3A%2F%2Fpic1.zhimg.com&amp;app=2002&amp;size=f9999,10000&amp;q=a80&amp;n=0&amp;g=0n&amp;fmt=jpeg?sec=1638183974&amp;t=4632f13fd487ed1cfcb12d67a6b71e52" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="详解命名实体识别模型：LSTM-CRF"/></a><div class="content"><a class="title" href="/2020/09/16/%E8%AF%A6%E8%A7%A3%E5%91%BD%E5%90%8D%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB%E6%A8%A1%E5%9E%8B%EF%BC%9ALSTM-CRF.html" title="详解命名实体识别模型：LSTM-CRF">详解命名实体识别模型：LSTM-CRF</a><time datetime="2020-09-16T09:26:44.000Z" title="发表于 2020-09-16 17:26:44">2020-09-16</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2020/06/14/%E8%AE%B0%E4%B8%80%E6%AC%A1MySQL%E8%A7%A3%E5%86%B3%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E6%97%B6%E7%9A%84%E5%88%86%E8%A1%A8%E9%97%AE%E9%A2%98.html" title="记一次MySQL解决大数据存储时的分表问题"><img src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="记一次MySQL解决大数据存储时的分表问题"/></a><div class="content"><a class="title" href="/2020/06/14/%E8%AE%B0%E4%B8%80%E6%AC%A1MySQL%E8%A7%A3%E5%86%B3%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E6%97%B6%E7%9A%84%E5%88%86%E8%A1%A8%E9%97%AE%E9%A2%98.html" title="记一次MySQL解决大数据存储时的分表问题">记一次MySQL解决大数据存储时的分表问题</a><time datetime="2020-06-14T15:24:27.000Z" title="发表于 2020-06-14 23:24:27">2020-06-14</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2022 By 徐耀彬</div><div class="footer_custom_text"><p><a style="margin-inline:5px"target="_blank"href="https://hexo.io/"><img src="https://img.shields.io/badge/Frame-Hexo-blue?style=flat&logo=hexo"title="博客框架为Hexo"alt="img"></a><a style="margin-inline:5px"target="_blank"href="https://butterfly.js.org/"><img src="https://img.shields.io/badge/Theme-Butterfly-6513df?style=flat&logo=bitdefender"title="主题采用butterfly"alt="img"></a><a style="margin-inline:5px"target="_blank"href="https://www.jsdelivr.com/"><img src="https://img.shields.io/badge/CDN-jsDelivr-orange?style=flat&logo=jsDelivr"title="本站使用JsDelivr为静态资源提供CDN加速"alt="img"></a><a style="margin-inline:5px"target="_blank"href="https://github.com/"><img src="https://img.shields.io/badge/Source-Github-d021d6?style=flat&logo=GitHub"title="本站项目由Gtihub托管"alt="img"></a><a style="margin-inline:5px"target="_blank"href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img src="https://img.shields.io/badge/Copyright-BY--NC--SA%204.0-d42328?style=flat&logo=Claris"alt="img"title="本站采用知识共享署名-非商业性使用-相同方式共享4.0国际许可协议进行许可"></a></br></p></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="font-plus" type="button" title="放大字体"><i class="fas fa-plus"></i></button><button id="font-minus" type="button" title="缩小字体"><i class="fas fa-minus"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div></div><hr/><div id="local-search-results"></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.css"><script>(() => {
  document.querySelectorAll('#article-container span.katex-display').forEach(item => {
    btf.wrap(item, 'div', '', 'katex-wrap')
  })
})()</script><script>(()=>{
  const $countDom = document.getElementById('twikoo-count')
  const init = () => {
    let initData = {
      el: '#twikoo-wrap',
      envId: 'blog-',
      region: ''
    }

    if (false) {
      const otherData = false
      initData = Object.assign(initData, otherData)
    }
    
    twikoo.init(initData)
  }

  const getCount = () => {
    twikoo.getCommentsCount({
      envId: 'blog-',
      region: '',
      urls: [window.location.pathname],
      includeReply: false
    }).then(function (res) {
      $countDom.innerText = res[0].count
    }).catch(function (err) {
      console.error(err);
    });
  }

  const loadTwikoo = (bool = false) => {
    if (typeof twikoo === 'object') {
      init()
      bool && $countDom && setTimeout(getCount,0)
    } else {
      getScript('https://cdn.jsdelivr.net/npm/twikoo/dist/twikoo.all.min.js').then(()=> {
        init()
        bool && $countDom && setTimeout(getCount,0)
      })
    }
  }

  if ('Twikoo' === 'Twikoo' || !false) {
    if (false) btf.loadComment(document.getElementById('twikoo-wrap'), loadTwikoo)
    else loadTwikoo(true)
  } else {
    window.loadOtherComment = () => {
      loadTwikoo()
    }
  }
})()</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><!-- hexo injector body_end start --> <script data-pjax>if(document.getElementById('recent-posts') && (location.pathname ==='/'|| '/' ==='all')){
    var parent = document.getElementById('recent-posts');
    var child = '<div class="recent-post-item" style="width:100%;height: auto"><div id="catalog_magnet"><div class="magnet_item"><a class="magnet_link" href="http://louishsu.xyz/categories/机器学习/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🐱 机器学习 (1)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://louishsu.xyz/categories/自然语言处理/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">📚 自然语言处理 (1)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://louishsu.xyz/categories/竞赛相关/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🎮 竞赛相关 (2)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://louishsu.xyz/categories/阅读笔记/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🎮 阅读笔记 (1)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><a class="magnet_link_more"  href="http://louishsu.xyz/categories" style="flex:1;text-align: center;margin-bottom: 10px;">查看更多...</a></div></div>';
    console.log('已挂载magnet')
    parent.insertAdjacentHTML("afterbegin",child)}
     </script><style>#catalog_magnet{flex-wrap: wrap;display: flex;width:100%;justify-content:space-between;padding: 10px 10px 0 10px;align-content: flex-start;}.magnet_item{flex-basis: calc(50% - 5px);background: #f2f2f2;margin-bottom: 10px;border-radius: 8px;transition: all 0.2s ease-in-out;}.magnet_item:hover{background: #b30070}.magnet_link_more{color:#555}.magnet_link{color:black}.magnet_link:hover{color:white}@media screen and (max-width: 600px) {.magnet_item {flex-basis: 100%;}}.magnet_link_context{display:flex;padding: 10px;font-size:16px;transition: all 0.2s ease-in-out;}.magnet_link_context:hover{padding: 10px 20px;}</style>
    <style></style>
  <script data-pjax src="https://cdn.jsdelivr.net/gh/Zfour/hexo-github-calendar@1.21/hexo_githubcalendar.js"></script>
  <script data-pjax>
        function GithubCalendarConfig(){
            var git_githubapiurl ="https://python-github-calendar-api.vercel.app/api?isLouisHsu";
            var git_color =['#ebedf0', '#fdcdec', '#fc9bd9', '#fa6ac5', '#f838b2', '#f5089f', '#c4067e', '#92055e', '#540336', '#48022f', '#30021f'];
            var git_user ="isLouisHsu";
            var parent_div_git = document.getElementById('recent-posts');
            var git_div_html = '<div class="recent-post-item" style="width:100%;height:auto;padding:10px;"><div id="github_loading" style="width:10%;height:100%;margin:0 auto;display: block"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"  viewBox="0 0 50 50" style="enable-background:new 0 0 50 50" xml:space="preserve"><path fill="#d0d0d0" d="M25.251,6.461c-10.318,0-18.683,8.365-18.683,18.683h4.068c0-8.071,6.543-14.615,14.615-14.615V6.461z" transform="rotate(275.098 25 25)"><animateTransform attributeType="xml" attributeName="transform" type="rotate" from="0 25 25" to="360 25 25" dur="0.6s" repeatCount="indefinite"></animateTransform></path></svg></div><div id="github_container"></div></div>';
            if(parent_div_git && location.pathname =='/'){
                console.log('已挂载github calendar')
                // parent_div_git.innerHTML=git_div_html+parent_div_git.innerHTML // 无报错，但不影响使用(支持pjax跳转)
                parent_div_git.insertAdjacentHTML("afterbegin",git_div_html) // 有报错，但不影响使用(支持pjax跳转)
            };
            GithubCalendar(git_githubapiurl,git_color,git_user)
        }
        if(document.getElementById('recent-posts')){
            GithubCalendarConfig()
        }
    </script>
    <style>#github_container{min-height:280px}@media screen and (max-width:650px) {#github_container{background-image:;min-height:0px}}</style>
    <style></style><script data-pjax>function electric_clock_injector_config(){
                var parent_div_git = document.getElementsByClassName('sticky_layout')[0];
                var item_html = '<div class="card-widget card-clock"><div class="card-glass"><div class="card-background"><div class="card-content"><div id="hexo_electric_clock"><img id="card-clock-loading" src="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-clock/clock/images/weather/loading.gif" style="height: 120px; width: 100%;" data-ll-status="loading" class="entered loading"></div></div></div></div></div>';
                console.log('已挂载electric_clock')
                // parent_div_git.innerHTML=item_html+parent_div_git.innerHTML // 无报错，但不影响使用(支持pjax跳转)
                parent_div_git.insertAdjacentHTML("afterbegin",item_html) // 有报错，但不影响使用(支持pjax跳转)
            }if( document.getElementsByClassName('sticky_layout')[0] && (location.pathname ==='all'|| 'all' ==='all')){

            electric_clock_injector_config()
        } </script><script src="https://pv.sohu.com/cityjson?ie=utf-8"></script><script data-pjax  src="https://cdn.jsdelivr.net/gh/Zfour/hexo-electric-clock@1.0.6/clock.js"></script><!-- hexo injector body_end end --><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"model":{"jsonPath":"/live2dw/assets/hijiki.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":false},"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body></html>