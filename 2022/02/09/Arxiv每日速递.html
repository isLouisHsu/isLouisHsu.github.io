<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Arxiv每日速递(2022-02-09) | LOUIS' BLOG</title><meta name="author" content="徐耀彬"><meta name="copyright" content="徐耀彬"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="本篇博文主要展示每日从Arxiv论文网站获取的最新论文列表，以计算机视觉、自然语言处理、机器学习、人工智能等大方向进行划分。 统计 今日共更新540篇论文，其中：  85篇计算机视觉（cs.CV） 36篇自然语言处理（cs.CL） 229篇机器学习（cs.LG） 106篇人工智能（cs.AI）  计算机视觉    1. 标题：Hybrid Contrastive Quantization for">
<meta property="og:type" content="article">
<meta property="og:title" content="Arxiv每日速递(2022-02-09)">
<meta property="og:url" content="http://louishsu.xyz/2022/02/09/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html">
<meta property="og:site_name" content="LOUIS&#39; BLOG">
<meta property="og:description" content="本篇博文主要展示每日从Arxiv论文网站获取的最新论文列表，以计算机视觉、自然语言处理、机器学习、人工智能等大方向进行划分。 统计 今日共更新540篇论文，其中：  85篇计算机视觉（cs.CV） 36篇自然语言处理（cs.CL） 229篇机器学习（cs.LG） 106篇人工智能（cs.AI）  计算机视觉    1. 标题：Hybrid Contrastive Quantization for">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png">
<meta property="article:published_time" content="2022-02-09T00:30:40.472Z">
<meta property="article:modified_time" content="2022-02-09T00:32:14.811Z">
<meta property="article:author" content="徐耀彬">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://louishsu.xyz/2022/02/09/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2022-02-09 08:32:14'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const fontSizeVal = saveToLocal.get('global-font-size')
    if (fontSizeVal !== undefined) {
      document.documentElement.style.setProperty('--global-font-size', fontSizeVal + 'px')
    }
    })(window)</script><link rel="stylesheet" href="/css/background.css"><script src="https://cdn.jsdelivr.net/npm/echarts@4.7.0/dist/echarts.min.js"></script><!-- hexo injector head_end start --><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Zfour/hexo-electric-clock@1.0.6/clock.css"><!-- hexo injector head_end end --><meta name="generator" content="Hexo 5.4.1"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="author-avatar"><img class="avatar-img" src="/img/touxiang.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">11</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">标签</div><div class="length-num">3</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">分类</div><div class="length-num">7</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/message/"><i class="fa-fw far fa-comment-dots"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa-fw fa fa-book"></i><span> 找文章</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></li><li><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></li><li><a class="site-page" href="/charts/"><i class="fa-fw fa fa-archive"></i><span> 统计</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-tools"></i><span> 工具</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/md_editor/"><i class="fa-fw fas fa-pen"></i><span> 在线markdown</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/isLouisHsu/blog/tree/master/source/_posts"><i class="fa-fw fa fa-star"></i><span> 在线push</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">LOUIS' BLOG</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/message/"><i class="fa-fw far fa-comment-dots"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa-fw fa fa-book"></i><span> 找文章</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></li><li><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></li><li><a class="site-page" href="/charts/"><i class="fa-fw fa fa-archive"></i><span> 统计</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-tools"></i><span> 工具</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/md_editor/"><i class="fa-fw fas fa-pen"></i><span> 在线markdown</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/isLouisHsu/blog/tree/master/source/_posts"><i class="fa-fw fa fa-star"></i><span> 在线push</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Arxiv每日速递(2022-02-09)<a class="post-edit-link" href="https://github.com/isLouisHsu/blog/tree/master/source_posts/Arxiv每日速递.md" title="编辑" target="_blank"><i class="fas fa-pencil-square"></i></a></h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-02-09T00:30:40.472Z" title="发表于 2022-02-09 08:30:40">2022-02-09</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2022-02-09T00:32:14.811Z" title="更新于 2022-02-09 08:32:14">2022-02-09</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">阅读笔记</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">71k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>425分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span><span class="post-meta-separator">|</span><span class="post-meta-commentcount"><i class="far fa-comments fa-fw post-meta-icon"></i><span class="post-meta-label">评论数:</span><a href="/2022/02/09/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html#post-comment"><span id="twikoo-count"></span></a></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><p>本篇博文主要展示每日从Arxiv论文网站获取的最新论文列表，以计算机视觉、自然语言处理、机器学习、人工智能等大方向进行划分。</p>
<h1>统计</h1>
<p>今日共更新540篇论文，其中：</p>
<ul>
<li>85篇计算机视觉（<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>）</li>
<li>36篇自然语言处理（<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>）</li>
<li>229篇机器学习（cs.LG）</li>
<li>106篇人工智能（<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>）</li>
</ul>
<h1>计算机视觉</h1>
<details>
  <summary>1. <b>标题：Hybrid Contrastive Quantization for Efficient Cross-View Video Retrieval</b></summary>
  <p><b>编号</b>：[13]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03384</p>
  <p><b>作者</b>：Jinpeng Wang,  Bin Chen,  Dongliang Liao,  Ziyun Zeng,  Gongfu Li,  Shu-Tao Xia,  Jin Xu</p>
  <p><b>备注</b>：Accepted to The Web Conference 2022 (WWW'22). 11 pages, 5 tables, 6 figures</p>
  <p><b>关键词</b>：web search engines widely apply vector compression libraries, tiktok ), video retrieval using sentence queries, three web video benchmark datasets demonstrate, first quantized representation learning method, preserve comprehensive semantic information</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>With the recent boom of video-based social platforms (e.g., YouTube and
TikTok), video retrieval using sentence queries has become an important demand
and attracts increasing research attention. Despite the decent performance,
existing text-video retrieval models in vision and language communities are
impractical for large-scale Web search because they adopt brute-force search
based on high-dimensional embeddings. To improve efficiency, Web search engines
widely apply vector compression libraries (e.g., FAISS) to post-process the
learned embeddings. Unfortunately, separate compression from feature encoding
degrades the robustness of representations and incurs performance decay. To
pursue a better balance between performance and efficiency, we propose the
first quantized representation learning method for cross-view video retrieval,
namely Hybrid Contrastive Quantization (HCQ). Specifically, HCQ learns both
coarse-grained and fine-grained quantizations with transformers, which provide
complementary understandings for texts and videos and preserve comprehensive
semantic information. By performing Asymmetric-Quantized Contrastive Learning
(AQ-CL) across views, HCQ aligns texts and videos at coarse-grained and
multiple fine-grained levels. This hybrid-grained learning strategy serves as
strong supervision on the cross-view video quantization model, where
contrastive learning at different levels can be mutually promoted. Extensive
experiments on three Web video benchmark datasets demonstrate that HCQ achieves
competitive performance with state-of-the-art non-compressed retrieval methods
while showing high efficiency in storage and computation. Code and
configurations are available at this https URL.</p>
  </details>
</details>
<details>
  <summary>2. <b>标题：Corrupted Image Modeling for Self-Supervised Visual Pre-Training</b></summary>
  <p><b>编号</b>：[14]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03382</p>
  <p><b>作者</b>：Yuxin Fang,  Li Dong,  Hangbo Bao,  Xinggang Wang,  Furu Wei</p>
  <p><b>备注</b>：Preprint. Work in progress. Code will be released at this https URL</p>
  <p><b>关键词</b>：learn rich visual representations using, using artificial mask tokens, approach achieves compelling results, introduce corrupted image modeling, 1k image classification respectively</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We introduce Corrupted Image Modeling (CIM) for self-supervised visual
pre-training. CIM uses an auxiliary generator with a small trainable BEiT to
corrupt the input image instead of using artificial mask tokens, where some
patches are randomly selected and replaced with plausible alternatives sampled
from the BEiT output distribution. Given this corrupted image, an enhancer
network learns to either recover all the original image pixels, or predict
whether each visual token is replaced by a generator sample or not. The
generator and the enhancer are simultaneously trained and synergistically
updated. After pre-training, the enhancer can be used as a high-capacity visual
encoder for downstream tasks. CIM is a general and flexible visual pre-training
framework that is suitable for various network architectures. For the first
time, CIM demonstrates that both ViT and CNN can learn rich visual
representations using a unified, non-Siamese framework. Experimental results
show that our approach achieves compelling results in vision benchmarks, such
as ImageNet classification and ADE20K semantic segmentation. For example,
300-epoch CIM pre-trained vanilla ViT-Base/16 and ResNet-50 obtain 83.3 and
80.6 Top-1 fine-tuning accuracy on ImageNet-1K image classification
respectively.</p>
  </details>
</details>
<details>
  <summary>3. <b>标题：Benchmarking and Analyzing Point Cloud Classification under Corruptions</b></summary>
  <p><b>编号</b>：[15]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03377</p>
  <p><b>作者</b>：Jiawei Ren,  Liang Pan,  Ziwei Liu</p>
  <p><b>备注</b>：Code and dataset are available at this https URL</p>
  <p><b>关键词</b>：proposed techniques could spark future research, although point cloud classification performance improves, enhance point cloud classifier robustness, especially point cloud classification, analyze point cloud classification</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>3D perception, especially point cloud classification, has achieved
substantial progress. However, in real-world deployment, point cloud
corruptions are inevitable due to the scene complexity, sensor inaccuracy, and
processing imprecision. In this work, we aim to rigorously benchmark and
analyze point cloud classification under corruptions. To conduct a systematic
investigation, we first provide a taxonomy of common 3D corruptions and
identify the atomic corruptions. Then, we perform a comprehensive evaluation on
a wide range of representative point cloud models to understand their
robustness and generalizability. Our benchmark results show that although point
cloud classification performance improves over time, the state-of-the-art
methods are on the verge of being less robust. Based on the obtained
observations, we propose several effective techniques to enhance point cloud
classifier robustness. We hope our comprehensive benchmark, in-depth analysis,
and proposed techniques could spark future research in robust 3D perception.</p>
  </details>
</details>
<details>
  <summary>4. <b>标题：Message Passing Neural PDE Solvers</b></summary>
  <p><b>编号</b>：[16]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03376</p>
  <p><b>作者</b>：Johannes Brandstetter,  Daniel Worrall,  Max Welling</p>
  <p><b>备注</b>：Published at ICLR 2022</p>
  <p><b>关键词</b>：accurate performance across different domain topologies, neural message passing solvers representationally contain, build neural -- numerical hybrid solvers, modern trend towards fully end, optimized neural function approximators</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The numerical solution of partial differential equations (PDEs) is difficult,
having led to a century of research so far. Recently, there have been pushes to
build neural--numerical hybrid solvers, which piggy-backs the modern trend
towards fully end-to-end learned systems. Most works so far can only generalize
over a subset of properties to which a generic solver would be faced,
including: resolution, topology, geometry, boundary conditions, domain
discretization regularity, dimensionality, etc. In this work, we build a
solver, satisfying these properties, where all the components are based on
neural message passing, replacing all heuristically designed components in the
computation graph with backprop-optimized neural function approximators. We
show that neural message passing solvers representationally contain some
classical methods, such as finite differences, finite volumes, and WENO
schemes. In order to encourage stability in training autoregressive models, we
put forward a method that is based on the principle of zero-stability, posing
stability as a domain adaptation problem. We validate our method on various
fluid-like flow problems, demonstrating fast, stable, and accurate performance
across different domain topologies, discretization, etc. in 1D and 2D. Our
model outperforms state-of-the-art numerical solvers in the low resolution
regime in terms of speed and accuracy.</p>
  </details>
</details>
<details>
  <summary>5. <b>标题：Simple Control Baselines for Evaluating Transfer Learning</b></summary>
  <p><b>编号</b>：[19]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03365</p>
  <p><b>作者</b>：Andrei Atanov,  Shijian Xu,  Onur Beker,  Andrei Filatov,  Amir Zamir</p>
  <p><b>备注</b>：Project website: this https URL</p>
  <p><b>关键词</b>：skewed towards image classification tasks versus dense pixel, simple yet critical control baselines, dataset bias ), scratch, communicate transfer learning performance, example empirical study investigating</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Transfer learning has witnessed remarkable progress in recent years, for
example, with the introduction of augmentation-based contrastive
self-supervised learning methods. While a number of large-scale empirical
studies on the transfer performance of such models have been conducted, there
is not yet an agreed-upon set of control baselines, evaluation practices, and
metrics to report, which often hinders a nuanced and calibrated understanding
of the real efficacy of the methods. We share an evaluation standard that aims
to quantify and communicate transfer learning performance in an informative and
accessible setup. This is done by baking a number of simple yet critical
control baselines in the evaluation method, particularly the blind-guess
(quantifying the dataset bias), scratch-model (quantifying the architectural
contribution), and maximal-supervision (quantifying the upper-bound). To
demonstrate how the evaluation standard can be employed, we provide an example
empirical study investigating a few basic questions about self-supervised
learning. For example, using this standard, the study shows the effectiveness
of existing self-supervised pre-training methods is skewed towards image
classification tasks versus dense pixel-wise predictions. In general, we
encourage using/reporting the suggested control baselines in evaluating
transfer learning in order to gain a more meaningful and informative
understanding.</p>
  </details>
</details>
<details>
  <summary>6. <b>标题：FrePGAN: Robust Deepfake Detection Using Frequency-level Perturbations</b></summary>
  <p><b>编号</b>：[27]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03347</p>
  <p><b>作者</b>：Yonghyun Jeong,  Doyeon Kim,  Youngmin Ro,  Jongwon Choi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：design new test scenarios varying, generalization across various gan models, various deepfake detectors, unseen gan models, gan models outside</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Various deepfake detectors have been proposed, but challenges still exist to
detect images of unknown categories or GAN models outside of the training
settings. Such issues arise from the overfitting issue, which we discover from
our own analysis and the previous studies to originate from the frequency-level
artifacts in generated images. We find that ignoring the frequency-level
artifacts can improve the detector's generalization across various GAN models,
but it can reduce the model's performance for the trained GAN models. Thus, we
design a framework to generalize the deepfake detector for both the known and
unseen GAN models. Our framework generates the frequency-level perturbation
maps to make the generated images indistinguishable from the real images. By
updating the deepfake detector along with the training of the perturbation
generator, our model is trained to detect the frequency-level artifacts at the
initial iterations and consider the image-level irregularities at the last
iterations. For experiments, we design new test scenarios varying from the
training settings in GAN models, color manipulations, and object categories.
Numerous experiments validate the state-of-the-art performance of our deepfake
detector.</p>
  </details>
</details>
<details>
  <summary>7. <b>标题：CZU-MHAD: A multimodal dataset for human action recognition utilizing a  depth camera and 10 wearable inertial sensors</b></summary>
  <p><b>编号</b>：[48]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03283</p>
  <p><b>作者</b>：Xin Chao,  Zhenjie Hou,  Yujian Mo</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：three modals temporal synchronized data, modal human action dataset )., modals include depth videos, 10 main motion joints, many human action datasets</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Human action recognition has been widely used in many fields of life, and
many human action datasets have been published at the same time. However, most
of the multi-modal databases have some shortcomings in the layout and number of
sensors, which cannot fully represent the action features. Regarding the
problems, this paper proposes a freely available dataset, named CZU-MHAD
(Changzhou University: a comprehensive multi-modal human action dataset). It
consists of 22 actions and three modals temporal synchronized data. These
modals include depth videos and skeleton positions from a kinect v2 camera, and
inertial signals from 10 wearable sensors. Compared with single modal sensors,
multi-modal sensors can collect different modal data, so the use of multi-modal
sensors can describe actions more accurately. Moreover, CZU-MHAD obtains the
3-axis acceleration and 3-axis angular velocity of 10 main motion joints by
binding inertial sensors to them, and these data were captured at the same
time. Experimental results are provided to show that this dataset can be used
to study structural relationships between different parts of the human body
when performing actions and fusion approaches that involve multi-modal sensor
data.</p>
  </details>
</details>
<details>
  <summary>8. <b>标题：Crafting Better Contrastive Views for Siamese Representation Learning</b></summary>
  <p><b>编号</b>：[51]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03278</p>
  <p><b>作者</b>：Xiangyu Peng,  Kai Wang,  Zheng Zhu,  Yang You</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：previous works simply apply random sampling, supervised contrastive learning methods greatly benefit, high performance siamese representation learning, could effectively generate better crops, e ., object vs</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent self-supervised contrastive learning methods greatly benefit from the
Siamese structure that aims at minimizing distances between positive pairs. For
high performance Siamese representation learning, one of the keys is to design
good contrastive pairs. Most previous works simply apply random sampling to
make different crops of the same image, which overlooks the semantic
information that may degrade the quality of views. In this work, we propose
ContrastiveCrop, which could effectively generate better crops for Siamese
representation learning. Firstly, a semantic-aware object localization strategy
is proposed within the training process in a fully unsupervised manner. This
guides us to generate contrastive views which could avoid most false positives
(i.e., object vs. background). Moreover, we empirically find that views with
similar appearances are trivial for the Siamese model training. Thus, a
center-suppressed sampling is further designed to enlarge the variance of
crops. Remarkably, our method takes a careful consideration of positive pairs
for contrastive learning with negligible extra training overhead. As a
plug-and-play and framework-agnostic module, ContrastiveCrop consistently
improves SimCLR, MoCo, BYOL, SimSiam by 0.4% ~ 2.0% classification accuracy on
CIFAR-10, CIFAR-100, Tiny ImageNet and STL-10. Superior results are also
achieved on downstream detection and segmentation tasks when pre-trained on
ImageNet-1K.</p>
  </details>
</details>
<details>
  <summary>9. <b>标题：Confidence Guided Depth Completion Network</b></summary>
  <p><b>编号</b>：[57]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03257</p>
  <p><b>作者</b>：Yongjin Lee,  Seokjun Park,  Beomgu Kang,  Hyunwook Park</p>
  <p><b>备注</b>：6 pages, 3 figures, 2 tables</p>
  <p><b>关键词</b>：proposed model shows much faster computation time, kitti depth completion online leaderboard, estimate accurate dense depth maps, guided depth completion method, first depth map using</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The paper proposes an image-guided depth completion method to estimate
accurate dense depth maps with fast computation time. The proposed network has
two-stage structure. The first stage predicts a first depth map. Then, the
second stage further refines the first depth map using the confidence maps. The
second stage consists of two layers, each of which focuses on different regions
and generates a refined depth map and a confidence map. The final depth map is
obtained by combining two depth maps from the second stage using the
corresponding confidence maps. Compared with the top-ranked models on the KITTI
depth completion online leaderboard, the proposed model shows much faster
computation time and competitive performance.</p>
  </details>
</details>
<details>
  <summary>10. <b>标题：Towards an Analytical Definition of Sufficient Data</b></summary>
  <p><b>编号</b>：[66]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03238</p>
  <p><b>作者</b>：Adam Byerly,  Tatiana Kalganova</p>
  <p><b>备注</b>：17 pages, 36 figures, 7 tables</p>
  <p><b>关键词</b>：reduced dimensional space relative, statistically significant difference, entire training set, certain training samples, samples nearer</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We show that, for each of five datasets of increasing complexity, certain
training samples are more informative of class membership than others. These
samples can be identified a priori to training by analyzing their position in
reduced dimensional space relative to the classes' centroids. Specifically, we
demonstrate that samples nearer the classes' centroids are less informative
than those that are furthest from it. For all five datasets, we show that there
is no statistically significant difference between training on the entire
training set and when excluding up to 2% of the data nearest to each class's
centroid.</p>
  </details>
</details>
<details>
  <summary>11. <b>标题：PSSNet: Planarity-sensible Semantic Segmentation of Large-scale Urban  Meshes</b></summary>
  <p><b>编号</b>：[73]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03209</p>
  <p><b>作者</b>：Weixiao Gao,  Liangliang Nan,  Hugo Ledoux,  Bas Boom</p>
  <p><b>备注</b>：8 pages,9 figures</p>
  <p><b>关键词</b>：large semantic urban mesh benchmark demonstrate, interpret 3d urban scenes represented, also introduce several new metrics, object boundaries typically align, framework achieves semantic segmentation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We introduce a novel deep learning-based framework to interpret 3D urban
scenes represented as textured meshes. Based on the observation that object
boundaries typically align with the boundaries of planar regions, our framework
achieves semantic segmentation in two steps: planarity-sensible
over-segmentation followed by semantic classification. The over-segmentation
step generates an initial set of mesh segments that capture the planar and
non-planar regions of urban scenes. In the subsequent classification step, we
construct a graph that encodes geometric and photometric features of the
segments in its nodes and multi-scale contextual features in its edges. The
final semantic segmentation is obtained by classifying the segments using a
graph convolutional network. Experiments and comparisons on a large semantic
urban mesh benchmark demonstrate that our approach outperforms the
state-of-the-art methods in terms of boundary quality and mean IoU
(intersection over union). Besides, we also introduce several new metrics for
evaluating mesh over-segmentation methods dedicated for semantic segmentation,
and our proposed over-segmentation approach outperforms state-of-the-art
methods on all metrics. Our source code will be released when the paper is
accepted.</p>
  </details>
</details>
<details>
  <summary>12. <b>标题：Recent Trends in 2D Object Detection and Applications in Video Event  Recognition</b></summary>
  <p><b>编号</b>：[76]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03206</p>
  <p><b>作者</b>：Prithwish Jana,  Partha Pratim Mohanta</p>
  <p><b>备注</b>：Book chapter: P Jana and PP Mohanta, Recent Trends in 2D Object Detection and Applications in Video Event Recognition, published in Advancement of Deep Learning and its Applications in Object Detection and Recognition, edited by R N Mir et al, 2022, published by River Publishers</p>
  <p><b>关键词</b>：art 2d object detection techniques proffer superlative results even, complex downstream computer vision tasks, art object detection techniques, first generate region proposals, grained video classification performance</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Object detection serves as a significant step in improving performance of
complex downstream computer vision tasks. It has been extensively studied for
many years now and current state-of-the-art 2D object detection techniques
proffer superlative results even in complex images. In this chapter, we discuss
the geometry-based pioneering works in object detection, followed by the recent
breakthroughs that employ deep learning. Some of these use a monolithic
architecture that takes a RGB image as input and passes it to a feed-forward
ConvNet or vision Transformer. These methods, thereby predict class-probability
and bounding-box coordinates, all in a single unified pipeline. Two-stage
architectures on the other hand, first generate region proposals and then feed
it to a CNN to extract features and predict object category and bounding-box.
We also elaborate upon the applications of object detection in video event
recognition, to achieve better fine-grained video classification performance.
Further, we highlight recent datasets for 2D object detection both in images
and videos, and present a comparative performance summary of various
state-of-the-art object detection techniques.</p>
  </details>
</details>
<details>
  <summary>13. <b>标题：Optical skin: Sensor-integration-free multimodal flexible sensing</b></summary>
  <p><b>编号</b>：[84]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03189</p>
  <p><b>作者</b>：Sho Shimadera,  Kei Kitagawa,  Koyo Sagehashi,  Tomoaki Niiyama,  Satoshi Sunada</p>
  <p><b>备注</b>：13 pages, 11 figures</p>
  <p><b>关键词</b>：single soft material without requiring complex integration, three different physical quantities, require integrating multiple sensors, large area remains challenging, demonstrate simultaneous sensing mode</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The biological skin enables animals to sense various stimuli. Extensive
efforts have been made recently to develop smart skin-like sensors to extend
the capabilities of biological skins; however, simultaneous sensing of several
types of stimuli in a large area remains challenging because this requires
large-scale sensor integration with numerous wire connections. We propose a
simple, highly sensitive, and multimodal sensing approach, which does not
require integrating multiple sensors. The proposed approach is based on an
optical interference technique, which can encode the information of various
stimuli as a spatial pattern. In contrast to the existing approach, the
proposed approach, combined with a deep neural network, enables us to freely
select the sensing mode according to our purpose. As a key example, we
demonstrate simultaneous sensing mode of three different physical quantities,
contact force, contact location, and temperature, using a single soft material
without requiring complex integration. Another unique property of the proposed
approach is spatially continuous sensing with ultrahigh resolution of few tens
of micrometers, which enables identifying the shape of the object in contact.
Furthermore, we present a haptic soft device for a human-machine interface. The
proposed approach encourages the development of high-performance optical skins.</p>
  </details>
</details>
<details>
  <summary>14. <b>标题：TransFollower: Long-Sequence Car-Following Trajectory Prediction through  Transformer</b></summary>
  <p><b>编号</b>：[88]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03183</p>
  <p><b>作者</b>：Meixin Zhu,  Simon S. Du,  Xuesong Wang, Hao (Frank) Yang,  Ziyuan Pu,  Yinhai Wang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：fully connected neural network model, historical driving context using multi, predicted future fv speed profile, one vehicle follows another vehicle, following trajectory prediction model based</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Car-following refers to a control process in which the following vehicle (FV)
tries to keep a safe distance between itself and the lead vehicle (LV) by
adjusting its acceleration in response to the actions of the vehicle ahead. The
corresponding car-following models, which describe how one vehicle follows
another vehicle in the traffic flow, form the cornerstone for microscopic
traffic simulation and intelligent vehicle development. One major motivation of
car-following models is to replicate human drivers' longitudinal driving
trajectories. To model the long-term dependency of future actions on historical
driving situations, we developed a long-sequence car-following trajectory
prediction model based on the attention-based Transformer model. The model
follows a general format of encoder-decoder architecture. The encoder takes
historical speed and spacing data as inputs and forms a mixed representation of
historical driving context using multi-head self-attention. The decoder takes
the future LV speed profile as input and outputs the predicted future FV speed
profile in a generative way (instead of an auto-regressive way, avoiding
compounding errors). Through cross-attention between encoder and decoder, the
decoder learns to build a connection between historical driving and future LV
speed, based on which a prediction of future FV speed can be obtained. We train
and test our model with 112,597 real-world car-following events extracted from
the Shanghai Naturalistic Driving Study (SH-NDS). Results show that the model
outperforms the traditional intelligent driver model (IDM), a fully connected
neural network model, and a long short-term memory (LSTM) based model in terms
of long-sequence trajectory prediction accuracy. We also visualized the
self-attention and cross-attention heatmaps to explain how the model derives
its predictions.</p>
  </details>
</details>
<details>
  <summary>15. <b>标题：Field-of-View IoU for Object Detection in 360° Images</b></summary>
  <p><b>编号</b>：[91]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03176</p>
  <p><b>作者</b>：Miao Cao,  Satoshi Ikehata,  Kiyoharu Aizawa</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：propose two fundamental techniques -- field, object detection neural networks designed, 360 ° object detection task, data augmentation technique specific, existing perspective object detectors</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>360° cameras have gained popularity over the last few years. In this
paper, we propose two fundamental techniques -- Field-of-View IoU (FoV-IoU) and
360Augmentation for object detection in 360° images. Although most object
detection neural networks designed for the perspective images are applicable to
360° images in equirectangular projection (ERP) format, their performance
deteriorates owing to the distortion in ERP images. Our method can be readily
integrated with existing perspective object detectors and significantly
improves the performance. The FoV-IoU computes the intersection-over-union of
two Field-of-View bounding boxes in a spherical image which could be used for
training, inference, and evaluation while 360Augmentation is a data
augmentation technique specific to 360° object detection task which
randomly rotates a spherical image and solves the bias due to the
sphere-to-plane projection. We conduct extensive experiments on the 360indoor
dataset with different types of perspective object detectors and show the
consistent effectiveness of our method.</p>
  </details>
</details>
<details>
  <summary>16. <b>标题：Patch-Based Stochastic Attention for Image Editing</b></summary>
  <p><b>编号</b>：[97]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03163</p>
  <p><b>作者</b>：Nicolas Cherel,  Andrés Almansa,  Yann Gousseau,  Alasdair Newson</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：footprint without sacrificing spatial precision, limitations curb network architectures, determining approximate nearest neighbors, several image editing tasks, efficient attention layer based</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Attention mechanisms have become of crucial importance in deep learning in
recent years. These non-local operations, which are similar to traditional
patch-based methods in image processing, complement local convolutions.
However, computing the full attention matrix is an expensive step with a heavy
memory and computational load. These limitations curb network architectures and
performances, in particular for the case of high resolution images. We propose
an efficient attention layer based on the stochastic algorithm PatchMatch,
which is used for determining approximate nearest neighbors. We refer to our
proposed layer as a "Patch-based Stochastic Attention Layer" (PSAL).
Furthermore, we propose different approaches, based on patch aggregation, to
ensure the differentiability of PSAL, thus allowing end-to-end training of any
network containing our layer. PSAL has a small memory footprint and can
therefore scale to high resolution images. It maintains this footprint without
sacrificing spatial precision and globality of the nearest neighbours, which
means that it can be easily inserted in any level of a deep architecture, even
in shallower levels. We demonstrate the usefulness of PSAL on several image
editing tasks, such as image inpainting and image colorization.</p>
  </details>
</details>
<details>
  <summary>17. <b>标题：Rate Coding or Direct Coding: Which One is Better for Accurate, Robust,  and Energy-efficient Spiking Neural Networks?</b></summary>
  <p><b>编号</b>：[108]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03133</p>
  <p><b>作者</b>：Youngeun Kim,  Hyoungseob Park,  Abhishek Moitra,  Abhiroop Bhattacharjee,  Yeshwanth Venkatesha,  Priyadarshini Panda</p>
  <p><b>备注</b>：Accepted to ICASSP2022</p>
  <p><b>关键词</b>：rate coding also yields higher energy, rate coding shows better robustness, recent spiking neural networks, differentiable spike generation process, achieve better accuracy especially</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent Spiking Neural Networks (SNNs) works focus on an image classification
task, therefore various coding techniques have been proposed to convert an
image into temporal binary spikes. Among them, rate coding and direct coding
are regarded as prospective candidates for building a practical SNN system as
they show state-of-the-art performance on large-scale datasets. Despite their
usage, there is little attention to comparing these two coding schemes in a
fair manner. In this paper, we conduct a comprehensive analysis of the two
codings from three perspectives: accuracy, adversarial robustness, and
energy-efficiency. First, we compare the performance of two coding techniques
with various architectures and datasets. Then, we measure the robustness of the
coding techniques on two adversarial attack methods. Finally, we compare the
energy-efficiency of two coding schemes on a digital hardware platform. Our
results show that direct coding can achieve better accuracy especially for a
small number of timesteps. In contrast, rate coding shows better robustness to
adversarial attacks owing to the non-differentiable spike generation process.
Rate coding also yields higher energy-efficiency than direct coding which
requires multi-bit precision for the first layer. Our study explores the
characteristics of two codings, which is an important design consideration for
building SNNs. The code is made available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>18. <b>标题：Transformers in Self-Supervised Monocular Depth Estimation with Unknown  Camera Intrinsics</b></summary>
  <p><b>编号</b>：[109]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03131</p>
  <p><b>作者</b>：Arnav Varma,  Hemang Chawla,  Bahram Zonooz,  Elahe Arani</p>
  <p><b>备注</b>：Published in 17th International Conference on Computer Vision Theory and Applications (VISAP, 2022)</p>
  <p><b>关键词</b>：advanced driver assistance systems necessitates continuous developments, kitti depth prediction benchmarks, supervised monocular depth estimation, supervised monocular depth estimation, supervised monocular depth estimation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The advent of autonomous driving and advanced driver assistance systems
necessitates continuous developments in computer vision for 3D scene
understanding. Self-supervised monocular depth estimation, a method for
pixel-wise distance estimation of objects from a single camera without the use
of ground truth labels, is an important task in 3D scene understanding.
However, existing methods for this task are limited to convolutional neural
network (CNN) architectures. In contrast with CNNs that use localized linear
operations and lose feature resolution across the layers, vision transformers
process at constant resolution with a global receptive field at every stage.
While recent works have compared transformers against their CNN counterparts
for tasks such as image classification, no study exists that investigates the
impact of using transformers for self-supervised monocular depth estimation.
Here, we first demonstrate how to adapt vision transformers for self-supervised
monocular depth estimation. Thereafter, we compare the transformer and
CNN-based architectures for their performance on KITTI depth prediction
benchmarks, as well as their robustness to natural corruptions and adversarial
attacks, including when the camera intrinsics are unknown. Our study
demonstrates how transformer-based architecture, though lower in run-time
efficiency, achieves comparable performance while being more robust and
generalizable.</p>
  </details>
</details>
<details>
  <summary>19. <b>标题：Reasoning for Complex Data through Ensemble-based Self-Supervised  Learning</b></summary>
  <p><b>编号</b>：[111]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03126</p>
  <p><b>作者</b>：Gabriel Bertocco,  Antônio Theófilo,  Fernanda Andaló,  Anderson Rocha</p>
  <p><b>备注</b>：On main article: 12 pages, 7 figures and 5 tables On Supplementary material: 5 pages, 4 figures and 2 tables</p>
  <p><b>关键词</b>：also consider different convolutional neural networks, optimal configuration per dataset, supervised learning methods fail, robust across different modalities, consider two applications</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Self-supervised learning deals with problems that have little or no available
labeled data. Recent work has shown impressive results when underlying classes
have significant semantic differences. One important dataset in which this
technique thrives is ImageNet, as intra-class distances are substantially lower
than inter-class distances. However, this is not the case for several critical
tasks, and general self-supervised learning methods fail to learn
discriminative features when classes have closer semantics, thus requiring more
robust strategies. We propose a strategy to tackle this problem, and to enable
learning from unlabeled data even when samples from different classes are not
prominently diverse. We approach the problem by leveraging a novel
ensemble-based clustering strategy where clusters derived from different
configurations are combined to generate a better grouping for the data samples
in a fully-unsupervised way. This strategy allows clusters with different
densities and higher variability to emerge, which in turn reduces intra-class
discrepancies, without requiring the burden of finding an optimal configuration
per dataset. We also consider different Convolutional Neural Networks to
compute distances between samples. We refine these distances by performing
context analysis and group them to capture complementary information. We
consider two applications to validate our pipeline: Person Re-Identification
and Text Authorship Verification. These are challenging applications
considering that classes are semantically close to each other and that training
and test sets have disjoint identities. Our method is robust across different
modalities and outperforms state-of-the-art results with a fully-unsupervised
solution without any labeling or human intervention.</p>
  </details>
</details>
<details>
  <summary>20. <b>标题：Bubble identification from images with machine learning methods</b></summary>
  <p><b>编号</b>：[114]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03107</p>
  <p><b>作者</b>：Hendrik Hessenkemper,  Sebastian Starke,  Yazan Atassi,  Thomas Ziegenhein,  Dirk Lucas</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：testing three different methods based, handle different image conditions, particular difficulty arises due, higher gas volume fractions, created test data sets</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>An automated and reliable processing of bubbly flow images is highly needed
to analyse large data sets of comprehensive experimental series. A particular
difficulty arises due to overlapping bubble projections in recorded images,
which highly complicates the identification of individual bubbles. Recent
approaches focus on the use of deep learning algorithms for this task and have
already proven the high potential of such techniques. The main difficulties are
the capability to handle different image conditions, higher gas volume
fractions and a proper reconstruction of the hidden segment of a partly
occluded bubble. In the present work, we try to tackle these points by testing
three different methods based on Convolutional Neural Networks (CNNs) for the
two former and two individual approaches that can be used subsequently to
address the latter. To validate our methodology, we created test data sets with
synthetic images that further demonstrate the capabilities as well as
limitations of our combined approach. The generated data, code and trained
models are made accessible to facilitate the use as well as further
developments in the research field of bubble recognition in experimental
images.</p>
  </details>
</details>
<details>
  <summary>21. <b>标题：Auto-Lambda: Disentangling Dynamic Task Relationships</b></summary>
  <p><b>编号</b>：[122]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03091</p>
  <p><b>作者</b>：Shikun Liu,  Stephen James,  Andrew J. Davison,  Edward Johns</p>
  <p><b>备注</b>：Tech Report. Project Page: this https URL Code: this https URL</p>
  <p><b>关键词</b>：validation loss automatically influences task weightings throughout training, dynamic task relationships via task, optimisation strategies designed specifically, extremely high computational cost, learn task relationships via</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Understanding the structure of multiple related tasks allows for multi-task
learning to improve the generalisation ability of one or all of them. However,
it usually requires training each pairwise combination of tasks together in
order to capture task relationships, at an extremely high computational cost.
In this work, we learn task relationships via an automated weighting framework,
named Auto-Lambda. Unlike previous methods where task relationships are assumed
to be fixed, Auto-Lambda is a gradient-based meta learning framework which
explores continuous, dynamic task relationships via task-specific weightings,
and can optimise any choice of combination of tasks through the formulation of
a meta-loss; where the validation loss automatically influences task weightings
throughout training. We apply the proposed framework to both multi-task and
auxiliary learning problems in computer vision and robotics, and show that
Auto-Lambda achieves state-of-the-art performance, even when compared to
optimisation strategies designed specifically for each problem and data domain.
Finally, we observe that Auto-Lambda can discover interesting learning
behaviors, leading to new insights in multi-task learning. Code is available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>22. <b>标题：Unsupervised Long-Term Person Re-Identification with Clothes Change</b></summary>
  <p><b>编号</b>：[123]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03087</p>
  <p><b>作者</b>：Mingkun Li,  Peng Xu,  Xiatian Zhu,  Jun Guo</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：supervised learning person identity discriminative representation, average person would often change, unsupervised clustering criterion according, novel curriculum person clustering, cpc outperforms sota unsupervised</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We investigate unsupervised person re-identification (Re-ID) with clothes
change, a new challenging problem with more practical usability and scalability
to real-world deployment. Most existing re-id methods artificially assume the
clothes of every single person to be stationary across space and time. This
condition is mostly valid for short-term re-id scenarios since an average
person would often change the clothes even within a single day. To alleviate
this assumption, several recent works have introduced the clothes change facet
to re-id, with a focus on supervised learning person identity discriminative
representation with invariance to clothes changes. Taking a step further
towards this long-term re-id direction, we further eliminate the requirement of
person identity labels, as they are significantly more expensive and more
tedious to annotate in comparison to short-term person re-id datasets. Compared
to conventional unsupervised short-term re-id, this new problem is drastically
more challenging as different people may have similar clothes whilst the same
person can wear multiple suites of clothes over different locations and times
with very distinct appearance. To overcome such obstacles, we introduce a novel
Curriculum Person Clustering (CPC) method that can adaptively regulate the
unsupervised clustering criterion according to the clustering confidence.
Experiments on three long-term person re-id datasets show that our CPC
outperforms SOTA unsupervised re-id methods and even closely matches the
supervised re-id models.</p>
  </details>
</details>
<details>
  <summary>23. <b>标题：Temporal Point Cloud Completion with Pose Disturbance</b></summary>
  <p><b>编号</b>：[125]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03084</p>
  <p><b>作者</b>：Jieqi Shi,  Lingyun Xu,  Peiliang Li,  Xiaozhi Chen,  Shaojie Shen</p>
  <p><b>备注</b>：8 pages; Accepted by RAL with ICRA 2022</p>
  <p><b>关键词</b>：also use temporal information, provide complete point clouds, point cloud completion framework, refined point cloud, point clouds collected</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Point clouds collected by real-world sensors are always unaligned and sparse,
which makes it hard to reconstruct the complete shape of object from a single
frame of data. In this work, we manage to provide complete point clouds from
sparse input with pose disturbance by limited translation and rotation. We also
use temporal information to enhance the completion model, refining the output
with a sequence of inputs. With the help of gated recovery units(GRU) and
attention mechanisms as temporal units, we propose a point cloud completion
framework that accepts a sequence of unaligned and sparse inputs, and outputs
consistent and aligned point clouds. Our network performs in an online manner
and presents a refined point cloud for each frame, which enables it to be
integrated into any SLAM or reconstruction pipeline. As far as we know, our
framework is the first to utilize temporal information and ensure temporal
consistency with limited transformation. Through experiments in ShapeNet and
KITTI, we prove that our framework is effective in both synthetic and
real-world datasets.</p>
  </details>
</details>
<details>
  <summary>24. <b>标题：Imposing Temporal Consistency on Deep Monocular Body Shape and Pose  Estimation</b></summary>
  <p><b>编号</b>：[130]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03074</p>
  <p><b>作者</b>：Alexandra Zimmer,  Anna Hilsmann,  Wieland Morgenstern,  Peter Eisert</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：assuming linear body joint trajectories, fitting one consistent body shape, understanding human social behavior, accurately estimated body shape, realistic 3d body models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Accurate and temporally consistent modeling of human bodies is essential for
a wide range of applications, including character animation, understanding
human social behavior and AR/VR interfaces. Capturing human motion accurately
from a monocular image sequence is still challenging and the modeling quality
is strongly influenced by the temporal consistency of the captured body motion.
Our work presents an elegant solution for the integration of temporal
constraints in the fitting process. This does not only increase temporal
consistency but also robustness during the optimization. In detail, we derive
parameters of a sequence of body models, representing shape and motion of a
person, including jaw poses, facial expressions, and finger poses. We optimize
these parameters over the complete image sequence, fitting one consistent body
shape while imposing temporal consistency on the body motion, assuming linear
body joint trajectories over a short time. Our approach enables the derivation
of realistic 3D body models from image sequences, including facial expression
and articulated hands. In extensive experiments, we show that our approach
results in accurately estimated body shape and motion, also for challenging
movements and poses. Further, we apply it to the special application of sign
language analysis, where accurate and temporal consistent motion modelling is
essential, and show that the approach is well-suited for this kind of
application.</p>
  </details>
</details>
<details>
  <summary>25. <b>标题：Evaluation of Runtime Monitoring for UAV Emergency Landing</b></summary>
  <p><b>编号</b>：[136]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03059</p>
  <p><b>作者</b>：Joris Guerin,  Kevin Delmas,  Jérémie Guiochet</p>
  <p><b>备注</b>：7 pages, 4 figures, 1 table. To appear in the proceedings of 2022 IEEE International Conference on Robotics and Automation (ICRA)</p>
  <p><b>关键词</b>：finding safe landing areas using, proposed el pipeline includes mechanisms, monitor learning based components, machine learning runtime monitoring, risk mitigation strategies --</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>To certify UAV operations in populated areas, risk mitigation strategies --
such as Emergency Landing (EL) -- must be in place to account for potential
failures. EL aims at reducing ground risk by finding safe landing areas using
on-board sensors. The first contribution of this paper is to present a new EL
approach, in line with safety requirements introduced in recent research. In
particular, the proposed EL pipeline includes mechanisms to monitor learning
based components during execution. This way, another contribution is to study
the behavior of Machine Learning Runtime Monitoring (MLRM) approaches within
the context of a real-world critical system. A new evaluation methodology is
introduced, and applied to assess the practical safety benefits of three MLRM
mechanisms. The proposed approach is compared to a default mitigation strategy
(open a parachute when a failure is detected), and appears to be much safer.</p>
  </details>
</details>
<details>
  <summary>26. <b>标题：Unifying Architectures, Tasks, and Modalities Through a Simple  Sequence-to-Sequence Learning Framework</b></summary>
  <p><b>编号</b>：[141]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03052</p>
  <p><b>作者</b>：Peng Wang,  An Yang,  Rui Men,  Junyang Lin,  Shuai Bai,  Zhikang Li,  Jianxin Ma,  Chang Zhou,  Jingren Zhou,  Hongxia Yang</p>
  <p><b>备注</b>：23 pages, 11 figures</p>
  <p><b>关键词</b>：ofa reaches comparable performance, ofa achieves new state, sequence learning framework based, unified multimodal pretrained model, g ., image generation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this work, we pursue a unified paradigm for multimodal pretraining to
break the scaffolds of complex task/modality-specific customization. We propose
OFA, a unified multimodal pretrained model that unifies modalities (i.e.,
cross-modality, vision, language) and tasks (e.g., image generation, visual
grounding, image captioning, image classification, text generation, etc.) to a
simple sequence-to-sequence learning framework based on the encoder-decoder
architecture. OFA performs pretraining and finetuning with task instructions
and introduces no extra task-specific layers for finetuning. Experimental
results show that OFA achieves new state-of-the-arts on a series of multimodal
tasks, including image captioning (COCO test CIDEr: 149.6), text-to-image
generation (COCO test FID: 10.5), VQA (test-std acc.: 80.02), SNLI-VE (test
acc.: 90.20), and referring expression comprehension (RefCOCO / RefCOCO+ /
RefCOCOg test acc.: 92.93 / 90.10 / 85.20). Through extensive analyses, we
demonstrate that OFA reaches comparable performance with uni-modal pretrained
models (e.g., BERT, MAE, MoCo v3, SimCLR v2, etc.) in uni-modal tasks,
including NLU, NLG, and image classification, and it effectively transfers to
unseen tasks and domains. Code shall be released soon at
this http URL</p>
  </details>
</details>
<details>
  <summary>27. <b>标题：A new face swap method for image and video domains: a technical report</b></summary>
  <p><b>编号</b>：[144]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03046</p>
  <p><b>作者</b>：Daniil Chesakov,  Anastasia Maltseva,  Alexander Groshev,  Andrey Kuznetsov,  Denis Dimitrov</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：researchers investigate sophisticated generative adversarial networks, deep fake unsupervised synthesis task, based face mask generation leads, deep fake technology became, new eye loss function</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep fake technology became a hot field of research in the last few years.
Researchers investigate sophisticated Generative Adversarial Networks (GAN),
autoencoders, and other approaches to establish precise and robust algorithms
for face swapping. Achieved results show that the deep fake unsupervised
synthesis task has problems in terms of the visual quality of generated data.
These problems usually lead to high fake detection accuracy when an expert
analyzes them. The first problem is that existing image-to-image approaches do
not consider video domain specificity and frame-by-frame processing leads to
face jittering and other clearly visible distortions. Another problem is the
generated data resolution, which is low for many existing methods due to high
computational complexity. The third problem appears when the source face has
larger proportions (like bigger cheeks), and after replacement it becomes
visible on the face border. Our main goal was to develop such an approach that
could solve these problems and outperform existing solutions on a number of
clue metrics. We introduce a new face swap pipeline that is based on
FaceShifter architecture and fixes the problems stated above. With a new eye
loss function, super-resolution block, and Gaussian-based face mask generation
leads to improvements in quality which is confirmed during evaluation.</p>
  </details>
</details>
<details>
  <summary>28. <b>标题：Context Autoencoder for Self-Supervised Representation Learning</b></summary>
  <p><b>编号</b>：[151]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03026</p>
  <p><b>作者</b>：Xiaokang Chen,  Mingyu Ding,  Xiaodi Wang,  Ying Xin,  Shentong Mo,  Yunhao Wang,  Shumin Han,  Ping Luo,  Gang Zeng,  Jingdong Wang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：masked patches )} using different modules, mim potentially performs better, masked patch representation estimation, masked patch representations computed, estimated masked patch representations</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present a novel masked image modeling (MIM) approach, context autoencoder
(CAE), for self-supervised learning. We randomly partition the image into two
sets: visible patches and masked patches. The CAE architecture consists of: (i)
an encoder that takes visible patches as input and outputs their latent
representations, (ii) a latent context regressor that predicts the masked patch
representations from the visible patch representations that are not updated in
this regressor, (iii) a decoder that takes the estimated masked patch
representations as input and makes predictions for the masked patches, and (iv)
an alignment module that aligns the masked patch representation estimation with
the masked patch representations computed from the encoder.
In comparison to previous MIM methods that couple the encoding and decoding
roles, e.g., using a single module in BEiT, our approach attempts
to~\emph{separate the encoding role (content understanding) from the decoding
role (making predictions for masked patches)} using different modules,
improving the content understanding capability. In addition, our approach makes
predictions from the visible patches to the masked patches in \emph{the latent
representation space} that is expected to take on semantics. In addition, we
present the explanations about why contrastive pretraining and supervised
pretraining perform similarly and why MIM potentially performs better. We
demonstrate the effectiveness of our CAE through superior transfer performance
in downstream tasks: semantic segmentation, and object detection and instance
segmentation.</p>
  </details>
</details>
<details>
  <summary>29. <b>标题：Learning Sound Localization Better From Semantically Similar Samples</b></summary>
  <p><b>编号</b>：[158]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03007</p>
  <p><b>作者</b>：Arda Senocak,  Hyeonggon Ryu,  Junsik Kim,  In So Kweon</p>
  <p><b>备注</b>：Accepted to ICASSP 2022. SOTA performance in Audio-Visual Sound Localization. 5 Pages</p>
  <p><b>关键词</b>：negative pairs may contain semantically matched audio, visual works employ contrastive learning, contrastive learning objective directly, give similar response maps, semantically correlated pairs</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The objective of this work is to localize the sound sources in visual scenes.
Existing audio-visual works employ contrastive learning by assigning
corresponding audio-visual pairs from the same source as positives while
randomly mismatched pairs as negatives. However, these negative pairs may
contain semantically matched audio-visual information. Thus, these semantically
correlated pairs, "hard positives", are mistakenly grouped as negatives. Our
key contribution is showing that hard positives can give similar response maps
to the corresponding pairs. Our approach incorporates these hard positives by
adding their response maps into a contrastive learning objective directly. We
demonstrate the effectiveness of our approach on VGG-SS and SoundNet-Flickr
test sets, showing favorable performance to the state-of-the-art methods.</p>
  </details>
</details>
<details>
  <summary>30. <b>标题：Automatic defect segmentation by unsupervised anomaly learning</b></summary>
  <p><b>编号</b>：[162]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02998</p>
  <p><b>作者</b>：Nati Ofir,  Ran Yacobi,  Omer Granoviter,  Boris Levant,  Ore Shtalrid</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：approach performs accurately also, apply defect implant augmentation, unsupervised learning methods, unlabeled data scenario, segment real defects</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper addresses the problem of defect segmentation in semiconductor
manufacturing. The input of our segmentation is a scanning-electron-microscopy
(SEM) image of the candidate defect region. We train a U-net shape network to
segment defects using a dataset of clean background images. The samples of the
training phase are produced automatically such that no manual labeling is
required. To enrich the dataset of clean background samples, we apply defect
implant augmentation. To that end, we apply a copy-and-paste of a random image
patch in the clean specimen. To improve robustness to the unlabeled data
scenario, we train the features of the network with unsupervised learning
methods and loss functions. Our experiments show that we succeed to segment
real defects with high quality, even though our dataset contains no defect
examples. Our approach performs accurately also on the problem of supervised
and labeled defect segmentation.</p>
  </details>
</details>
<details>
  <summary>31. <b>标题：3D Object Detection from Images for Autonomous Driving: A Survey</b></summary>
  <p><b>编号</b>：[167]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02980</p>
  <p><b>作者</b>：Xinzhu Ma,  Wanli Ouyang,  Andrea Simonelli,  Elisa Ricci</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：also propose two new taxonomies, continuously growing research field, based 3d detection research, based 3d detection, based 3d detection</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>3D object detection from images, one of the fundamental and challenging
problems in autonomous driving, has received increasing attention from both
industry and academia in recent years. Benefiting from the rapid development of
deep learning technologies, image-based 3D detection has achieved remarkable
progress. Particularly, more than 200 works have studied this problem from 2015
to 2021, encompassing a broad spectrum of theories, algorithms, and
applications. However, to date no recent survey exists to collect and organize
this knowledge. In this paper, we fill this gap in the literature and provide
the first comprehensive survey of this novel and continuously growing research
field, summarizing the most commonly used pipelines for image-based 3D
detection and deeply analyzing each of their components. Additionally, we also
propose two new taxonomies to organize the state-of-the-art methods into
different categories, with the intent of providing a more systematic review of
existing methods and facilitating fair comparisons with future works. In
retrospect of what has been achieved so far, we also analyze the current
challenges in the field and discuss future directions for image-based 3D
detection research.</p>
  </details>
</details>
<details>
  <summary>32. <b>标题：Towards Micro-video Thumbnail Selection via a Multi-label  Visual-semantic Embedding Model</b></summary>
  <p><b>编号</b>：[189]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02930</p>
  <p><b>作者</b>：Liu Bo</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：model significantly outperforms several state, attention embedding space associated, two embedding spaces, extensive experiments conducted, shared semantic space</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The thumbnail, as the first sight of a micro-video, plays a pivotal role in
attracting users to click and watch. While in the real scenario, the more the
thumbnails satisfy the users, the more likely the micro-videos will be clicked.
In this paper, we aim to select the thumbnail of a given micro-video that meets
most users` interests. Towards this end, we present a multi-label
visual-semantic embedding model to estimate the similarity between the pair of
each frame and the popular topics that users are interested in. In this model,
the visual and textual information is embedded into a shared semantic space,
whereby the similarity can be measured directly, even the unseen words.
Moreover, to compare the frame to all words from the popular topics, we devise
an attention embedding space associated with the semantic-attention projection.
With the help of these two embedding spaces, the popularity score of a frame,
which is defined by the sum of similarity scores over the corresponding visual
information and popular topic pairs, is achieved. Ultimately, we fuse the
visual representation score and the popularity score of each frame to select
the attractive thumbnail for the given micro-video. Extensive experiments
conducted on a real-world dataset have well-verified that our model
significantly outperforms several state-of-the-art baselines.</p>
  </details>
</details>
<details>
  <summary>33. <b>标题：Benchmarking Deep Models for Salient Object Detection</b></summary>
  <p><b>编号</b>：[194]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02925</p>
  <p><b>作者</b>：Huajun Zhou,  Yang Lin,  Lingxiao Yang,  Jianhuang Lai,  Xiaohua Xie</p>
  <p><b>备注</b>：24 pages</p>
  <p><b>关键词</b>：comprehensive comparison among several representative sod methods, different implementation details may conceal, implement 14 representative sod methods, existing loss functions usually specialized, general salient object detection</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In recent years, deep network-based methods have continuously refreshed
state-of-the-art performance on Salient Object Detection (SOD) task. However,
the performance discrepancy caused by different implementation details may
conceal the real progress in this task. Making an impartial comparison is
required for future researches. To meet this need, we construct a general
SALient Object Detection (SALOD) benchmark to conduct a comprehensive
comparison among several representative SOD methods. Specifically, we
re-implement 14 representative SOD methods by using consistent settings for
training. Moreover, two additional protocols are set up in our benchmark to
investigate the robustness of existing methods in some limited conditions. In
the first protocol, we enlarge the difference between objectness distributions
of train and test sets to evaluate the robustness of these SOD methods. In the
second protocol, we build multiple train subsets with different scales to
validate whether these methods can extract discriminative features from only a
few samples. In the above experiments, we find that existing loss functions
usually specialized in some metrics but reported inferior results on the
others. Therefore, we propose a novel Edge-Aware (EA) loss that promotes deep
networks to learn more discriminative features by integrating both pixel- and
image-level supervision signals. Experiments prove that our EA loss reports
more robust performances compared to existing losses.</p>
  </details>
</details>
<details>
  <summary>34. <b>标题：Dataset Condensation with Contrastive Signals</b></summary>
  <p><b>编号</b>：[197]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02916</p>
  <p><b>作者</b>：Saehyung Lee,  Sanghyuk Chun,  Sangwon Jung,  Sangdoo Yun,  Sungroh Yoon</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：successfully generate informative synthetic datasets, grained image classification tasks, wise gradient matching strategy, irrelevant information forms, experimental results indicate</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent studies have demonstrated that gradient matching-based dataset
synthesis, or dataset condensation (DC), methods can achieve state-of-the-art
performance when applied to data-efficient learning tasks. However, in this
study, we prove that the existing DC methods can perform worse than the random
selection method when task-irrelevant information forms a significant part of
the training dataset. We attribute this to the lack of participation of the
contrastive signals between the classes resulting from the class-wise gradient
matching strategy. To address this problem, we propose Dataset Condensation
with Contrastive signals (DCC) by modifying the loss function to enable the DC
methods to effectively capture the differences between classes. In addition, we
analyze the new loss function in terms of training dynamics by tracking the
kernel velocity. Furthermore, we introduce a bi-level warm-up strategy to
stabilize the optimization. Our experimental results indicate that while the
existing methods are ineffective for fine-grained image classification tasks,
the proposed method can successfully generate informative synthetic datasets
for the same tasks. Moreover, we demonstrate that the proposed method
outperforms the baselines even on benchmark datasets such as SVHN, CIFAR-10,
and CIFAR-100. Finally, we demonstrate the high applicability of the proposed
method by applying it to continual learning tasks.</p>
  </details>
</details>
<details>
  <summary>35. <b>标题：Block shuffling learning for Deepfake Detection</b></summary>
  <p><b>编号</b>：[237]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02819</p>
  <p><b>作者</b>：Sitong Liu,  Zhichao Lian,  Siqi Gu,  Liang Xiao</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：detectors show obvious performance degradation, novel block shuffling learning method, proposed method achieves state, including good generalization ability, extensive experiments show</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Although the deepfake detection based on convolutional neural network has
achieved good results, the detection results show that these detectors show
obvious performance degradation when the input images undergo some common
transformations (like resizing, blurring), which indicates that the
generalization ability of the detector is insufficient. In this paper, we
propose a novel block shuffling learning method to solve this problem.
Specifically, we divide the images into blocks and then introduce the random
shuffling to intra-block and inter-block. Intra-block shuffling increases the
robustness of the detector and we also propose an adversarial loss algorithm to
overcome the over-fitting problem brought by the noise introduced by shuffling.
Moreover, we encourage the detector to focus on finding differences among the
local features through inter-block shuffling, and reconstruct the spatial
layout of the blocks to model the semantic associations between them.
Especially, our method can be easily integrated with various CNN models.
Extensive experiments show that our proposed method achieves state-of-the-art
performance in forgery face detection, including good generalization ability in
the face of common image transformations.</p>
  </details>
</details>
<details>
  <summary>36. <b>标题：Low-confidence Samples Matter for Domain Adaptation</b></summary>
  <p><b>编号</b>：[244]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02802</p>
  <p><b>作者</b>：Yixin Zhang,  Junjie Li,  Zilei Wang</p>
  <p><b>备注</b>：11 pages, 5 figures</p>
  <p><b>关键词</b>：build reliable pseudo labels, intermediate representations across domains, novel contrastive learning method, way would overlook, instance discrimination process</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Domain adaptation (DA) aims to transfer knowledge from a label-rich source
domain to a related but label-scarce target domain. The conventional DA
strategy is to align the feature distributions of the two domains. Recently,
increasing researches have focused on self-training or other semi-supervised
algorithms to explore the data structure of the target domain. However, the
bulk of them depend largely on confident samples in order to build reliable
pseudo labels, prototypes or cluster centers. Representing the target data
structure in such a way would overlook the huge low-confidence samples,
resulting in sub-optimal transferability that is biased towards the samples
similar to the source domain. To overcome this issue, we propose a novel
contrastive learning method by processing low-confidence samples, which
encourages the model to make use of the target data structure through the
instance discrimination process. To be specific, we create positive and
negative pairs only using low-confidence samples, and then re-represent the
original features with the classifier weights rather than directly utilizing
them, which can better encode the task-specific semantic information.
Furthermore, we combine cross-domain mixup to augment the proposed contrastive
loss. Consequently, the domain gap can be well bridged through contrastive
learning of intermediate representations across domains. We evaluate the
proposed method in both unsupervised and semi-supervised DA settings, and
extensive experimental results on benchmarks reveal that our method is
effective and achieves state-of-the-art performance. The code can be found in
this https URL.</p>
  </details>
</details>
<details>
  <summary>37. <b>标题：GLPanoDepth: Global-to-Local Panoramic Depth Estimation</b></summary>
  <p><b>编号</b>：[247]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02796</p>
  <p><b>作者</b>：Jiayang Bai,  Shuichang Lai,  Haoyu Qin,  Jie Guo,  Yanwen Guo</p>
  <p><b>备注</b>：8 pages, 9 figures</p>
  <p><b>关键词</b>：provide globally coherent predictions, predicting dense depth values, local strategy allows us, capture rich global contexts, preserve important local features</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we propose a learning-based method for predicting dense depth
values of a scene from a monocular omnidirectional image. An omnidirectional
image has a full field-of-view, providing much more complete descriptions of
the scene than perspective images. However, fully-convolutional networks that
most current solutions rely on fail to capture rich global contexts from the
panorama. To address this issue and also the distortion of equirectangular
projection in the panorama, we propose Cubemap Vision Transformers (CViT), a
new transformer-based architecture that can model long-range dependencies and
extract distortion-free global features from the panorama. We show that cubemap
vision transformers have a global receptive field at every stage and can
provide globally coherent predictions for spherical signals. To preserve
important local features, we further design a convolution-based branch in our
pipeline (dubbed GLPanoDepth) and fuse global features from cubemap vision
transformers at multiple scales. This global-to-local strategy allows us to
fully exploit useful global and local features in the panorama, achieving
state-of-the-art performance in panoramic depth estimation.</p>
  </details>
</details>
<details>
  <summary>38. <b>标题：Energy awareness in low precision neural networks</b></summary>
  <p><b>编号</b>：[252]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02783</p>
  <p><b>作者</b>：Nurit Spingarn Eliezer,  Ron Banner,  Elad Hoffer,  Hilla Ben-Yaakov,  Tomer Michaeli</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：develop accurate power consumption models, reveal several important factors, reducing power consumption rely, aware neural network ),, deep neural networks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Power consumption is a major obstacle in the deployment of deep neural
networks (DNNs) on end devices. Existing approaches for reducing power
consumption rely on quite general principles, including avoidance of
multiplication operations and aggressive quantization of weights and
activations. However, these methods do not take into account the precise power
consumed by each module in the network, and are therefore not optimal. In this
paper we develop accurate power consumption models for all arithmetic
operations in the DNN, under various working conditions. We reveal several
important factors that have been overlooked to date. Based on our analysis, we
present PANN (power-aware neural network), a simple approach for approximating
any full-precision network by a low-power fixed-precision variant. Our method
can be applied to a pre-trained network, and can also be used during training
to achieve improved performance. In contrast to previous methods, PANN incurs
only a minor degradation in accuracy w.r.t. the full-precision version of the
network, even when working at the power-budget of a 2-bit quantized variant. In
addition, our scheme enables to seamlessly traverse the power-accuracy
trade-off at deployment time, which is a major advantage over existing
quantization methods that are constrained to specific bit widths.</p>
  </details>
</details>
<details>
  <summary>39. <b>标题：Multi-domain Unsupervised Image-to-Image Translation with Appearance  Adaptive Convolution</b></summary>
  <p><b>编号</b>：[254]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02779</p>
  <p><b>作者</b>：Somi Jeong,  Jiyoung Lee,  Kwanghoon Sohn</p>
  <p><b>备注</b>：ICASSP 2022</p>
  <p><b>关键词</b>：domain i2i translation still remains, proposed method produces visually diverse, semantically similar images, decomposed content feature, contrast learning objective</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Over the past few years, image-to-image (I2I) translation methods have been
proposed to translate a given image into diverse outputs. Despite the
impressive results, they mainly focus on the I2I translation between two
domains, so the multi-domain I2I translation still remains a challenge. To
address this problem, we propose a novel multi-domain unsupervised
image-to-image translation (MDUIT) framework that leverages the decomposed
content feature and appearance adaptive convolution to translate an image into
a target appearance while preserving the given geometric content. We also
exploit a contrast learning objective, which improves the disentanglement
ability and effectively utilizes multi-domain image data in the training
process by pairing the semantically similar images. This allows our method to
learn the diverse mappings between multiple visual domains with only a single
framework. We show that the proposed method produces visually diverse and
plausible results in multiple domains compared to the state-of-the-art methods.</p>
  </details>
</details>
<details>
  <summary>40. <b>标题：Learning Features with Parameter-Free Layers</b></summary>
  <p><b>编号</b>：[255]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02777</p>
  <p><b>作者</b>：Dongyoon Han,  YoungJoon Yoo,  Beomyoung Kim,  Byeongho Heo</p>
  <p><b>备注</b>：ICLR 2022</p>
  <p><b>关键词</b>：main building block without sacrificing, efficient trainable layers replacing spatial operations, studies eventually give us, simple yet effective idea, extensive experimental analyses based</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Trainable layers such as convolutional building blocks are the standard
network design choices by learning parameters to capture the global context
through successive spatial operations. When designing an efficient network,
trainable layers such as the depthwise convolution is the source of efficiency
in the number of parameters and FLOPs, but there was little improvement to the
model speed in practice. This paper argues that simple built-in parameter-free
operations can be a favorable alternative to the efficient trainable layers
replacing spatial operations in a network architecture. We aim to break the
stereotype of organizing the spatial operations of building blocks into
trainable layers. Extensive experimental analyses based on layer-level studies
with fully-trained models and neural architecture searches are provided to
investigate whether parameter-free operations such as the max-pool are
functional. The studies eventually give us a simple yet effective idea for
redesigning network architectures, where the parameter-free operations are
heavily used as the main building block without sacrificing the model accuracy
as much. Experimental results on the ImageNet dataset demonstrate that the
network architectures with parameter-free operations could enjoy the advantages
of further efficiency in terms of model speed, the number of the parameters,
and FLOPs. Code and ImageNet pretrained models are available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>41. <b>标题：Enhancing variational generation through self-decomposition</b></summary>
  <p><b>编号</b>：[266]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02738</p>
  <p><b>作者</b>：Andrea Asperti,  Laura Bugo,  Daniele Filippini</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：svae ), whose output $\ hat, {\ em make choices },, two complementary high frequency sub, two generated images $\ hat, follows two main schemes</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this article we introduce the notion of Split Variational Autoencoder
(SVAE), whose output $\hat{x}$ is obtained as a weighted sum $\sigma \odot
\hat{x_1} + (1-\sigma) \odot \hat{x_2}$ of two generated images
$\hat{x_1},\hat{x_2}$, and $\sigma$ is a learned compositional map. The network
is trained as a usual Variational Autoencoder with a negative loglikelihood
loss between training and reconstructed images. The decomposition is
nondeterministic, but follows two main schemes, that we may roughly categorize
as either "syntactic" or "semantic". In the first case, the map tends to
exploit the strong correlation between adjacent pixels, splitting the image in
two complementary high frequency sub-images. In the second case, the map
typically focuses on the contours of objects, splitting the image in
interesting variations of its content, with more marked and distinctive
features. In this case, the Fréchet Inception Distance (FID) of $\hat{x_1}$
and $\hat{x_2}$ is usually lower (hence better) than that of $\hat{x}$, that
clearly suffers from being the average of the formers. In a sense, a SVAE
forces the Variational Autoencoder to {\em make choices}, in contrast with its
intrinsic tendency to average between alternatives with the aim to minimize the
reconstruction loss towards a specific sample. According to the FID metric, our
technique, tested on typical datasets such as Mnist, Cifar10 and Celeba, allows
us to outperform all previous purely variational architectures (not relying on
normalization flows).</p>
  </details>
</details>
<details>
  <summary>42. <b>标题：FEAT: Face Editing with Attention</b></summary>
  <p><b>编号</b>：[272]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02713</p>
  <p><b>作者</b>：Xianxu Hou,  Linlin Shen,  Or Patashnik,  Daniel Cohen-Or,  Hui Huang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：quantitative experimental results demonstrate, incorporating learned attention maps, face manipulation often intends, explicitly encourages face manipulation, controllable face manipulations based</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Employing the latent space of pretrained generators has recently been shown
to be an effective means for GAN-based face manipulation. The success of this
approach heavily relies on the innate disentanglement of the latent space axes
of the generator. However, face manipulation often intends to affect local
regions only, while common generators do not tend to have the necessary spatial
disentanglement. In this paper, we build on the StyleGAN generator, and present
a method that explicitly encourages face manipulation to focus on the intended
regions by incorporating learned attention maps. During the generation of the
edited image, the attention map serves as a mask that guides a blending between
the original features and the modified ones. The guidance for the latent space
edits is achieved by employing CLIP, which has recently been shown to be
effective for text-driven edits. We perform extensive experiments and show that
our method can perform disentangled and controllable face manipulations based
on text descriptions by attending to the relevant regions only. Both
qualitative and quantitative experimental results demonstrate the superiority
of our method for facial region editing over alternative methods.</p>
  </details>
</details>
<details>
  <summary>43. <b>标题：Portrait Segmentation Using Deep Learning</b></summary>
  <p><b>编号</b>：[276]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02705</p>
  <p><b>作者</b>：Sumedh Vilas Datar and,  Jesus Gonzales Bernal</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：generate high quality portrait images, especially one depicting, portrait mode, novel approach, dslrs generally</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A portrait is a painting, drawing, photograph, or engraving of a person,
especially one depicting only the face or head and shoulders. In the digital
world the portrait of a person is captured by having the person as a subject in
the image and capturing the image of the person such that the background is
blurred. DSLRs generally do it by reducing the aperture to focus on very close
regions of interest and automatically blur the background. In this paper I have
come up with a novel approach to replicate the portrait mode from DSLR using
any smartphone to generate high quality portrait images.</p>
  </details>
</details>
<details>
  <summary>44. <b>标题：Multi-modal Sensor Fusion for Auto Driving Perception: A Survey</b></summary>
  <p><b>编号</b>：[278]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02703</p>
  <p><b>作者</b>：Keli Huang,  Botian Shi,  Xiang Li,  Xin Li,  Siyuan Huang,  Yikang Li</p>
  <p><b>备注</b>：14 pages, 8 figures</p>
  <p><b>关键词</b>：50 papers leveraging perception sensors including lidar, recently intrigued many researchers, autonomous driving perception tasks, detailed analysis including, two major classes</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Multi-modal fusion is a fundamental task for the perception of an autonomous
driving system, which has recently intrigued many researchers. However,
achieving a rather good performance is not an easy task due to the noisy raw
data, underutilized information, and the misalignment of multi-modal sensors.
In this paper, we provide a literature review of the existing multi-modal-based
methods for perception tasks in autonomous driving. Generally, we make a
detailed analysis including over 50 papers leveraging perception sensors
including LiDAR and camera trying to solve object detection and semantic
segmentation tasks. Different from traditional fusion methodology for
categorizing fusion models, we propose an innovative way that divides them into
two major classes, four minor classes by a more reasonable taxonomy in the view
of the fusion stage. Moreover, we dive deep into the current fusion methods,
focusing on the remaining problems and open-up discussions on the potential
research opportunities. In conclusion, what we expect to do in this paper is to
present a new taxonomy of multi-modal fusion methods for the autonomous driving
perception tasks and provoke thoughts of the fusion-based techniques in the
future.</p>
  </details>
</details>
<details>
  <summary>45. <b>标题：SRPCN: Structure Retrieval based Point Completion Network</b></summary>
  <p><b>编号</b>：[294]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02669</p>
  <p><b>作者</b>：Kaiyi Zhang,  Ximing Yang,  Yuan Wu,  Cheng Jin</p>
  <p><b>备注</b>：10 pages, 6 figures</p>
  <p><b>关键词</b>：propose structure retrieval based point completion network, existing methods pay little attention, retrieved structure point clouds, point cloud completion aims, proposed structure retrieval method</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Given partial objects and some complete ones as references, point cloud
completion aims to recover authentic shapes. However, existing methods pay
little attention to general shapes, which leads to the poor authenticity of
completion results. Besides, the missing patterns are diverse in reality, but
existing methods can only handle fixed ones, which means a poor generalization
ability. Considering that a partial point cloud is a subset of the
corresponding complete one, we regard them as different samples of the same
distribution and propose Structure Retrieval based Point Completion Network
(SRPCN). It first uses k-means clustering to extract structure points and
disperses them into distributions, and then KL Divergence is used as a metric
to find the complete structure point cloud that best matches the input in a
database. Finally, a PCN-like decoder network is adopted to generate the final
results based on the retrieved structure point clouds. As structure plays an
important role in describing the general shape of an object and the proposed
structure retrieval method is robust to missing patterns, experiments show that
our method can generate more authentic results and has a stronger
generalization ability.</p>
  </details>
</details>
<details>
  <summary>46. <b>标题：Simulation-to-Reality domain adaptation for offline 3D object annotation  on pointclouds with correlation alignment</b></summary>
  <p><b>编号</b>：[296]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02666</p>
  <p><b>作者</b>：Weishuang Zhang,  B Ravi Kiran,  Thomas Gauthier,  Yanis Mazouz,  Theo Steger</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：deployment vehicles using simulated data, unlabeled real pointcloud feature representations, costly human driven process, autonomous driving perception system, supervised object detection loss</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Annotating objects with 3D bounding boxes in LiDAR pointclouds is a costly
human driven process in an autonomous driving perception system. In this paper,
we present a method to semi-automatically annotate real-world pointclouds
collected by deployment vehicles using simulated data. We train a 3D object
detector model on labeled simulated data from CARLA jointly with real world
pointclouds from our target vehicle. The supervised object detection loss is
augmented with a CORAL loss term to reduce the distance between labeled
simulated and unlabeled real pointcloud feature representations. The goal here
is to learn representations that are invariant to simulated (labeled) and
real-world (unlabeled) target domains. We also provide an updated survey on
domain adaptation methods for pointclouds.</p>
  </details>
</details>
<details>
  <summary>47. <b>标题：LiDAR dataset distillation within bayesian active learning framework:  Understanding the effect of data augmentation</b></summary>
  <p><b>编号</b>：[298]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02661</p>
  <p><b>作者</b>：Ngoc Phuong Anh Duong,  Alexandre Almin,  Léo Lemarié,  B Ravi Kiran</p>
  <p><b>备注</b>：Accepted at VISAPP 2022</p>
  <p><b>关键词</b>：data augmentation achieves full dataset accuracy using, enable better deep representation learning, provides faster training time, demonstrated across different subsets, al based dataset distillation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Autonomous driving (AD) datasets have progressively grown in size in the past
few years to enable better deep representation learning. Active learning (AL)
has re-gained attention recently to address reduction of annotation costs and
dataset size. AL has remained relatively unexplored for AD datasets, especially
on point cloud data from LiDARs. This paper performs a principled evaluation of
AL based dataset distillation on (1/4th) of the large Semantic-KITTI dataset.
Further on, the gains in model performance due to data augmentation (DA) are
demonstrated across different subsets of the AL loop. We also demonstrate how
DA improves the selection of informative samples to annotate. We observe that
data augmentation achieves full dataset accuracy using only 60\% of samples
from the selected dataset configuration. This provides faster training time and
subsequent gains in annotation costs.</p>
  </details>
</details>
<details>
  <summary>48. <b>标题：A survey of top-down approaches for human pose estimation</b></summary>
  <p><b>编号</b>：[302]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02656</p>
  <p><b>作者</b>：Thong Duy Nguyen,  Milan Kresovic</p>
  <p><b>备注</b>：16 pages</p>
  <p><b>关键词</b>：computer vision problem recently due, brought tremendous remarkable results, paper presents significant detectors, step framework first incorporates, improving human life</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Human pose estimation in two-dimensional images videos has been a hot topic
in the computer vision problem recently due to its vast benefits and potential
applications for improving human life, such as behaviors recognition, motion
capture and augmented reality, training robots, and movement tracking. Many
state-of-the-art methods implemented with Deep Learning have addressed several
challenges and brought tremendous remarkable results in the field of human pose
estimation. Approaches are classified into two kinds: the two-step framework
(top-down approach) and the part-based framework (bottom-up approach). While
the two-step framework first incorporates a person detector and then estimates
the pose within each box independently, detecting all body parts in the image
and associating parts belonging to distinct persons is conducted in the
part-based framework. This paper aims to provide newcomers with an extensive
review of deep learning methods-based 2D images for recognizing the pose of
people, which only focuses on top-down approaches since 2016. The discussion
through this paper presents significant detectors and estimators depending on
mathematical background, the challenges and limitations, benchmark datasets,
evaluation metrics, and comparison between methods.</p>
  </details>
</details>
<details>
  <summary>49. <b>标题：The Unreasonable Effectiveness of Random Pruning: Return of the Most  Naive Baseline for Sparse Training</b></summary>
  <p><b>编号</b>：[308]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02643</p>
  <p><b>作者</b>：Shiwei Liu,  Tianlong Chen,  Xiaohan Chen,  Li Shen,  Decebal Constantin Mocanu,  Zhangyang Wang,  Mykola Pechenizkiy</p>
  <p><b>备注</b>：Published as a conference paper at ICLR 2022. Code is available at this https URL</p>
  <p><b>关键词</b>：randomly pruned networks outperform dense counterparts, universal beyond carefully designed pruning, original dense networks grow wider, carefully pursued sparsity structures, another important performance booster</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Random pruning is arguably the most naive way to attain sparsity in neural
networks, but has been deemed uncompetitive by either post-training pruning or
sparse training. In this paper, we focus on sparse training and highlight a
perhaps counter-intuitive finding, that random pruning at initialization can be
quite powerful for the sparse training of modern neural networks. Without any
delicate pruning criteria or carefully pursued sparsity structures, we
empirically demonstrate that sparsely training a randomly pruned network from
scratch can match the performance of its dense equivalent. There are two key
factors that contribute to this revival: (i) the network sizes matter: as the
original dense networks grow wider and deeper, the performance of training a
randomly pruned sparse network will quickly grow to matching that of its dense
equivalent, even at high sparsity ratios; (ii) appropriate layer-wise sparsity
ratios can be pre-chosen for sparse training, which shows to be another
important performance booster. Simple as it looks, a randomly pruned subnetwork
of Wide ResNet-50 can be sparsely trained to outperforming a dense Wide
ResNet-50, on ImageNet. We also observed such randomly pruned networks
outperform dense counterparts in other favorable aspects, such as
out-of-distribution detection, uncertainty estimation, and adversarial
robustness. Overall, our results strongly suggest there is larger-than-expected
room for sparse training at scale, and the benefits of sparsity might be more
universal beyond carefully designed pruning. Our source code can be found at
this https URL.</p>
  </details>
</details>
<details>
  <summary>50. <b>标题：Layer-wise Regularized Adversarial Training using Layers Sustainability  Analysis (LSA) framework</b></summary>
  <p><b>编号</b>：[316]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02626</p>
  <p><b>作者</b>：Mohammad Khalooei,  Mohammad Mehdi Homayounpour,  Maryam Amirmazlaghani</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：proposed idea performs well theoretically, improve conventional adversarial training approaches, adversarial training approaches towards improving, model layers via layer monitoring, obtaining robust neural networks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep neural network models are used today in various applications of
artificial intelligence, the strengthening of which, in the face of adversarial
attacks is of particular importance. An appropriate solution to adversarial
attacks is adversarial training, which reaches a trade-off between robustness
and generalization. This paper introduces a novel framework (Layer
Sustainability Analysis (LSA)) for the analysis of layer vulnerability in a
given neural network in the scenario of adversarial attacks. LSA can be a
helpful toolkit to assess deep neural networks and to extend the adversarial
training approaches towards improving the sustainability of model layers via
layer monitoring and analysis. The LSA framework identifies a list of Most
Vulnerable Layers (MVL list) of a given network. The relative error, as a
comparison measure, is used to evaluate representation sustainability of each
layer against adversarial attack inputs. The proposed approach for obtaining
robust neural networks to fend off adversarial attacks is based on a layer-wise
regularization (LR) over LSA proposal(s) for adversarial training (AT); i.e.
the AT-LR procedure. AT-LR could be used with any benchmark adversarial attack
to reduce the vulnerability of network layers and to improve conventional
adversarial training approaches. The proposed idea performs well theoretically
and experimentally for state-of-the-art multilayer perceptron and convolutional
neural network architectures. Compared with the AT-LR and its corresponding
base adversarial training, the classification accuracy of more significant
perturbations increased by 16.35%, 21.79%, and 10.730% on Moon, MNIST, and
CIFAR-10 benchmark datasets in comparison with the AT-LR and its corresponding
base adversarial training, respectively. The LSA framework is available and
published at this https URL.</p>
  </details>
</details>
<details>
  <summary>51. <b>标题：Memory Defense: More Robust Classification via a Memory-Masking  Autoencoder</b></summary>
  <p><b>编号</b>：[327]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02595</p>
  <p><b>作者</b>：Eashan Adhikarla (1),  Dan Luo (1),  Brian D. Davison (1) ((1) Lehigh University)</p>
  <p><b>备注</b>：11 pages</p>
  <p><b>关键词</b>：typical autoencoders easily mingle inter, many deep neural networks, four widely used attacks, could ignore small changes, specific independent latent representations</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Many deep neural networks are susceptible to minute perturbations of images
that have been carefully crafted to cause misclassification. Ideally, a robust
classifier would be immune to small variations in input images, and a number of
defensive approaches have been created as a result. One method would be to
discern a latent representation which could ignore small changes to the input.
However, typical autoencoders easily mingle inter-class latent representations
when there are strong similarities between classes, making it harder for a
decoder to accurately project the image back to the original high-dimensional
space. We propose a novel framework, Memory Defense, an augmented classifier
with a memory-masking autoencoder to counter this challenge. By masking other
classes, the autoencoder learns class-specific independent latent
representations. We test the model's robustness against four widely used
attacks. Experiments on the Fashion-MNIST & CIFAR-10 datasets demonstrate the
superiority of our model. We make available our source code at GitHub
repository: this https URL</p>
  </details>
</details>
<details>
  <summary>52. <b>标题：VIS-iTrack: Visual Intention through Gaze Tracking using Low-Cost Webcam</b></summary>
  <p><b>编号</b>：[329]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02587</p>
  <p><b>作者</b>：Shahed Anzarus Sabab (1, 2, 3, 4, and 5),  Mohammad Ridwan Kabir (1, 2, and 3),  Sayed Rizban Hussain (1, 2, and 3),  Hasan Mahmud (1, 2, and 3),  Md. Kamrul Hasan (1, 2, and 3),  Husne Ara Rubaiyeat (6) ((1) Systems and Software Lab (SSL), (2) Department of Computer Science and Engineering, (3) Islamic University of Technology (IUT), Gazipur, Bangladesh, (4) Department of Computer Science, (5) University of Manitoba, Winnipeg, Canada, (6) National University, Bangladesh.)</p>
  <p><b>备注</b>：15 pages, 9 figures, 4 tables</p>
  <p><b>关键词</b>：leaned towards graphical contents whereas older adults felt, interactive interfaces containing either textual, visual intention among 30 participants, including support vector machine, g ., fixation count</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Human intention is an internal, mental characterization for acquiring desired
information. From interactive interfaces containing either textual or graphical
information, intention to perceive desired information is subjective and
strongly connected with eye gaze. In this work, we determine such intention by
analyzing real-time eye gaze data with a low-cost regular webcam. We extracted
unique features (e.g., Fixation Count, Eye Movement Ratio) from the eye gaze
data of 31 participants to generate a dataset containing 124 samples of visual
intention for perceiving textual or graphical information, labeled as either
TEXT or IMAGE, having 48.39% and 51.61% distribution, respectively. Using this
dataset, we analyzed 5 classifiers, including Support Vector Machine (SVM)
(Accuracy: 92.19%). Using the trained SVM, we investigated the variation of
visual intention among 30 participants, distributed in 3 age groups, and found
out that young users were more leaned towards graphical contents whereas older
adults felt more interested in textual ones. This finding suggests that
real-time eye gaze data can be a potential source of identifying visual
intention, analyzing which intention aware interactive interfaces can be
designed and developed to facilitate human cognition.</p>
  </details>
</details>
<details>
  <summary>53. <b>标题：Catch Me if You Can: A Novel Task for Detection of Covert Geo-Locations  (CGL)</b></summary>
  <p><b>编号</b>：[340]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02567</p>
  <p><b>作者</b>：Binoy Saha,  Sukhendu Das</p>
  <p><b>备注</b>：This is an updated version of our accepted paper in: fourth workshop on Computer Vision Applications (WCVA), 12th Indian Conference on Computer Vision, Graphics and Image Processing (ICVGIP 20-21), IIT Jodhpur, India, December 2021. [work sponsored under IMPRINT grant]</p>
  <p><b>关键词</b>：method successfully extracts relevant depth features, annotated cgl detection dataset containing 1, involves delineating specific image regions around, scene also contain crucial information, quantitatively yields significant improvement</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Most visual scene understanding tasks in the field of computer vision involve
identification of the objects present in the scene. Image regions like
hideouts, turns, & other obscured regions of the scene also contain crucial
information, for specific surveillance tasks. Task proposed in this paper
involves the design of an intelligent visual aid for identification of such
locations in an image, which has either the potential to create an imminent
threat from an adversary or appear as the target zones needing further
investigation. Covert places (CGL) for hiding behind an occluding object are
concealed 3D locations, not detectable from the viewpoint (camera). Hence this
involves delineating specific image regions around the projections of outer
boundary of the occluding objects, as places to be accessed around the
potential hideouts. CGL detection finds applications in military
counter-insurgency operations, surveillance with path planning for an
exploratory robot. Given an RGB image, the goal is to identify all CGLs in the
2D scene. Identification of such regions would require knowledge about the 3D
boundaries of obscuring items (pillars, furniture), their spatial location with
respect to the neighboring regions of the scene. We propose this as a novel
task, termed Covert Geo-Location (CGL) Detection. Classification of any region
of an image as a CGL (as boundary sub-segments of an occluding object that
conceals the hideout) requires examining the 3D relation between boundaries of
occluding objects and their neighborhoods & surroundings. Our method
successfully extracts relevant depth features from a single RGB image and
quantitatively yields significant improvement over existing object detection
and segmentation models adapted and trained for CGL detection. We also
introduce a novel hand-annotated CGL detection dataset containing 1.5K
real-world images for experimentation.</p>
  </details>
</details>
<details>
  <summary>54. <b>标题：DEVO: Depth-Event Camera Visual Odometry in Challenging Conditions</b></summary>
  <p><b>编号</b>：[345]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02556</p>
  <p><b>作者</b>：Yi-Fan Zuo,  Jiaqi Yang,  Jiaben Chen,  Xia Wang,  Yifu Wang,  Laurent Kneip</p>
  <p><b>备注</b>：accepted in the 2022 IEEE International Conference on Robotics and Automation (ICRA), Philadelphia (PA), USA</p>
  <p><b>关键词</b>：computational efficiency towards strong performance, dense visual odometry towards time, time visual odometry framework, proposed method performs comparable, extrinsically calibrated depth camera</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present a novel real-time visual odometry framework for a stereo setup of
a depth and high-resolution event camera. Our framework balances accuracy and
robustness against computational efficiency towards strong performance in
challenging scenarios. We extend conventional edge-based semi-dense visual
odometry towards time-surface maps obtained from event streams. Semi-dense
depth maps are generated by warping the corresponding depth values of the
extrinsically calibrated depth camera. The tracking module updates the camera
pose through efficient, geometric semi-dense 3D-2D edge alignment. Our approach
is validated on both public and self-collected datasets captured under various
conditions. We show that the proposed method performs comparable to
state-of-the-art RGB-D camera-based alternatives in regular conditions, and
eventually outperforms in challenging conditions such as high dynamics or low
illumination.</p>
  </details>
</details>
<details>
  <summary>55. <b>标题：Unsupervised Learning on 3D Point Clouds by Clustering and Contrasting</b></summary>
  <p><b>编号</b>：[349]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02543</p>
  <p><b>作者</b>：Guofeng Mei,  Litao Yu,  Qiang Wu,  Jian Zhang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：extract features without human intervention, extract discriminating local features based, alleviate human labeling remains, criterion extends standard cross, like soft clustering algorithm</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Learning from unlabeled or partially labeled data to alleviate human labeling
remains a challenging research topic in 3D modeling. Along this line,
unsupervised representation learning is a promising direction to auto-extract
features without human intervention. This paper proposes a general unsupervised
approach, named \textbf{ConClu}, to perform the learning of point-wise and
global features by jointly leveraging point-level clustering and instance-level
contrasting. Specifically, for one thing, we design an Expectation-Maximization
(EM) like soft clustering algorithm that provides local supervision to extract
discriminating local features based on optimal transport. We show that this
criterion extends standard cross-entropy minimization to an optimal transport
problem, which we solve efficiently using a fast variant of the Sinkhorn-Knopp
algorithm. For another, we provide an instance-level contrasting method to
learn the global geometry, which is formulated by maximizing the similarity
between two augmentations of one point cloud. Experimental evaluations on
downstream applications such as 3D object classification and semantic
segmentation demonstrate the effectiveness of our framework and show that it
can outperform state-of-the-art techniques.</p>
  </details>
</details>
<details>
  <summary>56. <b>标题：PrivPAS: A real time Privacy-Preserving AI System and applied ethics</b></summary>
  <p><b>编号</b>：[359]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02524</p>
  <p><b>作者</b>：Harichandana B S S,  Vibhav Agarwal,  Sourav Ghosh,  Gopi Ramena,  Sumit Kumar andd Barath Raj Kandur Raja</p>
  <p><b>备注</b>：Accepted at 16th IEEE International Conference on Semantic Computing (ICSC), January 26-28, 2022</p>
  <p><b>关键词</b>：human population ), almost 3 billion images, 78 billion social media users worldwide, far received comparatively less attention, unauthorized image captures may also, raise dissent even</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>With 3.78 billion social media users worldwide in 2021 (48% of the human
population), almost 3 billion images are shared daily. At the same time, a
consistent evolution of smartphone cameras has led to a photography explosion
with 85% of all new pictures being captured using smartphones. However, lately,
there has been an increased discussion of privacy concerns when a person being
photographed is unaware of the picture being taken or has reservations about
the same being shared. These privacy violations are amplified for people with
disabilities, who may find it challenging to raise dissent even if they are
aware. Such unauthorized image captures may also be misused to gain sympathy by
third-party organizations, leading to a privacy breach. Privacy for people with
disabilities has so far received comparatively less attention from the AI
community. This motivates us to work towards a solution to generate
privacy-conscious cues for raising awareness in smartphone users of any
sensitivity in their viewfinder content. To this end, we introduce PrivPAS (A
real time Privacy-Preserving AI System) a novel framework to identify sensitive
content. Additionally, we curate and annotate a dataset to identify and
localize accessibility markers and classify whether an image is sensitive to a
featured subject with a disability. We demonstrate that the proposed
lightweight architecture, with a memory footprint of a mere 8.49MB, achieves a
high mAP of 89.52% on resource-constrained devices. Furthermore, our pipeline,
trained on face anonymized data, achieves an F1-score of 73.1%.</p>
  </details>
</details>
<details>
  <summary>57. <b>标题：Comparative study of 3D object detection frameworks based on LiDAR data  and sensor fusion techniques</b></summary>
  <p><b>编号</b>：[361]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02521</p>
  <p><b>作者</b>：Sreenivasa Hikkal Venugopala</p>
  <p><b>备注</b>：2021 2nd International Conference on Control Theory and Applications(ICoCTA 2021)</p>
  <p><b>关键词</b>：3d object detection frameworks performing object detection, sensor fusion techniques show significant improvement, perception system involves various subsystems, using sensor fusion techniques, 3d object detection methods</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Estimating and understanding the surroundings of the vehicle precisely forms
the basic and crucial step for the autonomous vehicle. The perception system
plays a significant role in providing an accurate interpretation of a vehicle's
environment in real-time. Generally, the perception system involves various
subsystems such as localization, obstacle (static and dynamic) detection, and
avoidance, mapping systems, and others. For perceiving the environment, these
vehicles will be equipped with various exteroceptive (both passive and active)
sensors in particular cameras, Radars, LiDARs, and others. These systems are
equipped with deep learning techniques that transform the huge amount of data
from the sensors into semantic information on which the object detection and
localization tasks are performed. For numerous driving tasks, to provide
accurate results, the location and depth information of a particular object is
necessary. 3D object detection methods, by utilizing the additional pose data
from the sensors such as LiDARs, stereo cameras, provides information on the
size and location of the object. Based on recent research, 3D object detection
frameworks performing object detection and localization on LiDAR data and
sensor fusion techniques show significant improvement in their performance. In
this work, a comparative study of the effect of using LiDAR data for object
detection frameworks and the performance improvement seen by using sensor
fusion techniques are performed. Along with discussing various state-of-the-art
methods in both the cases, performing experimental analysis, and providing
future research directions.</p>
  </details>
</details>
<details>
  <summary>58. <b>标题：Less is More: Reversible Steganography with Uncertainty-Aware Predictive  Analytics</b></summary>
  <p><b>编号</b>：[363]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02518</p>
  <p><b>作者</b>：Ching-Chun Chang,  Xu Wang,  Sisheng Chen,  Isao Echizen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：level binary classification problem, predict pixel intensity given, advanced reversible steganographic algorithm, level vision problem, wise contextual information</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Artificial neural networks have advanced the frontiers of reversible
steganography. The core strength of neural networks is the ability to render
accurate predictions for a bewildering variety of data. Residual modulation is
recognised as the most advanced reversible steganographic algorithm for digital
images and the pivot of which is the predictive module. The function of this
module is to predict pixel intensity given some pixel-wise contextual
information. This task can be perceived as a low-level vision problem and hence
neural networks for addressing a similar class of problems can be deployed. On
top of the prior art, this paper analyses the predictive uncertainty and endows
the predictive module with the option to abstain when encountering a high level
of uncertainty. Uncertainty analysis can be formulated as a pixel-level binary
classification problem and tackled by both supervised and unsupervised
learning. In contrast to handcrafted statistical analytics, learning-based
analytics can learn to follow some general statistical principles and
simultaneously adapt to a specific predictor. Experimental results show that
steganographic performance can be remarkably improved by adaptively filtering
out the unpredictable regions with the learning-based uncertainty analysers.</p>
  </details>
</details>
<details>
  <summary>59. <b>标题：Adversarial Detector with Robust Classifier</b></summary>
  <p><b>编号</b>：[369]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02503</p>
  <p><b>作者</b>：Takayuki Osakabe,  Maungmaung Aprilpyone,  Sayaka Shiota,  Hitoshi Kiya</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：easily misclassify prediction results, highly detect adversarial examples, called adversarial examples, using input images, novel adversarial detector</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep neural network (DNN) models are wellknown to easily misclassify
prediction results by using input images with small perturbations, called
adversarial examples. In this paper, we propose a novel adversarial detector,
which consists of a robust classifier and a plain one, to highly detect
adversarial examples. The proposed adversarial detector is carried out in
accordance with the logits of plain and robust classifiers. In an experiment,
the proposed detector is demonstrated to outperform a state-of-the-art detector
without any robust classifier.</p>
  </details>
</details>
<details>
  <summary>60. <b>标题：Investigating the Challenges of Class Imbalance and Scale Variation in  Object Detection in Aerial Images</b></summary>
  <p><b>编号</b>：[376]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02489</p>
  <p><b>作者</b>：Ahmed Elhagry,  Mohamed Saeed</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：densely packed small objects, better handle small objects, extract better features, proposed design achieves, generated anchor sizes</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>While object detection is a common problem in computer vision, it is even
more challenging when dealing with aerial satellite images. The variety in
object scales and orientations can make them difficult to identify. In
addition, there can be large amounts of densely packed small objects such as
cars. In this project, we propose a few changes to the Faster-RCNN
architecture. First, we experiment with different backbones to extract better
features. We also modify the data augmentations and generated anchor sizes for
region proposals in order to better handle small objects. Finally, we
investigate the effects of different loss functions. Our proposed design
achieves an improvement of 4.7 mAP over the baseline which used a vanilla
Faster R-CNN with a ResNet-101 FPN backbone.</p>
  </details>
</details>
<details>
  <summary>61. <b>标题：Few-shot Learning as Cluster-induced Voronoi Diagrams: A Geometric  Approach</b></summary>
  <p><b>编号</b>：[382]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02471</p>
  <p><b>作者</b>：Chunwei Ma,  Ziyun Huang,  Mingchen Gao,  Jinhui Xu</p>
  <p><b>备注</b>：Accepted for publication in ICLR 2022; this https URL</p>
  <p><b>关键词</b>：2 \%{-} 5 \%$ improvements upon, widely embraced protonet model, simplest nearest neighbor model, based workflow enables us, together make fsl stronger</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Few-shot learning (FSL) is the process of rapid generalization from abundant
base samples to inadequate novel samples. Despite extensive research in recent
years, FSL is still not yet able to generate satisfactory solutions for a wide
range of real-world applications. To confront this challenge, we study the FSL
problem from a geometric point of view in this paper. One observation is that
the widely embraced ProtoNet model is essentially a Voronoi Diagram (VD) in the
feature space. We retrofit it by making use of a recent advance in
computational geometry called Cluster-induced Voronoi Diagram (CIVD). Starting
from the simplest nearest neighbor model, CIVD gradually incorporates
cluster-to-point and then cluster-to-cluster relationships for space
subdivision, which is used to improve the accuracy and robustness at multiple
stages of FSL. Specifically, we use CIVD (1) to integrate parametric and
nonparametric few-shot classifiers; (2) to combine feature representation and
surrogate representation; (3) and to leverage feature-level,
transformation-level, and geometry-level heterogeneities for a better ensemble.
Our CIVD-based workflow enables us to achieve new state-of-the-art results on
mini-ImageNet, CUB, and tiered-ImagenNet datasets, with ${\sim}2\%{-}5\%$
improvements upon the next best. To summarize, CIVD provides a mathematically
elegant and geometrically interpretable framework that compensates for extreme
data insufficiency, prevents overfitting, and allows for fast geometric
ensemble for thousands of individual VD. These together make FSL stronger.</p>
  </details>
</details>
<details>
  <summary>62. <b>标题：Spelunking the Deep: Guaranteed Queries for General Neural Implicit  Surfaces</b></summary>
  <p><b>编号</b>：[399]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02444</p>
  <p><b>作者</b>：Nicholas Sharp,  Alec Jacobson</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：develop geometric queries including ray casting, offer concrete accuracy guarantees even, best evaluate geometric queries, using automatic arithmetic rules, general neural implicit functions</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Neural implicit representations, which encode a surface as the level set of a
neural network applied to spatial coordinates, have proven to be remarkably
effective for optimizing, compressing, and generating 3D geometry. Although
these representations are easy to fit, it is not clear how to best evaluate
geometric queries on the shape, such as intersecting against a ray or finding a
closest point. The predominant approach is to encourage the network to have a
signed distance property. However, this property typically holds only
approximately, leading to robustness issues, and holds only at the conclusion
of training, inhibiting the use of queries in loss functions. Instead, this
work presents a new approach to perform queries directly on general neural
implicit functions for a wide range of existing architectures. Our key tool is
the application of range analysis to neural networks, using automatic
arithmetic rules to bound the output of a network over a region; we conduct a
study of range analysis on neural networks, and identify variants of affine
arithmetic which are highly effective. We use the resulting bounds to develop
geometric queries including ray casting, intersection testing, constructing
spatial hierarchies, fast mesh extraction, closest-point evaluation, evaluating
bulk properties, and more. Our queries can be efficiently evaluated on GPUs,
and offer concrete accuracy guarantees even on randomly-initialized networks,
enabling their use in training objectives and beyond. We also show a
preliminary application to inverse rendering.</p>
  </details>
</details>
<details>
  <summary>63. <b>标题：Zero Experience Required: Plug & Play Modular Transfer Learning for  Semantic Visual Navigation</b></summary>
  <p><b>编号</b>：[402]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02440</p>
  <p><b>作者</b>：Ziad Al-Halah,  Santhosh K. Ramakrishnan,  Kristen Grauman</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：novel modular transfer learning model, target tasks without receiving, multiple target tasks, challenging tasks show, outperforms sota models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In reinforcement learning for visual navigation, it is common to develop a
model for each new task, and train that model from scratch with task-specific
interactions in 3D environments. However, this process is expensive; massive
amounts of interactions are needed for the model to generalize well. Moreover,
this process is repeated whenever there is a change in the task type or the
goal modality. We present a unified approach to visual navigation using a novel
modular transfer learning model. Our model can effectively leverage its
experience from one source task and apply it to multiple target tasks (e.g.,
ObjectNav, RoomNav, ViewNav) with various goal modalities (e.g., image, sketch,
audio, label). Furthermore, our model enables zero-shot experience learning,
whereby it can solve the target tasks without receiving any task-specific
interactive training. Our experiments on multiple photorealistic datasets and
challenging tasks show that our approach learns faster, generalizes better, and
outperforms SoTA models by a significant margin.</p>
  </details>
</details>
<details>
  <summary>64. <b>标题：The influence of labeling techniques in classifying human manipulation  movement of different speed</b></summary>
  <p><b>编号</b>：[411]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02426</p>
  <p><b>作者</b>：Sadique Adnan Siddiqui,  Lisa Gutzeit,  Frank Kirchner</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：stacking scenario comprising simple arm movements, labeled using two different approaches, labeled using two different approaches, paced data labeled using trajectories, extreme gradient boosting classifier</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this work, we investigate the influence of labeling methods on the
classification of human movements on data recorded using a marker-based motion
capture system. The dataset is labeled using two different approaches, one
based on video data of the movements, the other based on the movement
trajectories recorded using the motion capture system. The dataset is labeled
using two different approaches, one based on video data of the movements, the
other based on the movement trajectories recorded using the motion capture
system. The data was recorded from one participant performing a stacking
scenario comprising simple arm movements at three different speeds (slow,
normal, fast). Machine learning algorithms that include k-Nearest Neighbor,
Random Forest, Extreme Gradient Boosting classifier, Convolutional Neural
networks (CNN), Long Short-Term Memory networks (LSTM), and a combination of
CNN-LSTM networks are compared on their performance in recognition of these arm
movements. The models were trained on actions performed on slow and normal
speed movements segments and generalized on actions consisting of fast-paced
human movement. It was observed that all the models trained on normal-paced
data labeled using trajectories have almost 20% improvement in accuracy on test
data in comparison to the models trained on data labeled using videos of the
performed experiments.</p>
  </details>
</details>
<details>
  <summary>65. <b>标题：StandardSim: A Synthetic Dataset For Retail Environments</b></summary>
  <p><b>编号</b>：[414]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02418</p>
  <p><b>作者</b>：Cristina Mata,  Nick Locascio,  Mohammed Azeem Sheikh,  Kenny Kihara,  Dan Fischetti</p>
  <p><b>备注</b>：ICIAP 2022</p>
  <p><b>关键词</b>：scale photorealistic synthetic dataset featuring annotations, dataset provides multiple views per scene, retail environments present unique challenges compared, autonomous checkout called change detection, typical indoor scenes owing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Autonomous checkout systems rely on visual and sensory inputs to carry out
fine-grained scene understanding in retail environments. Retail environments
present unique challenges compared to typical indoor scenes owing to the vast
number of densely packed, unique yet similar objects. The problem becomes even
more difficult when only RGB input is available, especially for data-hungry
tasks such as instance segmentation. To address the lack of datasets for
retail, we present StandardSim, a large-scale photorealistic synthetic dataset
featuring annotations for semantic segmentation, instance segmentation, depth
estimation, and object detection. Our dataset provides multiple views per
scene, enabling multi-view representation learning. Further, we introduce a
novel task central to autonomous checkout called change detection, requiring
pixel-level classification of takes, puts and shifts in objects over time. We
benchmark widely-used models for segmentation and depth estimation on our
dataset, show that our test set constitutes a difficult benchmark compared to
current smaller-scale datasets and that our training set provides models with
crucial information for autonomous checkout tasks.</p>
  </details>
</details>
<details>
  <summary>66. <b>标题：LEDNet: Joint Low-light Enhancement and Deblurring in the Dark</b></summary>
  <p><b>编号</b>：[451]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03373</p>
  <p><b>作者</b>：Shangchen Zhou,  Chongyi Li,  Chen Change Loy</p>
  <p><b>备注</b>：19 pages, 23 figures</p>
  <p><b>关键词</b>：night photography typically suffers, methods cannot work harmoniously, deblurring methods could deal, novel data synthesis pipeline, extensive experiments demonstrate</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Night photography typically suffers from both low light and blurring issues
due to the dim environment and the common use of long exposure. While existing
light enhancement and deblurring methods could deal with each problem
individually, a cascade of such methods cannot work harmoniously to cope well
with joint degradation of visibility and textures. Training an end-to-end
network is also infeasible as no paired data is available to characterize the
coexistence of low light and blurs. We address the problem by introducing a
novel data synthesis pipeline that models realistic low-light blurring
degradations. With the pipeline, we present the first large-scale dataset for
joint low-light enhancement and deblurring. The dataset, LOL-Blur, contains
12,000 low-blur/normal-sharp pairs with diverse darkness and motion blurs in
different scenarios. We further present an effective network, named LEDNet, to
perform joint low-light enhancement and deblurring. Our network is unique as it
is specially designed to consider the synergy between the two inter-connected
tasks. Both the proposed dataset and network provide a foundation for this
challenging joint task. Extensive experiments demonstrate the effectiveness of
our method on both synthetic and real-world datasets.</p>
  </details>
</details>
<details>
  <summary>67. <b>标题：A Review of Landcover Classification with Very-High Resolution Remotely  Sensed Optical Images-Analysis Unit,Model Scalability and Transferability</b></summary>
  <p><b>编号</b>：[453]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03342</p>
  <p><b>作者</b>：Rongjun Qin,  Tao Liu</p>
  <p><b>备注</b>：29 pages</p>
  <p><b>关键词</b>：previous review articles regarding remote sensing classification, domain gaps across different geographical regions, revolve around general deep learning models, remote sensing classification focus including, ever advancing landcover mapping methods</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As an important application in remote sensing, landcover classification
remains one of the most challenging tasks in very-high-resolution (VHR) image
analysis. As the rapidly increasing number of Deep Learning (DL) based
landcover methods and training strategies are claimed to be the
state-of-the-art, the already fragmented technical landscape of landcover
mapping methods has been further complicated. Although there exists a plethora
of literature review work attempting to guide researchers in making an informed
choice of landcover mapping methods, the articles either focus on the review of
applications in a specific area or revolve around general deep learning models,
which lack a systematic view of the ever advancing landcover mapping methods.
In addition, issues related to training samples and model transferability have
become more critical than ever in an era dominated by data-driven approaches,
but these issues were addressed to a lesser extent in previous review articles
regarding remote sensing classification. Therefore, in this paper, we present a
systematic overview of existing methods by starting from learning methods and
varying basic analysis units for landcover mapping tasks, to challenges and
solutions on three aspects of scalability and transferability with a remote
sensing classification focus including (1) sparsity and imbalance of data; (2)
domain gaps across different geographical regions; and (3) multi-source and
multi-view fusion. We discuss in detail each of these categorical methods and
draw concluding remarks in these developments and recommend potential
directions for the continued endeavor.</p>
  </details>
</details>
<details>
  <summary>68. <b>标题：Motion-Plane-Adaptive Inter Prediction in 360-Degree Video Coding</b></summary>
  <p><b>编号</b>：[456]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03323</p>
  <p><b>作者</b>：Andy Regensky,  Christian Herglotz,  André Kaup</p>
  <p><b>备注</b>：13 pages, 9 figures, 5 tables; This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible</p>
  <p><b>关键词</b>：vvc video coding standard shows significant bjontegaard delta rate savings, allow compression using existing video coding standards, adaptive motion vector prediction technique, modern video coding standards, adaptive inter prediction technique</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Inter prediction is one of the key technologies enabling the high compression
efficiency of modern video coding standards. 360-degree video needs to be
mapped to the 2D image plane prior to coding in order to allow compression
using existing video coding standards. The distortions that inevitably occur
when mapping spherical data onto the 2D image plane, however, impair the
performance of classical inter prediction techniques. In this paper, we propose
a motion-plane-adaptive inter prediction technique (MPA) for 360-degree video
that takes the spherical characteristics of 360-degree video into account.
Based on the known projection format of the video, MPA allows to perform inter
prediction on different motion planes in 3D space instead of having to work on
the - in theory arbitrarily mapped - 2D image representation directly. We
furthermore derive a motion-plane-adaptive motion vector prediction technique
(MPA-MVP) that allows to translate motion information between different motion
planes and motion models. Our proposed integration of MPA together with MPA-MVP
into the state-of-the-art H.266/VVC video coding standard shows significant
Bjontegaard Delta rate savings of 1.72% with a peak of 3.97% based on PSNR and
1.56% with a peak of 3.40% based on WS-PSNR compared to the VTM-14.2 baseline
on average.</p>
  </details>
</details>
<details>
  <summary>69. <b>标题：Human Activity Recognition Using Tools of Convolutional Neural Networks:  A State of the Art Review, Data Sets, Challenges and Future Prospects</b></summary>
  <p><b>编号</b>：[458]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03274</p>
  <p><b>作者</b>：Md. Milon Islam,  Sheikh Nooruddin,  Fakhri Karray,  Ghulam Muhammad</p>
  <p><b>备注</b>：32 pages, 4 figures, 4 Tables</p>
  <p><b>关键词</b>：input devices like multimodal sensing devices, namely convolutional neural networks, available public data sources, summarize recent works based, deep neural networks architecture</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Human Activity Recognition (HAR) plays a significant role in the everyday
life of people because of its ability to learn extensive high-level information
about human activity from wearable or stationary devices. A substantial amount
of research has been conducted on HAR and numerous approaches based on deep
learning and machine learning have been exploited by the research community to
classify human activities. The main goal of this review is to summarize recent
works based on a wide range of deep neural networks architecture, namely
convolutional neural networks (CNNs) for human activity recognition. The
reviewed systems are clustered into four categories depending on the use of
input devices like multimodal sensing devices, smartphones, radar, and vision
devices. This review describes the performances, strengths, weaknesses, and the
used hyperparameters of CNN architectures for each reviewed system with an
overview of available public data sources. In addition, a discussion with the
current challenges to CNN-based HAR systems is presented. Finally, this review
is concluded with some potential future directions that would be of great
assistance for the researchers who would like to contribute to this field.</p>
  </details>
</details>
<details>
  <summary>70. <b>标题：A comprehensive benchmark analysis for sand dust image reconstruction</b></summary>
  <p><b>编号</b>：[479]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03031</p>
  <p><b>作者</b>：Yazhong Si,  Fan Yang,  Ya Guo,  Wei Zhang,  Yipu Yang</p>
  <p><b>备注</b>：13 pages, 12 figures</p>
  <p><b>关键词</b>：existing image transformation neural network trained, numerous sand dust image enhancement algorithms, sand dust image enhancement, sand dust image reconstruction, sand dust image reconstruction</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Numerous sand dust image enhancement algorithms have been proposed in recent
years. To our best acknowledge, however, most methods evaluated their
performance with no-reference way using few selected real-world images from
internet. It is unclear how to quantitatively analysis the performance of the
algorithms in a supervised way and how we could gauge the progress in the
field. Moreover, due to the absence of large-scale benchmark datasets, there
are no well-known reports of data-driven based method for sand dust image
enhancement up till now. To advance the development of deep learning-based
algorithms for sand dust image reconstruction, while enabling supervised
objective evaluation of algorithm performance. In this paper, we presented a
comprehensive perceptual study and analysis of real-world sand dust images,
then constructed a Sand-dust Image Reconstruction Benchmark (SIRB) for training
Convolutional Neural Networks (CNNs) and evaluating algorithms performance. In
addition, we adopted the existing image transformation neural network trained
on SIRB as baseline to illustrate the generalization of SIRB for training CNNs.
Finally, we conducted the qualitative and quantitative evaluation to
demonstrate the performance and limitations of the state-of-the-arts (SOTA),
which shed light on future research in sand dust image reconstruction.</p>
  </details>
</details>
<details>
  <summary>71. <b>标题：SUD: Supervision by Denoising for Medical Image Segmentation</b></summary>
  <p><b>编号</b>：[485]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02952</p>
  <p><b>作者</b>：Sean I. Young,  Adrian V. Dalca,  Enzo Ferrante,  Polina Golland,  Bruce Fischl,  Juan Eugenio Iglesias</p>
  <p><b>备注</b>：Author's manuscript for IEEE Trans. Pattern Anal. Mach. Intell</p>
  <p><b>关键词</b>：labeling even across domain experts, supervise segmentation models using, semantic segmentation typically requires, segmentation often necessitate hand, sud unifies temporal ensembling</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Training a fully convolutional network for semantic segmentation typically
requires a large, labeled dataset with little label noise if good
generalization is to be guaranteed. For many segmentation problems, however,
data with pixel- or voxel-level labeling accuracy are scarce due to the cost of
manual labeling. This problem is exacerbated in domains where manual annotation
is difficult, resulting in large amounts of variability in the labeling even
across domain experts. Therefore, training segmentation networks to generalize
better by learning from both labeled and unlabeled images (called
semi-supervised learning) is problem of both practical and theoretical
interest. However, traditional semi-supervised learning methods for
segmentation often necessitate hand-crafting a differentiable regularizer
specific to a given segmentation problem, which can be extremely
time-consuming. In this work, we propose "supervision by denoising" (SUD), a
framework that enables us to supervise segmentation models using their denoised
output as targets. SUD unifies temporal ensembling and spatial denoising
techniques under a spatio-temporal denoising framework and alternates denoising
and network weight update in an optimization framework for semi-supervision. We
validate SUD on three tasks-kidney and tumor (3D), and brain (3D) segmentation,
and cortical parcellation (2D)-demonstrating a significant improvement in the
Dice overlap and the Hausdorff distance of segmentations over supervised-only
and temporal ensemble baselines.</p>
  </details>
</details>
<details>
  <summary>72. <b>标题：Deep Deterministic Independent Component Analysis for Hyperspectral  Unmixing</b></summary>
  <p><b>编号</b>：[486]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02951</p>
  <p><b>作者</b>：Hongming Li,  Shujian Yu,  Jose C. Principe</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：new neural network based independent component analysis, $\ alpha $- order entropy functional, unmixing hyperspectral data }",, stochastic gradient descent, sgd ), without</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We develop a new neural network based independent component analysis (ICA)
method by directly minimizing the dependence amongst all extracted components.
Using the matrix-based R{é}nyi's $\alpha$-order entropy functional, our
network can be directly optimized by stochastic gradient descent (SGD), without
any variational approximation or adversarial training. As a solid application,
we evaluate our ICA in the problem of hyperspectral unmixing (HU) and refute a
statement that "\emph{ICA does not play a role in unmixing hyperspectral
data}", which was initially suggested by~\cite{nascimento2005does}. Code and
additional remarks of our DDICA is available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>73. <b>标题：Inter-subject Contrastive Learning for Subject Adaptive EEG-based Visual  Recognition</b></summary>
  <p><b>编号</b>：[489]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02901</p>
  <p><b>作者</b>：Pilhyeon Lee,  Sunhee Hwang,  Jewook Lee,  Minjung Shin,  Seogkyu Jeon,  Hyeran Byun</p>
  <p><b>备注</b>：Accepted by the 10th IEEE International Winter Conference on Brain-Computer Interface (BCI 2022). Code is available at this https URL</p>
  <p><b>关键词</b>：common knowledge shared across different subjects, five eeg samples per class, thereby achieving promising performance, visual stimuli based, dedicated sampling principle</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper tackles the problem of subject adaptive EEG-based visual
recognition. Its goal is to accurately predict the categories of visual stimuli
based on EEG signals with only a handful of samples for the target subject
during training. The key challenge is how to appropriately transfer the
knowledge obtained from abundant data of source subjects to the subject of
interest. To this end, we introduce a novel method that allows for learning
subject-independent representation by increasing the similarity of features
sharing the same class but coming from different subjects. With the dedicated
sampling principle, our model effectively captures the common knowledge shared
across different subjects, thereby achieving promising performance for the
target subject even under harsh problem settings with limited data.
Specifically, on the EEG-ImageNet40 benchmark, our model records the top-1 /
top-3 test accuracy of 72.6% / 91.6% when using only five EEG samples per class
for the target subject. Our code is available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>74. <b>标题：CheXstray: Real-time Multi-Modal Data Concordance for Drift Detection in  Medical Imaging AI</b></summary>
  <p><b>编号</b>：[499]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02833</p>
  <p><b>作者</b>：Arjun Soin,  Jameson Merkow,  Jin Long,  Joesph Paul Cohen,  Smitha Saligrama,  Stephen Kaiser,  Steven Borg,  Ivan Tarapov,  Matthew P Lungren</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：ground truth performance using unsupervised distributional shifts, model drift without contemporaneous ground truth, rapidly expanding clinical ai applications worldwide, medical imaging ai drift monitoring workflow, continuous medical imaging ai model monitoring</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Rapidly expanding Clinical AI applications worldwide have the potential to
impact to all areas of medical practice. Medical imaging applications
constitute a vast majority of approved clinical AI applications. Though
healthcare systems are eager to adopt AI solutions a fundamental question
remains: \textit{what happens after the AI model goes into production?} We use
the CheXpert and PadChest public datasets to build and test a medical imaging
AI drift monitoring workflow that tracks data and model drift without
contemporaneous ground truth. We simulate drift in multiple experiments to
compare model performance with our novel multi-modal drift metric, which uses
DICOM metadata, image appearance representation from a variational autoencoder
(VAE), and model output probabilities as input. Through experimentation, we
demonstrate a strong proxy for ground truth performance using unsupervised
distributional shifts in relevant metadata, predicted probabilities, and VAE
latent representation. Our key contributions include (1) proof-of-concept for
medical imaging drift detection including use of VAE and domain specific
statistical methods (2) a multi-modal methodology for measuring and unifying
drift metrics (3) new insights into the challenges and solutions for observing
deployed medical imaging AI (4) creation of open-source tools enabling others
to easily run their own workflows or scenarios. This work has important
implications for addressing the translation gap related to continuous medical
imaging AI model monitoring in dynamic healthcare environments.</p>
  </details>
</details>
<details>
  <summary>75. <b>标题：Detecting Melanoma Fairly: Skin Tone Detection and Debiasing for Skin  Lesion Classification</b></summary>
  <p><b>编号</b>：[500]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02832</p>
  <p><b>作者</b>：Peter J. Bevan,  Amir Atapour-Abarghouei</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：subsequently use two leading bias unlearning techniques, skin tone detection algorithm outperforms existing solutions, unlearning skin tone improves generalisation, efficient yet effective algorithm, uncover skin tone bias</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Convolutional Neural Networks have demonstrated human-level performance in
the classification of melanoma and other skin lesions, but evident performance
disparities between differing skin tones should be addressed before widespread
deployment. In this work, we utilise a modified variational autoencoder to
uncover skin tone bias in datasets commonly used as benchmarks. We propose an
efficient yet effective algorithm for automatically labelling the skin tone of
lesion images, and use this to annotate the benchmark ISIC dataset. We
subsequently use two leading bias unlearning techniques to mitigate skin tone
bias. Our experimental results provide evidence that our skin tone detection
algorithm outperforms existing solutions and that unlearning skin tone improves
generalisation and can reduce the performance disparity between melanoma
detection in lighter and darker skin tones.</p>
  </details>
</details>
<details>
  <summary>76. <b>标题：Perceptual Coding for Compressed Video Understanding: A New Framework  and Benchmark</b></summary>
  <p><b>编号</b>：[504]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02813</p>
  <p><b>作者</b>：Yuan Tian,  Guo Lu,  Yichao Yan,  Guangtao Zhai,  Li Chen,  Zhiyong Gao</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：pvc consistently demonstrates significantly stronger performances, bitstream perceptual video coding framework dual, sophisticatedly designed optimization target, new stream largely boosts, four different compression levels</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Most video understanding methods are learned on high-quality videos. However,
in most real-world scenarios, the videos are first compressed before the
transportation and then decompressed for understanding. The decompressed videos
are degraded in terms of perceptual quality, which may degenerate the
downstream tasks. To address this issue, we propose the first coding framework
for compressed video understanding, where another learnable perceptual
bitstream is introduced and simultaneously transported with the video
bitstream. With the sophisticatedly designed optimization target and network
architectures, this new stream largely boosts the perceptual quality of the
decoded videos yet with a small bit cost. Our framework can enjoy the best of
both two worlds, (1) highly efficient content-coding of industrial video codec
and (2) flexible perceptual-coding of neural networks (NNs). Finally, we build
a rigorous benchmark for compressed video understanding over four different
compression levels, six large-scale datasets, and two popular tasks. The
proposed Dual-bitstream Perceptual Video Coding framework Dual-PVC consistently
demonstrates significantly stronger performances than the baseline codec under
the same bitrate level.</p>
  </details>
</details>
<details>
  <summary>77. <b>标题：On Smart Gaze based Annotation of Histopathology Images for Training of  Deep Convolutional Neural Networks</b></summary>
  <p><b>编号</b>：[506]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02764</p>
  <p><b>作者</b>：Komal Mariam,  Osama Mohammed Afzal,  Wajahat Hussain,  Muhammad Umar Javed,  Amber Kiyani,  Nasir Rajpoot,  Syed Ali Khurram,  Hassan Aqeel Khan</p>
  <p><b>备注</b>：12 pages, 10 figures, 2 tables, journal</p>
  <p><b>关键词</b>：although slide digitization via whole slide imaging scanners, 85 \%$ less time per label, 6 \%$ less time per label, deep object detectors trained using hand, save valuable pathologist time</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Unavailability of large training datasets is a bottleneck that needs to be
overcome to realize the true potential of deep learning in histopathology
applications. Although slide digitization via whole slide imaging scanners has
increased the speed of data acquisition, labeling of virtual slides requires a
substantial time investment from pathologists. Eye gaze annotations have the
potential to speed up the slide labeling process. This work explores the
viability and timing comparisons of eye gaze labeling compared to conventional
manual labeling for training object detectors. Challenges associated with gaze
based labeling and methods to refine the coarse data annotations for subsequent
object detection are also discussed. Results demonstrate that gaze tracking
based labeling can save valuable pathologist time and delivers good performance
when employed for training a deep object detector. Using the task of
localization of Keratin Pearls in cases of oral squamous cell carcinoma as a
test case, we compare the performance gap between deep object detectors trained
using hand-labelled and gaze-labelled data. On average, compared to
`Bounding-box' based hand-labeling, gaze-labeling required $57.6\%$ less time
per label and compared to `Freehand' labeling, gaze-labeling required on
average $85\%$ less time per label.</p>
  </details>
</details>
<details>
  <summary>78. <b>标题：Hyper-Convolutions via Implicit Kernels for Medical Imaging</b></summary>
  <p><b>编号</b>：[510]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02701</p>
  <p><b>作者</b>：Tianyu Ma,  Alan Q. Wang,  Adrian V. Dalca,  Mert R. Sabuncu</p>
  <p><b>备注</b>：arXiv admin note: substantial text overlap with arXiv:2105.10559</p>
  <p><b>关键词</b>：convolutional kernel using spatial coordinates, convolutions decouple kernel size, convolutional neural network, shares weights across, novel building block</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The convolutional neural network (CNN) is one of the most commonly used
architectures for computer vision tasks. The key building block of a CNN is the
convolutional kernel that aggregates information from the pixel neighborhood
and shares weights across all pixels. A standard CNN's capacity, and thus its
performance, is directly related to the number of learnable kernel weights,
which is determined by the number of channels and the kernel size (support). In
this paper, we present the \textit{hyper-convolution}, a novel building block
that implicitly encodes the convolutional kernel using spatial coordinates.
Hyper-convolutions decouple kernel size from the total number of learnable
parameters, enabling a more flexible architecture design. We demonstrate in our
experiments that replacing regular convolutions with hyper-convolutions can
improve performance with less parameters, and increase robustness against
noise. We provide our code here:
\emph{this https URL}</p>
  </details>
</details>
<details>
  <summary>79. <b>标题：DSSIM: a structural similarity index for floating-point data</b></summary>
  <p><b>编号</b>：[519]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02616</p>
  <p><b>作者</b>：Allison H. Baker,  Alexander Pinard,  Dorit M. Hammerling</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：simulation data often generate, large model simulation codes, dssim may prove useful, applications involving simulation, structural similarity index</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Data visualization is a critical component in terms of interacting with
floating-point output data from large model simulation codes. Indeed,
postprocessing analysis workflows on simulation data often generate a large
number of images from the raw data, many of which are then compared to each
other or to specified reference images. In this image-comparison scenario,
image quality assessment (IQA) measures are quite useful, and the Structural
Similarity Index (SSIM) continues to be a popular choice. However, generating
large numbers of images can be costly, and plot-specific (but data independent)
choices can affect the SSIM value. A natural question is whether we can apply
the SSIM directly to the floating-point simulation data and obtain an
indication of whether differences in the data are likely to impact a visual
assessment, effectively bypassing the creation of a specific set of images from
the data. To this end, we propose an alternative to the popular SSIM that can
be applied directly to the floating point data, which we refer to as the Data
SSIM (DSSIM). While we demonstrate the usefulness of the DSSIM in the context
of evaluating differences due to lossy compression on large volumes of
simulation data from a popular climate model, the DSSIM may prove useful for
many other applications involving simulation or image data.</p>
  </details>
</details>
<details>
  <summary>80. <b>标题：ROMNet: Renovate the Old Memories</b></summary>
  <p><b>编号</b>：[520]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02606</p>
  <p><b>作者</b>：Runsheng Xu,  Zhengzhong Tu,  Yuanqi Du,  Xiaoyu Dong,  Jinlong Li,  Zibo Meng,  Jiaqi Ma,  Hongkai YU</p>
  <p><b>备注</b>：Submitted to TIP</p>
  <p><b>关键词</b>：scale paired old photo datasets makes, evaluating old photo restoration models, whole system takes advantage, world old photo dataset, manually restored pristine image</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Renovating the memories in old photos is an intriguing research topic in
computer vision fields. These legacy images often suffer from severe and
commingled degradations such as cracks, noise, and color-fading, while lack of
large-scale paired old photo datasets makes this restoration task very
challenging. In this work, we present a novel reference-based end-to-end
learning framework that can jointly repair and colorize the degraded legacy
pictures. Specifically, the proposed framework consists of three modules: a
restoration sub-network for degradation restoration, a similarity sub-network
for color histogram matching and transfer, and a colorization subnet that
learns to predict the chroma elements of the images conditioned on chromatic
reference signals. The whole system takes advantage of the color histogram
priors in a given reference image, which vastly reduces the dependency on
large-scale training data. Apart from the proposed method, we also create, to
our knowledge, the first public and real-world old photo dataset with paired
ground truth for evaluating old photo restoration models, wherein each old
photo is paired with a manually restored pristine image by PhotoShop experts.
Our extensive experiments conducted on both synthetic and real-world datasets
demonstrate that our method significantly outperforms state-of-the-arts both
quantitatively and qualitatively.</p>
  </details>
</details>
<details>
  <summary>81. <b>标题：Tensor-CSPNet: A Novel Geometric Deep Learning Framework for Motor  Imagery Classification</b></summary>
  <p><b>编号</b>：[528]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02472</p>
  <p><b>作者</b>：Ce Ju,  Cuntai Guan</p>
  <p><b>备注</b>：15 pages, 10 figures, 12 tables; This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible</p>
  <p><b>关键词</b>：frequential patterns using deep neural networks, eeg signals using convolutional neural networks, alternative network architecture despite cnns, interpretability analyses also exhibit, novel geometric deep learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep learning (DL) has been widely investigated in a vast majority of
applications in electroencephalography (EEG)-based brain-computer interfaces
(BCIs), especially for motor imagery (MI) classification in the past five
years. The mainstream DL methodology for the MI-EEG classification exploits the
temporospatial patterns of EEG signals using convolutional neural networks
(CNNs), which have been particularly successful in visual images. However,
since the statistical characteristics of visual images may not benefit EEG
signals, a natural question that arises is whether there exists an alternative
network architecture despite CNNs to extract features for the MI-EEG
classification. To address this question, we propose a novel geometric deep
learning (GDL) framework called Tensor-CSPNet to characterize EEG signals on
symmetric positive definite (SPD) manifolds and exploit the
temporo-spatio-frequential patterns using deep neural networks on SPD
manifolds. Meanwhile, many experiences of successful MI-EEG classifiers have
been integrated into the Tensor-CSPNet framework to make it more efficient. In
the experiments, Tensor-CSPNet attains or slightly outperforms the current
state-of-the-art performance on the cross-validation and holdout scenarios of
two MI-EEG datasets. The visualization and interpretability analyses also
exhibit its validity for the MI-EEG classification. To conclude, we provide a
feasible answer to the question by generalizing the previous DL methodologies
on SPD manifolds, which indicates the start of a specific class from the GDL
methodology for the MI-EEG classification.</p>
  </details>
</details>
<details>
  <summary>82. <b>标题：Machine Learning Method for Functional Assessment of Retinal Models</b></summary>
  <p><b>编号</b>：[530]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02443</p>
  <p><b>作者</b>：Nikolas Papadopoulos,  Nikos Melanitis,  Antonio Lozano,  Cristina Soto-Sanchez,  Eduardo Fernandez,  Konstantina S Nikita</p>
  <p><b>备注</b>：Accepted at 2021 43rd Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC)</p>
  <p><b>关键词</b>：accurately simulate retinal ganglion cells, feed traditional machine learning classifiers, accurately predict rgc response, optimally feed rgc responses, examined critical fa aspects</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Challenges in the field of retinal prostheses motivate the development of
retinal models to accurately simulate Retinal Ganglion Cells (RGCs) responses.
The goal of retinal prostheses is to enable blind individuals to solve complex,
reallife visual tasks. In this paper, we introduce the functional assessment
(FA) of retinal models, which describes the concept of evaluating the
performance of retinal models on visual understanding tasks. We present a
machine learning method for FA: we feed traditional machine learning
classifiers with RGC responses generated by retinal models, to solve object and
digit recognition tasks (CIFAR-10, MNIST, Fashion MNIST, Imagenette). We
examined critical FA aspects, including how the performance of FA depends on
the task, how to optimally feed RGC responses to the classifiers and how the
number of output neurons correlates with the model's accuracy. To increase the
number of output neurons, we manipulated input images - by splitting and then
feeding them to the retinal model and we found that image splitting does not
significantly improve the model's accuracy. We also show that differences in
the structure of datasets result in largely divergent performance of the
retinal model (MNIST and Fashion MNIST exceeded 80% accuracy, while CIFAR-10
and Imagenette achieved ~40%). Furthermore, retinal models which perform better
in standard evaluation, i.e. more accurately predict RGC response, perform
better in FA as well. However, unlike standard evaluation, FA results can be
straightforwardly interpreted in the context of comparing the quality of visual
perception.</p>
  </details>
</details>
<details>
  <summary>83. <b>标题：Stratification of carotid atheromatous plaque using interpretable deep  learning methods on B-mode ultrasound images</b></summary>
  <p><b>编号</b>：[532]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02428</p>
  <p><b>作者</b>：Theofanis Ganitidis,  Maria Athanasiou,  Kalliopi Dalakleidi,  Nikos Melanitis,  Spyretta Golemati,  Konstantina S Nikita</p>
  <p><b>备注</b>：Accepted at 2021 43rd Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC)</p>
  <p><b>关键词</b>：proposed approach achieved acceptable discrimination performance, auc ): 73 %, sensitivity, two fully connected layers, novel ultrasound image biomarkers, ensemble learning scheme based</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Carotid atherosclerosis is the major cause of ischemic stroke resulting in
significant rates of mortality and disability annually. Early diagnosis of such
cases is of great importance, since it enables clinicians to apply a more
effective treatment strategy. This paper introduces an interpretable
classification approach of carotid ultrasound images for the risk assessment
and stratification of patients with carotid atheromatous plaque. To address the
highly imbalanced distribution of patients between the symptomatic and
asymptomatic classes (16 vs 58, respectively), an ensemble learning scheme
based on a sub-sampling approach was applied along with a two-phase,
cost-sensitive strategy of learning, that uses the original and a resampled
data set. Convolutional Neural Networks (CNNs) were utilized for building the
primary models of the ensemble. A six-layer deep CNN was used to automatically
extract features from the images, followed by a classification stage of two
fully connected layers. The obtained results (Area Under the ROC Curve (AUC):
73%, sensitivity: 75%, specificity: 70%) indicate that the proposed approach
achieved acceptable discrimination performance. Finally, interpretability
methods were applied on the model's predictions in order to reveal insights on
the model's decision process as well as to enable the identification of novel
image biomarkers for the stratification of patients with carotid atheromatous
plaque.Clinical Relevance-The integration of interpretability methods with deep
learning strategies can facilitate the identification of novel ultrasound image
biomarkers for the stratification of patients with carotid atheromatous plaque.</p>
  </details>
</details>
<details>
  <summary>84. <b>标题：Fully Automated Tree Topology Estimation and Artery-Vein Classification</b></summary>
  <p><b>编号</b>：[536]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02382</p>
  <p><b>作者</b>：Aashis Khanal,  Saeid Motevali,  Rolando Estrada</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：also performed several ablation studies, hlos include detaching neighboring nodes, single color fundus image, estimated blood flow direction, vein labeling achieved state</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present a fully automatic technique for extracting the retinal vascular
topology, i.e., how the different vessels are connected to each other, given a
single color fundus image. Determining this connectivity is very challenging
because vessels cross each other in a 2D image, obscuring their true paths. We
validated the usefulness of our extraction method by using it to achieve
state-of-the-art results in retinal artery-vein classification.
Our proposed approach works as follows. We first segment the retinal vessels
using our previously developed state-of-the-art segmentation method. Then, we
estimate an initial graph from the extracted vessels and assign the most likely
blood flow to each edge. We then use a handful of high-level operations (HLOs)
to fix errors in the graph. These HLOs include detaching neighboring nodes,
shifting the endpoints of an edge, and reversing the estimated blood flow
direction for a branch. We use a novel cost function to find the optimal set of
HLO operations for a given graph. Finally, we show that our extracted vascular
structure is correct by propagating artery/vein labels along the branches. As
our experiments show, our topology-based artery-vein labeling achieved
state-of-the-art results on multiple datasets. We also performed several
ablation studies to verify the importance of the different components of our
proposed method.</p>
  </details>
</details>
<details>
  <summary>85. <b>标题：Boundary-aware Information Maximization for Self-supervised Medical  Image Segmentation</b></summary>
  <p><b>编号</b>：[538]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02371</p>
  <p><b>作者</b>：Jizong Peng,  Ping Wang,  Marco Pedersoli,  Christian Desrosiers</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：boost various downstream tasks given limited labeled data, train task using mutual information maximization, two benchmark medical segmentation datasets reveal, among various methods, improving segmentation performance</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Unsupervised pre-training has been proven as an effective approach to boost
various downstream tasks given limited labeled data. Among various methods,
contrastive learning learns a discriminative representation by constructing
positive and negative pairs. However, it is not trivial to build reasonable
pairs for a segmentation task in an unsupervised way. In this work, we propose
a novel unsupervised pre-training framework that avoids the drawback of
contrastive learning. Our framework consists of two principles: unsupervised
over-segmentation as a pre-train task using mutual information maximization and
boundary-aware preserving learning. Experimental results on two benchmark
medical segmentation datasets reveal our method's effectiveness in improving
segmentation performance when few annotated images are available.</p>
  </details>
</details>
<h1>自然语言处理</h1>
<details>
  <summary>1. <b>标题：Cedille: A large autoregressive French language model</b></summary>
  <p><b>编号</b>：[17]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03371</p>
  <p><b>作者</b>：Martin Müller,  Florian Laurent</p>
  <p><b>备注</b>：8 pages, 1 figure, 7 tables</p>
  <p><b>关键词</b>：solving natural language processing tasks using zero, cedille outperforms existing french language models, large open source auto, english remain largely unexplored, language model safety thanks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Scaling up the size and training of autoregressive language models has
enabled novel ways of solving Natural Language Processing tasks using zero-shot
and few-shot learning. While extreme-scale language models such as GPT-3 offer
multilingual capabilities, zero-shot learning for languages other than English
remain largely unexplored. Here, we introduce Cedille, a large open source
auto-regressive language model, specifically trained for the French language.
Our results show that Cedille outperforms existing French language models and
is competitive with GPT-3 on a range of French zero-shot benchmarks.
Furthermore, we provide an in-depth comparison of the toxicity exhibited by
these models, showing that Cedille marks an improvement in language model
safety thanks to dataset filtering.</p>
  </details>
</details>
<details>
  <summary>2. <b>标题：Robust Dialogue State Tracking with Weak Supervision and Sparse Data</b></summary>
  <p><b>编号</b>：[22]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03354</p>
  <p><b>作者</b>：Michael Heck,  Nurul Lubis,  Carel van Niekerk,  Shutong Feng,  Christian Geishauser,  Hsien-Chin Lin,  Milica Gašić</p>
  <p><b>备注</b>：13 pages, 7 figures</p>
  <p><b>关键词</b>：training strategies improve robustness towards sample sparsity, trained without manual span labels, build extractive dst models without, complementary predictions without violating, grained manual span labels</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Generalising dialogue state tracking (DST) to new data is especially
challenging due to the strong reliance on abundant and fine-grained supervision
during training. Sample sparsity, distributional shift and the occurrence of
new concepts and topics frequently lead to severe performance degradation
during inference. In this paper we propose a training strategy to build
extractive DST models without the need for fine-grained manual span labels. Two
novel input-level dropout methods mitigate the negative impact of sample
sparsity. We propose a new model architecture with a unified encoder that
supports value as well as slot independence by leveraging the attention
mechanism. We combine the strengths of triple copy strategy DST and value
matching to benefit from complementary predictions without violating the
principle of ontology independence. Our experiments demonstrate that an
extractive DST model can be trained without manual span labels. Our
architecture and training strategies improve robustness towards sample
sparsity, new concepts and topics, leading to state-of-the-art performance on a
range of benchmarks. We further highlight our model's ability to effectively
learn from non-dialogue data.</p>
  </details>
</details>
<details>
  <summary>3. <b>标题：Mental Disorders on Online Social Media Through the Lens of Language and  Behaviour: Analysis and Visualisation</b></summary>
  <p><b>编号</b>：[44]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03291</p>
  <p><b>作者</b>：Esteban A. Ríssola,  Mohammad Aliannejadi,  Fabio Crestani</p>
  <p><b>备注</b>：To appear in Elsevier Information Processing & Management</p>
  <p><b>关键词</b>：perform different experiments studying multiple dimensions, thorough analysis towards better visualising, differentiate social media users affected, findings reveal significant differences, twitter less quantifiable differences</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Due to the worldwide accessibility to the Internet along with the continuous
advances in mobile technologies, physical and digital worlds have become
completely blended, and the proliferation of social media platforms has taken a
leading role over this evolution. In this paper, we undertake a thorough
analysis towards better visualising and understanding the factors that
characterise and differentiate social media users affected by mental disorders.
We perform different experiments studying multiple dimensions of language,
including vocabulary uniqueness, word usage, linguistic style, psychometric
attributes, emotions' co-occurrence patterns, and online behavioural traits,
including social engagement and posting trends. Our findings reveal significant
differences on the use of function words, such as adverbs and verb tense, and
topic-specific vocabulary, such as biological processes. As for emotional
expression, we observe that affected users tend to share emotions more
regularly than control individuals on average. Overall, the monthly posting
variance of the affected groups is higher than the control groups. Moreover, we
found evidence suggesting that language use on micro-blogging platforms is less
distinguishable for users who have a mental disorder than other less
restrictive platforms. In particular, we observe on Twitter less quantifiable
differences between affected and control groups compared to Reddit.</p>
  </details>
</details>
<details>
  <summary>4. <b>标题：Red Teaming Language Models with Language Models</b></summary>
  <p><b>编号</b>：[47]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03286</p>
  <p><b>作者</b>：Ethan Perez,  Saffron Huang,  Francis Song,  Trevor Cai,  Roman Ring,  John Aslanides,  Amelia Glaese,  Nat McAleese,  Geoffrey Irving</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：generating test cases (" red teaming ") using another lm, prior work identifies harmful behaviors, generated test questions using, based red teaming, hospital phone numbers generated</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Language Models (LMs) often cannot be deployed because of their potential to
harm users in hard-to-predict ways. Prior work identifies harmful behaviors
before deployment by using human annotators to hand-write test cases. However,
human annotation is expensive, limiting the number and diversity of test cases.
In this work, we automatically find cases where a target LM behaves in a
harmful way, by generating test cases ("red teaming") using another LM. We
evaluate the target LM's replies to generated test questions using a classifier
trained to detect offensive content, uncovering tens of thousands of offensive
replies in a 280B parameter LM chatbot. We explore several methods, from
zero-shot generation to reinforcement learning, for generating test cases with
varying levels of diversity and difficulty. Furthermore, we use prompt
engineering to control LM-generated test cases to uncover a variety of other
harms, automatically finding groups of people that the chatbot discusses in
offensive ways, personal and hospital phone numbers generated as the chatbot's
own contact info, leakage of private training data in generated text, and harms
that occur over the course of a conversation. Overall, LM-based red teaming is
one promising tool (among many needed) for finding and fixing diverse,
undesirable LM behaviors before impacting users.</p>
  </details>
</details>
<details>
  <summary>5. <b>标题：Efficient Adapter Transfer of Self-Supervised Speech Models for  Automatic Speech Recognition</b></summary>
  <p><b>编号</b>：[71]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03218</p>
  <p><b>作者</b>：Bethan Thomas,  Samuel Kessler,  Salah Karout</p>
  <p><b>备注</b>：5 Pages, 4 figures. Accepted to ICASSP 2022</p>
  <p><b>关键词</b>：trained network gives similar performance, parameters per task compared, natural language processing, small lightweight modules, automatic speech recognition</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Self-supervised learning (SSL) is a powerful tool that allows learning of
underlying representations from unlabeled data. Transformer based models such
as wav2vec 2.0 and HuBERT are leading the field in the speech domain. Generally
these models are fine-tuned on a small amount of labeled data for a downstream
task such as Automatic Speech Recognition (ASR). This involves re-training the
majority of the model for each task. Adapters are small lightweight modules
which are commonly used in Natural Language Processing (NLP) to adapt
pre-trained models to new tasks. In this paper we propose applying adapters to
wav2vec 2.0 to reduce the number of parameters required for downstream ASR
tasks, and increase scalability of the model to multiple tasks or languages.
Using adapters we can perform ASR while training fewer than 10% of parameters
per task compared to full fine-tuning with little degradation of performance.
Ablations show that applying adapters into just the top few layers of the
pre-trained network gives similar performance to full transfer, supporting the
theory that higher pre-trained layers encode more phonemic information, and
further optimizing efficiency.</p>
  </details>
</details>
<details>
  <summary>6. <b>标题：Conversational Agents: Theory and Applications</b></summary>
  <p><b>编号</b>：[96]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03164</p>
  <p><b>作者</b>：Mattias Wahde,  Marco Virgolin</p>
  <p><b>备注</b>：preprint of a chapter to appear in Handbook of Computer Learning and Intelligence - Volume 1</p>
  <p><b>关键词</b>：cas ), discussing chatbots, potential risks regarding, many different approaches, future ca technology, briefly reviewing aspects</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this chapter, we provide a review of conversational agents (CAs),
discussing chatbots, intended for casual conversation with a user, as well as
task-oriented agents that generally engage in discussions intended to reach one
or several specific goals, often (but not always) within a specific domain. We
also consider the concept of embodied conversational agents, briefly reviewing
aspects such as character animation and speech processing. The many different
approaches for representing dialogue in CAs are discussed in some detail, along
with methods for evaluating such agents, emphasizing the important topics of
accountability and interpretability. A brief historical overview is given,
followed by an extensive overview of various applications, especially in the
fields of health and education. We end the chapter by discussing benefits and
potential risks regarding the societal impact of current and future CA
technology.</p>
  </details>
</details>
<details>
  <summary>7. <b>标题：To Tune or Not To Tune? Zero-shot Models for Legal Case Entailment</b></summary>
  <p><b>编号</b>：[112]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03120</p>
  <p><b>作者</b>：Guilherme Moraes Rosa,  Ruan Chaves Rodrigues,  Roberto de Alencar Lotufo,  Rodrigo Nogueira</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：given limited labeled data, legal case entailment task, pretrained language models fine, pretrained language models, six percentage points</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>There has been mounting evidence that pretrained language models fine-tuned
on large and diverse supervised datasets can transfer well to a variety of
out-of-domain tasks. In this work, we investigate this transfer ability to the
legal domain. For that, we participated in the legal case entailment task of
COLIEE 2021, in which we use such models with no adaptations to the target
domain. Our submissions achieved the highest scores, surpassing the second-best
team by more than six percentage points. Our experiments confirm a
counter-intuitive result in the new paradigm of pretrained language models:
given limited labeled data, models with little or no adaptation to the target
task can be more robust to changes in the data distribution than models
fine-tuned on it. Code is available at this https URL.</p>
  </details>
</details>
<details>
  <summary>8. <b>标题：Moving Other Way: Exploring Word Mover Distance Extensions</b></summary>
  <p><b>编号</b>：[113]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03119</p>
  <p><b>作者</b>：Ilya Smirnov,  Ivan P. Yamshchikov</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：position paper studies several possible extensions, proposed extensions show better results, six document classification datasets, popular semantic similarity metric, nearest neighbor classification error</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The word mover's distance (WMD) is a popular semantic similarity metric for
two texts. This position paper studies several possible extensions of WMD. We
experiment with the frequency of words in the corpus as a weighting factor and
the geometry of the word vector space. We validate possible extensions of WMD
on six document classification datasets. Some proposed extensions show better
results in terms of the k-nearest neighbor classification error than WMD.</p>
  </details>
</details>
<details>
  <summary>9. <b>标题：Document-Level Event Extraction via Human-Like Reading Process</b></summary>
  <p><b>编号</b>：[121]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03092</p>
  <p><b>作者</b>：Shiyao Cui,  Xin Cong,  Bowen Yu,  Tingwen Liu,  Yucheng Wang,  Jinqiao Shi</p>
  <p><b>备注</b>：To apper in ICASSP2022</p>
  <p><b>关键词</b>：second one reflects one document may simultaneously contain multiple, one event record could reside, human reading inspired extractor, elaborate reading hierarchically works, extract specific event arguments</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Document-level Event Extraction (DEE) is particularly tricky due to the two
challenges it poses: scattering-arguments and multi-events. The first challenge
means that arguments of one event record could reside in different sentences in
the document, while the second one reflects one document may simultaneously
contain multiple such event records. Motivated by humans' reading cognitive to
extract information of interests, in this paper, we propose a method called HRE
(Human Reading inspired Extractor for Document Events), where DEE is decomposed
into these two iterative stages, rough reading and elaborate reading.
Specifically, the first stage browses the document to detect the occurrence of
events, and the second stage serves to extract specific event arguments. For
each concrete event role, elaborate reading hierarchically works from sentences
to characters to locate arguments across sentences, thus the
scattering-arguments problem is tackled. Meanwhile, rough reading is explored
in a multi-round manner to discover undetected events, thus the multi-events
problem is handled. Experiment results show the superiority of HRE over prior
competitive methods.</p>
  </details>
</details>
<details>
  <summary>10. <b>标题：Machine Translation from Signed to Spoken Languages: State of the Art  and Challenges</b></summary>
  <p><b>编号</b>：[124]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03086</p>
  <p><b>作者</b>：Mathieu De Coster,  Dimitar Shterionov,  Mieke Van Herreweghe,  Joni Dambre</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：useful sign language translation models, spoken language machine translation research, sign language translation models, sign language translation applications, automatic sign language translation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Automatic translation from signed to spoken languages is an interdisciplinary
research domain, lying on the intersection of computer vision, machine
translation and linguistics. Nevertheless, research in this domain is performed
mostly by computer scientists in isolation. As the domain is becoming
increasingly popular - the majority of scientific papers on the topic of sign
language translation have been published in the past three years - we provide
an overview of the state of the art as well as some required background in the
different related disciplines. We give a high-level introduction to sign
language linguistics and machine translation to illustrate the requirements of
automatic sign language translation. We present a systematic literature review
to illustrate the state of the art in the domain and then, harking back to the
requirements, lay out several challenges for future research. We find that
significant advances have been made on the shoulders of spoken language machine
translation research. However, current approaches are often not linguistically
motivated or are not adapted to the different input modality of sign languages.
We explore challenges related to the representation of sign language data, the
collection of datasets, the need for interdisciplinary research and
requirements for moving beyond research, towards applications. Based on our
findings, we advocate for interdisciplinary research and to base future
research on linguistic analysis of sign languages. Furthermore, the inclusion
of deaf and hearing end users of sign language translation applications in use
case identification, data collection and evaluation is of the utmost importance
in the creation of useful sign language translation models. We recommend
iterative, human-in-the-loop, design and development of sign language
translation models.</p>
  </details>
</details>
<details>
  <summary>11. <b>标题：Gender stereotypes in the mediated personalization of politics:  Empirical evidence from a lexical, syntactic and sentiment analysis</b></summary>
  <p><b>编号</b>：[126]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03083</p>
  <p><b>作者</b>：Emanuele Brugnoli,  Rosaria Simone,  Marco Delmastro</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：observed gender differences comes, entrenched stereotypes including, certain stereotypes may, political office holders, hold political functions</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The media attention to the personal sphere of famous and important
individuals has become a key element of the gender narrative. Here we combine
lexical, syntactic and sentiment analysis to investigate the role of gender in
the personalization of a wide range of political office holders in Italy during
the period 2017-2020. On the basis of a score for words that is introduced to
account for gender unbalance in both representative and news coverage, we show
that the political personalization in Italy is more detrimental for women than
men, with the persistence of entrenched stereotypes including a masculine
connotation of leadership, the resulting women's unsuitability to hold
political functions, and a greater deal of focus on their attractiveness and
body parts. In addition, women politicians are covered with a more negative
tone than their men counterpart when personal details are reported. Further,
the major contribution to the observed gender differences comes from online
news rather than print news, suggesting that the expression of certain
stereotypes may be better conveyed when click baiting and personal targeting
have a major impact.</p>
  </details>
</details>
<details>
  <summary>12. <b>标题：Unifying Architectures, Tasks, and Modalities Through a Simple  Sequence-to-Sequence Learning Framework</b></summary>
  <p><b>编号</b>：[141]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03052</p>
  <p><b>作者</b>：Peng Wang,  An Yang,  Rui Men,  Junyang Lin,  Shuai Bai,  Zhikang Li,  Jianxin Ma,  Chang Zhou,  Jingren Zhou,  Hongxia Yang</p>
  <p><b>备注</b>：23 pages, 11 figures</p>
  <p><b>关键词</b>：ofa reaches comparable performance, ofa achieves new state, sequence learning framework based, unified multimodal pretrained model, g ., image generation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this work, we pursue a unified paradigm for multimodal pretraining to
break the scaffolds of complex task/modality-specific customization. We propose
OFA, a unified multimodal pretrained model that unifies modalities (i.e.,
cross-modality, vision, language) and tasks (e.g., image generation, visual
grounding, image captioning, image classification, text generation, etc.) to a
simple sequence-to-sequence learning framework based on the encoder-decoder
architecture. OFA performs pretraining and finetuning with task instructions
and introduces no extra task-specific layers for finetuning. Experimental
results show that OFA achieves new state-of-the-arts on a series of multimodal
tasks, including image captioning (COCO test CIDEr: 149.6), text-to-image
generation (COCO test FID: 10.5), VQA (test-std acc.: 80.02), SNLI-VE (test
acc.: 90.20), and referring expression comprehension (RefCOCO / RefCOCO+ /
RefCOCOg test acc.: 92.93 / 90.10 / 85.20). Through extensive analyses, we
demonstrate that OFA reaches comparable performance with uni-modal pretrained
models (e.g., BERT, MAE, MoCo v3, SimCLR v2, etc.) in uni-modal tasks,
including NLU, NLG, and image classification, and it effectively transfers to
unseen tasks and domains. Code shall be released soon at
this http URL</p>
  </details>
</details>
<details>
  <summary>13. <b>标题：Towards Learning Through Open-Domain Dialog</b></summary>
  <p><b>编号</b>：[146]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03040</p>
  <p><b>作者</b>：Eugénio Ribeiro,  Ricardo Ribeiro,  David Martins de Matos</p>
  <p><b>备注</b>：6 pages, 1 figure</p>
  <p><b>关键词</b>：dialog without domain restrictions, propose generic approaches, artificial agents able, similar manner, semantic network</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The development of artificial agents able to learn through dialog without
domain restrictions has the potential to allow machines to learn how to perform
tasks in a similar manner to humans and change how we relate to them. However,
research in this area is practically nonexistent. In this paper, we identify
the modifications required for a dialog system to be able to learn from the
dialog and propose generic approaches that can be used to implement those
modifications. More specifically, we discuss how knowledge can be extracted
from the dialog, used to update the agent's semantic network, and grounded in
action and observation. This way, we hope to raise awareness for this subject,
so that it can become a focus of research in the future.</p>
  </details>
</details>
<details>
  <summary>14. <b>标题：Comparison and Combination of Sentence Embeddings Derived from Different  Supervision Signals</b></summary>
  <p><b>编号</b>：[163]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02990</p>
  <p><b>作者</b>：Hayato Tsukagoshi,  Ryohei Sasano,  Koichi Takeda</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：recently seen many successful applications, embeddings yields substantially better performances, using natural language inference, sentence embeddings obtained, resulting sentence embeddings</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We have recently seen many successful applications of sentence embedding
methods. It has not been well understood, however, what kind of properties are
captured in the resulting sentence embeddings, depending on the supervision
signals. In this paper, we focus on two types of sentence embeddings obtained
by using natural language inference (NLI) datasets and definition sentences
from a word dictionary and investigate their properties by comparing their
performance with the semantic textual similarity (STS) task using the STS data
partitioned by two perspectives: 1) the sources of sentences, and 2) the
superficial similarity of the sentence pairs, and their performance on the
downstream and probing tasks. We also demonstrate that combining the two types
of embeddings yields substantially better performances than respective models
on unsupervised STS tasks and downstream tasks.</p>
  </details>
</details>
<details>
  <summary>15. <b>标题：Measuring and Reducing Model Update Regression in Structured Prediction  for NLP</b></summary>
  <p><b>编号</b>：[168]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02976</p>
  <p><b>作者</b>：Deng Cai,  Elman Mansimov,  Yi-An Lai,  Yixuan Su,  Lei Shu,  Yi Zhang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：reducing model update regression including model ensemble, work studies model update regression, better mitigate model update regression, machine learning based nlp models, analyze model update regression</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent advance in deep learning has led to rapid adoption of machine learning
based NLP models in a wide range of applications. Despite the continuous gain
in accuracy, backward compatibility is also an important aspect for industrial
applications, yet it received little research attention. Backward compatibility
requires that the new model does not regress on cases that were correctly
handled by its predecessor. This work studies model update regression in
structured prediction tasks. We choose syntactic dependency parsing and
conversational semantic parsing as representative examples of structured
prediction tasks in NLP. First, we measure and analyze model update regression
in different model update settings. Next, we explore and benchmark existing
techniques for reducing model update regression including model ensemble and
knowledge distillation. We further propose a simple and effective method,
Backward-Congruent Re-ranking (BCR), by taking into account the characteristics
of structured output. Experiments show that BCR can better mitigate model
update regression than model ensemble and knowledge distillation approaches.</p>
  </details>
</details>
<details>
  <summary>16. <b>标题：User Satisfaction Estimation with Sequential Dialogue Act Modeling in  Goal-oriented Conversational Systems</b></summary>
  <p><b>编号</b>：[199]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02912</p>
  <p><b>作者</b>：Yang Deng,  Wenxuan Zhang,  Wai Lam,  Hong Cheng,  Helen Meng</p>
  <p><b>备注</b>：Accepted by WWW 2022 (The Web Conference)</p>
  <p><b>关键词</b>：oriented dialogue datasets across different applications show, jointly learning user satisfaction estimation, existing studies often neglect, consistently outperforms existing methods, dialogue act recognition tasks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>User Satisfaction Estimation (USE) is an important yet challenging task in
goal-oriented conversational systems. Whether the user is satisfied with the
system largely depends on the fulfillment of the user's needs, which can be
implicitly reflected by users' dialogue acts. However, existing studies often
neglect the sequential transitions of dialogue act or rely heavily on annotated
dialogue act labels when utilizing dialogue acts to facilitate USE. In this
paper, we propose a novel framework, namely USDA, to incorporate the sequential
dynamics of dialogue acts for predicting user satisfaction, by jointly learning
User Satisfaction Estimation and Dialogue Act Recognition tasks. In specific,
we first employ a Hierarchical Transformer to encode the whole dialogue
context, with two task-adaptive pre-training strategies to be a second-phase
in-domain pre-training for enhancing the dialogue modeling ability. In terms of
the availability of dialogue act labels, we further develop two variants of
USDA to capture the dialogue act information in either supervised or
unsupervised manners. Finally, USDA leverages the sequential transitions of
both content and act features in the dialogue to predict the user satisfaction.
Experimental results on four benchmark goal-oriented dialogue datasets across
different applications show that the proposed method substantially and
consistently outperforms existing methods on USE, and validate the important
role of dialogue act sequences in USE.</p>
  </details>
</details>
<details>
  <summary>17. <b>标题：Evaluating natural language processing models with generalization  metrics that do not need access to any training or testing data</b></summary>
  <p><b>编号</b>：[230]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02842</p>
  <p><b>作者</b>：Yaoqing Yang,  Ryan Theisen,  Liam Hodgkinson,  Joseph E. Gonzalez,  Kannan Ramchandran,  Charles H. Martin,  Michael W. Mahoney</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：among forty generalization metrics studied, received comparatively less attention, predict test error instead, exponentially truncated power law, detailed empirical studies show</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The search for effective and robust generalization metrics has been the focus
of recent theoretical and empirical work.
In this paper, we discuss the performance of natural language processing
(NLP) models, and we evaluate various existing and novel generalization
metrics.
Compared to prior studies, we
(i) focus on NLP instead of computer vision (CV),
(ii) focus on generalization metrics that predict test error instead of the
generalization gap,
(iii) focus on generalization metrics that do not need the access to data,
and
(iv) focus on the heavy-tail (HT) phenomenon that has received comparatively
less attention in the study of deep neural networks (NNs).
We extend recent HT-based work which focuses on power law (PL) distributions,
and we study exponential (EXP) and exponentially truncated power law (E-TPL)
fitting to the empirical spectral densities (ESDs) of weight matrices.
Our detailed empirical studies show that
(i) \emph{shape metrics}, or the metrics obtained from fitting the shape of
the ESDs, perform uniformly better at predicting generalization performance
than \emph{scale metrics} commonly studied in the literature, as measured by
the \emph{average} rank correlations with the generalization performance for
all of our experiments;
(ii) among forty generalization metrics studied in our paper, the
\RANDDISTANCE metric, a new shape metric invented in this paper that measures
the distance between empirical eigenvalues of weight matrices and those of
randomly initialized weight matrices, achieves the highest worst-case rank
correlation with generalization performance under a variety of training
settings; and
(iii) among the three HT distributions considered in our paper, the E-TPL
fitting of ESDs performs the most robustly.</p>
  </details>
</details>
<details>
  <summary>18. <b>标题：How Effective is Incongruity? Implications for Code-mix Sarcasm  Detection</b></summary>
  <p><b>编号</b>：[279]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02702</p>
  <p><b>作者</b>：Aditya Shah,  Chandresh Kumar Maurya</p>
  <p><b>备注</b>：Published in ICON - ACL 2021</p>
  <p><b>关键词</b>：word level embeddings learned via fasttext, social media like chatbots, proposed model achieves f1, mix hinglish dataset comparable, training 10x faster</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The presence of sarcasm in conversational systems and social media like
chatbots, Facebook, Twitter, etc. poses several challenges for downstream NLP
tasks. This is attributed to the fact that the intended meaning of a sarcastic
text is contrary to what is expressed. Further, the use of code-mix language to
express sarcasm is increasing day by day. Current NLP techniques for code-mix
data have limited success due to the use of different lexicon, syntax, and
scarcity of labeled corpora. To solve the joint problem of code-mixing and
sarcasm detection, we propose the idea of capturing incongruity through
sub-word level embeddings learned via fastText. Empirical results shows that
our proposed model achieves F1-score on code-mix Hinglish dataset comparable to
pretrained multilingual models while training 10x faster and using a lower
memory footprint</p>
  </details>
</details>
<details>
  <summary>19. <b>标题：No Parameters Left Behind: Sensitivity Guided Adaptive Learning Rate for  Training Large Transformer Models</b></summary>
  <p><b>编号</b>：[297]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02664</p>
  <p><b>作者</b>：Chen Liang,  Haoming Jiang,  Simiao Zuo,  Pengcheng He,  Xiaodong Liu,  Jianfeng Gao,  Weizhu Chen,  Tuo Zhao</p>
  <p><b>备注</b>：Proceedings of ICLR 2022</p>
  <p><b>关键词</b>：redundant parameters without significantly sacrificing, proposed schedule indeed reduces, redundant parameters could, novel training strategy, neural machine translation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent research has shown the existence of significant redundancy in large
Transformer models. One can prune the redundant parameters without
significantly sacrificing the generalization performance. However, we question
whether the redundant parameters could have contributed more if they were
properly trained. To answer this question, we propose a novel training strategy
that encourages all parameters to be trained sufficiently. Specifically, we
adaptively adjust the learning rate for each parameter according to its
sensitivity, a robust gradient-based measure reflecting this parameter's
contribution to the model performance. A parameter with low sensitivity is
redundant, and we improve its fitting by increasing its learning rate. In
contrast, a parameter with high sensitivity is well-trained, and we regularize
it by decreasing its learning rate to prevent further overfitting. We conduct
extensive experiments on natural language understanding, neural machine
translation, and image classification to demonstrate the effectiveness of the
proposed schedule. Analysis shows that the proposed schedule indeed reduces the
redundancy and improves generalization performance.</p>
  </details>
</details>
<details>
  <summary>20. <b>标题：Ethics, Rules of Engagement, and AI: Neural Narrative Mapping Using  Large Transformer Language Models</b></summary>
  <p><b>编号</b>：[306]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02647</p>
  <p><b>作者</b>：Philip Feldman,  Aaron Dant,  David Rosenbluth</p>
  <p><b>备注</b>：18 Pages, 13 figures</p>
  <p><b>关键词</b>：bedeviled military planners throughout history, series offers new possibilities, demonstrate new ways, turn provide means, large language models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The problem of determining if a military unit has correctly understood an
order and is properly executing on it is one that has bedeviled military
planners throughout history. The advent of advanced language models such as
OpenAI's GPT-series offers new possibilities for addressing this problem. This
paper presents a mechanism to harness the narrative output of large language
models and produce diagrams or "maps" of the relationships that are latent in
the weights of such models as the GPT-3. The resulting "Neural Narrative Maps"
(NNMs), are intended to provide insight into the organization of information,
opinion, and belief in the model, which in turn provide means to understand
intent and response in the context of physical distance. This paper discusses
the problem of mapping information spaces in general, and then presents a
concrete implementation of this concept in the context of OpenAI's GPT-3
language model for determining if a subordinate is following a commander's
intent in a high-risk situation. The subordinate's locations within the NNM
allow a novel capability to evaluate the intent of the subordinate with respect
to the commander. We show that is is possible not only to determine if they are
nearby in narrative space, but also how they are oriented, and what
"trajectory" they are on. Our results show that our method is able to produce
high-quality maps, and demonstrate new ways of evaluating intent more
generally.</p>
  </details>
</details>
<details>
  <summary>21. <b>标题：RerrFact: Reduced Evidence Retrieval Representations for Scientific  Claim Verification</b></summary>
  <p><b>编号</b>：[307]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02646</p>
  <p><b>作者</b>：Ashish Rana,  Deepanshu Khanna,  Muskaan Singh,  Tirthankar Ghosal,  Harpreet Singh,  Prashant Singh Rana</p>
  <p><b>备注</b>：Accepted in the AAAI-22 Workshop on Scientific Document Understanding at the Thirty-Sixth AAAI Conference on Artificial Intelligence (SDU@AAAI-22)</p>
  <p><b>关键词</b>：develop automatic scientific claim verification systems via extracting, based approach uses reduced abstract representations, scientific claim verification requires, model parameters fairs competitively, assimilating relevant evidence rationales</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Exponential growth in digital information outlets and the race to publish has
made scientific misinformation more prevalent than ever. However, the task to
fact-verify a given scientific claim is not straightforward even for
researchers. Scientific claim verification requires in-depth knowledge and
great labor from domain experts to substantiate supporting and refuting
evidence from credible scientific sources. The SciFact dataset and
corresponding task provide a benchmarking leaderboard to the community to
develop automatic scientific claim verification systems via extracting and
assimilating relevant evidence rationales from source abstracts. In this work,
we propose a modular approach that sequentially carries out binary
classification for every prediction subtask as in the SciFact leaderboard. Our
simple classifier-based approach uses reduced abstract representations to
retrieve relevant abstracts. These are further used to train the relevant
rationale-selection model. Finally, we carry out two-step stance predictions
that first differentiate non-relevant rationales and then identify supporting
or refuting rationales for a given claim. Experimentally, our system RerrFact
with no fine-tuning, simple design, and a fraction of model parameters fairs
competitively on the leaderboard against large-scale, modular, and joint
modeling approaches. We make our codebase available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>22. <b>标题：Classification on Sentence Embeddings for Legal Assistance</b></summary>
  <p><b>编号</b>：[310]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02639</p>
  <p><b>作者</b>：Arka Mitra</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：information retrieval evaluation )., legal proceedings take plenty, team legalnlp obtained, rhetorical roles .", 7 predefined labels</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Legal proceedings take plenty of time and also cost a lot. The lawyers have
to do a lot of work in order to identify the different sections of prior cases
and statutes. The paper tries to solve the first tasks in AILA2021 (Artificial
Intelligence for Legal Assistance) that will be held in FIRE2021 (Forum for
Information Retrieval Evaluation). The task is to semantically segment the
document into different assigned one of the 7 predefined labels or "rhetorical
roles." The paper uses BERT to obtain the sentence embeddings from a sentence,
and then a linear classifier is used to output the final prediction. The
experiments show that when more weightage is assigned to the class with the
highest frequency, the results are better than those when more weightage is
given to the class with a lower frequency. In task 1, the team legalNLP
obtained a F1 score of 0.22.</p>
  </details>
</details>
<details>
  <summary>23. <b>标题：Multilingual Hate Speech and Offensive Content Detection using Modified  Cross-entropy Loss</b></summary>
  <p><b>编号</b>：[311]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02635</p>
  <p><b>作者</b>：Arka Mitra,  Priyanshu Sankhala</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：increased social media users, hindi corpora performs better, english subtask b respectively, team achieved macro f1, hindi subtask b</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The number of increased social media users has led to a lot of people
misusing these platforms to spread offensive content and use hate speech.
Manual tracking the vast amount of posts is impractical so it is necessary to
devise automated methods to identify them quickly. Large language models are
trained on a lot of data and they also make use of contextual embeddings. We
fine-tune the large language models to help in our task. The data is also quite
unbalanced; so we used a modified cross-entropy loss to tackle the issue. We
observed that using a model which is fine-tuned in hindi corpora performs
better. Our team (HNLP) achieved the macro F1-scores of 0.808, 0.639 in English
Subtask A and English Subtask B respectively. For Hindi Subtask A, Hindi
Subtask B our team achieved macro F1-scores of 0.737, 0.443 respectively in
HASOC 2021.</p>
  </details>
</details>
<details>
  <summary>24. <b>标题：Improving Probabilistic Models in Text Classification via Active  Learning</b></summary>
  <p><b>编号</b>：[313]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02629</p>
  <p><b>作者</b>：Mitchell Bosley,  Saki Kuzushima,  Ted Enamorado,  Yuki Shiraito</p>
  <p><b>备注</b>：27 pages, 6 figures</p>
  <p><b>关键词</b>：historical us supreme court opinions, social scientists often classify documents, human rights abuse allegations, model improves performance relative, iteratively labeling uncertain documents</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>When using text data, social scientists often classify documents in order to
use the resulting document labels as an outcome or predictor. Since it is
prohibitively costly to label a large number of documents manually, automated
text classification has become a standard tool. However, current approaches for
text classification do not take advantage of all the data at one's disposal. We
propose a fast new model for text classification that combines information from
both labeled and unlabeled data with an active learning component, where a
human iteratively labels documents that the algorithm is least certain about.
Using text data from Wikipedia discussion pages, BBC News articles, historical
US Supreme Court opinions, and human rights abuse allegations, we show that by
introducing information about the structure of unlabeled data and iteratively
labeling uncertain documents, our model improves performance relative to
classifiers that (a) only use information from labeled data and (b) randomly
decide which documents to label at the cost of manually labelling a small
number of documents.</p>
  </details>
</details>
<details>
  <summary>25. <b>标题：Adaptive Fine-Tuning of Transformer-Based Language Models for Named  Entity Recognition</b></summary>
  <p><b>编号</b>：[320]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02617</p>
  <p><b>作者</b>：Felix Stollenwerk</p>
  <p><b>备注</b>：28 pages, 19 figures</p>
  <p><b>关键词</b>：linear learning rate schedule, custom learning rate schedule, based language models includes, uses early stopping, optimization hyperparameter space</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The current standard approach for fine-tuning transformer-based language
models includes a fixed number of training epochs and a linear learning rate
schedule. In order to obtain a near-optimal model for the given downstream
task, a search in optimization hyperparameter space is usually required. In
particular, the number of training epochs needs to be adjusted to the dataset
size. In this paper, we introduce adaptive fine-tuning, which is an alternative
approach that uses early stopping and a custom learning rate schedule to
dynamically adjust the number of training epochs to the dataset size. For the
example use case of named entity recognition, we show that our approach not
only makes hyperparameter search with respect to the number of training epochs
redundant, but also leads to improved results in terms of performance,
stability and efficiency. This holds true especially for small datasets, where
we outperform the state-of-the-art fine-tuning method by a large margin.</p>
  </details>
</details>
<details>
  <summary>26. <b>标题：LST: Lexicon-Guided Self-Training for Few-Shot Text Classification</b></summary>
  <p><b>编号</b>：[341]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02566</p>
  <p><b>作者</b>：Hazel Kim,  Jaeman Son,  Yo-Sub Han</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：crafted lexical knowledge achieves 1, 30 labeled samples per class, put overconfident label belief, still rely heavily, predictions initially trained</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Self-training provides an effective means of using an extremely small amount
of labeled data to create pseudo-labels for unlabeled data. Many
state-of-the-art self-training approaches hinge on different regularization
methods to prevent overfitting and improve generalization. Yet they still rely
heavily on predictions initially trained with the limited labeled data as
pseudo-labels and are likely to put overconfident label belief on erroneous
classes depending on the first prediction. To tackle this issue in text
classification, we introduce LST, a simple self-training method that uses a
lexicon to guide the pseudo-labeling mechanism in a linguistically-enriched
manner. We consistently refine the lexicon by predicting confidence of the
unseen data to teach pseudo-labels better in the training iterations. We
demonstrate that this simple yet well-crafted lexical knowledge achieves
1.0-2.0% better performance on 30 labeled samples per class for five benchmark
datasets than the current state-of-the-art approaches.</p>
  </details>
</details>
<details>
  <summary>27. <b>标题：Optimization of a Real-Time Wavelet-Based Algorithm for Improving Speech  Intelligibility</b></summary>
  <p><b>编号</b>：[348]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02545</p>
  <p><b>作者</b>：Tianqu Kang,  Anh-Dung Dinh,  Binghong Wang,  Tianyuan Du,  Yijia Chen,  Kevin Chau (Hong Kong University of Science and Technology)</p>
  <p><b>备注</b>：12 pages, 7 figures, 4 tables</p>
  <p><b>关键词</b>：potential applications include speech enhancement, simulated hearing loss conditions, quantitatively using google speech, overall signal energy unchanged, level discrete wavelet transform</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The optimization of a wavelet-based algorithm to improve speech
intelligibility is reported. The discrete-time speech signal is split into
frequency sub-bands via a multi-level discrete wavelet transform. Various gains
are applied to the sub-band signals before they are recombined to form a
modified version of the speech. The sub-band gains are adjusted while keeping
the overall signal energy unchanged, and the speech intelligibility under
various background interference and simulated hearing loss conditions is
enhanced and evaluated objectively and quantitatively using Google
Speech-to-Text transcription. For English and Chinese noise-free speech,
overall intelligibility is improved, and the transcription accuracy can be
increased by as much as 80 percentage points by reallocating the spectral
energy toward the mid-frequency sub-bands, effectively increasing the
consonant-vowel intensity ratio. This is reasonable since the consonants are
relatively weak and of short duration, which are therefore the most likely to
become indistinguishable in the presence of background noise or high-frequency
hearing impairment. For speech already corrupted by noise, improving
intelligibility is challenging but still realizable. The proposed algorithm is
implementable for real-time signal processing and comparatively simpler than
previous algorithms. Potential applications include speech enhancement, hearing
aids, machine listening, and a better understanding of speech intelligibility.</p>
  </details>
</details>
<details>
  <summary>28. <b>标题：Aspect-based Sentiment Analysis through EDU-level Attentions</b></summary>
  <p><b>编号</b>：[354]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02535</p>
  <p><b>作者</b>：Ting Lin,  Aixin Sun,  Yequan Wang</p>
  <p><b>备注</b>：Accepted in PAKDD2022</p>
  <p><b>关键词</b>：three benchmark datasets show, manual edu boundary annotation, sentence may express sentiments, attention model outperforms state, often adversely affected</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A sentence may express sentiments on multiple aspects. When these aspects are
associated with different sentiment polarities, a model's accuracy is often
adversely affected. We observe that multiple aspects in such hard sentences are
mostly expressed through multiple clauses, or formally known as elementary
discourse units (EDUs), and one EDU tends to express a single aspect with
unitary sentiment towards that aspect. In this paper, we propose to consider
EDU boundaries in sentence modeling, with attentions at both word and EDU
levels. Specifically, we highlight sentiment-bearing words in EDU through
word-level sparse attention. Then at EDU level, we force the model to attend to
the right EDU for the right aspect, by using EDU-level sparse attention and
orthogonal regularization. Experiments on three benchmark datasets show that
our simple EDU-Attention model outperforms state-of-the-art baselines. Because
EDU can be automatically segmented with high accuracy, our model can be applied
to sentences directly without the need of manual EDU boundary annotation.</p>
  </details>
</details>
<details>
  <summary>29. <b>标题：LEAPMood: Light and Efficient Architecture to Predict Mood with Genetic  Algorithm driven Hyperparameter Tuning</b></summary>
  <p><b>编号</b>：[360]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02522</p>
  <p><b>作者</b>：Harichandana B S S,  Sumit Kumar</p>
  <p><b>备注</b>：Accepted at 16th IEEE International Conference on Semantic Computing (ICSC), January 26-28, 2022</p>
  <p><b>关键词</b>：model size (> 90 %), use cases like user profiling, one primary source indicative, device deep learning approach, first building block followed</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Accurate and automatic detection of mood serves as a building block for use
cases like user profiling which in turn power applications such as advertising,
recommendation systems, and many more. One primary source indicative of an
individual's mood is textual data. While there has been extensive research on
emotion recognition, the field of mood prediction has been barely explored. In
addition, very little work is done in the area of on-device inferencing, which
is highly important from the user privacy point of view. In this paper, we
propose for the first time, an on-device deep learning approach for mood
prediction from textual data, LEAPMood. We use a novel on-device
deployment-focused objective function for hyperparameter tuning based on the
Genetic Algorithm (GA) and optimize the parameters concerning both performance
and size. LEAPMood consists of Emotion Recognition in Conversion (ERC) as the
first building block followed by mood prediction using K-means clustering. We
show that using a combination of character embedding, phonetic hashing, and
attention along with Conditional Random Fields (CRF), results in a performance
closely comparable to that of the current State-Of-the-Art with a significant
reduction in model size (> 90%) for the task of ERC. We achieve a Micro F1
score of 62.05% with a memory footprint of a mere 1.67MB on the DailyDialog
dataset. Furthermore, we curate a dataset for the task of mood prediction
achieving a Macro F1-score of 72.12% with LEAPMood.</p>
  </details>
</details>
<details>
  <summary>30. <b>标题：A Survey on Automated Sarcasm Detection on Twitter</b></summary>
  <p><b>编号</b>：[364]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02516</p>
  <p><b>作者</b>：Bleau Moores,  Vijay Mago</p>
  <p><b>备注</b>：33 pages, 14 figures</p>
  <p><b>关键词</b>：shift towards deep learning methods, machine learning models, current methods used, social media platforms, discrete features combined</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Automatic sarcasm detection is a growing field in computer science. Short
text messages are increasingly used for communication, especially over social
media platforms such as Twitter. Due to insufficient or missing context,
unidentified sarcasm in these messages can invert the meaning of a statement,
leading to confusion and communication failures. This paper covers a variety of
current methods used for sarcasm detection, including detection by context,
posting history and machine learning models. Additionally, a shift towards deep
learning methods is observable, likely due to the benefit of using a model with
induced instead of discrete features combined with the innovation of
transformers.</p>
  </details>
</details>
<details>
  <summary>31. <b>标题：A simple language-agnostic yet very strong baseline system for hate  speech and offensive content identification</b></summary>
  <p><b>编号</b>：[366]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02511</p>
  <p><b>作者</b>：Yves Bestgen</p>
  <p><b>备注</b>：A slightly modified version of the paper: "A simple language-agnostic yet strong baseline system for hate speech and offensive content identification. In Working Notes of FIRE 2021 - Forum for Information Retrieval Evaluation (10 p.). ceur-ws.org</p>
  <p><b>关键词</b>：develop deep learning approaches relying, outperforming many deep learning approaches, multilingual hasoc 2021 challenge, many external linguistic resources, automatically identifying hate speech</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>For automatically identifying hate speech and offensive content in tweets, a
system based on a classical supervised algorithm only fed with character
n-grams, and thus completely language-agnostic, is proposed by the SATLab team.
After its optimization in terms of the feature weighting and the classifier
parameters, it reached, in the multilingual HASOC 2021 challenge, a medium
performance level in English, the language for which it is easy to develop deep
learning approaches relying on many external linguistic resources, but a far
better level for the two less resourced language, Hindi and Marathi. It ends
even first when performances are averaged over the three tasks in these
languages, outperforming many deep learning approaches. These performances
suggest that it is an interesting reference level to evaluate the benefits of
using more complex approaches such as deep learning or taking into account
complementary resources.</p>
  </details>
</details>
<details>
  <summary>32. <b>标题：Semantic Similarity Computing Model Based on Multi Model Fine-Grained  Nonlinear Fusion</b></summary>
  <p><b>编号</b>：[381]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02476</p>
  <p><b>作者</b>：Peiying Zhang,  Xingzhe Huang,  Yaqi Wang,  Chunxiao Jiang,  Shuqing He,  Haifeng Wang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：statistical sentence similarity evaluation algorithm reduces, sentence similarity calculation method based, fully connected neural network, multi model nonlinear fusion, multi model nonlinear fusion</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Natural language processing (NLP) task has achieved excellent performance in
many fields, including semantic understanding, automatic summarization, image
recognition and so on. However, most of the neural network models for NLP
extract the text in a fine-grained way, which is not conducive to grasp the
meaning of the text from a global perspective. To alleviate the problem, the
combination of the traditional statistical method and deep learning model as
well as a novel model based on multi model nonlinear fusion are proposed in
this paper. The model uses the Jaccard coefficient based on part of speech,
Term Frequency-Inverse Document Frequency (TF-IDF) and word2vec-CNN algorithm
to measure the similarity of sentences respectively. According to the
calculation accuracy of each model, the normalized weight coefficient is
obtained and the calculation results are compared. The weighted vector is input
into the fully connected neural network to give the final classification
results. As a result, the statistical sentence similarity evaluation algorithm
reduces the granularity of feature extraction, so it can grasp the sentence
features globally. Experimental results show that the matching of sentence
similarity calculation method based on multi model nonlinear fusion is 84%, and
the F1 value of the model is 75%.</p>
  </details>
</details>
<details>
  <summary>33. <b>标题：Neural Logic Analogy Learning</b></summary>
  <p><b>编号</b>：[403]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02436</p>
  <p><b>作者</b>：Yujia Fan,  Yongfeng Zhang</p>
  <p><b>备注</b>：11 pages, 1 figure, 3 tables</p>
  <p><b>关键词</b>：model builds computational graph integrating neural network, main idea behind current approaches, based noan approach outperforms state, problem makes current approaches unable, propose neural logic analogy learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Letter-string analogy is an important analogy learning task which seems to be
easy for humans but very challenging for machines. The main idea behind current
approaches to solving letter-string analogies is to design heuristic rules for
extracting analogy structures and constructing analogy mappings. However, one
key problem is that it is difficult to build a comprehensive and exhaustive set
of analogy structures which can fully describe the subtlety of analogies. This
problem makes current approaches unable to handle complicated letter-string
analogy problems. In this paper, we propose Neural logic analogy learning
(Noan), which is a dynamic neural architecture driven by differentiable logic
reasoning to solve analogy problems. Each analogy problem is converted into
logical expressions consisting of logical variables and basic logical
operations (AND, OR, and NOT). More specifically, Noan learns the logical
variables as vector embeddings and learns each logical operation as a neural
module. In this way, the model builds computational graph integrating neural
network with logical reasoning to capture the internal logical structure of the
input letter strings. The analogy learning problem then becomes a True/False
evaluation problem of the logical expressions. Experiments show that our
machine learning-based Noan approach outperforms state-of-the-art approaches on
standard letter-string analogy benchmark datasets.</p>
  </details>
</details>
<details>
  <summary>34. <b>标题：Transformers and the representation of biomedical background knowledge</b></summary>
  <p><b>编号</b>：[406]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02432</p>
  <p><b>作者</b>：Oskar Wysocki (1,2),  Zili Zhou (1,2),  Paul O'Regan (2),  Deborah Ferreira (1),  Magdalena Wysocka (2),  Dónal Landers (2),  André Freitas (1,2,3) ((1) Department of Computer Science, The University of Manchester, (2) digital Experimental Cancer Medicine Team, Cancer Biomarker Centre, CRUK Manchester Institute, University of Manchester, (3) Idiap Research Institute)</p>
  <p><b>备注</b>：22 pages, 12 figures, supplementary methods, tables and figures at the end of the manuscript</p>
  <p><b>关键词</b>：publicly available biomedical corpora, indeed encode biological knowledge, biomedical domain based, scale biological knowledge, different transformer baselines</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>BioBERT and BioMegatron are Transformers models adapted for the biomedical
domain based on publicly available biomedical corpora. As such, they have the
potential to encode large-scale biological knowledge. We investigate the
encoding and representation of biological knowledge in these models, and its
potential utility to support inference in cancer precision medicine - namely,
the interpretation of the clinical significance of genomic alterations. We
compare the performance of different transformer baselines; we use probing to
determine the consistency of encodings for distinct entities; and we use
clustering methods to compare and contrast the internal properties of the
embeddings for genes, variants, drugs and diseases. We show that these models
do indeed encode biological knowledge, although some of this is lost in
fine-tuning for specific tasks. Finally, we analyse how the models behave with
regard to biases and imbalances in the dataset.</p>
  </details>
</details>
<details>
  <summary>35. <b>标题：Pirá: A Bilingual Portuguese-English Dataset for Question-Answering  about the Ocean</b></summary>
  <p><b>编号</b>：[421]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02398</p>
  <p><b>作者</b>：André F. A. Paschoal,  Paulo Pirozelli,  Valdinei Freire,  Karina V. Delgado,  Sarajane M. Peres,  Marcos M. José,  Flávio Nakasato,  André S. Oliveira,  Anarosa A. F. Brandão,  Anna H. R. Costa,  Fabio G. Cozman</p>
  <p><b>备注</b>：this https URL</p>
  <p><b>关键词</b>：2261 properly curated question, first bilingual qa dataset, united nation reports, manually created based, first qa dataset</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Current research in natural language processing is highly dependent on
carefully produced corpora. Most existing resources focus on English; some
resources focus on languages such as Chinese and French; few resources deal
with more than one language. This paper presents the Pirá dataset, a large
set of questions and answers about the ocean and the Brazilian coast both in
Portuguese and English. Pirá is, to the best of our knowledge, the first QA
dataset with supporting texts in Portuguese, and, perhaps more importantly, the
first bilingual QA dataset that includes this language. The Pirá dataset
consists of 2261 properly curated question/answer (QA) sets in both languages.
The QA sets were manually created based on two corpora: abstracts related to
the Brazilian coast and excerpts of United Nation reports about the ocean. The
QA sets were validated in a peer-review process with the dataset contributors.
We discuss some of the advantages as well as limitations of Pirá, as this new
resource can support a set of tasks in NLP such as question-answering,
information retrieval, and machine translation.</p>
  </details>
</details>
<details>
  <summary>36. <b>标题：JARVix at SemEval-2022 Task 2: It Takes One to Know One? Idiomaticity  Detection using Zero and One Shot Learning</b></summary>
  <p><b>编号</b>：[425]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02394</p>
  <p><b>作者</b>：Ashwin Pathak,  Raj Shah,  Vaibhav Kumar,  Yash Jakhotiya</p>
  <p><b>备注</b>：Best Project Award for Georgia Tech CS 7650. Code available at this https URL</p>
  <p><b>关键词</b>：train multiple large language models, natural language processing tasks, large language models, given sentence contains, vector representations fail</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large Language Models have been successful in a wide variety of Natural
Language Processing tasks by capturing the compositionality of the text
representations. In spite of their great success, these vector representations
fail to capture meaning of idiomatic multi-word expressions (MWEs). In this
paper, we focus on the detection of idiomatic expressions by using binary
classification. We use a dataset consisting of the literal and idiomatic usage
of MWEs in English and Portuguese. Thereafter, we perform the classification in
two different settings: zero shot and one shot, to determine if a given
sentence contains an idiom or not. N shot classification for this task is
defined by N number of common idioms between the training and testing sets. In
this paper, we train multiple Large Language Models in both the settings and
achieve an F1 score (macro) of 0.73 for the zero shot setting and an F1 score
(macro) of 0.85 for the one shot setting. An implementation of our work can be
found at
this https URL .</p>
  </details>
</details>
<h1>机器学习</h1>
<details>
  <summary>1. <b>标题：Diversify and Disambiguate: Learning From Underspecified Data</b></summary>
  <p><b>编号</b>：[1]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03418</p>
  <p><b>作者</b>：Yoonho Lee,  Huaxiu Yao,  Chelsea Finn</p>
  <p><b>备注</b>：Preprint</p>
  <p><b>关键词</b>：discovered hypotheses using minimal additional supervision, several equally viable solutions, natural language processing problems, achieve low training loss, widely varying predictions</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Many datasets are underspecified, which means there are several equally
viable solutions for the data. Underspecified datasets can be problematic for
methods that learn a single hypothesis because different functions that achieve
low training loss can focus on different predictive features and thus have
widely varying predictions on out-of-distribution data. We propose DivDis, a
simple two-stage framework that first learns a diverse collection of hypotheses
for a task by leveraging unlabeled data from the test distribution. We then
disambiguate by selecting one of the discovered hypotheses using minimal
additional supervision, in the form of additional labels or inspection of
function visualization. We demonstrate the ability of DivDis to find hypotheses
that use robust features in image classification and natural language
processing problems with underspecification.</p>
  </details>
</details>
<details>
  <summary>2. <b>标题：Deep Impulse Responses: Estimating and Parameterizing Filters with Deep  Networks</b></summary>
  <p><b>编号</b>：[2]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03416</p>
  <p><b>作者</b>：Alexander Richard,  Peter Dodds,  Vamsi Krishna Ithapu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：carefully designed neural network, estimating impulse responses based, interpolate impulse responses, world speech data, underlying data distributions</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Impulse response estimation in high noise and in-the-wild settings, with
minimal control of the underlying data distributions, is a challenging problem.
We propose a novel framework for parameterizing and estimating impulse
responses based on recent advances in neural representation learning. Our
framework is driven by a carefully designed neural network that jointly
estimates the impulse response and the (apriori unknown) spectral noise
characteristics of an observed signal given the source signal. We demonstrate
robustness in estimation, even under low signal-to-noise ratios, and show
strong results when learning from spatio-temporal real-world speech data. Our
framework provides a natural way to interpolate impulse responses on a spatial
grid, while also allowing for efficiently compressing and storing them for
real-time rendering applications in augmented and virtual reality.</p>
  </details>
</details>
<details>
  <summary>3. <b>标题：Preserving Privacy and Security in Federated Learning</b></summary>
  <p><b>编号</b>：[5]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03402</p>
  <p><b>作者</b>：Truc Nguyen,  My T. Thai</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：identify poisoned model updates without violating, federated learning using homomorphic encryption, central server without revealing, new secure aggregation protocol, knowledge proof protocol</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Federated learning is known to be vulnerable to security and privacy issues.
Existing research has focused either on preventing poisoning attacks from users
or on protecting user privacy of model updates. However, integrating these two
lines of research remains a crucial challenge since they often conflict with
one another with respect to the threat model.
In this work, we develop a framework to combine secure aggregation with
defense mechanisms against poisoning attacks from users, while maintaining
their respective privacy guarantees. We leverage zero-knowledge proof protocol
to let users run the defense mechanisms locally and attest the result to the
central server without revealing any information about their model updates.
Furthermore, we propose a new secure aggregation protocol for federated
learning using homomorphic encryption that is robust against malicious users.
Our framework enables the central server to identify poisoned model updates
without violating the privacy guarantees of secure aggregation. Finally, we
analyze the computation and communication complexity of our proposed solution
and benchmark its performance.</p>
  </details>
</details>
<details>
  <summary>4. <b>标题：Link Prediction of Artificial Intelligence Concepts using Low  Computational Power</b></summary>
  <p><b>编号</b>：[7]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03393</p>
  <p><b>作者</b>：Francisco Valente</p>
  <p><b>备注</b>：Solution awarded a special prize in the Science4cast 2021 competition. Presented and published in the IEEE Big Data 2021 conference. Minor text improvements and typos corrected from the published version</p>
  <p><b>关键词</b>：low order topological features, low computational power, whose main goal, science4cast 2021 competition, machine learning concepts</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper presents an approach proposed for the Science4cast 2021
competition, organized by the Institute of Advanced Research in Artificial
Intelligence, whose main goal was to predict the likelihood of future
associations between machine learning concepts in a semantic network. The
developed methodology corresponds to a solution for a scenario of availability
of low computational power only, exploiting the extraction of low order
topological features and its incorporation in an optimized classifier to
estimate the degree of future connections between the nodes. The reasons that
motivated the developed methodologies will be discussed, as well as some
results, limitations and suggestions of improvements.</p>
  </details>
</details>
<details>
  <summary>5. <b>标题：Gradient-Based Learning of Discrete Structured Measurement Operators for  Signal Recovery</b></summary>
  <p><b>编号</b>：[9]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03391</p>
  <p><b>作者</b>：Jonathan Sauder,  Martin Genzel,  Peter Jung</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：learned measurement matrices outperform conventional designs based, countless signal processing applications include, several prototypical signal recovery applications, often even discrete optimization task, discrete structured measurement operators ).</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Countless signal processing applications include the reconstruction of
signals from few indirect linear measurements. The design of effective
measurement operators is typically constrained by the underlying hardware and
physics, posing a challenging and often even discrete optimization task. While
the potential of gradient-based learning via the unrolling of iterative
recovery algorithms has been demonstrated, it has remained unclear how to
leverage this technique when the set of admissible measurement operators is
structured and discrete. We tackle this problem by combining unrolled
optimization with Gumbel reparametrizations, which enable the computation of
low-variance gradient estimates of categorical random variables. Our approach
is formalized by GLODISMO (Gradient-based Learning of DIscrete Structured
Measurement Operators). This novel method is easy-to-implement, computationally
efficient, and extendable due to its compatibility with automatic
differentiation. We empirically demonstrate the performance and flexibility of
GLODISMO in several prototypical signal recovery applications, verifying that
the learned measurement matrices outperform conventional designs based on
randomization as well as discrete optimization baselines.</p>
  </details>
</details>
<details>
  <summary>6. <b>标题：GMC -- Geometric Multimodal Contrastive Representation Learning</b></summary>
  <p><b>编号</b>：[10]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03390</p>
  <p><b>作者</b>：Petra Poklukar,  Miguel Vasco,  Hang Yin,  Francisco S. Melo,  Ana Paiva,  Danica Kragic</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：three different learning problems including prediction, multimodal contrastive loss function, representation learning method comprised, novel geometric multimodal contrastive, reinforcement learning tasks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Learning representations of multimodal data that are both informative and
robust to missing modalities at test time remains a challenging problem due to
the inherent heterogeneity of data obtained from different channels. To address
it, we present a novel Geometric Multimodal Contrastive (GMC) representation
learning method comprised of two main components: i) a two-level architecture
consisting of modality-specific base encoder, allowing to process an arbitrary
number of modalities to an intermediate representation of fixed dimensionality,
and a shared projection head, mapping the intermediate representations to a
latent representation space; ii) a multimodal contrastive loss function that
encourages the geometric alignment of the learned representations. We
experimentally demonstrate that GMC representations are semantically rich and
achieve state-of-the-art performance with missing modality information on three
different learning problems including prediction and reinforcement learning
tasks.</p>
  </details>
</details>
<details>
  <summary>7. <b>标题：Hybrid Contrastive Quantization for Efficient Cross-View Video Retrieval</b></summary>
  <p><b>编号</b>：[13]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03384</p>
  <p><b>作者</b>：Jinpeng Wang,  Bin Chen,  Dongliang Liao,  Ziyun Zeng,  Gongfu Li,  Shu-Tao Xia,  Jin Xu</p>
  <p><b>备注</b>：Accepted to The Web Conference 2022 (WWW'22). 11 pages, 5 tables, 6 figures</p>
  <p><b>关键词</b>：web search engines widely apply vector compression libraries, tiktok ), video retrieval using sentence queries, three web video benchmark datasets demonstrate, first quantized representation learning method, preserve comprehensive semantic information</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>With the recent boom of video-based social platforms (e.g., YouTube and
TikTok), video retrieval using sentence queries has become an important demand
and attracts increasing research attention. Despite the decent performance,
existing text-video retrieval models in vision and language communities are
impractical for large-scale Web search because they adopt brute-force search
based on high-dimensional embeddings. To improve efficiency, Web search engines
widely apply vector compression libraries (e.g., FAISS) to post-process the
learned embeddings. Unfortunately, separate compression from feature encoding
degrades the robustness of representations and incurs performance decay. To
pursue a better balance between performance and efficiency, we propose the
first quantized representation learning method for cross-view video retrieval,
namely Hybrid Contrastive Quantization (HCQ). Specifically, HCQ learns both
coarse-grained and fine-grained quantizations with transformers, which provide
complementary understandings for texts and videos and preserve comprehensive
semantic information. By performing Asymmetric-Quantized Contrastive Learning
(AQ-CL) across views, HCQ aligns texts and videos at coarse-grained and
multiple fine-grained levels. This hybrid-grained learning strategy serves as
strong supervision on the cross-view video quantization model, where
contrastive learning at different levels can be mutually promoted. Extensive
experiments on three Web video benchmark datasets demonstrate that HCQ achieves
competitive performance with state-of-the-art non-compressed retrieval methods
while showing high efficiency in storage and computation. Code and
configurations are available at this https URL.</p>
  </details>
</details>
<details>
  <summary>8. <b>标题：Corrupted Image Modeling for Self-Supervised Visual Pre-Training</b></summary>
  <p><b>编号</b>：[14]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03382</p>
  <p><b>作者</b>：Yuxin Fang,  Li Dong,  Hangbo Bao,  Xinggang Wang,  Furu Wei</p>
  <p><b>备注</b>：Preprint. Work in progress. Code will be released at this https URL</p>
  <p><b>关键词</b>：learn rich visual representations using, using artificial mask tokens, approach achieves compelling results, introduce corrupted image modeling, 1k image classification respectively</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We introduce Corrupted Image Modeling (CIM) for self-supervised visual
pre-training. CIM uses an auxiliary generator with a small trainable BEiT to
corrupt the input image instead of using artificial mask tokens, where some
patches are randomly selected and replaced with plausible alternatives sampled
from the BEiT output distribution. Given this corrupted image, an enhancer
network learns to either recover all the original image pixels, or predict
whether each visual token is replaced by a generator sample or not. The
generator and the enhancer are simultaneously trained and synergistically
updated. After pre-training, the enhancer can be used as a high-capacity visual
encoder for downstream tasks. CIM is a general and flexible visual pre-training
framework that is suitable for various network architectures. For the first
time, CIM demonstrates that both ViT and CNN can learn rich visual
representations using a unified, non-Siamese framework. Experimental results
show that our approach achieves compelling results in vision benchmarks, such
as ImageNet classification and ADE20K semantic segmentation. For example,
300-epoch CIM pre-trained vanilla ViT-Base/16 and ResNet-50 obtain 83.3 and
80.6 Top-1 fine-tuning accuracy on ImageNet-1K image classification
respectively.</p>
  </details>
</details>
<details>
  <summary>9. <b>标题：Message Passing Neural PDE Solvers</b></summary>
  <p><b>编号</b>：[16]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03376</p>
  <p><b>作者</b>：Johannes Brandstetter,  Daniel Worrall,  Max Welling</p>
  <p><b>备注</b>：Published at ICLR 2022</p>
  <p><b>关键词</b>：accurate performance across different domain topologies, neural message passing solvers representationally contain, build neural -- numerical hybrid solvers, modern trend towards fully end, optimized neural function approximators</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The numerical solution of partial differential equations (PDEs) is difficult,
having led to a century of research so far. Recently, there have been pushes to
build neural--numerical hybrid solvers, which piggy-backs the modern trend
towards fully end-to-end learned systems. Most works so far can only generalize
over a subset of properties to which a generic solver would be faced,
including: resolution, topology, geometry, boundary conditions, domain
discretization regularity, dimensionality, etc. In this work, we build a
solver, satisfying these properties, where all the components are based on
neural message passing, replacing all heuristically designed components in the
computation graph with backprop-optimized neural function approximators. We
show that neural message passing solvers representationally contain some
classical methods, such as finite differences, finite volumes, and WENO
schemes. In order to encourage stability in training autoregressive models, we
put forward a method that is based on the principle of zero-stability, posing
stability as a domain adaptation problem. We validate our method on various
fluid-like flow problems, demonstrating fast, stable, and accurate performance
across different domain topologies, discretization, etc. in 1D and 2D. Our
model outperforms state-of-the-art numerical solvers in the low resolution
regime in terms of speed and accuracy.</p>
  </details>
</details>
<details>
  <summary>10. <b>标题：Simple Control Baselines for Evaluating Transfer Learning</b></summary>
  <p><b>编号</b>：[19]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03365</p>
  <p><b>作者</b>：Andrei Atanov,  Shijian Xu,  Onur Beker,  Andrei Filatov,  Amir Zamir</p>
  <p><b>备注</b>：Project website: this https URL</p>
  <p><b>关键词</b>：skewed towards image classification tasks versus dense pixel, simple yet critical control baselines, dataset bias ), scratch, communicate transfer learning performance, example empirical study investigating</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Transfer learning has witnessed remarkable progress in recent years, for
example, with the introduction of augmentation-based contrastive
self-supervised learning methods. While a number of large-scale empirical
studies on the transfer performance of such models have been conducted, there
is not yet an agreed-upon set of control baselines, evaluation practices, and
metrics to report, which often hinders a nuanced and calibrated understanding
of the real efficacy of the methods. We share an evaluation standard that aims
to quantify and communicate transfer learning performance in an informative and
accessible setup. This is done by baking a number of simple yet critical
control baselines in the evaluation method, particularly the blind-guess
(quantifying the dataset bias), scratch-model (quantifying the architectural
contribution), and maximal-supervision (quantifying the upper-bound). To
demonstrate how the evaluation standard can be employed, we provide an example
empirical study investigating a few basic questions about self-supervised
learning. For example, using this standard, the study shows the effectiveness
of existing self-supervised pre-training methods is skewed towards image
classification tasks versus dense pixel-wise predictions. In general, we
encourage using/reporting the suggested control baselines in evaluating
transfer learning in order to gain a more meaningful and informative
understanding.</p>
  </details>
</details>
<details>
  <summary>11. <b>标题：Discrete-Event Controller Synthesis for Autonomous Systems with  Deep-Learning Perception Components</b></summary>
  <p><b>编号</b>：[20]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03360</p>
  <p><b>作者</b>：Radu Calinescu (1),  Calum Imrie (1),  Ravi Mangal (2),  Corina Păsăreanu (2),  Misael Alpizar Santana (1),  Gricel Vázquez (1) ((1) University of York, (2) Carnegie Mellon University)</p>
  <p><b>备注</b>：18 pages 6 Figures 2 Tables</p>
  <p><b>关键词</b>：use deep neural network, controller synthesis method addresses, verified markov models, synthesised models correspond, robot collision avoidance</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present DEEPDECS, a new method for the synthesis of
correct-by-construction discrete-event controllers for autonomous systems that
use deep neural network (DNN) classifiers for the perception step of their
decision-making processes. Despite major advances in deep learning in recent
years, providing safety guarantees for these systems remains very challenging.
Our controller synthesis method addresses this challenge by integrating DNN
verification with the synthesis of verified Markov models. The synthesised
models correspond to discrete-event controllers guaranteed to satisfy the
safety, dependability and performance requirements of the autonomous system,
and to be Pareto optimal with respect to a set of optimisation criteria. We use
the method in simulation to synthesise controllers for mobile-robot collision
avoidance, and for maintaining driver attentiveness in shared-control
autonomous driving.</p>
  </details>
</details>
<details>
  <summary>12. <b>标题：Optimal Direct-Connect Topologies for Collective Communications</b></summary>
  <p><b>编号</b>：[21]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03356</p>
  <p><b>作者</b>：Liangyu Zhao,  Siddharth Pal,  Tapan Chugh,  Weiyang Wang,  Prithwish Basu,  Joud Khoury,  Arvind Krishnamurthy</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：schedules provide significant performance benefits, synthesize many different topologies, derive much larger topologies, distilling optimal network topologies, existing collective communications implementations</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We consider the problem of distilling optimal network topologies for
collective communications. We provide an algorithmic framework for constructing
direct-connect topologies optimized for the latency-bandwidth tradeoff given a
collective communication workload. Our algorithmic framework allows us to start
from small base topologies and associated communication schedules and use a set
of techniques that can be iteratively applied to derive much larger topologies
and associated schedules. Our approach allows us to synthesize many different
topologies and schedules for a given cluster size and degree constraint, and
then identify the optimal topology for a given workload. We provide an
analytical-model-based evaluation of the derived topologies and results on a
small-scale optical testbed that uses patch panels for configuring a topology
for the duration of an application's execution. We show that the derived
topologies and schedules provide significant performance benefits over existing
collective communications implementations.</p>
  </details>
</details>
<details>
  <summary>13. <b>标题：Conditional Gradients for the Approximately Vanishing Ideal</b></summary>
  <p><b>编号</b>：[25]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03349</p>
  <p><b>作者</b>：E. Wirth,  S. Pokutta</p>
  <p><b>备注</b>：22 pages</p>
  <p><b>关键词</b>：conditional gradients approximately vanishing ideal algorithm, generators captures polynomial structures, approximately vanishing ideal, approximately vanishing ideal, sparse coefficient vectors</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The vanishing ideal of a set of points $X\subseteq \mathbb{R}^n$ is the set
of polynomials that evaluate to $0$ over all points $\mathbf{x} \in X$ and
admits an efficient representation by a finite set of polynomials called
generators. To accommodate the noise in the data set, we introduce the
Conditional Gradients Approximately Vanishing Ideal algorithm (CGAVI) for the
construction of the set of generators of the approximately vanishing ideal. The
constructed set of generators captures polynomial structures in data and gives
rise to a feature map that can, for example, be used in combination with a
linear classifier for supervised learning. In CGAVI, we construct the set of
generators by solving specific instances of (constrained) convex optimization
problems with the Pairwise Frank-Wolfe algorithm (PFW). Among other things, the
constructed generators inherit the LASSO generalization bound and not only
vanish on the training but also on out-sample data. Moreover, CGAVI admits a
compact representation of the approximately vanishing ideal by constructing few
generators with sparse coefficient vectors.</p>
  </details>
</details>
<details>
  <summary>14. <b>标题：Failure and success of the spectral bias prediction for Kernel Ridge  Regression: the case of low-dimensional data</b></summary>
  <p><b>编号</b>：[26]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03348</p>
  <p><b>作者</b>：Umberto M. Tomasini,  Antonio Sclocchi,  Matthieu Wyart</p>
  <p><b>备注</b>：34 pages, 11 figures</p>
  <p><b>关键词</b>：,\ chi }( p )\ sim p ^{-\ frac, x )\ sim x_1 ^{\ chi }$., x )=$ sign $( x_1 )$, ,\ chi }( p )$,, ,\ chi }( p )$,</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recently, several theories including the replica method made predictions for
the generalization error of Kernel Ridge Regression. In some regimes, they
predict that the method has a `spectral bias': decomposing the true function
$f^*$ on the eigenbasis of the kernel, it fits well the coefficients associated
with the O(P) largest eigenvalues, where $P$ is the size of the training set.
This prediction works very well on benchmark data sets such as images, yet the
assumptions these approaches make on the data are never satisfied in practice.
To clarify when the spectral bias prediction holds, we first focus on a
one-dimensional model where rigorous results are obtained and then use scaling
arguments to generalize and test our findings in higher dimensions. Our
predictions include the classification case $f(x)=$sign$(x_1)$ with a data
distribution that vanishes at the decision boundary $p(x)\sim x_1^{\chi}$. For
$\chi>0$ and a Laplace kernel, we find that (i) there exists a cross-over ridge
$\lambda^*_{d,\chi}(P)\sim P^{-\frac{1}{d+\chi}}$ such that for $\lambda\gg
\lambda^*_{d,\chi}(P)$, the replica method applies, but not for
$\lambda\ll\lambda^*_{d,\chi}(P)$, (ii) in the ridge-less case, spectral bias
predicts the correct training curve exponent only in the limit
$d\rightarrow\infty$.</p>
  </details>
</details>
<details>
  <summary>15. <b>标题：FrePGAN: Robust Deepfake Detection Using Frequency-level Perturbations</b></summary>
  <p><b>编号</b>：[27]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03347</p>
  <p><b>作者</b>：Yonghyun Jeong,  Doyeon Kim,  Youngmin Ro,  Jongwon Choi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：design new test scenarios varying, generalization across various gan models, various deepfake detectors, unseen gan models, gan models outside</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Various deepfake detectors have been proposed, but challenges still exist to
detect images of unknown categories or GAN models outside of the training
settings. Such issues arise from the overfitting issue, which we discover from
our own analysis and the previous studies to originate from the frequency-level
artifacts in generated images. We find that ignoring the frequency-level
artifacts can improve the detector's generalization across various GAN models,
but it can reduce the model's performance for the trained GAN models. Thus, we
design a framework to generalize the deepfake detector for both the known and
unseen GAN models. Our framework generates the frequency-level perturbation
maps to make the generated images indistinguishable from the real images. By
updating the deepfake detector along with the training of the perturbation
generator, our model is trained to detect the frequency-level artifacts at the
initial iterations and consider the image-level irregularities at the last
iterations. For experiments, we design new test scenarios varying from the
training settings in GAN models, color manipulations, and object categories.
Numerous experiments validate the state-of-the-art performance of our deepfake
detector.</p>
  </details>
</details>
<details>
  <summary>16. <b>标题：Neighbor2Seq: Deep Learning on Massive Graphs by Transforming Neighbors  to Sequences</b></summary>
  <p><b>编号</b>：[29]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03341</p>
  <p><b>作者</b>：Meng Liu,  Shuiwang Ji</p>
  <p><b>备注</b>：Accepted by SDM2022</p>
  <p><b>关键词</b>：achieves superior performance across massive, recursive design inherently leads, modern graph neural networks, general deep learning operations, neighbor2seq naturally endows gnns</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Modern graph neural networks (GNNs) use a message passing scheme and have
achieved great success in many fields. However, this recursive design
inherently leads to excessive computation and memory requirements, making it
not applicable to massive real-world graphs. In this work, we propose the
Neighbor2Seq to transform the hierarchical neighborhood of each node into a
sequence. This novel transformation enables the subsequent mini-batch training
for general deep learning operations, such as convolution and attention, that
are designed for grid-like data and are shown to be powerful in various
domains. Therefore, our Neighbor2Seq naturally endows GNNs with the efficiency
and advantages of deep learning operations on grid-like data by precomputing
the Neighbor2Seq transformations. We evaluate our method on a massive graph,
with more than 111 million nodes and 1.6 billion edges, as well as several
medium-scale graphs. Results show that our proposed method is scalable to
massive graphs and achieves superior performance across massive and
medium-scale graphs. Our code is available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>17. <b>标题：Membership Inference Attacks and Defenses in Neural Network Pruning</b></summary>
  <p><b>编号</b>：[30]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03335</p>
  <p><b>作者</b>：Xiaoyong Yuan,  Lan Zhang</p>
  <p><b>备注</b>：This paper has been conditionally accepted to USENIX Security Symposium 2022. This is an extended version</p>
  <p><b>关键词</b>：reusing training samples pose serious privacy risks due, divergence even varies among different classes, e ., membership inference attacks, eight existing membership inference attacks, attention membership inference attack</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Neural network pruning has been an essential technique to reduce the
computation and memory requirements for using deep neural networks for
resource-constrained devices. Most existing research focuses primarily on
balancing the sparsity and accuracy of a pruned neural network by strategically
removing insignificant parameters and retraining the pruned model. Such efforts
on reusing training samples pose serious privacy risks due to increased
memorization, which, however, has not been investigated yet.
In this paper, we conduct the first analysis of privacy risks in neural
network pruning. Specifically, we investigate the impacts of neural network
pruning on training data privacy, i.e., membership inference attacks. We first
explore the impact of neural network pruning on prediction divergence, where
the pruning process disproportionately affects the pruned model's behavior for
members and non-members. Meanwhile, the influence of divergence even varies
among different classes in a fine-grained manner. Enlighten by such divergence,
we proposed a self-attention membership inference attack against the pruned
neural networks. Extensive experiments are conducted to rigorously evaluate the
privacy impacts of different pruning approaches, sparsity levels, and adversary
knowledge. The proposed attack shows the higher attack performance on the
pruned models when compared with eight existing membership inference attacks.
In addition, we propose a new defense mechanism to protect the pruning process
by mitigating the prediction divergence based on KL-divergence distance, whose
effectiveness has been experimentally demonstrated to effectively mitigate the
privacy risks while maintaining the sparsity and accuracy of the pruned models.</p>
  </details>
</details>
<details>
  <summary>18. <b>标题：Policy Optimization for Stochastic Shortest Path</b></summary>
  <p><b>编号</b>：[31]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03334</p>
  <p><b>作者</b>：Liyu Chen,  Haipeng Luo,  Aviv Rosenberg</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：luo et al ., 2021 )., one key technical contribution, better captures many applications, successful reinforcement learning algorithms, oriented reinforcement learning model</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Policy optimization is among the most popular and successful reinforcement
learning algorithms, and there is increasing interest in understanding its
theoretical guarantees. In this work, we initiate the study of policy
optimization for the stochastic shortest path (SSP) problem, a goal-oriented
reinforcement learning model that strictly generalizes the finite-horizon model
and better captures many applications. We consider a wide range of settings,
including stochastic and adversarial environments under full information or
bandit feedback, and propose a policy optimization algorithm for each setting
that makes use of novel correction terms and/or variants of dilated bonuses
(Luo et al., 2021). For most settings, our algorithm is shown to achieve a
near-optimal regret bound.
One key technical contribution of this work is a new approximation scheme to
tackle SSP problems that we call \textit{stacked discounted approximation} and
use in all our proposed algorithms. Unlike the finite-horizon approximation
that is heavily used in recent SSP algorithms, our new approximation enables us
to learn a near-stationary policy with only logarithmic changes during an
episode and could lead to an exponential improvement in space complexity.</p>
  </details>
</details>
<details>
  <summary>19. <b>标题：Training OOD Detectors in their Natural Habitats</b></summary>
  <p><b>编号</b>：[40]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03299</p>
  <p><b>作者</b>：Julian Katz-Samuels,  Julia Nakhleh,  Robert Nowak,  Yixuan Li</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：recent methods use auxiliary outlier data, leverages wild mixture data --, arises freely upon deploying, machine learning models deployed, common ood detection tasks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Out-of-distribution (OOD) detection is important for machine learning models
deployed in the wild. Recent methods use auxiliary outlier data to regularize
the model for improved OOD detection. However, these approaches make a strong
distributional assumption that the auxiliary outlier data is completely
separable from the in-distribution (ID) data. In this paper, we propose a novel
framework that leverages wild mixture data -- that naturally consists of both
ID and OOD samples. Such wild data is abundant and arises freely upon deploying
a machine learning classifier in their \emph{natural habitats}. Our key idea is
to formulate a constrained optimization problem and to show how to tractably
solve it. Our learning objective maximizes the OOD detection rate, subject to
constraints on the classification error of ID data and on the OOD error rate of
ID examples. We extensively evaluate our approach on common OOD detection tasks
and demonstrate superior performance.</p>
  </details>
</details>
<details>
  <summary>20. <b>标题：Theoretical characterization of uncertainty in high-dimensional linear  classification</b></summary>
  <p><b>编号</b>：[42]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03295</p>
  <p><b>作者</b>：Lucas Clarté,  Bruno Loureiro,  Florent Krzakala,  Lenka Zdeborová</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：approximate message passing algorithm, corresponding posterior probability measure, statistically optimal bayesian classifier, costly monte carlo sampling, dimensional gaussian input data</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Being able to reliably assess not only the accuracy but also the uncertainty
of models' predictions is an important endeavour in modern machine learning.
Even if the model generating the data and labels is known, computing the
intrinsic uncertainty after learning the model from a limited number of samples
amounts to sampling the corresponding posterior probability measure. Such
sampling is computationally challenging in high-dimensional problems and
theoretical results on heuristic uncertainty estimators in high-dimensions are
thus scarce. In this manuscript, we characterise uncertainty for learning from
limited number of samples of high-dimensional Gaussian input data and labels
generated by the probit model. We prove that the Bayesian uncertainty (i.e. the
posterior marginals) can be asymptotically obtained by the approximate message
passing algorithm, bypassing the canonical but costly Monte Carlo sampling of
the posterior. We then provide a closed-form formula for the joint statistics
between the logistic classifier, the uncertainty of the statistically optimal
Bayesian classifier and the ground-truth probit uncertainty. The formula allows
us to investigate calibration of the logistic classifier learning from limited
amount of samples. We discuss how over-confidence can be mitigated by
appropriately regularising, and show that cross-validating with respect to the
loss leads to better calibration than with the 0/1 error.</p>
  </details>
</details>
<details>
  <summary>21. <b>标题：Approximation error of single hidden layer neural networks with fixed  weights</b></summary>
  <p><b>编号</b>：[45]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03289</p>
  <p><b>作者</b>：Vugar Ismailov</p>
  <p><b>备注</b>：16 pages. arXiv admin note: text overlap with arXiv:2005.14125</p>
  <p><b>关键词</b>：single hidden layer neural networks, two fixed weights, paper provides, explicit formula, approximation error</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper provides an explicit formula for the approximation error of single
hidden layer neural networks with two fixed weights.</p>
  </details>
</details>
<details>
  <summary>22. <b>标题：Gaussian Graphical Models as an Ensemble Method for Distributed Gaussian  Processes</b></summary>
  <p><b>编号</b>：[46]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03287</p>
  <p><b>作者</b>：Hamed Jalali,  Gjergji Kasneci</p>
  <p><b>备注</b>：OPT2021: 13th Annual Workshop on Optimization for Machine Learning</p>
  <p><b>关键词</b>：generally yields poor results, new method outperforms, experimental evaluations illustrate, conditional independence assumption, acquire global prediction</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Distributed Gaussian process (DGP) is a popular approach to scale GP to big
data which divides the training data into some subsets, performs local
inference for each partition, and aggregates the results to acquire global
prediction. To combine the local predictions, the conditional independence
assumption is used which basically means there is a perfect diversity between
the subsets. Although it keeps the aggregation tractable, it is often violated
in practice and generally yields poor results. In this paper, we propose a
novel approach for aggregating the Gaussian experts' predictions by Gaussian
graphical model (GGM) where the target aggregation is defined as an unobserved
latent variable and the local predictions are the observed variables. We first
estimate the joint distribution of latent and observed variables using the
Expectation-Maximization (EM) algorithm. The interaction between experts can be
encoded by the precision matrix of the joint distribution and the aggregated
predictions are obtained based on the property of conditional Gaussian
distribution. Using both synthetic and real datasets, our experimental
evaluations illustrate that our new method outperforms other state-of-the-art
DGP approaches.</p>
  </details>
</details>
<details>
  <summary>23. <b>标题：Red Teaming Language Models with Language Models</b></summary>
  <p><b>编号</b>：[47]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03286</p>
  <p><b>作者</b>：Ethan Perez,  Saffron Huang,  Francis Song,  Trevor Cai,  Roman Ring,  John Aslanides,  Amelia Glaese,  Nat McAleese,  Geoffrey Irving</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：generating test cases (" red teaming ") using another lm, prior work identifies harmful behaviors, generated test questions using, based red teaming, hospital phone numbers generated</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Language Models (LMs) often cannot be deployed because of their potential to
harm users in hard-to-predict ways. Prior work identifies harmful behaviors
before deployment by using human annotators to hand-write test cases. However,
human annotation is expensive, limiting the number and diversity of test cases.
In this work, we automatically find cases where a target LM behaves in a
harmful way, by generating test cases ("red teaming") using another LM. We
evaluate the target LM's replies to generated test questions using a classifier
trained to detect offensive content, uncovering tens of thousands of offensive
replies in a 280B parameter LM chatbot. We explore several methods, from
zero-shot generation to reinforcement learning, for generating test cases with
varying levels of diversity and difficulty. Furthermore, we use prompt
engineering to control LM-generated test cases to uncover a variety of other
harms, automatically finding groups of people that the chatbot discusses in
offensive ways, personal and hospital phone numbers generated as the chatbot's
own contact info, leakage of private training data in generated text, and harms
that occur over the course of a conversation. Overall, LM-based red teaming is
one promising tool (among many needed) for finding and fixing diverse,
undesirable LM behaviors before impacting users.</p>
  </details>
</details>
<details>
  <summary>24. <b>标题：Personalized Public Policy Analysis in Social Sciences using  Causal-Graphical Normalizing Flows</b></summary>
  <p><b>编号</b>：[49]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03281</p>
  <p><b>作者</b>：Sourabh Balgi,  Jose M. Pena,  Adel Daoud</p>
  <p><b>备注</b>：9 pages, 3 figures, AAAI-2022: AI for Social Impact track</p>
  <p><b>关键词</b>：relatively closed systems ), p $^ 3, gnf ), facilitating p $^ 3, facilitating p $^ 3, traditional causal effect estimation methods, demonstrating promising empirical performance</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Structural Equation/Causal Models (SEMs/SCMs) are widely used in epidemiology
and social sciences to identify and analyze the average treatment effect (ATE)
and conditional ATE (CATE). Traditional causal effect estimation methods such
as Inverse Probability Weighting (IPW) and more recently
Regression-With-Residuals (RWR) are widely used - as they avoid the challenging
task of identifying the SCM parameters - to estimate ATE and CATE. However,
much work remains before traditional estimation methods can be used for
counterfactual inference, and for the benefit of Personalized Public Policy
Analysis (P$^3$A) in the social sciences. While doctors rely on personalized
medicine to tailor treatments to patients in laboratory settings (relatively
closed systems), P$^3$A draws inspiration from such tailoring but adapts it for
open social systems. In this article, we develop a method for counterfactual
inference that we name causal-Graphical Normalizing Flow (c-GNF), facilitating
P$^3$A. First, we show how c-GNF captures the underlying SCM without making any
assumption about functional forms. Second, we propose a novel dequantization
trick to deal with discrete variables, which is a limitation of normalizing
flows in general. Third, we demonstrate in experiments that c-GNF performs
on-par with IPW and RWR in terms of bias and variance for estimating the ATE,
when the true functional forms are known, and better when they are unknown.
Fourth and most importantly, we conduct counterfactual inference with c-GNFs,
demonstrating promising empirical performance. Because IPW and RWR, like other
traditional methods, lack the capability of counterfactual inference, c-GNFs
will likely play a major role in tailoring personalized treatment, facilitating
P$^3$A, optimizing social interventions - in contrast to the current
`one-size-fits-all' approach of existing methods.</p>
  </details>
</details>
<details>
  <summary>25. <b>标题：On The Empirical Effectiveness of Unrealistic Adversarial Hardening  Against Realistic Adversarial Attacks</b></summary>
  <p><b>编号</b>：[52]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03277</p>
  <p><b>作者</b>：Salijona Dyrmishi,  Salah Ghamizi,  Thibault Simonetto,  Yves Le Traon,  Maxime Cordy</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：evaluate whether unrealistic adversarial examples, makes two major contributions, results reveal discrepancies across, adversarial examples generated, unrealistic adversarial examples</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>While the literature on security attacks and defense of Machine Learning (ML)
systems mostly focuses on unrealistic adversarial examples, recent research has
raised concern about the under-explored field of realistic adversarial attacks
and their implications on the robustness of real-world systems. Our paper paves
the way for a better understanding of adversarial robustness against realistic
attacks and makes two major contributions. First, we conduct a study on three
real-world use cases (text classification, botnet detection, malware
detection)) and five datasets in order to evaluate whether unrealistic
adversarial examples can be used to protect models against realistic examples.
Our results reveal discrepancies across the use cases, where unrealistic
examples can either be as effective as the realistic ones or may offer only
limited improvement. Second, to explain these results, we analyze the latent
representation of the adversarial examples generated with realistic and
unrealistic attacks. We shed light on the patterns that discriminate which
unrealistic examples can be used for effective hardening. We release our code,
datasets and models to support future research in exploring how to reduce the
gap between unrealistic and realistic adversarial attacks.</p>
  </details>
</details>
<details>
  <summary>26. <b>标题：Asynchronous Parallel Incremental Block-Coordinate Descent for  Decentralized Machine Learning</b></summary>
  <p><b>编号</b>：[55]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03263</p>
  <p><b>作者</b>：Hao Chen,  Yu Ye,  Ming Xiao,  Mikael Skoglund</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：simulation results also show, promising emerging paradigm since, first introduce incremental block, bcd method outperforms state, asynchronous parallel incremental bcd</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Machine learning (ML) is a key technique for big-data-driven modelling and
analysis of massive Internet of Things (IoT) based intelligent and ubiquitous
computing. For fast-increasing applications and data amounts, distributed
learning is a promising emerging paradigm since it is often impractical or
inefficient to share/aggregate data to a centralized location from distinct
ones. This paper studies the problem of training an ML model over decentralized
systems, where data are distributed over many user devices and the learning
algorithm run on-device, with the aim of relaxing the burden at a central
entity/server. Although gossip-based approaches have been used for this purpose
in different use cases, they suffer from high communication costs, especially
when the number of devices is large. To mitigate this, incremental-based
methods are proposed. We first introduce incremental block-coordinate descent
(I-BCD) for the decentralized ML, which can reduce communication costs at the
expense of running time. To accelerate the convergence speed, an asynchronous
parallel incremental BCD (API-BCD) method is proposed, where multiple
devices/agents are active in an asynchronous fashion. We derive convergence
properties for the proposed methods. Simulation results also show that our
API-BCD method outperforms state of the art in terms of running time and
communication costs.</p>
  </details>
</details>
<details>
  <summary>27. <b>标题：Theory-inspired Parameter Control Benchmarks for Dynamic Algorithm  Configuration</b></summary>
  <p><b>编号</b>：[56]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03259</p>
  <p><b>作者</b>：André Biedenkapp,  Nguyen Dang,  Martin S. Krejca,  Frank Hutter,  Carola Doerr</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：dedicated training process (" dynamic algorithm configuration "), fly (" parameter control "), dynamic parameter setting problem exist, dynamic algorithm configuration, compute optimal parameter portfolios</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>It has long been observed that the performance of evolutionary algorithms and
other randomized search heuristics can benefit from a non-static choice of the
parameters that steer their optimization behavior. Mechanisms that identify
suitable configurations on the fly ("parameter control") or via a dedicated
training process ("dynamic algorithm configuration") are therefore an important
component of modern evolutionary computation frameworks. Several approaches to
address the dynamic parameter setting problem exist, but we barely understand
which ones to prefer for which applications. As in classical benchmarking,
problem collections with a known ground truth can offer very meaningful
insights in this context. Unfortunately, settings with well-understood control
policies are very rare.
One of the few exceptions for which we know which parameter settings minimize
the expected runtime is the LeadingOnes problem. We extend this benchmark by
analyzing optimal control policies that can select the parameters only from a
given portfolio of possible values. This also allows us to compute optimal
parameter portfolios of a given size. We demonstrate the usefulness of our
benchmarks by analyzing the behavior of the DDQN reinforcement learning
approach for dynamic algorithm configuration.</p>
  </details>
</details>
<details>
  <summary>28. <b>标题：ALM-KD: Knowledge Distillation with noisy labels via adaptive loss  mixing</b></summary>
  <p><b>编号</b>：[59]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03250</p>
  <p><b>作者</b>：Durga Sivasubramanian,  Pradeep Shenoy,  Prathosh AP,  Ganesh Ramakrishnan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：demonstrate performance gains obtained using, adaptive loss mixing scheme, using meta learning, validation metric signalling, specific convex combination</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Knowledge distillation is a technique where the outputs of a pretrained
model, often known as the teacher model is used for training a student model in
a supervised setting. The teacher model outputs being a richer distribution
over labels should improve the student model's performance as opposed to
training with the usual hard labels. However, the label distribution imposed by
the logits of the teacher network may not be always informative and may lead to
poor student performance. We tackle this problem via the use of an adaptive
loss mixing scheme during KD. Specifically, our method learns an
instance-specific convex combination of the teacher-matching and label
supervision objectives, using meta learning on a validation metric signalling
to the student `how much' of KD is to be used. Through a range of experiments
on controlled synthetic data and real-world datasets, we demonstrate
performance gains obtained using our approach in the standard KD setting as
well as in multi-teacher and self-distillation settings.</p>
  </details>
</details>
<details>
  <summary>29. <b>标题：Unsupervised physics-informed disentanglement of multimodal data for  high-throughput scientific discovery</b></summary>
  <p><b>编号</b>：[64]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03242</p>
  <p><b>作者</b>：Nathaniel Trask,  Carianne Martinez,  Kookjin Lee,  Brad Boyce</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：expert decoder imposing inductive biases encoding prior scientific knowledge, metal additive manufacturing demonstrates accurate cross modal inference, multimodal scientific datasets representative, avoiding traditional bottlenecks related, variational inference framework</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We introduce physics-informed multimodal autoencoders (PIMA) - a variational
inference framework for discovering shared information in multimodal scientific
datasets representative of high-throughput testing. Individual modalities are
embedded into a shared latent space and fused through a product of experts
formulation, enabling a Gaussian mixture prior to identify shared features.
Sampling from clusters allows cross-modal generative modeling, with a mixture
of expert decoder imposing inductive biases encoding prior scientific knowledge
and imparting structured disentanglement of the latent space. This approach
enables discovery of fingerprints which may be detected in high-dimensional
heterogeneous datasets, avoiding traditional bottlenecks related to
high-fidelity measurement and characterization. Motivated by accelerated
co-design and optimization of materials manufacturing processes, a dataset of
lattice metamaterials from metal additive manufacturing demonstrates accurate
cross modal inference between images of mesoscale topology and mechanical
stress-strain response.</p>
  </details>
</details>
<details>
  <summary>30. <b>标题：Towards an Analytical Definition of Sufficient Data</b></summary>
  <p><b>编号</b>：[66]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03238</p>
  <p><b>作者</b>：Adam Byerly,  Tatiana Kalganova</p>
  <p><b>备注</b>：17 pages, 36 figures, 7 tables</p>
  <p><b>关键词</b>：reduced dimensional space relative, statistically significant difference, entire training set, certain training samples, samples nearer</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We show that, for each of five datasets of increasing complexity, certain
training samples are more informative of class membership than others. These
samples can be identified a priori to training by analyzing their position in
reduced dimensional space relative to the classes' centroids. Specifically, we
demonstrate that samples nearer the classes' centroids are less informative
than those that are furthest from it. For all five datasets, we show that there
is no statistically significant difference between training on the entire
training set and when excluding up to 2% of the data nearest to each class's
centroid.</p>
  </details>
</details>
<details>
  <summary>31. <b>标题：Introducing the Expohedron for Efficient Pareto-optimal Fairness-Utility  Amortizations in Repeated Rankings</b></summary>
  <p><b>编号</b>：[67]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03237</p>
  <p><b>作者</b>：Till Kletti,  Jean-Michel Renders,  Patrick Loiseau</p>
  <p><b>备注</b>：10 pages, 6 figures, accepted at WSDM'22, February 21-25, 2022, Tempe, AZ, USA</p>
  <p><b>关键词</b>：whose points represent, whole pareto frontier, position based model, approach compares favorably, simple geometrical procedure</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We consider the problem of computing a sequence of rankings that maximizes
consumer-side utility while minimizing producer-side individual unfairness of
exposure. While prior work has addressed this problem using linear or quadratic
programs on bistochastic matrices, such approaches, relying on Birkhoff-von
Neumann (BvN) decompositions, are too slow to be implemented at large scale.
In this paper we introduce a geometrical object, a polytope that we call
expohedron, whose points represent all achievable exposures of items for a
Position Based Model (PBM). We exhibit some of its properties and lay out a
Carathéodory decomposition algorithm with complexity $O(n^2\log(n))$ able to
express any point inside the expohedron as a convex sum of at most $n$
vertices, where $n$ is the number of items to rank. Such a decomposition makes
it possible to express any feasible target exposure as a distribution over at
most $n$ rankings. Furthermore we show that we can use this polytope to recover
the whole Pareto frontier of the multi-objective fairness-utility optimization
problem, using a simple geometrical procedure with complexity $O(n^2\log(n))$.
Our approach compares favorably to linear or quadratic programming baselines in
terms of algorithmic complexity and empirical runtime and is applicable to any
merit that is a non-decreasing function of item relevance. Furthermore our
solution can be expressed as a distribution over only $n$ permutations, instead
of the $(n-1)^2 + 1$ achieved with BvN decompositions. We perform experiments
on synthetic and real-world datasets, confirming our theoretical results.</p>
  </details>
</details>
<details>
  <summary>32. <b>标题：Passive learning to address nonstationarity in virtual flow metering  applications</b></summary>
  <p><b>编号</b>：[68]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03236</p>
  <p><b>作者</b>：Mathilde Hotvedt,  Bjarne Grimstad,  Lars Imsland</p>
  <p><b>备注</b>：35 pages, 9 figures</p>
  <p><b>关键词</b>：virtual flow meter applications due, train virtual flow meters, state virtual flow meters, six different model types, state models typically degrades</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Steady-state process models are common in virtual flow meter applications due
to low computational complexity, and low model development and maintenance
cost. Nevertheless, the prediction performance of steady-state models typically
degrades with time due to the inherent nonstationarity of the underlying
process being modeled. Few studies have investigated how learning methods can
be applied to sustain the prediction accuracy of steady-state virtual flow
meters. This paper explores passive learning, where the model is frequently
calibrated to new data, as a way to address nonstationarity and improve
long-term performance. An advantage with passive learning is that it is
compatible with models used in the industry. Two passive learning methods,
periodic batch learning and online learning, are applied with varying
calibration frequency to train virtual flow meters. Six different model types,
ranging from data-driven to first-principles, are trained on historical
production data from 10 petroleum wells. The results are two-fold: first, in
the presence of frequently arriving measurements, frequent model updating
sustains an excellent prediction performance over time; second, in the presence
of intermittent and infrequently arriving measurements, frequent updating in
addition to the utilization of expert knowledge is essential to increase the
performance accuracy. The investigation may be of interest to experts
developing soft-sensors for nonstationary processes, such as virtual flow
meters.</p>
  </details>
</details>
<details>
  <summary>33. <b>标题：Neural Models for Output-Space Invariance in Combinatorial Problems</b></summary>
  <p><b>编号</b>：[69]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03229</p>
  <p><b>作者</b>：Yatin Nandwani,  Vidit Jain,  Mausam,  Parag Singla</p>
  <p><b>备注</b>：Published as a conference paper at ICLR 2022</p>
  <p><b>关键词</b>：implicitly learning underlying constraints using, three different combinatorial problems demonstrates, recently proposed recurrent relational networks, solve 16 x 16 sudoku, binarized model gives better performance</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recently many neural models have been proposed to solve combinatorial puzzles
by implicitly learning underlying constraints using their solved instances,
such as sudoku or graph coloring (GCP). One drawback of the proposed
architectures, which are often based on Graph Neural Networks (GNN), is that
they cannot generalize across the size of the output space from which variables
are assigned a value, for example, set of colors in a GCP, or board-size in
sudoku. We call the output space for the variables as 'value-set'. While many
works have demonstrated generalization of GNNs across graph size, there has
been no study on how to design a GNN for achieving value-set invariance for
problems that come from the same domain. For example, learning to solve 16 x 16
sudoku after being trained on only 9 x 9 sudokus. In this work, we propose
novel methods to extend GNN based architectures to achieve value-set
invariance. Specifically, our model builds on recently proposed Recurrent
Relational Networks. Our first approach exploits the graph-size invariance of
GNNs by converting a multi-class node classification problem into a binary node
classification problem. Our second approach works directly with multiple
classes by adding multiple nodes corresponding to the values in the value-set,
and then connecting variable nodes to value nodes depending on the problem
initialization. Our experimental evaluation on three different combinatorial
problems demonstrates that both our models perform well on our novel problem,
compared to a generic neural reasoner. Between two of our models, we observe an
inherent trade-off: while the binarized model gives better performance when
trained on smaller value-sets, multi-valued model is much more memory
efficient, resulting in improved performance when trained on larger value-sets,
where binarized model fails to train.</p>
  </details>
</details>
<details>
  <summary>34. <b>标题：Introducing explainable supervised machine learning into interactive  feedback loops for statistical production system</b></summary>
  <p><b>编号</b>：[72]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03212</p>
  <p><b>作者</b>：Carlos Mougan,  George Kanellos,  Johannes Micheler,  Jose Martinez,  Thomas Gottron</p>
  <p><b>备注</b>：Irving Fisher Committee (IFC) - Bank of Italy workshop on Data science in central banking: Applications and tools. arXiv admin note: text overlap with arXiv:2107.08045</p>
  <p><b>关键词</b>：statistical production systems cover multiple steps, national central banks thereby improving, tasks like data quality assurance, explainable ai taxonomy aiming, different explainable ai needs</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Statistical production systems cover multiple steps from the collection,
aggregation, and integration of data to tasks like data quality assurance and
dissemination. While the context of data quality assurance is one of the most
promising fields for applying machine learning, the lack of curated and labeled
training data is often a limiting factor.
The statistical production system for the Centralised Securities Database
features an interactive feedback loop between data collected by the European
Central Bank and data quality assurance performed by data quality managers at
National Central Banks. The quality assurance feedback loop is based on a set
of rule-based checks for raising exceptions, upon which the user either
confirms the data or corrects an actual error.
In this paper we use the information received from this feedback loop to
optimize the exceptions presented to the National Central Banks thereby
improving the quality of exceptions generated and the time consumed on the
system by the users authenticating those exceptions. For this approach we make
use of explainable supervised machine learning to (a) identify the types of
exceptions and (b) to prioritize which exceptions are more likely to require an
intervention or correction by the NCBs. Furthermore, we provide an explainable
AI taxonomy aiming to identify the different explainable AI needs that arose
during the project.</p>
  </details>
</details>
<details>
  <summary>35. <b>标题：Almost Optimal Proper Learning and Testing Polynomials</b></summary>
  <p><b>编号</b>：[75]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03207</p>
  <p><b>作者</b>：Nader H. Bshouty</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：almost tight lower bound $$ q_l =\ left (\ frac, 1 }{\ epsilon }\ right )\ log n ,$$ applying, 1 }{\ epsilon }\ right )\ log n $$ queries, }{\ epsilon }\ right )^{\ frac {\ log, }{\ epsilon }\ right )^{\ frac {\ log</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We give the first almost optimal polynomial-time proper learning algorithm of
Boolean sparse multivariate polynomial under the uniform distribution. For
$s$-sparse polynomial over $n$ variables and $\epsilon=1/s^\beta$, $\beta>1$,
our algorithm makes $$q_U=\left(\frac{s}{\epsilon}\right)^{\frac{\log
\beta}{\beta}+O(\frac{1}{\beta})}+ \tilde
O\left(s\right)\left(\log\frac{1}{\epsilon}\right)\log n$$ queries. Notice that
our query complexity is sublinear in $1/\epsilon$ and almost linear in $s$. All
previous algorithms have query complexity at least quadratic in $s$ and linear
in $1/\epsilon$.
We then prove the almost tight lower bound
$$q_L=\left(\frac{s}{\epsilon}\right)^{\frac{\log
\beta}{\beta}+\Omega(\frac{1}{\beta})}+
\Omega\left(s\right)\left(\log\frac{1}{\epsilon}\right)\log n,$$
Applying the reduction in~\cite{Bshouty19b} with the above algorithm, we give
the first almost optimal polynomial-time tester for $s$-sparse polynomial. Our
tester, for $\beta>3.404$, makes $$\tilde O\left(\frac{s}{\epsilon}\right)$$
queries.</p>
  </details>
</details>
<details>
  <summary>36. <b>标题：AI Research Associate for Early-Stage Scientific Discovery</b></summary>
  <p><b>编号</b>：[78]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03199</p>
  <p><b>作者</b>：Morad Behandish,  John Maxwell III,  Johan de Kleer</p>
  <p><b>备注</b>：Paper #203</p>
  <p><b>关键词</b>：even dogmatized ), stifling transformative discoveries, g ., postulated forms, stage scientific discovery based, g ., constitutive, real problems faced</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Artificial intelligence (AI) has been increasingly applied in scientific
activities for decades; however, it is still far from an insightful and
trustworthy collaborator in the scientific process. Most existing AI methods
are either too simplistic to be useful in real problems faced by scientists or
too domain-specialized (even dogmatized), stifling transformative discoveries
or paradigm shifts. We present an AI research associate for early-stage
scientific discovery based on (a) a novel minimally-biased ontology for
physics-based modeling that is context-aware, interpretable, and generalizable
across classical and relativistic physics; (b) automatic search for viable and
parsimonious hypotheses, represented at a high-level (via domain-agnostic
constructs) with built-in invariants, e.g., postulated forms of conservation
principles implied by a presupposed spacetime topology; and (c) automatic
compilation of the enumerated hypotheses to domain-specific, interpretable, and
trainable/testable tensor-based computation graphs to learn phenomenological
relations, e.g., constitutive or material laws, from sparse (and possibly
noisy) data sets.</p>
  </details>
</details>
<details>
  <summary>37. <b>标题：More is Better (Mostly): On the Backdoor Attacks in Federated Graph  Neural Networks</b></summary>
  <p><b>编号</b>：[80]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03195</p>
  <p><b>作者</b>：Jing Xu,  Rui Wang,  Kaitai Liang,  Stjepan Picek</p>
  <p><b>备注</b>：18 pages, 11 figures</p>
  <p><b>关键词</b>：widely used graph analysis method due, processing graph domain information, shared global model collaboratively, although many research works, dba attack success rate</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Graph Neural Networks (GNNs) are a class of deep learning-based methods for
processing graph domain information. GNNs have recently become a widely used
graph analysis method due to their superior ability to learn representations
for complex graph data. However, due to privacy concerns and regulation
restrictions, centralized GNNs can be difficult to apply to data-sensitive
scenarios. Federated learning (FL) is an emerging technology developed for
privacy-preserving settings when several parties need to train a shared global
model collaboratively. Although many research works have applied FL to train
GNNs (Federated GNNs), there is no research on their robustness to backdoor
attacks.
This paper bridges this gap by conducting two types of backdoor attacks in
Federated GNNs: centralized backdoor attacks (CBA) and distributed backdoor
attacks (DBA). CBA is conducted by embedding the same global trigger during
training for every malicious party, while DBA is conducted by decomposing a
global trigger into separate local triggers and embedding them into the
training dataset of different malicious parties, respectively. Our experiments
show that the DBA attack success rate is higher than CBA in almost all
evaluated cases, while rarely, the DBA attack performance is close to CBA. For
CBA, the attack success rate of all local triggers is similar to the global
trigger even if the training set of the adversarial party is embedded with the
global trigger. To further explore the properties of two backdoor attacks in
Federated GNNs, we evaluate the attack performance for different trigger sizes,
poisoning intensities, and trigger densities, with trigger density being the
most influential.</p>
  </details>
</details>
<details>
  <summary>38. <b>标题：Network Resource Allocation Strategy Based on Deep Reinforcement  Learning</b></summary>
  <p><b>编号</b>：[81]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03193</p>
  <p><b>作者</b>：Shidong Zhang,  Chao Wang,  Junsan Zhang,  Youxiang Duan,  Xinhong You,  Peiying Zhang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：existing vne algorithm often ignores, supports shows great potential, solving resource allocation problems, neural network model close, stage vne algorithm based</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The traditional Internet has encountered a bottleneck in allocating network
resources for emerging technology needs. Network virtualization (NV) technology
as a future network architecture, the virtual network embedding (VNE) algorithm
it supports shows great potential in solving resource allocation problems.
Combined with the efficient machine learning (ML) algorithm, a neural network
model close to the substrate network environment is constructed to train the
reinforcement learning agent. This paper proposes a two-stage VNE algorithm
based on deep reinforcement learning (DRL) (TS-DRL-VNE) for the problem that
the mapping result of existing heuristic algorithm is easy to converge to the
local optimal solution. For the problem that the existing VNE algorithm based
on ML often ignores the importance of substrate network representation and
training mode, a DRL VNE algorithm based on full attribute matrix (FAM-DRL-VNE)
is proposed. In view of the problem that the existing VNE algorithm often
ignores the underlying resource changes between virtual network requests, a DRL
VNE algorithm based on matrix perturbation theory (MPT-DRL-VNE) is proposed.
Experimental results show that the above algorithm is superior to other
algorithms.</p>
  </details>
</details>
<details>
  <summary>39. <b>标题：Optical skin: Sensor-integration-free multimodal flexible sensing</b></summary>
  <p><b>编号</b>：[84]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03189</p>
  <p><b>作者</b>：Sho Shimadera,  Kei Kitagawa,  Koyo Sagehashi,  Tomoaki Niiyama,  Satoshi Sunada</p>
  <p><b>备注</b>：13 pages, 11 figures</p>
  <p><b>关键词</b>：single soft material without requiring complex integration, three different physical quantities, require integrating multiple sensors, large area remains challenging, demonstrate simultaneous sensing mode</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The biological skin enables animals to sense various stimuli. Extensive
efforts have been made recently to develop smart skin-like sensors to extend
the capabilities of biological skins; however, simultaneous sensing of several
types of stimuli in a large area remains challenging because this requires
large-scale sensor integration with numerous wire connections. We propose a
simple, highly sensitive, and multimodal sensing approach, which does not
require integrating multiple sensors. The proposed approach is based on an
optical interference technique, which can encode the information of various
stimuli as a spatial pattern. In contrast to the existing approach, the
proposed approach, combined with a deep neural network, enables us to freely
select the sensing mode according to our purpose. As a key example, we
demonstrate simultaneous sensing mode of three different physical quantities,
contact force, contact location, and temperature, using a single soft material
without requiring complex integration. Another unique property of the proposed
approach is spatially continuous sensing with ultrahigh resolution of few tens
of micrometers, which enables identifying the shape of the object in contact.
Furthermore, we present a haptic soft device for a human-machine interface. The
proposed approach encourages the development of high-performance optical skins.</p>
  </details>
</details>
<details>
  <summary>40. <b>标题：TransFollower: Long-Sequence Car-Following Trajectory Prediction through  Transformer</b></summary>
  <p><b>编号</b>：[88]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03183</p>
  <p><b>作者</b>：Meixin Zhu,  Simon S. Du,  Xuesong Wang, Hao (Frank) Yang,  Ziyuan Pu,  Yinhai Wang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：fully connected neural network model, historical driving context using multi, predicted future fv speed profile, one vehicle follows another vehicle, following trajectory prediction model based</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Car-following refers to a control process in which the following vehicle (FV)
tries to keep a safe distance between itself and the lead vehicle (LV) by
adjusting its acceleration in response to the actions of the vehicle ahead. The
corresponding car-following models, which describe how one vehicle follows
another vehicle in the traffic flow, form the cornerstone for microscopic
traffic simulation and intelligent vehicle development. One major motivation of
car-following models is to replicate human drivers' longitudinal driving
trajectories. To model the long-term dependency of future actions on historical
driving situations, we developed a long-sequence car-following trajectory
prediction model based on the attention-based Transformer model. The model
follows a general format of encoder-decoder architecture. The encoder takes
historical speed and spacing data as inputs and forms a mixed representation of
historical driving context using multi-head self-attention. The decoder takes
the future LV speed profile as input and outputs the predicted future FV speed
profile in a generative way (instead of an auto-regressive way, avoiding
compounding errors). Through cross-attention between encoder and decoder, the
decoder learns to build a connection between historical driving and future LV
speed, based on which a prediction of future FV speed can be obtained. We train
and test our model with 112,597 real-world car-following events extracted from
the Shanghai Naturalistic Driving Study (SH-NDS). Results show that the model
outperforms the traditional intelligent driver model (IDM), a fully connected
neural network model, and a long short-term memory (LSTM) based model in terms
of long-sequence trajectory prediction accuracy. We also visualized the
self-attention and cross-attention heatmaps to explain how the model derives
its predictions.</p>
  </details>
</details>
<details>
  <summary>41. <b>标题：Towards Loosely-Coupling Knowledge Graph Embeddings and Ontology-based  Reasoning</b></summary>
  <p><b>编号</b>：[92]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03173</p>
  <p><b>作者</b>：Zoi Kaoudi,  Abelardo Carlos Martinez Lorenzo,  Volker Markl</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：g ., owl2 )., .~ link prediction ),, vanilla knowledge graph embeddings, input knowledge graph contains, combine knowledge graph embeddings</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Knowledge graph completion (a.k.a.~link prediction), i.e.,~the task of
inferring missing information from knowledge graphs, is a widely used task in
many applications, such as product recommendation and question answering. The
state-of-the-art approaches of knowledge graph embeddings and/or rule mining
and reasoning are data-driven and, thus, solely based on the information the
input knowledge graph contains. This leads to unsatisfactory prediction results
which make such solutions inapplicable to crucial domains such as healthcare.
To further enhance the accuracy of knowledge graph completion we propose to
loosely-couple the data-driven power of knowledge graph embeddings with
domain-specific reasoning stemming from experts or entailment regimes (e.g.,
OWL2). In this way, we not only enhance the prediction accuracy with domain
knowledge that may not be included in the input knowledge graph but also allow
users to plugin their own knowledge graph embedding and reasoning method. Our
initial results show that we enhance the MRR accuracy of vanilla knowledge
graph embeddings by up to 3x and outperform hybrid solutions that combine
knowledge graph embeddings with rule mining and reasoning up to 3.5x MRR.</p>
  </details>
</details>
<details>
  <summary>42. <b>标题：CITRIS: Causal Identifiability from Temporal Intervened Sequences</b></summary>
  <p><b>编号</b>：[94]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03169</p>
  <p><b>作者</b>：Phillip Lippe,  Sara Magliacane,  Sindy Löwe,  Yuki M. Asano,  Taco Cohen,  Efstratios Gavves</p>
  <p><b>备注</b>：46 pages</p>
  <p><b>关键词</b>：crucial step towards agents reasoning, opening future research areas, 3d rendered image sequences, citris outperforms previous methods, extending previous results</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Understanding the latent causal factors of a dynamical system from visual
observations is a crucial step towards agents reasoning in complex
environments. In this paper, we propose CITRIS, a variational autoencoder
framework that learns causal representations from temporal sequences of images
in which underlying causal factors have possibly been intervened upon. In
contrast to the recent literature, CITRIS exploits temporality and observing
intervention targets to identify scalar and multidimensional causal factors,
such as 3D rotation angles. Furthermore, by introducing a normalizing flow,
CITRIS can be easily extended to leverage and disentangle representations
obtained by already pretrained autoencoders. Extending previous results on
scalar causal factors, we prove identifiability in a more general setting, in
which only some components of a causal factor are affected by interventions. In
experiments on 3D rendered image sequences, CITRIS outperforms previous methods
on recovering the underlying causal variables. Moreover, using pretrained
autoencoders, CITRIS can even generalize to unseen instantiations of causal
factors, opening future research areas in sim-to-real generalization for causal
representation learning.</p>
  </details>
</details>
<details>
  <summary>43. <b>标题：Bayesian Linear Bandits for Large-Scale Recommender Systems</b></summary>
  <p><b>编号</b>：[95]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03167</p>
  <p><b>作者</b>：Saeed Ghoorchian,  Setareh Maghsudi</p>
  <p><b>备注</b>：10 pages, 2 figures</p>
  <p><b>关键词</b>：policy employs thompson sampling, available side information boosts, proposed recommender system follows, dimensionality reduction follows, reduced dimension instead</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Potentially, taking advantage of available side information boosts the
performance of recommender systems; nevertheless, with the rise of big data,
the side information has often several dimensions. Hence, it is imperative to
develop decision-making algorithms that can cope with such a high-dimensional
context in real-time. That is especially challenging when the decision-maker
has a variety of items to recommend. In this paper, we build upon the linear
contextual multi-armed bandit framework to address this problem. We develop a
decision-making policy for a linear bandit problem with high-dimensional
context vectors and several arms. Our policy employs Thompson sampling and
feeds it with reduced context vectors, where the dimensionality reduction
follows by random projection. Our proposed recommender system follows this
policy to learn online the item preferences of users while keeping its runtime
as low as possible. We prove a regret bound that scales as a factor of the
reduced dimension instead of the original one. For numerical evaluation, we use
our algorithm to build a recommender system and apply it to real-world
datasets. The theoretical and numerical results demonstrate the effectiveness
of our proposed algorithm compared to the state-of-the-art in terms of
computational complexity and regret performance.</p>
  </details>
</details>
<details>
  <summary>44. <b>标题：Over-the-Air Ensemble Inference with Model Privacy</b></summary>
  <p><b>编号</b>：[110]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03129</p>
  <p><b>作者</b>：Selim F. Yilmaz,  Burak Hasircioglu,  Deniz Gunduz</p>
  <p><b>备注</b>：15 pages</p>
  <p><b>关键词</b>：also provide experimental results verifying, schemes perform significantly better, efficient ensemble inference methods, maximizing inference accuracy, consider distributed inference</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We consider distributed inference at the wireless edge, where multiple
clients with an ensemble of models, each trained independently on a local
dataset, are queried in parallel to make an accurate decision on a new sample.
In addition to maximizing inference accuracy, we also want to maximize the
privacy of local models. We exploit the superposition property of the air to
implement bandwidth-efficient ensemble inference methods. We introduce
different over-the-air ensemble methods and show that these schemes perform
significantly better than their orthogonal counterparts, while using less
resources and providing privacy guarantees. We also provide experimental
results verifying the benefits of the proposed over-the-air inference approach,
whose source code is shared publicly on Github.</p>
  </details>
</details>
<details>
  <summary>45. <b>标题：To Tune or Not To Tune? Zero-shot Models for Legal Case Entailment</b></summary>
  <p><b>编号</b>：[112]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03120</p>
  <p><b>作者</b>：Guilherme Moraes Rosa,  Ruan Chaves Rodrigues,  Roberto de Alencar Lotufo,  Rodrigo Nogueira</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：given limited labeled data, legal case entailment task, pretrained language models fine, pretrained language models, six percentage points</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>There has been mounting evidence that pretrained language models fine-tuned
on large and diverse supervised datasets can transfer well to a variety of
out-of-domain tasks. In this work, we investigate this transfer ability to the
legal domain. For that, we participated in the legal case entailment task of
COLIEE 2021, in which we use such models with no adaptations to the target
domain. Our submissions achieved the highest scores, surpassing the second-best
team by more than six percentage points. Our experiments confirm a
counter-intuitive result in the new paradigm of pretrained language models:
given limited labeled data, models with little or no adaptation to the target
task can be more robust to changes in the data distribution than models
fine-tuned on it. Code is available at this https URL.</p>
  </details>
</details>
<details>
  <summary>46. <b>标题：SimGRACE: A Simple Framework for Graph Contrastive Learning without Data  Augmentation</b></summary>
  <p><b>编号</b>：[115]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03104</p>
  <p><b>作者</b>：Jun Xia,  Lirong Wu,  Jintao Chen,  Bozhen Hu,  Stan Z.Li</p>
  <p><b>备注</b>：Accepted by The Web Conference 2022 (WWW 2022)</p>
  <p><b>关键词</b>：manually picked per dataset, devise adversarial training scheme, obtain two correlated views, selected via cumbersome search, preserve semantics broadly fall</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Graph contrastive learning (GCL) has emerged as a dominant technique for
graph representation learning which maximizes the mutual information between
paired graph augmentations that share the same semantics. Unfortunately, it is
difficult to preserve semantics well during augmentations in view of the
diverse nature of graph data. Currently, data augmentations in GCL that are
designed to preserve semantics broadly fall into three unsatisfactory ways.
First, the augmentations can be manually picked per dataset by
trial-and-errors. Second, the augmentations can be selected via cumbersome
search. Third, the augmentations can be obtained by introducing expensive
domain-specific knowledge as guidance. All of these limit the efficiency and
more general applicability of existing GCL methods. To circumvent these crucial
issues, we propose a \underline{Sim}ple framework for \underline{GRA}ph
\underline{C}ontrastive l\underline{E}arning, \textbf{SimGRACE} for brevity,
which does not require data augmentations. Specifically, we take original graph
as input and GNN model with its perturbed version as two encoders to obtain two
correlated views for contrast. SimGRACE is inspired by the observation that
graph data can preserve their semantics well during encoder perturbations while
not requiring manual trial-and-errors, cumbersome search or expensive domain
knowledge for augmentations selection. Also, we explain why SimGRACE can
succeed. Furthermore, we devise adversarial training scheme, dubbed
\textbf{AT-SimGRACE}, to enhance the robustness of graph contrastive learning
and theoretically explain the reasons. Albeit simple, we show that SimGRACE can
yield competitive or better performance compared with state-of-the-art methods
in terms of generalizability, transferability and robustness, while enjoying
unprecedented degree of flexibility and efficiency.</p>
  </details>
</details>
<details>
  <summary>47. <b>标题：Combining Deep Learning and Reasoning for Address Detection in  Unstructured Text Documents</b></summary>
  <p><b>编号</b>：[116]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03103</p>
  <p><b>作者</b>：Matthias Engelbach,  Dennis Klau,  Jens Drawehn,  Maximilien Kintz</p>
  <p><b>备注</b>：5 pages, 1 figure, submitted to AAAI-22 workshop CLeaR, peer reviewed</p>
  <p><b>关键词</b>：containing text using domain knowledge represented, sender address would boost many companies, visual deep learning model, crucial document information like, possible address regions</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Extracting information from unstructured text documents is a demanding task,
since these documents can have a broad variety of different layouts and a
non-trivial reading order, like it is the case for multi-column documents or
nested tables. Additionally, many business documents are received in paper
form, meaning that the textual contents need to be digitized before further
analysis. Nonetheless, automatic detection and capturing of crucial document
information like the sender address would boost many companies' processing
efficiency. In this work we propose a hybrid approach that combines deep
learning with reasoning for finding and extracting addresses from unstructured
text documents. We use a visual deep learning model to detect the boundaries of
possible address regions on the scanned document images and validate these
results by analyzing the containing text using domain knowledge represented as
a rule based system.</p>
  </details>
</details>
<details>
  <summary>48. <b>标题：FL_PyTorch: optimization research simulator for federated learning</b></summary>
  <p><b>编号</b>：[118]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03099</p>
  <p><b>作者</b>：Konstantin Burlachenko,  Samuel Horváth,  Peter Richtárik</p>
  <p><b>备注</b>：DistributedML '21: Proceedings of the 2nd ACM International Workshop on Distributed Machine Learning</p>
  <p><b>关键词</b>：run several clients simultaneously using local cpus, even remote compute devices without, shared machine learning model, keeping training data locally, popular research deep learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Federated Learning (FL) has emerged as a promising technique for edge devices
to collaboratively learn a shared machine learning model while keeping training
data locally on the device, thereby removing the need to store and access the
full data in the cloud. However, FL is difficult to implement, test and deploy
in practice considering heterogeneity in common edge device settings, making it
fundamentally hard for researchers to efficiently prototype and test their
optimization algorithms. In this work, our aim is to alleviate this problem by
introducing FL_PyTorch : a suite of open-source software written in python that
builds on top of one the most popular research Deep Learning (DL) framework
PyTorch. We built FL_PyTorch as a research simulator for FL to enable fast
development, prototyping and experimenting with new and existing FL
optimization algorithms. Our system supports abstractions that provide
researchers with a sufficient level of flexibility to experiment with existing
and novel approaches to advance the state-of-the-art. Furthermore, FL_PyTorch
is a simple to use console system, allows to run several clients simultaneously
using local CPUs or GPU(s), and even remote compute devices without the need
for any distributed implementation provided by the user. FL_PyTorch also offers
a Graphical User Interface. For new methods, researchers only provide the
centralized implementation of their algorithm. To showcase the possibilities
and usefulness of our system, we experiment with several well-known
state-of-the-art FL algorithms and a few of the most common FL datasets.</p>
  </details>
</details>
<details>
  <summary>49. <b>标题：Auto-Lambda: Disentangling Dynamic Task Relationships</b></summary>
  <p><b>编号</b>：[122]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03091</p>
  <p><b>作者</b>：Shikun Liu,  Stephen James,  Andrew J. Davison,  Edward Johns</p>
  <p><b>备注</b>：Tech Report. Project Page: this https URL Code: this https URL</p>
  <p><b>关键词</b>：validation loss automatically influences task weightings throughout training, dynamic task relationships via task, optimisation strategies designed specifically, extremely high computational cost, learn task relationships via</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Understanding the structure of multiple related tasks allows for multi-task
learning to improve the generalisation ability of one or all of them. However,
it usually requires training each pairwise combination of tasks together in
order to capture task relationships, at an extremely high computational cost.
In this work, we learn task relationships via an automated weighting framework,
named Auto-Lambda. Unlike previous methods where task relationships are assumed
to be fixed, Auto-Lambda is a gradient-based meta learning framework which
explores continuous, dynamic task relationships via task-specific weightings,
and can optimise any choice of combination of tasks through the formulation of
a meta-loss; where the validation loss automatically influences task weightings
throughout training. We apply the proposed framework to both multi-task and
auxiliary learning problems in computer vision and robotics, and show that
Auto-Lambda achieves state-of-the-art performance, even when compared to
optimisation strategies designed specifically for each problem and data domain.
Finally, we observe that Auto-Lambda can discover interesting learning
behaviors, leading to new insights in multi-task learning. Code is available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>50. <b>标题：Fair Interpretable Representation Learning with Correction Vectors</b></summary>
  <p><b>编号</b>：[128]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03078</p>
  <p><b>作者</b>：Mattia Cerrato,  Alesia Vallenas Coronel,  Marius Köppel,  Alexander Segner,  Roberto Esposito,  Stefan Kramer</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：computed either explicitly via architectural constraints, several fair representation learning models constrained, various representation debiasing techniques, fair representation learning setting, fair representation learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Neural network architectures have been extensively employed in the fair
representation learning setting, where the objective is to learn a new
representation for a given vector which is independent of sensitive
information. Various representation debiasing techniques have been proposed in
the literature. However, as neural networks are inherently opaque, these
methods are hard to comprehend, which limits their usefulness. We propose a new
framework for fair representation learning that is centered around the learning
of "correction vectors", which have the same dimensionality as the given data
vectors. Correction vectors may be computed either explicitly via architectural
constraints or implicitly by training an invertible model based on Normalizing
Flows. We show experimentally that several fair representation learning models
constrained in such a way do not exhibit losses in ranking or classification
performance. Furthermore, we demonstrate that state-of-the-art results can be
achieved by the invertible model. Finally, we discuss the law standing of our
methodology in light of recent legislation in the European Union.</p>
  </details>
</details>
<details>
  <summary>51. <b>标题：Adversarial Attacks and Defense for Non-Parametric Two-Sample Tests</b></summary>
  <p><b>编号</b>：[129]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03077</p>
  <p><b>作者</b>：Xilie Xu,  Jingfeng Zhang,  Feng Liu,  Masashi Sugiyama,  Mohan Kankanhalli</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：proposes corresponding defense strategies, judge whether two sets, iteratively generates adversarial pairs, world datasets validate, trusted basic tools</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Non-parametric two-sample tests (TSTs) that judge whether two sets of samples
are drawn from the same distribution, have been widely used in the analysis of
critical data. People tend to employ TSTs as trusted basic tools and rarely
have any doubt about their reliability. This paper systematically uncovers the
failure mode of non-parametric TSTs through adversarial attacks and then
proposes corresponding defense strategies. First, we theoretically show that an
adversary can upper-bound the distributional shift which guarantees the
attack's invisibility. Furthermore, we theoretically find that the adversary
can also degrade the lower bound of a TST's test power, which enables us to
iteratively minimize the test criterion in order to search for adversarial
pairs. To enable TST-agnostic attacks, we propose an ensemble attack (EA)
framework that jointly minimizes the different types of test criteria. Second,
to robustify TSTs, we propose a max-min optimization that iteratively generates
adversarial pairs to train the deep kernels. Extensive experiments on both
simulated and real-world datasets validate the adversarial vulnerabilities of
non-parametric TSTs and the effectiveness of our proposed defense.</p>
  </details>
</details>
<details>
  <summary>52. <b>标题：Distributionally Robust Fair Principal Components via Geodesic Descents</b></summary>
  <p><b>编号</b>：[131]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03071</p>
  <p><b>作者</b>：Hieu Vu,  Toan Tran,  Man-Chung Yue,  Viet Anh Nguyen</p>
  <p><b>备注</b>：International Conference on Learning Representations (ICLR) 2022</p>
  <p><b>关键词</b>：simple yet useful dimensionality reduction technique, riemannian subgradient descent algorithm, modern machine learning pipelines, distributionally robust optimization problem, learned projection thus balances</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Principal component analysis is a simple yet useful dimensionality reduction
technique in modern machine learning pipelines. In consequential domains such
as college admission, healthcare and credit approval, it is imperative to take
into account emerging criteria such as the fairness and the robustness of the
learned projection. In this paper, we propose a distributionally robust
optimization problem for principal component analysis which internalizes a
fairness criterion in the objective function. The learned projection thus
balances the trade-off between the total reconstruction error and the
reconstruction error gap between subgroups, taken in the min-max sense over all
distributions in a moment-based ambiguity set. The resulting optimization
problem over the Stiefel manifold can be efficiently solved by a Riemannian
subgradient descent algorithm with a sub-linear convergence rate. Our
experimental results on real-world datasets show the merits of our proposed
method over state-of-the-art baselines.</p>
  </details>
</details>
<details>
  <summary>53. <b>标题：Addressing modern and practical challenges in machine learning: A survey  of online federated and transfer learning</b></summary>
  <p><b>编号</b>：[132]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03070</p>
  <p><b>作者</b>：Shuang Dai,  Fanlin Meng</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：overcoming modern machine learning challenges, potential future research areas, professionals developing online federated, two collaborative paradigms, survey provides insight</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Online federated learning (OFL) and online transfer learning (OTL) are two
collaborative paradigms for overcoming modern machine learning challenges such
as data silos, streaming data, and data security. This survey explored OFL and
OTL throughout their major evolutionary routes to enhance understanding of
online federated and transfer learning. Besides, practical aspects of popular
datasets and cutting-edge applications for online federated and transfer
learning are highlighted in this work. Furthermore, this survey provides
insight into potential future research areas and aims to serve as a resource
for professionals developing online federated and transfer learning frameworks.</p>
  </details>
</details>
<details>
  <summary>54. <b>标题：Artificial Intelligence based tool wear and defect prediction for  special purpose milling machinery using low-cost acceleration sensor  retrofits</b></summary>
  <p><b>编号</b>：[133]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03068</p>
  <p><b>作者</b>：Mahmoud Kheir-Eddine,  Michael Banf,  Gregor Steinhagen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：several machine learning based approaches, many industrial processing chains, insufficient transmission belt tension, edge classification setup comes, since retrofitting older machines</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Milling machines form an integral part of many industrial processing chains.
As a consequence, several machine learning based approaches for tool wear
detection have been proposed in recent years, yet these methods mostly deal
with standard milling machines, while machinery designed for more specialized
tasks has gained only limited attention so far. This paper demonstrates the
application of an acceleration sensor to allow for convenient condition
monitoring of such a special purpose machine, i.e. round seam milling machine.
We examine a variety of conditions including blade wear and blade breakage as
well as improper machine mounting or insufficient transmission belt tension. In
addition, we presents different approaches to supervised failure recognition
with limited amounts of training data. Hence, aside theoretical insights, our
analysis is of high, practical importance, since retrofitting older machines
with acceleration sensors and an on-edge classification setup comes at low cost
and effort, yet provides valuable insights into the state of the machine and
tools in particular and the production process in general.</p>
  </details>
</details>
<details>
  <summary>55. <b>标题：The Importance of Non-Markovianity in Maximum State Entropy Exploration</b></summary>
  <p><b>编号</b>：[135]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03060</p>
  <p><b>作者</b>：Mirco Mutti,  Riccardo De Santi,  Marcello Restelli</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：maximum state entropy exploration framework, maximum state entropy exploration, markovian exploration could benefit, maximum state entropy objective, markovian policies suffer non</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In the maximum state entropy exploration framework, an agent interacts with a
reward-free environment to learn a policy that maximizes the entropy of the
expected state visitations it is inducing. Hazan et al. (2019) noted that the
class of Markovian stochastic policies is sufficient for the maximum state
entropy objective, and exploiting non-Markovianity is generally considered
pointless in this setting. In this paper, we argue that non-Markovianity is
instead paramount for maximum state entropy exploration in a finite-sample
regime. Especially, we recast the objective to target the expected entropy of
the induced state visitations in a single trial. Then, we show that the class
of non-Markovian deterministic policies is sufficient for the introduced
objective, while Markovian policies suffer non-zero regret in general. However,
we prove that the problem of finding an optimal non-Markovian policy is at
least NP-complete. Despite this negative result, we discuss avenues to address
the problem in a tractable way and how non-Markovian exploration could benefit
the sample efficiency of online reinforcement learning in future works.</p>
  </details>
</details>
<details>
  <summary>56. <b>标题：Evaluation of Runtime Monitoring for UAV Emergency Landing</b></summary>
  <p><b>编号</b>：[136]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03059</p>
  <p><b>作者</b>：Joris Guerin,  Kevin Delmas,  Jérémie Guiochet</p>
  <p><b>备注</b>：7 pages, 4 figures, 1 table. To appear in the proceedings of 2022 IEEE International Conference on Robotics and Automation (ICRA)</p>
  <p><b>关键词</b>：finding safe landing areas using, proposed el pipeline includes mechanisms, monitor learning based components, machine learning runtime monitoring, risk mitigation strategies --</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>To certify UAV operations in populated areas, risk mitigation strategies --
such as Emergency Landing (EL) -- must be in place to account for potential
failures. EL aims at reducing ground risk by finding safe landing areas using
on-board sensors. The first contribution of this paper is to present a new EL
approach, in line with safety requirements introduced in recent research. In
particular, the proposed EL pipeline includes mechanisms to monitor learning
based components during execution. This way, another contribution is to study
the behavior of Machine Learning Runtime Monitoring (MLRM) approaches within
the context of a real-world critical system. A new evaluation methodology is
introduced, and applied to assess the practical safety benefits of three MLRM
mechanisms. The proposed approach is compared to a default mitigation strategy
(open a parachute when a failure is detected), and appears to be much safer.</p>
  </details>
</details>
<details>
  <summary>57. <b>标题：Enabling Automatic Repair of Source Code Vulnerabilities Using  Data-Driven Methods</b></summary>
  <p><b>编号</b>：[140]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03055</p>
  <p><b>作者</b>：Anastasiia Grishina</p>
  <p><b>备注</b>：Accepted for the ICSE '22 Doctoral Symposium</p>
  <p><b>关键词</b>：automatic program repair use pairs, systems regularly contain bugs, automatic program repair, facilitate bug fixing, security vulnerabilities remains</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Users around the world rely on software-intensive systems in their day-to-day
activities. These systems regularly contain bugs and security vulnerabilities.
To facilitate bug fixing, data-driven models of automatic program repair use
pairs of buggy and fixed code to learn transformations that fix errors in code.
However, automatic repair of security vulnerabilities remains under-explored.
In this work, we propose ways to improve code representations for vulnerability
repair from three perspectives: input data type, data-driven models, and
downstream tasks. The expected results of this work are improved code
representations for automatic program repair and, specifically, fixing security
vulnerabilities.</p>
  </details>
</details>
<details>
  <summary>58. <b>标题：Using Partial Monotonicity in Submodular Maximization</b></summary>
  <p><b>编号</b>：[142]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03051</p>
  <p><b>作者</b>：Loay Mualem,  Moran Feldman</p>
  <p><b>备注</b>：45 pages; 7 figures</p>
  <p><b>关键词</b>：many standard submodular maximization algorithms one, many discrete optimization problems, almost monotone often arise, prove new approximation guarantees, unfortunate since submoduar functions</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Over the last two decades, submodular function maximization has been the
workhorse of many discrete optimization problems in machine learning
applications. Traditionally, the study of submodular functions was based on
binary function properties. However, such properties have an inherit weakness,
namely, if an algorithm assumes functions that have a particular property, then
it provides no guarantee for functions that violate this property, even when
the violation is very slight. Therefore, recent works began to consider
continuous versions of function properties. Probably the most significant among
these (so far) are the submodularity ratio and the curvature, which were
studied extensively together and separately.
The monotonicity property of set functions plays a central role in submodular
maximization. Nevertheless, and despite all the above works, no continuous
version of this property has been suggested to date (as far as we know). This
is unfortunate since submoduar functions that are almost monotone often arise
in machine learning applications. In this work we fill this gap by defining the
monotonicity ratio, which is a continues version of the monotonicity property.
We then show that for many standard submodular maximization algorithms one can
prove new approximation guarantees that depend on the monotonicity ratio;
leading to improved approximation ratios for the common machine learning
applications of movie recommendation, quadratic programming and image
summarization.</p>
  </details>
</details>
<details>
  <summary>59. <b>标题：Metric-valued regression</b></summary>
  <p><b>编号</b>：[145]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03045</p>
  <p><b>作者</b>：Dan Tsir Cohen,  Aryeh Kontorovich</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：consistent whenever $\ x, {\ em semi, stable compression },, somewhat weakened )., two metric spaces</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose an efficient algorithm for learning mappings between two metric
spaces, $\X$ and $\Y$. Our procedure is strongly Bayes-consistent whenever $\X$
and $\Y$ are topologically separable and $\Y$ is "bounded in expectation" (our
term; the separability assumption can be somewhat weakened). At this level of
generality, ours is the first such learnability result for unbounded loss in
the agnostic setting. Our technique is based on metric medoids (a variant of
Fréchet means) and presents a significant departure from existing methods,
which, as we demonstrate, fail to achieve Bayes-consistency on general
instance- and label-space metrics. Our proofs introduce the technique of {\em
semi-stable compression}, which may be of independent interest.</p>
  </details>
</details>
<details>
  <summary>60. <b>标题：Deep Networks on Toroids: Removing Symmetries Reveals the Structure of  Flat Regions in the Landscape Geometry</b></summary>
  <p><b>编号</b>：[148]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03038</p>
  <p><b>作者</b>：Fabrizio Pittorino,  Antonio Ferraro,  Gabriele Perugini,  Christoph Feinauer,  Carlo Baldassi,  Riccardo Zecchina</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：recent analytical studies performed, using different optimization algorithms, observe similar qualitative results, deep neural network landscapes, function space flatter minima</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We systematize the approach to the investigation of deep neural network
landscapes by basing it on the geometry of the space of implemented functions
rather than the space of parameters. Grouping classifiers into equivalence
classes, we develop a standardized parameterization in which all symmetries are
removed, resulting in a toroidal topology. On this space, we explore the error
landscape rather than the loss. This lets us derive a meaningful notion of the
flatness of minimizers and of the geodesic paths connecting them. Using
different optimization algorithms that sample minimizers with different
flatness we study the mode connectivity and other characteristics. Testing a
variety of state-of-the-art architectures and benchmark datasets, we confirm
the correlation between flatness and generalization performance; we further
show that in function space flatter minima are closer to each other and that
the barriers along the geodesics connecting them are small. We also find that
minimizers found by variants of gradient descent can be connected by zero-error
paths with a single bend. We observe similar qualitative results in neural
networks with binary weights and activations, providing one of the first
results concerning the connectivity in this setting. Our results hinge on
symmetry removal, and are in remarkable agreement with the rich phenomenology
described by some recent analytical studies performed on simple shallow models.</p>
  </details>
</details>
<details>
  <summary>61. <b>标题：CECILIA: Comprehensive Secure Machine Learning Framework</b></summary>
  <p><b>编号</b>：[153]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03023</p>
  <p><b>作者</b>：Ali Burak Ünal,  Mete Akgün,  Nico Pfeifer</p>
  <p><b>备注</b>：~8 pages of the main paper, ~1 of Supplement, submitted to ICML 2022</p>
  <p><b>关键词</b>：sensitive information enforce privacy preserving machine learning algorithms, offering privacy preserving building blocks, since machine learning algorithms, first study ever accomplishing, high computational power required</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Since machine learning algorithms have proven their success in data mining
tasks, the data with sensitive information enforce privacy preserving machine
learning algorithms to emerge. Moreover, the increase in the number of data
sources and the high computational power required by those algorithms force
individuals to outsource the training and/or the inference of a machine
learning model to the clouds providing such services. To address this dilemma,
we propose a secure 3-party computation framework, CECILIA, offering privacy
preserving building blocks to enable more complex operations privately. Among
those building blocks, we have two novel methods, which are the exact
exponential of a public base raised to the power of a secret value and the
inverse square root of a secret Gram matrix. We employ CECILIA to realize the
private inference on pre-trained recurrent kernel networks, which require more
complex operations than other deep neural networks such as convolutional neural
networks, on the structural classification of proteins as the first study ever
accomplishing the privacy preserving inference on recurrent kernel networks.
The results demonstrate that we perform the exact and fully private exponential
computation, which is done by approximation in the literature so far. Moreover,
we can also perform the exact inverse square root of a secret Gram matrix
computation up to a certain privacy level, which has not been addressed in the
literature at all. We also analyze the scalability of CECILIA to various
settings on a synthetic dataset. The framework shows a great promise to make
other machine learning algorithms as well as further computations privately
computable by the building blocks of the framework.</p>
  </details>
</details>
<details>
  <summary>62. <b>标题：B2EA: An Evolutionary Algorithm Assisted by Two Bayesian Optimization  Modules for Neural Architecture Search</b></summary>
  <p><b>编号</b>：[159]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03005</p>
  <p><b>作者</b>：Hyunghun Cho,  Jungwook Shin,  Wonjong Rhee</p>
  <p><b>备注</b>：23 pages, submitted to ICML22</p>
  <p><b>关键词</b>：early pioneering neural architecture search, key strategies including evolutionary algorithm, two bo surrogate models, structured search space typically, subsequent works took advantage</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The early pioneering Neural Architecture Search (NAS) works were multi-trial
methods applicable to any general search space. The subsequent works took
advantage of the early findings and developed weight-sharing methods that
assume a structured search space typically with pre-fixed hyperparameters.
Despite the amazing computational efficiency of the weight-sharing NAS
algorithms, it is becoming apparent that multi-trial NAS algorithms are also
needed for identifying very high-performance architectures, especially when
exploring a general search space. In this work, we carefully review the latest
multi-trial NAS algorithms and identify the key strategies including
Evolutionary Algorithm (EA), Bayesian Optimization (BO), diversification, input
and output transformations, and lower fidelity estimation. To accommodate the
key strategies into a single framework, we develop B\textsuperscript{2}EA that
is a surrogate assisted EA with two BO surrogate models and a mutation step in
between. To show that B\textsuperscript{2}EA is robust and efficient, we
evaluate three performance metrics over 14 benchmarks with general and
cell-based search spaces. Comparisons with state-of-the-art multi-trial
algorithms reveal that B\textsuperscript{2}EA is robust and efficient over the
14 benchmarks for three difficulty levels of target performance. The
B\textsuperscript{2}EA code is publicly available at
\url{this https URL}.</p>
  </details>
</details>
<details>
  <summary>63. <b>标题：Network Calculus with Flow Prolongation -- A Feedforward FIFO Analysis  enabled by ML</b></summary>
  <p><b>编号</b>：[160]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03004</p>
  <p><b>作者</b>：Fabien Geyer,  Alexander Scheffler,  Steffen Bondorf</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：fastest available nc fifo analysis suffers, predicting prolongations using machine learning, improve delay bound accuracy significantly, negligible additional computational cost, feature called flow prolongation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The derivation of upper bounds on data flows' worst-case traversal times is
an important task in many application areas. For accurate bounds, model
simplifications should be avoided even in large networks. Network Calculus (NC)
provides a modeling framework and different analyses for delay bounding. We
investigate the analysis of feedforward networks where all queues implement
First-In First-Out (FIFO) service. Correctly considering the effect of data
flows onto each other under FIFO is already a challenging task. Yet, the
fastest available NC FIFO analysis suffers from limitations resulting in
unnecessarily loose bounds. A feature called Flow Prolongation (FP) has been
shown to improve delay bound accuracy significantly. Unfortunately, FP needs to
be executed within the NC FIFO analysis very often and each time it creates an
exponentially growing set of alternative networks with prolongations. FP
therefore does not scale and has been out of reach for the exhaustive analysis
of large networks. We introduce DeepFP, an approach to make FP scale by
predicting prolongations using machine learning. In our evaluation, we show
that DeepFP can improve results in FIFO networks considerably. Compared to the
standard NC FIFO analysis, DeepFP reduces delay bounds by 12.1% on average at
negligible additional computational cost.</p>
  </details>
</details>
<details>
  <summary>64. <b>标题：Graph Self-supervised Learning with Accurate Discrepancy Learning</b></summary>
  <p><b>编号</b>：[164]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02989</p>
  <p><b>作者</b>：Dongki Kim,  Jinheon Baek,  Sung Ju Hwang</p>
  <p><b>备注</b>：8 pages</p>
  <p><b>关键词</b>：two differently perturbed graphs may result, model largely outperforms relevant baselines, cannot discriminate two similar graphs, including molecular property prediction, cannot learn global graph</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Self-supervised learning of graph neural networks (GNNs) aims to learn an
accurate representation of the graphs in an unsupervised manner, to obtain
transferable representations of them for diverse downstream tasks. Predictive
learning and contrastive learning are the two most prevalent approaches for
graph self-supervised learning. However, they have their own drawbacks. While
the predictive learning methods can learn the contextual relationships between
neighboring nodes and edges, they cannot learn global graph-level similarities.
Contrastive learning, while it can learn global graph-level similarities, its
objective to maximize the similarity between two differently perturbed graphs
may result in representations that cannot discriminate two similar graphs with
different properties. To tackle such limitations, we propose a framework that
aims to learn the exact discrepancy between the original and the perturbed
graphs, coined as Discrepancy-based Self-supervised LeArning (D-SLA).
Specifically, we create multiple perturbations of the given graph with varying
degrees of similarity and train the model to predict whether each graph is the
original graph or a perturbed one. Moreover, we further aim to accurately
capture the amount of discrepancy for each perturbed graph using the graph edit
distance. We validate our method on various graph-related downstream tasks,
including molecular property prediction, protein function prediction, and link
prediction tasks, on which our model largely outperforms relevant baselines.</p>
  </details>
</details>
<details>
  <summary>65. <b>标题：Neural Tangent Kernel Analysis of Deep Narrow Neural Networks</b></summary>
  <p><b>编号</b>：[166]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02981</p>
  <p><b>作者</b>：Jongmin Lee,  Joo Young Choi,  Ernest K. Ryu,  Albert No</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：infinitely deep convolutional neural network, overparameterized neural networks, narrow neural networks, tremendous recent progress, trainability guarantee using</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The tremendous recent progress in analyzing the training dynamics of
overparameterized neural networks has primarily focused on wide networks and
therefore does not sufficiently address the role of depth in deep learning. In
this work, we present the first trainability guarantee of infinitely deep but
narrow neural networks. We study the infinite-depth limit of a multilayer
perceptron (MLP) with a specific initialization and establish a trainability
guarantee using the NTK theory. We then extend the analysis to an infinitely
deep convolutional neural network (CNN) and perform brief experiments</p>
  </details>
</details>
<details>
  <summary>66. <b>标题：Measuring and Reducing Model Update Regression in Structured Prediction  for NLP</b></summary>
  <p><b>编号</b>：[168]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02976</p>
  <p><b>作者</b>：Deng Cai,  Elman Mansimov,  Yi-An Lai,  Yixuan Su,  Lei Shu,  Yi Zhang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：reducing model update regression including model ensemble, work studies model update regression, better mitigate model update regression, machine learning based nlp models, analyze model update regression</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent advance in deep learning has led to rapid adoption of machine learning
based NLP models in a wide range of applications. Despite the continuous gain
in accuracy, backward compatibility is also an important aspect for industrial
applications, yet it received little research attention. Backward compatibility
requires that the new model does not regress on cases that were correctly
handled by its predecessor. This work studies model update regression in
structured prediction tasks. We choose syntactic dependency parsing and
conversational semantic parsing as representative examples of structured
prediction tasks in NLP. First, we measure and analyze model update regression
in different model update settings. Next, we explore and benchmark existing
techniques for reducing model update regression including model ensemble and
knowledge distillation. We further propose a simple and effective method,
Backward-Congruent Re-ranking (BCR), by taking into account the characteristics
of structured output. Experiments show that BCR can better mitigate model
update regression than model ensemble and knowledge distillation approaches.</p>
  </details>
</details>
<details>
  <summary>67. <b>标题：Locally Differentially Private Distributed Deep Learning via Knowledge  Distillation</b></summary>
  <p><b>编号</b>：[172]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02971</p>
  <p><b>作者</b>：Di Zhuang,  Mingchen Li,  J. Morris Chang</p>
  <p><b>备注</b>：10 pages, 6 figures, 1 table. Submitted to IEEE Transactions on Knowledge and Data Engineering</p>
  <p><b>关键词</b>：preserving distributed deep learning framework via local differential privacy, using three popular deep learning benchmark datasets, data segregated across multiple different data owners, often segregated across multiple organizations, conduct distributed deep learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep learning often requires a large amount of data. In real-world
applications, e.g., healthcare applications, the data collected by a single
organization (e.g., hospital) is often limited, and the majority of massive and
diverse data is often segregated across multiple organizations. As such, it
motivates the researchers to conduct distributed deep learning, where the data
user would like to build DL models using the data segregated across multiple
different data owners. However, this could lead to severe privacy concerns due
to the sensitive nature of the data, thus the data owners would be hesitant and
reluctant to participate. We propose LDP-DL, a privacy-preserving distributed
deep learning framework via local differential privacy and knowledge
distillation, where each data owner learns a teacher model using its own
(local) private dataset, and the data user learns a student model to mimic the
output of the ensemble of the teacher models. In the experimental evaluation, a
comprehensive comparison has been made among our proposed approach (i.e.,
LDP-DL), DP-SGD, PATE and DP-FL, using three popular deep learning benchmark
datasets (i.e., CIFAR10, MNIST and FashionMNIST). The experimental results show
that LDP-DL consistently outperforms the other competitors in terms of privacy
budget and model accuracy.</p>
  </details>
</details>
<details>
  <summary>68. <b>标题：Learning from Imperfect Demonstrations via Adversarial Confidence  Transfer</b></summary>
  <p><b>编号</b>：[174]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02967</p>
  <p><b>作者</b>：Zhangjie Cao,  Zihan Wang,  Dorsa Sadigh</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：demonstration algorithms usually assume access, real robot reaching task demonstrate, world applications since, length partial trajectories, highest expected return</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Existing learning from demonstration algorithms usually assume access to
expert demonstrations. However, this assumption is limiting in many real-world
applications since the collected demonstrations may be suboptimal or even
consist of failure cases. We therefore study the problem of learning from
imperfect demonstrations by learning a confidence predictor. Specifically, we
rely on demonstrations along with their confidence values from a different
correspondent environment (source environment) to learn a confidence predictor
for the environment we aim to learn a policy in (target environment -- where we
only have unlabeled demonstrations.) We learn a common latent space through
adversarial distribution matching of multi-length partial trajectories to
enable the transfer of confidence across source and target environments. The
learned confidence reweights the demonstrations to enable learning more from
informative demonstrations and discarding the irrelevant ones. Our experiments
in three simulated environments and a real robot reaching task demonstrate that
our approach learns a policy with the highest expected return.</p>
  </details>
</details>
<details>
  <summary>69. <b>标题：A Machine Learning Approach for Material Type Logging and Chemical  Assaying from Autonomous Measure-While-Drilling (MWD) Data</b></summary>
  <p><b>编号</b>：[179]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02959</p>
  <p><b>作者</b>：Rami N Khushaba (1),  Arman Melkumyan (1),  Andrew J Hill (1) ((1) University of Sydney)</p>
  <p><b>备注</b>：29 pages, 19 figures, mathematical geosciences, Rio Tinto Centre for Mine Automation</p>
  <p><b>关键词</b>：material type logging suffers, machine learning approach, different spatial regions, production blasthole logging, underlying mineral composition</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Understanding the structure and mineralogical composition of a region is an
essential step in mining, both during exploration (before mining) and in the
mining process. During exploration, sparse but high-quality data are gathered
to assess the overall orebody. During the mining process, boundary positions
and material properties are refined as the mine progresses. This refinement is
facilitated through drilling, material logging, and chemical assaying. Material
type logging suffers from a high degree of variability due to factors such as
the diversity in mineralization and geology, the subjective nature of human
measurement even by experts, and human error in manually recording results.
While laboratory-based chemical assaying is much more precise, it is
time-consuming and costly and does not always capture or correlate boundary
positions between all material types. This leads to significant challenges and
financial implications for the industry, as the accuracy of production
blasthole logging and assaying processes is essential for resource evaluation,
planning, and execution of mine plans. To overcome these challenges, this work
reports on a pilot study to automate the process of material logging and
chemical assaying. A machine learning approach has been trained on features
extracted from measurement-while-drilling (MWD) data, logged from autonomous
drilling systems (ADS). MWD data facilitate the construction of profiles of
physical drilling parameters as a function of hole depth. A hypothesis is
formed to link these drilling parameters to the underlying mineral composition.
The results of the pilot study discussed in this paper demonstrate the
feasibility of this process, with correlation coefficients of up to 0.92 for
chemical assays and 93% accuracy for material detection, depending on the
material or assay type and their generalization across the different spatial
regions.</p>
  </details>
</details>
<details>
  <summary>70. <b>标题：Jury Learning: Integrating Dissenting Voices into Machine Learning  Models</b></summary>
  <p><b>编号</b>：[180]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02950</p>
  <p><b>作者</b>：Mitchell L. Gordon,  Michelle S. Lam,  Joon Sung Park,  Kayur Patel,  Jeffrey T. Hancock,  Tatsunori Hashimoto,  Michael S. Bernstein</p>
  <p><b>备注</b>：To appear at CHI 2022</p>
  <p><b>关键词</b>：label disagreements implicitly using majority vote, online toxicity might centrally feature women, supervised ml today resolves, online comment toxicity, supervised ml approach</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Whose labels should a machine learning (ML) algorithm learn to emulate? For
ML tasks ranging from online comment toxicity to misinformation detection to
medical diagnosis, different groups in society may have irreconcilable
disagreements about ground truth labels. Supervised ML today resolves these
label disagreements implicitly using majority vote, which overrides minority
groups' labels. We introduce jury learning, a supervised ML approach that
resolves these disagreements explicitly through the metaphor of a jury:
defining which people or groups, in what proportion, determine the classifier's
prediction. For example, a jury learning model for online toxicity might
centrally feature women and Black jurors, who are commonly targets of online
harassment. To enable jury learning, we contribute a deep learning architecture
that models every annotator in a dataset, samples from annotators' models to
populate the jury, then runs inference to classify. Our architecture enables
juries that dynamically adapt their composition, explore counterfactuals, and
visualize dissent.</p>
  </details>
</details>
<details>
  <summary>71. <b>标题：Parallel Successive Learning for Dynamic Distributed Model Training over  Heterogeneous Wireless Networks</b></summary>
  <p><b>编号</b>：[182]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02947</p>
  <p><b>作者</b>：Seyyedali Hosseinalipour,  Su Wang,  Nicolo Michelusi,  Vaneet Aggarwal,  Christopher G. Brinton,  David J. Love,  Mung Chiang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：numerical results reveal new findings, fedl architecture along three dimensions, stochastic gradient descent iterations, allowing decentralized cooperation among, hard signomial programming problem</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Federated learning (FedL) has emerged as a popular technique for distributing
model training over a set of wireless devices, via iterative local updates (at
devices) and global aggregations (at the server). In this paper, we develop
\textit{parallel successive learning} (PSL), which expands the FedL
architecture along three dimensions: (i) Network, allowing decentralized
cooperation among the devices via device-to-device (D2D) communications. (ii)
Heterogeneity, interpreted at three levels: (ii-a) Learning: PSL considers
heterogeneous number of stochastic gradient descent iterations with different
mini-batch sizes at the devices; (ii-b) Data: PSL presumes a dynamic
environment with data arrival and departure, where the distributions of local
datasets evolve over time, captured via a new metric for model/concept drift.
(ii-c) Device: PSL considers devices with different computation and
communication capabilities. (iii) Proximity, where devices have different
distances to each other and the access point. PSL considers the realistic
scenario where global aggregations are conducted with idle times in-between
them for resource efficiency improvements, and incorporates data dispersion and
model dispersion with local model condensation into FedL. Our analysis sheds
light on the notion of cold vs. warmed up models, and model inertia in
distributed machine learning. We then propose network-aware dynamic model
tracking to optimize the model learning vs. resource efficiency tradeoff, which
we show is an NP-hard signomial programming problem. We finally solve this
problem through proposing a general optimization solver. Our numerical results
reveal new findings on the interdependencies between the idle times in-between
the global aggregations, model/concept drift, and D2D cooperation
configuration.</p>
  </details>
</details>
<details>
  <summary>72. <b>标题：Tractable Boolean and Arithmetic Circuits</b></summary>
  <p><b>编号</b>：[184]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02942</p>
  <p><b>作者</b>：Adnan Darwiche</p>
  <p><b>备注</b>：An earlier version of this article appeared in the following edited book. Pascal Hitzler and Md Kamruzzaman Sarker, editors. Neuro-Symbolic Artificial Intelligence: The State of the Art, volume 342 of Frontiers in Artificial Intelligence and Applications. IOS Press, 2021</p>
  <p><b>关键词</b>：forward fashion like neural networks, compiled objects ," meant, permit various types, two decades, tractable boolean</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Tractable Boolean and arithmetic circuits have been studied extensively in AI
for over two decades now. These circuits were initially proposed as "compiled
objects," meant to facilitate logical and probabilistic reasoning, as they
permit various types of inference to be performed in linear-time and a
feed-forward fashion like neural networks. In more recent years, the role of
tractable circuits has significantly expanded as they became a computational
and semantical backbone for some approaches that aim to integrate knowledge,
reasoning and learning. In this article, we review the foundations of tractable
circuits and some associated milestones, while focusing on their core
properties and techniques that make them particularly useful for the broad aims
of neuro-symbolic AI.</p>
  </details>
</details>
<details>
  <summary>73. <b>标题：TRGP: Trust Region Gradient Projection for Continual Learning</b></summary>
  <p><b>编号</b>：[188]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02931</p>
  <p><b>作者</b>：Sen Lin,  Li Yang,  Deliang Fan,  Junshan Zhang</p>
  <p><b>备注</b>：Published as a conference paper at ICLR 2022</p>
  <p><b>关键词</b>：effectively prompt knowledge transfer without forgetting, existing methods put restrictive constraints, propose trust region gradient projection, forward knowledge transfer based, approach achieves significant improvement</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Catastrophic forgetting is one of the major challenges in continual learning.
To address this issue, some existing methods put restrictive constraints on the
optimization space of the new task for minimizing the interference to old
tasks. However, this may lead to unsatisfactory performance for the new task,
especially when the new task is strongly correlated with old tasks. To tackle
this challenge, we propose Trust Region Gradient Projection (TRGP) for
continual learning to facilitate the forward knowledge transfer based on an
efficient characterization of task correlation. Particularly, we introduce a
notion of `trust region' to select the most related old tasks for the new task
in a layer-wise and single-shot manner, using the norm of gradient projection
onto the subspace spanned by task inputs. Then, a scaled weight projection is
proposed to cleverly reuse the frozen weights of the selected old tasks in the
trust region through a layer-wise scaling matrix. By jointly optimizing the
scaling matrices and the model, where the model is updated along the directions
orthogonal to the subspaces of old tasks, TRGP can effectively prompt knowledge
transfer without forgetting. Extensive experiments show that our approach
achieves significant improvement over related state-of-the-art methods.</p>
  </details>
</details>
<details>
  <summary>74. <b>标题：Model-Based Offline Meta-Reinforcement Learning with Regularization</b></summary>
  <p><b>编号</b>：[190]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02929</p>
  <p><b>作者</b>：Sen Lin,  Jialin Wan,  Tengyu Xu,  Yingbin Liang,  Junshan Zhang</p>
  <p><b>备注</b>：Published as a conference paper at ICLR 2022</p>
  <p><b>关键词</b>：learnt policy offers guaranteed improvement, efficient task structure inference, new tasks via offline meta, existing offline reinforcement learning, using conservative policy evaluation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Existing offline reinforcement learning (RL) methods face a few major
challenges, particularly the distributional shift between the learned policy
and the behavior policy. Offline Meta-RL is emerging as a promising approach to
address these challenges, aiming to learn an informative meta-policy from a
collection of tasks. Nevertheless, as shown in our empirical studies, offline
Meta-RL could be outperformed by offline single-task RL methods on tasks with
good quality of datasets, indicating that a right balance has to be delicately
calibrated between "exploring" the out-of-distribution state-actions by
following the meta-policy and "exploiting" the offline dataset by staying close
to the behavior policy. Motivated by such empirical analysis, we explore
model-based offline Meta-RL with regularized Policy Optimization (MerPO), which
learns a meta-model for efficient task structure inference and an informative
meta-policy for safe exploration of out-of-distribution state-actions. In
particular, we devise a new meta-Regularized model-based Actor-Critic (RAC)
method for within-task policy optimization, as a key building block of MerPO,
using conservative policy evaluation and regularized policy improvement; and
the intrinsic tradeoff therein is achieved via striking the right balance
between two regularizers, one based on the behavior policy and the other on the
meta-policy. We theoretically show that the learnt policy offers guaranteed
improvement over both the behavior policy and the meta-policy, thus ensuring
the performance improvement on new tasks via offline Meta-RL. Experiments
corroborate the superior performance of MerPO over existing offline Meta-RL
methods.</p>
  </details>
</details>
<details>
  <summary>75. <b>标题：ABG: A Multi-Party Mixed Protocol Framework for Privacy-Preserving  Cooperative Learning</b></summary>
  <p><b>编号</b>：[191]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02928</p>
  <p><b>作者</b>：Hao Wang,  Zhi Li,  Chunpeng Ge,  Willy Susilo</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：party mixed protocol framework, effectively implements arbitrary conversion, abg $^ n $,, abg $^ n $,, n $- party scenarios</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Cooperative learning, that enables two or more data owners to jointly train a
model, has been widely adopted to solve the problem of insufficient training
data in machine learning. Nowadays, there is an urgent need for institutions
and organizations to train a model cooperatively while keeping each other's
data privately. To address the issue of privacy-preserving in collaborative
learning, secure outsourced computation and federated learning are two typical
methods. Nevertheless, there are many drawbacks for these two methods when they
are leveraged in cooperative learning. For secure outsourced computation,
semi-honest servers need to be introduced. Once the outsourced servers collude
or perform other active attacks, the privacy of data will be disclosed. For
federated learning, it is difficult to apply to the scenarios where vertically
partitioned data are distributed over multiple parties. In this work, we
propose a multi-party mixed protocol framework, ABG$^n$, which effectively
implements arbitrary conversion between Arithmetic sharing (A), Boolean sharing
(B) and Garbled-Circuits sharing (G) for $n$-party scenarios. Based on ABG$^n$,
we design a privacy-preserving multi-party cooperative learning system, which
allows different data owners to cooperate in machine learning in terms of data
security and privacy-preserving. Additionally, we design specific
privacy-preserving computation protocols for some typical machine learning
methods such as logistic regression and neural networks. Compared with previous
work, the proposed method has a wider scope of application and does not need to
rely on additional servers. Finally, we evaluate the performance of ABG$^n$ on
the local setting and on the public cloud setting. The experiments indicate
that ABG$^n$ has excellent performance, especially in the network environment
with low latency.</p>
  </details>
</details>
<details>
  <summary>76. <b>标题：Soft Actor-Critic with Inhibitory Networks for Faster Retraining</b></summary>
  <p><b>编号</b>：[196]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02918</p>
  <p><b>作者</b>：Jaime S. Ide,  Daria Mićović,  Michael J. Guarino,  Kevin Alcedo,  David Rosenbluth</p>
  <p><b>备注</b>：16 pages including Appendix</p>
  <p><b>关键词</b>：novel approach using inhibitory networks, adaptive state value evaluations, reusing previously trained models, distinct automatic entropy tuning, exploring novel ones</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Reusing previously trained models is critical in deep reinforcement learning
to speed up training of new agents. However, it is unclear how to acquire new
skills when objectives and constraints are in conflict with previously learned
skills. Moreover, when retraining, there is an intrinsic conflict between
exploiting what has already been learned and exploring new skills. In soft
actor-critic (SAC) methods, a temperature parameter can be dynamically adjusted
to weight the action entropy and balance the explore $\times$ exploit
trade-off. However, controlling a single coefficient can be challenging within
the context of retraining, even more so when goals are contradictory. In this
work, inspired by neuroscience research, we propose a novel approach using
inhibitory networks to allow separate and adaptive state value evaluations, as
well as distinct automatic entropy tuning. Ultimately, our approach allows for
controlling inhibition to handle conflict between exploiting less risky,
acquired behaviors and exploring novel ones to overcome more challenging tasks.
We validate our method through experiments in OpenAI Gym environments.</p>
  </details>
</details>
<details>
  <summary>77. <b>标题：Dataset Condensation with Contrastive Signals</b></summary>
  <p><b>编号</b>：[197]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02916</p>
  <p><b>作者</b>：Saehyung Lee,  Sanghyuk Chun,  Sangwon Jung,  Sangdoo Yun,  Sungroh Yoon</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：successfully generate informative synthetic datasets, grained image classification tasks, wise gradient matching strategy, irrelevant information forms, experimental results indicate</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent studies have demonstrated that gradient matching-based dataset
synthesis, or dataset condensation (DC), methods can achieve state-of-the-art
performance when applied to data-efficient learning tasks. However, in this
study, we prove that the existing DC methods can perform worse than the random
selection method when task-irrelevant information forms a significant part of
the training dataset. We attribute this to the lack of participation of the
contrastive signals between the classes resulting from the class-wise gradient
matching strategy. To address this problem, we propose Dataset Condensation
with Contrastive signals (DCC) by modifying the loss function to enable the DC
methods to effectively capture the differences between classes. In addition, we
analyze the new loss function in terms of training dynamics by tracking the
kernel velocity. Furthermore, we introduce a bi-level warm-up strategy to
stabilize the optimization. Our experimental results indicate that while the
existing methods are ineffective for fine-grained image classification tasks,
the proposed method can successfully generate informative synthetic datasets
for the same tasks. Moreover, we demonstrate that the proposed method
outperforms the baselines even on benchmark datasets such as SVHN, CIFAR-10,
and CIFAR-100. Finally, we demonstrate the high applicability of the proposed
method by applying it to continual learning tasks.</p>
  </details>
</details>
<details>
  <summary>78. <b>标题：Universality of parametric Coupling Flows over parametric  diffeomorphisms</b></summary>
  <p><b>编号</b>：[201]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02906</p>
  <p><b>作者</b>：Junlong Lyu,  Zhitang Chen,  Chang Feng,  Wenjing Cun,  Shengyu Zhu,  Yanhui Geng,  Zhijie Xu,  Yongwei Chen</p>
  <p><b>备注</b>：22 pages, 6 figures</p>
  <p><b>关键词</b>：proposed parametric coupling flows named para, invertible neural networks based, invertible linear transforms achieves, contextual bayesian optimization tasks, coupling flows cflows</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Invertible neural networks based on Coupling Flows CFlows) have various
applications such as image synthesis and data compression. The approximation
universality for CFlows is of paramount importance to ensure the model
expressiveness. In this paper, we prove that CFlows can approximate any
diffeomorphism in C^k-norm if its layers can approximate certain
single-coordinate transforms. Specifically, we derive that a composition of
affine coupling layers and invertible linear transforms achieves this
universality. Furthermore, in parametric cases where the diffeomorphism depends
on some extra parameters, we prove the corresponding approximation theorems for
our proposed parametric coupling flows named Para-CFlows. In practice, we apply
Para-CFlows as a neural surrogate model in contextual Bayesian optimization
tasks, to demonstrate its superiority over other neural surrogate models in
terms of optimization performance.</p>
  </details>
</details>
<details>
  <summary>79. <b>标题：A Least Square Approach to Semi-supervised Local Cluster Extraction</b></summary>
  <p><b>编号</b>：[203]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02904</p>
  <p><b>作者</b>：Ming-Jun Lai,  Zhaiming Shen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：yaleb human faces data sets, supervised local clustering algorithm based, two stage approaches similar, several numerical experiments including, less computational complexity</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A least square semi-supervised local clustering algorithm based on the idea
of compressed sensing are proposed to extract clusters from a graph with known
adjacency matrix. The algorithm is based on a two stage approaches similar to
the one in \cite{LaiMckenzie2020}. However, under a weaker assumption and with
less computational complexity than the one in \cite{LaiMckenzie2020}, the
algorithm is shown to be able to find a desired cluster with high probability.
Several numerical experiments including the synthetic data and real data such
as MNIST, AT\&T and YaleB human faces data sets are conducted to demonstrate
the performance of our algorithm.</p>
  </details>
</details>
<details>
  <summary>80. <b>标题：Redactor: Targeted Disinformation Generation using Probabilistic  Decision Boundaries</b></summary>
  <p><b>编号</b>：[204]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02902</p>
  <p><b>作者</b>：Geon Heo,  Steven Euijong Whang</p>
  <p><b>备注</b>：9 pages, 7 figures</p>
  <p><b>关键词</b>：multiple classifiers using data programming techniques, various information becomes publicly available, private information could easily, machine learning models train, targeted data poisoning attacks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Information leakage is becoming a critical problem as various information
becomes publicly available by mistake, and machine learning models train on
that data to provide services. As a result, one's private information could
easily be memorized by such trained models. Unfortunately, deleting information
is out of the question as the data is already exposed to the Web or third-party
platforms. Moreover, we cannot necessarily control the labeling process and the
model trainings by other parties either. In this setting, we study the problem
of targeted disinformation where the goal is to lower the accuracy of inference
attacks on a specific target (e.g., a person's profile) only using data
insertion. While our problem is related to data privacy and defenses against
exploratory attacks, our techniques are inspired by targeted data poisoning
attacks with some key differences. We show that our problem is best solved by
finding the closest points to the target in the input space that will be
labeled as a different class. Since we do not control the labeling process, we
instead conservatively estimate the labels probabilistically by combining
decision boundaries of multiple classifiers using data programming techniques.
We also propose techniques for making the disinformation realistic. Our
experiments show that a probabilistic decision boundary can be a good proxy for
labelers, and that our approach outperforms other targeted poisoning methods
when using end-to-end training on real datasets.</p>
  </details>
</details>
<details>
  <summary>81. <b>标题：Gradient boosting machines and careful pre-processing work best: ASHRAE  Great Energy Predictor III lessons learned</b></summary>
  <p><b>编号</b>：[206]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02898</p>
  <p><b>作者</b>：Clayton Miller,  Liu Hao,  Chun Fu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：largest machine learning competitions ever held focused, performing solutions mostly used ensembles, ashrae great energy predictor iii, paper outlines lessons learned, survey respondents used python</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The ASHRAE Great Energy Predictor III (GEPIII) competition was held in late
2019 as one of the largest machine learning competitions ever held focused on
building performance. It was hosted on the Kaggle platform and resulted in
39,402 prediction submissions, with the top five teams splitting $25,000 in
prize money. This paper outlines lessons learned from participants, mainly from
teams who scored in the top 5% of the competition. Various insights were gained
from their experience through an online survey, analysis of publicly shared
submissions and notebooks, and the documentation of the winning teams. The
top-performing solutions mostly used ensembles of Gradient Boosting Machine
(GBM) tree-based models, with the LightGBM package being the most popular. The
survey participants indicated that the preprocessing and feature extraction
phases were the most important aspects of creating the best modeling approach.
All the survey respondents used Python as their primary modeling tool, and it
was common to use Jupyter-style Notebooks as development environments. These
conclusions are essential to help steer the research and practical
implementation of building energy meter prediction in the future.</p>
  </details>
</details>
<details>
  <summary>82. <b>标题：Evaluation Methods and Measures for Causal Learning Algorithms</b></summary>
  <p><b>编号</b>：[207]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02896</p>
  <p><b>作者</b>：Lu Cheng,  Ruocheng Guo,  Raha Moraffah,  Paras Sheth,  K. Selcuk Candan,  Huan Liu</p>
  <p><b>备注</b>：21 pages. Accepted to IEEE TAI</p>
  <p><b>关键词</b>：examine popular causal inference tools, developing causal learning algorithms aiming, e ., causal machine learning, developing publicly available benchmarks, therefore witnessed great effort</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The convenient access to copious multi-faceted data has encouraged machine
learning researchers to reconsider correlation-based learning and embrace the
opportunity of causality-based learning, i.e., causal machine learning (causal
learning). Recent years have therefore witnessed great effort in developing
causal learning algorithms aiming to help AI achieve human-level intelligence.
Due to the lack-of ground-truth data, one of the biggest challenges in current
causal learning research is algorithm evaluations. This largely impedes the
cross-pollination of AI and causal inference, and hinders the two fields to
benefit from the advances of the other. To bridge from conventional causal
inference (i.e., based on statistical methods) to causal learning with big data
(i.e., the intersection of causal inference and machine learning), in this
survey, we review commonly-used datasets, evaluation methods, and measures for
causal learning using an evaluation pipeline similar to conventional machine
learning. We focus on the two fundamental causal-inference tasks and
causality-aware machine learning tasks. Limitations of current evaluation
procedures are also discussed. We then examine popular causal inference
tools/packages and conclude with primary challenges and opportunities for
benchmarking causal learning algorithms in the era of big data. The survey
seeks to bring to the forefront the urgency of developing publicly available
benchmarks and consensus-building standards for causal learning evaluation with
observational data. In doing so, we hope to broaden the discussions and
facilitate collaboration to advance the innovation and application of causal
learning.</p>
  </details>
</details>
<details>
  <summary>83. <b>标题：Effects of Parametric and Non-Parametric Methods on High Dimensional  Sparse Matrix Representations</b></summary>
  <p><b>编号</b>：[209]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02894</p>
  <p><b>作者</b>：Sayali Tambe,  Raunak Joshi,  Abhishek Gupta,  Nandan Kanvinde,  Vidya Chitre</p>
  <p><b>备注</b>：7 pages, 6 tables, 13 equations</p>
  <p><b>关键词</b>：performed classification using linear discriminant analysis, high dimensional sparse matrix representations, high dimensional sparse matrix, every single algorithm detailed, every single dimension</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The semantics are derived from textual data that provide representations for
Machine Learning algorithms. These representations are interpretable form of
high dimensional sparse matrix that are given as an input to the machine
learning algorithms. Since learning methods are broadly classified as
parametric and non-parametric learning methods, in this paper we provide the
effects of these type of algorithms on the high dimensional sparse matrix
representations. In order to derive the representations from the text data, we
have considered TF-IDF representation with valid reason in the paper. We have
formed representations of 50, 100, 500, 1000 and 5000 dimensions respectively
over which we have performed classification using Linear Discriminant Analysis
and Naive Bayes as parametric learning method, Decision Tree and Support Vector
Machines as non-parametric learning method. We have later provided the metrics
on every single dimension of the representation and effect of every single
algorithm detailed in this paper.</p>
  </details>
</details>
<details>
  <summary>84. <b>标题：Learning under Storage and Privacy Constraints</b></summary>
  <p><b>编号</b>：[210]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02892</p>
  <p><b>作者</b>：Berivan Isik,  Tsachy Weissman</p>
  <p><b>备注</b>：6 pages, 3 figures</p>
  <p><b>关键词</b>：method comprises noise injection followed, noise level ), overall storage, time providing privacy guarantees, sensitive user data required, increasingly many learning tasks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Storage-efficient privacy-guaranteed learning is crucial due to enormous
amounts of sensitive user data required for increasingly many learning tasks.
We propose a framework for reducing the storage cost while at the same time
providing privacy guarantees, without essential loss in the utility of the data
for learning. Our method comprises noise injection followed by lossy
compression. We show that, when appropriately matching the lossy compression to
the distribution of the added noise, the compressed examples converge, in
distribution, to that of the noise-free training data. In this sense, the
utility of the data for learning is essentially maintained, while reducing
storage and privacy leakage by quantifiable amounts. We present experimental
results on the CelebA dataset for gender classification and find that our
suggested pipeline delivers in practice on the promise of the theory: the
individuals in the images are unrecognizable (or less recognizable, depending
on the noise level), overall storage of the data is substantially reduced, with
no essential loss of the classification accuracy. As an added bonus, our
experiments suggest that our method yields a substantial boost to robustness in
the face of adversarial test data.</p>
  </details>
</details>
<details>
  <summary>85. <b>标题：Causal Inference Using Tractable Circuits</b></summary>
  <p><b>编号</b>：[211]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02891</p>
  <p><b>作者</b>：Adnan Darwiche</p>
  <p><b>备注</b>：Appeared in Why-21 workshop of NeurIPS 2021 (Causal Inference & Machine Learning: Why now?)</p>
  <p><b>关键词</b>：exploit causal mechanisms computationally, may potentially contribute, based supervised learning, causal graph parametrized, versatile causal inference</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The aim of this paper is to discuss a recent result which shows that
probabilistic inference in the presence of (unknown) causal mechanisms can be
tractable for models that have traditionally been viewed as intractable. This
result was reported recently to facilitate model-based supervised learning but
it can be interpreted in a causality context as follows. One can compile a
non-parametric causal graph into an arithmetic circuit that supports inference
in time linear in the circuit size. The circuit is also non-parametric so it
can be used to estimate parameters from data and to further reason (in linear
time) about the causal graph parametrized by these estimates. Moreover, the
circuit size can sometimes be bounded even when the treewidth of the causal
graph is not, leading to tractable inference on models that have been deemed
intractable previously. This has been enabled by a new technique that can
exploit causal mechanisms computationally but without needing to know their
identities (the classical setup in causal inference). Our goal is to provide a
causality-oriented exposure to these new results and to speculate on how they
may potentially contribute to more scalable and versatile causal inference.</p>
  </details>
</details>
<details>
  <summary>86. <b>标题：Trusted Approximate Policy Iteration with Bisimulation Metrics</b></summary>
  <p><b>编号</b>：[215]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02881</p>
  <p><b>作者</b>：Mete Kemertas,  Allan Jepson</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：uses $\ epsilon $- aggregation, api ($\ alpha $) procedure, $\ pi $- bisimulation metrics, $\ pi $- bisimulation, novel trust region approach</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Bisimulation metrics define a distance measure between states of a Markov
decision process (MDP) based on a comparison of reward sequences. Due to this
property they provide theoretical guarantees in value function approximation.
In this work we first prove that bisimulation metrics can be defined via any
$p$-Wasserstein metric for $p\geq 1$. Then we describe an approximate policy
iteration (API) procedure that uses $\epsilon$-aggregation with
$\pi$-bisimulation and prove performance bounds for continuous state spaces. We
bound the difference between $\pi$-bisimulation metrics in terms of the change
in the policies themselves. Based on these theoretical results, we design an
API($\alpha$) procedure that employs conservative policy updates and enjoys
better performance bounds than the naive API approach. In addition, we propose
a novel trust region approach which circumvents the requirement to explicitly
solve a constrained optimization problem. Finally, we provide experimental
evidence of improved stability compared to non-conservative alternatives in
simulated continuous control.</p>
  </details>
</details>
<details>
  <summary>87. <b>标题：Differentiable Economics for Randomized Affine Maximizer Auctions</b></summary>
  <p><b>编号</b>：[219]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02872</p>
  <p><b>作者</b>：Michael Curry,  Tuomas Sandholm,  John Dickerson</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：classic affine maximizer auction, train lottery amas, supports multiple bidders, support multiple bidders, based optimization tools</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A recent approach to automated mechanism design, differentiable economics,
represents auctions by rich function approximators and optimizes their
performance by gradient descent. The ideal auction architecture for
differentiable economics would be perfectly strategyproof, support multiple
bidders and items, and be rich enough to represent the optimal (i.e.
revenue-maximizing) mechanism. So far, such an architecture does not exist.
There are single-bidder approaches (MenuNet, RochetNet) which are always
strategyproof and can represent optimal mechanisms. RegretNet is multi-bidder
and can approximate any mechanism, but is only approximately strategyproof. We
present an architecture that supports multiple bidders and is perfectly
strategyproof, but cannot necessarily represent the optimal mechanism. This
architecture is the classic affine maximizer auction (AMA), modified to offer
lotteries. By using the gradient-based optimization tools of differentiable
economics, we can now train lottery AMAs, competing with or outperforming prior
approaches in revenue.</p>
  </details>
</details>
<details>
  <summary>88. <b>标题：Applications of Machine Learning in Healthcare and Internet of Things  (IOT): A Comprehensive Review</b></summary>
  <p><b>编号</b>：[221]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02868</p>
  <p><b>作者</b>：Farid Ghareh Mohammadi,  Farzan Shenavarmasouleh,  Hamid R. Arabnia</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：art machine learning applications particularly, applying traditional centralized learning algorithms, perform medical distributed data analysis, smart healthcare iot devices, decentralized data collected</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In recent years, smart healthcare IoT devices have become ubiquitous, but
they work in isolated networks due to their policy. Having these devices
connected in a network enables us to perform medical distributed data analysis.
However, the presence of diverse IoT devices in terms of technology, structure,
and network policy, makes it a challenging issue while applying traditional
centralized learning algorithms on decentralized data collected from the IoT
devices. In this study, we present an extensive review of the state-of-the-art
machine learning applications particularly in healthcare, challenging issues in
IoT, and corresponding promising solutions. Finally, we highlight some
open-ended issues of IoT in healthcare that leaves further research studies and
investigation for scientists.</p>
  </details>
</details>
<details>
  <summary>89. <b>标题：Machine Learning Aided Holistic Handover Optimization for Emerging  Networks</b></summary>
  <p><b>编号</b>：[225]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02851</p>
  <p><b>作者</b>：Muhammad Umar Bin Farooq,  Marvin Manalastas,  Syed Muhammad Asad Zaidi,  Adnan Abu-Dayya,  Ali Imran</p>
  <p><b>备注</b>：Accepted in IEEE International Conference on Communications (ICC) 2022</p>
  <p><b>关键词</b>：kpis ): edge user reference signal received power, jointly maximize three critical key performance indicators, mobility parameters provides several insights, rsrp ), handover success rate, optimize five parameters namely a5</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In the wake of network densification and multi-band operation in emerging
cellular networks, mobility and handover management is becoming a major
bottleneck. The problem is further aggravated by the fact that holistic
mobility management solutions for different types of handovers, namely
inter-frequency and intra-frequency handovers, remain scarce. This paper
presents a first mobility management solution that concurrently optimizes
inter-frequency related A5 parameters and intra-frequency related A3
parameters. We analyze and optimize five parameters namely A5-time to trigger
(TTT), A5-threshold1, A5-threshold2, A3-TTT, and A3-offset to jointly maximize
three critical key performance indicators (KPIs): edge user reference signal
received power (RSRP), handover success rate (HOSR) and load between frequency
bands. In the absence of tractable analytical models due to system level
complexity, we leverage machine learning to quantify the KPIs as a function of
the mobility parameters. An XGBoost based model has the best performance for
edge RSRP and HOSR while random forest outperforms others for load prediction.
An analysis of the mobility parameters provides several insights: 1) there
exists a strong coupling between A3 and A5 parameters; 2) an optimal set of
parameters exists for each KPI; and 3) the optimal parameters vary for
different KPIs. We also perform a SHAP based sensitivity to help resolve the
parametric conflict between the KPIs. Finally, we formulate a maximization
problem, show it is non-convex, and solve it utilizing simulated annealing
(SA). Results indicate that ML-based SA-aided solution is more than 14x faster
than the brute force approach with a slight loss in optimality.</p>
  </details>
</details>
<details>
  <summary>90. <b>标题：Stochastic Gradient Descent with Dependent Data for Offline  Reinforcement Learning</b></summary>
  <p><b>编号</b>：[226]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02850</p>
  <p><b>作者</b>：Jing Dong,  Xin T. Tong</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：(\ epsilon ^{- 2 }( 1 -\ gamma )^{- 5 })$,, include algorithms making approximately contractive iterations, solved using approximate stochastic gradient descent, rl ), offline learning decoupled learning, discount factor $\ gamma $.</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In reinforcement learning (RL), offline learning decoupled learning from data
collection and is useful in dealing with exploration-exploitation tradeoff and
enables data reuse in many applications. In this work, we study two offline
learning tasks: policy evaluation and policy learning. For policy evaluation,
we formulate it as a stochastic optimization problem and show that it can be
solved using approximate stochastic gradient descent (aSGD) with time-dependent
data. We show aSGD achieves $\tilde O(1/t)$ convergence when the loss function
is strongly convex and the rate is independent of the discount factor $\gamma$.
This result can be extended to include algorithms making approximately
contractive iterations such as TD(0). The policy evaluation algorithm is then
combined with the policy iteration algorithm to learn the optimal policy. To
achieve an $\epsilon$ accuracy, the complexity of the algorithm is $\tilde
O(\epsilon^{-2}(1-\gamma)^{-5})$, which matches the complexity bound for
classic online RL algorithms such as Q-learning.</p>
  </details>
</details>
<details>
  <summary>91. <b>标题：A Novel Micro-service Based Platform for Composition, Deployment and  Execution of BDA Applications</b></summary>
  <p><b>编号</b>：[228]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02845</p>
  <p><b>作者</b>：Davide Profeta,  Nicola Masi,  Domenico Messina,  Davide Dalle Carbonare,  Susanna Bonura,  Vito Morreale</p>
  <p><b>备注</b>：45th Euromicro Conference on Software Engineering and Advanced Applications, SEAA 2019, Kallithea-Chalkidiki, Greece, August 28-30, 2019</p>
  <p><b>关键词</b>：big data frameworks deployment properties, register new bda applications, bda applications provided, web user interface, previous research activities</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Big Data are growing at an exponential rate and it becomes necessary the use
of tools and technologies to manage, process and visualize them in order to
extract value. In this paper a micro-service based platform is presented for
the composition, deployment and execution of Big Data Analytics (BDA)
application workflows in several domains and scenarios is presented. ALIDA is a
result coming from previous research activities by ENGINEERING. It aims to
achieve a unified platform that allows both BDA application developers and data
analysts to interact with it. Developers will be able to register new BDA
applications through the exposed API and/or through the web user interface.
Data analysts will be able to use the BDA applications provided to create
batch/stream workflows through a dashboard user interface to manipulate and
subsequently visualize results from one or more sources. The platform also
supports the auto-tuning of Big Data frameworks deployment properties to
improve metrics for analytics application. ALIDA has been properly extended and
integrated into a software solution for the analysis of large amounts of data
from the avionic industries. A use case within this context is then presented.</p>
  </details>
</details>
<details>
  <summary>92. <b>标题：Evaluating natural language processing models with generalization  metrics that do not need access to any training or testing data</b></summary>
  <p><b>编号</b>：[230]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02842</p>
  <p><b>作者</b>：Yaoqing Yang,  Ryan Theisen,  Liam Hodgkinson,  Joseph E. Gonzalez,  Kannan Ramchandran,  Charles H. Martin,  Michael W. Mahoney</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：among forty generalization metrics studied, received comparatively less attention, predict test error instead, exponentially truncated power law, detailed empirical studies show</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The search for effective and robust generalization metrics has been the focus
of recent theoretical and empirical work.
In this paper, we discuss the performance of natural language processing
(NLP) models, and we evaluate various existing and novel generalization
metrics.
Compared to prior studies, we
(i) focus on NLP instead of computer vision (CV),
(ii) focus on generalization metrics that predict test error instead of the
generalization gap,
(iii) focus on generalization metrics that do not need the access to data,
and
(iv) focus on the heavy-tail (HT) phenomenon that has received comparatively
less attention in the study of deep neural networks (NNs).
We extend recent HT-based work which focuses on power law (PL) distributions,
and we study exponential (EXP) and exponentially truncated power law (E-TPL)
fitting to the empirical spectral densities (ESDs) of weight matrices.
Our detailed empirical studies show that
(i) \emph{shape metrics}, or the metrics obtained from fitting the shape of
the ESDs, perform uniformly better at predicting generalization performance
than \emph{scale metrics} commonly studied in the literature, as measured by
the \emph{average} rank correlations with the generalization performance for
all of our experiments;
(ii) among forty generalization metrics studied in our paper, the
\RANDDISTANCE metric, a new shape metric invented in this paper that measures
the distance between empirical eigenvalues of weight matrices and those of
randomly initialized weight matrices, achieves the highest worst-case rank
correlation with generalization performance under a variety of training
settings; and
(iii) among the three HT distributions considered in our paper, the E-TPL
fitting of ESDs performs the most robustly.</p>
  </details>
</details>
<details>
  <summary>93. <b>标题：Discovering Personalized Semantics for Soft Attributes in Recommender  Systems using Concept Activation Vectors</b></summary>
  <p><b>编号</b>：[232]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02830</p>
  <p><b>作者</b>：Christina Göpfert,  Yinlam Chow,  Chih-wei Hsu,  Ivan Vendrov,  Tyler Lu,  Deepak Ramachandran,  Craig Boutilier</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：improve recommendations via interactive critiquing, cav representation accurately interprets users, leveraging concept activation vectors, often using natural language, interactive recommender systems</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Interactive recommender systems (RSs) allow users to express intent,
preferences and contexts in a rich fashion, often using natural language. One
challenge in using such feedback is inferring a user's semantic intent from the
open-ended terms used to describe an item, and using it to refine
recommendation results. Leveraging concept activation vectors (CAVs) [21], we
develop a framework to learn a representation that captures the semantics of
such attributes and connects them to user preferences and behaviors in RSs. A
novel feature of our approach is its ability to distinguish objective and
subjective attributes and associate different senses with different users.
Using synthetic and real-world datasets, we show that our CAV representation
accurately interprets users' subjective semantics, and can improve
recommendations via interactive critiquing</p>
  </details>
</details>
<details>
  <summary>94. <b>标题：BEAS: Blockchain Enabled Asynchronous & Secure Federated Machine  Learning</b></summary>
  <p><b>编号</b>：[239]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02817</p>
  <p><b>作者</b>：Arup Mondal,  Harpreet Virk,  Debayan Gupta</p>
  <p><b>备注</b>：The Third AAAI Workshop on Privacy-Preserving Artificial Intelligence (PPAI-22) at the Thirty-Sixth AAAI Conference on Artificial Intelligence (AAAI-22)</p>
  <p><b>关键词</b>：showing improved differential privacy compared, beas successfully prevents privacy leakage, training data using gradient pruning, provides strict privacy guarantees, computation overheads scale linearly</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Federated Learning (FL) enables multiple parties to distributively train a ML
model without revealing their private datasets. However, it assumes trust in
the centralized aggregator which stores and aggregates model updates. This
makes it prone to gradient tampering and privacy leakage by a malicious
aggregator. Malicious parties can also introduce backdoors into the joint model
by poisoning the training data or model gradients. To address these issues, we
present BEAS, the first blockchain-based framework for N-party FL that provides
strict privacy guarantees of training data using gradient pruning (showing
improved differential privacy compared to existing noise and clipping based
techniques). Anomaly detection protocols are used to minimize the risk of
data-poisoning attacks, along with gradient pruning that is further used to
limit the efficacy of model-poisoning attacks. We also define a novel protocol
to prevent premature convergence in heterogeneous learning environments. We
perform extensive experiments on multiple datasets with promising results: BEAS
successfully prevents privacy leakage from dataset reconstruction attacks, and
minimizes the efficacy of poisoning attacks. Moreover, it achieves an accuracy
similar to centralized frameworks, and its communication and computation
overheads scale linearly with the number of participants.</p>
  </details>
</details>
<details>
  <summary>95. <b>标题：Lossy Gradient Compression: How Much Accuracy Can One Bit Buy?</b></summary>
  <p><b>编号</b>：[240]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02812</p>
  <p><b>作者</b>：Sadaf Salehkalaibar,  Stefano Rini</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：meet communication rate constraints, aggregating model updates obtained, one would like, l_2 $" norm, generalized normal distribution</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In federated learning (FL), a global model is trained at a Parameter Server
(PS) by aggregating model updates obtained from multiple remote learners.
Critically, the communication between the remote users and the PS is limited by
the available power for transmission, while the transmission from the PS to the
remote users can be considered unbounded. This gives rise to the distributed
learning scenario in which the updates from the remote learners have to be
compressed so as to meet communication rate constraints in the uplink
transmission toward the PS. For this problem, one would like to compress the
model updates so as to minimize the resulting loss in accuracy. In this paper,
we take a rate-distortion approach to answer this question for the distributed
training of a deep neural network (DNN). In particular, we define a measure of
the compression performance, the \emph{per-bit accuracy}, which addresses the
ultimate model accuracy that a bit of communication brings to the centralized
model. In order to maximize the per-bit accuracy, we consider modeling the
gradient updates at remote learners as a generalized normal distribution. Under
this assumption on the model update distribution, we propose a class of
distortion measures for the design of quantizer for the compression of the
model updates. We argue that this family of distortion measures, which we refer
to as "$M$-magnitude weighted $L_2$" norm, capture the practitioner intuition
in the choice of gradient compressor. Numerical simulations are provided to
validate the proposed approach.</p>
  </details>
</details>
<details>
  <summary>96. <b>标题：Low-confidence Samples Matter for Domain Adaptation</b></summary>
  <p><b>编号</b>：[244]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02802</p>
  <p><b>作者</b>：Yixin Zhang,  Junjie Li,  Zilei Wang</p>
  <p><b>备注</b>：11 pages, 5 figures</p>
  <p><b>关键词</b>：build reliable pseudo labels, intermediate representations across domains, novel contrastive learning method, way would overlook, instance discrimination process</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Domain adaptation (DA) aims to transfer knowledge from a label-rich source
domain to a related but label-scarce target domain. The conventional DA
strategy is to align the feature distributions of the two domains. Recently,
increasing researches have focused on self-training or other semi-supervised
algorithms to explore the data structure of the target domain. However, the
bulk of them depend largely on confident samples in order to build reliable
pseudo labels, prototypes or cluster centers. Representing the target data
structure in such a way would overlook the huge low-confidence samples,
resulting in sub-optimal transferability that is biased towards the samples
similar to the source domain. To overcome this issue, we propose a novel
contrastive learning method by processing low-confidence samples, which
encourages the model to make use of the target data structure through the
instance discrimination process. To be specific, we create positive and
negative pairs only using low-confidence samples, and then re-represent the
original features with the classifier weights rather than directly utilizing
them, which can better encode the task-specific semantic information.
Furthermore, we combine cross-domain mixup to augment the proposed contrastive
loss. Consequently, the domain gap can be well bridged through contrastive
learning of intermediate representations across domains. We evaluate the
proposed method in both unsupervised and semi-supervised DA settings, and
extensive experimental results on benchmarks reveal that our method is
effective and achieves state-of-the-art performance. The code can be found in
this https URL.</p>
  </details>
</details>
<details>
  <summary>97. <b>标题：Learning to be a Statistician: Learned Estimator for Number of Distinct  Values</b></summary>
  <p><b>编号</b>：[245]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02800</p>
  <p><b>作者</b>：Renzhi Wu,  Bolin Ding,  Xu Chu,  Zhewei Wei,  Xiening Dai,  Tao Guan,  Jingren Zhou</p>
  <p><b>备注</b>：Published at International Conference on Very Large Data Bases (VLDB) 2022</p>
  <p><b>关键词</b>：robust performance across different datasets, based estimators typically rely, synthetically generated training data, derive accurate ndv estimations, learned model workload agnostic</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Estimating the number of distinct values (NDV) in a column is useful for many
tasks in database systems, such as columnstore compression and data profiling.
In this work, we focus on how to derive accurate NDV estimations from random
(online/offline) samples. Such efficient estimation is critical for tasks where
it is prohibitive to scan the data even once. Existing sample-based estimators
typically rely on heuristics or assumptions and do not have robust performance
across different datasets as the assumptions on data can easily break. On the
other hand, deriving an estimator from a principled formulation such as maximum
likelihood estimation is very challenging due to the complex structure of the
formulation. We propose to formulate the NDV estimation task in a supervised
learning framework, and aim to learn a model as the estimator. To this end, we
need to answer several questions: i) how to make the learned model workload
agnostic; ii) how to obtain training data; iii) how to perform model training.
We derive conditions of the learning framework under which the learned model is
workload agnostic, in the sense that the model/estimator can be trained with
synthetically generated training data, and then deployed into any data
warehouse simply as, e.g., user-defined functions (UDFs), to offer efficient
(within microseconds on CPU) and accurate NDV estimations for unseen tables and
workloads. We compare the learned estimator with the state-of-the-art
sample-based estimators on nine real-world datasets to demonstrate its superior
estimation accuracy. We publish our code for training data generation, model
training, and the learned estimator online for reproducibility.</p>
  </details>
</details>
<details>
  <summary>98. <b>标题：SIGMA: A Structural Inconsistency Reducing Graph Matching Algorithm</b></summary>
  <p><b>编号</b>：[246]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02797</p>
  <p><b>作者</b>：Weijie Liu,  Chao Zhang,  Nenggan Zheng,  Hui Qian</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：structural inconsistency reducing graph matching algorithm, nodes across two correlated graphs, graph matching finds, graph matching accuracy, graph side information</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Graph matching finds the correspondence of nodes across two correlated graphs
and lies at the core of many applications. When graph side information is not
available, the node correspondence is estimated on the sole basis of network
topologies. In this paper, we propose a novel criterion to measure the graph
matching accuracy, structural inconsistency (SI), which is defined based on the
network topological structure. Specifically, SI incorporates the heat diffusion
wavelet to accommodate the multi-hop structure of the graphs. Based on SI, we
propose a Structural Inconsistency reducing Graph Matching Algorithm (SIGMA),
which improves the alignment scores of node pairs that have low SI values in
each iteration. Under suitable assumptions, SIGMA can reduce SI values of true
counterparts. Furthermore, we demonstrate that SIGMA can be derived by using a
mirror descent method to solve the Gromov-Wasserstein distance with a novel
K-hop-structure-based matching costs. Extensive experiments show that our
method outperforms state-of-the-art methods.</p>
  </details>
</details>
<details>
  <summary>99. <b>标题：Active Learning on a Budget: Opposite Strategies Suit High and Low  Budgets</b></summary>
  <p><b>编号</b>：[248]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02794</p>
  <p><b>作者</b>：Guy Hacohen,  Avihu Dekel,  Daphna Weinshall</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：deep active learning strategy suited, suitable corresponding querying strategies, comparative empirical investigation using, active learning strategies, investigating active learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Investigating active learning, we focus on the relation between the number of
labeled examples (budget size), and suitable corresponding querying strategies.
Our theoretical analysis shows a behavior reminiscent of phase transition:
typical points should best be queried in the low budget regime, while atypical
(or uncertain) points are best queried when the budget is large. Combined
evidence from our theoretical and empirical studies shows that a similar
phenomenon occurs in simple classification models. Accordingly, we propose
TypiClust -- a deep active learning strategy suited for low budgets. In a
comparative empirical investigation using a variety of architectures and image
datasets, we report that in the low budget regime, TypiClust outperforms all
other active learning strategies. Using TypiClust in a semi-supervised
framework, the performance of competitive semi-supervised methods gets a
significant boost, surpassing the state of the art.</p>
  </details>
</details>
<details>
  <summary>100. <b>标题：Learning Synthetic Environments and Reward Networks for Reinforcement  Learning</b></summary>
  <p><b>编号</b>：[250]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02790</p>
  <p><b>作者</b>：Fabio Ferreira,  Thomas Nierhoff,  Andreas Saelinger,  Frank Hutter</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：learned se proxies allow us, agents towards relevant states, proposed new concept, outer loop trains, original task performance</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We introduce Synthetic Environments (SEs) and Reward Networks (RNs),
represented by neural networks, as proxy environment models for training
Reinforcement Learning (RL) agents. We show that an agent, after being trained
exclusively on the SE, is able to solve the corresponding real environment.
While an SE acts as a full proxy to a real environment by learning about its
state dynamics and rewards, an RN is a partial proxy that learns to augment or
replace rewards. We use bi-level optimization to evolve SEs and RNs: the inner
loop trains the RL agent, and the outer loop trains the parameters of the SE /
RN via an evolution strategy. We evaluate our proposed new concept on a broad
range of RL algorithms and classic control environments. In a one-to-one
comparison, learning an SE proxy requires more interactions with the real
environment than training agents only on the real environment. However, once
such an SE has been learned, we do not need any interactions with the real
environment to train new agents. Moreover, the learned SE proxies allow us to
train agents with fewer interactions while maintaining the original task
performance. Our empirical results suggest that SEs achieve this result by
learning informed representations that bias the agents towards relevant states.
Moreover, we find that these proxies are robust against hyperparameter
variation and can also transfer to unseen agents.</p>
  </details>
</details>
<details>
  <summary>101. <b>标题：Energy awareness in low precision neural networks</b></summary>
  <p><b>编号</b>：[252]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02783</p>
  <p><b>作者</b>：Nurit Spingarn Eliezer,  Ron Banner,  Elad Hoffer,  Hilla Ben-Yaakov,  Tomer Michaeli</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：develop accurate power consumption models, reveal several important factors, reducing power consumption rely, aware neural network ),, deep neural networks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Power consumption is a major obstacle in the deployment of deep neural
networks (DNNs) on end devices. Existing approaches for reducing power
consumption rely on quite general principles, including avoidance of
multiplication operations and aggressive quantization of weights and
activations. However, these methods do not take into account the precise power
consumed by each module in the network, and are therefore not optimal. In this
paper we develop accurate power consumption models for all arithmetic
operations in the DNN, under various working conditions. We reveal several
important factors that have been overlooked to date. Based on our analysis, we
present PANN (power-aware neural network), a simple approach for approximating
any full-precision network by a low-power fixed-precision variant. Our method
can be applied to a pre-trained network, and can also be used during training
to achieve improved performance. In contrast to previous methods, PANN incurs
only a minor degradation in accuracy w.r.t. the full-precision version of the
network, even when working at the power-budget of a 2-bit quantized variant. In
addition, our scheme enables to seamlessly traverse the power-accuracy
trade-off at deployment time, which is a major advantage over existing
quantization methods that are constrained to specific bit widths.</p>
  </details>
</details>
<details>
  <summary>102. <b>标题：Learning Features with Parameter-Free Layers</b></summary>
  <p><b>编号</b>：[255]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02777</p>
  <p><b>作者</b>：Dongyoon Han,  YoungJoon Yoo,  Beomyoung Kim,  Byeongho Heo</p>
  <p><b>备注</b>：ICLR 2022</p>
  <p><b>关键词</b>：main building block without sacrificing, efficient trainable layers replacing spatial operations, studies eventually give us, simple yet effective idea, extensive experimental analyses based</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Trainable layers such as convolutional building blocks are the standard
network design choices by learning parameters to capture the global context
through successive spatial operations. When designing an efficient network,
trainable layers such as the depthwise convolution is the source of efficiency
in the number of parameters and FLOPs, but there was little improvement to the
model speed in practice. This paper argues that simple built-in parameter-free
operations can be a favorable alternative to the efficient trainable layers
replacing spatial operations in a network architecture. We aim to break the
stereotype of organizing the spatial operations of building blocks into
trainable layers. Extensive experimental analyses based on layer-level studies
with fully-trained models and neural architecture searches are provided to
investigate whether parameter-free operations such as the max-pool are
functional. The studies eventually give us a simple yet effective idea for
redesigning network architectures, where the parameter-free operations are
heavily used as the main building block without sacrificing the model accuracy
as much. Experimental results on the ImageNet dataset demonstrate that the
network architectures with parameter-free operations could enjoy the advantages
of further efficiency in terms of model speed, the number of the parameters,
and FLOPs. Code and ImageNet pretrained models are available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>103. <b>标题：Human rights, democracy, and the rule of law assurance framework for AI  systems: A proposal</b></summary>
  <p><b>编号</b>：[256]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02776</p>
  <p><b>作者</b>：David Leslie,  Christopher Burr,  Mhairi Aitken,  Michael Katell,  Morgan Briggs,  Cami Rincon</p>
  <p><b>备注</b>：341 pages</p>
  <p><b>关键词</b>：based human rights due diligence, human right due diligence, alan turing institute undertook, trustworthy ai innovation practices, trustworthy ai innovation practices</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Following on from the publication of its Feasibility Study in December 2020,
the Council of Europe's Ad Hoc Committee on Artificial Intelligence (CAHAI) and
its subgroups initiated efforts to formulate and draft its Possible Elements of
a Legal Framework on Artificial Intelligence, based on the Council of Europe's
standards on human rights, democracy, and the rule of law. This document was
ultimately adopted by the CAHAI plenary in December 2021. To support this
effort, The Alan Turing Institute undertook a programme of research that
explored the governance processes and practical tools needed to operationalise
the integration of human right due diligence with the assurance of trustworthy
AI innovation practices.
The resulting framework was completed and submitted to the Council of Europe
in September 2021. It presents an end-to-end approach to the assurance of AI
project lifecycles that integrates context-based risk analysis and appropriate
stakeholder engagement with comprehensive impact assessment, and transparent
risk management, impact mitigation, and innovation assurance practices. Taken
together, these interlocking processes constitute a Human Rights, Democracy and
the Rule of Law Assurance Framework (HUDERAF). The HUDERAF combines the
procedural requirements for principles-based human rights due diligence with
the governance mechanisms needed to set up technical and socio-technical
guardrails for responsible and trustworthy AI innovation practices. Its purpose
is to provide an accessible and user-friendly set of mechanisms for
facilitating compliance with a binding legal framework on artificial
intelligence, based on the Council of Europe's standards on human rights,
democracy, and the rule of law, and to ensure that AI innovation projects are
carried out with appropriate levels of public accountability, transparency, and
democratic governance.</p>
  </details>
</details>
<details>
  <summary>104. <b>标题：Pushing the Efficiency-Regret Pareto Frontier for Online Learning of  Portfolios and Quantum States</b></summary>
  <p><b>编号</b>：[257]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02765</p>
  <p><b>作者</b>：Julian Zimmert,  Naman Agarwal,  Satyen Kale</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：classical online portfolio selection problem, step running time requirements, colt 2020 open problem, online portfolio selection, exponentially larger dependence</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We revisit the classical online portfolio selection problem. It is widely
assumed that a trade-off between computational complexity and regret is
unavoidable, with Cover's Universal Portfolios algorithm, SOFT-BAYES and
ADA-BARRONS currently constituting its state-of-the-art Pareto frontier. In
this paper, we present the first efficient algorithm, BISONS, that obtains
polylogarithmic regret with memory and per-step running time requirements that
are polynomial in the dimension, displacing ADA-BARRONS from the Pareto
frontier. Additionally, we resolve a COLT 2020 open problem by showing that a
certain Follow-The-Regularized-Leader algorithm with log-barrier regularization
suffers an exponentially larger dependence on the dimension than previously
conjectured. Thus, we rule out this algorithm as a candidate for the Pareto
frontier. We also extend our algorithm and analysis to a more general problem
than online portfolio selection, viz. online learning of quantum states with
log loss. This algorithm, called SCHRODINGER'S BISONS, is the first efficient
algorithm with polylogarithmic regret for this more general problem.</p>
  </details>
</details>
<details>
  <summary>105. <b>标题：Riemannian Score-Based Generative Modeling</b></summary>
  <p><b>编号</b>：[258]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02763</p>
  <p><b>作者</b>：Valentin De Bortoli,  Emile Mathieu,  Michael Hutchinson,  James Thornton,  Yee Whye Teh,  Arnaud Doucet</p>
  <p><b>备注</b>：31 pages</p>
  <p><b>关键词</b>：generative models demonstrating remarkable empirical performance, add progressively gaussian noise, based generative models, based generative models, schrödinger bridge problem</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Score-based generative models (SGMs) are a novel class of generative models
demonstrating remarkable empirical performance. One uses a diffusion to add
progressively Gaussian noise to the data, while the generative model is a
"denoising" process obtained by approximating the time-reversal of this
"noising" diffusion. However, current SGMs make the underlying assumption that
the data is supported on a Euclidean manifold with flat geometry. This prevents
the use of these models for applications in robotics, geoscience or protein
modeling which rely on distributions defined on Riemannian manifolds. To
overcome this issue, we introduce Riemannian Score-based Generative Models
(RSGMs) which extend current SGMs to the setting of compact Riemannian
manifolds. We illustrate our approach with earth and climate science data and
show how RSGMs can be accelerated by solving a Schrödinger bridge problem on
manifolds.</p>
  </details>
</details>
<details>
  <summary>106. <b>标题：Pipe Overflow: Smashing Voice Authentication for Fun and Profit</b></summary>
  <p><b>编号</b>：[263]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02751</p>
  <p><b>作者</b>：Shimaa Ahmed,  Yash Wani,  Ali Shahin Shamsabadi,  Mohammad Yaghini,  Ilia Shumailov,  Nicolas Papernot,  Kassem Fawaz</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：producing analog adversarial examples directly, enabled personal devices powered, tasks like speaker identification, targeted adversarial examples, modern systems protect</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent years have seen a surge of popularity of acoustics-enabled personal
devices powered by machine learning. Yet, machine learning has proven to be
vulnerable to adversarial examples. Large number of modern systems protect
themselves against such attacks by targeting the artificiality, i.e., they
deploy mechanisms to detect the lack of human involvement in generating the
adversarial examples. However, these defenses implicitly assume that humans are
incapable of producing meaningful and targeted adversarial examples. In this
paper, we show that this base assumption is wrong. In particular, we
demonstrate that for tasks like speaker identification, a human is capable of
producing analog adversarial examples directly with little cost and
supervision: by simply speaking through a tube, an adversary reliably
impersonates other speakers in eyes of ML models for speaker identification.
Our findings extend to a range of other acoustic-biometric tasks such as
liveness, bringing into question their use in security-critical settings in
real life, such as phone banking.</p>
  </details>
</details>
<details>
  <summary>107. <b>标题：Energy-Aware Edge Association for Cluster-based Personalized Federated  Learning</b></summary>
  <p><b>编号</b>：[269]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02727</p>
  <p><b>作者</b>：Y. Li,  X. Qin,  H. Chen,  K. Han,  P. Zhang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：diversified personal preferences causes disagreeing conditional distributions among user data, realize cost efficient personalized federated learning without, employs deep reinforcement learning based approach, proposed strategy outperforms existing strategies, wireless network enables data</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Federated Learning (FL) over wireless network enables data-conscious services
by leveraging the ubiquitous intelligence at network edge for
privacy-preserving model training. As the proliferation of context-aware
services, the diversified personal preferences causes disagreeing conditional
distributions among user data, which leads to poor inference performance. In
this sense, clustered federated learning is proposed to group user devices with
similar preference and provide each cluster with a personalized model. This
calls for innovative design in edge association that involves user clustering
and also resource management optimization. We formulate an accuracy-cost
trade-off optimization problem by jointly considering model accuracy,
communication resource allocation and energy consumption. To comply with
parameter encryption techniques in FL, we propose an iterative solution
procedure which employs deep reinforcement learning based approach at cloud
server for edge association. The reward function consists of minimized energy
consumption at each base station and the averaged model accuracy of all users.
Under our proposed solution, multiple edge base station are fully exploited to
realize cost efficient personalized federated learning without any prior
knowledge on model parameters. Simulation results show that our proposed
strategy outperforms existing strategies in achieving accurate learning at low
energy cost.</p>
  </details>
</details>
<details>
  <summary>108. <b>标题：Robust Anomaly Detection for Time-series Data</b></summary>
  <p><b>编号</b>：[270]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02721</p>
  <p><b>作者</b>：Min Hu,  Yi Wang,  Xiaowei Feng,  Shengchen Zhou,  Zhaoyu Wu,  Yuan Qin</p>
  <p><b>备注</b>：18 pages, 12 figures, 6 tables</p>
  <p><b>关键词</b>：benchmark datasets radtd possessed higher accuracy, three tunneling engineering simulation experiments, monitoring complex operation conditions, extreme learning machine autoencoder, extreme learning machine autoencoder</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Time-series anomaly detection plays a vital role in monitoring complex
operation conditions. However, the detection accuracy of existing approaches is
heavily influenced by pattern distribution, existence of multiple normal
patterns, dynamical features representation, and parameter settings. For the
purpose of improving the robustness and guaranteeing the accuracy, this
research combined the strengths of negative selection, unthresholded recurrence
plots, and an extreme learning machine autoencoder and then proposed robust
anomaly detection for time-series data (RADTD), which can automatically learn
dynamical features in time series and recognize anomalies with low label
dependency and high robustness. Yahoo benchmark datasets and three tunneling
engineering simulation experiments were used to evaluate the performance of
RADTD. The experiments showed that in benchmark datasets RADTD possessed higher
accuracy and robustness than recurrence qualification analysis and extreme
learning machine autoencoder, respectively, and that RADTD accurately detected
the occurrence of tunneling settlement accidents, indicating its remarkable
performance in accuracy and robustness.</p>
  </details>
</details>
<details>
  <summary>109. <b>标题：Spectrally Adapted Physics-Informed Neural Networks for Solving  Unbounded Domain Problems</b></summary>
  <p><b>编号</b>：[274]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02710</p>
  <p><b>作者</b>：Mingtao Xia,  Lucas Böttcher,  Tom Chou</p>
  <p><b>备注</b>：28 pages, 8 figures</p>
  <p><b>关键词</b>：solving analytically intractable partial differential equations, unbounded domain requires efficient numerical methods, recently introduced adaptive techniques, unbounded domain problems arise, least one variable defined</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Solving analytically intractable partial differential equations (PDEs) that
involve at least one variable defined in an unbounded domain requires efficient
numerical methods that accurately resolve the dependence of the PDE on that
variable over several orders of magnitude. Unbounded domain problems arise in
various application areas and solving such problems is important for
understanding multi-scale biological dynamics, resolving physical processes at
long time scales and distances, and performing parameter inference in
engineering problems. In this work, we combine two classes of numerical
methods: (i) physics-informed neural networks (PINNs) and (ii) adaptive
spectral methods. The numerical methods that we develop take advantage of the
ability of physics-informed neural networks to easily implement high-order
numerical schemes to efficiently solve PDEs. We then show how recently
introduced adaptive techniques for spectral methods can be integrated into
PINN-based PDE solvers to obtain numerical solutions of unbounded domain
problems that cannot be efficiently approximated by standard PINNs. Through a
number of examples, we demonstrate the advantages of the proposed spectrally
adapted PINNs (s-PINNs) over standard PINNs in approximating functions, solving
PDEs, and estimating model parameters from noisy observations in unbounded
domains.</p>
  </details>
</details>
<details>
  <summary>110. <b>标题：How Effective is Incongruity? Implications for Code-mix Sarcasm  Detection</b></summary>
  <p><b>编号</b>：[279]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02702</p>
  <p><b>作者</b>：Aditya Shah,  Chandresh Kumar Maurya</p>
  <p><b>备注</b>：Published in ICON - ACL 2021</p>
  <p><b>关键词</b>：word level embeddings learned via fasttext, social media like chatbots, proposed model achieves f1, mix hinglish dataset comparable, training 10x faster</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The presence of sarcasm in conversational systems and social media like
chatbots, Facebook, Twitter, etc. poses several challenges for downstream NLP
tasks. This is attributed to the fact that the intended meaning of a sarcastic
text is contrary to what is expressed. Further, the use of code-mix language to
express sarcasm is increasing day by day. Current NLP techniques for code-mix
data have limited success due to the use of different lexicon, syntax, and
scarcity of labeled corpora. To solve the joint problem of code-mixing and
sarcasm detection, we propose the idea of capturing incongruity through
sub-word level embeddings learned via fastText. Empirical results shows that
our proposed model achieves F1-score on code-mix Hinglish dataset comparable to
pretrained multilingual models while training 10x faster and using a lower
memory footprint</p>
  </details>
</details>
<details>
  <summary>111. <b>标题：Exploration with Multi-Sample Target Values for Distributional  Reinforcement Learning</b></summary>
  <p><b>编号</b>：[282]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02693</p>
  <p><b>作者</b>：Michael Teng,  Michiel van de Panne,  Frank Wood</p>
  <p><b>备注</b>：Submitted to ICML 2022</p>
  <p><b>关键词</b>：sample target value estimation, sample target values, often modeled via, method via visualization, improved distributional estimates</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Distributional reinforcement learning (RL) aims to learn a value-network that
predicts the full distribution of the returns for a given state, often modeled
via a quantile-based critic. This approach has been successfully integrated
into common RL methods for continuous control, giving rise to algorithms such
as Distributional Soft Actor-Critic (DSAC). In this paper, we introduce
multi-sample target values (MTV) for distributional RL, as a principled
replacement for single-sample target value estimation, as commonly employed in
current practice. The improved distributional estimates further lend themselves
to UCB-based exploration. These two ideas are combined to yield our
distributional RL algorithm, E2DC (Extra Exploration with Distributional
Critics). We evaluate our approach on a range of continuous control tasks and
demonstrate state-of-the-art model-free performance on difficult tasks such as
Humanoid control. We provide further insight into the method via visualization
and analysis of the learned distributions and their evolution during training.</p>
  </details>
</details>
<details>
  <summary>112. <b>标题：TTS-GAN: A Transformer-based Time-Series Generative Adversarial Network</b></summary>
  <p><b>编号</b>：[283]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02691</p>
  <p><b>作者</b>：Xiaomin Li,  Vangelis Metsis,  Huangyingrui Wang,  Anne Hee Hiong Ngu</p>
  <p><b>备注</b>：submitted to 20th International Conference on Artificial Intelligence in Medicine (AIME 2022)</p>
  <p><b>关键词</b>：deep neural network architectures ineffective, cannot effectively model long sequences, successfully generate realistic synthetic time, medical machine learning applications, pure transformer encoder architecture</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Signal measurements appearing in the form of time series are one of the most
common types of data used in medical machine learning applications. However,
such datasets are often small, making the training of deep neural network
architectures ineffective. For time-series, the suite of data augmentation
tricks we can use to expand the size of the dataset is limited by the need to
maintain the basic properties of the signal. Data generated by a Generative
Adversarial Network (GAN) can be utilized as another data augmentation tool.
RNN-based GANs suffer from the fact that they cannot effectively model long
sequences of data points with irregular temporal relations. To tackle these
problems, we introduce TTS-GAN, a transformer-based GAN which can successfully
generate realistic synthetic time-series data sequences of arbitrary length,
similar to the real ones. Both the generator and discriminator networks of the
GAN model are built using a pure transformer encoder architecture. We use
visualizations and dimensionality reduction techniques to demonstrate the
similarity of real and generated time-series data. We also compare the quality
of our generated data with the best existing alternative, which is an RNN-based
time-series GAN.</p>
  </details>
</details>
<details>
  <summary>113. <b>标题：Featherweight Assisted Vulnerability Discovery</b></summary>
  <p><b>编号</b>：[288]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02679</p>
  <p><b>作者</b>：David Binkley,  Leon Moonen,  Sibren Isaacman</p>
  <p><b>备注</b>：17 pages, 6 figures, 6 tables</p>
  <p><b>关键词</b>：predicting vulnerable source code helps, magnitude less training data, 950000 functions labeled benign, 73000 functions labeled vulnerable, predict potentially vulnerable functions</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Predicting vulnerable source code helps to focus attention on those parts of
the code that need to be examined with more scrutiny. Recent work proposed the
use of function names as semantic cues that can be learned by a deep neural
network (DNN) to aid in the hunt for vulnerability of functions.
Combining identifier splitting, which splits each function name into its
constituent words, with a novel frequency-based algorithm, we explore the
extent to which the words that make up a function's name can predict
potentially vulnerable functions. In contrast to *lightweight* predictions by a
DNN that considers only function names, avoiding the use of a DNN provides
*featherweight* predictions. The underlying idea is that function names that
contain certain "dangerous" words are more likely to accompany vulnerable
functions. Of course, this assumes that the frequency-based algorithm can be
properly tuned to focus on truly dangerous words.
Because it is more transparent than a DNN, the frequency-based algorithm
enables us to investigate the inner workings of the DNN. If successful, this
investigation into what the DNN does and does not learn will help us train more
effective future models.
We empirically evaluate our approach on a heterogeneous dataset containing
over 73000 functions labeled vulnerable, and over 950000 functions labeled
benign. Our analysis shows that words alone account for a significant portion
of the DNN's classification ability. We also find that words are of greatest
value in the datasets with a more homogeneous vocabulary. Thus, when working
within the scope of a given project, where the vocabulary is unavoidably
homogeneous, our approach provides a cheaper, potentially complementary,
technique to aid in the hunt for source-code vulnerabilities. Finally, this
approach has the advantage that it is viable with orders of magnitude less
training data.</p>
  </details>
</details>
<details>
  <summary>114. <b>标题：Simulation-to-Reality domain adaptation for offline 3D object annotation  on pointclouds with correlation alignment</b></summary>
  <p><b>编号</b>：[296]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02666</p>
  <p><b>作者</b>：Weishuang Zhang,  B Ravi Kiran,  Thomas Gauthier,  Yanis Mazouz,  Theo Steger</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：deployment vehicles using simulated data, unlabeled real pointcloud feature representations, costly human driven process, autonomous driving perception system, supervised object detection loss</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Annotating objects with 3D bounding boxes in LiDAR pointclouds is a costly
human driven process in an autonomous driving perception system. In this paper,
we present a method to semi-automatically annotate real-world pointclouds
collected by deployment vehicles using simulated data. We train a 3D object
detector model on labeled simulated data from CARLA jointly with real world
pointclouds from our target vehicle. The supervised object detection loss is
augmented with a CORAL loss term to reduce the distance between labeled
simulated and unlabeled real pointcloud feature representations. The goal here
is to learn representations that are invariant to simulated (labeled) and
real-world (unlabeled) target domains. We also provide an updated survey on
domain adaptation methods for pointclouds.</p>
  </details>
</details>
<details>
  <summary>115. <b>标题：No Parameters Left Behind: Sensitivity Guided Adaptive Learning Rate for  Training Large Transformer Models</b></summary>
  <p><b>编号</b>：[297]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02664</p>
  <p><b>作者</b>：Chen Liang,  Haoming Jiang,  Simiao Zuo,  Pengcheng He,  Xiaodong Liu,  Jianfeng Gao,  Weizhu Chen,  Tuo Zhao</p>
  <p><b>备注</b>：Proceedings of ICLR 2022</p>
  <p><b>关键词</b>：redundant parameters without significantly sacrificing, proposed schedule indeed reduces, redundant parameters could, novel training strategy, neural machine translation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent research has shown the existence of significant redundancy in large
Transformer models. One can prune the redundant parameters without
significantly sacrificing the generalization performance. However, we question
whether the redundant parameters could have contributed more if they were
properly trained. To answer this question, we propose a novel training strategy
that encourages all parameters to be trained sufficiently. Specifically, we
adaptively adjust the learning rate for each parameter according to its
sensitivity, a robust gradient-based measure reflecting this parameter's
contribution to the model performance. A parameter with low sensitivity is
redundant, and we improve its fitting by increasing its learning rate. In
contrast, a parameter with high sensitivity is well-trained, and we regularize
it by decreasing its learning rate to prevent further overfitting. We conduct
extensive experiments on natural language understanding, neural machine
translation, and image classification to demonstrate the effectiveness of the
proposed schedule. Analysis shows that the proposed schedule indeed reduces the
redundancy and improves generalization performance.</p>
  </details>
</details>
<details>
  <summary>116. <b>标题：LiDAR dataset distillation within bayesian active learning framework:  Understanding the effect of data augmentation</b></summary>
  <p><b>编号</b>：[298]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02661</p>
  <p><b>作者</b>：Ngoc Phuong Anh Duong,  Alexandre Almin,  Léo Lemarié,  B Ravi Kiran</p>
  <p><b>备注</b>：Accepted at VISAPP 2022</p>
  <p><b>关键词</b>：data augmentation achieves full dataset accuracy using, enable better deep representation learning, provides faster training time, demonstrated across different subsets, al based dataset distillation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Autonomous driving (AD) datasets have progressively grown in size in the past
few years to enable better deep representation learning. Active learning (AL)
has re-gained attention recently to address reduction of annotation costs and
dataset size. AL has remained relatively unexplored for AD datasets, especially
on point cloud data from LiDARs. This paper performs a principled evaluation of
AL based dataset distillation on (1/4th) of the large Semantic-KITTI dataset.
Further on, the gains in model performance due to data augmentation (DA) are
demonstrated across different subsets of the AL loop. We also demonstrate how
DA improves the selection of informative samples to annotate. We observe that
data augmentation achieves full dataset accuracy using only 60\% of samples
from the selected dataset configuration. This provides faster training time and
subsequent gains in annotation costs.</p>
  </details>
</details>
<details>
  <summary>117. <b>标题：A Game-theoretic Understanding of Repeated Explanations in ML Models</b></summary>
  <p><b>编号</b>：[300]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02659</p>
  <p><b>作者</b>：Kavita Kumari (1),  Murtuza Jadliwala (1),  Sumit Kumar Jha (1),  Anindya Maiti (2) ((1) University of Texas, San Antonio, (2) University of Oklahoma)</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：markov perfect equilibrium state within, time stochastic signaling game framework, system must strategically decide, user must strategically decide, strategic repeated interactions</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper formally models the strategic repeated interactions between a
system, comprising of a machine learning (ML) model and associated explanation
method, and an end-user who is seeking a prediction/label and its explanation
for a query/input, by means of game theory. In this game, a malicious end-user
must strategically decide when to stop querying and attempt to compromise the
system, while the system must strategically decide how much information (in the
form of noisy explanations) it should share with the end-user and when to stop
sharing, all without knowing the type (honest/malicious) of the end-user. This
paper formally models this trade-off using a continuous-time stochastic
Signaling game framework and characterizes the Markov perfect equilibrium state
within such a framework.</p>
  </details>
</details>
<details>
  <summary>118. <b>标题：Deep-HyROMnet: A deep learning-based operator approximation for  hyper-reduction of nonlinear parametrized PDEs</b></summary>
  <p><b>编号</b>：[301]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02658</p>
  <p><b>作者</b>：Ludovica Cicci,  Stefania Fresca,  Andrea Manzoni</p>
  <p><b>备注</b>：32 pages</p>
  <p><b>关键词</b>：learning nonlinear rom operators using deep neural networks, nonlinear structural mechanics show, surrogate models obtained via, deim ), thus making, approximate reduced residual vectors</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>To speed-up the solution to parametrized differential problems, reduced order
models (ROMs) have been developed over the years, including projection-based
ROMs such as the reduced-basis (RB) method, deep learning-based ROMs, as well
as surrogate models obtained via a machine learning approach. Thanks to its
physics-based structure, ensured by the use of a Galerkin projection of the
full order model (FOM) onto a linear low-dimensional subspace, RB methods yield
approximations that fulfill the physical problem at hand. However, to make the
assembling of a ROM independent of the FOM dimension, intrusive and expensive
hyper-reduction stages are usually required, such as the discrete empirical
interpolation method (DEIM), thus making this strategy less feasible for
problems characterized by (high-order polynomial or nonpolynomial)
nonlinearities. To overcome this bottleneck, we propose a novel strategy for
learning nonlinear ROM operators using deep neural networks (DNNs). The
resulting hyper-reduced order model enhanced by deep neural networks, to which
we refer to as Deep-HyROMnet, is then a physics-based model, still relying on
the RB method approach, however employing a DNN architecture to approximate
reduced residual vectors and Jacobian matrices once a Galerkin projection has
been performed. Numerical results dealing with fast simulations in nonlinear
structural mechanics show that Deep-HyROMnets are orders of magnitude faster
than POD-Galerkin-DEIM ROMs, keeping the same level of accuracy.</p>
  </details>
</details>
<details>
  <summary>119. <b>标题：A survey of top-down approaches for human pose estimation</b></summary>
  <p><b>编号</b>：[302]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02656</p>
  <p><b>作者</b>：Thong Duy Nguyen,  Milan Kresovic</p>
  <p><b>备注</b>：16 pages</p>
  <p><b>关键词</b>：computer vision problem recently due, brought tremendous remarkable results, paper presents significant detectors, step framework first incorporates, improving human life</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Human pose estimation in two-dimensional images videos has been a hot topic
in the computer vision problem recently due to its vast benefits and potential
applications for improving human life, such as behaviors recognition, motion
capture and augmented reality, training robots, and movement tracking. Many
state-of-the-art methods implemented with Deep Learning have addressed several
challenges and brought tremendous remarkable results in the field of human pose
estimation. Approaches are classified into two kinds: the two-step framework
(top-down approach) and the part-based framework (bottom-up approach). While
the two-step framework first incorporates a person detector and then estimates
the pose within each box independently, detecting all body parts in the image
and associating parts belonging to distinct persons is conducted in the
part-based framework. This paper aims to provide newcomers with an extensive
review of deep learning methods-based 2D images for recognizing the pose of
people, which only focuses on top-down approaches since 2016. The discussion
through this paper presents significant detectors and estimators depending on
mathematical background, the challenges and limitations, benchmark datasets,
evaluation metrics, and comparison between methods.</p>
  </details>
</details>
<details>
  <summary>120. <b>标题：Doing Right by Not Doing Wrong in Human-Robot Collaboration</b></summary>
  <p><b>编号</b>：[303]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02654</p>
  <p><b>作者</b>：Laura Londoño,  Adrian Röfer,  Tim Welschehold,  Abhinav Valada</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：exhibit antisocial behavior causing physical harm, issues considering sociable robotic manipulation, reproduce unfair behavior replicating, fair robotic decision making, human collaborators feel unsafe</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As robotic systems become more and more capable of assisting humans in their
everyday lives, we must consider the opportunities for these artificial agents
to make their human collaborators feel unsafe or to treat them unfairly. Robots
can exhibit antisocial behavior causing physical harm to people or reproduce
unfair behavior replicating and even amplifying historical and societal biases
which are detrimental to humans they interact with. In this paper, we discuss
these issues considering sociable robotic manipulation and fair robotic
decision making. We propose a novel approach to learning fair and sociable
behavior, not by reproducing positive behavior, but rather by avoiding negative
behavior. In this study, we highlight the importance of incorporating
sociability in robot manipulation, as well as the need to consider fairness in
human-robot interactions.</p>
  </details>
</details>
<details>
  <summary>121. <b>标题：A Graph Neural Network Framework for Grid-Based Simulation</b></summary>
  <p><b>编号</b>：[304]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02652</p>
  <p><b>作者</b>：Haoyu Tang,  Wennan Long</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：related subsurface optimization including oil, gnn framework shows great potential, previous step state variable, next step state variable, processed graph data designed</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Reservoir simulations are computationally expensive in the well control and
well placement optimization. Generally, numerous simulation runs (realizations)
are needed in order to achieve the optimal well locations. In this paper, we
propose a graph neural network (GNN) framework to build a surrogate
feed-forward model which replaces simulation runs to accelerate the
optimization process. Our GNN framework includes an encoder, a process, and a
decoder which takes input from the processed graph data designed and generated
from the simulation raw data. We train the GNN model with 6000 samples
(equivalent to 40 well configurations) with each containing the previous step
state variable and the next step state variable. We test the GNN model with
another 6000 samples and after model tuning, both one-step prediction and
rollout prediction achieve a close match with the simulation results. Our GNN
framework shows great potential in the application of well-related subsurface
optimization including oil and gas as well as carbon capture sequestration
(CCS).</p>
  </details>
</details>
<details>
  <summary>122. <b>标题：Efficient Logistic Regression with Local Differential Privacy</b></summary>
  <p><b>编号</b>：[305]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02650</p>
  <p><b>作者</b>：Guanhong Miao</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：proposed privacy preserving logistic regression model using matrix encryption approach, generate robust model results without increasing, secure scheme achieves local differential privacy, demonstrate high model accuracy, also raises public concern</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Internet of Things devices are expanding rapidly and generating huge amount
of data. There is an increasing need to explore data collected from these
devices. Collaborative learning provides a strategic solution for the Internet
of Things settings but also raises public concern over data privacy. In recent
years, large amount of privacy preserving techniques have been developed based
on differential privacy and secure multi-party computation. A major challenge
of collaborative learning is to balance disclosure risk and data utility while
maintaining high computation efficiency. In this paper, we proposed privacy
preserving logistic regression model using matrix encryption approach. The
secure scheme achieves local differential privacy and can be implemented for
both vertical and horizontal partitioning scenarios. Moreover, cross validation
is investigated to generate robust model results without increasing the
communication cost. Simulation illustrates the high efficiency of proposed
scheme to analyze dataset with millions of records. Experimental evaluations
further demonstrate high model accuracy while achieving privacy protection.</p>
  </details>
</details>
<details>
  <summary>123. <b>标题：The Unreasonable Effectiveness of Random Pruning: Return of the Most  Naive Baseline for Sparse Training</b></summary>
  <p><b>编号</b>：[308]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02643</p>
  <p><b>作者</b>：Shiwei Liu,  Tianlong Chen,  Xiaohan Chen,  Li Shen,  Decebal Constantin Mocanu,  Zhangyang Wang,  Mykola Pechenizkiy</p>
  <p><b>备注</b>：Published as a conference paper at ICLR 2022. Code is available at this https URL</p>
  <p><b>关键词</b>：randomly pruned networks outperform dense counterparts, universal beyond carefully designed pruning, original dense networks grow wider, carefully pursued sparsity structures, another important performance booster</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Random pruning is arguably the most naive way to attain sparsity in neural
networks, but has been deemed uncompetitive by either post-training pruning or
sparse training. In this paper, we focus on sparse training and highlight a
perhaps counter-intuitive finding, that random pruning at initialization can be
quite powerful for the sparse training of modern neural networks. Without any
delicate pruning criteria or carefully pursued sparsity structures, we
empirically demonstrate that sparsely training a randomly pruned network from
scratch can match the performance of its dense equivalent. There are two key
factors that contribute to this revival: (i) the network sizes matter: as the
original dense networks grow wider and deeper, the performance of training a
randomly pruned sparse network will quickly grow to matching that of its dense
equivalent, even at high sparsity ratios; (ii) appropriate layer-wise sparsity
ratios can be pre-chosen for sparse training, which shows to be another
important performance booster. Simple as it looks, a randomly pruned subnetwork
of Wide ResNet-50 can be sparsely trained to outperforming a dense Wide
ResNet-50, on ImageNet. We also observed such randomly pruned networks
outperform dense counterparts in other favorable aspects, such as
out-of-distribution detection, uncertainty estimation, and adversarial
robustness. Overall, our results strongly suggest there is larger-than-expected
room for sparse training at scale, and the benefits of sparsity might be more
universal beyond carefully designed pruning. Our source code can be found at
this https URL.</p>
  </details>
</details>
<details>
  <summary>124. <b>标题：Emblaze: Illuminating Machine Learning Representations through  Interactive Comparison of Embedding Spaces</b></summary>
  <p><b>编号</b>：[309]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02641</p>
  <p><b>作者</b>：Venkatesh Sivaraman,  Yiwei Wu,  Adam Perer</p>
  <p><b>备注</b>：23 pages, 5 figures, 2 tables. To be presented at IUI'22</p>
  <p><b>关键词</b>：modern machine learning techniques commonly rely, also employs novel neighborhood analysis, first interviewed nine embedding experts, compare across multiple embedding spaces, integrates embedding space comparison within</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Modern machine learning techniques commonly rely on complex, high-dimensional
embedding representations to capture underlying structure in the data and
improve performance. In order to characterize model flaws and choose a
desirable representation, model builders often need to compare across multiple
embedding spaces, a challenging analytical task supported by few existing
tools. We first interviewed nine embedding experts in a variety of fields to
characterize the diverse challenges they face and techniques they use when
analyzing embedding spaces. Informed by these perspectives, we developed a
novel system called Emblaze that integrates embedding space comparison within a
computational notebook environment. Emblaze uses an animated, interactive
scatter plot with a novel Star Trail augmentation to enable visual comparison.
It also employs novel neighborhood analysis and clustering procedures to
dynamically suggest groups of points with interesting changes between spaces.
Through a series of case studies with ML experts, we demonstrate how
interactive comparison with Emblaze can help gain new insights into embedding
space structure.</p>
  </details>
</details>
<details>
  <summary>125. <b>标题：Improved Certified Defenses against Data Poisoning with (Deterministic)  Finite Aggregation</b></summary>
  <p><b>编号</b>：[314]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02628</p>
  <p><b>作者</b>：Wenxiao Wang,  Alexander Levine,  Soheil Feizi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：proposed finite aggregation consistently improves certificates, thus improves certified robustness bounds, data poisoning attacks aim, namely finite aggregation, general poisoning attacks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Data poisoning attacks aim at manipulating model behaviors through distorting
training data. Previously, an aggregation-based certified defense, Deep
Partition Aggregation (DPA), was proposed to mitigate this threat. DPA predicts
through an aggregation of base classifiers trained on disjoint subsets of data,
thus restricting its sensitivity to dataset distortions. In this work, we
propose an improved certified defense against general poisoning attacks, namely
Finite Aggregation. In contrast to DPA, which directly splits the training set
into disjoint subsets, our method first splits the training set into smaller
disjoint subsets and then combines duplicates of them to build larger (but not
disjoint) subsets for training base classifiers. This reduces the worst-case
impacts of poison samples and thus improves certified robustness bounds. In
addition, we offer an alternative view of our method, bridging the designs of
deterministic and stochastic aggregation-based certified defenses. Empirically,
our proposed Finite Aggregation consistently improves certificates on MNIST,
CIFAR-10, and GTSRB, boosting certified fractions by up to 3.05%, 3.87% and
4.77%, respectively, while keeping the same clean accuracies as DPA's,
effectively establishing a new state of the art in (pointwise) certified
robustness against data poisoning.</p>
  </details>
</details>
<details>
  <summary>126. <b>标题：Training Differentially Private Models with Secure Multiparty  Computation</b></summary>
  <p><b>编号</b>：[317]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02625</p>
  <p><b>作者</b>：Sikha Pentyala,  Davis Railsback,  Ricardo Maia,  Rafael Dowsley,  David Melanson,  Anderson Nascimento,  Martine De Cock</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：dp approach achieves higher accuracy, providing formal privacy guarantees regarding, work obtained first place, idash2021 track iii competition, formal privacy guarantees</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We address the problem of learning a machine learning model from training
data that originates at multiple data owners while providing formal privacy
guarantees regarding the protection of each owner's data. Existing solutions
based on Differential Privacy (DP) achieve this at the cost of a drop in
accuracy. Solutions based on Secure Multiparty Computation (MPC) do not incur
such accuracy loss but leak information when the trained model is made publicly
available. We propose an MPC solution for training DP models. Our solution
relies on an MPC protocol for model training, and an MPC protocol for
perturbing the trained model coefficients with Laplace noise in a
privacy-preserving manner. The resulting MPC+DP approach achieves higher
accuracy than a pure DP approach while providing the same formal privacy
guarantees. Our work obtained first place in the iDASH2021 Track III
competition on confidential computing for secure genome analysis.</p>
  </details>
</details>
<details>
  <summary>127. <b>标题：Adaptive Fine-Tuning of Transformer-Based Language Models for Named  Entity Recognition</b></summary>
  <p><b>编号</b>：[320]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02617</p>
  <p><b>作者</b>：Felix Stollenwerk</p>
  <p><b>备注</b>：28 pages, 19 figures</p>
  <p><b>关键词</b>：linear learning rate schedule, custom learning rate schedule, based language models includes, uses early stopping, optimization hyperparameter space</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The current standard approach for fine-tuning transformer-based language
models includes a fixed number of training epochs and a linear learning rate
schedule. In order to obtain a near-optimal model for the given downstream
task, a search in optimization hyperparameter space is usually required. In
particular, the number of training epochs needs to be adjusted to the dataset
size. In this paper, we introduce adaptive fine-tuning, which is an alternative
approach that uses early stopping and a custom learning rate schedule to
dynamically adjust the number of training epochs to the dataset size. For the
example use case of named entity recognition, we show that our approach not
only makes hyperparameter search with respect to the number of training epochs
redundant, but also leads to improved results in terms of performance,
stability and efficiency. This holds true especially for small datasets, where
we outperform the state-of-the-art fine-tuning method by a large margin.</p>
  </details>
</details>
<details>
  <summary>128. <b>标题：Privacy-preserving Speech Emotion Recognition through Semi-Supervised  Federated Learning</b></summary>
  <p><b>编号</b>：[322]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02611</p>
  <p><b>作者</b>：Vasileios Tsouvalas,  Tanir Ozcelebi,  Nirvana Meratnia</p>
  <p><b>备注</b>：arXiv admin note: text overlap with arXiv:2107.06877</p>
  <p><b>关键词</b>：learn generalizable ser models even, distributed machine learning paradigm dealing, first federated ser approach, existing ser approaches, without considering users</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Speech Emotion Recognition (SER) refers to the recognition of human emotions
from natural speech. If done accurately, it can offer a number of benefits in
building human-centered context-aware intelligent systems. Existing SER
approaches are largely centralized, without considering users' privacy.
Federated Learning (FL) is a distributed machine learning paradigm dealing with
decentralization of privacy-sensitive personal data. In this paper, we present
a privacy-preserving and data-efficient SER approach by utilizing the concept
of FL. To the best of our knowledge, this is the first federated SER approach,
which utilizes self-training learning in conjunction with federated learning to
exploit both labeled and unlabeled on-device data. Our experimental evaluations
on the IEMOCAP dataset shows that our federated approach can learn
generalizable SER models even under low availability of data labels and highly
non-i.i.d. distributions. We show that our approach with as few as 10% labeled
data, on average, can improve the recognition rate by 8.67% compared to the
fully-supervised federated counterparts.</p>
  </details>
</details>
<details>
  <summary>129. <b>标题：Exemplar-Based Contrastive Self-Supervised Learning with Few-Shot Class  Incremental Learning</b></summary>
  <p><b>编号</b>：[326]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02601</p>
  <p><b>作者</b>：Daniel T. Chang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：shot class incremental learning, valuable supervised knowledge )., exemplars takes place within, learning new concepts, discuss extending cssl</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Humans are capable of learning new concepts from only a few (labeled)
exemplars, incrementally and continually. This happens within the context that
we can differentiate among the exemplars, and between the exemplars and large
amounts of other data (unlabeled and labeled). This suggests, in human
learning, supervised learning of concepts based on exemplars takes place within
the larger context of contrastive self-supervised learning (CSSL) based on
unlabeled and labeled data. We discuss extending CSSL (1) to be based mainly on
exemplars and only secondly on data augmentation, and (2) to apply to both
unlabeled data (a large amount is available in general) and labeled data (a few
exemplars can be obtained with valuable supervised knowledge). A major benefit
of the extensions is that exemplar-based CSSL, with supervised finetuning,
supports few-shot class incremental learning (CIL). Specifically, we discuss
exemplar-based CSSL including: nearest-neighbor CSSL, neighborhood CSSL with
supervised pretraining, and exemplar CSSL with supervised finetuning. We
further discuss using exemplar-based CSSL to facilitate few-shot learning and,
in particular, few-shot CIL.</p>
  </details>
</details>
<details>
  <summary>130. <b>标题：Memory Defense: More Robust Classification via a Memory-Masking  Autoencoder</b></summary>
  <p><b>编号</b>：[327]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02595</p>
  <p><b>作者</b>：Eashan Adhikarla (1),  Dan Luo (1),  Brian D. Davison (1) ((1) Lehigh University)</p>
  <p><b>备注</b>：11 pages</p>
  <p><b>关键词</b>：typical autoencoders easily mingle inter, many deep neural networks, four widely used attacks, could ignore small changes, specific independent latent representations</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Many deep neural networks are susceptible to minute perturbations of images
that have been carefully crafted to cause misclassification. Ideally, a robust
classifier would be immune to small variations in input images, and a number of
defensive approaches have been created as a result. One method would be to
discern a latent representation which could ignore small changes to the input.
However, typical autoencoders easily mingle inter-class latent representations
when there are strong similarities between classes, making it harder for a
decoder to accurately project the image back to the original high-dimensional
space. We propose a novel framework, Memory Defense, an augmented classifier
with a memory-masking autoencoder to counter this challenge. By masking other
classes, the autoencoder learns class-specific independent latent
representations. We test the model's robustness against four widely used
attacks. Experiments on the Fashion-MNIST & CIFAR-10 datasets demonstrate the
superiority of our model. We make available our source code at GitHub
repository: this https URL</p>
  </details>
</details>
<details>
  <summary>131. <b>标题：VIS-iTrack: Visual Intention through Gaze Tracking using Low-Cost Webcam</b></summary>
  <p><b>编号</b>：[329]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02587</p>
  <p><b>作者</b>：Shahed Anzarus Sabab (1, 2, 3, 4, and 5),  Mohammad Ridwan Kabir (1, 2, and 3),  Sayed Rizban Hussain (1, 2, and 3),  Hasan Mahmud (1, 2, and 3),  Md. Kamrul Hasan (1, 2, and 3),  Husne Ara Rubaiyeat (6) ((1) Systems and Software Lab (SSL), (2) Department of Computer Science and Engineering, (3) Islamic University of Technology (IUT), Gazipur, Bangladesh, (4) Department of Computer Science, (5) University of Manitoba, Winnipeg, Canada, (6) National University, Bangladesh.)</p>
  <p><b>备注</b>：15 pages, 9 figures, 4 tables</p>
  <p><b>关键词</b>：leaned towards graphical contents whereas older adults felt, interactive interfaces containing either textual, visual intention among 30 participants, including support vector machine, g ., fixation count</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Human intention is an internal, mental characterization for acquiring desired
information. From interactive interfaces containing either textual or graphical
information, intention to perceive desired information is subjective and
strongly connected with eye gaze. In this work, we determine such intention by
analyzing real-time eye gaze data with a low-cost regular webcam. We extracted
unique features (e.g., Fixation Count, Eye Movement Ratio) from the eye gaze
data of 31 participants to generate a dataset containing 124 samples of visual
intention for perceiving textual or graphical information, labeled as either
TEXT or IMAGE, having 48.39% and 51.61% distribution, respectively. Using this
dataset, we analyzed 5 classifiers, including Support Vector Machine (SVM)
(Accuracy: 92.19%). Using the trained SVM, we investigated the variation of
visual intention among 30 participants, distributed in 3 age groups, and found
out that young users were more leaned towards graphical contents whereas older
adults felt more interested in textual ones. This finding suggests that
real-time eye gaze data can be a potential source of identifying visual
intention, analyzing which intention aware interactive interfaces can be
designed and developed to facilitate human cognition.</p>
  </details>
</details>
<details>
  <summary>132. <b>标题：Communication Efficient Federated Learning via Ordered ADMM in a Fully  Decentralized Setting</b></summary>
  <p><b>编号</b>：[333]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02580</p>
  <p><b>作者</b>：Yicheng Chen,  Rick S. Blum,  Brian M. Sadler</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：general fully decentralized network setting, based alternating direction method, existing algorithms including admm, local variables based, numerical results demonstrate</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The challenge of communication-efficient distributed optimization has
attracted attention in recent years. In this paper, a communication efficient
algorithm, called ordering-based alternating direction method of multipliers
(OADMM) is devised in a general fully decentralized network setting where a
worker can only exchange messages with neighbors. Compared to the classical
ADMM, a key feature of OADMM is that transmissions are ordered among workers at
each iteration such that a worker with the most informative data broadcasts its
local variable to neighbors first, and neighbors who have not transmitted yet
can update their local variables based on that received transmission. In OADMM,
we prohibit workers from transmitting if their current local variables are not
sufficiently different from their previously transmitted value. A variant of
OADMM, called SOADMM, is proposed where transmissions are ordered but
transmissions are never stopped for each node at each iteration. Numerical
results demonstrate that given a targeted accuracy, OADMM can significantly
reduce the number of communications compared to existing algorithms including
ADMM. We also show numerically that SOADMM can accelerate convergence,
resulting in communication savings compared to the classical ADMM.</p>
  </details>
</details>
<details>
  <summary>133. <b>标题：Causal Disentanglement for Semantics-Aware Intent Learning in  Recommendation</b></summary>
  <p><b>编号</b>：[334]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02576</p>
  <p><b>作者</b>：Xiangmeng Wang,  Qian Li,  Dianer Yu,  Peng Cui,  Zhichao Wang,  Guandong Xu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：aware representations via disentangling users true intents aware, causal relations underlying recommendation task, aware disentanglement learning called cadsi, traditional recommendation models trained, eliminate confounding bias stemmed</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Traditional recommendation models trained on observational interaction data
have generated large impacts in a wide range of applications, it faces bias
problems that cover users' true intent and thus deteriorate the recommendation
effectiveness. Existing methods tracks this problem as eliminating bias for the
robust recommendation, e.g., by re-weighting training samples or learning
disentangled representation. The disentangled representation methods as the
state-of-the-art eliminate bias through revealing cause-effect of the bias
generation. However, how to design the semantics-aware and unbiased
representation for users true intents is largely unexplored. To bridge the gap,
we are the first to propose an unbiased and semantics-aware disentanglement
learning called CaDSI (Causal Disentanglement for Semantics-Aware Intent
Learning) from a causal perspective. Particularly, CaDSI explicitly models the
causal relations underlying recommendation task, and thus produces
semantics-aware representations via disentangling users true intents aware of
specific item context. Moreover, the causal intervention mechanism is designed
to eliminate confounding bias stemmed from context information, which further
to align the semantics-aware representation with users true intent. Extensive
experiments and case studies both validate the robustness and interpretability
of our proposed model.</p>
  </details>
</details>
<details>
  <summary>134. <b>标题：Differentially Private Graph Classification with GNNs</b></summary>
  <p><b>编号</b>：[335]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02575</p>
  <p><b>作者</b>：Tamara T. Mueller,  Johannes C. Paetzold,  Chinmay Prabhakar,  Dmitrii Usynin,  Daniel Rueckert,  Georgios Kaissis</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：differentially private stochastic gradient descent, assess whether similar representations, differentially private graph classification, many machine learning applications, differentially private training</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Graph Neural Networks (GNNs) have established themselves as the
state-of-the-art models for many machine learning applications such as the
analysis of social networks, protein interactions and molecules. Several among
these datasets contain privacy-sensitive data. Machine learning with
differential privacy is a promising technique to allow deriving insight from
sensitive data while offering formal guarantees of privacy protection. However,
the differentially private training of GNNs has so far remained under-explored
due to the challenges presented by the intrinsic structural connectivity of
graphs. In this work, we introduce differential privacy for graph-level
classification, one of the key applications of machine learning on graphs. Our
method is applicable to deep learning on multi-graph datasets and relies on
differentially private stochastic gradient descent (DP-SGD). We show results on
a variety of synthetic and public datasets and evaluate the impact of different
GNN architectures and training hyperparameters on model performance for
differentially private graph classification. Finally, we apply explainability
techniques to assess whether similar representations are learned in the private
and non-private settings and establish robust baselines for future work in this
area.</p>
  </details>
</details>
<details>
  <summary>135. <b>标题：TorchMD-NET: Equivariant Transformers for Neural Network based Molecular  Potentials</b></summary>
  <p><b>编号</b>：[350]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02541</p>
  <p><b>作者</b>：Philipp Thölke,  Gianni De Fabritiis</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：previously shown great success, extensive attention weight analysis, conformers versus conformations sampled, reaching increasingly better accuracy, maintaining computational efficiency comparable</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The prediction of quantum mechanical properties is historically plagued by a
trade-off between accuracy and speed. Machine learning potentials have
previously shown great success in this domain, reaching increasingly better
accuracy while maintaining computational efficiency comparable with classical
force fields. In this work we propose TorchMD-NET, a novel equivariant
transformer (ET) architecture, outperforming state-of-the-art on MD17, ANI-1,
and many QM9 targets in both accuracy and computational efficiency. Through an
extensive attention weight analysis, we gain valuable insights into the black
box predictor and show differences in the learned representation of conformers
versus conformations sampled from molecular dynamics or normal modes.
Furthermore, we highlight the importance of datasets including off-equilibrium
conformations for the evaluation of molecular potentials.</p>
  </details>
</details>
<details>
  <summary>136. <b>标题：Multidimensional Cybersecurity Framework for Strategic Foresight</b></summary>
  <p><b>编号</b>：[353]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02537</p>
  <p><b>作者</b>：Cyril Onwubiko,  Karim Ouazzane</p>
  <p><b>备注</b>：31 pages, 7 figures</p>
  <p><b>关键词</b>：conceptual cybersecurity framework comprising six domains, organisational digital transformative agendas, sustainability issues demonstrate, multidimensional cybersecurity framework, guiding principles underpinning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Cybersecurity is now at the forefront of most organisational digital
transformative agendas and National economic, social and political programmes.
Hence its impact to society can no longer be seen to be one dimensional. The
rise in National cybersecurity laws and regulations is a good indicator of its
perceived importance to nations. And the recent awakening for social and
ethical transparency in society and coupled with sustainability issues
demonstrate the need for a paradigm shift in how cybersecurity discourses can
now happen. In response to this shift, a multidimensional cybersecurity
framework for strategic foresight underpinned on situational awareness is
proposed. The conceptual cybersecurity framework comprising six domains such as
Physical, Cultural, Economic, Social, Political and Cyber, is discussed. The
guiding principles underpinning the framework are outlined, followed by
in-depth reflection on the Business, Operational, Technological and Human
(BOTH) factors and their implications for strategic foresight for
cybersecurity.</p>
  </details>
</details>
<details>
  <summary>137. <b>标题：Graph Neural Network with Curriculum Learning for Imbalanced Node  Classification</b></summary>
  <p><b>编号</b>：[357]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02529</p>
  <p><b>作者</b>：Xiaohe Li,  Lijie Wen,  Yawen Deng,  Fuli Feng,  Xuming Hu,  Lei Wang,  Zide Fan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：evaluated via several widely used graph datasets, acquire certain reliable interpolation nodes, novel graph neural network framework, may even bring overfitting, proposed model consistently outperforms</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Graph Neural Network (GNN) is an emerging technique for graph-based learning
tasks such as node classification. In this work, we reveal the vulnerability of
GNN to the imbalance of node labels. Traditional solutions for imbalanced
classification (e.g. resampling) are ineffective in node classification without
considering the graph structure. Worse still, they may even bring overfitting
or underfitting results due to lack of sufficient prior knowledge. To solve
these problems, we propose a novel graph neural network framework with
curriculum learning (GNN-CL) consisting of two modules. For one thing, we hope
to acquire certain reliable interpolation nodes and edges through the novel
graph-based oversampling based on smoothness and homophily. For another, we
combine graph classification loss and metric learning loss which adjust the
distance between different nodes associated with minority class in feature
space. Inspired by curriculum learning, we dynamically adjust the weights of
different modules during training process to achieve better ability of
generalization and discrimination. The proposed framework is evaluated via
several widely used graph datasets, showing that our proposed model
consistently outperforms the existing state-of-the-art methods.</p>
  </details>
</details>
<details>
  <summary>138. <b>标题：LyaNet: A Lyapunov Framework for Training Neural ODEs</b></summary>
  <p><b>编号</b>：[358]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02526</p>
  <p><b>作者</b>：Ivan Dario Jimenez Rodriguez,  Aaron D. Ames,  Yisong Yue</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：minimizing lyapunov loss guarantees exponential convergence, novel lyapunov loss formulation, training ordinary differential equations, standard neural ode training, also provide practical algorithms</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose a method for training ordinary differential equations by using a
control-theoretic Lyapunov condition for stability. Our approach, called
LyaNet, is based on a novel Lyapunov loss formulation that encourages the
inference dynamics to converge quickly to the correct prediction.
Theoretically, we show that minimizing Lyapunov loss guarantees exponential
convergence to the correct solution and enables a novel robustness guarantee.
We also provide practical algorithms, including one that avoids the cost of
backpropagating through a solver or using the adjoint method. Relative to
standard Neural ODE training, we empirically find that LyaNet can offer
improved prediction performance, faster convergence of inference dynamics, and
improved adversarial robustness. Our code available at
this https URL .</p>
  </details>
</details>
<details>
  <summary>139. <b>标题：Score-based Generative Modeling of Graphs via the System of Stochastic  Differential Equations</b></summary>
  <p><b>编号</b>：[365]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02514</p>
  <p><b>作者</b>：Jaehyeong Jo,  Seul Lee,  Sung Ju Hwang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：derive novel score matching objectives tailored, previous graph generative methods either fail, either achieves significantly superior, structured data requires learning, new graph diffusion process</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Generating graph-structured data requires learning the underlying
distribution of graphs. Yet, this is a challenging problem, and the previous
graph generative methods either fail to capture the permutation-invariance
property of graphs or cannot sufficiently model the complex dependency between
nodes and edges, which is crucial for generating real-world graphs such as
molecules. To overcome such limitations, we propose a novel score-based
generative model for graphs with a continuous-time framework. Specifically, we
propose a new graph diffusion process that models the joint distribution of the
nodes and edges through a system of stochastic differential equations (SDEs).
Then, we derive novel score matching objectives tailored for the proposed
diffusion process to estimate the gradient of the joint log-density with
respect to each component, and introduce a new solver for the system of SDEs to
efficiently sample from the reverse diffusion process. We validate our graph
generation method on diverse datasets, on which it either achieves
significantly superior or competitive performance to the baselines. Further
analysis shows that our method is able to generate molecules that lie close to
the training distribution yet do not violate the chemical valency rule,
demonstrating the effectiveness of the system of SDEs in modeling the node-edge
relationships.</p>
  </details>
</details>
<details>
  <summary>140. <b>标题：A Survey on Poisoning Attacks Against Supervised Machine Learning</b></summary>
  <p><b>编号</b>：[367]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02510</p>
  <p><b>作者</b>：Wenjun Qiu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：propose several unanswered research questions, supervised machine learning models, major concerns regarding, categorize existing studies, prevent poisoning attacks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>With the rise of artificial intelligence and machine learning in modern
computing, one of the major concerns regarding such techniques is to provide
privacy and security against adversaries. We present this survey paper to cover
the most representative papers in poisoning attacks against supervised machine
learning models. We first provide a taxonomy to categorize existing studies and
then present detailed summaries for selected papers. We summarize and compare
the methodology and limitations of existing literature. We conclude this paper
with potential improvements and future directions to further exploit and
prevent poisoning attacks on supervised models. We propose several unanswered
research questions to encourage and inspire researchers for future work.</p>
  </details>
</details>
<details>
  <summary>141. <b>标题：Adversarial Detector with Robust Classifier</b></summary>
  <p><b>编号</b>：[369]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02503</p>
  <p><b>作者</b>：Takayuki Osakabe,  Maungmaung Aprilpyone,  Sayaka Shiota,  Hitoshi Kiya</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：easily misclassify prediction results, highly detect adversarial examples, called adversarial examples, using input images, novel adversarial detector</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep neural network (DNN) models are wellknown to easily misclassify
prediction results by using input images with small perturbations, called
adversarial examples. In this paper, we propose a novel adversarial detector,
which consists of a robust classifier and a plain one, to highly detect
adversarial examples. The proposed adversarial detector is carried out in
accordance with the logits of plain and robust classifiers. In an experiment,
the proposed detector is demonstrated to outperform a state-of-the-art detector
without any robust classifier.</p>
  </details>
</details>
<details>
  <summary>142. <b>标题：A Coalition Formation Game Approach for Personalized Federated Learning</b></summary>
  <p><b>编号</b>：[370]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02502</p>
  <p><b>作者</b>：Leijie Wu</p>
  <p><b>备注</b>：6 pages exclude the reference, 6 figures</p>
  <p><b>关键词</b>：complex multiwise influences take place among clients, perform personalized model aggregation based, first apply shapley value, achieve superior personalized accuracy, client local data distribution</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Facing the challenge of statistical diversity in client local data
distribution, personalized federated learning (PFL) has become a growing
research hotspot. Although the state-of-the-art methods with model
similarity-based pairwise collaboration have achieved promising performance,
they neglect the fact that model aggregation is essentially a collaboration
process within the coalition, where the complex multiwise influences take place
among clients. In this paper, we first apply Shapley value (SV) from coalition
game theory into the PFL scenario. To measure the multiwise collaboration among
a group of clients on the personalized learning performance, SV takes their
marginal contribution to the final result as a metric. We propose a novel
personalized algorithm: pFedSV, which can 1. identify each client's optimal
collaborator coalition and 2. perform personalized model aggregation based on
SV. Extensive experiments on various datasets (MNIST, Fashion-MNIST, and
CIFAR-10) are conducted with different Non-IID data settings (Pathological and
Dirichlet). The results show that pFedSV can achieve superior personalized
accuracy for each client, compared to the state-of-the-art benchmarks.</p>
  </details>
</details>
<details>
  <summary>143. <b>标题：GraphEye: A Novel Solution for Detecting Vulnerable Functions Based on  Graph Attention Network</b></summary>
  <p><b>编号</b>：[371]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02501</p>
  <p><b>作者</b>：Li Zhou,  Minhuan Huang,  Yujun Li,  Yuanping Nie,  Jin Li,  Yiwei Liu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：deep learning model based, graph classification problem according, automatedly detect software vulnerabilities, vulnerable function naturally differs, novel solution named grapheye</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>With the continuous extension of the Industrial Internet, cyber incidents
caused by software vulnerabilities have been increasing in recent years.
However, software vulnerabilities detection is still heavily relying on code
review done by experts, and how to automatedly detect software vulnerabilities
is an open problem so far. In this paper, we propose a novel solution named
GraphEye to identify whether a function of C/C++ code has vulnerabilities,
which can greatly alleviate the burden of code auditors. GraphEye is originated
from the observation that the code property graph of a non-vulnerable function
naturally differs from the code property graph of a vulnerable function with
the same functionality. Hence, detecting vulnerable functions is attributed to
the graph classification problem.GraphEye is comprised of VecCPG and GcGAT.
VecCPG is a vectorization for the code property graph, which is proposed to
characterize the key syntax and semantic features of the corresponding source
code. GcGAT is a deep learning model based on the graph attention graph, which
is proposed to solve the graph classification problem according to VecCPG.
Finally, GraphEye is verified by the SARD Stack-based Buffer Overflow,
Divide-Zero, Null Pointer Deference, Buffer Error, and Resource Error datasets,
the corresponding F1 scores are 95.6%, 95.6%,96.1%,92.6%, and 96.1%
respectively, which validate the effectiveness of the proposed solution.</p>
  </details>
</details>
<details>
  <summary>144. <b>标题：Weisfeiler-Lehman meets Gromov-Wasserstein</b></summary>
  <p><b>编号</b>：[373]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02495</p>
  <p><b>作者</b>：Samantha Chen,  Sunhyuk Lim,  Facundo Mémoli,  Zhengchao Wan,  Yusu Wang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：comparing metric markov chains, polynomial time lower bound, labeled measure markov chains, analyzing graph neural networks, polynomial time computable</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The Weisfeiler-Lehman (WL) test is a classical procedure for graph
isomorphism testing. The WL test has also been widely used both for designing
graph kernels and for analyzing graph neural networks. In this paper, we
propose the Weisfeiler-Lehman (WL) distance, a notion of distance between
labeled measure Markov chains (LMMCs), of which labeled graphs are special
cases. The WL distance is polynomial time computable and is also compatible
with the WL test in the sense that the former is positive if and only if the WL
test can distinguish the two involved graphs. The WL distance captures and
compares subtle structures of the underlying LMMCs and, as a consequence of
this, it is more discriminating than the distance between graphs used for
defining the state-of-the-art Wasserstein Weisfeiler-Lehman graph kernel.
Inspired by the structure of the WL distance we identify a neural network
architecture on LMMCs which turns out to be universal w.r.t. continuous
functions defined on the space of all LMMCs (which includes all graphs) endowed
with the WL distance. Finally, the WL distance turns out to be stable w.r.t. a
natural variant of the Gromov-Wasserstein (GW) distance for comparing metric
Markov chains that we identify. Hence, the WL distance can also be construed as
a polynomial time lower bound for the GW distance which is in general NP-hard
to compute.</p>
  </details>
</details>
<details>
  <summary>145. <b>标题：Distributed Learning With Sparsified Gradient Differences</b></summary>
  <p><b>编号</b>：[375]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02491</p>
  <p><b>作者</b>：Yicheng Chen,  Rick S. Blum,  Martin Takac,  Brian M. Sadler</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：scale model learning without sacrificing convergence, best existing algorithms without slowing, solve distributed learning tasks, wireless communications learning scenarios, fast linear convergence rate</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A very large number of communications are typically required to solve
distributed learning tasks, and this critically limits scalability and
convergence speed in wireless communications applications. In this paper, we
devise a Gradient Descent method with Sparsification and Error Correction
(GD-SEC) to improve the communications efficiency in a general worker-server
architecture. Motivated by a variety of wireless communications learning
scenarios, GD-SEC reduces the number of bits per communication from worker to
server with no degradation in the order of the convergence rate. This enables
larger-scale model learning without sacrificing convergence or accuracy. At
each iteration of GD-SEC, instead of directly transmitting the entire gradient
vector, each worker computes the difference between its current gradient and a
linear combination of its previously transmitted gradients, and then transmits
the sparsified gradient difference to the server. A key feature of GD-SEC is
that any given component of the gradient difference vector will not be
transmitted if its magnitude is not sufficiently large. An error correction
technique is used at each worker to compensate for the error resulting from
sparsification. We prove that GD-SEC is guaranteed to converge for strongly
convex, convex, and nonconvex optimization problems with the same order of
convergence rate as GD. Furthermore, if the objective function is strongly
convex, GD-SEC has a fast linear convergence rate. Numerical results not only
validate the convergence rate of GD-SEC but also explore the communication bit
savings it provides. Given a target accuracy, GD-SEC can significantly reduce
the communications load compared to the best existing algorithms without
slowing down the optimization process.</p>
  </details>
</details>
<details>
  <summary>146. <b>标题：LotRec: A Recommender for Urban Vacant Lot Conversion</b></summary>
  <p><b>编号</b>：[378]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02481</p>
  <p><b>作者</b>：Md Towhidul A Chowdhury,  Naveen Sharma</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：recommender yields mean f, world vacant lot datasets, provide computational support, across two cities, two key questions</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Vacant lots are neglected properties in a city that lead to environmental
hazards and poor standard of living for the community. Thus, reclaiming vacant
lots and putting them to productive use is an important consideration for many
cities. Given a large number of vacant lots and resource constraints for
conversion, two key questions for a city are (1) whether to convert a vacant
lot or not; and (2) what to convert a vacant lot as. We seek to provide
computational support to answer these questions. To this end, we identify the
determinants of a vacant lot conversion and build a recommender based on those
determinants. We evaluate our models on real-world vacant lot datasets from the
US cities of Philadelphia,PA and Baltimore, MD. Our results indicate that our
recommender yields mean F-measures of (1) 90% in predicting whether a vacant
lot should be converted or not within a single city, (2) 91% in predicting what
a vacant lot should be converted to, within a single city and, (3) 85% in
predicting whether a vacant lot should be converted or not across two cities.</p>
  </details>
</details>
<details>
  <summary>147. <b>标题：Few-shot Learning as Cluster-induced Voronoi Diagrams: A Geometric  Approach</b></summary>
  <p><b>编号</b>：[382]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02471</p>
  <p><b>作者</b>：Chunwei Ma,  Ziyun Huang,  Mingchen Gao,  Jinhui Xu</p>
  <p><b>备注</b>：Accepted for publication in ICLR 2022; this https URL</p>
  <p><b>关键词</b>：2 \%{-} 5 \%$ improvements upon, widely embraced protonet model, simplest nearest neighbor model, based workflow enables us, together make fsl stronger</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Few-shot learning (FSL) is the process of rapid generalization from abundant
base samples to inadequate novel samples. Despite extensive research in recent
years, FSL is still not yet able to generate satisfactory solutions for a wide
range of real-world applications. To confront this challenge, we study the FSL
problem from a geometric point of view in this paper. One observation is that
the widely embraced ProtoNet model is essentially a Voronoi Diagram (VD) in the
feature space. We retrofit it by making use of a recent advance in
computational geometry called Cluster-induced Voronoi Diagram (CIVD). Starting
from the simplest nearest neighbor model, CIVD gradually incorporates
cluster-to-point and then cluster-to-cluster relationships for space
subdivision, which is used to improve the accuracy and robustness at multiple
stages of FSL. Specifically, we use CIVD (1) to integrate parametric and
nonparametric few-shot classifiers; (2) to combine feature representation and
surrogate representation; (3) and to leverage feature-level,
transformation-level, and geometry-level heterogeneities for a better ensemble.
Our CIVD-based workflow enables us to achieve new state-of-the-art results on
mini-ImageNet, CUB, and tiered-ImagenNet datasets, with ${\sim}2\%{-}5\%$
improvements upon the next best. To summarize, CIVD provides a mathematically
elegant and geometrically interpretable framework that compensates for extreme
data insufficiency, prevents overfitting, and allows for fast geometric
ensemble for thousands of individual VD. These together make FSL stronger.</p>
  </details>
</details>
<details>
  <summary>148. <b>标题：MarkovGNN: Graph Neural Networks on Markov Diffusion</b></summary>
  <p><b>编号</b>：[383]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02470</p>
  <p><b>作者</b>：Md. Khaledur Rahman,  Abhigya Agrawal,  Ariful Azad</p>
  <p><b>备注</b>：total 12 pages</p>
  <p><b>关键词</b>：markovgnn generates different stochastic matrices using, densely connected internally within communities, world networks contain well, different convolutional layers, graph neural networks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Most real-world networks contain well-defined community structures where
nodes are densely connected internally within communities. To learn from these
networks, we develop MarkovGNN that captures the formation and evolution of
communities directly in different convolutional layers. Unlike most Graph
Neural Networks (GNNs) that consider a static graph at every layer, MarkovGNN
generates different stochastic matrices using a Markov process and then uses
these community-capturing matrices in different layers. MarkovGNN is a general
approach that could be used with most existing GNNs. We experimentally show
that MarkovGNN outperforms other GNNs for clustering, node classification, and
visualization tasks. The source code of MarkovGNN is publicly available at
\url{this https URL}.</p>
  </details>
</details>
<details>
  <summary>149. <b>标题：Rethinking ValueDice: Does It Really Improve Performance?</b></summary>
  <p><b>编号</b>：[384]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02468</p>
  <p><b>作者</b>：Ziniu Li,  Tian Xu,  Yang Yu,  Zhi-Quan Luo</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：imitation learning studies beyond valuedice, classical approach behavioral cloning, first two claims explain, bc also nearly matches, adversarial imitation learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Since the introduction of GAIL, adversarial imitation learning (AIL) methods
attract lots of research interests. Among these methods, ValueDice has achieved
significant improvements: it beats the classical approach Behavioral Cloning
(BC) under the offline setting, and it requires fewer interactions than GAIL
under the online setting. Are these improvements benefited from more advanced
algorithm designs? We answer this question with the following conclusions.
First, we show that ValueDice could reduce to BC under the offline setting.
Second, we verify that overfitting exists and regularization matters.
Specifically, we demonstrate that with weight decay, BC also nearly matches the
expert performance as ValueDice does. The first two claims explain the superior
offline performance of ValueDice. Third, we establish that ValueDice does not
work at all when the expert trajectory is subsampled. Instead, the mentioned
success holds when the expert trajectory is complete, in which ValueDice is
closely related to BC that performs well as mentioned. Finally, we discuss the
implications of our research for imitation learning studies beyond ValueDice.</p>
  </details>
</details>
<details>
  <summary>150. <b>标题：Handling Distribution Shifts on Graphs: An Invariance Perspective</b></summary>
  <p><b>编号</b>：[386]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02466</p>
  <p><b>作者</b>：Qitian Wu,  Hengrui Zhang,  Junchi Yan,  David Wipf</p>
  <p><b>备注</b>：ICLR2022, 31 pages</p>
  <p><b>关键词</b>：increasing evidence suggesting neural networks, current endeavors mostly focus, design multiple context explorers, leverage invariant graph features, multiple virtual environments</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>There is increasing evidence suggesting neural networks' sensitivity to
distribution shifts, so that research on out-of-distribution (OOD)
generalization comes into the spotlight. Nonetheless, current endeavors mostly
focus on Euclidean data, and its formulation for graph-structured data is not
clear and remains under-explored, given the two-fold fundamental challenges: 1)
the inter-connection among nodes in one graph, which induces non-IID generation
of data points even under the same environment, and 2) the structural
information in the input graph, which is also informative for prediction. In
this paper, we formulate the OOD problem for node-level prediction on graphs
and develop a new domain-invariant learning approach, named
Explore-to-Extrapolate Risk Minimization, that facilitates GNNs to leverage
invariant graph features for prediction. The key difference to existing
invariant models is that we design multiple context explorers (specified as
graph editers in our case) that are adversarially trained to maximize the
variance of risks from multiple virtual environments. Such a design enables the
model to extrapolate from a single observed environment which is the common
case for node-level prediction. We prove the validity of our method by
theoretically showing its guarantee of a valid OOD solution and further
demonstrate its power on various real-world datasets for handling distribution
shifts from artificial spurious features, cross-domain transfers and dynamic
graph evolution.</p>
  </details>
</details>
<details>
  <summary>151. <b>标题：ASHA: Assistive Teleoperation via Human-in-the-Loop Reinforcement  Learning</b></summary>
  <p><b>编号</b>：[387]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02465</p>
  <p><b>作者</b>：Sean Chen,  Jensen Gao,  Siddharth Reddy,  Glen Berseth,  Anca D. Dragan,  Sergey Levine</p>
  <p><b>备注</b>：Accepted to IEEE Conference on Robotics and Automation (ICRA) 2022</p>
  <p><b>关键词</b>：three simulated robotic manipulation domains using, employ different gaze strategies, g ., webcam images, using online user feedback, reach objects inside</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Building assistive interfaces for controlling robots through arbitrary,
high-dimensional, noisy inputs (e.g., webcam images of eye gaze) can be
challenging, especially when it involves inferring the user's desired action in
the absence of a natural 'default' interface. Reinforcement learning from
online user feedback on the system's performance presents a natural solution to
this problem, and enables the interface to adapt to individual users. However,
this approach tends to require a large amount of human-in-the-loop training
data, especially when feedback is sparse. We propose a hierarchical solution
that learns efficiently from sparse user feedback: we use offline pre-training
to acquire a latent embedding space of useful, high-level robot behaviors,
which, in turn, enables the system to focus on using online user feedback to
learn a mapping from user inputs to desired high-level behaviors. The key
insight is that access to a pre-trained policy enables the system to learn more
from sparse rewards than a naïve RL algorithm: using the pre-trained policy,
the system can make use of successful task executions to relabel, in hindsight,
what the user actually meant to do during unsuccessful executions. We evaluate
our method primarily through a user study with 12 participants who perform
tasks in three simulated robotic manipulation domains using a webcam and their
eye gaze: flipping light switches, opening a shelf door to reach objects
inside, and rotating a valve. The results show that our method successfully
learns to map 128-dimensional gaze features to 7-dimensional joint torques from
sparse rewards in under 10 minutes of online training, and seamlessly helps
users who employ different gaze strategies, while adapting to distributional
shift in webcam inputs, tasks, and environments.</p>
  </details>
</details>
<details>
  <summary>152. <b>标题：Application of Machine Learning-Based Pattern Recognition in IoT  Devices: Review</b></summary>
  <p><b>编号</b>：[391]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02456</p>
  <p><b>作者</b>：Zachary Menter,  Wei Tee,  Rushit Dave</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：overall required processing power, different machine learning algorithms, based pattern recognition algorithms, optimal machine learning, pattern recognition algorithms</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The Internet of things (IoT) is a rapidly advancing area of technology that
has quickly become more widespread in recent years. With greater numbers of
everyday objects being connected to the Internet, many different innovations
have been presented to make our everyday lives more straightforward. Pattern
recognition is extremely prevalent in IoT devices because of the many
applications and benefits that can come from it. A multitude of studies has
been conducted with the intention of improving speed and accuracy, decreasing
complexity, and reducing the overall required processing power of pattern
recognition algorithms in IoT devices. After reviewing the applications of
different machine learning algorithms, results vary from case to case, but a
general conclusion can be drawn that the optimal machine learning-based pattern
recognition algorithms to be used with IoT devices are support vector machine,
k-nearest neighbor, and random forest.</p>
  </details>
</details>
<details>
  <summary>153. <b>标题：Supervised Learning based QoE Prediction of Video Streaming in Future  Networks: A Tutorial with Comparative Study</b></summary>
  <p><b>编号</b>：[393]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02454</p>
  <p><b>作者</b>：Arslan Ahmad,  Atif Bin Mansoor,  Alcardo Alex Barakabitze,  Andrew Hines,  Luigi Atzori,  Ray Walshe</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：covers several stages including data collection, sdn ), network function virtualization, based video streaming qoe prediction models, based service management remains key, art supervised learning ml models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The Quality of Experience (QoE) based service management remains key for
successful provisioning of multimedia services in next-generation networks such
as 5G/6G, which requires proper tools for quality monitoring, prediction and
resource management where machine learning (ML) can play a crucial role. In
this paper, we provide a tutorial on the development and deployment of the QoE
measurement and prediction solutions for video streaming services based on
supervised learning ML models. Firstly, we provide a detailed pipeline for
developing and deploying supervised learning-based video streaming QoE
prediction models which covers several stages including data collection,
feature engineering, model optimization and training, testing and prediction
and evaluation. Secondly, we discuss the deployment of the ML model for the QoE
prediction/measurement in the next generation networks (5G/6G) using network
enabling technologies such as Software-Defined Networking (SDN), Network
Function Virtualization (NFV) and Mobile Edge Computing (MEC) by proposing
reference architecture. Thirdly, we present a comparative study of the
state-of-the-art supervised learning ML models for QoE prediction of video
streaming applications based on multiple performance metrics.</p>
  </details>
</details>
<details>
  <summary>154. <b>标题：Linear Model with Local Differential Privacy</b></summary>
  <p><b>编号</b>：[397]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02448</p>
  <p><b>作者</b>：Guanhong Miao,  A. Adam Ding,  Samuel S. Wu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：select optimal parameters without additional communication cost, security techniques sacrificing partial data utility, analyze distributed data across different agencies, n << p )., achieving local differential privacy</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Scientific collaborations benefit from collaborative learning of distributed
sources, but remain difficult to achieve when data are sensitive. In recent
years, privacy preserving techniques have been widely studied to analyze
distributed data across different agencies while protecting sensitive
information. Secure multiparty computation has been widely studied for privacy
protection with high privacy level but intense computation cost. There are also
other security techniques sacrificing partial data utility to reduce disclosure
risk. A major challenge is to balance data utility and disclosure risk while
maintaining high computation efficiency. In this paper, matrix masking
technique is applied to encrypt data such that the secure schemes are against
malicious adversaries while achieving local differential privacy. The proposed
schemes are designed for linear models and can be implemented for both vertical
and horizontal partitioning scenarios. Moreover, cross validation is studied to
prevent overfitting and select optimal parameters without additional
communication cost. Simulation results present the efficiency of proposed
schemes to analyze dataset with millions of records and high-dimensional data
(n << p).</p>
  </details>
</details>
<details>
  <summary>155. <b>标题：Adversarially Trained Actor Critic for Offline Reinforcement Learning</b></summary>
  <p><b>编号</b>：[398]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02446</p>
  <p><b>作者</b>：Ching-An Cheng,  Tengyang Xie,  Nan Jiang,  Alekh Agarwal</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：propose adversarially trained actor critic, adversarially trained value critic, deep rl implementation scalable, art offline rl algorithms, player stackelberg game framing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose Adversarially Trained Actor Critic (ATAC), a new model-free
algorithm for offline reinforcement learning under insufficient data coverage,
based on a two-player Stackelberg game framing of offline RL: A policy actor
competes against an adversarially trained value critic, who finds
data-consistent scenarios where the actor is inferior to the data-collection
behavior policy. We prove that, when the actor attains no regret in the
two-player game, running ATAC produces a policy that provably 1) outperforms
the behavior policy over a wide range of hyperparameters, and 2) competes with
the best policy covered by data with appropriately chosen hyperparameters.
Compared with existing works, notably our framework offers both theoretical
guarantees for general function approximation and a deep RL implementation
scalable to complex environments and large datasets. In the D4RL benchmark,
ATAC consistently outperforms state-of-the-art offline RL algorithms on a range
of continuous control tasks</p>
  </details>
</details>
<details>
  <summary>156. <b>标题：Spelunking the Deep: Guaranteed Queries for General Neural Implicit  Surfaces</b></summary>
  <p><b>编号</b>：[399]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02444</p>
  <p><b>作者</b>：Nicholas Sharp,  Alec Jacobson</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：develop geometric queries including ray casting, offer concrete accuracy guarantees even, best evaluate geometric queries, using automatic arithmetic rules, general neural implicit functions</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Neural implicit representations, which encode a surface as the level set of a
neural network applied to spatial coordinates, have proven to be remarkably
effective for optimizing, compressing, and generating 3D geometry. Although
these representations are easy to fit, it is not clear how to best evaluate
geometric queries on the shape, such as intersecting against a ray or finding a
closest point. The predominant approach is to encourage the network to have a
signed distance property. However, this property typically holds only
approximately, leading to robustness issues, and holds only at the conclusion
of training, inhibiting the use of queries in loss functions. Instead, this
work presents a new approach to perform queries directly on general neural
implicit functions for a wide range of existing architectures. Our key tool is
the application of range analysis to neural networks, using automatic
arithmetic rules to bound the output of a network over a region; we conduct a
study of range analysis on neural networks, and identify variants of affine
arithmetic which are highly effective. We use the resulting bounds to develop
geometric queries including ray casting, intersection testing, constructing
spatial hierarchies, fast mesh extraction, closest-point evaluation, evaluating
bulk properties, and more. Our queries can be efficiently evaluated on GPUs,
and offer concrete accuracy guarantees even on randomly-initialized networks,
enabling their use in training objectives and beyond. We also show a
preliminary application to inverse rendering.</p>
  </details>
</details>
<details>
  <summary>157. <b>标题：Transfer Reinforcement Learning for Differing Action Spaces via  Q-Network Representations</b></summary>
  <p><b>编号</b>：[400]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02442</p>
  <p><b>作者</b>：Nathan Beck,  Abhiramon Rajasekharan,  Trung Hieu Tran</p>
  <p><b>备注</b>：5 pages, 2 figures, 1 table</p>
  <p><b>关键词</b>：recent research focus within, reward shaping method based, source embedding similarity, different transition dynamics, brockman et al</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Transfer learning approaches in reinforcement learning aim to assist agents
in learning their target domains by leveraging the knowledge learned from other
agents that have been trained on similar source domains. For example, recent
research focus within this space has been placed on knowledge transfer between
tasks that have different transition dynamics and reward functions; however,
little focus has been placed on knowledge transfer between tasks that have
different action spaces. In this paper, we approach the task of transfer
learning between domains that differ in action spaces. We present a reward
shaping method based on source embedding similarity that is applicable to
domains with both discrete and continuous action spaces. The efficacy of our
approach is evaluated on transfer to restricted action spaces in the Acrobot-v1
and Pendulum-v0 domains (Brockman et al. 2016). A comparison with two baselines
shows that our method does not outperform these baselines in these continuous
action spaces but does show an improvement in these discrete action spaces. We
conclude our analysis with future directions for this work.</p>
  </details>
</details>
<details>
  <summary>158. <b>标题：SEED: Sound Event Early Detection via Evidential Uncertainty</b></summary>
  <p><b>编号</b>：[401]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02441</p>
  <p><b>作者</b>：Xujiang Zhao,  Xuchao Zhang,  Wei Cheng,  Wenchao Yu,  Yuncong Chen,  Haifeng Chen,  Feng Chen</p>
  <p><b>备注</b>：ICASSP 2022</p>
  <p><b>关键词</b>：novel polyphonic evidential neural network, evidential uncertainty enriches uncertainty representation, usually yield unreliable results, detection f1 score compared, offline sound event detection</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Sound Event Early Detection (SEED) is an essential task in recognizing the
acoustic environments and soundscapes. However, most of the existing methods
focus on the offline sound event detection, which suffers from the
over-confidence issue of early-stage event detection and usually yield
unreliable results. To solve the problem, we propose a novel Polyphonic
Evidential Neural Network (PENet) to model the evidential uncertainty of the
class probability with Beta distribution. Specifically, we use a Beta
distribution to model the distribution of class probabilities, and the
evidential uncertainty enriches uncertainty representation with evidence
information, which plays a central role in reliable prediction. To further
improve the event detection performance, we design the backtrack inference
method that utilizes both the forward and backward audio features of an ongoing
event. Experiments on the DESED database show that the proposed method can
simultaneously improve 13.0\% and 3.8\% in time delay and detection F1 score
compared to the state-of-the-art methods.</p>
  </details>
</details>
<details>
  <summary>159. <b>标题：Zero Experience Required: Plug & Play Modular Transfer Learning for  Semantic Visual Navigation</b></summary>
  <p><b>编号</b>：[402]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02440</p>
  <p><b>作者</b>：Ziad Al-Halah,  Santhosh K. Ramakrishnan,  Kristen Grauman</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：novel modular transfer learning model, target tasks without receiving, multiple target tasks, challenging tasks show, outperforms sota models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In reinforcement learning for visual navigation, it is common to develop a
model for each new task, and train that model from scratch with task-specific
interactions in 3D environments. However, this process is expensive; massive
amounts of interactions are needed for the model to generalize well. Moreover,
this process is repeated whenever there is a change in the task type or the
goal modality. We present a unified approach to visual navigation using a novel
modular transfer learning model. Our model can effectively leverage its
experience from one source task and apply it to multiple target tasks (e.g.,
ObjectNav, RoomNav, ViewNav) with various goal modalities (e.g., image, sketch,
audio, label). Furthermore, our model enables zero-shot experience learning,
whereby it can solve the target tasks without receiving any task-specific
interactive training. Our experiments on multiple photorealistic datasets and
challenging tasks show that our approach learns faster, generalizes better, and
outperforms SoTA models by a significant margin.</p>
  </details>
</details>
<details>
  <summary>160. <b>标题：Neural Logic Analogy Learning</b></summary>
  <p><b>编号</b>：[403]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02436</p>
  <p><b>作者</b>：Yujia Fan,  Yongfeng Zhang</p>
  <p><b>备注</b>：11 pages, 1 figure, 3 tables</p>
  <p><b>关键词</b>：model builds computational graph integrating neural network, main idea behind current approaches, based noan approach outperforms state, problem makes current approaches unable, propose neural logic analogy learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Letter-string analogy is an important analogy learning task which seems to be
easy for humans but very challenging for machines. The main idea behind current
approaches to solving letter-string analogies is to design heuristic rules for
extracting analogy structures and constructing analogy mappings. However, one
key problem is that it is difficult to build a comprehensive and exhaustive set
of analogy structures which can fully describe the subtlety of analogies. This
problem makes current approaches unable to handle complicated letter-string
analogy problems. In this paper, we propose Neural logic analogy learning
(Noan), which is a dynamic neural architecture driven by differentiable logic
reasoning to solve analogy problems. Each analogy problem is converted into
logical expressions consisting of logical variables and basic logical
operations (AND, OR, and NOT). More specifically, Noan learns the logical
variables as vector embeddings and learns each logical operation as a neural
module. In this way, the model builds computational graph integrating neural
network with logical reasoning to capture the internal logical structure of the
input letter strings. The analogy learning problem then becomes a True/False
evaluation problem of the logical expressions. Experiments show that our
machine learning-based Noan approach outperforms state-of-the-art approaches on
standard letter-string analogy benchmark datasets.</p>
  </details>
</details>
<details>
  <summary>161. <b>标题：On Neural Differential Equations</b></summary>
  <p><b>编号</b>：[404]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02435</p>
  <p><b>作者</b>：Patrick Kidger</p>
  <p><b>备注</b>：Doctoral thesis, Mathematical Institute, University of Oxford. 231 pages</p>
  <p><b>关键词</b>：physical systems ); neural controlled differential equations, brownian reconstruction ); symbolic regression, many popular neural network architectures, via regularised evolution );, reversible differential equations solvers</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The conjoining of dynamical systems and deep learning has become a topic of
great interest. In particular, neural differential equations (NDEs) demonstrate
that neural networks and differential equation are two sides of the same coin.
Traditional parameterised differential equations are a special case. Many
popular neural network architectures, such as residual networks and recurrent
networks, are discretisations.
NDEs are suitable for tackling generative problems, dynamical systems, and
time series (particularly in physics, finance, ...) and are thus of interest to
both modern machine learning and traditional mathematical modelling. NDEs offer
high-capacity function approximation, strong priors on model space, the ability
to handle irregular data, memory efficiency, and a wealth of available theory
on both sides.
This doctoral thesis provides an in-depth survey of the field.
Topics include: neural ordinary differential equations (e.g. for hybrid
neural/mechanistic modelling of physical systems); neural controlled
differential equations (e.g. for learning functions of irregular time series);
and neural stochastic differential equations (e.g. to produce generative models
capable of representing complex stochastic dynamics, or sampling from complex
high-dimensional distributions).
Further topics include: numerical methods for NDEs (e.g. reversible
differential equations solvers, backpropagation through differential equations,
Brownian reconstruction); symbolic regression for dynamical systems (e.g. via
regularised evolution); and deep implicit models (e.g. deep equilibrium models,
differentiable optimisation).
We anticipate this thesis will be of interest to anyone interested in the
marriage of deep learning with dynamical systems, and hope it will provide a
useful reference for the current state of the art.</p>
  </details>
</details>
<details>
  <summary>162. <b>标题：SMODICE: Versatile Offline Imitation Learning via State Occupancy  Matching</b></summary>
  <p><b>编号</b>：[405]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02433</p>
  <p><b>作者</b>：Yecheng Jason Ma,  Andrew Shen,  Dinesh Jayaraman,  Osbert Bastani</p>
  <p><b>备注</b>：Project website: this https URL</p>
  <p><b>关键词</b>：propose state matching offline distribution correction estimation, significantly outperforms prior state, three offline il settings, dimensional offline benchmarks, three problem settings</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose State Matching Offline DIstribution Correction Estimation
(SMODICE), a novel and versatile algorithm for offline imitation learning (IL)
via state-occupancy matching. We show that the SMODICE objective admits a
simple optimization procedure through an application of Fenchel duality and an
analytic solution in tabular MDPs. Without requiring access to expert actions,
SMODICE can be effectively applied to three offline IL settings: (i) imitation
from observations (IfO), (ii) IfO with dynamics or morphologically mismatched
expert, and (iii) example-based reinforcement learning, which we show can be
formulated as a state-occupancy matching problem. We extensively evaluate
SMODICE on both gridworld environments as well as on high-dimensional offline
benchmarks. Our results demonstrate that SMODICE is effective for all three
problem settings and significantly outperforms prior state-of-art.</p>
  </details>
</details>
<details>
  <summary>163. <b>标题：Transformers and the representation of biomedical background knowledge</b></summary>
  <p><b>编号</b>：[406]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02432</p>
  <p><b>作者</b>：Oskar Wysocki (1,2),  Zili Zhou (1,2),  Paul O'Regan (2),  Deborah Ferreira (1),  Magdalena Wysocka (2),  Dónal Landers (2),  André Freitas (1,2,3) ((1) Department of Computer Science, The University of Manchester, (2) digital Experimental Cancer Medicine Team, Cancer Biomarker Centre, CRUK Manchester Institute, University of Manchester, (3) Idiap Research Institute)</p>
  <p><b>备注</b>：22 pages, 12 figures, supplementary methods, tables and figures at the end of the manuscript</p>
  <p><b>关键词</b>：publicly available biomedical corpora, indeed encode biological knowledge, biomedical domain based, scale biological knowledge, different transformer baselines</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>BioBERT and BioMegatron are Transformers models adapted for the biomedical
domain based on publicly available biomedical corpora. As such, they have the
potential to encode large-scale biological knowledge. We investigate the
encoding and representation of biological knowledge in these models, and its
potential utility to support inference in cancer precision medicine - namely,
the interpretation of the clinical significance of genomic alterations. We
compare the performance of different transformer baselines; we use probing to
determine the consistency of encodings for distinct entities; and we use
clustering methods to compare and contrast the internal properties of the
embeddings for genes, variants, drugs and diseases. We show that these models
do indeed encode biological knowledge, although some of this is lost in
fine-tuning for specific tasks. Finally, we analyse how the models behave with
regard to biases and imbalances in the dataset.</p>
  </details>
</details>
<details>
  <summary>164. <b>标题：Verifying Inverse Model Neural Networks</b></summary>
  <p><b>编号</b>：[409]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02429</p>
  <p><b>作者</b>：Chelsea Sidrane,  Sydney Katz,  Anthony Corso,  Mykel J. Kochenderfer</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：consequently trust inverse model neural networks allows, world airplane fuel gauge case study, inverse model neural networks, inverse model neural networks, neural network inverse model</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Inverse problems exist in a wide variety of physical domains from aerospace
engineering to medical imaging. The goal is to infer the underlying state from
a set of observations. When the forward model that produced the observations is
nonlinear and stochastic, solving the inverse problem is very challenging.
Neural networks are an appealing solution for solving inverse problems as they
can be trained from noisy data and once trained are computationally efficient
to run. However, inverse model neural networks do not have guarantees of
correctness built-in, which makes them unreliable for use in safety and
accuracy-critical contexts. In this work we introduce a method for verifying
the correctness of inverse model neural networks. Our approach is to
overapproximate a nonlinear, stochastic forward model with piecewise linear
constraints and encode both the overapproximate forward model and the neural
network inverse model as a mixed-integer program. We demonstrate this
verification procedure on a real-world airplane fuel gauge case study. The
ability to verify and consequently trust inverse model neural networks allows
their use in a wide variety of contexts, from aerospace to medicine.</p>
  </details>
</details>
<details>
  <summary>165. <b>标题：Lightweight Compositional Embeddings for Incremental Streaming  Recommendation</b></summary>
  <p><b>编号</b>：[410]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02427</p>
  <p><b>作者</b>：Mengyue Hang,  Tobias Schnabel,  Longqi Yang,  Jennifer Neville</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：compositional recommendation model -- lightweight compositional embedding, based recommendation models would need, static setting makes little sense, nodes {\ em implicitly },, update model predictions incrementally</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Most work in graph-based recommender systems considers a {\em static} setting
where all information about test nodes (i.e., users and items) is available
upfront at training time. However, this static setting makes little sense for
many real-world applications where data comes in continuously as a stream of
new edges and nodes, and one has to update model predictions incrementally to
reflect the latest state. To fully capitalize on the newly available data in
the stream, recent graph-based recommendation models would need to be
repeatedly retrained, which is infeasible in practice.
In this paper, we study the graph-based streaming recommendation setting and
propose a compositional recommendation model -- Lightweight Compositional
Embedding (LCE) -- that supports incremental updates under low computational
cost. Instead of learning explicit embeddings for the full set of nodes, LCE
learns explicit embeddings for only a subset of nodes and represents the other
nodes {\em implicitly}, through a composition function based on their
interactions in the graph. This provides an effective, yet efficient, means to
leverage streaming graph data when one node type (e.g., items) is more amenable
to static representation. We conduct an extensive empirical study to compare
LCE to a set of competitive baselines on three large-scale user-item
recommendation datasets with interactions under a streaming setting. The
results demonstrate the superior performance of LCE, showing that it achieves
nearly skyline performance with significantly fewer parameters than alternative
graph-based models.</p>
  </details>
</details>
<details>
  <summary>166. <b>标题：The influence of labeling techniques in classifying human manipulation  movement of different speed</b></summary>
  <p><b>编号</b>：[411]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02426</p>
  <p><b>作者</b>：Sadique Adnan Siddiqui,  Lisa Gutzeit,  Frank Kirchner</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：stacking scenario comprising simple arm movements, labeled using two different approaches, labeled using two different approaches, paced data labeled using trajectories, extreme gradient boosting classifier</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this work, we investigate the influence of labeling methods on the
classification of human movements on data recorded using a marker-based motion
capture system. The dataset is labeled using two different approaches, one
based on video data of the movements, the other based on the movement
trajectories recorded using the motion capture system. The dataset is labeled
using two different approaches, one based on video data of the movements, the
other based on the movement trajectories recorded using the motion capture
system. The data was recorded from one participant performing a stacking
scenario comprising simple arm movements at three different speeds (slow,
normal, fast). Machine learning algorithms that include k-Nearest Neighbor,
Random Forest, Extreme Gradient Boosting classifier, Convolutional Neural
networks (CNN), Long Short-Term Memory networks (LSTM), and a combination of
CNN-LSTM networks are compared on their performance in recognition of these arm
movements. The models were trained on actions performed on slow and normal
speed movements segments and generalized on actions consisting of fast-paced
human movement. It was observed that all the models trained on normal-paced
data labeled using trajectories have almost 20% improvement in accuracy on test
data in comparison to the models trained on data labeled using videos of the
performed experiments.</p>
  </details>
</details>
<details>
  <summary>167. <b>标题：Improved Information Theoretic Generalization Bounds for Distributed and  Federated Learning</b></summary>
  <p><b>编号</b>：[412]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02423</p>
  <p><b>作者</b>：L. P. Barnes,  Alex Dytso,  H. V. Poor</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：lipschitz continuous losses, generalization properties inherent, final centralized model, expected generalization error, expected generalization error</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We consider information-theoretic bounds on expected generalization error for
statistical learning problems in a networked setting. In this setting, there
are $K$ nodes, each with its own independent dataset, and the models from each
node have to be aggregated into a final centralized model. We consider both
simple averaging of the models as well as more complicated multi-round
algorithms. We give upper bounds on the expected generalization error for a
variety of problems, such as those with Bregman divergence or Lipschitz
continuous losses, that demonstrate an improved dependence of $1/K$ on the
number of nodes. These "per node" bounds are in terms of the mutual information
between the training dataset and the trained weights at each node, and are
therefore useful in describing the generalization properties inherent to having
communication or privacy constraints at each node.</p>
  </details>
</details>
<details>
  <summary>168. <b>标题：Learning a Discrete Set of Optimal Allocation Rules in Queueing Systems  with Unknown Service Rates</b></summary>
  <p><b>编号</b>：[413]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02419</p>
  <p><b>作者</b>：Saghar Adler,  Mehrdad Moharrami,  Vijay Subramanian</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：certainty equivalent optimal control policies leads, uses maximum likelihood estimation followed, certainty equivalent control switches, proposed policy asymptotically learns, cost per unit time</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We study learning-based admission control for a classical Erlang-B blocking
system with unknown service rate, i.e., an $M/M/k/k$ queueing system. At every
job arrival, a dispatcher decides to assign the job to an available server or
to block it. Every served job yields a fixed reward for the dispatcher, but it
also results in a cost per unit time of service. Our goal is to design a
dispatching policy that maximizes the long-term average reward for the
dispatcher based on observing the arrival times and the state of the system at
each arrival; critically, the dispatcher observes neither the service times nor
departure times.
We develop our learning-based dispatch scheme as a parametric learning
problem a'la self-tuning adaptive control. In our problem, certainty equivalent
control switches between an always admit policy (always explore) and a never
admit policy (immediately terminate learning), which is distinct from the
adaptive control literature. Our learning scheme then uses maximum likelihood
estimation followed by certainty equivalent control but with judicious use of
the always admit policy so that learning doesn't stall. We prove that for all
service rates, the proposed policy asymptotically learns to take the optimal
action. Further, we also present finite-time regret guarantees for our scheme.
The extreme contrast in the certainty equivalent optimal control policies leads
to difficulties in learning that show up in our regret bounds for different
parameter regimes. We explore this aspect in our simulations and also follow-up
sampling related questions for our continuous-time system.</p>
  </details>
</details>
<details>
  <summary>169. <b>标题：Parameter-free Online Linear Optimization with Side Information via  Universal Coin Betting</b></summary>
  <p><b>编号</b>：[417]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02406</p>
  <p><b>作者</b>：J. Jon Ryu,  Alankrita Bhatt,  Young-Han Kim</p>
  <p><b>备注</b>：23 pages, 5 figures, to appear at AISTATS 2022</p>
  <p><b>关键词</b>：free online linear optimization algorithms, incorporating sequential side information, online linear optimization, adapting coin betting algorithms, universal compression techniques</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A class of parameter-free online linear optimization algorithms is proposed
that harnesses the structure of an adversarial sequence by adapting to some
side information. These algorithms combine the reduction technique of Orabona
and P{á}l (2016) for adapting coin betting algorithms for online linear
optimization with universal compression techniques in information theory for
incorporating sequential side information to coin betting. Concrete examples
are studied in which the side information has a tree structure and consists of
quantized values of the previous symbols of the adversarial sequence, including
fixed-order and variable-order Markov cases. By modifying the context-tree
weighting technique of Willems, Shtarkov, and Tjalkens (1995), the proposed
algorithm is further refined to achieve the best performance over all adaptive
algorithms with tree-structured side information of a given maximum order in a
computationally efficient manner.</p>
  </details>
</details>
<details>
  <summary>170. <b>标题：BAM: Bayes with Adaptive Memory</b></summary>
  <p><b>编号</b>：[418]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02405</p>
  <p><b>作者</b>：Josue Nassar,  Jennifer Brennan,  Ben Evans,  Kendall Lowrey</p>
  <p><b>备注</b>：International Conference on Learning Representations (ICLR), 2022</p>
  <p><b>关键词</b>：bam generalizes many popular bayesian update rules, world environments involve revisiting similar states, theorem allows new data, online learning via bayes, wrong parameter value</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Online learning via Bayes' theorem allows new data to be continuously
integrated into an agent's current beliefs. However, a naive application of
Bayesian methods in non-stationary environments leads to slow adaptation and
results in state estimates that may converge confidently to the wrong parameter
value. A common solution when learning in changing environments is to
discard/downweight past data; however, this simple mechanism of "forgetting"
fails to account for the fact that many real-world environments involve
revisiting similar states. We propose a new framework, Bayes with Adaptive
Memory (BAM), that takes advantage of past experience by allowing the agent to
choose which past observations to remember and which to forget. We demonstrate
that BAM generalizes many popular Bayesian update rules for non-stationary
environments. Through a variety of experiments, we demonstrate the ability of
BAM to continuously adapt in an ever-changing world.</p>
  </details>
</details>
<details>
  <summary>171. <b>标题：Self-Adaptive Forecasting for Improved Deep Learning on Non-Stationary  Time-Series</b></summary>
  <p><b>编号</b>：[420]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02403</p>
  <p><b>作者</b>：Sercan O. Arik,  Nathanael C. Yoder,  Tomas Pfister</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：predicting masked inputs backward, model selection procedures suboptimal, method enables efficient adaptation, series datasets often violate, adaptation stage prior</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Real-world time-series datasets often violate the assumptions of standard
supervised learning for forecasting -- their distributions evolve over time,
rendering the conventional training and model selection procedures suboptimal.
In this paper, we propose a novel method, Self-Adaptive Forecasting (SAF), to
modify the training of time-series forecasting models to improve their
performance on forecasting tasks with such non-stationary time-series data. SAF
integrates a self-adaptation stage prior to forecasting based on `backcasting',
i.e. predicting masked inputs backward in time. This is a form of test-time
training that creates a self-supervised learning problem on test samples before
performing the prediction task. In this way, our method enables efficient
adaptation of encoded representations to evolving distributions, leading to
superior generalization. SAF can be integrated with any canonical
encoder-decoder based time-series architecture such as recurrent neural
networks or attention-based architectures. On synthetic and real-world datasets
in domains where time-series data are known to be notoriously non-stationary,
such as healthcare and finance, we demonstrate a significant benefit of SAF in
improving forecasting accuracy.</p>
  </details>
</details>
<details>
  <summary>172. <b>标题：A Temporal-Difference Approach to Policy Gradient Estimation</b></summary>
  <p><b>编号</b>：[423]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02396</p>
  <p><b>作者</b>：Samuele Tosatto,  Andrew Patterson,  Martha White,  A. Rupam Mahmood</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：sutton et al ., 2000, start state without requiring, cumulative discounted state distribution, recursively estimated due, certain realizability conditions</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The policy gradient theorem (Sutton et al., 2000) prescribes the usage of a
cumulative discounted state distribution under the target policy to approximate
the gradient. Most algorithms based on this theorem, in practice, break this
assumption, introducing a distribution shift that can cause the convergence to
poor solutions. In this paper, we propose a new approach of reconstructing the
policy gradient from the start state without requiring a particular sampling
strategy. The policy gradient calculation in this form can be simplified in
terms of a gradient critic, which can be recursively estimated due to a new
Bellman equation of gradients. By using temporal-difference updates of the
gradient critic from an off-policy data stream, we develop the first estimator
that sidesteps the distribution shift issue in a model-free way. We prove that,
under certain realizability conditions, our estimator is unbiased regardless of
the sampling strategy. We empirically show that our technique achieves a
superior bias-variance trade-off and performance in presence of off-policy
samples.</p>
  </details>
</details>
<details>
  <summary>173. <b>标题：JARVix at SemEval-2022 Task 2: It Takes One to Know One? Idiomaticity  Detection using Zero and One Shot Learning</b></summary>
  <p><b>编号</b>：[425]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02394</p>
  <p><b>作者</b>：Ashwin Pathak,  Raj Shah,  Vaibhav Kumar,  Yash Jakhotiya</p>
  <p><b>备注</b>：Best Project Award for Georgia Tech CS 7650. Code available at this https URL</p>
  <p><b>关键词</b>：train multiple large language models, natural language processing tasks, large language models, given sentence contains, vector representations fail</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large Language Models have been successful in a wide variety of Natural
Language Processing tasks by capturing the compositionality of the text
representations. In spite of their great success, these vector representations
fail to capture meaning of idiomatic multi-word expressions (MWEs). In this
paper, we focus on the detection of idiomatic expressions by using binary
classification. We use a dataset consisting of the literal and idiomatic usage
of MWEs in English and Portuguese. Thereafter, we perform the classification in
two different settings: zero shot and one shot, to determine if a given
sentence contains an idiom or not. N shot classification for this task is
defined by N number of common idioms between the training and testing sets. In
this paper, we train multiple Large Language Models in both the settings and
achieve an F1 score (macro) of 0.73 for the zero shot setting and an F1 score
(macro) of 0.85 for the one shot setting. An implementation of our work can be
found at
this https URL .</p>
  </details>
</details>
<details>
  <summary>174. <b>标题：Deep Dynamic Effective Connectivity Estimation from Multivariate Time  Series</b></summary>
  <p><b>编号</b>：[426]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02393</p>
  <p><b>作者</b>：Usman Mahmood,  Zening Fu,  Vince Calhoun,  Sergey Plis</p>
  <p><b>备注</b>：In review at IJCNN 2022</p>
  <p><b>关键词</b>：developed dynamic effective connectivity estimation via neural network training, system whose applications go beyond classification, functional neuroimaging data align well, many highly dynamic systems, multivariate time series data</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recently, methods that represent data as a graph, such as graph neural
networks (GNNs) have been successfully used to learn data representations and
structures to solve classification and link prediction problems. The
applications of such methods are vast and diverse, but most of the current work
relies on the assumption of a static graph. This assumption does not hold for
many highly dynamic systems, where the underlying connectivity structure is
non-stationary and is mostly unobserved. Using a static model in these
situations may result in sub-optimal performance. In contrast, modeling changes
in graph structure with time can provide information about the system whose
applications go beyond classification. Most work of this type does not learn
effective connectivity and focuses on cross-correlation between nodes to
generate undirected graphs. An undirected graph is unable to capture direction
of an interaction which is vital in many fields, including neuroscience. To
bridge this gap, we developed dynamic effective connectivity estimation via
neural network training (DECENNT), a novel model to learn an interpretable
directed and dynamic graph induced by the downstream classification/prediction
task. DECENNT outperforms state-of-the-art (SOTA) methods on five different
tasks and infers interpretable task-specific dynamic graphs. The dynamic graphs
inferred from functional neuroimaging data align well with the existing
literature and provide additional information. Additionally, the temporal
attention module of DECENNT identifies time-intervals crucial for predictive
downstream task from multivariate time series data.</p>
  </details>
</details>
<details>
  <summary>175. <b>标题：The impact of feature importance methods on the interpretation of defect  classifiers</b></summary>
  <p><b>编号</b>：[429]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02389</p>
  <p><b>作者</b>：Gopi Krishnan Rajbahadur,  Shaowei Wang,  Yasutaka Kamei,  Ahmed E. Hassan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：commonly used cs methods yield vastly different feature importance ranks, simple methods like cfs improves agreement, compute different feature importance ranks even, advanced feature interaction removal methods, strong agreement among different methods</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Classifier specific (CS) and classifier agnostic (CA) feature importance
methods are widely used (often interchangeably) by prior studies to derive
feature importance ranks from a defect classifier. However, different feature
importance methods are likely to compute different feature importance ranks
even for the same dataset and classifier. Hence such interchangeable use of
feature importance methods can lead to conclusion instabilities unless there is
a strong agreement among different methods. Therefore, in this paper, we
evaluate the agreement between the feature importance ranks associated with the
studied classifiers through a case study of 18 software projects and six
commonly used classifiers. We find that: 1) The computed feature importance
ranks by CA and CS methods do not always strongly agree with each other. 2) The
computed feature importance ranks by the studied CA methods exhibit a strong
agreement including the features reported at top-1 and top-3 ranks for a given
dataset and classifier, while even the commonly used CS methods yield vastly
different feature importance ranks. Such findings raise concerns about the
stability of conclusions across replicated studies. We further observe that the
commonly used defect datasets are rife with feature interactions and these
feature interactions impact the computed feature importance ranks of the CS
methods (not the CA methods). We demonstrate that removing these feature
interactions, even with simple methods like CFS improves agreement between the
computed feature importance ranks of CA and CS methods. In light of our
findings, we provide guidelines for stakeholders and practitioners when
performing model interpretation and directions for future research, e.g.,
future research is needed to investigate the impact of advanced feature
interaction removal methods on computed feature importance ranks of different
CS methods.</p>
  </details>
</details>
<details>
  <summary>176. <b>标题：Marius++: Large-Scale Training of Graph Neural Networks on a Single  Machine</b></summary>
  <p><b>编号</b>：[433]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02365</p>
  <p><b>作者</b>：Roger Waleffe,  Jason Mohoney,  Theodoros Rekatsinas,  Shivaram Venkataraman</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：deep graph library using seven benchmark, based training allows marius ++ deployments, based training exhibit accuracy similar, single machine outperforms resource, art models aggregate information</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Graph Neural Networks (GNNs) have emerged as a powerful model for ML over
graph-structured data. Yet, scalability remains a major challenge for using
GNNs over billion-edge inputs. The creation of mini-batches used for training
incurs computational and data movement costs that grow exponentially with the
number of GNN layers as state-of-the-art models aggregate information from the
multi-hop neighborhood of each input node. In this paper, we focus on scalable
training of GNNs with emphasis on resource efficiency. We show that out-of-core
pipelined mini-batch training in a single machine outperforms resource-hungry
multi-GPU solutions. We introduce Marius++, a system for training GNNs over
billion-scale graphs. Marius++ provides disk-optimized training for GNNs and
introduces a series of data organization and algorithmic contributions that 1)
minimize the memory-footprint and end-to-end time required for training and 2)
ensure that models learned with disk-based training exhibit accuracy similar to
those fully trained in mixed CPU/GPU settings. We evaluate Marius++ against
PyTorch Geometric and Deep Graph Library using seven benchmark (model, data
set) settings and find that Marius++ with one GPU can achieve the same level of
model accuracy up to 8$\times$ faster than these systems when they are using up
to eight GPUs. For these experiments, disk-based training allows Marius++
deployments to be up to 64$\times$ cheaper in monetary cost than those of the
competing systems.</p>
  </details>
</details>
<details>
  <summary>177. <b>标题：A Discourse on MetODS: Meta-Optimized Dynamical Synapses for  Meta-Reinforcement Learning</b></summary>
  <p><b>编号</b>：[434]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02363</p>
  <p><b>作者</b>：Mathieu Chalvidal,  Thomas Serre,  Rufin VanRullen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：computational mechanisms support flexible behavioral adaptation, robust reinforcement learning programs emerge spontaneously, leverages fast synaptic dynamics influenced, parameters governing metods synaptic processes, model learning powerful control rules</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent meta-reinforcement learning work has emphasized the importance of
mnemonic control for agents to quickly assimilate relevant experience in new
contexts and suitably adapt their policy. However, what computational
mechanisms support flexible behavioral adaptation from past experience remains
an open question. Inspired by neuroscience, we propose MetODS (for
Meta-Optimized Dynamical Synapses), a broadly applicable model of
meta-reinforcement learning which leverages fast synaptic dynamics influenced
by action-reward feedback. We develop a theoretical interpretation of MetODS as
a model learning powerful control rules in the policy space and demonstrate
empirically that robust reinforcement learning programs emerge spontaneously
from them. We further propose a formalism which efficiently optimizes the
meta-parameters governing MetODS synaptic processes. In multiple experiments
and domains, MetODS outperforms or compares favorably with previous
meta-reinforcement learning approaches. Our agents can perform one-shot
learning, approaches optimal exploration/exploitation strategies, generalize
navigation principles to unseen environments and demonstrate a strong ability
to learn adaptive motor policies.</p>
  </details>
</details>
<details>
  <summary>178. <b>标题：A Fast Network Exploration Strategy to Profile Low Energy Consumption  for Keyword Spotting</b></summary>
  <p><b>编号</b>：[435]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02361</p>
  <p><b>作者</b>：Arnab Neelim Mazumder,  Tinoosh Mohsenin</p>
  <p><b>备注</b>：accepted in tinyML Research Symposium 2022</p>
  <p><b>关键词</b>：xilinx ac 701 platform, based network exploration technique, oriented user interaction targeted, quantization ($ q $), efficient network configuration promptly</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Keyword Spotting nowadays is an integral part of speech-oriented user
interaction targeted for smart devices. To this extent, neural networks are
extensively used for their flexibility and high accuracy. However, coming up
with a suitable configuration for both accuracy requirements and hardware
deployment is a challenge. We propose a regression-based network exploration
technique that considers the scaling of the network filters ($s$) and
quantization ($q$) of the network layers, leading to a friendly and
energy-efficient configuration for FPGA hardware implementation. We experiment
with different combinations of $\mathcal{NN}\scriptstyle\langle q,\,s\rangle
\displaystyle$ on the FPGA to profile the energy consumption of the deployed
network so that the user can choose the most energy-efficient network
configuration promptly. Our accelerator design is deployed on the Xilinx AC 701
platform and has at least 2.1$\times$ and 4$\times$ improvements on energy and
energy efficiency results, respectively, compared to recent hardware
implementations for keyword spotting.</p>
  </details>
</details>
<details>
  <summary>179. <b>标题：A note on the complex and bicomplex valued neural networks</b></summary>
  <p><b>编号</b>：[439]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02354</p>
  <p><b>作者</b>：Daniel Alpay,  Kamal Diki,  Mihaela Vajiac</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：complex multivalued neural networks, bicomplex multivalued neural networks, neural networks based, perceptron convergence algorithm, perceptron convergence algorithm</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper we first write a proof of the perceptron convergence algorithm
for the complex multivalued neural networks (CMVNNs). Our primary goal is to
formulate and prove the perceptron convergence algorithm for the bicomplex
multivalued neural networks (BMVNNs) and other important results in the theory
of neural networks based on a bicomplex algebra.</p>
  </details>
</details>
<details>
  <summary>180. <b>标题：Learning Interpretable, High-Performing Policies for Continuous Control  Problems</b></summary>
  <p><b>编号</b>：[440]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02352</p>
  <p><b>作者</b>：Rohan Paleja,  Yaru Niu,  Andrew Silva,  Chace Ritchie,  Sugju Choi,  Matthew Gombolay</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：propose interpretable continuous control trees, baselines across six domains, learning interpretable policy representations, continuous control problems, verifiable control policies</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Gradient-based approaches in reinforcement learning (RL) have achieved
tremendous success in learning policies for continuous control problems. While
the performance of these approaches warrants real-world adoption in domains,
such as in autonomous driving and robotics, these policies lack
interpretability, limiting deployability in safety-critical and
legally-regulated domains. Such domains require interpretable and verifiable
control policies that maintain high performance. We propose Interpretable
Continuous Control Trees (ICCTs), a tree-based model that can be optimized via
modern, gradient-based, RL approaches to produce high-performing, interpretable
policies. The key to our approach is a procedure for allowing direct
optimization in a sparse decision-tree-like representation. We validate ICCTs
against baselines across six domains, showing that ICCTs are capable of
learning interpretable policy representations that parity or outperform
baselines by up to 33$\%$ in autonomous driving scenarios while achieving a
$300$x-$600$x reduction in the number of policy parameters against deep
learning baselines.</p>
  </details>
</details>
<details>
  <summary>181. <b>标题：Selective Network Linearization for Efficient Private Inference</b></summary>
  <p><b>编号</b>：[443]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02340</p>
  <p><b>作者</b>：Minsu Cho,  Ameya Joshi,  Siddharth Garg,  Brandon Reagen,  Chinmay Hegde</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：practical pi demands novel relu, seen limited use due, address many privacy issues, several standard pi benchmarks, selectively linearizes relus</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Private inference (PI) enables inference directly on cryptographically secure
data. While promising to address many privacy issues, it has seen limited use
due to extreme runtimes. Unlike plaintext inference, where latency is dominated
by FLOPs, in PI non-linear functions (namely ReLU) are the bottleneck. Thus,
practical PI demands novel ReLU-aware optimizations. To reduce PI latency we
propose a gradient-based algorithm that selectively linearizes ReLUs while
maintaining prediction accuracy. We evaluate our algorithm on several standard
PI benchmarks. The results demonstrate up to $4.25\%$ more accuracy (iso-ReLU
count at 50K) or $2.2\times$ less latency (iso-accuracy at 70\%) than the
current state of the art and advance the Pareto frontier across the
latency-accuracy space. To complement empirical results, we present a "no free
lunch" theorem that sheds light on how and when network linearization is
possible while maintaining prediction accuracy.</p>
  </details>
</details>
<details>
  <summary>182. <b>标题：Discovering Distribution Shifts using Latent Space Representations</b></summary>
  <p><b>编号</b>：[444]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02339</p>
  <p><b>作者</b>：Leo Betthauser,  Urszula Chajewska,  Maurice Diesendruck,  Rohith Pesala</p>
  <p><b>备注</b>：10 pages, 5 figures, 3 tables, 2 algorithms</p>
  <p><b>关键词</b>：second test detects shifts, first test detects shifts, various shift scenarios, generalize may lead, classifying multiple subsamples</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Rapid progress in representation learning has led to a proliferation of
embedding models, and to associated challenges of model selection and practical
application. It is non-trivial to assess a model's generalizability to new,
candidate datasets and failure to generalize may lead to poor performance on
downstream tasks. Distribution shifts are one cause of reduced
generalizability, and are often difficult to detect in practice. In this paper,
we use the embedding space geometry to propose a non-parametric framework for
detecting distribution shifts, and specify two tests. The first test detects
shifts by establishing a robustness boundary, determined by an intelligible
performance criterion, for comparing reference and candidate datasets. The
second test detects shifts by featurizing and classifying multiple subsamples
of two datasets as in-distribution and out-of-distribution. In evaluation, both
tests detect model-impacting distribution shifts, in various shift scenarios,
for both synthetic and real-world datasets.</p>
  </details>
</details>
<details>
  <summary>183. <b>标题：Towards Training Reproducible Deep Learning Models</b></summary>
  <p><b>编号</b>：[445]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02326</p>
  <p><b>作者</b>：Boyuan Chen,  Mingzhi Wen,  Yong Shi,  Dayi Lin,  Gopi Krishnan Rajbahadur,  Zhen Ming (Jack) Jiang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：successfully reproduce six open source, approach includes three main parts, case study results show, g ., gpu )., g ., dl algorithms</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Reproducibility is an increasing concern in Artificial Intelligence (AI),
particularly in the area of Deep Learning (DL). Being able to reproduce DL
models is crucial for AI-based systems, as it is closely tied to various tasks
like training, testing, debugging, and auditing. However, DL models are
challenging to be reproduced due to issues like randomness in the software
(e.g., DL algorithms) and non-determinism in the hardware (e.g., GPU). There
are various practices to mitigate some of the aforementioned issues. However,
many of them are either too intrusive or can only work for a specific usage
context. In this paper, we propose a systematic approach to training
reproducible DL models. Our approach includes three main parts: (1) a set of
general criteria to thoroughly evaluate the reproducibility of DL models for
two different domains, (2) a unified framework which leverages a
record-and-replay technique to mitigate software-related randomness and a
profile-and-patch technique to control hardware-related non-determinism, and
(3) a reproducibility guideline which explains the rationales and the
mitigation strategies on conducting a reproducible training process for DL
models. Case study results show our approach can successfully reproduce six
open source and one commercial DL models.</p>
  </details>
</details>
<details>
  <summary>184. <b>标题：Investigating the fidelity of explainable artificial intelligence  methods for applications of convolutional neural networks in geoscience</b></summary>
  <p><b>编号</b>：[448]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03407</p>
  <p><b>作者</b>：Antonios Mamalakis,  Elizabeth A. Barnes,  Imme Ebert-Uphoff</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：results highlight several important issues, recently attracted great attention, g ., gradient shattering, extract predictive spatiotemporal patterns, help guide best practices</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Convolutional neural networks (CNNs) have recently attracted great attention
in geoscience due to their ability to capture non-linear system behavior and
extract predictive spatiotemporal patterns. Given their black-box nature
however, and the importance of prediction explainability, methods of
explainable artificial intelligence (XAI) are gaining popularity as a means to
explain the CNN decision-making strategy. Here, we establish an intercomparison
of some of the most popular XAI methods and investigate their fidelity in
explaining CNN decisions for geoscientific applications. Our goal is to raise
awareness of the theoretical limitations of these methods and gain insight into
the relative strengths and weaknesses to help guide best practices. The
considered XAI methods are first applied to an idealized attribution benchmark,
where the ground truth of explanation of the network is known a priori, to help
objectively assess their performance. Secondly, we apply XAI to a
climate-related prediction setting, namely to explain a CNN that is trained to
predict the number of atmospheric rivers in daily snapshots of climate
simulations. Our results highlight several important issues of XAI methods
(e.g., gradient shattering, inability to distinguish the sign of attribution,
ignorance to zero input) that have previously been overlooked in our field and,
if not considered cautiously, may lead to a distorted picture of the CNN
decision-making strategy. We envision that our analysis will motivate further
investigation into XAI fidelity and will help towards a cautious implementation
of XAI in geoscience, which can lead to further exploitation of CNNs and deep
learning for prediction problems.</p>
  </details>
</details>
<details>
  <summary>185. <b>标题：Dependence model assessment and selection with DecoupleNets</b></summary>
  <p><b>编号</b>：[449]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03406</p>
  <p><b>作者</b>：Marius Hofert,  Avinash Prasad,  Mu Zhu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：real world data illustrate, '= 2 $, graphically, '= 2 $., underlying dependence structure, simulation studies based</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Neural networks are suggested for learning a map from $d$-dimensional samples
with any underlying dependence structure to multivariate uniformity in $d'$
dimensions. This map, termed DecoupleNet, is used for dependence model
assessment and selection. If the data-generating dependence model was known,
and if it was among the few analytically tractable ones, one such
transformation for $d'=d$ is Rosenblatt's transform. DecoupleNets only require
an available sample and are applicable to $d'<d$, in particular $d'="2$." this allows for simpler model assessment and selection without loss of information, both numerically and, because graphically. through simulation studies based on data from various copulas, the feasibility validity novel approach is demonstrated. applications to real world illustrate its usefulness selection.< p>
  </d$,></p></details>
</details>
<details>
  <summary>186. <b>标题：Bilevel Optimization with a Lower-level Contraction: Optimal Sample  Complexity without Warm-Start</b></summary>
  <p><b>编号</b>：[450]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03397</p>
  <p><b>作者</b>：Riccardo Grazzi,  Massimiliano Pontil,  Saverio Salzo</p>
  <p><b>备注</b>：30 pages</p>
  <p><b>关键词</b>：}(\ epsilon ^{- 1 })$ samples, $\ epsilon $- stationary point using, (\ epsilon ^{- 2 })$, uses stochastic fixed point iterations, projected inexact gradient descent</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We analyze a general class of bilevel problems, in which the upper-level
problem consists in the minimization of a smooth objective function and the
lower-level problem is to find the fixed point of a smooth contraction map.
This type of problems include instances of meta-learning, hyperparameter
optimization and data poisoning adversarial attacks. Several recent works have
proposed algorithms which warm-start the lower-level problem, i.e. they use the
previous lower-level approximate solution as a staring point for the
lower-level solver. This warm-start procedure allows one to improve the sample
complexity in both the stochastic and deterministic settings, achieving in some
cases the order-wise optimal sample complexity. We show that without
warm-start, it is still possible to achieve order-wise optimal and near-optimal
sample complexity for the stochastic and deterministic settings, respectively.
In particular, we propose a simple method which uses stochastic fixed point
iterations at the lower-level and projected inexact gradient descent at the
upper-level, that reaches an $\epsilon$-stationary point using
$O(\epsilon^{-2})$ and $\tilde{O}(\epsilon^{-1})$ samples for the stochastic
and the deterministic setting, respectively. Compared to methods using
warm-start, ours is better suited for meta-learning and yields a simpler
analysis that does not need to study the coupled interactions between the
upper-level and lower-level iterates.</p>
  </details>
</details>
<details>
  <summary>187. <b>标题：Robust Semantic Communications Against Semantic Noise</b></summary>
  <p><b>编号</b>：[454]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03338</p>
  <p><b>作者</b>：Qiyu Hu,  Guangyi Zhang,  Zhijin Qin,  Yunlong Cai,  Guanding Yu</p>
  <p><b>备注</b>：7 pages, 6 figures</p>
  <p><b>关键词</b>：proposed method significantly improves, robust semantic communication system, end semantic communication systems, simulation results show, exhibited satisfactory performance</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Although the semantic communications have exhibited satisfactory performance
in a large number of tasks, the impact of semantic noise and the robustness of
the systems have not been well investigated. Semantic noise is a particular
kind of noise in semantic communication systems, which refers to the misleading
between the intended semantic symbols and received ones. In this paper, we
first propose a framework for the robust end-to-end semantic communication
systems to combat the semantic noise. Particularly, we analyze the causes of
semantic noise and propose a practical method to generate it. To remove the
effect of semantic noise, adversarial training is proposed to incorporate the
samples with semantic noise in the training dataset. Then, the masked
autoencoder is designed as the architecture of a robust semantic communication
system, where a portion of the input is masked. To further improve the
robustness of semantic communication systems, we design a discrete codebook
shared by the transmitter and the receiver for encoded feature representation.
Thus, the transmitter simply needs to transmit the indices of these features in
the codebook. Simulation results show that our proposed method significantly
improves the robustness of semantic communication systems against semantic
noise with significant reduction on the transmission overhead.</p>
  </details>
</details>
<details>
  <summary>188. <b>标题：Optimal Ratio for Data Splitting</b></summary>
  <p><b>编号</b>：[455]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03326</p>
  <p><b>作者</b>：V. Roshan Joseph</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：p }: 1 $,, optimal splitting ratio, machine learning model, linear regression model, much data</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>It is common to split a dataset into training and testing sets before fitting
a statistical or machine learning model. However, there is no clear guidance on
how much data should be used for training and testing. In this article we show
that the optimal splitting ratio is $\sqrt{p}:1$, where $p$ is the number of
parameters in a linear regression model that explains the data well.</p>
  </details>
</details>
<details>
  <summary>189. <b>标题：Grassmann Stein Variational Gradient Descent</b></summary>
  <p><b>编号</b>：[457]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03297</p>
  <p><b>作者</b>：Xing Liu,  Harrison Zhu,  Jean-François Ton,  George Wynne,  Andrew Duncan</p>
  <p><b>备注</b>：20 pages, 13 figures, to appear in AISTATS 2022</p>
  <p><b>关键词</b>：permits projections onto arbitrary dimensional subspaces, propose grassmann stein variational gradient descent, stein variational gradient descent, markov chain monte carlo, deterministic particle inference algorithm</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Stein variational gradient descent (SVGD) is a deterministic particle
inference algorithm that provides an efficient alternative to Markov chain
Monte Carlo. However, SVGD has been found to suffer from variance
underestimation when the dimensionality of the target distribution is high.
Recent developments have advocated projecting both the score function and the
data onto real lines to sidestep this issue, although this can severely
overestimate the epistemic (model) uncertainty. In this work, we propose
Grassmann Stein variational gradient descent (GSVGD) as an alternative
approach, which permits projections onto arbitrary dimensional subspaces.
Compared with other variants of SVGD that rely on dimensionality reduction,
GSVGD updates the projectors simultaneously for the score function and the
data, and the optimal projectors are determined through a coupled
Grassmann-valued diffusion process which explores favourable subspaces. Both
our theoretical and experimental results suggest that GSVGD enjoys efficient
state-space exploration in high-dimensional problems that have an intrinsic
low-dimensional structure.</p>
  </details>
</details>
<details>
  <summary>190. <b>标题：Human Activity Recognition Using Tools of Convolutional Neural Networks:  A State of the Art Review, Data Sets, Challenges and Future Prospects</b></summary>
  <p><b>编号</b>：[458]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03274</p>
  <p><b>作者</b>：Md. Milon Islam,  Sheikh Nooruddin,  Fakhri Karray,  Ghulam Muhammad</p>
  <p><b>备注</b>：32 pages, 4 figures, 4 Tables</p>
  <p><b>关键词</b>：input devices like multimodal sensing devices, namely convolutional neural networks, available public data sources, summarize recent works based, deep neural networks architecture</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Human Activity Recognition (HAR) plays a significant role in the everyday
life of people because of its ability to learn extensive high-level information
about human activity from wearable or stationary devices. A substantial amount
of research has been conducted on HAR and numerous approaches based on deep
learning and machine learning have been exploited by the research community to
classify human activities. The main goal of this review is to summarize recent
works based on a wide range of deep neural networks architecture, namely
convolutional neural networks (CNNs) for human activity recognition. The
reviewed systems are clustered into four categories depending on the use of
input devices like multimodal sensing devices, smartphones, radar, and vision
devices. This review describes the performances, strengths, weaknesses, and the
used hyperparameters of CNN architectures for each reviewed system with an
overview of available public data sources. In addition, a discussion with the
current challenges to CNN-based HAR systems is presented. Finally, this review
is concluded with some potential future directions that would be of great
assistance for the researchers who would like to contribute to this field.</p>
  </details>
</details>
<details>
  <summary>191. <b>标题：Spectro Temporal EEG Biomarkers For Binary Emotion Classification</b></summary>
  <p><b>编号</b>：[460]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03271</p>
  <p><b>作者</b>：Upasana Tiwari,  Rupayan Chakraborty,  Sunil Kumar Kopparapu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：standard features like discrete wavelet transformation, extensive experiments using state, extract two novel features, reliable physiological signal, marginal hilbert spectrum</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Electroencephalogram (EEG) is one of the most reliable physiological signal
for emotion detection. Being non-stationary in nature, EEGs are better analysed
by spectro temporal representations. Standard features like Discrete Wavelet
Transformation (DWT) can represent temporal changes in spectral dynamics of an
EEG, but is insufficient to extract information other way around, i.e. spectral
changes in temporal dynamics. On the other hand, Empirical mode decomposition
(EMD) based features can be useful to bridge the above mentioned gap. Towards
this direction, we extract two novel features on top of EMD, namely, (a)
marginal hilbert spectrum (MHS) and (b) Holo-Hilbert spectral analysis (HHSA)
based on EMD, to better represent emotions in 2D arousal-valence (A-V) space.
The usefulness of these features for EEG emotion classification is investigated
through extensive experiments using state-of-the-art classifiers. In addition,
experiments conducted on DEAP dataset for binary emotion classification in both
A-V space, reveal the efficacy of the proposed features over the standard set
of temporal and spectral features.</p>
  </details>
</details>
<details>
  <summary>192. <b>标题：Team Cogitat at NeurIPS 2021: Benchmarks for EEG Transfer Learning  Competition</b></summary>
  <p><b>编号</b>：[462]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03267</p>
  <p><b>作者</b>：Stylianos Bakas,  Siegfried Ludwig,  Konstantinos Barmpas,  Mehdi Bahri,  Yannis Panagakis,  Nikolaos Laskaris,  Dimitrios A. Adamos,  Stefanos Zafeiriou</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：older age groups without personalized calibration data, explicitly align feature distributions, source motor imagery datasets, shift across different datasets, personalized calibration data</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Building subject-independent deep learning models for EEG decoding faces the
challenge of strong covariate-shift across different datasets, subjects and
recording sessions. Our approach to address this difficulty is to explicitly
align feature distributions at various layers of the deep learning model, using
both simple statistical techniques as well as trainable methods with more
representational capacity. This follows in a similar vein as covariance-based
alignment methods, often used in a Riemannian manifold context. The methodology
proposed herein won first place in the 2021 Benchmarks in EEG Transfer Learning
(BEETL) competition, hosted at the NeurIPS conference. The first task of the
competition consisted of sleep stage classification, which required the
transfer of models trained on younger subjects to perform inference on multiple
subjects of older age groups without personalized calibration data, requiring
subject-independent models. The second task required to transfer models trained
on the subjects of one or more source motor imagery datasets to perform
inference on two target datasets, providing a small set of personalized
calibration data for multiple test subjects.</p>
  </details>
</details>
<details>
  <summary>193. <b>标题：Short-term Multi-horizon Residential Electric Load Forecasting using  Deep Learning and Signal Decomposition Methods</b></summary>
  <p><b>编号</b>：[463]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03264</p>
  <p><b>作者</b>：Mohamed Aymane Ahajjam,  Daniel Bonilla Licea,  Mounir Ghogho,  Abdellatif Kobbane</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：deep learning technique providing better forecasting performance, five distinct deep learning networks, level wavelet decomposition network model, garnered comparatively less attention, intrinsic mode functions using</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>With the booming growth of advanced digital technologies, it has become
possible for users as well as distributors of energy to obtain detailed and
timely information about the electricity consumption of households. These
technologies can also be used to forecast the household's electricity
consumption (a.k.a. the load). In this paper, we investigate the use of
Variational Mode Decomposition and deep learning techniques to improve the
accuracy of the load forecasting problem. Although this problem has been
studied in the literature, selecting an appropriate decomposition level and a
deep learning technique providing better forecasting performance have garnered
comparatively less attention. This study bridges this gap by studying the
effect of six decomposition levels and five distinct deep learning networks.
The raw load profiles are first decomposed into intrinsic mode functions using
the Variational Mode Decomposition in order to mitigate their non-stationary
aspect. Then, day, hour, and past electricity consumption data are fed as a
three-dimensional input sequence to a four-level Wavelet Decomposition Network
model. Finally, the forecast sequences related to the different intrinsic mode
functions are combined to form the aggregate forecast sequence. The proposed
method was assessed using load profiles of five Moroccan households from the
Moroccan buildings' electricity consumption dataset (MORED) and was benchmarked
against state-of-the-art time-series models and a baseline persistence model.</p>
  </details>
</details>
<details>
  <summary>194. <b>标题：A Variational Edge Partition Model for Supervised Graph Representation  Learning</b></summary>
  <p><b>编号</b>：[465]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03233</p>
  <p><b>作者</b>：Yilin He,  Chaojie Wang,  Hao Zhang,  Bo Chen,  Mingyuan Zhou</p>
  <p><b>备注</b>：14 pages, 3 figures, 13 pages of appendix</p>
  <p><b>关键词</b>：gnn based inference network, variational inference framework, gnn based predictor, supervised feature extraction, learning discriminative representations</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Graph neural networks (GNNs), which propagate the node features through the
edges and learn how to transform the aggregated features under label
supervision, have achieved great success in supervised feature extraction for
both node-level and graph-level classification tasks. However, GNNs typically
treat the graph structure as given and ignore how the edges are formed. This
paper introduces a graph generative process to model how the observed edges are
generated by aggregating the node interactions over a set of overlapping node
communities, each of which contributes to the edges via a logical OR mechanism.
Based on this generative model, we partition each edge into the summation of
multiple community-specific weighted edges and use them to define
community-specific GNNs. A variational inference framework is proposed to
jointly learn a GNN based inference network that partitions the edges into
different communities, these community-specific GNNs, and a GNN based predictor
that combines community-specific GNNs for the end classification task.
Extensive evaluations on real-world graph datasets have verified the
effectiveness of the proposed method in learning discriminative representations
for both node-level and graph-level classification tasks.</p>
  </details>
</details>
<details>
  <summary>195. <b>标题：SODA: Self-organizing data augmentation in deep neural networks --  Application to biomedical image segmentation tasks</b></summary>
  <p><b>编号</b>：[466]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03223</p>
  <p><b>作者</b>：Arnaud Deleruyelle,  John Klein,  Cristian Versari</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：newly created samples per epoch, paper leverages online learning, greener machine learning practices, exploits gradient based signals, usually uniformly distributed</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In practice, data augmentation is assigned a predefined budget in terms of
newly created samples per epoch. When using several types of data augmentation,
the budget is usually uniformly distributed over the set of augmentations but
one can wonder if this budget should not be allocated to each type in a more
efficient way. This paper leverages online learning to allocate on the fly this
budget as part of neural network training. This meta-algorithm can be run at
almost no extra cost as it exploits gradient based signals to determine which
type of data augmentation should be preferred. Experiments suggest that this
strategy can save computation time and thus goes in the way of greener machine
learning practices.</p>
  </details>
</details>
<details>
  <summary>196. <b>标题：SLIDE: a surrogate fairness constraint to ensure fairness consistency</b></summary>
  <p><b>编号</b>：[470]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03165</p>
  <p><b>作者</b>：Kunwoong Kim,  Ilsang Ohn,  Sara Kim,  Yongdai Kim</p>
  <p><b>备注</b>：41 pages including appendix</p>
  <p><b>关键词</b>：new surrogate fairness constraint called slide, existing surrogate fairness constraints, surrogate fairness constraint, slide works well, given fairness constraint</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As they have a vital effect on social decision makings, AI algorithms should
be not only accurate and but also fair. Among various algorithms for fairness
AI, learning a prediction model by minimizing the empirical risk (e.g.,
cross-entropy) subject to a given fairness constraint has received much
attention. To avoid computational difficulty, however, a given fairness
constraint is replaced by a surrogate fairness constraint as the 0-1 loss is
replaced by a convex surrogate loss for classification problems. In this paper,
we investigate the validity of existing surrogate fairness constraints and
propose a new surrogate fairness constraint called SLIDE, which is
computationally feasible and asymptotically valid in the sense that the learned
model satisfies the fairness constraint asymptotically and achieves a fast
convergence rate. Numerical experiments confirm that the SLIDE works well for
various benchmark datasets.</p>
  </details>
</details>
<details>
  <summary>197. <b>标题：Dual-CLVSA: a Novel Deep Learning Approach to Predict Financial Markets  with Sentiment Measurements</b></summary>
  <p><b>编号</b>：[472]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03158</p>
  <p><b>作者</b>：Jia Wang,  Hongwei Zhu,  Jiancheng Shen,  Yu Cao,  Benyuan Liu</p>
  <p><b>备注</b>：8 pages, 2021 20th IEEE International Conference on Machine Learning and Applications (ICMLA). IEEE, 2021</p>
  <p><b>关键词</b>：hybrid convolutional lstm based variational sequence, spdr sp 500 trust etf, also contain extra profitable features, novel deep learning approach, corresponding social sentiment measurements</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>It is a challenging task to predict financial markets. The complexity of this
task is mainly due to the interaction between financial markets and market
participants, who are not able to keep rational all the time, and often
affected by emotions such as fear and ecstasy. Based on the state-of-the-art
approach particularly for financial market predictions, a hybrid convolutional
LSTM Based variational sequence-to-sequence model with attention (CLVSA), we
propose a novel deep learning approach, named dual-CLVSA, to predict financial
market movement with both trading data and the corresponding social sentiment
measurements, each through a separate sequence-to-sequence channel. We evaluate
the performance of our approach with backtesting on historical trading data of
SPDR SP 500 Trust ETF over eight years. The experiment results show that
dual-CLVSA can effectively fuse the two types of data, and verify that
sentiment measurements are not only informative for financial market
predictions, but they also contain extra profitable features to boost the
performance of our predicting system.</p>
  </details>
</details>
<details>
  <summary>198. <b>标题：Comparative Study of Machine Learning Models for Stock Price Prediction</b></summary>
  <p><b>编号</b>：[473]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03156</p>
  <p><b>作者</b>：Ogulcan E. Orsel,  Sasha S. Yamada</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：complex lstm algorithms significantly outperform, handling time series data, apply machine learning techniques, simple linear kalman filter, linear kalman filter</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this work, we apply machine learning techniques to historical stock prices
to forecast future prices. To achieve this, we use recursive approaches that
are appropriate for handling time series data. In particular, we apply a linear
Kalman filter and different varieties of long short-term memory (LSTM)
architectures to historical stock prices over a 10-year range (1/1/2011 -
1/1/2021). We quantify the results of these models by computing the error of
the predicted values versus the historical values of each stock. We find that
of the algorithms we investigated, a simple linear Kalman filter can predict
the next-day value of stocks with low-volatility (e.g., Microsoft) surprisingly
well. However, in the case of high-volatility stocks (e.g., Tesla) the more
complex LSTM algorithms significantly outperform the Kalman filter. Our results
show that we can classify different types of stocks and then train an LSTM for
each stock type. This method could be used to automate portfolio generation for
a target return rate.</p>
  </details>
</details>
<details>
  <summary>199. <b>标题：Neural Network based Inter bi-prediction Blending</b></summary>
  <p><b>编号</b>：[474]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03149</p>
  <p><b>作者</b>：Franck Galpin,  Philippe Bordes,  Thierry Dumas,  Pavel Nikitin,  Fabrice Le Leannec</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：already decoded reference pictures stands, recently standardized vvc codec, averaging two different motion, final temporal prediction accuracy, conventional video coding solutions</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper presents a learning-based method to improve bi-prediction in video
coding. In conventional video coding solutions, the motion compensation of
blocks from already decoded reference pictures stands out as the principal tool
used to predict the current frame. Especially, the bi-prediction, in which a
block is obtained by averaging two different motion-compensated prediction
blocks, significantly improves the final temporal prediction accuracy. In this
context, we introduce a simple neural network that further improves the
blending operation. A complexity balance, both in terms of network size and
encoder mode selection, is carried out. Extensive tests on top of the recently
standardized VVC codec are performed and show a BD-rate improvement of -1.4% in
random access configuration for a network size of fewer than 10k parameters. We
also propose a simple CPU-based implementation and direct network quantization
to assess the complexity/gains tradeoff in a conventional codec framework.</p>
  </details>
</details>
<details>
  <summary>200. <b>标题：NUQ: Nonparametric Uncertainty Quantification for Deterministic Neural  Networks</b></summary>
  <p><b>编号</b>：[476]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03101</p>
  <p><b>作者</b>：Nikita Kotelevskii,  Aleksandr Artemenkov,  Kirill Fedyanin,  Fedor Noskov,  Alexander Fishkov,  Aleksandr Petiushko,  Maxim Panov</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：resulting method works directly, world image datasets, machine learning models, disentangle explicitly aleatoric, conditional label distribution</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper proposes a fast and scalable method for uncertainty quantification
of machine learning models' predictions. First, we show the principled way to
measure the uncertainty of predictions for a classifier based on
Nadaraya-Watson's nonparametric estimate of the conditional label distribution.
Importantly, the approach allows to disentangle explicitly aleatoric and
epistemic uncertainties. The resulting method works directly in the feature
space. However, one can apply it to any neural network by considering an
embedding of the data induced by the network. We demonstrate the strong
performance of the method in uncertainty estimation tasks on a variety of
real-world image datasets, such as MNIST, SVHN, CIFAR-100 and several versions
of ImageNet.</p>
  </details>
</details>
<details>
  <summary>201. <b>标题：Structure-Aware Transformer for Graph Representation Learning</b></summary>
  <p><b>编号</b>：[478]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03036</p>
  <p><b>作者</b>：Dexiong Chen,  Leslie O'Bray,  Karsten Borgwardt</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：flexible graph transformers built upon, graph structure via positional encoding, five graph prediction benchmarks, strict structural inductive biases, necessarily capture structural similarity</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The Transformer architecture has gained growing attention in graph
representation learning recently, as it naturally overcomes several limitations
of graph neural networks (GNNs) by avoiding their strict structural inductive
biases and instead only encoding the graph structure via positional encoding.
Here, we show that the node representations generated by the Transformer with
positional encoding do not necessarily capture structural similarity between
them. To address this issue, we propose the Structure-Aware Transformer, a
class of simple and flexible graph transformers built upon a new self-attention
mechanism. This new self-attention incorporates structural information into the
original self-attention by extracting a subgraph representation rooted at each
node before computing the attention. We propose several methods for
automatically generating the subgraph representation and show theoretically
that the resulting representations are at least as expressive as the subgraph
representations. Empirically, our method achieves state-of-the-art performance
on five graph prediction benchmarks. Our structure-aware framework can leverage
any existing GNN to extract the subgraph representation, and we show that it
systematically improves performance relative to the base GNN model,
successfully combining the advantages of GNNs and transformers.</p>
  </details>
</details>
<details>
  <summary>202. <b>标题：Algorithms that get old : the case of generative algorithms</b></summary>
  <p><b>编号</b>：[481]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03008</p>
  <p><b>作者</b>：Gabriel Turinici</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：entire target probability measure, probability measure described, two following requirements, sobolev statistical distances, generative ia networks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Generative IA networks, like the Variational Auto-Encoders (VAE), and
Generative Adversarial Networks (GANs) produce new objects each time when asked
to do so. However, this behavior is unlike that of human artists that change
their style as times go by and seldom return to the initial point. We
investigate a situation where VAEs are requested to sample from a probability
measure described by some empirical set. Based on recent works on Radon-Sobolev
statistical distances, we propose a numerical paradigm, to be used in
conjunction with a generative algorithm, that satisfies the two following
requirements: the objects created do not repeat and evolve to fill the entire
target probability measure.</p>
  </details>
</details>
<details>
  <summary>203. <b>标题：Deep Residual Shrinkage Networks for EMG-based Gesture Identification</b></summary>
  <p><b>编号</b>：[483]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02984</p>
  <p><b>作者</b>：Yueying Ma,  Chengbo Wang,  Chengbo Wang,  Zimo Li</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：newly developed deep learning method, drsn excel traditional neural networks, deep residual shrinkage network, accuracy emg based gesture identification, perform gesture identification</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This work introduces a method for high-accuracy EMG based gesture
identification. A newly developed deep learning method, namely, deep residual
shrinkage network is applied to perform gesture identification. Based on the
feature of EMG signal resulting from gestures, optimizations are made to
improve the identification accuracy. Finally, three different algorithms are
applied to compare the accuracy of EMG signal recognition with that of DRSN.
The result shows that DRSN excel traditional neural networks in terms of EMG
recognition accuracy. This paper provides a reliable way to classify EMG
signals, as well as exploring possible applications of DRSN.</p>
  </details>
</details>
<details>
  <summary>204. <b>标题：Comprehensive survey of computational learning methods for analysis of  gene expression data in genomics</b></summary>
  <p><b>编号</b>：[484]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02958</p>
  <p><b>作者</b>：Nikita Bhandari,  Rahee Walambe,  Ketan Kotech,  Satyajeet Khare</p>
  <p><b>备注</b>：51 pages, 9 figures, 5 tables</p>
  <p><b>关键词</b>：sample observations requires sophisticated computational approaches, computational analysis methods including machine learning, rna sequencing produce enormous amounts, analysis methods including class comparison, throughput gene expression analysis methods</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Computational analysis methods including machine learning have a significant
impact in the fields of genomics and medicine. High-throughput gene expression
analysis methods such as microarray technology and RNA sequencing produce
enormous amounts of data. Traditionally, statistical methods are used for
comparative analysis of the gene expression data. However, more complex
analysis for classification and discovery of feature genes or sample
observations requires sophisticated computational approaches. In this review,
we compile various statistical and computational tools used in analysis of
expression microarray data. Even though, the methods are discussed in the
context of expression microarray data, they can also be applied for the
analysis of RNA sequencing or quantitative proteomics datasets. We specifically
discuss methods for missing value (gene expression) imputation, feature gene
scaling, selection and extraction of features for dimensionality reduction, and
learning and analysis of expression data. We discuss the types of missing
values and the methods and approaches usually employed in their imputation. We
also discuss methods of data transformation and feature scaling viz.
normalization and standardization. Various approaches used in feature selection
and extraction are also reviewed. Lastly, learning and analysis methods
including class comparison, class prediction, and class discovery along with
their evaluation parameters are described in detail. We have described the
process of generation of a microarray gene expression data along with
advantages and limitations of the above-mentioned techniques. We believe that
this detailed review will help the users to select appropriate methods based on
the type of data and the expected outcome.</p>
  </details>
</details>
<details>
  <summary>205. <b>标题：SUD: Supervision by Denoising for Medical Image Segmentation</b></summary>
  <p><b>编号</b>：[485]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02952</p>
  <p><b>作者</b>：Sean I. Young,  Adrian V. Dalca,  Enzo Ferrante,  Polina Golland,  Bruce Fischl,  Juan Eugenio Iglesias</p>
  <p><b>备注</b>：Author's manuscript for IEEE Trans. Pattern Anal. Mach. Intell</p>
  <p><b>关键词</b>：labeling even across domain experts, supervise segmentation models using, semantic segmentation typically requires, segmentation often necessitate hand, sud unifies temporal ensembling</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Training a fully convolutional network for semantic segmentation typically
requires a large, labeled dataset with little label noise if good
generalization is to be guaranteed. For many segmentation problems, however,
data with pixel- or voxel-level labeling accuracy are scarce due to the cost of
manual labeling. This problem is exacerbated in domains where manual annotation
is difficult, resulting in large amounts of variability in the labeling even
across domain experts. Therefore, training segmentation networks to generalize
better by learning from both labeled and unlabeled images (called
semi-supervised learning) is problem of both practical and theoretical
interest. However, traditional semi-supervised learning methods for
segmentation often necessitate hand-crafting a differentiable regularizer
specific to a given segmentation problem, which can be extremely
time-consuming. In this work, we propose "supervision by denoising" (SUD), a
framework that enables us to supervise segmentation models using their denoised
output as targets. SUD unifies temporal ensembling and spatial denoising
techniques under a spatio-temporal denoising framework and alternates denoising
and network weight update in an optimization framework for semi-supervision. We
validate SUD on three tasks-kidney and tumor (3D), and brain (3D) segmentation,
and cortical parcellation (2D)-demonstrating a significant improvement in the
Dice overlap and the Hausdorff distance of segmentations over supervised-only
and temporal ensemble baselines.</p>
  </details>
</details>
<details>
  <summary>206. <b>标题：Learning fair representation with a parametric integral probability  metric</b></summary>
  <p><b>编号</b>：[487]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02943</p>
  <p><b>作者</b>：Dongha Kim,  Kunwoong Kim,  Insung Kong,  Ilsang Ohn,  Yongdai Kim</p>
  <p><b>备注</b>：24 pages, including references and appendix</p>
  <p><b>关键词</b>：generative adversarial network type algorithms, new adversarial training scheme, lfr ), whose goal, done heuristically without justification, adversarial training scheme</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As they have a vital effect on social decision-making, AI algorithms should
be not only accurate but also fair. Among various algorithms for fairness AI,
learning fair representation (LFR), whose goal is to find a fair representation
with respect to sensitive variables such as gender and race, has received much
attention. For LFR, the adversarial training scheme is popularly employed as is
done in the generative adversarial network type algorithms. The choice of a
discriminator, however, is done heuristically without justification. In this
paper, we propose a new adversarial training scheme for LFR, where the integral
probability metric (IPM) with a specific parametric family of discriminators is
used. The most notable result of the proposed LFR algorithm is its theoretical
guarantee about the fairness of the final prediction model, which has not been
considered yet. That is, we derive theoretical relations between the fairness
of representation and the fairness of the prediction model built on the top of
the representation (i.e., using the representation as the input). Moreover, by
numerical experiments, we show that our proposed LFR algorithm is
computationally lighter and more stable, and the final prediction model is
competitive or superior to other LFR algorithms using more complex
discriminators.</p>
  </details>
</details>
<details>
  <summary>207. <b>标题：On Using Transformers for Speech-Separation</b></summary>
  <p><b>编号</b>：[491]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02884</p>
  <p><b>作者</b>：Cem Subakan,  Mirco Ravanelli,  Samuele Cornell,  Francois Grondin,  Mirko Bronzi</p>
  <p><b>备注</b>：arXiv admin note: text overlap with arXiv:2010.13154</p>
  <p><b>关键词</b>：also investigate incorporating recently proposed efficient self, using efficient self, often outperform recurrent, memory requirements significantly, enabled major improvements</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Transformers have enabled major improvements in deep learning. They often
outperform recurrent and convolutional models in many tasks while taking
advantage of parallel processing. Recently, we have proposed SepFormer, which
uses self-attention and obtains state-of-the art results on WSJ0-2/3 Mix
datasets for speech separation. In this paper, we extend our previous work by
providing results on more datasets including LibriMix, and WHAM!, WHAMR! which
include noisy and noisy-reverberant conditions. Moreover we provide denoising,
and denoising+dereverberation results in the context of speech enhancement,
respectively on WHAM! and WHAMR! datasets. We also investigate incorporating
recently proposed efficient self-attention mechanisms inside the SepFormer
model, and show that by using efficient self-attention mechanisms it is
possible to reduce the memory requirements significantly while performing
better than the popular convtasnet model on WSJ0-2Mix dataset.</p>
  </details>
</details>
<details>
  <summary>208. <b>标题：HARFE: Hard-Ridge Random Feature Expansion</b></summary>
  <p><b>编号</b>：[492]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02877</p>
  <p><b>作者</b>：Esha Saha,  Hayden Schaeffer,  Giang Tran</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：dimensional sparse additive functions called, ridge random feature expansion method, random sparse connectivity pattern, harfe approach obtains lower, given error bound depending</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose a random feature model for approximating high-dimensional sparse
additive functions called the hard-ridge random feature expansion method
(HARFE). This method utilizes a hard-thresholding pursuit-based algorithm
applied to the sparse ridge regression (SRR) problem to approximate the
coefficients with respect to the random feature matrix. The SRR formulation
balances between obtaining sparse models that use fewer terms in their
representation and ridge-based smoothing that tend to be robust to noise and
outliers. In addition, we use a random sparse connectivity pattern in the
random feature matrix to match the additive function assumption. We prove that
the HARFE method is guaranteed to converge with a given error bound depending
on the noise and the parameters of the sparse ridge regression model. Based on
numerical results on synthetic data as well as on real datasets, the HARFE
approach obtains lower (or comparable) error than other state-of-the-art
algorithms.</p>
  </details>
</details>
<details>
  <summary>209. <b>标题：Deep Learning-Aided Spatial Multiplexing with Index Modulation</b></summary>
  <p><b>编号</b>：[494]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02856</p>
  <p><b>作者</b>：Merve Turhan,  Ersin Ozturk,  Hakan Ali Cirpan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：zf detector without increasing computational complexity, significant error performance gains compared, dl )- aided data detection, eventually reveals reduced complexity, using subblockbased detection provided</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, deep learning (DL)-aided data detection of spatial
multiplexing (SMX) multiple-input multiple-output (MIMO) transmission with
index modulation (IM) (Deep-SMX-IM) has been proposed. Deep-SMX-IM has been
constructed by combining a zero-forcing (ZF) detector and DL technique. The
proposed method uses the significant advantages of DL techniques to learn
transmission characteristics of the frequency and spatial domains. Furthermore,
thanks to using subblockbased detection provided by IM, Deep-SMX-IM is a
straightforward method, which eventually reveals reduced complexity. It has
been shown that Deep-SMX-IM has significant error performance gains compared to
ZF detector without increasing computational complexity for different system
configurations.</p>
  </details>
</details>
<details>
  <summary>210. <b>标题：A new similarity measure for covariate shift with applications to  nonparametric regression</b></summary>
  <p><b>编号</b>：[498]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02837</p>
  <p><b>作者</b>：Reese Pathak,  Cong Ma,  Martin J. Wainwright</p>
  <p><b>备注</b>：22 pages, 2 figures, 1 table</p>
  <p><b>关键词</b>：recently proposed notion, hölder continuous functions, study covariate shift, covariate shift, covariate shift</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We study covariate shift in the context of nonparametric regression. We
introduce a new measure of distribution mismatch between the source and target
distributions that is based on the integrated ratio of probabilities of balls
at a given radius. We use the scaling of this measure with respect to the
radius to characterize the minimax rate of estimation over a family of Hölder
continuous functions under covariate shift. In comparison to the recently
proposed notion of transfer exponent, this measure leads to a sharper rate of
convergence and is more fine-grained. We accompany our theory with concrete
instances of covariate shift that illustrate this sharp difference.</p>
  </details>
</details>
<details>
  <summary>211. <b>标题：CheXstray: Real-time Multi-Modal Data Concordance for Drift Detection in  Medical Imaging AI</b></summary>
  <p><b>编号</b>：[499]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02833</p>
  <p><b>作者</b>：Arjun Soin,  Jameson Merkow,  Jin Long,  Joesph Paul Cohen,  Smitha Saligrama,  Stephen Kaiser,  Steven Borg,  Ivan Tarapov,  Matthew P Lungren</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：ground truth performance using unsupervised distributional shifts, model drift without contemporaneous ground truth, rapidly expanding clinical ai applications worldwide, medical imaging ai drift monitoring workflow, continuous medical imaging ai model monitoring</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Rapidly expanding Clinical AI applications worldwide have the potential to
impact to all areas of medical practice. Medical imaging applications
constitute a vast majority of approved clinical AI applications. Though
healthcare systems are eager to adopt AI solutions a fundamental question
remains: \textit{what happens after the AI model goes into production?} We use
the CheXpert and PadChest public datasets to build and test a medical imaging
AI drift monitoring workflow that tracks data and model drift without
contemporaneous ground truth. We simulate drift in multiple experiments to
compare model performance with our novel multi-modal drift metric, which uses
DICOM metadata, image appearance representation from a variational autoencoder
(VAE), and model output probabilities as input. Through experimentation, we
demonstrate a strong proxy for ground truth performance using unsupervised
distributional shifts in relevant metadata, predicted probabilities, and VAE
latent representation. Our key contributions include (1) proof-of-concept for
medical imaging drift detection including use of VAE and domain specific
statistical methods (2) a multi-modal methodology for measuring and unifying
drift metrics (3) new insights into the challenges and solutions for observing
deployed medical imaging AI (4) creation of open-source tools enabling others
to easily run their own workflows or scenarios. This work has important
implications for addressing the translation gap related to continuous medical
imaging AI model monitoring in dynamic healthcare environments.</p>
  </details>
</details>
<details>
  <summary>212. <b>标题：Anticorrelated Noise Injection for Improved Generalization</b></summary>
  <p><b>编号</b>：[501]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02831</p>
  <p><b>作者</b>：Antonio Orvieto,  Hans Kersting,  Frank Proske,  Francis Bach,  Aurelien Lucchi</p>
  <p><b>备注</b>：22 pages, 16 figures</p>
  <p><b>关键词</b>：noise could provide better generalization performance, pgd ") generalizes significantly better, training machine learning models, anticorrelated perturbations (" anti, machine learning models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Injecting artificial noise into gradient descent (GD) is commonly employed to
improve the performance of machine learning models. Usually, uncorrelated noise
is used in such perturbed gradient descent (PGD) methods. It is, however, not
known if this is optimal or whether other types of noise could provide better
generalization performance. In this paper, we zoom in on the problem of
correlating the perturbations of consecutive PGD steps. We consider a variety
of objective functions for which we find that GD with anticorrelated
perturbations ("Anti-PGD") generalizes significantly better than GD and
standard (uncorrelated) PGD. To support these experimental findings, we also
derive a theoretical analysis that demonstrates that Anti-PGD moves to wider
minima, while GD and PGD remain stuck in suboptimal regions or even diverge.
This new connection between anticorrelated noise and generalization opens the
field to novel ways to exploit noise for training machine learning models.</p>
  </details>
</details>
<details>
  <summary>213. <b>标题：Learning Sparse Graphs via Majorization-Minimization for Smooth Node  Signals</b></summary>
  <p><b>编号</b>：[502]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02815</p>
  <p><b>作者</b>：Ghania Fatima,  Aakash Arora,  Prabhu Babu,  Petre Stoica</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：simple closed form solution, observed signals vary smoothly, numerical simulations conducted using, proposed algorithm converges faster, tight surrogate function</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this letter, we propose an algorithm for learning a sparse weighted graph
by estimating its adjacency matrix under the assumption that the observed
signals vary smoothly over the nodes of the graph. The proposed algorithm is
based on the principle of majorization-minimization (MM), wherein we first
obtain a tight surrogate function for the graph learning objective and then
solve the resultant surrogate problem which has a simple closed form solution.
The proposed algorithm does not require tuning of any hyperparameter and it has
the desirable feature of eliminating the inactive variables in the course of
the iterations - which can help speeding up the algorithm. The numerical
simulations conducted using both synthetic and real world (brain-network) data
show that the proposed algorithm converges faster, in terms of the average
number of iterations, than several existing methods in the literature.</p>
  </details>
</details>
<details>
  <summary>214. <b>标题：Wave-Encoded Model-based Deep Learning for Highly Accelerated Imaging  with Joint Reconstruction</b></summary>
  <p><b>编号</b>：[503]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02814</p>
  <p><b>作者</b>：Jaejin Cho,  Borjan Gagoski,  Taehyung Kim,  Qiyuan Tian,  Stephen Robert Frost,  Itthi Chatnuntawech,  Berkin Bilgic</p>
  <p><b>备注</b>：8 figures, 1 table</p>
  <p><b>关键词</b>：recently introduced modl technique successfully incorporates convolutional neural network, enable rapid quantitative imaging using, modl allows rapid mr acquisition, based parallel imaging reconstruction using, incorporating unrolled neural networks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Purpose: To propose a wave-encoded model-based deep learning (wave-MoDL)
strategy for highly accelerated 3D imaging and joint multi-contrast image
reconstruction, and further extend this to enable rapid quantitative imaging
using an interleaved look-locker acquisition sequence with T2 preparation pulse
(3D-QALAS).
Method: Recently introduced MoDL technique successfully incorporates
convolutional neural network (CNN)-based regularizers into physics-based
parallel imaging reconstruction using a small number of network parameters.
Wave-CAIPI is an emerging parallel imaging method that accelerates the imaging
speed by employing sinusoidal gradients in the phase- and slice-encoding
directions during the readout to take better advantage of 3D coil sensitivity
profiles. In wave-MoDL, we propose to combine the wave-encoding strategy with
unrolled network constraints to accelerate the acquisition speed while
enforcing wave-encoded data consistency. We further extend wave-MoDL to
reconstruct multi-contrast data with controlled aliasing in parallel imaging
(CAIPI) sampling patterns to leverage similarity between multiple images to
improve the reconstruction quality.
Result: Wave-MoDL enables a 47-second MPRAGE acquisition at 1 mm resolution
at 16-fold acceleration. For quantitative imaging, wave-MoDL permits a 2-minute
acquisition for T1, T2, and proton density mapping at 1 mm resolution at
12-fold acceleration, from which contrast weighted images can be synthesized as
well.
Conclusion: Wave-MoDL allows rapid MR acquisition and high-fidelity image
reconstruction and may facilitate clinical and neuroscientific applications by
incorporating unrolled neural networks into wave-CAIPI reconstruction.</p>
  </details>
</details>
<details>
  <summary>215. <b>标题：Optimal Algorithms for Decentralized Stochastic Variational Inequalities</b></summary>
  <p><b>编号</b>：[505]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02771</p>
  <p><b>作者</b>：Dmitry Kovalev,  Aleksandr Beznosikov,  Abdurakhmon Sadiev,  Michael Persiianov,  Peter Richtárik,  Alexander Gasnikov</p>
  <p><b>备注</b>：52 pages, 2 algorithms (with 2 modifications), 5 theorems</p>
  <p><b>关键词</b>：including machine learning problems, present lower complexity bounds, therefore universal approaches, many applied tasks, experimental results confirm</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Variational inequalities are a formalism that includes games, minimization,
saddle point, and equilibrium problems as special cases. Methods for
variational inequalities are therefore universal approaches for many applied
tasks, including machine learning problems. This work concentrates on the
decentralized setting, which is increasingly important but not well understood.
In particular, we consider decentralized stochastic (sum-type) variational
inequalities over fixed and time-varying networks. We present lower complexity
bounds for both communication and local iterations and construct optimal
algorithms that match these lower bounds. Our algorithms are the best among the
available literature not only in the decentralized stochastic case, but also in
the decentralized deterministic and non-distributed stochastic cases.
Experimental results confirm the effectiveness of the presented algorithms.</p>
  </details>
</details>
<details>
  <summary>216. <b>标题：Estimating the Euclidean Quantum Propagator with Deep Generative  Modelling of Feynman paths</b></summary>
  <p><b>编号</b>：[508]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02750</p>
  <p><b>作者</b>：Yanming Che,  Clemens Gneiting,  Franco Nori</p>
  <p><b>备注</b>：4 figures, 6+2 pages, with supplemental information</p>
  <p><b>关键词</b>：way toward generative modelling, ground state wave function, feynman path integrals provide, efficiently generates feynman paths, may also provide</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Feynman path integrals provide an elegant, classically-inspired
representation for the quantum propagator and the quantum dynamics, through
summing over a huge manifold of all possible paths. From computational and
simulational perspectives, the ergodic tracking of the whole path manifold is a
hard problem. Machine learning can help, in an efficient manner, to identify
the relevant subspace and the intrinsic structure residing at a small fraction
of the vast path manifold. In this work, we propose the concept of Feynman path
generator, which efficiently generates Feynman paths with fixed endpoints from
a (low-dimensional) latent space, by targeting a desired density of paths in
the Euclidean space-time. With such path generators, the Euclidean propagator
as well as the ground state wave function can be estimated efficiently for a
generic potential energy. Our work leads to a fresh approach for calculating
the quantum propagator, paves the way toward generative modelling of Feynman
paths, and may also provide a future new perspective to understand the
quantum-classical correspondence through deep learning.</p>
  </details>
</details>
<details>
  <summary>217. <b>标题：Portfolio Optimization on NIFTY Thematic Sector Stocks Using an LSTM  Model</b></summary>
  <p><b>编号</b>：[509]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02723</p>
  <p><b>作者</b>：Jaydip Sen,  Saikat Mondal,  Sidra Mehtab</p>
  <p><b>备注</b>：The is the preprint version of our published paper listed in the IEEE Xplore. The final paper is published in the Proceedings of the IEEE International Conference on Data Analytics for Business and Industry, pp. 364-369, Bahrain, October 25-26, 2021. The preprint consists of 6 pages and it contains 10 figures and 16 tables</p>
  <p><b>关键词</b>：predicting future stock prices, statistical finance researchers, five thematic sectors, actual returns indicate, ten critical stocks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Portfolio optimization has been a broad and intense area of interest for
quantitative and statistical finance researchers and financial analysts. It is
a challenging task to design a portfolio of stocks to arrive at the optimized
values of the return and risk. This paper presents an algorithmic approach for
designing optimum risk and eigen portfolios for five thematic sectors of the
NSE of India. The prices of the stocks are extracted from the web from Jan 1,
2016, to Dec 31, 2020. Optimum risk and eigen portfolios for each sector are
designed based on ten critical stocks from the sector. An LSTM model is
designed for predicting future stock prices. Seven months after the portfolios
were formed, on Aug 3, 2021, the actual returns of the portfolios are compared
with the LSTM-predicted returns. The predicted and the actual returns indicate
a very high-level accuracy of the LSTM model.</p>
  </details>
</details>
<details>
  <summary>218. <b>标题：Beyond Black Box Densities: Parameter Learning for the Deviated  Components</b></summary>
  <p><b>编号</b>：[514]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02651</p>
  <p><b>作者</b>：Dat Do,  Nhat Ho,  XuanLong Nguyen</p>
  <p><b>备注</b>：44 pages, 3 figures. Dat Do and Nhat Ho contributed equally to this work</p>
  <p><b>关键词</b>：$( 1 -\ lambda ^{*}) h_0, delta_ {\ theta_i ^{*}}$ associated, deviated proportion $\ lambda ^{*}$, known density function estimate may, data set may result</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As we collect additional samples from a data population for which a known
density function estimate may have been previously obtained by a black box
method, the increased complexity of the data set may result in the true density
being deviated from the known estimate by a mixture distribution. To model this
phenomenon, we consider the \emph{deviating mixture model} $(1-\lambda^{*})h_0
+ \lambda^{*} (\sum_{i = 1}^{k} p_{i}^{*} f(x|\theta_{i}^{*}))$, where $h_0$ is
a known density function, while the deviated proportion $\lambda^{*}$ and
latent mixing measure $G_{*} = \sum_{i = 1}^{k} p_{i}^{*}
\delta_{\theta_i^{*}}$ associated with the mixture distribution are unknown.
Via a novel notion of distinguishability between the known density $h_{0}$ and
the deviated mixture distribution, we establish rates of convergence for the
maximum likelihood estimates of $\lambda^{*}$ and $G^{*}$ under Wasserstein
metric. Simulation studies are carried out to illustrate the theory.</p>
  </details>
</details>
<details>
  <summary>219. <b>标题：The Implicit Bias of Gradient Descent on Generalized Gated Linear  Networks</b></summary>
  <p><b>编号</b>：[515]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02649</p>
  <p><b>作者</b>：Samuel Lippl,  L. F. Abbott,  SueYeon Chung</p>
  <p><b>备注</b>：23 pages, 5 figures</p>
  <p><b>关键词</b>：deep nonlinear neural networks, gradient descent affect performance, deep neural networks, improving network performance, robust learning algorithms</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Understanding the asymptotic behavior of gradient-descent training of deep
neural networks is essential for revealing inductive biases and improving
network performance. We derive the infinite-time training limit of a
mathematically tractable class of deep nonlinear neural networks, gated linear
networks (GLNs), and generalize these results to gated networks described by
general homogeneous polynomials. We study the implications of our results,
focusing first on two-layer GLNs. We then apply our theoretical predictions to
GLNs trained on MNIST and show how architectural constraints and the implicit
bias of gradient descent affect performance. Finally, we show that our theory
captures a substantial portion of the inductive bias of ReLU networks. By
making the inductive bias explicit, our framework is poised to inform the
development of more efficient, biologically plausible, and robust learning
algorithms.</p>
  </details>
</details>
<details>
  <summary>220. <b>标题：ROMNet: Renovate the Old Memories</b></summary>
  <p><b>编号</b>：[520]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02606</p>
  <p><b>作者</b>：Runsheng Xu,  Zhengzhong Tu,  Yuanqi Du,  Xiaoyu Dong,  Jinlong Li,  Zibo Meng,  Jiaqi Ma,  Hongkai YU</p>
  <p><b>备注</b>：Submitted to TIP</p>
  <p><b>关键词</b>：scale paired old photo datasets makes, evaluating old photo restoration models, whole system takes advantage, world old photo dataset, manually restored pristine image</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Renovating the memories in old photos is an intriguing research topic in
computer vision fields. These legacy images often suffer from severe and
commingled degradations such as cracks, noise, and color-fading, while lack of
large-scale paired old photo datasets makes this restoration task very
challenging. In this work, we present a novel reference-based end-to-end
learning framework that can jointly repair and colorize the degraded legacy
pictures. Specifically, the proposed framework consists of three modules: a
restoration sub-network for degradation restoration, a similarity sub-network
for color histogram matching and transfer, and a colorization subnet that
learns to predict the chroma elements of the images conditioned on chromatic
reference signals. The whole system takes advantage of the color histogram
priors in a given reference image, which vastly reduces the dependency on
large-scale training data. Apart from the proposed method, we also create, to
our knowledge, the first public and real-world old photo dataset with paired
ground truth for evaluating old photo restoration models, wherein each old
photo is paired with a manually restored pristine image by PhotoShop experts.
Our extensive experiments conducted on both synthetic and real-world datasets
demonstrate that our method significantly outperforms state-of-the-arts both
quantitatively and qualitatively.</p>
  </details>
</details>
<details>
  <summary>221. <b>标题：Importance Weighting Approach in Kernel Bayes' Rule</b></summary>
  <p><b>编号</b>：[527]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02474</p>
  <p><b>作者</b>：Liyuan Xu,  Yutian Chen,  Arnaud Doucet,  Arthur Gretton</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：proposed method yields uniformly better empirical performance, space model involving high dimensional image observations, bayesian computation via feature means, yield expected posterior features, method entirely model</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We study a nonparametric approach to Bayesian computation via feature means,
where the expectation of prior features is updated to yield expected posterior
features, based on regression from kernel or neural net features of the
observations. All quantities involved in the Bayesian update are learned from
observed data, making the method entirely model-free. The resulting algorithm
is a novel instance of a kernel Bayes' rule (KBR). Our approach is based on
importance weighting, which results in superior numerical stability to the
existing approach to KBR, which requires operator inversion. We show the
convergence of the estimator using a novel consistency analysis on the
importance weighting estimator in the infinity norm. We evaluate our KBR on
challenging synthetic benchmarks, including a filtering problem with a
state-space model involving high dimensional image observations. The proposed
method yields uniformly better empirical performance than the existing KBR, and
competitive performance with other competing methods.</p>
  </details>
</details>
<details>
  <summary>222. <b>标题：Tensor-CSPNet: A Novel Geometric Deep Learning Framework for Motor  Imagery Classification</b></summary>
  <p><b>编号</b>：[528]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02472</p>
  <p><b>作者</b>：Ce Ju,  Cuntai Guan</p>
  <p><b>备注</b>：15 pages, 10 figures, 12 tables; This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible</p>
  <p><b>关键词</b>：frequential patterns using deep neural networks, eeg signals using convolutional neural networks, alternative network architecture despite cnns, interpretability analyses also exhibit, novel geometric deep learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep learning (DL) has been widely investigated in a vast majority of
applications in electroencephalography (EEG)-based brain-computer interfaces
(BCIs), especially for motor imagery (MI) classification in the past five
years. The mainstream DL methodology for the MI-EEG classification exploits the
temporospatial patterns of EEG signals using convolutional neural networks
(CNNs), which have been particularly successful in visual images. However,
since the statistical characteristics of visual images may not benefit EEG
signals, a natural question that arises is whether there exists an alternative
network architecture despite CNNs to extract features for the MI-EEG
classification. To address this question, we propose a novel geometric deep
learning (GDL) framework called Tensor-CSPNet to characterize EEG signals on
symmetric positive definite (SPD) manifolds and exploit the
temporo-spatio-frequential patterns using deep neural networks on SPD
manifolds. Meanwhile, many experiences of successful MI-EEG classifiers have
been integrated into the Tensor-CSPNet framework to make it more efficient. In
the experiments, Tensor-CSPNet attains or slightly outperforms the current
state-of-the-art performance on the cross-validation and holdout scenarios of
two MI-EEG datasets. The visualization and interpretability analyses also
exhibit its validity for the MI-EEG classification. To conclude, we provide a
feasible answer to the question by generalizing the previous DL methodologies
on SPD manifolds, which indicates the start of a specific class from the GDL
methodology for the MI-EEG classification.</p>
  </details>
</details>
<details>
  <summary>223. <b>标题：One-Nearest-Neighbor Search is All You Need for Minimax Optimal  Regression and Classification</b></summary>
  <p><b>编号</b>：[529]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02464</p>
  <p><b>作者</b>：J. Jon Ryu,  Young-Han Kim</p>
  <p><b>备注</b>：25 pages, 2 figures</p>
  <p><b>关键词</b>：attain exact minimax optimal rates, minimax optimal error rate, sufficiently large number, standard $\ theta, refined aggregation method</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recently, Qiao, Duan, and Cheng~(2019) proposed a distributed
nearest-neighbor classification method, in which a massive dataset is split
into smaller groups, each processed with a $k$-nearest-neighbor classifier, and
the final class label is predicted by a majority vote among these groupwise
class labels. This paper shows that the distributed algorithm with $k=1$ over a
sufficiently large number of groups attains a minimax optimal error rate up to
a multiplicative logarithmic factor under some regularity conditions, for both
regression and classification problems. Roughly speaking, distributed
1-nearest-neighbor rules with $M$ groups has a performance comparable to
standard $\Theta(M)$-nearest-neighbor rules. In the analysis, alternative rules
with a refined aggregation method are proposed and shown to attain exact
minimax optimal rates.</p>
  </details>
</details>
<details>
  <summary>224. <b>标题：Machine Learning Method for Functional Assessment of Retinal Models</b></summary>
  <p><b>编号</b>：[530]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02443</p>
  <p><b>作者</b>：Nikolas Papadopoulos,  Nikos Melanitis,  Antonio Lozano,  Cristina Soto-Sanchez,  Eduardo Fernandez,  Konstantina S Nikita</p>
  <p><b>备注</b>：Accepted at 2021 43rd Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC)</p>
  <p><b>关键词</b>：accurately simulate retinal ganglion cells, feed traditional machine learning classifiers, accurately predict rgc response, optimally feed rgc responses, examined critical fa aspects</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Challenges in the field of retinal prostheses motivate the development of
retinal models to accurately simulate Retinal Ganglion Cells (RGCs) responses.
The goal of retinal prostheses is to enable blind individuals to solve complex,
reallife visual tasks. In this paper, we introduce the functional assessment
(FA) of retinal models, which describes the concept of evaluating the
performance of retinal models on visual understanding tasks. We present a
machine learning method for FA: we feed traditional machine learning
classifiers with RGC responses generated by retinal models, to solve object and
digit recognition tasks (CIFAR-10, MNIST, Fashion MNIST, Imagenette). We
examined critical FA aspects, including how the performance of FA depends on
the task, how to optimally feed RGC responses to the classifiers and how the
number of output neurons correlates with the model's accuracy. To increase the
number of output neurons, we manipulated input images - by splitting and then
feeding them to the retinal model and we found that image splitting does not
significantly improve the model's accuracy. We also show that differences in
the structure of datasets result in largely divergent performance of the
retinal model (MNIST and Fashion MNIST exceeded 80% accuracy, while CIFAR-10
and Imagenette achieved ~40%). Furthermore, retinal models which perform better
in standard evaluation, i.e. more accurately predict RGC response, perform
better in FA as well. However, unlike standard evaluation, FA results can be
straightforwardly interpreted in the context of comparing the quality of visual
perception.</p>
  </details>
</details>
<details>
  <summary>225. <b>标题：Stratification of carotid atheromatous plaque using interpretable deep  learning methods on B-mode ultrasound images</b></summary>
  <p><b>编号</b>：[532]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02428</p>
  <p><b>作者</b>：Theofanis Ganitidis,  Maria Athanasiou,  Kalliopi Dalakleidi,  Nikos Melanitis,  Spyretta Golemati,  Konstantina S Nikita</p>
  <p><b>备注</b>：Accepted at 2021 43rd Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC)</p>
  <p><b>关键词</b>：proposed approach achieved acceptable discrimination performance, auc ): 73 %, sensitivity, two fully connected layers, novel ultrasound image biomarkers, ensemble learning scheme based</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Carotid atherosclerosis is the major cause of ischemic stroke resulting in
significant rates of mortality and disability annually. Early diagnosis of such
cases is of great importance, since it enables clinicians to apply a more
effective treatment strategy. This paper introduces an interpretable
classification approach of carotid ultrasound images for the risk assessment
and stratification of patients with carotid atheromatous plaque. To address the
highly imbalanced distribution of patients between the symptomatic and
asymptomatic classes (16 vs 58, respectively), an ensemble learning scheme
based on a sub-sampling approach was applied along with a two-phase,
cost-sensitive strategy of learning, that uses the original and a resampled
data set. Convolutional Neural Networks (CNNs) were utilized for building the
primary models of the ensemble. A six-layer deep CNN was used to automatically
extract features from the images, followed by a classification stage of two
fully connected layers. The obtained results (Area Under the ROC Curve (AUC):
73%, sensitivity: 75%, specificity: 70%) indicate that the proposed approach
achieved acceptable discrimination performance. Finally, interpretability
methods were applied on the model's predictions in order to reveal insights on
the model's decision process as well as to enable the identification of novel
image biomarkers for the stratification of patients with carotid atheromatous
plaque.Clinical Relevance-The integration of interpretability methods with deep
learning strategies can facilitate the identification of novel ultrasound image
biomarkers for the stratification of patients with carotid atheromatous plaque.</p>
  </details>
</details>
<details>
  <summary>226. <b>标题：OMLT: Optimization & Machine Learning Toolkit</b></summary>
  <p><b>编号</b>：[533]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02414</p>
  <p><b>作者</b>：Francesco Ceccon,  Jordan Jalving,  Joshua Haddad,  Alexander Thebelt,  Calvin Tsay,  Carl D. Laird,  Ruth Misener</p>
  <p><b>备注</b>：7 pages, 1 figure</p>
  <p><b>关键词</b>：source software package incorporating neural network, boosted tree surrogate models, algebraic modeling language pyomo, trained using machine learning, machine learning toolkit</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The optimization and machine learning toolkit (OMLT) is an open-source
software package incorporating neural network and gradient-boosted tree
surrogate models, which have been trained using machine learning, into larger
optimization problems. We discuss the advances in optimization technology that
made OMLT possible and show how OMLT seamlessly integrates with the algebraic
modeling language Pyomo. We demonstrate how to use OMLT for solving
decision-making problems in both computer science and engineering.</p>
  </details>
</details>
<details>
  <summary>227. <b>标题：An Experimental Design Approach for Regret Minimization in Logistic  Bandits</b></summary>
  <p><b>编号</b>：[534]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02407</p>
  <p><b>作者</b>：Blake Mason,  Kwang-Sung Jun,  Lalit Jain</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：unknown parameter $\ theta_ {\ ast }$., potentially large problem dependent constant $\ kappa, 2 (\ kappa )\ sqrt {\ dot, case dependence providing regret guarantees like, 2 (\ kappa )$</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this work we consider the problem of regret minimization for logistic
bandits. The main challenge of logistic bandits is reducing the dependence on a
potentially large problem dependent constant $\kappa$ that can at worst scale
exponentially with the norm of the unknown parameter $\theta_{\ast}$. Abeille
et al. (2021) have applied self-concordance of the logistic function to remove
this worst-case dependence providing regret guarantees like
$O(d\log^2(\kappa)\sqrt{\dot\mu T}\log(|\mathcal{X}|))$ where $d$ is the
dimensionality, $T$ is the time horizon, and $\dot\mu$ is the variance of the
best-arm. This work improves upon this bound in the fixed arm setting by
employing an experimental design procedure that achieves a minimax regret of
$O(\sqrt{d \dot\mu T\log(|\mathcal{X}|)})$. Our regret bound in fact takes a
tighter instance (i.e., gap) dependent regret bound for the first time in
logistic bandits. We also propose a new warmup sampling algorithm that can
dramatically reduce the lower order term in the regret in general and prove
that it can replace the lower order term dependency on $\kappa$ to
$\log^2(\kappa)$ for some instances. Finally, we discuss the impact of the bias
of the MLE on the logistic bandit problem, providing an example where $d^2$
lower order regret (cf., it is $d$ for linear bandits) may not be improved as
long as the MLE is used and how bias-corrected estimators may be used to make
it closer to $d$.</p>
  </details>
</details>
<details>
  <summary>228. <b>标题：Bregman Plug-and-Play Priors</b></summary>
  <p><b>编号</b>：[535]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02388</p>
  <p><b>作者</b>：Abdullah H. Al-Shabili,  Xiaojian Xu,  Ivan Selesnick,  Ulugbek S. Kamilov</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：new bregman proximal gradient method variant, bregman steepest descent variant, poisson linear inverse problems, solving inverse problems, general bregman distance</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The past few years have seen a surge of activity around integration of deep
learning networks and optimization algorithms for solving inverse problems.
Recent work on plug-and-play priors (PnP), regularization by denoising (RED),
and deep unfolding has shown the state-of-the-art performance of such
integration in a variety of applications. However, the current paradigm for
designing such algorithms is inherently Euclidean, due to the usage of the
quadratic norm within the projection and proximal operators. We propose to
broaden this perspective by considering a non-Euclidean setting based on the
more general Bregman distance. Our new Bregman Proximal Gradient Method variant
of PnP (PnP-BPGM) and Bregman Steepest Descent variant of RED (RED-BSD) replace
the traditional updates in PnP and RED from the quadratic norms to more general
Bregman distance. We present a theoretical convergence result for PnP-BPGM and
demonstrate the effectiveness of our algorithms on Poisson linear inverse
problems.</p>
  </details>
</details>
<details>
  <summary>229. <b>标题：Frequency comb and machine learning-based breath analysis for COVID-19  classification</b></summary>
  <p><b>编号</b>：[540]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02321</p>
  <p><b>作者</b>：Qizhong Liang,  Ya-Chu Chan,  Jutta Toscano,  Kristen K. Bjorkman,  Leslie A. Leinwand,  Roy Parker,  David J. Nesbitt,  Jun Ye</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：frequency comb spectroscopy thus help establish precise digital spectral fingerprints, 4 ), providing excellent prediction performance, enhanced direct frequency comb spectroscopy, readily scalable comb spectral coverage, unambiguous binary medical response classification</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Human breath contains hundreds of volatile molecules that can provide
powerful, non-intrusive spectral diagnosis of a diverse set of diseases and
physiological/metabolic states. To unleash this tremendous potential for
medical science, we present a robust analytical method that simultaneously
measures tens of thousands of spectral features in each breath sample, followed
by efficient and detail-specific multivariate data analysis for unambiguous
binary medical response classification. We combine mid-infrared cavity-enhanced
direct frequency comb spectroscopy (CE-DFCS), capable of real-time collection
of tens of thousands of distinct molecular features at parts-per-trillion
sensitivity, with supervised machine learning, capable of analysis and
verification of extremely high-dimensional input data channels. Here, we
present the first application of this method to the breath detection of
Coronavirus Disease 2019 (COVID-19). Using 170 individual samples at the
University of Colorado, we report a cross-validated area under the
Receiver-Operating-Characteristics curve of 0.849(4), providing excellent
prediction performance. Further, this method detected a significant difference
between male and female breath as well as other variables such as smoking and
abdominal pain. Together, these highlight the utility of CE-DFCS for rapid,
non-invasive detection of diverse biological conditions and disease states. The
unique properties of frequency comb spectroscopy thus help establish precise
digital spectral fingerprints for building accurate databases and provide means
for simultaneous multi-response classifications. The predictive power can be
further enhanced with readily scalable comb spectral coverage.</p>
  </details>
</details>
<h1>人工智能</h1>
<details>
  <summary>1. <b>标题：GMC -- Geometric Multimodal Contrastive Representation Learning</b></summary>
  <p><b>编号</b>：[10]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03390</p>
  <p><b>作者</b>：Petra Poklukar,  Miguel Vasco,  Hang Yin,  Francisco S. Melo,  Ana Paiva,  Danica Kragic</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：three different learning problems including prediction, multimodal contrastive loss function, representation learning method comprised, novel geometric multimodal contrastive, reinforcement learning tasks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Learning representations of multimodal data that are both informative and
robust to missing modalities at test time remains a challenging problem due to
the inherent heterogeneity of data obtained from different channels. To address
it, we present a novel Geometric Multimodal Contrastive (GMC) representation
learning method comprised of two main components: i) a two-level architecture
consisting of modality-specific base encoder, allowing to process an arbitrary
number of modalities to an intermediate representation of fixed dimensionality,
and a shared projection head, mapping the intermediate representations to a
latent representation space; ii) a multimodal contrastive loss function that
encourages the geometric alignment of the learned representations. We
experimentally demonstrate that GMC representations are semantically rich and
achieve state-of-the-art performance with missing modality information on three
different learning problems including prediction and reinforcement learning
tasks.</p>
  </details>
</details>
<details>
  <summary>2. <b>标题：Corrupted Image Modeling for Self-Supervised Visual Pre-Training</b></summary>
  <p><b>编号</b>：[14]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03382</p>
  <p><b>作者</b>：Yuxin Fang,  Li Dong,  Hangbo Bao,  Xinggang Wang,  Furu Wei</p>
  <p><b>备注</b>：Preprint. Work in progress. Code will be released at this https URL</p>
  <p><b>关键词</b>：learn rich visual representations using, using artificial mask tokens, approach achieves compelling results, introduce corrupted image modeling, 1k image classification respectively</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We introduce Corrupted Image Modeling (CIM) for self-supervised visual
pre-training. CIM uses an auxiliary generator with a small trainable BEiT to
corrupt the input image instead of using artificial mask tokens, where some
patches are randomly selected and replaced with plausible alternatives sampled
from the BEiT output distribution. Given this corrupted image, an enhancer
network learns to either recover all the original image pixels, or predict
whether each visual token is replaced by a generator sample or not. The
generator and the enhancer are simultaneously trained and synergistically
updated. After pre-training, the enhancer can be used as a high-capacity visual
encoder for downstream tasks. CIM is a general and flexible visual pre-training
framework that is suitable for various network architectures. For the first
time, CIM demonstrates that both ViT and CNN can learn rich visual
representations using a unified, non-Siamese framework. Experimental results
show that our approach achieves compelling results in vision benchmarks, such
as ImageNet classification and ADE20K semantic segmentation. For example,
300-epoch CIM pre-trained vanilla ViT-Base/16 and ResNet-50 obtain 83.3 and
80.6 Top-1 fine-tuning accuracy on ImageNet-1K image classification
respectively.</p>
  </details>
</details>
<details>
  <summary>3. <b>标题：A Robot Web for Distributed Many-Device Localisation</b></summary>
  <p><b>编号</b>：[36]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03314</p>
  <p><b>作者</b>：Riku Murai,  Joseph Ortiz,  Sajad Saeedi,  Paul H.J. Kelly,  Andrew J. Davison</p>
  <p><b>备注</b>：18 pages, 7 figures</p>
  <p><b>关键词</b>：solution convergently achieves global accuracy, globally localise via efficient ad, linear factor graph solver, linear factor graph describing, observations robots make internally</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We show that a distributed network of robots or other devices which make
measurements of each other can collaborate to globally localise via efficient
ad-hoc peer to peer communication. Our Robot Web solution is based on Gaussian
Belief Propagation on the fundamental non-linear factor graph describing the
probabilistic structure of all of the observations robots make internally or of
each other, and is flexible for any type of robot, motion or sensor. We define
a simple and efficient communication protocol which can be implemented by the
publishing and reading of web pages or other asynchronous communication
technologies. We show in simulations with up to 1000 robots interacting in
arbitrary patterns that our solution convergently achieves global accuracy as
accurate as a centralised non-linear factor graph solver while operating with
high distributed efficiency of computation and communication. Via the use of
robust factors in GBP, our method is tolerant to a high percentage of faults in
sensor measurements or dropped communication packets.</p>
  </details>
</details>
<details>
  <summary>4. <b>标题：Training OOD Detectors in their Natural Habitats</b></summary>
  <p><b>编号</b>：[40]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03299</p>
  <p><b>作者</b>：Julian Katz-Samuels,  Julia Nakhleh,  Robert Nowak,  Yixuan Li</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：recent methods use auxiliary outlier data, leverages wild mixture data --, arises freely upon deploying, machine learning models deployed, common ood detection tasks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Out-of-distribution (OOD) detection is important for machine learning models
deployed in the wild. Recent methods use auxiliary outlier data to regularize
the model for improved OOD detection. However, these approaches make a strong
distributional assumption that the auxiliary outlier data is completely
separable from the in-distribution (ID) data. In this paper, we propose a novel
framework that leverages wild mixture data -- that naturally consists of both
ID and OOD samples. Such wild data is abundant and arises freely upon deploying
a machine learning classifier in their \emph{natural habitats}. Our key idea is
to formulate a constrained optimization problem and to show how to tractably
solve it. Our learning objective maximizes the OOD detection rate, subject to
constraints on the classification error of ID data and on the OOD error rate of
ID examples. We extensively evaluate our approach on common OOD detection tasks
and demonstrate superior performance.</p>
  </details>
</details>
<details>
  <summary>5. <b>标题：Mental Disorders on Online Social Media Through the Lens of Language and  Behaviour: Analysis and Visualisation</b></summary>
  <p><b>编号</b>：[44]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03291</p>
  <p><b>作者</b>：Esteban A. Ríssola,  Mohammad Aliannejadi,  Fabio Crestani</p>
  <p><b>备注</b>：To appear in Elsevier Information Processing & Management</p>
  <p><b>关键词</b>：perform different experiments studying multiple dimensions, thorough analysis towards better visualising, differentiate social media users affected, findings reveal significant differences, twitter less quantifiable differences</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Due to the worldwide accessibility to the Internet along with the continuous
advances in mobile technologies, physical and digital worlds have become
completely blended, and the proliferation of social media platforms has taken a
leading role over this evolution. In this paper, we undertake a thorough
analysis towards better visualising and understanding the factors that
characterise and differentiate social media users affected by mental disorders.
We perform different experiments studying multiple dimensions of language,
including vocabulary uniqueness, word usage, linguistic style, psychometric
attributes, emotions' co-occurrence patterns, and online behavioural traits,
including social engagement and posting trends. Our findings reveal significant
differences on the use of function words, such as adverbs and verb tense, and
topic-specific vocabulary, such as biological processes. As for emotional
expression, we observe that affected users tend to share emotions more
regularly than control individuals on average. Overall, the monthly posting
variance of the affected groups is higher than the control groups. Moreover, we
found evidence suggesting that language use on micro-blogging platforms is less
distinguishable for users who have a mental disorder than other less
restrictive platforms. In particular, we observe on Twitter less quantifiable
differences between affected and control groups compared to Reddit.</p>
  </details>
</details>
<details>
  <summary>6. <b>标题：Red Teaming Language Models with Language Models</b></summary>
  <p><b>编号</b>：[47]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03286</p>
  <p><b>作者</b>：Ethan Perez,  Saffron Huang,  Francis Song,  Trevor Cai,  Roman Ring,  John Aslanides,  Amelia Glaese,  Nat McAleese,  Geoffrey Irving</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：generating test cases (" red teaming ") using another lm, prior work identifies harmful behaviors, generated test questions using, based red teaming, hospital phone numbers generated</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Language Models (LMs) often cannot be deployed because of their potential to
harm users in hard-to-predict ways. Prior work identifies harmful behaviors
before deployment by using human annotators to hand-write test cases. However,
human annotation is expensive, limiting the number and diversity of test cases.
In this work, we automatically find cases where a target LM behaves in a
harmful way, by generating test cases ("red teaming") using another LM. We
evaluate the target LM's replies to generated test questions using a classifier
trained to detect offensive content, uncovering tens of thousands of offensive
replies in a 280B parameter LM chatbot. We explore several methods, from
zero-shot generation to reinforcement learning, for generating test cases with
varying levels of diversity and difficulty. Furthermore, we use prompt
engineering to control LM-generated test cases to uncover a variety of other
harms, automatically finding groups of people that the chatbot discusses in
offensive ways, personal and hospital phone numbers generated as the chatbot's
own contact info, leakage of private training data in generated text, and harms
that occur over the course of a conversation. Overall, LM-based red teaming is
one promising tool (among many needed) for finding and fixing diverse,
undesirable LM behaviors before impacting users.</p>
  </details>
</details>
<details>
  <summary>7. <b>标题：Personalized Public Policy Analysis in Social Sciences using  Causal-Graphical Normalizing Flows</b></summary>
  <p><b>编号</b>：[49]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03281</p>
  <p><b>作者</b>：Sourabh Balgi,  Jose M. Pena,  Adel Daoud</p>
  <p><b>备注</b>：9 pages, 3 figures, AAAI-2022: AI for Social Impact track</p>
  <p><b>关键词</b>：relatively closed systems ), p $^ 3, gnf ), facilitating p $^ 3, facilitating p $^ 3, traditional causal effect estimation methods, demonstrating promising empirical performance</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Structural Equation/Causal Models (SEMs/SCMs) are widely used in epidemiology
and social sciences to identify and analyze the average treatment effect (ATE)
and conditional ATE (CATE). Traditional causal effect estimation methods such
as Inverse Probability Weighting (IPW) and more recently
Regression-With-Residuals (RWR) are widely used - as they avoid the challenging
task of identifying the SCM parameters - to estimate ATE and CATE. However,
much work remains before traditional estimation methods can be used for
counterfactual inference, and for the benefit of Personalized Public Policy
Analysis (P$^3$A) in the social sciences. While doctors rely on personalized
medicine to tailor treatments to patients in laboratory settings (relatively
closed systems), P$^3$A draws inspiration from such tailoring but adapts it for
open social systems. In this article, we develop a method for counterfactual
inference that we name causal-Graphical Normalizing Flow (c-GNF), facilitating
P$^3$A. First, we show how c-GNF captures the underlying SCM without making any
assumption about functional forms. Second, we propose a novel dequantization
trick to deal with discrete variables, which is a limitation of normalizing
flows in general. Third, we demonstrate in experiments that c-GNF performs
on-par with IPW and RWR in terms of bias and variance for estimating the ATE,
when the true functional forms are known, and better when they are unknown.
Fourth and most importantly, we conduct counterfactual inference with c-GNFs,
demonstrating promising empirical performance. Because IPW and RWR, like other
traditional methods, lack the capability of counterfactual inference, c-GNFs
will likely play a major role in tailoring personalized treatment, facilitating
P$^3$A, optimizing social interventions - in contrast to the current
`one-size-fits-all' approach of existing methods.</p>
  </details>
</details>
<details>
  <summary>8. <b>标题：AI-based artistic representation of emotions from EEG signals: a  discussion on fairness, inclusion, and aesthetics</b></summary>
  <p><b>编号</b>：[60]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03246</p>
  <p><b>作者</b>：Piera Riccio,  Kristin Bergaust,  Boel Christensen-Scheel,  Juan-Carlos De Martin,  Maria A. Zuluaga,  Stefano Nichele</p>
  <p><b>备注</b>：Accepted to the Politics of the Machines conference 2021 (POM Berlin 2021)</p>
  <p><b>关键词</b>：reach better co, images give opportunities, express feelings artistically, progressively developed, machines interact</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>While Artificial Intelligence (AI) technologies are being progressively
developed, artists and researchers are investigating their role in artistic
practices. In this work, we present an AI-based Brain-Computer Interface (BCI)
in which humans and machines interact to express feelings artistically. This
system and its production of images give opportunities to reflect on the
complexities and range of human emotions and their expressions. In this
discussion, we seek to understand the dynamics of this interaction to reach
better co-existence in fairness, inclusion, and aesthetics.</p>
  </details>
</details>
<details>
  <summary>9. <b>标题：Neural Models for Output-Space Invariance in Combinatorial Problems</b></summary>
  <p><b>编号</b>：[69]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03229</p>
  <p><b>作者</b>：Yatin Nandwani,  Vidit Jain,  Mausam,  Parag Singla</p>
  <p><b>备注</b>：Published as a conference paper at ICLR 2022</p>
  <p><b>关键词</b>：implicitly learning underlying constraints using, three different combinatorial problems demonstrates, recently proposed recurrent relational networks, solve 16 x 16 sudoku, binarized model gives better performance</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recently many neural models have been proposed to solve combinatorial puzzles
by implicitly learning underlying constraints using their solved instances,
such as sudoku or graph coloring (GCP). One drawback of the proposed
architectures, which are often based on Graph Neural Networks (GNN), is that
they cannot generalize across the size of the output space from which variables
are assigned a value, for example, set of colors in a GCP, or board-size in
sudoku. We call the output space for the variables as 'value-set'. While many
works have demonstrated generalization of GNNs across graph size, there has
been no study on how to design a GNN for achieving value-set invariance for
problems that come from the same domain. For example, learning to solve 16 x 16
sudoku after being trained on only 9 x 9 sudokus. In this work, we propose
novel methods to extend GNN based architectures to achieve value-set
invariance. Specifically, our model builds on recently proposed Recurrent
Relational Networks. Our first approach exploits the graph-size invariance of
GNNs by converting a multi-class node classification problem into a binary node
classification problem. Our second approach works directly with multiple
classes by adding multiple nodes corresponding to the values in the value-set,
and then connecting variable nodes to value nodes depending on the problem
initialization. Our experimental evaluation on three different combinatorial
problems demonstrates that both our models perform well on our novel problem,
compared to a generic neural reasoner. Between two of our models, we observe an
inherent trade-off: while the binarized model gives better performance when
trained on smaller value-sets, multi-valued model is much more memory
efficient, resulting in improved performance when trained on larger value-sets,
where binarized model fails to train.</p>
  </details>
</details>
<details>
  <summary>10. <b>标题：AI Research Associate for Early-Stage Scientific Discovery</b></summary>
  <p><b>编号</b>：[78]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03199</p>
  <p><b>作者</b>：Morad Behandish,  John Maxwell III,  Johan de Kleer</p>
  <p><b>备注</b>：Paper #203</p>
  <p><b>关键词</b>：even dogmatized ), stifling transformative discoveries, g ., postulated forms, stage scientific discovery based, g ., constitutive, real problems faced</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Artificial intelligence (AI) has been increasingly applied in scientific
activities for decades; however, it is still far from an insightful and
trustworthy collaborator in the scientific process. Most existing AI methods
are either too simplistic to be useful in real problems faced by scientists or
too domain-specialized (even dogmatized), stifling transformative discoveries
or paradigm shifts. We present an AI research associate for early-stage
scientific discovery based on (a) a novel minimally-biased ontology for
physics-based modeling that is context-aware, interpretable, and generalizable
across classical and relativistic physics; (b) automatic search for viable and
parsimonious hypotheses, represented at a high-level (via domain-agnostic
constructs) with built-in invariants, e.g., postulated forms of conservation
principles implied by a presupposed spacetime topology; and (c) automatic
compilation of the enumerated hypotheses to domain-specific, interpretable, and
trainable/testable tensor-based computation graphs to learn phenomenological
relations, e.g., constitutive or material laws, from sparse (and possibly
noisy) data sets.</p>
  </details>
</details>
<details>
  <summary>11. <b>标题：A Conditional Perspective on the Logic of Iterated Belief Contraction</b></summary>
  <p><b>编号</b>：[79]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03196</p>
  <p><b>作者</b>：Kai Sauerwald,  Gabriele Kern-Isberner,  Christoph Beierle</p>
  <p><b>备注</b>：This is a largely extended version of the following conference paper: Kai Sauerwald, Gabriele Kern-Isberner, Christoph Beierle: A Conditional Perspective for Iterated Belief Contraction. ECAI 2020: 889-896 this https URL (see also arXiv:1911.08833 )</p>
  <p><b>关键词</b>：provide semantic characterization theorems, provide novel syntactic counterparts, evaluate four groups, alpha $- equivalence, consider semantic postulates</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this article, we consider iteration principles for contraction, with the
goal of identifying properties for contractions that respect conditional
beliefs. Therefore, we investigate and evaluate four groups of iteration
principles for contraction which consider the dynamics of conditional beliefs.
For all these principles, we provide semantic characterization theorems and
provide formulations by postulates which highlight how the change of beliefs
and of conditional beliefs is constrained, whenever that is possible. The first
group is similar to the syntactic Darwiche-Pearl postulates. As a second group,
we consider semantic postulates for iteration of contraction by Chopra, Ghose,
Meyer and Wong, and by Konieczny and Pino Pérez, respectively, and we provide
novel syntactic counterparts. Third, we propose a contraction analogue of the
independence condition by Jin and Thielscher. For the fourth group, we consider
natural and moderate contraction by Nayak. Methodically, we make use of
conditionals for contractions, so-called contractionals and furthermore, we
propose and employ the novel notion of $ \alpha $-equivalence for formulating
some of the new postulates.</p>
  </details>
</details>
<details>
  <summary>12. <b>标题：Reward is not enough: can we liberate AI from the reinforcement learning  paradigm?</b></summary>
  <p><b>编号</b>：[82]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03192</p>
  <p><b>作者</b>：Vacslav Glukhov</p>
  <p><b>备注</b>：17 pages, 1 figure</p>
  <p><b>关键词</b>：explain many activities associated, robust artificially intelligent agents, artificial intelligence including knowledge, reductio ad lucrum, hypothesis put forward</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>I present arguments against the hypothesis put forward by Silver, Singh,
Precup, and Sutton (
this https URL ) : reward
maximization is not enough to explain many activities associated with natural
and artificial intelligence including knowledge, learning, perception, social
intelligence, evolution, language, generalisation and imitation. I show such
reductio ad lucrum has its intellectual origins in the political economy of
Homo economicus and substantially overlaps with the radical version of
behaviourism. I show why the reinforcement learning paradigm, despite its
demonstrable usefulness in some practical application, is an incomplete
framework for intelligence -- natural and artificial. Complexities of
intelligent behaviour are not simply second-order complications on top of
reward maximisation. This fact has profound implications for the development of
practically usable, smart, safe and robust artificially intelligent agents.</p>
  </details>
</details>
<details>
  <summary>13. <b>标题：Efficient Autoprecoder-based deep learning for massive MU-MIMO Downlink  under PA Non-Linearities</b></summary>
  <p><b>编号</b>：[83]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03190</p>
  <p><b>作者</b>：Xinying Cheng (CNAM, CEDRIC - LAETITIA),  Rafik Zayani (CEA-LETI),  Marin Ferecatu (CNAM, CEDRIC - VERTIGO),  Nicolas Audebert (CNAM, CEDRIC - VERTIGO)</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：varying block fading channel scenario, mmimo approach achieves competitive performance, significantly lower complexity compared, serves multiple user terminals, based deep learning approach</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper introduces a new efficient autoprecoder (AP) based deep learning
approach for massive multiple-input multiple-output (mMIMO) downlink systems in
which the base station is equipped with a large number of antennas with
energy-efficient power amplifiers (PAs) and serves multiple user terminals. We
present AP-mMIMO, a new method that jointly eliminates the multiuser
interference and compensates the severe nonlinear (NL) PA distortions. Unlike
previous works, AP-mMIMO has a low computational complexity, making it suitable
for a global energy-efficient system. Specifically, we aim to design the
PA-aware precoder and the receive decoder by leveraging the concept of
autoprecoder, whereas the end-to-end massive multiuser (MU)-MIMO downlink is
designed using a deep neural network (NN). Most importantly, the proposed
AP-mMIMO is suited for the varying block fading channel scenario. To deal with
such scenarios, we consider a two-stage precoding scheme: 1) a NN-precoder is
used to address the PA non-linearities and 2) a linear precoder is used to
suppress the multiuser interference. The NN-precoder and the receive decoder
are trained off-line and when the channel varies, only the linear precoder
changes on-line. This latter is designed by using the widely used zero-forcing
precoding scheme or its lowcomplexity version based on matrix polynomials.
Numerical simulations show that the proposed AP-mMIMO approach achieves
competitive performance with a significantly lower complexity compared to
existing literature. Index Terms-multiuser (MU) precoding, massive
multipleinput multiple-output (MIMO), energy-efficiency, hardware impairment,
power amplifier (PA) nonlinearities, autoprecoder, deep learning, neural
network (NN)</p>
  </details>
</details>
<details>
  <summary>14. <b>标题：Knowledge-Integrated Informed AI for National Security</b></summary>
  <p><b>编号</b>：[85]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03188</p>
  <p><b>作者</b>：Anu K. Myne,  Kevin J. Leahy,  Ryan J. Soklaski</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：suggest worthwhile future research directions, apparent trade space across variants, two broad categories emerge, integrated informed ai stand, integrated informed ai ."</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The state of artificial intelligence technology has a rich history that dates
back decades and includes two fall-outs before the explosive resurgence of
today, which is credited largely to data-driven techniques. While AI technology
has and continues to become increasingly mainstream with impact across domains
and industries, it's not without several drawbacks, weaknesses, and potential
to cause undesired effects. AI techniques are numerous with many approaches and
variants, but they can be classified simply based on the degree of knowledge
they capture and how much data they require; two broad categories emerge as
prominent across AI to date: (1) techniques that are primarily, and often
solely, data-driven while leveraging little to no knowledge and (2) techniques
that primarily leverage knowledge and depend less on data. Now, a third
category is starting to emerge that leverages both data and knowledge, that
some refer to as "informed AI." This third category can be a game changer
within the national security domain where there is ample scientific and
domain-specific knowledge that stands ready to be leveraged, and where purely
data-driven AI can lead to serious unwanted consequences.
This report shares findings from a thorough exploration of AI approaches that
exploit data as well as principled and/or practical knowledge, which we refer
to as "knowledge-integrated informed AI." Specifically, we review illuminating
examples of knowledge integrated in deep learning and reinforcement learning
pipelines, taking note of the performance gains they provide. We also discuss
an apparent trade space across variants of knowledge-integrated informed AI,
along with observed and prominent issues that suggest worthwhile future
research directions. Most importantly, this report suggests how the advantages
of knowledge-integrated informed AI stand to benefit the national security
domain.</p>
  </details>
</details>
<details>
  <summary>15. <b>标题：TransFollower: Long-Sequence Car-Following Trajectory Prediction through  Transformer</b></summary>
  <p><b>编号</b>：[88]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03183</p>
  <p><b>作者</b>：Meixin Zhu,  Simon S. Du,  Xuesong Wang, Hao (Frank) Yang,  Ziyuan Pu,  Yinhai Wang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：fully connected neural network model, historical driving context using multi, predicted future fv speed profile, one vehicle follows another vehicle, following trajectory prediction model based</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Car-following refers to a control process in which the following vehicle (FV)
tries to keep a safe distance between itself and the lead vehicle (LV) by
adjusting its acceleration in response to the actions of the vehicle ahead. The
corresponding car-following models, which describe how one vehicle follows
another vehicle in the traffic flow, form the cornerstone for microscopic
traffic simulation and intelligent vehicle development. One major motivation of
car-following models is to replicate human drivers' longitudinal driving
trajectories. To model the long-term dependency of future actions on historical
driving situations, we developed a long-sequence car-following trajectory
prediction model based on the attention-based Transformer model. The model
follows a general format of encoder-decoder architecture. The encoder takes
historical speed and spacing data as inputs and forms a mixed representation of
historical driving context using multi-head self-attention. The decoder takes
the future LV speed profile as input and outputs the predicted future FV speed
profile in a generative way (instead of an auto-regressive way, avoiding
compounding errors). Through cross-attention between encoder and decoder, the
decoder learns to build a connection between historical driving and future LV
speed, based on which a prediction of future FV speed can be obtained. We train
and test our model with 112,597 real-world car-following events extracted from
the Shanghai Naturalistic Driving Study (SH-NDS). Results show that the model
outperforms the traditional intelligent driver model (IDM), a fully connected
neural network model, and a long short-term memory (LSTM) based model in terms
of long-sequence trajectory prediction accuracy. We also visualized the
self-attention and cross-attention heatmaps to explain how the model derives
its predictions.</p>
  </details>
</details>
<details>
  <summary>16. <b>标题：Towards Loosely-Coupling Knowledge Graph Embeddings and Ontology-based  Reasoning</b></summary>
  <p><b>编号</b>：[92]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03173</p>
  <p><b>作者</b>：Zoi Kaoudi,  Abelardo Carlos Martinez Lorenzo,  Volker Markl</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：g ., owl2 )., .~ link prediction ),, vanilla knowledge graph embeddings, input knowledge graph contains, combine knowledge graph embeddings</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Knowledge graph completion (a.k.a.~link prediction), i.e.,~the task of
inferring missing information from knowledge graphs, is a widely used task in
many applications, such as product recommendation and question answering. The
state-of-the-art approaches of knowledge graph embeddings and/or rule mining
and reasoning are data-driven and, thus, solely based on the information the
input knowledge graph contains. This leads to unsatisfactory prediction results
which make such solutions inapplicable to crucial domains such as healthcare.
To further enhance the accuracy of knowledge graph completion we propose to
loosely-couple the data-driven power of knowledge graph embeddings with
domain-specific reasoning stemming from experts or entailment regimes (e.g.,
OWL2). In this way, we not only enhance the prediction accuracy with domain
knowledge that may not be included in the input knowledge graph but also allow
users to plugin their own knowledge graph embedding and reasoning method. Our
initial results show that we enhance the MRR accuracy of vanilla knowledge
graph embeddings by up to 3x and outperform hybrid solutions that combine
knowledge graph embeddings with rule mining and reasoning up to 3.5x MRR.</p>
  </details>
</details>
<details>
  <summary>17. <b>标题：The 6-Ds of Creating AI-Enabled Systems</b></summary>
  <p><b>编号</b>：[93]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03172</p>
  <p><b>作者</b>：John Piorkowski</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：precision medicine use case, ineffective approaches towards navigating, previous ai hype cycles, identify potential ai solutions, current artificial intelligence</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We are entering our tenth year of the current Artificial Intelligence (AI)
spring, and, as with previous AI hype cycles, the threat of an AI winter looms.
AI winters occurred because of ineffective approaches towards navigating the
technology valley of death. The 6-D framework provides an end-to-end framework
to successfully navigate this challenge. The 6-D framework starts with problem
decomposition to identify potential AI solutions, and ends with considerations
for deployment of AI-enabled systems. Each component of the 6-D framework and a
precision medicine use case is described in this paper.</p>
  </details>
</details>
<details>
  <summary>18. <b>标题：CITRIS: Causal Identifiability from Temporal Intervened Sequences</b></summary>
  <p><b>编号</b>：[94]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03169</p>
  <p><b>作者</b>：Phillip Lippe,  Sara Magliacane,  Sindy Löwe,  Yuki M. Asano,  Taco Cohen,  Efstratios Gavves</p>
  <p><b>备注</b>：46 pages</p>
  <p><b>关键词</b>：crucial step towards agents reasoning, opening future research areas, 3d rendered image sequences, citris outperforms previous methods, extending previous results</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Understanding the latent causal factors of a dynamical system from visual
observations is a crucial step towards agents reasoning in complex
environments. In this paper, we propose CITRIS, a variational autoencoder
framework that learns causal representations from temporal sequences of images
in which underlying causal factors have possibly been intervened upon. In
contrast to the recent literature, CITRIS exploits temporality and observing
intervention targets to identify scalar and multidimensional causal factors,
such as 3D rotation angles. Furthermore, by introducing a normalizing flow,
CITRIS can be easily extended to leverage and disentangle representations
obtained by already pretrained autoencoders. Extending previous results on
scalar causal factors, we prove identifiability in a more general setting, in
which only some components of a causal factor are affected by interventions. In
experiments on 3D rendered image sequences, CITRIS outperforms previous methods
on recovering the underlying causal variables. Moreover, using pretrained
autoencoders, CITRIS can even generalize to unseen instantiations of causal
factors, opening future research areas in sim-to-real generalization for causal
representation learning.</p>
  </details>
</details>
<details>
  <summary>19. <b>标题：Conversational Agents: Theory and Applications</b></summary>
  <p><b>编号</b>：[96]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03164</p>
  <p><b>作者</b>：Mattias Wahde,  Marco Virgolin</p>
  <p><b>备注</b>：preprint of a chapter to appear in Handbook of Computer Learning and Intelligence - Volume 1</p>
  <p><b>关键词</b>：cas ), discussing chatbots, potential risks regarding, many different approaches, future ca technology, briefly reviewing aspects</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this chapter, we provide a review of conversational agents (CAs),
discussing chatbots, intended for casual conversation with a user, as well as
task-oriented agents that generally engage in discussions intended to reach one
or several specific goals, often (but not always) within a specific domain. We
also consider the concept of embodied conversational agents, briefly reviewing
aspects such as character animation and speech processing. The many different
approaches for representing dialogue in CAs are discussed in some detail, along
with methods for evaluating such agents, emphasizing the important topics of
accountability and interpretability. A brief historical overview is given,
followed by an extensive overview of various applications, especially in the
fields of health and education. We end the chapter by discussing benefits and
potential risks regarding the societal impact of current and future CA
technology.</p>
  </details>
</details>
<details>
  <summary>20. <b>标题：Existence and perception as the basis of AGI (Artificial General  Intelligence)</b></summary>
  <p><b>编号</b>：[99]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03155</p>
  <p><b>作者</b>：Victor V. Senkevich</p>
  <p><b>备注</b>：11 pages</p>
  <p><b>关键词</b>：artificial general intelligence ), unlike ai, face recognition etc .), successful ai implementations, emulates human thinking, related cognitive concepts</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As is known, AGI (Artificial General Intelligence), unlike AI, should operate
with meanings. And that's what distinguishes it from AI. Any successful AI
implementations (playing chess, unmanned driving, face recognition etc.) do not
operate with the meanings of the processed objects in any way and do not
recognize the meaning. And they don't need to. But for AGI, which emulates
human thinking, this ability is crucial. Numerous attempts to define the
concept of "meaning" have one very significant drawback - all such definitions
are not strict and formalized, so they cannot be programmed. The meaning search
procedure should use a formalized description of its existence and possible
forms of its perception. For the practical implementation of AGI, it is
necessary to develop such "ready-to-code" descriptions in the context of their
use for processing the related cognitive concepts of "meaning" and "knowledge".
An attempt to formalize the definition of such concepts is made in this
article.</p>
  </details>
</details>
<details>
  <summary>21. <b>标题：Approaches to Artificial General Intelligence: An Analysis</b></summary>
  <p><b>编号</b>：[100]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03153</p>
  <p><b>作者</b>：Soumil Rathi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：including human brain emulation, human brain emulation, human brain emulation, require scanning technologies, integrated cognitive architectures</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper is an analysis of the different methods proposed to achieve AGI,
including Human Brain Emulation, AIXI and Integrated Cognitive Architecture.
First, the definition of AGI as used in this paper has been defined, and its
requirements have been stated. For each proposed method mentioned, the method
in question was summarized and its key processes were detailed, showcasing how
it functioned. Then, each method listed was analyzed, taking various factors
into consideration, such as technological requirements, computational ability,
and adequacy to the requirements. It was concluded that while there are various
methods to achieve AGI that could work, such as Human Brain Emulation and
Integrated Cognitive Architectures, the most promising method to achieve AGI is
Integrated Cognitive Architectures. This is because Human Brain Emulation was
found to require scanning technologies that will most likely not be available
until the 2030s, making it unlikely to be created before then. Moreover,
Integrated Cognitive Architectures has reduced computational requirements and a
suitable functionality for General Intelligence, making it the most likely way
to achieve AGI.</p>
  </details>
</details>
<details>
  <summary>22. <b>标题：OPP-Miner: Order-preserving sequential pattern mining</b></summary>
  <p><b>编号</b>：[106]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03140</p>
  <p><b>作者</b>：Youxi Wu,  Qian Hu,  Yan Li,  Lei Guo,  Xingquan Zhu,  Xindong Wu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：existing methods often convert time series data, existing methods mainly neglect, uses pattern fusion strategy, also discover similar sub, time series data</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A time series is a collection of measurements in chronological order.
Discovering patterns from time series is useful in many domains, such as stock
analysis, disease detection, and weather forecast. To discover patterns,
existing methods often convert time series data into another form, such as
nominal/symbolic format, to reduce dimensionality, which inevitably deviates
the data values. Moreover, existing methods mainly neglect the order
relationships between time series values. To tackle these issues, inspired by
order-preserving matching, this paper proposes an Order-Preserving sequential
Pattern (OPP) mining method, which represents patterns based on the order
relationships of the time series data. An inherent advantage of such
representation is that the trend of a time series can be represented by the
relative order of the values underneath the time series data. To obtain
frequent trends in time series, we propose the OPP-Miner algorithm to mine
patterns with the same trend (sub-sequences with the same relative order).
OPP-Miner employs the filtration and verification strategies to calculate the
support and uses pattern fusion strategy to generate candidate patterns. To
compress the result set, we also study finding the maximal OPPs. Experiments
validate that OPP-Miner is not only efficient and scalable but can also
discover similar sub-sequences in time series. In addition, case studies show
that our algorithms have high utility in analyzing the COVID-19 epidemic by
identifying critical trends and improve the clustering performance.</p>
  </details>
</details>
<details>
  <summary>23. <b>标题：Transformers in Self-Supervised Monocular Depth Estimation with Unknown  Camera Intrinsics</b></summary>
  <p><b>编号</b>：[109]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03131</p>
  <p><b>作者</b>：Arnav Varma,  Hemang Chawla,  Bahram Zonooz,  Elahe Arani</p>
  <p><b>备注</b>：Published in 17th International Conference on Computer Vision Theory and Applications (VISAP, 2022)</p>
  <p><b>关键词</b>：advanced driver assistance systems necessitates continuous developments, kitti depth prediction benchmarks, supervised monocular depth estimation, supervised monocular depth estimation, supervised monocular depth estimation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The advent of autonomous driving and advanced driver assistance systems
necessitates continuous developments in computer vision for 3D scene
understanding. Self-supervised monocular depth estimation, a method for
pixel-wise distance estimation of objects from a single camera without the use
of ground truth labels, is an important task in 3D scene understanding.
However, existing methods for this task are limited to convolutional neural
network (CNN) architectures. In contrast with CNNs that use localized linear
operations and lose feature resolution across the layers, vision transformers
process at constant resolution with a global receptive field at every stage.
While recent works have compared transformers against their CNN counterparts
for tasks such as image classification, no study exists that investigates the
impact of using transformers for self-supervised monocular depth estimation.
Here, we first demonstrate how to adapt vision transformers for self-supervised
monocular depth estimation. Thereafter, we compare the transformer and
CNN-based architectures for their performance on KITTI depth prediction
benchmarks, as well as their robustness to natural corruptions and adversarial
attacks, including when the camera intrinsics are unknown. Our study
demonstrates how transformer-based architecture, though lower in run-time
efficiency, achieves comparable performance while being more robust and
generalizable.</p>
  </details>
</details>
<details>
  <summary>24. <b>标题：Combining Deep Learning and Reasoning for Address Detection in  Unstructured Text Documents</b></summary>
  <p><b>编号</b>：[116]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03103</p>
  <p><b>作者</b>：Matthias Engelbach,  Dennis Klau,  Jens Drawehn,  Maximilien Kintz</p>
  <p><b>备注</b>：5 pages, 1 figure, submitted to AAAI-22 workshop CLeaR, peer reviewed</p>
  <p><b>关键词</b>：containing text using domain knowledge represented, sender address would boost many companies, visual deep learning model, crucial document information like, possible address regions</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Extracting information from unstructured text documents is a demanding task,
since these documents can have a broad variety of different layouts and a
non-trivial reading order, like it is the case for multi-column documents or
nested tables. Additionally, many business documents are received in paper
form, meaning that the textual contents need to be digitized before further
analysis. Nonetheless, automatic detection and capturing of crucial document
information like the sender address would boost many companies' processing
efficiency. In this work we propose a hybrid approach that combines deep
learning with reasoning for finding and extracting addresses from unstructured
text documents. We use a visual deep learning model to detect the boundaries of
possible address regions on the scanned document images and validate these
results by analyzing the containing text using domain knowledge represented as
a rule based system.</p>
  </details>
</details>
<details>
  <summary>25. <b>标题：FL_PyTorch: optimization research simulator for federated learning</b></summary>
  <p><b>编号</b>：[118]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03099</p>
  <p><b>作者</b>：Konstantin Burlachenko,  Samuel Horváth,  Peter Richtárik</p>
  <p><b>备注</b>：DistributedML '21: Proceedings of the 2nd ACM International Workshop on Distributed Machine Learning</p>
  <p><b>关键词</b>：run several clients simultaneously using local cpus, even remote compute devices without, shared machine learning model, keeping training data locally, popular research deep learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Federated Learning (FL) has emerged as a promising technique for edge devices
to collaboratively learn a shared machine learning model while keeping training
data locally on the device, thereby removing the need to store and access the
full data in the cloud. However, FL is difficult to implement, test and deploy
in practice considering heterogeneity in common edge device settings, making it
fundamentally hard for researchers to efficiently prototype and test their
optimization algorithms. In this work, our aim is to alleviate this problem by
introducing FL_PyTorch : a suite of open-source software written in python that
builds on top of one the most popular research Deep Learning (DL) framework
PyTorch. We built FL_PyTorch as a research simulator for FL to enable fast
development, prototyping and experimenting with new and existing FL
optimization algorithms. Our system supports abstractions that provide
researchers with a sufficient level of flexibility to experiment with existing
and novel approaches to advance the state-of-the-art. Furthermore, FL_PyTorch
is a simple to use console system, allows to run several clients simultaneously
using local CPUs or GPU(s), and even remote compute devices without the need
for any distributed implementation provided by the user. FL_PyTorch also offers
a Graphical User Interface. For new methods, researchers only provide the
centralized implementation of their algorithm. To showcase the possibilities
and usefulness of our system, we experiment with several well-known
state-of-the-art FL algorithms and a few of the most common FL datasets.</p>
  </details>
</details>
<details>
  <summary>26. <b>标题：Auto-Lambda: Disentangling Dynamic Task Relationships</b></summary>
  <p><b>编号</b>：[122]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03091</p>
  <p><b>作者</b>：Shikun Liu,  Stephen James,  Andrew J. Davison,  Edward Johns</p>
  <p><b>备注</b>：Tech Report. Project Page: this https URL Code: this https URL</p>
  <p><b>关键词</b>：validation loss automatically influences task weightings throughout training, dynamic task relationships via task, optimisation strategies designed specifically, extremely high computational cost, learn task relationships via</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Understanding the structure of multiple related tasks allows for multi-task
learning to improve the generalisation ability of one or all of them. However,
it usually requires training each pairwise combination of tasks together in
order to capture task relationships, at an extremely high computational cost.
In this work, we learn task relationships via an automated weighting framework,
named Auto-Lambda. Unlike previous methods where task relationships are assumed
to be fixed, Auto-Lambda is a gradient-based meta learning framework which
explores continuous, dynamic task relationships via task-specific weightings,
and can optimise any choice of combination of tasks through the formulation of
a meta-loss; where the validation loss automatically influences task weightings
throughout training. We apply the proposed framework to both multi-task and
auxiliary learning problems in computer vision and robotics, and show that
Auto-Lambda achieves state-of-the-art performance, even when compared to
optimisation strategies designed specifically for each problem and data domain.
Finally, we observe that Auto-Lambda can discover interesting learning
behaviors, leading to new insights in multi-task learning. Code is available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>27. <b>标题：Artificial Intelligence based tool wear and defect prediction for  special purpose milling machinery using low-cost acceleration sensor  retrofits</b></summary>
  <p><b>编号</b>：[133]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03068</p>
  <p><b>作者</b>：Mahmoud Kheir-Eddine,  Michael Banf,  Gregor Steinhagen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：several machine learning based approaches, many industrial processing chains, insufficient transmission belt tension, edge classification setup comes, since retrofitting older machines</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Milling machines form an integral part of many industrial processing chains.
As a consequence, several machine learning based approaches for tool wear
detection have been proposed in recent years, yet these methods mostly deal
with standard milling machines, while machinery designed for more specialized
tasks has gained only limited attention so far. This paper demonstrates the
application of an acceleration sensor to allow for convenient condition
monitoring of such a special purpose machine, i.e. round seam milling machine.
We examine a variety of conditions including blade wear and blade breakage as
well as improper machine mounting or insufficient transmission belt tension. In
addition, we presents different approaches to supervised failure recognition
with limited amounts of training data. Hence, aside theoretical insights, our
analysis is of high, practical importance, since retrofitting older machines
with acceleration sensors and an on-edge classification setup comes at low cost
and effort, yet provides valuable insights into the state of the machine and
tools in particular and the production process in general.</p>
  </details>
</details>
<details>
  <summary>28. <b>标题：Evaluation of Runtime Monitoring for UAV Emergency Landing</b></summary>
  <p><b>编号</b>：[136]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03059</p>
  <p><b>作者</b>：Joris Guerin,  Kevin Delmas,  Jérémie Guiochet</p>
  <p><b>备注</b>：7 pages, 4 figures, 1 table. To appear in the proceedings of 2022 IEEE International Conference on Robotics and Automation (ICRA)</p>
  <p><b>关键词</b>：finding safe landing areas using, proposed el pipeline includes mechanisms, monitor learning based components, machine learning runtime monitoring, risk mitigation strategies --</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>To certify UAV operations in populated areas, risk mitigation strategies --
such as Emergency Landing (EL) -- must be in place to account for potential
failures. EL aims at reducing ground risk by finding safe landing areas using
on-board sensors. The first contribution of this paper is to present a new EL
approach, in line with safety requirements introduced in recent research. In
particular, the proposed EL pipeline includes mechanisms to monitor learning
based components during execution. This way, another contribution is to study
the behavior of Machine Learning Runtime Monitoring (MLRM) approaches within
the context of a real-world critical system. A new evaluation methodology is
introduced, and applied to assess the practical safety benefits of three MLRM
mechanisms. The proposed approach is compared to a default mitigation strategy
(open a parachute when a failure is detected), and appears to be much safer.</p>
  </details>
</details>
<details>
  <summary>29. <b>标题：Multi-Objective Quality Diversity Optimization</b></summary>
  <p><b>编号</b>：[138]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03057</p>
  <p><b>作者</b>：Thomas Pierrot,  Guillaume Richard,  Karim Beguir,  Antoine Cully</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：life problems exhibit several potentially antagonist objectives, providing global performances similar, standard optimization problems, performing solutions instead, exploring different compromises</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this work, we consider the problem of Quality-Diversity (QD) optimization
with multiple objectives. QD algorithms have been proposed to search for a
large collection of both diverse and high-performing solutions instead of a
single set of local optima. Thriving for diversity was shown to be useful in
many industrial and robotics applications. On the other hand, most real-life
problems exhibit several potentially antagonist objectives to be optimized.
Hence being able to optimize for multiple objectives with an appropriate
technique while thriving for diversity is important to many fields. Here, we
propose an extension of the MAP-Elites algorithm in the multi-objective
setting: Multi-Objective MAP-Elites (MOME). Namely, it combines the diversity
inherited from the MAP-Elites grid algorithm with the strength of
multi-objective optimizations by filling each cell with a Pareto Front. As
such, it allows to extract diverse solutions in the descriptor space while
exploring different compromises between objectives. We evaluate our method on
several tasks, from standard optimization problems to robotics simulations. Our
experimental evaluation shows the ability of MOME to provide diverse solutions
while providing global performances similar to standard multi-objective
algorithms.</p>
  </details>
</details>
<details>
  <summary>30. <b>标题：Data set creation and empirical analysis for detecting signs of  depression from social media postings</b></summary>
  <p><b>编号</b>：[143]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03047</p>
  <p><b>作者</b>：Kayalvizhi S,  Thenmozhi D</p>
  <p><b>备注</b>：12 pages</p>
  <p><b>关键词</b>：mental health using social media data, diagnosing mental health using, gold standard data set, social media data, social media data</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Depression is a common mental illness that has to be detected and treated at
an early stage to avoid serious consequences. There are many methods and
modalities for detecting depression that involves physical examination of the
individual. However, diagnosing mental health using their social media data is
more effective as it avoids such physical examinations. Also, people express
their emotions well in social media, it is desirable to diagnose their mental
health using social media data. Though there are many existing systems that
detects mental illness of a person by analysing their social media data,
detecting the level of depression is also important for further treatment.
Thus, in this research, we developed a gold standard data set that detects the
levels of depression as `not depressed', `moderately depressed' and `severely
depressed' from the social media postings. Traditional learning algorithms were
employed on this data set and an empirical analysis was presented in this
paper. Data augmentation technique was applied to overcome the data imbalance.
Among the several variations that are implemented, the model with Word2Vec
vectorizer and Random Forest classifier on augmented data outperforms the other
variations with a score of 0.877 for both accuracy and F1 measure.</p>
  </details>
</details>
<details>
  <summary>31. <b>标题：Mental Stress Detection using Data from Wearable and Non-wearable  Sensors: A Review</b></summary>
  <p><b>编号</b>：[149]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03033</p>
  <p><b>作者</b>：Aamir Arsalan,  Syed Muhammad Anwar,  Muhammad Majid</p>
  <p><b>备注</b>：Under Review in Artificial Intelligence Review</p>
  <p><b>关键词</b>：measuring human stress responses could include subjective questionnaires, objective human stress detection techniques available, future research enabling effective detection, artificial intelligence utilizing relevant data, objective markers observed using data</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper presents a comprehensive review of methods covering significant
subjective and objective human stress detection techniques available in the
literature. The methods for measuring human stress responses could include
subjective questionnaires (developed by psychologists) and objective markers
observed using data from wearable and non-wearable sensors. In particular,
wearable sensor-based methods commonly use data from electroencephalography,
electrocardiogram, galvanic skin response, electromyography, electrodermal
activity, heart rate, heart rate variability, and photoplethysmography both
individually and in multimodal fusion strategies. Whereas, methods based on
non-wearable sensors include strategies such as analyzing pupil dilation and
speech, smartphone data, eye movement, body posture, and thermal imaging.
Whenever a stressful situation is encountered by an individual, physiological,
physical, or behavioral changes are induced which help in coping with the
challenge at hand. A wide range of studies has attempted to establish a
relationship between these stressful situations and the response of human
beings by using different kinds of psychological, physiological, physical, and
behavioral measures. Inspired by the lack of availability of a definitive
verdict about the relationship of human stress with these different kinds of
markers, a detailed survey about human stress detection methods is conducted in
this paper. In particular, we explore how stress detection methods can benefit
from artificial intelligence utilizing relevant data from various sources. This
review will prove to be a reference document that would provide guidelines for
future research enabling effective detection of human stress conditions.</p>
  </details>
</details>
<details>
  <summary>32. <b>标题：Graph Self-supervised Learning with Accurate Discrepancy Learning</b></summary>
  <p><b>编号</b>：[164]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02989</p>
  <p><b>作者</b>：Dongki Kim,  Jinheon Baek,  Sung Ju Hwang</p>
  <p><b>备注</b>：8 pages</p>
  <p><b>关键词</b>：two differently perturbed graphs may result, model largely outperforms relevant baselines, cannot discriminate two similar graphs, including molecular property prediction, cannot learn global graph</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Self-supervised learning of graph neural networks (GNNs) aims to learn an
accurate representation of the graphs in an unsupervised manner, to obtain
transferable representations of them for diverse downstream tasks. Predictive
learning and contrastive learning are the two most prevalent approaches for
graph self-supervised learning. However, they have their own drawbacks. While
the predictive learning methods can learn the contextual relationships between
neighboring nodes and edges, they cannot learn global graph-level similarities.
Contrastive learning, while it can learn global graph-level similarities, its
objective to maximize the similarity between two differently perturbed graphs
may result in representations that cannot discriminate two similar graphs with
different properties. To tackle such limitations, we propose a framework that
aims to learn the exact discrepancy between the original and the perturbed
graphs, coined as Discrepancy-based Self-supervised LeArning (D-SLA).
Specifically, we create multiple perturbations of the given graph with varying
degrees of similarity and train the model to predict whether each graph is the
original graph or a perturbed one. Moreover, we further aim to accurately
capture the amount of discrepancy for each perturbed graph using the graph edit
distance. We validate our method on various graph-related downstream tasks,
including molecular property prediction, protein function prediction, and link
prediction tasks, on which our model largely outperforms relevant baselines.</p>
  </details>
</details>
<details>
  <summary>33. <b>标题：Measuring and Reducing Model Update Regression in Structured Prediction  for NLP</b></summary>
  <p><b>编号</b>：[168]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02976</p>
  <p><b>作者</b>：Deng Cai,  Elman Mansimov,  Yi-An Lai,  Yixuan Su,  Lei Shu,  Yi Zhang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：reducing model update regression including model ensemble, work studies model update regression, better mitigate model update regression, machine learning based nlp models, analyze model update regression</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent advance in deep learning has led to rapid adoption of machine learning
based NLP models in a wide range of applications. Despite the continuous gain
in accuracy, backward compatibility is also an important aspect for industrial
applications, yet it received little research attention. Backward compatibility
requires that the new model does not regress on cases that were correctly
handled by its predecessor. This work studies model update regression in
structured prediction tasks. We choose syntactic dependency parsing and
conversational semantic parsing as representative examples of structured
prediction tasks in NLP. First, we measure and analyze model update regression
in different model update settings. Next, we explore and benchmark existing
techniques for reducing model update regression including model ensemble and
knowledge distillation. We further propose a simple and effective method,
Backward-Congruent Re-ranking (BCR), by taking into account the characteristics
of structured output. Experiments show that BCR can better mitigate model
update regression than model ensemble and knowledge distillation approaches.</p>
  </details>
</details>
<details>
  <summary>34. <b>标题：Locally Differentially Private Distributed Deep Learning via Knowledge  Distillation</b></summary>
  <p><b>编号</b>：[172]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02971</p>
  <p><b>作者</b>：Di Zhuang,  Mingchen Li,  J. Morris Chang</p>
  <p><b>备注</b>：10 pages, 6 figures, 1 table. Submitted to IEEE Transactions on Knowledge and Data Engineering</p>
  <p><b>关键词</b>：preserving distributed deep learning framework via local differential privacy, using three popular deep learning benchmark datasets, data segregated across multiple different data owners, often segregated across multiple organizations, conduct distributed deep learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep learning often requires a large amount of data. In real-world
applications, e.g., healthcare applications, the data collected by a single
organization (e.g., hospital) is often limited, and the majority of massive and
diverse data is often segregated across multiple organizations. As such, it
motivates the researchers to conduct distributed deep learning, where the data
user would like to build DL models using the data segregated across multiple
different data owners. However, this could lead to severe privacy concerns due
to the sensitive nature of the data, thus the data owners would be hesitant and
reluctant to participate. We propose LDP-DL, a privacy-preserving distributed
deep learning framework via local differential privacy and knowledge
distillation, where each data owner learns a teacher model using its own
(local) private dataset, and the data user learns a student model to mimic the
output of the ensemble of the teacher models. In the experimental evaluation, a
comprehensive comparison has been made among our proposed approach (i.e.,
LDP-DL), DP-SGD, PATE and DP-FL, using three popular deep learning benchmark
datasets (i.e., CIFAR10, MNIST and FashionMNIST). The experimental results show
that LDP-DL consistently outperforms the other competitors in terms of privacy
budget and model accuracy.</p>
  </details>
</details>
<details>
  <summary>35. <b>标题：Jury Learning: Integrating Dissenting Voices into Machine Learning  Models</b></summary>
  <p><b>编号</b>：[180]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02950</p>
  <p><b>作者</b>：Mitchell L. Gordon,  Michelle S. Lam,  Joon Sung Park,  Kayur Patel,  Jeffrey T. Hancock,  Tatsunori Hashimoto,  Michael S. Bernstein</p>
  <p><b>备注</b>：To appear at CHI 2022</p>
  <p><b>关键词</b>：label disagreements implicitly using majority vote, online toxicity might centrally feature women, supervised ml today resolves, online comment toxicity, supervised ml approach</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Whose labels should a machine learning (ML) algorithm learn to emulate? For
ML tasks ranging from online comment toxicity to misinformation detection to
medical diagnosis, different groups in society may have irreconcilable
disagreements about ground truth labels. Supervised ML today resolves these
label disagreements implicitly using majority vote, which overrides minority
groups' labels. We introduce jury learning, a supervised ML approach that
resolves these disagreements explicitly through the metaphor of a jury:
defining which people or groups, in what proportion, determine the classifier's
prediction. For example, a jury learning model for online toxicity might
centrally feature women and Black jurors, who are commonly targets of online
harassment. To enable jury learning, we contribute a deep learning architecture
that models every annotator in a dataset, samples from annotators' models to
populate the jury, then runs inference to classify. Our architecture enables
juries that dynamically adapt their composition, explore counterfactuals, and
visualize dissent.</p>
  </details>
</details>
<details>
  <summary>36. <b>标题：Parallel Successive Learning for Dynamic Distributed Model Training over  Heterogeneous Wireless Networks</b></summary>
  <p><b>编号</b>：[182]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02947</p>
  <p><b>作者</b>：Seyyedali Hosseinalipour,  Su Wang,  Nicolo Michelusi,  Vaneet Aggarwal,  Christopher G. Brinton,  David J. Love,  Mung Chiang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：numerical results reveal new findings, fedl architecture along three dimensions, stochastic gradient descent iterations, allowing decentralized cooperation among, hard signomial programming problem</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Federated learning (FedL) has emerged as a popular technique for distributing
model training over a set of wireless devices, via iterative local updates (at
devices) and global aggregations (at the server). In this paper, we develop
\textit{parallel successive learning} (PSL), which expands the FedL
architecture along three dimensions: (i) Network, allowing decentralized
cooperation among the devices via device-to-device (D2D) communications. (ii)
Heterogeneity, interpreted at three levels: (ii-a) Learning: PSL considers
heterogeneous number of stochastic gradient descent iterations with different
mini-batch sizes at the devices; (ii-b) Data: PSL presumes a dynamic
environment with data arrival and departure, where the distributions of local
datasets evolve over time, captured via a new metric for model/concept drift.
(ii-c) Device: PSL considers devices with different computation and
communication capabilities. (iii) Proximity, where devices have different
distances to each other and the access point. PSL considers the realistic
scenario where global aggregations are conducted with idle times in-between
them for resource efficiency improvements, and incorporates data dispersion and
model dispersion with local model condensation into FedL. Our analysis sheds
light on the notion of cold vs. warmed up models, and model inertia in
distributed machine learning. We then propose network-aware dynamic model
tracking to optimize the model learning vs. resource efficiency tradeoff, which
we show is an NP-hard signomial programming problem. We finally solve this
problem through proposing a general optimization solver. Our numerical results
reveal new findings on the interdependencies between the idle times in-between
the global aggregations, model/concept drift, and D2D cooperation
configuration.</p>
  </details>
</details>
<details>
  <summary>37. <b>标题：Prompt-Guided Injection of Conformation to Pre-trained Protein Model</b></summary>
  <p><b>编号</b>：[183]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02944</p>
  <p><b>作者</b>：Qiang Zhang,  Zeyuan Wang,  Yuqiang Han,  Haoran Yu,  Xurui Jin,  Huajun Chen</p>
  <p><b>备注</b>：Work in progress</p>
  <p><b>关键词</b>：conformation prompt significantly improves ptpms, masked language modeling task, various biological processes, prior ptpm optimization, one fixed embedding</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Pre-trained protein models (PTPMs) represent a protein with one fixed
embedding and thus are not capable for diverse tasks. For example, protein
structures can shift, namely protein folding, between several conformations in
various biological processes. To enable PTPMs to produce task-aware
representations, we propose to learn interpretable, pluggable and extensible
protein prompts as a way of injecting task-related knowledge into PTPMs. In
this regard, prior PTPM optimization with the masked language modeling task can
be interpreted as learning a sequence prompt (Seq prompt) that enables PTPMs to
capture the sequential dependency between amino acids. To incorporate
conformational knowledge to PTPMs, we propose an interaction-conformation
prompt (IC prompt) that is learned through back-propagation with the
protein-protein interaction task. As an instantiation, we present a
conformation-aware pre-trained protein model that learns both sequence and
interaction-conformation prompts in a multi-task setting. We conduct
comprehensive experiments on nine protein datasets. Results confirm our
expectation that using the sequence prompt does not hurt PTPMs' performance on
sequence-related tasks while incorporating the interaction-conformation prompt
significantly improves PTPMs' performance on tasks where conformational
knowledge counts. We also show the learned prompts can be combined and extended
to deal with new complex tasks.</p>
  </details>
</details>
<details>
  <summary>38. <b>标题：Tractable Boolean and Arithmetic Circuits</b></summary>
  <p><b>编号</b>：[184]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02942</p>
  <p><b>作者</b>：Adnan Darwiche</p>
  <p><b>备注</b>：An earlier version of this article appeared in the following edited book. Pascal Hitzler and Md Kamruzzaman Sarker, editors. Neuro-Symbolic Artificial Intelligence: The State of the Art, volume 342 of Frontiers in Artificial Intelligence and Applications. IOS Press, 2021</p>
  <p><b>关键词</b>：forward fashion like neural networks, compiled objects ," meant, permit various types, two decades, tractable boolean</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Tractable Boolean and arithmetic circuits have been studied extensively in AI
for over two decades now. These circuits were initially proposed as "compiled
objects," meant to facilitate logical and probabilistic reasoning, as they
permit various types of inference to be performed in linear-time and a
feed-forward fashion like neural networks. In more recent years, the role of
tractable circuits has significantly expanded as they became a computational
and semantical backbone for some approaches that aim to integrate knowledge,
reasoning and learning. In this article, we review the foundations of tractable
circuits and some associated milestones, while focusing on their core
properties and techniques that make them particularly useful for the broad aims
of neuro-symbolic AI.</p>
  </details>
</details>
<details>
  <summary>39. <b>标题：Soft Actor-Critic with Inhibitory Networks for Faster Retraining</b></summary>
  <p><b>编号</b>：[196]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02918</p>
  <p><b>作者</b>：Jaime S. Ide,  Daria Mićović,  Michael J. Guarino,  Kevin Alcedo,  David Rosenbluth</p>
  <p><b>备注</b>：16 pages including Appendix</p>
  <p><b>关键词</b>：novel approach using inhibitory networks, adaptive state value evaluations, reusing previously trained models, distinct automatic entropy tuning, exploring novel ones</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Reusing previously trained models is critical in deep reinforcement learning
to speed up training of new agents. However, it is unclear how to acquire new
skills when objectives and constraints are in conflict with previously learned
skills. Moreover, when retraining, there is an intrinsic conflict between
exploiting what has already been learned and exploring new skills. In soft
actor-critic (SAC) methods, a temperature parameter can be dynamically adjusted
to weight the action entropy and balance the explore $\times$ exploit
trade-off. However, controlling a single coefficient can be challenging within
the context of retraining, even more so when goals are contradictory. In this
work, inspired by neuroscience research, we propose a novel approach using
inhibitory networks to allow separate and adaptive state value evaluations, as
well as distinct automatic entropy tuning. Ultimately, our approach allows for
controlling inhibition to handle conflict between exploiting less risky,
acquired behaviors and exploring novel ones to overcome more challenging tasks.
We validate our method through experiments in OpenAI Gym environments.</p>
  </details>
</details>
<details>
  <summary>40. <b>标题：Universality of parametric Coupling Flows over parametric  diffeomorphisms</b></summary>
  <p><b>编号</b>：[201]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02906</p>
  <p><b>作者</b>：Junlong Lyu,  Zhitang Chen,  Chang Feng,  Wenjing Cun,  Shengyu Zhu,  Yanhui Geng,  Zhijie Xu,  Yongwei Chen</p>
  <p><b>备注</b>：22 pages, 6 figures</p>
  <p><b>关键词</b>：proposed parametric coupling flows named para, invertible neural networks based, invertible linear transforms achieves, contextual bayesian optimization tasks, coupling flows cflows</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Invertible neural networks based on Coupling Flows CFlows) have various
applications such as image synthesis and data compression. The approximation
universality for CFlows is of paramount importance to ensure the model
expressiveness. In this paper, we prove that CFlows can approximate any
diffeomorphism in C^k-norm if its layers can approximate certain
single-coordinate transforms. Specifically, we derive that a composition of
affine coupling layers and invertible linear transforms achieves this
universality. Furthermore, in parametric cases where the diffeomorphism depends
on some extra parameters, we prove the corresponding approximation theorems for
our proposed parametric coupling flows named Para-CFlows. In practice, we apply
Para-CFlows as a neural surrogate model in contextual Bayesian optimization
tasks, to demonstrate its superiority over other neural surrogate models in
terms of optimization performance.</p>
  </details>
</details>
<details>
  <summary>41. <b>标题：Redactor: Targeted Disinformation Generation using Probabilistic  Decision Boundaries</b></summary>
  <p><b>编号</b>：[204]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02902</p>
  <p><b>作者</b>：Geon Heo,  Steven Euijong Whang</p>
  <p><b>备注</b>：9 pages, 7 figures</p>
  <p><b>关键词</b>：multiple classifiers using data programming techniques, various information becomes publicly available, private information could easily, machine learning models train, targeted data poisoning attacks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Information leakage is becoming a critical problem as various information
becomes publicly available by mistake, and machine learning models train on
that data to provide services. As a result, one's private information could
easily be memorized by such trained models. Unfortunately, deleting information
is out of the question as the data is already exposed to the Web or third-party
platforms. Moreover, we cannot necessarily control the labeling process and the
model trainings by other parties either. In this setting, we study the problem
of targeted disinformation where the goal is to lower the accuracy of inference
attacks on a specific target (e.g., a person's profile) only using data
insertion. While our problem is related to data privacy and defenses against
exploratory attacks, our techniques are inspired by targeted data poisoning
attacks with some key differences. We show that our problem is best solved by
finding the closest points to the target in the input space that will be
labeled as a different class. Since we do not control the labeling process, we
instead conservatively estimate the labels probabilistically by combining
decision boundaries of multiple classifiers using data programming techniques.
We also propose techniques for making the disinformation realistic. Our
experiments show that a probabilistic decision boundary can be a good proxy for
labelers, and that our approach outperforms other targeted poisoning methods
when using end-to-end training on real datasets.</p>
  </details>
</details>
<details>
  <summary>42. <b>标题：Evaluation Methods and Measures for Causal Learning Algorithms</b></summary>
  <p><b>编号</b>：[207]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02896</p>
  <p><b>作者</b>：Lu Cheng,  Ruocheng Guo,  Raha Moraffah,  Paras Sheth,  K. Selcuk Candan,  Huan Liu</p>
  <p><b>备注</b>：21 pages. Accepted to IEEE TAI</p>
  <p><b>关键词</b>：examine popular causal inference tools, developing causal learning algorithms aiming, e ., causal machine learning, developing publicly available benchmarks, therefore witnessed great effort</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The convenient access to copious multi-faceted data has encouraged machine
learning researchers to reconsider correlation-based learning and embrace the
opportunity of causality-based learning, i.e., causal machine learning (causal
learning). Recent years have therefore witnessed great effort in developing
causal learning algorithms aiming to help AI achieve human-level intelligence.
Due to the lack-of ground-truth data, one of the biggest challenges in current
causal learning research is algorithm evaluations. This largely impedes the
cross-pollination of AI and causal inference, and hinders the two fields to
benefit from the advances of the other. To bridge from conventional causal
inference (i.e., based on statistical methods) to causal learning with big data
(i.e., the intersection of causal inference and machine learning), in this
survey, we review commonly-used datasets, evaluation methods, and measures for
causal learning using an evaluation pipeline similar to conventional machine
learning. We focus on the two fundamental causal-inference tasks and
causality-aware machine learning tasks. Limitations of current evaluation
procedures are also discussed. We then examine popular causal inference
tools/packages and conclude with primary challenges and opportunities for
benchmarking causal learning algorithms in the era of big data. The survey
seeks to bring to the forefront the urgency of developing publicly available
benchmarks and consensus-building standards for causal learning evaluation with
observational data. In doing so, we hope to broaden the discussions and
facilitate collaboration to advance the innovation and application of causal
learning.</p>
  </details>
</details>
<details>
  <summary>43. <b>标题：Causal Inference Using Tractable Circuits</b></summary>
  <p><b>编号</b>：[211]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02891</p>
  <p><b>作者</b>：Adnan Darwiche</p>
  <p><b>备注</b>：Appeared in Why-21 workshop of NeurIPS 2021 (Causal Inference & Machine Learning: Why now?)</p>
  <p><b>关键词</b>：exploit causal mechanisms computationally, may potentially contribute, based supervised learning, causal graph parametrized, versatile causal inference</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The aim of this paper is to discuss a recent result which shows that
probabilistic inference in the presence of (unknown) causal mechanisms can be
tractable for models that have traditionally been viewed as intractable. This
result was reported recently to facilitate model-based supervised learning but
it can be interpreted in a causality context as follows. One can compile a
non-parametric causal graph into an arithmetic circuit that supports inference
in time linear in the circuit size. The circuit is also non-parametric so it
can be used to estimate parameters from data and to further reason (in linear
time) about the causal graph parametrized by these estimates. Moreover, the
circuit size can sometimes be bounded even when the treewidth of the causal
graph is not, leading to tractable inference on models that have been deemed
intractable previously. This has been enabled by a new technique that can
exploit causal mechanisms computationally but without needing to know their
identities (the classical setup in causal inference). Our goal is to provide a
causality-oriented exposure to these new results and to speculate on how they
may potentially contribute to more scalable and versatile causal inference.</p>
  </details>
</details>
<details>
  <summary>44. <b>标题：Leveraging Approximate Symbolic Models for Reinforcement Learning via  Skill Diversity</b></summary>
  <p><b>编号</b>：[213]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02886</p>
  <p><b>作者</b>：Lin Guan,  Sarath Sreedharan,  Subbarao Kambhampati</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：three different benchmark domains, model guided reinforcement learning, using symbolic models along, incomplete symbolic model information, incorporating symbolic task knowledge</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Creating reinforcement learning (RL) agents that are capable of accepting and
leveraging task-specific knowledge from humans has been long identified as a
possible strategy for developing scalable approaches for solving long-horizon
problems. While previous works have looked at the possibility of using symbolic
models along with RL approaches, they tend to assume that the high-level action
models are executable at low level and the fluents can exclusively characterize
all desirable MDP states. This need not be true and this assumption overlooks
one of the central technical challenges of incorporating symbolic task
knowledge, namely, that these symbolic models are going to be an incomplete
representation of the underlying task. To this end, we introduce Symbolic-Model
Guided Reinforcement Learning, wherein we will formalize the relationship
between the symbolic model and the underlying MDP that will allow us to capture
the incompleteness of the symbolic model. We will use these models to extract
high-level landmarks that will be used to decompose the task, and at the low
level, we learn a set of diverse policies for each possible task sub-goal
identified by the landmark. We evaluate our system by testing on three
different benchmark domains and we show how even with incomplete symbolic model
information, our approach is able to discover the task structure and
efficiently guide the RL agent towards the goal.</p>
  </details>
</details>
<details>
  <summary>45. <b>标题：Trusted Approximate Policy Iteration with Bisimulation Metrics</b></summary>
  <p><b>编号</b>：[215]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02881</p>
  <p><b>作者</b>：Mete Kemertas,  Allan Jepson</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：uses $\ epsilon $- aggregation, api ($\ alpha $) procedure, $\ pi $- bisimulation metrics, $\ pi $- bisimulation, novel trust region approach</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Bisimulation metrics define a distance measure between states of a Markov
decision process (MDP) based on a comparison of reward sequences. Due to this
property they provide theoretical guarantees in value function approximation.
In this work we first prove that bisimulation metrics can be defined via any
$p$-Wasserstein metric for $p\geq 1$. Then we describe an approximate policy
iteration (API) procedure that uses $\epsilon$-aggregation with
$\pi$-bisimulation and prove performance bounds for continuous state spaces. We
bound the difference between $\pi$-bisimulation metrics in terms of the change
in the policies themselves. Based on these theoretical results, we design an
API($\alpha$) procedure that employs conservative policy updates and enjoys
better performance bounds than the naive API approach. In addition, we propose
a novel trust region approach which circumvents the requirement to explicitly
solve a constrained optimization problem. Finally, we provide experimental
evidence of improved stability compared to non-conservative alternatives in
simulated continuous control.</p>
  </details>
</details>
<details>
  <summary>46. <b>标题：An Empirical Analysis of AI Contributions to Sustainable Cities (SDG11)</b></summary>
  <p><b>编号</b>：[217]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02879</p>
  <p><b>作者</b>：Shivam Gupta,  Auriol Degbelo</p>
  <p><b>备注</b>：to appear in Mazzi, F. and Floridi, L. (eds) The Ethics of Artificial Intelligence for the Sustainable Development Goals</p>
  <p><b>关键词</b>：g ., waste management, 17 sustainable development goals, transportation management ),, sustainable urban development, disaster response management</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Artificial Intelligence (AI) presents opportunities to develop tools and
techniques for addressing some of the major global challenges and deliver
solutions with significant social and economic impacts. The application of AI
has far-reaching implications for the 17 Sustainable Development Goals (SDGs)
in general, and sustainable urban development in particular. However, existing
attempts to understand and use the opportunities offered by AI for SDG 11 have
been explored sparsely, and the shortage of empirical evidence about the
practical application of AI remains. In this chapter, we analyze the
contribution of AI to support the progress of SDG 11 (Sustainable Cities and
Communities). We address the knowledge gap by empirically analyzing the AI
systems (N = 29) from the AIxSDG database and the Community Research and
Development Information Service (CORDIS) database. Our analysis revealed that
AI systems have indeed contributed to advancing sustainable cities in several
ways (e.g., waste management, air quality monitoring, disaster response
management, transportation management), but many projects are still working for
citizens and not with them. This snapshot of AI's impact on SDG11 is inherently
partial, yet useful to advance our understanding as we move towards more mature
systems and research on the impact of AI systems for social good.</p>
  </details>
</details>
<details>
  <summary>47. <b>标题：Applications of Machine Learning in Healthcare and Internet of Things  (IOT): A Comprehensive Review</b></summary>
  <p><b>编号</b>：[221]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02868</p>
  <p><b>作者</b>：Farid Ghareh Mohammadi,  Farzan Shenavarmasouleh,  Hamid R. Arabnia</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：art machine learning applications particularly, applying traditional centralized learning algorithms, perform medical distributed data analysis, smart healthcare iot devices, decentralized data collected</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In recent years, smart healthcare IoT devices have become ubiquitous, but
they work in isolated networks due to their policy. Having these devices
connected in a network enables us to perform medical distributed data analysis.
However, the presence of diverse IoT devices in terms of technology, structure,
and network policy, makes it a challenging issue while applying traditional
centralized learning algorithms on decentralized data collected from the IoT
devices. In this study, we present an extensive review of the state-of-the-art
machine learning applications particularly in healthcare, challenging issues in
IoT, and corresponding promising solutions. Finally, we highlight some
open-ended issues of IoT in healthcare that leaves further research studies and
investigation for scientists.</p>
  </details>
</details>
<details>
  <summary>48. <b>标题：Aligning Eyes between Humans and Deep Neural Network through Interactive  Attention Alignment</b></summary>
  <p><b>编号</b>：[231]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02838</p>
  <p><b>作者</b>：Yuyang Gao,  Tong Sun,  Liang Zhao,  Sungsoo Hong</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：future interactive user interfaces design towards human, iaa leverages dnn model explanation method, study 1 found applying iaa, steerable deep neural networks, jointly maximizes attention quality</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>While Deep Neural Networks (DNNs) are deriving the major innovations in
nearly every field through their powerful automation, we are also witnessing
the peril behind automation as a form of bias, such as automated racism, gender
bias, and adversarial bias. As the societal impact of DNNs grows, finding an
effective way to steer DNNs to align their behavior with the human mental model
has become indispensable in realizing fair and accountable models. We propose a
novel framework of Interactive Attention Alignment (IAA) that aims at realizing
human-steerable Deep Neural Networks (DNNs). IAA leverages DNN model
explanation method as an interactive medium that humans can use to unveil the
cases of biased model attention and directly adjust the attention. In improving
the DNN using human-generated adjusted attention, we introduce GRADIA, a novel
computational pipeline that jointly maximizes attention quality and prediction
accuracy. We evaluated IAA framework in Study 1 and GRADIA in Study 2 in a
gender classification problem. Study 1 found applying IAA can significantly
improve the perceived quality of model attention from human eyes. In Study 2,
we found using GRADIA can (1) significantly improve the perceived quality of
model attention and (2) significantly improve model performance in scenarios
where the training samples are limited. We present implications for future
interactive user interfaces design towards human-alignable AI.</p>
  </details>
</details>
<details>
  <summary>49. <b>标题：Discovering Personalized Semantics for Soft Attributes in Recommender  Systems using Concept Activation Vectors</b></summary>
  <p><b>编号</b>：[232]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02830</p>
  <p><b>作者</b>：Christina Göpfert,  Yinlam Chow,  Chih-wei Hsu,  Ivan Vendrov,  Tyler Lu,  Deepak Ramachandran,  Craig Boutilier</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：improve recommendations via interactive critiquing, cav representation accurately interprets users, leveraging concept activation vectors, often using natural language, interactive recommender systems</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Interactive recommender systems (RSs) allow users to express intent,
preferences and contexts in a rich fashion, often using natural language. One
challenge in using such feedback is inferring a user's semantic intent from the
open-ended terms used to describe an item, and using it to refine
recommendation results. Leveraging concept activation vectors (CAVs) [21], we
develop a framework to learn a representation that captures the semantics of
such attributes and connects them to user preferences and behaviors in RSs. A
novel feature of our approach is its ability to distinguish objective and
subjective attributes and associate different senses with different users.
Using synthetic and real-world datasets, we show that our CAV representation
accurately interprets users' subjective semantics, and can improve
recommendations via interactive critiquing</p>
  </details>
</details>
<details>
  <summary>50. <b>标题：Block shuffling learning for Deepfake Detection</b></summary>
  <p><b>编号</b>：[237]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02819</p>
  <p><b>作者</b>：Sitong Liu,  Zhichao Lian,  Siqi Gu,  Liang Xiao</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：detectors show obvious performance degradation, novel block shuffling learning method, proposed method achieves state, including good generalization ability, extensive experiments show</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Although the deepfake detection based on convolutional neural network has
achieved good results, the detection results show that these detectors show
obvious performance degradation when the input images undergo some common
transformations (like resizing, blurring), which indicates that the
generalization ability of the detector is insufficient. In this paper, we
propose a novel block shuffling learning method to solve this problem.
Specifically, we divide the images into blocks and then introduce the random
shuffling to intra-block and inter-block. Intra-block shuffling increases the
robustness of the detector and we also propose an adversarial loss algorithm to
overcome the over-fitting problem brought by the noise introduced by shuffling.
Moreover, we encourage the detector to focus on finding differences among the
local features through inter-block shuffling, and reconstruct the spatial
layout of the blocks to model the semantic associations between them.
Especially, our method can be easily integrated with various CNN models.
Extensive experiments show that our proposed method achieves state-of-the-art
performance in forgery face detection, including good generalization ability in
the face of common image transformations.</p>
  </details>
</details>
<details>
  <summary>51. <b>标题：SFMGNet: A Physics-based Neural Network To Predict Pedestrian  Trajectories</b></summary>
  <p><b>编号</b>：[249]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02791</p>
  <p><b>作者</b>：Sakif Hossain,  Fatema T. Johora,  Jörg P. Müller,  Sven Hartmann,  Andreas Reinhardt</p>
  <p><b>备注</b>：16 pages, 6 figures, AAAI-MAKE 2022: Machine Learning and Knowledge Engineering for Hybrid Intelligence</p>
  <p><b>关键词</b>：interpretable behavior remain key obstacles, unsatisfactory issues regarding interaction, social force model extended, predict pedestrian trajectories considering, initial results suggest</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Autonomous robots and vehicles are expected to soon become an integral part
of our environment. Unsatisfactory issues regarding interaction with existing
road users, performance in mixed-traffic areas and lack of interpretable
behavior remain key obstacles. To address these, we present a physics-based
neural network, based on a hybrid approach combining a social force model
extended by group force (SFMG) with Multi-Layer Perceptron (MLP) to predict
pedestrian trajectories considering its interaction with static obstacles,
other pedestrians and pedestrian groups. We quantitatively and qualitatively
evaluate the model with respect to realistic prediction, prediction performance
and prediction "interpretability". Initial results suggest, the model even when
solely trained on a synthetic dataset, can predict realistic and interpretable
trajectories with better than state-of-the-art accuracy.</p>
  </details>
</details>
<details>
  <summary>52. <b>标题：Learning Synthetic Environments and Reward Networks for Reinforcement  Learning</b></summary>
  <p><b>编号</b>：[250]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02790</p>
  <p><b>作者</b>：Fabio Ferreira,  Thomas Nierhoff,  Andreas Saelinger,  Frank Hutter</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：learned se proxies allow us, agents towards relevant states, proposed new concept, outer loop trains, original task performance</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We introduce Synthetic Environments (SEs) and Reward Networks (RNs),
represented by neural networks, as proxy environment models for training
Reinforcement Learning (RL) agents. We show that an agent, after being trained
exclusively on the SE, is able to solve the corresponding real environment.
While an SE acts as a full proxy to a real environment by learning about its
state dynamics and rewards, an RN is a partial proxy that learns to augment or
replace rewards. We use bi-level optimization to evolve SEs and RNs: the inner
loop trains the RL agent, and the outer loop trains the parameters of the SE /
RN via an evolution strategy. We evaluate our proposed new concept on a broad
range of RL algorithms and classic control environments. In a one-to-one
comparison, learning an SE proxy requires more interactions with the real
environment than training agents only on the real environment. However, once
such an SE has been learned, we do not need any interactions with the real
environment to train new agents. Moreover, the learned SE proxies allow us to
train agents with fewer interactions while maintaining the original task
performance. Our empirical results suggest that SEs achieve this result by
learning informed representations that bias the agents towards relevant states.
Moreover, we find that these proxies are robust against hyperparameter
variation and can also transfer to unseen agents.</p>
  </details>
</details>
<details>
  <summary>53. <b>标题：Human rights, democracy, and the rule of law assurance framework for AI  systems: A proposal</b></summary>
  <p><b>编号</b>：[256]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02776</p>
  <p><b>作者</b>：David Leslie,  Christopher Burr,  Mhairi Aitken,  Michael Katell,  Morgan Briggs,  Cami Rincon</p>
  <p><b>备注</b>：341 pages</p>
  <p><b>关键词</b>：based human rights due diligence, human right due diligence, alan turing institute undertook, trustworthy ai innovation practices, trustworthy ai innovation practices</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Following on from the publication of its Feasibility Study in December 2020,
the Council of Europe's Ad Hoc Committee on Artificial Intelligence (CAHAI) and
its subgroups initiated efforts to formulate and draft its Possible Elements of
a Legal Framework on Artificial Intelligence, based on the Council of Europe's
standards on human rights, democracy, and the rule of law. This document was
ultimately adopted by the CAHAI plenary in December 2021. To support this
effort, The Alan Turing Institute undertook a programme of research that
explored the governance processes and practical tools needed to operationalise
the integration of human right due diligence with the assurance of trustworthy
AI innovation practices.
The resulting framework was completed and submitted to the Council of Europe
in September 2021. It presents an end-to-end approach to the assurance of AI
project lifecycles that integrates context-based risk analysis and appropriate
stakeholder engagement with comprehensive impact assessment, and transparent
risk management, impact mitigation, and innovation assurance practices. Taken
together, these interlocking processes constitute a Human Rights, Democracy and
the Rule of Law Assurance Framework (HUDERAF). The HUDERAF combines the
procedural requirements for principles-based human rights due diligence with
the governance mechanisms needed to set up technical and socio-technical
guardrails for responsible and trustworthy AI innovation practices. Its purpose
is to provide an accessible and user-friendly set of mechanisms for
facilitating compliance with a binding legal framework on artificial
intelligence, based on the Council of Europe's standards on human rights,
democracy, and the rule of law, and to ensure that AI innovation projects are
carried out with appropriate levels of public accountability, transparency, and
democratic governance.</p>
  </details>
</details>
<details>
  <summary>54. <b>标题：Pipe Overflow: Smashing Voice Authentication for Fun and Profit</b></summary>
  <p><b>编号</b>：[263]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02751</p>
  <p><b>作者</b>：Shimaa Ahmed,  Yash Wani,  Ali Shahin Shamsabadi,  Mohammad Yaghini,  Ilia Shumailov,  Nicolas Papernot,  Kassem Fawaz</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：producing analog adversarial examples directly, enabled personal devices powered, tasks like speaker identification, targeted adversarial examples, modern systems protect</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent years have seen a surge of popularity of acoustics-enabled personal
devices powered by machine learning. Yet, machine learning has proven to be
vulnerable to adversarial examples. Large number of modern systems protect
themselves against such attacks by targeting the artificiality, i.e., they
deploy mechanisms to detect the lack of human involvement in generating the
adversarial examples. However, these defenses implicitly assume that humans are
incapable of producing meaningful and targeted adversarial examples. In this
paper, we show that this base assumption is wrong. In particular, we
demonstrate that for tasks like speaker identification, a human is capable of
producing analog adversarial examples directly with little cost and
supervision: by simply speaking through a tube, an adversary reliably
impersonates other speakers in eyes of ML models for speaker identification.
Our findings extend to a range of other acoustic-biometric tasks such as
liveness, bringing into question their use in security-critical settings in
real life, such as phone banking.</p>
  </details>
</details>
<details>
  <summary>55. <b>标题：The Self-Driving Car: Crossroads at the Bleeding Edge of Artificial  Intelligence and Law</b></summary>
  <p><b>编号</b>：[267]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02734</p>
  <p><b>作者</b>：Scott McLachlan,  Evangelia Kyrimi,  Kudakwashe Dube,  Norman Fenton,  Burkhard Schafer</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：areas truly requiring ongoing legislative attention, effort expended towards understanding, still mostly speculative, help us understand, comprehensive literature review</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Artificial intelligence (AI) features are increasingly being embedded in cars
and are central to the operation of self-driving cars (SDC). There is little or
no effort expended towards understanding and assessing the broad legal and
regulatory impact of the decisions made by AI in cars. A comprehensive
literature review was conducted to determine the perceived barriers, benefits
and facilitating factors of SDC in order to help us understand the suitability
and limitations of existing and proposed law and regulation. (1) existing and
proposed laws are largely based on claimed benefits of SDV that are still
mostly speculative and untested; (2) while publicly presented as issues of
assigning blame and identifying who pays where the SDC is involved in an
accident, the barriers broadly intersect with almost every area of society,
laws and regulations; and (3) new law and regulation are most frequently
identified as the primary factor for enabling SDC. Research on assessing the
impact of AI in SDC needs to be broadened beyond negligence and liability to
encompass barriers, benefits and facilitating factors identified in this paper.
Results of this paper are significant in that they point to the need for deeper
comprehension of the broad impact of all existing law and regulations on the
introduction of SDC technology, with a focus on identifying only those areas
truly requiring ongoing legislative attention.</p>
  </details>
</details>
<details>
  <summary>56. <b>标题：Energy-Aware Edge Association for Cluster-based Personalized Federated  Learning</b></summary>
  <p><b>编号</b>：[269]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02727</p>
  <p><b>作者</b>：Y. Li,  X. Qin,  H. Chen,  K. Han,  P. Zhang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：diversified personal preferences causes disagreeing conditional distributions among user data, realize cost efficient personalized federated learning without, employs deep reinforcement learning based approach, proposed strategy outperforms existing strategies, wireless network enables data</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Federated Learning (FL) over wireless network enables data-conscious services
by leveraging the ubiquitous intelligence at network edge for
privacy-preserving model training. As the proliferation of context-aware
services, the diversified personal preferences causes disagreeing conditional
distributions among user data, which leads to poor inference performance. In
this sense, clustered federated learning is proposed to group user devices with
similar preference and provide each cluster with a personalized model. This
calls for innovative design in edge association that involves user clustering
and also resource management optimization. We formulate an accuracy-cost
trade-off optimization problem by jointly considering model accuracy,
communication resource allocation and energy consumption. To comply with
parameter encryption techniques in FL, we propose an iterative solution
procedure which employs deep reinforcement learning based approach at cloud
server for edge association. The reward function consists of minimized energy
consumption at each base station and the averaged model accuracy of all users.
Under our proposed solution, multiple edge base station are fully exploited to
realize cost efficient personalized federated learning without any prior
knowledge on model parameters. Simulation results show that our proposed
strategy outperforms existing strategies in achieving accurate learning at low
energy cost.</p>
  </details>
</details>
<details>
  <summary>57. <b>标题：Triangle Graph Interest Network for Click-through Rate Prediction</b></summary>
  <p><b>编号</b>：[280]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02698</p>
  <p><b>作者</b>：Wensen Jiang,  Yizhu Jiao,  Qingqin Wang,  Chuanming Liang,  Lijie Guo,  Yao Zhang,  Zhijun Sun,  Yun Xiong,  Yangyong Zhu</p>
  <p><b>备注</b>：This paper is accepted by WSDM 2022. Source code: this https URL</p>
  <p><b>关键词</b>：effective framework named triangle graph interest network, many existing methods attempt, industrial datasets clearly verify, attention mechanism determines users, characterize every click behavior</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Click-through rate prediction is a critical task in online advertising.
Currently, many existing methods attempt to extract user potential interests
from historical click behavior sequences. However, it is difficult to handle
sparse user behaviors or broaden interest exploration. Recently, some
researchers incorporate the item-item co-occurrence graph as an auxiliary. Due
to the elusiveness of user interests, those works still fail to determine the
real motivation of user click behaviors. Besides, those works are more biased
towards popular or similar commodities. They lack an effective mechanism to
break the diversity restrictions. In this paper, we point out two special
properties of triangles in the item-item graphs for recommendation systems:
Intra-triangle homophily and Inter-triangle heterophiy. Based on this, we
propose a novel and effective framework named Triangle Graph Interest Network
(TGIN). For each clicked item in user behavior sequences, we introduce the
triangles in its neighborhood of the item-item graphs as a supplement. TGIN
regards these triangles as the basic units of user interests, which provide the
clues to capture the real motivation for a user clicking an item. We
characterize every click behavior by aggregating the information of several
interest units to alleviate the elusive motivation problem. The attention
mechanism determines users' preference for different interest units. By
selecting diverse and relative triangles, TGIN brings in novel and
serendipitous items to expand exploration opportunities of user interests.
Then, we aggregate the multi-level interests of historical behavior sequences
to improve CTR prediction. Extensive experiments on both public and industrial
datasets clearly verify the effectiveness of our framework.</p>
  </details>
</details>
<details>
  <summary>58. <b>标题：Exploration with Multi-Sample Target Values for Distributional  Reinforcement Learning</b></summary>
  <p><b>编号</b>：[282]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02693</p>
  <p><b>作者</b>：Michael Teng,  Michiel van de Panne,  Frank Wood</p>
  <p><b>备注</b>：Submitted to ICML 2022</p>
  <p><b>关键词</b>：sample target value estimation, sample target values, often modeled via, method via visualization, improved distributional estimates</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Distributional reinforcement learning (RL) aims to learn a value-network that
predicts the full distribution of the returns for a given state, often modeled
via a quantile-based critic. This approach has been successfully integrated
into common RL methods for continuous control, giving rise to algorithms such
as Distributional Soft Actor-Critic (DSAC). In this paper, we introduce
multi-sample target values (MTV) for distributional RL, as a principled
replacement for single-sample target value estimation, as commonly employed in
current practice. The improved distributional estimates further lend themselves
to UCB-based exploration. These two ideas are combined to yield our
distributional RL algorithm, E2DC (Extra Exploration with Distributional
Critics). We evaluate our approach on a range of continuous control tasks and
demonstrate state-of-the-art model-free performance on difficult tasks such as
Humanoid control. We provide further insight into the method via visualization
and analysis of the learned distributions and their evolution during training.</p>
  </details>
</details>
<details>
  <summary>59. <b>标题：TTS-GAN: A Transformer-based Time-Series Generative Adversarial Network</b></summary>
  <p><b>编号</b>：[283]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02691</p>
  <p><b>作者</b>：Xiaomin Li,  Vangelis Metsis,  Huangyingrui Wang,  Anne Hee Hiong Ngu</p>
  <p><b>备注</b>：submitted to 20th International Conference on Artificial Intelligence in Medicine (AIME 2022)</p>
  <p><b>关键词</b>：deep neural network architectures ineffective, cannot effectively model long sequences, successfully generate realistic synthetic time, medical machine learning applications, pure transformer encoder architecture</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Signal measurements appearing in the form of time series are one of the most
common types of data used in medical machine learning applications. However,
such datasets are often small, making the training of deep neural network
architectures ineffective. For time-series, the suite of data augmentation
tricks we can use to expand the size of the dataset is limited by the need to
maintain the basic properties of the signal. Data generated by a Generative
Adversarial Network (GAN) can be utilized as another data augmentation tool.
RNN-based GANs suffer from the fact that they cannot effectively model long
sequences of data points with irregular temporal relations. To tackle these
problems, we introduce TTS-GAN, a transformer-based GAN which can successfully
generate realistic synthetic time-series data sequences of arbitrary length,
similar to the real ones. Both the generator and discriminator networks of the
GAN model are built using a pure transformer encoder architecture. We use
visualizations and dimensionality reduction techniques to demonstrate the
similarity of real and generated time-series data. We also compare the quality
of our generated data with the best existing alternative, which is an RNN-based
time-series GAN.</p>
  </details>
</details>
<details>
  <summary>60. <b>标题：(Almost) Envy-Free, Proportional and Efficient Allocations of an  Indivisible Mixed Manna</b></summary>
  <p><b>编号</b>：[292]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02672</p>
  <p><b>作者</b>：Vasilis Livanos,  Ruta Mehta,  Aniket Murhekar</p>
  <p><b>备注</b>：23 pages</p>
  <p><b>关键词</b>：j $, every agent, strongest possible relaxations, ordered pure bads, let pure bads, identical pure bads</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We study the problem of finding fair and efficient allocations of a set of
indivisible items to a set of agents, where each item may be a good (positively
valued) for some agents and a bad (negatively valued) for others, i.e., a mixed
manna. As fairness notions, we consider arguably the strongest possible
relaxations of envy-freeness and proportionality, namely envy-free up to any
item (EFX and EFX$_0$), and proportional up to the maximin good or any bad
(PropMX and PropMX$_0$). Our efficiency notion is Pareto-optimality (PO).
We study two types of instances:
(i) Separable, where the item set can be partitioned into goods and bads, and
(ii) Restricted mixed goods (RMG), where for each item $j$, every agent has
either a non-positive value for $j$, or values $j$ at the same $v_j>0$. We
obtain polynomial-time algorithms for the following:
(i) Separable instances: PropMX$_0$ allocation.
(ii) RMG instances: Let pure bads be the set of items that everyone values
negatively.
- PropMX allocation for general pure bads.
- EFX+PropMX allocation for identically-ordered pure bads.
- EFX+PropMX+PO allocation for identical pure bads.
Finally, if the RMG instances are further restricted to binary mixed goods
where all the $v_j$'s are the same, we strengthen the results to guarantee
EFX$_0$ and PropMX$_0$ respectively.</p>
  </details>
</details>
<details>
  <summary>61. <b>标题：A survey of top-down approaches for human pose estimation</b></summary>
  <p><b>编号</b>：[302]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02656</p>
  <p><b>作者</b>：Thong Duy Nguyen,  Milan Kresovic</p>
  <p><b>备注</b>：16 pages</p>
  <p><b>关键词</b>：computer vision problem recently due, brought tremendous remarkable results, paper presents significant detectors, step framework first incorporates, improving human life</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Human pose estimation in two-dimensional images videos has been a hot topic
in the computer vision problem recently due to its vast benefits and potential
applications for improving human life, such as behaviors recognition, motion
capture and augmented reality, training robots, and movement tracking. Many
state-of-the-art methods implemented with Deep Learning have addressed several
challenges and brought tremendous remarkable results in the field of human pose
estimation. Approaches are classified into two kinds: the two-step framework
(top-down approach) and the part-based framework (bottom-up approach). While
the two-step framework first incorporates a person detector and then estimates
the pose within each box independently, detecting all body parts in the image
and associating parts belonging to distinct persons is conducted in the
part-based framework. This paper aims to provide newcomers with an extensive
review of deep learning methods-based 2D images for recognizing the pose of
people, which only focuses on top-down approaches since 2016. The discussion
through this paper presents significant detectors and estimators depending on
mathematical background, the challenges and limitations, benchmark datasets,
evaluation metrics, and comparison between methods.</p>
  </details>
</details>
<details>
  <summary>62. <b>标题：Doing Right by Not Doing Wrong in Human-Robot Collaboration</b></summary>
  <p><b>编号</b>：[303]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02654</p>
  <p><b>作者</b>：Laura Londoño,  Adrian Röfer,  Tim Welschehold,  Abhinav Valada</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：exhibit antisocial behavior causing physical harm, issues considering sociable robotic manipulation, reproduce unfair behavior replicating, fair robotic decision making, human collaborators feel unsafe</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As robotic systems become more and more capable of assisting humans in their
everyday lives, we must consider the opportunities for these artificial agents
to make their human collaborators feel unsafe or to treat them unfairly. Robots
can exhibit antisocial behavior causing physical harm to people or reproduce
unfair behavior replicating and even amplifying historical and societal biases
which are detrimental to humans they interact with. In this paper, we discuss
these issues considering sociable robotic manipulation and fair robotic
decision making. We propose a novel approach to learning fair and sociable
behavior, not by reproducing positive behavior, but rather by avoiding negative
behavior. In this study, we highlight the importance of incorporating
sociability in robot manipulation, as well as the need to consider fairness in
human-robot interactions.</p>
  </details>
</details>
<details>
  <summary>63. <b>标题：A Graph Neural Network Framework for Grid-Based Simulation</b></summary>
  <p><b>编号</b>：[304]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02652</p>
  <p><b>作者</b>：Haoyu Tang,  Wennan Long</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：related subsurface optimization including oil, gnn framework shows great potential, previous step state variable, next step state variable, processed graph data designed</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Reservoir simulations are computationally expensive in the well control and
well placement optimization. Generally, numerous simulation runs (realizations)
are needed in order to achieve the optimal well locations. In this paper, we
propose a graph neural network (GNN) framework to build a surrogate
feed-forward model which replaces simulation runs to accelerate the
optimization process. Our GNN framework includes an encoder, a process, and a
decoder which takes input from the processed graph data designed and generated
from the simulation raw data. We train the GNN model with 6000 samples
(equivalent to 40 well configurations) with each containing the previous step
state variable and the next step state variable. We test the GNN model with
another 6000 samples and after model tuning, both one-step prediction and
rollout prediction achieve a close match with the simulation results. Our GNN
framework shows great potential in the application of well-related subsurface
optimization including oil and gas as well as carbon capture sequestration
(CCS).</p>
  </details>
</details>
<details>
  <summary>64. <b>标题：Ethics, Rules of Engagement, and AI: Neural Narrative Mapping Using  Large Transformer Language Models</b></summary>
  <p><b>编号</b>：[306]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02647</p>
  <p><b>作者</b>：Philip Feldman,  Aaron Dant,  David Rosenbluth</p>
  <p><b>备注</b>：18 Pages, 13 figures</p>
  <p><b>关键词</b>：bedeviled military planners throughout history, series offers new possibilities, demonstrate new ways, turn provide means, large language models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The problem of determining if a military unit has correctly understood an
order and is properly executing on it is one that has bedeviled military
planners throughout history. The advent of advanced language models such as
OpenAI's GPT-series offers new possibilities for addressing this problem. This
paper presents a mechanism to harness the narrative output of large language
models and produce diagrams or "maps" of the relationships that are latent in
the weights of such models as the GPT-3. The resulting "Neural Narrative Maps"
(NNMs), are intended to provide insight into the organization of information,
opinion, and belief in the model, which in turn provide means to understand
intent and response in the context of physical distance. This paper discusses
the problem of mapping information spaces in general, and then presents a
concrete implementation of this concept in the context of OpenAI's GPT-3
language model for determining if a subordinate is following a commander's
intent in a high-risk situation. The subordinate's locations within the NNM
allow a novel capability to evaluate the intent of the subordinate with respect
to the commander. We show that is is possible not only to determine if they are
nearby in narrative space, but also how they are oriented, and what
"trajectory" they are on. Our results show that our method is able to produce
high-quality maps, and demonstrate new ways of evaluating intent more
generally.</p>
  </details>
</details>
<details>
  <summary>65. <b>标题：The Unreasonable Effectiveness of Random Pruning: Return of the Most  Naive Baseline for Sparse Training</b></summary>
  <p><b>编号</b>：[308]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02643</p>
  <p><b>作者</b>：Shiwei Liu,  Tianlong Chen,  Xiaohan Chen,  Li Shen,  Decebal Constantin Mocanu,  Zhangyang Wang,  Mykola Pechenizkiy</p>
  <p><b>备注</b>：Published as a conference paper at ICLR 2022. Code is available at this https URL</p>
  <p><b>关键词</b>：randomly pruned networks outperform dense counterparts, universal beyond carefully designed pruning, original dense networks grow wider, carefully pursued sparsity structures, another important performance booster</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Random pruning is arguably the most naive way to attain sparsity in neural
networks, but has been deemed uncompetitive by either post-training pruning or
sparse training. In this paper, we focus on sparse training and highlight a
perhaps counter-intuitive finding, that random pruning at initialization can be
quite powerful for the sparse training of modern neural networks. Without any
delicate pruning criteria or carefully pursued sparsity structures, we
empirically demonstrate that sparsely training a randomly pruned network from
scratch can match the performance of its dense equivalent. There are two key
factors that contribute to this revival: (i) the network sizes matter: as the
original dense networks grow wider and deeper, the performance of training a
randomly pruned sparse network will quickly grow to matching that of its dense
equivalent, even at high sparsity ratios; (ii) appropriate layer-wise sparsity
ratios can be pre-chosen for sparse training, which shows to be another
important performance booster. Simple as it looks, a randomly pruned subnetwork
of Wide ResNet-50 can be sparsely trained to outperforming a dense Wide
ResNet-50, on ImageNet. We also observed such randomly pruned networks
outperform dense counterparts in other favorable aspects, such as
out-of-distribution detection, uncertainty estimation, and adversarial
robustness. Overall, our results strongly suggest there is larger-than-expected
room for sparse training at scale, and the benefits of sparsity might be more
universal beyond carefully designed pruning. Our source code can be found at
this https URL.</p>
  </details>
</details>
<details>
  <summary>66. <b>标题：Privacy-preserving Speech Emotion Recognition through Semi-Supervised  Federated Learning</b></summary>
  <p><b>编号</b>：[322]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02611</p>
  <p><b>作者</b>：Vasileios Tsouvalas,  Tanir Ozcelebi,  Nirvana Meratnia</p>
  <p><b>备注</b>：arXiv admin note: text overlap with arXiv:2107.06877</p>
  <p><b>关键词</b>：learn generalizable ser models even, distributed machine learning paradigm dealing, first federated ser approach, existing ser approaches, without considering users</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Speech Emotion Recognition (SER) refers to the recognition of human emotions
from natural speech. If done accurately, it can offer a number of benefits in
building human-centered context-aware intelligent systems. Existing SER
approaches are largely centralized, without considering users' privacy.
Federated Learning (FL) is a distributed machine learning paradigm dealing with
decentralization of privacy-sensitive personal data. In this paper, we present
a privacy-preserving and data-efficient SER approach by utilizing the concept
of FL. To the best of our knowledge, this is the first federated SER approach,
which utilizes self-training learning in conjunction with federated learning to
exploit both labeled and unlabeled on-device data. Our experimental evaluations
on the IEMOCAP dataset shows that our federated approach can learn
generalizable SER models even under low availability of data labels and highly
non-i.i.d. distributions. We show that our approach with as few as 10% labeled
data, on average, can improve the recognition rate by 8.67% compared to the
fully-supervised federated counterparts.</p>
  </details>
</details>
<details>
  <summary>67. <b>标题：Communication Efficient Federated Learning via Ordered ADMM in a Fully  Decentralized Setting</b></summary>
  <p><b>编号</b>：[333]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02580</p>
  <p><b>作者</b>：Yicheng Chen,  Rick S. Blum,  Brian M. Sadler</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：general fully decentralized network setting, based alternating direction method, existing algorithms including admm, local variables based, numerical results demonstrate</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The challenge of communication-efficient distributed optimization has
attracted attention in recent years. In this paper, a communication efficient
algorithm, called ordering-based alternating direction method of multipliers
(OADMM) is devised in a general fully decentralized network setting where a
worker can only exchange messages with neighbors. Compared to the classical
ADMM, a key feature of OADMM is that transmissions are ordered among workers at
each iteration such that a worker with the most informative data broadcasts its
local variable to neighbors first, and neighbors who have not transmitted yet
can update their local variables based on that received transmission. In OADMM,
we prohibit workers from transmitting if their current local variables are not
sufficiently different from their previously transmitted value. A variant of
OADMM, called SOADMM, is proposed where transmissions are ordered but
transmissions are never stopped for each node at each iteration. Numerical
results demonstrate that given a targeted accuracy, OADMM can significantly
reduce the number of communications compared to existing algorithms including
ADMM. We also show numerically that SOADMM can accelerate convergence,
resulting in communication savings compared to the classical ADMM.</p>
  </details>
</details>
<details>
  <summary>68. <b>标题：Symmetric Volume Maps</b></summary>
  <p><b>编号</b>：[339]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02568</p>
  <p><b>作者</b>：S. Mazdak Abulnaga,  Oded Stein,  Polina Golland,  Justin Solomon</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：boundary representations -- presents unique challenges, e ., without dependence, even improving surface maps, volumetric correspondence --, extract maps symmetrically</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Although shape correspondence is a central problem in geometry processing,
most methods for this task apply only to two-dimensional surfaces. The
neglected task of volumetric correspondence--a natural extension relevant to
shapes extracted from simulation, medical imaging, volume rendering, and even
improving surface maps of boundary representations--presents unique challenges
that do not appear in the two-dimensional case. In this work, we propose a
method for mapping between volumes represented as tetrahedral meshes. Our
formulation minimizes a distortion energy designed to extract maps
symmetrically, i.e., without dependence on the ordering of the source and
target domains. We accompany our method with theoretical discussion describing
the consequences of this symmetry assumption, leading us to select a
symmetrized ARAP energy that favors isometric correspondences. Our final
formulation optimizes for near-isometry while matching the boundary. We
demonstrate our method on a diverse geometric dataset, producing low-distortion
matchings that align to the boundary.</p>
  </details>
</details>
<details>
  <summary>69. <b>标题：Unsupervised Learning on 3D Point Clouds by Clustering and Contrasting</b></summary>
  <p><b>编号</b>：[349]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02543</p>
  <p><b>作者</b>：Guofeng Mei,  Litao Yu,  Qiang Wu,  Jian Zhang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：extract features without human intervention, extract discriminating local features based, alleviate human labeling remains, criterion extends standard cross, like soft clustering algorithm</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Learning from unlabeled or partially labeled data to alleviate human labeling
remains a challenging research topic in 3D modeling. Along this line,
unsupervised representation learning is a promising direction to auto-extract
features without human intervention. This paper proposes a general unsupervised
approach, named \textbf{ConClu}, to perform the learning of point-wise and
global features by jointly leveraging point-level clustering and instance-level
contrasting. Specifically, for one thing, we design an Expectation-Maximization
(EM) like soft clustering algorithm that provides local supervision to extract
discriminating local features based on optimal transport. We show that this
criterion extends standard cross-entropy minimization to an optimal transport
problem, which we solve efficiently using a fast variant of the Sinkhorn-Knopp
algorithm. For another, we provide an instance-level contrasting method to
learn the global geometry, which is formulated by maximizing the similarity
between two augmentations of one point cloud. Experimental evaluations on
downstream applications such as 3D object classification and semantic
segmentation demonstrate the effectiveness of our framework and show that it
can outperform state-of-the-art techniques.</p>
  </details>
</details>
<details>
  <summary>70. <b>标题：TorchMD-NET: Equivariant Transformers for Neural Network based Molecular  Potentials</b></summary>
  <p><b>编号</b>：[350]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02541</p>
  <p><b>作者</b>：Philipp Thölke,  Gianni De Fabritiis</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：previously shown great success, extensive attention weight analysis, conformers versus conformations sampled, reaching increasingly better accuracy, maintaining computational efficiency comparable</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The prediction of quantum mechanical properties is historically plagued by a
trade-off between accuracy and speed. Machine learning potentials have
previously shown great success in this domain, reaching increasingly better
accuracy while maintaining computational efficiency comparable with classical
force fields. In this work we propose TorchMD-NET, a novel equivariant
transformer (ET) architecture, outperforming state-of-the-art on MD17, ANI-1,
and many QM9 targets in both accuracy and computational efficiency. Through an
extensive attention weight analysis, we gain valuable insights into the black
box predictor and show differences in the learned representation of conformers
versus conformations sampled from molecular dynamics or normal modes.
Furthermore, we highlight the importance of datasets including off-equilibrium
conformations for the evaluation of molecular potentials.</p>
  </details>
</details>
<details>
  <summary>71. <b>标题：Science Facing Interoperability as a Necessary Condition of Success and  Evil</b></summary>
  <p><b>编号</b>：[351]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02540</p>
  <p><b>作者</b>：Remy Demichelis</p>
  <p><b>备注</b>：5 pages, The Society for Philosophy and Technology Conference 2021</p>
  <p><b>关键词</b>：deep ethical problem lays essentially, systems make therefore spheres permeable, new interactions create dominances, new connections made possible, creating new bridges</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Artificial intelligence (AI) systems, such as machine learning algorithms,
have allowed scientists, marketers and governments to shed light on
correlations that remained invisible until now. Beforehand, the dots that we
had to connect in order to imagine a new knowledge were either too numerous,
too sparse or not even detected. Sometimes, the information was not stored in
the same data lake or format and was not able to communicate. But in creating
new bridges with AI, many problems appeared such as bias reproduction, unfair
inferences or mass surveillance. Our aim is to show that, on one hand, the AI's
deep ethical problem lays essentially in these new connections made possible by
systems interoperability. In connecting the spheres of our life, these systems
undermine the notion of justice particular to each of them, because the new
interactions create dominances of social goods from a sphere to another. These
systems make therefore spheres permeable to one another and, in doing so, they
open to progress as well as to tyranny. On another hand, however, we would like
to emphasize that the act to connect what used to seem a priori disjoint is a
necessary move of knowledge and scientific progress.</p>
  </details>
</details>
<details>
  <summary>72. <b>标题：Graph Neural Network with Curriculum Learning for Imbalanced Node  Classification</b></summary>
  <p><b>编号</b>：[357]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02529</p>
  <p><b>作者</b>：Xiaohe Li,  Lijie Wen,  Yawen Deng,  Fuli Feng,  Xuming Hu,  Lei Wang,  Zide Fan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：evaluated via several widely used graph datasets, acquire certain reliable interpolation nodes, novel graph neural network framework, may even bring overfitting, proposed model consistently outperforms</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Graph Neural Network (GNN) is an emerging technique for graph-based learning
tasks such as node classification. In this work, we reveal the vulnerability of
GNN to the imbalance of node labels. Traditional solutions for imbalanced
classification (e.g. resampling) are ineffective in node classification without
considering the graph structure. Worse still, they may even bring overfitting
or underfitting results due to lack of sufficient prior knowledge. To solve
these problems, we propose a novel graph neural network framework with
curriculum learning (GNN-CL) consisting of two modules. For one thing, we hope
to acquire certain reliable interpolation nodes and edges through the novel
graph-based oversampling based on smoothness and homophily. For another, we
combine graph classification loss and metric learning loss which adjust the
distance between different nodes associated with minority class in feature
space. Inspired by curriculum learning, we dynamically adjust the weights of
different modules during training process to achieve better ability of
generalization and discrimination. The proposed framework is evaluated via
several widely used graph datasets, showing that our proposed model
consistently outperforms the existing state-of-the-art methods.</p>
  </details>
</details>
<details>
  <summary>73. <b>标题：LyaNet: A Lyapunov Framework for Training Neural ODEs</b></summary>
  <p><b>编号</b>：[358]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02526</p>
  <p><b>作者</b>：Ivan Dario Jimenez Rodriguez,  Aaron D. Ames,  Yisong Yue</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：minimizing lyapunov loss guarantees exponential convergence, novel lyapunov loss formulation, training ordinary differential equations, standard neural ode training, also provide practical algorithms</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose a method for training ordinary differential equations by using a
control-theoretic Lyapunov condition for stability. Our approach, called
LyaNet, is based on a novel Lyapunov loss formulation that encourages the
inference dynamics to converge quickly to the correct prediction.
Theoretically, we show that minimizing Lyapunov loss guarantees exponential
convergence to the correct solution and enables a novel robustness guarantee.
We also provide practical algorithms, including one that avoids the cost of
backpropagating through a solver or using the adjoint method. Relative to
standard Neural ODE training, we empirically find that LyaNet can offer
improved prediction performance, faster convergence of inference dynamics, and
improved adversarial robustness. Our code available at
this https URL .</p>
  </details>
</details>
<details>
  <summary>74. <b>标题：Comparative study of 3D object detection frameworks based on LiDAR data  and sensor fusion techniques</b></summary>
  <p><b>编号</b>：[361]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02521</p>
  <p><b>作者</b>：Sreenivasa Hikkal Venugopala</p>
  <p><b>备注</b>：2021 2nd International Conference on Control Theory and Applications(ICoCTA 2021)</p>
  <p><b>关键词</b>：3d object detection frameworks performing object detection, sensor fusion techniques show significant improvement, perception system involves various subsystems, using sensor fusion techniques, 3d object detection methods</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Estimating and understanding the surroundings of the vehicle precisely forms
the basic and crucial step for the autonomous vehicle. The perception system
plays a significant role in providing an accurate interpretation of a vehicle's
environment in real-time. Generally, the perception system involves various
subsystems such as localization, obstacle (static and dynamic) detection, and
avoidance, mapping systems, and others. For perceiving the environment, these
vehicles will be equipped with various exteroceptive (both passive and active)
sensors in particular cameras, Radars, LiDARs, and others. These systems are
equipped with deep learning techniques that transform the huge amount of data
from the sensors into semantic information on which the object detection and
localization tasks are performed. For numerous driving tasks, to provide
accurate results, the location and depth information of a particular object is
necessary. 3D object detection methods, by utilizing the additional pose data
from the sensors such as LiDARs, stereo cameras, provides information on the
size and location of the object. Based on recent research, 3D object detection
frameworks performing object detection and localization on LiDAR data and
sensor fusion techniques show significant improvement in their performance. In
this work, a comparative study of the effect of using LiDAR data for object
detection frameworks and the performance improvement seen by using sensor
fusion techniques are performed. Along with discussing various state-of-the-art
methods in both the cases, performing experimental analysis, and providing
future research directions.</p>
  </details>
</details>
<details>
  <summary>75. <b>标题：Intent Contrastive Learning for Sequential Recommendation</b></summary>
  <p><b>编号</b>：[362]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02519</p>
  <p><b>作者</b>：Yongjun Chen,  Zhiwei Liu,  Jia Li,  Julian McAuley,  Caiming Xiong</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：sr model optimization steps within, sr also improves model robustness, sr models via contrastive ssl, unlabeled user behavior sequences, fusing user intent information</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Users' interactions with items are driven by various intents (e.g., preparing
for holiday gifts, shopping for fishing equipment, etc.).However, users'
underlying intents are often unobserved/latent, making it challenging to
leverage such latent intents forSequentialrecommendation(SR). To investigate
the benefits of latent intents and leverage them effectively for
recommendation, we proposeIntentContrastiveLearning(ICL), a general learning
paradigm that leverages a latent intent variable into SR. The core idea is to
learn users' intent distribution functions from unlabeled user behavior
sequences and optimize SR models with contrastive self-supervised learning
(SSL) by considering the learned intents to improve recommendation.
Specifically, we introduce a latent variable to represent users' intents and
learn the distribution function of the latent variable via clustering. We
propose to leverage the learned intents into SR models via contrastive SSL,
which maximizes the agreement between a view of sequence and its corresponding
intent. The training is alternated between intent representation learning and
the SR model optimization steps within the generalized expectation-maximization
(EM) framework. Fusing user intent information into SR also improves model
robustness. Experiments conducted on four real-world datasets demonstrate the
superiority of the proposed learning paradigm, which improves performance, and
robustness against data sparsity and noisy interaction issues.</p>
  </details>
</details>
<details>
  <summary>76. <b>标题：A Coalition Formation Game Approach for Personalized Federated Learning</b></summary>
  <p><b>编号</b>：[370]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02502</p>
  <p><b>作者</b>：Leijie Wu</p>
  <p><b>备注</b>：6 pages exclude the reference, 6 figures</p>
  <p><b>关键词</b>：complex multiwise influences take place among clients, perform personalized model aggregation based, first apply shapley value, achieve superior personalized accuracy, client local data distribution</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Facing the challenge of statistical diversity in client local data
distribution, personalized federated learning (PFL) has become a growing
research hotspot. Although the state-of-the-art methods with model
similarity-based pairwise collaboration have achieved promising performance,
they neglect the fact that model aggregation is essentially a collaboration
process within the coalition, where the complex multiwise influences take place
among clients. In this paper, we first apply Shapley value (SV) from coalition
game theory into the PFL scenario. To measure the multiwise collaboration among
a group of clients on the personalized learning performance, SV takes their
marginal contribution to the final result as a metric. We propose a novel
personalized algorithm: pFedSV, which can 1. identify each client's optimal
collaborator coalition and 2. perform personalized model aggregation based on
SV. Extensive experiments on various datasets (MNIST, Fashion-MNIST, and
CIFAR-10) are conducted with different Non-IID data settings (Pathological and
Dirichlet). The results show that pFedSV can achieve superior personalized
accuracy for each client, compared to the state-of-the-art benchmarks.</p>
  </details>
</details>
<details>
  <summary>77. <b>标题：Distributed Learning With Sparsified Gradient Differences</b></summary>
  <p><b>编号</b>：[375]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02491</p>
  <p><b>作者</b>：Yicheng Chen,  Rick S. Blum,  Martin Takac,  Brian M. Sadler</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：scale model learning without sacrificing convergence, best existing algorithms without slowing, solve distributed learning tasks, wireless communications learning scenarios, fast linear convergence rate</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A very large number of communications are typically required to solve
distributed learning tasks, and this critically limits scalability and
convergence speed in wireless communications applications. In this paper, we
devise a Gradient Descent method with Sparsification and Error Correction
(GD-SEC) to improve the communications efficiency in a general worker-server
architecture. Motivated by a variety of wireless communications learning
scenarios, GD-SEC reduces the number of bits per communication from worker to
server with no degradation in the order of the convergence rate. This enables
larger-scale model learning without sacrificing convergence or accuracy. At
each iteration of GD-SEC, instead of directly transmitting the entire gradient
vector, each worker computes the difference between its current gradient and a
linear combination of its previously transmitted gradients, and then transmits
the sparsified gradient difference to the server. A key feature of GD-SEC is
that any given component of the gradient difference vector will not be
transmitted if its magnitude is not sufficiently large. An error correction
technique is used at each worker to compensate for the error resulting from
sparsification. We prove that GD-SEC is guaranteed to converge for strongly
convex, convex, and nonconvex optimization problems with the same order of
convergence rate as GD. Furthermore, if the objective function is strongly
convex, GD-SEC has a fast linear convergence rate. Numerical results not only
validate the convergence rate of GD-SEC but also explore the communication bit
savings it provides. Given a target accuracy, GD-SEC can significantly reduce
the communications load compared to the best existing algorithms without
slowing down the optimization process.</p>
  </details>
</details>
<details>
  <summary>78. <b>标题：MarkovGNN: Graph Neural Networks on Markov Diffusion</b></summary>
  <p><b>编号</b>：[383]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02470</p>
  <p><b>作者</b>：Md. Khaledur Rahman,  Abhigya Agrawal,  Ariful Azad</p>
  <p><b>备注</b>：total 12 pages</p>
  <p><b>关键词</b>：markovgnn generates different stochastic matrices using, densely connected internally within communities, world networks contain well, different convolutional layers, graph neural networks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Most real-world networks contain well-defined community structures where
nodes are densely connected internally within communities. To learn from these
networks, we develop MarkovGNN that captures the formation and evolution of
communities directly in different convolutional layers. Unlike most Graph
Neural Networks (GNNs) that consider a static graph at every layer, MarkovGNN
generates different stochastic matrices using a Markov process and then uses
these community-capturing matrices in different layers. MarkovGNN is a general
approach that could be used with most existing GNNs. We experimentally show
that MarkovGNN outperforms other GNNs for clustering, node classification, and
visualization tasks. The source code of MarkovGNN is publicly available at
\url{this https URL}.</p>
  </details>
</details>
<details>
  <summary>79. <b>标题：Handling Distribution Shifts on Graphs: An Invariance Perspective</b></summary>
  <p><b>编号</b>：[386]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02466</p>
  <p><b>作者</b>：Qitian Wu,  Hengrui Zhang,  Junchi Yan,  David Wipf</p>
  <p><b>备注</b>：ICLR2022, 31 pages</p>
  <p><b>关键词</b>：increasing evidence suggesting neural networks, current endeavors mostly focus, design multiple context explorers, leverage invariant graph features, multiple virtual environments</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>There is increasing evidence suggesting neural networks' sensitivity to
distribution shifts, so that research on out-of-distribution (OOD)
generalization comes into the spotlight. Nonetheless, current endeavors mostly
focus on Euclidean data, and its formulation for graph-structured data is not
clear and remains under-explored, given the two-fold fundamental challenges: 1)
the inter-connection among nodes in one graph, which induces non-IID generation
of data points even under the same environment, and 2) the structural
information in the input graph, which is also informative for prediction. In
this paper, we formulate the OOD problem for node-level prediction on graphs
and develop a new domain-invariant learning approach, named
Explore-to-Extrapolate Risk Minimization, that facilitates GNNs to leverage
invariant graph features for prediction. The key difference to existing
invariant models is that we design multiple context explorers (specified as
graph editers in our case) that are adversarially trained to maximize the
variance of risks from multiple virtual environments. Such a design enables the
model to extrapolate from a single observed environment which is the common
case for node-level prediction. We prove the validity of our method by
theoretically showing its guarantee of a valid OOD solution and further
demonstrate its power on various real-world datasets for handling distribution
shifts from artificial spurious features, cross-domain transfers and dynamic
graph evolution.</p>
  </details>
</details>
<details>
  <summary>80. <b>标题：Space-Air-Ground Integrated Multi-domain Network Resource Orchestration  based on Virtual Network Architecture: a DRL Method</b></summary>
  <p><b>编号</b>：[388]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02459</p>
  <p><b>作者</b>：Peiying Zhang,  Chao Wang,  Neeraj Kumar,  Lei Liu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：traditional ground wireless communication networks cannot provide high, traditional wireless communication networks, sagin still faces huge challenges, domain virtual network embedding, ground integrated network</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Traditional ground wireless communication networks cannot provide
high-quality services for artificial intelligence (AI) applications such as
intelligent transportation systems (ITS) due to deployment, coverage and
capacity issues. The space-air-ground integrated network (SAGIN) has become a
research focus in the industry. Compared with traditional wireless
communication networks, SAGIN is more flexible and reliable, and it has wider
coverage and higher quality of seamless connection. However, due to its
inherent heterogeneity, time-varying and self-organizing characteristics, the
deployment and use of SAGIN still faces huge challenges, among which the
orchestration of heterogeneous resources is a key issue. Based on virtual
network architecture and deep reinforcement learning (DRL), we model SAGIN's
heterogeneous resource orchestration as a multi-domain virtual network
embedding (VNE) problem, and propose a SAGIN cross-domain VNE algorithm. We
model the different network segments of SAGIN, and set the network attributes
according to the actual situation of SAGIN and user needs. In DRL, the agent is
acted by a five-layer policy network. We build a feature matrix based on
network attributes extracted from SAGIN and use it as the agent training
environment. Through training, the probability of each underlying node being
embedded can be derived. In test phase, we complete the embedding process of
virtual nodes and links in turn based on this probability. Finally, we verify
the effectiveness of the algorithm from both training and testing.</p>
  </details>
</details>
<details>
  <summary>81. <b>标题：Security-Aware Virtual Network Embedding Algorithm based on  Reinforcement Learning</b></summary>
  <p><b>编号</b>：[395]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02452</p>
  <p><b>作者</b>：Peiying Zhang,  Chao Wang,  Chunxiao Jiang,  Abderrahim Benslimane</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：add security requirements level constraint, term revenue consumption ratio, aware vne algorithm based, term average return, security level constraint</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Virtual network embedding (VNE) algorithm is always the key problem in
network virtualization (NV) technology. At present, the research in this field
still has the following problems. The traditional way to solve VNE problem is
to use heuristic algorithm. However, this method relies on manual embedding
rules, which does not accord with the actual situation of VNE. In addition, as
the use of intelligent learning algorithm to solve the problem of VNE has
become a trend, this method is gradually outdated. At the same time, there are
some security problems in VNE. However, there is no intelligent algorithm to
solve the security problem of VNE. For this reason, this paper proposes a
security-aware VNE algorithm based on reinforcement learning (RL). In the
training phase, we use a policy network as a learning agent and take the
extracted attributes of the substrate nodes to form a feature matrix as input.
The learning agent is trained in this environment to get the mapping
probability of each substrate node. In the test phase, we map nodes according
to the mapping probability and use the breadth-first strategy (BFS) to map
links. For the security problem, we add security requirements level constraint
for each virtual node and security level constraint for each substrate node.
Virtual nodes can only be embedded on substrate nodes that are not lower than
the level of security requirements. Experimental results show that the proposed
algorithm is superior to other typical algorithms in terms of long-term average
return, long-term revenue consumption ratio and virtual network request (VNR)
acceptance rate.</p>
  </details>
</details>
<details>
  <summary>82. <b>标题：Transfer Reinforcement Learning for Differing Action Spaces via  Q-Network Representations</b></summary>
  <p><b>编号</b>：[400]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02442</p>
  <p><b>作者</b>：Nathan Beck,  Abhiramon Rajasekharan,  Trung Hieu Tran</p>
  <p><b>备注</b>：5 pages, 2 figures, 1 table</p>
  <p><b>关键词</b>：recent research focus within, reward shaping method based, source embedding similarity, different transition dynamics, brockman et al</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Transfer learning approaches in reinforcement learning aim to assist agents
in learning their target domains by leveraging the knowledge learned from other
agents that have been trained on similar source domains. For example, recent
research focus within this space has been placed on knowledge transfer between
tasks that have different transition dynamics and reward functions; however,
little focus has been placed on knowledge transfer between tasks that have
different action spaces. In this paper, we approach the task of transfer
learning between domains that differ in action spaces. We present a reward
shaping method based on source embedding similarity that is applicable to
domains with both discrete and continuous action spaces. The efficacy of our
approach is evaluated on transfer to restricted action spaces in the Acrobot-v1
and Pendulum-v0 domains (Brockman et al. 2016). A comparison with two baselines
shows that our method does not outperform these baselines in these continuous
action spaces but does show an improvement in these discrete action spaces. We
conclude our analysis with future directions for this work.</p>
  </details>
</details>
<details>
  <summary>83. <b>标题：Zero Experience Required: Plug & Play Modular Transfer Learning for  Semantic Visual Navigation</b></summary>
  <p><b>编号</b>：[402]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02440</p>
  <p><b>作者</b>：Ziad Al-Halah,  Santhosh K. Ramakrishnan,  Kristen Grauman</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：novel modular transfer learning model, target tasks without receiving, multiple target tasks, challenging tasks show, outperforms sota models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In reinforcement learning for visual navigation, it is common to develop a
model for each new task, and train that model from scratch with task-specific
interactions in 3D environments. However, this process is expensive; massive
amounts of interactions are needed for the model to generalize well. Moreover,
this process is repeated whenever there is a change in the task type or the
goal modality. We present a unified approach to visual navigation using a novel
modular transfer learning model. Our model can effectively leverage its
experience from one source task and apply it to multiple target tasks (e.g.,
ObjectNav, RoomNav, ViewNav) with various goal modalities (e.g., image, sketch,
audio, label). Furthermore, our model enables zero-shot experience learning,
whereby it can solve the target tasks without receiving any task-specific
interactive training. Our experiments on multiple photorealistic datasets and
challenging tasks show that our approach learns faster, generalizes better, and
outperforms SoTA models by a significant margin.</p>
  </details>
</details>
<details>
  <summary>84. <b>标题：Neural Logic Analogy Learning</b></summary>
  <p><b>编号</b>：[403]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02436</p>
  <p><b>作者</b>：Yujia Fan,  Yongfeng Zhang</p>
  <p><b>备注</b>：11 pages, 1 figure, 3 tables</p>
  <p><b>关键词</b>：model builds computational graph integrating neural network, main idea behind current approaches, based noan approach outperforms state, problem makes current approaches unable, propose neural logic analogy learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Letter-string analogy is an important analogy learning task which seems to be
easy for humans but very challenging for machines. The main idea behind current
approaches to solving letter-string analogies is to design heuristic rules for
extracting analogy structures and constructing analogy mappings. However, one
key problem is that it is difficult to build a comprehensive and exhaustive set
of analogy structures which can fully describe the subtlety of analogies. This
problem makes current approaches unable to handle complicated letter-string
analogy problems. In this paper, we propose Neural logic analogy learning
(Noan), which is a dynamic neural architecture driven by differentiable logic
reasoning to solve analogy problems. Each analogy problem is converted into
logical expressions consisting of logical variables and basic logical
operations (AND, OR, and NOT). More specifically, Noan learns the logical
variables as vector embeddings and learns each logical operation as a neural
module. In this way, the model builds computational graph integrating neural
network with logical reasoning to capture the internal logical structure of the
input letter strings. The analogy learning problem then becomes a True/False
evaluation problem of the logical expressions. Experiments show that our
machine learning-based Noan approach outperforms state-of-the-art approaches on
standard letter-string analogy benchmark datasets.</p>
  </details>
</details>
<details>
  <summary>85. <b>标题：SMODICE: Versatile Offline Imitation Learning via State Occupancy  Matching</b></summary>
  <p><b>编号</b>：[405]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02433</p>
  <p><b>作者</b>：Yecheng Jason Ma,  Andrew Shen,  Dinesh Jayaraman,  Osbert Bastani</p>
  <p><b>备注</b>：Project website: this https URL</p>
  <p><b>关键词</b>：propose state matching offline distribution correction estimation, significantly outperforms prior state, three offline il settings, dimensional offline benchmarks, three problem settings</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose State Matching Offline DIstribution Correction Estimation
(SMODICE), a novel and versatile algorithm for offline imitation learning (IL)
via state-occupancy matching. We show that the SMODICE objective admits a
simple optimization procedure through an application of Fenchel duality and an
analytic solution in tabular MDPs. Without requiring access to expert actions,
SMODICE can be effectively applied to three offline IL settings: (i) imitation
from observations (IfO), (ii) IfO with dynamics or morphologically mismatched
expert, and (iii) example-based reinforcement learning, which we show can be
formulated as a state-occupancy matching problem. We extensively evaluate
SMODICE on both gridworld environments as well as on high-dimensional offline
benchmarks. Our results demonstrate that SMODICE is effective for all three
problem settings and significantly outperforms prior state-of-art.</p>
  </details>
</details>
<details>
  <summary>86. <b>标题：Transformers and the representation of biomedical background knowledge</b></summary>
  <p><b>编号</b>：[406]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02432</p>
  <p><b>作者</b>：Oskar Wysocki (1,2),  Zili Zhou (1,2),  Paul O'Regan (2),  Deborah Ferreira (1),  Magdalena Wysocka (2),  Dónal Landers (2),  André Freitas (1,2,3) ((1) Department of Computer Science, The University of Manchester, (2) digital Experimental Cancer Medicine Team, Cancer Biomarker Centre, CRUK Manchester Institute, University of Manchester, (3) Idiap Research Institute)</p>
  <p><b>备注</b>：22 pages, 12 figures, supplementary methods, tables and figures at the end of the manuscript</p>
  <p><b>关键词</b>：publicly available biomedical corpora, indeed encode biological knowledge, biomedical domain based, scale biological knowledge, different transformer baselines</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>BioBERT and BioMegatron are Transformers models adapted for the biomedical
domain based on publicly available biomedical corpora. As such, they have the
potential to encode large-scale biological knowledge. We investigate the
encoding and representation of biological knowledge in these models, and its
potential utility to support inference in cancer precision medicine - namely,
the interpretation of the clinical significance of genomic alterations. We
compare the performance of different transformer baselines; we use probing to
determine the consistency of encodings for distinct entities; and we use
clustering methods to compare and contrast the internal properties of the
embeddings for genes, variants, drugs and diseases. We show that these models
do indeed encode biological knowledge, although some of this is lost in
fine-tuning for specific tasks. Finally, we analyse how the models behave with
regard to biases and imbalances in the dataset.</p>
  </details>
</details>
<details>
  <summary>87. <b>标题：HENRI: High Efficiency Negotiation-based Robust Interface for  Multi-party Multi-issue Negotiation over the Internet</b></summary>
  <p><b>编号</b>：[408]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02430</p>
  <p><b>作者</b>：Saurabh Deochake,  Shashank Kanth,  Subhadip Chakraborty,  Suresh Sarode,  Vidyasagar Potdar,  Debajyoti Mukhopadhyay</p>
  <p><b>备注</b>：CUBE '12: Proceedings of the CUBE International Information Technology Conference. arXiv admin note: substantial text overlap with arXiv:1206.5884</p>
  <p><b>关键词</b>：allows multi party multi issue negotiation, multiple issues concerning every party, full fledged negotiation system, system also provides enhancements, utility considering non</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper proposes a framework for a full fledged negotiation system that
allows multi party multi issue negotiation. It focuses on the negotiation
protocol to be observed and provides a platform for concurrent and independent
negotiation on individual issues using the concept of multi threading. It
depicts the architecture of an agent detailing its components. The paper sets
forth a hierarchical pattern for the multiple issues concerning every party.
The system also provides enhancements such as the time-to-live counters for
every advertisement, refinement of utility considering non-functional
attributes, prioritization of issues, by assigning weights to issues.</p>
  </details>
</details>
<details>
  <summary>88. <b>标题：The influence of labeling techniques in classifying human manipulation  movement of different speed</b></summary>
  <p><b>编号</b>：[411]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02426</p>
  <p><b>作者</b>：Sadique Adnan Siddiqui,  Lisa Gutzeit,  Frank Kirchner</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：stacking scenario comprising simple arm movements, labeled using two different approaches, labeled using two different approaches, paced data labeled using trajectories, extreme gradient boosting classifier</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this work, we investigate the influence of labeling methods on the
classification of human movements on data recorded using a marker-based motion
capture system. The dataset is labeled using two different approaches, one
based on video data of the movements, the other based on the movement
trajectories recorded using the motion capture system. The dataset is labeled
using two different approaches, one based on video data of the movements, the
other based on the movement trajectories recorded using the motion capture
system. The data was recorded from one participant performing a stacking
scenario comprising simple arm movements at three different speeds (slow,
normal, fast). Machine learning algorithms that include k-Nearest Neighbor,
Random Forest, Extreme Gradient Boosting classifier, Convolutional Neural
networks (CNN), Long Short-Term Memory networks (LSTM), and a combination of
CNN-LSTM networks are compared on their performance in recognition of these arm
movements. The models were trained on actions performed on slow and normal
speed movements segments and generalized on actions consisting of fast-paced
human movement. It was observed that all the models trained on normal-paced
data labeled using trajectories have almost 20% improvement in accuracy on test
data in comparison to the models trained on data labeled using videos of the
performed experiments.</p>
  </details>
</details>
<details>
  <summary>89. <b>标题：Model-Free Reinforcement Learning for Symbolic Automata-encoded  Objectives</b></summary>
  <p><b>编号</b>：[419]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02404</p>
  <p><b>作者</b>：Anand Balakrishnan,  Stefan Jaksic,  Edgar Aguilar Lozano,  Dejan Nickovic,  Jyotirmoy Deshmukh</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：based rewarding strategy still allows us, symbolic automata allows us, satisfy desired task objectives, agent receives positive rewards, rl agent crucially depend</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Reinforcement learning (RL) is a popular approach for robotic path planning
in uncertain environments. However, the control policies trained for an RL
agent crucially depend on user-defined, state-based reward functions. Poorly
designed rewards can lead to policies that do get maximal rewards but fail to
satisfy desired task objectives or are unsafe. There are several examples of
the use of formal languages such as temporal logics and automata to specify
high-level task specifications for robots (in lieu of Markovian rewards).
Recent efforts have focused on inferring state-based rewards from formal
specifications; here, the goal is to provide (probabilistic) guarantees that
the policy learned using RL (with the inferred rewards) satisfies the
high-level formal specification. A key drawback of several of these techniques
is that the rewards that they infer are sparse: the agent receives positive
rewards only upon completion of the task and no rewards otherwise. This
naturally leads to poor convergence properties and high variance during RL. In
this work, we propose using formal specifications in the form of symbolic
automata: these serve as a generalization of both bounded-time temporal
logic-based specifications as well as automata. Furthermore, our use of
symbolic automata allows us to define non-sparse potential-based rewards which
empirically shape the reward surface, leading to better convergence during RL.
We also show that our potential-based rewarding strategy still allows us to
obtain the policy that maximizes the satisfaction of the given specification.</p>
  </details>
</details>
<details>
  <summary>90. <b>标题：Self-Adaptive Forecasting for Improved Deep Learning on Non-Stationary  Time-Series</b></summary>
  <p><b>编号</b>：[420]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02403</p>
  <p><b>作者</b>：Sercan O. Arik,  Nathanael C. Yoder,  Tomas Pfister</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：predicting masked inputs backward, model selection procedures suboptimal, method enables efficient adaptation, series datasets often violate, adaptation stage prior</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Real-world time-series datasets often violate the assumptions of standard
supervised learning for forecasting -- their distributions evolve over time,
rendering the conventional training and model selection procedures suboptimal.
In this paper, we propose a novel method, Self-Adaptive Forecasting (SAF), to
modify the training of time-series forecasting models to improve their
performance on forecasting tasks with such non-stationary time-series data. SAF
integrates a self-adaptation stage prior to forecasting based on `backcasting',
i.e. predicting masked inputs backward in time. This is a form of test-time
training that creates a self-supervised learning problem on test samples before
performing the prediction task. In this way, our method enables efficient
adaptation of encoded representations to evolving distributions, leading to
superior generalization. SAF can be integrated with any canonical
encoder-decoder based time-series architecture such as recurrent neural
networks or attention-based architectures. On synthetic and real-world datasets
in domains where time-series data are known to be notoriously non-stationary,
such as healthcare and finance, we demonstrate a significant benefit of SAF in
improving forecasting accuracy.</p>
  </details>
</details>
<details>
  <summary>91. <b>标题：A Temporal-Difference Approach to Policy Gradient Estimation</b></summary>
  <p><b>编号</b>：[423]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02396</p>
  <p><b>作者</b>：Samuele Tosatto,  Andrew Patterson,  Martha White,  A. Rupam Mahmood</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：sutton et al ., 2000, start state without requiring, cumulative discounted state distribution, recursively estimated due, certain realizability conditions</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The policy gradient theorem (Sutton et al., 2000) prescribes the usage of a
cumulative discounted state distribution under the target policy to approximate
the gradient. Most algorithms based on this theorem, in practice, break this
assumption, introducing a distribution shift that can cause the convergence to
poor solutions. In this paper, we propose a new approach of reconstructing the
policy gradient from the start state without requiring a particular sampling
strategy. The policy gradient calculation in this form can be simplified in
terms of a gradient critic, which can be recursively estimated due to a new
Bellman equation of gradients. By using temporal-difference updates of the
gradient critic from an off-policy data stream, we develop the first estimator
that sidesteps the distribution shift issue in a model-free way. We prove that,
under certain realizability conditions, our estimator is unbiased regardless of
the sampling strategy. We empirically show that our technique achieves a
superior bias-variance trade-off and performance in presence of off-policy
samples.</p>
  </details>
</details>
<details>
  <summary>92. <b>标题：Malleable Agents for Re-Configurable Robotic Manipulators</b></summary>
  <p><b>编号</b>：[424]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02395</p>
  <p><b>作者</b>：Athindran Ramesh Kumar,  Gurudutt Hosangadi</p>
  <p><b>备注</b>：8 pages, 8 figures, 2 tables</p>
  <p><b>关键词</b>：sequence neural networks embedded, multiple rigid links connected, robots requires adapting, configurable robots potentially, deep reinforcement learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Re-configurable robots potentially have more utility and flexibility for many
real-world tasks. Designing a learning agent to operate such robots requires
adapting to different configurations. While deep reinforcement learning has had
immense success in robotic manipulation, domain adaptation is a significant
problem that limits its applicability to real-world robotics. We focus on
robotic arms with multiple rigid links connected by joints. Recent attempts
have performed domain adaptation and Sim2Real transfer to provide robustness to
robotic arm dynamics and sensor/camera variations. However, there have been no
previous attempts to adapt to robotic arms with a varying number of links. We
propose an RL agent with sequence neural networks embedded in the deep neural
network to adapt to robotic arms that have a varying number of links. Further,
with the additional tool of domain randomization, this agent adapts to
different configurations with varying number/length of links and dynamics
noise. We perform simulations on a 2D N-link arm to show the ability of our
network to transfer and generalize efficiently.</p>
  </details>
</details>
<details>
  <summary>93. <b>标题：JARVix at SemEval-2022 Task 2: It Takes One to Know One? Idiomaticity  Detection using Zero and One Shot Learning</b></summary>
  <p><b>编号</b>：[425]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02394</p>
  <p><b>作者</b>：Ashwin Pathak,  Raj Shah,  Vaibhav Kumar,  Yash Jakhotiya</p>
  <p><b>备注</b>：Best Project Award for Georgia Tech CS 7650. Code available at this https URL</p>
  <p><b>关键词</b>：train multiple large language models, natural language processing tasks, large language models, given sentence contains, vector representations fail</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large Language Models have been successful in a wide variety of Natural
Language Processing tasks by capturing the compositionality of the text
representations. In spite of their great success, these vector representations
fail to capture meaning of idiomatic multi-word expressions (MWEs). In this
paper, we focus on the detection of idiomatic expressions by using binary
classification. We use a dataset consisting of the literal and idiomatic usage
of MWEs in English and Portuguese. Thereafter, we perform the classification in
two different settings: zero shot and one shot, to determine if a given
sentence contains an idiom or not. N shot classification for this task is
defined by N number of common idioms between the training and testing sets. In
this paper, we train multiple Large Language Models in both the settings and
achieve an F1 score (macro) of 0.73 for the zero shot setting and an F1 score
(macro) of 0.85 for the one shot setting. An implementation of our work can be
found at
this https URL .</p>
  </details>
</details>
<details>
  <summary>94. <b>标题：The impact of feature importance methods on the interpretation of defect  classifiers</b></summary>
  <p><b>编号</b>：[429]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02389</p>
  <p><b>作者</b>：Gopi Krishnan Rajbahadur,  Shaowei Wang,  Yasutaka Kamei,  Ahmed E. Hassan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：commonly used cs methods yield vastly different feature importance ranks, simple methods like cfs improves agreement, compute different feature importance ranks even, advanced feature interaction removal methods, strong agreement among different methods</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Classifier specific (CS) and classifier agnostic (CA) feature importance
methods are widely used (often interchangeably) by prior studies to derive
feature importance ranks from a defect classifier. However, different feature
importance methods are likely to compute different feature importance ranks
even for the same dataset and classifier. Hence such interchangeable use of
feature importance methods can lead to conclusion instabilities unless there is
a strong agreement among different methods. Therefore, in this paper, we
evaluate the agreement between the feature importance ranks associated with the
studied classifiers through a case study of 18 software projects and six
commonly used classifiers. We find that: 1) The computed feature importance
ranks by CA and CS methods do not always strongly agree with each other. 2) The
computed feature importance ranks by the studied CA methods exhibit a strong
agreement including the features reported at top-1 and top-3 ranks for a given
dataset and classifier, while even the commonly used CS methods yield vastly
different feature importance ranks. Such findings raise concerns about the
stability of conclusions across replicated studies. We further observe that the
commonly used defect datasets are rife with feature interactions and these
feature interactions impact the computed feature importance ranks of the CS
methods (not the CA methods). We demonstrate that removing these feature
interactions, even with simple methods like CFS improves agreement between the
computed feature importance ranks of CA and CS methods. In light of our
findings, we provide guidelines for stakeholders and practitioners when
performing model interpretation and directions for future research, e.g.,
future research is needed to investigate the impact of advanced feature
interaction removal methods on computed feature importance ranks of different
CS methods.</p>
  </details>
</details>
<details>
  <summary>95. <b>标题：Automatic Identification of Self-Admitted Technical Debt from Different  Sources</b></summary>
  <p><b>编号</b>：[430]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02387</p>
  <p><b>作者</b>：Yikun Li,  Mohamed Soliman,  Paris Avgeriou</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：e ., source code comments, g ., code comments, issue tracking systems ),, source code comments, g ., maintainability</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Technical debt is a metaphor describing the situation that long-term benefits
(e.g., maintainability and evolvability of software) are traded for short-term
goals. When technical debt is admitted explicitly by developers in software
artifacts (e.g., code comments or issue tracking systems), it is termed as
Self-Admitted Technical Debt or SATD. Technical debt could be admitted in
different sources, such as source code comments, issue tracking systems, pull
requests, and commit messages. However, there is no approach proposed for
identifying SATD from different sources. Thus, in this paper, we propose an
approach for automatically identifying SATD from different sources (i.e.,
source code comments, issue trackers, commit messages, and pull requests).</p>
  </details>
</details>
<details>
  <summary>96. <b>标题：Using Large-scale Heterogeneous Graph Representation Learning for Code  Review Recommendations</b></summary>
  <p><b>编号</b>：[431]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02385</p>
  <p><b>作者</b>：Jiyang Zhang,  Chandra Maddila,  Ram Bairi,  Christian Bird,  Ujjwal Raizada,  Apoorva Agrawal,  Yamini Jhawar,  Kim Herzig,  Arie van Deursen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：modern source code management systems, reviewer recommendation systems rely primarily, reviewer recommendation systems perform better, well accepted problem within, traditional reviewer recommenders miss</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Code review is an integral part of any mature software development process,
and identifying the best reviewer for a code change is a well accepted problem
within the software engineering community. Selecting a reviewer who lacks
expertise and understanding can slow development or result in more defects. To
date, most reviewer recommendation systems rely primarily on historical file
change and review information; those who changed or reviewed a file in the past
are the best positioned to review in the future. We posit that while these
approaches are able to identify and suggest qualified reviewers, they may be
blind to reviewers who have the needed expertise and have simply never
interacted with the changed files before. To address this, we present CORAL, a
novel approach to reviewer recommendation that leverages a socio-technical
graph built from the rich set of entities (developers, repositories, files,
pull requests, work-items, etc.) and their relationships in modern source code
management systems. We employ a graph convolutional neural network on this
graph and train it on two and a half years of history on 332 repositories. We
show that CORAL is able to model the manual history of reviewer selection
remarkably well. Further, based on an extensive user study, we demonstrate that
this approach identifies relevant and qualified reviewers who traditional
reviewer recommenders miss, and that these developers desire to be included in
the review process. Finally, we find that "classical" reviewer recommendation
systems perform better on smaller (in terms of developers) software projects
while CORAL excels on larger projects, suggesting that there is "no one model
to rule them all."</p>
  </details>
</details>
<details>
  <summary>97. <b>标题：A Discourse on MetODS: Meta-Optimized Dynamical Synapses for  Meta-Reinforcement Learning</b></summary>
  <p><b>编号</b>：[434]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02363</p>
  <p><b>作者</b>：Mathieu Chalvidal,  Thomas Serre,  Rufin VanRullen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：computational mechanisms support flexible behavioral adaptation, robust reinforcement learning programs emerge spontaneously, leverages fast synaptic dynamics influenced, parameters governing metods synaptic processes, model learning powerful control rules</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent meta-reinforcement learning work has emphasized the importance of
mnemonic control for agents to quickly assimilate relevant experience in new
contexts and suitably adapt their policy. However, what computational
mechanisms support flexible behavioral adaptation from past experience remains
an open question. Inspired by neuroscience, we propose MetODS (for
Meta-Optimized Dynamical Synapses), a broadly applicable model of
meta-reinforcement learning which leverages fast synaptic dynamics influenced
by action-reward feedback. We develop a theoretical interpretation of MetODS as
a model learning powerful control rules in the policy space and demonstrate
empirically that robust reinforcement learning programs emerge spontaneously
from them. We further propose a formalism which efficiently optimizes the
meta-parameters governing MetODS synaptic processes. In multiple experiments
and domains, MetODS outperforms or compares favorably with previous
meta-reinforcement learning approaches. Our agents can perform one-shot
learning, approaches optimal exploration/exploitation strategies, generalize
navigation principles to unseen environments and demonstrate a strong ability
to learn adaptive motor policies.</p>
  </details>
</details>
<details>
  <summary>98. <b>标题：Towards Training Reproducible Deep Learning Models</b></summary>
  <p><b>编号</b>：[445]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02326</p>
  <p><b>作者</b>：Boyuan Chen,  Mingzhi Wen,  Yong Shi,  Dayi Lin,  Gopi Krishnan Rajbahadur,  Zhen Ming (Jack) Jiang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：successfully reproduce six open source, approach includes three main parts, case study results show, g ., gpu )., g ., dl algorithms</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Reproducibility is an increasing concern in Artificial Intelligence (AI),
particularly in the area of Deep Learning (DL). Being able to reproduce DL
models is crucial for AI-based systems, as it is closely tied to various tasks
like training, testing, debugging, and auditing. However, DL models are
challenging to be reproduced due to issues like randomness in the software
(e.g., DL algorithms) and non-determinism in the hardware (e.g., GPU). There
are various practices to mitigate some of the aforementioned issues. However,
many of them are either too intrusive or can only work for a specific usage
context. In this paper, we propose a systematic approach to training
reproducible DL models. Our approach includes three main parts: (1) a set of
general criteria to thoroughly evaluate the reproducibility of DL models for
two different domains, (2) a unified framework which leverages a
record-and-replay technique to mitigate software-related randomness and a
profile-and-patch technique to control hardware-related non-determinism, and
(3) a reproducibility guideline which explains the rationales and the
mitigation strategies on conducting a reproducible training process for DL
models. Case study results show our approach can successfully reproduce six
open source and one commercial DL models.</p>
  </details>
</details>
<details>
  <summary>99. <b>标题：Investigating the fidelity of explainable artificial intelligence  methods for applications of convolutional neural networks in geoscience</b></summary>
  <p><b>编号</b>：[448]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03407</p>
  <p><b>作者</b>：Antonios Mamalakis,  Elizabeth A. Barnes,  Imme Ebert-Uphoff</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：results highlight several important issues, recently attracted great attention, g ., gradient shattering, extract predictive spatiotemporal patterns, help guide best practices</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Convolutional neural networks (CNNs) have recently attracted great attention
in geoscience due to their ability to capture non-linear system behavior and
extract predictive spatiotemporal patterns. Given their black-box nature
however, and the importance of prediction explainability, methods of
explainable artificial intelligence (XAI) are gaining popularity as a means to
explain the CNN decision-making strategy. Here, we establish an intercomparison
of some of the most popular XAI methods and investigate their fidelity in
explaining CNN decisions for geoscientific applications. Our goal is to raise
awareness of the theoretical limitations of these methods and gain insight into
the relative strengths and weaknesses to help guide best practices. The
considered XAI methods are first applied to an idealized attribution benchmark,
where the ground truth of explanation of the network is known a priori, to help
objectively assess their performance. Secondly, we apply XAI to a
climate-related prediction setting, namely to explain a CNN that is trained to
predict the number of atmospheric rivers in daily snapshots of climate
simulations. Our results highlight several important issues of XAI methods
(e.g., gradient shattering, inability to distinguish the sign of attribution,
ignorance to zero input) that have previously been overlooked in our field and,
if not considered cautiously, may lead to a distorted picture of the CNN
decision-making strategy. We envision that our analysis will motivate further
investigation into XAI fidelity and will help towards a cautious implementation
of XAI in geoscience, which can lead to further exploitation of CNNs and deep
learning for prediction problems.</p>
  </details>
</details>
<details>
  <summary>100. <b>标题：Cyber-resilience for marine navigation by information fusion and change  detection</b></summary>
  <p><b>编号</b>：[461]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03268</p>
  <p><b>作者</b>：Dimitrios Dagdilelis,  Mogens Blanke,  Rasmus Hjorth Andersen,  Roberto Galeazzi</p>
  <p><b>备注</b>：18 pages, 21 figures</p>
  <p><b>关键词</b>：generalized likelihood ratio change detector, first stage extracts shoreline features, second stage associates buoy, combined parametric gaussian modelling, using real data logged</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Cyber-resilience is an increasing concern in developing autonomous navigation
solutions for marine vessels. This paper scrutinizes cyber-resilience
properties of marine navigation through a prism with three edges: multiple
sensor information fusion, diagnosis of not-normal behaviours, and change
detection. It proposes a two-stage estimator for diagnosis and mitigation of
sensor signals used for coastal navigation. Developing a Likelihood Field
approach, a first stage extracts shoreline features from radar and matches them
to the electronic navigation chart. A second stage associates buoy and beacon
features from the radar with chart information. Using real data logged at sea
tests combined with simulated spoofing, the paper verifies the ability to
timely diagnose and isolate an attempt to compromise position measurements. A
new approach is suggested for high level processing of received data to
evaluate their consistency, that is agnostic to the underlying technology of
the individual sensory input. A combined parametric Gaussian modelling and
Kernel Density Estimation is suggested and compared with a generalized
likelihood ratio change detector that uses sliding windows. The paper shows how
deviations from nominal behaviour and isolation of the components is possible
when under attack or when defects in sensors occur.</p>
  </details>
</details>
<details>
  <summary>101. <b>标题：Team Cogitat at NeurIPS 2021: Benchmarks for EEG Transfer Learning  Competition</b></summary>
  <p><b>编号</b>：[462]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03267</p>
  <p><b>作者</b>：Stylianos Bakas,  Siegfried Ludwig,  Konstantinos Barmpas,  Mehdi Bahri,  Yannis Panagakis,  Nikolaos Laskaris,  Dimitrios A. Adamos,  Stefanos Zafeiriou</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：older age groups without personalized calibration data, explicitly align feature distributions, source motor imagery datasets, shift across different datasets, personalized calibration data</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Building subject-independent deep learning models for EEG decoding faces the
challenge of strong covariate-shift across different datasets, subjects and
recording sessions. Our approach to address this difficulty is to explicitly
align feature distributions at various layers of the deep learning model, using
both simple statistical techniques as well as trainable methods with more
representational capacity. This follows in a similar vein as covariance-based
alignment methods, often used in a Riemannian manifold context. The methodology
proposed herein won first place in the 2021 Benchmarks in EEG Transfer Learning
(BEETL) competition, hosted at the NeurIPS conference. The first task of the
competition consisted of sleep stage classification, which required the
transfer of models trained on younger subjects to perform inference on multiple
subjects of older age groups without personalized calibration data, requiring
subject-independent models. The second task required to transfer models trained
on the subjects of one or more source motor imagery datasets to perform
inference on two target datasets, providing a small set of personalized
calibration data for multiple test subjects.</p>
  </details>
</details>
<details>
  <summary>102. <b>标题：Comprehensive survey of computational learning methods for analysis of  gene expression data in genomics</b></summary>
  <p><b>编号</b>：[484]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02958</p>
  <p><b>作者</b>：Nikita Bhandari,  Rahee Walambe,  Ketan Kotech,  Satyajeet Khare</p>
  <p><b>备注</b>：51 pages, 9 figures, 5 tables</p>
  <p><b>关键词</b>：sample observations requires sophisticated computational approaches, computational analysis methods including machine learning, rna sequencing produce enormous amounts, analysis methods including class comparison, throughput gene expression analysis methods</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Computational analysis methods including machine learning have a significant
impact in the fields of genomics and medicine. High-throughput gene expression
analysis methods such as microarray technology and RNA sequencing produce
enormous amounts of data. Traditionally, statistical methods are used for
comparative analysis of the gene expression data. However, more complex
analysis for classification and discovery of feature genes or sample
observations requires sophisticated computational approaches. In this review,
we compile various statistical and computational tools used in analysis of
expression microarray data. Even though, the methods are discussed in the
context of expression microarray data, they can also be applied for the
analysis of RNA sequencing or quantitative proteomics datasets. We specifically
discuss methods for missing value (gene expression) imputation, feature gene
scaling, selection and extraction of features for dimensionality reduction, and
learning and analysis of expression data. We discuss the types of missing
values and the methods and approaches usually employed in their imputation. We
also discuss methods of data transformation and feature scaling viz.
normalization and standardization. Various approaches used in feature selection
and extraction are also reviewed. Lastly, learning and analysis methods
including class comparison, class prediction, and class discovery along with
their evaluation parameters are described in detail. We have described the
process of generation of a microarray gene expression data along with
advantages and limitations of the above-mentioned techniques. We believe that
this detailed review will help the users to select appropriate methods based on
the type of data and the expected outcome.</p>
  </details>
</details>
<details>
  <summary>103. <b>标题：Inter-subject Contrastive Learning for Subject Adaptive EEG-based Visual  Recognition</b></summary>
  <p><b>编号</b>：[489]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02901</p>
  <p><b>作者</b>：Pilhyeon Lee,  Sunhee Hwang,  Jewook Lee,  Minjung Shin,  Seogkyu Jeon,  Hyeran Byun</p>
  <p><b>备注</b>：Accepted by the 10th IEEE International Winter Conference on Brain-Computer Interface (BCI 2022). Code is available at this https URL</p>
  <p><b>关键词</b>：common knowledge shared across different subjects, five eeg samples per class, thereby achieving promising performance, visual stimuli based, dedicated sampling principle</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper tackles the problem of subject adaptive EEG-based visual
recognition. Its goal is to accurately predict the categories of visual stimuli
based on EEG signals with only a handful of samples for the target subject
during training. The key challenge is how to appropriately transfer the
knowledge obtained from abundant data of source subjects to the subject of
interest. To this end, we introduce a novel method that allows for learning
subject-independent representation by increasing the similarity of features
sharing the same class but coming from different subjects. With the dedicated
sampling principle, our model effectively captures the common knowledge shared
across different subjects, thereby achieving promising performance for the
target subject even under harsh problem settings with limited data.
Specifically, on the EEG-ImageNet40 benchmark, our model records the top-1 /
top-3 test accuracy of 72.6% / 91.6% when using only five EEG samples per class
for the target subject. Our code is available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>104. <b>标题：Deep Convolutional Learning-Aided Detector for Generalized Frequency  Division Multiplexing with Index Modulation</b></summary>
  <p><b>编号</b>：[493]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02876</p>
  <p><b>作者</b>：Merve Turhan,  Ersin Öztürk,  Hakan Ali Çırpan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：demodulation scheme provides better ber performance compared, enables im blocks processing independently, proposed deep convolutional neural network, generalized frequency division multiplexing, proposed method first pre</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, a deep convolutional neural network-based symbol detection and
demodulation is proposed for generalized frequency division multiplexing with
index modulation (GFDM-IM) scheme in order to improve the error performance of
the system. The proposed method first pre-processes the received signal by
using a zero-forcing (ZF) detector and then uses a neural network consisting of
a convolutional neural network (CNN) followed by a fully-connected neural
network (FCNN). The FCNN part uses only two fully-connected layers, which can
be adapted to yield a trade-off between complexity and bit error rate (BER)
performance. This two-stage approach prevents the getting stuck of neural
network in a saddle point and enables IM blocks processing independently. It
has been demonstrated that the proposed deep convolutional neural network-based
detection and demodulation scheme provides better BER performance compared to
ZF detector with a reasonable complexity increase. We conclude that
non-orthogonal waveforms combined with IM schemes with the help of deep
learning is a promising physical layer (PHY) scheme for future wireless
networks</p>
  </details>
</details>
<details>
  <summary>105. <b>标题：Deep Learning-Aided Spatial Multiplexing with Index Modulation</b></summary>
  <p><b>编号</b>：[494]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02856</p>
  <p><b>作者</b>：Merve Turhan,  Ersin Ozturk,  Hakan Ali Cirpan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：zf detector without increasing computational complexity, significant error performance gains compared, dl )- aided data detection, eventually reveals reduced complexity, using subblockbased detection provided</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, deep learning (DL)-aided data detection of spatial
multiplexing (SMX) multiple-input multiple-output (MIMO) transmission with
index modulation (IM) (Deep-SMX-IM) has been proposed. Deep-SMX-IM has been
constructed by combining a zero-forcing (ZF) detector and DL technique. The
proposed method uses the significant advantages of DL techniques to learn
transmission characteristics of the frequency and spatial domains. Furthermore,
thanks to using subblockbased detection provided by IM, Deep-SMX-IM is a
straightforward method, which eventually reveals reduced complexity. It has
been shown that Deep-SMX-IM has significant error performance gains compared to
ZF detector without increasing computational complexity for different system
configurations.</p>
  </details>
</details>
<details>
  <summary>106. <b>标题：OMLT: Optimization & Machine Learning Toolkit</b></summary>
  <p><b>编号</b>：[533]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.02414</p>
  <p><b>作者</b>：Francesco Ceccon,  Jordan Jalving,  Joshua Haddad,  Alexander Thebelt,  Calvin Tsay,  Carl D. Laird,  Ruth Misener</p>
  <p><b>备注</b>：7 pages, 1 figure</p>
  <p><b>关键词</b>：source software package incorporating neural network, boosted tree surrogate models, algebraic modeling language pyomo, trained using machine learning, machine learning toolkit</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The optimization and machine learning toolkit (OMLT) is an open-source
software package incorporating neural network and gradient-boosted tree
surrogate models, which have been trained using machine learning, into larger
optimization problems. We discuss the advances in optimization technology that
made OMLT possible and show how OMLT seamlessly integrates with the algebraic
modeling language Pyomo. We demonstrate how to use OMLT for solving
decision-making problems in both computer science and engineering.</p>
  </details>
</details>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">徐耀彬</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://louishsu.xyz/2022/02/09/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html">http://louishsu.xyz/2022/02/09/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://louishsu.xyz" target="_blank">LOUIS' BLOG</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"></div><div class="post_share"><div class="social-share" data-image="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="next-post pull-full"><a href="/2021/10/22/%E4%B8%AD%E5%9B%BD%E6%B3%95%E5%BE%8B%E6%99%BA%E8%83%BD%E6%8A%80%E6%9C%AF%E8%AF%84%E6%B5%8B(CAIL2021)%EF%BC%9A%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96(Rank2).html"><img class="next-cover" src="http://cail.cipsc.org.cn/img/index_mainpic.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">中国法律智能技术评测(CAIL2021)：信息抽取(Rank2)</div></div></a></div></nav><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="twikoo-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="card-info-avatar is-center"><img class="avatar-img" src="/img/touxiang.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/><div class="author-info__name">徐耀彬</div><div class="author-info__description">做知识的原创者！</div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">11</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">标签</div><div class="length-num">3</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">分类</div><div class="length-num">7</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/isLouisHsu"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/isLouisHsu" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:is.louishsu@foxmail.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>公告</span></div><div class="announcement_content">记录和分享一些学习和开源内容，若有问题可通过邮箱is.louishsu@foxmail.com联系，欢迎交流！！</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">1.</span> <span class="toc-text">统计</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">2.</span> <span class="toc-text">计算机视觉</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">3.</span> <span class="toc-text">自然语言处理</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">4.</span> <span class="toc-text">机器学习</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">5.</span> <span class="toc-text">人工智能</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2022/02/09/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html" title="Arxiv每日速递(2022-02-09)"><img src="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Arxiv每日速递(2022-02-09)"/></a><div class="content"><a class="title" href="/2022/02/09/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html" title="Arxiv每日速递(2022-02-09)">Arxiv每日速递(2022-02-09)</a><time datetime="2022-02-09T00:30:40.472Z" title="发表于 2022-02-09 08:30:40">2022-02-09</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/10/22/%E4%B8%AD%E5%9B%BD%E6%B3%95%E5%BE%8B%E6%99%BA%E8%83%BD%E6%8A%80%E6%9C%AF%E8%AF%84%E6%B5%8B(CAIL2021)%EF%BC%9A%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96(Rank2).html" title="中国法律智能技术评测(CAIL2021)：信息抽取(Rank2)"><img src="http://cail.cipsc.org.cn/img/index_mainpic.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="中国法律智能技术评测(CAIL2021)：信息抽取(Rank2)"/></a><div class="content"><a class="title" href="/2021/10/22/%E4%B8%AD%E5%9B%BD%E6%B3%95%E5%BE%8B%E6%99%BA%E8%83%BD%E6%8A%80%E6%9C%AF%E8%AF%84%E6%B5%8B(CAIL2021)%EF%BC%9A%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96(Rank2).html" title="中国法律智能技术评测(CAIL2021)：信息抽取(Rank2)">中国法律智能技术评测(CAIL2021)：信息抽取(Rank2)</a><time datetime="2021-10-22T14:29:06.000Z" title="发表于 2021-10-22 22:29:06">2021-10-22</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/05/19/%E5%85%A8%E7%90%83%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%8A%80%E6%9C%AF%E5%88%9B%E6%96%B0%E5%A4%A7%E8%B5%9B%E3%80%90%E8%B5%9B%E9%81%93%E4%B8%80%E3%80%91%EF%BC%9A%E5%8C%BB%E5%AD%A6%E5%BD%B1%E5%83%8F%E6%8A%A5%E5%91%8A%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B.html" title="全球人工智能技术创新大赛【赛道一】：医学影像报告异常检测"><img src="https://tianchi-public.oss-cn-hangzhou.aliyuncs.com/public/files/forum/161037709574435991610377095138.jpeg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="全球人工智能技术创新大赛【赛道一】：医学影像报告异常检测"/></a><div class="content"><a class="title" href="/2021/05/19/%E5%85%A8%E7%90%83%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%8A%80%E6%9C%AF%E5%88%9B%E6%96%B0%E5%A4%A7%E8%B5%9B%E3%80%90%E8%B5%9B%E9%81%93%E4%B8%80%E3%80%91%EF%BC%9A%E5%8C%BB%E5%AD%A6%E5%BD%B1%E5%83%8F%E6%8A%A5%E5%91%8A%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B.html" title="全球人工智能技术创新大赛【赛道一】：医学影像报告异常检测">全球人工智能技术创新大赛【赛道一】：医学影像报告异常检测</a><time datetime="2021-05-19T09:57:06.000Z" title="发表于 2021-05-19 17:57:06">2021-05-19</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2020/09/16/%E8%AF%A6%E8%A7%A3%E5%91%BD%E5%90%8D%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB%E6%A8%A1%E5%9E%8B%EF%BC%9ALSTM-CRF.html" title="详解命名实体识别模型：LSTM-CRF"><img src="https://gimg2.baidu.com/image_search/src=http%3A%2F%2Fpic1.zhimg.com%2Fv2-1ed6a10dbb239a148e42df088c5870a6_1440w.jpg%3Fsource%3D172ae18b&amp;refer=http%3A%2F%2Fpic1.zhimg.com&amp;app=2002&amp;size=f9999,10000&amp;q=a80&amp;n=0&amp;g=0n&amp;fmt=jpeg?sec=1638183974&amp;t=4632f13fd487ed1cfcb12d67a6b71e52" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="详解命名实体识别模型：LSTM-CRF"/></a><div class="content"><a class="title" href="/2020/09/16/%E8%AF%A6%E8%A7%A3%E5%91%BD%E5%90%8D%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB%E6%A8%A1%E5%9E%8B%EF%BC%9ALSTM-CRF.html" title="详解命名实体识别模型：LSTM-CRF">详解命名实体识别模型：LSTM-CRF</a><time datetime="2020-09-16T09:26:44.000Z" title="发表于 2020-09-16 17:26:44">2020-09-16</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2020/06/14/%E8%AE%B0%E4%B8%80%E6%AC%A1MySQL%E8%A7%A3%E5%86%B3%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E6%97%B6%E7%9A%84%E5%88%86%E8%A1%A8%E9%97%AE%E9%A2%98.html" title="记一次MySQL解决大数据存储时的分表问题"><img src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="记一次MySQL解决大数据存储时的分表问题"/></a><div class="content"><a class="title" href="/2020/06/14/%E8%AE%B0%E4%B8%80%E6%AC%A1MySQL%E8%A7%A3%E5%86%B3%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E6%97%B6%E7%9A%84%E5%88%86%E8%A1%A8%E9%97%AE%E9%A2%98.html" title="记一次MySQL解决大数据存储时的分表问题">记一次MySQL解决大数据存储时的分表问题</a><time datetime="2020-06-14T15:24:27.000Z" title="发表于 2020-06-14 23:24:27">2020-06-14</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2022 By 徐耀彬</div><div class="footer_custom_text"><p><a style="margin-inline:5px"target="_blank"href="https://hexo.io/"><img src="https://img.shields.io/badge/Frame-Hexo-blue?style=flat&logo=hexo"title="博客框架为Hexo"alt="img"></a><a style="margin-inline:5px"target="_blank"href="https://butterfly.js.org/"><img src="https://img.shields.io/badge/Theme-Butterfly-6513df?style=flat&logo=bitdefender"title="主题采用butterfly"alt="img"></a><a style="margin-inline:5px"target="_blank"href="https://www.jsdelivr.com/"><img src="https://img.shields.io/badge/CDN-jsDelivr-orange?style=flat&logo=jsDelivr"title="本站使用JsDelivr为静态资源提供CDN加速"alt="img"></a><a style="margin-inline:5px"target="_blank"href="https://github.com/"><img src="https://img.shields.io/badge/Source-Github-d021d6?style=flat&logo=GitHub"title="本站项目由Gtihub托管"alt="img"></a><a style="margin-inline:5px"target="_blank"href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img src="https://img.shields.io/badge/Copyright-BY--NC--SA%204.0-d42328?style=flat&logo=Claris"alt="img"title="本站采用知识共享署名-非商业性使用-相同方式共享4.0国际许可协议进行许可"></a></br></p></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="font-plus" type="button" title="放大字体"><i class="fas fa-plus"></i></button><button id="font-minus" type="button" title="缩小字体"><i class="fas fa-minus"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div></div><hr/><div id="local-search-results"></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.css"><script>(() => {
  document.querySelectorAll('#article-container span.katex-display').forEach(item => {
    btf.wrap(item, 'div', '', 'katex-wrap')
  })
})()</script><script>(()=>{
  const $countDom = document.getElementById('twikoo-count')
  const init = () => {
    let initData = {
      el: '#twikoo-wrap',
      envId: 'blog-',
      region: ''
    }

    if (false) {
      const otherData = false
      initData = Object.assign(initData, otherData)
    }
    
    twikoo.init(initData)
  }

  const getCount = () => {
    twikoo.getCommentsCount({
      envId: 'blog-',
      region: '',
      urls: [window.location.pathname],
      includeReply: false
    }).then(function (res) {
      $countDom.innerText = res[0].count
    }).catch(function (err) {
      console.error(err);
    });
  }

  const loadTwikoo = (bool = false) => {
    if (typeof twikoo === 'object') {
      init()
      bool && $countDom && setTimeout(getCount,0)
    } else {
      getScript('https://cdn.jsdelivr.net/npm/twikoo/dist/twikoo.all.min.js').then(()=> {
        init()
        bool && $countDom && setTimeout(getCount,0)
      })
    }
  }

  if ('Twikoo' === 'Twikoo' || !false) {
    if (false) btf.loadComment(document.getElementById('twikoo-wrap'), loadTwikoo)
    else loadTwikoo(true)
  } else {
    window.loadOtherComment = () => {
      loadTwikoo()
    }
  }
})()</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><!-- hexo injector body_end start --> <script data-pjax>if(document.getElementById('recent-posts') && (location.pathname ==='/'|| '/' ==='all')){
    var parent = document.getElementById('recent-posts');
    var child = '<div class="recent-post-item" style="width:100%;height: auto"><div id="catalog_magnet"><div class="magnet_item"><a class="magnet_link" href="http://louishsu.xyz/categories/机器学习/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🐱 机器学习 (1)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://louishsu.xyz/categories/自然语言处理/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">📚 自然语言处理 (1)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://louishsu.xyz/categories/竞赛相关/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🎮 竞赛相关 (2)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://louishsu.xyz/categories/阅读笔记/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🎮 阅读笔记 (1)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><a class="magnet_link_more"  href="http://louishsu.xyz/categories" style="flex:1;text-align: center;margin-bottom: 10px;">查看更多...</a></div></div>';
    console.log('已挂载magnet')
    parent.insertAdjacentHTML("afterbegin",child)}
     </script><style>#catalog_magnet{flex-wrap: wrap;display: flex;width:100%;justify-content:space-between;padding: 10px 10px 0 10px;align-content: flex-start;}.magnet_item{flex-basis: calc(50% - 5px);background: #f2f2f2;margin-bottom: 10px;border-radius: 8px;transition: all 0.2s ease-in-out;}.magnet_item:hover{background: #b30070}.magnet_link_more{color:#555}.magnet_link{color:black}.magnet_link:hover{color:white}@media screen and (max-width: 600px) {.magnet_item {flex-basis: 100%;}}.magnet_link_context{display:flex;padding: 10px;font-size:16px;transition: all 0.2s ease-in-out;}.magnet_link_context:hover{padding: 10px 20px;}</style>
    <style></style>
  <script data-pjax src="https://cdn.jsdelivr.net/gh/Zfour/hexo-github-calendar@1.21/hexo_githubcalendar.js"></script>
  <script data-pjax>
        function GithubCalendarConfig(){
            var git_githubapiurl ="https://python-github-calendar-api.vercel.app/api?isLouisHsu";
            var git_color =['#ebedf0', '#fdcdec', '#fc9bd9', '#fa6ac5', '#f838b2', '#f5089f', '#c4067e', '#92055e', '#540336', '#48022f', '#30021f'];
            var git_user ="isLouisHsu";
            var parent_div_git = document.getElementById('recent-posts');
            var git_div_html = '<div class="recent-post-item" style="width:100%;height:auto;padding:10px;"><div id="github_loading" style="width:10%;height:100%;margin:0 auto;display: block"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"  viewBox="0 0 50 50" style="enable-background:new 0 0 50 50" xml:space="preserve"><path fill="#d0d0d0" d="M25.251,6.461c-10.318,0-18.683,8.365-18.683,18.683h4.068c0-8.071,6.543-14.615,14.615-14.615V6.461z" transform="rotate(275.098 25 25)"><animateTransform attributeType="xml" attributeName="transform" type="rotate" from="0 25 25" to="360 25 25" dur="0.6s" repeatCount="indefinite"></animateTransform></path></svg></div><div id="github_container"></div></div>';
            if(parent_div_git && location.pathname =='/'){
                console.log('已挂载github calendar')
                // parent_div_git.innerHTML=git_div_html+parent_div_git.innerHTML // 无报错，但不影响使用(支持pjax跳转)
                parent_div_git.insertAdjacentHTML("afterbegin",git_div_html) // 有报错，但不影响使用(支持pjax跳转)
            };
            GithubCalendar(git_githubapiurl,git_color,git_user)
        }
        if(document.getElementById('recent-posts')){
            GithubCalendarConfig()
        }
    </script>
    <style>#github_container{min-height:280px}@media screen and (max-width:650px) {#github_container{background-image:;min-height:0px}}</style>
    <style></style><script data-pjax>function electric_clock_injector_config(){
                var parent_div_git = document.getElementsByClassName('sticky_layout')[0];
                var item_html = '<div class="card-widget card-clock"><div class="card-glass"><div class="card-background"><div class="card-content"><div id="hexo_electric_clock"><img id="card-clock-loading" src="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-clock/clock/images/weather/loading.gif" style="height: 120px; width: 100%;" data-ll-status="loading" class="entered loading"></div></div></div></div></div>';
                console.log('已挂载electric_clock')
                // parent_div_git.innerHTML=item_html+parent_div_git.innerHTML // 无报错，但不影响使用(支持pjax跳转)
                parent_div_git.insertAdjacentHTML("afterbegin",item_html) // 有报错，但不影响使用(支持pjax跳转)
            }if( document.getElementsByClassName('sticky_layout')[0] && (location.pathname ==='all'|| 'all' ==='all')){

            electric_clock_injector_config()
        } </script><script src="https://pv.sohu.com/cityjson?ie=utf-8"></script><script data-pjax  src="https://cdn.jsdelivr.net/gh/Zfour/hexo-electric-clock@1.0.6/clock.js"></script><!-- hexo injector body_end end --><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"model":{"jsonPath":"/live2dw/assets/hijiki.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":false},"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body></html>