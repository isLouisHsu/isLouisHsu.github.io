<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Arxiv每日速递(2022-02-10) | LOUIS' BLOG</title><meta name="author" content="徐耀彬"><meta name="copyright" content="徐耀彬"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="本篇博文主要展示每日从Arxiv论文网站获取的最新论文列表，以计算机视觉、自然语言处理、机器学习、人工智能等大方向进行划分。 统计 今日共更新298篇论文，其中：  67篇计算机视觉（cs.CV） 17篇自然语言处理（cs.CL） 121篇机器学习（cs.LG） 58篇人工智能（cs.AI）  计算机视觉    1. 标题：DALL-Eval: Probing the Reasoning Skil">
<meta property="og:type" content="article">
<meta property="og:title" content="Arxiv每日速递(2022-02-10)">
<meta property="og:url" content="http://louishsu.xyz/2022/02/10/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html">
<meta property="og:site_name" content="LOUIS&#39; BLOG">
<meta property="og:description" content="本篇博文主要展示每日从Arxiv论文网站获取的最新论文列表，以计算机视觉、自然语言处理、机器学习、人工智能等大方向进行划分。 统计 今日共更新298篇论文，其中：  67篇计算机视觉（cs.CV） 17篇自然语言处理（cs.CL） 121篇机器学习（cs.LG） 58篇人工智能（cs.AI）  计算机视觉    1. 标题：DALL-Eval: Probing the Reasoning Skil">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png">
<meta property="article:published_time" content="2022-02-10T00:28:44.836Z">
<meta property="article:modified_time" content="2022-02-10T00:30:16.116Z">
<meta property="article:author" content="徐耀彬">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://louishsu.xyz/2022/02/10/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2022-02-10 08:30:16'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const fontSizeVal = saveToLocal.get('global-font-size')
    if (fontSizeVal !== undefined) {
      document.documentElement.style.setProperty('--global-font-size', fontSizeVal + 'px')
    }
    })(window)</script><link rel="stylesheet" href="/css/background.css"><script src="https://cdn.jsdelivr.net/npm/echarts@4.7.0/dist/echarts.min.js"></script><!-- hexo injector head_end start --><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Zfour/hexo-electric-clock@1.0.6/clock.css"><!-- hexo injector head_end end --><meta name="generator" content="Hexo 5.4.1"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="author-avatar"><img class="avatar-img" src="/img/touxiang.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">11</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">标签</div><div class="length-num">3</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">分类</div><div class="length-num">7</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/message/"><i class="fa-fw far fa-comment-dots"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa-fw fa fa-book"></i><span> 找文章</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></li><li><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></li><li><a class="site-page" href="/charts/"><i class="fa-fw fa fa-archive"></i><span> 统计</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-tools"></i><span> 工具</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/md_editor/"><i class="fa-fw fas fa-pen"></i><span> 在线markdown</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/isLouisHsu/blog/tree/master/source/_posts"><i class="fa-fw fa fa-star"></i><span> 在线push</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">LOUIS' BLOG</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/message/"><i class="fa-fw far fa-comment-dots"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa-fw fa fa-book"></i><span> 找文章</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></li><li><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></li><li><a class="site-page" href="/charts/"><i class="fa-fw fa fa-archive"></i><span> 统计</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-tools"></i><span> 工具</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/md_editor/"><i class="fa-fw fas fa-pen"></i><span> 在线markdown</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/isLouisHsu/blog/tree/master/source/_posts"><i class="fa-fw fa fa-star"></i><span> 在线push</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Arxiv每日速递(2022-02-10)<a class="post-edit-link" href="https://github.com/isLouisHsu/blog/tree/master/source_posts/Arxiv每日速递.md" title="编辑" target="_blank"><i class="fas fa-pencil-square"></i></a></h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-02-10T00:28:44.836Z" title="发表于 2022-02-10 08:28:44">2022-02-10</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2022-02-10T00:30:16.116Z" title="更新于 2022-02-10 08:30:16">2022-02-10</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">阅读笔记</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">25k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>149分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span><span class="post-meta-separator">|</span><span class="post-meta-commentcount"><i class="far fa-comments fa-fw post-meta-icon"></i><span class="post-meta-label">评论数:</span><a href="/2022/02/10/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html#post-comment"><span id="twikoo-count"></span></a></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><p>本篇博文主要展示每日从Arxiv论文网站获取的最新论文列表，以计算机视觉、自然语言处理、机器学习、人工智能等大方向进行划分。</p>
<h1>统计</h1>
<p>今日共更新298篇论文，其中：</p>
<ul>
<li>67篇计算机视觉（<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>）</li>
<li>17篇自然语言处理（<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>）</li>
<li>121篇机器学习（cs.LG）</li>
<li>58篇人工智能（<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>）</li>
</ul>
<h1>计算机视觉</h1>
<details>
  <summary>1. <b>标题：DALL-Eval: Probing the Reasoning Skills and Social Biases of  Text-to-Image Generative Transformers</b></summary>
  <p><b>编号</b>：[4]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.04053</p>
  <p><b>作者</b>：Jaemin Cho,  Abhay Zala,  Mohit Bansal</p>
  <p><b>备注</b>：20 pages, 10 figures, 13 tables</p>
  <p><b>关键词</b>：image models learn specific gender, measure four visual reasoning skills, help guide future progress, multimodal transformer language model, four visual reasoning skills</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Generating images from textual descriptions has gained a lot of attention.
Recently, DALL-E, a multimodal transformer language model, and its variants
have shown high-quality text-to-image generation capabilities with a simple
architecture and training objective, powered by large-scale training data and
computation. However, despite the interesting image generation results, there
has not been a detailed analysis on how to evaluate such models. In this work,
we investigate the reasoning capabilities and social biases of such
text-to-image generative transformers in detail. First, we measure four visual
reasoning skills: object recognition, object counting, color recognition, and
spatial relation understanding. For this, we propose PaintSkills, a diagnostic
dataset and evaluation toolkit that measures these four visual reasoning
skills. Second, we measure the text alignment and quality of the generated
images based on pretrained image captioning, image-text retrieval, and image
classification models. Third, we assess social biases in the models. For this,
we suggest evaluation of gender and racial biases of text-to-image generation
models based on a pretrained image-text retrieval model and human evaluation.
In our experiments, we show that recent text-to-image models perform better in
recognizing and counting objects than recognizing colors and understanding
spatial relations, while there exists a large gap between model performances
and oracle accuracy on all skills. Next, we demonstrate that recent
text-to-image models learn specific gender/racial biases from web image-text
pairs. We also show that our automatic evaluations of visual reasoning skills
and gender bias are highly correlated with human judgments. We hope our work
will help guide future progress in improving text-to-image models on visual
reasoning skills and social biases. Code and data at:
this https URL</p>
  </details>
</details>
<details>
  <summary>2. <b>标题：Decision boundaries and convex hulls in the feature space that deep  learning functions learn from images</b></summary>
  <p><b>编号</b>：[5]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.04052</p>
  <p><b>作者</b>：Roozbeh Yousefzadeh</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：significantly different compared, last hidden layer, identify regions guaranteed, deep neural networks, dimensional space based</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The success of deep neural networks in image classification and learning can
be partly attributed to the features they extract from images. It is often
speculated about the properties of a low-dimensional manifold that models
extract and learn from images. However, there is not sufficient understanding
about this low-dimensional space based on theory or empirical evidence. For
image classification models, their last hidden layer is the one where images of
each class is separated from other classes and it also has the least number of
features. Here, we develop methods and formulations to study that feature space
for any model. We study the partitioning of the domain in feature space,
identify regions guaranteed to have certain classifications, and investigate
its implications for the pixel space. We observe that geometric arrangements of
decision boundaries in feature space is significantly different compared to
pixel space, providing insights about adversarial vulnerabilities, image
morphing, extrapolation, ambiguity in classification, and the mathematical
understanding of image classification models.</p>
  </details>
</details>
<details>
  <summary>3. <b>标题：Self-Conditioned Generative Adversarial Networks for Image Editing</b></summary>
  <p><b>编号</b>：[12]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.04040</p>
  <p><b>作者</b>：Yunzhe Liu,  Rinon Gal,  Amit H. Bermano,  Baoquan Chen,  Daniel Cohen-Or</p>
  <p><b>备注</b>：Project page: this https URL</p>
  <p><b>关键词</b>：achieve finer semantic control, rare semantic attributes, traversal editing methods, provide initial labels, generative adversarial networks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Generative Adversarial Networks (GANs) are susceptible to bias, learned from
either the unbalanced data, or through mode collapse. The networks focus on the
core of the data distribution, leaving the tails - or the edges of the
distribution - behind. We argue that this bias is responsible not only for
fairness concerns, but that it plays a key role in the collapse of
latent-traversal editing methods when deviating away from the distribution's
core. Building on this observation, we outline a method for mitigating
generative bias through a self-conditioning process, where distances in the
latent-space of a pre-trained generator are used to provide initial labels for
the data. By fine-tuning the generator on a re-sampled distribution drawn from
these self-labeled data, we force the generator to better contend with rare
semantic attributes and enable more realistic generation of these properties.
We compare our models to a wide range of latent editing methods, and show that
by alleviating the bias they achieve finer semantic control and better identity
preservation through a wider range of transformations. Our code and models will
be available at this https URL</p>
  </details>
</details>
<details>
  <summary>4. <b>标题：Residual Aligned: Gradient Optimization for Non-Negative Image Synthesis</b></summary>
  <p><b>编号</b>：[14]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.04036</p>
  <p><b>作者</b>：Flora Yu Shen,  Katie Luo,  Guandao Yang,  Harald Haraldsson,  Serge Belongie</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：thus capturing high frequency details, high dynamic range image transfer, cannot create darker pixels, preserve lightness constancy well, method shows strong performance</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this work, we address an important problem of optical see through (OST)
augmented reality: non-negative image synthesis. Most of the image generation
methods fail under this condition, since they assume full control over each
pixel and cannot create darker pixels by adding light. In order to solve the
non-negative image generation problem in AR image synthesis, prior works have
attempted to utilize optical illusion to simulate human vision but fail to
preserve lightness constancy well under situations such as high dynamic range.
In our paper, we instead propose a method that is able to preserve lightness
constancy at a local level, thus capturing high frequency details. Compared
with existing work, our method shows strong performance in image-to-image
translation tasks, particularly in scenarios such as large scale images, high
resolution images, and high dynamic range image transfer.</p>
  </details>
</details>
<details>
  <summary>5. <b>标题：Self-supervised Contrastive Learning for Volcanic Unrest Detection</b></summary>
  <p><b>编号</b>：[15]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.04030</p>
  <p><b>作者</b>：Nikolaos Ioannis Bountos,  Ioannis Papoutsis,  Dimitrios Michail,  Nantheera Anantrasirichai</p>
  <p><b>备注</b>：5 pages, 3 figures</p>
  <p><b>关键词</b>：learn quality visual representations hidden, towards global volcanic hazard mitigation, supervised pipeline achieves higher accuracy, recent icelandic fagradalsfjall volcanic eruption, shows excellent generalisation even</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Ground deformation measured from Interferometric Synthetic Aperture Radar
(InSAR) data is considered a sign of volcanic unrest, statistically linked to a
volcanic eruption. Recent studies have shown the potential of using Sentinel-1
InSAR data and supervised deep learning (DL) methods for the detection of
volcanic deformation signals, towards global volcanic hazard mitigation.
However, detection accuracy is compromised from the lack of labelled data and
class imbalance. To overcome this, synthetic data are typically used for
finetuning DL models pre-trained on the ImageNet dataset. This approach suffers
from poor generalisation on real InSAR data. This letter proposes the use of
self-supervised contrastive learning to learn quality visual representations
hidden in unlabeled InSAR data. Our approach, based on the SimCLR framework,
provides a solution that does not require a specialized architecture nor a
large labelled or synthetic dataset. We show that our self-supervised pipeline
achieves higher accuracy with respect to the state-of-the-art methods, and
shows excellent generalisation even for out-of-distribution test data. Finally,
we showcase the effectiveness of our approach for detecting the unrest episodes
preceding the recent Icelandic Fagradalsfjall volcanic eruption.</p>
  </details>
</details>
<details>
  <summary>6. <b>标题：NEWSKVQA: Knowledge-Aware News Video Question Answering</b></summary>
  <p><b>编号</b>：[17]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.04015</p>
  <p><b>作者</b>：Pranay Gupta,  Manish Gupta</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：12k news videos spanning across 156 hours, answer pairs covering 8263 unique entities, aware news video question answering, visual question answering, video question answering</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Answering questions in the context of videos can be helpful in video
indexing, video retrieval systems, video summarization, learning management
systems and surveillance video analysis. Although there exists a large body of
work on visual question answering, work on video question answering (1) is
limited to domains like movies, TV shows, gameplay, or human activity, and (2)
is mostly based on common sense reasoning. In this paper, we explore a new
frontier in video question answering: answering knowledge-based questions in
the context of news videos. To this end, we curate a new dataset of 12K news
videos spanning across 156 hours with 1M multiple-choice question-answer pairs
covering 8263 unique entities. We make the dataset publicly available. Using
this dataset, we propose a novel approach, NEWSKVQA (Knowledge-Aware News Video
Question Answering) which performs multi-modal inferencing over textual
multiple-choice questions, videos, their transcripts and knowledge base, and
presents a strong baseline.</p>
  </details>
</details>
<details>
  <summary>7. <b>标题：Results and findings of the 2021 Image Similarity Challenge</b></summary>
  <p><b>编号</b>：[20]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.04007</p>
  <p><b>作者</b>：Zoë Papakipos,  Giorgos Tolias,  Tomas Jenicek,  Ed Pizzi,  Shuhei Yokoo,  Wenhao Wang,  Yifan Sun,  Weipu Zhang,  Yi Yang,  Sanjay Addicam,  Sergio Manuel Papadakis,  Cristian Canton Ferrer,  Ondrej Chum,  Matthijs Douze</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：difficult image transformations involve either severe image crops, evaluate recent image copy detection methods, 2021 image similarity challenge introduced, global descriptor matching followed, pairwise image comparison</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The 2021 Image Similarity Challenge introduced a dataset to serve as a new
benchmark to evaluate recent image copy detection methods. There were 200
participants to the competition. This paper presents a quantitative and
qualitative analysis of the top submissions. It appears that the most difficult
image transformations involve either severe image crops or hiding into
unrelated images, combined with local pixel perturbations. The key algorithmic
elements in the winning submissions are: training on strong augmentations,
self-supervised learning, score normalization, explicit overlay detection, and
global descriptor matching followed by pairwise image comparison.</p>
  </details>
</details>
<details>
  <summary>8. <b>标题：Equivariance versus Augmentation for Spherical Images</b></summary>
  <p><b>编号</b>：[27]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03990</p>
  <p><b>作者</b>：Jan E. Gerken,  Oscar Carlsson,  Hampus Linander,  Fredrik Ohlsson,  Christoffer Petersson,  Daniel Persson</p>
  <p><b>备注</b>：19 pages of which 8 in main body, 16 figures</p>
  <p><b>关键词</b>：fashionmnist dataset projected onto, enabling detailed tradeoff considerations, group equivariant networks known, equivariant spherical networks used, significantly fewer parameters</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We analyze the role of rotational equivariance in convolutional neural
networks (CNNs) applied to spherical images. We compare the performance of the
group equivariant networks known as S2CNNs and standard non-equivariant CNNs
trained with an increasing amount of data augmentation. The chosen
architectures can be considered baseline references for the respective design
paradigms. Our models are trained and evaluated on single or multiple items
from the MNIST or FashionMNIST dataset projected onto the sphere. For the task
of image classification, which is inherently rotationally invariant, we find
that by considerably increasing the amount of data augmentation and the size of
the networks, it is possible for the standard CNNs to reach at least the same
performance as the equivariant network. In contrast, for the inherently
equivariant task of semantic segmentation, the non-equivariant networks are
consistently outperformed by the equivariant networks with significantly fewer
parameters. We also analyze and compare the inference latency and training
times of the different networks, enabling detailed tradeoff considerations
between equivariant architectures and data augmentation for practical problems.
The equivariant spherical networks used in the experiments will be made
available at this https URL .</p>
  </details>
</details>
<details>
  <summary>9. <b>标题：Segmentation by Test-Time Optimization (TTO) for CBCT-based Adaptive  Radiation Therapy</b></summary>
  <p><b>编号</b>：[34]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03978</p>
  <p><b>作者</b>：Xiao Liang,  Jaehee Chun,  Howard Morgan,  Ti Bai,  Dan Nguyen,  Justin C. Park,  Steve Jiang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：neck squamous cell carcinoma, 2 mm hd95 improvement, based deformable image registration, obtain 39 individualized models, remaining 39 test patients</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Online adaptive radiotherapy (ART) requires accurate and efficient
auto-segmentation of target volumes and organs-at-risk (OARs) in mostly
cone-beam computed tomography (CBCT) images. Propagating expert-drawn contours
from the pre-treatment planning CT (pCT) through traditional or deep learning
(DL) based deformable image registration (DIR) can achieve improved results in
many situations. Typical DL-based DIR models are population based, that is,
trained with a dataset for a population of patients, so they may be affected by
the generalizability problem. In this paper, we propose a method called
test-time optimization (TTO) to refine a pre-trained DL-based DIR population
model, first for each individual test patient, and then progressively for each
fraction of online ART treatment. Our proposed method is less susceptible to
the generalizability problem, and thus can improve overall performance of
different DL-based DIR models by improving model accuracy, especially for
outliers. Our experiments used data from 239 patients with head and neck
squamous cell carcinoma to test the proposed method. Firstly, we trained a
population model with 200 patients, and then applied TTO to the remaining 39
test patients by refining the trained population model to obtain 39
individualized models. We compared each of the individualized models with the
population model in terms of segmentation accuracy. The number of patients with
at least 0.05 DSC improvement or 2 mm HD95 improvement by TTO averaged over the
17 selected structures for the state-of-the-art architecture Voxelmorph is 10
out of 39 test patients. The average time for deriving the individualized model
using TTO from the pre-trained population model is approximately four minutes.
When adapting the individualized model to a later fraction of the same patient,
the average time is reduced to about one minute and the accuracy is slightly
improved.</p>
  </details>
</details>
<details>
  <summary>10. <b>标题：Self-supervised Contrastive Learning for Cross-domain Hyperspectral  Image Representation</b></summary>
  <p><b>编号</b>：[40]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03968</p>
  <p><b>作者</b>：Hyungtae Lee,  Heesung Kwon</p>
  <p><b>备注</b>：Accepted to ICASSP 2022</p>
  <p><b>关键词</b>：common representation space encompassing multiple hyperspectral images, classification tasks without using semantic labels, proposed framework architecture leverages cross, supervised learning framework suitable, learned via contrastive learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recently, self-supervised learning has attracted attention due to its
remarkable ability to acquire meaningful representations for classification
tasks without using semantic labels. This paper introduces a self-supervised
learning framework suitable for hyperspectral images that are inherently
challenging to annotate. The proposed framework architecture leverages
cross-domain CNN, allowing for learning representations from different
hyperspectral images with varying spectral characteristics and no pixel-level
annotation. In the framework, cross-domain representations are learned via
contrastive learning where neighboring spectral vectors in the same image are
clustered together in a common representation space encompassing multiple
hyperspectral images. In contrast, spectral vectors in different hyperspectral
images are separated into distinct clusters in the space. To verify that the
learned representation through contrastive learning is effectively transferred
into a downstream task, we perform a classification task on hyperspectral
images. The experimental results demonstrate the advantage of the proposed
self-supervised representation over models trained from scratch or other
transfer learning methods.</p>
  </details>
</details>
<details>
  <summary>11. <b>标题：Uncertainty Modeling for Out-of-Distribution Generalization</b></summary>
  <p><b>编号</b>：[44]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03958</p>
  <p><b>作者</b>：Xiaotong Li,  Yongxing Dai,  Yixiao Ge,  Jun Liu,  Ying Shan,  Ling-Yu Duan</p>
  <p><b>备注</b>：Accepted by ICLR 2022</p>
  <p><b>关键词</b>：deep neural networks still suffer obvious performance degradation, networks without additional parameters, common methods often consider, proposed method consistently improves, uncertain statistics discrepancy caused</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Though remarkable progress has been achieved in various vision tasks, deep
neural networks still suffer obvious performance degradation when tested in
out-of-distribution scenarios. We argue that the feature statistics (mean and
standard deviation), which carry the domain characteristics of the training
data, can be properly manipulated to improve the generalization ability of deep
learning models. Common methods often consider the feature statistics as
deterministic values measured from the learned features and do not explicitly
consider the uncertain statistics discrepancy caused by potential domain shifts
during testing. In this paper, we improve the network generalization ability by
modeling the uncertainty of domain shifts with synthesized feature statistics
during training. Specifically, we hypothesize that the feature statistic, after
considering the potential uncertainties, follows a multivariate Gaussian
distribution. Hence, each feature statistic is no longer a deterministic value,
but a probabilistic point with diverse distribution possibilities. With the
uncertain feature statistics, the models can be trained to alleviate the domain
perturbations and achieve better robustness against potential domain shifts.
Our method can be readily integrated into networks without additional
parameters. Extensive experiments demonstrate that our proposed method
consistently improves the network generalization ability on multiple vision
tasks, including image classification, semantic segmentation, and instance
retrieval. The code will be released soon at
this https URL.</p>
  </details>
</details>
<details>
  <summary>12. <b>标题：Bingham Policy Parameterization for 3D Rotations in Reinforcement  Learning</b></summary>
  <p><b>编号</b>：[45]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03957</p>
  <p><b>作者</b>：Stephen James,  Pieter Abbeel</p>
  <p><b>备注</b>：Project page and code: this https URL</p>
  <p><b>关键词</b>：best pose robot manipulation tasks, continuous control reinforcement learning literature, full 6d pose output, many stochastic policy parameterizations, rotation wahba problem task</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose a new policy parameterization for representing 3D rotations during
reinforcement learning. Today in the continuous control reinforcement learning
literature, many stochastic policy parameterizations are Gaussian. We argue
that universally applying a Gaussian policy parameterization is not always
desirable for all environments. One such case in particular where this is true
are tasks that involve predicting a 3D rotation output, either in isolation, or
coupled with translation as part of a full 6D pose output. Our proposed Bingham
Policy Parameterization (BPP) models the Bingham distribution and allows for
better rotation (quaternion) prediction over a Gaussian policy parameterization
in a range of reinforcement learning tasks. We evaluate BPP on the rotation
Wahba problem task, as well as a set of vision-based next-best pose robot
manipulation tasks from RLBench. We hope that this paper encourages more
research into developing other policy parameterization that are more suited for
particular environments, rather than always assuming Gaussian.</p>
  </details>
</details>
<details>
  <summary>13. <b>标题：Social-DualCVAE: Multimodal Trajectory Forecasting Based on Social  Interactions Pattern Aware and Dual Conditional Variational Auto-Encoder</b></summary>
  <p><b>编号</b>：[47]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03954</p>
  <p><b>作者</b>：Jiashi Gao,  Xinming Shi,  James J.Q. Yu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：mainly existing literature learns representations, intricate social interactions among pedestrians, widely used trajectory benchmarks, dual conditional variational auto, unlabeled social interaction patterns</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Pedestrian trajectory forecasting is a fundamental task in multiple utility
areas, such as self-driving, autonomous robots, and surveillance systems. The
future trajectory forecasting is multi-modal, influenced by physical
interaction with scene contexts and intricate social interactions among
pedestrians. The mainly existing literature learns representations of social
interactions by deep learning networks, while the explicit interaction patterns
are not utilized. Different interaction patterns, such as following or
collision avoiding, will generate different trends of next movement, thus, the
awareness of social interaction patterns is important for trajectory
forecasting. Moreover, the social interaction patterns are privacy concerned or
lack of labels. To jointly address the above issues, we present a social-dual
conditional variational auto-encoder (Social-DualCVAE) for multi-modal
trajectory forecasting, which is based on a generative model conditioned not
only on the past trajectories but also the unsupervised classification of
interaction patterns. After generating the category distribution of the
unlabeled social interaction patterns, DualCVAE, conditioned on the past
trajectories and social interaction pattern, is proposed for multi-modal
trajectory prediction by latent variables estimating. A variational bound is
derived as the minimization objective during training. The proposed model is
evaluated on widely used trajectory benchmarks and outperforms the prior
state-of-the-art methods.</p>
  </details>
</details>
<details>
  <summary>14. <b>标题：If a Human Can See It, So Should Your System: Reliability Requirements  for Machine Vision Components</b></summary>
  <p><b>编号</b>：[58]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03930</p>
  <p><b>作者</b>：Boyue Caroline Hu,  Lina Marsso,  Krzysztof Czarnecki,  Rick Salay,  Huakun Shen,  Marsha Chechik</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：image recognition involving eight commonly used transformations, requirements classes using human performance experiment data, human performance experiment data, trained image classification models, approach detects reliability gaps</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Machine Vision Components (MVC) are becoming safety-critical. Assuring their
quality, including safety, is essential for their successful deployment.
Assurance relies on the availability of precisely specified and, ideally,
machine-verifiable requirements. MVCs with state-of-the-art performance rely on
machine learning (ML) and training data but largely lack such requirements.
In this paper, we address the need for defining machine-verifiable
reliability requirements for MVCs against transformations that simulate the
full range of realistic and safety-critical changes in the environment. Using
human performance as a baseline, we define reliability requirements as: 'if the
changes in an image do not affect a human's decision, neither should they
affect the MVC's.' To this end, we provide: (1) a class of safety-related image
transformations; (2) reliability requirement classes to specify
correctness-preservation and prediction-preservation for MVCs; (3) a method to
instantiate machine-verifiable requirements from these requirements classes
using human performance experiment data; (4) human performance experiment data
for image recognition involving eight commonly used transformations, from about
2000 human participants; and (5) a method for automatically checking whether an
MVC satisfies our requirements. Further, we show that our reliability
requirements are feasible and reusable by evaluating our methods on 13
state-of-the-art pre-trained image classification models. Finally, we
demonstrate that our approach detects reliability gaps in MVCs that other
existing methods are unable to detect.</p>
  </details>
</details>
<details>
  <summary>15. <b>标题：GLPU: A Geometric Approach For Lidar Pointcloud Upsampling</b></summary>
  <p><b>编号</b>：[65]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03901</p>
  <p><b>作者</b>：George Eskandar,  Janaranjani Palaniswamy,  Karim Guirguis,  Barath Somashekar,  Bin Yang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：supervised geometric lidar pointcloud upsampling, pointcloud upsampling predicts high, although many upsampling frameworks, denser pointcloud depicts, three common factors</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In autonomous driving, lidar is inherent for the understanding of the 3D
environment. Lidar sensors vary in vertical resolutions, where a denser
pointcloud depicts a more detailed environment, albeit at a significantly
higher cost. Pointcloud upsampling predicts high-resolution pointclouds from
sparser ones to bridge this performance gap at a lower cost. Although many
upsampling frameworks have achieved a robust performance, a fair comparison is
difficult as they were tested on different datasets and metrics. In this work,
we first conduct a consistent comparative study to benchmark the existing
algorithms on the KITTI dataset. Then, we observe that there are three common
factors that hinder the performance: an inefficient data representation, a
small receptive field, and low-frequency losses. By leveraging the scene
geometry, a new self-supervised geometric lidar pointcloud upsampling (GLPU)
framework is proposed to address the aforementioned limitations. Our
experiments demonstrate the effectiveness and superior performance of GLPU
compared to other techniques on the KITTI benchmark.</p>
  </details>
</details>
<details>
  <summary>16. <b>标题：BIQ2021: A Large-Scale Blind Image Quality Assessment Database</b></summary>
  <p><b>编号</b>：[73]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03879</p>
  <p><b>作者</b>：Nisar Ahmed,  Shahzad Asif</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：evaluate existing blind image quality assessment approaches, blind image quality assessment database, objective quality assessment training, intentionally introduced natural distortions, reference image quality assessment</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The assessment of the perceptual quality of digital images is becoming
increasingly important as a result of the widespread use of digital multimedia
devices. Smartphones and high-speed internet are just two examples of
technologies that have multiplied the amount of multimedia content available.
Thus, obtaining a representative dataset, which is required for objective
quality assessment training, is a significant challenge. The Blind Image
Quality Assessment Database, BIQ2021, is presented in this article. By
selecting images with naturally occurring distortions and reliable labeling,
the dataset addresses the challenge of obtaining representative images for
no-reference image quality assessment. The dataset consists of three sets of
images: those taken without the intention of using them for image quality
assessment, those taken with intentionally introduced natural distortions, and
those taken from an open-source image-sharing platform. It is attempted to
maintain a diverse collection of images from various devices, containing a
variety of different types of objects and varying degrees of foreground and
background information. To obtain reliable scores, these images are
subjectively scored in a laboratory environment using a single stimulus method.
The database contains information about subjective scoring, human subject
statistics, and the standard deviation of each image. The dataset's Mean
Opinion Scores (MOS) make it useful for assessing visual quality. Additionally,
the proposed database is used to evaluate existing blind image quality
assessment approaches, and the scores are analyzed using Pearson and Spearman's
correlation coefficients. The image database and MOS are freely available for
use and benchmarking.</p>
  </details>
</details>
<details>
  <summary>17. <b>标题：Mapping DNN Embedding Manifolds for Network Generalization Prediction</b></summary>
  <p><b>编号</b>：[77]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03868</p>
  <p><b>作者</b>：Molly O'Brien,  Julia Bukowski,  Mathias Unberath,  Aria Pezeshk,  Greg Hager</p>
  <p><b>备注</b>：11 pages, 5 figures</p>
  <p><b>关键词</b>：15 ngp tasks without requiring domain knowledge, predicts dnn performance based solely, external operating domain map, understanding deep neural network, new operating domain</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Understanding Deep Neural Network (DNN) performance in changing conditions is
essential for deploying DNNs in safety critical applications with unconstrained
environments, e.g., perception for self-driving vehicles or medical image
analysis. Recently, the task of Network Generalization Prediction (NGP) has
been proposed to predict how a DNN will generalize in a new operating domain.
Previous NGP approaches have relied on labeled metadata and known distributions
for the new operating domains. In this study, we propose the first NGP approach
that predicts DNN performance based solely on how unlabeled images from an
external operating domain map in the DNN embedding space. We demonstrate this
technique for pedestrian, melanoma, and animal classification tasks and show
state of the art NGP in 13 of 15 NGP tasks without requiring domain knowledge.
Additionally, we show that our NGP embedding maps can be used to identify
misclassified images when the DNN performance is poor.</p>
  </details>
</details>
<details>
  <summary>18. <b>标题：Learning Optical Flow with Adaptive Graph Reasoning</b></summary>
  <p><b>编号</b>：[83]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03857</p>
  <p><b>作者</b>：Ao Luo,  Fan Yang,  Kunming Luo,  Xin Li,  Haoqiang Fan,  Shuaicheng Liu</p>
  <p><b>备注</b>：To appear in AAAI-22</p>
  <p><b>关键词</b>：contemporary optical flow techniques largely focus, effectively assist motion estimation, called adaptive graph reasoning, 6 %, respectively, holistic motion understanding</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Estimating per-pixel motion between video frames, known as optical flow, is a
long-standing problem in video understanding and analysis. Most contemporary
optical flow techniques largely focus on addressing the cross-image matching
with feature similarity, with few methods considering how to explicitly reason
over the given scene for achieving a holistic motion understanding. In this
work, taking a fresh perspective, we introduce a novel graph-based approach,
called adaptive graph reasoning for optical flow (AGFlow), to emphasize the
value of scene/context information in optical flow. Our key idea is to decouple
the context reasoning from the matching procedure, and exploit scene
information to effectively assist motion estimation by learning to reason over
the adaptive graph. The proposed AGFlow can effectively exploit the context
information and incorporate it within the matching procedure, producing more
robust and accurate results. On both Sintel clean and final passes, our AGFlow
achieves the best accuracy with EPE of 1.43 and 2.47 pixels, outperforming
state-of-the-art approaches by 11.2% and 13.6%, respectively.</p>
  </details>
</details>
<details>
  <summary>19. <b>标题：Class Density and Dataset Quality in High-Dimensional, Unstructured Data</b></summary>
  <p><b>编号</b>：[84]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03856</p>
  <p><b>作者</b>：Adam Byerly,  Tatiana Kalganova</p>
  <p><b>备注</b>：13 pages, 27 tables</p>
  <p><b>关键词</b>：corresponding individual class test accuracies achieved, put forth several candidate methods, eliding redundant data based, individual class densities, calculating class density</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We provide a definition for class density that can be used to measure the
aggregate similarity of the samples within each of the classes in a
high-dimensional, unstructured dataset. We then put forth several candidate
methods for calculating class density and analyze the correlation between the
values each method produces with the corresponding individual class test
accuracies achieved on a trained model. Additionally, we propose a definition
for dataset quality for high-dimensional, unstructured data and show that those
datasets that met a certain quality threshold (experimentally demonstrated to
be > 10 for the datasets studied) were candidates for eliding redundant data
based on the individual class densities.</p>
  </details>
</details>
<details>
  <summary>20. <b>标题：A Unified Multi-Task Learning Framework of Real-Time Drone Supervision  for Crowd Counting</b></summary>
  <p><b>编号</b>：[90]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03843</p>
  <p><b>作者</b>：Siqi Gu,  Zhichao Lian</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：extensive context extraction module, image fusion encoder process, unified training loss functions, image fusion network architecture, thermal infrared images captured</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, a novel Unified Multi-Task Learning Framework of Real-Time
Drone Supervision for Crowd Counting (MFCC) is proposed, which utilizes an
image fusion network architecture to fuse images from the visible and thermal
infrared image, and a crowd counting network architecture to estimate the
density map. The purpose of our framework is to fuse two modalities, including
visible and thermal infrared images captured by drones in real-time, that
exploit the complementary information to accurately count the dense population
and then automatically guide the flight of the drone to supervise the dense
crowd. To this end, we propose the unified multi-task learning framework for
crowd counting for the first time and re-design the unified training loss
functions to align the image fusion network and crowd counting network. We also
design the Assisted Learning Module (ALM) to fuse the density map feature to
the image fusion encoder process for learning the counting features. To improve
the accuracy, we propose the Extensive Context Extraction Module (ECEM) that is
based on a dense connection architecture to encode multi-receptive-fields
contextual information and apply the Multi-domain Attention Block (MAB) for
concerning the head region in the drone view. Finally, we apply the prediction
map to automatically guide the drones to supervise the dense crowd. The
experimental results on the DroneRGBT dataset show that, compared with the
existing methods, ours has comparable results on objective evaluations and an
easier training process.</p>
  </details>
</details>
<details>
  <summary>21. <b>标题：A Novel Plug-in Module for Fine-Grained Visual Classification</b></summary>
  <p><b>编号</b>：[97]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03822</p>
  <p><b>作者</b>：Po-Yung Chou,  Cheng-Hung Lin,  Wen-Chung Kao</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：grained visual classification often requires professional experts, proposed plugin module outperforms state, grained classification represents classifications, grained classification represents categories, provide strongly discriminative regions</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Visual classification can be divided into coarse-grained and fine-grained
classification. Coarse-grained classification represents categories with a
large degree of dissimilarity, such as the classification of cats and dogs,
while fine-grained classification represents classifications with a large
degree of similarity, such as cat species, bird species, and the makes or
models of vehicles. Unlike coarse-grained visual classification, fine-grained
visual classification often requires professional experts to label data, which
makes data more expensive. To meet this challenge, many approaches propose to
automatically find the most discriminative regions and use local features to
provide more precise features. These approaches only require image-level
annotations, thereby reducing the cost of annotation. However, most of these
methods require two- or multi-stage architectures and cannot be trained
end-to-end. Therefore, we propose a novel plug-in module that can be integrated
to many common backbones, including CNN-based or Transformer-based networks to
provide strongly discriminative regions. The plugin module can output
pixel-level feature maps and fuse filtered features to enhance fine-grained
visual classification. Experimental results show that the proposed plugin
module outperforms state-of-the-art approaches and significantly improves the
accuracy to 92.77\% and 92.83\% on CUB200-2011 and NABirds, respectively. We
have released our source code in Github
this https URL.</p>
  </details>
</details>
<details>
  <summary>22. <b>标题：Ada-NETS: Face Clustering via Adaptive Neighbour Discovery in the  Structure Space</b></summary>
  <p><b>编号</b>：[105]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03800</p>
  <p><b>作者</b>：Yaohua Wang,  Yaobin Zhang,  Fangyi Zhang,  Senzhang Wang,  Ming Lin,  YuQi Zhang,  Xiuyu Sun</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：based methods build face graphs mainly according, attracted rising research interest recently, multiple public clustering datasets show, nets significantly outperforms current state, noise edges connecting two faces</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Face clustering has attracted rising research interest recently to take
advantage of massive amounts of face images on the web. State-of-the-art
performance has been achieved by Graph Convolutional Networks (GCN) due to
their powerful representation capacity. However, existing GCN-based methods
build face graphs mainly according to kNN relations in the feature space, which
may lead to a lot of noise edges connecting two faces of different classes. The
face features will be polluted when messages pass along these noise edges, thus
degrading the performance of GCNs. In this paper, a novel algorithm named
Ada-NETS is proposed to cluster faces by constructing clean graphs for GCNs. In
Ada-NETS, each face is transformed to a new structure space, obtaining robust
features by considering face features of the neighbour images. Then, an
adaptive neighbour discovery strategy is proposed to determine a proper number
of edges connecting to each face image. It significantly reduces the noise
edges while maintaining the good ones to build a graph with clean yet rich
edges for GCNs to cluster faces. Experiments on multiple public clustering
datasets show that Ada-NETS significantly outperforms current state-of-the-art
methods, proving its superiority and generalization.</p>
  </details>
</details>
<details>
  <summary>23. <b>标题：SCR: Smooth Contour Regression with Geometric Priors</b></summary>
  <p><b>编号</b>：[112]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03784</p>
  <p><b>作者</b>：Gaetan Bahl,  Lionel Daniel,  Florent Lafarge</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：popular coco 2017 instance segmentation dataset, object detection methods traditionally make use, efficient geometric shape priors, defining object shapes, free object contours</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>While object detection methods traditionally make use of pixel-level masks or
bounding boxes, alternative representations such as polygons or active contours
have recently emerged. Among them, methods based on the regression of Fourier
or Chebyshev coefficients have shown high potential on freeform objects. By
defining object shapes as polar functions, they are however limited to
star-shaped domains. We address this issue with SCR: a method that captures
resolution-free object contours as complex periodic functions. The method
offers a good compromise between accuracy and compactness thanks to the design
of efficient geometric shape priors. We benchmark SCR on the popular COCO 2017
instance segmentation dataset, and show its competitiveness against existing
algorithms in the field. In addition, we design a compact version of our
network, which we benchmark on embedded hardware with a wide range of power
targets, achieving up to real-time performance.</p>
  </details>
</details>
<details>
  <summary>24. <b>标题：Addressing Data Scarcity in Multimodal User State Recognition by  Combining Semi-Supervised and Supervised Learning</b></summary>
  <p><b>编号</b>：[114]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03775</p>
  <p><b>作者</b>：Hendric Voß,  Heiko Wersing,  Stefan Kopp</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：training automatic recognition algorithms, dis -/ agreement detection, detecting dis -/ agreement, multimodal machine learning approach, large unlabeled data set</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Detecting mental states of human users is crucial for the development of
cooperative and intelligent robots, as it enables the robot to understand the
user's intentions and desires. Despite their importance, it is difficult to
obtain a large amount of high quality data for training automatic recognition
algorithms as the time and effort required to collect and label such data is
prohibitively high. In this paper we present a multimodal machine learning
approach for detecting dis-/agreement and confusion states in a human-robot
interaction environment, using just a small amount of manually annotated data.
We collect a data set by conducting a human-robot interaction study and develop
a novel preprocessing pipeline for our machine learning approach. By combining
semi-supervised and supervised architectures, we are able to achieve an average
F1-score of 81.1\% for dis-/agreement detection with a small amount of labeled
data and a large unlabeled data set, while simultaneously increasing the
robustness of the model compared to the supervised approach.</p>
  </details>
</details>
<details>
  <summary>25. <b>标题：STC: Spatio-Temporal Contrastive Learning for Video Instance  Segmentation</b></summary>
  <p><b>编号</b>：[126]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03747</p>
  <p><b>作者</b>：Zhengkai Jiang,  Zhangxuan Gu,  Jinlong Peng,  Hang Zhou,  Liang Liu,  Yabiao Wang,  Ying Tai,  Chengjie Wang,  Liqing Zhang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：wise temporal consistency scheme, temporal contrastive learning strategy, produce temporally coherent results, tracking embedding across frames, recent vis approaches rely</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Video Instance Segmentation (VIS) is a task that simultaneously requires
classification, segmentation, and instance association in a video. Recent VIS
approaches rely on sophisticated pipelines to achieve this goal, including
RoI-related operations or 3D convolutions. In contrast, we present a simple and
efficient single-stage VIS framework based on the instance segmentation method
CondInst by adding an extra tracking head. To improve instance association
accuracy, a novel bi-directional spatio-temporal contrastive learning strategy
for tracking embedding across frames is proposed. Moreover, an instance-wise
temporal consistency scheme is utilized to produce temporally coherent results.
Experiments conducted on the YouTube-VIS-2019, YouTube-VIS-2021, and OVIS-2021
datasets validate the effectiveness and efficiency of the proposed method. We
hope the proposed framework can serve as a simple and strong alternative for
many other instance-level video association tasks. Code will be made available.</p>
  </details>
</details>
<details>
  <summary>26. <b>标题：Consistency-Regularized Region-Growing Network for Semantic Segmentation  of Urban Scenes with Point-Level Annotations</b></summary>
  <p><b>编号</b>：[127]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03740</p>
  <p><b>作者</b>：Yonghao Xu,  Pedram Ghamisi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：two benchmark datasets demonstrate, iteratively select unlabeled pixels, proposed crgnet significantly outperforms, original sparse points, obtained great success</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep learning algorithms have obtained great success in semantic segmentation
of very high-resolution (VHR) images. Nevertheless, training these models
generally requires a large amount of accurate pixel-wise annotations, which is
very laborious and time-consuming to collect. To reduce the annotation burden,
this paper proposes a consistency-regularized region-growing network (CRGNet)
to achieve semantic segmentation of VHR images with point-level annotations.
The key idea of CRGNet is to iteratively select unlabeled pixels with high
confidence to expand the annotated area from the original sparse points.
However, since there may exist some errors and noises in the expanded
annotations, directly learning from them may mislead the training of the
network. To this end, we further propose the consistency regularization
strategy, where a base classifier and an expanded classifier are employed.
Specifically, the base classifier is supervised by the original sparse
annotations, while the expanded classifier aims to learn from the expanded
annotations generated by the base classifier with the region-growing mechanism.
The consistency regularization is thereby achieved by minimizing the
discrepancy between the predictions from both the base and the expanded
classifiers. We find such a simple regularization strategy is yet very useful
to control the quality of the region-growing mechanism. Extensive experiments
on two benchmark datasets demonstrate that the proposed CRGNet significantly
outperforms the existing state-of-the-art methods. Codes and pre-trained models
will be available online.</p>
  </details>
</details>
<details>
  <summary>27. <b>标题：Navigating to Objects in Unseen Environments by Distance Prediction</b></summary>
  <p><b>编号</b>：[128]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03735</p>
  <p><b>作者</b>：Minzhao Zhu,  Binglei Zhao,  Tao Kong</p>
  <p><b>备注</b>：Tech report</p>
  <p><b>关键词</b>：could directly perform path planning based, visually realistic simulation environments show, traditional navigation paradigm plans, object goal navigation framework, target objects based</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Object Goal Navigation (ObjectNav) task is to navigate an agent to an object
instance in unseen environments. The traditional navigation paradigm plans the
shortest path on a pre-built map. Inspired by this, we propose an object goal
navigation framework, which could directly perform path planning based on an
estimated distance map. Specifically, our model takes a birds-eye-view semantic
map as input, and estimates the distance from the map cells to the target
object based on the learned prior knowledge. With the estimated distance map,
the agent could explore the environment and navigate to the target objects
based on either human-designed or learned navigation policy. Empirical results
in visually realistic simulation environments show that the proposed method
outperforms a wide range of baselines on success rate and efficiency.</p>
  </details>
</details>
<details>
  <summary>28. <b>标题：Hair Color Digitization through Imaging and Deep Inverse Graphics</b></summary>
  <p><b>编号</b>：[134]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03723</p>
  <p><b>作者</b>：Robin Kips,  Panagiotis-Alexandros Bokaris,  Matthieu Perrot,  Pietro Gori,  Isabelle Bloch</p>
  <p><b>备注</b>：Electronic Imaging (EI) 2022</p>
  <p><b>关键词</b>：hair shape estimation many applications could benefit, material capture using deep neural networks, since rendering realistic hair images requires path, current hair capture methods focus, conventional inverse graphics approach based</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Hair appearance is a complex phenomenon due to hair geometry and how the
light bounces on different hair fibers. For this reason, reproducing a specific
hair color in a rendering environment is a challenging task that requires
manual work and expert knowledge in computer graphics to tune the result
visually. While current hair capture methods focus on hair shape estimation
many applications could benefit from an automated method for capturing the
appearance of a physical hair sample, from augmented/virtual reality to hair
dying development. Building on recent advances in inverse graphics and material
capture using deep neural networks, we introduce a novel method for hair color
digitization. Our proposed pipeline allows capturing the color appearance of a
physical hair sample and renders synthetic images of hair with a similar
appearance, simulating different hair styles and/or lighting environments.
Since rendering realistic hair images requires path-tracing rendering, the
conventional inverse graphics approach based on differentiable rendering is
untractable. Our method is based on the combination of a controlled imaging
device, a path-tracing renderer, and an inverse graphics model based on
self-supervised machine learning, which does not require to use differentiable
rendering to be trained. We illustrate the performance of our hair digitization
method on both real and synthetic images and show that our approach can
accurately capture and render hair color.</p>
  </details>
</details>
<details>
  <summary>29. <b>标题：Binary Neural Networks as a general-propose compute paradigm for  on-device computer vision</b></summary>
  <p><b>编号</b>：[136]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03716</p>
  <p><b>作者</b>：Guhong Nie (1),  Lirui Xiao (1),  Menglong Zhu (1),  Dongliang Chu (1),  Yue Shen (1),  Peng Li (1),  Kang Yang (1),  Li Du (2),  Bo Chen (1) ((1) DJI Innovations Inc, (2) School of Electronic Science and Engineering, Nanjing University)</p>
  <p><b>备注</b>：13 pages, 3 figures</p>
  <p><b>关键词</b>：scale bnn adoption could, device computer vision algorithm, bnn framework comprising 1, resultant framework overtakes 8, alternative bnn designs</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>For binary neural networks (BNNs) to become the mainstream on-device computer
vision algorithm, they must achieve a superior speed-vs-accuracy tradeoff than
8-bit quantization and establish a similar degree of general applicability in
vision tasks. To this end, we propose a BNN framework comprising 1) a
minimalistic inference scheme for hardware-friendliness, 2) an
over-parameterized training scheme for high accuracy, and 3) a simple procedure
to adapt to different vision tasks. The resultant framework overtakes 8-bit
quantization in the speed-vs-accuracy tradeoff for classification, detection,
segmentation, super-resolution and matching: our BNNs not only retain the
accuracy levels of their 8-bit baselines but also showcase 1.3-2.4$\times$
faster FPS on mobile CPUs. Similar conclusions can be drawn for prototypical
systolic-array-based AI accelerators, where our BNNs promise 2.8-7$\times$
fewer execution cycles than 8-bit and 2.1-2.7$\times$ fewer cycles than
alternative BNN designs. These results suggest that the time for large-scale
BNN adoption could be upon us.</p>
  </details>
</details>
<details>
  <summary>30. <b>标题：What's Cracking? A Review and Analysis of Deep Learning Methods for  Structural Crack Segmentation, Detection and Quantification</b></summary>
  <p><b>编号</b>：[137]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03714</p>
  <p><b>作者</b>：Jacob König,  Mark Jenkins,  Mike Mannion,  Peter Barrie,  Gordon Morison</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：review also highlights popular datasets used, structural health monitoring setting, applying computer vision algorithms, structural health monitoring, potential structural faults</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Surface cracks are a very common indicator of potential structural faults.
Their early detection and monitoring is an important factor in structural
health monitoring. Left untreated, they can grow in size over time and require
expensive repairs or maintenance. With recent advances in computer vision and
deep learning algorithms, the automatic detection and segmentation of cracks
for this monitoring process have become a major topic of interest. This review
aims to give researchers an overview of the published work within the field of
crack analysis algorithms that make use of deep learning. It outlines the
various tasks that are solved through applying computer vision algorithms to
surface cracks in a structural health monitoring setting and also provides
in-depth reviews of recent fully, semi and unsupervised approaches that perform
crack classification, detection, segmentation and quantification. Additionally,
this review also highlights popular datasets used for cracks and the metrics
that are used to evaluate the performance of those algorithms. Finally,
potential research gaps are outlined and further research directions are
provided.</p>
  </details>
</details>
<details>
  <summary>31. <b>标题：Self-Paced Imbalance Rectification for Class Incremental Learning</b></summary>
  <p><b>编号</b>：[143]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03703</p>
  <p><b>作者</b>：Zhiheng Liu,  Kai Zhu,  Yang Cao</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：three benchmarks demonstrate stable incremental performance, paced imbalance rectification scheme, inheritance transfer strategy, frequency compensation strategy, chronological attenuation mechanism</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Exemplar-based class-incremental learning is to recognize new classes while
not forgetting old ones, whose samples can only be saved in limited memory. The
ratio fluctuation of new samples to old exemplars, which is caused by the
variation of memory capacity at different environments, will bring challenges
to stabilize the incremental optimization process. To address this problem, we
propose a novel self-paced imbalance rectification scheme, which dynamically
maintains the incremental balance during the representation learning phase.
Specifically, our proposed scheme consists of a frequency compensation strategy
that adjusts the logits margin between old and new classes with the
corresponding number ratio to strengthen the expression ability of the old
classes, and an inheritance transfer strategy to reduce the representation
confusion by estimating the similarity of different classes in the old
embedding space. Furthermore, a chronological attenuation mechanism is proposed
to mitigate the repetitive optimization of the older classes at multiple
step-wise increments. Extensive experiments on three benchmarks demonstrate
stable incremental performance, significantly outperforming the
state-of-the-art methods.</p>
  </details>
</details>
<details>
  <summary>32. <b>标题：Network Comparison Study of Deep Activation Feature Discriminability  with Novel Objects</b></summary>
  <p><b>编号</b>：[147]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03695</p>
  <p><b>作者</b>：Michael Karnes,  Alper Yilmaz</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：decaf object manifolds across two visual object tracking benchmark data sets, efficiently compare estimated network performance characteristics, novel object visual appearances encoded, uav123 benchmark data sets, creating deep convolutional activation features</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Feature extraction has always been a critical component of the computer
vision field. More recently, state-of-the-art computer visions algorithms have
incorporated Deep Neural Networks (DNN) in feature extracting roles, creating
Deep Convolutional Activation Features (DeCAF). The transferability of DNN
knowledge domains has enabled the wide use of pretrained DNN feature extraction
for applications with novel object classes, especially those with limited
training data. This study analyzes the general discriminability of novel object
visual appearances encoded into the DeCAF space of six of the leading visual
recognition DNN architectures. The results of this study characterize the
Mahalanobis distances and cosine similarities between DeCAF object manifolds
across two visual object tracking benchmark data sets. The backgrounds
surrounding each object are also included as an object classes in the manifold
analysis, providing a wider range of novel classes. This study found that
different network architectures led to different network feature focuses that
must to be considered in the network selection process. These results are
generated from the VOT2015 and UAV123 benchmark data sets; however, the
proposed methods can be applied to efficiently compare estimated network
performance characteristics for any labeled visual data set.</p>
  </details>
</details>
<details>
  <summary>33. <b>标题：Exploring Inter-Channel Correlation for Diversity-preserved  KnowledgeDistillation</b></summary>
  <p><b>编号</b>：[153]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03680</p>
  <p><b>作者</b>：Li Liu,  Qingle Huang,  Sihao Lin,  Hongwei Xie,  Bing Wang,  Xiaojun Chang,  Xiaodan Liang</p>
  <p><b>备注</b>：Accepted by ICCV 2021</p>
  <p><b>关键词</b>：edge distillation boosts resnet18 beyond 72, tently outperforms many existing methods, important role ofretaining inter, student ). despitemany efforts, prior methods ignore</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Knowledge Distillation has shown very promising abil-ity in transferring
learned representation from the largermodel (teacher) to the smaller one
(student).Despitemany efforts, prior methods ignore the important role
ofretaining inter-channel correlation of features, leading tothe lack of
capturing intrinsic distribution of the featurespace and sufficient diversity
properties of features in theteacher this http URL solve the issue, we propose
thenovel Inter-Channel Correlation for Knowledge Distillation(ICKD), with which
the diversity and homology of the fea-ture space of the student network can
align with that ofthe teacher network. The correlation between these
twochannels is interpreted as diversity if they are irrelevantto each other,
otherwise homology. Then the student isrequired to mimic the correlation within
its own embed-ding space. In addition, we introduce the grid-level
inter-channel correlation, making it capable of dense predictiontasks.
Extensive experiments on two vision tasks, includ-ing ImageNet classification
and Pascal VOC segmentation,demonstrate the superiority of our ICKD, which
consis-tently outperforms many existing methods, advancing thestate-of-the-art
in the fields of Knowledge Distillation. Toour knowledge, we are the first
method based on knowl-edge distillation boosts ResNet18 beyond 72% Top-1
ac-curacy on ImageNet classification. Code is available
at:this https URL.</p>
  </details>
</details>
<details>
  <summary>34. <b>标题：Quality Metric Guided Portrait Line Drawing Generation from Unpaired  Training Data</b></summary>
  <p><b>编号</b>：[155]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03678</p>
  <p><b>作者</b>：Ran Yi,  Yong-Jin Liu,  Yu-Kun Lai,  Paul L. Rosin</p>
  <p><b>备注</b>：Accepted by IEEE Transactions on Pattern Analysis and Machine Intelligence, this https URL, code: this https URL</p>
  <p><b>关键词</b>：network toward generating better looking portrait drawings, generate portrait drawings using paired training data, portrait drawings using unpaired training data, embed invisible reconstruction information indiscriminately, generate high quality portrait drawings</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Face portrait line drawing is a unique style of art which is highly abstract
and expressive. However, due to its high semantic constraints, many existing
methods learn to generate portrait drawings using paired training data, which
is costly and time-consuming to obtain. In this paper, we propose a novel
method to automatically transform face photos to portrait drawings using
unpaired training data with two new features; i.e., our method can (1) learn to
generate high quality portrait drawings in multiple styles using a single
network and (2) generate portrait drawings in a "new style" unseen in the
training data. To achieve these benefits, we (1) propose a novel quality metric
for portrait drawings which is learned from human perception, and (2) introduce
a quality loss to guide the network toward generating better looking portrait
drawings. We observe that existing unpaired translation methods such as
CycleGAN tend to embed invisible reconstruction information indiscriminately in
the whole drawings due to significant information imbalance between the photo
and portrait drawing domains, which leads to important facial features missing.
To address this problem, we propose a novel asymmetric cycle mapping that
enforces the reconstruction information to be visible and only embedded in the
selected facial regions. Along with localized discriminators for important
facial regions, our method well preserves all important facial features in the
generated drawings. Generator dissection further explains that our model learns
to incorporate face semantic information during drawing generation. Extensive
experiments including a user study show that our model outperforms
state-of-the-art methods.</p>
  </details>
</details>
<details>
  <summary>35. <b>标题：A Novel Image Descriptor with Aggregated Semantic Skeleton  Representation for Long-term Visual Place Recognition</b></summary>
  <p><b>编号</b>：[156]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03677</p>
  <p><b>作者</b>：Nie Jiwei,  Feng Joe-Mei,  Xue Dingyu,  Pan Feng,  Liu Wei,  Hu Jun,  Cheng Shuai</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：aggregated semantic skeleton representation, ssr ), dubbed ssr, semantic skeleton features, locally aggregated descriptor, semantic segmentation images</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In a Simultaneous Localization and Mapping (SLAM) system, a loop-closure can
eliminate accumulated errors, which is accomplished by Visual Place Recognition
(VPR), a task that retrieves the current scene from a set of pre-stored
sequential images through matching specific scene-descriptors. In urban scenes,
the appearance variation caused by seasons and illumination has brought great
challenges to the robustness of scene descriptors. Semantic segmentation images
can not only deliver the shape information of objects but also their categories
and spatial relations that will not be affected by the appearance variation of
the scene. Innovated by the Vector of Locally Aggregated Descriptor (VLAD), in
this paper, we propose a novel image descriptor with aggregated semantic
skeleton representation (SSR), dubbed SSR-VLAD, for the VPR under drastic
appearance-variation of environments. The SSR-VLAD of one image aggregates the
semantic skeleton features of each category and encodes the spatial-temporal
distribution information of the image semantic information. We conduct a series
of experiments on three public datasets of challenging urban scenes. Compared
with four state-of-the-art VPR methods- CoHOG, NetVLAD, LOST-X, and
Region-VLAD, VPR by matching SSR-VLAD outperforms those methods and maintains
competitive real-time performance at the same time.</p>
  </details>
</details>
<details>
  <summary>36. <b>标题：Trained Model in Supervised Deep Learning is a Conditional Risk  Minimizer</b></summary>
  <p><b>编号</b>：[157]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03674</p>
  <p><b>作者</b>：Yutong Xie,  Dufan Wu,  Bin Dong,  Quanzheng Li</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：noisy labels using theorem 2, supervised deep learning minimizes, original supervised learning problem, using mnist dataset, using imagenet dataset</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We proved that a trained model in supervised deep learning minimizes the
conditional risk for each input (Theorem 2.1). This property provided insights
into the behavior of trained models and established a connection between
supervised and unsupervised learning in some cases. In addition, when the
labels are intractable but can be written as a conditional risk minimizer, we
proved an equivalent form of the original supervised learning problem with
accessible labels (Theorem 2.2). We demonstrated that many existing works, such
as Noise2Score, Noise2Noise and score function estimation can be explained by
our theorem. Moreover, we derived a property of classification problem with
noisy labels using Theorem 2.1 and validated it using MNIST dataset.
Furthermore, We proposed a method to estimate uncertainty in image
super-resolution based on Theorem 2.2 and validated it using ImageNet dataset.
Our code is available on github.</p>
  </details>
</details>
<details>
  <summary>37. <b>标题：How to Understand Masked Autoencoders</b></summary>
  <p><b>编号</b>：[160]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03670</p>
  <p><b>作者</b>：Shuhao Cao,  Peng Xu,  David A. Clifton</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：overlapping domain decomposition setting, scalable vision learners, contribute five questions, linguistic masked autoencoding, based attention approaches</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>"Masked Autoencoders (MAE) Are Scalable Vision Learners" revolutionizes the
self-supervised learning that not only achieves the state-of-the-art for image
pretraining, but also is a milestone that bridged the gap between the visual
and linguistic masked autoencoding (BERT-style) pretrainings. However, to our
knowledge, to date there are no theoretical perspectives to explain the
powerful expressivity of MAE. In this paper, we, for the first time, propose a
unified theoretical framework that provides a mathematical understanding for
MAE. Particularly, we explain the patch-based attention approaches of MAE using
an integral kernel under a non-overlapping domain decomposition setting. To
help the researchers to further grasp the main reasons of the great success of
MAE, based on our framework, we contribute five questions and answer them by
insights from operator theory with mathematical rigor.</p>
  </details>
</details>
<details>
  <summary>38. <b>标题：Causal Scene BERT: Improving object detection by searching for  challenging groups of data</b></summary>
  <p><b>编号</b>：[165]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03651</p>
  <p><b>作者</b>：Cinjon Resnick,  Or Litany,  Amlan Kar,  Karsten Kreis,  James Lucas,  Kyunghyun Cho,  Sanja Fidler</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：modern computer vision applications rely, prioritized groups found via intervention, utilize masked language models, tasks like object detection, groups helps inordinately compared</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Modern computer vision applications rely on learning-based perception modules
parameterized with neural networks for tasks like object detection. These
modules frequently have low expected error overall but high error on atypical
groups of data due to biases inherent in the training process. In building
autonomous vehicles (AV), this problem is an especially important challenge
because their perception modules are crucial to the overall system performance.
After identifying failures in AV, a human team will comb through the associated
data to group perception failures that share common causes. More data from
these groups is then collected and annotated before retraining the model to fix
the issue. In other words, error groups are found and addressed in hindsight.
Our main contribution is a pseudo-automatic method to discover such groups in
foresight by performing causal interventions on simulated scenes. To keep our
interventions on the data manifold, we utilize masked language models. We
verify that the prioritized groups found via intervention are challenging for
the object detector and show that retraining with data collected from these
groups helps inordinately compared to adding more IID data. We also plan to
release software to run interventions in simulated scenes, which we hope will
benefit the causality community.</p>
  </details>
</details>
<details>
  <summary>39. <b>标题：MOST-Net: A Memory Oriented Style Transfer Network for Face Sketch  Synthesis</b></summary>
  <p><b>编号</b>：[193]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03596</p>
  <p><b>作者</b>：Fan Ji,  Muyi Sun,  Xingqun Qi,  Qi Li,  Zhenan Sun</p>
  <p><b>备注</b>：7 pages, 4 figures</p>
  <p><b>关键词</b>：based face sketch synthesis frequently encounters, end memory oriented style transfer network, realistic face sketch synthesis, proposed model could obtain, supervised dynamic memory module</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Face sketch synthesis has been widely used in multi-media entertainment and
law enforcement. Despite the recent developments in deep neural networks,
accurate and realistic face sketch synthesis is still a challenging task due to
the diversity and complexity of human faces. Current image-to-image
translation-based face sketch synthesis frequently encounters over-fitting
problems when it comes to small-scale datasets. To tackle this problem, we
present an end-to-end Memory Oriented Style Transfer Network (MOST-Net) for
face sketch synthesis which can produce high-fidelity sketches with limited
data. Specifically, an external self-supervised dynamic memory module is
introduced to capture the domain alignment knowledge in the long term. In this
way, our proposed model could obtain the domain-transfer ability by
establishing the durable relationship between faces and corresponding sketches
on the feature level. Furthermore, we design a novel Memory Refinement Loss (MR
Loss) for feature alignment in the memory module, which enhances the accuracy
of memory slots in an unsupervised manner. Extensive experiments on the CUFS
and the CUFSF datasets show that our MOST-Net achieves state-of-the-art
performance, especially in terms of the Structural Similarity Index(SSIM).</p>
  </details>
</details>
<details>
  <summary>40. <b>标题：Fair SA: Sensitivity Analysis for Fairness in Face Recognition</b></summary>
  <p><b>编号</b>：[197]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03586</p>
  <p><b>作者</b>：Aparna R. Joshi,  Xavier Suau,  Nivedha Sivakumar,  Luca Zappella,  Nicholas Apostoloff</p>
  <p><b>备注</b>：8 pages, 5 figures, to be published in NeurIPS 2021 Workshop, Algorithmic Fairness through the Lens of Causality and Robustness</p>
  <p><b>关键词</b>：real world applications involving images affected, images captured across different attributes, high impact domains becomes ubiquitous, perturbations may affect subgroups differently, traditional summary statistics suggest</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As the use of deep learning in high impact domains becomes ubiquitous, it is
increasingly important to assess the resilience of models. One such high impact
domain is that of face recognition, with real world applications involving
images affected by various degradations, such as motion blur or high exposure.
Moreover, images captured across different attributes, such as gender and race,
can also challenge the robustness of a face recognition algorithm. While
traditional summary statistics suggest that the aggregate performance of face
recognition models has continued to improve, these metrics do not directly
measure the robustness or fairness of the models. Visual Psychophysics
Sensitivity Analysis (VPSA) [1] provides a way to pinpoint the individual
causes of failure by way of introducing incremental perturbations in the data.
However, perturbations may affect subgroups differently. In this paper, we
propose a new fairness evaluation based on robustness in the form of a generic
framework that extends VPSA. With this framework, we can analyze the ability of
a model to perform fairly for different subgroups of a population affected by
perturbations, and pinpoint the exact failure modes for a subgroup by measuring
targeted robustness. With the increasing focus on the fairness of models, we
use face recognition as an example application of our framework and propose to
compactly visualize the fairness analysis of a model via AUC matrices. We
analyze the performance of common face recognition models and empirically show
that certain subgroups are at a disadvantage when images are perturbed, thereby
uncovering trends that were not visible using the model's performance on
subgroups without perturbations.</p>
  </details>
</details>
<details>
  <summary>41. <b>标题：Learnability Lock: Authorized Learnability Control Through Adversarial  Invertible Transformations</b></summary>
  <p><b>编号</b>：[203]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03576</p>
  <p><b>作者</b>：Weiqi Peng,  Jinghui Chen</p>
  <p><b>备注</b>：Accepted at ICLR 2022</p>
  <p><b>关键词</b>：proposed learnability lock leverages class, propose adversarial invertible transformation, train models normally using, deep learning benefits incredibly, slightly modify data samples</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Owing much to the revolution of information technology, the recent progress
of deep learning benefits incredibly from the vastly enhanced access to data
available in various digital formats. However, in certain scenarios, people may
not want their data being used for training commercial models and thus studied
how to attack the learnability of deep learning models. Previous works on
learnability attack only consider the goal of preventing unauthorized
exploitation on the specific dataset but not the process of restoring the
learnability for authorized cases. To tackle this issue, this paper introduces
and investigates a new concept called "learnability lock" for controlling the
model's learnability on a specific dataset with a special key. In particular,
we propose adversarial invertible transformation, that can be viewed as a
mapping from image to image, to slightly modify data samples so that they
become "unlearnable" by machine learning models with negligible loss of visual
features. Meanwhile, one can unlock the learnability of the dataset and train
models normally using the corresponding key. The proposed learnability lock
leverages class-wise perturbation that applies a universal transformation
function on data samples of the same label. This ensures that the learnability
can be easily restored with a simple inverse transformation while remaining
difficult to be detected or reverse-engineered. We empirically demonstrate the
success and practicability of our method on visual classification tasks.</p>
  </details>
</details>
<details>
  <summary>42. <b>标题：Structured Prediction Problem Archive</b></summary>
  <p><b>编号</b>：[205]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03574</p>
  <p><b>作者</b>：Paul Swoboda,  Andrea Hornakova,  Paul Roetzer,  Ahmed Abbas</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：problem characteristics including size, provide archival links, facilitate algorithm development, established works easier, structured prediction problems</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Structured prediction problems are one of the fundamental tools in machine
learning. In order to facilitate algorithm development for their numerical
solution, we collect in one place a large number of datasets in easy to read
formats for a diverse set of problem classes. We provide archival links to
datasets, description of the considered problems and problem formats, and a
short summary of problem characteristics including size, number of instances
etc. For reference we also give a non-exhaustive selection of algorithms
proposed in the literature for their solution. We hope that this central
repository will make benchmarking and comparison to established works easier.
We welcome submission of interesting new datasets and algorithms for inclusion
in our archive.</p>
  </details>
</details>
<details>
  <summary>43. <b>标题：HeadPosr: End-to-end Trainable Head Pose Estimation using Transformer  Encoders</b></summary>
  <p><b>编号</b>：[213]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03548</p>
  <p><b>作者</b>：Naina Dhingra</p>
  <p><b>备注</b>：8 pages, 4 figures</p>
  <p><b>关键词</b>：conducted using three different open, using different learning rates, source widely used datasets, different position embeddings, single rgb image</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, HeadPosr is proposed to predict the head poses using a single
RGB image. \textit{HeadPosr} uses a novel architecture which includes a
transformer encoder. In concrete, it consists of: (1) backbone; (2) connector;
(3) transformer encoder; (4) prediction head. The significance of using a
transformer encoder for HPE is studied. An extensive ablation study is
performed on varying the (1) number of encoders; (2) number of heads; (3)
different position embeddings; (4) different activations; (5) input channel
size, in a transformer used in HeadPosr. Further studies on using: (1)
different backbones, (2) using different learning rates are also shown. The
elaborated experiments and ablations studies are conducted using three
different open-source widely used datasets for HPE, i.e., 300W-LP, AFLW2000,
and BIWI datasets. Experiments illustrate that \textit{HeadPosr} outperforms
all the state-of-art methods including both the landmark-free and the others
based on using landmark or depth estimation on the AFLW2000 dataset and BIWI
datasets when trained with 300W-LP. It also outperforms when averaging the
results from the compared datasets, hence setting a benchmark for the problem
of HPE, also demonstrating the effectiveness of using transformers over the
state-of-the-art.</p>
  </details>
</details>
<details>
  <summary>44. <b>标题：LwPosr: Lightweight Efficient Fine-Grained Head Pose Estimation</b></summary>
  <p><b>编号</b>：[214]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03544</p>
  <p><b>作者</b>：Naina Dhingra</p>
  <p><b>备注</b>：11 pages, 3 figures</p>
  <p><b>关键词</b>：using less parameter space, learn head poses efficiently, estimating head poses compared, source datasets namely 300w, conducted using three open</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper presents a lightweight network for head pose estimation (HPE)
task. While previous approaches rely on convolutional neural networks, the
proposed network \textit{LwPosr} uses mixture of depthwise separable
convolutional (DSC) and transformer encoder layers which are structured in two
streams and three stages to provide fine-grained regression for predicting head
poses. The quantitative and qualitative demonstration is provided to show that
the proposed network is able to learn head poses efficiently while using less
parameter space. Extensive ablations are conducted using three open-source
datasets namely 300W-LP, AFLW2000, and BIWI datasets. To our knowledge, (1)
\textit{LwPosr} is the lightest network proposed for estimating head poses
compared to both keypoints-based and keypoints-free approaches; (2) it sets a
benchmark for both overperforming the previous lightweight network on mean
absolute error and on reducing number of parameters; (3) it is first of its
kind to use mixture of DSCs and transformer encoders for HPE. This approach is
suitable for mobile devices which require lightweight networks.</p>
  </details>
</details>
<details>
  <summary>45. <b>标题：SliTraNet: Automatic Detection of Slide Transitions in Lecture Videos  using Convolutional Neural Networks</b></summary>
  <p><b>编号</b>：[216]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03540</p>
  <p><b>作者</b>：Aline Sindel,  Abner Hernandez,  Seung Hee Yang,  Vincent Christlein,  Andreas Maier</p>
  <p><b>备注</b>：6 pages, 5 figures, 1 table, accepted to OAGM Workshop 2021</p>
  <p><b>关键词</b>：online learning material, finding slide transitions, evaluation results demonstrate, employing two 3, detect slide transitions</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>With the increasing number of online learning material in the web, search for
specific content in lecture videos can be time consuming. Therefore, automatic
slide extraction from the lecture videos can be helpful to give a brief
overview of the main content and to support the students in their studies. For
this task, we propose a deep learning method to detect slide transitions in
lectures videos. We first process each frame of the video by a heuristic-based
approach using a 2-D convolutional neural network to predict transition
candidates. Then, we increase the complexity by employing two 3-D convolutional
neural networks to refine the transition candidates. Evaluation results
demonstrate the effectiveness of our method in finding slide transitions.</p>
  </details>
</details>
<details>
  <summary>46. <b>标题：MINER: Multiscale Implicit Neural Representations</b></summary>
  <p><b>编号</b>：[219]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03532</p>
  <p><b>作者</b>：Vishwanath Saragadam,  Jasper Tan,  Guha Balakrishnan,  Richard G. Baraniuk,  Ashok Veeraraghavan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：new neural signal representation designed, representing small disjoint patches, extremely fast training process, multiscale implicit neural representation, scale signal representation tasks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We introduce a new neural signal representation designed for the efficient
high-resolution representation of large-scale signals. The key innovation in
our multiscale implicit neural representation (MINER) is an internal
representation via a Laplacian pyramid, which provides a sparse multiscale
representation of the signal that captures orthogonal parts of the signal
across scales. We leverage the advantages of the Laplacian pyramid by
representing small disjoint patches of the pyramid at each scale with a tiny
MLP. This enables the capacity of the network to adaptively increase from
coarse to fine scales, and only represent parts of the signal with strong
signal energy. The parameters of each MLP are optimized from coarse-to-fine
scale which results in faster approximations at coarser scales, thereby
ultimately an extremely fast training process. We apply MINER to a range of
large-scale signal representation tasks, including gigapixel images and very
large point clouds, and demonstrate that it requires fewer than 25% of the
parameters, 33% of the memory footprint, and 10% of the computation time of
competing techniques such as ACORN to reach the same representation error.</p>
  </details>
</details>
<details>
  <summary>47. <b>标题：Integrated Multiscale Domain Adaptive YOLO</b></summary>
  <p><b>编号</b>：[221]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03527</p>
  <p><b>作者</b>：Mazin Hnewa,  Hayder Radha</p>
  <p><b>备注</b>：arXiv admin note: substantial text overlap with arXiv:2106.01483</p>
  <p><b>关键词</b>：introduce three novel deep learning architectures, novel multiscale domain adaptive yolo, recently introduced yolov4 object detector, providing comparable object detection performance, employs multiple domain adaptation paths</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The area of domain adaptation has been instrumental in addressing the domain
shift problem encountered by many applications. This problem arises due to the
difference between the distributions of source data used for training in
comparison with target data used during realistic testing scenarios. In this
paper, we introduce a novel MultiScale Domain Adaptive YOLO (MS-DAYOLO)
framework that employs multiple domain adaptation paths and corresponding
domain classifiers at different scales of the recently introduced YOLOv4 object
detector. Building on our baseline multiscale DAYOLO framework, we introduce
three novel deep learning architectures for a Domain Adaptation Network (DAN)
that generates domain-invariant features. In particular, we propose a
Progressive Feature Reduction (PFR), a Unified Classifier (UC), and an
Integrated architecture. We train and test our proposed DAN architectures in
conjunction with YOLOv4 using popular datasets. Our experiments show
significant improvements in object detection performance when training YOLOv4
using the proposed MS-DAYOLO architectures and when tested on target data for
autonomous driving applications. Moreover, MS-DAYOLO framework achieves an
order of magnitude real-time speed improvement relative to Faster R-CNN
solutions while providing comparable object detection performance.</p>
  </details>
</details>
<details>
  <summary>48. <b>标题：Scribble-based Boundary-aware Network for Weakly Supervised Salient  Object Detection in Remote Sensing Images</b></summary>
  <p><b>编号</b>：[226]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03501</p>
  <p><b>作者</b>：Zhou Huang,  Tian-Zhu Xiang,  Huai-Xin Chen,  Hang Dai</p>
  <p><b>备注</b>：33 pages, 10 figures</p>
  <p><b>关键词</b>：sparse annotation usually contains scanty information, supervised salient object detection framework, remote sensing salient object detection, based remote sensing saliency dataset, usually lack targeted discrimination</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Existing CNNs-based salient object detection (SOD) heavily depends on the
large-scale pixel-level annotations, which is labor-intensive, time-consuming,
and expensive. By contrast, the sparse annotations become appealing to the
salient object detection community. However, few efforts are devoted to
learning salient object detection from sparse annotations, especially in the
remote sensing field. In addition, the sparse annotation usually contains
scanty information, which makes it challenging to train a well-performing
model, resulting in its performance largely lagging behind the fully-supervised
models. Although some SOD methods adopt some prior cues to improve the
detection performance, they usually lack targeted discrimination of object
boundaries and thus provide saliency maps with poor boundary localization. To
this end, in this paper, we propose a novel weakly-supervised salient object
detection framework to predict the saliency of remote sensing images from
sparse scribble annotations. To implement it, we first construct the
scribble-based remote sensing saliency dataset by relabelling an existing
large-scale SOD dataset with scribbles, namely S-EOR dataset. After that, we
present a novel scribble-based boundary-aware network (SBA-Net) for remote
sensing salient object detection. Specifically, we design a boundary-aware
module (BAM) to explore the object boundary semantics, which is explicitly
supervised by the high-confidence object boundary (pseudo) labels generated by
the boundary label generation (BLG) module, forcing the model to learn features
that highlight the object structure and thus boosting the boundary localization
of objects. Then, the boundary semantics are integrated with high-level
features to guide the salient object detection under the supervision of
scribble labels.</p>
  </details>
</details>
<details>
  <summary>49. <b>标题：Random Ferns for Semantic Segmentation of PolSAR Images</b></summary>
  <p><b>编号</b>：[227]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03498</p>
  <p><b>作者</b>：Pengchao Wei,  Ronny Hänsch</p>
  <p><b>备注</b>：This is the author's version of the article as accepted for publication in IEEE Transactions on Geoscience and Remote Sensing, 2021. Link to original: this https URL</p>
  <p><b>关键词</b>：many computer vision applications ranging, polarimetric synthetic aperture radar images, explicitly compute predefined image features, polarimetric covariance matrices without, complex random forest model</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Random Ferns -- as a less known example of Ensemble Learning -- have been
successfully applied in many Computer Vision applications ranging from keypoint
matching to object detection. This paper extends the Random Fern framework to
the semantic segmentation of polarimetric synthetic aperture radar images. By
using internal projections that are defined over the space of Hermitian
matrices, the proposed classifier can be directly applied to the polarimetric
covariance matrices without the need to explicitly compute predefined image
features. Furthermore, two distinct optimization strategies are proposed: The
first based on pre-selection and grouping of internal binary features before
the creation of the classifier; and the second based on iteratively improving
the properties of a given Random Fern. Both strategies are able to boost the
performance by filtering features that are either redundant or have a low
information content and by grouping correlated features to best fulfill the
independence assumptions made by the Random Fern classifier. Experiments show
that results can be achieved that are similar to a more complex Random Forest
model and competitive to a deep learning baseline.</p>
  </details>
</details>
<details>
  <summary>50. <b>标题：PatClArC: Using Pattern Concept Activation Vectors for Noise-Robust  Model Debugging</b></summary>
  <p><b>编号</b>：[236]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03482</p>
  <p><b>作者</b>：Frederik Pahde,  Leander Weber,  Christopher J. Anders,  Wojciech Samek,  Sebastian Lapuschkin</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：learn undesired behavior based upon spurious correlations, propose pattern concept activation vectors, art machine learning models, corrects models using cavs, concept activation vectors</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>State-of-the-art machine learning models are commonly (pre-)trained on large
benchmark datasets. These often contain biases, artifacts, or errors that have
remained unnoticed in the data collection process and therefore fail in
representing the real world truthfully. This can cause models trained on these
datasets to learn undesired behavior based upon spurious correlations, e.g.,
the existence of a copyright tag in an image. Concept Activation Vectors (CAV)
have been proposed as a tool to model known concepts in latent space and have
been used for concept sensitivity testing and model correction. Specifically,
class artifact compensation (ClArC) corrects models using CAVs to represent
data artifacts in feature space linearly. Modeling CAVs with filters of linear
models, however, causes a significant influence of the noise portion within the
data, as recent work proposes the unsuitability of linear model filters to find
the signal direction in the input, which can be avoided by instead using
patterns. In this paper we propose Pattern Concept Activation Vectors (PCAV)
for noise-robust concept representations in latent space. We demonstrate that
pattern-based artifact modeling has beneficial effects on the application of
CAVs as a means to remove influence of confounding features from models via the
ClArC framework.</p>
  </details>
</details>
<details>
  <summary>51. <b>标题：Backdoor Defense via Decoupling the Training Process</b></summary>
  <p><b>编号</b>：[250]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03423</p>
  <p><b>作者</b>：Kunzhe Huang,  Yiming Li,  Baoyuan Wu,  Zhan Qin,  Kui Ren</p>
  <p><b>备注</b>：This work is accepted by the ICLR 2022. The first two authors contributed equally to this work. 25 pages</p>
  <p><b>关键词</b>：remaining fully connected layers via standard training, novel backdoor defense via decoupling, attackers embed hidden backdoors, attacked model behaves normally, end supervised training paradigm</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent studies have revealed that deep neural networks (DNNs) are vulnerable
to backdoor attacks, where attackers embed hidden backdoors in the DNN model by
poisoning a few training samples. The attacked model behaves normally on benign
samples, whereas its prediction will be maliciously changed when the backdoor
is activated. We reveal that poisoned samples tend to cluster together in the
feature space of the attacked DNN model, which is mostly due to the end-to-end
supervised training paradigm. Inspired by this observation, we propose a novel
backdoor defense via decoupling the original end-to-end training process into
three stages. Specifically, we first learn the backbone of a DNN model via
\emph{self-supervised learning} based on training samples without their labels.
The learned backbone will map samples with the same ground-truth label to
similar locations in the feature space. Then, we freeze the parameters of the
learned backbone and train the remaining fully connected layers via standard
training with all (labeled) training samples. Lastly, to further alleviate
side-effects of poisoned samples in the second stage, we remove labels of some
`low-credible' samples determined based on the learned model and conduct a
\emph{semi-supervised fine-tuning} of the whole model. Extensive experiments on
multiple benchmark datasets and DNN models verify that the proposed defense is
effective in reducing backdoor threats while preserving high accuracy in
predicting benign samples. Our code is available at
\url{this https URL}.</p>
  </details>
</details>
<details>
  <summary>52. <b>标题：Edge-based fever screening system over private 5G</b></summary>
  <p><b>编号</b>：[260]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03917</p>
  <p><b>作者</b>：Murugan Sankaradas,  Kunal Rao,  Ravi Rajendran,  Amit Redkar,  Srimat Chakradhar</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：30 ms per full hd frame, representative object level features required, uses edge machine learning techniques, uniquely associate objects across visual, low latency response times</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Edge computing and 5G have made it possible to perform analytics closer to
the source of data and achieve super-low latency response times, which is not
possible with centralized cloud deployment. In this paper, we present a novel
fever-screening system, which uses edge machine learning techniques and
leverages private 5G to accurately identify and screen individuals with fever
in real-time. Particularly, we present deep-learning based novel techniques for
fusion and alignment of cross-spectral visual and thermal data streams at the
edge. Our novel Cross-Spectral Generative Adversarial Network (CS-GAN)
synthesizes visual images that have the key, representative object level
features required to uniquely associate objects across visual and thermal
spectrum. Two key features of CS-GAN are a novel, feature-preserving loss
function that results in high-quality pairing of corresponding cross-spectral
objects, and dual bottleneck residual layers with skip connections (a new,
network enhancement) to not only accelerate real-time inference, but to also
speed up convergence during model training at the edge. To the best of our
knowledge, this is the first technique that leverages 5G networks and limited
edge resources to enable real-time feature-level association of objects in
visual and thermal streams (30 ms per full HD frame on an Intel Core i7-8650
4-core, 1.9GHz mobile processor). To the best of our knowledge, this is also
the first system to achieve real-time operation, which has enabled fever
screening of employees and guests in arenas, theme parks, airports and other
critical facilities. By leveraging edge computing and 5G, our fever screening
system is able to achieve 98.5% accuracy and is able to process about 5X more
people when compared to a centralized cloud deployment.</p>
  </details>
</details>
<details>
  <summary>53. <b>标题：On the Pitfalls of Using the Residual Error as Anomaly Score</b></summary>
  <p><b>编号</b>：[266]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03826</p>
  <p><b>作者</b>：Felix Meissen,  Benedikt Wiestler,  Georgios Kaissis,  Daniel Rueckert</p>
  <p><b>备注</b>：8 pages, 4 figures, under Review for MIDL 2022</p>
  <p><b>关键词</b>：machine learning models used, potentially anomalous input image, unseen anomalous region, yields large residuals, therefore strongly question</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Many current state-of-the-art methods for anomaly localization in medical
images rely on calculating a residual image between a potentially anomalous
input image and its "healthy" reconstruction. As the reconstruction of the
unseen anomalous region should be erroneous, this yields large residuals as a
score to detect anomalies in medical images. However, this assumption does not
take into account residuals resulting from imperfect reconstructions of the
machine learning models used. Such errors can easily overshadow residuals of
interest and therefore strongly question the use of residual images as scoring
function. Our work explores this fundamental problem of residual images in
detail. We theoretically define the problem and thoroughly evaluate the
influence of intensity and texture of anomalies against the effect of imperfect
reconstructions in a series of experiments. Code and experiments are available
under this https URL</p>
  </details>
</details>
<details>
  <summary>54. <b>标题：A Survey of Breast Cancer Screening Techniques: Thermography and  Electrical Impedance Tomography</b></summary>
  <p><b>编号</b>：[273]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03737</p>
  <p><b>作者</b>：Juan Zuluaga-Gomez,  N. Zerhouni,  Z. Al Masry,  C. Devalland,  C. Varnier</p>
  <p><b>备注</b>：Article published at: Journal of Medical Engineering & Technology (Volume 43, 2019 - Issue 5)</p>
  <p><b>关键词</b>：many countries still lack access, several machine learning techniques applied, parallel techniques like thermography, mixing several computational skills, breast cancer diagnosis going</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Breast cancer is a disease that threatens many women's life, thus, early and
accurate detection plays a key role in reducing the mortality rate. Mammography
stands as the reference technique for breast cancer screening; nevertheless,
many countries still lack access to mammograms due to economic, social, and
cultural issues. Last advances in computational tools, infrared cameras, and
devices for bio-impedance quantification allowed the development of parallel
techniques like thermography, infrared imaging, and electrical impedance
tomography, these being faster, reliable and cheaper. In the last decades,
these have been considered as complement procedures for breast cancer
diagnosis, where many studies concluded that false positive and false negative
rates are greatly reduced. This work aims to review the last breakthroughs
about the three above-mentioned techniques describing the benefits of mixing
several computational skills to obtain a better global performance. In
addition, we provide a comparison between several machine learning techniques
applied to breast cancer diagnosis going from logistic regression, decision
trees, and random forest to artificial, deep, and convolutional neural
networks. Finally, it is mentioned several recommendations for 3D breast
simulations, pre-processing techniques, biomedical devices in the research
field, prediction of tumor location and size.</p>
  </details>
</details>
<details>
  <summary>55. <b>标题：CAD-RADS Scoring using Deep Learning and Task-Specific Centerline  Labeling</b></summary>
  <p><b>编号</b>：[276]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03671</p>
  <p><b>作者</b>：Felix Denzinger,  Michael Wels,  Oliver Taubmann,  Mehmet A. Gülsün,  Max Schöbinger,  Florian André,  Sebastian J. Buss,  Johannes Görich,  Michael Sühling,  Andreas Maier,  Katharina Breininger</p>
  <p><b>备注</b>：Under review MIDL 2020</p>
  <p><b>关键词</b>：receiver operating characteristic curve, heuristic coronary segment labeling, consistent parts across patients, specific deep learning architecture, subdivides coronary trees</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>With coronary artery disease (CAD) persisting to be one of the leading causes
of death worldwide, interest in supporting physicians with algorithms to speed
up and improve diagnosis is high. In clinical practice, the severeness of CAD
is often assessed with a coronary CT angiography (CCTA) scan and manually
graded with the CAD-Reporting and Data System (CAD-RADS) score. The clinical
questions this score assesses are whether patients have CAD or not (rule-out)
and whether they have severe CAD or not (hold-out). In this work, we reach new
state-of-the-art performance for automatic CAD-RADS scoring. We propose using
severity-based label encoding, test time augmentation (TTA) and model
ensembling for a task-specific deep learning architecture. Furthermore, we
introduce a novel task- and model-specific, heuristic coronary segment
labeling, which subdivides coronary trees into consistent parts across
patients. It is fast, robust, and easy to implement. We were able to raise the
previously reported area under the receiver operating characteristic curve
(AUC) from 0.914 to 0.942 in the rule-out and from 0.921 to 0.950 in the
hold-out task respectively.</p>
  </details>
</details>
<details>
  <summary>56. <b>标题：Model and predict age and sex in healthy subjects using brain white  matter features: A deep learning approach</b></summary>
  <p><b>编号</b>：[282]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03595</p>
  <p><b>作者</b>：Hao He,  Fan Zhang,  Steve Pieper,  Nikos Makris,  Yogesh Rathi,  William Wells III,  Lauren J. O'Donnell</p>
  <p><b>备注</b>：accepted by ISBI 2022</p>
  <p><b>关键词</b>：novel ensembled neural network classifier, related brain structure differences, brain wm structure noninvasively, young adult dataset, potentially enable monitoring</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The human brain's white matter (WM) structure is of immense interest to the
scientific community. Diffusion MRI gives a powerful tool to describe the brain
WM structure noninvasively. To potentially enable monitoring of age-related
changes and investigation of sex-related brain structure differences on the
mapping between the brain connectome and healthy subjects' age and sex, we
extract fiber-cluster-based diffusion features and predict sex and age with a
novel ensembled neural network classifier. We conduct experiments on the Human
Connectome Project (HCP) young adult dataset and show that our model achieves
94.82% accuracy in sex prediction and 2.51 years MAE in age prediction. We also
show that the fractional anisotropy (FA) is the most predictive of sex, while
the number of fibers is the most predictive of age and the combination of
different features can improve the model performance.</p>
  </details>
</details>
<details>
  <summary>57. <b>标题：Multi-Label Classification of Thoracic Diseases using Dense  Convolutional Network on Chest Radiographs</b></summary>
  <p><b>编号</b>：[284]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03583</p>
  <p><b>作者</b>：Dipkamal Bhusal,  Dr. Sanjeeb Prasad Panday</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：using dense convolutional neural network, ray images requires skilled manpower, identify different thoracic diseases, obtain high classification predictions, common medical diagnosis techniques</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Chest X-ray images are one of the most common medical diagnosis techniques to
identify different thoracic diseases. However, identification of pathologies in
X-ray images requires skilled manpower and are often cited as a time-consuming
task with varied level of interpretation, particularly in cases where the
identification of disease only by images is difficult for human eyes. With
recent achievements of deep learning in image classification, its application
in disease diagnosis has been widely explored. This research project presents a
multi-label disease diagnosis model of chest x-rays. Using Dense Convolutional
Neural Network (DenseNet), the diagnosis system was able to obtain high
classification predictions. The model obtained the highest AUC score of 0.896
for condition Cardiomegaly and the lowest AUC score for Nodule, 0.655. The
model also localized the parts of the chest radiograph that indicated the
presence of each pathology using GRADCAM, thus contributing to the model
interpretability of a deep learning algorithm.</p>
  </details>
</details>
<details>
  <summary>58. <b>标题：Metal Artifact Reduction with Intra-Oral Scan Data for 3D Low Dose  Maxillofacial CBCT Modeling</b></summary>
  <p><b>编号</b>：[285]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03571</p>
  <p><b>作者</b>：Chang Min Hyun,  Taigyntuya Bayaraa,  Hye Sun Yun,  Tae Jun Jang,  Hyoung Suk Park,  Jin Keun Seo</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：dose dental cone beam computed tomography, utilize explicit tooth shape prior information, 3d low dose maxillofacial cbct modeling, oral scan data whose acquisition, dose maxillofacial cbct modeling</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Low-dose dental cone beam computed tomography (CBCT) has been increasingly
used for maxillofacial modeling. However, the presence of metallic inserts,
such as implants, crowns, and dental filling, causes severe streaking and
shading artifacts in a CBCT image and loss of the morphological structures of
the teeth, which consequently prevents accurate segmentation of bones. A
two-stage metal artifact reduction method is proposed for accurate 3D low-dose
maxillofacial CBCT modeling, where a key idea is to utilize explicit tooth
shape prior information from intra-oral scan data whose acquisition does not
require any extra radiation exposure. In the first stage, an image-to-image
deep learning network is employed to mitigate metal-related artifacts. To
improve the learning ability, the proposed network is designed to take
advantage of the intra-oral scan data as side-inputs and perform multi-task
learning of auxiliary tooth segmentation. In the second stage, a 3D
maxillofacial model is constructed by segmenting the bones from the dental CBCT
image corrected in the first stage. For accurate bone segmentation, weighted
thresholding is applied, wherein the weighting region is determined depending
on the geometry of the intra-oral scan data. Because acquiring a paired
training dataset of metal-artifact-free and metal artifact-affected dental CBCT
images is challenging in clinical practice, an automatic method of generating a
realistic dataset according to the CBCT physics model is introduced. Numerical
simulations and clinical experiments show the feasibility of the proposed
method, which takes advantage of tooth surface information from intra-oral scan
data in 3D low dose maxillofacial CBCT modeling.</p>
  </details>
</details>
<details>
  <summary>59. <b>标题：Phase-Stretch Adaptive Gradient-Field Extractor (PAGE)</b></summary>
  <p><b>编号</b>：[286]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03570</p>
  <p><b>作者</b>：Callen MacPhee,  Madhuri Suthar,  Bahram Jalali</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：simultaneously made available within, algorithm performs exceptionally well, image brightness changes abruptly, computational imaging algorithm, stretch adaptive gradient</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Phase-Stretch Adaptive Gradient-Field Extractor (PAGE) is an edge detection
algorithm that is inspired by physics of electromagnetic diffraction and
dispersion. A computational imaging algorithm, it identifies edges, their
orientations and sharpness in a digital image where the image brightness
changes abruptly. Edge detection is a basic operation performed by the eye and
is crucial to visual perception. PAGE embeds an original image into a set of
feature maps that can be used for object representation and classification. The
algorithm performs exceptionally well as an edge and texture extractor in low
light level and low contrast images. This manuscript is prepared to support the
open-source code which is being simultaneously made available within the GitHub
repository this https URL.</p>
  </details>
</details>
<details>
  <summary>60. <b>标题：Accurate super-resolution low-field brain MRI</b></summary>
  <p><b>编号</b>：[287]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03564</p>
  <p><b>作者</b>：Juan Eugenio Iglesias,  Riana Schleicher,  Sonia Laguna,  Benjamin Billot,  Pamela Schaefer,  Brenna McKaig,  Joshua N. Goldstein,  Kevin N. Sheth,  Matthew S. Rosen,  W. Taylor Kimberly</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：synthesize 1 mm isotropic mprage, available automated segmentation tools directly, higher resolution images derived, multiple lower resolution scans, segmentation tools succeed</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The recent introduction of portable, low-field MRI (LF-MRI) into the clinical
setting has the potential to transform neuroimaging. However, LF-MRI is limited
by lower resolution and signal-to-noise ratio, leading to incomplete
characterization of brain regions. To address this challenge, recent advances
in machine learning facilitate the synthesis of higher resolution images
derived from one or multiple lower resolution scans. Here, we report the
extension of a machine learning super-resolution (SR) algorithm to synthesize 1
mm isotropic MPRAGE-like scans from LF-MRI T1-weighted and T2-weighted
sequences. Our initial results on a paired dataset of LF and high-field (HF,
1.5T-3T) clinical scans show that: (i) application of available automated
segmentation tools directly to LF-MRI images falters; but (ii) segmentation
tools succeed when applied to SR images with high correlation to gold standard
measurements from HF-MRI (e.g., r = 0.85 for hippocampal volume, r = 0.84 for
the thalamus, r = 0.92 for the whole cerebrum). This work demonstrates
proof-of-principle post-processing image enhancement from lower resolution
LF-MRI sequences. These results lay the foundation for future work to enhance
the detection of normal and abnormal image findings at LF and ultimately
improve the diagnostic performance of LF-MRI. Our tools are publicly available
on FreeSurfer (this http URL).</p>
  </details>
</details>
<details>
  <summary>61. <b>标题：Aladdin: Joint Atlas Building and Diffeomorphic Registration Learning  with Pairwise Alignment</b></summary>
  <p><b>编号</b>：[288]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03563</p>
  <p><b>作者</b>：Zhipeng Ding,  Marc Niethammer</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：atlas building often define similarity measures, proposed framework achieves better performance, 3d knee magnetic resonance images, utilizes pairwise image alignment losses, may cause alignment difficulties</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Atlas building and image registration are important tasks for medical image
analysis. Once one or multiple atlases from an image population have been
constructed, commonly (1) images are warped into an atlas space to study
intra-subject or inter-subject variations or (2) a possibly probabilistic atlas
is warped into image space to assign anatomical labels. Atlas estimation and
nonparametric transformations are computationally expensive as they usually
require numerical optimization. Additionally, previous approaches for atlas
building often define similarity measures between a fuzzy atlas and each
individual image, which may cause alignment difficulties because a fuzzy atlas
does not exhibit clear anatomical structures in contrast to the individual
images. This work explores using a convolutional neural network (CNN) to
jointly predict the atlas and a stationary velocity field (SVF)
parameterization for diffeomorphic image registration with respect to the
atlas. Our approach does not require affine pre-registrations and utilizes
pairwise image alignment losses to increase registration accuracy. We evaluate
our model on 3D knee magnetic resonance images (MRI) from the OAI-ZIB dataset.
Our results show that the proposed framework achieves better performance than
other state-of-the-art image registration algorithms, allows for end-to-end
training, and for fast inference at test time.</p>
  </details>
</details>
<details>
  <summary>62. <b>标题：Self-Supervised Representation Learning for Speech Using Visual  Grounding and Masked Language Modeling</b></summary>
  <p><b>编号</b>：[289]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03543</p>
  <p><b>作者</b>：Puyuan Peng,  David Harwath</p>
  <p><b>备注</b>：SAS workshop at AAAI2022</p>
  <p><b>关键词</b>：models also achieve strong performance, masked language modeling objective, associate raw speech waveforms, models perform competitively, visual grounding objective</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we describe our submissions to the ZeroSpeech 2021 Challenge
and SUPERB benchmark. Our submissions are based on the recently proposed
FaST-VGS model, which is a Transformer-based model that learns to associate raw
speech waveforms with semantically related images, all without the use of any
transcriptions of the speech. Additionally, we introduce a novel extension of
this model, FaST-VGS+, which is learned in a multi-task fashion with a masked
language modeling objective in addition to the visual grounding objective. On
ZeroSpeech 2021, we show that our models perform competitively on the ABX task,
outperform all other concurrent submissions on the Syntactic and Semantic
tasks, and nearly match the best system on the Lexical task. On the SUPERB
benchmark, we show that our models also achieve strong performance, in some
cases even outperforming the popular wav2vec2.0 model.</p>
  </details>
</details>
<details>
  <summary>63. <b>标题：Multi-modal data generation with a deep metric variational autoencoder</b></summary>
  <p><b>编号</b>：[293]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03434</p>
  <p><b>作者</b>：Josefine Vilsbøll Sundgaard,  Morten Rieger Hannemose,  Søren Laugesen,  Peter Bray,  James Harte,  Yosuke Kamide,  Chiemi Tanaka,  Rasmus R. Paulsen,  Anders Nymark Christensen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：variational autoencoder employs triplet loss, deep metric variational autoencoder, corresponding wideband tympanometry measurements, approach shows promising results, represent different aspects</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present a deep metric variational autoencoder for multi-modal data
generation. The variational autoencoder employs triplet loss in the latent
space, which allows for conditional data generation by sampling in the latent
space within each class cluster. The approach is evaluated on a multi-modal
dataset consisting of otoscopy images of the tympanic membrane with
corresponding wideband tympanometry measurements. The modalities in this
dataset are correlated, as they represent different aspects of the state of the
middle ear, but they do not present a direct pixel-to-pixel correlation. The
approach shows promising results for the conditional generation of pairs of
images and tympanograms, and will allow for efficient data augmentation of data
from multi-modal sources.</p>
  </details>
</details>
<details>
  <summary>64. <b>标题：A Coarse-to-fine Morphological Approach With Knowledge-based Rules and  Self-adapting Correction for Lung Nodules Segmentation</b></summary>
  <p><b>编号</b>：[294]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03433</p>
  <p><b>作者</b>：Xinliang Fu,  Jiayin Zheng,  Juanyun Mai,  Yanbo Shao,  Minghao Wang,  Linyu Li,  Zhaoqi Diao,  Yulong Chen,  Jianyu Xiao,  Jian You,  Airu Yin,  Yang Yang,  Xiangcheng Qiu,  Jinsheng Tao,  Bo Wang,  Hua Ji</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：effectively removes noisy pixels, recent strong morphological baselines, available morphological methods, sota deep learning, achieve high accuracy</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The segmentation module which precisely outlines the nodules is a crucial
step in a computer-aided diagnosis(CAD) system. The most challenging part of
such a module is how to achieve high accuracy of the segmentation, especially
for the juxtapleural, non-solid and small nodules. In this research, we present
a coarse-to-fine methodology that greatly improves the thresholding method
performance with a novel self-adapting correction algorithm and effectively
removes noisy pixels with well-defined knowledge-based principles. Compared
with recent strong morphological baselines, our algorithm, by combining dataset
features, achieves state-of-the-art performance on both the public LIDC-IDRI
dataset (DSC 0.699) and our private LC015 dataset (DSC 0.760) which closely
approaches the SOTA deep learning-based models' performances. Furthermore,
unlike most available morphological methods that can only segment the isolated
and well-circumscribed nodules accurately, the precision of our method is
totally independent of the nodule type or diameter, proving its applicability
and generality.</p>
  </details>
</details>
<details>
  <summary>65. <b>标题：Inference of captions from histopathological patches</b></summary>
  <p><b>编号</b>：[295]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03432</p>
  <p><b>作者</b>：Masayuki Tsuneki,  Fahdi Kanavati</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：stomach adenocarcinoma endoscopic biopsy specimens, stained whole slide images, associated whole slide images, 262k patches publicly available, gastric adenocarcinoma subtypes</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Computational histopathology has made significant strides in the past few
years, slowly getting closer to clinical adoption. One area of benefit would be
the automatic generation of diagnostic reports from H\&E-stained whole slide
images which would further increase the efficiency of the pathologists' routine
diagnostic workflows. In this study, we compiled a dataset (PatchGastricADC22)
of histopathological captions of stomach adenocarcinoma endoscopic biopsy
specimens, which we extracted from diagnostic reports and paired with patches
extracted from the associated whole slide images. The dataset contains a
variety of gastric adenocarcinoma subtypes. We trained a baseline
attention-based model to predict the captions from features extracted from the
patches and obtained promising results. We make the captioned dataset of 262K
patches publicly available.</p>
  </details>
</details>
<details>
  <summary>66. <b>标题：A Topology-Attention ConvLSTM Network and Its Application to EM Images</b></summary>
  <p><b>编号</b>：[296]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03430</p>
  <p><b>作者</b>：Jiaqi Yang,  Xiaoling Hu,  Chao Chen,  Chialing Tsai</p>
  <p><b>备注</b>：12 pages, 6 figures, Accepted by MICCAI'21</p>
  <p><b>关键词</b>：proposed method outperforms various baselines, leverage contextual structure information, novel topologyattention convlstm network, critical information across slices, achieve high structural accuracy</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Structural accuracy of segmentation is important for finescale structures in
biomedical images. We propose a novel TopologyAttention ConvLSTM Network
(TACNet) for 3D image segmentation in order to achieve high structural accuracy
for 3D segmentation tasks. Specifically, we propose a Spatial
Topology-Attention (STA) module to process a 3D image as a stack of 2D image
slices and adopt ConvLSTM to leverage contextual structure information from
adjacent slices. In order to effectively transfer topology-critical information
across slices, we propose an Iterative-Topology Attention (ITA) module that
provides a more stable topology-critical map for segmentation. Quantitative and
qualitative results show that our proposed method outperforms various baselines
in terms of topology-aware evaluation metrics.</p>
  </details>
</details>
<details>
  <summary>67. <b>标题：Performance Evaluation of Infrared Image Enhancement Techniques</b></summary>
  <p><b>编号</b>：[297]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03427</p>
  <p><b>作者</b>：Rania Gaber,  AbdElmgied Ali,  Kareem Ahmed</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：survey covers spatial enhancement techniques, capturing devices use electromagnetic radiation, survey includes ir radiation types, domain based enhancement techniques, ir imaging enhancement techniques</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Infrared (IR) images are widely used in many fields such as medical imaging,
object tracking, astronomy and military purposes for securing borders. Infrared
images can be captured day or night based on the type of capturing device. The
capturing devices use electromagnetic radiation with longer wavelengths. There
are several types of IR radiation based on the range of wavelength and
corresponding frequency. Due to noising and other artifacts, IR images are not
clearly visible. In this paper, we present a complete up-todate survey on IR
imaging enhancement techniques. The survey includes IR radiation types and
devices and existing IR datasets. The survey covers spatial enhancement
techniques, frequency-domain based enhancement techniques and Deep
learning-based techniques.</p>
  </details>
</details>
<h1>自然语言处理</h1>
<details>
  <summary>1. <b>标题：DALL-Eval: Probing the Reasoning Skills and Social Biases of  Text-to-Image Generative Transformers</b></summary>
  <p><b>编号</b>：[4]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.04053</p>
  <p><b>作者</b>：Jaemin Cho,  Abhay Zala,  Mohit Bansal</p>
  <p><b>备注</b>：20 pages, 10 figures, 13 tables</p>
  <p><b>关键词</b>：image models learn specific gender, measure four visual reasoning skills, help guide future progress, multimodal transformer language model, four visual reasoning skills</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Generating images from textual descriptions has gained a lot of attention.
Recently, DALL-E, a multimodal transformer language model, and its variants
have shown high-quality text-to-image generation capabilities with a simple
architecture and training objective, powered by large-scale training data and
computation. However, despite the interesting image generation results, there
has not been a detailed analysis on how to evaluate such models. In this work,
we investigate the reasoning capabilities and social biases of such
text-to-image generative transformers in detail. First, we measure four visual
reasoning skills: object recognition, object counting, color recognition, and
spatial relation understanding. For this, we propose PaintSkills, a diagnostic
dataset and evaluation toolkit that measures these four visual reasoning
skills. Second, we measure the text alignment and quality of the generated
images based on pretrained image captioning, image-text retrieval, and image
classification models. Third, we assess social biases in the models. For this,
we suggest evaluation of gender and racial biases of text-to-image generation
models based on a pretrained image-text retrieval model and human evaluation.
In our experiments, we show that recent text-to-image models perform better in
recognizing and counting objects than recognizing colors and understanding
spatial relations, while there exists a large gap between model performances
and oracle accuracy on all skills. Next, we demonstrate that recent
text-to-image models learn specific gender/racial biases from web image-text
pairs. We also show that our automatic evaluations of visual reasoning skills
and gender bias are highly correlated with human judgments. We hope our work
will help guide future progress in improving text-to-image models on visual
reasoning skills and social biases. Code and data at:
this https URL</p>
  </details>
</details>
<details>
  <summary>2. <b>标题：Integrating question answering and text-to-SQL in Portuguese</b></summary>
  <p><b>编号</b>：[9]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.04048</p>
  <p><b>作者</b>：Marcos Menon José,  Marcelo Archanjo José,  Denis Deratani Mauá,  Fábio Gagliardi Cozman</p>
  <p><b>备注</b>：Accepted at International Conference on the Computational Processing of Portuguese (PROPOR 2022), but not yet published</p>
  <p><b>关键词</b>：different questions demand different answering techniques, neural question answering reasoner, modular question answering strategy, 99 \%), thus validating, answer two distinct kinds</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep learning transformers have drastically improved systems that
automatically answer questions in natural language. However, different
questions demand different answering techniques; here we propose, build and
validate an architecture that integrates different modules to answer two
distinct kinds of queries. Our architecture takes a free-form natural language
text and classifies it to send it either to a Neural Question Answering
Reasoner or a Natural Language parser to SQL. We implemented a complete system
for the Portuguese language, using some of the main tools available for the
language and translating training and testing datasets. Experiments show that
our system selects the appropriate answering method with high accuracy (over
99\%), thus validating a modular question answering strategy.</p>
  </details>
</details>
<details>
  <summary>3. <b>标题：Differentiable N-gram Objective on Abstractive Summarization</b></summary>
  <p><b>编号</b>：[23]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.04003</p>
  <p><b>作者</b>：Yunqi Zhu,  Wensheng Zhang,  Mingjin Zhu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：standard automatic evaluation metric based, providing decent rouge score enhancement, neural network language model, abstractive summarization dataset cnn, ground truth count</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>ROUGE is a standard automatic evaluation metric based on n-grams for
sequence-to-sequence tasks, while cross-entropy loss is an essential objective
of neural network language model that optimizes at a unigram level. We present
differentiable n-gram objectives, attempting to alleviate the discrepancy
between training criterion and evaluating criterion. The objective maximizes
the probabilistic weight of matched sub-sequences, and the novelty of our work
is the objective weights the matched sub-sequences equally and does not ceil
the number of matched sub-sequences by the ground truth count of n-grams in
reference sequence. We jointly optimize cross-entropy loss and the proposed
objective, providing decent ROUGE score enhancement over abstractive
summarization dataset CNN/DM and XSum, outperforming alternative n-gram
objectives.</p>
  </details>
</details>
<details>
  <summary>4. <b>标题：TimeLMs: Diachronic Language Models from Twitter</b></summary>
  <p><b>编号</b>：[95]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03829</p>
  <p><b>作者</b>：Daniel Loureiro,  Francesco Barbieri,  Leonardo Neves,  Luis Espinosa Anke,  Jose Camacho-Collados</p>
  <p><b>备注</b>：GitHub: this https URL</p>
  <p><b>关键词</b>：activity involving specific named entities, continual learning strategy contributes, qualitative analyses showing, language models specialized, language model literature</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Despite its importance, the time variable has been largely neglected in the
NLP and language model literature. In this paper, we present TimeLMs, a set of
language models specialized on diachronic Twitter data. We show that a
continual learning strategy contributes to enhancing Twitter-based language
models' capacity to deal with future and out-of-distribution tweets, while
making them competitive with standardized and more monolithic benchmarks. We
also perform a number of qualitative analyses showing how they cope with trends
and peaks in activity involving specific named entities or concept drift.</p>
  </details>
</details>
<details>
  <summary>5. <b>标题：What are the best systems? New perspectives on NLP Benchmarking</b></summary>
  <p><b>编号</b>：[106]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03799</p>
  <p><b>作者</b>：Pierre Colombo,  Nathan Noiry,  Ekhine Irurozki,  Stephan Clemencon</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：new methods along different axes, conduct extensive numerical experiments, method yields different conclusions, aggregate different systems performances, performance across different tasks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In Machine Learning, a benchmark refers to an ensemble of datasets associated
with one or multiple metrics together with a way to aggregate different systems
performances. They are instrumental in (i) assessing the progress of new
methods along different axes and (ii) selecting the best systems for practical
use. This is particularly the case for NLP with the development of large
pre-trained models (e.g. GPT, BERT) that are expected to generalize well on a
variety of tasks. While the community mainly focused on developing new datasets
and metrics, there has been little interest in the aggregation procedure, which
is often reduced to a simple average over various performance measures.
However, this procedure can be problematic when the metrics are on a different
scale, which may lead to spurious conclusions. This paper proposes a new
procedure to rank systems based on their performance across different tasks.
Motivated by the social choice theory, the final system ordering is obtained
through aggregating the rankings induced by each task and is theoretically
grounded. We conduct extensive numerical experiments (on over 270k scores) to
assess the soundness of our approach both on synthetic and real scores (e.g.
GLUE, EXTREM, SEVAL, TAC, FLICKR). In particular, we show that our method
yields different conclusions on state-of-the-art systems than the
mean-aggregation procedure while being both more reliable and robust.</p>
  </details>
</details>
<details>
  <summary>6. <b>标题：Counterfactual Multi-Token Fairness in Text Classification</b></summary>
  <p><b>编号</b>：[108]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03792</p>
  <p><b>作者</b>：Pranay Lohia</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：support beyond traditionally used sensitive attributes like, machine learning classification models towards, showcase significant performance improvement, sensitive attribute gets bounded, counterfactual fairness gets narrowed</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The counterfactual token generation has been limited to perturbing only a
single token in texts that are generally short and single sentences. These
tokens are often associated with one of many sensitive attributes. With limited
counterfactuals generated, the goal to achieve invariant nature for machine
learning classification models towards any sensitive attribute gets bounded,
and the formulation of Counterfactual Fairness gets narrowed. In this paper, we
overcome these limitations by solving root problems and opening bigger domains
for understanding. We have curated a resource of sensitive tokens and their
corresponding perturbation tokens, even extending the support beyond
traditionally used sensitive attributes like \textit{Age}, \textit{Gender}, and
\textit{Race} to \textit{Nationality}, \textit{Disability}, and
\textit{Religion}. The concept of Counterfactual Generation has been extended
to multi-token support valid over all forms of texts and documents. We define
the method of generating counterfactuals by perturbing multiple sensitive
tokens as \textbf{Counterfactual Multi-token Generation}. The method has been
conceptualized to showcase significant performance improvement over
single-token methods and validated over multiple benchmark datasets. The
emendation in counterfactual generation propagates in achieving improved
\textbf{Counterfactual Multi-token Fairness}.</p>
  </details>
</details>
<details>
  <summary>7. <b>标题：Modeling Structure with Undirected Neural Networks</b></summary>
  <p><b>编号</b>：[118]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03760</p>
  <p><b>作者</b>：Tsvetomila Mihaylova,  Vlad Niculae,  André F. T. Martins</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：g ., factor graphs -- neural networks, extend many existing architectures, proposing undirected neural networks, problem -- e, undirected neural architectures</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Neural networks are powerful function estimators, leading to their status as
a paradigm of choice for modeling structured data. However, unlike other
structured representations that emphasize the modularity of the problem --
e.g., factor graphs -- neural networks are usually monolithic mappings from
inputs to outputs, with a fixed computation order. This limitation prevents
them from capturing different directions of computation and interaction between
the modeled variables.
In this paper, we combine the representational strengths of factor graphs and
of neural networks, proposing undirected neural networks (UNNs): a flexible
framework for specifying computations that can be performed in any order. For
particular choices, our proposed models subsume and extend many existing
architectures: feed-forward, recurrent, self-attention networks, auto-encoders,
and networks with implicit layers. We demonstrate the effectiveness of
undirected neural architectures, both unstructured and structured, on a range
of tasks: tree-constrained dependency parsing, convolutional image
classification, and sequence completion with attention. By varying the
computation order, we show how a single UNN can be used both as a classifier
and a prototype generator, and how it can fill in missing parts of an input
sequence, making them a promising field for further research.</p>
  </details>
</details>
<details>
  <summary>8. <b>标题：Semantic features of object concepts generated with GPT-3</b></summary>
  <p><b>编号</b>：[123]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03753</p>
  <p><b>作者</b>：Hannes Hansen,  Martin N. Hebart</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：generated feature norms rivaled human norms, automatically generating interpretable feature sets, models would produce features similar, existing human feature norms, given recent promising developments</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Semantic features have been playing a central role in investigating the
nature of our conceptual representations. Yet the enormous time and effort
required to empirically sample and norm features from human raters has
restricted their use to a limited set of manually curated concepts. Given
recent promising developments with transformer-based language models, here we
asked whether it was possible to use such models to automatically generate
meaningful lists of properties for arbitrary object concepts and whether these
models would produce features similar to those found in humans. To this end, we
probed a GPT-3 model to generate semantic features for 1,854 objects and
compared automatically-generated features to existing human feature norms.
GPT-3 generated many more features than humans, yet showed a similar
distribution in the types of generated features. Generated feature norms
rivaled human norms in predicting similarity, relatedness, and category
membership, while variance partitioning demonstrated that these predictions
were driven by similar variance in humans and GPT-3. Together, these results
highlight the potential of large language models to capture important facets of
human knowledge and yield a new approach for automatically generating
interpretable feature sets, thus drastically expanding the potential use of
semantic features in psychological and linguistic studies.</p>
  </details>
</details>
<details>
  <summary>9. <b>标题：A two-step approach to leverage contextual data: speech recognition in  air-traffic communications</b></summary>
  <p><b>编号</b>：[133]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03725</p>
  <p><b>作者</b>：Iuliia Nigmatulina,  Juan Zuluaga-Gomez,  Amrutha Prasad,  Seyyed Saeed Sarfjoo,  Petr Motlicek</p>
  <p><b>备注</b>：20XX IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works. arXiv admin note: text overlap with arXiv:2108.12156</p>
  <p><b>关键词</b>：nlp methods eventually leads, step callsign boosting approach, improve air traffic management, nlp ), callsigns extracted, boosting callsign n</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Automatic Speech Recognition (ASR), as the assistance of speech communication
between pilots and air-traffic controllers, can significantly reduce the
complexity of the task and increase the reliability of transmitted information.
ASR application can lead to a lower number of incidents caused by
misunderstanding and improve air traffic management (ATM) efficiency.
Evidently, high accuracy predictions, especially, of key information, i.e.,
callsigns and commands, are required to minimize the risk of errors. We prove
that combining the benefits of ASR and Natural Language Processing (NLP)
methods to make use of surveillance data (i.e. additional modality) helps to
considerably improve the recognition of callsigns (named entity). In this
paper, we investigate a two-step callsign boosting approach: (1) at the 1 step
(ASR), weights of probable callsign n-grams are reduced in G.fst and/or in the
decoding FST (lattices), (2) at the 2 step (NLP), callsigns extracted from the
improved recognition outputs with Named Entity Recognition (NER) are correlated
with the surveillance data to select the most suitable one. Boosting callsign
n-grams with the combination of ASR and NLP methods eventually leads up to
53.7% of an absolute, or 60.4% of a relative, improvement in callsign
recognition.</p>
  </details>
</details>
<details>
  <summary>10. <b>标题：Survey of Hallucination in Natural Language Generation</b></summary>
  <p><b>编号</b>：[178]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03629</p>
  <p><b>作者</b>：Ziwei Ji,  Nayeon Lee,  Rita Frieske,  Tiezheng Yu,  Dan Su,  Yan Xu,  Etsuko Ishii,  Yejin Bang,  Andrea Madotto,  Pascale Fung</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：survey could facilitate collaborative efforts among researchers, generation includes hallucinated texts, coherent natural language generation, natural language generation, based language models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Natural Language Generation (NLG) has improved exponentially in recent years
thanks to the development of deep learning technologies such as
Transformer-based language models. This advancement has led to more fluent and
coherent natural language generation, naturally leading to development in
downstream tasks such as abstractive summarization, dialogue generation and
data-to-text generation. However, it is also investigated that such generation
includes hallucinated texts, which makes the performances of text generation
fail to meet users' expectations in many real-world scenarios. In order to
address this issue, studies in evaluation and mitigation methods of
hallucinations have been presented in various tasks, but have not been reviewed
in a combined manner. In this survey, we provide a broad overview of the
research progress and challenges in the hallucination problem of NLG. The
survey is organized into two big divisions: (i) a general overview of metrics,
mitigation methods, and future directions; (ii) task-specific research progress
for hallucinations in a large set of downstream tasks: abstractive
summarization, dialogue generation, generative question answering, data-to-text
generation, and machine translation. This survey could facilitate collaborative
efforts among researchers in these tasks.</p>
  </details>
</details>
<details>
  <summary>11. <b>标题：Towards Property-Based Tests in Natural Language</b></summary>
  <p><b>编号</b>：[183]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03616</p>
  <p><b>作者</b>：Colin S. Gordon (Drexel University)</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：combinatory categorial grammars, apply classic ideas, translate natural, textbook chapter, templated extraction</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We consider a new approach to generate tests from natural language. Rather
than relying on machine learning or templated extraction from structured
comments, we propose to apply classic ideas from linguistics to translate
natural-language sentences into executable tests. This paper explores the
application of combinatory categorial grammars (CCGs) to generating
property-based tests. Our prototype is able to generate tests from English
descriptions for each example in a textbook chapter on property-based testing.</p>
  </details>
</details>
<details>
  <summary>12. <b>标题：HistBERT: A Pre-trained Language Model for Diachronic Lexical Semantic  Analysis</b></summary>
  <p><b>编号</b>：[186]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03612</p>
  <p><b>作者</b>：Wenjun Qiu,  Yang Xu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：historical corpus data improves diachronic semantic analysis, various natural language processing tasks including, study historical semantic change, concern historical semantic change, diachronic semantic analysis</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Contextualized word embeddings have demonstrated state-of-the-art performance
in various natural language processing tasks including those that concern
historical semantic change. However, language models such as BERT was trained
primarily on contemporary corpus data. To investigate whether training on
historical corpus data improves diachronic semantic analysis, we present a
pre-trained BERT-based language model, HistBERT, trained on the balanced Corpus
of Historical American English. We examine the effectiveness of our approach by
comparing the performance of the original BERT and that of HistBERT, and we
report promising results in word similarity and semantic shift analysis. Our
work suggests that the effectiveness of contextual embeddings in diachronic
semantic analysis is dependent on the temporal profile of the input text and
care should be taken in applying this methodology to study historical semantic
change.</p>
  </details>
</details>
<details>
  <summary>13. <b>标题：Do Language Models Learn Position-Role Mappings?</b></summary>
  <p><b>编号</b>：[187]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03611</p>
  <p><b>作者</b>：Jackson Petty,  Michael Wilson,  Robert Frank</p>
  <p><b>备注</b>：To appear in the BUCLD 46 Proceedings</p>
  <p><b>关键词</b>：shared across construction type, performing pertained language models, knowledge persists across alternations, underlies model performance, one paradigm allows</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>How is knowledge of position-role mappings in natural language learned? We
explore this question in a computational setting, testing whether a variety of
well-performing pertained language models (BERT, RoBERTa, and DistilBERT)
exhibit knowledge of these mappings, and whether this knowledge persists across
alternations in syntactic, structural, and lexical alternations. In Experiment
1, we show that these neural models do indeed recognize distinctions between
theme and recipient roles in ditransitive constructions, and that these
distinct patterns are shared across construction type. We strengthen this
finding in Experiment 2 by showing that fine-tuning these language models on
novel theme- and recipient-like tokens in one paradigm allows the models to
make correct predictions about their placement in other paradigms, suggesting
that the knowledge of these mappings is shared rather than independently
learned. We do, however, observe some limitations of this generalization when
tasks involve constructions with novel ditransitive verbs, hinting at a degree
of lexical specificity which underlies model performance.</p>
  </details>
</details>
<details>
  <summary>14. <b>标题：Approximation Algorithms for ROUND-UFP and ROUND-SAP</b></summary>
  <p><b>编号</b>：[230]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03492</p>
  <p><b>作者</b>：Debajyoti Kar,  Arindam Khan,  Andreas Wiese</p>
  <p><b>备注</b>：26 pages, 5 figures</p>
  <p><b>关键词</b>：asymptotic $( 16 +\ varepsilon )$- approximation algorithms, obtain asymptotic $( 2 +\ varepsilon )$- approximations, $( 1 +\ delta )$- resource augmentation, 1 }{\ delta })$- approximation, log n )$- approximation algorithm</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We study ROUND-UFP and ROUND-SAP, two generalizations of the classical BIN
PACKING problem that correspond to the unsplittable flow problem on a path
(UFP) and the storage allocation problem (SAP), respectively. We are given a
path with capacities on its edges and a set of tasks where for each task we are
given a demand and a subpath. In ROUND-UFP, the goal is to find a packing of
all tasks into a minimum number of copies (rounds) of the given path such that
for each copy, the total demand of tasks on any edge does not exceed the
capacity of the respective edge. In ROUND-SAP, the tasks are considered to be
rectangles and the goal is to find a non-overlapping packing of these
rectangles into a minimum number of rounds such that all rectangles lie
completely below the capacity profile of the edges.
We show that in contrast to BIN PACKING, both the problems do not admit an
asymptotic polynomial-time approximation scheme (APTAS), even when all edge
capacities are equal. However, for this setting, we obtain asymptotic
$(2+\varepsilon)$-approximations for both problems. For the general case, we
obtain an $O(\log\log n)$-approximation algorithm and an
$O(\log\log\frac{1}{\delta})$-approximation under $(1+\delta)$-resource
augmentation for both problems. For the intermediate setting of the no
bottleneck assumption (i.e., the maximum task demand is at most the minimum
edge capacity), we obtain absolute $12$- and asymptotic
$(16+\varepsilon)$-approximation algorithms for ROUND-UFP and ROUND-SAP,
respectively.</p>
  </details>
</details>
<details>
  <summary>15. <b>标题：Universal Spam Detection using Transfer Learning of BERT Model</b></summary>
  <p><b>编号</b>：[238]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03480</p>
  <p><b>作者</b>：Vijay Srinivas Tida,  Sonya Hsu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：novel universal spam detection model using pre, deep learning transformer models become important, overall accuracy reached 97 %,, universal spam detection model, spamtext message classification datasets</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep learning transformer models become important by training on text data
based on self-attention mechanisms. This manuscript demonstrated a novel
universal spam detection model using pre-trained Google's Bidirectional Encoder
Representations from Transformers (BERT) base uncased models with four datasets
by efficiently classifying ham or spam emails in real-time scenarios. Different
methods for Enron, Spamassain, Lingspam, and Spamtext message classification
datasets, were used to train models individually in which a single model was
obtained with acceptable performance on four datasets. The Universal Spam
Detection Model (USDM) was trained with four datasets and leveraged
hyperparameters from each model. The combined model was finetuned with the same
hyperparameters from these four models separately. When each model using its
corresponding dataset, an F1-score is at and above 0.9 in individual models. An
overall accuracy reached 97%, with an F1 score of 0.96. Research results and
implications were discussed.</p>
  </details>
</details>
<details>
  <summary>16. <b>标题：Selecting Seed Words for Wordle using Character Statistics</b></summary>
  <p><b>编号</b>：[246]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03457</p>
  <p><b>作者</b>：Nisansa de Silva</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：letter english word within six tries, study uses character statistics, word guessing game rose, best three starting words, best starting word</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Wordle, a word guessing game rose to global popularity in the January of
2022. The goal of the game is to guess a five-letter English word within six
tries. Each try provides the player with hints by means of colour changing
tiles which inform whether or not a given character is part of the solution as
well as, in cases where it is part of the solution, whether or not it is in the
correct placement. Numerous attempts have been made to find the best starting
word and best strategy to solve the daily wordle. This study uses character
statistics of five-letter words to determine the best three starting words.</p>
  </details>
</details>
<details>
  <summary>17. <b>标题：Self-Supervised Representation Learning for Speech Using Visual  Grounding and Masked Language Modeling</b></summary>
  <p><b>编号</b>：[289]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03543</p>
  <p><b>作者</b>：Puyuan Peng,  David Harwath</p>
  <p><b>备注</b>：SAS workshop at AAAI2022</p>
  <p><b>关键词</b>：models also achieve strong performance, masked language modeling objective, associate raw speech waveforms, models perform competitively, visual grounding objective</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we describe our submissions to the ZeroSpeech 2021 Challenge
and SUPERB benchmark. Our submissions are based on the recently proposed
FaST-VGS model, which is a Transformer-based model that learns to associate raw
speech waveforms with semantically related images, all without the use of any
transcriptions of the speech. Additionally, we introduce a novel extension of
this model, FaST-VGS+, which is learned in a multi-task fashion with a masked
language modeling objective in addition to the visual grounding objective. On
ZeroSpeech 2021, we show that our models perform competitively on the ABX task,
outperform all other concurrent submissions on the Syntactic and Semantic
tasks, and nearly match the best system on the Lexical task. On the SUPERB
benchmark, we show that our models also achieve strong performance, in some
cases even outperforming the popular wav2vec2.0 model.</p>
  </details>
</details>
<h1>机器学习</h1>
<details>
  <summary>1. <b>标题：Time Series Anomaly Detection by Cumulative Radon Features</b></summary>
  <p><b>编号</b>：[1]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.04067</p>
  <p><b>作者</b>：Yedid Hoshen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：normal training set therefore requires efficiently measuring, time series using cumulative radon features, often using deep neural networks, detecting anomalous time series, high dimensional empirical distribution</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Detecting anomalous time series is key for scientific, medical and industrial
tasks, but is challenging due to its inherent unsupervised nature. In recent
years, progress has been made on this task by learning increasingly more
complex features, often using deep neural networks. In this work, we argue that
shallow features suffice when combined with distribution distance measures. Our
approach models each time series as a high dimensional empirical distribution
of features, where each time-point constitutes a single sample. Modeling the
distance between a test time series and the normal training set therefore
requires efficiently measuring the distance between multivariate probability
distributions. We show that by parameterizing each time series using cumulative
Radon features, we are able to efficiently and effectively model the
distribution of normal time series. Our theoretically grounded but
simple-to-implement approach is evaluated on multiple datasets and shown to
achieve better results than established, classical methods as well as complex,
state-of-the-art deep learning methods. Code is provided.</p>
  </details>
</details>
<details>
  <summary>2. <b>标题：PrivFair: a Library for Privacy-Preserving Fairness Auditing</b></summary>
  <p><b>编号</b>：[3]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.04058</p>
  <p><b>作者</b>：Sikha Pentyala,  David Melanson,  Martine De Cock,  Golnoosh Farnadi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：audited using sensitive audit data, sensitive user characteristics, secure multiparty computation, proprietary classifier owned, directly affect people</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Machine learning (ML) has become prominent in applications that directly
affect people's quality of life, including in healthcare, justice, and finance.
ML models have been found to exhibit discrimination based on sensitive
attributes such as gender, race, or disability. Assessing if an ML model is
free of bias remains challenging to date, and by definition has to be done with
sensitive user characteristics that are subject of anti-discrimination and data
protection law. Existing libraries for fairness auditing of ML models offer no
mechanism to protect the privacy of the audit data. We present PrivFair, a
library for privacy-preserving fairness audits of ML models. Through the use of
Secure Multiparty Computation (MPC), \textsc{PrivFair} protects the
confidentiality of the model under audit and the sensitive data used for the
audit, hence it supports scenarios in which a proprietary classifier owned by a
company is audited using sensitive audit data from an external investigator. We
demonstrate the use of PrivFair for group fairness auditing with tabular data
or image data, without requiring the investigator to disclose their data to
anyone in an unencrypted manner, or the model owner to reveal their model
parameters to anyone in plaintext.</p>
  </details>
</details>
<details>
  <summary>3. <b>标题：Decision boundaries and convex hulls in the feature space that deep  learning functions learn from images</b></summary>
  <p><b>编号</b>：[5]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.04052</p>
  <p><b>作者</b>：Roozbeh Yousefzadeh</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：significantly different compared, last hidden layer, identify regions guaranteed, deep neural networks, dimensional space based</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The success of deep neural networks in image classification and learning can
be partly attributed to the features they extract from images. It is often
speculated about the properties of a low-dimensional manifold that models
extract and learn from images. However, there is not sufficient understanding
about this low-dimensional space based on theory or empirical evidence. For
image classification models, their last hidden layer is the one where images of
each class is separated from other classes and it also has the least number of
features. Here, we develop methods and formulations to study that feature space
for any model. We study the partitioning of the domain in feature space,
identify regions guaranteed to have certain classifications, and investigate
its implications for the pixel space. We observe that geometric arrangements of
decision boundaries in feature space is significantly different compared to
pixel space, providing insights about adversarial vulnerabilities, image
morphing, extrapolation, ambiguity in classification, and the mathematical
understanding of image classification models.</p>
  </details>
</details>
<details>
  <summary>4. <b>标题：Towards automated Capability Assessment leveraging Deep Learning</b></summary>
  <p><b>编号</b>：[6]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.04051</p>
  <p><b>作者</b>：Raoul Schönhof,  Manuel Fechter</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：production relevant geometries features, questionnaire based evaluation scheme, assessment using voxelization techniques, single engineer performing, results strongly depend</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Aiming for a higher economic efficiency in manufacturing, an increased degree
of automation is a key enabler. However, assessing the technical feasibility of
an automated assembly solution for a dedicated process is difficult and often
determined by the geometry of the given product parts. Among others, decisive
criterions of the automation feasibility are the ability to separate and
isolate single parts or the capability of component self-alignment in final
position. To assess the feasibility, a questionnaire based evaluation scheme
has been developed and applied by Fraunhofer researchers. However, the results
strongly depend on the implicit knowledge and experience of the single engineer
performing the assessment. This paper presents NeuroCAD, a software tool that
automates the assessment using voxelization techniques. The approach enables
the assessment of abstract and production relevant geometries features through
deep-learning based on CAD files.</p>
  </details>
</details>
<details>
  <summary>5. <b>标题：Physics-informed neural networks for solving parametric magnetostatic  problems</b></summary>
  <p><b>编号</b>：[11]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.04041</p>
  <p><b>作者</b>：Andrés Beltrán-Pulido,  Ilias Bilionis,  Dionysios Aliprantis</p>
  <p><b>备注</b>：77 pages, 12 figures</p>
  <p><b>关键词</b>：magnetic devices becomes intractable using current computational methods, residual connections always improve relative errors, conduct systematic numerical studies using, sufficiently parameterized dense networks result, one hundred different possibilities</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The optimal design of magnetic devices becomes intractable using current
computational methods when the number of design parameters is high. The
emerging physics-informed deep learning framework has the potential to
alleviate this curse of dimensionality. The objective of this paper is to
investigate the ability of physics-informed neural networks to learn the
magnetic field response as a function of design parameters in the context of a
two-dimensional (2-D) magnetostatic problem. Our approach is as follows. We
derive the variational principle for 2-D parametric magnetostatic problems, and
prove the existence and uniqueness of the solution that satisfies the equations
of the governing physics, i.e., Maxwell's equations. We use a deep neural
network (DNN) to represent the magnetic field as a function of space and a
total of ten parameters that describe geometric features and operating point
conditions. We train the DNN by minimizing the physics-informed loss function
using a variant of stochastic gradient descent. Subsequently, we conduct
systematic numerical studies using a parametric EI-core electromagnet problem.
In these studies, we vary the DNN architecture trying more than one hundred
different possibilities. For each study, we evaluate the accuracy of the DNN by
comparing its predictions to those of finite element analysis. In an exhaustive
non-parametric study, we observe that sufficiently parameterized dense networks
result in relative errors of less than 1%. Residual connections always improve
relative errors for the same number of training iterations. Also, we observe
that Fourier encoding features aligned with the device geometry do improve the
rate of convergence, albeit higher-order harmonics are not necessary. Finally,
we demonstrate our approach on a ten-dimensional problem with parameterized
geometry.</p>
  </details>
</details>
<details>
  <summary>6. <b>标题：Self-Conditioned Generative Adversarial Networks for Image Editing</b></summary>
  <p><b>编号</b>：[12]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.04040</p>
  <p><b>作者</b>：Yunzhe Liu,  Rinon Gal,  Amit H. Bermano,  Baoquan Chen,  Daniel Cohen-Or</p>
  <p><b>备注</b>：Project page: this https URL</p>
  <p><b>关键词</b>：achieve finer semantic control, rare semantic attributes, traversal editing methods, provide initial labels, generative adversarial networks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Generative Adversarial Networks (GANs) are susceptible to bias, learned from
either the unbalanced data, or through mode collapse. The networks focus on the
core of the data distribution, leaving the tails - or the edges of the
distribution - behind. We argue that this bias is responsible not only for
fairness concerns, but that it plays a key role in the collapse of
latent-traversal editing methods when deviating away from the distribution's
core. Building on this observation, we outline a method for mitigating
generative bias through a self-conditioning process, where distances in the
latent-space of a pre-trained generator are used to provide initial labels for
the data. By fine-tuning the generator on a re-sampled distribution drawn from
these self-labeled data, we force the generator to better contend with rare
semantic attributes and enable more realistic generation of these properties.
We compare our models to a wide range of latent editing methods, and show that
by alleviating the bias they achieve finer semantic control and better identity
preservation through a wider range of transformations. Our code and models will
be available at this https URL</p>
  </details>
</details>
<details>
  <summary>7. <b>标题：Results and findings of the 2021 Image Similarity Challenge</b></summary>
  <p><b>编号</b>：[20]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.04007</p>
  <p><b>作者</b>：Zoë Papakipos,  Giorgos Tolias,  Tomas Jenicek,  Ed Pizzi,  Shuhei Yokoo,  Wenhao Wang,  Yifan Sun,  Weipu Zhang,  Yi Yang,  Sanjay Addicam,  Sergio Manuel Papadakis,  Cristian Canton Ferrer,  Ondrej Chum,  Matthijs Douze</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：difficult image transformations involve either severe image crops, evaluate recent image copy detection methods, 2021 image similarity challenge introduced, global descriptor matching followed, pairwise image comparison</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The 2021 Image Similarity Challenge introduced a dataset to serve as a new
benchmark to evaluate recent image copy detection methods. There were 200
participants to the competition. This paper presents a quantitative and
qualitative analysis of the top submissions. It appears that the most difficult
image transformations involve either severe image crops or hiding into
unrelated images, combined with local pixel perturbations. The key algorithmic
elements in the winning submissions are: training on strong augmentations,
self-supervised learning, score normalization, explicit overlay detection, and
global descriptor matching followed by pairwise image comparison.</p>
  </details>
</details>
<details>
  <summary>8. <b>标题：Improved Convergence Rates for Sparse Approximation Methods in  Kernel-Based Learning</b></summary>
  <p><b>编号</b>：[22]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.04005</p>
  <p><b>作者</b>：Sattar Vakili,  Jonathan Scarlett,  Da-shan Shiu,  Alberto Bernacchia</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：sparse variational gaussian processes approximation method, confidence intervals using novel interpretations, provide novel confidence intervals, existing sparse approximation methods, confidence intervals lead</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Kernel-based models such as kernel ridge regression and Gaussian processes
are ubiquitous in machine learning applications for regression and
optimization. It is well known that a serious downside for kernel-based models
is the high computational cost; given a dataset of $n$ samples, the cost grows
as $\mathcal{O}(n^3)$. Existing sparse approximation methods can yield a
significant reduction in the computational cost, effectively reducing the real
world cost down to as low as $\mathcal{O}(n)$ in certain cases. Despite this
remarkable empirical success, significant gaps remain in the existing results
for the analytical confidence bounds on the error due to approximation. In this
work, we provide novel confidence intervals for the Nyström method and the
sparse variational Gaussian processes approximation method. Our confidence
intervals lead to improved error bounds in both regression and optimization. We
establish these confidence intervals using novel interpretations of the
approximate (surrogate) posterior variance of the models.</p>
  </details>
</details>
<details>
  <summary>9. <b>标题：Learning Sinkhorn divergences for supervised change point detection</b></summary>
  <p><b>编号</b>：[24]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.04000</p>
  <p><b>作者</b>：Nauman Ahad,  Eva L. Dyer,  Keith B. Hengen,  Yao Xie,  Mark A. Davenport</p>
  <p><b>备注</b>：19 pages, 13 figures</p>
  <p><b>关键词</b>：many modern applications require detecting change points, existing unsupervised change point detection methods using, substantially improve change point detection performance, novel change point detection framework, dimensional change point detection settings</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Many modern applications require detecting change points in complex
sequential data. Most existing methods for change point detection are
unsupervised and, as a consequence, lack any information regarding what kind of
changes we want to detect or if some kinds of changes are safe to ignore. This
often results in poor change detection performance. We present a novel change
point detection framework that uses true change point instances as supervision
for learning a ground metric such that Sinkhorn divergences can be then used in
two-sample tests on sliding windows to detect change points in an online
manner. Our method can be used to learn a sparse metric which can be useful for
both feature selection and interpretation in high-dimensional change point
detection settings. Experiments on simulated as well as real world sequences
show that our proposed method can substantially improve change point detection
performance over existing unsupervised change point detection methods using
only few labeled change point instances.</p>
  </details>
</details>
<details>
  <summary>10. <b>标题：Equivariance versus Augmentation for Spherical Images</b></summary>
  <p><b>编号</b>：[27]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03990</p>
  <p><b>作者</b>：Jan E. Gerken,  Oscar Carlsson,  Hampus Linander,  Fredrik Ohlsson,  Christoffer Petersson,  Daniel Persson</p>
  <p><b>备注</b>：19 pages of which 8 in main body, 16 figures</p>
  <p><b>关键词</b>：fashionmnist dataset projected onto, enabling detailed tradeoff considerations, group equivariant networks known, equivariant spherical networks used, significantly fewer parameters</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We analyze the role of rotational equivariance in convolutional neural
networks (CNNs) applied to spherical images. We compare the performance of the
group equivariant networks known as S2CNNs and standard non-equivariant CNNs
trained with an increasing amount of data augmentation. The chosen
architectures can be considered baseline references for the respective design
paradigms. Our models are trained and evaluated on single or multiple items
from the MNIST or FashionMNIST dataset projected onto the sphere. For the task
of image classification, which is inherently rotationally invariant, we find
that by considerably increasing the amount of data augmentation and the size of
the networks, it is possible for the standard CNNs to reach at least the same
performance as the equivariant network. In contrast, for the inherently
equivariant task of semantic segmentation, the non-equivariant networks are
consistently outperformed by the equivariant networks with significantly fewer
parameters. We also analyze and compare the inference latency and training
times of the different networks, enabling detailed tradeoff considerations
between equivariant architectures and data augmentation for practical problems.
The equivariant spherical networks used in the experiments will be made
available at this https URL .</p>
  </details>
</details>
<details>
  <summary>11. <b>标题：Data Consistency for Weakly Supervised Learning</b></summary>
  <p><b>编号</b>：[29]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03987</p>
  <p><b>作者</b>：Chidubem Arachie,  Bert Huang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：training machine learning models involves using large amounts, paradigm data consistent weak supervision, novel weak supervision algorithm, art weak supervision methods, enforces data consistency among</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In many applications, training machine learning models involves using large
amounts of human-annotated data. Obtaining precise labels for the data is
expensive. Instead, training with weak supervision provides a low-cost
alternative. We propose a novel weak supervision algorithm that processes noisy
labels, i.e., weak signals, while also considering features of the training
data to produce accurate labels for training. Our method searches over
classifiers of the data representation to find plausible labelings. We call
this paradigm data consistent weak supervision. A key facet of our framework is
that we are able to estimate labels for data examples low or no coverage from
the weak supervision. In addition, we make no assumptions about the joint
distribution of the weak signals and true labels of the data. Instead, we use
weak signals and the data features to solve a constrained optimization that
enforces data consistency among the labels we generate. Empirical evaluation of
our method on different datasets shows that it significantly outperforms
state-of-the-art weak supervision methods on both text and image classification
tasks.</p>
  </details>
</details>
<details>
  <summary>12. <b>标题：CAUSPref: Causal Preference Learning for Out-of-Distribution  Recommendation</b></summary>
  <p><b>编号</b>：[31]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03984</p>
  <p><b>作者</b>：Yue He,  Zimu Wang,  Peng Cui,  Hao Zou,  Yafeng Zhang,  Qiang Cui,  Yong Jiang</p>
  <p><b>备注</b>：WWW '22: The ACM Web Conference Proceedings</p>
  <p><b>关键词</b>：based recommendation framework named causpref, world datasets clearly demonstrate, specific dag learner, recommender system owing, preference negative sampling</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In spite of the tremendous development of recommender system owing to the
progressive capability of machine learning recently, the current recommender
system is still vulnerable to the distribution shift of users and items in
realistic scenarios, leading to the sharp decline of performance in testing
environments. It is even more severe in many common applications where only the
implicit feedback from sparse data is available. Hence, it is crucial to
promote the performance stability of recommendation method in different
environments. In this work, we first make a thorough analysis of implicit
recommendation problem from the viewpoint of out-of-distribution (OOD)
generalization. Then under the guidance of our theoretical analysis, we propose
to incorporate the recommendation-specific DAG learner into a novel causal
preference-based recommendation framework named CAUSPref, mainly consisting of
causal learning of invariant user preference and anti-preference negative
sampling to deal with implicit feedback. Extensive experimental results from
real-world datasets clearly demonstrate that our approach surpasses the
benchmark models significantly under types of out-of-distribution settings, and
show its impressive interpretability.</p>
  </details>
</details>
<details>
  <summary>13. <b>标题：Provable Reinforcement Learning with a Short-Term Memory</b></summary>
  <p><b>编号</b>：[32]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03983</p>
  <p><b>作者</b>：Yonathan Efroni,  Chi Jin,  Akshay Krishnamurthy,  Sobhan Miryoosefi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：world sequential decision making problems commonly involve partial observability, learning partially observable markov decision processes, commonly used technique known, develop new algorithms using, partial observability</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Real-world sequential decision making problems commonly involve partial
observability, which requires the agent to maintain a memory of history in
order to infer the latent states, plan and make good decisions. Coping with
partial observability in general is extremely challenging, as a number of
worst-case statistical and computational barriers are known in learning
Partially Observable Markov Decision Processes (POMDPs). Motivated by the
problem structure in several physical applications, as well as a commonly used
technique known as "frame stacking", this paper proposes to study a new
subclass of POMDPs, whose latent states can be decoded by the most recent
history of a short length $m$. We establish a set of upper and lower bounds on
the sample complexity for learning near-optimal policies for this class of
problems in both tabular and rich-observation settings (where the number of
observations is enormous). In particular, in the rich-observation setting, we
develop new algorithms using a novel "moment matching" approach with a sample
complexity that scales exponentially with the short length $m$ rather than the
problem horizon, and is independent of the number of observations. Our results
show that a short-term memory suffices for reinforcement learning in these
environments.</p>
  </details>
</details>
<details>
  <summary>14. <b>标题：Transferable Student Performance Modeling for Intelligent Tutoring  Systems</b></summary>
  <p><b>编号</b>：[33]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03980</p>
  <p><b>作者</b>：Robin Schmucker,  Tom M. Mitchell</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：limited student interaction training data (< 100 students, proposed techniques using student interaction sequence data, 5 different mathematics courses containing data, trained using interaction sequence data, student interaction training data</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Millions of learners worldwide are now using intelligent tutoring systems
(ITSs). At their core, ITSs rely on machine learning algorithms to track each
user's changing performance level over time to provide personalized
instruction. Crucially, student performance models are trained using
interaction sequence data of previous learners to analyse data generated by
future learners. This induces a cold-start problem when a new course is
introduced for which no training data is available. Here, we consider transfer
learning techniques as a way to provide accurate performance predictions for
new courses by leveraging log data from existing courses. We study two
settings: (i) In the naive transfer setting, we propose course-agnostic
performance models that can be applied to any course. (ii) In the inductive
transfer setting, we tune pre-trained course-agnostic performance models to new
courses using small-scale target course data (e.g., collected during a pilot
study). We evaluate the proposed techniques using student interaction sequence
data from 5 different mathematics courses containing data from over 47,000
students in a real world large-scale ITS. The course-agnostic models that use
additional features provided by human domain experts (e.g, difficulty ratings
for questions in the new course) but no student interaction training data for
the new course, achieve prediction accuracy on par with standard BKT and PFA
models that use training data from thousands of students in the new course. In
the inductive setting our transfer learning approach yields more accurate
predictions than conventional performance models when only limited student
interaction training data (<100 students) is available to both.< p>
  </100></p></details>
</details>
<details>
  <summary>15. <b>标题：Rainbow Differential Privacy</b></summary>
  <p><b>编号</b>：[37]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03974</p>
  <p><b>作者</b>：Ziqi Zhou,  Onur Günlü,  Rafael G. L. D'Oliveira,  Muriel Médard,  Parastoo Sadeghi,  Rafael F. Schaefer</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：mechanisms via randomized graph colorings, paper displays enough richness, show closed form expressions, dimensional query spaces, designing differentially private</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We extend a previous framework for designing differentially private (DP)
mechanisms via randomized graph colorings that was restricted to binary
functions, corresponding to colorings in a graph, to multi-valued functions. As
before, datasets are nodes in the graph and any two neighboring datasets are
connected by an edge. In our setting, we assume each dataset has a preferential
ordering for the possible outputs of the mechanism, which we refer to as a
rainbow. Different rainbows partition the graph of datasets into different
regions. We show that when the DP mechanism is pre-specified at the boundary of
such regions, at most one optimal mechanism can exist. Moreover, if the
mechanism is to behave identically for all same-rainbow boundary datasets, the
problem can be greatly simplified and solved by means of a morphism to a line
graph. We then show closed form expressions for the line graph in the case of
ternary functions. Treatment of ternary queries in this paper displays enough
richness to be extended to higher-dimensional query spaces with preferential
query ordering, but the optimality proof does not seem to follow directly from
the ternary proof.</p>
  </details>
</details>
<details>
  <summary>16. <b>标题：Improving the Sample-Complexity of Deep Classification Networks with  Invariant Integration</b></summary>
  <p><b>编号</b>：[41]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03967</p>
  <p><b>作者</b>：Matthias Rath,  Alexandru Paul Condurache</p>
  <p><b>备注</b>：Accepted at VISAPP 2022</p>
  <p><b>关键词</b>：equivariant convolutional neural network using pooling, iterative approach requiring expensive pre, novel monomial selection algorithm based, art results using full data, previous work investigated replacing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Leveraging prior knowledge on intraclass variance due to transformations is a
powerful method to improve the sample complexity of deep neural networks. This
makes them applicable to practically important use-cases where training data is
scarce. Rather than being learned, this knowledge can be embedded by enforcing
invariance to those transformations. Invariance can be imposed using
group-equivariant convolutions followed by a pooling operation.
For rotation-invariance, previous work investigated replacing the spatial
pooling operation with invariant integration which explicitly constructs
invariant representations. Invariant integration uses monomials which are
selected using an iterative approach requiring expensive pre-training. We
propose a novel monomial selection algorithm based on pruning methods to allow
an application to more complex problems. Additionally, we replace monomials
with different functions such as weighted sums, multi-layer perceptrons and
self-attention, thereby streamlining the training of
invariant-integration-based architectures.
We demonstrate the improved sample complexity on the Rotated-MNIST, SVHN and
CIFAR-10 datasets where rotation-invariant-integration-based Wide-ResNet
architectures using monomials and weighted sums outperform the respective
baselines in the limited sample regime. We achieve state-of-the-art results
using full data on Rotated-MNIST and SVHN where rotation is a main source of
intraclass variation. On STL-10 we outperform a standard and a
rotation-equivariant convolutional neural network using pooling.</p>
  </details>
</details>
<details>
  <summary>17. <b>标题：Uncertainty Modeling for Out-of-Distribution Generalization</b></summary>
  <p><b>编号</b>：[44]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03958</p>
  <p><b>作者</b>：Xiaotong Li,  Yongxing Dai,  Yixiao Ge,  Jun Liu,  Ying Shan,  Ling-Yu Duan</p>
  <p><b>备注</b>：Accepted by ICLR 2022</p>
  <p><b>关键词</b>：deep neural networks still suffer obvious performance degradation, networks without additional parameters, common methods often consider, proposed method consistently improves, uncertain statistics discrepancy caused</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Though remarkable progress has been achieved in various vision tasks, deep
neural networks still suffer obvious performance degradation when tested in
out-of-distribution scenarios. We argue that the feature statistics (mean and
standard deviation), which carry the domain characteristics of the training
data, can be properly manipulated to improve the generalization ability of deep
learning models. Common methods often consider the feature statistics as
deterministic values measured from the learned features and do not explicitly
consider the uncertain statistics discrepancy caused by potential domain shifts
during testing. In this paper, we improve the network generalization ability by
modeling the uncertainty of domain shifts with synthesized feature statistics
during training. Specifically, we hypothesize that the feature statistic, after
considering the potential uncertainties, follows a multivariate Gaussian
distribution. Hence, each feature statistic is no longer a deterministic value,
but a probabilistic point with diverse distribution possibilities. With the
uncertain feature statistics, the models can be trained to alleviate the domain
perturbations and achieve better robustness against potential domain shifts.
Our method can be readily integrated into networks without additional
parameters. Extensive experiments demonstrate that our proposed method
consistently improves the network generalization ability on multiple vision
tasks, including image classification, semantic segmentation, and instance
retrieval. The code will be released soon at
this https URL.</p>
  </details>
</details>
<details>
  <summary>18. <b>标题：Bingham Policy Parameterization for 3D Rotations in Reinforcement  Learning</b></summary>
  <p><b>编号</b>：[45]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03957</p>
  <p><b>作者</b>：Stephen James,  Pieter Abbeel</p>
  <p><b>备注</b>：Project page and code: this https URL</p>
  <p><b>关键词</b>：best pose robot manipulation tasks, continuous control reinforcement learning literature, full 6d pose output, many stochastic policy parameterizations, rotation wahba problem task</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose a new policy parameterization for representing 3D rotations during
reinforcement learning. Today in the continuous control reinforcement learning
literature, many stochastic policy parameterizations are Gaussian. We argue
that universally applying a Gaussian policy parameterization is not always
desirable for all environments. One such case in particular where this is true
are tasks that involve predicting a 3D rotation output, either in isolation, or
coupled with translation as part of a full 6D pose output. Our proposed Bingham
Policy Parameterization (BPP) models the Bingham distribution and allows for
better rotation (quaternion) prediction over a Gaussian policy parameterization
in a range of reinforcement learning tasks. We evaluate BPP on the rotation
Wahba problem task, as well as a set of vision-based next-best pose robot
manipulation tasks from RLBench. We hope that this paper encourages more
research into developing other policy parameterization that are more suited for
particular environments, rather than always assuming Gaussian.</p>
  </details>
</details>
<details>
  <summary>19. <b>标题：From Generalisation Error to Transportation-cost Inequalities and Back</b></summary>
  <p><b>编号</b>：[46]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03956</p>
  <p><b>作者</b>：Amedeo Roberto Esposito,  Michael Gastpar</p>
  <p><b>备注</b>：Submitted to ISIT 2022</p>
  <p><b>关键词</b>：standard generalisation error bounds involving mutual information, involve arbitrary divergence measures, expected generalisation error, one involving measures, one involving functionals</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this work, we connect the problem of bounding the expected generalisation
error with transportation-cost inequalities. Exposing the underlying pattern
behind both approaches we are able to generalise them and go beyond
Kullback-Leibler Divergences/Mutual Information and sub-Gaussian measures. In
particular, we are able to provide a result showing the equivalence between two
families of inequalities: one involving functionals and one involving measures.
This result generalises the one proposed by Bobkov and Götze that connects
transportation-cost inequalities with concentration of measure. Moreover, it
allows us to recover all standard generalisation error bounds involving mutual
information and to introduce new, more general bounds, that involve arbitrary
divergence measures.</p>
  </details>
</details>
<details>
  <summary>20. <b>标题：Systematically improving existing k-means initialization algorithms at  nearly no cost, by pairwise-nearest-neighbor smoothing</b></summary>
  <p><b>编号</b>：[50]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03949</p>
  <p><b>作者</b>：Carlo Baldassi</p>
  <p><b>备注</b>：10 pages (+10 appendix), 2 figures (+1 appendix), 3 tables (+11 appendix)</p>
  <p><b>关键词</b>：k $- means clustering algorithm called pnn, using several existing seeding methods, k $, pnn, systematically better costs, also almost linear</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present a meta-method for initializing (seeding) the $k$-means clustering
algorithm called PNN-smoothing. It consists in splitting a given dataset into
$J$ random subsets, clustering each of them individually, and merging the
resulting clusterings with the pairwise-nearest-neighbor (PNN) method. It is a
meta-method in the sense that when clustering the individual subsets any
seeding algorithm can be used. If the computational complexity of that seeding
algorithm is linear in the size of the data $N$ and the number of clusters $k$,
PNN-smoothing is also almost linear with an appropriate choice of $J$, and in
fact only at most a few percent slower in most cases in practice. We show
empirically, using several existing seeding methods and testing on several
synthetic and real datasets, that this procedure results in systematically
better costs. It can even be applied recursively, and easily parallelized. Our
implementation is publicly available at
this https URL</p>
  </details>
</details>
<details>
  <summary>21. <b>标题：Detecting Anomalies within Time Series using Local Neural  Transformations</b></summary>
  <p><b>编号</b>：[52]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03944</p>
  <p><b>作者</b>：Tim Schneider,  Chen Qiu,  Marius Kloft,  Decky Aspandi Latif,  Steffen Staab,  Stephan Mandt,  Maja Rudolph</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：detect anomalies within time series, detect anomalies within time series, facilitating deep anomaly detection, learned transformations gives insight, previous deep anomaly detection</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We develop a new method to detect anomalies within time series, which is
essential in many application domains, reaching from self-driving cars,
finance, and marketing to medical diagnosis and epidemiology. The method is
based on self-supervised deep learning that has played a key role in
facilitating deep anomaly detection on images, where powerful image
transformations are available. However, such transformations are widely
unavailable for time series. Addressing this, we develop Local Neural
Transformations(LNT), a method learning local transformations of time series
from data. The method produces an anomaly score for each time step and thus can
be used to detect anomalies within time series. We prove in a theoretical
analysis that our novel training objective is more suitable for transformation
learning than previous deep Anomaly detection(AD) methods. Our experiments
demonstrate that LNT can find anomalies in speech segments from the LibriSpeech
data set and better detect interruptions to cyber-physical systems than
previous work. Visualization of the learned transformations gives insight into
the type of transformations that LNT learns.</p>
  </details>
</details>
<details>
  <summary>22. <b>标题：Accelerometer-based Bed Occupancy Detection for Automatic, Non-invasive  Long-term Cough Monitoring</b></summary>
  <p><b>编号</b>：[54]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03936</p>
  <p><b>作者</b>：Madhurananda Pahar,  Igor Miranda,  Andreas Diacon,  Thomas Niesler</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：term cough monitoring requires bed occupancy detection, seven adult male patients undergoing treatment, also calculated colony forming unit, bed occupancy detection process consists, predict daily cough rates</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present a machine learning based long-term cough monitoring system by
detecting patient's bed occupancy from a bed-attached smartphone-inbuilt
accelerometer automatically. Previously this system was used to detect cough
events successfully and long-term cough monitoring requires bed occupancy
detection, as the initial experiments show that patients leave their bed very
often for long period of time and using video-monitoring or pressure sensors
are not patient-favourite alternatives. We have compiled a 249-hour dataset of
manually-labelled acceleration signals gathered from seven adult male patients
undergoing treatment for tuberculosis (TB). The bed occupancy detection process
consists of three detectors, among which the first one classifies
occupancy-change with high sensitivity, low specificity and the second one
classifies occupancy-interval with high specificity, low sensitivity. The final
state detector corrects the miss-classified sections. After using a
leave-one-patient-out cross-validation scheme to train and evaluate four
classifiers such as LR, MLP, CNN and LSTM; LSTM produces the highest area under
the curve (AUC) of 0.94 while comparing the predicted bed occupancy as the
output from the final state detector with the actual bed occupancy sample by
sample. We have also calculated colony forming unit and time to positivity of
the sputum samples of TB positive patients who were monitored for 14 days and
the proposed system was used to predict daily cough rates. The results show
that patients who improve under TB treatment have decreasing daily cough rates,
indicating the proposed automatic, quick, non-invasive, non-intrusive,
cost-effective long-term cough monitoring system can be extremely useful in
monitoring patients' recovery rate.</p>
  </details>
</details>
<details>
  <summary>23. <b>标题：Robustness Verification for Attention Networks using Mixed Integer  Programming</b></summary>
  <p><b>编号</b>：[57]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03932</p>
  <p><b>作者</b>：Hsuan-Cheng Liao,  Chih-Hong Cheng,  Maximilian Kneissl,  Alois Knoll</p>
  <p><b>备注</b>：Submitted to IROS 2022</p>
  <p><b>关键词</b>：although attention networks typically deliver higher accuracy, attention networks containing linearized layer normalization, layer perceptron surprisingly shows, mixed integer programming problem, general neural networks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Attention networks such as transformers have been shown powerful in many
applications ranging from natural language processing to object recognition.
This paper further considers their robustness properties from both theoretical
and empirical perspectives. Theoretically, we formulate a variant of attention
networks containing linearized layer normalization and sparsemax activation,
and reduce its robustness verification to a Mixed Integer Programming problem.
Apart from a naïve encoding, we derive tight intervals from admissible
perturbation regions and examine several heuristics to speed up the
verification process. More specifically, we find a novel bounding technique for
sparsemax activation, which is also applicable to softmax activation in general
neural networks. Empirically, we evaluate our proposed techniques with a case
study on lane departure warning and demonstrate a performance gain of
approximately an order of magnitude. Furthermore, although attention networks
typically deliver higher accuracy than general neural networks, contrasting its
robustness against a similar-sized multi-layer perceptron surprisingly shows
that they are not necessarily more robust.</p>
  </details>
</details>
<details>
  <summary>24. <b>标题：Learnings from Federated Learning in the Real world</b></summary>
  <p><b>编号</b>：[59]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03925</p>
  <p><b>作者</b>：Christophe Dupuy,  Tanya G. Roosta,  Leo Long,  Clement Chung,  Rahul Gupta,  Salman Avestimehr</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：large scale nlu system serving thousands, real world data may suffer, uniform device selection based, models trained using fl, data distribution across devices</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Federated Learning (FL) applied to real world data may suffer from several
idiosyncrasies. One such idiosyncrasy is the data distribution across devices.
Data across devices could be distributed such that there are some "heavy
devices" with large amounts of data while there are many "light users" with
only a handful of data points. There also exists heterogeneity of data across
devices. In this study, we evaluate the impact of such idiosyncrasies on
Natural Language Understanding (NLU) models trained using FL. We conduct
experiments on data obtained from a large scale NLU system serving thousands of
devices and show that simple non-uniform device selection based on the number
of interactions at each round of FL training boosts the performance of the
model. This benefit is further amplified in continual FL on consecutive time
periods, where non-uniform sampling manages to swiftly catch up with FL methods
using all data at once.</p>
  </details>
</details>
<details>
  <summary>25. <b>标题：Context-Aware Discrimination Detection in Job Vacancies using  Computational Language Models</b></summary>
  <p><b>编号</b>：[61]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03907</p>
  <p><b>作者</b>：S. Vethman,  A. Adhikari,  M. H. T. de Boer,  J. A. G. M. van Genabeek,  C. J. Veenman</p>
  <p><b>备注</b>：17 pages, 2 figures</p>
  <p><b>关键词</b>：machine learning based computational language models, job vacancies containing potentially discriminating terms, machine learning based methods, detect unforeseen discriminating terms, potentially discriminating terms</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Discriminatory job vacancies are disapproved worldwide, but remain
persistent. Discrimination in job vacancies can be explicit by directly
referring to demographic memberships of candidates. More implicit forms of
discrimination are also present that may not always be illegal but still
influence the diversity of applicants. Explicit written discrimination is still
present in numerous job vacancies, as was recently observed in the Netherlands.
Current efforts for the detection of explicit discrimination concern the
identification of job vacancies containing potentially discriminating terms
such as "young" or "male". However, automatic detection is inefficient due to
low precision: e.g. "we are a young company" or "working with mostly male
patients" are phrases that contain explicit terms, while the context shows that
these do not reflect discriminatory content.
In this paper, we show how machine learning based computational language
models can raise precision in the detection of explicit discrimination by
identifying when the potentially discriminating terms are used in a
discriminatory context. We focus on gender discrimination, which indeed suffers
from low precision when filtering explicit terms. First, we created a data set
for gender discrimination in job vacancies. Second, we investigated a variety
of computational language models for discriminatory context detection. Third,
we evaluated the capability of these models to detect unforeseen discriminating
terms in context. The results show that machine learning based methods can
detect explicit gender discrimination with high precision and help in finding
new forms of discrimination. Accordingly, the proposed methods can
substantially increase the effectiveness of detecting job vacancies which are
highly suspected to be discriminatory. In turn, this may lower the
discrimination experienced at the start of the recruitment process.</p>
  </details>
</details>
<details>
  <summary>26. <b>标题：KENN: Enhancing Deep Neural Networks by Leveraging Knowledge for Time  Series Forecasting</b></summary>
  <p><b>编号</b>：[64]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03903</p>
  <p><b>作者</b>：Muhammad Ali Chattha,  Ludger van Elst,  Muhammad Imran Malik,  Andreas Dengel,  Sheraz Ahmed</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：specifically aims towards combining strengths, driven machine learning methods often, problems like disaster prediction, novel knowledge fusion architecture, knowledge enhanced neural network</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>End-to-end data-driven machine learning methods often have exuberant
requirements in terms of quality and quantity of training data which are often
impractical to fulfill in real-world applications. This is specifically true in
time series domain where problems like disaster prediction, anomaly detection,
and demand prediction often do not have a large amount of historical data.
Moreover, relying purely on past examples for training can be sub-optimal since
in doing so we ignore one very important domain i.e knowledge, which has its
own distinct advantages. In this paper, we propose a novel knowledge fusion
architecture, Knowledge Enhanced Neural Network (KENN), for time series
forecasting that specifically aims towards combining strengths of both
knowledge and data domains while mitigating their individual weaknesses. We
show that KENN not only reduces data dependency of the overall framework but
also improves performance by producing predictions that are better than the
ones produced by purely knowledge and data driven domains. We also compare KENN
with state-of-the-art forecasting methods and show that predictions produced by
KENN are significantly better even when trained on only 50\% of the data.</p>
  </details>
</details>
<details>
  <summary>27. <b>标题：Verification-Aided Deep Ensemble Selection</b></summary>
  <p><b>编号</b>：[67]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03898</p>
  <p><b>作者</b>：Guy Amir,  Guy Katz,  Michael Schapira</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：adversarially perturbed -- resulting, practitioners apply joint classification, work puts forth, stochastic training process, proposed framework uses</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep neural networks (DNNs) have become the technology of choice for
realizing a variety of complex tasks. However, as highlighted by many recent
studies, even an imperceptible perturbation to a correctly classified input can
lead to misclassification by a DNN. This renders DNNs vulnerable to strategic
input manipulations by attackers, and also prone to oversensitivity to
environmental noise.
To mitigate this phenomenon, practitioners apply joint classification by an
ensemble of DNNs. By aggregating the classification outputs of different
individual DNNs for the same input, ensemble-based classification reduces the
risk of misclassifications due to the specific realization of the stochastic
training process of any single DNN. However, the effectiveness of a DNN
ensemble is highly dependent on its members not simultaneously erring on many
different inputs.
In this case study, we harness recent advances in DNN verification to devise
a methodology for identifying ensemble compositions that are less prone to
simultaneous errors, even when the input is adversarially perturbed --
resulting in more robustly-accurate ensemble-based classification.
Our proposed framework uses a DNN verifier as a backend, and includes
heuristics that help reduce the high complexity of directly verifying
ensembles. More broadly, our work puts forth a novel universal objective for
formal verification that can potentially improve the robustness of real-world,
deep-learning-based systems across a variety of application domains.</p>
  </details>
</details>
<details>
  <summary>28. <b>标题：Speech Emotion Recognition using Self-Supervised Features</b></summary>
  <p><b>编号</b>：[68]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03896</p>
  <p><b>作者</b>：Edmilson Morais,  Ron Hoory,  Weizhong Zhu,  Itai Gat,  Matheus Damasceno,  Hagai Aronowitz</p>
  <p><b>备注</b>：5 pages, 4 figures, 2 tables, ICASSP 2022</p>
  <p><b>关键词</b>：experiments investigate interactions among fine, proposed monomodal speechonly based system, sota multimodal systems using, predicting categorical emotion classes, ser system based</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Self-supervised pre-trained features have consistently delivered state-of-art
results in the field of natural language processing (NLP); however, their
merits in the field of speech emotion recognition (SER) still need further
investigation. In this paper we introduce a modular End-to- End (E2E) SER
system based on an Upstream + Downstream architecture paradigm, which allows
easy use/integration of a large variety of self-supervised features. Several
SER experiments for predicting categorical emotion classes from the IEMOCAP
dataset are performed. These experiments investigate interactions among
fine-tuning of self-supervised feature models, aggregation of frame-level
features into utterance-level features and back-end classification networks.
The proposed monomodal speechonly based system not only achieves SOTA results,
but also brings light to the possibility of powerful and well finetuned
self-supervised acoustic features that reach results similar to the results
achieved by SOTA multimodal systems using both Speech and Text modalities.</p>
  </details>
</details>
<details>
  <summary>29. <b>标题：GraphDCA -- a Framework for Node Distribution Comparison in Real and  Synthetic Graphs</b></summary>
  <p><b>编号</b>：[70]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03884</p>
  <p><b>作者</b>：Ciwan Ceylan,  Petra Poklukar,  Hanna Hultin,  Alexander Kravchenko,  Anastasia Varava,  Danica Kragic</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：graphdca satisfyingly captures gradually decreasing similarity, using three node structure feature extractors, evaluate three publicly available real, graphs exhibiting different structural patterns, adequately reproduce local structural features</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We argue that when comparing two graphs, the distribution of node structural
features is more informative than global graph statistics which are often used
in practice, especially to evaluate graph generative models. Thus, we present
GraphDCA - a framework for evaluating similarity between graphs based on the
alignment of their respective node representation sets. The sets are compared
using a recently proposed method for comparing representation spaces, called
Delaunay Component Analysis (DCA), which we extend to graph data. To evaluate
our framework, we generate a benchmark dataset of graphs exhibiting different
structural patterns and show, using three node structure feature extractors,
that GraphDCA recognizes graphs with both similar and dissimilar local
structure. We then apply our framework to evaluate three publicly available
real-world graph datasets and demonstrate, using gradual edge perturbations,
that GraphDCA satisfyingly captures gradually decreasing similarity, unlike
global statistics. Finally, we use GraphDCA to evaluate two state-of-the-art
graph generative models, NetGAN and CELL, and conclude that further
improvements are needed for these models to adequately reproduce local
structural features.</p>
  </details>
</details>
<details>
  <summary>30. <b>标题：Robust Hybrid Learning With Expert Augmentation</b></summary>
  <p><b>编号</b>：[71]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03881</p>
  <p><b>作者</b>：Antoine Wehenkel,  Jens Behrmann,  Hsiang Hsu,  Guillermo Sapiro,  Gilles Louppe and,  Jörn-Henrik Jacobsen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：hybrid data augmentation strategy termed, usually valid even outside, modelling dynamical systems described, expert augmentation improves generalization, hybrid model performance guarantees</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Hybrid modelling reduces the misspecification of expert models by combining
them with machine learning (ML) components learned from data. Like for many ML
algorithms, hybrid model performance guarantees are limited to the training
distribution. Leveraging the insight that the expert model is usually valid
even outside the training domain, we overcome this limitation by introducing a
hybrid data augmentation strategy termed \textit{expert augmentation}. Based on
a probabilistic formalization of hybrid modelling, we show why expert
augmentation improves generalization. Finally, we validate the practical
benefits of augmented hybrid models on a set of controlled experiments,
modelling dynamical systems described by ordinary and partial differential
equations.</p>
  </details>
</details>
<details>
  <summary>31. <b>标题：Maximum Likelihood Uncertainty Estimation: Robustness to Outliers</b></summary>
  <p><b>编号</b>：[75]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03870</p>
  <p><b>作者</b>：Deebul S. Nair,  Nico Hochgeschwender,  Miguel A. Olivares-Mendez</p>
  <p><b>备注</b>：8 Pages, 8 Figures, The Thirty-Sixth AAAI Conference on Artificial Intelligence (AAAI-22), The AAAI's Workshop on Artificial Intelligence Safety</p>
  <p><b>关键词</b>：tailed distribution based maximum likelihood provides better uncertainty estimates, maximum likelihood based uncertainty estimation methods, evaluated using standard regression benchmarks, monocular depth estimation, dimensional regression task</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We benchmark the robustness of maximum likelihood based uncertainty
estimation methods to outliers in training data for regression tasks. Outliers
or noisy labels in training data results in degraded performances as well as
incorrect estimation of uncertainty. We propose the use of a heavy-tailed
distribution (Laplace distribution) to improve the robustness to outliers. This
property is evaluated using standard regression benchmarks and on a
high-dimensional regression task of monocular depth estimation, both containing
outliers. In particular, heavy-tailed distribution based maximum likelihood
provides better uncertainty estimates, better separation in uncertainty for
out-of-distribution data, as well as better detection of adversarial attacks in
the presence of outliers.</p>
  </details>
</details>
<details>
  <summary>32. <b>标题：COVID-19 Hospitalizations Forecasts Using Internet Search Data</b></summary>
  <p><b>编号</b>：[76]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03869</p>
  <p><b>作者</b>：Tao Wang,  Simin Ma,  Soobin Baek,  Shihao Yang</p>
  <p><b>备注</b>：arXiv admin note: text overlap with arXiv:2202.02621</p>
  <p><b>关键词</b>：average 15 \% error reduction, 19 related time series information, proposed influenza tracking model, best alternative models collected, future infectious disease outbreak</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As the COVID-19 spread over the globe and new variants of COVID-19 keep
occurring, reliable real-time forecasts of COVID-19 hospitalizations are
critical for public health decision on medical resources allocations such as
ICU beds, ventilators, and personnel to prepare for the surge of COVID-19
pandemics. Inspired by the strong association between public search behavior
and hospitalization admission, we extended previously-proposed influenza
tracking model, ARGO (AutoRegression with GOogle search data), to predict
future 2-week national and state-level COVID-19 new hospital admissions.
Leveraging the COVID-19 related time series information and Google search data,
our method is able to robustly capture new COVID-19 variants' surges, and
self-correct at both national and state level. Based on our retrospective
out-of-sample evaluation over 12-month comparison period, our method achieves
on average 15\% error reduction over the best alternative models collected from
COVID-19 forecast hub. Overall, we showed that our method is flexible,
self-correcting, robust, accurate, and interpretable, making it a potentially
powerful tool to assist health-care officials and decision making for the
current and future infectious disease outbreak.</p>
  </details>
</details>
<details>
  <summary>33. <b>标题：Mapping DNN Embedding Manifolds for Network Generalization Prediction</b></summary>
  <p><b>编号</b>：[77]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03868</p>
  <p><b>作者</b>：Molly O'Brien,  Julia Bukowski,  Mathias Unberath,  Aria Pezeshk,  Greg Hager</p>
  <p><b>备注</b>：11 pages, 5 figures</p>
  <p><b>关键词</b>：15 ngp tasks without requiring domain knowledge, predicts dnn performance based solely, external operating domain map, understanding deep neural network, new operating domain</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Understanding Deep Neural Network (DNN) performance in changing conditions is
essential for deploying DNNs in safety critical applications with unconstrained
environments, e.g., perception for self-driving vehicles or medical image
analysis. Recently, the task of Network Generalization Prediction (NGP) has
been proposed to predict how a DNN will generalize in a new operating domain.
Previous NGP approaches have relied on labeled metadata and known distributions
for the new operating domains. In this study, we propose the first NGP approach
that predicts DNN performance based solely on how unlabeled images from an
external operating domain map in the DNN embedding space. We demonstrate this
technique for pedestrian, melanoma, and animal classification tasks and show
state of the art NGP in 13 of 15 NGP tasks without requiring domain knowledge.
Additionally, we show that our NGP embedding maps can be used to identify
misclassified images when the DNN performance is poor.</p>
  </details>
</details>
<details>
  <summary>34. <b>标题：Offline Reinforcement Learning for Mobile Notifications</b></summary>
  <p><b>编号</b>：[78]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03867</p>
  <p><b>作者</b>：Yiping Yuan,  Ajith Muralidharan,  Preetam Nandy,  Miao Cheng,  Prakruthi Prabhakar</p>
  <p><b>备注</b>：11 pages, 5 figures. submitted</p>
  <p><b>关键词</b>：marginalized importance sampling policy evaluation approach, offline double deep q, scale recommendation system use, reinforcement learning modeling approach, optimize sequential notification decisions</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Mobile notification systems have taken a major role in driving and
maintaining user engagement for online platforms. They are interesting
recommender systems to machine learning practitioners with more sequential and
long-term feedback considerations. Most machine learning applications in
notification systems are built around response-prediction models, trying to
attribute both short-term impact and long-term impact to a notification
decision. However, a user's experience depends on a sequence of notifications
and attributing impact to a single notification is not always accurate, if not
impossible. In this paper, we argue that reinforcement learning is a better
framework for notification systems in terms of performance and iteration speed.
We propose an offline reinforcement learning framework to optimize sequential
notification decisions for driving user engagement. We describe a
state-marginalized importance sampling policy evaluation approach, which can be
used to evaluate the policy offline and tune learning hyperparameters. Through
simulations that approximate the notifications ecosystem, we demonstrate the
performance and benefits of the offline evaluation approach as a part of the
reinforcement learning modeling approach. Finally, we collect data through
online exploration in the production system, train an offline Double Deep
Q-Network and launch a successful policy online. We also discuss the practical
considerations and results obtained by deploying these policies for a
large-scale recommendation system use-case.</p>
  </details>
</details>
<details>
  <summary>35. <b>标题：Backtrack Tie-Breaking for Decision Trees: A Note on Deodata Predictors</b></summary>
  <p><b>编号</b>：[80]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03865</p>
  <p><b>作者</b>：Cristian Alb</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：similar technique used, predicted class, deodata predictors, decision tree, breaking method</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A tie-breaking method is proposed for choosing the predicted class, or
outcome, in a decision tree. The method is an adaptation of a similar technique
used for deodata predictors.</p>
  </details>
</details>
<details>
  <summary>36. <b>标题：Class Density and Dataset Quality in High-Dimensional, Unstructured Data</b></summary>
  <p><b>编号</b>：[84]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03856</p>
  <p><b>作者</b>：Adam Byerly,  Tatiana Kalganova</p>
  <p><b>备注</b>：13 pages, 27 tables</p>
  <p><b>关键词</b>：corresponding individual class test accuracies achieved, put forth several candidate methods, eliding redundant data based, individual class densities, calculating class density</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We provide a definition for class density that can be used to measure the
aggregate similarity of the samples within each of the classes in a
high-dimensional, unstructured dataset. We then put forth several candidate
methods for calculating class density and analyze the correlation between the
values each method produces with the corresponding individual class test
accuracies achieved on a trained model. Additionally, we propose a definition
for dataset quality for high-dimensional, unstructured data and show that those
datasets that met a certain quality threshold (experimentally demonstrated to
be > 10 for the datasets studied) were candidates for eliding redundant data
based on the individual class densities.</p>
  </details>
</details>
<details>
  <summary>37. <b>标题：Comparative Study Between Distance Measures On Supervised Optimum-Path  Forest Classification</b></summary>
  <p><b>编号</b>：[85]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03854</p>
  <p><b>作者</b>：Gustavo Henrique de Rosa,  Mateus Roder,  João Paulo Papa</p>
  <p><b>备注</b>：16 pages, 2 figures</p>
  <p><b>关键词</b>：attracted considerable attention throughout, compared across benchmarking classifiers, support vector machines, past decade due, may vary according</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Machine Learning has attracted considerable attention throughout the past
decade due to its potential to solve far-reaching tasks, such as image
classification, object recognition, anomaly detection, and data forecasting. A
standard approach to tackle such applications is based on supervised learning,
which is assisted by large sets of labeled data and is conducted by the
so-called classifiers, such as Logistic Regression, Decision Trees, Random
Forests, and Support Vector Machines, among others. An alternative to
traditional classifiers is the parameterless Optimum-Path Forest (OPF), which
uses a graph-based methodology and a distance measure to create arcs between
nodes and hence sets of trees, responsible for conquering the nodes, defining
their labels, and shaping the forests. Nevertheless, its performance is
strongly associated with an appropriate distance measure, which may vary
according to the dataset's nature. Therefore, this work proposes a comparative
study over a wide range of distance measures applied to the supervised
Optimum-Path Forest classification. The experimental results are conducted
using well-known literature datasets and compared across benchmarking
classifiers, illustrating OPF's ability to adapt to distinct domains.</p>
  </details>
</details>
<details>
  <summary>38. <b>标题：Width is Less Important than Depth in ReLU Neural Networks</b></summary>
  <p><b>编号</b>：[91]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03841</p>
  <p><b>作者</b>：Gal Vardi,  Gilad Yehudai,  Ohad Shamir</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：similar result cannot hold, shallow networks using deep, previous depth separation theorems, minimal possible width due, architecture ), whose number</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We solve an open question from Lu et al. (2017), by showing that any target
network with inputs in $\mathbb{R}^d$ can be approximated by a width $O(d)$
network (independent of the target network's architecture), whose number of
parameters is essentially larger only by a linear factor. In light of previous
depth separation theorems, which imply that a similar result cannot hold when
the roles of width and depth are interchanged, it follows that depth plays a
more significant role than width in the expressive power of neural networks.
We extend our results to constructing networks with bounded weights, and to
constructing networks with width at most $d+2$, which is close to the minimal
possible width due to previous lower bounds. Both of these constructions cause
an extra polynomial factor in the number of parameters over the target network.
We also show an exact representation of wide and shallow networks using deep
and narrow networks which, in certain cases, does not increase the number of
parameters over the target network.</p>
  </details>
</details>
<details>
  <summary>39. <b>标题：An Improved Analysis of Gradient Tracking for Decentralized Machine  Learning</b></summary>
  <p><b>编号</b>：[92]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03836</p>
  <p><b>作者</b>：Anastasia Koloskova,  Tao Lin,  Sebastian U. Stich</p>
  <p><b>备注</b>：published at NeurIPS 2021</p>
  <p><b>关键词</b>：}( p ^{- 2 })$, consider decentralized machine learning, }( p ^{- 3, }( p ^{- 1, }( p ^{- 1</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We consider decentralized machine learning over a network where the training
data is distributed across $n$ agents, each of which can compute stochastic
model updates on their local data. The agent's common goal is to find a model
that minimizes the average of all local loss functions. While gradient tracking
(GT) algorithms can overcome a key challenge, namely accounting for differences
between workers' local data distributions, the known convergence rates for GT
algorithms are not optimal with respect to their dependence on the mixing
parameter $p$ (related to the spectral gap of the connectivity matrix).
We provide a tighter analysis of the GT method in the stochastic strongly
convex, convex and non-convex settings. We improve the dependency on $p$ from
$\mathcal{O}(p^{-2})$ to $\mathcal{O}(p^{-1}c^{-1})$ in the noiseless case and
from $\mathcal{O}(p^{-3/2})$ to $\mathcal{O}(p^{-1/2}c^{-1})$ in the general
stochastic case, where $c \geq p$ is related to the negative eigenvalues of the
connectivity matrix (and is a constant in most practical applications). This
improvement was possible due to a new proof technique which could be of
independent interest.</p>
  </details>
</details>
<details>
  <summary>40. <b>标题：skrl: Modular and Flexible Library for Reinforcement Learning</b></summary>
  <p><b>编号</b>：[96]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03825</p>
  <p><b>作者</b>：Antonio Serrano-Muñoz,  Nestor Arana-Arexolaleiba,  Dimitrios Chrysostomou,  Simon Bøgh</p>
  <p><b>备注</b>：6 pages, 7 figures</p>
  <p><b>关键词</b>：operating nvidia isaac gym environments, traditional openai gym interface, reinforcement learning written, source modular library, supporting environments</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>skrl is an open-source modular library for reinforcement learning written in
Python and designed with a focus on readability, simplicity, and transparency
of algorithm implementations. Apart from supporting environments that use the
traditional OpenAI Gym interface, it allows loading, configuring, and operating
NVIDIA Isaac Gym environments, enabling the parallel training of several agents
with adjustable scopes, which may or may not share resources, in the same
execution. The library's documentation can be found at
this https URL and its source code is available on GitHub at
url{this https URL.</p>
  </details>
</details>
<details>
  <summary>41. <b>标题：Optimal Transport of Binary Classifiers to Fairness</b></summary>
  <p><b>编号</b>：[99]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03814</p>
  <p><b>作者</b>：Maarten Buyl,  Tijl De Bie</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：otf ), applies optimal transport, methods often simply perform, standard classification setting, similar statistical properties, unfairness cost term</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Much of the past work on fairness in machine learning has focused on forcing
the predictions of classifiers to have similar statistical properties for
individuals of different demographics. Yet, such methods often simply perform a
rescaling of the classifier scores and ignore whether individuals of different
groups have similar features. Our proposed method, Optimal Transport to
Fairness (OTF), applies Optimal Transport (OT) to take this similarity into
account by quantifying unfairness as the smallest cost of OT between a
classifier and any score function that satisfies fairness constraints. For a
flexible class of linear fairness constraints, we show a practical way to
compute OTF as an unfairness cost term that can be added to any standard
classification setting. Experiments show that OTF can be used to achieve an
effective trade-off between predictive power and fairness.</p>
  </details>
</details>
<details>
  <summary>42. <b>标题：SCR: Smooth Contour Regression with Geometric Priors</b></summary>
  <p><b>编号</b>：[112]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03784</p>
  <p><b>作者</b>：Gaetan Bahl,  Lionel Daniel,  Florent Lafarge</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：popular coco 2017 instance segmentation dataset, object detection methods traditionally make use, efficient geometric shape priors, defining object shapes, free object contours</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>While object detection methods traditionally make use of pixel-level masks or
bounding boxes, alternative representations such as polygons or active contours
have recently emerged. Among them, methods based on the regression of Fourier
or Chebyshev coefficients have shown high potential on freeform objects. By
defining object shapes as polar functions, they are however limited to
star-shaped domains. We address this issue with SCR: a method that captures
resolution-free object contours as complex periodic functions. The method
offers a good compromise between accuracy and compactness thanks to the design
of efficient geometric shape priors. We benchmark SCR on the popular COCO 2017
instance segmentation dataset, and show its competitiveness against existing
algorithms in the field. In addition, we design a compact version of our
network, which we benchmark on embedded hardware with a wide range of power
targets, achieving up to real-time performance.</p>
  </details>
</details>
<details>
  <summary>43. <b>标题：Impact of Parameter Sparsity on Stochastic Gradient MCMC Methods for  Bayesian Deep Learning</b></summary>
  <p><b>编号</b>：[116]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03770</p>
  <p><b>作者</b>：Meet P. Vadera,  Adam D. Cobb,  Brian Jalaian,  Benjamin M. Marlin</p>
  <p><b>备注</b>：Preprint. Work in progress</p>
  <p><b>关键词</b>：drastically reducing model training times, bayesian methods hold significant promise, use stochastic gradient mcmc methods, markov chain monte carlo, art iterative pruning methods</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Bayesian methods hold significant promise for improving the uncertainty
quantification ability and robustness of deep neural network models. Recent
research has seen the investigation of a number of approximate Bayesian
inference methods for deep neural networks, building on both the variational
Bayesian and Markov chain Monte Carlo (MCMC) frameworks. A fundamental issue
with MCMC methods is that the improvements they enable are obtained at the
expense of increased computation time and model storage costs. In this paper,
we investigate the potential of sparse network structures to flexibly trade-off
model storage costs and inference run time against predictive performance and
uncertainty quantification ability. We use stochastic gradient MCMC methods as
the core Bayesian inference method and consider a variety of approaches for
selecting sparse network structures. Surprisingly, our results show that
certain classes of randomly selected substructures can perform as well as
substructures derived from state-of-the-art iterative pruning methods while
drastically reducing model training times.</p>
  </details>
</details>
<details>
  <summary>44. <b>标题：Modeling Structure with Undirected Neural Networks</b></summary>
  <p><b>编号</b>：[118]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03760</p>
  <p><b>作者</b>：Tsvetomila Mihaylova,  Vlad Niculae,  André F. T. Martins</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：g ., factor graphs -- neural networks, extend many existing architectures, proposing undirected neural networks, problem -- e, undirected neural architectures</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Neural networks are powerful function estimators, leading to their status as
a paradigm of choice for modeling structured data. However, unlike other
structured representations that emphasize the modularity of the problem --
e.g., factor graphs -- neural networks are usually monolithic mappings from
inputs to outputs, with a fixed computation order. This limitation prevents
them from capturing different directions of computation and interaction between
the modeled variables.
In this paper, we combine the representational strengths of factor graphs and
of neural networks, proposing undirected neural networks (UNNs): a flexible
framework for specifying computations that can be performed in any order. For
particular choices, our proposed models subsume and extend many existing
architectures: feed-forward, recurrent, self-attention networks, auto-encoders,
and networks with implicit layers. We demonstrate the effectiveness of
undirected neural architectures, both unstructured and structured, on a range
of tasks: tree-constrained dependency parsing, convolutional image
classification, and sequence completion with attention. By varying the
computation order, we show how a single UNN can be used both as a classifier
and a prototype generator, and how it can fill in missing parts of an input
sequence, making them a promising field for further research.</p>
  </details>
</details>
<details>
  <summary>45. <b>标题：Practical Challenges in Differentially-Private Federated Survival  Analysis of Medical Data</b></summary>
  <p><b>编号</b>：[120]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03758</p>
  <p><b>作者</b>：Shadi Rahimian,  Raouf Kerkouche,  Ina Kurth,  Mario Fritz</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：standard differentially private federated learning scheme, private federated learning scheme, noisy average parameter update, medical domain since data, extra step helps</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Survival analysis or time-to-event analysis aims to model and predict the
time it takes for an event of interest to happen in a population or an
individual. In the medical context this event might be the time of dying,
metastasis, recurrence of cancer, etc. Recently, the use of neural networks
that are specifically designed for survival analysis has become more popular
and an attractive alternative to more traditional methods. In this paper, we
take advantage of the inherent properties of neural networks to federate the
process of training of these models. This is crucial in the medical domain
since data is scarce and collaboration of multiple health centers is essential
to make a conclusive decision about the properties of a treatment or a disease.
To ensure the privacy of the datasets, it is common to utilize differential
privacy on top of federated learning. Differential privacy acts by introducing
random noise to different stages of training, thus making it harder for an
adversary to extract details about the data. However, in the realistic setting
of small medical datasets and only a few data centers, this noise makes it
harder for the models to converge. To address this problem, we propose
DPFed-post which adds a post-processing stage to the private federated learning
scheme. This extra step helps to regulate the magnitude of the noisy average
parameter update and easier convergence of the model. For our experiments, we
choose 3 real-world datasets in the realistic setting when each health center
has only a few hundred records, and we show that DPFed-post successfully
increases the performance of the models by an average of up to $17\%$ compared
to the standard differentially private federated learning scheme.</p>
  </details>
</details>
<details>
  <summary>46. <b>标题：Can We Generate Shellcodes via Natural Language? An Empirical Study</b></summary>
  <p><b>编号</b>：[122]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03755</p>
  <p><b>作者</b>：Pietro Liguori,  Erfan Al-Hossami,  Domenico Cotroneo,  Roberto Natella,  Bojan Cukic,  Samira Shaikh</p>
  <p><b>备注</b>：33 pages, 5 figures, 9 tables. To be published in Automated Software Engineering journal</p>
  <p><b>关键词</b>：200 assembly code snippets, generate assembly code snippets, annotated using natural language, empirical study using, writing software exploits</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Writing software exploits is an important practice for offensive security
analysts to investigate and prevent attacks. In particular, shellcodes are
especially time-consuming and a technical challenge, as they are written in
assembly language. In this work, we address the task of automatically
generating shellcodes, starting purely from descriptions in natural language,
by proposing an approach based on Neural Machine Translation (NMT). We then
present an empirical study using a novel dataset (Shellcode_IA32), which
consists of 3,200 assembly code snippets of real Linux/x86 shellcodes from
public databases, annotated using natural language. Moreover, we propose novel
metrics to evaluate the accuracy of NMT at generating shellcodes. The empirical
analysis shows that NMT can generate assembly code snippets from the natural
language with high accuracy and that in many cases can generate entire
shellcodes with no errors.</p>
  </details>
</details>
<details>
  <summary>47. <b>标题：Semantic features of object concepts generated with GPT-3</b></summary>
  <p><b>编号</b>：[123]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03753</p>
  <p><b>作者</b>：Hannes Hansen,  Martin N. Hebart</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：generated feature norms rivaled human norms, automatically generating interpretable feature sets, models would produce features similar, existing human feature norms, given recent promising developments</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Semantic features have been playing a central role in investigating the
nature of our conceptual representations. Yet the enormous time and effort
required to empirically sample and norm features from human raters has
restricted their use to a limited set of manually curated concepts. Given
recent promising developments with transformer-based language models, here we
asked whether it was possible to use such models to automatically generate
meaningful lists of properties for arbitrary object concepts and whether these
models would produce features similar to those found in humans. To this end, we
probed a GPT-3 model to generate semantic features for 1,854 objects and
compared automatically-generated features to existing human feature norms.
GPT-3 generated many more features than humans, yet showed a similar
distribution in the types of generated features. Generated feature norms
rivaled human norms in predicting similarity, relatedness, and category
membership, while variance partitioning demonstrated that these predictions
were driven by similar variance in humans and GPT-3. Together, these results
highlight the potential of large language models to capture important facets of
human knowledge and yield a new approach for automatically generating
interpretable feature sets, thus drastically expanding the potential use of
semantic features in psychological and linguistic studies.</p>
  </details>
</details>
<details>
  <summary>48. <b>标题：Cascaded Debiasing : Studying the Cumulative Effect of Multiple  Fairness-Enhancing Interventions</b></summary>
  <p><b>编号</b>：[129]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03734</p>
  <p><b>作者</b>：Bhavya Ghai,  Mihir Mishra,  Klaus Mueller</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：extensive empirical study comprising 60 combinations, negatively impact different population groups, across 4 benchmark datasets, different population groups apart, designing fair ml pipelines</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Understanding the cumulative effect of multiple fairness enhancing
interventions at different stages of the machine learning (ML) pipeline is a
critical and underexplored facet of the fairness literature. Such knowledge can
be valuable to data scientists/ML practitioners in designing fair ML pipelines.
This paper takes the first step in exploring this area by undertaking an
extensive empirical study comprising 60 combinations of interventions, 9
fairness metrics, 2 utility metrics (Accuracy and F1 Score) across 4 benchmark
datasets. We quantitatively analyze the experimental data to measure the impact
of multiple interventions on fairness, utility and population groups. We found
that applying multiple interventions results in better fairness and lower
utility than individual interventions on aggregate. However, adding more
interventions do no always result in better fairness or worse utility. The
likelihood of achieving high performance (F1 Score) along with high fairness
increases with larger number of interventions. On the downside, we found that
fairness-enhancing interventions can negatively impact different population
groups, especially the privileged group. This study highlights the need for new
fairness metrics that account for the impact on different population groups
apart from just the disparity between groups. Lastly, we offer a list of
combinations of interventions that perform best for different fairness and
utility metrics to aid the design of fair ML pipelines.</p>
  </details>
</details>
<details>
  <summary>49. <b>标题：A two-step approach to leverage contextual data: speech recognition in  air-traffic communications</b></summary>
  <p><b>编号</b>：[133]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03725</p>
  <p><b>作者</b>：Iuliia Nigmatulina,  Juan Zuluaga-Gomez,  Amrutha Prasad,  Seyyed Saeed Sarfjoo,  Petr Motlicek</p>
  <p><b>备注</b>：20XX IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works. arXiv admin note: text overlap with arXiv:2108.12156</p>
  <p><b>关键词</b>：nlp methods eventually leads, step callsign boosting approach, improve air traffic management, nlp ), callsigns extracted, boosting callsign n</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Automatic Speech Recognition (ASR), as the assistance of speech communication
between pilots and air-traffic controllers, can significantly reduce the
complexity of the task and increase the reliability of transmitted information.
ASR application can lead to a lower number of incidents caused by
misunderstanding and improve air traffic management (ATM) efficiency.
Evidently, high accuracy predictions, especially, of key information, i.e.,
callsigns and commands, are required to minimize the risk of errors. We prove
that combining the benefits of ASR and Natural Language Processing (NLP)
methods to make use of surveillance data (i.e. additional modality) helps to
considerably improve the recognition of callsigns (named entity). In this
paper, we investigate a two-step callsign boosting approach: (1) at the 1 step
(ASR), weights of probable callsign n-grams are reduced in G.fst and/or in the
decoding FST (lattices), (2) at the 2 step (NLP), callsigns extracted from the
improved recognition outputs with Named Entity Recognition (NER) are correlated
with the surveillance data to select the most suitable one. Boosting callsign
n-grams with the combination of ASR and NLP methods eventually leads up to
53.7% of an absolute, or 60.4% of a relative, improvement in callsign
recognition.</p>
  </details>
</details>
<details>
  <summary>50. <b>标题：Fourier Representations for Black-Box Optimization over Categorical  Variables</b></summary>
  <p><b>编号</b>：[138]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03712</p>
  <p><b>作者</b>：Hamid Dadkhahi,  Jesus Rios,  Karthikeyan Shanmugam,  Payel Das</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：hot encoded boolean fourier expansion, monte carlo tree search, adversarial online regression setting, selected via thompson sampling, present two different representations</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Optimization of real-world black-box functions defined over purely
categorical variables is an active area of research. In particular,
optimization and design of biological sequences with specific functional or
structural properties have a profound impact in medicine, materials science,
and biotechnology. Standalone search algorithms, such as simulated annealing
(SA) and Monte Carlo tree search (MCTS), are typically used for such
optimization problems. In order to improve the performance and sample
efficiency of such algorithms, we propose to use existing methods in
conjunction with a surrogate model for the black-box evaluations over purely
categorical variables. To this end, we present two different representations, a
group-theoretic Fourier expansion and an abridged one-hot encoded Boolean
Fourier expansion. To learn such representations, we consider two different
settings to update our surrogate model. First, we utilize an adversarial online
regression setting where Fourier characters of each representation are
considered as experts and their respective coefficients are updated via an
exponential weight update rule each time the black box is evaluated. Second, we
consider a Bayesian setting where queries are selected via Thompson sampling
and the posterior is updated via a sparse Bayesian regression model (over our
proposed representation) with a regularized horseshoe prior. Numerical
experiments over synthetic benchmarks as well as real-world RNA sequence
optimization and design problems demonstrate the representational power of the
proposed methods, which achieve competitive or superior performance compared to
state-of-the-art counterparts, while improving the computation cost and/or
sample efficiency, substantially.</p>
  </details>
</details>
<details>
  <summary>51. <b>标题：Budgeted Combinatorial Multi-Armed Bandits</b></summary>
  <p><b>编号</b>：[142]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03704</p>
  <p><b>作者</b>：Debojit Das,  Shweta Jain,  Sujit Gujar</p>
  <p><b>备注</b>：9 pages, 4 figures. To be published in AAMAS 2022. arXiv admin note: text overlap with arXiv:1305.2545 by other authors</p>
  <p><b>关键词</b>：rigorously prove regret bounds, ucb performs incrementally better, total expected regret, budgeted combinatorial multi, uses primaldualbwk ingeniously</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We consider a budgeted combinatorial multi-armed bandit setting where, in
every round, the algorithm selects a super-arm consisting of one or more arms.
The goal is to minimize the total expected regret after all rounds within a
limited budget. Existing techniques in this literature either fix the budget
per round or fix the number of arms pulled in each round. Our setting is more
general where based on the remaining budget and remaining number of rounds, the
algorithm can decide how many arms to be pulled in each round. First, we
propose CBwK-Greedy-UCB algorithm, which uses a greedy technique, CBwK-Greedy,
to allocate the arms to the rounds. Next, we propose a reduction of this
problem to Bandits with Knapsacks (BwK) with a single pull. With this
reduction, we propose CBwK-LPUCB that uses PrimalDualBwK ingeniously. We
rigorously prove regret bounds for CBwK-LP-UCB. We experimentally compare the
two algorithms and observe that CBwK-Greedy-UCB performs incrementally better
than CBwK-LP-UCB. We also show that for very high budgets, the regret goes to
zero.</p>
  </details>
</details>
<details>
  <summary>52. <b>标题：Efficiently Escaping Saddle Points in Bilevel Optimization</b></summary>
  <p><b>编号</b>：[152]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03684</p>
  <p><b>作者</b>：Minhui Huang,  Kaiyi Ji,  Shiqian Ma,  Lifeng Lai</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：warm start strategy finds $\ epsilon $- approximate local minimum, }(\ epsilon ^{- 2 })$ iterations, perturbed approximate implicit differentiation, step gradient descent ascent, find local minimum</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Bilevel optimization is one of the fundamental problems in machine learning
and optimization. Recent theoretical developments in bilevel optimization focus
on finding the first-order stationary points for nonconvex-strongly-convex
cases. In this paper, we analyze algorithms that can escape saddle points in
nonconvex-strongly-convex bilevel optimization. Specifically, we show that the
perturbed approximate implicit differentiation (AID) with a warm start strategy
finds $\epsilon$-approximate local minimum of bilevel optimization in
$\tilde{O}(\epsilon^{-2})$ iterations with high probability. Moreover, we
propose an inexact NEgative-curvature-Originated-from-Noise Algorithm (iNEON),
a pure first-order algorithm that can escape saddle point and find local
minimum of stochastic bilevel optimization. As a by-product, we provide the
first nonasymptotic analysis of perturbed multi-step gradient descent ascent
(GDmax) algorithm that converges to local minimax point for minimax problems.</p>
  </details>
</details>
<details>
  <summary>53. <b>标题：A Unified Prediction Framework for Signal Maps</b></summary>
  <p><b>编号</b>：[154]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03679</p>
  <p><b>作者</b>：Emmanouil Alimpertis (1),  Athina Markopoulou (1),  Carter T. Butts (1),  Evita Bakopoulou (1),  Konstantinos Psounis (2) ((1) University of California Irvine (2) University of Southern California)</p>
  <p><b>备注</b>：Coverage Maps; Signal Strength Maps; LTE; RSRP; CQI; RSRQ; RSS; Importance Sampling; Random Forests; Carrier's Objectives; Call Drops;Key Performance Indicators</p>
  <p><b>关键词</b>：service functions ($ q $)}, including signal strength, assign values ($\ phi $), low signal strength regime, 76 \%- 92 \%), {\ em data shapley</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Signal maps are essential for the planning and operation of cellular
networks. However, the measurements needed to create such maps are expensive,
often biased, not always reflecting the metrics of interest, and posing privacy
risks. In this paper, we develop a unified framework for predicting cellular
signal maps from limited measurements. We propose and combine three mechanisms
that deal with the fact that not all measurements are equally important for a
particular prediction task. First, we design \emph{quality-of-service functions
($Q$)}, including signal strength (RSRP) but also other metrics of interest,
such as coverage (improving recall by 76\%-92\%) and call drop probability
(reducing error by as much as 32\%). By implicitly altering the training loss
function, quality functions can also improve prediction for RSRP itself where
it matters (e.g. MSE reduction up to 27\% in the low signal strength regime,
where errors are critical). Second, we introduce \emph{weight functions} ($W$)
to specify the relative importance of prediction at different parts of the
feature space. We propose re-weighting based on importance sampling to obtain
unbiased estimators when the sampling and target distributions
mismatch(yielding 20\% improvement for targets on spatially uniform loss or on
user population density). Third, we apply the {\em Data Shapley} framework for
the first time in this context: to assign values ($\phi$) to individual
measurement points, which capture the importance of their contribution to the
prediction task. This can improve prediction (e.g. from 64\% to 94\% in recall
for coverage loss) by removing points with negative values, and can also enable
data minimization (i.e. we show that we can remove 70\% of data w/o loss in
performance). We evaluate our methods and demonstrate significant improvement
in prediction performance, using several real-world datasets.</p>
  </details>
</details>
<details>
  <summary>54. <b>标题：Trained Model in Supervised Deep Learning is a Conditional Risk  Minimizer</b></summary>
  <p><b>编号</b>：[157]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03674</p>
  <p><b>作者</b>：Yutong Xie,  Dufan Wu,  Bin Dong,  Quanzheng Li</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：noisy labels using theorem 2, supervised deep learning minimizes, original supervised learning problem, using mnist dataset, using imagenet dataset</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We proved that a trained model in supervised deep learning minimizes the
conditional risk for each input (Theorem 2.1). This property provided insights
into the behavior of trained models and established a connection between
supervised and unsupervised learning in some cases. In addition, when the
labels are intractable but can be written as a conditional risk minimizer, we
proved an equivalent form of the original supervised learning problem with
accessible labels (Theorem 2.2). We demonstrated that many existing works, such
as Noise2Score, Noise2Noise and score function estimation can be explained by
our theorem. Moreover, we derived a property of classification problem with
noisy labels using Theorem 2.1 and validated it using MNIST dataset.
Furthermore, We proposed a method to estimate uncertainty in image
super-resolution based on Theorem 2.2 and validated it using ImageNet dataset.
Our code is available on github.</p>
  </details>
</details>
<details>
  <summary>55. <b>标题：Calibrated Learning to Defer with One-vs-All Classifiers</b></summary>
  <p><b>编号</b>：[158]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03673</p>
  <p><b>作者</b>：Rajeev Verma,  Eric Nalisnick</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：make ai systems safer, produce valid probabilities due, hate speech detection, produce calibrated probabilities, l2d system based</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The learning to defer (L2D) framework has the potential to make AI systems
safer. For a given input, the system can defer the decision to a human if the
human is more likely than the model to take the correct action. We study the
calibration of L2D systems, investigating if the probabilities they output are
sound. We find that Mozannar & Sontag's (2020) multiclass framework is not
calibrated with respect to expert correctness. Moreover, it is not even
guaranteed to produce valid probabilities due to its parameterization being
degenerate for this purpose. We propose an L2D system based on one-vs-all
classifiers that is able to produce calibrated probabilities of expert
correctness. Furthermore, our loss function is also a consistent surrogate for
multiclass L2D, like Mozannar & Sontag's (2020). Our experiments verify that
not only is our system calibrated, but this benefit comes at no cost to
accuracy. Our model's accuracy is always comparable (and often superior) to
Mozannar & Sontag's (2020) model's in tasks ranging from hate speech detection
to galaxy classification to diagnosis of skin lesions.</p>
  </details>
</details>
<details>
  <summary>56. <b>标题：APPFL: Open-Source Software Framework for Privacy-Preserving Federated  Learning</b></summary>
  <p><b>编号</b>：[159]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03672</p>
  <p><b>作者</b>：Minseok Ryu,  Youngdae Kim,  Kibaek Kim,  Ravi K. Madduri</p>
  <p><b>备注</b>：9 pages, 4 figures, 1 table</p>
  <p><b>关键词</b>：algorithm requires significantly less communication, rapidly growing research field, inexact alternating direction method, modular framework enables users, including differentially private fl</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Federated learning (FL) enables training models at different sites and
updating the weights from the training instead of transferring data to a
central location and training as in classical machine learning. The FL
capability is especially important to domains such as biomedicine and smart
grid, where data may not be shared freely or stored at a central location
because of policy challenges. Thanks to the capability of learning from
decentralized datasets, FL is now a rapidly growing research field, and
numerous FL frameworks have been developed. In this work, we introduce APPFL,
the Argonne Privacy-Preserving Federated Learning framework. APPFL allows users
to leverage implemented privacy-preserving algorithms, implement new
algorithms, and simulate and deploy various FL algorithms with
privacy-preserving techniques. The modular framework enables users to customize
the components for algorithms, privacy, communication protocols, neural network
models, and user data. We also present a new communication-efficient algorithm
based on an inexact alternating direction method of multipliers. The algorithm
requires significantly less communication between the server and the clients
than does the current state of the art. We demonstrate the computational
capabilities of APPFL, including differentially private FL on various test
datasets and its scalability, by using multiple algorithms and datasets on
different computing environments.</p>
  </details>
</details>
<details>
  <summary>57. <b>标题：How to Understand Masked Autoencoders</b></summary>
  <p><b>编号</b>：[160]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03670</p>
  <p><b>作者</b>：Shuhao Cao,  Peng Xu,  David A. Clifton</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：overlapping domain decomposition setting, scalable vision learners, contribute five questions, linguistic masked autoencoding, based attention approaches</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>"Masked Autoencoders (MAE) Are Scalable Vision Learners" revolutionizes the
self-supervised learning that not only achieves the state-of-the-art for image
pretraining, but also is a milestone that bridged the gap between the visual
and linguistic masked autoencoding (BERT-style) pretrainings. However, to our
knowledge, to date there are no theoretical perspectives to explain the
powerful expressivity of MAE. In this paper, we, for the first time, propose a
unified theoretical framework that provides a mathematical understanding for
MAE. Particularly, we explain the patch-based attention approaches of MAE using
an integral kernel under a non-overlapping domain decomposition setting. To
help the researchers to further grasp the main reasons of the great success of
MAE, based on our framework, we contribute five questions and answer them by
insights from operator theory with mathematical rigor.</p>
  </details>
</details>
<details>
  <summary>58. <b>标题：Approximating Gradients for Differentiable Quality Diversity in  Reinforcement Learning</b></summary>
  <p><b>编号</b>：[161]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03666</p>
  <p><b>作者</b>：Bryon Tjanaka,  Matthew C. Fontaine,  Julian Togelius,  Stefanos Nikolaidis</p>
  <p><b>备注</b>：Online article available at this http URL</p>
  <p><b>关键词</b>：one variant achieves comparable performance, algorithms greatly accelerate qd optimization, four simulated walking tasks, variant performs comparably, require rigorous optimization</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Consider a walking agent that must adapt to damage. To approach this task, we
can train a collection of policies and have the agent select a suitable policy
when damaged. Training this collection may be viewed as a quality diversity
(QD) optimization problem, where we search for solutions (policies) which
maximize an objective (walking forward) while spanning a set of measures
(measurable characteristics). Recent work shows that differentiable quality
diversity (DQD) algorithms greatly accelerate QD optimization when exact
gradients are available for the objective and measures. However, such gradients
are typically unavailable in RL settings due to non-differentiable
environments. To apply DQD in RL settings, we propose to approximate objective
and measure gradients with evolution strategies and actor-critic methods. We
develop two variants of the DQD algorithm CMA-MEGA, each with different
gradient approximations, and evaluate them on four simulated walking tasks. One
variant achieves comparable performance (QD score) with the state-of-the-art
PGA-MAP-Elites in two tasks. The other variant performs comparably in all tasks
but is less efficient than PGA-MAP-Elites in two tasks. These results provide
insight into the limitations of CMA-MEGA in domains that require rigorous
optimization of the objective and where exact gradients are unavailable.</p>
  </details>
</details>
<details>
  <summary>59. <b>标题：Linear Time Kernel Matrix Approximation via Hyperspherical Harmonics</b></summary>
  <p><b>编号</b>：[162]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03655</p>
  <p><b>作者</b>：John Paul Ryan,  Anil Damle</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：novel automatically constructed analytic expansion, commonly used nystrom method, desired error tolerance, dependent compression step, approach produces near</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose a new technique for constructing low-rank approximations of
matrices that arise in kernel methods for machine learning. Our approach pairs
a novel automatically constructed analytic expansion of the underlying kernel
function with a data-dependent compression step to further optimize the
approximation. This procedure works in linear time and is applicable to any
isotropic kernel. Moreover, our method accepts the desired error tolerance as
input, in contrast to prevalent methods which accept the rank as input.
Experimental results show our approach compares favorably to the commonly used
Nystrom method with respect to both accuracy for a given rank and computational
time for a given accuracy across a variety of kernels, dimensions, and
datasets. Notably, in many of these problem settings our approach produces
near-optimal low-rank approximations. We provide an efficient open-source
implementation of our new technique to complement our theoretical developments
and experimental results.</p>
  </details>
</details>
<details>
  <summary>60. <b>标题：NxtPost: User to Post Recommendations in Facebook Groups</b></summary>
  <p><b>编号</b>：[168]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03645</p>
  <p><b>作者</b>：Kaushik Rangadurai,  Yiqun Liu,  Siddarth Malreddy,  Xiaoyi Liu,  Piyush Maheshwari,  Vishwanath Sangale,  Fedor Borisyuk</p>
  <p><b>备注</b>：9 pages</p>
  <p><b>关键词</b>：explore causal masked multi, personalized sequential recommender system, based sequential recommender system, next post user may, reach higher efficiency</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we present NxtPost, a deployed user-to-post content-based
sequential recommender system for Facebook Groups. Inspired by recent advances
in NLP, we have adapted a Transformer-based model to the domain of sequential
recommendation. We explore causal masked multi-head attention that optimizes
both short and long-term user interests. From a user's past activities
validated by defined safety process, NxtPost seeks to learn a representation
for the user's dynamic content preference and to predict the next post user may
be interested in. In contrast to previous Transformer-based methods, we do not
assume that the recommendable posts have a fixed corpus. Accordingly, we use an
external item/token embedding to extend a sequence-based approach to a large
vocabulary. We achieve 49% abs. improvement in offline evaluation. As a result
of NxtPost deployment, 0.6% more users are meeting new people, engaging with
the community, sharing knowledge and getting support. The paper shares our
experience in developing a personalized sequential recommender system, lessons
deploying the model for cold start users, how to deal with freshness, and
tuning strategies to reach higher efficiency in online A/B experiments.</p>
  </details>
</details>
<details>
  <summary>61. <b>标题：Contrastive predictive coding for Anomaly Detection in Multi-variate  Time Series Data</b></summary>
  <p><b>编号</b>：[170]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03639</p>
  <p><b>作者</b>：Theivendiram Pranavan,  Terence Sim,  Arulmurugan Ambikapathi,  Savitha Ramasamy</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：sota anomaly detection methods shows, long term temporal dependencies, correlations across multiple variables, three mvts data sets, towards anomaly detection</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Anomaly detection in multi-variate time series (MVTS) data is a huge
challenge as it requires simultaneous representation of long term temporal
dependencies and correlations across multiple variables. More often, this is
solved by breaking the complexity through modeling one dependency at a time. In
this paper, we propose a Time-series Representational Learning through
Contrastive Predictive Coding (TRL-CPC) towards anomaly detection in MVTS data.
First, we jointly optimize an encoder, an auto-regressor and a non-linear
transformation function to effectively learn the representations of the MVTS
data sets, for predicting future trends. It must be noted that the context
vectors are representative of the observation window in the MTVS. Next, the
latent representations for the succeeding instants obtained through non-linear
transformations of these context vectors, are contrasted with the latent
representations of the encoder for the multi-variables such that the density
for the positive pair is maximized. Thus, the TRL-CPC helps to model the
temporal dependencies and the correlations of the parameters for a healthy
signal pattern. Finally, fitting the latent representations are fit into a
Gaussian scoring function to detect anomalies. Evaluation of the proposed
TRL-CPC on three MVTS data sets against SOTA anomaly detection methods shows
the superiority of TRL-CPC.</p>
  </details>
</details>
<details>
  <summary>62. <b>标题：Invertible Tabular GANs: Killing Two Birds with OneStone for Tabular  Data Synthesis</b></summary>
  <p><b>编号</b>：[172]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03636</p>
  <p><b>作者</b>：Jaehoon Lee,  Jihyeon Hyeong,  Jinsung Jeon,  Noseong Park,  Jihoon Cho</p>
  <p><b>备注</b>：19 pages</p>
  <p><b>关键词</b>：two distinctive objectives, received wide attention, potential information leakage, oriented evaluation metrics, invertible neural networks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Tabular data synthesis has received wide attention in the literature. This is
because available data is often limited, incomplete, or cannot be obtained
easily, and data privacy is becoming increasingly important. In this work, we
present a generalized GAN framework for tabular synthesis, which combines the
adversarial training of GANs and the negative log-density regularization of
invertible neural networks. The proposed framework can be used for two
distinctive objectives. First, we can further improve the synthesis quality, by
decreasing the negative log-density of real records in the process of
adversarial training. On the other hand, by increasing the negative log-density
of real records, realistic fake records can be synthesized in a way that they
are not too much close to real records and reduce the chance of potential
information leakage. We conduct experiments with real-world datasets for
classification, regression, and privacy attacks. In general, the proposed
method demonstrates the best synthesis quality (in terms of task-oriented
evaluation metrics, e.g., F1) when decreasing the negative log-density during
the adversarial training. If increasing the negative log-density, our
experimental results show that the distance between real and fake records
increases, enhancing robustness against privacy attacks.</p>
  </details>
</details>
<details>
  <summary>63. <b>标题：Multi-Agent Path Finding with Prioritized Communication Learning</b></summary>
  <p><b>编号</b>：[173]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03634</p>
  <p><b>作者</b>：Wenhao Li,  Hongjun Chen,  Bo Jin,  Wenzhe Tan,  Hongyuan Zha,  Xiangfeng Wang</p>
  <p><b>备注</b>：7 pages, 5 figures, 4 tables, published at ICRA 2022</p>
  <p><b>关键词</b>：existing methods might generate significantly, pico performs significantly better, agent reinforcement learning framework, agent path finding tasks, implicit priority learning module</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Multi-agent path finding (MAPF) has been widely used to solve large-scale
real-world problems, e.g. automation warehouse. The learning-based fully
decentralized framework has been introduced to simultaneously alleviate
real-time problem and pursuit the optimal planning policy. However, existing
methods might generate significantly more vertex conflicts (called collision),
which lead to low success rate or more makespan. In this paper, we propose a
PrIoritized COmmunication learning method (PICO), which incorporates the
implicit planning priorities into the communication topology within the
decentralized multi-agent reinforcement learning framework. Assembling with the
classic coupled planners, the implicit priority learning module can be utilized
to form the dynamic communication topology, which also build an effective
collision-avoiding mechanism. PICO performs significantly better in large-scale
multi-agent path finding tasks in both success rates and collision rates than
state-of-the-art learning-based planners.</p>
  </details>
</details>
<details>
  <summary>64. <b>标题：ECRECer: Enzyme Commission Number Recommendation and Benchmarking based  on Multiagent Dual-core Learning</b></summary>
  <p><b>编号</b>：[175]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03632</p>
  <p><b>作者</b>：Zhenkun Shi,  Qianqian Yuan,  Ruoyu Wang,  Hoaran Li,  Xiaoping Liao,  Hongwu Ma</p>
  <p><b>备注</b>：16 pages, 14 figures</p>
  <p><b>关键词</b>：evaluate different protein representation methods, accurately predicting ec numbers based, novel deep learning techniques, given input sequences directly, four representative methods demonstrate</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Enzyme Commission (EC) numbers, which associate a protein sequence with the
biochemical reactions it catalyzes, are essential for the accurate
understanding of enzyme functions and cellular metabolism. Many ab-initio
computational approaches were proposed to predict EC numbers for given input
sequences directly. However, the prediction performance (accuracy, recall,
precision), usability, and efficiency of existing methods still have much room
to be improved. Here, we report ECRECer, a cloud platform for accurately
predicting EC numbers based on novel deep learning techniques. To build
ECRECer, we evaluate different protein representation methods and adopt a
protein language model for protein sequence embedding. After embedding, we
propose a multi-agent hierarchy deep learning-based framework to learn the
proposed tasks in a multi-task manner. Specifically, we used an extreme
multi-label classifier to perform the EC prediction and employed a greedy
strategy to integrate and fine-tune the final model. Comparative analyses
against four representative methods demonstrate that ECRECer delivers the
highest performance, which improves accuracy and F1 score by 70% and 20% over
the state-of-the-the-art, respectively. With ECRECer, we can annotate numerous
enzymes in the Swiss-Prot database with incomplete EC numbers to their full
fourth level. Take UniPort protein "A0A0U5GJ41" as an example (1.14.-.-),
ECRECer annotated it with "this http URL", which supported by further protein
structure analysis based on AlphaFold2. Finally, we established a webserver
(this https URL) and provided an offline bundle to improve
usability.</p>
  </details>
</details>
<details>
  <summary>65. <b>标题：Domain Adversarial Spatial-Temporal Network: A Transferable Framework  for Short-term Traffic Forecasting across Cities</b></summary>
  <p><b>编号</b>：[177]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03630</p>
  <p><b>作者</b>：Yihong Tang,  Ao Qu,  Andy H.F. Chow,  William H.K. Lam,  S.C. Wong,  Wei Ma</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：novel transferable traffic forecasting framework, cities lacking historical traffic data, various smart mobility applications, wide traffic forecasting problems, developing new model structures</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Accurate real-time traffic forecast is critical for intelligent
transportation systems (ITS) and it serves as the cornerstone of various smart
mobility applications. Though this research area is dominated by deep learning,
recent studies indicate that the accuracy improvement by developing new model
structures is becoming marginal. Instead, we envision that the improvement can
be achieved by transferring the "forecasting-related knowledge" across cities
with different data distributions and network topologies. To this end, this
paper aims to propose a novel transferable traffic forecasting framework:
Domain Adversarial Spatial-Temporal Network (DASTNet). DASTNet is pre-trained
on multiple source networks and fine-tuned with the target network's traffic
data. Specifically, we leverage the graph representation learning and
adversarial domain adaptation techniques to learn the domain-invariant node
embeddings, which are further incorporated to model the temporal traffic data.
To the best of our knowledge, we are the first to employ adversarial
multi-domain adaptation for network-wide traffic forecasting problems. DASTNet
consistently outperforms all state-of-the-art baseline methods on three
benchmark datasets. The trained DASTNet is applied to Hong Kong's new traffic
detectors, and accurate traffic predictions can be delivered immediately
(within one day) when the detector is available. Overall, this study suggests
an alternative to enhance the traffic forecasting methods and provides
practical implications for cities lacking historical traffic data.</p>
  </details>
</details>
<details>
  <summary>66. <b>标题：Graph-Relational Domain Adaptation</b></summary>
  <p><b>编号</b>：[179]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03628</p>
  <p><b>作者</b>：Zihao Xu,  Hao he,  Guang-He Lee,  Yuyang Wang,  Hao Wang</p>
  <p><b>备注</b>：Accepted by ICLR 2022</p>
  <p><b>关键词</b>：uniform alignment ignores topological structures among different domains, improves upon existing domain adaptation methods, existing domain adaptation methods tend, approach successfully generalizes uniform alignment, method recovers classic domain adaptation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Existing domain adaptation methods tend to treat every domain equally and
align them all perfectly. Such uniform alignment ignores topological structures
among different domains; therefore it may be beneficial for nearby domains, but
not necessarily for distant domains. In this work, we relax such uniform
alignment by using a domain graph to encode domain adjacency, e.g., a graph of
states in the US with each state as a domain and each edge indicating
adjacency, thereby allowing domains to align flexibly based on the graph
structure. We generalize the existing adversarial learning framework with a
novel graph discriminator using encoding-conditioned graph embeddings.
Theoretical analysis shows that at equilibrium, our method recovers classic
domain adaptation when the graph is a clique, and achieves non-trivial
alignment for other types of graphs. Empirical results show that our approach
successfully generalizes uniform alignment, naturally incorporates domain
information represented by graphs, and improves upon existing domain adaptation
methods on both synthetic and real-world datasets. Code will soon be available
at this https URL.</p>
  </details>
</details>
<details>
  <summary>67. <b>标题：Bandit Sampling for Multiplex Networks</b></summary>
  <p><b>编号</b>：[181]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03621</p>
  <p><b>作者</b>：Cenk Baykal,  Vamsi K. Potluru,  Sameena Shah,  Manuela M. Veloso</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：existing work focuses primarily, recent layer sampling method, sample relevant neighboring layers, present experimental results, gained prominence due</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Graph neural networks have gained prominence due to their excellent
performance in many classification and prediction tasks. In particular, they
are used for node classification and link prediction which have a wide range of
applications in social networks, biomedical data sets, and financial
transaction graphs. Most of the existing work focuses primarily on the monoplex
setting where we have access to a network with only a single type of connection
between entities. However, in the multiplex setting, where there are multiple
types of connections, or \emph{layers}, between entities, performance on tasks
such as link prediction has been shown to be stronger when information from
other connection types is taken into account. We propose an algorithm for
scalable learning on multiplex networks with a large number of layers. The
efficiency of our method is enabled by an online learning algorithm that learns
how to sample relevant neighboring layers so that only the layers with relevant
information are aggregated during training. This sampling differs from prior
work, such as MNE, which aggregates information across \emph{all} layers and
consequently leads to computational intractability on large networks. Our
approach also improves on the recent layer sampling method of \textsc{DeePlex}
in that the unsampled layers do not need to be trained, enabling further
increases in efficiency.We present experimental results on both synthetic and
real-world scenarios that demonstrate the practical effectiveness of our
proposed approach.</p>
  </details>
</details>
<details>
  <summary>68. <b>标题：Conformal prediction for the design problem</b></summary>
  <p><b>编号</b>：[185]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03613</p>
  <p><b>作者</b>：Clara Fannjiang,  Stephen Bates,  Anastasios Angelopoulos,  Jennifer Listgarten,  Michael I. Jordan</p>
  <p><b>备注</b>：32 pages, 8 figures</p>
  <p><b>关键词</b>：designed protein using several real data sets, since validating designed sequences, propose new sequences believed, exhibit higher property values, designed sequences --</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In many real-world deployments of machine learning, we use a prediction
algorithm to choose what data to test next. For example, in the protein design
problem, we have a regression model that predicts some real-valued property of
a protein sequence, which we use to propose new sequences believed to exhibit
higher property values than observed in the training data. Since validating
designed sequences in the wet lab is typically costly, it is important to know
how much we can trust the model's predictions. In such settings, however, there
is a distinct type of distribution shift between the training and test data:
one where the training and test data are statistically dependent, as the latter
is chosen based on the former. Consequently, the model's error on the test data
-- that is, the designed sequences -- has some non-trivial relationship with
its error on the training data. Herein, we introduce a method to quantify
predictive uncertainty in such settings. We do so by constructing confidence
sets for predictions that account for the dependence between the training and
test data. The confidence sets we construct have finite-sample guarantees that
hold for any prediction algorithm, even when a trained model chooses the
test-time input distribution. As a motivating use case, we demonstrate how our
method quantifies uncertainty for the predicted fitness of designed protein
using several real data sets.</p>
  </details>
</details>
<details>
  <summary>69. <b>标题：HistBERT: A Pre-trained Language Model for Diachronic Lexical Semantic  Analysis</b></summary>
  <p><b>编号</b>：[186]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03612</p>
  <p><b>作者</b>：Wenjun Qiu,  Yang Xu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：historical corpus data improves diachronic semantic analysis, various natural language processing tasks including, study historical semantic change, concern historical semantic change, diachronic semantic analysis</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Contextualized word embeddings have demonstrated state-of-the-art performance
in various natural language processing tasks including those that concern
historical semantic change. However, language models such as BERT was trained
primarily on contemporary corpus data. To investigate whether training on
historical corpus data improves diachronic semantic analysis, we present a
pre-trained BERT-based language model, HistBERT, trained on the balanced Corpus
of Historical American English. We examine the effectiveness of our approach by
comparing the performance of the original BERT and that of HistBERT, and we
report promising results in word similarity and semantic shift analysis. Our
work suggests that the effectiveness of contextual embeddings in diachronic
semantic analysis is dependent on the temporal profile of the input text and
care should be taken in applying this methodology to study historical semantic
change.</p>
  </details>
</details>
<details>
  <summary>70. <b>标题：Backdoor Detection in Reinforcement Learning</b></summary>
  <p><b>编号</b>：[189]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03609</p>
  <p><b>作者</b>：Junfeng Guo,  Ang Li,  Cong Liu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：trojan agents across various types, also trigger low performance, find approximate trigger actions, reinforcement learning solution trojanseeker, backdoor trigger actions</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>While the real world application of reinforcement learning (RL) is becoming
popular, the safety concern and the robustness of an RL system require more
attention. A recent work reveals that, in a multi-agent RL environment,
backdoor trigger actions can be injected into a victim agent (a.k.a. trojan
agent), which can result in a catastrophic failure as soon as it sees the
backdoor trigger action. We propose the problem of RL Backdoor Detection,
aiming to address this safety vulnerability. An interesting observation we drew
from extensive empirical studies is a trigger smoothness property where normal
actions similar to the backdoor trigger actions can also trigger low
performance of the trojan agent. Inspired by this observation, we propose a
reinforcement learning solution TrojanSeeker to find approximate trigger
actions for the trojan agents, and further propose an efficient approach to
mitigate the trojan agents based on machine unlearning. Experiments show that
our approach can correctly distinguish and mitigate all the trojan agents
across various types of agents and environments.</p>
  </details>
</details>
<details>
  <summary>71. <b>标题：Penalizing Gradient Norm for Efficiently Improving Generalization in  Deep Learning</b></summary>
  <p><b>编号</b>：[191]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03599</p>
  <p><b>作者</b>：Yang Zhao,  Hao Zhang,  Xiuyuan Hu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：optimizers towards finding flat minima, method could give new state, loss function could help lead, severely overparameterized networks nowadays, train deep neural networks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>How to train deep neural networks (DNNs) to generalize well is a central
concern in deep learning, especially for severely overparameterized networks
nowadays. In this paper, we propose an effective method to improve the model
generalization by additionally penalizing the gradient norm of loss function
during optimization. We demonstrate that confining the gradient norm of loss
function could help lead the optimizers towards finding flat minima. We
leverage the first-order approximation to efficiently implement the
corresponding gradient to fit well in the gradient descent framework. In our
experiments, we confirm that when using our methods, generalization performance
of various models could be improved on different datasets. Also, we show that
the recent sharpness-aware minimization method \cite{DBLP:conf/iclr/ForetKMN21}
is a special, but not the best, case of our method, where the best case of our
method could give new state-of-art performance on these tasks.</p>
  </details>
</details>
<details>
  <summary>72. <b>标题：Local Explanations for Reinforcement Learning</b></summary>
  <p><b>编号</b>：[192]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03597</p>
  <p><b>作者</b>：Ronny Luss,  Amit Dhurandhar,  Miao Liu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：efficient high quality greedy selection, carefully conducted user study illustrate, received much less attention, explaining deep reinforcement learning, expert policy dynamics rather</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Many works in explainable AI have focused on explaining black-box
classification models. Explaining deep reinforcement learning (RL) policies in
a manner that could be understood by domain users has received much less
attention. In this paper, we propose a novel perspective to understanding RL
policies based on identifying important states from automatically learned
meta-states. The key conceptual difference between our approach and many
previous ones is that we form meta-states based on locality governed by the
expert policy dynamics rather than based on similarity of actions, and that we
do not assume any particular knowledge of the underlying topology of the state
space. Theoretically, we show that our algorithm to find meta-states converges
and the objective that selects important states from each meta-state is
submodular leading to efficient high quality greedy selection. Experiments on
four domains (four rooms, door-key, minipacman, and pong) and a carefully
conducted user study illustrate that our perspective leads to better
understanding of the policy. We conjecture that this is a result of our
meta-states being more intuitive in that the corresponding important states are
strong indicators of tractable intermediate goals that are easier for humans to
interpret and follow.</p>
  </details>
</details>
<details>
  <summary>73. <b>标题：Nonmyopic Multiclass Active Search for Diverse Discovery</b></summary>
  <p><b>编号</b>：[194]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03593</p>
  <p><b>作者</b>：Quan Nguyen,  Roman Garnett</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：existing active search policies either assume, encourage diversity via simple heuristics, label diversity among discoveries via, superior empirical performance across, diverse discoveries offer</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Active search is a setting in adaptive experimental design where we aim to
uncover members of rare, valuable class(es) subject to a budget constraint. An
important consideration in this problem is diversity among the discovered
targets -- in many applications, diverse discoveries offer more insight and may
be preferable in downstream tasks. However, most existing active search
policies either assume that all targets belong to a common positive class or
encourage diversity via simple heuristics. We present a novel formulation of
active search with multiple target classes, characterized by a utility function
that naturally induces a preference for label diversity among discoveries via a
diminishing returns mechanism. We then study this problem under the Bayesian
lens and prove a hardness result for approximating the optimal policy. Finally,
we propose an efficient, nonmyopic approximation to the optimal policy and
demonstrate its superior empirical performance across a wide variety of
experimental settings, including drug discovery.</p>
  </details>
</details>
<details>
  <summary>74. <b>标题：Fair SA: Sensitivity Analysis for Fairness in Face Recognition</b></summary>
  <p><b>编号</b>：[197]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03586</p>
  <p><b>作者</b>：Aparna R. Joshi,  Xavier Suau,  Nivedha Sivakumar,  Luca Zappella,  Nicholas Apostoloff</p>
  <p><b>备注</b>：8 pages, 5 figures, to be published in NeurIPS 2021 Workshop, Algorithmic Fairness through the Lens of Causality and Robustness</p>
  <p><b>关键词</b>：real world applications involving images affected, images captured across different attributes, high impact domains becomes ubiquitous, perturbations may affect subgroups differently, traditional summary statistics suggest</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As the use of deep learning in high impact domains becomes ubiquitous, it is
increasingly important to assess the resilience of models. One such high impact
domain is that of face recognition, with real world applications involving
images affected by various degradations, such as motion blur or high exposure.
Moreover, images captured across different attributes, such as gender and race,
can also challenge the robustness of a face recognition algorithm. While
traditional summary statistics suggest that the aggregate performance of face
recognition models has continued to improve, these metrics do not directly
measure the robustness or fairness of the models. Visual Psychophysics
Sensitivity Analysis (VPSA) [1] provides a way to pinpoint the individual
causes of failure by way of introducing incremental perturbations in the data.
However, perturbations may affect subgroups differently. In this paper, we
propose a new fairness evaluation based on robustness in the form of a generic
framework that extends VPSA. With this framework, we can analyze the ability of
a model to perform fairly for different subgroups of a population affected by
perturbations, and pinpoint the exact failure modes for a subgroup by measuring
targeted robustness. With the increasing focus on the fairness of models, we
use face recognition as an example application of our framework and propose to
compactly visualize the fairness analysis of a model via AUC matrices. We
analyze the performance of common face recognition models and empirically show
that certain subgroups are at a disadvantage when images are perturbed, thereby
uncovering trends that were not visible using the model's performance on
subgroups without perturbations.</p>
  </details>
</details>
<details>
  <summary>75. <b>标题：Convolutional Neural Networks on Graphs with Chebyshev Approximation,  Revisited</b></summary>
  <p><b>编号</b>：[199]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03580</p>
  <p><b>作者</b>：Mingguo He,  Zhewei Wei,  Ji-Rong Wen</p>
  <p><b>备注</b>：13 pages</p>
  <p><b>关键词</b>：learn arbitrary graph spectrum filters, chebnet approximating analytic filter functions, spectral convolution using chebyshev polynomials, supervised node classification tasks, bernstein bases also outperform</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Designing spectral convolutional networks is a challenging problem in graph
learning. ChebNet, one of the early attempts, approximates the spectral
convolution using Chebyshev polynomials. GCN simplifies ChebNet by utilizing
only the first two Chebyshev polynomials while still outperforming it on
real-world datasets. GPR-GNN and BernNet demonstrate that the Monomial and
Bernstein bases also outperform the Chebyshev basis in terms of learning the
spectral convolution. Such conclusions are counter-intuitive in the field of
approximation theory, where it is established that the Chebyshev polynomial
achieves the optimum convergent rate for approximating a function.
In this paper, we revisit the problem of approximating the spectral
convolution with Chebyshev polynomials. We show that ChebNet's inferior
performance is primarily due to illegal coefficients learnt by ChebNet
approximating analytic filter functions, which leads to over-fitting. We then
propose ChebNetII, a new GNN model based on Chebyshev interpolation, which
enhances the original Chebyshev polynomial approximation while reducing the
Runge phenomena. We conducted an extensive experimental study to demonstrate
that ChebNetII can learn arbitrary graph spectrum filters and achieve superior
performance in both full- and semi-supervised node classification tasks.</p>
  </details>
</details>
<details>
  <summary>76. <b>标题：Stop Oversampling for Class Imbalance Learning: A Critical Review</b></summary>
  <p><b>编号</b>：[200]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03579</p>
  <p><b>作者</b>：Ahmad B. Hassanat,  Ahmad S. Tarawneh,  Ghada A. Altarawneh</p>
  <p><b>备注</b>：19 pages, 5 figures, 4 tables, and more than 72 m=oversampling methods reviewed</p>
  <p><b>关键词</b>：oversampling methods studied generate minority samples, fictitious data may fail spectacularly, new oversampling evaluation system based, represent minority may result, synthesized samples may</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>For the last two decades, oversampling has been employed to overcome the
challenge of learning from imbalanced datasets. Many approaches to solving this
challenge have been offered in the literature. Oversampling, on the other hand,
is a concern. That is, models trained on fictitious data may fail spectacularly
when put to real-world problems. The fundamental difficulty with oversampling
approaches is that, given a real-life population, the synthesized samples may
not truly belong to the minority class. As a result, training a classifier on
these samples while pretending they represent minority may result in incorrect
predictions when the model is used in the real world. We analyzed a large
number of oversampling methods in this paper and devised a new oversampling
evaluation system based on hiding a number of majority examples and comparing
them to those generated by the oversampling process. Based on our evaluation
system, we ranked all these methods based on their incorrectly generated
examples for comparison. Our experiments using more than 70 oversampling
methods and three imbalanced real-world datasets reveal that all oversampling
methods studied generate minority samples that are most likely to be majority.
Given data and methods in hand, we argue that oversampling in its current forms
and methodologies is unreliable for learning from class imbalanced data and
should be avoided in real-world applications.</p>
  </details>
</details>
<details>
  <summary>77. <b>标题：Data driven design of optical resonators</b></summary>
  <p><b>编号</b>：[201]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03578</p>
  <p><b>作者</b>：Joeri Lenaerts,  Hannah Pinson,  Vincent Ginis</p>
  <p><b>备注</b>：85 pages, 68 figures, Master thesis in Physics and Astronomy</p>
  <p><b>关键词</b>：optical behavior using computational simulations, optimal design much faster compared, brute force approach quickly becomes, create optimal optical devices, brute force approach</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Optical devices lie at the heart of most of the technology we see around us.
When one actually wants to make such an optical device, one can predict its
optical behavior using computational simulations of Maxwell's equations. If one
then asks what the optimal design would be in order to obtain a certain optical
behavior, the only way to go further would be to try out all of the possible
designs and compute the electromagnetic spectrum they produce. When there are
many design parameters, this brute force approach quickly becomes too
computationally expensive. We therefore need other methods to create optimal
optical devices. An alternative to the brute force approach is inverse design.
In this paradigm, one starts from the desired optical response of a material
and then determines the design parameters that are needed to obtain this
optical response. There are many algorithms known in the literature that
implement this inverse design. Some of the best performing, recent approaches
are based on Deep Learning. The central idea is to train a neural network to
predict the optical response for given design parameters. Since neural networks
are completely differentiable, we can compute gradients of the response with
respect to the design parameters. We can use these gradients to update the
design parameters and get an optical response closer to the one we want. This
allows us to obtain an optimal design much faster compared to the brute force
approach. In my thesis, I use Deep Learning for the inverse design of the
Fabry-Pérot resonator. This system can be described fully analytically and is
therefore ideal to study.</p>
  </details>
</details>
<details>
  <summary>78. <b>标题：Integration of a machine learning model into a decision support tool to  predict absenteeism at work of prospective employees</b></summary>
  <p><b>编号</b>：[202]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03577</p>
  <p><b>作者</b>：Gopal Nath,  Antoine Harfouche,  Austin Coursey,  Krishna K. Saha,  Srikanth Prabhu,  Saptarshi Sengupta</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：based decision tool allows hiring managers, svm ), artificial neural networks, mlr ), support vector machines, hiring managers may lack experience, predict absenteeism among potential employees</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Purpose - Inefficient hiring may result in lower productivity and higher
training costs. Productivity losses caused by absenteeism at work cost U.S.
employers billions of dollars each year. Also, employers typically spend a
considerable amount of time managing employees who perform poorly. The purpose
of this study is to develop a decision support tool to predict absenteeism
among potential employees. Design/methodology/approach - We utilized a popular
open-access dataset. In order to categorize absenteeism classes, the data have
been preprocessed, and four methods of machine learning classification have
been applied: Multinomial Logistic Regression (MLR), Support Vector Machines
(SVM), Artificial Neural Networks (ANN), and Random Forests (RF). We selected
the best model, based on several validation scores, and compared its
performance against the existing model; we then integrated the best model into
our proposed web-based for hiring managers. Findings - A web-based decision
tool allows hiring managers to make more informed decisions before hiring a
potential employee, thus reducing time, financial loss and reducing the
probability of economic insolvency. Originality/value - In this paper, we
propose a model that is trained based on attributes that can be collected
during the hiring process. Furthermore, hiring managers may lack experience in
machine learning or do not have the time to spend developing machine learning
algorithms. Thus, we propose a web-based interactive tool that can be used
without prior knowledge of machine learning algorithms.</p>
  </details>
</details>
<details>
  <summary>79. <b>标题：Learnability Lock: Authorized Learnability Control Through Adversarial  Invertible Transformations</b></summary>
  <p><b>编号</b>：[203]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03576</p>
  <p><b>作者</b>：Weiqi Peng,  Jinghui Chen</p>
  <p><b>备注</b>：Accepted at ICLR 2022</p>
  <p><b>关键词</b>：proposed learnability lock leverages class, propose adversarial invertible transformation, train models normally using, deep learning benefits incredibly, slightly modify data samples</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Owing much to the revolution of information technology, the recent progress
of deep learning benefits incredibly from the vastly enhanced access to data
available in various digital formats. However, in certain scenarios, people may
not want their data being used for training commercial models and thus studied
how to attack the learnability of deep learning models. Previous works on
learnability attack only consider the goal of preventing unauthorized
exploitation on the specific dataset but not the process of restoring the
learnability for authorized cases. To tackle this issue, this paper introduces
and investigates a new concept called "learnability lock" for controlling the
model's learnability on a specific dataset with a special key. In particular,
we propose adversarial invertible transformation, that can be viewed as a
mapping from image to image, to slightly modify data samples so that they
become "unlearnable" by machine learning models with negligible loss of visual
features. Meanwhile, one can unlock the learnability of the dataset and train
models normally using the corresponding key. The proposed learnability lock
leverages class-wise perturbation that applies a universal transformation
function on data samples of the same label. This ensures that the learnability
can be easily restored with a simple inverse transformation while remaining
difficult to be detected or reverse-engineered. We empirically demonstrate the
success and practicability of our method on visual classification tasks.</p>
  </details>
</details>
<details>
  <summary>80. <b>标题：Deep Reinforcement Learning Assisted Federated Learning Algorithm for  Data Management of IIoT</b></summary>
  <p><b>编号</b>：[204]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03575</p>
  <p><b>作者</b>：Peiying Zhang,  Chao Wang,  Chunxiao Jiang,  Zhu Han</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：iiot equipments generating massive amounts, user data every moment, apply deep reinforcement learning, iiot equipment selection process, manage iiot equipment data</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The continuous expanded scale of the industrial Internet of Things (IIoT)
leads to IIoT equipments generating massive amounts of user data every moment.
According to the different requirement of end users, these data usually have
high heterogeneity and privacy, while most of users are reluctant to expose
them to the public view. How to manage these time series data in an efficient
and safe way in the field of IIoT is still an open issue, such that it has
attracted extensive attention from academia and industry. As a new machine
learning (ML) paradigm, federated learning (FL) has great advantages in
training heterogeneous and private data. This paper studies the FL technology
applications to manage IIoT equipment data in wireless network environments. In
order to increase the model aggregation rate and reduce communication costs, we
apply deep reinforcement learning (DRL) to IIoT equipment selection process,
specifically to select those IIoT equipment nodes with accurate models.
Therefore, we propose a FL algorithm assisted by DRL, which can take into
account the privacy and efficiency of data training of IIoT equipment. By
analyzing the data characteristics of IIoT equipments, we use MNIST, fashion
MNIST and CIFAR-10 data sets to represent the data generated by IIoT. During
the experiment, we employ the deep neural network (DNN) model to train the
data, and experimental results show that the accuracy can reach more than 97\%,
which corroborates the effectiveness of the proposed algorithm.</p>
  </details>
</details>
<details>
  <summary>81. <b>标题：Structured Prediction Problem Archive</b></summary>
  <p><b>编号</b>：[205]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03574</p>
  <p><b>作者</b>：Paul Swoboda,  Andrea Hornakova,  Paul Roetzer,  Ahmed Abbas</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：problem characteristics including size, provide archival links, facilitate algorithm development, established works easier, structured prediction problems</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Structured prediction problems are one of the fundamental tools in machine
learning. In order to facilitate algorithm development for their numerical
solution, we collect in one place a large number of datasets in easy to read
formats for a diverse set of problem classes. We provide archival links to
datasets, description of the considered problems and problem formats, and a
short summary of problem characteristics including size, number of instances
etc. For reference we also give a non-exhaustive selection of algorithms
proposed in the literature for their solution. We hope that this central
repository will make benchmarking and comparison to established works easier.
We welcome submission of interesting new datasets and algorithms for inclusion
in our archive.</p>
  </details>
</details>
<details>
  <summary>82. <b>标题：Evaluating Robustness of Cooperative MARL: A Model-based Approach</b></summary>
  <p><b>编号</b>：[211]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03558</p>
  <p><b>作者</b>：Nhan H. Pham,  Lam M. Nguyen,  Jie Chen,  Hoang Thanh Lam,  Subhro Das,  Tsui-Wei Weng</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：craft stronger adversarial state perturbations, develop even stronger adversarial attack, lower total team rewards, based attack consistently outperforms, agent mujoco benchmarks illustrate</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In recent years, a proliferation of methods were developed for cooperative
multi-agent reinforcement learning (c-MARL). However, the robustness of c-MARL
agents against adversarial attacks has been rarely explored. In this paper, we
propose to evaluate the robustness of c-MARL agents via a model-based approach.
Our proposed formulation can craft stronger adversarial state perturbations of
c-MARL agents(s) to lower total team rewards more than existing model-free
approaches. In addition, we propose the first victim-agent selection strategy
which allows us to develop even stronger adversarial attack. Numerical
experiments on multi-agent MuJoCo benchmarks illustrate the advantage of our
approach over other baselines. The proposed model-based attack consistently
outperforms other baselines in all tested environments.</p>
  </details>
</details>
<details>
  <summary>83. <b>标题：data2vec: A General Framework for Self-supervised Learning in Speech,  Vision and Language</b></summary>
  <p><b>编号</b>：[212]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03555</p>
  <p><b>作者</b>：Alexei Baevski,  Wei-Ning Hsu,  Qiantong Xu,  Arun Babu,  Jiatao Gu,  Michael Auli</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：data2vec predicts contextualized latent representations, natural language understanding demonstrate, full input data based, predict latent representations, standard transformer architecture</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>While the general idea of self-supervised learning is identical across
modalities, the actual algorithms and objectives differ widely because they
were developed with a single modality in mind. To get us closer to general
self-supervised learning, we present data2vec, a framework that uses the same
learning method for either speech, NLP or computer vision. The core idea is to
predict latent representations of the full input data based on a masked view of
the input in a self-distillation setup using a standard Transformer
architecture. Instead of predicting modality-specific targets such as words,
visual tokens or units of human speech which are local in nature, data2vec
predicts contextualized latent representations that contain information from
the entire input. Experiments on the major benchmarks of speech recognition,
image classification, and natural language understanding demonstrate a new
state of the art or competitive performance to predominant approaches.</p>
  </details>
</details>
<details>
  <summary>84. <b>标题：On Continuous Integration / Continuous Delivery for Automated Deployment  of Machine Learning Models using MLOps</b></summary>
  <p><b>编号</b>：[215]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03541</p>
  <p><b>作者</b>：Satvik Garg,  Pradyumn Pundir,  Geetanjali Rathee,  P.K. Gupta,  Somya Garg,  Saransh Ahlawat</p>
  <p><b>备注</b>：Paper Accepted in AIKE 2021 : IEEE Artificial Intelligence & Knowledge Engineering 2021. The final version of this paper will appear in the conference proceedings</p>
  <p><b>关键词</b>：may guide future study, includes machine learning operations, open exploration issues, machine learning lifecycle, machine learning frameworks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Model deployment in machine learning has emerged as an intriguing field of
research in recent years. It is comparable to the procedure defined for
conventional software development. Continuous Integration and Continuous
Delivery (CI/CD) have been shown to smooth down software advancement and speed
up businesses when used in conjunction with development and operations
(DevOps). Using CI/CD pipelines in an application that includes Machine
Learning Operations (MLOps) components, on the other hand, has difficult
difficulties, and pioneers in the area solve them by using unique tools, which
is typically provided by cloud providers. This research provides a more
in-depth look at the machine learning lifecycle and the key distinctions
between DevOps and MLOps. In the MLOps approach, we discuss tools and
approaches for executing the CI/CD pipeline of machine learning frameworks.
Following that, we take a deep look into push and pull-based deployments in
Github Operations (GitOps). Open exploration issues are also identified and
added, which may guide future study.</p>
  </details>
</details>
<details>
  <summary>85. <b>标题：Structured Time Series Prediction without Structural Prior</b></summary>
  <p><b>编号</b>：[217]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03539</p>
  <p><b>作者</b>：Darko Drakulic,  Jean-Marc Andreoli</p>
  <p><b>备注</b>：13 pages, 6 figures</p>
  <p><b>关键词</b>：may even become detrimental, since data already contains, several neural network models, well studied problem, econometry etc .).</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Time series prediction is a widespread and well studied problem with
applications in many domains (medical, geoscience, network analysis, finance,
econometry etc.). In the case of multivariate time series, the key to good
performances is to properly capture the dependencies between the variates.
Often, these variates are structured, i.e. they are localised in an abstract
space, usually representing an aspect of the physical world, and prediction
amounts to a form of diffusion of the information across that space over time.
Several neural network models of diffusion have been proposed in the
literature. However, most of the existing proposals rely on some a priori
knowledge on the structure of the space, usually in the form of a graph
weighing the pairwise diffusion capacity of its points. We argue that this
piece of information can often be dispensed with, since data already contains
the diffusion capacity information, and in a more reliable form than that
obtained from the usually largely hand-crafted graphs. We propose instead a
fully data-driven model which does not rely on such a graph, nor any other
prior structural information. We conduct a first set of experiments to measure
the impact on performance of a structural prior, as used in baseline models,
and show that, except at very low data levels, it remains negligible, and
beyond a threshold, it may even become detrimental. We then investigate,
through a second set of experiments, the capacity of our model in two respects:
treatment of missing data and domain adaptation.</p>
  </details>
</details>
<details>
  <summary>86. <b>标题：Noise Regularizes Over-parameterized Rank One Matrix Recovery, Provably</b></summary>
  <p><b>编号</b>：[218]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03535</p>
  <p><b>作者</b>：Tianyi Liu,  Yan Li,  Enlu Zhou,  Tuo Zhao</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：randomly perturbed gradient descent algorithm using, gradient descent without random perturbation, xx ^\ top $,, square loss function, result partially justifies</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We investigate the role of noise in optimization algorithms for learning
over-parameterized models. Specifically, we consider the recovery of a rank one
matrix $Y^*\in R^{d\times d}$ from a noisy observation $Y$ using an
over-parameterization model. We parameterize the rank one matrix $Y^*$ by
$XX^\top$, where $X\in R^{d\times d}$. We then show that under mild conditions,
the estimator, obtained by the randomly perturbed gradient descent algorithm
using the square loss function, attains a mean square error of $O(\sigma^2/d)$,
where $\sigma^2$ is the variance of the observational noise. In contrast, the
estimator obtained by gradient descent without random perturbation only attains
a mean square error of $O(\sigma^2)$. Our result partially justifies the
implicit regularization effect of noise when learning over-parameterized
models, and provides new understanding of training over-parameterized neural
networks.</p>
  </details>
</details>
<details>
  <summary>87. <b>标题：TACTiS: Transformer-Attentional Copulas for Time Series</b></summary>
  <p><b>编号</b>：[220]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03528</p>
  <p><b>作者</b>：Alexandre Drouin,  Étienne Marcotte,  Nicolas Chapados</p>
  <p><b>备注</b>：27 pages, 15 figures</p>
  <p><b>关键词</b>：estimates joint distributions using, dimensional multivariate time series, joint predictive distribution, quantify predictive uncertainty, uniformly sampled data</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The estimation of time-varying quantities is a fundamental component of
decision making in fields such as healthcare and finance. However, the
practical utility of such estimates is limited by how accurately they quantify
predictive uncertainty. In this work, we address the problem of estimating the
joint predictive distribution of high-dimensional multivariate time series. We
propose a versatile method, based on the transformer architecture, that
estimates joint distributions using an attention-based decoder that provably
learns to mimic the properties of non-parametric copulas. The resulting model
has several desirable properties: it can scale to hundreds of time series,
supports both forecasting and interpolation, can handle unaligned and
non-uniformly sampled data, and can seamlessly adapt to missing data during
training. We demonstrate these properties empirically and show that our model
produces state-of-the-art predictions on several real-world datasets.</p>
  </details>
</details>
<details>
  <summary>88. <b>标题：Finite-Sum Optimization: A New Perspective for Convergence to a Global  Solution</b></summary>
  <p><b>编号</b>：[222]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03524</p>
  <p><b>作者</b>：Lam M. Nguyen,  Trang H. Tran,  Marten van Dijk</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：minimum using $\ mathcal {\ tilde, }}( 1 /\ varepsilon, using bounded style assumptions, many machine learning tasks, 3 )$ gradient computations</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep neural networks (DNNs) have shown great success in many machine learning
tasks. Their training is challenging since the loss surface of the network
architecture is generally non-convex, or even non-smooth. How and under what
assumptions is guaranteed convergence to a \textit{global} minimum possible? We
propose a reformulation of the minimization problem allowing for a new
recursive algorithmic framework. By using bounded style assumptions, we prove
convergence to an $\varepsilon$-(global) minimum using
$\mathcal{\tilde{O}}(1/\varepsilon^3)$ gradient computations. Our theoretical
foundation motivates further study, implementation, and optimization of the new
algorithmic framework and further investigation of its non-standard bounded
style assumptions. This new direction broadens our understanding of why and
under what circumstances training of a DNN converges to a global minimum.</p>
  </details>
</details>
<details>
  <summary>89. <b>标题：Online Optimization with Untrusted Predictions</b></summary>
  <p><b>编号</b>：[224]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03519</p>
  <p><b>作者</b>：Daan Rutten,  Nico Christianson,  Debankur Mukherjee,  Adam Wierman</p>
  <p><b>备注</b>：35 pages, 3 figures</p>
  <p><b>关键词</b>：2 ^{\ tilde {\ omega }( 1 /(\ alpha, 2 ^{\ tilde {\ mathcal, decision maker must sequentially choose points, $( 1 +\ delta )$- competitive, globally $\ alpha $- polyhedral</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We examine the problem of online optimization, where a decision maker must
sequentially choose points in a general metric space to minimize the sum of
per-round, non-convex hitting costs and the costs of switching decisions
between rounds. The decision maker has access to a black-box oracle, such as a
machine learning model, that provides untrusted and potentially inaccurate
predictions of the optimal decision in each round. The goal of the decision
maker is to exploit the predictions if they are accurate, while guaranteeing
performance that is not much worse than the hindsight optimal sequence of
decisions, even when predictions are inaccurate. We impose the standard
assumption that hitting costs are globally $\alpha$-polyhedral. We propose a
novel algorithm, Adaptive Online Switching (AOS), and prove that, for any
desired $\delta > 0$, it is $(1+2\delta)$-competitive if predictions are
perfect, while also maintaining a uniformly bounded competitive ratio of
$2^{\tilde{\mathcal{O}}(1/(\alpha \delta))}$ even when predictions are
adversarial. Further, we prove that this trade-off is necessary and nearly
optimal in the sense that any deterministic algorithm which is
$(1+\delta)$-competitive if predictions are perfect must be at least
$2^{\tilde{\Omega}(1/(\alpha \delta))}$-competitive when predictions are
inaccurate.</p>
  </details>
</details>
<details>
  <summary>90. <b>标题：Maximizing Audio Event Detection Model Performance on Small Datasets  Through Knowledge Transfer, Data Augmentation, And Pretraining: An Ablation  Study</b></summary>
  <p><b>编号</b>：[225]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03514</p>
  <p><b>作者</b>：Daniel Tompkins,  Kshitiz Kumar,  Jian Wu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：fly data augmentation pipeline, xception model reaches state, smaller xception model, audio event detection, nears sota performance</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>An Xception model reaches state-of-the-art (SOTA) accuracy on the ESC-50
dataset for audio event detection through knowledge transfer from ImageNet
weights, pretraining on AudioSet, and an on-the-fly data augmentation pipeline.
This paper presents an ablation study that analyzes which components contribute
to the boost in performance and training time. A smaller Xception model is also
presented which nears SOTA performance with almost a third of the parameters.</p>
  </details>
</details>
<details>
  <summary>91. <b>标题：DeepStability: A Study of Unstable Numerical Methods and Their Solutions  in Deep Learning</b></summary>
  <p><b>编号</b>：[229]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03493</p>
  <p><b>作者</b>：E. Kloberdanz,  K. G. Kloberdanz,  W. Le</p>
  <p><b>备注</b>：to be published in ICSE (2022)</p>
  <p><b>关键词</b>：study two mature dl libraries pytorch, designing numerically stable algorithm implementations, fix numerically unstable algorithm implementations, different numerical stability properties, identifying unstable numerical methods</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep learning (DL) has become an integral part of solutions to various
important problems, which is why ensuring the quality of DL systems is
essential. One of the challenges of achieving reliability and robustness of DL
software is to ensure that algorithm implementations are numerically stable. DL
algorithms require a large amount and a wide variety of numerical computations.
A naive implementation of numerical computation can lead to errors that may
result in incorrect or inaccurate learning and results. A numerical algorithm
or a mathematical formula can have several implementations that are
mathematically equivalent, but have different numerical stability properties.
Designing numerically stable algorithm implementations is challenging, because
it requires an interdisciplinary knowledge of software engineering, DL, and
numerical analysis. In this paper, we study two mature DL libraries PyTorch and
Tensorflow with the goal of identifying unstable numerical methods and their
solutions. Specifically, we investigate which DL algorithms are numerically
unstable and conduct an in-depth analysis of the root cause, manifestation, and
patches to numerical instabilities. Based on these findings, we launch, the
first database of numerical stability issues and solutions in DL. Our findings
and provide future references to developers and tool builders to prevent,
detect, localize and fix numerically unstable algorithm implementations. To
demonstrate that, using {\it DeepStability} we have located numerical stability
issues in Tensorflow, and submitted a fix which has been accepted and merged
in.</p>
  </details>
</details>
<details>
  <summary>92. <b>标题：Targeted-BEHRT: Deep learning for observational causal inference on  longitudinal electronic health records</b></summary>
  <p><b>编号</b>：[232]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03487</p>
  <p><b>作者</b>：Shishir Rao,  Mohammad Mamouei,  Gholamreza Salimi-Khorshidi,  Yikuan Li,  Rema Ramakrishnan,  Abdelaali Hassaine,  Dexter Canoy,  Kazem Rahimi</p>
  <p><b>备注</b>：This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible</p>
  <p><b>关键词</b>：least sum absolute error, comprehensive electronic health records, deliver unconfounded causal conclusions, estimate average risk ratio, established null causal association</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Observational causal inference is useful for decision making in medicine when
randomized clinical trials (RCT) are infeasible or non generalizable. However,
traditional approaches fail to deliver unconfounded causal conclusions in
practice. The rise of "doubly robust" non-parametric tools coupled with the
growth of deep learning for capturing rich representations of multimodal data,
offers a unique opportunity to develop and test such models for causal
inference on comprehensive electronic health records (EHR). In this paper, we
investigate causal modelling of an RCT-established null causal association: the
effect of antihypertensive use on incident cancer risk. We develop a dataset
for our observational study and a Transformer-based model, Targeted BEHRT
coupled with doubly robust estimation, we estimate average risk ratio (RR). We
compare our model to benchmark statistical and deep learning models for causal
inference in multiple experiments on semi-synthetic derivations of our dataset
with various types and intensities of confounding. In order to further test the
reliability of our approach, we test our model on situations of limited data.
We find that our model provides more accurate estimates of RR (least sum
absolute error from ground truth) compared to benchmarks for risk ratio
estimation on high-dimensional EHR across experiments. Finally, we apply our
model to investigate the original case study: antihypertensives' effect on
cancer and demonstrate that our model generally captures the validated null
association.</p>
  </details>
</details>
<details>
  <summary>93. <b>标题：Optimizing Warfarin Dosing using Deep Reinforcement Learning</b></summary>
  <p><b>编号</b>：[233]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03486</p>
  <p><b>作者</b>：Sadjad Anzabi Zadeh (1),  W. Nick Street (1),  Barrett W. Thomas (1) ((1) The University of Iowa Tippie College of Business)</p>
  <p><b>备注</b>：submitted to Journal of Biomedical Informatics</p>
  <p><b>关键词</b>：relatively small sample sizes, clinically accepted dosing protocols, virtual test patients shows, widely used anticoagulant, since slight overdosing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Warfarin is a widely used anticoagulant, and has a narrow therapeutic range.
Dosing of warfarin should be individualized, since slight overdosing or
underdosing can have catastrophic or even fatal consequences. Despite much
research on warfarin dosing, current dosing protocols do not live up to
expectations, especially for patients sensitive to warfarin. We propose a deep
reinforcement learning-based dosing model for warfarin. To overcome the issue
of relatively small sample sizes in dosing trials, we use a Pharmacokinetic/
Pharmacodynamic (PK/PD) model of warfarin to simulate dose-responses of virtual
patients. Applying the proposed algorithm on virtual test patients shows that
this model outperforms a set of clinically accepted dosing protocols by a wide
margin.</p>
  </details>
</details>
<details>
  <summary>94. <b>标题：Self-supervised Speaker Recognition Training Using Human-Machine  Dialogues</b></summary>
  <p><b>编号</b>：[234]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03484</p>
  <p><b>作者</b>：Metehan Cekic,  Ruirui Li,  Zeya Chen,  Yuguang Yang,  Andreas Stolcke,  Upamanyu Madhow</p>
  <p><b>备注</b>：5 pages, 2 figures</p>
  <p><b>关键词</b>：proposed method provides significant performance improvements, multiple speakers may speak, enables important downstream applications, also provides valuable information, rejection mechanism yields 27</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Speaker recognition, recognizing speaker identities based on voice alone,
enables important downstream applications, such as personalization and
authentication. Learning speaker representations, in the context of supervised
learning, heavily depends on both clean and sufficient labeled data, which is
always difficult to acquire. Noisy unlabeled data, on the other hand, also
provides valuable information that can be exploited using self-supervised
training methods. In this work, we investigate how to pretrain speaker
recognition models by leveraging dialogues between customers and smart-speaker
devices. However, the supervisory information in such dialogues is inherently
noisy, as multiple speakers may speak to a device in the course of the same
dialogue. To address this issue, we propose an effective rejection mechanism
that selectively learns from dialogues based on their acoustic homogeneity.
Both reconstruction-based and contrastive-learning-based self-supervised
methods are compared. Experiments demonstrate that the proposed method provides
significant performance improvements, superior to earlier work. Dialogue
pretraining when combined with the rejection mechanism yields 27.10% equal
error rate (EER) reduction in speaker recognition, compared to a model without
self-supervised pretraining.</p>
  </details>
</details>
<details>
  <summary>95. <b>标题：MAML and ANIL Provably Learn Representations</b></summary>
  <p><b>编号</b>：[235]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03483</p>
  <p><b>作者</b>：Liam Collins,  Aryan Mokhtari,  Sewoong Oh,  Sanjay Shakkottai</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：task linear representation learning setting, driving force causing maml, learning common representation among, anil learn expressive representations, underlying task diversity</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent empirical evidence has driven conventional wisdom to believe that
gradient-based meta-learning (GBML) methods perform well at few-shot learning
because they learn an expressive data representation that is shared across
tasks. However, the mechanics of GBML have remained largely mysterious from a
theoretical perspective. In this paper, we prove that two well-known GBML
methods, MAML and ANIL, as well as their first-order approximations, are
capable of learning common representation among a set of given tasks.
Specifically, in the well-known multi-task linear representation learning
setting, they are able to recover the ground-truth representation at an
exponentially fast rate. Moreover, our analysis illuminates that the driving
force causing MAML and ANIL to recover the underlying representation is that
they adapt the final layer of their model, which harnesses the underlying task
diversity to improve the representation in all directions of interest. To the
best of our knowledge, these are the first results to show that MAML and/or
ANIL learn expressive representations and to rigorously explain why they do so.</p>
  </details>
</details>
<details>
  <summary>96. <b>标题：PatClArC: Using Pattern Concept Activation Vectors for Noise-Robust  Model Debugging</b></summary>
  <p><b>编号</b>：[236]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03482</p>
  <p><b>作者</b>：Frederik Pahde,  Leander Weber,  Christopher J. Anders,  Wojciech Samek,  Sebastian Lapuschkin</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：learn undesired behavior based upon spurious correlations, propose pattern concept activation vectors, art machine learning models, corrects models using cavs, concept activation vectors</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>State-of-the-art machine learning models are commonly (pre-)trained on large
benchmark datasets. These often contain biases, artifacts, or errors that have
remained unnoticed in the data collection process and therefore fail in
representing the real world truthfully. This can cause models trained on these
datasets to learn undesired behavior based upon spurious correlations, e.g.,
the existence of a copyright tag in an image. Concept Activation Vectors (CAV)
have been proposed as a tool to model known concepts in latent space and have
been used for concept sensitivity testing and model correction. Specifically,
class artifact compensation (ClArC) corrects models using CAVs to represent
data artifacts in feature space linearly. Modeling CAVs with filters of linear
models, however, causes a significant influence of the noise portion within the
data, as recent work proposes the unsuitability of linear model filters to find
the signal direction in the input, which can be avoided by instead using
patterns. In this paper we propose Pattern Concept Activation Vectors (PCAV)
for noise-robust concept representations in latent space. We demonstrate that
pattern-based artifact modeling has beneficial effects on the application of
CAVs as a means to remove influence of confounding features from models via the
ClArC framework.</p>
  </details>
</details>
<details>
  <summary>97. <b>标题：A Ranking Game for Imitation Learning</b></summary>
  <p><b>编号</b>：[237]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03481</p>
  <p><b>作者</b>：Harshit Sikchi,  Akanksha Saran,  Wonjoon Goo,  Scott Niekum</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：satisfy pairwise performance rankings within, stackelberg game formulation allows us, using automatically generated rankings, solve previously unsolvable tasks, proposed method achieves state</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose a new framework for imitation learning - treating imitation as a
two-player ranking-based Stackelberg game between a $\textit{policy}$ and a
$\textit{reward}$ function. In this game, the reward agent learns to satisfy
pairwise performance rankings within a set of policies, while the policy agent
learns to maximize this reward. This game encompasses a large subset of both
inverse reinforcement learning (IRL) methods and methods which learn from
offline preferences. The Stackelberg game formulation allows us to use
optimization methods that take the game structure into account, leading to more
sample efficient and stable learning dynamics compared to existing IRL methods.
We theoretically analyze the requirements of the loss function used for ranking
policy performances to facilitate near-optimal imitation learning at
equilibrium. We use insights from this analysis to further increase sample
efficiency of the ranking game by using automatically generated rankings or
with offline annotated rankings. Our experiments show that the proposed method
achieves state-of-the-art sample efficiency and is able to solve previously
unsolvable tasks in the Learning from Observation (LfO) setting.</p>
  </details>
</details>
<details>
  <summary>98. <b>标题：Universal Spam Detection using Transfer Learning of BERT Model</b></summary>
  <p><b>编号</b>：[238]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03480</p>
  <p><b>作者</b>：Vijay Srinivas Tida,  Sonya Hsu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：novel universal spam detection model using pre, deep learning transformer models become important, overall accuracy reached 97 %,, universal spam detection model, spamtext message classification datasets</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep learning transformer models become important by training on text data
based on self-attention mechanisms. This manuscript demonstrated a novel
universal spam detection model using pre-trained Google's Bidirectional Encoder
Representations from Transformers (BERT) base uncased models with four datasets
by efficiently classifying ham or spam emails in real-time scenarios. Different
methods for Enron, Spamassain, Lingspam, and Spamtext message classification
datasets, were used to train models individually in which a single model was
obtained with acceptable performance on four datasets. The Universal Spam
Detection Model (USDM) was trained with four datasets and leveraged
hyperparameters from each model. The combined model was finetuned with the same
hyperparameters from these four models separately. When each model using its
corresponding dataset, an F1-score is at and above 0.9 in individual models. An
overall accuracy reached 97%, with an F1 score of 0.96. Research results and
implications were discussed.</p>
  </details>
</details>
<details>
  <summary>99. <b>标题：Random Gegenbauer Features for Scalable Kernel Methods</b></summary>
  <p><b>编号</b>：[240]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03474</p>
  <p><b>作者</b>：Insu Han,  Amir Zandieh,  Haim Avron</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：proposed features outperform recent kernel approximation methods, recently introduced neural tangent kernels, prove subspace embedding guarantees, approximately solving learning problems, propose efficient random features</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose efficient random features for approximating a new and rich class
of kernel functions that we refer to as Generalized Zonal Kernels (GZK). Our
proposed GZK family, generalizes the zonal kernels (i.e., dot-product kernels
on the unit sphere) by introducing radial factors in their Gegenbauer series
expansion, and includes a wide range of ubiquitous kernel functions such as the
entirety of dot-product kernels as well as the Gaussian and the recently
introduced Neural Tangent kernels. Interestingly, by exploiting the reproducing
property of the Gegenbauer polynomials, we can construct efficient random
features for the GZK family based on randomly oriented Gegenbauer kernels. We
prove subspace embedding guarantees for our Gegenbauer features which ensures
that our features can be used for approximately solving learning problems such
as kernel k-means clustering, kernel ridge regression, etc. Empirical results
show that our proposed features outperform recent kernel approximation methods.</p>
  </details>
</details>
<details>
  <summary>100. <b>标题：Locally Random P-adic Alloy Codes with ChannelCoding Theorems for  Distributed Coded Tensors</b></summary>
  <p><b>编号</b>：[242]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03469</p>
  <p><b>作者</b>：Pedro Soto,  Haibin Guan,  Jun Li</p>
  <p><b>备注</b>：6 pages, preprint</p>
  <p><b>关键词</b>：e ., locally random p, practical random code constructions, general framework encompasses many, distributed coded tensor operations, e ., multi</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Tensors, i.e., multi-linear functions, are a fundamental building block of
machine learning algorithms. In order to train on large data-sets, it is common
practice to distribute the computation amongst workers. However, stragglers and
other faults can severely impact the performance and overall training time. A
novel strategy to mitigate these failures is the use of coded computation. We
introduce a new metric for analysis called the typical recovery threshold,
which focuses on the most likely event and provide a novel construction of
distributed coded tensor operations which are optimal with this measure. We
show that our general framework encompasses many other computational schemes
and metrics as a special case. In particular, we prove that the recovery
threshold and the tensor rank can be recovered as a special case of the typical
recovery threshold when the probability of noise, i.e., a fault, is equal to
zero, thereby providing a noisy generalization of noiseless computation as a
serendipitous result. Far from being a purely theoretical construction, these
definitions lead us to practical random code constructions, i.e., locally
random p-adic alloy codes, which are optimal with respect to the measures. We
analyze experiments conducted on Amazon EC2 and establish that they are faster
and more numerically stable than many other benchmark computation schemes in
practice, as is predicted by theory.</p>
  </details>
</details>
<details>
  <summary>101. <b>标题：Reward-Respecting Subtasks for Model-Based Reinforcement Learning</b></summary>
  <p><b>编号</b>：[243]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03466</p>
  <p><b>作者</b>：Richard S. Sutton,  Marlos C. Machado,  G. Zacharias Holland,  David Szepesvari Finbarr Timbers,  Brian Tanner,  Adam White</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：unified using general value functions, policy using existing learning algorithms, reinforcement learning must include planning, reward respecting subtasks strongly constrain, thereby also provide</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>To achieve the ambitious goals of artificial intelligence, reinforcement
learning must include planning with a model of the world that is abstract in
state and time. Deep learning has made progress in state abstraction, but,
although the theory of time abstraction has been extensively developed based on
the options framework, in practice options have rarely been used in planning.
One reason for this is that the space of possible options is immense and the
methods previously proposed for option discovery do not take into account how
the option models will be used in planning. Options are typically discovered by
posing subsidiary tasks such as reaching a bottleneck state, or maximizing a
sensory signal other than the reward. Each subtask is solved to produce an
option, and then a model of the option is learned and made available to the
planning process. The subtasks proposed in most previous work ignore the reward
on the original problem, whereas we propose subtasks that use the original
reward plus a bonus based on a feature of the state at the time the option
stops. We show that options and option models obtained from such
reward-respecting subtasks are much more likely to be useful in planning and
can be learned online and off-policy using existing learning algorithms. Reward
respecting subtasks strongly constrain the space of options and thereby also
provide a partial solution to the problem of option discovery. Finally, we show
how the algorithms for learning values, policies, options, and models can be
unified using general value functions.</p>
  </details>
</details>
<details>
  <summary>102. <b>标题：On learning Whittle index policy for restless bandits with scalable  regret</b></summary>
  <p><b>编号</b>：[244]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03463</p>
  <p><b>作者</b>：Nima Akbarzadeh,  Aditya Mahajan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：}(\ cdot )$ notation hides logarithmic terms, learn good resource allocation, }( n ^{ 1, sampling based learning algorithm, whittle index policy</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Reinforcement learning is an attractive approach to learn good resource
allocation and scheduling policies based on data when the system model is
unknown. However, the cumulative regret of most RL algorithms scales as $\tilde
O(\mathsf{S} \sqrt{\mathsf{A} T})$, where $\mathsf{S}$ is the size of the state
space, $\mathsf{A}$ is the size of the action space, $T$ is the horizon, and
the $\tilde{O}(\cdot)$ notation hides logarithmic terms. Due to the linear
dependence on the size of the state space, these regret bounds are
prohibitively large for resource allocation and scheduling problems. In this
paper, we present a model-based RL algorithm for such problem which has
scalable regret. In particular, we consider a restless bandit model, and
propose a Thompson-sampling based learning algorithm which is tuned to the
underlying structure of the model. We present two characterizations of the
regret of the proposed algorithm with respect to the Whittle index policy.
First, we show that for a restless bandit with $n$ arms and at most $m$
activations at each time, the regret scales either as $\tilde{O}(mn\sqrt{T})$
or $\tilde{O}(n^2 \sqrt{T})$ depending on the reward model. Second, under an
additional technical assumption, we show that the regret scales as
$\tilde{O}(n^{1.5} \sqrt{T})$. We present numerical examples to illustrate the
salient features of the algorithm.</p>
  </details>
</details>
<details>
  <summary>103. <b>标题：Deletion Inference, Reconstruction, and Compliance in Machine  (Un)Learning</b></summary>
  <p><b>编号</b>：[245]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03460</p>
  <p><b>作者</b>：Ji Gao,  Sanjam Garg,  Mohammad Mahmoody,  Prashant Nalini Vasudevan</p>
  <p><b>备注</b>：Full version of a paper appearing in the 22nd Privacy Enhancing Technologies Symposium (PETS 2022)</p>
  <p><b>关键词</b>：privacy attacks could potentially become, formally study privacy implications, meet new legal requirements, meet new legal requirements, many machine learning methods</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Privacy attacks on machine learning models aim to identify the data that is
used to train such models. Such attacks, traditionally, are studied on static
models that are trained once and are accessible by the adversary. Motivated to
meet new legal requirements, many machine learning methods are recently
extended to support machine unlearning, i.e., updating models as if certain
examples are removed from their training sets, and meet new legal requirements.
However, privacy attacks could potentially become more devastating in this new
setting, since an attacker could now access both the original model before
deletion and the new model after the deletion. In fact, the very act of
deletion might make the deleted record more vulnerable to privacy attacks.
Inspired by cryptographic definitions and the differential privacy framework,
we formally study privacy implications of machine unlearning. We formalize
(various forms of) deletion inference and deletion reconstruction attacks, in
which the adversary aims to either identify which record is deleted or to
reconstruct (perhaps part of) the deleted records. We then present successful
deletion inference and reconstruction attacks for a variety of machine learning
models and tasks such as classification, regression, and language models.
Finally, we show that our attacks would provably be precluded if the schemes
satisfy (variants of) Deletion Compliance (Garg, Goldwasser, and Vasudevan,
Eurocrypt' 20).</p>
  </details>
</details>
<details>
  <summary>104. <b>标题：Reinforcement learning for multi-item retrieval in the puzzle-based  storage system</b></summary>
  <p><b>编号</b>：[249]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03424</p>
  <p><b>作者</b>：Jing He,  Xinglu Liu,  Qiyao Duan,  Wai Kin Victor Chan,  Mingyao Qi</p>
  <p><b>备注</b>：32 pages, 13 figures, 5 tables, journal</p>
  <p><b>关键词</b>：general compact integer programming model, outperforms three related state, extensive numerical experiments demonstrate, dueling deep q network, deep reinforcement learning algorithm</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Nowadays, fast delivery services have created the need for high-density
warehouses. The puzzle-based storage system is a practical way to enhance the
storage density, however, facing difficulties in the retrieval process. In this
work, a deep reinforcement learning algorithm, specifically the Double&Dueling
Deep Q Network, is developed to solve the multi-item retrieval problem in the
system with general settings, where multiple desired items, escorts, and I/O
points are placed randomly. Additionally, we propose a general compact integer
programming model to evaluate the solution quality. Extensive numerical
experiments demonstrate that the reinforcement learning approach can yield
high-quality solutions and outperforms three related state-of-the-art heuristic
algorithms. Furthermore, a conversion algorithm and a decomposition framework
are proposed to handle simultaneous movement and large-scale instances
respectively, thus improving the applicability of the PBS system.</p>
  </details>
</details>
<details>
  <summary>105. <b>标题：Backdoor Defense via Decoupling the Training Process</b></summary>
  <p><b>编号</b>：[250]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03423</p>
  <p><b>作者</b>：Kunzhe Huang,  Yiming Li,  Baoyuan Wu,  Zhan Qin,  Kui Ren</p>
  <p><b>备注</b>：This work is accepted by the ICLR 2022. The first two authors contributed equally to this work. 25 pages</p>
  <p><b>关键词</b>：remaining fully connected layers via standard training, novel backdoor defense via decoupling, attackers embed hidden backdoors, attacked model behaves normally, end supervised training paradigm</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent studies have revealed that deep neural networks (DNNs) are vulnerable
to backdoor attacks, where attackers embed hidden backdoors in the DNN model by
poisoning a few training samples. The attacked model behaves normally on benign
samples, whereas its prediction will be maliciously changed when the backdoor
is activated. We reveal that poisoned samples tend to cluster together in the
feature space of the attacked DNN model, which is mostly due to the end-to-end
supervised training paradigm. Inspired by this observation, we propose a novel
backdoor defense via decoupling the original end-to-end training process into
three stages. Specifically, we first learn the backbone of a DNN model via
\emph{self-supervised learning} based on training samples without their labels.
The learned backbone will map samples with the same ground-truth label to
similar locations in the feature space. Then, we freeze the parameters of the
learned backbone and train the remaining fully connected layers via standard
training with all (labeled) training samples. Lastly, to further alleviate
side-effects of poisoned samples in the second stage, we remove labels of some
`low-credible' samples determined based on the learned model and conduct a
\emph{semi-supervised fine-tuning} of the whole model. Extensive experiments on
multiple benchmark datasets and DNN models verify that the proposed defense is
effective in reducing backdoor threats while preserving high accuracy in
predicting benign samples. Our code is available at
\url{this https URL}.</p>
  </details>
</details>
<details>
  <summary>106. <b>标题：Development of a deep learning platform for optimising sheet stamping  geometries subject to manufacturing constraints</b></summary>
  <p><b>编号</b>：[251]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03422</p>
  <p><b>作者</b>：Hamid Reza Attar,  Alistair Foster,  Nan Li</p>
  <p><b>备注</b>：44 pages, 35 figures</p>
  <p><b>关键词</b>：generator predicts continuous 3d signed distance fields, latest sheet stamping processes enable efficient manufacturing, complex shape structural components, optimising 3d component geometries, multiple geometric parameterisation schema</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The latest sheet stamping processes enable efficient manufacturing of complex
shape structural components that have high stiffness to weight ratios, but
these processes can introduce defects. To assist component design for stamping
processes, this paper presents a novel deep-learning-based platform for
optimising 3D component geometries. The platform adopts a non-parametric
modelling approach that is capable of optimising arbitrary geometries from
multiple geometric parameterisation schema. This approach features the
interaction of two neural networks: 1) a geometry generator and 2) a
manufacturing performance evaluator. The generator predicts continuous 3D
signed distance fields (SDFs) for geometries of different classes, and each SDF
is conditioned on a latent vector. The zero-level-set of each SDF implicitly
represents a generated geometry. Novel training strategies for the generator
are introduced and include a new loss function which is tailored for sheet
stamping applications. These strategies enable the differentiable generation of
high quality, large scale component geometries with tight local features for
the first time. The evaluator maps a 2D projection of these generated
geometries to their post-stamping physical (e.g., strain) distributions.
Manufacturing constraints are imposed based on these distributions and are used
to formulate a novel objective function for optimisation. A new gradient-based
optimisation technique is employed to iteratively update the latent vectors,
and therefore geometries, to minimise this objective function and thus meet the
manufacturing constraints. Case studies based on optimising box geometries
subject to a sheet thinning constraint for a hot stamping process are presented
and discussed. The results show that expressive geometric changes are
achievable, and that these changes are driven by stamping performance.</p>
  </details>
</details>
<details>
  <summary>107. <b>标题：Low-Rank Extragradient Method for Nonsmooth and Low-Rank Matrix  Optimization Problems</b></summary>
  <p><b>编号</b>：[254]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.04026</p>
  <p><b>作者</b>：Dan Garber,  Atara Kaplan</p>
  <p><b>备注</b>：Appeared in Conference on Neural Information Processing Systems (NeurIPS), 2021</p>
  <p><b>关键词</b>：nonsmooth matrix optimization problems capture many fundamental tasks, rank matrix recovery tasks, consider standard convex relaxations, extragradient method produces exactly, rank optimization problems</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Low-rank and nonsmooth matrix optimization problems capture many fundamental
tasks in statistics and machine learning. While significant progress has been
made in recent years in developing efficient methods for \textit{smooth}
low-rank optimization problems that avoid maintaining high-rank matrices and
computing expensive high-rank SVDs, advances for nonsmooth problems have been
slow paced.
In this paper we consider standard convex relaxations for such problems.
Mainly, we prove that under a natural \textit{generalized strict
complementarity} condition and under the relatively mild assumption that the
nonsmooth objective can be written as a maximum of smooth functions, the
\textit{extragradient method}, when initialized with a "warm-start" point,
converges to an optimal solution with rate $O(1/t)$ while requiring only two
\textit{low-rank} SVDs per iteration. We give a precise trade-off between the
rank of the SVDs required and the radius of the ball in which we need to
initialize the method. We support our theoretical results with empirical
experiments on several nonsmooth low-rank matrix recovery tasks, demonstrating
that using simple initializations, the extragradient method produces exactly
the same iterates when full-rank SVDs are replaced with SVDs of rank that
matches the rank of the (low-rank) ground-truth matrix to be recovered.</p>
  </details>
</details>
<details>
  <summary>108. <b>标题：Efficient Algorithms for High-Dimensional Convex Subspace Optimization  via Strict Complementarity</b></summary>
  <p><b>编号</b>：[255]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.04020</p>
  <p><b>作者</b>：Dan Garber,  Ron Fisher</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：start ", converges linearly, gradient orthogonal iteration },, k $- dimensional subspace, nonconvex projected gradient method, also establish similar results</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We consider optimization problems in which the goal is find a $k$-dimensional
subspace of $\reals^n$, $k<<n$, which minimizes a convex and smooth loss. such problemsgeneralize the fundamental task of principal component analysis (pca) to include robust sparse counterparts, logistic pca for binary data, among others. while this problem is not it admits natural algorithms with very efficient iterations memory requirements, highly desired in high-dimensional regimes however, arguing about their fast convergence global optimal solution difficult. on other hand, there exists simple relaxation optimum straightforward, however corresponding are when dimension large. work we present deterministic sufficient condition so that unique also original nonconvex problem. mainly, prove under condition, highly-efficient gradient method, refer as \textit{gradient orthogonal iteration}, initialized "warm-start", converges linearly establish similar results projected frank-wolfe method applied relaxation. conclude empirical evidence synthetic data demonstrate appeal our approach.< p>
  </n$,></p></details>
</details>
<details>
  <summary>109. <b>标题：Distribution Regression with Sliced Wasserstein Kernels</b></summary>
  <p><b>编号</b>：[258]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03926</p>
  <p><b>作者</b>：Dimitri Meunier,  Massimiliano Pontil,  Carlo Ciliberto</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：kernel mean embeddings implicitly hinge, kernel ridge regression estimator based, capture key geometrical relations, kernel mean embeddings, maximum mean discrepancy</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The problem of learning functions over spaces of probabilities - or
distribution regression - is gaining significant interest in the machine
learning community. A key challenge behind this problem is to identify a
suitable representation capturing all relevant properties of the underlying
functional mapping. A principled approach to distribution regression is
provided by kernel mean embeddings, which lifts kernel-induced similarity on
the input domain at the probability level. This strategy effectively tackles
the two-stage sampling nature of the problem, enabling one to derive estimators
with strong statistical guarantees, such as universal consistency and excess
risk bounds. However, kernel mean embeddings implicitly hinge on the maximum
mean discrepancy (MMD), a metric on probabilities, which may fail to capture
key geometrical relations between distributions. In contrast, optimal transport
(OT) metrics, are potentially more appealing, as documented by the recent
literature on the topic. In this work, we propose the first OT-based estimator
for distribution regression. We build on the Sliced Wasserstein distance to
obtain an OT-based representation. We study the theoretical properties of a
kernel ridge regression estimator based on such representation, for which we
prove universal consistency and excess risk bounds. Preliminary experiments
complement our theoretical findings by showing the effectiveness of the
proposed approach and compare it with MMD-based estimators.</p>
  </details>
</details>
<details>
  <summary>110. <b>标题：Unsupervised Source Separation via Self-Supervised Training</b></summary>
  <p><b>编号</b>：[264]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03875</p>
  <p><b>作者</b>：Ertuğ Karamatlı,  Serap Kırbız</p>
  <p><b>备注</b>：Submitted to IEEE Signal Processing Letters</p>
  <p><b>关键词</b>：second method cyclic mixture permutation invariant training, first method employs permutation invariant training, named mixture permutation invariant training, ground truth source signals, introduce two novel unsupervised</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We introduce two novel unsupervised (blind) source separation methods, which
involve self-supervised training from single-channel two-source speech mixtures
without any access to the ground truth source signals. Our first method employs
permutation invariant training (PIT) to separate artificially-generated
mixtures of the original mixtures back into the original mixtures, which we
named mixture permutation invariant training (MixPIT). We found this
challenging objective to be a valid proxy task for learning to separate the
underlying sources. We improve upon this first method by creating mixtures of
source estimates and employing PIT to separate these new mixtures in a cyclic
fashion. We named this second method cyclic mixture permutation invariant
training (MixCycle), where cyclic refers to the fact that we use the same model
to produce artificial mixtures and to learn from them continuously. We show
that MixPIT outperforms a common baseline (MixIT) on our small dataset
(SC09Mix), and they have comparable performance on a standard dataset
(LibriMix). Strikingly, we also show that MixCycle surpasses the performance of
supervised PIT by being data-efficient, thanks to its inherent data
augmentation mechanism. To the best of our knowledge, no other purely
unsupervised method is able to match or exceed the performance of supervised
training.</p>
  </details>
</details>
<details>
  <summary>111. <b>标题：FisrEbp: Enterprise Bankruptcy Prediction via Fusing its Intra-risk and  Spillover-Risk</b></summary>
  <p><b>编号</b>：[265]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03874</p>
  <p><b>作者</b>：Yu Zhao,  Shaopeng Wei,  Yu Guo,  Qing Yang,  Gang Kou</p>
  <p><b>备注</b>：11 pages, 7 figures</p>
  <p><b>关键词</b>：multiplex heterogeneous relations among enterprise knowledge graph, heterogeneous graph neural networks, model enterprise bankruptcy risk, hypergraph neural networks, smes bankruptcy prediction</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we propose to model enterprise bankruptcy risk by fusing its
intra-risk and spillover-risk. Under this framework, we propose a novel method
that is equipped with an LSTM-based intra-risk encoder and GNNs-based
spillover-risk encoder. Specifically, the intra-risk encoder is able to capture
enterprise intra-risk using the statistic correlated indicators from the basic
business information and litigation information. The spillover-risk encoder
consists of hypergraph neural networks and heterogeneous graph neural networks,
which aim to model spillover risk through two aspects, i.e. hyperedge and
multiplex heterogeneous relations among enterprise knowledge graph,
respectively. To evaluate the proposed model, we collect multi-sources SMEs
data and build a new dataset SMEsD, on which the experimental results
demonstrate the superiority of the proposed method. The dataset is expected to
become a significant benchmark dataset for SMEs bankruptcy prediction and
promote the development of financial risk study further.</p>
  </details>
</details>
<details>
  <summary>112. <b>标题：Learning to Predict Graphs with Fused Gromov-Wasserstein Barycenters</b></summary>
  <p><b>编号</b>：[267]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03813</p>
  <p><b>作者</b>：Luc Brogat-Motte,  Rémi Flamary,  Céline Brouard,  Juho Rousu,  Florence d'Alché-Buc</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：fgw barycenter whose weights depend, leveraging optimal transport tools, supervised labeled graph prediction, difficult metabolic identification problem, labeled graph space</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper introduces a novel and generic framework to solve the flagship
task of supervised labeled graph prediction by leveraging Optimal Transport
tools. We formulate the problem as regression with the Fused Gromov-Wasserstein
(FGW) loss and propose a predictive model relying on a FGW barycenter whose
weights depend on inputs. First we introduce a non-parametric estimator based
on kernel ridge regression for which theoretical results such as consistency
and excess risk bound are proved. Next we propose an interpretable parametric
model where the barycenter weights are modeled with a neural network and the
graphs on which the FGW barycenter is calculated are additionally learned.
Numerical experiments show the strength of the method and its ability to
interpolate in the labeled graph space on simulated data and on a difficult
metabolic identification problem where it can reach very good performance with
very little engineering.</p>
  </details>
</details>
<details>
  <summary>113. <b>标题：Deep learning fluid flow reconstruction around arbitrary two-dimensional  objects from sparse sensors using conformal mappings</b></summary>
  <p><b>编号</b>：[268]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03798</p>
  <p><b>作者</b>：Ali Girayhan Özbay,  Sylvain Laizet</p>
  <p><b>备注</b>：40 pages, 14 figures. Submitted to Physics of Fluids</p>
  <p><b>关键词</b>：64 objects randomly generated using bezier curves, handle fluid flows around different objects without, reconstructing fluid flows around different two, fluid flow around arbitrary objects, flow around 16 unseen objects</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The usage of deep neural networks (DNNs) for flow reconstruction (FR) tasks
from a limited number of sensors is attracting strong research interest, owing
to DNNs' ability to replicate very high dimensional relationships. Trained over
a single flow case for a given Reynolds number or over a reduced range of
Reynolds numbers, these models are unfortunately not able to handle fluid flows
around different objects without re-training. In this work, we propose a new
framework called Spatial Multi-Geometry FR (SMGFR) task, capable of
reconstructing fluid flows around different two-dimensional objects without
re-training, mapping the computational domain as an annulus. Different DNNs for
different sensor setups (where information about the flow is collected) are
trained with high-fidelity simulation data for a Reynolds number equal to
approximately $300$ for 64 objects randomly generated using Bezier curves. The
performance of the models and sensor setups are then assessed for the flow
around 16 unseen objects. It is shown that our mapping approach improves
percentage errors by up to 15\% in SMGFR when compared to a more conventional
approach where the models are trained on a Cartesian grid. Finally, the SMGFR
task is extended to predictions of fluid flow snapshots in the future,
introducing the Spatio-temporal MGFR (STMGFR) task. For this spatio-temporal
reconstruction task, a novel approach is developed involving splitting DNNs
into a spatial and a temporal component. Our results demonstrate that this
approach is able to reproduce, in time and in space, the main features of a
fluid flow around arbitrary objects.</p>
  </details>
</details>
<details>
  <summary>114. <b>标题：Particle Transformer for Jet Tagging</b></summary>
  <p><b>编号</b>：[269]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03772</p>
  <p><b>作者</b>：Huilin Qu,  Congqiao Li,  Sitian Qian</p>
  <p><b>备注</b>：12 pages, 3 figures</p>
  <p><b>关键词</b>：two widely adopted jet tagging benchmarks, critical yet challenging classification task, part achieves higher tagging performance, incorporating pairwise particle interactions, including several types unexplored</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Jet tagging is a critical yet challenging classification task in particle
physics. While deep learning has transformed jet tagging and significantly
improved performance, the lack of a large-scale public dataset impedes further
enhancement. In this work, we present JetClass, a new comprehensive dataset for
jet tagging. The JetClass dataset consists of 100 M jets, about two orders of
magnitude larger than existing public datasets. A total of 10 types of jets are
simulated, including several types unexplored for tagging so far. Based on the
large dataset, we propose a new Transformer-based architecture for jet tagging,
called Particle Transformer (ParT). By incorporating pairwise particle
interactions in the attention mechanism, ParT achieves higher tagging
performance than a plain Transformer and surpasses the previous
state-of-the-art, ParticleNet, by a large margin. The pre-trained ParT models,
once fine-tuned, also substantially enhance the performance on two widely
adopted jet tagging benchmarks.</p>
  </details>
</details>
<details>
  <summary>115. <b>标题：A Survey of Breast Cancer Screening Techniques: Thermography and  Electrical Impedance Tomography</b></summary>
  <p><b>编号</b>：[273]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03737</p>
  <p><b>作者</b>：Juan Zuluaga-Gomez,  N. Zerhouni,  Z. Al Masry,  C. Devalland,  C. Varnier</p>
  <p><b>备注</b>：Article published at: Journal of Medical Engineering & Technology (Volume 43, 2019 - Issue 5)</p>
  <p><b>关键词</b>：many countries still lack access, several machine learning techniques applied, parallel techniques like thermography, mixing several computational skills, breast cancer diagnosis going</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Breast cancer is a disease that threatens many women's life, thus, early and
accurate detection plays a key role in reducing the mortality rate. Mammography
stands as the reference technique for breast cancer screening; nevertheless,
many countries still lack access to mammograms due to economic, social, and
cultural issues. Last advances in computational tools, infrared cameras, and
devices for bio-impedance quantification allowed the development of parallel
techniques like thermography, infrared imaging, and electrical impedance
tomography, these being faster, reliable and cheaper. In the last decades,
these have been considered as complement procedures for breast cancer
diagnosis, where many studies concluded that false positive and false negative
rates are greatly reduced. This work aims to review the last breakthroughs
about the three above-mentioned techniques describing the benefits of mixing
several computational skills to obtain a better global performance. In
addition, we provide a comparison between several machine learning techniques
applied to breast cancer diagnosis going from logistic regression, decision
trees, and random forest to artificial, deep, and convolutional neural
networks. Finally, it is mentioned several recommendations for 3D breast
simulations, pre-processing techniques, biomedical devices in the research
field, prediction of tumor location and size.</p>
  </details>
</details>
<details>
  <summary>116. <b>标题：Accelerating Part-Scale Simulation in Liquid Metal Jet Additive  Manufacturing via Operator Learning</b></summary>
  <p><b>编号</b>：[277]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03665</p>
  <p><b>作者</b>：Søren Taverniers,  Svyatoslav Korneev,  Kyle M. Pietrzyk,  Morad Behandish</p>
  <p><b>备注</b>：Paper #25</p>
  <p><b>关键词</b>：lmj may include coupled incompressible fluid flow, quick inference capabilities often come, magnitude fewer data points, demand liquid metal jetting, achieving similar prediction error</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Predicting part quality for additive manufacturing (AM) processes requires
high-fidelity numerical simulation of partial differential equations (PDEs)
governing process multiphysics on a scale of minimum manufacturable features.
This makes part-scale predictions computationally demanding, especially when
they require many small-scale simulations. We consider drop-on-demand liquid
metal jetting (LMJ) as an illustrative example of such computational
complexity. A model describing droplet coalescence for LMJ may include coupled
incompressible fluid flow, heat transfer, and phase change equations.
Numerically solving these equations becomes prohibitively expensive when
simulating the build process for a full part consisting of thousands to
millions of droplets. Reduced-order models (ROMs) based on neural networks (NN)
or k-nearest neighbor (kNN) algorithms have been built to replace the original
physics-based solver and are computationally tractable for part-level
simulations. However, their quick inference capabilities often come at the
expense of accuracy, robustness, and generalizability. We apply an operator
learning (OL) approach to learn a mapping between initial and final states of
the droplet coalescence process for enabling rapid and accurate part-scale
build simulation. Preliminary results suggest that OL requires
order-of-magnitude fewer data points than a kNN approach and is generalizable
beyond the training set while achieving similar prediction error.</p>
  </details>
</details>
<details>
  <summary>117. <b>标题：On the Convergence of Gradient Extrapolation Methods for Unbalanced  Optimal Transport</b></summary>
  <p><b>编号</b>：[281]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03618</p>
  <p><b>作者</b>：Quang Minh Nguyen,  Hoang H. Nguyen,  Yi Zhou,  Lam M. Nguyen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：big (\ frac {\ tau n }{\ varepsilon }\ big, squared $\ ell_2 $- norm regularized uot objective, n )}{\ varepsilon }\ big )\ big )$, }\ big (\ tfrac {\ tau n, n }{\ varepsilon }\ big</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We study the Unbalanced Optimal Transport (UOT) between two measures of
possibly different masses with at most $n$ components, where marginal
constraints of the standard Optimal Transport (OT) are relaxed via
Kullback-Leibler divergence with regularization factor $\tau$. We propose a
novel algorithm based on Gradient Extrapolation Method (GEM-UOT) to find an
$\varepsilon$-approximate solution to the UOT problem in $O\big( \kappa n^2
\log\big(\frac{\tau n}{\varepsilon}\big) \big)$, where $\kappa$ is the
condition number depending on only the two input measures. Compared to the only
known complexity ${O}\big(\tfrac{\tau n^2 \log(n)}{\varepsilon}
\log\big(\tfrac{\log(n)}{\varepsilon}\big)\big)$ for solving the UOT problem
via the Sinkhorn algorithm, ours is better in $\varepsilon$ and lifts
Sinkhorn's linear dependence on $\tau$, which hindered its practicality to
approximate the standard OT via UOT. Our proof technique is based on a novel
dual formulation of the squared $\ell_2$-norm regularized UOT objective, which
is of independent interest and also leads to a new characterization of
approximation error between UOT and OT in terms of both the transportation plan
and transport distance. To this end, we further present an algorithm, based on
GEM-UOT with fine tuned $\tau$ and a post-process projection step, to find an
$\varepsilon$-approximate solution to the standard OT problem in $O\big( \kappa
n^2 \log\big(\frac{ n}{\varepsilon}\big) \big)$, which is a new complexity in
the literature of OT. Extensive experiments on synthetic and real datasets
validate our theories and demonstrate the favorable performance of our methods
in practice.</p>
  </details>
</details>
<details>
  <summary>118. <b>标题：Multi-Label Classification of Thoracic Diseases using Dense  Convolutional Network on Chest Radiographs</b></summary>
  <p><b>编号</b>：[284]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03583</p>
  <p><b>作者</b>：Dipkamal Bhusal,  Dr. Sanjeeb Prasad Panday</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：using dense convolutional neural network, ray images requires skilled manpower, identify different thoracic diseases, obtain high classification predictions, common medical diagnosis techniques</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Chest X-ray images are one of the most common medical diagnosis techniques to
identify different thoracic diseases. However, identification of pathologies in
X-ray images requires skilled manpower and are often cited as a time-consuming
task with varied level of interpretation, particularly in cases where the
identification of disease only by images is difficult for human eyes. With
recent achievements of deep learning in image classification, its application
in disease diagnosis has been widely explored. This research project presents a
multi-label disease diagnosis model of chest x-rays. Using Dense Convolutional
Neural Network (DenseNet), the diagnosis system was able to obtain high
classification predictions. The model obtained the highest AUC score of 0.896
for condition Cardiomegaly and the lowest AUC score for Nodule, 0.655. The
model also localized the parts of the chest radiograph that indicated the
presence of each pathology using GRADCAM, thus contributing to the model
interpretability of a deep learning algorithm.</p>
  </details>
</details>
<details>
  <summary>119. <b>标题：Self-Supervised Representation Learning for Speech Using Visual  Grounding and Masked Language Modeling</b></summary>
  <p><b>编号</b>：[289]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03543</p>
  <p><b>作者</b>：Puyuan Peng,  David Harwath</p>
  <p><b>备注</b>：SAS workshop at AAAI2022</p>
  <p><b>关键词</b>：models also achieve strong performance, masked language modeling objective, associate raw speech waveforms, models perform competitively, visual grounding objective</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we describe our submissions to the ZeroSpeech 2021 Challenge
and SUPERB benchmark. Our submissions are based on the recently proposed
FaST-VGS model, which is a Transformer-based model that learns to associate raw
speech waveforms with semantically related images, all without the use of any
transcriptions of the speech. Additionally, we introduce a novel extension of
this model, FaST-VGS+, which is learned in a multi-task fashion with a masked
language modeling objective in addition to the visual grounding objective. On
ZeroSpeech 2021, we show that our models perform competitively on the ABX task,
outperform all other concurrent submissions on the Syntactic and Semantic
tasks, and nearly match the best system on the Lexical task. On the SUPERB
benchmark, we show that our models also achieve strong performance, in some
cases even outperforming the popular wav2vec2.0 model.</p>
  </details>
</details>
<details>
  <summary>120. <b>标题：Nesterov Accelerated Shuffling Gradient Method for Convex Optimization</b></summary>
  <p><b>编号</b>：[291]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03525</p>
  <p><b>作者</b>：Trang H. Tran,  Lam M. Nguyen,  Katya Scheinberg</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：)$ using unified shuffling schemes, propose nesterov accelerated shuffling gradient, different shuffling sampling schemes, method converges faster near, randomized shuffling schemes</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we propose Nesterov Accelerated Shuffling Gradient (NASG), a
new algorithm for the convex finite-sum minimization problems. Our method
integrates the traditional Nesterov's acceleration momentum with different
shuffling sampling schemes. We show that our algorithm has an improved rate of
$\mathcal{O}(1/T)$ using unified shuffling schemes, where $T$ is the number of
epochs. This rate is better than that of any other shuffling gradient methods
in convex regime. Our convergence analysis does not require an assumption on
bounded domain or a bounded gradient condition. For randomized shuffling
schemes, we improve the convergence bound further. When employing some initial
condition, we show that our method converges faster near the small neighborhood
of the solution. Numerical simulations demonstrate the efficiency of our
algorithm.</p>
  </details>
</details>
<details>
  <summary>121. <b>标题：Forecasting: theory and practice</b></summary>
  <p><b>编号</b>：[298]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2012.03854</p>
  <p><b>作者</b>：Fotios Petropoulos,  Daniele Apiletti,  Vassilios Assimakopoulos,  Mohamed Zied Babai,  Devon K. Barrow,  Souhaib Ben Taieb,  Christoph Bergmeir,  Ricardo J. Bessa,  Jakub Bijak,  John E. Boylan,  Jethro Browell,  Claudio Carnevale,  Jennifer L. Castle,  Pasquale Cirillo,  Michael P. Clements,  Clara Cordeiro,  Fernando Luiz Cyrino Oliveira,  Shari De Baets,  Alexander Dokumentov,  Joanne Ellison,  Piotr Fiszeder,  Philip Hans Franses,  David T. Frazier,  Michael Gilliland,  M. Sinan Gönül,  Paul Goodwin,  Luigi Grossi,  Yael Grushka-Cockayne,  Mariangela Guidolin,  Massimo Guidolin,  Ulrich Gunter,  Xiaojia Guo,  Renato Guseo,  Nigel Harvey,  David F. Hendry,  Ross Hollyman,  Tim Januschowski,  Jooyoung Jeon,  Victor Richmond R. Jose,  Yanfei Kang,  Anne B. Koehler,  Stephan Kolassa,  Nikolaos Kourentzes,  Sonia Leva,  Feng Li,  et al. (35 additional authors not shown)</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：source software implementations, forecasting applications calls, wide range, various topics, rich work</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Forecasting has always been at the forefront of decision making and planning.
The uncertainty that surrounds the future is both exciting and challenging,
with individuals and organisations seeking to minimise risks and maximise
utilities. The large number of forecasting applications calls for a diverse set
of forecasting methods to tackle real-life challenges. This article provides a
non-systematic review of the theory and the practice of forecasting. We provide
an overview of a wide range of theoretical, state-of-the-art models, methods,
principles, and approaches to prepare, produce, organise, and evaluate
forecasts. We then demonstrate how such theoretical concepts are applied in a
variety of real-life contexts.
We do not claim that this review is an exhaustive list of methods and
applications. However, we wish that our encyclopedic presentation will offer a
point of reference for the rich work that has been undertaken over the last
decades, with some key insights for the future of forecasting theory and
practice. Given its encyclopedic nature, the intended mode of reading is
non-linear. We offer cross-references to allow the readers to navigate through
the various topics. We complement the theoretical concepts and applications
covered by large lists of free or open-source software implementations and
publicly-available databases.</p>
  </details>
</details>
<h1>人工智能</h1>
<details>
  <summary>1. <b>标题：DALL-Eval: Probing the Reasoning Skills and Social Biases of  Text-to-Image Generative Transformers</b></summary>
  <p><b>编号</b>：[4]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.04053</p>
  <p><b>作者</b>：Jaemin Cho,  Abhay Zala,  Mohit Bansal</p>
  <p><b>备注</b>：20 pages, 10 figures, 13 tables</p>
  <p><b>关键词</b>：image models learn specific gender, measure four visual reasoning skills, help guide future progress, multimodal transformer language model, four visual reasoning skills</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Generating images from textual descriptions has gained a lot of attention.
Recently, DALL-E, a multimodal transformer language model, and its variants
have shown high-quality text-to-image generation capabilities with a simple
architecture and training objective, powered by large-scale training data and
computation. However, despite the interesting image generation results, there
has not been a detailed analysis on how to evaluate such models. In this work,
we investigate the reasoning capabilities and social biases of such
text-to-image generative transformers in detail. First, we measure four visual
reasoning skills: object recognition, object counting, color recognition, and
spatial relation understanding. For this, we propose PaintSkills, a diagnostic
dataset and evaluation toolkit that measures these four visual reasoning
skills. Second, we measure the text alignment and quality of the generated
images based on pretrained image captioning, image-text retrieval, and image
classification models. Third, we assess social biases in the models. For this,
we suggest evaluation of gender and racial biases of text-to-image generation
models based on a pretrained image-text retrieval model and human evaluation.
In our experiments, we show that recent text-to-image models perform better in
recognizing and counting objects than recognizing colors and understanding
spatial relations, while there exists a large gap between model performances
and oracle accuracy on all skills. Next, we demonstrate that recent
text-to-image models learn specific gender/racial biases from web image-text
pairs. We also show that our automatic evaluations of visual reasoning skills
and gender bias are highly correlated with human judgments. We hope our work
will help guide future progress in improving text-to-image models on visual
reasoning skills and social biases. Code and data at:
this https URL</p>
  </details>
</details>
<details>
  <summary>2. <b>标题：Decision boundaries and convex hulls in the feature space that deep  learning functions learn from images</b></summary>
  <p><b>编号</b>：[5]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.04052</p>
  <p><b>作者</b>：Roozbeh Yousefzadeh</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：significantly different compared, last hidden layer, identify regions guaranteed, deep neural networks, dimensional space based</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The success of deep neural networks in image classification and learning can
be partly attributed to the features they extract from images. It is often
speculated about the properties of a low-dimensional manifold that models
extract and learn from images. However, there is not sufficient understanding
about this low-dimensional space based on theory or empirical evidence. For
image classification models, their last hidden layer is the one where images of
each class is separated from other classes and it also has the least number of
features. Here, we develop methods and formulations to study that feature space
for any model. We study the partitioning of the domain in feature space,
identify regions guaranteed to have certain classifications, and investigate
its implications for the pixel space. We observe that geometric arrangements of
decision boundaries in feature space is significantly different compared to
pixel space, providing insights about adversarial vulnerabilities, image
morphing, extrapolation, ambiguity in classification, and the mathematical
understanding of image classification models.</p>
  </details>
</details>
<details>
  <summary>3. <b>标题：Provable Reinforcement Learning with a Short-Term Memory</b></summary>
  <p><b>编号</b>：[32]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03983</p>
  <p><b>作者</b>：Yonathan Efroni,  Chi Jin,  Akshay Krishnamurthy,  Sobhan Miryoosefi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：world sequential decision making problems commonly involve partial observability, learning partially observable markov decision processes, commonly used technique known, develop new algorithms using, partial observability</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Real-world sequential decision making problems commonly involve partial
observability, which requires the agent to maintain a memory of history in
order to infer the latent states, plan and make good decisions. Coping with
partial observability in general is extremely challenging, as a number of
worst-case statistical and computational barriers are known in learning
Partially Observable Markov Decision Processes (POMDPs). Motivated by the
problem structure in several physical applications, as well as a commonly used
technique known as "frame stacking", this paper proposes to study a new
subclass of POMDPs, whose latent states can be decoded by the most recent
history of a short length $m$. We establish a set of upper and lower bounds on
the sample complexity for learning near-optimal policies for this class of
problems in both tabular and rich-observation settings (where the number of
observations is enormous). In particular, in the rich-observation setting, we
develop new algorithms using a novel "moment matching" approach with a sample
complexity that scales exponentially with the short length $m$ rather than the
problem horizon, and is independent of the number of observations. Our results
show that a short-term memory suffices for reinforcement learning in these
environments.</p>
  </details>
</details>
<details>
  <summary>4. <b>标题：Computing Rule-Based Explanations of Machine Learning Classifiers using  Knowledge Graphs</b></summary>
  <p><b>编号</b>：[39]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03971</p>
  <p><b>作者</b>：Edmund Dervakos,  Orfeas Menis-Mastromichalakis,  Alexandros Chortaras,  Giorgos Stamou</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：order logic rules expressed, lately attracts many researchers, underlying framework providing, machine learning classifiers, symbolic knowledge representation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The use of symbolic knowledge representation and reasoning as a way to
resolve the lack of transparency of machine learning classifiers is a research
area that lately attracts many researchers. In this work, we use knowledge
graphs as the underlying framework providing the terminology for representing
explanations for the operation of a machine learning classifier. In particular,
given a description of the application domain of the classifier in the form of
a knowledge graph, we introduce a novel method for extracting and representing
black-box explanations of its operation, in the form of first-order logic rules
expressed in the terminology of the knowledge graph.</p>
  </details>
</details>
<details>
  <summary>5. <b>标题：Bingham Policy Parameterization for 3D Rotations in Reinforcement  Learning</b></summary>
  <p><b>编号</b>：[45]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03957</p>
  <p><b>作者</b>：Stephen James,  Pieter Abbeel</p>
  <p><b>备注</b>：Project page and code: this https URL</p>
  <p><b>关键词</b>：best pose robot manipulation tasks, continuous control reinforcement learning literature, full 6d pose output, many stochastic policy parameterizations, rotation wahba problem task</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose a new policy parameterization for representing 3D rotations during
reinforcement learning. Today in the continuous control reinforcement learning
literature, many stochastic policy parameterizations are Gaussian. We argue
that universally applying a Gaussian policy parameterization is not always
desirable for all environments. One such case in particular where this is true
are tasks that involve predicting a 3D rotation output, either in isolation, or
coupled with translation as part of a full 6D pose output. Our proposed Bingham
Policy Parameterization (BPP) models the Bingham distribution and allows for
better rotation (quaternion) prediction over a Gaussian policy parameterization
in a range of reinforcement learning tasks. We evaluate BPP on the rotation
Wahba problem task, as well as a set of vision-based next-best pose robot
manipulation tasks from RLBench. We hope that this paper encourages more
research into developing other policy parameterization that are more suited for
particular environments, rather than always assuming Gaussian.</p>
  </details>
</details>
<details>
  <summary>6. <b>标题：Social-DualCVAE: Multimodal Trajectory Forecasting Based on Social  Interactions Pattern Aware and Dual Conditional Variational Auto-Encoder</b></summary>
  <p><b>编号</b>：[47]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03954</p>
  <p><b>作者</b>：Jiashi Gao,  Xinming Shi,  James J.Q. Yu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：mainly existing literature learns representations, intricate social interactions among pedestrians, widely used trajectory benchmarks, dual conditional variational auto, unlabeled social interaction patterns</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Pedestrian trajectory forecasting is a fundamental task in multiple utility
areas, such as self-driving, autonomous robots, and surveillance systems. The
future trajectory forecasting is multi-modal, influenced by physical
interaction with scene contexts and intricate social interactions among
pedestrians. The mainly existing literature learns representations of social
interactions by deep learning networks, while the explicit interaction patterns
are not utilized. Different interaction patterns, such as following or
collision avoiding, will generate different trends of next movement, thus, the
awareness of social interaction patterns is important for trajectory
forecasting. Moreover, the social interaction patterns are privacy concerned or
lack of labels. To jointly address the above issues, we present a social-dual
conditional variational auto-encoder (Social-DualCVAE) for multi-modal
trajectory forecasting, which is based on a generative model conditioned not
only on the past trajectories but also the unsupervised classification of
interaction patterns. After generating the category distribution of the
unlabeled social interaction patterns, DualCVAE, conditioned on the past
trajectories and social interaction pattern, is proposed for multi-modal
trajectory prediction by latent variables estimating. A variational bound is
derived as the minimization objective during training. The proposed model is
evaluated on widely used trajectory benchmarks and outperforms the prior
state-of-the-art methods.</p>
  </details>
</details>
<details>
  <summary>7. <b>标题：Detecting Anomalies within Time Series using Local Neural  Transformations</b></summary>
  <p><b>编号</b>：[52]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03944</p>
  <p><b>作者</b>：Tim Schneider,  Chen Qiu,  Marius Kloft,  Decky Aspandi Latif,  Steffen Staab,  Stephan Mandt,  Maja Rudolph</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：detect anomalies within time series, detect anomalies within time series, facilitating deep anomaly detection, learned transformations gives insight, previous deep anomaly detection</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We develop a new method to detect anomalies within time series, which is
essential in many application domains, reaching from self-driving cars,
finance, and marketing to medical diagnosis and epidemiology. The method is
based on self-supervised deep learning that has played a key role in
facilitating deep anomaly detection on images, where powerful image
transformations are available. However, such transformations are widely
unavailable for time series. Addressing this, we develop Local Neural
Transformations(LNT), a method learning local transformations of time series
from data. The method produces an anomaly score for each time step and thus can
be used to detect anomalies within time series. We prove in a theoretical
analysis that our novel training objective is more suitable for transformation
learning than previous deep Anomaly detection(AD) methods. Our experiments
demonstrate that LNT can find anomalies in speech segments from the LibriSpeech
data set and better detect interruptions to cyber-physical systems than
previous work. Visualization of the learned transformations gives insight into
the type of transformations that LNT learns.</p>
  </details>
</details>
<details>
  <summary>8. <b>标题：Robustness Verification for Attention Networks using Mixed Integer  Programming</b></summary>
  <p><b>编号</b>：[57]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03932</p>
  <p><b>作者</b>：Hsuan-Cheng Liao,  Chih-Hong Cheng,  Maximilian Kneissl,  Alois Knoll</p>
  <p><b>备注</b>：Submitted to IROS 2022</p>
  <p><b>关键词</b>：although attention networks typically deliver higher accuracy, attention networks containing linearized layer normalization, layer perceptron surprisingly shows, mixed integer programming problem, general neural networks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Attention networks such as transformers have been shown powerful in many
applications ranging from natural language processing to object recognition.
This paper further considers their robustness properties from both theoretical
and empirical perspectives. Theoretically, we formulate a variant of attention
networks containing linearized layer normalization and sparsemax activation,
and reduce its robustness verification to a Mixed Integer Programming problem.
Apart from a naïve encoding, we derive tight intervals from admissible
perturbation regions and examine several heuristics to speed up the
verification process. More specifically, we find a novel bounding technique for
sparsemax activation, which is also applicable to softmax activation in general
neural networks. Empirically, we evaluate our proposed techniques with a case
study on lane departure warning and demonstrate a performance gain of
approximately an order of magnitude. Furthermore, although attention networks
typically deliver higher accuracy than general neural networks, contrasting its
robustness against a similar-sized multi-layer perceptron surprisingly shows
that they are not necessarily more robust.</p>
  </details>
</details>
<details>
  <summary>9. <b>标题：KENN: Enhancing Deep Neural Networks by Leveraging Knowledge for Time  Series Forecasting</b></summary>
  <p><b>编号</b>：[64]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03903</p>
  <p><b>作者</b>：Muhammad Ali Chattha,  Ludger van Elst,  Muhammad Imran Malik,  Andreas Dengel,  Sheraz Ahmed</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：specifically aims towards combining strengths, driven machine learning methods often, problems like disaster prediction, novel knowledge fusion architecture, knowledge enhanced neural network</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>End-to-end data-driven machine learning methods often have exuberant
requirements in terms of quality and quantity of training data which are often
impractical to fulfill in real-world applications. This is specifically true in
time series domain where problems like disaster prediction, anomaly detection,
and demand prediction often do not have a large amount of historical data.
Moreover, relying purely on past examples for training can be sub-optimal since
in doing so we ignore one very important domain i.e knowledge, which has its
own distinct advantages. In this paper, we propose a novel knowledge fusion
architecture, Knowledge Enhanced Neural Network (KENN), for time series
forecasting that specifically aims towards combining strengths of both
knowledge and data domains while mitigating their individual weaknesses. We
show that KENN not only reduces data dependency of the overall framework but
also improves performance by producing predictions that are better than the
ones produced by purely knowledge and data driven domains. We also compare KENN
with state-of-the-art forecasting methods and show that predictions produced by
KENN are significantly better even when trained on only 50\% of the data.</p>
  </details>
</details>
<details>
  <summary>10. <b>标题：Speech Emotion Recognition using Self-Supervised Features</b></summary>
  <p><b>编号</b>：[68]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03896</p>
  <p><b>作者</b>：Edmilson Morais,  Ron Hoory,  Weizhong Zhu,  Itai Gat,  Matheus Damasceno,  Hagai Aronowitz</p>
  <p><b>备注</b>：5 pages, 4 figures, 2 tables, ICASSP 2022</p>
  <p><b>关键词</b>：experiments investigate interactions among fine, proposed monomodal speechonly based system, sota multimodal systems using, predicting categorical emotion classes, ser system based</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Self-supervised pre-trained features have consistently delivered state-of-art
results in the field of natural language processing (NLP); however, their
merits in the field of speech emotion recognition (SER) still need further
investigation. In this paper we introduce a modular End-to- End (E2E) SER
system based on an Upstream + Downstream architecture paradigm, which allows
easy use/integration of a large variety of self-supervised features. Several
SER experiments for predicting categorical emotion classes from the IEMOCAP
dataset are performed. These experiments investigate interactions among
fine-tuning of self-supervised feature models, aggregation of frame-level
features into utterance-level features and back-end classification networks.
The proposed monomodal speechonly based system not only achieves SOTA results,
but also brings light to the possibility of powerful and well finetuned
self-supervised acoustic features that reach results similar to the results
achieved by SOTA multimodal systems using both Speech and Text modalities.</p>
  </details>
</details>
<details>
  <summary>11. <b>标题：Learning MAX-SAT from Contextual Examples for Combinatorial Optimisation</b></summary>
  <p><b>编号</b>：[69]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03888</p>
  <p><b>作者</b>：Mohit Kumar,  Samuel Kolb,  Stefano Teso,  Luc De Raedt</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：stochastic local search learner scales much better, also contribute two implementations based, stochastic local search techniques, simple yet powerful setting, learning combinatorial optimisation problems</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Combinatorial optimisation problems are ubiquitous in artificial
intelligence. Designing the underlying models, however, requires substantial
expertise, which is a limiting factor in practice. The models typically consist
of hard and soft constraints, or combine hard constraints with an objective
function. We introduce a novel setting for learning combinatorial optimisation
problems from contextual examples. These positive and negative examples show -
in a particular context - whether the solutions are good enough or not. We
develop our framework using the MAX-SAT formalism as it is simple yet powerful
setting having these features. We study the learnability of MAX-SAT models. Our
theoretical results show that high-quality MAX-SAT models can be learned from
contextual examples in the realisable and agnostic settings, as long as the
data satisfies an intuitive "representativeness" condition. We also contribute
two implementations based on our theoretical results: one leverages ideas from
syntax-guided synthesis while the other makes use of stochastic local search
techniques. The two implementations are evaluated by recovering synthetic and
benchmark models from contextual examples. The experimental results support our
theoretical analysis, showing that MAX-SAT models can be learned from
contextual examples. Among the two implementations, the stochastic local search
learner scales much better than the syntax-guided implementation while
providing comparable or better models.</p>
  </details>
</details>
<details>
  <summary>12. <b>标题：GraphDCA -- a Framework for Node Distribution Comparison in Real and  Synthetic Graphs</b></summary>
  <p><b>编号</b>：[70]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03884</p>
  <p><b>作者</b>：Ciwan Ceylan,  Petra Poklukar,  Hanna Hultin,  Alexander Kravchenko,  Anastasia Varava,  Danica Kragic</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：graphdca satisfyingly captures gradually decreasing similarity, using three node structure feature extractors, evaluate three publicly available real, graphs exhibiting different structural patterns, adequately reproduce local structural features</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We argue that when comparing two graphs, the distribution of node structural
features is more informative than global graph statistics which are often used
in practice, especially to evaluate graph generative models. Thus, we present
GraphDCA - a framework for evaluating similarity between graphs based on the
alignment of their respective node representation sets. The sets are compared
using a recently proposed method for comparing representation spaces, called
Delaunay Component Analysis (DCA), which we extend to graph data. To evaluate
our framework, we generate a benchmark dataset of graphs exhibiting different
structural patterns and show, using three node structure feature extractors,
that GraphDCA recognizes graphs with both similar and dissimilar local
structure. We then apply our framework to evaluate three publicly available
real-world graph datasets and demonstrate, using gradual edge perturbations,
that GraphDCA satisfyingly captures gradually decreasing similarity, unlike
global statistics. Finally, we use GraphDCA to evaluate two state-of-the-art
graph generative models, NetGAN and CELL, and conclude that further
improvements are needed for these models to adequately reproduce local
structural features.</p>
  </details>
</details>
<details>
  <summary>13. <b>标题：Maximum Likelihood Uncertainty Estimation: Robustness to Outliers</b></summary>
  <p><b>编号</b>：[75]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03870</p>
  <p><b>作者</b>：Deebul S. Nair,  Nico Hochgeschwender,  Miguel A. Olivares-Mendez</p>
  <p><b>备注</b>：8 Pages, 8 Figures, The Thirty-Sixth AAAI Conference on Artificial Intelligence (AAAI-22), The AAAI's Workshop on Artificial Intelligence Safety</p>
  <p><b>关键词</b>：tailed distribution based maximum likelihood provides better uncertainty estimates, maximum likelihood based uncertainty estimation methods, evaluated using standard regression benchmarks, monocular depth estimation, dimensional regression task</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We benchmark the robustness of maximum likelihood based uncertainty
estimation methods to outliers in training data for regression tasks. Outliers
or noisy labels in training data results in degraded performances as well as
incorrect estimation of uncertainty. We propose the use of a heavy-tailed
distribution (Laplace distribution) to improve the robustness to outliers. This
property is evaluated using standard regression benchmarks and on a
high-dimensional regression task of monocular depth estimation, both containing
outliers. In particular, heavy-tailed distribution based maximum likelihood
provides better uncertainty estimates, better separation in uncertainty for
out-of-distribution data, as well as better detection of adversarial attacks in
the presence of outliers.</p>
  </details>
</details>
<details>
  <summary>14. <b>标题：The application of Evolutionary and Nature Inspired Algorithms in Data  Science and Data Analytics</b></summary>
  <p><b>编号</b>：[82]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03859</p>
  <p><b>作者</b>：Farid Ghareh Mohammadi,  Farzan Shenavarmasouleh,  Khaled Rasheed,  Thiab Taha,  M. Hadi Amini,  Hamid R. Arabnia</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：inspired algorithms within data science, investigate four optimization algorithms, scale science challenges, three main topics, past 30 years</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In the past 30 years, scientists have searched nature, including animals and
insects, and biology in order to discover, understand, and model solutions for
solving large-scale science challenges. The study of bionics reveals that how
the biological structures, functions found in nature have improved our modern
technologies. In this study, we present our discovery of evolutionary and
nature-inspired algorithms applications in Data Science and Data Analytics in
three main topics of pre-processing, supervised algorithms, and unsupervised
algorithms. Among all applications, in this study, we aim to investigate four
optimization algorithms that have been performed using the evolutionary and
nature-inspired algorithms within data science and analytics. Feature selection
optimization in pre-processing section, Hyper-parameter tuning optimization,
and knowledge discovery optimization in supervised algorithms, and clustering
optimization in the unsupervised algorithms.</p>
  </details>
</details>
<details>
  <summary>15. <b>标题：Comparative Study Between Distance Measures On Supervised Optimum-Path  Forest Classification</b></summary>
  <p><b>编号</b>：[85]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03854</p>
  <p><b>作者</b>：Gustavo Henrique de Rosa,  Mateus Roder,  João Paulo Papa</p>
  <p><b>备注</b>：16 pages, 2 figures</p>
  <p><b>关键词</b>：attracted considerable attention throughout, compared across benchmarking classifiers, support vector machines, past decade due, may vary according</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Machine Learning has attracted considerable attention throughout the past
decade due to its potential to solve far-reaching tasks, such as image
classification, object recognition, anomaly detection, and data forecasting. A
standard approach to tackle such applications is based on supervised learning,
which is assisted by large sets of labeled data and is conducted by the
so-called classifiers, such as Logistic Regression, Decision Trees, Random
Forests, and Support Vector Machines, among others. An alternative to
traditional classifiers is the parameterless Optimum-Path Forest (OPF), which
uses a graph-based methodology and a distance measure to create arcs between
nodes and hence sets of trees, responsible for conquering the nodes, defining
their labels, and shaping the forests. Nevertheless, its performance is
strongly associated with an appropriate distance measure, which may vary
according to the dataset's nature. Therefore, this work proposes a comparative
study over a wide range of distance measures applied to the supervised
Optimum-Path Forest classification. The experimental results are conducted
using well-known literature datasets and compared across benchmarking
classifiers, illustrating OPF's ability to adapt to distinct domains.</p>
  </details>
</details>
<details>
  <summary>16. <b>标题：MetaKG: Meta-learning on Knowledge Graph for Cold-start Recommendation</b></summary>
  <p><b>编号</b>：[86]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03851</p>
  <p><b>作者</b>：Yuntao Du,  Xinjun Zhu,  Lu Chen,  Ziquan Fang,  Yunjun Gao</p>
  <p><b>备注</b>：TKDE 2022 Under review</p>
  <p><b>关键词</b>：globally generalize knowledge representation across different user preference learning tasks, start scenarios using three real data sets demonstrate, based recommendation methods target modeling high, learning based framework called metakg, user preference learning task</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A knowledge graph (KG) consists of a set of interconnected typed entities and
their attributes. Recently, KGs are popularly used as the auxiliary information
to enable more accurate, explainable, and diverse user preference
recommendations. Specifically, existing KG-based recommendation methods target
modeling high-order relations/dependencies from long connectivity user-item
interactions hidden in KG. However, most of them ignore the cold-start problems
(i.e., user cold-start and item cold-start) of recommendation analytics, which
restricts their performance in scenarios when involving new users or new items.
Inspired by the success of meta-learning on scarce training samples, we propose
a novel meta-learning based framework called MetaKG, which encompasses a
collaborative-aware meta learner and a knowledge-aware meta learner, to capture
meta users' preference and entities' knowledge for cold-start recommendations.
The collaborative-aware meta learner aims to locally aggregate user preferences
for each user preference learning task. In contrast, the knowledge-aware meta
learner is to globally generalize knowledge representation across different
user preference learning tasks. Guided by two meta learners, MetaKG can
effectively capture the high-order collaborative relations and semantic
representations, which could be easily adapted to cold-start scenarios.
Besides, we devise a novel adaptive task scheduler which can adaptively select
the informative tasks for meta learning in order to prevent the model from
being corrupted by noisy tasks. Extensive experiments on various cold-start
scenarios using three real data sets demonstrate that our presented MetaKG
outperforms all the existing state-of-the-art competitors in terms of
effectiveness, efficiency, and scalability.</p>
  </details>
</details>
<details>
  <summary>17. <b>标题：TimeLMs: Diachronic Language Models from Twitter</b></summary>
  <p><b>编号</b>：[95]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03829</p>
  <p><b>作者</b>：Daniel Loureiro,  Francesco Barbieri,  Leonardo Neves,  Luis Espinosa Anke,  Jose Camacho-Collados</p>
  <p><b>备注</b>：GitHub: this https URL</p>
  <p><b>关键词</b>：activity involving specific named entities, continual learning strategy contributes, qualitative analyses showing, language models specialized, language model literature</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Despite its importance, the time variable has been largely neglected in the
NLP and language model literature. In this paper, we present TimeLMs, a set of
language models specialized on diachronic Twitter data. We show that a
continual learning strategy contributes to enhancing Twitter-based language
models' capacity to deal with future and out-of-distribution tweets, while
making them competitive with standardized and more monolithic benchmarks. We
also perform a number of qualitative analyses showing how they cope with trends
and peaks in activity involving specific named entities or concept drift.</p>
  </details>
</details>
<details>
  <summary>18. <b>标题：skrl: Modular and Flexible Library for Reinforcement Learning</b></summary>
  <p><b>编号</b>：[96]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03825</p>
  <p><b>作者</b>：Antonio Serrano-Muñoz,  Nestor Arana-Arexolaleiba,  Dimitrios Chrysostomou,  Simon Bøgh</p>
  <p><b>备注</b>：6 pages, 7 figures</p>
  <p><b>关键词</b>：operating nvidia isaac gym environments, traditional openai gym interface, reinforcement learning written, source modular library, supporting environments</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>skrl is an open-source modular library for reinforcement learning written in
Python and designed with a focus on readability, simplicity, and transparency
of algorithm implementations. Apart from supporting environments that use the
traditional OpenAI Gym interface, it allows loading, configuring, and operating
NVIDIA Isaac Gym environments, enabling the parallel training of several agents
with adjustable scopes, which may or may not share resources, in the same
execution. The library's documentation can be found at
this https URL and its source code is available on GitHub at
url{this https URL.</p>
  </details>
</details>
<details>
  <summary>19. <b>标题：A Novel Plug-in Module for Fine-Grained Visual Classification</b></summary>
  <p><b>编号</b>：[97]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03822</p>
  <p><b>作者</b>：Po-Yung Chou,  Cheng-Hung Lin,  Wen-Chung Kao</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：grained visual classification often requires professional experts, proposed plugin module outperforms state, grained classification represents classifications, grained classification represents categories, provide strongly discriminative regions</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Visual classification can be divided into coarse-grained and fine-grained
classification. Coarse-grained classification represents categories with a
large degree of dissimilarity, such as the classification of cats and dogs,
while fine-grained classification represents classifications with a large
degree of similarity, such as cat species, bird species, and the makes or
models of vehicles. Unlike coarse-grained visual classification, fine-grained
visual classification often requires professional experts to label data, which
makes data more expensive. To meet this challenge, many approaches propose to
automatically find the most discriminative regions and use local features to
provide more precise features. These approaches only require image-level
annotations, thereby reducing the cost of annotation. However, most of these
methods require two- or multi-stage architectures and cannot be trained
end-to-end. Therefore, we propose a novel plug-in module that can be integrated
to many common backbones, including CNN-based or Transformer-based networks to
provide strongly discriminative regions. The plugin module can output
pixel-level feature maps and fuse filtered features to enhance fine-grained
visual classification. Experimental results show that the proposed plugin
module outperforms state-of-the-art approaches and significantly improves the
accuracy to 92.77\% and 92.83\% on CUB200-2011 and NABirds, respectively. We
have released our source code in Github
this https URL.</p>
  </details>
</details>
<details>
  <summary>20. <b>标题：Indy Autonomous Challenge -- Autonomous Race Cars at the Handling Limits</b></summary>
  <p><b>编号</b>：[102]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03807</p>
  <p><b>作者</b>：Alexander Wischnewski,  Maximilian Geisslinger,  Johannes Betz,  Tobias Betz,  Felix Fent,  Alexander Heilmeier,  Leonhard Hermansdorfer,  Thomas Herrmann,  Sebastian Huch,  Phillip Karle,  Felix Nobis,  Levent Ögretmen,  Matthias Rowold,  Florian Sauerbeck,  Tim Stahl,  Rainer Trauth,  Markus Lienkamp,  Boris Lohmann</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：sport related track safety precautions, several edge cases en, maximum sensor detection range, ten autonomous dallara av, formance autonomous racing software</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Motorsport has always been an enabler for technological advancement, and the
same applies to the autonomous driving industry. The team TUM Auton-omous
Motorsports will participate in the Indy Autonomous Challenge in Octo-ber 2021
to benchmark its self-driving software-stack by racing one out of ten
autonomous Dallara AV-21 racecars at the Indianapolis Motor Speedway. The first
part of this paper explains the reasons for entering an autonomous vehicle race
from an academic perspective: It allows focusing on several edge cases
en-countered by autonomous vehicles, such as challenging evasion maneuvers and
unstructured scenarios. At the same time, it is inherently safe due to the
motor-sport related track safety precautions. It is therefore an ideal testing
ground for the development of autonomous driving algorithms capable of
mastering the most challenging and rare situations. In addition, we provide
insight into our soft-ware development workflow and present our
Hardware-in-the-Loop simulation setup. It is capable of running simulations of
up to eight autonomous vehicles in real time. The second part of the paper
gives a high-level overview of the soft-ware architecture and covers our
development priorities in building a high-per-formance autonomous racing
software: maximum sensor detection range, relia-ble handling of multi-vehicle
situations, as well as reliable motion control under uncertainty.</p>
  </details>
</details>
<details>
  <summary>21. <b>标题：What are the best systems? New perspectives on NLP Benchmarking</b></summary>
  <p><b>编号</b>：[106]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03799</p>
  <p><b>作者</b>：Pierre Colombo,  Nathan Noiry,  Ekhine Irurozki,  Stephan Clemencon</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：new methods along different axes, conduct extensive numerical experiments, method yields different conclusions, aggregate different systems performances, performance across different tasks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In Machine Learning, a benchmark refers to an ensemble of datasets associated
with one or multiple metrics together with a way to aggregate different systems
performances. They are instrumental in (i) assessing the progress of new
methods along different axes and (ii) selecting the best systems for practical
use. This is particularly the case for NLP with the development of large
pre-trained models (e.g. GPT, BERT) that are expected to generalize well on a
variety of tasks. While the community mainly focused on developing new datasets
and metrics, there has been little interest in the aggregation procedure, which
is often reduced to a simple average over various performance measures.
However, this procedure can be problematic when the metrics are on a different
scale, which may lead to spurious conclusions. This paper proposes a new
procedure to rank systems based on their performance across different tasks.
Motivated by the social choice theory, the final system ordering is obtained
through aggregating the rankings induced by each task and is theoretically
grounded. We conduct extensive numerical experiments (on over 270k scores) to
assess the soundness of our approach both on synthetic and real scores (e.g.
GLUE, EXTREM, SEVAL, TAC, FLICKR). In particular, we show that our method
yields different conclusions on state-of-the-art systems than the
mean-aggregation procedure while being both more reliable and robust.</p>
  </details>
</details>
<details>
  <summary>22. <b>标题：Counterfactual Multi-Token Fairness in Text Classification</b></summary>
  <p><b>编号</b>：[108]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03792</p>
  <p><b>作者</b>：Pranay Lohia</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：support beyond traditionally used sensitive attributes like, machine learning classification models towards, showcase significant performance improvement, sensitive attribute gets bounded, counterfactual fairness gets narrowed</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The counterfactual token generation has been limited to perturbing only a
single token in texts that are generally short and single sentences. These
tokens are often associated with one of many sensitive attributes. With limited
counterfactuals generated, the goal to achieve invariant nature for machine
learning classification models towards any sensitive attribute gets bounded,
and the formulation of Counterfactual Fairness gets narrowed. In this paper, we
overcome these limitations by solving root problems and opening bigger domains
for understanding. We have curated a resource of sensitive tokens and their
corresponding perturbation tokens, even extending the support beyond
traditionally used sensitive attributes like \textit{Age}, \textit{Gender}, and
\textit{Race} to \textit{Nationality}, \textit{Disability}, and
\textit{Religion}. The concept of Counterfactual Generation has been extended
to multi-token support valid over all forms of texts and documents. We define
the method of generating counterfactuals by perturbing multiple sensitive
tokens as \textbf{Counterfactual Multi-token Generation}. The method has been
conceptualized to showcase significant performance improvement over
single-token methods and validated over multiple benchmark datasets. The
emendation in counterfactual generation propagates in achieving improved
\textbf{Counterfactual Multi-token Fairness}.</p>
  </details>
</details>
<details>
  <summary>23. <b>标题：Impact of Parameter Sparsity on Stochastic Gradient MCMC Methods for  Bayesian Deep Learning</b></summary>
  <p><b>编号</b>：[116]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03770</p>
  <p><b>作者</b>：Meet P. Vadera,  Adam D. Cobb,  Brian Jalaian,  Benjamin M. Marlin</p>
  <p><b>备注</b>：Preprint. Work in progress</p>
  <p><b>关键词</b>：drastically reducing model training times, bayesian methods hold significant promise, use stochastic gradient mcmc methods, markov chain monte carlo, art iterative pruning methods</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Bayesian methods hold significant promise for improving the uncertainty
quantification ability and robustness of deep neural network models. Recent
research has seen the investigation of a number of approximate Bayesian
inference methods for deep neural networks, building on both the variational
Bayesian and Markov chain Monte Carlo (MCMC) frameworks. A fundamental issue
with MCMC methods is that the improvements they enable are obtained at the
expense of increased computation time and model storage costs. In this paper,
we investigate the potential of sparse network structures to flexibly trade-off
model storage costs and inference run time against predictive performance and
uncertainty quantification ability. We use stochastic gradient MCMC methods as
the core Bayesian inference method and consider a variety of approaches for
selecting sparse network structures. Surprisingly, our results show that
certain classes of randomly selected substructures can perform as well as
substructures derived from state-of-the-art iterative pruning methods while
drastically reducing model training times.</p>
  </details>
</details>
<details>
  <summary>24. <b>标题：Time to Focus: A Comprehensive Benchmark Using Time Series Attribution  Methods</b></summary>
  <p><b>编号</b>：[119]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03759</p>
  <p><b>作者</b>：Dominique Mercier,  Jwalin Bhatt,  Andreas Dengel,  Sheraz Ahmed</p>
  <p><b>备注</b>：12 pages, 6 figures, 8 tables, Presented at ICAART 2022</p>
  <p><b>关键词</b>：shown outstanding performance across, last decade neural network, achieving super human performance, presented experiments involve gradient, time series analysis</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In the last decade neural network have made huge impact both in industry and
research due to their ability to extract meaningful features from imprecise or
complex data, and by achieving super human performance in several domains.
However, due to the lack of transparency the use of these networks is hampered
in the areas with safety critical areas. In safety-critical areas, this is
necessary by law. Recently several methods have been proposed to uncover this
black box by providing interpreation of predictions made by these models. The
paper focuses on time series analysis and benchmark several state-of-the-art
attribution methods which compute explanations for convolutional classifiers.
The presented experiments involve gradient-based and perturbation-based
attribution methods. A detailed analysis shows that perturbation-based
approaches are superior concerning the Sensitivity and occlusion game. These
methods tend to produce explanations with higher continuity. Contrarily, the
gradient-based techniques are superb in runtime and Infidelity. In addition, a
validation the dependence of the methods on the trained model, feasible
application domains, and individual characteristics is attached. The findings
accentuate that choosing the best-suited attribution method is strongly
correlated with the desired use case. Neither category of attribution methods
nor a single approach has shown outstanding performance across all aspects.</p>
  </details>
</details>
<details>
  <summary>25. <b>标题：Cascaded Debiasing : Studying the Cumulative Effect of Multiple  Fairness-Enhancing Interventions</b></summary>
  <p><b>编号</b>：[129]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03734</p>
  <p><b>作者</b>：Bhavya Ghai,  Mihir Mishra,  Klaus Mueller</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：extensive empirical study comprising 60 combinations, negatively impact different population groups, across 4 benchmark datasets, different population groups apart, designing fair ml pipelines</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Understanding the cumulative effect of multiple fairness enhancing
interventions at different stages of the machine learning (ML) pipeline is a
critical and underexplored facet of the fairness literature. Such knowledge can
be valuable to data scientists/ML practitioners in designing fair ML pipelines.
This paper takes the first step in exploring this area by undertaking an
extensive empirical study comprising 60 combinations of interventions, 9
fairness metrics, 2 utility metrics (Accuracy and F1 Score) across 4 benchmark
datasets. We quantitatively analyze the experimental data to measure the impact
of multiple interventions on fairness, utility and population groups. We found
that applying multiple interventions results in better fairness and lower
utility than individual interventions on aggregate. However, adding more
interventions do no always result in better fairness or worse utility. The
likelihood of achieving high performance (F1 Score) along with high fairness
increases with larger number of interventions. On the downside, we found that
fairness-enhancing interventions can negatively impact different population
groups, especially the privileged group. This study highlights the need for new
fairness metrics that account for the impact on different population groups
apart from just the disparity between groups. Lastly, we offer a list of
combinations of interventions that perform best for different fairness and
utility metrics to aid the design of fair ML pipelines.</p>
  </details>
</details>
<details>
  <summary>26. <b>标题：Computing H-Partitions in ASP and Datalog</b></summary>
  <p><b>编号</b>：[130]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03730</p>
  <p><b>作者</b>：Chloé Capon,  Nicolas Lecomte,  Jef Wijsen</p>
  <p><b>备注</b>：17 pages, 8 figures</p>
  <p><b>关键词</b>：finite undirected simple graph, answer set solver clingo, check programs run faster, deterministic polynomial time whether, deterministic polynomial time</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A $H$-partition of a finite undirected simple graph $G$ is a labeling of
$G$'s vertices such that the constraints expressed by the model graph $H$ are
satisfied. For every model graph $H$, it can be decided in non-deterministic
polynomial time whether a given input graph $G$ admits a $H$-partition.
Moreover, it has been shown by Dantas et al. that for most model graphs, this
decision problem is in deterministic polynomial time. In this paper, we show
that these polynomial-time algorithms for finding $H$-partitions can be
expressed in Datalog with stratified negation. Moreover, using the answer set
solver Clingo, we have conducted experiments to compare straightforward
guess-and-check programs with Datalog programs. Our experiments indicate that
in Clingo, guess-and-check programs run faster than their equivalent Datalog
programs.</p>
  </details>
</details>
<details>
  <summary>27. <b>标题：The Weights can be Harmful: Pareto Search versus Weighted Search in  Multi-Objective Search-Based Software Engineering</b></summary>
  <p><b>编号</b>：[131]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03728</p>
  <p><b>作者</b>：Tao Chen,  Miqing Li</p>
  <p><b>备注</b>：This paper has been accepted by the ACM Transactions on Software Engineering and Methodology (TOSEM); DOI: 10.1145/3514233</p>
  <p><b>关键词</b>：large scale empirical study, consuming relatively less resources, three representative sbse problems, sbse ), pareto search, reflect relative importance</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In presence of multiple objectives to be optimized in Search-Based Software
Engineering (SBSE), Pareto search has been commonly adopted. It searches for a
good approximation of the problem's Pareto optimal solutions, from which the
stakeholders choose the most preferred solution according to their preferences.
However, when clear preferences of the stakeholders (e.g., a set of weights
which reflect relative importance between objectives) are available prior to
the search, weighted search is believed to be the first choice since it
simplifies the search via converting the original multi-objective problem into
a single-objective one and enable the search to focus on what only the
stakeholders are interested in.
This paper questions such a "weighted search first" belief. We show that the
weights can, in fact, be harmful to the search process even in the presence of
clear preferences. Specifically, we conduct a large scale empirical study which
consists of 38 systems/projects from three representative SBSE problems,
together with two types of search budget and nine sets of weights, leading to
604 cases of comparisons. Our key finding is that weighted search reaches a
certain level of solution quality by consuming relatively less resources at the
early stage of the search; however, Pareto search is at the majority of the
time (up to 77% of the cases) significantly better than its weighted
counterpart, as long as we allow a sufficient, but not unrealistic search
budget. This, together with other findings and actionable suggestions in the
paper, allows us to codify pragmatic and comprehensive guidance on choosing
weighted and Pareto search for SBSE under the circumstance that clear
preferences are available. All code and data can be accessed at:
this https URL.</p>
  </details>
</details>
<details>
  <summary>28. <b>标题：Cyrus 2D Simulation Team Description Paper 2016</b></summary>
  <p><b>编号</b>：[132]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03726</p>
  <p><b>作者</b>：Nader Zare,  Ashkan Keshavarzi,  Seyed Ehsan Beheshtian,  Hadi Mowla,  Aryan Akbarpour,  Hossein Jafari,  Keyvan Arab Baraghi,  Mohammad Amin Zarifi,  Reza Javidan</p>
  <p><b>备注</b>：RoboCup 2016, Soccer Simulation 2D league</p>
  <p><b>关键词</b>：cyrus team members, cyrus used, defensive decision, base code, also explained</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This description includes some explanation about algorithms and also
algorithms that are being implemented by Cyrus team members. The objectives of
this description are to express a brief explanation about shoot, block, mark
and defensive decision will be given. It also explained about the parts that
has been implemented. The base code that Cyrus used is agent 3.11.</p>
  </details>
</details>
<details>
  <summary>29. <b>标题：Hair Color Digitization through Imaging and Deep Inverse Graphics</b></summary>
  <p><b>编号</b>：[134]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03723</p>
  <p><b>作者</b>：Robin Kips,  Panagiotis-Alexandros Bokaris,  Matthieu Perrot,  Pietro Gori,  Isabelle Bloch</p>
  <p><b>备注</b>：Electronic Imaging (EI) 2022</p>
  <p><b>关键词</b>：hair shape estimation many applications could benefit, material capture using deep neural networks, since rendering realistic hair images requires path, current hair capture methods focus, conventional inverse graphics approach based</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Hair appearance is a complex phenomenon due to hair geometry and how the
light bounces on different hair fibers. For this reason, reproducing a specific
hair color in a rendering environment is a challenging task that requires
manual work and expert knowledge in computer graphics to tune the result
visually. While current hair capture methods focus on hair shape estimation
many applications could benefit from an automated method for capturing the
appearance of a physical hair sample, from augmented/virtual reality to hair
dying development. Building on recent advances in inverse graphics and material
capture using deep neural networks, we introduce a novel method for hair color
digitization. Our proposed pipeline allows capturing the color appearance of a
physical hair sample and renders synthetic images of hair with a similar
appearance, simulating different hair styles and/or lighting environments.
Since rendering realistic hair images requires path-tracing rendering, the
conventional inverse graphics approach based on differentiable rendering is
untractable. Our method is based on the combination of a controlled imaging
device, a path-tracing renderer, and an inverse graphics model based on
self-supervised machine learning, which does not require to use differentiable
rendering to be trained. We illustrate the performance of our hair digitization
method on both real and synthetic images and show that our approach can
accurately capture and render hair color.</p>
  </details>
</details>
<details>
  <summary>30. <b>标题：Fourier Representations for Black-Box Optimization over Categorical  Variables</b></summary>
  <p><b>编号</b>：[138]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03712</p>
  <p><b>作者</b>：Hamid Dadkhahi,  Jesus Rios,  Karthikeyan Shanmugam,  Payel Das</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：hot encoded boolean fourier expansion, monte carlo tree search, adversarial online regression setting, selected via thompson sampling, present two different representations</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Optimization of real-world black-box functions defined over purely
categorical variables is an active area of research. In particular,
optimization and design of biological sequences with specific functional or
structural properties have a profound impact in medicine, materials science,
and biotechnology. Standalone search algorithms, such as simulated annealing
(SA) and Monte Carlo tree search (MCTS), are typically used for such
optimization problems. In order to improve the performance and sample
efficiency of such algorithms, we propose to use existing methods in
conjunction with a surrogate model for the black-box evaluations over purely
categorical variables. To this end, we present two different representations, a
group-theoretic Fourier expansion and an abridged one-hot encoded Boolean
Fourier expansion. To learn such representations, we consider two different
settings to update our surrogate model. First, we utilize an adversarial online
regression setting where Fourier characters of each representation are
considered as experts and their respective coefficients are updated via an
exponential weight update rule each time the black box is evaluated. Second, we
consider a Bayesian setting where queries are selected via Thompson sampling
and the posterior is updated via a sparse Bayesian regression model (over our
proposed representation) with a regularized horseshoe prior. Numerical
experiments over synthetic benchmarks as well as real-world RNA sequence
optimization and design problems demonstrate the representational power of the
proposed methods, which achieve competitive or superior performance compared to
state-of-the-art counterparts, while improving the computation cost and/or
sample efficiency, substantially.</p>
  </details>
</details>
<details>
  <summary>31. <b>标题：Exploring Inter-Channel Correlation for Diversity-preserved  KnowledgeDistillation</b></summary>
  <p><b>编号</b>：[153]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03680</p>
  <p><b>作者</b>：Li Liu,  Qingle Huang,  Sihao Lin,  Hongwei Xie,  Bing Wang,  Xiaojun Chang,  Xiaodan Liang</p>
  <p><b>备注</b>：Accepted by ICCV 2021</p>
  <p><b>关键词</b>：edge distillation boosts resnet18 beyond 72, tently outperforms many existing methods, important role ofretaining inter, student ). despitemany efforts, prior methods ignore</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Knowledge Distillation has shown very promising abil-ity in transferring
learned representation from the largermodel (teacher) to the smaller one
(student).Despitemany efforts, prior methods ignore the important role
ofretaining inter-channel correlation of features, leading tothe lack of
capturing intrinsic distribution of the featurespace and sufficient diversity
properties of features in theteacher this http URL solve the issue, we propose
thenovel Inter-Channel Correlation for Knowledge Distillation(ICKD), with which
the diversity and homology of the fea-ture space of the student network can
align with that ofthe teacher network. The correlation between these
twochannels is interpreted as diversity if they are irrelevantto each other,
otherwise homology. Then the student isrequired to mimic the correlation within
its own embed-ding space. In addition, we introduce the grid-level
inter-channel correlation, making it capable of dense predictiontasks.
Extensive experiments on two vision tasks, includ-ing ImageNet classification
and Pascal VOC segmentation,demonstrate the superiority of our ICKD, which
consis-tently outperforms many existing methods, advancing thestate-of-the-art
in the fields of Knowledge Distillation. Toour knowledge, we are the first
method based on knowl-edge distillation boosts ResNet18 beyond 72% Top-1
ac-curacy on ImageNet classification. Code is available
at:this https URL.</p>
  </details>
</details>
<details>
  <summary>32. <b>标题：Approximating Gradients for Differentiable Quality Diversity in  Reinforcement Learning</b></summary>
  <p><b>编号</b>：[161]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03666</p>
  <p><b>作者</b>：Bryon Tjanaka,  Matthew C. Fontaine,  Julian Togelius,  Stefanos Nikolaidis</p>
  <p><b>备注</b>：Online article available at this http URL</p>
  <p><b>关键词</b>：one variant achieves comparable performance, algorithms greatly accelerate qd optimization, four simulated walking tasks, variant performs comparably, require rigorous optimization</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Consider a walking agent that must adapt to damage. To approach this task, we
can train a collection of policies and have the agent select a suitable policy
when damaged. Training this collection may be viewed as a quality diversity
(QD) optimization problem, where we search for solutions (policies) which
maximize an objective (walking forward) while spanning a set of measures
(measurable characteristics). Recent work shows that differentiable quality
diversity (DQD) algorithms greatly accelerate QD optimization when exact
gradients are available for the objective and measures. However, such gradients
are typically unavailable in RL settings due to non-differentiable
environments. To apply DQD in RL settings, we propose to approximate objective
and measure gradients with evolution strategies and actor-critic methods. We
develop two variants of the DQD algorithm CMA-MEGA, each with different
gradient approximations, and evaluate them on four simulated walking tasks. One
variant achieves comparable performance (QD score) with the state-of-the-art
PGA-MAP-Elites in two tasks. The other variant performs comparably in all tasks
but is less efficient than PGA-MAP-Elites in two tasks. These results provide
insight into the limitations of CMA-MEGA in domains that require rigorous
optimization of the objective and where exact gradients are unavailable.</p>
  </details>
</details>
<details>
  <summary>33. <b>标题：Boolean Observation Games</b></summary>
  <p><b>编号</b>：[171]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03637</p>
  <p><b>作者</b>：Hans van Ditmarsch,  Sunil Simon</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：boolean observation games player goals describe multi, therefore observation games capture aspects, introduce boolean observation games, present various outcome relations, boolean observation game corresponds</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We introduce Boolean Observation Games, a subclass of multi-player finite
strategic games with incomplete information and qualitative objectives. In
Boolean observation games, each player is associated with a finite set of
propositional variables of which only it can observe the value, and it controls
whether and to whom it can reveal that value. It does not control the given,
fixed, value of variables. Boolean observation games are a generalization of
Boolean games, a well-studied subclass of strategic games but with complete
information, and wherein each player controls the value of its variables.
In Boolean observation games player goals describe multi-agent knowledge of
variables. As in classical strategic games, players choose their strategies
simultaneously and therefore observation games capture aspects of both
imperfect and incomplete information. They require reasoning about sets of
outcomes given sets of indistinguishable valuations of variables. What a Nash
equilibrium is, depends on an outcome relation between such sets. We present
various outcome relations, including a qualitative variant of ex-post
equilibrium. We identify conditions under which, given an outcome relation,
Nash equilibria are guaranteed to exist. We also study the complexity of
checking for the existence of Nash equilibria and of verifying if a strategy
profile is a Nash equilibrium. We further study the subclass of Boolean
observation games with `knowing whether' goal formulas, for which the
satisfaction does not depend on the value of variables. We show that each such
Boolean observation game corresponds to a Boolean game and vice versa, by a
different correspondence, and that both correspondences are precise in terms of
existence of Nash equilibria.</p>
  </details>
</details>
<details>
  <summary>34. <b>标题：Invertible Tabular GANs: Killing Two Birds with OneStone for Tabular  Data Synthesis</b></summary>
  <p><b>编号</b>：[172]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03636</p>
  <p><b>作者</b>：Jaehoon Lee,  Jihyeon Hyeong,  Jinsung Jeon,  Noseong Park,  Jihoon Cho</p>
  <p><b>备注</b>：19 pages</p>
  <p><b>关键词</b>：two distinctive objectives, received wide attention, potential information leakage, oriented evaluation metrics, invertible neural networks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Tabular data synthesis has received wide attention in the literature. This is
because available data is often limited, incomplete, or cannot be obtained
easily, and data privacy is becoming increasingly important. In this work, we
present a generalized GAN framework for tabular synthesis, which combines the
adversarial training of GANs and the negative log-density regularization of
invertible neural networks. The proposed framework can be used for two
distinctive objectives. First, we can further improve the synthesis quality, by
decreasing the negative log-density of real records in the process of
adversarial training. On the other hand, by increasing the negative log-density
of real records, realistic fake records can be synthesized in a way that they
are not too much close to real records and reduce the chance of potential
information leakage. We conduct experiments with real-world datasets for
classification, regression, and privacy attacks. In general, the proposed
method demonstrates the best synthesis quality (in terms of task-oriented
evaluation metrics, e.g., F1) when decreasing the negative log-density during
the adversarial training. If increasing the negative log-density, our
experimental results show that the distance between real and fake records
increases, enhancing robustness against privacy attacks.</p>
  </details>
</details>
<details>
  <summary>35. <b>标题：ECRECer: Enzyme Commission Number Recommendation and Benchmarking based  on Multiagent Dual-core Learning</b></summary>
  <p><b>编号</b>：[175]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03632</p>
  <p><b>作者</b>：Zhenkun Shi,  Qianqian Yuan,  Ruoyu Wang,  Hoaran Li,  Xiaoping Liao,  Hongwu Ma</p>
  <p><b>备注</b>：16 pages, 14 figures</p>
  <p><b>关键词</b>：evaluate different protein representation methods, accurately predicting ec numbers based, novel deep learning techniques, given input sequences directly, four representative methods demonstrate</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Enzyme Commission (EC) numbers, which associate a protein sequence with the
biochemical reactions it catalyzes, are essential for the accurate
understanding of enzyme functions and cellular metabolism. Many ab-initio
computational approaches were proposed to predict EC numbers for given input
sequences directly. However, the prediction performance (accuracy, recall,
precision), usability, and efficiency of existing methods still have much room
to be improved. Here, we report ECRECer, a cloud platform for accurately
predicting EC numbers based on novel deep learning techniques. To build
ECRECer, we evaluate different protein representation methods and adopt a
protein language model for protein sequence embedding. After embedding, we
propose a multi-agent hierarchy deep learning-based framework to learn the
proposed tasks in a multi-task manner. Specifically, we used an extreme
multi-label classifier to perform the EC prediction and employed a greedy
strategy to integrate and fine-tune the final model. Comparative analyses
against four representative methods demonstrate that ECRECer delivers the
highest performance, which improves accuracy and F1 score by 70% and 20% over
the state-of-the-the-art, respectively. With ECRECer, we can annotate numerous
enzymes in the Swiss-Prot database with incomplete EC numbers to their full
fourth level. Take UniPort protein "A0A0U5GJ41" as an example (1.14.-.-),
ECRECer annotated it with "this http URL", which supported by further protein
structure analysis based on AlphaFold2. Finally, we established a webserver
(this https URL) and provided an offline bundle to improve
usability.</p>
  </details>
</details>
<details>
  <summary>36. <b>标题：Domain Adversarial Spatial-Temporal Network: A Transferable Framework  for Short-term Traffic Forecasting across Cities</b></summary>
  <p><b>编号</b>：[177]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03630</p>
  <p><b>作者</b>：Yihong Tang,  Ao Qu,  Andy H.F. Chow,  William H.K. Lam,  S.C. Wong,  Wei Ma</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：novel transferable traffic forecasting framework, cities lacking historical traffic data, various smart mobility applications, wide traffic forecasting problems, developing new model structures</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Accurate real-time traffic forecast is critical for intelligent
transportation systems (ITS) and it serves as the cornerstone of various smart
mobility applications. Though this research area is dominated by deep learning,
recent studies indicate that the accuracy improvement by developing new model
structures is becoming marginal. Instead, we envision that the improvement can
be achieved by transferring the "forecasting-related knowledge" across cities
with different data distributions and network topologies. To this end, this
paper aims to propose a novel transferable traffic forecasting framework:
Domain Adversarial Spatial-Temporal Network (DASTNet). DASTNet is pre-trained
on multiple source networks and fine-tuned with the target network's traffic
data. Specifically, we leverage the graph representation learning and
adversarial domain adaptation techniques to learn the domain-invariant node
embeddings, which are further incorporated to model the temporal traffic data.
To the best of our knowledge, we are the first to employ adversarial
multi-domain adaptation for network-wide traffic forecasting problems. DASTNet
consistently outperforms all state-of-the-art baseline methods on three
benchmark datasets. The trained DASTNet is applied to Hong Kong's new traffic
detectors, and accurate traffic predictions can be delivered immediately
(within one day) when the detector is available. Overall, this study suggests
an alternative to enhance the traffic forecasting methods and provides
practical implications for cities lacking historical traffic data.</p>
  </details>
</details>
<details>
  <summary>37. <b>标题：Graph-Relational Domain Adaptation</b></summary>
  <p><b>编号</b>：[179]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03628</p>
  <p><b>作者</b>：Zihao Xu,  Hao he,  Guang-He Lee,  Yuyang Wang,  Hao Wang</p>
  <p><b>备注</b>：Accepted by ICLR 2022</p>
  <p><b>关键词</b>：uniform alignment ignores topological structures among different domains, improves upon existing domain adaptation methods, existing domain adaptation methods tend, approach successfully generalizes uniform alignment, method recovers classic domain adaptation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Existing domain adaptation methods tend to treat every domain equally and
align them all perfectly. Such uniform alignment ignores topological structures
among different domains; therefore it may be beneficial for nearby domains, but
not necessarily for distant domains. In this work, we relax such uniform
alignment by using a domain graph to encode domain adjacency, e.g., a graph of
states in the US with each state as a domain and each edge indicating
adjacency, thereby allowing domains to align flexibly based on the graph
structure. We generalize the existing adversarial learning framework with a
novel graph discriminator using encoding-conditioned graph embeddings.
Theoretical analysis shows that at equilibrium, our method recovers classic
domain adaptation when the graph is a clique, and achieves non-trivial
alignment for other types of graphs. Empirical results show that our approach
successfully generalizes uniform alignment, naturally incorporates domain
information represented by graphs, and improves upon existing domain adaptation
methods on both synthetic and real-world datasets. Code will soon be available
at this https URL.</p>
  </details>
</details>
<details>
  <summary>38. <b>标题：Backdoor Detection in Reinforcement Learning</b></summary>
  <p><b>编号</b>：[189]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03609</p>
  <p><b>作者</b>：Junfeng Guo,  Ang Li,  Cong Liu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：trojan agents across various types, also trigger low performance, find approximate trigger actions, reinforcement learning solution trojanseeker, backdoor trigger actions</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>While the real world application of reinforcement learning (RL) is becoming
popular, the safety concern and the robustness of an RL system require more
attention. A recent work reveals that, in a multi-agent RL environment,
backdoor trigger actions can be injected into a victim agent (a.k.a. trojan
agent), which can result in a catastrophic failure as soon as it sees the
backdoor trigger action. We propose the problem of RL Backdoor Detection,
aiming to address this safety vulnerability. An interesting observation we drew
from extensive empirical studies is a trigger smoothness property where normal
actions similar to the backdoor trigger actions can also trigger low
performance of the trojan agent. Inspired by this observation, we propose a
reinforcement learning solution TrojanSeeker to find approximate trigger
actions for the trojan agents, and further propose an efficient approach to
mitigate the trojan agents based on machine unlearning. Experiments show that
our approach can correctly distinguish and mitigate all the trojan agents
across various types of agents and environments.</p>
  </details>
</details>
<details>
  <summary>39. <b>标题：Penalizing Gradient Norm for Efficiently Improving Generalization in  Deep Learning</b></summary>
  <p><b>编号</b>：[191]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03599</p>
  <p><b>作者</b>：Yang Zhao,  Hao Zhang,  Xiuyuan Hu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：optimizers towards finding flat minima, method could give new state, loss function could help lead, severely overparameterized networks nowadays, train deep neural networks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>How to train deep neural networks (DNNs) to generalize well is a central
concern in deep learning, especially for severely overparameterized networks
nowadays. In this paper, we propose an effective method to improve the model
generalization by additionally penalizing the gradient norm of loss function
during optimization. We demonstrate that confining the gradient norm of loss
function could help lead the optimizers towards finding flat minima. We
leverage the first-order approximation to efficiently implement the
corresponding gradient to fit well in the gradient descent framework. In our
experiments, we confirm that when using our methods, generalization performance
of various models could be improved on different datasets. Also, we show that
the recent sharpness-aware minimization method \cite{DBLP:conf/iclr/ForetKMN21}
is a special, but not the best, case of our method, where the best case of our
method could give new state-of-art performance on these tasks.</p>
  </details>
</details>
<details>
  <summary>40. <b>标题：Local Explanations for Reinforcement Learning</b></summary>
  <p><b>编号</b>：[192]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03597</p>
  <p><b>作者</b>：Ronny Luss,  Amit Dhurandhar,  Miao Liu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：efficient high quality greedy selection, carefully conducted user study illustrate, received much less attention, explaining deep reinforcement learning, expert policy dynamics rather</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Many works in explainable AI have focused on explaining black-box
classification models. Explaining deep reinforcement learning (RL) policies in
a manner that could be understood by domain users has received much less
attention. In this paper, we propose a novel perspective to understanding RL
policies based on identifying important states from automatically learned
meta-states. The key conceptual difference between our approach and many
previous ones is that we form meta-states based on locality governed by the
expert policy dynamics rather than based on similarity of actions, and that we
do not assume any particular knowledge of the underlying topology of the state
space. Theoretically, we show that our algorithm to find meta-states converges
and the objective that selects important states from each meta-state is
submodular leading to efficient high quality greedy selection. Experiments on
four domains (four rooms, door-key, minipacman, and pong) and a carefully
conducted user study illustrate that our perspective leads to better
understanding of the policy. We conjecture that this is a result of our
meta-states being more intuitive in that the corresponding important states are
strong indicators of tractable intermediate goals that are easier for humans to
interpret and follow.</p>
  </details>
</details>
<details>
  <summary>41. <b>标题：MOST-Net: A Memory Oriented Style Transfer Network for Face Sketch  Synthesis</b></summary>
  <p><b>编号</b>：[193]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03596</p>
  <p><b>作者</b>：Fan Ji,  Muyi Sun,  Xingqun Qi,  Qi Li,  Zhenan Sun</p>
  <p><b>备注</b>：7 pages, 4 figures</p>
  <p><b>关键词</b>：based face sketch synthesis frequently encounters, end memory oriented style transfer network, realistic face sketch synthesis, proposed model could obtain, supervised dynamic memory module</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Face sketch synthesis has been widely used in multi-media entertainment and
law enforcement. Despite the recent developments in deep neural networks,
accurate and realistic face sketch synthesis is still a challenging task due to
the diversity and complexity of human faces. Current image-to-image
translation-based face sketch synthesis frequently encounters over-fitting
problems when it comes to small-scale datasets. To tackle this problem, we
present an end-to-end Memory Oriented Style Transfer Network (MOST-Net) for
face sketch synthesis which can produce high-fidelity sketches with limited
data. Specifically, an external self-supervised dynamic memory module is
introduced to capture the domain alignment knowledge in the long term. In this
way, our proposed model could obtain the domain-transfer ability by
establishing the durable relationship between faces and corresponding sketches
on the feature level. Furthermore, we design a novel Memory Refinement Loss (MR
Loss) for feature alignment in the memory module, which enhances the accuracy
of memory slots in an unsupervised manner. Extensive experiments on the CUFS
and the CUFSF datasets show that our MOST-Net achieves state-of-the-art
performance, especially in terms of the Structural Similarity Index(SSIM).</p>
  </details>
</details>
<details>
  <summary>42. <b>标题：Fair SA: Sensitivity Analysis for Fairness in Face Recognition</b></summary>
  <p><b>编号</b>：[197]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03586</p>
  <p><b>作者</b>：Aparna R. Joshi,  Xavier Suau,  Nivedha Sivakumar,  Luca Zappella,  Nicholas Apostoloff</p>
  <p><b>备注</b>：8 pages, 5 figures, to be published in NeurIPS 2021 Workshop, Algorithmic Fairness through the Lens of Causality and Robustness</p>
  <p><b>关键词</b>：real world applications involving images affected, images captured across different attributes, high impact domains becomes ubiquitous, perturbations may affect subgroups differently, traditional summary statistics suggest</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As the use of deep learning in high impact domains becomes ubiquitous, it is
increasingly important to assess the resilience of models. One such high impact
domain is that of face recognition, with real world applications involving
images affected by various degradations, such as motion blur or high exposure.
Moreover, images captured across different attributes, such as gender and race,
can also challenge the robustness of a face recognition algorithm. While
traditional summary statistics suggest that the aggregate performance of face
recognition models has continued to improve, these metrics do not directly
measure the robustness or fairness of the models. Visual Psychophysics
Sensitivity Analysis (VPSA) [1] provides a way to pinpoint the individual
causes of failure by way of introducing incremental perturbations in the data.
However, perturbations may affect subgroups differently. In this paper, we
propose a new fairness evaluation based on robustness in the form of a generic
framework that extends VPSA. With this framework, we can analyze the ability of
a model to perform fairly for different subgroups of a population affected by
perturbations, and pinpoint the exact failure modes for a subgroup by measuring
targeted robustness. With the increasing focus on the fairness of models, we
use face recognition as an example application of our framework and propose to
compactly visualize the fairness analysis of a model via AUC matrices. We
analyze the performance of common face recognition models and empirically show
that certain subgroups are at a disadvantage when images are perturbed, thereby
uncovering trends that were not visible using the model's performance on
subgroups without perturbations.</p>
  </details>
</details>
<details>
  <summary>43. <b>标题：Convolutional Neural Networks on Graphs with Chebyshev Approximation,  Revisited</b></summary>
  <p><b>编号</b>：[199]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03580</p>
  <p><b>作者</b>：Mingguo He,  Zhewei Wei,  Ji-Rong Wen</p>
  <p><b>备注</b>：13 pages</p>
  <p><b>关键词</b>：learn arbitrary graph spectrum filters, chebnet approximating analytic filter functions, spectral convolution using chebyshev polynomials, supervised node classification tasks, bernstein bases also outperform</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Designing spectral convolutional networks is a challenging problem in graph
learning. ChebNet, one of the early attempts, approximates the spectral
convolution using Chebyshev polynomials. GCN simplifies ChebNet by utilizing
only the first two Chebyshev polynomials while still outperforming it on
real-world datasets. GPR-GNN and BernNet demonstrate that the Monomial and
Bernstein bases also outperform the Chebyshev basis in terms of learning the
spectral convolution. Such conclusions are counter-intuitive in the field of
approximation theory, where it is established that the Chebyshev polynomial
achieves the optimum convergent rate for approximating a function.
In this paper, we revisit the problem of approximating the spectral
convolution with Chebyshev polynomials. We show that ChebNet's inferior
performance is primarily due to illegal coefficients learnt by ChebNet
approximating analytic filter functions, which leads to over-fitting. We then
propose ChebNetII, a new GNN model based on Chebyshev interpolation, which
enhances the original Chebyshev polynomial approximation while reducing the
Runge phenomena. We conducted an extensive experimental study to demonstrate
that ChebNetII can learn arbitrary graph spectrum filters and achieve superior
performance in both full- and semi-supervised node classification tasks.</p>
  </details>
</details>
<details>
  <summary>44. <b>标题：Stop Oversampling for Class Imbalance Learning: A Critical Review</b></summary>
  <p><b>编号</b>：[200]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03579</p>
  <p><b>作者</b>：Ahmad B. Hassanat,  Ahmad S. Tarawneh,  Ghada A. Altarawneh</p>
  <p><b>备注</b>：19 pages, 5 figures, 4 tables, and more than 72 m=oversampling methods reviewed</p>
  <p><b>关键词</b>：oversampling methods studied generate minority samples, fictitious data may fail spectacularly, new oversampling evaluation system based, represent minority may result, synthesized samples may</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>For the last two decades, oversampling has been employed to overcome the
challenge of learning from imbalanced datasets. Many approaches to solving this
challenge have been offered in the literature. Oversampling, on the other hand,
is a concern. That is, models trained on fictitious data may fail spectacularly
when put to real-world problems. The fundamental difficulty with oversampling
approaches is that, given a real-life population, the synthesized samples may
not truly belong to the minority class. As a result, training a classifier on
these samples while pretending they represent minority may result in incorrect
predictions when the model is used in the real world. We analyzed a large
number of oversampling methods in this paper and devised a new oversampling
evaluation system based on hiding a number of majority examples and comparing
them to those generated by the oversampling process. Based on our evaluation
system, we ranked all these methods based on their incorrectly generated
examples for comparison. Our experiments using more than 70 oversampling
methods and three imbalanced real-world datasets reveal that all oversampling
methods studied generate minority samples that are most likely to be majority.
Given data and methods in hand, we argue that oversampling in its current forms
and methodologies is unreliable for learning from class imbalanced data and
should be avoided in real-world applications.</p>
  </details>
</details>
<details>
  <summary>45. <b>标题：Data driven design of optical resonators</b></summary>
  <p><b>编号</b>：[201]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03578</p>
  <p><b>作者</b>：Joeri Lenaerts,  Hannah Pinson,  Vincent Ginis</p>
  <p><b>备注</b>：85 pages, 68 figures, Master thesis in Physics and Astronomy</p>
  <p><b>关键词</b>：optical behavior using computational simulations, optimal design much faster compared, brute force approach quickly becomes, create optimal optical devices, brute force approach</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Optical devices lie at the heart of most of the technology we see around us.
When one actually wants to make such an optical device, one can predict its
optical behavior using computational simulations of Maxwell's equations. If one
then asks what the optimal design would be in order to obtain a certain optical
behavior, the only way to go further would be to try out all of the possible
designs and compute the electromagnetic spectrum they produce. When there are
many design parameters, this brute force approach quickly becomes too
computationally expensive. We therefore need other methods to create optimal
optical devices. An alternative to the brute force approach is inverse design.
In this paradigm, one starts from the desired optical response of a material
and then determines the design parameters that are needed to obtain this
optical response. There are many algorithms known in the literature that
implement this inverse design. Some of the best performing, recent approaches
are based on Deep Learning. The central idea is to train a neural network to
predict the optical response for given design parameters. Since neural networks
are completely differentiable, we can compute gradients of the response with
respect to the design parameters. We can use these gradients to update the
design parameters and get an optical response closer to the one we want. This
allows us to obtain an optimal design much faster compared to the brute force
approach. In my thesis, I use Deep Learning for the inverse design of the
Fabry-Pérot resonator. This system can be described fully analytically and is
therefore ideal to study.</p>
  </details>
</details>
<details>
  <summary>46. <b>标题：Learnability Lock: Authorized Learnability Control Through Adversarial  Invertible Transformations</b></summary>
  <p><b>编号</b>：[203]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03576</p>
  <p><b>作者</b>：Weiqi Peng,  Jinghui Chen</p>
  <p><b>备注</b>：Accepted at ICLR 2022</p>
  <p><b>关键词</b>：proposed learnability lock leverages class, propose adversarial invertible transformation, train models normally using, deep learning benefits incredibly, slightly modify data samples</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Owing much to the revolution of information technology, the recent progress
of deep learning benefits incredibly from the vastly enhanced access to data
available in various digital formats. However, in certain scenarios, people may
not want their data being used for training commercial models and thus studied
how to attack the learnability of deep learning models. Previous works on
learnability attack only consider the goal of preventing unauthorized
exploitation on the specific dataset but not the process of restoring the
learnability for authorized cases. To tackle this issue, this paper introduces
and investigates a new concept called "learnability lock" for controlling the
model's learnability on a specific dataset with a special key. In particular,
we propose adversarial invertible transformation, that can be viewed as a
mapping from image to image, to slightly modify data samples so that they
become "unlearnable" by machine learning models with negligible loss of visual
features. Meanwhile, one can unlock the learnability of the dataset and train
models normally using the corresponding key. The proposed learnability lock
leverages class-wise perturbation that applies a universal transformation
function on data samples of the same label. This ensures that the learnability
can be easily restored with a simple inverse transformation while remaining
difficult to be detected or reverse-engineered. We empirically demonstrate the
success and practicability of our method on visual classification tasks.</p>
  </details>
</details>
<details>
  <summary>47. <b>标题：Four Geometry Problems to Introduce Automated Deduction in Secondary  Schools</b></summary>
  <p><b>编号</b>：[209]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03566</p>
  <p><b>作者</b>：Pedro Quaresma (CISUC / Department of Mathematics, University of Coimbra, Portugal),  Vanda Santos (CIDTFF / University of Aveiro and CISUC, Portugal)</p>
  <p><b>备注</b>：In Proceedings ThEdu'21, arXiv:2202.02144</p>
  <p><b>关键词</b>：addressing four secondary schools geometry problems, secondary schools face several bottlenecks, rigorous mathematical demonstrations, automated deduction tools, automated deduction systems</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The introduction of automated deduction systems in secondary schools face
several bottlenecks, the absence of the subject of rigorous mathematical
demonstrations in the curricula, the lack of knowledge by the teachers about
the subject and the difficulty of tackling the task by automatic means.
Despite those difficulties we claim that the subject of automated deduction
in geometry can be introduced, by addressing it in particular cases: simple to
manipulate by students and teachers and reasonably easy to be dealt by
automatic deduction tools.
The subject is discussed by addressing four secondary schools geometry
problems: their rigorous proofs, visual proofs, numeric proofs, algebraic
formal proofs, synthetic formal proofs, or the lack of them. For these problems
we discuss a lesson plan to address them with the help of Information and
Communications Technology, more specifically, automated deduction tools.</p>
  </details>
</details>
<details>
  <summary>48. <b>标题：Evaluating Robustness of Cooperative MARL: A Model-based Approach</b></summary>
  <p><b>编号</b>：[211]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03558</p>
  <p><b>作者</b>：Nhan H. Pham,  Lam M. Nguyen,  Jie Chen,  Hoang Thanh Lam,  Subhro Das,  Tsui-Wei Weng</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：craft stronger adversarial state perturbations, develop even stronger adversarial attack, lower total team rewards, based attack consistently outperforms, agent mujoco benchmarks illustrate</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In recent years, a proliferation of methods were developed for cooperative
multi-agent reinforcement learning (c-MARL). However, the robustness of c-MARL
agents against adversarial attacks has been rarely explored. In this paper, we
propose to evaluate the robustness of c-MARL agents via a model-based approach.
Our proposed formulation can craft stronger adversarial state perturbations of
c-MARL agents(s) to lower total team rewards more than existing model-free
approaches. In addition, we propose the first victim-agent selection strategy
which allows us to develop even stronger adversarial attack. Numerical
experiments on multi-agent MuJoCo benchmarks illustrate the advantage of our
approach over other baselines. The proposed model-based attack consistently
outperforms other baselines in all tested environments.</p>
  </details>
</details>
<details>
  <summary>49. <b>标题：Stakeholder utility measures for declarative processes and their use in  process comparisons</b></summary>
  <p><b>编号</b>：[223]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03520</p>
  <p><b>作者</b>：Mark Dukes</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：areas include business process analysis, activities may freely happen, specific form must hold, illustrated using several examples, stakeholder utility function ought</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present a method for calculating and analyzing stakeholder utilities of
processes that arise in, but are not limited to, the social sciences. These
areas include business process analysis, healthcare workflow analysis and
policy process analysis. This method is quite general and applicable to any
situation in which declarative-type constraints of a modal and/or temporal
nature play a part.
A declarative process is a process in which activities may freely happen
while respecting a set of constraints. For such a process, anything may happen
so long as it is not explicitly forbidden. Declarative processes have been used
and studied as models of business and healthcare workflows by several authors.
In considering a declarative process as a model of some system it is natural to
consider how the process behaves with respect to stakeholders. We derive a
measure for stakeholder utility that can be applied in a very general setting.
This derivation is achieved by listing a collection a properties which we argue
such a stakeholder utility function ought to satisfy, and then using these to
show a very specific form must hold for such a utility. The utility measure
depends on the set of unique traces of the declarative process, and calculating
this set requires a combinatorial analysis of the declarative graph that
represents the process.
This builds on previous work of the author wherein the combinatorial
diversity metrics for declarative processes were derived for use in policy
process analysis. The collection of stakeholder utilities can themselves then
be used to form a metric with which we can compare different declarative
processes to one another. These are illustrated using several examples of
declarative processes that already exist in the literature.</p>
  </details>
</details>
<details>
  <summary>50. <b>标题：IoV Scenario: Implementation of a Bandwidth Aware Algorithm in Wireless  Network Communication Mode</b></summary>
  <p><b>编号</b>：[231]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03488</p>
  <p><b>作者</b>：Peiying Zhang,  Chao Wang,  Gagangeet Singh Aujla,  Neeraj Kumar,  Mohsen Guizani</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：bandwidth aware multi domain virtual network embedding algorithm, wireless network communication mode represented, still facing great challenges, introduce particle swarm optimization, virtual network embedding</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The wireless network communication mode represented by the Internet of
vehicles (IoV) has been widely used. However, due to the limitations of
traditional network architecture, resource scheduling in wireless network
environment is still facing great challenges. This paper focuses on the
allocation of bandwidth resources in the virtual network environment. This
paper proposes a bandwidth aware multi domain virtual network embedding
algorithm (BA-VNE). The algorithm is mainly aimed at the problem that users
need a lot of bandwidth in wireless communication mode, and solves the problem
of bandwidth resource allocation from the perspective of virtual network
embedding (VNE). In order to improve the performance of the algorithm, we
introduce particle swarm optimization (PSO) algorithm to optimize the
performance of the algorithm. In order to verify the effectiveness of the
algorithm, we have carried out simulation experiments from link bandwidth,
mapping cost and virtual network request (VNR) acceptance rate. The final
results show that the proposed algorithm is better than other representative
algorithms in the above indicators.</p>
  </details>
</details>
<details>
  <summary>51. <b>标题：PatClArC: Using Pattern Concept Activation Vectors for Noise-Robust  Model Debugging</b></summary>
  <p><b>编号</b>：[236]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03482</p>
  <p><b>作者</b>：Frederik Pahde,  Leander Weber,  Christopher J. Anders,  Wojciech Samek,  Sebastian Lapuschkin</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：learn undesired behavior based upon spurious correlations, propose pattern concept activation vectors, art machine learning models, corrects models using cavs, concept activation vectors</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>State-of-the-art machine learning models are commonly (pre-)trained on large
benchmark datasets. These often contain biases, artifacts, or errors that have
remained unnoticed in the data collection process and therefore fail in
representing the real world truthfully. This can cause models trained on these
datasets to learn undesired behavior based upon spurious correlations, e.g.,
the existence of a copyright tag in an image. Concept Activation Vectors (CAV)
have been proposed as a tool to model known concepts in latent space and have
been used for concept sensitivity testing and model correction. Specifically,
class artifact compensation (ClArC) corrects models using CAVs to represent
data artifacts in feature space linearly. Modeling CAVs with filters of linear
models, however, causes a significant influence of the noise portion within the
data, as recent work proposes the unsuitability of linear model filters to find
the signal direction in the input, which can be avoided by instead using
patterns. In this paper we propose Pattern Concept Activation Vectors (PCAV)
for noise-robust concept representations in latent space. We demonstrate that
pattern-based artifact modeling has beneficial effects on the application of
CAVs as a means to remove influence of confounding features from models via the
ClArC framework.</p>
  </details>
</details>
<details>
  <summary>52. <b>标题：A Ranking Game for Imitation Learning</b></summary>
  <p><b>编号</b>：[237]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03481</p>
  <p><b>作者</b>：Harshit Sikchi,  Akanksha Saran,  Wonjoon Goo,  Scott Niekum</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：satisfy pairwise performance rankings within, stackelberg game formulation allows us, using automatically generated rankings, solve previously unsolvable tasks, proposed method achieves state</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose a new framework for imitation learning - treating imitation as a
two-player ranking-based Stackelberg game between a $\textit{policy}$ and a
$\textit{reward}$ function. In this game, the reward agent learns to satisfy
pairwise performance rankings within a set of policies, while the policy agent
learns to maximize this reward. This game encompasses a large subset of both
inverse reinforcement learning (IRL) methods and methods which learn from
offline preferences. The Stackelberg game formulation allows us to use
optimization methods that take the game structure into account, leading to more
sample efficient and stable learning dynamics compared to existing IRL methods.
We theoretically analyze the requirements of the loss function used for ranking
policy performances to facilitate near-optimal imitation learning at
equilibrium. We use insights from this analysis to further increase sample
efficiency of the ranking game by using automatically generated rankings or
with offline annotated rankings. Our experiments show that the proposed method
achieves state-of-the-art sample efficiency and is able to solve previously
unsolvable tasks in the Learning from Observation (LfO) setting.</p>
  </details>
</details>
<details>
  <summary>53. <b>标题：Reward-Respecting Subtasks for Model-Based Reinforcement Learning</b></summary>
  <p><b>编号</b>：[243]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03466</p>
  <p><b>作者</b>：Richard S. Sutton,  Marlos C. Machado,  G. Zacharias Holland,  David Szepesvari Finbarr Timbers,  Brian Tanner,  Adam White</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：unified using general value functions, policy using existing learning algorithms, reinforcement learning must include planning, reward respecting subtasks strongly constrain, thereby also provide</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>To achieve the ambitious goals of artificial intelligence, reinforcement
learning must include planning with a model of the world that is abstract in
state and time. Deep learning has made progress in state abstraction, but,
although the theory of time abstraction has been extensively developed based on
the options framework, in practice options have rarely been used in planning.
One reason for this is that the space of possible options is immense and the
methods previously proposed for option discovery do not take into account how
the option models will be used in planning. Options are typically discovered by
posing subsidiary tasks such as reaching a bottleneck state, or maximizing a
sensory signal other than the reward. Each subtask is solved to produce an
option, and then a model of the option is learned and made available to the
planning process. The subtasks proposed in most previous work ignore the reward
on the original problem, whereas we propose subtasks that use the original
reward plus a bonus based on a feature of the state at the time the option
stops. We show that options and option models obtained from such
reward-respecting subtasks are much more likely to be useful in planning and
can be learned online and off-policy using existing learning algorithms. Reward
respecting subtasks strongly constrain the space of options and thereby also
provide a partial solution to the problem of option discovery. Finally, we show
how the algorithms for learning values, policies, options, and models can be
unified using general value functions.</p>
  </details>
</details>
<details>
  <summary>54. <b>标题：VNE Strategy based on Chaotic Hybrid Flower Pollination Algorithm  Considering Multi-criteria Decision Making</b></summary>
  <p><b>编号</b>：[247]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03429</p>
  <p><b>作者</b>：Peiying Zhang,  Fanglin Liu,  Gagangeet Singh Aujla,  Sahil Vashist</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：solved becomes extremely complex, hybrid flower pollination algorithm, virtual network embedding, received extensive attention, producing invalid individuals</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>With the development of science and technology and the need for
Multi-Criteria Decision-Making (MCDM), the optimization problem to be solved
becomes extremely complex. The theoretically accurate and optimal solutions are
often difficult to obtain. Therefore, meta-heuristic algorithms based on
multi-point search have received extensive attention. Aiming at these problems,
the design strategy of hybrid flower pollination algorithm for Virtual Network
Embedding (VNE) problem is discussed. Combining the advantages of the Genetic
Algorithm (GA) and FPA, the algorithm is optimized for the characteristics of
discrete optimization problems. The cross operation is used to replace the
cross-pollination operation to complete the global search and replace the
mutation operation with self-pollination operation to enhance the ability of
local search. Moreover, a life cycle mechanism is introduced as a complement to
the traditional fitness-based selection strategy to avoid premature
convergence. A chaotic optimization strategy is introduced to replace the
random sequence-guided crossover process to strengthen the global search
capability and reduce the probability of producing invalid individuals.</p>
  </details>
</details>
<details>
  <summary>55. <b>标题：A Reliable Data-transmission Mechanism using Blockchain in Edge  Computing Scenarios</b></summary>
  <p><b>编号</b>：[248]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03428</p>
  <p><b>作者</b>：Peiying Zhang,  Xue Pang,  Neeraj Kumar,  Gagangeet Singh Aujla,  Haotong Cao</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：thing centralized management mode, data transmission mechanism based, simulation results show, facing many difficulties, four working steps</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>With the advent of the Internet of things (IoT) era, more and more devices
are connected to the IoT. Under the traditional cloud-thing centralized
management mode, the transmission of massive data is facing many difficulties,
and the reliability of data is difficult to be guaranteed. As emerging
technologies, blockchain technology and edge computing (EC) technology have
attracted the attention of academia in improving the reliability, privacy and
invariability of IoT technology. In this paper, we combine the characteristics
of the EC and blockchain to ensure the reliability of data transmission in the
IoT. First of all, we propose a data transmission mechanism based on
blockchain, which uses the distributed architecture of blockchain to ensure
that the data is not tampered with; secondly, we introduce the three-tier
structure in the architecture in turn; finally, we introduce the four working
steps of the mechanism, which are similar to the working mechanism of
blockchain. In the end, the simulation results show that the proposed scheme
can ensure the reliability of data transmission in the Internet of things to a
great extent.</p>
  </details>
</details>
<details>
  <summary>56. <b>标题：Reinforcement learning for multi-item retrieval in the puzzle-based  storage system</b></summary>
  <p><b>编号</b>：[249]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03424</p>
  <p><b>作者</b>：Jing He,  Xinglu Liu,  Qiyao Duan,  Wai Kin Victor Chan,  Mingyao Qi</p>
  <p><b>备注</b>：32 pages, 13 figures, 5 tables, journal</p>
  <p><b>关键词</b>：general compact integer programming model, outperforms three related state, extensive numerical experiments demonstrate, dueling deep q network, deep reinforcement learning algorithm</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Nowadays, fast delivery services have created the need for high-density
warehouses. The puzzle-based storage system is a practical way to enhance the
storage density, however, facing difficulties in the retrieval process. In this
work, a deep reinforcement learning algorithm, specifically the Double&Dueling
Deep Q Network, is developed to solve the multi-item retrieval problem in the
system with general settings, where multiple desired items, escorts, and I/O
points are placed randomly. Additionally, we propose a general compact integer
programming model to evaluate the solution quality. Extensive numerical
experiments demonstrate that the reinforcement learning approach can yield
high-quality solutions and outperforms three related state-of-the-art heuristic
algorithms. Furthermore, a conversion algorithm and a decomposition framework
are proposed to handle simultaneous movement and large-scale instances
respectively, thus improving the applicability of the PBS system.</p>
  </details>
</details>
<details>
  <summary>57. <b>标题：CAD-RADS Scoring using Deep Learning and Task-Specific Centerline  Labeling</b></summary>
  <p><b>编号</b>：[276]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03671</p>
  <p><b>作者</b>：Felix Denzinger,  Michael Wels,  Oliver Taubmann,  Mehmet A. Gülsün,  Max Schöbinger,  Florian André,  Sebastian J. Buss,  Johannes Görich,  Michael Sühling,  Andreas Maier,  Katharina Breininger</p>
  <p><b>备注</b>：Under review MIDL 2020</p>
  <p><b>关键词</b>：receiver operating characteristic curve, heuristic coronary segment labeling, consistent parts across patients, specific deep learning architecture, subdivides coronary trees</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>With coronary artery disease (CAD) persisting to be one of the leading causes
of death worldwide, interest in supporting physicians with algorithms to speed
up and improve diagnosis is high. In clinical practice, the severeness of CAD
is often assessed with a coronary CT angiography (CCTA) scan and manually
graded with the CAD-Reporting and Data System (CAD-RADS) score. The clinical
questions this score assesses are whether patients have CAD or not (rule-out)
and whether they have severe CAD or not (hold-out). In this work, we reach new
state-of-the-art performance for automatic CAD-RADS scoring. We propose using
severity-based label encoding, test time augmentation (TTA) and model
ensembling for a task-specific deep learning architecture. Furthermore, we
introduce a novel task- and model-specific, heuristic coronary segment
labeling, which subdivides coronary trees into consistent parts across
patients. It is fast, robust, and easy to implement. We were able to raise the
previously reported area under the receiver operating characteristic curve
(AUC) from 0.914 to 0.942 in the rule-out and from 0.921 to 0.950 in the
hold-out task respectively.</p>
  </details>
</details>
<details>
  <summary>58. <b>标题：Multi-Label Classification of Thoracic Diseases using Dense  Convolutional Network on Chest Radiographs</b></summary>
  <p><b>编号</b>：[284]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2202.03583</p>
  <p><b>作者</b>：Dipkamal Bhusal,  Dr. Sanjeeb Prasad Panday</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：using dense convolutional neural network, ray images requires skilled manpower, identify different thoracic diseases, obtain high classification predictions, common medical diagnosis techniques</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Chest X-ray images are one of the most common medical diagnosis techniques to
identify different thoracic diseases. However, identification of pathologies in
X-ray images requires skilled manpower and are often cited as a time-consuming
task with varied level of interpretation, particularly in cases where the
identification of disease only by images is difficult for human eyes. With
recent achievements of deep learning in image classification, its application
in disease diagnosis has been widely explored. This research project presents a
multi-label disease diagnosis model of chest x-rays. Using Dense Convolutional
Neural Network (DenseNet), the diagnosis system was able to obtain high
classification predictions. The model obtained the highest AUC score of 0.896
for condition Cardiomegaly and the lowest AUC score for Nodule, 0.655. The
model also localized the parts of the chest radiograph that indicated the
presence of each pathology using GRADCAM, thus contributing to the model
interpretability of a deep learning algorithm.</p>
  </details>
</details>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">徐耀彬</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://louishsu.xyz/2022/02/10/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html">http://louishsu.xyz/2022/02/10/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://louishsu.xyz" target="_blank">LOUIS' BLOG</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"></div><div class="post_share"><div class="social-share" data-image="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="next-post pull-full"><a href="/2021/10/22/%E4%B8%AD%E5%9B%BD%E6%B3%95%E5%BE%8B%E6%99%BA%E8%83%BD%E6%8A%80%E6%9C%AF%E8%AF%84%E6%B5%8B(CAIL2021)%EF%BC%9A%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96(Rank2).html"><img class="next-cover" src="http://cail.cipsc.org.cn/img/index_mainpic.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">中国法律智能技术评测(CAIL2021)：信息抽取(Rank2)</div></div></a></div></nav><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="twikoo-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="card-info-avatar is-center"><img class="avatar-img" src="/img/touxiang.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/><div class="author-info__name">徐耀彬</div><div class="author-info__description">做知识的原创者！</div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">11</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">标签</div><div class="length-num">3</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">分类</div><div class="length-num">7</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/isLouisHsu"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/isLouisHsu" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:is.louishsu@foxmail.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>公告</span></div><div class="announcement_content">记录和分享一些学习和开源内容，若有问题可通过邮箱is.louishsu@foxmail.com联系，欢迎交流！！</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">1.</span> <span class="toc-text">统计</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">2.</span> <span class="toc-text">计算机视觉</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">3.</span> <span class="toc-text">自然语言处理</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">4.</span> <span class="toc-text">机器学习</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">5.</span> <span class="toc-text">人工智能</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2022/02/10/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html" title="Arxiv每日速递(2022-02-10)"><img src="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Arxiv每日速递(2022-02-10)"/></a><div class="content"><a class="title" href="/2022/02/10/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html" title="Arxiv每日速递(2022-02-10)">Arxiv每日速递(2022-02-10)</a><time datetime="2022-02-10T00:28:44.836Z" title="发表于 2022-02-10 08:28:44">2022-02-10</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/10/22/%E4%B8%AD%E5%9B%BD%E6%B3%95%E5%BE%8B%E6%99%BA%E8%83%BD%E6%8A%80%E6%9C%AF%E8%AF%84%E6%B5%8B(CAIL2021)%EF%BC%9A%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96(Rank2).html" title="中国法律智能技术评测(CAIL2021)：信息抽取(Rank2)"><img src="http://cail.cipsc.org.cn/img/index_mainpic.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="中国法律智能技术评测(CAIL2021)：信息抽取(Rank2)"/></a><div class="content"><a class="title" href="/2021/10/22/%E4%B8%AD%E5%9B%BD%E6%B3%95%E5%BE%8B%E6%99%BA%E8%83%BD%E6%8A%80%E6%9C%AF%E8%AF%84%E6%B5%8B(CAIL2021)%EF%BC%9A%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96(Rank2).html" title="中国法律智能技术评测(CAIL2021)：信息抽取(Rank2)">中国法律智能技术评测(CAIL2021)：信息抽取(Rank2)</a><time datetime="2021-10-22T14:29:06.000Z" title="发表于 2021-10-22 22:29:06">2021-10-22</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/05/19/%E5%85%A8%E7%90%83%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%8A%80%E6%9C%AF%E5%88%9B%E6%96%B0%E5%A4%A7%E8%B5%9B%E3%80%90%E8%B5%9B%E9%81%93%E4%B8%80%E3%80%91%EF%BC%9A%E5%8C%BB%E5%AD%A6%E5%BD%B1%E5%83%8F%E6%8A%A5%E5%91%8A%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B.html" title="全球人工智能技术创新大赛【赛道一】：医学影像报告异常检测"><img src="https://tianchi-public.oss-cn-hangzhou.aliyuncs.com/public/files/forum/161037709574435991610377095138.jpeg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="全球人工智能技术创新大赛【赛道一】：医学影像报告异常检测"/></a><div class="content"><a class="title" href="/2021/05/19/%E5%85%A8%E7%90%83%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%8A%80%E6%9C%AF%E5%88%9B%E6%96%B0%E5%A4%A7%E8%B5%9B%E3%80%90%E8%B5%9B%E9%81%93%E4%B8%80%E3%80%91%EF%BC%9A%E5%8C%BB%E5%AD%A6%E5%BD%B1%E5%83%8F%E6%8A%A5%E5%91%8A%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B.html" title="全球人工智能技术创新大赛【赛道一】：医学影像报告异常检测">全球人工智能技术创新大赛【赛道一】：医学影像报告异常检测</a><time datetime="2021-05-19T09:57:06.000Z" title="发表于 2021-05-19 17:57:06">2021-05-19</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2020/09/16/%E8%AF%A6%E8%A7%A3%E5%91%BD%E5%90%8D%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB%E6%A8%A1%E5%9E%8B%EF%BC%9ALSTM-CRF.html" title="详解命名实体识别模型：LSTM-CRF"><img src="https://gimg2.baidu.com/image_search/src=http%3A%2F%2Fpic1.zhimg.com%2Fv2-1ed6a10dbb239a148e42df088c5870a6_1440w.jpg%3Fsource%3D172ae18b&amp;refer=http%3A%2F%2Fpic1.zhimg.com&amp;app=2002&amp;size=f9999,10000&amp;q=a80&amp;n=0&amp;g=0n&amp;fmt=jpeg?sec=1638183974&amp;t=4632f13fd487ed1cfcb12d67a6b71e52" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="详解命名实体识别模型：LSTM-CRF"/></a><div class="content"><a class="title" href="/2020/09/16/%E8%AF%A6%E8%A7%A3%E5%91%BD%E5%90%8D%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB%E6%A8%A1%E5%9E%8B%EF%BC%9ALSTM-CRF.html" title="详解命名实体识别模型：LSTM-CRF">详解命名实体识别模型：LSTM-CRF</a><time datetime="2020-09-16T09:26:44.000Z" title="发表于 2020-09-16 17:26:44">2020-09-16</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2020/06/14/%E8%AE%B0%E4%B8%80%E6%AC%A1MySQL%E8%A7%A3%E5%86%B3%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E6%97%B6%E7%9A%84%E5%88%86%E8%A1%A8%E9%97%AE%E9%A2%98.html" title="记一次MySQL解决大数据存储时的分表问题"><img src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="记一次MySQL解决大数据存储时的分表问题"/></a><div class="content"><a class="title" href="/2020/06/14/%E8%AE%B0%E4%B8%80%E6%AC%A1MySQL%E8%A7%A3%E5%86%B3%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E6%97%B6%E7%9A%84%E5%88%86%E8%A1%A8%E9%97%AE%E9%A2%98.html" title="记一次MySQL解决大数据存储时的分表问题">记一次MySQL解决大数据存储时的分表问题</a><time datetime="2020-06-14T15:24:27.000Z" title="发表于 2020-06-14 23:24:27">2020-06-14</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2022 By 徐耀彬</div><div class="footer_custom_text"><p><a style="margin-inline:5px"target="_blank"href="https://hexo.io/"><img src="https://img.shields.io/badge/Frame-Hexo-blue?style=flat&logo=hexo"title="博客框架为Hexo"alt="img"></a><a style="margin-inline:5px"target="_blank"href="https://butterfly.js.org/"><img src="https://img.shields.io/badge/Theme-Butterfly-6513df?style=flat&logo=bitdefender"title="主题采用butterfly"alt="img"></a><a style="margin-inline:5px"target="_blank"href="https://www.jsdelivr.com/"><img src="https://img.shields.io/badge/CDN-jsDelivr-orange?style=flat&logo=jsDelivr"title="本站使用JsDelivr为静态资源提供CDN加速"alt="img"></a><a style="margin-inline:5px"target="_blank"href="https://github.com/"><img src="https://img.shields.io/badge/Source-Github-d021d6?style=flat&logo=GitHub"title="本站项目由Gtihub托管"alt="img"></a><a style="margin-inline:5px"target="_blank"href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img src="https://img.shields.io/badge/Copyright-BY--NC--SA%204.0-d42328?style=flat&logo=Claris"alt="img"title="本站采用知识共享署名-非商业性使用-相同方式共享4.0国际许可协议进行许可"></a></br></p></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="font-plus" type="button" title="放大字体"><i class="fas fa-plus"></i></button><button id="font-minus" type="button" title="缩小字体"><i class="fas fa-minus"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div></div><hr/><div id="local-search-results"></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.css"><script>(() => {
  document.querySelectorAll('#article-container span.katex-display').forEach(item => {
    btf.wrap(item, 'div', '', 'katex-wrap')
  })
})()</script><script>(()=>{
  const $countDom = document.getElementById('twikoo-count')
  const init = () => {
    let initData = {
      el: '#twikoo-wrap',
      envId: 'blog-',
      region: ''
    }

    if (false) {
      const otherData = false
      initData = Object.assign(initData, otherData)
    }
    
    twikoo.init(initData)
  }

  const getCount = () => {
    twikoo.getCommentsCount({
      envId: 'blog-',
      region: '',
      urls: [window.location.pathname],
      includeReply: false
    }).then(function (res) {
      $countDom.innerText = res[0].count
    }).catch(function (err) {
      console.error(err);
    });
  }

  const loadTwikoo = (bool = false) => {
    if (typeof twikoo === 'object') {
      init()
      bool && $countDom && setTimeout(getCount,0)
    } else {
      getScript('https://cdn.jsdelivr.net/npm/twikoo/dist/twikoo.all.min.js').then(()=> {
        init()
        bool && $countDom && setTimeout(getCount,0)
      })
    }
  }

  if ('Twikoo' === 'Twikoo' || !false) {
    if (false) btf.loadComment(document.getElementById('twikoo-wrap'), loadTwikoo)
    else loadTwikoo(true)
  } else {
    window.loadOtherComment = () => {
      loadTwikoo()
    }
  }
})()</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><!-- hexo injector body_end start --> <script data-pjax>if(document.getElementById('recent-posts') && (location.pathname ==='/'|| '/' ==='all')){
    var parent = document.getElementById('recent-posts');
    var child = '<div class="recent-post-item" style="width:100%;height: auto"><div id="catalog_magnet"><div class="magnet_item"><a class="magnet_link" href="http://louishsu.xyz/categories/机器学习/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🐱 机器学习 (1)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://louishsu.xyz/categories/自然语言处理/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">📚 自然语言处理 (1)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://louishsu.xyz/categories/竞赛相关/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🎮 竞赛相关 (2)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://louishsu.xyz/categories/阅读笔记/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🎮 阅读笔记 (1)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><a class="magnet_link_more"  href="http://louishsu.xyz/categories" style="flex:1;text-align: center;margin-bottom: 10px;">查看更多...</a></div></div>';
    console.log('已挂载magnet')
    parent.insertAdjacentHTML("afterbegin",child)}
     </script><style>#catalog_magnet{flex-wrap: wrap;display: flex;width:100%;justify-content:space-between;padding: 10px 10px 0 10px;align-content: flex-start;}.magnet_item{flex-basis: calc(50% - 5px);background: #f2f2f2;margin-bottom: 10px;border-radius: 8px;transition: all 0.2s ease-in-out;}.magnet_item:hover{background: #b30070}.magnet_link_more{color:#555}.magnet_link{color:black}.magnet_link:hover{color:white}@media screen and (max-width: 600px) {.magnet_item {flex-basis: 100%;}}.magnet_link_context{display:flex;padding: 10px;font-size:16px;transition: all 0.2s ease-in-out;}.magnet_link_context:hover{padding: 10px 20px;}</style>
    <style></style>
  <script data-pjax src="https://cdn.jsdelivr.net/gh/Zfour/hexo-github-calendar@1.21/hexo_githubcalendar.js"></script>
  <script data-pjax>
        function GithubCalendarConfig(){
            var git_githubapiurl ="https://python-github-calendar-api.vercel.app/api?isLouisHsu";
            var git_color =['#ebedf0', '#fdcdec', '#fc9bd9', '#fa6ac5', '#f838b2', '#f5089f', '#c4067e', '#92055e', '#540336', '#48022f', '#30021f'];
            var git_user ="isLouisHsu";
            var parent_div_git = document.getElementById('recent-posts');
            var git_div_html = '<div class="recent-post-item" style="width:100%;height:auto;padding:10px;"><div id="github_loading" style="width:10%;height:100%;margin:0 auto;display: block"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"  viewBox="0 0 50 50" style="enable-background:new 0 0 50 50" xml:space="preserve"><path fill="#d0d0d0" d="M25.251,6.461c-10.318,0-18.683,8.365-18.683,18.683h4.068c0-8.071,6.543-14.615,14.615-14.615V6.461z" transform="rotate(275.098 25 25)"><animateTransform attributeType="xml" attributeName="transform" type="rotate" from="0 25 25" to="360 25 25" dur="0.6s" repeatCount="indefinite"></animateTransform></path></svg></div><div id="github_container"></div></div>';
            if(parent_div_git && location.pathname =='/'){
                console.log('已挂载github calendar')
                // parent_div_git.innerHTML=git_div_html+parent_div_git.innerHTML // 无报错，但不影响使用(支持pjax跳转)
                parent_div_git.insertAdjacentHTML("afterbegin",git_div_html) // 有报错，但不影响使用(支持pjax跳转)
            };
            GithubCalendar(git_githubapiurl,git_color,git_user)
        }
        if(document.getElementById('recent-posts')){
            GithubCalendarConfig()
        }
    </script>
    <style>#github_container{min-height:280px}@media screen and (max-width:650px) {#github_container{background-image:;min-height:0px}}</style>
    <style></style><script data-pjax>function electric_clock_injector_config(){
                var parent_div_git = document.getElementsByClassName('sticky_layout')[0];
                var item_html = '<div class="card-widget card-clock"><div class="card-glass"><div class="card-background"><div class="card-content"><div id="hexo_electric_clock"><img id="card-clock-loading" src="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-clock/clock/images/weather/loading.gif" style="height: 120px; width: 100%;" data-ll-status="loading" class="entered loading"></div></div></div></div></div>';
                console.log('已挂载electric_clock')
                // parent_div_git.innerHTML=item_html+parent_div_git.innerHTML // 无报错，但不影响使用(支持pjax跳转)
                parent_div_git.insertAdjacentHTML("afterbegin",item_html) // 有报错，但不影响使用(支持pjax跳转)
            }if( document.getElementsByClassName('sticky_layout')[0] && (location.pathname ==='all'|| 'all' ==='all')){

            electric_clock_injector_config()
        } </script><script src="https://pv.sohu.com/cityjson?ie=utf-8"></script><script data-pjax  src="https://cdn.jsdelivr.net/gh/Zfour/hexo-electric-clock@1.0.6/clock.js"></script><!-- hexo injector body_end end --><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"model":{"jsonPath":"/live2dw/assets/hijiki.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":false},"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body></html>