<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Arxiv每日速递(2022-03-11) | LOUIS' BLOG</title><meta name="author" content="徐耀彬"><meta name="copyright" content="徐耀彬"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="本篇博文主要展示每日从Arxiv论文网站获取的最新论文列表，以计算机视觉、自然语言处理、机器学习、人工智能等大方向进行划分。 统计 今日共更新308篇论文，其中：  85篇计算机视觉（cs.CV） 28篇自然语言处理（cs.CL） 111篇机器学习（cs.LG） 62篇人工智能（cs.AI）  计算机视觉    1. 标题：On the surprising tradeoff between Im">
<meta property="og:type" content="article">
<meta property="og:title" content="Arxiv每日速递(2022-03-11)">
<meta property="og:url" content="http://louishsu.xyz/2022/03/11/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html">
<meta property="og:site_name" content="LOUIS&#39; BLOG">
<meta property="og:description" content="本篇博文主要展示每日从Arxiv论文网站获取的最新论文列表，以计算机视觉、自然语言处理、机器学习、人工智能等大方向进行划分。 统计 今日共更新308篇论文，其中：  85篇计算机视觉（cs.CV） 28篇自然语言处理（cs.CL） 111篇机器学习（cs.LG） 62篇人工智能（cs.AI）  计算机视觉    1. 标题：On the surprising tradeoff between Im">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png">
<meta property="article:published_time" content="2022-03-11T00:36:40.477Z">
<meta property="article:modified_time" content="2022-03-11T00:38:17.634Z">
<meta property="article:author" content="徐耀彬">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://louishsu.xyz/2022/03/11/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2022-03-11 08:38:17'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const fontSizeVal = saveToLocal.get('global-font-size')
    if (fontSizeVal !== undefined) {
      document.documentElement.style.setProperty('--global-font-size', fontSizeVal + 'px')
    }
    })(window)</script><link rel="stylesheet" href="/css/background.css"><script src="https://cdn.jsdelivr.net/npm/echarts@4.7.0/dist/echarts.min.js"></script><!-- hexo injector head_end start --><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Zfour/hexo-electric-clock@1.0.6/clock.css"><!-- hexo injector head_end end --><meta name="generator" content="Hexo 5.4.1"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="author-avatar"><img class="avatar-img" src="/img/touxiang.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">11</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">标签</div><div class="length-num">3</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">分类</div><div class="length-num">7</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/message/"><i class="fa-fw far fa-comment-dots"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa-fw fa fa-book"></i><span> 找文章</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></li><li><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></li><li><a class="site-page" href="/charts/"><i class="fa-fw fa fa-archive"></i><span> 统计</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-tools"></i><span> 工具</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/md_editor/"><i class="fa-fw fas fa-pen"></i><span> 在线markdown</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/isLouisHsu/blog/tree/master/source/_posts"><i class="fa-fw fa fa-star"></i><span> 在线push</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">LOUIS' BLOG</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/message/"><i class="fa-fw far fa-comment-dots"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa-fw fa fa-book"></i><span> 找文章</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></li><li><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></li><li><a class="site-page" href="/charts/"><i class="fa-fw fa fa-archive"></i><span> 统计</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-tools"></i><span> 工具</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/md_editor/"><i class="fa-fw fas fa-pen"></i><span> 在线markdown</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/isLouisHsu/blog/tree/master/source/_posts"><i class="fa-fw fa fa-star"></i><span> 在线push</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Arxiv每日速递(2022-03-11)<a class="post-edit-link" href="https://github.com/isLouisHsu/blog/tree/master/source_posts/Arxiv每日速递.md" title="编辑" target="_blank"><i class="fas fa-pencil-square"></i></a></h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-03-11T00:36:40.477Z" title="发表于 2022-03-11 08:36:40">2022-03-11</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2022-03-11T00:38:17.634Z" title="更新于 2022-03-11 08:38:17">2022-03-11</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">阅读笔记</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">72.5k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>434分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span><span class="post-meta-separator">|</span><span class="post-meta-commentcount"><i class="far fa-comments fa-fw post-meta-icon"></i><span class="post-meta-label">评论数:</span><a href="/2022/03/11/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html#post-comment"><span id="twikoo-count"></span></a></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><p>本篇博文主要展示每日从Arxiv论文网站获取的最新论文列表，以计算机视觉、自然语言处理、机器学习、人工智能等大方向进行划分。</p>
<h1>统计</h1>
<p>今日共更新308篇论文，其中：</p>
<ul>
<li>85篇计算机视觉（<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>）</li>
<li>28篇自然语言处理（<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>）</li>
<li>111篇机器学习（cs.LG）</li>
<li>62篇人工智能（<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>）</li>
</ul>
<h1>计算机视觉</h1>
<details>
  <summary>1. <b>标题：On the surprising tradeoff between ImageNet accuracy and perceptual  similarity</b></summary>
  <p><b>编号</b>：[4]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04946</p>
  <p><b>作者</b>：Manoj Kumar,  Neil Houlsby,  Nal Kalchbrenner,  Ekin D. Cubuk</p>
  <p><b>备注</b>：Preprint</p>
  <p><b>关键词</b>：better classifiers achieve worse perceptual scores, whose emergent perceptual score matches, prior best networks trained directly, higher accuracy improves perceptual score, supervised human perceptual judgements</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Perceptual distances between images, as measured in the space of pre-trained
deep features, have outperformed prior low-level, pixel-based metrics on
assessing image similarity. While the capabilities of older and less accurate
models such as AlexNet and VGG to capture perceptual similarity are well known,
modern and more accurate models are less studied. First, we observe a
surprising inverse correlation between ImageNet accuracy and Perceptual Scores
of modern networks such as ResNets, EfficientNets, and Vision Transformers:
that is better classifiers achieve worse Perceptual Scores. Then, we perform a
large-scale study and examine the ImageNet accuracy/Perceptual Score
relationship on varying the depth, width, number of training steps, weight
decay, label smoothing, and dropout. Higher accuracy improves Perceptual Score
up to a certain point, but we uncover a Pareto frontier between accuracies and
Perceptual Score in the mid-to-high accuracy regime. We explore this
relationship further using distortion invariance, spatial frequency
sensitivity, and alternative perceptual functions. Interestingly we discover
shallow ResNets, trained for less than 5 epochs only on ImageNet, whose
emergent Perceptual Score matches the prior best networks trained directly on
supervised human perceptual judgements.</p>
  </details>
</details>
<details>
  <summary>2. <b>标题：Triangular Character Animation Sampling with Motion, Emotion, and  Relation</b></summary>
  <p><b>编号</b>：[8]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04930</p>
  <p><b>作者</b>：Yizhou Zhao,  Liang Qiu,  Wensi Ai,  Pan Lu,  Song-Chun Zhu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：emotion using markov chain monte carlo, enhance machine emotion intelligence, still lack automatic control, generate 3d character animations, conditional random field</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Dramatic progress has been made in animating individual characters. However,
we still lack automatic control over activities between characters, especially
those involving interactions. In this paper, we present a novel energy-based
framework to sample and synthesize animations by associating the characters'
body motions, facial expressions, and social relations. We propose a
Spatial-Temporal And-Or graph (ST-AOG), a stochastic grammar model, to encode
the contextual relationship between motion, emotion, and relation, forming a
triangle in a conditional random field. We train our model from a labeled
dataset of two-character interactions. Experiments demonstrate that our method
can recognize the social relation between two characters and sample new scenes
of vivid motion and emotion using Markov Chain Monte Carlo (MCMC) given the
social relation. Thus, our method can provide animators with an automatic way
to generate 3D character animations, help synthesize interactions between
Non-Player Characters (NPCs), and enhance machine emotion intelligence (EQ) in
virtual reality (VR).</p>
  </details>
</details>
<details>
  <summary>3. <b>标题：Leveling Down in Computer Vision: Pareto Inefficiencies in Fair Deep  Classifiers</b></summary>
  <p><b>编号</b>：[15]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04913</p>
  <p><b>作者</b>：Dominik Zietlow,  Michael Lohaus,  Guha Balakrishnan,  Matthäus Kleindessner,  Francesco Locatello,  Bernhard Schölkopf,  Chris Russell</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：computer vision also degrade performance, applying existing fairness approaches, best performing groups )., computer vision improve fairness, settings involving high</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Algorithmic fairness is frequently motivated in terms of a trade-off in which
overall performance is decreased so as to improve performance on disadvantaged
groups where the algorithm would otherwise be less accurate. Contrary to this,
we find that applying existing fairness approaches to computer vision improve
fairness by degrading the performance of classifiers across all groups (with
increased degradation on the best performing groups).
Extending the bias-variance decomposition for classification to fairness, we
theoretically explain why the majority of fairness classifiers designed for low
capacity models should not be used in settings involving high-capacity models,
a scenario common to computer vision. We corroborate this analysis with
extensive experimental support that shows that many of the fairness heuristics
used in computer vision also degrade performance on the most disadvantaged
groups. Building on these insights, we propose an adaptive augmentation
strategy that, uniquely, of all methods tested, improves performance for the
disadvantaged groups.</p>
  </details>
</details>
<details>
  <summary>4. <b>标题：Pose Guided Multi-person Image Generation From Text</b></summary>
  <p><b>编号</b>：[18]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04907</p>
  <p><b>作者</b>：Soon Yau Cheong,  Armin Mustafa,  Andrew Gilbert</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：generate high quality images, person images accurately representing, proposed keypoint pose encoding, create high fidelity full, low dimensional representation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Transformers have recently been shown to generate high quality images from
texts. However, existing methods struggle to create high fidelity full-body
images, especially multiple people. A person's pose has a high degree of
freedom that is difficult to describe using words only; this creates errors in
the generated image, such as incorrect body proportions and pose. We propose a
pose-guided text-to-image model, using pose as an additional input constraint.
Using the proposed Keypoint Pose Encoding (KPE) to encode human pose into low
dimensional representation, our model can generate novel multi-person images
accurately representing the pose and text descriptions provided, with minimal
errors. We demonstrate that KPE is invariant to changes in the target image
domain and image resolution; we show results on the Deepfashion dataset and
create a new multi-person Deepfashion dataset to demonstrate the
multi-capabilities of our approach.</p>
  </details>
</details>
<details>
  <summary>5. <b>标题：What Matters For Meta-Learning Vision Regression Tasks?</b></summary>
  <p><b>编号</b>：[19]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04905</p>
  <p><b>作者</b>：Ning Gao,  Hanna Ziesche,  Ngo Anh Vien,  Michael Volpp,  Gerhard Neumann</p>
  <p><b>备注</b>：Accepted at CVPR 2022</p>
  <p><b>关键词</b>：various deep learning techniques commonly used, paper makes two main contributions, category level vision regression tasks, design two new types, exhaustively evaluate common meta</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Meta-learning is widely used in few-shot classification and function
regression due to its ability to quickly adapt to unseen tasks. However, it has
not yet been well explored on regression tasks with high dimensional inputs
such as images. This paper makes two main contributions that help understand
this barely explored area. \emph{First}, we design two new types of
cross-category level vision regression tasks, namely object discovery and pose
estimation of unprecedented complexity in the meta-learning domain for computer
vision. To this end, we (i) exhaustively evaluate common meta-learning
techniques on these tasks, and (ii) quantitatively analyze the effect of
various deep learning techniques commonly used in recent meta-learning
algorithms in order to strengthen the generalization capability: data
augmentation, domain randomization, task augmentation and meta-regularization.
Finally, we (iii) provide some insights and practical recommendations for
training meta-learning algorithms on vision regression tasks. \emph{Second}, we
propose the addition of functional contrastive learning (FCL) over the task
representations in Conditional Neural Processes (CNPs) and train in an
end-to-end fashion. The experimental results show that the results of prior
work are misleading as a consequence of a poor choice of the loss function as
well as too small meta-training sets. Specifically, we find that CNPs
outperform MAML on most tasks without fine-tuning. Furthermore, we observe that
naive task augmentation without a tailored design results in underfitting.</p>
  </details>
</details>
<details>
  <summary>6. <b>标题：Model-Agnostic Multitask Fine-tuning for Few-shot Vision-Language  Transfer Learning</b></summary>
  <p><b>编号</b>：[20]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04904</p>
  <p><b>作者</b>：Zhenhailong Wang,  Hang Yu,  Manling Li,  Han Zhao,  Heng Ji</p>
  <p><b>备注</b>：7 pages, 6 figures, under review</p>
  <p><b>关键词</b>：uniform task sampling procedure, g ., fungi classification, prevent highly expressive model, simple yet efficient fine, uniform task sampling</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Despite achieving state-of-the-art zero-shot performance, existing
vision-language models, e.g., CLIP, still fall short of domain-specific
classification tasks, e.g., Fungi Classification. In the context of few-shot
transfer learning, traditional fine-tuning fails to prevent highly expressive
model from exploiting spurious correlations in the training data. On the other
hand, although model-agnostic meta-learning (MAML) presents as a natural
alternative for transfer learning, the expensive computation due to implicit
second-order optimization limits its use in large-scale models and datasets. In
this work we aim to further improve the generalization of existing
vision-language models on unseen tasks via a simple yet efficient fine-tuning
strategy based on uniform task sampling. We term our method as Model-Agnostic
Multitask Fine-tuning (MAMF). Compared with MAML, MAMF discards the bi-level
optimization and uses only first-order gradients, which makes it easily
scalable and computationally efficient. Due to the uniform task sampling
procedure, MAMF consistently outperforms the classical fine-tuning method for
few-shot transfer learning on five benchmark datasets. Empirically, we further
discover that the effectiveness of first-order MAML is highly dependent on the
zero-shot performance of the pretrained model, and our simple algorithm can
outperform first-order MAML on more challenging datasets with low zero-shot
performance.</p>
  </details>
</details>
<details>
  <summary>7. <b>标题：Joint Learning of Salient Object Detection, Depth Estimation and Contour  Extraction</b></summary>
  <p><b>编号</b>：[23]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04895</p>
  <p><b>作者</b>：Xiaoqi Zhao,  Youwei Pang,  Lihe Zhang,  Huchuan Lu</p>
  <p><b>备注</b>：Manuscript Version</p>
  <p><b>关键词</b>：sod methods obtain significant performance gain, provide important supplemental information, unify three complementary tasks, general depth sensors produce, location discrimination attributed</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Benefiting from color independence, illumination invariance and location
discrimination attributed by the depth map, it can provide important
supplemental information for extracting salient objects in complex
environments. However, high-quality depth sensors are expensive and can not be
widely applied. While general depth sensors produce the noisy and sparse depth
information, which brings the depth-based networks with irreversible
interference. In this paper, we propose a novel multi-task and multi-modal
filtered transformer (MMFT) network for RGB-D salient object detection (SOD).
Specifically, we unify three complementary tasks: depth estimation, salient
object detection and contour estimation. The multi-task mechanism promotes the
model to learn the task-aware features from the auxiliary tasks. In this way,
the depth information can be completed and purified. Moreover, we introduce a
multi-modal filtered transformer (MFT) module, which equips with three
modality-specific filters to generate the transformer-enhanced feature for each
modality. The proposed model works in a depth-free style during the testing
phase. Experiments show that it not only significantly surpasses the
depth-based RGB-D SOD methods on multiple datasets, but also precisely predicts
a high-quality depth map and salient contour at the same time. And, the
resulted depth map can help existing RGB-D SOD methods obtain significant
performance gain.</p>
  </details>
</details>
<details>
  <summary>8. <b>标题：Low-light Image and Video Enhancement via Selective Manipulation of  Chromaticity</b></summary>
  <p><b>编号</b>：[25]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04889</p>
  <p><b>作者</b>：Sumit Shekhar,  Max Reimann,  Amir Semmo,  Sebastian Pasewaldt,  Jürgen Döllner,  Matthias Trapp</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：standard lowlight image datasets show, simple yet effective approach, additional temporal domain makes, image processing algorithms applied, various computer vision</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Image acquisition in low-light conditions suffers from poor quality and
significant degradation in visual aesthetics. This affects the visual
perception of the acquired image and the performance of various computer vision
and image processing algorithms applied after acquisition. Especially for
videos, the additional temporal domain makes it more challenging, wherein we
need to preserve quality in a temporally coherent manner. We present a simple
yet effective approach for low-light image and video enhancement. To this end,
we introduce "Adaptive Chromaticity", which refers to an adaptive computation
of image chromaticity. The above adaptivity allows us to avoid the costly step
of low-light image decomposition into illumination and reflectance, employed by
many existing techniques. All stages in our method consist of only point-based
operations and high-pass or low-pass filtering, thereby ensuring that the
amount of temporal incoherence is negligible when applied on a per-frame basis
for videos. Our results on standard lowlight image datasets show the efficacy
of our algorithm and its qualitative and quantitative superiority over several
state-of-the-art techniques. For videos captured in the wild, we perform a user
study to demonstrate the preference for our method in comparison to
state-of-the-art approaches.</p>
  </details>
</details>
<details>
  <summary>9. <b>标题：Efficient Image Representation Learning with Federated Sampled Softmax</b></summary>
  <p><b>编号</b>：[26]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04888</p>
  <p><b>作者</b>：Sagar M. Waghmare,  Hang Qi,  Huizhong Chen,  Mikhail Sirotenko,  Tomer Meron</p>
  <p><b>备注</b>：15 pages, 10 figures, 4 tables and 1 algorithm</p>
  <p><b>关键词</b>：standard full softmax method, global full softmax objective, softmax cross entropy loss, aggregated across data silos, introduce federated sampled softmax</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Learning image representations on decentralized data can bring many benefits
in cases where data cannot be aggregated across data silos. Softmax cross
entropy loss is highly effective and commonly used for learning image
representations. Using a large number of classes has proven to be particularly
beneficial for the descriptive power of such representations in centralized
learning. However, doing so on decentralized data with Federated Learning is
not straightforward as the demand on FL clients' computation and communication
increases proportionally to the number of classes. In this work we introduce
federated sampled softmax (FedSS), a resource-efficient approach for learning
image representation with Federated Learning. Specifically, the FL clients
sample a set of classes and optimize only the corresponding model parameters
with respect to a sampled softmax objective that approximates the global full
softmax objective. We examine the loss formulation and empirically show that
our method significantly reduces the number of parameters transferred to and
optimized by the client devices, while performing on par with the standard full
softmax method. This work creates a possibility for efficiently learning image
representations on decentralized data with a large number of classes under the
federated setting.</p>
  </details>
</details>
<details>
  <summary>10. <b>标题：VGQ-CNN: Moving Beyond Fixed Cameras and Top-Grasps for Grasp Quality  Prediction</b></summary>
  <p><b>编号</b>：[30]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04874</p>
  <p><b>作者</b>：A. Konrad,  J. McDonald,  R. Villing</p>
  <p><b>备注</b>：Submitted to WCCI</p>
  <p><b>关键词</b>：based grasp evaluation methods like gq, versatile grasp quality convolutional neural network, make 128 grasp quality predictions, new versatile grasp dataset, grasp quality prediction network</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present the Versatile Grasp Quality Convolutional Neural Network
(VGQ-CNN), a grasp quality prediction network for 6-DOF grasps. VGQ-CNN can be
used when evaluating grasps for objects seen from a wide range of camera poses
or mobile robots without the need to retrain the network. By defining the grasp
orientation explicitly as an input to the network, VGQ-CNN can evaluate 6-DOF
grasp poses, moving beyond the 4-DOF grasps used in most image-based grasp
evaluation methods like GQ-CNN. We train VGQ-CNN on our new Versatile Grasp
dataset (VG-dset), containing 6-DOF grasps observed from a wide range of camera
poses. VGQ-CNN achieves a balanced accuracy of 82.1% on our test-split while
generalising to a variety of camera poses. Meanwhile, it achieves competitive
performance for overhead cameras and top-grasps with a balanced accuracy of
74.2% compared to GQ-CNN's 76.6%. We also propose a modified network
architecture, FAST-VGQ-CNN, that speeds up inference using a shared encoder
architecture and can make 128 grasp quality predictions in 12ms on a CPU. Code
and data are available at this https URL.</p>
  </details>
</details>
<details>
  <summary>11. <b>标题：CEU-Net: Ensemble Semantic Segmentation of Hyperspectral Images Using  Clustering</b></summary>
  <p><b>编号</b>：[31]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04873</p>
  <p><b>作者</b>：Nicholas Soucy,  Salimeh Yasaei Sekeh</p>
  <p><b>备注</b>：11 Pages, 5 Tables, 1 Algorithm, 5 Figures</p>
  <p><b>关键词</b>：accurately classify diversified land cover, net model outperforms existing state, art hsi semantic segmentation methods, combine spectral information extracted, high performance across botswana</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Most semantic segmentation approaches of Hyperspectral images (HSIs) use and
require preprocessing steps in the form of patching to accurately classify
diversified land cover in remotely sensed images. These approaches use patching
to incorporate the rich neighborhood information in images and exploit the
simplicity and segmentability of the most common HSI datasets. In contrast,
most landmasses in the world consist of overlapping and diffused classes,
making neighborhood information weaker than what is seen in common HSI
datasets. To combat this issue and generalize the segmentation models to more
complex and diverse HSI datasets, in this work, we propose our novel flagship
model: Clustering Ensemble U-Net (CEU-Net). CEU-Net uses the ensemble method to
combine spectral information extracted from convolutional neural network (CNN)
training on a cluster of landscape pixels. Our CEU-Net model outperforms
existing state-of-the-art HSI semantic segmentation methods and gets
competitive performance with and without patching when compared to baseline
models. We highlight CEU-Net's high performance across Botswana, KSC, and
Salinas datasets compared to HybridSN and AeroRIT methods.</p>
  </details>
</details>
<details>
  <summary>12. <b>标题：Coarse-to-Fine Sparse Transformer for Hyperspectral Image Reconstruction</b></summary>
  <p><b>编号</b>：[38]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04845</p>
  <p><b>作者</b>：Jing Lin,  Yuanhao Cai,  Xiaowan Hu,  Haoqian Wang,  Xin Yuan,  Yulun Zhang,  Radu Timofte,  Luc Van Gool</p>
  <p><b>备注</b>：A novel state-of-the-art Transformer-based method for hyperspectral image reconstruction</p>
  <p><b>关键词</b>：cst ), firstly embedding hsi sparsity, coded aperture snapshot spectral imaging, based methods densely sample tokens, requiring cheaper computational costs, cst significantly outperforms state</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Many algorithms have been developed to solve the inverse problem of coded
aperture snapshot spectral imaging (CASSI), i.e., recovering the 3D
hyperspectral images (HSIs) from a 2D compressive measurement. In recent years,
learning-based methods have demonstrated promising performance and dominated
the mainstream research direction. However, existing CNN-based methods show
limitations in capturing long-range dependencies and non-local self-similarity.
Previous Transformer-based methods densely sample tokens, some of which are
uninformative, and calculate the multi-head self-attention (MSA) between some
tokens that are unrelated in content. This does not fit the spatially sparse
nature of HSI signals and limits the model scalability. In this paper, we
propose a novel Transformer-based method, coarse-to-fine sparse Transformer
(CST), firstly embedding HSI sparsity into deep learning for HSI
reconstruction. In particular, CST uses our proposed spectra-aware screening
mechanism (SASM) for coarse patch selecting. Then the selected patches are fed
into our customized spectra-aggregation hashing multi-head self-attention
(SAH-MSA) for fine pixel clustering and self-similarity capturing.
Comprehensive experiments show that our CST significantly outperforms
state-of-the-art methods while requiring cheaper computational costs. The code
and models will be made public.</p>
  </details>
</details>
<details>
  <summary>13. <b>标题：CMX: Cross-Modal Fusion for RGB-X Semantic Segmentation with  Transformers</b></summary>
  <p><b>编号</b>：[40]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04838</p>
  <p><b>作者</b>：Huayao Liu,  Jiaming Zhang,  Kailun Yang,  Xinxin Hu,  Rainer Stiefelhagen</p>
  <p><b>备注</b>：Code is available at this https URL</p>
  <p><b>关键词</b>：different sensing modalities encompassing various uncertainties, event semantic segmentation benchmark based, modal feature rectification module, final semantic prediction, sparse data fusion</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The performance of semantic segmentation of RGB images can be advanced by
exploiting informative features from supplementary modalities. In this work, we
propose CMX, a vision-transformer-based cross-modal fusion framework for RGB-X
semantic segmentation. To generalize to different sensing modalities
encompassing various uncertainties, we consider that comprehensive cross-modal
interactions should be provided. CMX is built with two streams to extract
features from RGB images and the complementary modality (X-modality). In each
feature extraction stage, we design a Cross-Modal Feature Rectification Module
(CM-FRM) to calibrate the feature of the current modality by combining the
feature from the other modality, in spatial- and channel-wise dimensions. With
rectified feature pairs, we deploy a Feature Fusion Module (FFM) to mix them
for the final semantic prediction. FFM is constructed with a cross-attention
mechanism, which enables exchange of long-range contexts, enhancing both
modalities' features at a global level. Extensive experiments show that CMX
generalizes to diverse multi-modal combinations, achieving state-of-the-art
performances on four RGB-Depth benchmarks, as well as RGB-Thermal and
RGB-Polarization datasets. Besides, to investigate the generalizability to
dense-sparse data fusion, we establish a RGB-Event semantic segmentation
benchmark based on the EventScape dataset, on which CMX sets the new
state-of-the-art. Code is available at
this https URL</p>
  </details>
</details>
<details>
  <summary>14. <b>标题：A high-precision underwater object detection based on joint  self-supervised deblurring and improved spatial transformer network</b></summary>
  <p><b>编号</b>：[45]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04822</p>
  <p><b>作者</b>：Xiuyuan Li,  Fengchao Li,  Jiangang Yu,  Guowen An</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：obtain sufficient underwater object images captured, task learning aided object detection architecture, adaptively enriching image features within, proposed uod approach achieved 47, based underwater object detection</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep learning-based underwater object detection (UOD) remains a major
challenge due to the degraded visibility and difficulty to obtain sufficient
underwater object images captured from various perspectives for training. To
address these issues, this paper presents a high-precision UOD based on joint
self-supervised deblurring and improved spatial transformer network. A
self-supervised deblurring subnetwork is introduced into the designed
multi-task learning aided object detection architecture to force the shared
feature extraction module to output clean features for detection subnetwork.
Aiming at alleviating the limitation of insufficient photos from different
perspectives, an improved spatial transformer network is designed based on
perspective transformation, adaptively enriching image features within the
network. The experimental results show that the proposed UOD approach achieved
47.9 mAP in URPC2017 and 70.3 mAP in URPC2018, outperforming many
state-of-the-art UOD methods and indicating the designed method is more
suitable for UOD.</p>
  </details>
</details>
<details>
  <summary>15. <b>标题：Text-DIAE: Degradation Invariant Autoencoders for Text Recognition and  Document Enhancement</b></summary>
  <p><b>编号</b>：[49]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04814</p>
  <p><b>作者</b>：Mohamed Ali Souibgui,  Sanket Biswas,  Andres Mafla,  Ali Furkan Biten,  Alicia Fornés,  Yousri Kessentini,  Josep Lladós,  Lluis Gomez,  Dimosthenis Karatzas</p>
  <p><b>备注</b>：Submitted to ECCV 2022</p>
  <p><b>关键词</b>：time requiring essentially fewer data samples, http :// upon_acceptance }., conduct several ablation experiments, define three pretext tasks, degradation invariant auto encoder</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this work, we propose Text-Degradation Invariant Auto Encoder (Text-DIAE)
aimed to solve two tasks, text recognition (handwritten or scene-text) and
document image enhancement. We define three pretext tasks as learning
objectives to be optimized during pre-training without the usage of labelled
data. Each of the pre-text objectives is specifically tailored for the final
downstream tasks. We conduct several ablation experiments that show the
importance of each degradation for a specific domain. Exhaustive
experimentation shows that our method does not have limitations of previous
state-of-the-art based on contrastive losses while at the same time requiring
essentially fewer data samples to converge. Finally, we demonstrate that our
method surpasses the state-of-the-art significantly in existing supervised and
self-supervised settings in handwritten and scene text recognition and document
image enhancement. Our code and trained models will be made publicly available
at~\url{ http://Upon_Acceptance}.</p>
  </details>
</details>
<details>
  <summary>16. <b>标题：A high-precision self-supervised monocular visual odometry in foggy  weather based on robust cycled generative adversarial networks and multi-task  learning aided depth estimation</b></summary>
  <p><b>编号</b>：[51]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04812</p>
  <p><b>作者</b>：Xiuyuan Li,  Jiangang Yu,  Fengchao Li,  Guowen An</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：task learning aided depth estimation module, synthetic foggy kitti dataset show, supervised monocular vo performs better, cycled generative adversarial network, supervised loss via forcing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper proposes a high-precision self-supervised monocular VO, which is
specifically designed for navigation in foggy weather. A cycled generative
adversarial network is designed to obtain high-quality self-supervised loss via
forcing the forward and backward half-cycle to output consistent estimation.
Moreover, gradient-based loss and perceptual loss are introduced to eliminate
the interference of complex photometric change on self-supervised loss in foggy
weather. To solve the ill-posed problem of depth estimation, a self-supervised
multi-task learning aided depth estimation module is designed based on the
strong correlation between the depth estimation and transmission map
calculation of hazy images in foggy weather. The experimental results on the
synthetic foggy KITTI dataset show that the proposed self-supervised monocular
VO performs better in depth and pose estimation than other state-of-the-art
monocular VO in the literature, indicating the designed method is more suitable
for foggy weather.</p>
  </details>
</details>
<details>
  <summary>17. <b>标题：NeRF-Pose: A First-Reconstruct-Then-Regress Approach for  Weakly-supervised 6D Object Pose Estimation</b></summary>
  <p><b>编号</b>：[55]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04802</p>
  <p><b>作者</b>：Fu Li,  Hao Yu,  Ivan Shugurov,  Benjamin Busam,  Shaowu Yang,  Slobodan Ilic</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：best 6d pose estimation methods, 6d pose estimation typically rely, existing deep learning approaches, synthetic data scales well, known relative camera poses</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Pose estimation of 3D objects in monocular images is a fundamental and
long-standing problem in computer vision. Existing deep learning approaches for
6D pose estimation typically rely on the assumption of availability of 3D
object models and 6D pose annotations. However, precise annotation of 6D poses
in real data is intricate, time-consuming and not scalable, while synthetic
data scales well but lacks realism. To avoid these problems, we present a
weakly-supervised reconstruction-based pipeline, named NeRF-Pose, which needs
only 2D object segmentation and known relative camera poses during training.
Following the first-reconstruct-then-regress idea, we first reconstruct the
objects from multiple views in the form of an implicit neural representation.
Then, we train a pose regression network to predict pixel-wise 2D-3D
correspondences between images and the reconstructed model. At inference, the
approach only needs a single image as input. A NeRF-enabled PnP+RANSAC
algorithm is used to estimate stable and accurate pose from the predicted
correspondences. Experiments on LineMod and LineMod-Occlusion show that the
proposed method has state-of-the-art accuracy in comparison to the best 6D pose
estimation methods in spite of being trained only with weak labels. Besides, we
extend the Homebrewed DB dataset with more real training images to support the
weakly supervised task and achieve compelling results on this dataset. The
extended dataset and code will be released soon.</p>
  </details>
</details>
<details>
  <summary>18. <b>标题：Evaluation of YOLO Models with Sliced Inference for Small Object  Detection</b></summary>
  <p><b>编号</b>：[57]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04799</p>
  <p><b>作者</b>：Muhammed Can Keles,  Batuhan Salmanoglu,  Mehmet Serdar Guzel,  Baran Gursoy,  Gazi Erkan Bostanci</p>
  <p><b>备注</b>：6 pages, 5 figures</p>
  <p><b>关键词</b>：sliced inference combined produced substantial improvement, art yolo based object detection models, use object detection models, small object detection, small object detection</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Small object detection has major applications in the fields of UAVs,
surveillance, farming and many others. In this work we investigate the
performance of state of the art Yolo based object detection models for the task
of small object detection as they are one of the most popular and easy to use
object detection models. We evaluated YOLOv5 and YOLOX models in this study. We
also investigate the effects of slicing aided inference and fine-tuning the
model for slicing aided inference. We used the VisDrone2019Det dataset for
training and evaluating our models. This dataset is challenging in the sense
that most objects are relatively small compared to the image sizes. This work
aims to benchmark the YOLOv5 and YOLOX models for small object detection. We
have seen that sliced inference increases the AP50 score in all experiments,
this effect was greater for the YOLOv5 models compared to the YOLOX models. The
effects of sliced fine-tuning and sliced inference combined produced
substantial improvement for all models. The highest AP50 score was achieved by
the YOLOv5- Large model on the VisDrone2019Det test-dev subset with the score
being 48.8.</p>
  </details>
</details>
<details>
  <summary>19. <b>标题：How many Observations are Enough? Knowledge Distillation for Trajectory  Forecasting</b></summary>
  <p><b>编号</b>：[63]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04781</p>
  <p><b>作者</b>：Alessio Monti,  Angelo Porrello,  Simone Calderara,  Pasquale Coscia,  Lamberto Ballan,  Rita Cucchiara</p>
  <p><b>备注</b>：Accepted by CVPR 2022</p>
  <p><b>关键词</b>：common trajectory forecasting datasets highlight, common schema neglects critical traits, input trajectories involves machine perception, properly defined teacher supervision allows, fragmentation errors may accumulate</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Accurate prediction of future human positions is an essential task for modern
video-surveillance systems. Current state-of-the-art models usually rely on a
"history" of past tracked locations (e.g., 3 to 5 seconds) to predict a
plausible sequence of future locations (e.g., up to the next 5 seconds). We
feel that this common schema neglects critical traits of realistic
applications: as the collection of input trajectories involves machine
perception (i.e., detection and tracking), incorrect detection and
fragmentation errors may accumulate in crowded scenes, leading to tracking
drifts. On this account, the model would be fed with corrupted and noisy input
data, thus fatally affecting its prediction performance.
In this regard, we focus on delivering accurate predictions when only few
input observations are used, thus potentially lowering the risks associated
with automatic perception. To this end, we conceive a novel distillation
strategy that allows a knowledge transfer from a teacher network to a student
one, the latter fed with fewer observations (just two ones). We show that a
properly defined teacher supervision allows a student network to perform
comparably to state-of-the-art approaches that demand more observations.
Besides, extensive experiments on common trajectory forecasting datasets
highlight that our student network better generalizes to unseen scenarios.</p>
  </details>
</details>
<details>
  <summary>20. <b>标题：Multiscale Convolutional Transformer with Center Mask Pretraining for  Hyperspectral Image Classificationtion</b></summary>
  <p><b>编号</b>：[66]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04771</p>
  <p><b>作者</b>：Yifan Wang,  Sen Jia,  Zhongfan Zhang</p>
  <p><b>备注</b>：8 pages, 26 figures, conference paper</p>
  <p><b>关键词</b>：also contain rich spectral information, scale convolutional embedding module, http url recent years, http url order, realize effective extraction</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Hyperspectral images (HSI) not only have a broad macroscopic field of view
but also contain rich spectral information, and the types of surface objects
can be identified through spectral information, which is one of the main
applications in hyperspectral image related this http URL recent years, more and
more deep learning methods have been proposed, among which convolutional neural
networks (CNN) are the most influential. However, CNN-based methods are
difficult to capture long-range dependencies, and also require a large amount
of labeled data for model training.Besides, most of the self-supervised
training methods in the field of HSI classification are based on the
reconstruction of input samples, and it is difficult to achieve effective use
of unlabeled samples. To address the shortcomings of CNN networks, we propose a
noval multi-scale convolutional embedding module for HSI to realize effective
extraction of spatial-spectral information, which can be better combined with
Transformer this http URL order to make more efficient use of unlabeled data, we
propose a new self-supervised pretask. Similar to Mask autoencoder, but our
pre-training method only masks the corresponding token of the central pixel in
the encoder, and inputs the remaining token into the decoder to reconstruct the
spectral information of the central pixel.Such a pretask can better model the
relationship between the central feature and the domain feature, and obtain
more stable training results.</p>
  </details>
</details>
<details>
  <summary>21. <b>标题：SkinningNet: Two-Stream Graph Convolutional Neural Network for Skinning  Prediction of Synthetic Characters</b></summary>
  <p><b>编号</b>：[79]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04746</p>
  <p><b>作者</b>：Albert Mosella-Montoro,  Javier Ruiz-Hidalgo</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：stream graph neural network architecture, whereas previous methods pre, skinningnet outperforming current state, aggregator graph convolution, work presents skinningnet</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This work presents SkinningNet, an end-to-end Two-Stream Graph Neural Network
architecture that computes skinning weights from an input mesh and its
associated skeleton, without making any assumptions on shape class and
structure of the provided mesh. Whereas previous methods pre-compute
handcrafted features that relate the mesh and the skeleton or assume a fixed
topology of the skeleton, the proposed method extracts this information in an
end-to-end learnable fashion by jointly learning the best relationship between
mesh vertices and skeleton joints. The proposed method exploits the benefits of
the novel Multi-Aggregator Graph Convolution that combines the results of
different aggregators during the summarizing step of the Message-Passing
scheme, helping the operation to generalize for unseen topologies. Experimental
results demonstrate the effectiveness of the contributions of our novel
architecture, with SkinningNet outperforming current state-of-the-art
alternatives.</p>
  </details>
</details>
<details>
  <summary>22. <b>标题：Parallel Training of GRU Networks with a Multi-Grid Solver for Long  Sequences</b></summary>
  <p><b>编号</b>：[84]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04738</p>
  <p><b>作者</b>：Gordon Euhyun Moon,  Eric C. Cyr</p>
  <p><b>备注</b>：Accepted at ICLR 2022</p>
  <p><b>关键词</b>：parallel gru algorithm achieves significant performance improvement, new parallel training scheme achieves, still inevitably performance limited, parallelizing gated recurrent unit, novel parallel training scheme</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Parallelizing Gated Recurrent Unit (GRU) networks is a challenging task, as
the training procedure of GRU is inherently sequential. Prior efforts to
parallelize GRU have largely focused on conventional parallelization strategies
such as data-parallel and model-parallel training algorithms. However, when the
given sequences are very long, existing approaches are still inevitably
performance limited in terms of training time. In this paper, we present a
novel parallel training scheme (called parallel-in-time) for GRU based on a
multigrid reduction in time (MGRIT) solver. MGRIT partitions a sequence into
multiple shorter sub-sequences and trains the sub-sequences on different
processors in parallel. The key to achieving speedup is a hierarchical
correction of the hidden state to accelerate end-to-end communication in both
the forward and backward propagation phases of gradient descent. Experimental
results on the HMDB51 dataset, where each video is an image sequence,
demonstrate that the new parallel training scheme achieves up to 6.5$\times$
speedup over a serial approach. As efficiency of our new parallelization
strategy is associated with the sequence length, our parallel GRU algorithm
achieves significant performance improvement as the sequence length increases.</p>
  </details>
</details>
<details>
  <summary>23. <b>标题：P2M: A Processing-in-Pixel-in-Memory Paradigm for Resource-Constrained  TinyML Applications</b></summary>
  <p><b>编号</b>：[85]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04737</p>
  <p><b>作者</b>：Gourav Datta,  Souvik Kundu,  Zihan Yin,  Ravi Teja Lakkireddy,  Peter A. Beerel,  Ajey Jacob,  Akhilesh R. Jaiswal</p>
  <p><b>备注</b>：13 pages, 7 figures</p>
  <p><b>关键词</b>：resolution input images still need, manufacturable cmos image sensor platforms, p2m reduces data transfer bandwidth, subsequent ai processing using analog, visual wake words dataset</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The demand to process vast amounts of data generated from state-of-the-art
high resolution cameras has motivated novel energy-efficient on-device AI
solutions. Visual data in such cameras are usually captured in the form of
analog voltages by a sensor pixel array, and then converted to the digital
domain for subsequent AI processing using analog-to-digital converters (ADC).
Recent research has tried to take advantage of massively parallel low-power
analog/digital computing in the form of near- and in-sensor processing, in
which the AI computation is performed partly in the periphery of the pixel
array and partly in a separate on-board CPU/accelerator. Unfortunately,
high-resolution input images still need to be streamed between the camera and
the AI processing unit, frame by frame, causing energy, bandwidth, and security
bottlenecks. To mitigate this problem, we propose a novel
Processing-in-Pixel-in-memory (P2M) paradigm, that customizes the pixel array
by adding support for analog multi-channel, multi-bit convolution and ReLU
(Rectified Linear Units). Our solution includes a holistic algorithm-circuit
co-design approach and the resulting P2M paradigm can be used as a drop-in
replacement for embedding memory-intensive first few layers of convolutional
neural network (CNN) models within foundry-manufacturable CMOS image sensor
platforms. Our experimental results indicate that P2M reduces data transfer
bandwidth from sensors and analog to digital conversions by ~21x, and the
energy-delay product (EDP) incurred in processing a MobileNetV2 model on a
TinyML use case for visual wake words dataset (VWW) by up to ~11x compared to
standard near-processing or in-sensor implementations, without any significant
drop in test accuracy.</p>
  </details>
</details>
<details>
  <summary>24. <b>标题：Defending Black-box Skeleton-based Human Activity Classifiers</b></summary>
  <p><b>编号</b>：[91]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04713</p>
  <p><b>作者</b>：He Wang,  Yunfeng Diao,  Zichang Tan,  Guodong Guo</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：robust ones without sacrificing accuracy, based human activity recognition, robust discriminative classifiers, universal effectiveness across, turns vulnerable black</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep learning has been regarded as the `go to' solution for many tasks today,
but its intrinsic vulnerability to malicious attacks has become a major
concern. The vulnerability is affected by a variety of factors including
models, tasks, data, and attackers. Consequently, methods such as Adversarial
Training and Randomized Smoothing have been proposed to tackle the problem in a
wide range of applications. In this paper, we investigate skeleton-based Human
Activity Recognition, which is an important type of time-series data but
under-explored in defense against attacks. Our method is featured by (1) a new
Bayesian Energy-based formulation of robust discriminative classifiers, (2) a
new parameterization of the adversarial sample manifold of actions, and (3) a
new post-train Bayesian treatment on both the adversarial samples and the
classifier. We name our framework Bayesian Energy-based Adversarial Training or
BEAT. BEAT is straightforward but elegant, which turns vulnerable black-box
classifiers into robust ones without sacrificing accuracy. It demonstrates
surprising and universal effectiveness across a wide range of action
classifiers and datasets, under various attacks.</p>
  </details>
</details>
<details>
  <summary>25. <b>标题：A Unified Transformer Framework for Group-based Segmentation:  Co-Segmentation, Co-Saliency Detection and Video Salient Object Detection</b></summary>
  <p><b>编号</b>：[94]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04708</p>
  <p><b>作者</b>：Yukun Su,  Jingliang Deng,  Ruizhou Sun,  Guosheng Lin,  Qingyao Wu</p>
  <p><b>备注</b>：Code: this https URL</p>
  <p><b>关键词</b>：previous approaches design different networks, msrc ), three cosd benchmarks, patch structured similarities among, video salient object detection, three different tasks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Humans tend to mine objects by learning from a group of images or several
frames of video since we live in a dynamic world. In the computer vision area,
many researches focus on co-segmentation (CoS), co-saliency detection (CoSD)
and video salient object detection (VSOD) to discover the co-occurrent objects.
However, previous approaches design different networks on these similar tasks
separately, and they are difficult to apply to each other, which lowers the
upper bound of the transferability of deep learning frameworks. Besides, they
fail to take full advantage of the cues among inter- and intra-feature within a
group of images. In this paper, we introduce a unified framework to tackle
these issues, term as UFO (Unified Framework for Co-Object Segmentation).
Specifically, we first introduce a transformer block, which views the image
feature as a patch token and then captures their long-range dependencies
through the self-attention mechanism. This can help the network to excavate the
patch structured similarities among the relevant objects. Furthermore, we
propose an intra-MLP learning module to produce self-mask to enhance the
network to avoid partial activation. Extensive experiments on four CoS
benchmarks (PASCAL, iCoseg, Internet and MSRC), three CoSD benchmarks
(Cosal2015, CoSOD3k, and CocA) and four VSOD benchmarks (DAVIS16, FBMS, ViSal
and SegV2) show that our method outperforms other state-of-the-arts on three
different tasks in both accuracy and speed by using the same network
architecture , which can reach 140 FPS in real-time.</p>
  </details>
</details>
<details>
  <summary>26. <b>标题：FlexIT: Towards Flexible Semantic Image Translation</b></summary>
  <p><b>编号</b>：[95]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04705</p>
  <p><b>作者</b>：Guillaume Couairon,  Asya Grechka,  Jakob Verbeek,  Holger Schwenk,  Matthieu Cord</p>
  <p><b>备注</b>：accepted at CVPR 2022</p>
  <p><b>关键词</b>：clip multimodal embedding space, made publicly available, generate near photo, deep generative models, semantic image translation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep generative models, like GANs, have considerably improved the state of
the art in image synthesis, and are able to generate near photo-realistic
images in structured domains such as human faces. Based on this success, recent
work on image editing proceeds by projecting images to the GAN latent space and
manipulating the latent vector. However, these approaches are limited in that
only images from a narrow domain can be transformed, and with only a limited
number of editing operations. We propose FlexIT, a novel method which can take
any input image and a user-defined text instruction for editing. Our method
achieves flexible and natural editing, pushing the limits of semantic image
translation. First, FlexIT combines the input image and text into a single
target point in the CLIP multimodal embedding space. Via the latent space of an
auto-encoder, we iteratively transform the input image toward the target point,
ensuring coherence and quality with a variety of novel regularization terms. We
propose an evaluation protocol for semantic image translation, and thoroughly
evaluate our method on ImageNet. Code will be made publicly available.</p>
  </details>
</details>
<details>
  <summary>27. <b>标题：Align-Deform-Subtract: An Interventional Framework for Explaining Object  Differences</b></summary>
  <p><b>编号</b>：[102]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04694</p>
  <p><b>作者</b>：Cian Eastwood,  Li Nanbo,  Christopher K. I. Williams</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：given two object images, synthetic data illustrate, leveraging semantic alignments, explaining object differences, underlying object properties</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Given two object images, how can we explain their differences in terms of the
underlying object properties? To address this question, we propose
Align-Deform-Subtract (ADS) -- an interventional framework for explaining
object differences. By leveraging semantic alignments in image-space as
counterfactual interventions on the underlying object properties, ADS
iteratively quantifies and removes differences in object properties. The result
is a set of "disentangled" error measures which explain object differences in
terms of their underlying properties. Experiments on real and synthetic data
illustrate the efficacy of the framework.</p>
  </details>
</details>
<details>
  <summary>28. <b>标题：Structure-Aware Flow Generation for Human Body Reshaping</b></summary>
  <p><b>编号</b>：[106]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04670</p>
  <p><b>作者</b>：Jianqiang Ren,  Yuan Yao,  Biwen Lei,  Miaomiao Cui,  Xuansong Xie</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：3d domain via body morphable model, manipulation consistency among related parts, approach significantly outperforms existing state, existing methods either fall back, achieve unprecedentedly controllable performance</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Body reshaping is an important procedure in portrait photo retouching. Due to
the complicated structure and multifarious appearance of human bodies, existing
methods either fall back on the 3D domain via body morphable model or resort to
keypoint-based image deformation, leading to inefficiency and unsatisfied
visual quality. In this paper, we address these limitations by formulating an
end-to-end flow generation architecture under the guidance of body structural
priors, including skeletons and Part Affinity Fields, and achieve
unprecedentedly controllable performance under arbitrary poses and garments. A
compositional attention mechanism is introduced for capturing both visual
perceptual correlations and structural associations of the human body to
reinforce the manipulation consistency among related parts. For a comprehensive
evaluation, we construct the first large-scale body reshaping dataset, namely
BR-5K, which contains 5,000 portrait photos as well as professionally retouched
targets. Extensive experiments demonstrate that our approach significantly
outperforms existing state-of-the-art methods in terms of visual performance,
controllability, and efficiency. The dataset is available at our website:
this https URL.</p>
  </details>
</details>
<details>
  <summary>29. <b>标题：Inadequately Pre-trained Models are Better Feature Extractors</b></summary>
  <p><b>编号</b>：[107]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04668</p>
  <p><b>作者</b>：Andong Deng,  Xingjian Li,  Zhibing Li,  Di Hu,  Chengzhong Xu,  Dejing Dou</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：first learn spectral components corresponding, better feature extractor fails, outperform fully trained models, residual components contribute, tuned better accordingly</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Pre-training has been a popular learning paradigm in deep learning era,
especially in annotation-insufficient scenario. Better ImageNet pre-trained
models have been demonstrated, from the perspective of architecture, by
previous research to have better transferability to downstream tasks. However,
in this paper, we found that during the same pre-training process, models at
middle epochs, which is inadequately pre-trained, can outperform fully trained
models when used as feature extractors (FE), while the fine-tuning (FT)
performance still grows with the source performance. This reveals that there is
not a solid positive correlation between top-1 accuracy on ImageNet and the
transferring result on target data. Based on the contradictory phenomenon
between FE and FT that better feature extractor fails to be fine-tuned better
accordingly, we conduct comprehensive analyses on features before softmax layer
to provide insightful explanations. Our discoveries suggest that, during
pre-training, models tend to first learn spectral components corresponding to
large singular values and the residual components contribute more when
fine-tuning.</p>
  </details>
</details>
<details>
  <summary>30. <b>标题：Simulation of Plenoptic Cameras</b></summary>
  <p><b>编号</b>：[110]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04662</p>
  <p><b>作者</b>：Tim Michels,  Arne Petersen,  Luca Palmieri,  Reinhard Koch</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：different plenoptic camera types, area currently lacks data, ground truth data, use blender model, simulation publicly available</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Plenoptic cameras enable the capturing of spatial as well as angular color
information which can be used for various applications among which are image
refocusing and depth calculations. However, these cameras are expensive and
research in this area currently lacks data for ground truth comparisons. In
this work we describe a flexible, easy-to-use Blender model for the different
plenoptic camera types which is on the one hand able to provide the ground
truth data for research and on the other hand allows an inexpensive assessment
of the cameras usefulness for the desired applications. Furthermore we show
that the rendering results exhibit the same image degradation effects as real
cameras and make our simulation publicly available.</p>
  </details>
</details>
<details>
  <summary>31. <b>标题：Creating Realistic Ground Truth Data for the Evaluation of Calibration  Methods for Plenoptic and Conventional Cameras</b></summary>
  <p><b>编号</b>：[111]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04661</p>
  <p><b>作者</b>：Tim Michels,  Arne Petersen,  Reinhard Koch</p>
  <p><b>备注</b>：9 pages, 8 figures. Accepted at 3DV 2019</p>
  <p><b>关键词</b>：create realistic ground truth data, synthetic ground truth data available, camera calibration methods usually consist, every camera perfectly complies, realistic synthetic data</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Camera calibration methods usually consist of capturing images of known
calibration patterns and using the detected correspondences to optimize the
parameters of the assumed camera model. A meaningful evaluation of these
methods relies on the availability of realistic synthetic data. In previous
works concerned with conventional cameras the synthetic data was mainly created
by rendering perfect images with a pinhole camera and subsequently adding
distortions and aberrations to the renderings and correspondences according to
the assumed camera model. This method can bias the evaluation since not every
camera perfectly complies with an assumed model. Furthermore, in the field of
plenoptic camera calibration there is no synthetic ground truth data available
at all. We address these problems by proposing a method based on backward ray
tracing to create realistic ground truth data that can be used for an unbiased
evaluation of calibration methods for both types of cameras.</p>
  </details>
</details>
<details>
  <summary>32. <b>标题：Ray Tracing-Guided Design of Plenoptic Cameras</b></summary>
  <p><b>编号</b>：[112]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04660</p>
  <p><b>作者</b>：Tim Michels,  Reinhard Koch</p>
  <p><b>备注</b>：9 pages, 9 figures. Accepted at 3DV 2021. 2021 International Conference on 3D Vision (3DV). IEEE, 2021</p>
  <p><b>关键词</b>：evaluation setup including 30 plenoptic camera designs, two dissimilar optical systems, multiple plenoptic camera setups, commonly used paraxial approximations, main lens data given</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The design of a plenoptic camera requires the combination of two dissimilar
optical systems, namely a main lens and an array of microlenses. And while the
construction process of a conventional camera is mainly concerned with focusing
the image onto a single plane, in the case of plenoptic cameras there can be
additional requirements such as a predefined depth of field or a desired range
of disparities in neighboring microlens images. Due to this complexity, the
manual creation of multiple plenoptic camera setups is often a time-consuming
task. In this work we assume a simulation framework as well as the main lens
data given and present a method to calculate the remaining aperture, sensor and
microlens array parameters under different sets of constraints. Our ray
tracing-based approach is shown to result in models outperforming their
pendants generated with the commonly used paraxial approximations in terms of
image quality, while still meeting the desired constraints. Both the
implementation and evaluation setup including 30 plenoptic camera designs are
made publicly available.</p>
  </details>
</details>
<details>
  <summary>33. <b>标题：Normal and Visibility Estimation of Human Face from a Single Image</b></summary>
  <p><b>编号</b>：[115]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04647</p>
  <p><b>作者</b>：Fuzhi Zhong,  Rui Wang,  Yuchi Huo,  Hujun Bao</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：shading details especially around regions, method better reveals, light transfer function, light transfer function, decomposition allows us</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent work on the intrinsic image of humans starts to consider the
visibility of incident illumination and encodes the light transfer function by
spherical harmonics. In this paper, we show that such a light transfer function
can be further decomposed into visibility and cosine terms related to surface
normal. Such decomposition allows us to recover the surface normal in addition
to visibility. We propose a deep learning-based approach with a reconstruction
loss for training on real-world images. Results show that compared with
previous works, the reconstruction of human face from our method better reveals
the surface normal and shading details especially around regions where
visibility effect is strong.</p>
  </details>
</details>
<details>
  <summary>34. <b>标题：3D Dense Face Alignment with Fused Features by Aggregating CNNs and GCNs</b></summary>
  <p><b>编号</b>：[117]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04643</p>
  <p><b>作者</b>：Yanda Meng,  Xu Chen,  Dongxu Gao,  Yitian Zhao,  Xiaoyun Yang,  Yihong Qiao,  Xiaowei Huang,  Yalin Zheng</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：seamlessly combining standard convolutional neural networks, several challenging datasets demonstrate, features across different layers, 3d face reconstruction simultaneously, 3d face alignment tasks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we propose a novel multi-level aggregation network to regress
the coordinates of the vertices of a 3D face from a single 2D image in an
end-to-end manner. This is achieved by seamlessly combining standard
convolutional neural networks (CNNs) with Graph Convolution Networks (GCNs). By
iteratively and hierarchically fusing the features across different layers and
stages of the CNNs and GCNs, our approach can provide a dense face alignment
and 3D face reconstruction simultaneously for the benefit of direct feature
learning of 3D face mesh. Experiments on several challenging datasets
demonstrate that our method outperforms state-of-the-art approaches on both 2D
and 3D face alignment tasks.</p>
  </details>
</details>
<details>
  <summary>35. <b>标题：Evaluation and Generation of Physical Adversarial Patch</b></summary>
  <p><b>编号</b>：[123]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04623</p>
  <p><b>作者</b>：Xiao Yang,  Yinpeng Dong,  Tianyu Pang,  Zihao Xiao,  Hang Su,  Jun Zhu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：diverse physically realizable adversarial patches, conduct reproducible evaluations comprehensively, control different face variations, generic framework allows us, deployed face recognition systems</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent studies have revealed the vulnerability of face recognition models
against physical adversarial patches, which raises security concerns about the
deployed face recognition systems. However, it is still challenging to ensure
the reproducibility for most attack algorithms under complex physical
conditions, which leads to the lack of a systematic evaluation of the existing
methods. It is therefore imperative to develop a framework that can enable a
comprehensive evaluation of the vulnerability of face recognition in the
physical world. To this end, we propose to simulate the complex transformations
of faces in the physical world via 3D-face modeling, which serves as a digital
counterpart of physical faces. The generic framework allows us to control
different face variations and physical conditions to conduct reproducible
evaluations comprehensively. With this digital simulator, we further propose a
Face3DAdv method considering the 3D face transformations and realistic physical
variations. Extensive experiments validate that Face3DAdv can significantly
improve the effectiveness of diverse physically realizable adversarial patches
in both simulated and physical environments, against various white-box and
black-box face recognition models.</p>
  </details>
</details>
<details>
  <summary>36. <b>标题：Object-Based Visual Camera Pose Estimation From Ellipsoidal Model and  3D-Aware Ellipse Prediction</b></summary>
  <p><b>编号</b>：[126]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04613</p>
  <p><b>作者</b>：Matthieu Zins,  Gilles Simon,  Marie-Odile Berger</p>
  <p><b>备注</b>：International Journal of Computer Vision (IJCV)</p>
  <p><b>关键词</b>：computed pose significantly increases thanks, three need manual object annotation, initial camera pose estimation, camera pose accurately enough, detects improved elliptic approximations</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we propose a method for initial camera pose estimation from
just a single image which is robust to viewing conditions and does not require
a detailed model of the scene. This method meets the growing need of easy
deployment of robotics or augmented reality applications in any environments,
especially those for which no accurate 3D model nor huge amount of ground truth
data are available. It exploits the ability of deep learning techniques to
reliably detect objects regardless of viewing conditions. Previous works have
also shown that abstracting the geometry of a scene of objects by an ellipsoid
cloud allows to compute the camera pose accurately enough for various
application needs. Though promising, these approaches use the ellipses fitted
to the detection bounding boxes as an approximation of the imaged objects. In
this paper, we go one step further and propose a learning-based method which
detects improved elliptic approximations of objects which are coherent with the
3D ellipsoids in terms of perspective projection. Experiments prove that the
accuracy of the computed pose significantly increases thanks to our method.
This is achieved with very little effort in terms of training data acquisition
- a few hundred calibrated images of which only three need manual object
annotation. Code and models are released at
this https URL</p>
  </details>
</details>
<details>
  <summary>37. <b>标题：Practical No-box Adversarial Attacks with Training-free Hybrid Image  Transformation</b></summary>
  <p><b>编号</b>：[128]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04607</p>
  <p><b>作者</b>：Qilong Zhang,  Chaoning Zhang,  Chaoqun Li,  Jingkuan Song,  Lianli Gao,  Heng Tao Shen</p>
  <p><b>备注</b>：This is the revision (the previous version rated 8,8,5,4 in ICLR2022, where 8 denotes "accept, good paper"), which has been further polished and added many new experiments</p>
  <p><b>关键词</b>：raised increasing attention, extremely challenging since, deep neural networks, similar substitute model, new substitute model</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In recent years, the adversarial vulnerability of deep neural networks (DNNs)
has raised increasing attention. Among all the threat models, no-box attacks
are the most practical but extremely challenging since they neither rely on any
knowledge of the target model or similar substitute model, nor access the
dataset for training a new substitute model. Although a recent method has
attempted such an attack in a loose sense, its performance is not good enough
and computational overhead of training is expensive. In this paper, we move a
step forward and show the existence of a \textbf{training-free} adversarial
perturbation under the no-box threat model, which can be successfully used to
attack different DNNs in real-time. Motivated by our observation that
high-frequency component (HFC) domains in low-level features and plays a
crucial role in classification, we attack an image mainly by manipulating its
frequency components. Specifically, the perturbation is manipulated by
suppression of the original HFC and adding of noisy HFC. We empirically and
experimentally analyze the requirements of effective noisy HFC and show that it
should be regionally homogeneous, repeating and dense. Extensive experiments on
the ImageNet dataset demonstrate the effectiveness of our proposed no-box
method. It attacks ten well-known models with a success rate of
\textbf{98.13\%} on average, which outperforms state-of-the-art no-box attacks
by \textbf{29.39\%}. Furthermore, our method is even competitive to mainstream
transfer-based black-box attacks.</p>
  </details>
</details>
<details>
  <summary>38. <b>标题：Domain Generalization using Pretrained Models without Fine-tuning</b></summary>
  <p><b>编号</b>：[130]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04600</p>
  <p><b>作者</b>：Ziyue Li,  Kan Ren,  Xinyang Jiang,  Bo Li,  Haipeng Zhang,  Dongsheng Li</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：linear label space adapter upon fixed pretrained models, achieve decent performance regarding specific domains, sedge achieves significant performance improvements comparing, pretrained models could vary significantly, dynamically dispatch proper pretrained models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Fine-tuning pretrained models is a common practice in domain generalization
(DG) tasks. However, fine-tuning is usually computationally expensive due to
the ever-growing size of pretrained models. More importantly, it may cause
over-fitting on source domain and compromise their generalization ability as
shown in recent works. Generally, pretrained models possess some level of
generalization ability and can achieve decent performance regarding specific
domains and samples. However, the generalization performance of pretrained
models could vary significantly over different test domains even samples, which
raises challenges for us to best leverage pretrained models in DG tasks. In
this paper, we propose a novel domain generalization paradigm to better
leverage various pretrained models, named specialized ensemble learning for
domain generalization (SEDGE). It first trains a linear label space adapter
upon fixed pretrained models, which transforms the outputs of the pretrained
model to the label space of the target domain. Then, an ensemble network aware
of model specialty is proposed to dynamically dispatch proper pretrained models
to predict each test sample. Experimental studies on several benchmarks show
that SEDGE achieves significant performance improvements comparing to strong
baselines including state-of-the-art method in DG tasks and reduces the
trainable parameters by ~99% and the training time by ~99.5%.</p>
  </details>
</details>
<details>
  <summary>39. <b>标题：Mapping global dynamics of benchmark creation and saturation in  artificial intelligence</b></summary>
  <p><b>编号</b>：[133]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04592</p>
  <p><b>作者</b>：Adriano Barbosa-Silva,  Simon Ott,  Kathrin Blagec,  Jan Brauner,  Matthias Samwald</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：benchmarks quickly trended towards near, recent studies raised concerns, mapping benchmark performance gains, benchmark performance gains, scale community collaboration</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Benchmarks are crucial to measuring and steering progress in artificial
intelligence (AI). However, recent studies raised concerns over the state of AI
benchmarking, reporting issues such as benchmark overfitting, benchmark
saturation and increasing centralization of benchmark dataset creation. To
facilitate monitoring of the health of the AI benchmarking ecosystem, we
introduce methodologies for creating condensed maps of the global dynamics of
benchmark creation and saturation. We curated data for 1688 benchmarks covering
the entire domains of computer vision and natural language processing, and show
that a large fraction of benchmarks quickly trended towards near-saturation,
that many benchmarks fail to find widespread utilization, and that benchmark
performance gains for different AI tasks were prone to unforeseen bursts. We
conclude that future work should focus on large-scale community collaboration
and on mapping benchmark performance gains to real-world utility and impact of
AI.</p>
  </details>
</details>
<details>
  <summary>40. <b>标题：A Neuro-vector-symbolic Architecture for Solving Raven's Progressive  Matrices</b></summary>
  <p><b>编号</b>：[139]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04571</p>
  <p><b>作者</b>：Michael Hersche,  Mustafa Zeqiri,  Luca Benini,  Abu Sebastian,  Abbas Rahimi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：width holographic vectorized representations, called binding problem ),, neither deep neural networks, magnitude faster execution, exhaustive rule searches</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Neither deep neural networks nor symbolic AI alone have approached the kind
of intelligence expressed in humans. This is mainly because neural networks are
not able to decompose distinct objects from their joint representation (the
so-called binding problem), while symbolic AI suffers from exhaustive rule
searches, among other problems. These two problems are still pronounced in
neuro-symbolic AI which aims to combine the best of the two paradigms. Here, we
show that the two problems can be addressed with our proposed
neuro-vector-symbolic architecture (NVSA) by exploiting its powerful operators
on fixed-width holographic vectorized representations that serve as a common
language between neural networks and symbolic logical reasoning. The efficacy
of NVSA is demonstrated by solving the Raven's progressive matrices. NVSA
achieves a new record of 97.7% average accuracy in RAVEN, and 98.8% in I-RAVEN
datasets, with two orders of magnitude faster execution than the symbolic
logical reasoning on CPUs.</p>
  </details>
</details>
<details>
  <summary>41. <b>标题：CP-ViT: Cascade Vision Transformer Pruning via Progressive Sparsity  Prediction</b></summary>
  <p><b>编号</b>：[140]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04570</p>
  <p><b>作者</b>：Zhuoran Song,  Yihong Xu,  Zhezhi He,  Li Jiang,  Naifeng Jing,  Xiaoyao Liang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：dynamic pruning ratio adjustment technique based, maintaining accuracy loss within 1 \%., cascade pruning framework named cp, progressively pruning 50 \% patches, 40 \% flops</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Vision transformer (ViT) has achieved competitive accuracy on a variety of
computer vision applications, but its computational cost impedes the deployment
on resource-limited mobile devices.
We explore the sparsity in ViT and observe that informative patches and heads
are sufficient for accurate image recognition.
In this paper, we propose a cascade pruning framework named CP-ViT by
predicting sparsity in ViT models progressively and dynamically to reduce
computational redundancy while minimizing the accuracy loss. Specifically, we
define the cumulative score to reserve the informative patches and heads across
the ViT model for better accuracy. We also propose the dynamic pruning ratio
adjustment technique based on layer-aware attention range. CP-ViT has great
general applicability for practical deployment, which can be applied to a wide
range of ViT models and can achieve superior accuracy with or without
fine-tuning.
Extensive experiments on ImageNet, CIFAR-10, and CIFAR-100 with various
pre-trained models have demonstrated the effectiveness and efficiency of
CP-ViT. By progressively pruning 50\% patches, our CP-ViT method reduces over
40\% FLOPs while maintaining accuracy loss within 1\%.</p>
  </details>
</details>
<details>
  <summary>42. <b>标题：All You Need is LUV: Unsupervised Collection of Labeled Images using  Invisible UV Fluorescent Indicators</b></summary>
  <p><b>编号</b>：[141]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04566</p>
  <p><b>作者</b>：Brijen Thananjeyan,  Justin Kerr,  Huang Huang,  Joseph E. Gonzalez,  Ken Goldberg</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：collecting around 200 semantic segmentation labels, real manipulation environments without human labeling, surgical needle pose estimation task, scale semantic image annotation, keypoints via color segmentation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large-scale semantic image annotation is a significant challenge for
learning-based perception systems in robotics. Current approaches often rely on
human labelers, which can be expensive, or simulation data, which can visually
or physically differ from real data. This paper proposes Labels from
UltraViolet (LUV), a novel framework that enables rapid, labeled data
collection in real manipulation environments without human labeling. LUV uses
transparent, ultraviolet-fluorescent paint with programmable ultraviolet LEDs
to collect paired images of a scene in standard lighting and UV lighting to
autonomously extract segmentation masks and keypoints via color segmentation.
We apply LUV to a suite of diverse robot perception tasks to evaluate its
labeling quality, flexibility, and data collection rate. Results suggest that
LUV is 180-2500 times faster than a human labeler across the tasks. We show
that LUV provides labels consistent with human annotations on unpainted test
images. The networks trained on these labels are used to smooth and fold
crumpled towels with 83% success rate and achieve 1.7mm position error with
respect to human labels on a surgical needle pose estimation task. The low cost
of LUV makes it ideal as a lightweight replacement for human labeling systems,
with the one-time setup costs at $300 equivalent to the cost of collecting
around 200 semantic segmentation labels on Amazon Mechanical Turk. Code,
datasets, visualizations, and supplementary material can be found at
this https URL</p>
  </details>
</details>
<details>
  <summary>43. <b>标题：Region-Aware Face Swapping</b></summary>
  <p><b>编号</b>：[143]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04564</p>
  <p><b>作者</b>：Chao Xu,  Jiangning Zhang,  Miao Hua,  Qian He,  Zili Yi,  Yong Liu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：2 )} global source feature, 1 )} local facial region, effectively model misaligned cross, 87 $\ uparrow $., relevant soft facial masks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper presents a novel Region-Aware Face Swapping (RAFSwap) network to
achieve identity-consistent harmonious high-resolution face generation in a
local-global manner: \textbf{1)} Local Facial Region-Aware (FRA) branch
augments local identity-relevant features by introducing the Transformer to
effectively model misaligned cross-scale semantic interaction. \textbf{2)}
Global Source Feature-Adaptive (SFA) branch further complements global
identity-relevant cues for generating identity-consistent swapped faces.
Besides, we propose a \textit{Face Mask Predictor} (FMP) module incorporated
with StyleGAN2 to predict identity-relevant soft facial masks in an
unsupervised manner that is more practical for generating harmonious
high-resolution faces. Abundant experiments qualitatively and quantitatively
demonstrate the superiority of our method for generating more
identity-consistent high-resolution swapped faces over SOTA methods, \eg,
obtaining 96.70 ID retrieval that outperforms SOTA MegaFS by 5.87$\uparrow$.</p>
  </details>
</details>
<details>
  <summary>44. <b>标题：MLNav: Learning to Safely Navigate on Martian Terrains</b></summary>
  <p><b>编号</b>：[144]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04563</p>
  <p><b>作者</b>：Shreyansh Daftry,  Neil Abcouwer,  Tyler Del Sesto,  Siddarth Venkatraman,  Jialin Song,  Lucas Igel,  Amos Byon,  Ugo Rosolia,  Yisong Yue,  Masahiro Ono</p>
  <p><b>备注</b>：IEEE Robotics and Automation Letters (RA-L) and ICRA 2022</p>
  <p><b>关键词</b>：real martian terrain data collected, successfully navigate highly challenging terrains, navigating real martian terrains, fully respecting safety constraints, mlnav makes judicious use</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present MLNav, a learning-enhanced path planning framework for
safety-critical and resource-limited systems operating in complex environments,
such as rovers navigating on Mars. MLNav makes judicious use of machine
learning to enhance the efficiency of path planning while fully respecting
safety constraints. In particular, the dominant computational cost in such
safety-critical settings is running a model-based safety checker on the
proposed paths. Our learned search heuristic can simultaneously predict the
feasibility for all path options in a single run, and the model-based safety
checker is only invoked on the top-scoring paths. We validate in high-fidelity
simulations using both real Martian terrain data collected by the Perseverance
rover, as well as a suite of challenging synthetic terrains. Our experiments
show that: (i) compared to the baseline ENav path planner on board the
Perserverance rover, MLNav can provide a significant improvement in multiple
key metrics, such as a 10x reduction in collision checks when navigating real
Martian terrains, despite being trained with synthetic terrains; and (ii) MLNav
can successfully navigate highly challenging terrains where the baseline ENav
fails to find a feasible path before timing out.</p>
  </details>
</details>
<details>
  <summary>45. <b>标题：Active Self-Semi-Supervised Learning for Few Labeled Samples Fast  Training</b></summary>
  <p><b>编号</b>：[145]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04560</p>
  <p><b>作者</b>：Ziting Wen,  Oscar Pizarro,  Stefan Williams</p>
  <p><b>备注</b>：11 pages, 7 figures</p>
  <p><b>关键词</b>：supervised learning benchmarks demonstrate effectiveness, method achieves similar accuracy, obtain better prior pseudo, quality labeled samples produced, good prior pseudo</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Faster training and fewer annotations are two key issues for applying deep
models to various practical domains. Now, semi-supervised learning has achieved
great success in training with few annotations. However, low-quality labeled
samples produced by random sampling make it difficult to continue to reduce the
number of annotations. In this paper we propose an active self-semi-supervised
training framework that bootstraps semi-supervised models with good prior
pseudo-labels, where the priors are obtained by label propagation over
self-supervised features. Because the accuracy of the prior is not only
affected by the quality of features, but also by the selection of the labeled
samples. We develop active learning and label propagation strategies to obtain
better prior pseudo-labels. Consequently, our framework can greatly improve the
performance of models with few annotations and greatly reduce the training
time. Experiments on three semi-supervised learning benchmarks demonstrate
effectiveness. Our method achieves similar accuracy to standard semi-supervised
approaches in about 1/3 of the training time, and even outperform them when
fewer annotations are available (84.10\% in CIFAR-10 with 10 labels).</p>
  </details>
</details>
<details>
  <summary>46. <b>标题：Learning Temporal Consistency for Source-Free Video Domain Adaptation</b></summary>
  <p><b>编号</b>：[146]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04559</p>
  <p><b>作者</b>：Yuecong Xu,  Jianfei Yang,  Haozhi Cao,  Keyu Wu,  Wu Min,  Zhenghua Chen</p>
  <p><b>备注</b>：22 pages, 5 figures, 7 tables</p>
  <p><b>关键词</b>：require source data access would raise serious privacy issues, action recognition tasks across different environments, novel attentive temporal consistent network, constructs effective overall temporal features, performed across local temporal features</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Video-based Unsupervised Domain Adaptation (VUDA) methods improve the
robustness of video models, enabling them to be applied to action recognition
tasks across different environments. However, these methods require constant
access to source data during the adaptation process. Yet in many real-world
applications, subjects and scenes in the source video domain should be
irrelevant to those in the target video domain. With the increasing emphasis on
data privacy, such methods that require source data access would raise serious
privacy issues. Therefore, to cope with such concern, a more practical domain
adaptation scenario is formulated as the Source-Free Video-based Domain
Adaptation (SFVDA). Though there are a few methods for Source-Free Domain
Adaptation (SFDA) on image data, these methods yield degenerating performance
in SFVDA due to the multi-modality nature of videos, with the existence of
additional temporal features. In this paper, we propose a novel Attentive
Temporal Consistent Network (ATCoN) to address SFVDA by learning temporal
consistency, guaranteed by two novel consistency objectives, namely feature
consistency and source prediction consistency, performed across local temporal
features. ATCoN further constructs effective overall temporal features by
attending to local temporal features based on prediction confidence. Empirical
results demonstrate the state-of-the-art performance of ATCoN across various
cross-domain action recognition benchmarks.</p>
  </details>
</details>
<details>
  <summary>47. <b>标题：ChiTransformer:Towards Reliable Stereo from Cues</b></summary>
  <p><b>编号</b>：[147]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04554</p>
  <p><b>作者</b>：Qing Su,  Shihao Ji</p>
  <p><b>备注</b>：11 pages, 3 figures, CVPR2022</p>
  <p><b>关键词</b>：supervised binocular depth estimation method, single image depth estimation, extensive context information aggregated, architecture yields substantial improvements, current stereo matching techniques</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Current stereo matching techniques are challenged by restricted searching
space, occluded regions, and sheer size. While single image depth estimation is
spared from these challenges and can achieve satisfactory results with the
extracted monocular cues, the lack of stereoscopic relationship renders the
monocular prediction less reliable on its own, especially in highly dynamic or
cluttered environments. To address these issues in both scenarios, we present
an optic-chiasm-inspired self-supervised binocular depth estimation method,
wherein vision transformer (ViT) with a gated positional cross-attention (GPCA)
layer is designed to enable feature-sensitive pattern retrieval between views
while retaining the extensive context information aggregated through
self-attentions. Monocular cues from a single view are thereafter conditionally
rectified by a blending layer with the retrieved pattern pairs. This crossover
design is biologically analogous to the optic-chasma structure in human visual
system and hence the name, ChiTransformer. Our experiments show that this
architecture yields substantial improvements over state-of-the-art
self-supervised stereo approaches by 11%, and can be used on both rectilinear
and non-rectilinear (e.g., fisheye) images.</p>
  </details>
</details>
<details>
  <summary>48. <b>标题：Monocular Depth Distribution Alignment with Low Computation</b></summary>
  <p><b>编号</b>：[153]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04538</p>
  <p><b>作者</b>：Fei Sheng,  Feng Xue,  Yicong Chang,  Wenteng Liang,  Anlong Ming</p>
  <p><b>备注</b>：Accepted by ICRA 2022</p>
  <p><b>关键词</b>：monocular depth estimation generally depends, point operations per second, widely used nyudv2 dataset, reasonable scene structure, pyramid scene transformer</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The performance of monocular depth estimation generally depends on the amount
of parameters and computational cost. It leads to a large accuracy contrast
between light-weight networks and heavy-weight networks, which limits their
application in the real world. In this paper, we model the majority of accuracy
contrast between them as the difference of depth distribution, which we call
"Distribution drift". To this end, a distribution alignment network (DANet) is
proposed. We firstly design a pyramid scene transformer (PST) module to capture
inter-region interaction in multiple scales. By perceiving the difference of
depth features between every two regions, DANet tends to predict a reasonable
scene structure, which fits the shape of distribution to ground truth. Then, we
propose a local-global optimization (LGO) scheme to realize the supervision of
global range of scene depth. Thanks to the alignment of depth distribution
shape and scene depth range, DANet sharply alleviates the distribution drift,
and achieves a comparable performance with prior heavy-weight methods, but uses
only 1% floating-point operations per second (FLOPs) of them. The experiments
on two datasets, namely the widely used NYUDv2 dataset and the more challenging
iBims-1 dataset, demonstrate the effectiveness of our method. The source code
is available at this https URL.</p>
  </details>
</details>
<details>
  <summary>49. <b>标题：Fast Road Segmentation via Uncertainty-aware Symmetric Network</b></summary>
  <p><b>编号</b>：[154]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04537</p>
  <p><b>作者</b>：Yicong Chang,  Feng Xue,  Fei Sheng,  Wenteng Liang,  Anlong Ming</p>
  <p><b>备注</b>：Accepted by ICRA 2022</p>
  <p><b>关键词</b>：prior methods cannot achieve high inference speed, instead separately adopt two light, based road segmentation methods contrasts, modal feature fusion operations, time inference speed</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The high performance of RGB-D based road segmentation methods contrasts with
their rare application in commercial autonomous driving, which is owing to two
reasons: 1) the prior methods cannot achieve high inference speed and high
accuracy in both ways; 2) the different properties of RGB and depth data are
not well-exploited, limiting the reliability of predicted road. In this paper,
based on the evidence theory, an uncertainty-aware symmetric network (USNet) is
proposed to achieve a trade-off between speed and accuracy by fully fusing RGB
and depth data. Firstly, cross-modal feature fusion operations, which are
indispensable in the prior RGB-D based methods, are abandoned. We instead
separately adopt two light-weight subnetworks to learn road representations
from RGB and depth inputs. The light-weight structure guarantees the real-time
inference of our method. Moreover, a multiscale evidence collection (MEC)
module is designed to collect evidence in multiple scales for each modality,
which provides sufficient evidence for pixel class determination. Finally, in
uncertainty-aware fusion (UAF) module, the uncertainty of each modality is
perceived to guide the fusion of the two subnetworks. Experimental results
demonstrate that our method achieves a state-of-the-art accuracy with real-time
inference speed of 43+ FPS. The source code is available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>50. <b>标题：Update Compression for Deep Neural Networks on the Edge</b></summary>
  <p><b>编号</b>：[161]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04516</p>
  <p><b>作者</b>：Bo Chen,  Ali Bakhshi,  Gustavo Batista,  Brian Ng,  Tat-Jun Chin</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：many practical reasons motivate, method usually requires less, small additional parameters, simple approach based, server side based</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>An increasing number of artificial intelligence (AI) applications involve the
execution of deep neural networks (DNNs) on edge devices. Many practical
reasons motivate the need to update the DNN model on the edge device
post-deployment, such as refining the model, concept drift, or outright change
in the learning task. In this paper, we consider the scenario where retraining
can be done on the server side based on a copy of the DNN model, with only the
necessary data transmitted to the edge to update the deployed model. However,
due to bandwidth constraints, we want to minimise the transmission required to
achieve the update. We develop a simple approach based on matrix factorisation
to compress the model update -- this differs from compressing the model itself.
The key idea is to preserve existing knowledge in the current model and
optimise only small additional parameters for the update which can be used to
reconstitute the model on the edge. We compared our method to similar
techniques used in federated learning; our method usually requires less than
half of the update size of existing methods to achieve the same accuracy.</p>
  </details>
</details>
<details>
  <summary>51. <b>标题：Image Steganography based on Style Transfer</b></summary>
  <p><b>编号</b>：[168]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04500</p>
  <p><b>作者</b>：Donghui Hu,  Yu Zhang,  Cong Yu,  Jian Wang,  Yaofei Wang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：end unsupervised model without pre, propose image steganography network based, traditional image steganography, benchmark dataset demonstrate, normal stylized images</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Image steganography is the art and science of using images as cover for
covert communications. With the development of neural networks, traditional
image steganography is more likely to be detected by deep learning-based
steganalysis. To improve upon this, we propose image steganography network
based on style transfer, and the embedding of secret messages can be disguised
as image stylization. We embed secret information while transforming the
content image style. In latent space, the secret information is integrated into
the latent representation of the cover image to generate the stego images,
which are indistinguishable from normal stylized images. It is an end-to-end
unsupervised model without pre-training. Extensive experiments on the benchmark
dataset demonstrate the reliability, quality and security of stego images
generated by our steganographic network.</p>
  </details>
</details>
<details>
  <summary>52. <b>标题：3SD: Self-Supervised Saliency Detection With No Labels</b></summary>
  <p><b>编号</b>：[171]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04478</p>
  <p><b>作者</b>：Rajeev Yasarla,  Renliang Weng,  Wongun Choi,  Vishal Patel,  Amir Sadeghian</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：classification tasks provide important saliency cues like structure, weak labels like scribbles )., six benchmark datasets demonstrate, obtain class activation maps, cam maps ).</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present a conceptually simple self-supervised method for saliency
detection. Our method generates and uses pseudo-ground truth labels for
training. The generated pseudo-GT labels don't require any kind of human
annotations (e.g., pixel-wise labels or weak labels like scribbles). Recent
works show that features extracted from classification tasks provide important
saliency cues like structure and semantic information of salient objects in the
image. Our method, called 3SD, exploits this idea by adding a branch for a
self-supervised classification task in parallel with salient object detection,
to obtain class activation maps (CAM maps). These CAM maps along with the edges
of the input image are used to generate the pseudo-GT saliency maps to train
our 3SD network. Specifically, we propose a contrastive learning-based training
on multiple image patches for the classification task. We show the multi-patch
classification with contrastive loss improves the quality of the CAM maps
compared to naive classification on the entire image. Experiments on six
benchmark datasets demonstrate that without any labels, our 3SD method
outperforms all existing weakly supervised and unsupervised methods, and its
performance is on par with the fully-supervised methods. Code is available at
:this https URL</p>
  </details>
</details>
<details>
  <summary>53. <b>标题：Part-level Action Parsing via a Pose-guided Coarse-to-Fine Framework</b></summary>
  <p><b>编号</b>：[172]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04476</p>
  <p><b>作者</b>：Xiaodong Chen,  Xinchen Liu,  Wu Liu,  Kun Liu,  Dong Wu,  Yongdong Zhang,  Tao Mei</p>
  <p><b>备注</b>：Accepted by IEEE ISCAS 2022, 5 pages, 2 figures</p>
  <p><b>关键词</b>：g ., convolutional neural networks, guided positional embedding method, existing methods usually consider, accurately localize body parts, outperforms existing methods</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Action recognition from videos, i.e., classifying a video into one of the
pre-defined action types, has been a popular topic in the communities of
artificial intelligence, multimedia, and signal processing. However, existing
methods usually consider an input video as a whole and learn models, e.g.,
Convolutional Neural Networks (CNNs), with coarse video-level class labels.
These methods can only output an action class for the video, but cannot provide
fine-grained and explainable cues to answer why the video shows a specific
action. Therefore, researchers start to focus on a new task, Part-level Action
Parsing (PAP), which aims to not only predict the video-level action but also
recognize the frame-level fine-grained actions or interactions of body parts
for each person in the video. To this end, we propose a coarse-to-fine
framework for this challenging task. In particular, our framework first
predicts the video-level class of the input video, then localizes the body
parts and predicts the part-level action. Moreover, to balance the accuracy and
computation in part-level action parsing, we propose to recognize the
part-level actions by segment-level features. Furthermore, to overcome the
ambiguity of body parts, we propose a pose-guided positional embedding method
to accurately localize body parts. Through comprehensive experiments on a
large-scale dataset, i.e., Kinetics-TPS, our framework achieves
state-of-the-art performance and outperforms existing methods over a 31.10% ROC
score.</p>
  </details>
</details>
<details>
  <summary>54. <b>标题：The Combinatorial Brain Surgeon: Pruning Weights That Cancel One Another  in Neural Networks</b></summary>
  <p><b>编号</b>：[177]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04466</p>
  <p><b>作者</b>：Xin Yu,  Thiago Serra,  Shandian Zhe,  Srikumar Ramalingam</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：smallest absolute value -- even though magnitude, optimal brain surgeon ~( obs )., training may also produce models, obtaining significantly better performance, larger -- even</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Neural networks tend to achieve better accuracy with training if they are
larger -- even if the resulting models are overparameterized. Nevertheless,
carefully removing such excess parameters before, during, or after training may
also produce models with similar or even improved accuracy. In many cases, that
can be curiously achieved by heuristics as simple as removing a percentage of
the weights with the smallest absolute value -- even though magnitude is not a
perfect proxy for weight relevance. With the premise that obtaining
significantly better performance from pruning depends on accounting for the
combined effect of removing multiple weights, we revisit one of the classic
approaches for impact-based pruning: the Optimal Brain Surgeon~(OBS). We
propose a tractable heuristic for solving the combinatorial extension of OBS,
in which we select weights for simultaneous removal, as well as a systematic
update of the remaining weights. Our selection method outperforms other methods
under high sparsity, and the weight update is advantageous even when combined
with the other methods.</p>
  </details>
</details>
<details>
  <summary>55. <b>标题：Autonomous Mosquito Habitat Detection Using Satellite Imagery and  Convolutional Neural Networks for Disease Risk Mapping</b></summary>
  <p><b>编号</b>：[179]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04463</p>
  <p><b>作者</b>：Sriram Elango,  Nandini Ramachandran,  Russanne Low</p>
  <p><b>备注</b>：8 pages, 11 figures</p>
  <p><b>关键词</b>：autonomous mosquito habitat detection technology, proposed convolutional neural network, one million deaths globally, larger land cover variables, finer spatial scale whereas</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Mosquitoes are known vectors for disease transmission that cause over one
million deaths globally each year. The majority of natural mosquito habitats
are areas containing standing water that are challenging to detect using
conventional ground-based technology on a macro scale. Contemporary approaches,
such as drones, UAVs, and other aerial imaging technology are costly when
implemented and are only most accurate on a finer spatial scale whereas the
proposed convolutional neural network(CNN) approach can be applied for disease
risk mapping and further guide preventative efforts on a more global scale. By
assessing the performance of autonomous mosquito habitat detection technology,
the transmission of mosquito-borne diseases can be prevented in a
cost-effective manner. This approach aims to identify the spatiotemporal
distribution of mosquito habitats in extensive areas that are difficult to
survey using ground-based technology by employing computer vision on satellite
imagery for proof of concept. The research presents an evaluation and the
results of 3 different CNN models to determine their accuracy of predicting
large-scale mosquito habitats. For this approach, a dataset was constructed
containing a variety of geographical features. Larger land cover variables such
as ponds/lakes, inlets, and rivers were utilized to classify mosquito habitats
while minute sites were omitted for higher accuracy on a larger scale. Using
the dataset, multiple CNN networks were trained and evaluated for accuracy of
habitat prediction. Utilizing a CNN-based approach on readily available
satellite imagery is cost-effective and scalable, unlike most aerial imaging
technology. Testing revealed that YOLOv4 obtained greater accuracy in mosquito
habitat detection for identifying large-scale mosquito habitats.</p>
  </details>
</details>
<details>
  <summary>56. <b>标题：Probabilistic Rotation Representation With an Efficiently Computable  Bingham Loss Function and Its Application to Pose Estimation</b></summary>
  <p><b>编号</b>：[182]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04456</p>
  <p><b>作者</b>：Hiroya Sato,  Takuya Ikeda,  Koichi Nishiwaki</p>
  <p><b>备注</b>：This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible</p>
  <p><b>关键词</b>：training neural networks based, one promising solution, deep learning framework, object pose estimation, implement loss function</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In recent years, a deep learning framework has been widely used for object
pose estimation. While quaternion is a common choice for rotation
representation of 6D pose, it cannot represent an uncertainty of the
observation. In order to handle the uncertainty, Bingham distribution is one
promising solution because this has suitable features, such as a smooth
representation over SO(3), in addition to the ambiguity representation.
However, it requires the complex computation of the normalizing constants. This
is the bottleneck of loss computation in training neural networks based on
Bingham representation. As such, we propose a fast-computable and
easy-to-implement loss function for Bingham distribution. We also show not only
to examine the parametrization of Bingham distribution but also an application
based on our loss function.</p>
  </details>
</details>
<details>
  <summary>57. <b>标题：CIDER: Exploiting Hyperspherical Embeddings for Out-of-Distribution  Detection</b></summary>
  <p><b>编号</b>：[187]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04450</p>
  <p><b>作者</b>：Yifei Ming,  Yiyou Sun,  Ousmane Dia,  Yixuan Li</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：promotes large angular distances among different class prototypes, cider jointly optimizes two losses, hard ood detection task cifar, prior methods directly take, representation learning give rise</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Out-of-distribution (OOD) detection is a critical task for reliable machine
learning. Recent advances in representation learning give rise to developments
in distance-based OOD detection, where testing samples are detected as OOD if
they are relatively far away from the centroids or prototypes of
in-distribution (ID) classes. However, prior methods directly take
off-the-shelf loss functions that suffice for classifying ID samples, but are
not optimally designed for OOD detection. In this paper, we propose CIDER, a
simple and effective representation learning framework by exploiting
hyperspherical embeddings for OOD detection. CIDER jointly optimizes two losses
to promote strong ID-OOD separability: (1) a dispersion loss that promotes
large angular distances among different class prototypes, and (2) a compactness
loss that encourages samples to be close to their class prototypes. We show
that CIDER is effective under various settings and establishes state-of-the-art
performance. On a hard OOD detection task CIFAR-100 vs. CIFAR-10, our method
substantially improves the AUROC by 14.20% compared to the embeddings learned
by the cross-entropy loss.</p>
  </details>
</details>
<details>
  <summary>58. <b>标题：Tune your Place Recognition: Self-Supervised Domain Calibration via  Robust SLAM</b></summary>
  <p><b>编号</b>：[189]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04446</p>
  <p><b>作者</b>：Pierre-Yves Lajoie,  Giovanni Beltrame</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：supervision signal without requiring gps, supervised domain calibration procedure based, visual place recognition techniques based, visual place recognition system, robust place recognition solutions</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Visual place recognition techniques based on deep learning, which have
imposed themselves as the state-of-the-art in recent years, do not always
generalize well to environments that are visually different from the training
set. Thus, to achieve top performance, it is sometimes necessary to fine-tune
the networks to the target environment. To this end, we propose a completely
self-supervised domain calibration procedure based on robust pose graph
estimation from Simultaneous Localization and Mapping (SLAM) as the supervision
signal without requiring GPS or manual labeling. We first show that the
training samples produced by our technique are sufficient to train a visual
place recognition system from a pre-trained classification model. Then, we show
that our approach can improve the performance of a state-of-the-art technique
on a target environment dissimilar from the training set. We believe that this
approach will help practitioners to deploy more robust place recognition
solutions in real-world applications.</p>
  </details>
</details>
<details>
  <summary>59. <b>标题：Self-Supervision, Remote Sensing and Abstraction: Representation  Learning Across 3 Million Locations</b></summary>
  <p><b>编号</b>：[190]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04445</p>
  <p><b>作者</b>：Sachith Seneviratne,  Kerry A. Nice,  Jasper S. Wijnands,  Mark Stevenson,  Jason Thompson</p>
  <p><b>备注</b>：Preprint of this https URL</p>
  <p><b>关键词</b>：supervision based deep learning classification approaches, map imagery across 2 domains, explore contrastive representation learning methods, remote sensing imagery domains remains, based city classification</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Self-supervision based deep learning classification approaches have received
considerable attention in academic literature. However, the performance of such
methods on remote sensing imagery domains remains under-explored. In this work,
we explore contrastive representation learning methods on the task of
imagery-based city classification, an important problem in urban computing. We
use satellite and map imagery across 2 domains, 3 million locations and more
than 1500 cities. We show that self-supervised methods can build a
generalizable representation from as few as 200 cities, with representations
achieving over 95\% accuracy in unseen cities with minimal additional training.
We also find that the performance discrepancy of such methods, when compared to
supervised methods, induced by the domain discrepancy between natural imagery
and abstract imagery is significant for remote sensing imagery. We compare all
analysis against existing supervised models from academic literature and
open-source our models for broader usage and further criticism.</p>
  </details>
</details>
<details>
  <summary>60. <b>标题：Pointillism: Accurate 3D bounding box estimation with multi-radars</b></summary>
  <p><b>编号</b>：[193]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04440</p>
  <p><b>作者</b>：Kshitiz Bansal,  Keshav Rungta,  Siyuan Zhu,  Dinesh Bharadia</p>
  <p><b>备注</b>：Accepted in SenSys '20. Dataset has been made publicly available</p>
  <p><b>关键词</b>：enable accurate 3d bounding box estimation, wireless signals cause poor performance, autonomous perception requires high, novel deep learning architecture, cross potential point clouds</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Autonomous perception requires high-quality environment sensing in the form
of 3D bounding boxes of dynamic objects. The primary sensors used in automotive
systems are light-based cameras and LiDARs. However, they are known to fail in
adverse weather conditions. Radars can potentially solve this problem as they
are barely affected by adverse weather conditions. However, specular
reflections of wireless signals cause poor performance of radar point clouds.
We introduce Pointillism, a system that combines data from multiple spatially
separated radars with an optimal separation to mitigate these problems. We
introduce a novel concept of Cross Potential Point Clouds, which uses the
spatial diversity induced by multiple radars and solves the problem of noise
and sparsity in radar point clouds. Furthermore, we present the design of
RP-net, a novel deep learning architecture, designed explicitly for radar's
sparse data distribution, to enable accurate 3D bounding box estimation. The
spatial techniques designed and proposed in this paper are fundamental to
radars point cloud distribution and would benefit other radar sensing
applications.</p>
  </details>
</details>
<details>
  <summary>61. <b>标题：ImageNet-Patch: A Dataset for Benchmarking Machine Learning Robustness  against Adversarial Patches</b></summary>
  <p><b>编号</b>：[208]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04412</p>
  <p><b>作者</b>：Maura Pintor,  Daniele Angioni,  Angelo Sotgiu,  Luca Demetrio,  Ambra Demontis,  Battista Biggio,  Fabio Roli</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：approximate yet faster robustness evaluation, requires careful hyperparameter tuning, generalize across different models, optimized contiguous pixel blocks, suboptimal robustness evaluations</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Adversarial patches are optimized contiguous pixel blocks in an input image
that cause a machine-learning model to misclassify it. However, their
optimization is computationally demanding, and requires careful hyperparameter
tuning, potentially leading to suboptimal robustness evaluations. To overcome
these issues, we propose ImageNet-Patch, a dataset to benchmark
machine-learning models against adversarial patches. It consists of a set of
patches, optimized to generalize across different models, and readily
applicable to ImageNet data after preprocessing them with affine
transformations. This process enables an approximate yet faster robustness
evaluation, leveraging the transferability of adversarial perturbations. We
showcase the usefulness of this dataset by testing the effectiveness of the
computed patches against 127 models. We conclude by discussing how our dataset
could be used as a benchmark for robustness, and how our methodology can be
generalized to other domains. We open source our dataset and evaluation code at
this https URL.</p>
  </details>
</details>
<details>
  <summary>62. <b>标题：Unrolled Primal-Dual Networks for Lensless Cameras</b></summary>
  <p><b>编号</b>：[228]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04353</p>
  <p><b>作者</b>：Oliver Kingshott,  Nick Antipa,  Emrah Bostan,  Kaan Akşit</p>
  <p><b>备注</b>：8 pages, 5 figures, not published at any conference</p>
  <p><b>关键词</b>：reconstructed images (+ 5db psnr, image reconstruction models fall short, simulating lensless cameras truthfully, lensless cameras often assume, concept lensless camera prototype</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Conventional image reconstruction models for lensless cameras often assume
that each measurement results from convolving a given scene with a single
experimentally measured point-spread function. These image reconstruction
models fall short in simulating lensless cameras truthfully as these models are
not sophisticated enough to account for optical aberrations or scenes with
depth variations. Our work shows that learning a supervised primal-dual
reconstruction method results in image quality matching state of the art in the
literature without demanding a large network capacity. This improvement stems
from our primary finding that embedding learnable forward and adjoint models in
a learned primal-dual optimization framework can even improve the quality of
reconstructed images (+5dB PSNR) compared to works that do not correct for the
model error. In addition, we built a proof-of-concept lensless camera prototype
that uses a pseudo-random phase mask to demonstrate our point. Finally, we
share the extensive evaluation of our learned model based on an open dataset
and a dataset from our proof-of-concept lensless camera prototype.</p>
  </details>
</details>
<details>
  <summary>63. <b>标题：UENAS: A Unified Evolution-based NAS Framework</b></summary>
  <p><b>编号</b>：[239]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04300</p>
  <p><b>作者</b>：Zimian Wei,  Hengyue Pan,  Xin Niu,  Peijie Dong,  Dongsheng Li</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：population without compromising performance, supports optimizing network architectures, child networks share weights, uenas achieves error rates, huge search cost caused</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Neural architecture search (NAS) has gained significant attention for
automatic network design in recent years. Previous NAS methods suffer from
limited search spaces, which may lead to sub-optimal results. In this paper, we
propose UENAS, an evolution-based NAS framework with a broader search space
that supports optimizing network architectures, pruning strategies, and
hyperparameters simultaneously. To alleviate the huge search cost caused by the
expanded search space, three strategies are adopted: First, an adaptive pruning
strategy that iteratively trims the average model size in the population
without compromising performance. Second, child networks share weights of
overlapping layers with pre-trained parent networks to reduce the training
epochs. Third, an online predictor scores the joint representations of
architecture, pruning strategy, and hyperparameters to filter out inferior
combos. By the proposed three strategies, the search efficiency is
significantly improved and more well-performed compact networks with tailored
hyper-parameters are derived. In experiments, UENAS achieves error rates of
2.81% on CIFAR-10, 20.24% on CIFAR-100, and 33% on Tiny-ImageNet, which shows
the effectiveness of our method.</p>
  </details>
</details>
<details>
  <summary>64. <b>标题：Learning from Few Examples: A Summary of Approaches to Few-Shot Learning</b></summary>
  <p><b>编号</b>：[242]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04291</p>
  <p><b>作者</b>：Archit Parnami,  Minwoo Lee</p>
  <p><b>备注</b>：32 pages, 20 figures, 9 tables</p>
  <p><b>关键词</b>：many deep learning solutions suffer, building machine learning applications emerges, e ., different variations, extensively high computation time, shot learning problem ).</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Few-Shot Learning refers to the problem of learning the underlying pattern in
the data just from a few training samples. Requiring a large number of data
samples, many deep learning solutions suffer from data hunger and extensively
high computation time and resources. Furthermore, data is often not available
due to not only the nature of the problem or privacy concerns but also the cost
of data preparation. Data collection, preprocessing, and labeling are strenuous
human tasks. Therefore, few-shot learning that could drastically reduce the
turnaround time of building machine learning applications emerges as a low-cost
solution. This survey paper comprises a representative list of recently
proposed few-shot learning algorithms. Given the learning dynamics and
characteristics, the approaches to few-shot learning problems are discussed in
the perspectives of meta-learning, transfer learning, and hybrid approaches
(i.e., different variations of the few-shot learning problem).</p>
  </details>
</details>
<details>
  <summary>65. <b>标题：Rethinking data-driven point spread function modeling with a  differentiable optical model</b></summary>
  <p><b>编号</b>：[246]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04908</p>
  <p><b>作者</b>：Tobias Liaudat,  Jean-Luc Starck,  Martin Kilbinger,  Pierre-Antoine Frugier</p>
  <p><b>备注</b>：Submitted. 44 pages, 11 figures, 4 tables</p>
  <p><b>关键词</b>：order optimization techniques recently developed, spatially varying point spread function, pixel reconstruction errors decrease 6, point spread function field, efficient automatic differentiation technology</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In astronomy, upcoming space telescopes with wide-field optical instruments
have a spatially varying point spread function (PSF). Certain scientific goals
require a high-fidelity estimation of the PSF at target positions where no
direct measurement of the PSF is provided. Even though observations of the PSF
are available at some positions of the field of view (FOV), they are
undersampled, noisy, and integrated in wavelength in the instrument's passband.
PSF modeling requires building a model from these observations that can infer a
super-resolved PSF at any wavelength and any position in the FOV. Current
data-driven PSF models can tackle spatial variations and super-resolution, but
are not capable of capturing chromatic variations. Our model, coined WaveDiff,
proposes a paradigm shift in the data-driven modeling of the point spread
function field of telescopes. By adding a differentiable optical forward model
into the modeling framework, we change the data-driven modeling space from the
pixels to the wavefront. The proposed model relies on efficient automatic
differentiation technology as well as modern stochastic first-order
optimization techniques recently developed by the thriving machine-learning
community. Our framework paves the way to building powerful models that are
physically motivated and do not require special calibration data. This paper
demonstrates the WaveDiff model on a simplified setting of a space telescope.
The proposed framework represents a performance breakthrough with respect to
existing data-driven approaches. The pixel reconstruction errors decrease
6-fold at observation resolution and 44-fold for a 3x super-resolution. The
ellipticity errors are reduced by a factor of at least 20 and the size error by
a factor of more than 250. By only using noisy broad-band in-focus
observations, we successfully capture the PSF chromatic variations due to
diffraction.</p>
  </details>
</details>
<details>
  <summary>66. <b>标题：Using Human Gaze For Surgical Activity Recognition</b></summary>
  <p><b>编号</b>：[258]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04752</p>
  <p><b>作者</b>：Abdishakour Awale,  Duygu Sarikaya</p>
  <p><b>备注</b>：in Turkish language</p>
  <p><b>关键词</b>：art surgical activity recognition models learn spatial temporal features, publicly available surgical video understanding dataset, temporal features using 3d convolutions, automatically recognizing surgical activities plays, spatial temporal attention mechanism</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Automatically recognizing surgical activities plays an important role in
providing feedback to surgeons, and is a fundamental step towards
computer-aided surgical systems. Human gaze and visual saliency carry important
information about visual attention, and can be used in computer vision systems.
Although state-of-the-art surgical activity recognition models learn spatial
temporal features, none of these models make use of human gaze and visual
saliency. In this study, we propose to use human gaze with a spatial temporal
attention mechanism for activity recognition in surgical videos. Our model
consists of an I3D-based architecture, learns spatio-temporal features using 3D
convolutions, as well as learning an attention map using human gaze. We
evaluated our model on the Suturing task of JIGSAWS which is a publicly
available surgical video understanding dataset. Our evaluations on a subset of
random video segments in this task suggest that our approach achieves promising
results with an accuracy of 86.2%.</p>
  </details>
</details>
<details>
  <summary>67. <b>标题：Predicting conversion of mild cognitive impairment to Alzheimer's  disease</b></summary>
  <p><b>编号</b>：[260]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04725</p>
  <p><b>作者</b>：Yiran Wei,  Stephen J. Price,  Carola-Bibiane Schönlieb,  Chao Li</p>
  <p><b>备注</b>：Under review</p>
  <p><b>关键词</b>：recurrent neural networks based approach, classify dementia using deep learning, supervised contrastive learning approach, generate structural brain networks, white matter tracts</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Alzheimer's disease (AD) is the most common age-related dementia. Mild
cognitive impairment (MCI) is the early stage of cognitive decline before AD.
It is crucial to predict the MCI-to-AD conversion for precise management, which
remains challenging due to the diversity of patients. Previous evidence shows
that the brain network generated from diffusion MRI promises to classify
dementia using deep learning. However, the limited availability of diffusion
MRI challenges the model training. In this study, we develop a self-supervised
contrastive learning approach to generate structural brain networks from
routine anatomical MRI under the guidance of diffusion MRI. The generated brain
networks are applied to train a learning framework for predicting the MCI-to-AD
conversion. Instead of directly modelling the AD brain networks, we train a
graph encoder and a variational autoencoder to model the healthy ageing
trajectories from brain networks of healthy controls. To predict the MCI-to-AD
conversion, we further design a recurrent neural networks based approach to
model the longitudinal deviation of patients' brain networks from the healthy
ageing trajectory. Numerical results show that the proposed methods outperform
the benchmarks in the prediction task. We also visualize the model
interpretation to explain the prediction and identify abnormal changes of white
matter tracts.</p>
  </details>
</details>
<details>
  <summary>68. <b>标题：Uni4Eye: Unified 2D and 3D Self-supervised Pre-training via Masked Image  Modeling Transformer for Ophthalmic Image Classification</b></summary>
  <p><b>编号</b>：[269]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04614</p>
  <p><b>作者</b>：Zhiyuan Cai,  Huaqing He,  Li Lin,  Xiaoying Tang</p>
  <p><b>备注</b>：this https URL</p>
  <p><b>关键词</b>：six downstream ophthalmic image classification tasks, simultaneously perform two reconstruction tasks, branch multitask decoder module, unified patch embedding module, origin patch embedding module</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A large-scale labeled dataset is a key factor for the success of supervised
deep learning in computer vision. However, a limited number of annotated data
is very common, especially in ophthalmic image analysis, since manual
annotation is time-consuming and labor-intensive. Self-supervised learning
(SSL) methods bring huge opportunities for better utilizing unlabeled data, as
they do not need massive annotations. With an attempt to use as many as
possible unlabeled ophthalmic images, it is necessary to break the dimension
barrier, simultaneously making use of both 2D and 3D images. In this paper, we
propose a universal self-supervised Transformer framework, named Uni4Eye, to
discover the inherent image property and capture domain-specific feature
embedding in ophthalmic images. Uni4Eye can serve as a global feature
extractor, which builds its basis on a Masked Image Modeling task with a Vision
Transformer (ViT) architecture. We employ a Unified Patch Embedding module to
replace the origin patch embedding module in ViT for jointly processing both 2D
and 3D input images. Besides, we design a dual-branch multitask decoder module
to simultaneously perform two reconstruction tasks on the input image and its
gradient map, delivering discriminative representations for better convergence.
We evaluate the performance of our pre-trained Uni4Eye encoder by fine-tuning
it on six downstream ophthalmic image classification tasks. The superiority of
Uni4Eye is successfully established through comparisons to other
state-of-the-art SSL pre-training methods.</p>
  </details>
</details>
<details>
  <summary>69. <b>标题：Attention-effective multiple instance learning on weakly stem cell  colony segmentation</b></summary>
  <p><b>编号</b>：[271]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04606</p>
  <p><b>作者</b>：Novanto Yudistira,  Muthu Subash Kavitha,  Jeny Rajan,  Takio Kurita</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：colonies without using finely labeled samples, image level label without using, like convolution neural network, induced pluripotent stem cell, existing computerized systems relied</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The detection of induced pluripotent stem cell (iPSC) colonies often needs
the precise extraction of the colony features. However, existing computerized
systems relied on segmentation of contours by preprocessing for classifying the
colony conditions were task-extensive. To maximize the efficiency in
categorizing colony conditions, we propose a multiple instance learning (MIL)
in weakly supervised settings. It is designed in a single model to produce weak
segmentation and classification of colonies without using finely labeled
samples. As a single model, we employ a U-net-like convolution neural network
(CNN) to train on binary image-level labels for MIL colonies classification.
Furthermore, to specify the object of interest we used a simple post-processing
method. The proposed approach is compared over conventional methods using
five-fold cross-validation and receiver operating characteristic (ROC) curve.
The maximum accuracy of the MIL-net is 95%, which is 15 % higher than the
conventional methods. Furthermore, the ability to interpret the location of the
iPSC colonies based on the image level label without using a pixel-wise ground
truth image is more appealing and cost-effective in colony condition
recognition.</p>
  </details>
</details>
<details>
  <summary>70. <b>标题：Multi-modal Brain Tumor Segmentation via Missing Modality Synthesis and  Modality-level Attention Fusion</b></summary>
  <p><b>编号</b>：[274]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04586</p>
  <p><b>作者</b>：Ziqi Huang,  Li Lin,  Pujin Cheng,  Linkai Peng,  Xiaoying Tang</p>
  <p><b>备注</b>：6 pages, 5 figures, submitted to ICPR 2022</p>
  <p><b>关键词</b>：innovatively conduct patchwise contrastive learning, yield superior t1ce synthesis performance, g ., brain tumor segmentation, level attention fusion network, imaging provides great potential</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Multi-modal magnetic resonance (MR) imaging provides great potential for
diagnosing and analyzing brain gliomas. In clinical scenarios, common MR
sequences such as T1, T2 and FLAIR can be obtained simultaneously in a single
scanning process. However, acquiring contrast enhanced modalities such as T1ce
requires additional time, cost, and injection of contrast agent. As such, it is
clinically meaningful to develop a method to synthesize unavailable modalities
which can also be used as additional inputs to downstream tasks (e.g., brain
tumor segmentation) for performance enhancing. In this work, we propose an
end-to-end framework named Modality-Level Attention Fusion Network (MAF-Net),
wherein we innovatively conduct patchwise contrastive learning for extracting
multi-modal latent features and dynamically assigning attention weights to fuse
different modalities. Through extensive experiments on BraTS2020, our proposed
MAF-Net is found to yield superior T1ce synthesis performance (SSIM of 0.8879
and PSNR of 22.78) and accurate brain tumor segmentation (mean Dice scores of
67.9%, 41.8% and 88.0% on segmenting the tumor core, enhancing tumor and whole
tumor).</p>
  </details>
</details>
<details>
  <summary>71. <b>标题：PHTrans: Parallelly Aggregating Global and Local Representations for  Medical Image Segmentation</b></summary>
  <p><b>编号</b>：[277]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04568</p>
  <p><b>作者</b>：Wentao Liu,  Tong Tian,  Weijin Xu,  Huihua Yang,  Xipeng Pan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：modified 3d swin transformer learn local features, automated cardiac diagnosis challeng datasets corroborate, many excellent hybrid architectures based, medical image segmentation called phtrans, obtain better segmentation performance</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The success of Transformer in computer vision has attracted increasing
attention in the medical imaging community. Especially for medical image
segmentation, many excellent hybrid architectures based on convolutional neural
networks (CNNs) and Transformer have been presented and achieve impressive
performance. However, most of these methods, which embed modular Transformer
into CNNs, struggle to reach their full potential. In this paper, we propose a
novel hybrid architecture for medical image segmentation called PHTrans, which
parallelly hybridizes Transformer and CNN in main building blocks to produce
hierarchical representations from global and local features and adaptively
aggregate them, aiming to fully exploit their strengths to obtain better
segmentation performance. Specifically, PHTrans follows the U-shaped
encoder-decoder design and introduces the parallel hybird module in deep
stages, where convolution blocks and the modified 3D Swin Transformer learn
local features and global dependencies separately, then a sequence-to-volume
operation unifies the dimensions of the outputs to achieve feature aggregation.
Extensive experimental results on both Multi-Atlas Labeling Beyond the Cranial
Vault and Automated Cardiac Diagnosis Challeng datasets corroborate its
effectiveness, consistently outperforming state-of-the-art methods.</p>
  </details>
</details>
<details>
  <summary>72. <b>标题：The Flag Median and FlagIRLS</b></summary>
  <p><b>编号</b>：[284]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04437</p>
  <p><b>作者</b>：Nathan Mankovich,  Emily King,  Chris Peterson,  Michael Kirby</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：produce highly imperfect clustering, common machine learning algorithms, $\ ell_2 $- median, $\ ell_2 $- median, ucf youtube action dataset</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Finding prototypes (e.g., mean and median) for a dataset is central to a
number of common machine learning algorithms. Subspaces have been shown to
provide useful, robust representations for datasets of images, videos and more.
Since subspaces correspond to points on a Grassmann manifold, one is led to
consider the idea of a subspace prototype for a Grassmann-valued dataset. While
a number of different subspace prototypes have been described, the calculation
of some of these prototypes has proven to be computationally expensive while
other prototypes are affected by outliers and produce highly imperfect
clustering on noisy data. This work proposes a new subspace prototype, the flag
median, and introduces the FlagIRLS algorithm for its calculation. We provide
evidence that the flag median is robust to outliers and can be used effectively
in algorithms like Linde-Buzo-Grey (LBG) to produce improved clusterings on
Grassmannians. Numerical experiments include a synthetic dataset, the MNIST
handwritten digits dataset, the Mind's Eye video dataset and the UCF YouTube
action dataset. The flag median is compared the other leading algorithms for
computing prototypes on the Grassmannian, namely, the $\ell_2$-median and to
the flag mean. We find that using FlagIRLS to compute the flag median converges
in $4$ iterations on a synthetic dataset. We also see that Grassmannian LBG
with a codebook size of $20$ and using the flag median produces at least a
$10\%$ improvement in cluster purity over Grassmannian LBG using the flag mean
or $\ell_2$-median on the Mind's Eye dataset.</p>
  </details>
</details>
<details>
  <summary>73. <b>标题：MICDIR: Multi-scale Inverse-consistent Deformable Image Registration  using UNetMSS with Self-Constructing Graph Latent</b></summary>
  <p><b>编号</b>：[293]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04317</p>
  <p><b>作者</b>：Soumick Chatterjee,  Himanshi Bajaj,  Istiyak H. Siddiquee,  Nandish Bandi Subbarayappa,  Steve Simon,  Suraj Bangalore Shashidhar,  Oliver Speck,  Andreas Nürnberge</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：tackle various complex medical image processing problems, proposed method achieved significant improvements, deep learning based techniques, proposed using deep learning, including medical image registration</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Image registration is the process of bringing different images into a common
coordinate system - a technique widely used in various applications of computer
vision, such as remote sensing, image retrieval, and most commonly in medical
imaging. Deep Learning based techniques have been applied successfully to
tackle various complex medical image processing problems, including medical
image registration. Over the years, several image registration techniques have
been proposed using deep learning. Deformable image registration techniques
such as Voxelmorph have been successful in capturing finer changes and
providing smoother deformations. However, Voxelmorph, as well as ICNet and
FIRE, do not explicitly encode global dependencies (i.e. the overall anatomical
view of the supplied image) and therefore can not track large deformations. In
order to tackle the aforementioned problems, this paper extends the Voxelmorph
approach in three different ways. To improve the performance in case of small
as well as large deformations, supervision of the model at different
resolutions have been integrated using a multi-scale UNet. To support the
network to learn and encode the minute structural co-relations of the given
image-pairs, a self-constructing graph network (SCGNet) has been used as the
latent of the multi-scale UNet - which can improve the learning process of the
model and help the model to generalise better. And finally, to make the
deformations inverse-consistent, cycle consistency loss has been employed. On
the task of registration of brain MRIs, the proposed method achieved
significant improvements over ANTs and VoxelMorph, obtaining a Dice score of
0.8013$\pm$0.0243 for intramodal and 0.6211$\pm$0.0309 for intermodal, while
VoxelMorph achieved 0.7747$\pm$0.0260 and 0.6071$\pm$0.0510, respectively.</p>
  </details>
</details>
<details>
  <summary>74. <b>标题：PyNET-QxQ: A Distilled PyNET for QxQ Bayer Pattern Demosaicing in CMOS  Image Sensor</b></summary>
  <p><b>编号</b>：[294]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04314</p>
  <p><b>作者</b>：Minhyeok Cho,  Haechang Lee,  Hyunwoo Je,  Kijeong Kim,  Dongil Ryu,  Jinsu Kim,  Jonghyun Bae,  Albert No</p>
  <p><b>备注</b>：in review</p>
  <p><b>关键词</b>：recent mobile cameras adopt non, qxq despite significant parameter reductions, based isp models mainly focus, mobile cameras produce high, weighted isp explicitly designed</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The deep learning-based ISP models for mobile cameras produce high-quality
images comparable to the professional DSLR camera. However, many of them are
computationally expensive, which may not be appropriate for mobile
environments. Also, the recent mobile cameras adopt non-Bayer CFAs (e.g., Quad
Bayer, Nona Bayer, and QxQ Bayer) to improve image quality; however, most deep
learning-based ISP models mainly focus on standard Bayer CFA. In this work, we
propose PyNET-QxQ based on PyNET, a light-weighted ISP explicitly designed for
the QxQ CFA pattern. The number of parameters of PyNET-QxQ is less than 2.5% of
PyNET. We also introduce a novel knowledge distillation technique, progressive
distillation, to train the compressed network effectively. Finally, experiments
with QxQ images (obtained by an actual QxQ camera sensor, under development)
demonstrate the outstanding performance of PyNET-QxQ despite significant
parameter reductions.</p>
  </details>
</details>
<details>
  <summary>75. <b>标题：Multi-Scale Adaptive Network for Single Image Denoising</b></summary>
  <p><b>编号</b>：[295]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04313</p>
  <p><b>作者</b>：Yuanbiao Gou,  Peng Hu,  Jiancheng Lv,  Xi Peng</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：existing methods treat different scale features equally without considering, six synthetic noisy image datasets show, tasks including single image denoising, e ., adaptive feature block, three novel neural blocks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Multi-scale architectures have shown effectiveness in a variety of tasks
including single image denoising, thanks to appealing cross-scale
complementarity. However, existing methods treat different scale features
equally without considering their scale-specific characteristics, i.e., the
within-scale characteristics are ignored. In this paper, we reveal this missing
piece for multi-scale architecture design and accordingly propose a novel
Multi-Scale Adaptive Network (MSANet) for single image denoising. To be
specific, MSANet simultaneously embraces the within-scale characteristics and
the cross-scale complementarity thanks to three novel neural blocks, i.e.,
adaptive feature block (AFeB), adaptive multi-scale block (AMB), and adaptive
fusion block (AFuB). In brief, AFeB is designed to adaptively select details
and filter noises, which is highly expected for fine-grained features. AMB
could enlarge the receptive field and aggregate the multi-scale information,
which is designed to satisfy the demands of both fine- and coarse-grained
features. AFuB devotes to adaptively sampling and transferring the features
from one scale to another scale, which is used to fuse the features with
varying characteristics from coarse to fine. Extensive experiments on both
three real and six synthetic noisy image datasets show the superiority of
MSANet compared with 12 methods.</p>
  </details>
</details>
<details>
  <summary>76. <b>标题：Breast cancer detection using artificial intelligence techniques: A  systematic literature review</b></summary>
  <p><b>编号</b>：[296]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04308</p>
  <p><b>作者</b>：Ali Bou Nassif,  Manar Abu Talib,  Qassim Nasir,  Yaman Afadar,  Omar Elgendy</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：systematically reviewed previous work done, breast cancer using genetic sequencing, national breast cancer foundation, important features affecting detection, detected using genes</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Cancer is one of the most dangerous diseases to humans, and yet no permanent
cure has been developed for it. Breast cancer is one of the most common cancer
types. According to the National Breast Cancer foundation, in 2020 alone, more
than 276,000 new cases of invasive breast cancer and more than 48,000
non-invasive cases were diagnosed in the US. To put these figures in
perspective, 64% of these cases are diagnosed early in the disease's cycle,
giving patients a 99% chance of survival. Artificial intelligence and machine
learning have been used effectively in detection and treatment of several
dangerous diseases, helping in early diagnosis and treatment, and thus
increasing the patient's chance of survival. Deep learning has been designed to
analyze the most important features affecting detection and treatment of
serious diseases. For example, breast cancer can be detected using genes or
histopathological imaging. Analysis at the genetic level is very expensive, so
histopathological imaging is the most common approach used to detect breast
cancer. In this research work, we systematically reviewed previous work done on
detection and treatment of breast cancer using genetic sequencing or
histopathological imaging with the help of deep learning and machine learning.
We also provide recommendations to researchers who will work in this field</p>
  </details>
</details>
<details>
  <summary>77. <b>标题：Diffusion Models for Medical Anomaly Detection</b></summary>
  <p><b>编号</b>：[297]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04306</p>
  <p><b>作者</b>：Julia Wolleb,  Florentin Bieder,  Robin Sandkühler,  Philippe C. Cattin</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：novel weakly supervised anomaly detection method based, current anomaly detection methods mainly rely, weakly supervised anomaly detection methods, detailed anomaly maps without, denoising diffusion implicit models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In medical applications, weakly supervised anomaly detection methods are of
great interest, as only image-level annotations are required for training.
Current anomaly detection methods mainly rely on generative adversarial
networks or autoencoder models. Those models are often complicated to train or
have difficulties to preserve fine details in the image. We present a novel
weakly supervised anomaly detection method based on denoising diffusion
implicit models. We combine the deterministic iterative noising and denoising
scheme with classifier guidance for image-to-image translation between diseased
and healthy subjects. Our method generates very detailed anomaly maps without
the need for a complex training procedure. We evaluate our method on the
BRATS2020 dataset for brain tumor detection and the CheXpert dataset for
detecting pleural effusions.</p>
  </details>
</details>
<details>
  <summary>78. <b>标题：Dynamic Dual-Output Diffusion Models</b></summary>
  <p><b>编号</b>：[298]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04304</p>
  <p><b>作者</b>：Yaniv Benny,  Lior Wolf</p>
  <p><b>备注</b>：To be presented at CVPR 2022</p>
  <p><b>关键词</b>：consider two opposite equations, image quality gradually deteriorates, various sota architectures, negligible added complexity, extensive ablation study</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Iterative denoising-based generation, also known as denoising diffusion
models, has recently been shown to be comparable in quality to other classes of
generative models, and even surpass them. Including, in particular, Generative
Adversarial Networks, which are currently the state of the art in many
sub-tasks of image generation. However, a major drawback of this method is that
it requires hundreds of iterations to produce a competitive result. Recent
works have proposed solutions that allow for faster generation with fewer
iterations, but the image quality gradually deteriorates with increasingly
fewer iterations being applied during generation. In this paper, we reveal some
of the causes that affect the generation quality of diffusion models,
especially when sampling with few iterations, and come up with a simple, yet
effective, solution to mitigate them. We consider two opposite equations for
the iterative denoising, the first predicts the applied noise, and the second
predicts the image directly. Our solution takes the two options and learns to
dynamically alternate between them through the denoising process. Our proposed
solution is general and can be applied to any existing diffusion model. As we
show, when applied to various SOTA architectures, our solution immediately
improves their generation quality, with negligible added complexity and
parameters. We experiment on multiple datasets and configurations and run an
extensive ablation study to support these findings.</p>
  </details>
</details>
<details>
  <summary>79. <b>标题：SuperPoint features in endoscopy</b></summary>
  <p><b>编号</b>：[299]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04302</p>
  <p><b>作者</b>：O. L. Barbed,  F. Chadebecq,  J. Morlana,  J.M. Martínez-Montiel,  A. C. Murillo</p>
  <p><b>备注</b>：9 pages, 6 figures</p>
  <p><b>关键词</b>：superpoint based models achieve significantly higher matching quality, adapted model avoids features within specularity regions, specially regarding 3d modelling, many computer vision applications, commonly used local features</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>There is often a significant gap between research results and applicability
in routine medical practice. This work studies the performance of well-known
local features on a medical dataset captured during routine colonoscopy
procedures. Local feature extraction and matching is a key step for many
computer vision applications, specially regarding 3D modelling. In the medical
domain, handcrafted local features such as SIFT, with public pipelines such as
COLMAP, are still a predominant tool for this kind of tasks. We explore the
potential of the well known self-supervised approach SuperPoint, present an
adapted variation for the endoscopic domain and propose a challenging
evaluation framework. SuperPoint based models achieve significantly higher
matching quality than commonly used local features in this domain. Our adapted
model avoids features within specularity regions, a frequent and problematic
artifact in endoscopic images, with consequent benefits for matching and
reconstruction results.</p>
  </details>
</details>
<details>
  <summary>80. <b>标题：Live Laparoscopic Video Retrieval with Compressed Uncertainty</b></summary>
  <p><b>编号</b>：[300]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04301</p>
  <p><b>作者</b>：Tong Yu,  Pietro Mascagni,  Juan Verde,  Jacques Marescaux,  Didier Mutter,  Nicolas Padoy</p>
  <p><b>备注</b>：14 pages, 12 figures</p>
  <p><b>关键词</b>：critical events across six different surgery types, top 10 mean average precision, hashing converts large data entries, largely unexplored research problem, challenging yet crucial task</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Searching through large volumes of medical data to retrieve relevant
information is a challenging yet crucial task for clinical care. However the
primitive and most common approach to retrieval, involving text in the form of
keywords, is severely limited when dealing with complex media formats.
Content-based retrieval offers a way to overcome this limitation, by using rich
media as the query itself. Surgical video-to-video retrieval in particular is a
new and largely unexplored research problem with high clinical value,
especially in the real-time case: using real-time video hashing, search can be
achieved directly inside of the operating room. Indeed, the process of hashing
converts large data entries into compact binary arrays or hashes, enabling
large-scale search operations at a very fast rate. However, due to fluctuations
over the course of a video, not all bits in a given hash are equally reliable.
In this work, we propose a method capable of mitigating this uncertainty while
maintaining a light computational footprint. We present superior retrieval
results (3-4 % top 10 mean average precision) on a multi-task evaluation
protocol for surgery, using cholecystectomy phases, bypass phases, and coming
from an entirely new dataset introduced here, critical events across six
different surgery types. Success on this multi-task benchmark shows the
generalizability of our approach for surgical video retrieval.</p>
  </details>
</details>
<details>
  <summary>81. <b>标题：Source-free Domain Adaptation for Multi-site and Lifespan Brain Skull  Stripping</b></summary>
  <p><b>编号</b>：[301]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04299</p>
  <p><b>作者</b>：Yunxiang Li,  Ruilong Dan,  Shuai Wang,  Yifan Cao,  Xiangde Luo,  Chenghao Tan,  Gangyong Jia,  Huiyu Zhou,  Yaqi Wang,  Li Wang</p>
  <p><b>备注</b>：11 page</p>
  <p><b>关键词</b>：accomplish domain adaptation without access, without disclosing private information, although many excellent works, free domain adaptation framework, numerous domain adaptation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Skull stripping is a crucial prerequisite step in the analysis of brain
magnetic resonance (MR) images. Although many excellent works or tools have
been proposed, they suffer from low generalization capability. For instance,
the model trained on a dataset with specific imaging parameters (source domain)
cannot be well applied to other datasets with different imaging parameters
(target domain). Especially, for the lifespan datasets, the model trained on an
adult dataset is not applicable to an infant dataset due to the large domain
difference. To address this issue, numerous domain adaptation (DA) methods have
been proposed to align the extracted features between the source and target
domains, requiring concurrent access to the input images of both domains.
Unfortunately, it is problematic to share the images due to privacy. In this
paper, we design a source-free domain adaptation framework (SDAF) for
multi-site and lifespan skull stripping that can accomplish domain adaptation
without access to source domain images. Our method only needs to share the
source labels as shape dictionaries and the weights trained on the source data,
without disclosing private information from source domain subjects. To deal
with the domain shift between multi-site lifespan datasets, we take advantage
of the brain shape prior which is invariant to imaging parameters and ages.
Experiments demonstrate that our framework can significantly outperform the
state-of-the-art methods on multi-site lifespan datasets.</p>
  </details>
</details>
<details>
  <summary>82. <b>标题：Region Specific Optimization (RSO)-based Deep Interactive Registration</b></summary>
  <p><b>编号</b>：[302]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04295</p>
  <p><b>作者</b>：Ti Bai,  Muhan Lin,  Xiao Liang,  Biling Wang,  Michael Dohopolski,  Bin Cai,  Dan Nguyen,  Steve Jiang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：dl )- based deformable image registration, exhibited large registration errors even, based image registration workflow, registration result reviewing process, many downstream clinical tasks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Medical image registration is a fundamental and vital task which will affect
the efficacy of many downstream clinical tasks. Deep learning (DL)-based
deformable image registration (DIR) methods have been investigated, showing
state-of-the-art performance. A test time optimization (TTO) technique was
proposed to further improve the DL models' performance. Despite the substantial
accuracy improvement with this TTO technique, there still remained some regions
that exhibited large registration errors even after many TTO iterations. To
mitigate this challenge, we firstly identified the reason why the TTO technique
was slow, or even failed, to improve those regions' registration results. We
then proposed a two-levels TTO technique, i.e., image-specific optimization
(ISO) and region-specific optimization (RSO), where the region can be
interactively indicated by the clinician during the registration result
reviewing process. For both efficiency and accuracy, we further envisioned a
three-step DL-based image registration workflow. Experimental results showed
that our proposed method outperformed the conventional method qualitatively and
quantitatively.</p>
  </details>
</details>
<details>
  <summary>83. <b>标题：NaviAirway: a bronchiole-sensitive deep learning-based airway  segmentation pipeline for planning of navigation bronchoscopy</b></summary>
  <p><b>编号</b>：[303]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04294</p>
  <p><b>作者</b>：Andong Wang,  Terence Chi Chun Tam,  Ho Ming Poon,  Kun-Chang Yu,  Wei-Ning Lee</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：inspired iterative training strategy, four major novel components, propose two new metrics, naviairway takes five minutes, naviairway outperformed existing methods</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Navigation bronchoscopy is a minimally invasive procedure in which doctors
pass a bronchoscope into a subject's airways to sample the target pulmonary
lesion. A three-dimensional (3D) airway roadmap reconstructed from Computer
Tomography (CT) scans is a prerequisite for this procedure, especially when the
target is distally located. Therefore, an accurate and efficient airway
segmentation algorithm is essential to reduce bronchoscopists' burden of
pre-procedural airway identification as well as patients' discomfort during the
prolonged procedure. However, airway segmentation remains a challenging task
because of the intrinsic complex tree-like structure, imbalanced sizes of
airway branches, potential domain shifts of CT scans, and few available labeled
images. To address these problems, we present a deep learning-based pipeline,
denoted as NaviAirway, which finds finer bronchioles through four major novel
components - feature extractor modules in model architecture design, a
bronchiole-sensitive loss function, a human-vision-inspired iterative training
strategy, and a semi-supervised learning framework to utilize unlabeled CT
images. Experimental results showed that NaviAirway outperformed existing
methods, particularly in identification of higher generation bronchioles and
robustness to new CT scans. On average, NaviAirway takes five minutes to
segment the CT scans of one patient on a GPU-embedded computer. Moreover, we
propose two new metrics to complement conventional ones for a more
comprehensive and fairer evaluation of deep learning-based airway segmentation
approaches. The code is publicly available on
this https URL.</p>
  </details>
</details>
<details>
  <summary>84. <b>标题：Towards performant and reliable undersampled MR reconstruction via  diffusion model sampling</b></summary>
  <p><b>编号</b>：[304]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04292</p>
  <p><b>作者</b>：Cheng Peng,  Pengfei Guo,  S. Kevin Zhou,  Vishal Patel,  Rama Chellappa</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：sampled acquisition promises faster scanning time, explicitly visualize different potential reconstruction solutions, proposed diffuserecon achieves sota performances reconstructing, approaches leverage deep neural networks, approaches achieve impressive performances</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Magnetic Resonance (MR) image reconstruction from under-sampled acquisition
promises faster scanning time. To this end, current State-of-The-Art (SoTA)
approaches leverage deep neural networks and supervised training to learn a
recovery model. While these approaches achieve impressive performances, the
learned model can be fragile on unseen degradation, e.g. when given a different
acceleration factor. These methods are also generally deterministic and provide
a single solution to an ill-posed problem; as such, it can be difficult for
practitioners to understand the reliability of the reconstruction. We introduce
DiffuseRecon, a novel diffusion model-based MR reconstruction method.
DiffuseRecon guides the generation process based on the observed signals and a
pre-trained diffusion model, and does not require additional training on
specific acceleration factors. DiffuseRecon is stochastic in nature and
generates results from a distribution of fully-sampled MR images; as such, it
allows us to explicitly visualize different potential reconstruction solutions.
Lastly, DiffuseRecon proposes an accelerated, coarse-to-fine Monte-Carlo
sampling scheme to approximate the most likely reconstruction candidate. The
proposed DiffuseRecon achieves SoTA performances reconstructing from raw
acquisition signals in fastMRI and SKM-TEA.</p>
  </details>
</details>
<details>
  <summary>85. <b>标题：Residual Aligner Network</b></summary>
  <p><b>编号</b>：[305]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04290</p>
  <p><b>作者</b>：Jian-Qing Zheng,  Ziyang Wang,  Baoru Huang,  Ngee Han Lim,  Bartlomiej W. Papiez</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：efficiently perform 3d image registration, new network achieves results, head displacement field used, ra module achieve one, splenic vein ),</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Image registration is important for medical imaging, the estimation of the
spatial transformation between different images. Many previous studies have
used learning-based methods for coarse-to-fine registration to efficiently
perform 3D image registration. The coarse-to-fine approach, however, is limited
when dealing with the different motions of nearby objects. Here we propose a
novel Motion-Aware (MA) structure that captures the different motions in a
region. The MA structure incorporates a novel Residual Aligner (RA) module
which predicts the multi-head displacement field used to disentangle the
different motions of multiple neighbouring objects. Compared with other deep
learning methods, the network based on the MA structure and RA module achieve
one of the most accurate unsupervised inter-subject registration on the 9
organs of assorted sizes in abdominal CT scans, with the highest-ranked
registration of the veins (Dice Similarity Coefficient / Average surface
distance: 62\%/4.9mm for the vena cava and 34\%/7.9mm for the portal and
splenic vein), with a half-sized structure and more efficient computation.
Applied to the segmentation of lungs in chest CT scans, the new network
achieves results which were indistinguishable from the best-ranked networks
(94\%/3.0mm). Additionally, the theorem on predicted motion pattern and the
design of MA structure are validated by further analysis.</p>
  </details>
</details>
<h1>自然语言处理</h1>
<details>
  <summary>1. <b>标题：DUAL: Textless Spoken Question Answering with Speech Discrete Unit  Adaptive Learning</b></summary>
  <p><b>编号</b>：[16]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04911</p>
  <p><b>作者</b>：Guan-Ting Lin,  Yung-Sung Chuang,  Ho-Lam Chung,  Shu-wen Yang,  Hsuan-Jui Chen,  Shang-Wen Li,  Abdelrahman Mohamed,  Hung-yi Lee,  Lin-shan Lee</p>
  <p><b>备注</b>：Submitted to Interspeech 2022</p>
  <p><b>关键词</b>：free sqa framework named discrete unit adaptive learning, new sqa benchmark corpus natural multi, existing sqa methods rely, speaker spoken question answering, spoken question answering</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Spoken Question Answering (SQA) has gained research attention and made
remarkable progress in recent years. However, existing SQA methods rely on
Automatic Speech Recognition (ASR) transcripts, which are time and
cost-prohibitive to collect. This work proposes an ASR transcript-free SQA
framework named Discrete Unit Adaptive Learning (DUAL), which leverages
unlabeled data for pre-training and is fine-tuned by the SQA downstream task.
DAUL can directly predict the time interval of the spoken answer from the
spoken document. We also release a new SQA benchmark corpus Natural
Multi-speaker Spoken Question Answering (NMSQA) for testing SQA in realistic
scenarios. The experimental results show that DUAL performs competitively with
the cascade approach (ASR + text QA), and DUAL is robust to real-world speech.
We will open-source our code and model to inspire more SQA innovations from the
community</p>
  </details>
</details>
<details>
  <summary>2. <b>标题：Pose Guided Multi-person Image Generation From Text</b></summary>
  <p><b>编号</b>：[18]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04907</p>
  <p><b>作者</b>：Soon Yau Cheong,  Armin Mustafa,  Andrew Gilbert</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：generate high quality images, person images accurately representing, proposed keypoint pose encoding, create high fidelity full, low dimensional representation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Transformers have recently been shown to generate high quality images from
texts. However, existing methods struggle to create high fidelity full-body
images, especially multiple people. A person's pose has a high degree of
freedom that is difficult to describe using words only; this creates errors in
the generated image, such as incorrect body proportions and pose. We propose a
pose-guided text-to-image model, using pose as an additional input constraint.
Using the proposed Keypoint Pose Encoding (KPE) to encode human pose into low
dimensional representation, our model can generate novel multi-person images
accurately representing the pose and text descriptions provided, with minimal
errors. We demonstrate that KPE is invariant to changes in the target image
domain and image resolution; we show results on the Deepfashion dataset and
create a new multi-person Deepfashion dataset to demonstrate the
multi-capabilities of our approach.</p>
  </details>
</details>
<details>
  <summary>3. <b>标题：Model-Agnostic Multitask Fine-tuning for Few-shot Vision-Language  Transfer Learning</b></summary>
  <p><b>编号</b>：[20]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04904</p>
  <p><b>作者</b>：Zhenhailong Wang,  Hang Yu,  Manling Li,  Han Zhao,  Heng Ji</p>
  <p><b>备注</b>：7 pages, 6 figures, under review</p>
  <p><b>关键词</b>：uniform task sampling procedure, g ., fungi classification, prevent highly expressive model, simple yet efficient fine, uniform task sampling</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Despite achieving state-of-the-art zero-shot performance, existing
vision-language models, e.g., CLIP, still fall short of domain-specific
classification tasks, e.g., Fungi Classification. In the context of few-shot
transfer learning, traditional fine-tuning fails to prevent highly expressive
model from exploiting spurious correlations in the training data. On the other
hand, although model-agnostic meta-learning (MAML) presents as a natural
alternative for transfer learning, the expensive computation due to implicit
second-order optimization limits its use in large-scale models and datasets. In
this work we aim to further improve the generalization of existing
vision-language models on unseen tasks via a simple yet efficient fine-tuning
strategy based on uniform task sampling. We term our method as Model-Agnostic
Multitask Fine-tuning (MAMF). Compared with MAML, MAMF discards the bi-level
optimization and uses only first-order gradients, which makes it easily
scalable and computationally efficient. Due to the uniform task sampling
procedure, MAMF consistently outperforms the classical fine-tuning method for
few-shot transfer learning on five benchmark datasets. Empirically, we further
discover that the effectiveness of first-order MAML is highly dependent on the
zero-shot performance of the pretrained model, and our simple algorithm can
outperform first-order MAML on more challenging datasets with low zero-shot
performance.</p>
  </details>
</details>
<details>
  <summary>4. <b>标题：Unsupervised Alignment of Distributional Word Embeddings</b></summary>
  <p><b>编号</b>：[33]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04863</p>
  <p><b>作者</b>：Aissatou Diallo</p>
  <p><b>备注</b>：7 pages, preliminary work</p>
  <p><b>关键词</b>：bilingual lexicon induction task across several language pairs, proposed approach achieves good performance, point vectors although distributional embeddings, bilingual lexicon without relying, propose stochastic optimization approach</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Cross-domain alignment play a key roles in tasks ranging from machine
translation to transfer learning. Recently, purely unsupervised methods
operating on monolingual embeddings have successfully been used to infer a
bilingual lexicon without relying on supervision. However, current state-of-the
art methods only focus on point vectors although distributional embeddings have
proven to embed richer semantic information when representing words. In this
paper, we propose stochastic optimization approach for aligning probabilistic
embeddings. Finally, we evaluate our method on the problem of unsupervised word
translation, by aligning word embeddings trained on monolingual data. We show
that the proposed approach achieves good performance on the bilingual lexicon
induction task across several language pairs and performs better than the
point-vector based approach.</p>
  </details>
</details>
<details>
  <summary>5. <b>标题：PET: A new Dataset for Process Extraction from Natural Language Text</b></summary>
  <p><b>编号</b>：[34]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04860</p>
  <p><b>作者</b>：Patrizio Bellan,  Han van der Aa,  Mauro Dragoni,  Chiara Ghidini,  Simone Paolo Ponzetto</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：first steps towards bridging data, driven information extraction methodologies, business process descriptions annotated, business process extraction, natural language processing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Although there is a long tradition of work in NLP on extracting entities and
relations from text, to date there exists little work on the acquisition of
business processes from unstructured data such as textual corpora of process
descriptions. With this work we aim at filling this gap and establishing the
first steps towards bridging data-driven information extraction methodologies
from Natural Language Processing and the model-based formalization that is
aimed from Business Process Management. For this, we develop the first corpus
of business process descriptions annotated with activities, gateways, actors
and flow information. We present our new resource, including a detailed
overview of the annotation schema and guidelines, as well as a variety of
baselines to benchmark the difficulty and challenges of business process
extraction from text.</p>
  </details>
</details>
<details>
  <summary>6. <b>标题：Neuro-symbolic Natural Logic with Introspective Revision for Natural  Language Inference</b></summary>
  <p><b>编号</b>：[35]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04857</p>
  <p><b>作者</b>：Yufei Feng,  Xiaoyu Yang,  Xiaodan Zhu,  Michael Greenspan</p>
  <p><b>备注</b>：To appear at TACL 2022, MIT Press</p>
  <p><b>关键词</b>：introspective revision algorithm modifies intermediate symbolic reasoning steps, symbolic natural logic framework based, properly designed local relation models, rewards specific reasoning paths, alleviate spurious reasoning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We introduce a neuro-symbolic natural logic framework based on reinforcement
learning with introspective revision. The model samples and rewards specific
reasoning paths through policy gradient, in which the introspective revision
algorithm modifies intermediate symbolic reasoning steps to discover
reward-earning operations as well as leverages external knowledge to alleviate
spurious reasoning and training inefficiency. The framework is supported by
properly designed local relation models to avoid input entangling, which helps
ensure the interpretability of the proof paths. The proposed model has built-in
interpretability and shows superior capability in monotonicity inference,
systematic generalization, and interpretability, compared to previous models on
the existing datasets.</p>
  </details>
</details>
<details>
  <summary>7. <b>标题：Automatic Language Identification for Celtic Texts</b></summary>
  <p><b>编号</b>：[43]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04831</p>
  <p><b>作者</b>：Olha Dovbnia,  Anna Wróblewska</p>
  <p><b>备注</b>：14 pages, 6 figures</p>
  <p><b>关键词</b>：dense neural network consistently outperformed, important natural language processing task, help achieve comparable classification performance, traditional statistical features alongside, available annotated training data</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Language identification is an important Natural Language Processing task. It
has been thoroughly researched in the literature. However, some issues are
still open. This work addresses the identification of the related low-resource
languages on the example of the Celtic language family.
This work's main goals were: (1) to collect the dataset of three Celtic
languages; (2) to prepare a method to identify the languages from the Celtic
family, i.e. to train a successful classification model; (3) to evaluate the
influence of different feature extraction methods, and explore the
applicability of the unsupervised models as a feature extraction technique; (4)
to experiment with the unsupervised feature extraction on a reduced annotated
set.
We collected a new dataset including Irish, Scottish, Welsh and English
records. We tested supervised models such as SVM and neural networks with
traditional statistical features alongside the output of clustering,
autoencoder, and topic modelling methods. The analysis showed that the
unsupervised features could serve as a valuable extension to the n-gram feature
vectors. It led to an improvement in performance for more entangled classes.
The best model achieved a 98\% F1 score and 97\% MCC. The dense neural network
consistently outperformed the SVM model.
The low-resource languages are also challenging due to the scarcity of
available annotated training data. This work evaluated the performance of the
classifiers using the unsupervised feature extraction on the reduced labelled
dataset to handle this issue. The results uncovered that the unsupervised
feature vectors are more robust to the labelled set reduction. Therefore, they
proved to help achieve comparable classification performance with much less
labelled data.</p>
  </details>
</details>
<details>
  <summary>8. <b>标题：Efficient Sub-structured Knowledge Distillation</b></summary>
  <p><b>编号</b>：[44]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04825</p>
  <p><b>作者</b>：Wenye Lin,  Yangming Li,  Lemao Liu,  Shuming Shi,  Hai-tao Zheng</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：consuming techniques like dynamic programming, two structured prediction tasks demonstrate, structured prediction models aim, training process even faster, approach outperforms previous methods</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Structured prediction models aim at solving a type of problem where the
output is a complex structure, rather than a single variable. Performing
knowledge distillation for such models is not trivial due to their
exponentially large output space. In this work, we propose an approach that is
much simpler in its formulation and far more efficient for training than
existing approaches. Specifically, we transfer the knowledge from a teacher
model to its student model by locally matching their predictions on all
sub-structures, instead of the whole output space. In this manner, we avoid
adopting some time-consuming techniques like dynamic programming (DP) for
decoding output structures, which permits parallel computation and makes the
training process even faster in practice. Besides, it encourages the student
model to better mimic the internal behavior of the teacher model. Experiments
on two structured prediction tasks demonstrate that our approach outperforms
previous methods and halves the time cost for one training epoch.</p>
  </details>
</details>
<details>
  <summary>9. <b>标题：One-Shot Learning from a Demonstration with Hierarchical Latent Language</b></summary>
  <p><b>编号</b>：[53]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04806</p>
  <p><b>作者</b>：Nathaniel Weir,  Xingdi Yuan,  Marc-Alexandre Côté,  Matthew Hausknecht,  Romain Laroche,  Ida Momennejad,  Harm Van Seijen,  Benjamin Van Durme</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：hierarchical latent language --, multiple evaluation scenarios, like grid world, neural agent infused, agent first generates</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Humans have the capability, aided by the expressive compositionality of their
language, to learn quickly by demonstration. They are able to describe unseen
task-performing procedures and generalize their execution to other contexts. In
this work, we introduce DescribeWorld, an environment designed to test this
sort of generalization skill in grounded agents, where tasks are linguistically
and procedurally composed of elementary concepts. The agent observes a single
task demonstration in a Minecraft-like grid world, and is then asked to carry
out the same task in a new map. To enable such a level of generalization, we
propose a neural agent infused with hierarchical latent language--both at the
level of task inference and subtask planning. Our agent first generates a
textual description of the demonstrated unseen task, then leverages this
description to replicate it. Through multiple evaluation scenarios and a suite
of generalization tests, we find that agents that perform text-based inference
are better equipped for the challenge under a random split of tasks.</p>
  </details>
</details>
<details>
  <summary>10. <b>标题：Enhance Topics Analysis based on Keywords Properties</b></summary>
  <p><b>编号</b>：[61]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04786</p>
  <p><b>作者</b>：Antonio Penta</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：prevalent text analysis technique used, recent coherence score presented, art topic modelling results, topic model algorithms, specificity score based</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Topic Modelling is one of the most prevalent text analysis technique used to
explore and retrieve collection of documents. The evaluation of the topic model
algorithms is still a very challenging tasks due to the absence of
gold-standard list of topics to compare against for every corpus. In this work,
we present a specificity score based on keywords properties that is able to
select the most informative topics. This approach helps the user to focus on
the most informative topics. In the experiments, we show that we are able to
compress the state-of-the-art topic modelling results of different factors with
an information loss that is much lower than the solution based on the recent
coherence score presented in literature.</p>
  </details>
</details>
<details>
  <summary>11. <b>标题：Pretrained Domain-Specific Language Model for General Information  Retrieval Tasks in the AEC Domain</b></summary>
  <p><b>编号</b>：[88]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04729</p>
  <p><b>作者</b>：Zhe Zheng,  Xin-Zheng Lu,  Ke-Yin Chen,  Yu-Cheng Zhou,  Jia-Rui Lin</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：based models dramatically outperform traditional methods, including traditional wording embedding models, several widely used dl models, traditional word embedding models, unstructured textual data based</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As an essential task for the architecture, engineering, and construction
(AEC) industry, information retrieval (IR) from unstructured textual data based
on natural language processing (NLP) is gaining increasing attention. Although
various deep learning (DL) models for IR tasks have been investigated in the
AEC domain, it is still unclear how domain corpora and domain-specific
pretrained DL models can improve performance in various IR tasks. To this end,
this work systematically explores the impacts of domain corpora and various
transfer learning techniques on the performance of DL models for IR tasks and
proposes a pretrained domain-specific language model for the AEC domain. First,
both in-domain and close-domain corpora are developed. Then, two types of
pretrained models, including traditional wording embedding models and
BERT-based models, are pretrained based on various domain corpora and transfer
learning strategies. Finally, several widely used DL models for IR tasks are
further trained and tested based on various configurations and pretrained
models. The result shows that domain corpora have opposite effects on
traditional word embedding models for text classification and named entity
recognition tasks but can further improve the performance of BERT-based models
in all tasks. Meanwhile, BERT-based models dramatically outperform traditional
methods in all IR tasks, with maximum improvements of 5.4% and 10.1% in the F1
score, respectively. This research contributes to the body of knowledge in two
ways: 1) demonstrating the advantages of domain corpora and pretrained DL
models and 2) opening the first domain-specific dataset and pretrained language
model for the AEC domain, to the best of our knowledge. Thus, this work sheds
light on the adoption and application of pretrained models in the AEC domain.</p>
  </details>
</details>
<details>
  <summary>12. <b>标题：Language Diversity: Visible to Humans, Exploitable by Machines</b></summary>
  <p><b>编号</b>：[90]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04723</p>
  <p><b>作者</b>：Gábor Bella,  Erdenebileg Byambadorj,  Yamini Chandrashekar,  Khuyagbaatar Batsuren,  Danish Ashgar Cheema,  Fausto Giunchiglia</p>
  <p><b>备注</b>：Accepted for publication in ACL 2022</p>
  <p><b>关键词</b>：ukc website lets users explore millions, large multilingual lexical database, universal knowledge core, somewhat abstract notion, ukc livelanguage catalogue</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The Universal Knowledge Core (UKC) is a large multilingual lexical database
with a focus on language diversity and covering over a thousand languages. The
aim of the database, as well as its tools and data catalogue, is to make the
somewhat abstract notion of diversity visually understandable for humans and
formally exploitable by machines. The UKC website lets users explore millions
of individual words and their meanings, but also phenomena of cross-lingual
convergence and divergence, such as shared interlingual meanings, lexicon
similarities, cognate clusters, or lexical gaps. The UKC LiveLanguage
Catalogue, in turn, provides access to the underlying lexical data in a
computer-processable form, ready to be reused in cross-lingual applications.</p>
  </details>
</details>
<details>
  <summary>13. <b>标题：Nested Named Entity Recognition as Latent Lexicalized Constituency  Parsing</b></summary>
  <p><b>编号</b>：[108]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04665</p>
  <p><b>作者</b>：Chao Lou,  Songlin Yang,  Kewei Tu</p>
  <p><b>备注</b>：ACL 2022 camera ready</p>
  <p><b>关键词</b>：method cannot leverage entity heads, nested named entity recognition, entity mention detection, treat nested entities, model nested entities</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Nested named entity recognition (NER) has been receiving increasing
attention. Recently, (Fu et al, 2021) adapt a span-based constituency parser to
tackle nested NER. They treat nested entities as partially-observed
constituency trees and propose the masked inside algorithm for partial
marginalization. However, their method cannot leverage entity heads, which have
been shown useful in entity mention detection and entity typing. In this work,
we resort to more expressive structures, lexicalized constituency trees in
which constituents are annotated by headwords, to model nested entities. We
leverage the Eisner-Satta algorithm to perform partial marginalization and
inference efficiently. In addition, we propose to use (1) a two-stage strategy
(2) a head regularization loss and (3) a head-aware labeling loss in order to
enhance the performance. We make a thorough ablation study to investigate the
functionality of each component. Experimentally, our method achieves the
state-of-the-art performance on ACE2004, ACE2005 and NNE, and competitive
performance on GENIA, and meanwhile has a fast inference speed.</p>
  </details>
</details>
<details>
  <summary>14. <b>标题：ASET: Ad-hoc Structured Exploration of Text Collections [Extended  Abstract]</b></summary>
  <p><b>编号</b>：[109]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04663</p>
  <p><b>作者</b>：Benjamin Hättasch,  Jan-Micha Bodensohn,  Carsten Binnig</p>
  <p><b>备注</b>：Accepted at the 3rd International Workshop on Applied AI for Database Systems and Applications (AIDB'21), August 20, 2021, Copenhagen, Denmark</p>
  <p><b>关键词</b>：texts using existing extractors, design extraction pipelines upfront, new system called aset, structured table definition, perform structured explorations</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we propose a new system called ASET that allows users to
perform structured explorations of text collections in an ad-hoc manner. The
main idea of ASET is to use a new two-phase approach that first extracts a
superset of information nuggets from the texts using existing extractors such
as named entity recognizers and then matches the extractions to a structured
table definition as requested by the user based on embeddings. In our
evaluation, we show that ASET is thus able to extract structured data from
real-world text collections in high quality without the need to design
extraction pipelines upfront.</p>
  </details>
</details>
<details>
  <summary>15. <b>标题：Slangvolution: A Causal Analysis of Semantic Change and Frequency  Dynamics in Slang</b></summary>
  <p><b>编号</b>：[113]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04651</p>
  <p><b>作者</b>：Daphna Keidar,  Andreas Opedal,  Zhijing Jin,  Mrinmaya Sachan</p>
  <p><b>备注</b>：Accepted as a main conference paper at ACL 2022</p>
  <p><b>关键词</b>：slang words undergo less semantic change, various distributional factors associate, causal inference techniques, approach language evolution, larger frequency shifts</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Languages are continuously undergoing changes, and the mechanisms that
underlie these changes are still a matter of debate. In this work, we approach
language evolution through the lens of causality in order to model not only how
various distributional factors associate with language change, but how they
causally affect it. In particular, we study slang, which is an informal
language that is typically restricted to a specific group or social setting. We
analyze the semantic change and frequency shift of slang words and compare them
to those of standard, nonslang words. With causal discovery and causal
inference techniques, we measure the effect that word type (slang/nonslang) has
on both semantic change and frequency shift, as well as its relationship to
frequency, polysemy and part of speech. Our analysis provides some new insights
in the study of semantic change, e.g., we show that slang words undergo less
semantic change but tend to have larger frequency shifts over time.</p>
  </details>
</details>
<details>
  <summary>16. <b>标题：Memory Efficient Continual Learning for Neural Text Classification</b></summary>
  <p><b>编号</b>：[119]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04640</p>
  <p><b>作者</b>：Beyza Ermis,  Giovanni Zappella,  Martin Wistuba,  Cedric Archambeau</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：algorithm learns new tasks without performance degradation, method requires significantly less model parameters compared, perform text classification using pre, training large neural language models, method suffers little forgetting</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Learning text classifiers based on pre-trained language models has become the
standard practice in natural language processing applications. Unfortunately,
training large neural language models, such as transformers, from scratch is
very costly and requires a vast amount of training data, which might not be
available in the application domain of interest. Moreover, in many real-world
scenarios, classes are uncovered as more data is seen, calling for
class-incremental modelling approaches. In this work we devise a method to
perform text classification using pre-trained models on a sequence of
classification tasks provided in sequence. We formalize the problem as a
continual learning problem where the algorithm learns new tasks without
performance degradation on the previous ones and without re-training the model
from scratch. We empirically demonstrate that our method requires significantly
less model parameters compared to other state of the art methods and that it is
significantly faster at inference time. The tight control on the number of
model parameters, and so the memory, is not only improving efficiency. It is
making possible the usage of the algorithm in real-world applications where
deploying a solution with a constantly increasing memory consumption is just
unrealistic. While our method suffers little forgetting, it retains a
predictive performance on-par with state of the art but less memory efficient
methods.</p>
  </details>
</details>
<details>
  <summary>17. <b>标题：LEBP -- Language Expectation & Binding Policy: A Two-Stream Framework  for Embodied Vision-and-Language Interaction Task Learning Agents</b></summary>
  <p><b>编号</b>：[121]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04637</p>
  <p><b>作者</b>：Haoyu Liu,  Yang Liu,  Hongkai He,  Hangfang Yang</p>
  <p><b>备注</b>：6 pages</p>
  <p><b>关键词</b>：perform complicated daily household tasks following natural language instructions, propose lebp -- language expectation, currently published sota methods, approach achieves comparable performance, language interaction benchmark alfred</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>People always desire an embodied agent that can perform a task by
understanding language instruction. Moreover, they also want to monitor and
expect agents to understand commands the way they expected. But, how to build
such an embodied agent is still unclear. Recently, people can explore this
problem with the Vision-and-Language Interaction benchmark ALFRED, which
requires an agent to perform complicated daily household tasks following
natural language instructions in unseen scenes. In this paper, we propose LEBP
-- Language Expectation and Binding Policy Module to tackle the ALFRED. The
LEBP contains a two-stream process: 1) It first conducts a language expectation
module to generate an expectation describing how to perform tasks by
understanding the language instruction. The expectation consists of a sequence
of sub-steps for the task (e.g., Pick an apple). The expectation allows people
to access and check the understanding results of instructions before the agent
takes actual actions, in case the task might go wrong. 2) Then, it uses the
binding policy module to bind sub-steps in expectation to actual actions to
specific scenarios. Actual actions include navigation and object manipulation.
Experimental results suggest our approach achieves comparable performance to
currently published SOTA methods and can avoid large decay from seen scenarios
to unseen scenarios.</p>
  </details>
</details>
<details>
  <summary>18. <b>标题：PALI-NLP at SemEval-2022 Task 4: Discriminative Fine-tuning of Deep  Transformers for Patronizing and Condescending Language Detection</b></summary>
  <p><b>编号</b>：[125]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04616</p>
  <p><b>作者</b>：Dou Hu,  Mengyuan Zhou,  Xiyang Du,  Mengfei Yuan,  Meizhi Jin,  Lianxin Jiang,  Yang Mo,  Xiaofeng Shi</p>
  <p><b>备注</b>：8 pages, submitted in SemEval-2022 Workshop (co-located with NAACL)</p>
  <p><b>关键词</b>：system achieves remarkable results, large harmful impact, existing nlp systems, diverse linguistic behaviour, capture discriminative features</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Patronizing and condescending language (PCL) has a large harmful impact and
is difficult to detect, both for human judges and existing NLP systems. At
SemEval-2022 Task 4, we propose a novel Transformer-based model and its
ensembles to accurately understand such language context for PCL detection. To
facilitate comprehension of the subtle and subjective nature of PCL, two
fine-tuning strategies are applied to capture discriminative features from
diverse linguistic behaviour and categorical distribution. The system achieves
remarkable results on the official ranking, namely 1st in Subtask 1 and 5th in
Subtask 2. Extensive experiments on the task demonstrate the effectiveness of
our system and its strategies.</p>
  </details>
</details>
<details>
  <summary>19. <b>标题：Mapping global dynamics of benchmark creation and saturation in  artificial intelligence</b></summary>
  <p><b>编号</b>：[133]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04592</p>
  <p><b>作者</b>：Adriano Barbosa-Silva,  Simon Ott,  Kathrin Blagec,  Jan Brauner,  Matthias Samwald</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：benchmarks quickly trended towards near, recent studies raised concerns, mapping benchmark performance gains, benchmark performance gains, scale community collaboration</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Benchmarks are crucial to measuring and steering progress in artificial
intelligence (AI). However, recent studies raised concerns over the state of AI
benchmarking, reporting issues such as benchmark overfitting, benchmark
saturation and increasing centralization of benchmark dataset creation. To
facilitate monitoring of the health of the AI benchmarking ecosystem, we
introduce methodologies for creating condensed maps of the global dynamics of
benchmark creation and saturation. We curated data for 1688 benchmarks covering
the entire domains of computer vision and natural language processing, and show
that a large fraction of benchmarks quickly trended towards near-saturation,
that many benchmarks fail to find widespread utilization, and that benchmark
performance gains for different AI tasks were prone to unforeseen bursts. We
conclude that future work should focus on large-scale community collaboration
and on mapping benchmark performance gains to real-world utility and impact of
AI.</p>
  </details>
</details>
<details>
  <summary>20. <b>标题：Onception: Active Learning with Expert Advice for Real World Machine  Translation</b></summary>
  <p><b>编号</b>：[165]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04507</p>
  <p><b>作者</b>：Vânia Mendonça (1 and 2),  Ricardo Rei (1 and 2 and 3),  Luisa Coheur (1 and 2),  Alberto Sardinha (1 and 2) ((1) INESC-ID Lisboa, (2) Instituto Superior Técnico, (3) Unbabel AI)</p>
  <p><b>备注</b>：Submitted to Machine Translation</p>
  <p><b>关键词</b>：expert advice often outperforms several individual active learning strategies, dynamically combine multiple strategies using prediction, combining multiple strategies using prediction, based active learning query strategies, using active learning allows</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Active learning can play an important role in low-resource settings (i.e.,
where annotated data is scarce), by selecting which instances may be more
worthy to annotate. Most active learning approaches for Machine Translation
assume the existence of a pool of sentences in a source language, and rely on
human annotators to provide translations or post-edits, which can still be
costly. In this paper, we assume a real world human-in-the-loop scenario in
which: (i) the source sentences may not be readily available, but instead
arrive in a stream; (ii) the automatic translations receive feedback in the
form of a rating, instead of a correct/edited translation, since the
human-in-the-loop might be a user looking for a translation, but not be able to
provide one. To tackle the challenge of deciding whether each incoming pair
source-translations is worthy to query for human feedback, we resort to a
number of stream-based active learning query strategies. Moreover, since we not
know in advance which query strategy will be the most adequate for a certain
language pair and set of Machine Translation models, we propose to dynamically
combine multiple strategies using prediction with expert advice. Our
experiments show that using active learning allows to converge to the best
Machine Translation systems with fewer human interactions. Furthermore,
combining multiple strategies using prediction with expert advice often
outperforms several individual active learning strategies with even fewer
interactions.</p>
  </details>
</details>
<details>
  <summary>21. <b>标题：Boilerplate Detection via Semantic Classification of TextBlocks</b></summary>
  <p><b>编号</b>：[176]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04467</p>
  <p><b>作者</b>：Hao Zhang,  Jie Wang</p>
  <p><b>备注</b>：IJCNN 2021</p>
  <p><b>关键词</b>：hierarchical neural network model called semtext, also detects boilerplate effectively, detect html boilerplate based, novel semantic representation, three published datasets</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present a hierarchical neural network model called SemText to detect HTML
boilerplate based on a novel semantic representation of HTML tags, class names,
and text blocks. We train SemText on three published datasets of news webpages
and fine-tune it using a small number of development data in CleanEval and
GoogleTrends-2017. We show that SemText achieves the state-of-the-art accuracy
on these datasets. We then demonstrate the robustness of SemText by showing
that it also detects boilerplate effectively on out-of-domain community-based
question-answer webpages.</p>
  </details>
</details>
<details>
  <summary>22. <b>标题：On the Evaluation of Answer-Agnostic Paragraph-level Multi-Question  Generation</b></summary>
  <p><b>编号</b>：[178]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04464</p>
  <p><b>作者</b>：Jishnu Ray Chowdhury,  Debanjan Mahata,  Cornelia Caragea</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：make two main contributions, trained seq2seq model, proposed evaluation strategy, practical properties compared, compare different strategies</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We study the task of predicting a set of salient questions from a given
paragraph without any prior knowledge of the precise answer. We make two main
contributions. First, we propose a new method to evaluate a set of predicted
questions against the set of references by using the Hungarian algorithm to
assign predicted questions to references before scoring the assigned pairs. We
show that our proposed evaluation strategy has better theoretical and practical
properties compared to prior methods because it can properly account for the
coverage of references. Second, we compare different strategies to utilize a
pre-trained seq2seq model to generate and select a set of questions related to
a given paragraph. The code is available.</p>
  </details>
</details>
<details>
  <summary>23. <b>标题：Contextual Networks and Unsupervised Ranking of Sentences</b></summary>
  <p><b>编号</b>：[181]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04459</p>
  <p><b>作者</b>：Hao Zhang,  You Zhou,  Jie Wang</p>
  <p><b>备注</b>：ICTAI 2021</p>
  <p><b>关键词</b>：three human judges provided, 1 knapsack maximization problem, outperforms previous supervised algorithms, unsupervised algorithm called cnatar, latest supervised neural</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We construct a contextual network to represent a document with syntactic and
semantic relations between word-sentence pairs, based on which we devise an
unsupervised algorithm called CNATAR (Contextual Network And Text Analysis
Rank) to score sentences, and rank them through a bi-objective 0-1 knapsack
maximization problem over topic analysis and sentence scores. We show that
CNATAR outperforms the combined ranking of the three human judges provided on
the SummBank dataset under both ROUGE and BLEU metrics, which in term
significantly outperforms each individual judge's ranking. Moreover, CNATAR
produces so far the highest ROUGE scores over DUC-02, and outperforms previous
supervised algorithms on the CNN/DailyMail and NYT datasets. We also compare
the performance of CNATAR and the latest supervised neural-network
summarization models and compute oracle results.</p>
  </details>
</details>
<details>
  <summary>24. <b>标题：Estimating the Uncertainty in Emotion Class Labels with  Utterance-Specific Dirichlet Priors</b></summary>
  <p><b>编号</b>：[192]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04443</p>
  <p><b>作者</b>：Wen Wu,  Chao Zhang,  Xixin Wu,  Philip C. Woodland</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：widely used iemocap dataset demonstrate, novel bayesian training loss based, leibler divergence training loss, common iemocap test setups, branch structure achieves state</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Emotion recognition is a key attribute for artificial intelligence systems
that need to naturally interact with humans. However, the task definition is
still an open problem due to inherent ambiguity of emotions. In this paper, a
novel Bayesian training loss based on per-utterance Dirichlet prior
distributions is proposed for verbal emotion recognition, which models the
uncertainty in one-hot labels created when human annotators assign the same
utterance to different emotion classes. An additional metric is used to
evaluate the performance by detecting test utterances with high labelling
uncertainty. This removes a major limitation that emotion classification
systems only consider utterances with majority labels.Furthermore, a
frequentist approach is studied to leverage the continuous-valued "soft" labels
obtained by averaging the one-hot labels. We propose a two-branch model
structure for emotion classification on a per-utterance basis. Experiments with
the widely used IEMOCAP dataset demonstrate that the two-branch structure
achieves state-of-the-art classification results with all common IEMOCAP test
setups. Based on this, uncertainty estimation experiments were performed. The
best performance in terms of the area under the precision-recall curve when
detecting utterances with high uncertainty was achieved by interpolating the
Bayesian training loss with the Kullback-Leibler divergence training loss for
the soft labels.</p>
  </details>
</details>
<details>
  <summary>25. <b>标题：iSEA: An Interactive Pipeline for Semantic Error Analysis of NLP Models</b></summary>
  <p><b>编号</b>：[210]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04408</p>
  <p><b>作者</b>：Jun Yuan,  Jesse Vig,  Nazneen Rajani</p>
  <p><b>备注</b>：Accepted at IUI 2022, 11 pages, 6 figures</p>
  <p><b>关键词</b>：existing approaches typically define subpopulations based, tool supports semantic descriptions, isea enables model developers, one common approach, automatically discovers semantically</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Error analysis in NLP models is essential to successful model development and
deployment. One common approach for diagnosing errors is to identify
subpopulations in the dataset where the model produces the most errors.
However, existing approaches typically define subpopulations based on
pre-defined features, which requires users to form hypotheses of errors in
advance. To complement these approaches, we propose iSEA, an Interactive
Pipeline for Semantic Error Analysis in NLP Models, which automatically
discovers semantically-grounded subpopulations with high error rates in the
context of a human-in-the-loop interactive system. iSEA enables model
developers to learn more about their model errors through discovered
subpopulations, validate the sources of errors through interactive analysis on
the discovered subpopulations, and test hypotheses about model errors by
defining custom subpopulations. The tool supports semantic descriptions of
error-prone subpopulations at the token and concept level, as well as
pre-defined higher-level features. Through use cases and expert interviews, we
demonstrate how iSEA can assist error understanding and analysis.</p>
  </details>
</details>
<details>
  <summary>26. <b>标题：It's AI Match: A Two-Step Approach for Schema Matching Using Embeddings</b></summary>
  <p><b>编号</b>：[224]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04366</p>
  <p><b>作者</b>：Benjamin Hättasch,  Michael Truong-Ngoc,  Andreas Schmidt,  Carsten Binnig</p>
  <p><b>备注</b>：Accepted to the 2nd International Workshop on Applied AI for Database Systems and Applications (AIDB'20), August 31, 2020, Tokyo, Japan</p>
  <p><b>关键词</b>：different levels either representing, traditional schema matching approaches, table matching step followed, manual effort involved, attribute matching step</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Since data is often stored in different sources, it needs to be integrated to
gather a global view that is required in order to create value and derive
knowledge from it. A critical step in data integration is schema matching which
aims to find semantic correspondences between elements of two schemata. In
order to reduce the manual effort involved in schema matching, many solutions
for the automatic determination of schema correspondences have already been
developed.
In this paper, we propose a novel end-to-end approach for schema matching
based on neural embeddings. The main idea is to use a two-step approach
consisting of a table matching step followed by an attribute matching step. In
both steps we use embeddings on different levels either representing the whole
table or single attributes. Our results show that our approach is able to
determine correspondences in a robust and reliable way and compared to
traditional schema matching approaches can find non-trivial correspondences.</p>
  </details>
</details>
<details>
  <summary>27. <b>标题：Which side are you on? Insider-Outsider classification in  conspiracy-theoretic social media</b></summary>
  <p><b>编号</b>：[227]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04356</p>
  <p><b>作者</b>：Pavan Holur,  Tianyi Wang,  Shadi Shahsavari,  Timothy Tangherlini,  Vwani Roychowdhury</p>
  <p><b>备注</b>：ACL 2022: 60th Annual Meeting of the Association for Computational Linguistics 8+4 pages, 6 figures</p>
  <p><b>关键词</b>：follow common negative sentiment patterns, np2io leverages pretrained language modeling, sharply defined group identities, challenging new nlp task, imply outsider status often</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Social media is a breeding ground for threat narratives and related
conspiracy theories. In these, an outside group threatens the integrity of an
inside group, leading to the emergence of sharply defined group identities:
Insiders -- agents with whom the authors identify and Outsiders -- agents who
threaten the insiders. Inferring the members of these groups constitutes a
challenging new NLP task: (i) Information is distributed over many
poorly-constructed posts; (ii) Threats and threat agents are highly contextual,
with the same post potentially having multiple agents assigned to membership in
either group; (iii) An agent's identity is often implicit and transitive; and
(iv) Phrases used to imply Outsider status often do not follow common negative
sentiment patterns. To address these challenges, we define a novel
Insider-Outsider classification task. Because we are not aware of any
appropriate existing datasets or attendant models, we introduce a labeled
dataset (CT5K) and design a model (NP2IO) to address this task. NP2IO leverages
pretrained language modeling to classify Insiders and Outsiders. NP2IO is shown
to be robust, generalizing to noun phrases not seen during training, and
exceeding the performance of non-trivial baseline models by $20\%$.</p>
  </details>
</details>
<details>
  <summary>28. <b>标题：'Beach' to 'Bitch': Inadvertent Unsafe Transcription of Kids' Content on  YouTube</b></summary>
  <p><b>编号</b>：[250]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04837</p>
  <p><b>作者</b>：Krithika Ramesh,  Ashiqur R. KhudaBukhsh,  Sumeet Kumar</p>
  <p><b>备注</b>：This paper got accepted at AAAI 2022, AI for Social Impact track</p>
  <p><b>关键词</b>：systems may produce text content highly inappropriate, art asr systems hallucinate inappropriate content, asr systems often produce, known automatic speech recognition, fixed using language models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Over the last few years, YouTube Kids has emerged as one of the highly
competitive alternatives to television for children's entertainment.
Consequently, YouTube Kids' content should receive an additional level of
scrutiny to ensure children's safety. While research on detecting offensive or
inappropriate content for kids is gaining momentum, little or no current work
exists that investigates to what extent AI applications can (accidentally)
introduce content that is inappropriate for kids.
In this paper, we present a novel (and troubling) finding that well-known
automatic speech recognition (ASR) systems may produce text content highly
inappropriate for kids while transcribing YouTube Kids' videos. We dub this
phenomenon as \emph{inappropriate content hallucination}. Our analyses suggest
that such hallucinations are far from occasional, and the ASR systems often
produce them with high confidence. We release a first-of-its-kind data set of
audios for which the existing state-of-the-art ASR systems hallucinate
inappropriate content for kids. In addition, we demonstrate that some of these
errors can be fixed using language models.</p>
  </details>
</details>
<h1>机器学习</h1>
<details>
  <summary>1. <b>标题：Temporal Difference Learning for Model Predictive Control</b></summary>
  <p><b>编号</b>：[1]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04955</p>
  <p><b>作者</b>：Nicklas Hansen,  Xiaolong Wang,  Hao Su</p>
  <p><b>备注</b>：Code and videos: this https URL</p>
  <p><b>关键词</b>：based continuous control tasks, achieves superior sample efficiency, learned terminal value function, oriented latent dynamics model, driven model predictive control</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Data-driven model predictive control has two key advantages over model-free
methods: a potential for improved sample efficiency through model learning, and
better performance as computational budget for planning increases. However, it
is both costly to plan over long horizons and challenging to obtain an accurate
model of the environment. In this work, we combine the strengths of model-free
and model-based methods. We use a learned task-oriented latent dynamics model
for local trajectory optimization over a short horizon, and use a learned
terminal value function to estimate long-term return, both of which are learned
jointly by temporal difference learning. Our method, TD-MPC, achieves superior
sample efficiency and asymptotic performance over prior work on both state and
image-based continuous control tasks from DMControl and Meta-World. Code and
video results are available at this https URL.</p>
  </details>
</details>
<details>
  <summary>2. <b>标题：Learning from Physical Human Feedback: An Object-Centric One-Shot  Adaptation Method</b></summary>
  <p><b>编号</b>：[2]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04951</p>
  <p><b>作者</b>：Alvin Shek,  Rui Chen,  Changliu Liu</p>
  <p><b>备注</b>：Submitted to IROS</p>
  <p><b>关键词</b>：existing methods either require repeated episodes, assume prior known reward features, produces new behaviors never seen, either correct undesirable behavior, cheap synthetic data instead</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>For robots to be effectively deployed in novel environments and tasks, they
must be able to understand the feedback expressed by humans during
intervention. This can either correct undesirable behavior or indicate
additional preferences. Existing methods either require repeated episodes of
interactions or assume prior known reward features, which is data-inefficient
and can hardly transfer to new tasks. We relax these assumptions by describing
human tasks in terms of object-centric sub-tasks and interpreting physical
interventions in relation to specific objects. Our method, Object Preference
Adaptation (OPA), is composed of two key stages: 1) pre-training a base policy
to produce a wide variety of behaviors, and 2) online-updating only certain
weights in the model according to human feedback. The key to our fast, yet
simple adaptation is that general interaction dynamics between agents and
objects are fixed, and only object-specific preferences are updated. Our
adaptation occurs online, requires only one human intervention (one-shot), and
produces new behaviors never seen during training. Trained on cheap synthetic
data instead of expensive human demonstrations, our policy demonstrates
impressive adaptation to human perturbations on challenging, realistic tasks in
our user study. Videos, code, and supplementary material provided.</p>
  </details>
</details>
<details>
  <summary>3. <b>标题：Renyi Fair Information Bottleneck for Image Classification</b></summary>
  <p><b>编号</b>：[3]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04950</p>
  <p><b>作者</b>：Adam Gronowski,  William Paul,  Fady Alajaji,  Bahman Gharesifard,  Philippe Burlina</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：consider two different fairness constraints, tunable parameter $\ alpha, eyepacs medical imaging dataset, renyi fair information bottleneck, outperforms competing state</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We develop a novel method for ensuring fairness in machine learning which we
term as the Renyi Fair Information Bottleneck (RFIB). We consider two different
fairness constraints - demographic parity and equalized odds - for learning
fair representations and derive a loss function via a variational approach that
uses Renyi's divergence with its tunable parameter $\alpha$ and that takes into
account the triple constraints of utility, fairness, and compactness of
representation. We then evaluate the performance of our method for image
classification using the EyePACS medical imaging dataset, showing it
outperforms competing state of the art techniques with performance measured
using a variety of compound utility/fairness metrics, including accuracy gap
and Rawls' minimal accuracy.</p>
  </details>
</details>
<details>
  <summary>4. <b>标题：Data-Efficient Structured Pruning via Submodular Optimization</b></summary>
  <p><b>编号</b>：[5]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04940</p>
  <p><b>作者</b>：Marwa El Halabi,  Suraj Srinivas,  Simon Lacoste-Julien</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：trained neural networks without significantly affecting, involves removing redundant regular regions, method outperforms popular baseline methods, efficient structured pruning method based, current structured pruning methods</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Structured pruning is an effective approach for compressing large pre-trained
neural networks without significantly affecting their performance, which
involves removing redundant regular regions of weights. However, current
structured pruning methods are highly empirical in nature, do not provide any
theoretical guarantees, and often require fine-tuning, which makes them
inapplicable in the limited-data regime. We propose a principled data-efficient
structured pruning method based on submodular optimization. In particular, for
a given layer, we select neurons/channels to prune and corresponding new
weights for the next layer, that minimize the change in the next layer's input
induced by pruning. We show that this selection problem is a weakly submodular
maximization problem, thus it can be provably approximated using an efficient
greedy algorithm. Our method is one of the few in the literature that uses only
a limited-number of training data and no labels. Our experimental results
demonstrate that our method outperforms popular baseline methods in various
one-shot pruning settings.</p>
  </details>
</details>
<details>
  <summary>5. <b>标题：Addressing Bias in Visualization Recommenders by Identifying Trends in  Training Data: Improving VizML Through a Statistical Analysis of the Plotly  Community Feed</b></summary>
  <p><b>编号</b>：[6]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04937</p>
  <p><b>作者</b>：Allen Tu,  Priyanka Mehta,  Alexander Wu,  Nandhini Krishnan,  Amar Mujumdar</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：machine learning visualization recommendation systems, visualization recommendation due, machine learning models, research project aims, may negatively affect</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Machine learning is a promising approach to visualization recommendation due
to its high scalability and representational power. Researchers can create a
neural network to predict visualizations from input data by training it over a
corpus of datasets and visualization examples. However, these machine learning
models can reflect trends in their training data that may negatively affect
their performance. Our research project aims to address training bias in
machine learning visualization recommendation systems by identifying trends in
the training data through statistical analysis.</p>
  </details>
</details>
<details>
  <summary>6. <b>标题：Deep Generative Models for Downlink Channel Estimation in FDD Massive  MIMO Systems</b></summary>
  <p><b>编号</b>：[7]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04935</p>
  <p><b>作者</b>：Javad Mirzaei,  Shahram ShahbazPanahi,  Raviraj Adve,  Navaneetha Gopal</p>
  <p><b>备注</b>：To appear in IEEE Transactions on Signal Processing 2022</p>
  <p><b>关键词</b>：acquiring downlink channel state information, based channel estimation technique outperforms, aods ), via uplink training, estimated via downlink training using, dgm )- based technique</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>It is well accepted that acquiring downlink channel state information in
frequency division duplexing (FDD) massive multiple-input multiple-output
(MIMO) systems is challenging because of the large overhead in training and
feedback. In this paper, we propose a deep generative model (DGM)-based
technique to address this challenge. Exploiting the partial reciprocity of
uplink and downlink channels, we first estimate the frequency-independent
underlying channel parameters, i.e., the magnitudes of path gains, delays,
angles-of-arrivals (AoAs) and angles-of-departures (AoDs), via uplink training,
since these parameters are common in both uplink and downlink. Then, the
frequency-specific underlying channel parameters, namely, the phase of each
propagation path, are estimated via downlink training using a very short
training signal. In the first step, we incorporate the underlying distribution
of the channel parameters as a prior into our channel estimation algorithm. We
use DGMs to learn this distribution. Simulation results indicate that our
proposed DGM-based channel estimation technique outperforms, by a large gap,
the conventional channel estimation techniques in practical ranges of
signal-to-noise ratio (SNR). In addition, a near-optimal performance is
achieved using only few downlink pilot measurements.</p>
  </details>
</details>
<details>
  <summary>7. <b>标题：DISCO: Comprehensive and Explainable Disinformation Detection</b></summary>
  <p><b>编号</b>：[9]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04928</p>
  <p><b>作者</b>：Dongqi Fu,  Yikun Ban,  Hanghang Tong,  Ross Maciejewski,  Jingrui He</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：explainable disinformation detection framework called disco, world fake news detection task, false information deliberately spread, satisfactory detection accuracy, automated disinformation detection</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Disinformation refers to false information deliberately spread to influence
the general public, and the negative impact of disinformation on society can be
observed for numerous issues, such as political agendas and manipulating
financial markets. In this paper, we identify prevalent challenges and advances
related to automated disinformation detection from multiple aspects, and
propose a comprehensive and explainable disinformation detection framework
called DISCO. It leverages the heterogeneity of disinformation and addresses
the prediction opaqueness. Then we provide a demonstration of DISCO on a
real-world fake news detection task with satisfactory detection accuracy and
explanation. The demo video and source code of DISCO is now publicly available.
We expect that our demo could pave the way for addressing the limitations of
identification, comprehension, and explainability as a whole.</p>
  </details>
</details>
<details>
  <summary>8. <b>标题：Investigation of Factorized Optical Flows as Mid-Level Representations</b></summary>
  <p><b>编号</b>：[10]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04927</p>
  <p><b>作者</b>：Hsuan-Kung Yang,  Tsu-Ching Hsiao,  Ting-Hsuan Liao,  Hsu-Shen Liu,  Li-Yuan Tsao,  Tzu-Wen Wang,  Shan-Ya Yang,  Yu-Wen Chen,  Huang-Ru Liao,  Chun-Yi Lee</p>
  <p><b>备注</b>：This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible</p>
  <p><b>关键词</b>：modular learning based robotic frameworks, deep reinforcement learning agents, incorporating factorized flow maps, factorized optical flow maps, factorized flow maps</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we introduce a new concept of incorporating factorized flow
maps as mid-level representations, for bridging the perception and the control
modules in modular learning based robotic frameworks. To investigate the
advantages of factorized flow maps and examine their interplay with the other
types of mid-level representations, we further develop a configurable
framework, along with four different environments that contain both static and
dynamic objects, for analyzing the impacts of factorized optical flow maps on
the performance of deep reinforcement learning agents. Based on this framework,
we report our experimental results on various scenarios, and offer a set of
analyses to justify our hypothesis. Finally, we validate flow factorization in
real world scenarios.</p>
  </details>
</details>
<details>
  <summary>9. <b>标题：Correlated quantization for distributed mean estimation and optimization</b></summary>
  <p><b>编号</b>：[11]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04925</p>
  <p><b>作者</b>：Ananda Theertha Suresh,  Ziteng Sun,  Jae Hun Ro,  Felix Yu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：correlated quantization protocol whose error guarantee depends, proposed algorithm outperforms existing mean estimation protocols, distributed optimization algorithms leads, distributed mean estimation, data points instead</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We study the problem of distributed mean estimation and optimization under
communication constraints. We propose a correlated quantization protocol whose
error guarantee depends on the deviation of data points instead of their
absolute range. The design doesn't need any prior knowledge on the
concentration property of the dataset, which is required to get such dependence
in previous works. We show that applying the proposed protocol as sub-routine
in distributed optimization algorithms leads to better convergence rates. We
also prove the optimality of our protocol under mild assumptions. Experimental
results show that our proposed algorithm outperforms existing mean estimation
protocols on a diverse set of tasks.</p>
  </details>
</details>
<details>
  <summary>10. <b>标题：The Severity Prediction of The Binary And Multi-Class Cardiovascular  Disease -- A Machine Learning-Based Fusion Approach</b></summary>
  <p><b>编号</b>：[13]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04921</p>
  <p><b>作者</b>：Hafsa Binte Kibria,  Abdul Matin</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：mainly health care industry contains many data consisting, algorithms like artificial neural network, save many lives using, different test training ratios, weighted score fusion approach</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In today's world, a massive amount of data is available in almost every
sector. This data has become an asset as we can use this enormous amount of
data to find information. Mainly health care industry contains many data
consisting of patient and disease-related information. By using the machine
learning technique, we can look for hidden data patterns to predict various
diseases. Recently CVDs, or cardiovascular disease, have become a leading cause
of death around the world. The number of death due to CVDs is frightening. That
is why many researchers are trying their best to design a predictive model that
can save many lives using the data mining model. In this research, some fusion
models have been constructed to diagnose CVDs along with its severity. Machine
learning(ML) algorithms like artificial neural network, SVM, logistic
regression, decision tree, random forest, and AdaBoost have been applied to the
heart disease dataset to predict disease. Randomoversampler was implemented
because of the class imbalance in multiclass classification. To improve the
performance of classification, a weighted score fusion approach was taken. At
first, the models were trained. After training, two algorithms' decision was
combined using a weighted sum rule. A total of three fusion models have been
developed from the six ML algorithms. The results were promising in the
performance parameter. The proposed approach has been experimented with
different test training ratios for binary and multiclass classification
problems, and for both of them, the fusion models performed well. The highest
accuracy for multiclass classification was found as 75%, and it was 95% for
binary. The code can be found in :
this https URL</p>
  </details>
</details>
<details>
  <summary>11. <b>标题：Leveling Down in Computer Vision: Pareto Inefficiencies in Fair Deep  Classifiers</b></summary>
  <p><b>编号</b>：[15]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04913</p>
  <p><b>作者</b>：Dominik Zietlow,  Michael Lohaus,  Guha Balakrishnan,  Matthäus Kleindessner,  Francesco Locatello,  Bernhard Schölkopf,  Chris Russell</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：computer vision also degrade performance, applying existing fairness approaches, best performing groups )., computer vision improve fairness, settings involving high</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Algorithmic fairness is frequently motivated in terms of a trade-off in which
overall performance is decreased so as to improve performance on disadvantaged
groups where the algorithm would otherwise be less accurate. Contrary to this,
we find that applying existing fairness approaches to computer vision improve
fairness by degrading the performance of classifiers across all groups (with
increased degradation on the best performing groups).
Extending the bias-variance decomposition for classification to fairness, we
theoretically explain why the majority of fairness classifiers designed for low
capacity models should not be used in settings involving high-capacity models,
a scenario common to computer vision. We corroborate this analysis with
extensive experimental support that shows that many of the fairness heuristics
used in computer vision also degrade performance on the most disadvantaged
groups. Building on these insights, we propose an adaptive augmentation
strategy that, uniquely, of all methods tested, improves performance for the
disadvantaged groups.</p>
  </details>
</details>
<details>
  <summary>12. <b>标题：What Matters For Meta-Learning Vision Regression Tasks?</b></summary>
  <p><b>编号</b>：[19]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04905</p>
  <p><b>作者</b>：Ning Gao,  Hanna Ziesche,  Ngo Anh Vien,  Michael Volpp,  Gerhard Neumann</p>
  <p><b>备注</b>：Accepted at CVPR 2022</p>
  <p><b>关键词</b>：various deep learning techniques commonly used, paper makes two main contributions, category level vision regression tasks, design two new types, exhaustively evaluate common meta</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Meta-learning is widely used in few-shot classification and function
regression due to its ability to quickly adapt to unseen tasks. However, it has
not yet been well explored on regression tasks with high dimensional inputs
such as images. This paper makes two main contributions that help understand
this barely explored area. \emph{First}, we design two new types of
cross-category level vision regression tasks, namely object discovery and pose
estimation of unprecedented complexity in the meta-learning domain for computer
vision. To this end, we (i) exhaustively evaluate common meta-learning
techniques on these tasks, and (ii) quantitatively analyze the effect of
various deep learning techniques commonly used in recent meta-learning
algorithms in order to strengthen the generalization capability: data
augmentation, domain randomization, task augmentation and meta-regularization.
Finally, we (iii) provide some insights and practical recommendations for
training meta-learning algorithms on vision regression tasks. \emph{Second}, we
propose the addition of functional contrastive learning (FCL) over the task
representations in Conditional Neural Processes (CNPs) and train in an
end-to-end fashion. The experimental results show that the results of prior
work are misleading as a consequence of a poor choice of the loss function as
well as too small meta-training sets. Specifically, we find that CNPs
outperform MAML on most tasks without fine-tuning. Furthermore, we observe that
naive task augmentation without a tailored design results in underfitting.</p>
  </details>
</details>
<details>
  <summary>13. <b>标题：A Brain-Inspired Low-Dimensional Computing Classifier for Inference on  Tiny Devices</b></summary>
  <p><b>编号</b>：[24]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04894</p>
  <p><b>作者</b>：Shijin Duan,  Xiaolin Xu,  Shaolei Ren</p>
  <p><b>备注</b>：8 pages, 9 figures, accepted by and presented as a full paper at TinyML Research Symposium 2022</p>
  <p><b>关键词</b>：g ., 8000 vs, large model sizes beyond, also implement different models, considering different datasets, stringent resource constraints</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>By mimicking brain-like cognition and exploiting parallelism,
hyperdimensional computing (HDC) classifiers have been emerging as a
lightweight framework to achieve efficient on-device inference. Nonetheless,
they have two fundamental drawbacks, heuristic training process and ultra-high
dimension, which result in sub-optimal inference accuracy and large model sizes
beyond the capability of tiny devices with stringent resource constraints. In
this paper, we address these fundamental drawbacks and propose a
low-dimensional computing (LDC) alternative. Specifically, by mapping our LDC
classifier into an equivalent neural network, we optimize our model using a
principled training approach. Most importantly, we can improve the inference
accuracy while successfully reducing the ultra-high dimension of existing HDC
models by orders of magnitude (e.g., 8000 vs. 4/64). We run experiments to
evaluate our LDC classifier by considering different datasets for inference on
tiny devices, and also implement different models on an FPGA platform for
acceleration. The results highlight that our LDC classifier offers an
overwhelming advantage over the existing brain-inspired HDC models and is
particularly suitable for inference on tiny devices.</p>
  </details>
</details>
<details>
  <summary>14. <b>标题：Efficient Image Representation Learning with Federated Sampled Softmax</b></summary>
  <p><b>编号</b>：[26]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04888</p>
  <p><b>作者</b>：Sagar M. Waghmare,  Hang Qi,  Huizhong Chen,  Mikhail Sirotenko,  Tomer Meron</p>
  <p><b>备注</b>：15 pages, 10 figures, 4 tables and 1 algorithm</p>
  <p><b>关键词</b>：standard full softmax method, global full softmax objective, softmax cross entropy loss, aggregated across data silos, introduce federated sampled softmax</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Learning image representations on decentralized data can bring many benefits
in cases where data cannot be aggregated across data silos. Softmax cross
entropy loss is highly effective and commonly used for learning image
representations. Using a large number of classes has proven to be particularly
beneficial for the descriptive power of such representations in centralized
learning. However, doing so on decentralized data with Federated Learning is
not straightforward as the demand on FL clients' computation and communication
increases proportionally to the number of classes. In this work we introduce
federated sampled softmax (FedSS), a resource-efficient approach for learning
image representation with Federated Learning. Specifically, the FL clients
sample a set of classes and optimize only the corresponding model parameters
with respect to a sampled softmax objective that approximates the global full
softmax objective. We examine the loss formulation and empirically show that
our method significantly reduces the number of parameters transferred to and
optimized by the client devices, while performing on par with the standard full
softmax method. This work creates a possibility for efficiently learning image
representations on decentralized data with a large number of classes under the
federated setting.</p>
  </details>
</details>
<details>
  <summary>15. <b>标题：Reverse Engineering $\ell_p$ attacks: A block-sparse optimization  approach with recovery guarantees</b></summary>
  <p><b>编号</b>：[28]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04886</p>
  <p><b>作者</b>：Darshan Thaker,  Paris Giampouras,  René Vidal</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：$\ ell_p $- bounded norm adversarial attacks, attack ($\ ell_1 $, $\ ell_2, includes one subspace per class, one subspace per attack type, reverse engineering adversarial attacks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep neural network-based classifiers have been shown to be vulnerable to
imperceptible perturbations to their input, such as $\ell_p$-bounded norm
adversarial attacks. This has motivated the development of many defense
methods, which are then broken by new attacks, and so on. This paper focuses on
a different but related problem of reverse engineering adversarial attacks.
Specifically, given an attacked signal, we study conditions under which one can
determine the type of attack ($\ell_1$, $\ell_2$ or $\ell_\infty$) and recover
the clean signal. We pose this problem as a block-sparse recovery problem,
where both the signal and the attack are assumed to lie in a union of subspaces
that includes one subspace per class and one subspace per attack type. We
derive geometric conditions on the subspaces under which any attacked signal
can be decomposed as the sum of a clean signal plus an attack. In addition, by
determining the subspaces that contain the signal and the attack, we can also
classify the signal and determine the attack type. Experiments on digit and
face classification demonstrate the effectiveness of the proposed approach.</p>
  </details>
</details>
<details>
  <summary>16. <b>标题：CEU-Net: Ensemble Semantic Segmentation of Hyperspectral Images Using  Clustering</b></summary>
  <p><b>编号</b>：[31]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04873</p>
  <p><b>作者</b>：Nicholas Soucy,  Salimeh Yasaei Sekeh</p>
  <p><b>备注</b>：11 Pages, 5 Tables, 1 Algorithm, 5 Figures</p>
  <p><b>关键词</b>：accurately classify diversified land cover, net model outperforms existing state, art hsi semantic segmentation methods, combine spectral information extracted, high performance across botswana</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Most semantic segmentation approaches of Hyperspectral images (HSIs) use and
require preprocessing steps in the form of patching to accurately classify
diversified land cover in remotely sensed images. These approaches use patching
to incorporate the rich neighborhood information in images and exploit the
simplicity and segmentability of the most common HSI datasets. In contrast,
most landmasses in the world consist of overlapping and diffused classes,
making neighborhood information weaker than what is seen in common HSI
datasets. To combat this issue and generalize the segmentation models to more
complex and diverse HSI datasets, in this work, we propose our novel flagship
model: Clustering Ensemble U-Net (CEU-Net). CEU-Net uses the ensemble method to
combine spectral information extracted from convolutional neural network (CNN)
training on a cluster of landscape pixels. Our CEU-Net model outperforms
existing state-of-the-art HSI semantic segmentation methods and gets
competitive performance with and without patching when compared to baseline
models. We highlight CEU-Net's high performance across Botswana, KSC, and
Salinas datasets compared to HybridSN and AeroRIT methods.</p>
  </details>
</details>
<details>
  <summary>17. <b>标题：Binary Classification Under $\ell_0$ Attacks for General Noise  Distribution</b></summary>
  <p><b>编号</b>：[36]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04855</p>
  <p><b>作者</b>：Payam Delgosha,  Hamed Hassani,  Ramtin Pedarsani</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：recently drawn considerable attention, nonlinear component called truncation, robust machine learning, major performance degradation, optimal classification error</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Adversarial examples have recently drawn considerable attention in the field
of machine learning due to the fact that small perturbations in the data can
result in major performance degradation. This phenomenon is usually modeled by
a malicious adversary that can apply perturbations to the data in a constrained
fashion, such as being bounded in a certain norm. In this paper, we study this
problem when the adversary is constrained by the $\ell_0$ norm; i.e., it can
perturb a certain number of coordinates in the input, but has no limit on how
much it can perturb those coordinates. Due to the combinatorial nature of this
setting, we need to go beyond the standard techniques in robust machine
learning to address this problem. We consider a binary classification scenario
where $d$ noisy data samples of the true label are provided to us after
adversarial perturbations. We introduce a classification method which employs a
nonlinear component called truncation, and show in an asymptotic scenario, as
long as the adversary is restricted to perturb no more than $\sqrt{d}$ data
samples, we can almost achieve the optimal classification error in the absence
of the adversary, i.e. we can completely neutralize adversary's effect.
Surprisingly, we observe a phase transition in the sense that using a converse
argument, we show that if the adversary can perturb more than $\sqrt{d}$
coordinates, no classifier can do better than a random guess.</p>
  </details>
</details>
<details>
  <summary>18. <b>标题：Automatic Language Identification for Celtic Texts</b></summary>
  <p><b>编号</b>：[43]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04831</p>
  <p><b>作者</b>：Olha Dovbnia,  Anna Wróblewska</p>
  <p><b>备注</b>：14 pages, 6 figures</p>
  <p><b>关键词</b>：dense neural network consistently outperformed, important natural language processing task, help achieve comparable classification performance, traditional statistical features alongside, available annotated training data</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Language identification is an important Natural Language Processing task. It
has been thoroughly researched in the literature. However, some issues are
still open. This work addresses the identification of the related low-resource
languages on the example of the Celtic language family.
This work's main goals were: (1) to collect the dataset of three Celtic
languages; (2) to prepare a method to identify the languages from the Celtic
family, i.e. to train a successful classification model; (3) to evaluate the
influence of different feature extraction methods, and explore the
applicability of the unsupervised models as a feature extraction technique; (4)
to experiment with the unsupervised feature extraction on a reduced annotated
set.
We collected a new dataset including Irish, Scottish, Welsh and English
records. We tested supervised models such as SVM and neural networks with
traditional statistical features alongside the output of clustering,
autoencoder, and topic modelling methods. The analysis showed that the
unsupervised features could serve as a valuable extension to the n-gram feature
vectors. It led to an improvement in performance for more entangled classes.
The best model achieved a 98\% F1 score and 97\% MCC. The dense neural network
consistently outperformed the SVM model.
The low-resource languages are also challenging due to the scarcity of
available annotated training data. This work evaluated the performance of the
classifiers using the unsupervised feature extraction on the reduced labelled
dataset to handle this issue. The results uncovered that the unsupervised
feature vectors are more robust to the labelled set reduction. Therefore, they
proved to help achieve comparable classification performance with much less
labelled data.</p>
  </details>
</details>
<details>
  <summary>19. <b>标题：Efficient Sub-structured Knowledge Distillation</b></summary>
  <p><b>编号</b>：[44]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04825</p>
  <p><b>作者</b>：Wenye Lin,  Yangming Li,  Lemao Liu,  Shuming Shi,  Hai-tao Zheng</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：consuming techniques like dynamic programming, two structured prediction tasks demonstrate, structured prediction models aim, training process even faster, approach outperforms previous methods</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Structured prediction models aim at solving a type of problem where the
output is a complex structure, rather than a single variable. Performing
knowledge distillation for such models is not trivial due to their
exponentially large output space. In this work, we propose an approach that is
much simpler in its formulation and far more efficient for training than
existing approaches. Specifically, we transfer the knowledge from a teacher
model to its student model by locally matching their predictions on all
sub-structures, instead of the whole output space. In this manner, we avoid
adopting some time-consuming techniques like dynamic programming (DP) for
decoding output structures, which permits parallel computation and makes the
training process even faster in practice. Besides, it encourages the student
model to better mimic the internal behavior of the teacher model. Experiments
on two structured prediction tasks demonstrate that our approach outperforms
previous methods and halves the time cost for one training epoch.</p>
  </details>
</details>
<details>
  <summary>20. <b>标题：Machine Learning based Optimal Feedback Control for Microgrid  Stabilization</b></summary>
  <p><b>编号</b>：[48]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04815</p>
  <p><b>作者</b>：Tianwei Xia,  Kai Sun,  Wei Kang</p>
  <p><b>备注</b>：Accepted by 2022 IEEE PES General Meeting in Denver, CO</p>
  <p><b>关键词</b>：force method respectively addressing small, energy storage based feedback controller, based optimal feedback control scheme, optimal feedback control, optimal feedback control</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Microgrids have more operational flexibilities as well as uncertainties than
conventional power grids, especially when renewable energy resources are
utilized. An energy storage based feedback controller can compensate undesired
dynamics of a microgrid to improve its stability. However, the optimal feedback
control of a microgrid subject to a large disturbance needs to solve a
Hamilton-Jacobi-Bellman problem. This paper proposes a machine learning-based
optimal feedback control scheme. Its training dataset is generated from a
linear-quadratic regulator and a brute-force method respectively addressing
small and large disturbances. Then, a three-layer neural network is constructed
from the data for the purpose of optimal feedback control. A case study is
carried out for a microgrid model based on a modified Kundur two-area system to
test the real-time performance of the proposed control scheme.</p>
  </details>
</details>
<details>
  <summary>21. <b>标题：Benchmarking Graphormer on Large-Scale Molecular Modeling Datasets</b></summary>
  <p><b>编号</b>：[52]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04810</p>
  <p><b>作者</b>：Yu Shi,  Shuxin Zheng,  Guolin Ke,  Yifei Shen,  Jiacheng You,  Jiyan He,  Shengjie Luo,  Chang Liu,  Di He,  Tie-Yan Liu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：graphormer could achieve much less mae, pcqm4m quantum chemistry dataset used, 3d molecular graph modeling tasks, graphormer could attain better results, scale molecular modeling datasets</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This technical note describes the recent updates of Graphormer, including
architecture design modifications, and the adaption to 3D molecular dynamics
simulation. With these simple modifications, Graphormer could attain better
results on large-scale molecular modeling datasets than the vanilla one, and
the performance gain could be consistently obtained on 2D and 3D molecular
graph modeling tasks. In addition, we show that with a global receptive field
and an adaptive aggregation strategy, Graphormer is more powerful than classic
message-passing-based GNNs. Empirically, Graphormer could achieve much less MAE
than the originally reported results on the PCQM4M quantum chemistry dataset
used in KDD Cup 2021. In the meanwhile, it greatly outperforms the competitors
in the recent Open Catalyst Challenge, which is a competition track on NeurIPS
2021 workshop, and aims to model the catalyst-adsorbate reaction system with
advanced AI models. All codes could be found at
this https URL.</p>
  </details>
</details>
<details>
  <summary>22. <b>标题：Dimensionality Reduction and Prioritized Exploration for Policy Search</b></summary>
  <p><b>编号</b>：[59]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04791</p>
  <p><b>作者</b>：Marius Memmel,  Puze Liu,  Davide Tateo,  Jan Peters</p>
  <p><b>备注</b>：The 25th International Conference on Artificial Intelligence and Statistics (AISTATS)</p>
  <p><b>关键词</b>：action level could cause actuator damage, relative entropy policy search algorithm, effective parameters requires fewer samples, full covariance matrix updates, requires fewer samples</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Black-box policy optimization is a class of reinforcement learning algorithms
that explores and updates the policies at the parameter level. This class of
algorithms is widely applied in robotics with movement primitives or
non-differentiable policies. Furthermore, these approaches are particularly
relevant where exploration at the action level could cause actuator damage or
other safety issues. However, Black-box optimization does not scale well with
the increasing dimensionality of the policy, leading to high demand for
samples, which are expensive to obtain in real-world systems. In many practical
applications, policy parameters do not contribute equally to the return.
Identifying the most relevant parameters allows to narrow down the exploration
and speed up the learning. Furthermore, updating only the effective parameters
requires fewer samples, improving the scalability of the method. We present a
novel method to prioritize the exploration of effective parameters and cope
with full covariance matrix updates. Our algorithm learns faster than recent
approaches and requires fewer samples to achieve state-of-the-art results. To
select the effective parameters, we consider both the Pearson correlation
coefficient and the Mutual Information. We showcase the capabilities of our
approach on the Relative Entropy Policy Search algorithm in several simulated
environments, including robotics simulations. Code is available at
this https URL\_code/aistats2022/dr-creps}{this http URL\_code/aistats2022/dr-creps.</p>
  </details>
</details>
<details>
  <summary>23. <b>标题：Explainable Machine Learning for Predicting Homicide Clearance in the  United States</b></summary>
  <p><b>编号</b>：[67]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04768</p>
  <p><b>作者</b>：Gian Maria Campedelli</p>
  <p><b>备注</b>：41 pages, 18 figures</p>
  <p><b>关键词</b>：two theoretical perspectives emerged, consistently predicting investigation outcomes, developing ad hoc state, predicting cleared homicides country, predicting clearance outcomes state</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Purpose: To explore the potential of Explainable Machine Learning in the
prediction and detection of drivers of cleared homicides at the national- and
state-levels in the United States.
Methods: First, nine algorithmic approaches are compared to assess the best
performance in predicting cleared homicides country-wise, using data from the
Murder Accountability Project. The most accurate algorithm among all (XGBoost)
is then used for predicting clearance outcomes state-wise. Second, SHAP, a
framework for Explainable Artificial Intelligence, is employed to capture the
most important features in explaining clearance patterns both at the national
and state levels.
Results: At the national level, XGBoost demonstrates to achieve the best
performance overall. Substantial predictive variability is detected state-wise.
In terms of explainability, SHAP highlights the relevance of several features
in consistently predicting investigation outcomes. These include homicide
circumstances, weapons, victims' sex and race, as well as number of involved
offenders and victims.
Conclusions: Explainable Machine Learning demonstrates to be a helpful
framework for predicting homicide clearance. SHAP outcomes suggest a more
organic integration of the two theoretical perspectives emerged in the
literature. Furthermore, jurisdictional heterogeneity highlights the importance
of developing ad hoc state-level strategies to improve police performance in
clearing homicides.</p>
  </details>
</details>
<details>
  <summary>24. <b>标题：Machine Learning Methods in Solving the Boolean Satisfiability Problem</b></summary>
  <p><b>编号</b>：[72]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04755</p>
  <p><b>作者</b>：Wenxuan Guo,  Junchi Yan,  Hui-Ling Zhen,  Xijun Li,  Mingxuan Yuan,  Yaohui Jin</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：promising yet challenging research topic, expressive machine learning methods provide, suggest possible future directions, solve large industrial instances, machine learning methods</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper reviews the recent literature on solving the Boolean
satisfiability problem (SAT), an archetypal NP-complete problem, with the help
of machine learning techniques. Despite the great success of modern SAT solvers
to solve large industrial instances, the design of handcrafted heuristics is
time-consuming and empirical. Under the circumstances, the flexible and
expressive machine learning methods provide a proper alternative to solve this
long-standing problem. We examine the evolving ML-SAT solvers from naive
classifiers with handcrafted features to the emerging end-to-end SAT solvers
such as NeuroSAT, as well as recent progress on combinations of existing CDCL
and local search solvers with machine learning methods. Overall, solving SAT
with machine learning is a promising yet challenging research topic. We
conclude the limitations of current works and suggest possible future
directions.</p>
  </details>
</details>
<details>
  <summary>25. <b>标题：Using Statistical Models to Detect Occupancy in Buildings through  Monitoring VOC, CO$_2$, and other Environmental Factors</b></summary>
  <p><b>编号</b>：[75]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04750</p>
  <p><b>作者</b>：Mahsa Pahlavikhah Varnosfaderani,  Arsalan Heydarian,  Farrokh Jazizadeh</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：based techniques provide highly accurate information, developing appropriate global occupancy detection models, 000 sqft open office space, using different statistical models, widely adopted worldwide</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Dynamic models of occupancy patterns have shown to be effective in optimizing
building-systems operations. Previous research has relied on CO$_2$ sensors and
vision-based techniques to determine occupancy patterns. Vision-based
techniques provide highly accurate information; however, they are very
intrusive. Therefore, motion or CO$_2$ sensors are more widely adopted
worldwide. Volatile Organic Compounds (VOCs) are another pollutant originating
from the occupants. However, a limited number of studies have evaluated the
impact of occupants on the VOC level. In this paper, continuous measurements of
CO$_2$, VOC, light, temperature, and humidity were recorded in a 17,000 sqft
open office space for around four months. Using different statistical models
(e.g., SVM, K-Nearest Neighbors, and Random Forest) we evaluated which
combination of environmental factors provides more accurate insights on
occupant presence. Our preliminary results indicate that VOC is a good
indicator of occupancy detection in some cases. It is also concluded that
proper feature selection and developing appropriate global occupancy detection
models can reduce the cost and energy of data collection without a significant
impact on accuracy.</p>
  </details>
</details>
<details>
  <summary>26. <b>标题：Bilateral Deep Reinforcement Learning Approach for Better-than-human Car  Following Model</b></summary>
  <p><b>编号</b>：[76]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04749</p>
  <p><b>作者</b>：Tianyu Shi,  Yifei Ai,  Omar ElSamadisy,  Baher Abdulhai</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：potentially smarter traffic control methods exploiting automation, vehicle behind exhibits better system stability, existing rl methods model car following, achieving performance levels comparable, bilateral control model</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In the coming years and decades, autonomous vehicles (AVs) will become
increasingly prevalent, offering new opportunities for safer and more
convenient travel and potentially smarter traffic control methods exploiting
automation and connectivity. Car following is a prime function in autonomous
driving. Car following based on reinforcement learning has received attention
in recent years with the goal of learning and achieving performance levels
comparable to humans. However, most existing RL methods model car following as
a unilateral problem, sensing only the vehicle ahead. Recent literature,
however, Wang and Horn [16] has shown that bilateral car following that
considers the vehicle ahead and the vehicle behind exhibits better system
stability. In this paper we hypothesize that this bilateral car following can
be learned using RL, while learning other goals such as efficiency
maximisation, jerk minimization, and safety rewards leading to a learned model
that outperforms human driving.
We propose and introduce a Deep Reinforcement Learning (DRL) framework for
car following control by integrating bilateral information into both state and
reward function based on the bilateral control model (BCM) for car following
control. Furthermore, we use a decentralized multi-agent reinforcement learning
framework to generate the corresponding control action for each agent. Our
simulation results demonstrate that our learned policy is better than the human
driving policy in terms of (a) inter-vehicle headways, (b) average speed, (c)
jerk, (d) Time to Collision (TTC) and (e) string stability.</p>
  </details>
</details>
<details>
  <summary>27. <b>标题：SkinningNet: Two-Stream Graph Convolutional Neural Network for Skinning  Prediction of Synthetic Characters</b></summary>
  <p><b>编号</b>：[79]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04746</p>
  <p><b>作者</b>：Albert Mosella-Montoro,  Javier Ruiz-Hidalgo</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：stream graph neural network architecture, whereas previous methods pre, skinningnet outperforming current state, aggregator graph convolution, work presents skinningnet</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This work presents SkinningNet, an end-to-end Two-Stream Graph Neural Network
architecture that computes skinning weights from an input mesh and its
associated skeleton, without making any assumptions on shape class and
structure of the provided mesh. Whereas previous methods pre-compute
handcrafted features that relate the mesh and the skeleton or assume a fixed
topology of the skeleton, the proposed method extracts this information in an
end-to-end learnable fashion by jointly learning the best relationship between
mesh vertices and skeleton joints. The proposed method exploits the benefits of
the novel Multi-Aggregator Graph Convolution that combines the results of
different aggregators during the summarizing step of the Message-Passing
scheme, helping the operation to generalize for unseen topologies. Experimental
results demonstrate the effectiveness of the contributions of our novel
architecture, with SkinningNet outperforming current state-of-the-art
alternatives.</p>
  </details>
</details>
<details>
  <summary>28. <b>标题：Regularized Deep Signed Distance Fields for Reactive Motion Generation</b></summary>
  <p><b>编号</b>：[83]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04739</p>
  <p><b>作者</b>：Puze Liu,  Kuo Zhang,  Davide Tateo,  Snehal Jauhri,  Jan Peters,  Georgia Chalvatzaki</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：different applications require different distance resolutions, propose regularized deep signed distance fields, measuring distance fields w, compute smooth distance fields, single neural implicit function</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Autonomous robots should operate in real-world dynamic environments and
collaborate with humans in tight spaces. A key component for allowing robots to
leave structured lab and manufacturing settings is their ability to evaluate
online and real-time collisions with the world around them. Distance-based
constraints are fundamental for enabling robots to plan their actions and act
safely, protecting both humans and their hardware. However, different
applications require different distance resolutions, leading to various
heuristic approaches for measuring distance fields w.r.t. obstacles, which are
computationally expensive and hinder their application in dynamic obstacle
avoidance use-cases. We propose Regularized Deep Signed Distance Fields
(ReDSDF), a single neural implicit function that can compute smooth distance
fields at any scale, with fine-grained resolution over high-dimensional
manifolds and articulated bodies like humans, thanks to our effective data
generation and a simple inductive bias during training. We demonstrate the
effectiveness of our approach in representative simulated tasks for whole-body
control (WBC) and safe Human-Robot Interaction (HRI) in shared workspaces.
Finally, we provide proof of concept of a real-world application in a HRI
handover task with a mobile manipulator robot.</p>
  </details>
</details>
<details>
  <summary>29. <b>标题：Parallel Training of GRU Networks with a Multi-Grid Solver for Long  Sequences</b></summary>
  <p><b>编号</b>：[84]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04738</p>
  <p><b>作者</b>：Gordon Euhyun Moon,  Eric C. Cyr</p>
  <p><b>备注</b>：Accepted at ICLR 2022</p>
  <p><b>关键词</b>：parallel gru algorithm achieves significant performance improvement, new parallel training scheme achieves, still inevitably performance limited, parallelizing gated recurrent unit, novel parallel training scheme</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Parallelizing Gated Recurrent Unit (GRU) networks is a challenging task, as
the training procedure of GRU is inherently sequential. Prior efforts to
parallelize GRU have largely focused on conventional parallelization strategies
such as data-parallel and model-parallel training algorithms. However, when the
given sequences are very long, existing approaches are still inevitably
performance limited in terms of training time. In this paper, we present a
novel parallel training scheme (called parallel-in-time) for GRU based on a
multigrid reduction in time (MGRIT) solver. MGRIT partitions a sequence into
multiple shorter sub-sequences and trains the sub-sequences on different
processors in parallel. The key to achieving speedup is a hierarchical
correction of the hidden state to accelerate end-to-end communication in both
the forward and backward propagation phases of gradient descent. Experimental
results on the HMDB51 dataset, where each video is an image sequence,
demonstrate that the new parallel training scheme achieves up to 6.5$\times$
speedup over a serial approach. As efficiency of our new parallelization
strategy is associated with the sequence length, our parallel GRU algorithm
achieves significant performance improvement as the sequence length increases.</p>
  </details>
</details>
<details>
  <summary>30. <b>标题：P2M: A Processing-in-Pixel-in-Memory Paradigm for Resource-Constrained  TinyML Applications</b></summary>
  <p><b>编号</b>：[85]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04737</p>
  <p><b>作者</b>：Gourav Datta,  Souvik Kundu,  Zihan Yin,  Ravi Teja Lakkireddy,  Peter A. Beerel,  Ajey Jacob,  Akhilesh R. Jaiswal</p>
  <p><b>备注</b>：13 pages, 7 figures</p>
  <p><b>关键词</b>：resolution input images still need, manufacturable cmos image sensor platforms, p2m reduces data transfer bandwidth, subsequent ai processing using analog, visual wake words dataset</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The demand to process vast amounts of data generated from state-of-the-art
high resolution cameras has motivated novel energy-efficient on-device AI
solutions. Visual data in such cameras are usually captured in the form of
analog voltages by a sensor pixel array, and then converted to the digital
domain for subsequent AI processing using analog-to-digital converters (ADC).
Recent research has tried to take advantage of massively parallel low-power
analog/digital computing in the form of near- and in-sensor processing, in
which the AI computation is performed partly in the periphery of the pixel
array and partly in a separate on-board CPU/accelerator. Unfortunately,
high-resolution input images still need to be streamed between the camera and
the AI processing unit, frame by frame, causing energy, bandwidth, and security
bottlenecks. To mitigate this problem, we propose a novel
Processing-in-Pixel-in-memory (P2M) paradigm, that customizes the pixel array
by adding support for analog multi-channel, multi-bit convolution and ReLU
(Rectified Linear Units). Our solution includes a holistic algorithm-circuit
co-design approach and the resulting P2M paradigm can be used as a drop-in
replacement for embedding memory-intensive first few layers of convolutional
neural network (CNN) models within foundry-manufacturable CMOS image sensor
platforms. Our experimental results indicate that P2M reduces data transfer
bandwidth from sensors and analog to digital conversions by ~21x, and the
energy-delay product (EDP) incurred in processing a MobileNetV2 model on a
TinyML use case for visual wake words dataset (VWW) by up to ~11x compared to
standard near-processing or in-sensor implementations, without any significant
drop in test accuracy.</p>
  </details>
</details>
<details>
  <summary>31. <b>标题：A Survey on Reinforcement Learning Methods in Character Animation</b></summary>
  <p><b>编号</b>：[86]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04735</p>
  <p><b>作者</b>：Ariel Kwiatkowski,  Eduardo Alvarado,  Vicky Kalogeiton,  C. Karen Liu,  Julien Pettré,  Michiel van de Panne,  Marie-Paule Cani</p>
  <p><b>备注</b>：27 pages, 6 figures, Eurographics STAR, Computer Graphics Forum</p>
  <p><b>关键词</b>：modern deep reinforcement learning methods, repeatedly take actions based, yet reactive characters, training drl systems, receive appropriate rewards</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Reinforcement Learning is an area of Machine Learning focused on how agents
can be trained to make sequential decisions, and achieve a particular goal
within an arbitrary environment. While learning, they repeatedly take actions
based on their observation of the environment, and receive appropriate rewards
which define the objective. This experience is then used to progressively
improve the policy controlling the agent's behavior, typically represented by a
neural network. This trained module can then be reused for similar problems,
which makes this approach promising for the animation of autonomous, yet
reactive characters in simulators, video games or virtual reality environments.
This paper surveys the modern Deep Reinforcement Learning methods and discusses
their possible applications in Character Animation, from skeletal control of a
single, physically-based character to navigation controllers for individual
agents and virtual crowds. It also describes the practical side of training DRL
systems, comparing the different frameworks available to build such agents.</p>
  </details>
</details>
<details>
  <summary>32. <b>标题：Anomaly Detection for Unmanned Aerial Vehicle Sensor Data Using a  Stacked Recurrent Autoencoder Method with Dynamic Thresholding</b></summary>
  <p><b>编号</b>：[87]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04734</p>
  <p><b>作者</b>：Victoria Bell1,  Divish Rengasamy,  Benjamin Rothwell,  Grazziela P Figueredo</p>
  <p><b>备注</b>：16 pages</p>
  <p><b>关键词</b>：weighted loss functions showed promising improvements, deep learning autoencoder based method, accurately identify anomalous behaviour, standard static thresholding method, novel dynamic thresholding algorithm</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>With substantial recent developments in aviation technologies, Unmanned
Aerial Vehicles (UAVs) are becoming increasingly integrated in commercial and
military operations internationally. Research into the applications of aircraft
data is essential in improving safety, reducing operational costs, and
developing the next frontier of aerial technology. Having an outlier detection
system that can accurately identify anomalous behaviour in aircraft is crucial
for these reasons. This paper proposes a system incorporating a Long Short-Term
Memory (LSTM) Deep Learning Autoencoder based method with a novel dynamic
thresholding algorithm and weighted loss function for anomaly detection of a
UAV dataset, in order to contribute to the ongoing efforts that leverage
innovations in machine learning and data analysis within the aviation industry.
The dynamic thresholding and weighted loss functions showed promising
improvements to the standard static thresholding method, both in
accuracy-related performance metrics and in speed of true fault detection.</p>
  </details>
</details>
<details>
  <summary>33. <b>标题：Pretrained Domain-Specific Language Model for General Information  Retrieval Tasks in the AEC Domain</b></summary>
  <p><b>编号</b>：[88]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04729</p>
  <p><b>作者</b>：Zhe Zheng,  Xin-Zheng Lu,  Ke-Yin Chen,  Yu-Cheng Zhou,  Jia-Rui Lin</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：based models dramatically outperform traditional methods, including traditional wording embedding models, several widely used dl models, traditional word embedding models, unstructured textual data based</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As an essential task for the architecture, engineering, and construction
(AEC) industry, information retrieval (IR) from unstructured textual data based
on natural language processing (NLP) is gaining increasing attention. Although
various deep learning (DL) models for IR tasks have been investigated in the
AEC domain, it is still unclear how domain corpora and domain-specific
pretrained DL models can improve performance in various IR tasks. To this end,
this work systematically explores the impacts of domain corpora and various
transfer learning techniques on the performance of DL models for IR tasks and
proposes a pretrained domain-specific language model for the AEC domain. First,
both in-domain and close-domain corpora are developed. Then, two types of
pretrained models, including traditional wording embedding models and
BERT-based models, are pretrained based on various domain corpora and transfer
learning strategies. Finally, several widely used DL models for IR tasks are
further trained and tested based on various configurations and pretrained
models. The result shows that domain corpora have opposite effects on
traditional word embedding models for text classification and named entity
recognition tasks but can further improve the performance of BERT-based models
in all tasks. Meanwhile, BERT-based models dramatically outperform traditional
methods in all IR tasks, with maximum improvements of 5.4% and 10.1% in the F1
score, respectively. This research contributes to the body of knowledge in two
ways: 1) demonstrating the advantages of domain corpora and pretrained DL
models and 2) opening the first domain-specific dataset and pretrained language
model for the AEC domain, to the best of our knowledge. Thus, this work sheds
light on the adoption and application of pretrained models in the AEC domain.</p>
  </details>
</details>
<details>
  <summary>34. <b>标题：On a linear fused Gromov-Wasserstein distance for graph structured data</b></summary>
  <p><b>编号</b>：[92]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04711</p>
  <p><b>作者</b>：Dai Hai Nguyen,  Koji Tsuda</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：embedding graph structured data, scale data sets, particularly fused gromov, discussing theoretical properties, demonstrate experimental results</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present a framework for embedding graph structured data into a vector
space, taking into account node features and topology of a graph into the
optimal transport (OT) problem. Then we propose a novel distance between two
graphs, named linearFGW, defined as the Euclidean distance between their
embeddings. The advantages of the proposed distance are twofold: 1) it can take
into account node feature and structure of graphs for measuring the similarity
between graphs in a kernel-based framework, 2) it can be much faster for
computing kernel matrix than pairwise OT-based distances, particularly fused
Gromov-Wasserstein, making it possible to deal with large-scale data sets.
After discussing theoretical properties of linearFGW, we demonstrate
experimental results on classification and clustering tasks, showing the
effectiveness of the proposed linearFGW.</p>
  </details>
</details>
<details>
  <summary>35. <b>标题：Language Model-driven Negative Sampling</b></summary>
  <p><b>编号</b>：[96]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04703</p>
  <p><b>作者</b>：Mirza Mohtashim Alam,  Md Rashad Al Hasan Rony,  Semab Ali,  Jens Lehmann,  Sahar Vahdati</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：proposed approach across several benchmark datasets, e ., link prediction, also require negative samples, generating negative sampling considering, generating negative sampling affects</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Knowledge Graph Embeddings (KGEs) encode the entities and relations of a
knowledge graph (KG) into a vector space with a purpose of representation
learning and reasoning for an ultimate downstream task (i.e., link prediction,
question answering). Since KGEs follow closed-world assumption and assume all
the present facts in KGs to be positive (correct), they also require negative
samples as a counterpart for learning process for truthfulness test of existing
triples. Therefore, there are several approaches for creating negative samples
from the existing positive ones through a randomized distribution. This choice
of generating negative sampling affects the performance of the embedding models
as well as their generalization. In this paper, we propose an approach for
generating negative sampling considering the existing rich textual knowledge in
KGs. %The proposed approach is leveraged to cluster other relevant
representations of the entities inside a KG. Particularly, a pre-trained
Language Model (LM) is utilized to obtain the contextual representation of
symbolic entities. Our approach is then capable of generating more meaningful
negative samples in comparison to other state of the art methods. Our
comprehensive evaluations demonstrate the effectiveness of the proposed
approach across several benchmark datasets for like prediction task. In
addition, we show cased our the functionality of our approach on a clustering
task where other methods fall short.</p>
  </details>
</details>
<details>
  <summary>36. <b>标题：Score-Based Generative Models for Molecule Generation</b></summary>
  <p><b>编号</b>：[100]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04698</p>
  <p><b>作者</b>：Dwaraknath Gnaneshwar,  Bharath Ramsundar,  Dhairya Gandhi,  Rachel Kurchin,  Venkatasubramanian Viswanathan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：made exploring design spaces easier, popular generative models like gans, based generative models could open, using annealed langevin dynamics, log probability density using</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent advances in generative models have made exploring design spaces easier
for de novo molecule generation. However, popular generative models like GANs
and normalizing flows face challenges such as training instabilities due to
adversarial training and architectural constraints, respectively. Score-based
generative models sidestep these challenges by modelling the gradient of the
log probability density using a score function approximation, as opposed to
modelling the density function directly, and sampling from it using annealed
Langevin Dynamics. We believe that score-based generative models could open up
new opportunities in molecule generation due to their architectural
flexibility, such as replacing the score function with an SE(3) equivariant
model. In this work, we lay the foundations by testing the efficacy of
score-based models for molecule generation. We train a Transformer-based score
function on Self-Referencing Embedded Strings (SELFIES) representations of 1.5
million samples from the ZINC dataset and use the Moses benchmarking framework
to evaluate the generated samples on a suite of metrics.</p>
  </details>
</details>
<details>
  <summary>37. <b>标题：Robust Federated Learning Against Adversarial Attacks for Speech Emotion  Recognition</b></summary>
  <p><b>编号</b>：[101]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04696</p>
  <p><b>作者</b>：Yi Chang,  Sofiane Laridi,  Zhao Ren,  Gregory Palmer,  Björn W. Schuller,  Marco Fisichella</p>
  <p><b>备注</b>：11 pages, 6 figures, 3 tables</p>
  <p><b>关键词</b>：deep neural networks wrongly predicting, novel federated adversarial learning framework, deep neural networks, deep neural networks, popular research topic</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Due to the development of machine learning and speech processing, speech
emotion recognition has been a popular research topic in recent years. However,
the speech data cannot be protected when it is uploaded and processed on
servers in the internet-of-things applications of speech emotion recognition.
Furthermore, deep neural networks have proven to be vulnerable to
human-indistinguishable adversarial perturbations. The adversarial attacks
generated from the perturbations may result in deep neural networks wrongly
predicting the emotional states. We propose a novel federated adversarial
learning framework for protecting both data and deep neural networks. The
proposed framework consists of i) federated learning for data privacy, and ii)
adversarial training at the training stage and randomisation at the testing
stage for model robustness. The experiments show that our proposed framework
can effectively protect the speech data locally and improve the model
robustness against a series of adversarial attacks.</p>
  </details>
</details>
<details>
  <summary>38. <b>标题：Align-Deform-Subtract: An Interventional Framework for Explaining Object  Differences</b></summary>
  <p><b>编号</b>：[102]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04694</p>
  <p><b>作者</b>：Cian Eastwood,  Li Nanbo,  Christopher K. I. Williams</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：given two object images, synthetic data illustrate, leveraging semantic alignments, explaining object differences, underlying object properties</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Given two object images, how can we explain their differences in terms of the
underlying object properties? To address this question, we propose
Align-Deform-Subtract (ADS) -- an interventional framework for explaining
object differences. By leveraging semantic alignments in image-space as
counterfactual interventions on the underlying object properties, ADS
iteratively quantifies and removes differences in object properties. The result
is a set of "disentangled" error measures which explain object differences in
terms of their underlying properties. Experiments on real and synthetic data
illustrate the efficacy of the framework.</p>
  </details>
</details>
<details>
  <summary>39. <b>标题：FragmGAN: Generative Adversarial Nets for Fragmentary Data Imputation  and Prediction</b></summary>
  <p><b>编号</b>：[103]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04692</p>
  <p><b>作者</b>：Fang Fang,  Shenliao Bao</p>
  <p><b>备注</b>：17 pages</p>
  <p><b>关键词</b>：linkage mechanism shows significant advantages, generative model based imputation methods, generative adversarial nets, flexible framework based, modern scientific research</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Modern scientific research and applications very often encounter "fragmentary
data" which brings big challenges to imputation and prediction. By leveraging
the structure of response patterns, we propose a unified and flexible framework
based on Generative Adversarial Nets (GAN) to deal with fragmentary data
imputation and label prediction at the same time. Unlike most of the other
generative model based imputation methods that either have no theoretical
guarantee or only consider Missing Completed At Random (MCAR), the proposed
FragmGAN has theoretical guarantees for imputation with data Missing At Random
(MAR) while no hint mechanism is needed. FragmGAN trains a predictor with the
generator and discriminator simultaneously. This linkage mechanism shows
significant advantages for predictive performances in extensive experiments.</p>
  </details>
</details>
<details>
  <summary>40. <b>标题：The Cross-evaluation of Machine Learning-based Network Intrusion  Detection Systems</b></summary>
  <p><b>编号</b>：[104]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04686</p>
  <p><b>作者</b>：Giovanni Apruzzese,  Luca Pajola,  Mauro Conti</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：labels demand costly expert knowledge, enhancing network intrusion detection systems, supervised machine learning, still unknown qualities, situation improved recently</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Enhancing Network Intrusion Detection Systems (NIDS) with supervised Machine
Learning (ML) is tough. ML-NIDS must be trained and evaluated, operations
requiring data where benign and malicious samples are clearly labelled. Such
labels demand costly expert knowledge, resulting in a lack of real deployments,
as well as on papers always relying on the same outdated data. The situation
improved recently, as some efforts disclosed their labelled datasets. However,
most past works used such datasets just as a 'yet another' testbed, overlooking
the added potential provided by such availability.
In contrast, we promote using such existing labelled data to cross-evaluate
ML-NIDS. Such approach received only limited attention and, due to its
complexity, requires a dedicated treatment. We hence propose the first
cross-evaluation model. Our model highlights the broader range of realistic
use-cases that can be assessed via cross-evaluations, allowing the discovery of
still unknown qualities of state-of-the-art ML-NIDS. For instance, their
detection surface can be extended--at no additional labelling cost. However,
conducting such cross-evaluations is challenging. Hence, we propose the first
framework, XeNIDS, for reliable cross-evaluations based on Network Flows. By
using XeNIDS on six well-known datasets, we demonstrate the concealed
potential, but also the risks, of cross-evaluations of ML-NIDS.</p>
  </details>
</details>
<details>
  <summary>41. <b>标题：HAIDA: Biometric technological therapy tools for neurorehabilitation of  Cognitive Impairment</b></summary>
  <p><b>编号</b>：[116]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04645</p>
  <p><b>作者</b>：Elsa Fernandez,  Jordi Sole-Casals,  Pilar M. Calvo,  Marcos Faundez-Zanuy,  Karmele Lopez-de-Ipina</p>
  <p><b>备注</b>：2 pages</p>
  <p><b>关键词</b>：invasive biometric analysis, important diseases suffered, widely used non, musical therapy oriented, platform support system</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Dementia, and specially Alzheimer s disease (AD) and Mild Cognitive
Impairment (MCI) are one of the most important diseases suffered by elderly
population. Music therapy is one of the most widely used non-pharmacological
treatment in the field of cognitive impairments, given that music influences
their mood, behavior, the decrease of anxiety, as well as facilitating
reminiscence, emotional expressions and movement. In this work we present
HAIDA, a multi-platform support system for Musical Therapy oriented to
cognitive impairment, which includes not only therapy tools but also
non-invasive biometric analysis, speech, activity and hand activity. At this
moment the system is on use and recording the first sets of data.</p>
  </details>
</details>
<details>
  <summary>42. <b>标题：Speaker Identification Experiments Under Gender De-Identification</b></summary>
  <p><b>编号</b>：[120]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04638</p>
  <p><b>作者</b>：Marcos Faundez-Zanuy,  Enric Sesa-Nogueras,  Stefano Marinozzi</p>
  <p><b>备注</b>：5 pages</p>
  <p><b>关键词</b>：cost action ic1206, test four algorithms, speech gender recognizer, speech tone modification, speech recognizer</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The present work is based on the COST Action IC1206 for De-identification in
multimedia content. It was performed to test four algorithms of voice
modifications on a speech gender recognizer to find the degree of modification
of pitch when the speech recognizer have the probability of success equal to
the probability of failure. The purpose of this analysis is to assess the
intensity of the speech tone modification, the quality, the reversibility and
not-reversibility of the changes made. Keywords DeIdentification; Speech
Algorithms</p>
  </details>
</details>
<details>
  <summary>43. <b>标题：Representation, learning, and planning algorithms for geometric task and  motion planning</b></summary>
  <p><b>编号</b>：[129]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04605</p>
  <p><b>作者</b>：Beomjoon Kim,  Luke Shimanuki,  Leslie Pack Kaelbling,  Tomás Lozano-Pérez</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：gtamp problems involve hybrid search spaces, target regions among movable obstacles, promising state action pairs, expensive action feasibility checks, extends basic heuristic search</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present a framework for learning to guide geometric task and motion
planning (GTAMP). GTAMP is a subclass of task and motion planning in which the
goal is to move multiple objects to target regions among movable obstacles. A
standard graph search algorithm is not directly applicable, because GTAMP
problems involve hybrid search spaces and expensive action feasibility checks.
To handle this, we introduce a novel planner that extends basic heuristic
search with random sampling and a heuristic function that prioritizes
feasibility checking on promising state action pairs. The main drawback of such
pure planners is that they lack the ability to learn from planning experience
to improve their efficiency. We propose two learning algorithms to address
this. The first is an algorithm for learning a rank function that guides the
discrete task level search, and the second is an algorithm for learning a
sampler that guides the continuous motionlevel search. We propose design
principles for designing data efficient algorithms for learning from planning
experience and representations for effective generalization. We evaluate our
framework in challenging GTAMP problems, and show that we can improve both
planning and data efficiency</p>
  </details>
</details>
<details>
  <summary>44. <b>标题：Multi-Objective reward generalization: Improving performance of Deep  Reinforcement Learning for selected applications in stock and cryptocurrency  trading</b></summary>
  <p><b>编号</b>：[136]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04579</p>
  <p><b>作者</b>：Federico Cornalba,  Constantin Disselkamp,  Davide Scassola,  Christopher Helf</p>
  <p><b>备注</b>：9 pages, 12 figures</p>
  <p><b>关键词</b>：provide preliminary statistical evidence showing, generalized setting à la fontaine, objective algorithm generalizes well, open source format, deep reinforcement learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We investigate the potential of Multi-Objective, Deep Reinforcement Learning
for stock and cryptocurrency trading. More specifically, we build on the
generalized setting à la Fontaine and Friedman arXiv:1809.06364 (where the
reward weighting mechanism is not specified a priori, but embedded in the
learning process) by complementing it with computational speed-ups, and adding
the cumulative reward's discount factor to the learning process. Firstly, we
verify that the resulting Multi-Objective algorithm generalizes well, and we
provide preliminary statistical evidence showing that its prediction is more
stable than the corresponding Single-Objective strategy's. Secondly, we show
that the Multi-Objective algorithm has a clear edge over the corresponding
Single-Objective strategy when the reward mechanism is sparse (i.e., when
non-null feedback is infrequent over time). Finally, we discuss the
generalization properties of the discount factor. The entirety of our code is
provided in open source format.</p>
  </details>
</details>
<details>
  <summary>45. <b>标题：Reinforced Meta Active Learning</b></summary>
  <p><b>编号</b>：[138]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04573</p>
  <p><b>作者</b>：Michael Katz,  Eli Kravchik</p>
  <p><b>备注</b>：14 pages, 5 figures</p>
  <p><b>关键词</b>：learn optimal selection strategies directly, based meta active learning method, combines episodic policy search, numerous active learning strategies, informativeness measure directly</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In stream-based active learning, the learning procedure typically has access
to a stream of unlabeled data instances and must decide for each instance
whether to label it and use it for training or to discard it. There are
numerous active learning strategies which try to minimize the number of labeled
samples required for training in this setting by identifying and retaining the
most informative data samples. Most of these schemes are rule-based and rely on
the notion of uncertainty, which captures how small the distance of a data
sample is from the classifier's decision boundary. Recently, there have been
some attempts to learn optimal selection strategies directly from the data, but
many of them are still lacking generality for several reasons: 1) They focus on
specific classification setups, 2) They rely on rule-based metrics, 3) They
require offline pre-training of the active learner on related tasks. In this
work we address the above limitations and present an online stream-based meta
active learning method which learns on the fly an informativeness measure
directly from the data, and is applicable to a general class of classification
problems without any need for pretraining of the active learner on related
tasks. The method is based on reinforcement learning and combines episodic
policy search and a contextual bandits approach which are used to train the
active learner in conjunction with training of the model. We demonstrate on
several real datasets that this method learns to select training samples more
efficiently than existing state-of-the-art methods.</p>
  </details>
</details>
<details>
  <summary>46. <b>标题：A Neuro-vector-symbolic Architecture for Solving Raven's Progressive  Matrices</b></summary>
  <p><b>编号</b>：[139]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04571</p>
  <p><b>作者</b>：Michael Hersche,  Mustafa Zeqiri,  Luca Benini,  Abu Sebastian,  Abbas Rahimi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：width holographic vectorized representations, called binding problem ),, neither deep neural networks, magnitude faster execution, exhaustive rule searches</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Neither deep neural networks nor symbolic AI alone have approached the kind
of intelligence expressed in humans. This is mainly because neural networks are
not able to decompose distinct objects from their joint representation (the
so-called binding problem), while symbolic AI suffers from exhaustive rule
searches, among other problems. These two problems are still pronounced in
neuro-symbolic AI which aims to combine the best of the two paradigms. Here, we
show that the two problems can be addressed with our proposed
neuro-vector-symbolic architecture (NVSA) by exploiting its powerful operators
on fixed-width holographic vectorized representations that serve as a common
language between neural networks and symbolic logical reasoning. The efficacy
of NVSA is demonstrated by solving the Raven's progressive matrices. NVSA
achieves a new record of 97.7% average accuracy in RAVEN, and 98.8% in I-RAVEN
datasets, with two orders of magnitude faster execution than the symbolic
logical reasoning on CPUs.</p>
  </details>
</details>
<details>
  <summary>47. <b>标题：All You Need is LUV: Unsupervised Collection of Labeled Images using  Invisible UV Fluorescent Indicators</b></summary>
  <p><b>编号</b>：[141]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04566</p>
  <p><b>作者</b>：Brijen Thananjeyan,  Justin Kerr,  Huang Huang,  Joseph E. Gonzalez,  Ken Goldberg</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：collecting around 200 semantic segmentation labels, real manipulation environments without human labeling, surgical needle pose estimation task, scale semantic image annotation, keypoints via color segmentation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large-scale semantic image annotation is a significant challenge for
learning-based perception systems in robotics. Current approaches often rely on
human labelers, which can be expensive, or simulation data, which can visually
or physically differ from real data. This paper proposes Labels from
UltraViolet (LUV), a novel framework that enables rapid, labeled data
collection in real manipulation environments without human labeling. LUV uses
transparent, ultraviolet-fluorescent paint with programmable ultraviolet LEDs
to collect paired images of a scene in standard lighting and UV lighting to
autonomously extract segmentation masks and keypoints via color segmentation.
We apply LUV to a suite of diverse robot perception tasks to evaluate its
labeling quality, flexibility, and data collection rate. Results suggest that
LUV is 180-2500 times faster than a human labeler across the tasks. We show
that LUV provides labels consistent with human annotations on unpainted test
images. The networks trained on these labels are used to smooth and fold
crumpled towels with 83% success rate and achieve 1.7mm position error with
respect to human labels on a surgical needle pose estimation task. The low cost
of LUV makes it ideal as a lightweight replacement for human labeling systems,
with the one-time setup costs at $300 equivalent to the cost of collecting
around 200 semantic segmentation labels on Amazon Mechanical Turk. Code,
datasets, visualizations, and supplementary material can be found at
this https URL</p>
  </details>
</details>
<details>
  <summary>48. <b>标题：MLNav: Learning to Safely Navigate on Martian Terrains</b></summary>
  <p><b>编号</b>：[144]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04563</p>
  <p><b>作者</b>：Shreyansh Daftry,  Neil Abcouwer,  Tyler Del Sesto,  Siddarth Venkatraman,  Jialin Song,  Lucas Igel,  Amos Byon,  Ugo Rosolia,  Yisong Yue,  Masahiro Ono</p>
  <p><b>备注</b>：IEEE Robotics and Automation Letters (RA-L) and ICRA 2022</p>
  <p><b>关键词</b>：real martian terrain data collected, successfully navigate highly challenging terrains, navigating real martian terrains, fully respecting safety constraints, mlnav makes judicious use</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present MLNav, a learning-enhanced path planning framework for
safety-critical and resource-limited systems operating in complex environments,
such as rovers navigating on Mars. MLNav makes judicious use of machine
learning to enhance the efficiency of path planning while fully respecting
safety constraints. In particular, the dominant computational cost in such
safety-critical settings is running a model-based safety checker on the
proposed paths. Our learned search heuristic can simultaneously predict the
feasibility for all path options in a single run, and the model-based safety
checker is only invoked on the top-scoring paths. We validate in high-fidelity
simulations using both real Martian terrain data collected by the Perseverance
rover, as well as a suite of challenging synthetic terrains. Our experiments
show that: (i) compared to the baseline ENav path planner on board the
Perserverance rover, MLNav can provide a significant improvement in multiple
key metrics, such as a 10x reduction in collision checks when navigating real
Martian terrains, despite being trained with synthetic terrains; and (ii) MLNav
can successfully navigate highly challenging terrains where the baseline ENav
fails to find a feasible path before timing out.</p>
  </details>
</details>
<details>
  <summary>49. <b>标题：MetaCon: Unified Predictive Segments System with Trillion Concept  Meta-Learning</b></summary>
  <p><b>编号</b>：[152]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04540</p>
  <p><b>作者</b>：Keqian Li,  Yifan Hu,  Logan Palanisamy,  Lisa Jones,  Akshay Gupta,  Jason Grigsby,  Ili Selinger,  Matt Gillingham,  Fei Tan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：leverages principled meta learning approach, public structured learning tasks demonstrate, trillion concepts meta learning, long tail predictive tasks, efficient first order meta</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Accurate understanding of users in terms of predicative segments play an
essential role in the day to day operation of modern internet enterprises.
Nevertheless, there are significant challenges that limit the quality of data,
especially on long tail predictive tasks. In this work, we present MetaCon, our
unified predicative segments system with scalable, trillion concepts meta
learning that addresses these challenges. It builds on top of a flat concept
representation that summarizes entities' heterogeneous digital footprint,
jointly considers the entire spectrum of predicative tasks as a single learning
task, and leverages principled meta learning approach with efficient first
order meta-optimization procedure under a provable performance guarantee in
order to solve the learning task. Experiments on both proprietary production
datasets and public structured learning tasks demonstrate that MetaCon can lead
to substantial improvements over state of the art recommendation and ranking
approaches.</p>
  </details>
</details>
<details>
  <summary>50. <b>标题：Metric Entropy Duality and the Sample Complexity of Outcome  Indistinguishability</b></summary>
  <p><b>编号</b>：[155]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04536</p>
  <p><b>作者</b>：Lunjia Hu,  Charlotte Peale,  Omer Reingold</p>
  <p><b>备注</b>：37 pages. To appear in ALT 2022</p>
  <p><b>关键词</b>：standing metric entropy duality conjecture, dual minkowski norm defined, dual minkowski norm defined, machine learning recently introduced, strong sample complexity separation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We give the first sample complexity characterizations for outcome
indistinguishability, a theoretical framework of machine learning recently
introduced by Dwork, Kim, Reingold, Rothblum, and Yona (STOC 2021). In outcome
indistinguishability, the goal of the learner is to output a predictor that
cannot be distinguished from the target predictor by a class $D$ of
distinguishers examining the outcomes generated according to the predictors'
predictions.
In the distribution-specific and realizable setting where the learner is
given the data distribution together with a predictor class $P$ containing the
target predictor, we show that the sample complexity of outcome
indistinguishability is characterized by the metric entropy of $P$ w.r.t. the
dual Minkowski norm defined by $D$, and equivalently by the metric entropy of
$D$ w.r.t. the dual Minkowski norm defined by $P$. This equivalence makes an
intriguing connection to the long-standing metric entropy duality conjecture in
convex geometry. Our sample complexity characterization implies a variant of
metric entropy duality, which we show is nearly tight. In the distribution-free
setting, we focus on the case considered by Dwork et al. where $P$ contains all
possible predictors, hence the sample complexity only depends on $D$. In this
setting, we show that the sample complexity of outcome indistinguishability is
characterized by the fat-shattering dimension of $D$.
We also show a strong sample complexity separation between realizable and
agnostic outcome indistinguishability in both the distribution-free and the
distribution-specific settings. This is in contrast to distribution-free (resp.
distribution-specific) PAC learning where the sample complexity in both the
realizable and the agnostic settings can be characterized by the VC dimension
(resp. metric entropy).</p>
  </details>
</details>
<details>
  <summary>51. <b>标题：Multi-Agent Active Search using Detection and Location Uncertainty</b></summary>
  <p><b>编号</b>：[158]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04524</p>
  <p><b>作者</b>：Arundhati Banerjee,  Ramina Ghods,  Jeff Schneider</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：decision making algorithms outperform competing baselines, search space using decision making algorithms, active search algorithms must contend, sparse signal processing literature, enable efficient active search</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Active search refers to the task of autonomous robots (agents) detecting
objects of interest (targets) in a search space using decision making
algorithms that adapt to the history of their observations. It has important
applications in search and rescue missions, wildlife patrolling and environment
monitoring. Active search algorithms must contend with two types of
uncertainty: detection uncertainty and location uncertainty. Prior work has
typically focused on one of these while ignoring or engineering away the other.
The more common approach in robotics is to focus on location uncertainty and
remove detection uncertainty by thresholding the detection probability to zero
or one. On the other hand, it is common in the sparse signal processing
literature to assume the target location is accurate and focus on the
uncertainty of its detection. In this work, we propose an inference method to
jointly handle both target detection and location uncertainty. We then build a
decision making algorithm on this inference method that uses Thompson sampling
to enable efficient active search in both the single agent and multi-agent
settings. We perform experiments in simulation over varying number of agents
and targets to show that our inference and decision making algorithms
outperform competing baselines that only account for either target detection or
location uncertainty.</p>
  </details>
</details>
<details>
  <summary>52. <b>标题：Structure and Distribution Metric for Quantifying the Quality of  Uncertainty: Assessing Gaussian Processes, Deep Neural Nets, and Deep Neural  Operators for Regression</b></summary>
  <p><b>编号</b>：[162]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04515</p>
  <p><b>作者</b>：Ethan Pickering,  Themistoklis P. Sapsis</p>
  <p><b>备注</b>：9 pages, 6 figures</p>
  <p><b>关键词</b>：gps ), ensemble deep neural nets, propose two bounded comparison metrics, ensemble deep neural operators, compelling ground truth assessment, provide encouraging metric values</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose two bounded comparison metrics that may be implemented to
arbitrary dimensions in regression tasks. One quantifies the structure of
uncertainty and the other quantifies the distribution of uncertainty. The
structure metric assesses the similarity in shape and location of uncertainty
with the true error, while the distribution metric quantifies the supported
magnitudes between the two. We apply these metrics to Gaussian Processes (GPs),
Ensemble Deep Neural Nets (DNNs), and Ensemble Deep Neural Operators (DNOs) on
high-dimensional and nonlinear test cases. We find that comparing a model's
uncertainty estimates with the model's squared error provides a compelling
ground truth assessment. We also observe that both DNNs and DNOs, especially
when compared to GPs, provide encouraging metric values in high dimensions with
either sparse or plentiful data.</p>
  </details>
</details>
<details>
  <summary>53. <b>标题：Revealing the Excitation Causality between Climate and Political  Violence via a Neural Forward-Intensity Poisson Process</b></summary>
  <p><b>编号</b>：[163]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04511</p>
  <p><b>作者</b>：Schyler C. Sun,  Bailu Jin,  Zhuangkun Wei,  Weisi Guo</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：g ., drought forces agricultural producers, results span 20 recent years, current quantitative causal models rely, know conflict drivers often excite, climate drivers persistently generate conflict</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The causal mechanism between climate and political violence is fraught with
complex mechanisms. Current quantitative causal models rely on one or more
assumptions: (1) the climate drivers persistently generate conflict, (2) the
causal mechanisms have a linear relationship with the conflict generation
parameter, and/or (3) there is sufficient data to inform the prior
distribution. Yet, we know conflict drivers often excite a social
transformation process which leads to violence (e.g., drought forces
agricultural producers to join urban militia), but further climate effects do
not necessarily contribute to further violence. Therefore, not only is this
bifurcation relationship highly non-linear, there is also often a lack of data
to support prior assumptions for high resolution modeling. Here, we aim to
overcome the aforementioned causal modeling challenges by proposing a neural
forward-intensity Poisson process (NFIPP) model. The NFIPP is designed to
capture the potential non-linear causal mechanism in climate induced political
violence, whilst being robust to sparse and timing-uncertain data. Our results
span 20 recent years and reveal an excitation-based causal link between extreme
climate events and political violence across diverse countries. Our
climate-induced conflict model results are cross-validated against qualitative
climate vulnerability indices. Furthermore, we label historical events that
either improve or reduce our predictability gain, demonstrating the importance
of domain expertise in informing interpretation.</p>
  </details>
</details>
<details>
  <summary>54. <b>标题：ReVar: Strengthening Policy Evaluation via Reduced Variance Sampling</b></summary>
  <p><b>编号</b>：[164]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04510</p>
  <p><b>作者</b>：Subhojyoti Mukherjee,  Josiah P. Hanna,  Robert Nowak</p>
  <p><b>备注</b>：37 pages, 7 figures</p>
  <p><b>关键词</b>：mean squared error comparable, optimal data collection within, oracle data collection strategy, markov decision processes, expected cumulative reward</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper studies the problem of data collection for policy evaluation in
Markov decision processes (MDPs). In policy evaluation, we are given a target
policy and asked to estimate the expected cumulative reward it will obtain in
an environment formalized as an MDP. We develop theory for optimal data
collection within the class of tree-structured MDPs by first deriving an oracle
data collection strategy that uses knowledge of the variance of the reward
distributions. We then introduce the Reduced Variance Sampling (ReVar)
algorithm that approximates the oracle strategy when the reward variances are
unknown a priori and bound its sub-optimality compared to the oracle strategy.
Finally, we empirically validate that ReVar leads to policy evaluation with
mean squared error comparable to the oracle strategy and significantly lower
than simply running the target policy.</p>
  </details>
</details>
<details>
  <summary>55. <b>标题：Multi-Agent Policy Transfer via Task Relationship Modeling</b></summary>
  <p><b>编号</b>：[170]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04482</p>
  <p><b>作者</b>：Rongjun Qin,  Feng Chen,  Tonghan Wang,  Lei Yuan,  Xiaoran Wu,  Zongzhang Zhang,  Chongjie Zhang,  Yang Yu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：help transfer learned cooperation knowledge, transferred policies help solve tasks, agent transfer learning accommodate teams, exploit common structures among tasks, alternatively fixed training scheme</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Team adaptation to new cooperative tasks is a hallmark of human intelligence,
which has yet to be fully realized in learning agents. Previous work on
multi-agent transfer learning accommodate teams of different sizes, heavily
relying on the generalization ability of neural networks for adapting to unseen
tasks. We believe that the relationship among tasks provides the key
information for policy adaptation. In this paper, we try to discover and
exploit common structures among tasks for more efficient transfer, and propose
to learn effect-based task representations as a common space of tasks, using an
alternatively fixed training scheme. We demonstrate that the task
representation can capture the relationship among tasks, and can generalize to
unseen tasks. As a result, the proposed method can help transfer learned
cooperation knowledge to new tasks after training on a few source tasks. We
also find that fine-tuning the transferred policies help solve tasks that are
hard to learn from scratch.</p>
  </details>
</details>
<details>
  <summary>56. <b>标题：Boilerplate Detection via Semantic Classification of TextBlocks</b></summary>
  <p><b>编号</b>：[176]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04467</p>
  <p><b>作者</b>：Hao Zhang,  Jie Wang</p>
  <p><b>备注</b>：IJCNN 2021</p>
  <p><b>关键词</b>：hierarchical neural network model called semtext, also detects boilerplate effectively, detect html boilerplate based, novel semantic representation, three published datasets</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present a hierarchical neural network model called SemText to detect HTML
boilerplate based on a novel semantic representation of HTML tags, class names,
and text blocks. We train SemText on three published datasets of news webpages
and fine-tune it using a small number of development data in CleanEval and
GoogleTrends-2017. We show that SemText achieves the state-of-the-art accuracy
on these datasets. We then demonstrate the robustness of SemText by showing
that it also detects boilerplate effectively on out-of-domain community-based
question-answer webpages.</p>
  </details>
</details>
<details>
  <summary>57. <b>标题：The Combinatorial Brain Surgeon: Pruning Weights That Cancel One Another  in Neural Networks</b></summary>
  <p><b>编号</b>：[177]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04466</p>
  <p><b>作者</b>：Xin Yu,  Thiago Serra,  Shandian Zhe,  Srikumar Ramalingam</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：smallest absolute value -- even though magnitude, optimal brain surgeon ~( obs )., training may also produce models, obtaining significantly better performance, larger -- even</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Neural networks tend to achieve better accuracy with training if they are
larger -- even if the resulting models are overparameterized. Nevertheless,
carefully removing such excess parameters before, during, or after training may
also produce models with similar or even improved accuracy. In many cases, that
can be curiously achieved by heuristics as simple as removing a percentage of
the weights with the smallest absolute value -- even though magnitude is not a
perfect proxy for weight relevance. With the premise that obtaining
significantly better performance from pruning depends on accounting for the
combined effect of removing multiple weights, we revisit one of the classic
approaches for impact-based pruning: the Optimal Brain Surgeon~(OBS). We
propose a tractable heuristic for solving the combinatorial extension of OBS,
in which we select weights for simultaneous removal, as well as a systematic
update of the remaining weights. Our selection method outperforms other methods
under high sparsity, and the weight update is advantageous even when combined
with the other methods.</p>
  </details>
</details>
<details>
  <summary>58. <b>标题：Downstream Fairness Caveats with Synthetic Healthcare Data</b></summary>
  <p><b>编号</b>：[180]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04462</p>
  <p><b>作者</b>：Karan Bhanot,  Ioana Baldini,  Dennis Wei,  Jiaming Zeng,  Kristin P. Bennett</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：certain protected groups might experience worse outcomes, paper evaluates synthetically generated healthcare data, real healthcare data without privacy risks, generative adversarial network called healthgan, synthetically generated health data comes</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper evaluates synthetically generated healthcare data for biases and
investigates the effect of fairness mitigation techniques on utility-fairness.
Privacy laws limit access to health data such as Electronic Medical Records
(EMRs) to preserve patient privacy. Albeit essential, these laws hinder
research reproducibility. Synthetic data is a viable solution that can enable
access to data similar to real healthcare data without privacy risks.
Healthcare datasets may have biases in which certain protected groups might
experience worse outcomes than others. With the real data having biases, the
fairness of synthetically generated health data comes into question. In this
paper, we evaluate the fairness of models generated on two healthcare datasets
for gender and race biases. We generate synthetic versions of the dataset using
a Generative Adversarial Network called HealthGAN, and compare the real and
synthetic model's balanced accuracy and fairness scores. We find that synthetic
data has different fairness properties compared to real data and fairness
mitigation techniques perform differently, highlighting that synthetic data is
not bias free.</p>
  </details>
</details>
<details>
  <summary>59. <b>标题：Contextual Networks and Unsupervised Ranking of Sentences</b></summary>
  <p><b>编号</b>：[181]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04459</p>
  <p><b>作者</b>：Hao Zhang,  You Zhou,  Jie Wang</p>
  <p><b>备注</b>：ICTAI 2021</p>
  <p><b>关键词</b>：three human judges provided, 1 knapsack maximization problem, outperforms previous supervised algorithms, unsupervised algorithm called cnatar, latest supervised neural</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We construct a contextual network to represent a document with syntactic and
semantic relations between word-sentence pairs, based on which we devise an
unsupervised algorithm called CNATAR (Contextual Network And Text Analysis
Rank) to score sentences, and rank them through a bi-objective 0-1 knapsack
maximization problem over topic analysis and sentence scores. We show that
CNATAR outperforms the combined ranking of the three human judges provided on
the SummBank dataset under both ROUGE and BLEU metrics, which in term
significantly outperforms each individual judge's ranking. Moreover, CNATAR
produces so far the highest ROUGE scores over DUC-02, and outperforms previous
supervised algorithms on the CNN/DailyMail and NYT datasets. We also compare
the performance of CNATAR and the latest supervised neural-network
summarization models and compute oracle results.</p>
  </details>
</details>
<details>
  <summary>60. <b>标题：Pruning Graph Convolutional Networks to select meaningful graph  frequencies for fMRI decoding</b></summary>
  <p><b>编号</b>：[183]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04455</p>
  <p><b>作者</b>：Yassine El Ouahidi,  Hugo Tessier,  Giulia Lioi,  Nicolas Farrugia,  Bastien Pasdeloup,  Vincent Gripon</p>
  <p><b>备注</b>：Submitted to the 30th European Signal Processing Conference, EUSIPCO 2022</p>
  <p><b>关键词</b>：work provides novel insights, increase fmri decoding accuracy, deep learning architecture, decode fmri signals, graph signal processing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Graph Signal Processing is a promising framework to manipulate brain signals
as it allows to encompass the spatial dependencies between the activity in
regions of interest in the brain. In this work, we are interested in better
understanding what are the graph frequencies that are the most useful to decode
fMRI signals. To this end, we introduce a deep learning architecture and adapt
a pruning methodology to automatically identify such frequencies. We experiment
with various datasets, architectures and graphs, and show that low graph
frequencies are consistently identified as the most important for fMRI
decoding, with a stronger contribution for the functional graph over the
structural one. We believe that this work provides novel insights on how
graph-based methods can be deployed to increase fMRI decoding accuracy and
interpretability.</p>
  </details>
</details>
<details>
  <summary>61. <b>标题：Machine Learning in NextG Networks via Generative Adversarial Networks</b></summary>
  <p><b>编号</b>：[184]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04453</p>
  <p><b>作者</b>：Ender Ayanoglu,  Kemal Davaslioglu,  Yalin E. Sagduyu</p>
  <p><b>备注</b>：47 pages, 7 figures, 12 tables</p>
  <p><b>关键词</b>：address competitive resource allocation problems together, g ., user authentication, outperforming another state, mitigating security attacks, future research directions</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Generative Adversarial Networks (GANs) are Machine Learning (ML) algorithms
that have the ability to address competitive resource allocation problems
together with detection and mitigation of anomalous behavior. In this paper, we
investigate their use in next-generation (NextG) communications within the
context of cognitive networks to address i) spectrum sharing, ii) detecting
anomalies, and iii) mitigating security attacks. GANs have the following
advantages. First, they can learn and synthesize field data, which can be
costly, time consuming, and nonrepeatable. Second, they enable pre-training
classifiers by using semi-supervised data. Third, they facilitate increased
resolution. Fourth, they enable the recovery of corrupted bits in the spectrum.
The paper provides the basics of GANs, a comparative discussion on different
kinds of GANs, performance measures for GANs in computer vision and image
processing as well as wireless applications, a number of datasets for wireless
applications, performance measures for general classifiers, a survey of the
literature on GANs for i)-iii) above, and future research directions. As a use
case of GAN for NextG communications, we show that a GAN can be effectively
applied for anomaly detection in signal classification (e.g., user
authentication) outperforming another state-of-the-art ML technique such as an
autoencoder.</p>
  </details>
</details>
<details>
  <summary>62. <b>标题：CIDER: Exploiting Hyperspherical Embeddings for Out-of-Distribution  Detection</b></summary>
  <p><b>编号</b>：[187]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04450</p>
  <p><b>作者</b>：Yifei Ming,  Yiyou Sun,  Ousmane Dia,  Yixuan Li</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：promotes large angular distances among different class prototypes, cider jointly optimizes two losses, hard ood detection task cifar, prior methods directly take, representation learning give rise</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Out-of-distribution (OOD) detection is a critical task for reliable machine
learning. Recent advances in representation learning give rise to developments
in distance-based OOD detection, where testing samples are detected as OOD if
they are relatively far away from the centroids or prototypes of
in-distribution (ID) classes. However, prior methods directly take
off-the-shelf loss functions that suffice for classifying ID samples, but are
not optimally designed for OOD detection. In this paper, we propose CIDER, a
simple and effective representation learning framework by exploiting
hyperspherical embeddings for OOD detection. CIDER jointly optimizes two losses
to promote strong ID-OOD separability: (1) a dispersion loss that promotes
large angular distances among different class prototypes, and (2) a compactness
loss that encourages samples to be close to their class prototypes. We show
that CIDER is effective under various settings and establishes state-of-the-art
performance. On a hard OOD detection task CIFAR-100 vs. CIFAR-10, our method
substantially improves the AUROC by 14.20% compared to the embeddings learned
by the cross-entropy loss.</p>
  </details>
</details>
<details>
  <summary>63. <b>标题：Reproducible Subjective Evaluation</b></summary>
  <p><b>编号</b>：[191]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04444</p>
  <p><b>作者</b>：Max Morrison,  Brian Tang,  Gefei Tan,  Bryan Pardo</p>
  <p><b>备注</b>：Submitted to ICLR 2022 Workshop on Setting up ML Evaluation Standards to Accelerate Progress</p>
  <p><b>关键词</b>：quickly deploying crowdsourced subjective evaluations directly, many researchers use objective measures, studies require significant time, propose reproducible subjective evaluation, reseval lets researchers launch</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Human perceptual studies are the gold standard for the evaluation of many
research tasks in machine learning, linguistics, and psychology. However, these
studies require significant time and cost to perform. As a result, many
researchers use objective measures that can correlate poorly with human
evaluation. When subjective evaluations are performed, they are often not
reported with sufficient detail to ensure reproducibility. We propose
Reproducible Subjective Evaluation (ReSEval), an open-source framework for
quickly deploying crowdsourced subjective evaluations directly from Python.
ReSEval lets researchers launch A/B, ABX, Mean Opinion Score (MOS) and MUltiple
Stimuli with Hidden Reference and Anchor (MUSHRA) tests on audio, image, text,
or video data from a command-line interface or using one line of Python, making
it as easy to run as objective evaluation. With ReSEval, researchers can
reproduce each other's subjective evaluations by sharing a configuration file
and the audio, image, text, or video files.</p>
  </details>
</details>
<details>
  <summary>64. <b>标题：Variational Inference with Locally Enhanced Bounds for Hierarchical  Models</b></summary>
  <p><b>编号</b>：[196]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04432</p>
  <p><b>作者</b>：Tomas Geffner,  Justin Domke</p>
  <p><b>备注</b>：Preprint</p>
  <p><b>关键词</b>：provide accurate approximations due, build tighter lower bounds, integrate monte carlo methods, accurate posterior approximations, lower dimensional spaces</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Hierarchical models represent a challenging setting for inference algorithms.
MCMC methods struggle to scale to large models with many local variables and
observations, and variational inference (VI) may fail to provide accurate
approximations due to the use of simple variational families. Some variational
methods (e.g. importance weighted VI) integrate Monte Carlo methods to give
better accuracy, but these tend to be unsuitable for hierarchical models, as
they do not allow for subsampling and their performance tends to degrade for
high dimensional models. We propose a new family of variational bounds for
hierarchical models, based on the application of tightening methods (e.g.
importance weighting) separately for each group of local random variables. We
show that our approach naturally allows the use of subsampling to get unbiased
gradients, and that it fully leverages the power of methods that build tighter
lower bounds by applying them independently in lower dimensional spaces,
leading to better results and more accurate posterior approximations than
relevant baselines.</p>
  </details>
</details>
<details>
  <summary>65. <b>标题：Leveraging Smooth Attention Prior for Multi-Agent Trajectory Prediction</b></summary>
  <p><b>编号</b>：[203]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04421</p>
  <p><b>作者</b>：Zhangjie Cao,  Erdem Bıyık,  Guy Rosman,  Dorsa Sadigh</p>
  <p><b>备注</b>：8 pages</p>
  <p><b>关键词</b>：may introduce fluctuating attention across time steps, new sequence prediction loss terms leads, total variation temporal smoothness prior, total variation attention prior along, existing attention modeling works ignore</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Multi-agent interactions are important to model for forecasting other agents'
behaviors and trajectories. At a certain time, to forecast a reasonable future
trajectory, each agent needs to pay attention to the interactions with only a
small group of most relevant agents instead of unnecessarily paying attention
to all the other agents. However, existing attention modeling works ignore that
human attention in driving does not change rapidly, and may introduce
fluctuating attention across time steps. In this paper, we formulate an
attention model for multi-agent interactions based on a total variation
temporal smoothness prior and propose a trajectory prediction architecture that
leverages the knowledge of these attended interactions. We demonstrate how the
total variation attention prior along with the new sequence prediction loss
terms leads to smoother attention and more sample-efficient learning of
multi-agent trajectory prediction, and show its advantages in terms of
prediction accuracy by comparing it with the state-of-the-art approaches on
both synthetic and naturalistic driving data. We demonstrate the performance of
our algorithm for trajectory prediction on the INTERACTION dataset on our
website.</p>
  </details>
</details>
<details>
  <summary>66. <b>标题：Survival Prediction of Brain Cancer with Incomplete Radiology,  Pathology, Genomics, and Demographic Data</b></summary>
  <p><b>编号</b>：[204]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04419</p>
  <p><b>作者</b>：Can Cui,  Han Liu,  Quan Liu,  Ruining Deng,  Zuhayr Asad,  Yaohong WangShilin Zhao,  Haichun Yang,  Bennett A. Landman,  Yuankai Huo</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：systematically evaluate glioma tumor survival prediction using four modalities, effectively predict brain cancer survival, brain cancer survival prediction, using four modalities, brain cancer diagnosis</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Integrating cross-department multi-modal data (e.g., radiological,
pathological, genomic, and clinical data) is ubiquitous in brain cancer
diagnosis and survival prediction. To date, such an integration is typically
conducted by human physicians (and panels of experts), which can be subjective
and semi-quantitative. Recent advances in multi-modal deep learning, however,
have opened a door to leverage such a process to a more objective and
quantitative manner. Unfortunately, the prior arts of using four modalities on
brain cancer survival prediction are limited by a "complete modalities" setting
(i.e., with all modalities available). Thus, there are still open questions on
how to effectively predict brain cancer survival from the incomplete
radiological, pathological, genomic, and demographic data (e.g., one or more
modalities might not be collected for a patient). For instance, should we use
both complete and incomplete data, and more importantly, how to use those data?
To answer the preceding questions, we generalize the multi-modal learning on
cross-department multi-modal data to a missing data setting. Our contribution
is three-fold: 1) We introduce optimal multi-modal learning with missing data
(MMD) pipeline with optimized hardware consumption and computational
efficiency; 2) We extend multi-modal learning on radiological, pathological,
genomic, and demographic data into missing data scenarios; 3) a large-scale
public dataset (with 962 patients) is collected to systematically evaluate
glioma tumor survival prediction using four modalities. The proposed method
improved the C-index of survival prediction from 0.7624 to 0.8053.</p>
  </details>
</details>
<details>
  <summary>67. <b>标题：Score matching enables causal discovery of nonlinear additive noise  models</b></summary>
  <p><b>编号</b>：[207]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04413</p>
  <p><b>作者</b>：Paul Rolland,  Volkan Cevher,  Matthäus Kleindessner,  Chris Russel,  Bernhard Schölkopf,  Dominik Janzing,  Francesco Locatello</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：scalable causal discovery methods, art causal discovery methods, using score matching algorithms, new efficient method, recover causal graphs</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper demonstrates how to recover causal graphs from the score of the
data distribution in non-linear additive (Gaussian) noise models. Using score
matching algorithms as a building block, we show how to design a new generation
of scalable causal discovery methods. To showcase our approach, we also propose
a new efficient method for approximating the score's Jacobian, enabling to
recover the causal graph. Empirically, we find that the new algorithm, called
SCORE, is competitive with state-of-the-art causal discovery methods while
being significantly faster.</p>
  </details>
</details>
<details>
  <summary>68. <b>标题：ImageNet-Patch: A Dataset for Benchmarking Machine Learning Robustness  against Adversarial Patches</b></summary>
  <p><b>编号</b>：[208]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04412</p>
  <p><b>作者</b>：Maura Pintor,  Daniele Angioni,  Angelo Sotgiu,  Luca Demetrio,  Ambra Demontis,  Battista Biggio,  Fabio Roli</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：approximate yet faster robustness evaluation, requires careful hyperparameter tuning, generalize across different models, optimized contiguous pixel blocks, suboptimal robustness evaluations</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Adversarial patches are optimized contiguous pixel blocks in an input image
that cause a machine-learning model to misclassify it. However, their
optimization is computationally demanding, and requires careful hyperparameter
tuning, potentially leading to suboptimal robustness evaluations. To overcome
these issues, we propose ImageNet-Patch, a dataset to benchmark
machine-learning models against adversarial patches. It consists of a set of
patches, optimized to generalize across different models, and readily
applicable to ImageNet data after preprocessing them with affine
transformations. This process enables an approximate yet faster robustness
evaluation, leveraging the transferability of adversarial perturbations. We
showcase the usefulness of this dataset by testing the effectiveness of the
computed patches against 127 models. We conclude by discussing how our dataset
could be used as a benchmark for robustness, and how our methodology can be
generalized to other domains. We open source our dataset and evaluation code at
this https URL.</p>
  </details>
</details>
<details>
  <summary>69. <b>标题：Art-Attack: Black-Box Adversarial Attack via Evolutionary Art</b></summary>
  <p><b>编号</b>：[212]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04405</p>
  <p><b>作者</b>：Phoenix Williams,  Ke Li</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：art image classification models trained, higher attack success rate, three baseline models, shown extreme vulnerabilities, predicted class probabilities</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep neural networks (DNNs) have achieved state-of-the-art performance in
many tasks but have shown extreme vulnerabilities to attacks generated by
adversarial examples. Many works go with a white-box attack that assumes total
access to the targeted model including its architecture and gradients. A more
realistic assumption is the black-box scenario where an attacker only has
access to the targeted model by querying some input and observing its predicted
class probabilities. Different from most prevalent black-box attacks that make
use of substitute models or gradient estimation, this paper proposes a
gradient-free attack by using a concept of evolutionary art to generate
adversarial examples that iteratively evolves a set of overlapping transparent
shapes. To evaluate the effectiveness of our proposed method, we attack three
state-of-the-art image classification models trained on the CIFAR-10 dataset in
a targeted manner. We conduct a parameter study outlining the impact the number
and type of shapes have on the proposed attack's performance. In comparison to
state-of-the-art black-box attacks, our attack is more effective at generating
adversarial examples and achieves a higher attack success rate on all three
baseline models.</p>
  </details>
</details>
<details>
  <summary>70. <b>标题：Model-free feature selection to facilitate automatic discovery of  divergent subgroups in tabular data</b></summary>
  <p><b>编号</b>：[214]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04386</p>
  <p><b>作者</b>：Girmaw Abebe Tadesse,  William Ogallo,  Celia Cintas,  Skyler Speakman</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：automatic discovery techniques often search across potentially exponential combinations, validated safs across two publicly available datasets, claims dataset detected divergent samples similar, objective measures among feature values, tabular data often involve fitting</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Data-centric AI encourages the need of cleaning and understanding of data in
order to achieve trustworthy AI. Existing technologies, such as AutoML, make it
easier to design and train models automatically, but there is a lack of a
similar level of capabilities to extract data-centric insights. Manual
stratification of tabular data per a feature (e.g., gender) is limited to scale
up for higher feature dimension, which could be addressed using automatic
discovery of divergent subgroups. Nonetheless, these automatic discovery
techniques often search across potentially exponential combinations of features
that could be simplified using a preceding feature selection step. Existing
feature selection techniques for tabular data often involve fitting a
particular model in order to select important features. However, such
model-based selection is prone to model-bias and spurious correlations in
addition to requiring extra resource to design, fine-tune and train a model. In
this paper, we propose a model-free and sparsity-based automatic feature
selection (SAFS) framework to facilitate automatic discovery of divergent
subgroups. Different from filter-based selection techniques, we exploit the
sparsity of objective measures among feature values to rank and select
features. We validated SAFS across two publicly available datasets (MIMIC-III
and Allstate Claims) and compared it with six existing feature selection
methods. SAFS achieves a reduction of feature selection time by a factor of 81x
and 104x, averaged cross the existing methods in the MIMIC-III and Claims
datasets respectively. SAFS-selected features are also shown to achieve
competitive detection performance, e.g., 18.3% of features selected by SAFS in
the Claims dataset detected divergent samples similar to those detected by
using the whole features with a Jaccard similarity of 0.95 but with a 16x
reduction in detection time.</p>
  </details>
</details>
<details>
  <summary>71. <b>标题：On generative models as the basis for digital twins</b></summary>
  <p><b>编号</b>：[215]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04384</p>
  <p><b>作者</b>：G. Tsialiamanis,  D.J. Wagg,  N. Dervilis,  K. Worden</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：conditional generative adversarial networks, deterministic models cannot account, driven cgans model outperform, using machine learning, stochastic finite element</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A framework is proposed for generative models as a basis for digital twins or
mirrors of structures. The proposal is based on the premise that deterministic
models cannot account for the uncertainty present in most structural modelling
applications. Two different types of generative models are considered here. The
first is a physics-based model based on the stochastic finite element (SFE)
method, which is widely used when modelling structures that have material and
loading uncertainties imposed. Such models can be calibrated according to data
from the structure and would be expected to outperform any other model if the
modelling accurately captures the true underlying physics of the structure. The
potential use of SFE models as digital mirrors is illustrated via application
to a linear structure with stochastic material properties. For situations where
the physical formulation of such models does not suffice, a data-driven
framework is proposed, using machine learning and conditional generative
adversarial networks (cGANs). The latter algorithm is used to learn the
distribution of the quantity of interest in a structure with material
nonlinearities and uncertainties. For the examples considered in this work, the
data-driven cGANs model outperform the physics-based approach. Finally, an
example is shown where the two methods are coupled such that a hybrid model
approach is demonstrated.</p>
  </details>
</details>
<details>
  <summary>72. <b>标题：A Novel Deep Learning Model for Hotel Demand and Revenue Prediction amid  COVID-19</b></summary>
  <p><b>编号</b>：[216]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04383</p>
  <p><b>作者</b>：Ashkan Farhangi,  Arthur Huang,  Zhishan Guo</p>
  <p><b>备注</b>：55th Hawaii International Conference on System Sciences (HICSS) 2022</p>
  <p><b>关键词</b>：framework using daily hotel demand, novel deep learning framework, significantly affected tourist activities, predicting time series data, time series data</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The COVID-19 pandemic has significantly impacted the tourism and hospitality
sector. Public policies such as travel restrictions and stay-at-home orders had
significantly affected tourist activities and service businesses' operations
and profitability. To this end, it is essential to develop an interpretable
forecast model that supports managerial and organizational decision-making. We
developed DemandNet, a novel deep learning framework for predicting time series
data under the influence of the COVID-19 pandemic. The framework starts by
selecting the top static and dynamic features embedded in the time series data.
Then, it includes a nonlinear model which can provide interpretable insight
into the previously seen data. Lastly, a prediction model is developed to
leverage the above characteristics to make robust long-term forecasts. We
evaluated the framework using daily hotel demand and revenue data from eight
cities in the US. Our findings reveal that DemandNet outperforms the
state-of-art models and can accurately predict the impact of the COVID-19
pandemic on hotel demand and revenues.</p>
  </details>
</details>
<details>
  <summary>73. <b>标题：Regularized Training of Intermediate Layers for Generative Models for  Inverse Problems</b></summary>
  <p><b>编号</b>：[217]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04382</p>
  <p><b>作者</b>：Sean Gunn,  Jorio Cocola,  Paul Hand</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：multiple proposed inversion algorithms reduce representation error, two notable recent inversion algorithms, new regularized gan training algorithm, lower reconstruction errors across, learned generative model results</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Generative Adversarial Networks (GANs) have been shown to be powerful and
flexible priors when solving inverse problems. One challenge of using them is
overcoming representation error, the fundamental limitation of the network in
representing any particular signal. Recently, multiple proposed inversion
algorithms reduce representation error by optimizing over intermediate layer
representations. These methods are typically applied to generative models that
were trained agnostic of the downstream inversion algorithm. In our work, we
introduce a principle that if a generative model is intended for inversion
using an algorithm based on optimization of intermediate layers, it should be
trained in a way that regularizes those intermediate layers. We instantiate
this principle for two notable recent inversion algorithms: Intermediate Layer
Optimization and the Multi-Code GAN prior. For both of these inversion
algorithms, we introduce a new regularized GAN training algorithm and
demonstrate that the learned generative model results in lower reconstruction
errors across a wide range of under sampling ratios when solving compressed
sensing, inpainting, and super-resolution problems.</p>
  </details>
</details>
<details>
  <summary>74. <b>标题：Logic-based AI for Interpretable Board Game Winner Prediction with  Tsetlin Machine</b></summary>
  <p><b>编号</b>：[219]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04378</p>
  <p><b>作者</b>：Charul Giri,  Ole-Christoffer Granmo,  Herke van Hoof,  Christian D. Blakely</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：popular machine learning algorithms like xgboost, resulting interpretability establishes building blocks, board positions using neural networks, losing board game positions, considering various board configurations</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Hex is a turn-based two-player connection game with a high branching factor,
making the game arbitrarily complex with increasing board sizes. As such,
top-performing algorithms for playing Hex rely on accurate evaluation of board
positions using neural networks. However, the limited interpretability of
neural networks is problematic when the user wants to understand the reasoning
behind the predictions made. In this paper, we propose to use propositional
logic expressions to describe winning and losing board game positions,
facilitating precise visual interpretation. We employ a Tsetlin Machine (TM) to
learn these expressions from previously played games, describing where pieces
must be located or not located for a board position to be strong. Extensive
experiments on $6\times6$ boards compare our TM-based solution with popular
machine learning algorithms like XGBoost, InterpretML, decision trees, and
neural networks, considering various board configurations with $2$ to $22$
moves played. On average, the TM testing accuracy is $92.1\%$, outperforming
all the other evaluated algorithms. We further demonstrate the global
interpretation of the logical expressions and map them down to particular board
game configurations to investigate local interpretability. We believe the
resulting interpretability establishes building blocks for accurate assistive
AI and human-AI collaboration, also for more complex prediction tasks.</p>
  </details>
</details>
<details>
  <summary>75. <b>标题：New Coresets for Projective Clustering and Applications</b></summary>
  <p><b>编号</b>：[222]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04370</p>
  <p><b>作者</b>：Murad Tukan,  Xuan Wu,  Samson Zhou,  Vladimir Braverman,  Dan Feldman</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：construction provides efficient coreset constructions, j $- subspace clustering problems, provide experimental results based, e ., affine subspaces, first strong coreset construction</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>$(j,k)$-projective clustering is the natural generalization of the family of
$k$-clustering and $j$-subspace clustering problems. Given a set of points $P$
in $\mathbb{R}^d$, the goal is to find $k$ flats of dimension $j$, i.e., affine
subspaces, that best fit $P$ under a given distance measure. In this paper, we
propose the first algorithm that returns an $L_\infty$ coreset of size
polynomial in $d$. Moreover, we give the first strong coreset construction for
general $M$-estimator regression. Specifically, we show that our construction
provides efficient coreset constructions for Cauchy, Welsch, Huber,
Geman-McClure, Tukey, $L_1-L_2$, and Fair regression, as well as general
concave and power-bounded loss functions. Finally, we provide experimental
results based on real-world datasets, showing the efficacy of our approach.</p>
  </details>
</details>
<details>
  <summary>76. <b>标题：TTML: tensor trains for general supervised machine learning</b></summary>
  <p><b>编号</b>：[229]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04352</p>
  <p><b>作者</b>：Bart Vandereycken,  Rik Voorhaar</p>
  <p><b>备注</b>：23 pages</p>
  <p><b>关键词</b>：optimized using riemannian gradient descent, supervised machine learning, parametrize discretized functions, lower memory usage, estimator uses tts</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This work proposes a novel general-purpose estimator for supervised machine
learning (ML) based on tensor trains (TT). The estimator uses TTs to
parametrize discretized functions, which are then optimized using Riemannian
gradient descent under the form of a tensor completion problem. Since this
optimization is sensitive to initialization, it turns out that the use of other
ML estimators for initialization is crucial. This results in a competitive,
fast ML estimator with lower memory usage than many other ML estimators, like
the ones used for the initialization.</p>
  </details>
</details>
<details>
  <summary>77. <b>标题：Beam Search for Feature Selection</b></summary>
  <p><b>编号</b>：[230]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04350</p>
  <p><b>作者</b>：Nicolas Fraiman,  Zichao Li</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：cases classification models could obtain comparable performance using, different classification models using different sets, beam search could outperform forward selection, classification models using, use beam search</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we present and prove some consistency results about the
performance of classification models using a subset of features. In addition,
we propose to use beam search to perform feature selection, which can be viewed
as a generalization of forward selection. We apply beam search to both
simulated and real-world data, by evaluating and comparing the performance of
different classification models using different sets of features. The results
demonstrate that beam search could outperform forward selection, especially
when the features are correlated so that they have more discriminative power
when considered jointly than individually. Moreover, in some cases
classification models could obtain comparable performance using only ten
features selected by beam search instead of hundreds of original features.</p>
  </details>
</details>
<details>
  <summary>78. <b>标题：Cluster Head Detection for Hierarchical UAV Swarm With Graph  Self-supervised Learning</b></summary>
  <p><b>编号</b>：[234]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04311</p>
  <p><b>作者</b>：Zhiyu Mou,  Jun Liu,  Xiang Yun,  Feifei Gao,  Qihui Wu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：gru )- based metric learning scheme, single uav clusters obeying various kinds, level unmanned aerial vehicle, simulation results also show, cluster head detection problem</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we study the cluster head detection problem of a two-level
unmanned aerial vehicle (UAV) swarm network (USNET) with multiple UAV clusters,
where the inherent follow strategy (IFS) of low-level follower UAVs (FUAVs)
with respect to high-level cluster head UAVs (HUAVs) is unknown. We first
propose a graph attention self-supervised learning algorithm (GASSL) to detect
the HUAVs of a single UAV cluster, where the GASSL can fit the IFS at the same
time. Then, to detect the HUAVs in the USNET with multiple UAV clusters, we
develop a multi-cluster graph attention self-supervised learning algorithm
(MC-GASSL) based on the GASSL. The MC-GASSL clusters the USNET with a gated
recurrent unit (GRU)-based metric learning scheme and finds the HUAVs in each
cluster with GASSL. Numerical results show that the GASSL can detect the HUAVs
in single UAV clusters obeying various kinds of IFSs with over 98% average
accuracy. The simulation results also show that the clustering purity of the
USNET with MC-GASSL exceeds that with traditional clustering algorithms by at
least 10% average. Furthermore, the MC-GASSL can efficiently detect all the
HUAVs in USNETs with various IFSs and cluster numbers with low detection
redundancies.</p>
  </details>
</details>
<details>
  <summary>79. <b>标题：Multi-Agent Broad Reinforcement Learning for Intelligent Traffic Light  Control</b></summary>
  <p><b>编号</b>：[235]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04310</p>
  <p><b>作者</b>：Ruijie Zhu,  Lulu Li,  Shuning Wu,  Pei Lv,  Yafai Li,  Mingliang Xu</p>
  <p><b>备注</b>：13 pages, 12 figures</p>
  <p><b>关键词</b>：intelligent traffic light control scenario, intelligent traffic light control system, single agent deep reinforcement learning, agent deep reinforcement learning, agent broad reinforcement learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Intelligent Traffic Light Control System (ITLCS) is a typical Multi-Agent
System (MAS), which comprises multiple roads and traffic lights.Constructing a
model of MAS for ITLCS is the basis to alleviate traffic congestion. Existing
approaches of MAS are largely based on Multi-Agent Deep Reinforcement Learning
(MADRL). Although the Deep Neural Network (DNN) of MABRL is effective, the
training time is long, and the parameters are difficult to trace. Recently,
Broad Learning Systems (BLS) provided a selective way for learning in the deep
neural networks by a flat network. Moreover, Broad Reinforcement Learning (BRL)
extends BLS in Single Agent Deep Reinforcement Learning (SADRL) problem with
promising results. However, BRL does not focus on the intricate structures and
interaction of agents. Motivated by the feature of MADRL and the issue of BRL,
we propose a Multi-Agent Broad Reinforcement Learning (MABRL) framework to
explore the function of BLS in MAS. Firstly, unlike most existing MADRL
approaches, which use a series of deep neural networks structures, we model
each agent with broad networks. Then, we introduce a dynamic self-cycling
interaction mechanism to confirm the "3W" information: When to interact, Which
agents need to consider, What information to transmit. Finally, we do the
experiments based on the intelligent traffic light control scenario. We compare
the MABRL approach with six different approaches, and experimental results on
three datasets verify the effectiveness of MABRL.</p>
  </details>
</details>
<details>
  <summary>80. <b>标题：A Machine Learning Approach to Digital Contact Tracing: TC4TL Challenge</b></summary>
  <p><b>编号</b>：[236]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04307</p>
  <p><b>作者</b>：Badrinath Singhal,  Chris Vorster,  Di Meng,  Gargi Gupta,  Laura Dunne,  Mark Germaine</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：two mobile phone devices using bluetooth low energy, 08 ), significantly outperforming existing models, considered utilising phone sensor data, total ndcf 0, public health organisations</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Contact tracing is a method used by public health organisations to try
prevent the spread of infectious diseases in the community. Traditionally
performed by manual contact tracers, more recently the use of apps have been
considered utilising phone sensor data to determine the distance between two
phones. In this paper, we investigate the development of machine learning
approaches to determine the distance between two mobile phone devices using
Bluetooth Low Energy, sensory data and meta data. We use TableNet architecture
and feature engineering to improve on the existing state of the art (total nDCF
0.21 vs 2.08), significantly outperforming existing models.</p>
  </details>
</details>
<details>
  <summary>81. <b>标题：LSTMSPLIT: Effective SPLIT Learning based LSTM on Sequential Time-Series  Data</b></summary>
  <p><b>编号</b>：[237]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04305</p>
  <p><b>作者</b>：Lianlian Jiang,  Yuexuan Wang,  Wenyi Zheng,  Chao Jin,  Zengxiang Li,  Sin G. Teo</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：many researchers typically use 1d convolutional neural networks, two popular distributed machine learning, distributed across various clients, also achieve good accuracy, human activity recognition dataset</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Federated learning (FL) and split learning (SL) are the two popular
distributed machine learning (ML) approaches that provide some data privacy
protection mechanisms. In the time-series classification problem, many
researchers typically use 1D convolutional neural networks (1DCNNs) based on
the SL approach with a single client to reduce the computational overhead at
the client-side while still preserving data privacy. Another method, recurrent
neural network (RNN), is utilized on sequentially partitioned data where
segments of multiple-segment sequential data are distributed across various
clients. However, to the best of our knowledge, it is still not much work done
in SL with long short-term memory (LSTM) network, even the LSTM network is
practically effective in processing time-series data. In this work, we propose
a new approach, LSTMSPLIT, that uses SL architecture with an LSTM network to
classify time-series data with multiple clients. The differential privacy (DP)
is applied to solve the data privacy leakage. The proposed method, LSTMSPLIT,
has achieved better or reasonable accuracy compared to the Split-1DCNN method
using the electrocardiogram dataset and the human activity recognition dataset.
Furthermore, the proposed method, LSTMSPLIT, can also achieve good accuracy
after applying differential privacy to preserve the user privacy of the cut
layer of the LSTMSPLIT.</p>
  </details>
</details>
<details>
  <summary>82. <b>标题：UENAS: A Unified Evolution-based NAS Framework</b></summary>
  <p><b>编号</b>：[239]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04300</p>
  <p><b>作者</b>：Zimian Wei,  Hengyue Pan,  Xin Niu,  Peijie Dong,  Dongsheng Li</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：population without compromising performance, supports optimizing network architectures, child networks share weights, uenas achieves error rates, huge search cost caused</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Neural architecture search (NAS) has gained significant attention for
automatic network design in recent years. Previous NAS methods suffer from
limited search spaces, which may lead to sub-optimal results. In this paper, we
propose UENAS, an evolution-based NAS framework with a broader search space
that supports optimizing network architectures, pruning strategies, and
hyperparameters simultaneously. To alleviate the huge search cost caused by the
expanded search space, three strategies are adopted: First, an adaptive pruning
strategy that iteratively trims the average model size in the population
without compromising performance. Second, child networks share weights of
overlapping layers with pre-trained parent networks to reduce the training
epochs. Third, an online predictor scores the joint representations of
architecture, pruning strategy, and hyperparameters to filter out inferior
combos. By the proposed three strategies, the search efficiency is
significantly improved and more well-performed compact networks with tailored
hyper-parameters are derived. In experiments, UENAS achieves error rates of
2.81% on CIFAR-10, 20.24% on CIFAR-100, and 33% on Tiny-ImageNet, which shows
the effectiveness of our method.</p>
  </details>
</details>
<details>
  <summary>83. <b>标题：CaSS: A Channel-aware Self-supervised Representation Learning Framework  for Multivariate Time Series Classification</b></summary>
  <p><b>编号</b>：[240]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04298</p>
  <p><b>作者</b>：Yijiang Chen,  Xiangdong Zhou,  Zhen Xing,  Zhidan Liu,  Minyang Xu</p>
  <p><b>备注</b>：16 pages, 4 figures, DASFAA 2022</p>
  <p><b>关键词</b>：combine two novel pretext tasks next trend prediction, several commonly used benchmark datasets, supervised mts representation learning methods, attracts increasing research interests, many previous works focus</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Self-supervised representation learning of Multivariate Time Series (MTS) is
a challenging task and attracts increasing research interests in recent years.
Many previous works focus on the pretext task of self-supervised learning and
usually neglect the complex problem of MTS encoding, leading to unpromising
results. In this paper, we tackle this challenge from two aspects: encoder and
pretext task, and propose a unified channel-aware self-supervised learning
framework CaSS. Specifically, we first design a new Transformer-based encoder
Channel-aware Transformer (CaT) to capture the complex relationships between
different time channels of MTS. Second, we combine two novel pretext tasks Next
Trend Prediction (NTP) and Contextual Similarity (CS) for the self-supervised
representation learning with our proposed encoder. Extensive experiments are
conducted on several commonly used benchmark datasets. The experimental results
show that our framework achieves new state-of-the-art comparing with previous
self-supervised MTS representation learning methods (up to +7.70\% improvement
on LSST dataset) and can be well applied to the downstream MTS classification.</p>
  </details>
</details>
<details>
  <summary>84. <b>标题：Rényi State Entropy for Exploration Acceleration in Reinforcement  Learning</b></summary>
  <p><b>编号</b>：[241]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04297</p>
  <p><b>作者</b>：Mingqi Yuan,  Man-on Pun,  Dong Wang</p>
  <p><b>备注</b>：10 pages, 6 figures</p>
  <p><b>关键词</b>：k $- nearest neighbor estimator, conventional methods incur complex models, k $- value search method, novel intrinsic reward module based, existing state entropy maximization methods</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>One of the most critical challenges in deep reinforcement learning is to
maintain the long-term exploration capability of the agent. To tackle this
problem, it has been recently proposed to provide intrinsic rewards for the
agent to encourage exploration. However, most existing intrinsic reward-based
methods proposed in the literature fail to provide sustainable exploration
incentives, a problem known as vanishing rewards. In addition, these
conventional methods incur complex models and additional memory in their
learning procedures, resulting in high computational complexity and low
robustness. In this work, a novel intrinsic reward module based on the Rényi
entropy is proposed to provide high-quality intrinsic rewards. It is shown that
the proposed method actually generalizes the existing state entropy
maximization methods. In particular, a $k$-nearest neighbor estimator is
introduced for entropy estimation while a $k$-value search method is designed
to guarantee the estimation accuracy. Extensive simulation results demonstrate
that the proposed Rényi entropy-based method can achieve higher performance
as compared to existing schemes.</p>
  </details>
</details>
<details>
  <summary>85. <b>标题：Learning from Few Examples: A Summary of Approaches to Few-Shot Learning</b></summary>
  <p><b>编号</b>：[242]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04291</p>
  <p><b>作者</b>：Archit Parnami,  Minwoo Lee</p>
  <p><b>备注</b>：32 pages, 20 figures, 9 tables</p>
  <p><b>关键词</b>：many deep learning solutions suffer, building machine learning applications emerges, e ., different variations, extensively high computation time, shot learning problem ).</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Few-Shot Learning refers to the problem of learning the underlying pattern in
the data just from a few training samples. Requiring a large number of data
samples, many deep learning solutions suffer from data hunger and extensively
high computation time and resources. Furthermore, data is often not available
due to not only the nature of the problem or privacy concerns but also the cost
of data preparation. Data collection, preprocessing, and labeling are strenuous
human tasks. Therefore, few-shot learning that could drastically reduce the
turnaround time of building machine learning applications emerges as a low-cost
solution. This survey paper comprises a representative list of recently
proposed few-shot learning algorithms. Given the learning dynamics and
characteristics, the approaches to few-shot learning problems are discussed in
the perspectives of meta-learning, transfer learning, and hybrid approaches
(i.e., different variations of the few-shot learning problem).</p>
  </details>
</details>
<details>
  <summary>86. <b>标题：Why Interpretable Causal Inference is Important for High-Stakes Decision  Making for Critically Ill Patients and How To Do It</b></summary>
  <p><b>编号</b>：[244]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04920</p>
  <p><b>作者</b>：Harsh Parikh,  Kentaro Hoffman,  Haoqi Sun,  Wendong Ge,  Jin Jing,  Rajesh Amerineni,  Lin Liu,  Jimeng Sun,  Sahar Zafar,  Aaron Struck,  Alexander Volfovsky,  Cynthia Rudin,  M. Brandon Westover</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：extremely important problem affecting critically ill patients, limited data could potentially suffice --, average ea burden >= 50 %), called epileptiform activity -- ea, also cannot easily perform studies</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Many fundamental problems affecting the care of critically ill patients lead
to similar analytical challenges: physicians cannot easily estimate the effects
of at-risk medical conditions or treatments because the causal effects of
medical conditions and drugs are entangled. They also cannot easily perform
studies: there are not enough high-quality data for high-dimensional
observational causal inference, and RCTs often cannot ethically be conducted.
However, mechanistic knowledge is available, including how drugs are absorbed
into the body, and the combination of this knowledge with the limited data
could potentially suffice -- if we knew how to combine them. In this work, we
present a framework for interpretable estimation of causal effects for
critically ill patients under exactly these complex conditions: interactions
between drugs and observations over time, patient data sets that are not large,
and mechanistic knowledge that can substitute for lack of data. We apply this
framework to an extremely important problem affecting critically ill patients,
namely the effect of seizures and other potentially harmful electrical events
in the brain (called epileptiform activity -- EA) on outcomes. Given the high
stakes involved and the high noise in the data, interpretability is critical
for troubleshooting such complex problems. Interpretability of our matched
groups allowed neurologists to perform chart reviews to verify the quality of
our causal analysis. For instance, our work indicates that a patient who
experiences a high level of seizure-like activity (75% high EA burden) and is
untreated for a six-hour window, has, on average, a 16.7% increased chance of
adverse outcomes such as severe brain damage, lifetime disability, or death. We
find that patients with mild but long-lasting EA (average EA burden >= 50%)
have their risk of an adverse outcome increased by 11.2%.</p>
  </details>
</details>
<details>
  <summary>87. <b>标题：Monitoring Time Series With Missing Values: a Deep Probabilistic  Approach</b></summary>
  <p><b>编号</b>：[245]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04916</p>
  <p><b>作者</b>：Oshri Barazani,  David Tolpin</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：multilayer recurrent neural network architectures make, ongoing forecast must include uncertainty, variate time series predictions, time series forecasting due, time series monitoring based</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Systems are commonly monitored for health and security through collection and
streaming of multivariate time series. Advances in time series forecasting due
to adoption of multilayer recurrent neural network architectures make it
possible to forecast in high-dimensional time series, and identify and classify
novelties early, based on subtle changes in the trends. However, mainstream
approaches to multi-variate time series predictions do not handle well cases
when the ongoing forecast must include uncertainty, nor they are robust to
missing data. We introduce a new architecture for time series monitoring based
on combination of state-of-the-art methods of forecasting in high-dimensional
time series with full probabilistic handling of uncertainty. We demonstrate
advantage of the architecture for time series forecasting and novelty
detection, in particular with partially missing data, and empirically evaluate
and compare the architecture to state-of-the-art approaches on a real-world
data set.</p>
  </details>
</details>
<details>
  <summary>88. <b>标题：Structural & Granger CAUSALITY for IoT Digital Twin</b></summary>
  <p><b>编号</b>：[247]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04876</p>
  <p><b>作者</b>：PG Madhavan</p>
  <p><b>备注</b>：7 pages</p>
  <p><b>关键词</b>：nasa prognostic data repository bearing data collection, measured multichannel sensor data, generalized granger causality factors, call causal digital twin, granger causality factors</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this foundational expository article on the application of Causality
Analysis in IoT, we establish the basic theory and algorithms for estimating
Structural and Granger causality factors from measured multichannel sensor data
(vector timeseries). Vector timeseries is modeled as a Structural Vector
Autoregressive (SVAR) model; utilizing Kalman Filter and Independent Component
Analysis (ICA) methods, Structural and generalized Granger causality factors
are estimated. The estimated causal factors are presented as a Fence graph
which we call Causal Digital Twin. Practical applications of Causal Digital
Twin are demonstrated on NASA Prognostic Data Repository Bearing data
collection. Use of Causal Digital Twin for counterfactual experiments are
indicated.
Causal Digital Twin is a horizontal solution that applies to diverse use
cases in multiple industries such as Industrial, Manufacturing, Automotive,
Consumer, Building and Smart City.</p>
  </details>
</details>
<details>
  <summary>89. <b>标题：Federated Minimax Optimization: Improved Convergence Analyses and  Algorithms</b></summary>
  <p><b>编号</b>：[249]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04850</p>
  <p><b>作者</b>：Pranay Sharma,  Rohan Panda,  Gauri Joshi,  Pramod K. Varshney</p>
  <p><b>备注</b>：52 pages, 4 figures</p>
  <p><b>关键词</b>：analyze local stochastic gradient descent ascent, many modern machine learning applications, efficient distributed optimization algorithms, consider nonconvex minimax optimization, nonconcave minimax problems</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we consider nonconvex minimax optimization, which is gaining
prominence in many modern machine learning applications such as GANs.
Large-scale edge-based collection of training data in these applications calls
for communication-efficient distributed optimization algorithms, such as those
used in federated learning, to process the data. In this paper, we analyze
Local stochastic gradient descent ascent (SGDA), the local-update version of
the SGDA algorithm. SGDA is the core algorithm used in minimax optimization,
but it is not well-understood in a distributed setting. We prove that Local
SGDA has \textit{order-optimal} sample complexity for several classes of
nonconvex-concave and nonconvex-nonconcave minimax problems, and also enjoys
\textit{linear speedup} with respect to the number of clients. We provide a
novel and tighter analysis, which improves the convergence and communication
guarantees in the existing literature. For nonconvex-PL and
nonconvex-one-point-concave functions, we improve the existing complexity
results for centralized minimax problems. Furthermore, we propose a
momentum-based local-update algorithm, which has the same convergence
guarantees, but outperforms Local SGDA as demonstrated in our experiments.</p>
  </details>
</details>
<details>
  <summary>90. <b>标题：Geometric Optimisation on Manifolds with Applications to Deep Learning</b></summary>
  <p><b>编号</b>：[254]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04794</p>
  <p><b>作者</b>：Mario Lezcano-Casado</p>
  <p><b>备注</b>：DPhil Thesis. 154 pages</p>
  <p><b>关键词</b>：time series analysis, one extra line, geotorch allow us, exploding gradient problems, regularise recurrent models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We design and implement a Python library to help the non-expert using all
these powerful tools in a way that is efficient, extensible, and simple to
incorporate into the workflow of the data scientist, practitioner, and applied
researcher. The algorithms implemented in this library have been designed with
usability and GPU efficiency in mind, and they can be added to any PyTorch
model with just one extra line of code.
We showcase the effectiveness of these tools on an application of
optimisation on manifolds in the setting of time series analysis. In this
setting, orthogonal and unitary optimisation is used to constraint and
regularise recurrent models and avoid vanishing and exploding gradient
problems. The algorithms designed for GeoTorch allow us to achieve state of the
art results in the standard tests for this family of models.
We use tools from comparison geometry to give bounds on quantities that are
of interest in optimisation problems. In particular, we build on the work of
(Kaul 1976) to give explicit bounds on the norm of the second derivative of the
Riemannian exponential.</p>
  </details>
</details>
<details>
  <summary>91. <b>标题：Autoregressive based Drift Detection Method</b></summary>
  <p><b>编号</b>：[255]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04769</p>
  <p><b>作者</b>：Mansour Zoubeirou A Mayaki,  Michel Riveill</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：new concept drift detection method outperforms, new concept drift detection method based, concept drift adaptation based, art drift detection methods, classic machine learning framework</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In the classic machine learning framework, models are trained on historical
data and used to predict future values. It is assumed that the data
distribution does not change over time (stationarity). However, in real-world
scenarios, the data generation process changes over time and the model has to
adapt to the new incoming data. This phenomenon is known as concept drift and
leads to a decrease in the predictive model's performance. In this study, we
propose a new concept drift detection method based on autoregressive models
called ADDM. This method can be integrated into any machine learning algorithm
from deep neural networks to simple linear regression model. Our results show
that this new concept drift detection method outperforms the state-of-the-art
drift detection methods, both on synthetic data sets and real-world data sets.
Our approach is theoretically guaranteed as well as empirical and effective for
the detection of various concept drifts. In addition to the drift detector, we
proposed a new method of concept drift adaptation based on the severity of the
drift.</p>
  </details>
</details>
<details>
  <summary>92. <b>标题：Data Representativity for Machine Learning and AI Systems</b></summary>
  <p><b>编号</b>：[261]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04706</p>
  <p><b>作者</b>：Line H. Clemmensen,  Rune D. Kjærsgaard</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：data representativeness without specific clarification, paper analyzes data representativity, using empirical demonstrations, make better predictions, limited work exists</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Data representativity is crucial when drawing inference from data through
machine learning models. Scholars have increased focus on unraveling the bias
and fairness in the models, also in relation to inherent biases in the input
data. However, limited work exists on the representativity of samples
(datasets) for appropriate inference in AI systems. This paper analyzes data
representativity in scientific literature related to AI and sampling, and gives
a brief overview of statistical sampling methodology from disciplines like
sampling of physical materials, experimental design, survey analysis, and
observational studies. Different notions of a 'representative sample' exist in
past and present literature. In particular, the contrast between the notion of
a representative sample in the sense of coverage of the input space, versus a
representative sample as a miniature of the target population is of relevance
when building AI systems. Using empirical demonstrations on US Census data, we
demonstrate that the first is useful for providing equality and demographic
parity, and is more robust to distribution shifts, whereas the latter notion is
useful in situations where the purpose is to make historical inference or draw
inference about the underlying population in general, or make better
predictions for the majority in the underlying population. We propose a
framework of questions for creating and documenting data, with data
representativity in mind, as an addition to existing datasheets for datasets.
Finally, we will also like to call for caution of implicit, in addition to
explicit, use of a notion of data representativeness without specific
clarification.</p>
  </details>
</details>
<details>
  <summary>93. <b>标题：Non-equilibrium molecular geometries in graph neural networks</b></summary>
  <p><b>编号</b>：[262]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04697</p>
  <p><b>作者</b>：Ali Raza,  E. Adrian Henle,  Xiaoli Fern</p>
  <p><b>备注</b>：accepted paper at the ELLIS Machine Learning for Molecule Discovery Workshop</p>
  <p><b>关键词</b>：3d geometries obtained using less, use 3d geometries computed, using 3d geometry information, 3d geometry information, graph neural networks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Graph neural networks have become a powerful framework for learning complex
structure-property relationships and fast screening of chemical compounds.
Recently proposed methods have demonstrated that using 3D geometry information
of the molecule along with the bonding structure can lead to more accurate
prediction on a wide range of properties. A common practice is to use 3D
geometries computed through density functional theory (DFT) for both training
and testing of models. However, the computational time needed for DFT
calculations can be prohibitively large. Moreover, many of the properties that
we aim to predict can often be obtained with little or no overhead on top of
the DFT calculations used to produce the 3D geometry information, voiding the
need for a predictive model. To be practically useful for high-throughput
chemical screening and drug discovery, it is desirable to work with 3D
geometries obtained using less-accurate but much more efficient non-DFT
methods. In this work we investigate the impact of using non-DFT conformations
in the training and the testing of existing models and propose a data
augmentation method for improving the prediction accuracy of classical
forcefield-derived geometries.</p>
  </details>
</details>
<details>
  <summary>94. <b>标题：Structured Multi-task Learning for Molecular Property Prediction</b></summary>
  <p><b>编号</b>：[263]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04695</p>
  <p><b>作者</b>：Shengchao Liu,  Meng Qu,  Zuobai Zhang,  Huiyu Cai,  Jian Tang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：dataset including around 400 tasks, state graph neural network, molecular property prediction, molecular property prediction, employ structured prediction</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Multi-task learning for molecular property prediction is becoming
increasingly important in drug discovery. However, in contrast to other
domains, the performance of multi-task learning in drug discovery is still not
satisfying as the number of labeled data for each task is too limited, which
calls for additional data to complement the data scarcity. In this paper, we
study multi-task learning for molecular property prediction in a novel setting,
where a relation graph between tasks is available. We first construct a dataset
including around 400 tasks as well as a task relation graph. Then to better
utilize such relation graph, we propose a method called SGNN-EBM to
systematically investigate the structured task modeling from two perspectives.
(1) In the \emph{latent} space, we model the task representations by applying a
state graph neural network (SGNN) on the relation graph. (2) In the
\emph{output} space, we employ structured prediction with the energy-based
model (EBM), which can be efficiently trained through noise-contrastive
estimation (NCE) approach. Empirical results justify the effectiveness of
SGNN-EBM. Code is available on this https URL.</p>
  </details>
</details>
<details>
  <summary>95. <b>标题：SparseChem: Fast and accurate machine learning model for small molecules</b></summary>
  <p><b>编号</b>：[264]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04676</p>
  <p><b>作者</b>：Adam Arany,  Jaak Simm,  Martijn Oldenhof,  Yves Moreau</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：accurate machine learning models, sparsechem provides fast, dimensional sparse inputs, censored regression models, g ., millions</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>SparseChem provides fast and accurate machine learning models for biochemical
applications. Especially, the package supports very high-dimensional sparse
inputs, e.g., millions of features and millions of compounds. It is possible to
train classification, regression and censored regression models, or combination
of them from command line. Additionally, the library can be accessed directly
from Python. Source code and documentation is freely available under MIT
License on GitHub.</p>
  </details>
</details>
<details>
  <summary>96. <b>标题：Deep learning-based reconstruction of highly accelerated 3D MRI</b></summary>
  <p><b>编号</b>：[265]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04674</p>
  <p><b>作者</b>：Sangtae Ahn,  Uri Wollner,  Graeme McKinnon,  Isabelle Heukensfeldt Jansen,  Rafi Brada,  Dan Rettmann,  Ty A. Cashen,  John Huston,  J. Kevin DeMarco,  Robert Y. Shih,  Joshua D. Trzasko,  Christopher J. Hardy,  Thomas K. F. Foo</p>
  <p><b>备注</b>：8 pages, 8 figures</p>
  <p><b>关键词</b>：3d mprage brain scan data retrospectively, accelerate brain 3d mri scans, 5 times faster scans compared, reconstructing abdominal lava scan data, maintaining diagnostic image quality</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Purpose: To accelerate brain 3D MRI scans by using a deep learning method for
reconstructing images from highly-undersampled multi-coil k-space data
Methods: DL-Speed, an unrolled optimization architecture with dense
skip-layer connections, was trained on 3D T1-weighted brain scan data to
reconstruct complex-valued images from highly-undersampled k-space data. The
trained model was evaluated on 3D MPRAGE brain scan data
retrospectively-undersampled with a 10-fold acceleration, compared to a
conventional parallel imaging method with a 2-fold acceleration. Scores of SNR,
artifacts, gray/white matter contrast, resolution/sharpness, deep gray-matter,
cerebellar vermis, anterior commissure, and overall quality, on a 5-point
Likert scale, were assessed by experienced radiologists. In addition, the
trained model was tested on retrospectively-undersampled 3D T1-weighted LAVA
(Liver Acquisition with Volume Acceleration) abdominal scan data, and
prospectively-undersampled 3D MPRAGE and LAVA scans in three healthy volunteers
and one, respectively.
Results: The qualitative scores for DL-Speed with a 10-fold acceleration were
higher than or equal to those for the parallel imaging with 2-fold
acceleration. DL-Speed outperformed a compressed sensing method in quantitative
metrics on retrospectively-undersampled LAVA data. DL-Speed was demonstrated to
perform reasonably well on prospectively-undersampled scan data, realizing a
2-5 times reduction in scan time.
Conclusion: DL-Speed was shown to accelerate 3D MPRAGE and LAVA with up to a
net 10-fold acceleration, achieving 2-5 times faster scans compared to
conventional parallel imaging and acceleration, while maintaining diagnostic
image quality and real-time reconstruction. The brain scan data-trained
DL-Speed also performed well when reconstructing abdominal LAVA scan data,
demonstrating versatility of the network.</p>
  </details>
</details>
<details>
  <summary>97. <b>标题：Quantum neural networks force fields generation</b></summary>
  <p><b>编号</b>：[266]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04666</p>
  <p><b>作者</b>：Oriel Kiss,  Francesco Tacchino,  Sofia Vallecorsa,  Ivano Tavernelli</p>
  <p><b>备注</b>：12 pages, 7 figures</p>
  <p><b>关键词</b>：natural science applications via quantum machine learning, thus pointing towards potential quantum advantages, quantum models exhibit larger effective dimension, offer new viable computational paradigms, learning neural network potentials</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Accurate molecular force fields are of paramount importance for the efficient
implementation of molecular dynamics techniques at large scales. In the last
decade, machine learning methods have demonstrated impressive performances in
predicting accurate values for energy and forces when trained on finite size
ensembles generated with ab initio techniques. At the same time, quantum
computers have recently started to offer new viable computational paradigms to
tackle such problems. On the one hand, quantum algorithms may notably be used
to extend the reach of electronic structure calculations. On the other hand,
quantum machine learning is also emerging as an alternative and promising path
to quantum advantage. Here we follow this second route and establish a direct
connection between classical and quantum solutions for learning neural network
potentials. To this end, we design a quantum neural network architecture and
apply it successfully to different molecules of growing complexity. The quantum
models exhibit larger effective dimension with respect to classical
counterparts and can reach competitive performances, thus pointing towards
potential quantum advantages in natural science applications via quantum
machine learning.</p>
  </details>
</details>
<details>
  <summary>98. <b>标题：Attention-effective multiple instance learning on weakly stem cell  colony segmentation</b></summary>
  <p><b>编号</b>：[271]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04606</p>
  <p><b>作者</b>：Novanto Yudistira,  Muthu Subash Kavitha,  Jeny Rajan,  Takio Kurita</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：colonies without using finely labeled samples, image level label without using, like convolution neural network, induced pluripotent stem cell, existing computerized systems relied</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The detection of induced pluripotent stem cell (iPSC) colonies often needs
the precise extraction of the colony features. However, existing computerized
systems relied on segmentation of contours by preprocessing for classifying the
colony conditions were task-extensive. To maximize the efficiency in
categorizing colony conditions, we propose a multiple instance learning (MIL)
in weakly supervised settings. It is designed in a single model to produce weak
segmentation and classification of colonies without using finely labeled
samples. As a single model, we employ a U-net-like convolution neural network
(CNN) to train on binary image-level labels for MIL colonies classification.
Furthermore, to specify the object of interest we used a simple post-processing
method. The proposed approach is compared over conventional methods using
five-fold cross-validation and receiver operating characteristic (ROC) curve.
The maximum accuracy of the MIL-net is 95%, which is 15 % higher than the
conventional methods. Furthermore, the ability to interpret the location of the
iPSC colonies based on the image level label without using a pixel-wise ground
truth image is more appealing and cost-effective in colony condition
recognition.</p>
  </details>
</details>
<details>
  <summary>99. <b>标题：Data-driven detector signal characterization with constrained bottleneck  autoencoders</b></summary>
  <p><b>编号</b>：[272]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04604</p>
  <p><b>作者</b>：César Jesús Valls,  Thorsten Lux,  Federico Sánchez</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：underlying unknown detector response model directly, made introducing modeling errors, waveform toy model, constrained bottleneck autoencoders, build parametric maps</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A common technique in high energy physics is to characterize the response of
a detector by means of models tunned to data which build parametric maps from
the physical parameters of the system to the expected signal of the detector.
When the underlying model is unknown it is difficult to apply this method, and
often, simplifying assumptions are made introducing modeling errors. In this
article, using a waveform toy model we present how deep learning in the form of
constrained bottleneck autoencoders can be used to learn the underlying unknown
detector response model directly from data. The results show that excellent
performance results can be achieved even when the signals are significantly
affected by random noise. The trained algorithm can be used simultaneously to
perform estimations on the physical parameters of the model, simulate the
detector response with high fidelity and to denoise detector signals.</p>
  </details>
</details>
<details>
  <summary>100. <b>标题：Unsupervised Domain Adaptation across FMCW Radar Configurations Using  Margin Disparity Discrepancy</b></summary>
  <p><b>编号</b>：[273]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04588</p>
  <p><b>作者</b>：Rodrigo Hernangomez,  Igor Bjelakovic,  Lorenzo Servadei,  Slawomir Stanczak</p>
  <p><b>备注</b>：Submitted to conference</p>
  <p><b>关键词</b>：unsupervised domain adaptation across radar configurations, learning human activity classification using frequency, machine learning algorithms constitute one, margin disparity discrepancy, fewshot supervised approaches</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Commercial radar sensing is gaining relevance and machine learning algorithms
constitute one of the key components that are enabling the spread of this radio
technology into areas like surveillance or healthcare. However, radar datasets
are still scarce and generalization cannot be yet achieved for all radar
systems, environment conditions or design parameters. A certain degree of fine
tuning is, therefore, usually required to deploy machine-learning-enabled radar
applications. In this work, we consider the problem of unsupervised domain
adaptation across radar configurations in the context of deep-learning human
activity classification using frequency-modulated continuous-wave. For that, we
focus on the theory-inspired technique of Margin Disparity Discrepancy, which
has already been proved successful in the area of computer vision. Our
experiments extend this technique to radar data, achieving a comparable
accuracy to fewshot supervised approaches for the same classification problem.</p>
  </details>
</details>
<details>
  <summary>101. <b>标题：The Flag Median and FlagIRLS</b></summary>
  <p><b>编号</b>：[284]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04437</p>
  <p><b>作者</b>：Nathan Mankovich,  Emily King,  Chris Peterson,  Michael Kirby</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：produce highly imperfect clustering, common machine learning algorithms, $\ ell_2 $- median, $\ ell_2 $- median, ucf youtube action dataset</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Finding prototypes (e.g., mean and median) for a dataset is central to a
number of common machine learning algorithms. Subspaces have been shown to
provide useful, robust representations for datasets of images, videos and more.
Since subspaces correspond to points on a Grassmann manifold, one is led to
consider the idea of a subspace prototype for a Grassmann-valued dataset. While
a number of different subspace prototypes have been described, the calculation
of some of these prototypes has proven to be computationally expensive while
other prototypes are affected by outliers and produce highly imperfect
clustering on noisy data. This work proposes a new subspace prototype, the flag
median, and introduces the FlagIRLS algorithm for its calculation. We provide
evidence that the flag median is robust to outliers and can be used effectively
in algorithms like Linde-Buzo-Grey (LBG) to produce improved clusterings on
Grassmannians. Numerical experiments include a synthetic dataset, the MNIST
handwritten digits dataset, the Mind's Eye video dataset and the UCF YouTube
action dataset. The flag median is compared the other leading algorithms for
computing prototypes on the Grassmannian, namely, the $\ell_2$-median and to
the flag mean. We find that using FlagIRLS to compute the flag median converges
in $4$ iterations on a synthetic dataset. We also see that Grassmannian LBG
with a codebook size of $20$ and using the flag median produces at least a
$10\%$ improvement in cluster purity over Grassmannian LBG using the flag mean
or $\ell_2$-median on the Mind's Eye dataset.</p>
  </details>
</details>
<details>
  <summary>102. <b>标题：Harmonicity Plays a Critical Role in DNN Based Versus in  Biologically-Inspired Monaural Speech Segregation Systems</b></summary>
  <p><b>编号</b>：[285]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04420</p>
  <p><b>作者</b>：Rahil Parikh (1),  Ilya Kavalerov (2),  Carol Espy-Wilson (1),  Shihab Shamma (1) ((1) Institute for Systems Research, University of Maryland, (2) Google Inc.)</p>
  <p><b>备注</b>：5 pages, IEEE International Conference on Acoustics, Speech, & Signal Processing (ICASSP), 2022</p>
  <p><b>关键词</b>：natural speech versus slightly manipulated inharmonic speech, even slightly harmonically jittered, dnn algorithms deviate markedly, harmonic jitter degrades performance, dnn )- based models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent advancements in deep learning have led to drastic improvements in
speech segregation models. Despite their success and growing applicability, few
efforts have been made to analyze the underlying principles that these networks
learn to perform segregation. Here we analyze the role of harmonicity on two
state-of-the-art Deep Neural Networks (DNN)-based models- Conv-TasNet and
DPT-Net. We evaluate their performance with mixtures of natural speech versus
slightly manipulated inharmonic speech, where harmonics are slightly frequency
jittered. We find that performance deteriorates significantly if one source is
even slightly harmonically jittered, e.g., an imperceptible 3% harmonic jitter
degrades performance of Conv-TasNet from 15.4 dB to 0.70 dB. Training the model
on inharmonic speech does not remedy this sensitivity, instead resulting in
worse performance on natural speech mixtures, making inharmonicity a powerful
adversarial factor in DNN models. Furthermore, additional analyses reveal that
DNN algorithms deviate markedly from biologically inspired algorithms that rely
primarily on timing cues and not harmonicity to segregate speech.</p>
  </details>
</details>
<details>
  <summary>103. <b>标题：KPF-AE-LSTM: A Deep Probabilistic Model for Net-Load Forecasting in High  Solar Scenarios</b></summary>
  <p><b>编号</b>：[287]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04401</p>
  <p><b>作者</b>：Deepthi Sen,  Indrasis Chakraborty,  Soumya Kundu,  Andrew P. Reiman,  Ian Beil,  Andy Eiden</p>
  <p><b>备注</b>：presently under review at a IEEE PES journal</p>
  <p><b>关键词</b>：model performance across various solar penetration levels, 24 \, hr ahead ),, g ., 15 \, min, various solar penetration levels, meter solar penetration within</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>With the expected rise in behind-the-meter solar penetration within the
distribution networks, there is a need to develop time-series forecasting
methods that can reliably predict the net-load, accurately quantifying its
uncertainty and variability. This paper presents a deep learning method to
generate probabilistic forecasts of day-ahead net-load at 15-min resolution, at
various solar penetration levels. Our proposed deep-learning based architecture
utilizes the dimensional reduction, from a higher-dimensional input to a
lower-dimensional latent space, via a convolutional Autoencoder (AE). The
extracted features from AE are then utilized to generate probability
distributions across the latent space, by passing the features through a
kernel-embedded Perron-Frobenius (kPF) operator. Finally, long short-term
memory (LSTM) layers are used to synthesize time-series probability
distributions of the forecasted net-load, from the latent space distributions.
The models are shown to deliver superior forecast performance (as per several
metrics), as well as maintain superior training efficiency, in comparison to
existing benchmark models. Detailed analysis is carried out to evaluate the
model performance across various solar penetration levels (up to 50\%),
prediction horizons (e.g., 15\,min and 24\,hr ahead), and aggregation level of
houses, as well as its robustness against missing measurements.</p>
  </details>
</details>
<details>
  <summary>104. <b>标题：Embedding Temporal Convolutional Networks for Energy-Efficient PPG-Based  Heart Rate Monitoring</b></summary>
  <p><b>编号</b>：[290]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04396</p>
  <p><b>作者</b>：Alessio Burrello,  Daniele Jahier Pagliari,  Pierangelo Maria Rapa,  Matilde Semilia,  Matteo Risso,  Tommaso Polonelli,  Massimo Poncino,  Luca Benini,  Simone Benatti</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：selects among multiple hr estimators depending, computationally lightweight yet robust deep learning, leveraging neural architecture search, 84 beats per minute, several data fusion techniques</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Photoplethysmography (PPG) sensors allow for non-invasive and comfortable
heart-rate (HR) monitoring, suitable for compact wrist-worn devices.
Unfortunately, Motion Artifacts (MAs) severely impact the monitoring accuracy,
causing high variability in the skin-to-sensor interface. Several data fusion
techniques have been introduced to cope with this problem, based on combining
PPG signals with inertial sensor data. Until know, both commercial and
reasearch solutions are computationally efficient but not very robust, or
strongly dependent on hand-tuned parameters, which leads to poor generalization
performance. % In this work, we tackle these limitations by proposing a
computationally lightweight yet robust deep learning-based approach for
PPG-based HR estimation. Specifically, we derive a diverse set of Temporal
Convolutional Networks (TCN) for HR estimation, leveraging Neural Architecture
Search (NAS). Moreover, we also introduce ActPPG, an adaptive algorithm that
selects among multiple HR estimators depending on the amount of MAs, to improve
energy efficiency. We validate our approaches on two benchmark datasets,
achieving as low as 3.84 Beats per Minute (BPM) of Mean Absolute Error (MAE) on
PPGDalia, which outperforms the previous state-of-the-art. Moreover, we deploy
our models on a low-power commercial microcontroller (STM32L4), obtaining a
rich set of Pareto optimal solutions in the complexity vs. accuracy space.</p>
  </details>
</details>
<details>
  <summary>105. <b>标题：Structural Learning of Simple Staged Trees</b></summary>
  <p><b>编号</b>：[291]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04390</p>
  <p><b>作者</b>：Manuele Leonelli,  Gherardo Varando</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：learned simple staged trees often outperform bayesian networks, categorical random vectors whose graph represents non, symmetric conditional independences via vertex coloring, bayesian networks faithfully represent, first structural learning algorithms</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Bayesian networks faithfully represent the symmetric conditional
independences existing between the components of a random vector. Staged trees
are an extension of Bayesian networks for categorical random vectors whose
graph represents non-symmetric conditional independences via vertex coloring.
However, since they are based on a tree representation of the sample space, the
underlying graph becomes cluttered and difficult to visualize as the number of
variables increases. Here we introduce the first structural learning algorithms
for the class of simple staged trees, entertaining a compact coalescence of the
underlying tree from which non-symmetric independences can be easily read. We
show that data-learned simple staged trees often outperform Bayesian networks
in model fit and illustrate how the coalesced graph is used to identify
non-symmetric conditional independences.</p>
  </details>
</details>
<details>
  <summary>106. <b>标题：Deep Learning for Sleep Stages Classification: Modified Rectified Linear  Unit Activation Function and Modified Orthogonal Weight Initialisation</b></summary>
  <p><b>编号</b>：[292]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04371</p>
  <p><b>作者</b>：Akriti Bhusal,  Abeer Alsadoon,  P.W.C. Prasad,  Nada Alsalami,  Tarik A. Rashid</p>
  <p><b>备注</b>：20 pages</p>
  <p><b>关键词</b>：ucd ), beth israel deaconess medical center mit database, proposed system uses leaky rectified linear unit, proposed system called enhanced sleep stage classification system, bih ), sleep european data format, diagnosed using convolutional neural network classifier</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Background and Aim: Each stage of sleep can affect human health, and not
getting enough sleep at any stage may lead to sleep disorder like parasomnia,
apnea, insomnia, etc. Sleep-related diseases could be diagnosed using
Convolutional Neural Network Classifier. However, this classifier has not been
successfully implemented into sleep stage classification systems due to high
complexity and low accuracy of classification. The aim of this research is to
increase the accuracy and reduce the learning time of Convolutional Neural
Network Classifier. Methodology: The proposed system used a modified Orthogonal
Convolutional Neural Network and a modified Adam optimisation technique to
improve the sleep stage classification accuracy and reduce the gradient
saturation problem that occurs due to sigmoid activation function. The proposed
system uses Leaky Rectified Linear Unit (ReLU) instead of sigmoid activation
function as an activation function. Results: The proposed system called
Enhanced Sleep Stage Classification system (ESSC) used six different databases
for training and testing the proposed model on the different sleep stages.
These databases are University College Dublin database (UCD), Beth Israel
Deaconess Medical Center MIT database (MIT-BIH), Sleep European Data Format
(EDF), Sleep EDF Extended, Montreal Archive of Sleep Studies (MASS), and Sleep
Heart Health Study (SHHS). Our results show that the gradient saturation
problem does not exist anymore. The modified Adam optimiser helps to reduce the
noise which in turn result in faster convergence time. Conclusion: The
convergence speed of ESSC is increased along with better classification
accuracy compared to the state of art solution.</p>
  </details>
</details>
<details>
  <summary>107. <b>标题：MICDIR: Multi-scale Inverse-consistent Deformable Image Registration  using UNetMSS with Self-Constructing Graph Latent</b></summary>
  <p><b>编号</b>：[293]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04317</p>
  <p><b>作者</b>：Soumick Chatterjee,  Himanshi Bajaj,  Istiyak H. Siddiquee,  Nandish Bandi Subbarayappa,  Steve Simon,  Suraj Bangalore Shashidhar,  Oliver Speck,  Andreas Nürnberge</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：tackle various complex medical image processing problems, proposed method achieved significant improvements, deep learning based techniques, proposed using deep learning, including medical image registration</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Image registration is the process of bringing different images into a common
coordinate system - a technique widely used in various applications of computer
vision, such as remote sensing, image retrieval, and most commonly in medical
imaging. Deep Learning based techniques have been applied successfully to
tackle various complex medical image processing problems, including medical
image registration. Over the years, several image registration techniques have
been proposed using deep learning. Deformable image registration techniques
such as Voxelmorph have been successful in capturing finer changes and
providing smoother deformations. However, Voxelmorph, as well as ICNet and
FIRE, do not explicitly encode global dependencies (i.e. the overall anatomical
view of the supplied image) and therefore can not track large deformations. In
order to tackle the aforementioned problems, this paper extends the Voxelmorph
approach in three different ways. To improve the performance in case of small
as well as large deformations, supervision of the model at different
resolutions have been integrated using a multi-scale UNet. To support the
network to learn and encode the minute structural co-relations of the given
image-pairs, a self-constructing graph network (SCGNet) has been used as the
latent of the multi-scale UNet - which can improve the learning process of the
model and help the model to generalise better. And finally, to make the
deformations inverse-consistent, cycle consistency loss has been employed. On
the task of registration of brain MRIs, the proposed method achieved
significant improvements over ANTs and VoxelMorph, obtaining a Dice score of
0.8013$\pm$0.0243 for intramodal and 0.6211$\pm$0.0309 for intermodal, while
VoxelMorph achieved 0.7747$\pm$0.0260 and 0.6071$\pm$0.0510, respectively.</p>
  </details>
</details>
<details>
  <summary>108. <b>标题：PyNET-QxQ: A Distilled PyNET for QxQ Bayer Pattern Demosaicing in CMOS  Image Sensor</b></summary>
  <p><b>编号</b>：[294]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04314</p>
  <p><b>作者</b>：Minhyeok Cho,  Haechang Lee,  Hyunwoo Je,  Kijeong Kim,  Dongil Ryu,  Jinsu Kim,  Jonghyun Bae,  Albert No</p>
  <p><b>备注</b>：in review</p>
  <p><b>关键词</b>：recent mobile cameras adopt non, qxq despite significant parameter reductions, based isp models mainly focus, mobile cameras produce high, weighted isp explicitly designed</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The deep learning-based ISP models for mobile cameras produce high-quality
images comparable to the professional DSLR camera. However, many of them are
computationally expensive, which may not be appropriate for mobile
environments. Also, the recent mobile cameras adopt non-Bayer CFAs (e.g., Quad
Bayer, Nona Bayer, and QxQ Bayer) to improve image quality; however, most deep
learning-based ISP models mainly focus on standard Bayer CFA. In this work, we
propose PyNET-QxQ based on PyNET, a light-weighted ISP explicitly designed for
the QxQ CFA pattern. The number of parameters of PyNET-QxQ is less than 2.5% of
PyNET. We also introduce a novel knowledge distillation technique, progressive
distillation, to train the compressed network effectively. Finally, experiments
with QxQ images (obtained by an actual QxQ camera sensor, under development)
demonstrate the outstanding performance of PyNET-QxQ despite significant
parameter reductions.</p>
  </details>
</details>
<details>
  <summary>109. <b>标题：Breast cancer detection using artificial intelligence techniques: A  systematic literature review</b></summary>
  <p><b>编号</b>：[296]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04308</p>
  <p><b>作者</b>：Ali Bou Nassif,  Manar Abu Talib,  Qassim Nasir,  Yaman Afadar,  Omar Elgendy</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：systematically reviewed previous work done, breast cancer using genetic sequencing, national breast cancer foundation, important features affecting detection, detected using genes</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Cancer is one of the most dangerous diseases to humans, and yet no permanent
cure has been developed for it. Breast cancer is one of the most common cancer
types. According to the National Breast Cancer foundation, in 2020 alone, more
than 276,000 new cases of invasive breast cancer and more than 48,000
non-invasive cases were diagnosed in the US. To put these figures in
perspective, 64% of these cases are diagnosed early in the disease's cycle,
giving patients a 99% chance of survival. Artificial intelligence and machine
learning have been used effectively in detection and treatment of several
dangerous diseases, helping in early diagnosis and treatment, and thus
increasing the patient's chance of survival. Deep learning has been designed to
analyze the most important features affecting detection and treatment of
serious diseases. For example, breast cancer can be detected using genes or
histopathological imaging. Analysis at the genetic level is very expensive, so
histopathological imaging is the most common approach used to detect breast
cancer. In this research work, we systematically reviewed previous work done on
detection and treatment of breast cancer using genetic sequencing or
histopathological imaging with the help of deep learning and machine learning.
We also provide recommendations to researchers who will work in this field</p>
  </details>
</details>
<details>
  <summary>110. <b>标题：Towards performant and reliable undersampled MR reconstruction via  diffusion model sampling</b></summary>
  <p><b>编号</b>：[304]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04292</p>
  <p><b>作者</b>：Cheng Peng,  Pengfei Guo,  S. Kevin Zhou,  Vishal Patel,  Rama Chellappa</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：sampled acquisition promises faster scanning time, explicitly visualize different potential reconstruction solutions, proposed diffuserecon achieves sota performances reconstructing, approaches leverage deep neural networks, approaches achieve impressive performances</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Magnetic Resonance (MR) image reconstruction from under-sampled acquisition
promises faster scanning time. To this end, current State-of-The-Art (SoTA)
approaches leverage deep neural networks and supervised training to learn a
recovery model. While these approaches achieve impressive performances, the
learned model can be fragile on unseen degradation, e.g. when given a different
acceleration factor. These methods are also generally deterministic and provide
a single solution to an ill-posed problem; as such, it can be difficult for
practitioners to understand the reliability of the reconstruction. We introduce
DiffuseRecon, a novel diffusion model-based MR reconstruction method.
DiffuseRecon guides the generation process based on the observed signals and a
pre-trained diffusion model, and does not require additional training on
specific acceleration factors. DiffuseRecon is stochastic in nature and
generates results from a distribution of fully-sampled MR images; as such, it
allows us to explicitly visualize different potential reconstruction solutions.
Lastly, DiffuseRecon proposes an accelerated, coarse-to-fine Monte-Carlo
sampling scheme to approximate the most likely reconstruction candidate. The
proposed DiffuseRecon achieves SoTA performances reconstructing from raw
acquisition signals in fastMRI and SKM-TEA.</p>
  </details>
</details>
<details>
  <summary>111. <b>标题：Self-supervised learning for analysis of temporal and morphological drug  effects in cancer cell imaging data</b></summary>
  <p><b>编号</b>：[306]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04289</p>
  <p><b>作者</b>：Andrei Dmitrenko,  Mauro M. Masiero,  Nicola Zamboni</p>
  <p><b>备注</b>：Accepted to MIDL 2022 conference. 17 pages, 12 figures, 3 tables</p>
  <p><b>关键词</b>：different experimental conditions using imaging data, identify clusters allowing annotation, 2d cancer cell cultures, morphological phenotypic effects caused, foster transfer learning applications</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this work, we propose two novel methodologies to study temporal and
morphological phenotypic effects caused by different experimental conditions
using imaging data. As a proof of concept, we apply them to analyze drug
effects in 2D cancer cell cultures. We train a convolutional autoencoder on 1M
images dataset with random augmentations and multi-crops to use as feature
extractor. We systematically compare it to the pretrained state-of-the-art
models. We further use the feature extractor in two ways. First, we apply
distance-based analysis and dynamic time warping to cluster temporal patterns
of 31 drugs. We identify clusters allowing annotation of drugs as having
cytotoxic, cytostatic, mixed or no effect. Second, we implement an
adversarial/regularized learning setup to improve classification of 31 drugs
and visualize image regions that contribute to the improvement. We increase
top-3 classification accuracy by 8% on average and mine examples of
morphological feature importance maps. We provide the feature extractor and the
weights to foster transfer learning applications in biology. We also discuss
utility of other pretrained models and applicability of our methods to other
types of biomedical data.</p>
  </details>
</details>
<h1>人工智能</h1>
<details>
  <summary>1. <b>标题：Learning from Physical Human Feedback: An Object-Centric One-Shot  Adaptation Method</b></summary>
  <p><b>编号</b>：[2]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04951</p>
  <p><b>作者</b>：Alvin Shek,  Rui Chen,  Changliu Liu</p>
  <p><b>备注</b>：Submitted to IROS</p>
  <p><b>关键词</b>：existing methods either require repeated episodes, assume prior known reward features, produces new behaviors never seen, either correct undesirable behavior, cheap synthetic data instead</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>For robots to be effectively deployed in novel environments and tasks, they
must be able to understand the feedback expressed by humans during
intervention. This can either correct undesirable behavior or indicate
additional preferences. Existing methods either require repeated episodes of
interactions or assume prior known reward features, which is data-inefficient
and can hardly transfer to new tasks. We relax these assumptions by describing
human tasks in terms of object-centric sub-tasks and interpreting physical
interventions in relation to specific objects. Our method, Object Preference
Adaptation (OPA), is composed of two key stages: 1) pre-training a base policy
to produce a wide variety of behaviors, and 2) online-updating only certain
weights in the model according to human feedback. The key to our fast, yet
simple adaptation is that general interaction dynamics between agents and
objects are fixed, and only object-specific preferences are updated. Our
adaptation occurs online, requires only one human intervention (one-shot), and
produces new behaviors never seen during training. Trained on cheap synthetic
data instead of expensive human demonstrations, our policy demonstrates
impressive adaptation to human perturbations on challenging, realistic tasks in
our user study. Videos, code, and supplementary material provided.</p>
  </details>
</details>
<details>
  <summary>2. <b>标题：Data-Efficient Structured Pruning via Submodular Optimization</b></summary>
  <p><b>编号</b>：[5]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04940</p>
  <p><b>作者</b>：Marwa El Halabi,  Suraj Srinivas,  Simon Lacoste-Julien</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：trained neural networks without significantly affecting, involves removing redundant regular regions, method outperforms popular baseline methods, efficient structured pruning method based, current structured pruning methods</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Structured pruning is an effective approach for compressing large pre-trained
neural networks without significantly affecting their performance, which
involves removing redundant regular regions of weights. However, current
structured pruning methods are highly empirical in nature, do not provide any
theoretical guarantees, and often require fine-tuning, which makes them
inapplicable in the limited-data regime. We propose a principled data-efficient
structured pruning method based on submodular optimization. In particular, for
a given layer, we select neurons/channels to prune and corresponding new
weights for the next layer, that minimize the change in the next layer's input
induced by pruning. We show that this selection problem is a weakly submodular
maximization problem, thus it can be provably approximated using an efficient
greedy algorithm. Our method is one of the few in the literature that uses only
a limited-number of training data and no labels. Our experimental results
demonstrate that our method outperforms popular baseline methods in various
one-shot pruning settings.</p>
  </details>
</details>
<details>
  <summary>3. <b>标题：Investigation of Factorized Optical Flows as Mid-Level Representations</b></summary>
  <p><b>编号</b>：[10]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04927</p>
  <p><b>作者</b>：Hsuan-Kung Yang,  Tsu-Ching Hsiao,  Ting-Hsuan Liao,  Hsu-Shen Liu,  Li-Yuan Tsao,  Tzu-Wen Wang,  Shan-Ya Yang,  Yu-Wen Chen,  Huang-Ru Liao,  Chun-Yi Lee</p>
  <p><b>备注</b>：This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible</p>
  <p><b>关键词</b>：modular learning based robotic frameworks, deep reinforcement learning agents, incorporating factorized flow maps, factorized optical flow maps, factorized flow maps</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we introduce a new concept of incorporating factorized flow
maps as mid-level representations, for bridging the perception and the control
modules in modular learning based robotic frameworks. To investigate the
advantages of factorized flow maps and examine their interplay with the other
types of mid-level representations, we further develop a configurable
framework, along with four different environments that contain both static and
dynamic objects, for analyzing the impacts of factorized optical flow maps on
the performance of deep reinforcement learning agents. Based on this framework,
we report our experimental results on various scenarios, and offer a set of
analyses to justify our hypothesis. Finally, we validate flow factorization in
real world scenarios.</p>
  </details>
</details>
<details>
  <summary>4. <b>标题：The Severity Prediction of The Binary And Multi-Class Cardiovascular  Disease -- A Machine Learning-Based Fusion Approach</b></summary>
  <p><b>编号</b>：[13]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04921</p>
  <p><b>作者</b>：Hafsa Binte Kibria,  Abdul Matin</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：mainly health care industry contains many data consisting, algorithms like artificial neural network, save many lives using, different test training ratios, weighted score fusion approach</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In today's world, a massive amount of data is available in almost every
sector. This data has become an asset as we can use this enormous amount of
data to find information. Mainly health care industry contains many data
consisting of patient and disease-related information. By using the machine
learning technique, we can look for hidden data patterns to predict various
diseases. Recently CVDs, or cardiovascular disease, have become a leading cause
of death around the world. The number of death due to CVDs is frightening. That
is why many researchers are trying their best to design a predictive model that
can save many lives using the data mining model. In this research, some fusion
models have been constructed to diagnose CVDs along with its severity. Machine
learning(ML) algorithms like artificial neural network, SVM, logistic
regression, decision tree, random forest, and AdaBoost have been applied to the
heart disease dataset to predict disease. Randomoversampler was implemented
because of the class imbalance in multiclass classification. To improve the
performance of classification, a weighted score fusion approach was taken. At
first, the models were trained. After training, two algorithms' decision was
combined using a weighted sum rule. A total of three fusion models have been
developed from the six ML algorithms. The results were promising in the
performance parameter. The proposed approach has been experimented with
different test training ratios for binary and multiclass classification
problems, and for both of them, the fusion models performed well. The highest
accuracy for multiclass classification was found as 75%, and it was 95% for
binary. The code can be found in :
this https URL</p>
  </details>
</details>
<details>
  <summary>5. <b>标题：Pose Guided Multi-person Image Generation From Text</b></summary>
  <p><b>编号</b>：[18]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04907</p>
  <p><b>作者</b>：Soon Yau Cheong,  Armin Mustafa,  Andrew Gilbert</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：generate high quality images, person images accurately representing, proposed keypoint pose encoding, create high fidelity full, low dimensional representation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Transformers have recently been shown to generate high quality images from
texts. However, existing methods struggle to create high fidelity full-body
images, especially multiple people. A person's pose has a high degree of
freedom that is difficult to describe using words only; this creates errors in
the generated image, such as incorrect body proportions and pose. We propose a
pose-guided text-to-image model, using pose as an additional input constraint.
Using the proposed Keypoint Pose Encoding (KPE) to encode human pose into low
dimensional representation, our model can generate novel multi-person images
accurately representing the pose and text descriptions provided, with minimal
errors. We demonstrate that KPE is invariant to changes in the target image
domain and image resolution; we show results on the Deepfashion dataset and
create a new multi-person Deepfashion dataset to demonstrate the
multi-capabilities of our approach.</p>
  </details>
</details>
<details>
  <summary>6. <b>标题：What Matters For Meta-Learning Vision Regression Tasks?</b></summary>
  <p><b>编号</b>：[19]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04905</p>
  <p><b>作者</b>：Ning Gao,  Hanna Ziesche,  Ngo Anh Vien,  Michael Volpp,  Gerhard Neumann</p>
  <p><b>备注</b>：Accepted at CVPR 2022</p>
  <p><b>关键词</b>：various deep learning techniques commonly used, paper makes two main contributions, category level vision regression tasks, design two new types, exhaustively evaluate common meta</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Meta-learning is widely used in few-shot classification and function
regression due to its ability to quickly adapt to unseen tasks. However, it has
not yet been well explored on regression tasks with high dimensional inputs
such as images. This paper makes two main contributions that help understand
this barely explored area. \emph{First}, we design two new types of
cross-category level vision regression tasks, namely object discovery and pose
estimation of unprecedented complexity in the meta-learning domain for computer
vision. To this end, we (i) exhaustively evaluate common meta-learning
techniques on these tasks, and (ii) quantitatively analyze the effect of
various deep learning techniques commonly used in recent meta-learning
algorithms in order to strengthen the generalization capability: data
augmentation, domain randomization, task augmentation and meta-regularization.
Finally, we (iii) provide some insights and practical recommendations for
training meta-learning algorithms on vision regression tasks. \emph{Second}, we
propose the addition of functional contrastive learning (FCL) over the task
representations in Conditional Neural Processes (CNPs) and train in an
end-to-end fashion. The experimental results show that the results of prior
work are misleading as a consequence of a poor choice of the loss function as
well as too small meta-training sets. Specifically, we find that CNPs
outperform MAML on most tasks without fine-tuning. Furthermore, we observe that
naive task augmentation without a tailored design results in underfitting.</p>
  </details>
</details>
<details>
  <summary>7. <b>标题：Computing unsatisfiable cores for LTLf specifications</b></summary>
  <p><b>编号</b>：[42]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04834</p>
  <p><b>作者</b>：Marco Roveri,  Claudio Di Ciccio,  Chiara Di Francescomarino,  Chiara Ghidini</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：several studies approached, reactive synthesis )., many application domains, g ., planning, business process management</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Linear-time temporal logic on finite traces (LTLf) is rapidly becoming a
de-facto standard to produce specifications in many application domains (e.g.,
planning, business process management, run-time monitoring, reactive
synthesis). Several studies approached the respective satisfiability problem.
In this paper, we investigate the problem of extracting the unsatisfiable core
in LTLf specifications. We provide four algorithms for extracting an
unsatisfiable core leveraging the adaptation of state-of-the-art approaches to
LTLf satisfiability checking. We implement the different approaches within the
respective tools and carry out an experimental evaluation on a set of reference
benchmarks, restricting to the unsatisfiable ones. The results show the
feasibility, effectiveness, and complementarities of the different algorithms
and tools.</p>
  </details>
</details>
<details>
  <summary>8. <b>标题：No Efficient Disjunction or Conjunction of Switch-Lists</b></summary>
  <p><b>编号</b>：[60]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04788</p>
  <p><b>作者</b>：Stefan Mengel</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：representation size exponentially, lists also leads, negated without, two switch, since switch</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>It is shown that disjunction of two switch-lists can blow up the
representation size exponentially. Since switch-lists can be negated without
any increase in size, this shows that conjunction of switch-lists also leads to
an exponential blow-up in general.</p>
  </details>
</details>
<details>
  <summary>9. <b>标题：How many Observations are Enough? Knowledge Distillation for Trajectory  Forecasting</b></summary>
  <p><b>编号</b>：[63]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04781</p>
  <p><b>作者</b>：Alessio Monti,  Angelo Porrello,  Simone Calderara,  Pasquale Coscia,  Lamberto Ballan,  Rita Cucchiara</p>
  <p><b>备注</b>：Accepted by CVPR 2022</p>
  <p><b>关键词</b>：common trajectory forecasting datasets highlight, common schema neglects critical traits, input trajectories involves machine perception, properly defined teacher supervision allows, fragmentation errors may accumulate</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Accurate prediction of future human positions is an essential task for modern
video-surveillance systems. Current state-of-the-art models usually rely on a
"history" of past tracked locations (e.g., 3 to 5 seconds) to predict a
plausible sequence of future locations (e.g., up to the next 5 seconds). We
feel that this common schema neglects critical traits of realistic
applications: as the collection of input trajectories involves machine
perception (i.e., detection and tracking), incorrect detection and
fragmentation errors may accumulate in crowded scenes, leading to tracking
drifts. On this account, the model would be fed with corrupted and noisy input
data, thus fatally affecting its prediction performance.
In this regard, we focus on delivering accurate predictions when only few
input observations are used, thus potentially lowering the risks associated
with automatic perception. To this end, we conceive a novel distillation
strategy that allows a knowledge transfer from a teacher network to a student
one, the latter fed with fewer observations (just two ones). We show that a
properly defined teacher supervision allows a student network to perform
comparably to state-of-the-art approaches that demand more observations.
Besides, extensive experiments on common trajectory forecasting datasets
highlight that our student network better generalizes to unseen scenarios.</p>
  </details>
</details>
<details>
  <summary>10. <b>标题：Explainable Machine Learning for Predicting Homicide Clearance in the  United States</b></summary>
  <p><b>编号</b>：[67]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04768</p>
  <p><b>作者</b>：Gian Maria Campedelli</p>
  <p><b>备注</b>：41 pages, 18 figures</p>
  <p><b>关键词</b>：two theoretical perspectives emerged, consistently predicting investigation outcomes, developing ad hoc state, predicting cleared homicides country, predicting clearance outcomes state</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Purpose: To explore the potential of Explainable Machine Learning in the
prediction and detection of drivers of cleared homicides at the national- and
state-levels in the United States.
Methods: First, nine algorithmic approaches are compared to assess the best
performance in predicting cleared homicides country-wise, using data from the
Murder Accountability Project. The most accurate algorithm among all (XGBoost)
is then used for predicting clearance outcomes state-wise. Second, SHAP, a
framework for Explainable Artificial Intelligence, is employed to capture the
most important features in explaining clearance patterns both at the national
and state levels.
Results: At the national level, XGBoost demonstrates to achieve the best
performance overall. Substantial predictive variability is detected state-wise.
In terms of explainability, SHAP highlights the relevance of several features
in consistently predicting investigation outcomes. These include homicide
circumstances, weapons, victims' sex and race, as well as number of involved
offenders and victims.
Conclusions: Explainable Machine Learning demonstrates to be a helpful
framework for predicting homicide clearance. SHAP outcomes suggest a more
organic integration of the two theoretical perspectives emerged in the
literature. Furthermore, jurisdictional heterogeneity highlights the importance
of developing ad hoc state-level strategies to improve police performance in
clearing homicides.</p>
  </details>
</details>
<details>
  <summary>11. <b>标题：Machine Learning Methods in Solving the Boolean Satisfiability Problem</b></summary>
  <p><b>编号</b>：[72]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04755</p>
  <p><b>作者</b>：Wenxuan Guo,  Junchi Yan,  Hui-Ling Zhen,  Xijun Li,  Mingxuan Yuan,  Yaohui Jin</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：promising yet challenging research topic, expressive machine learning methods provide, suggest possible future directions, solve large industrial instances, machine learning methods</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper reviews the recent literature on solving the Boolean
satisfiability problem (SAT), an archetypal NP-complete problem, with the help
of machine learning techniques. Despite the great success of modern SAT solvers
to solve large industrial instances, the design of handcrafted heuristics is
time-consuming and empirical. Under the circumstances, the flexible and
expressive machine learning methods provide a proper alternative to solve this
long-standing problem. We examine the evolving ML-SAT solvers from naive
classifiers with handcrafted features to the emerging end-to-end SAT solvers
such as NeuroSAT, as well as recent progress on combinations of existing CDCL
and local search solvers with machine learning methods. Overall, solving SAT
with machine learning is a promising yet challenging research topic. We
conclude the limitations of current works and suggest possible future
directions.</p>
  </details>
</details>
<details>
  <summary>12. <b>标题：System Cards for AI-Based Decision-Making for Public Policy</b></summary>
  <p><b>编号</b>：[73]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04754</p>
  <p><b>作者</b>：Furkan Gursoy,  Ioannis A. Kakadiaris</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：identifying individuals using face recognition, suggested measurement scale indicating whether, proposed system accountability benchmark reflects, 50 criteria organized within, way towards ensuring algorithms</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Decisions in public policy are increasingly being made or assisted by
automated decision-making algorithms. Many of these algorithms process personal
data for tasks such as predicting recidivism, assisting welfare decisions,
identifying individuals using face recognition, and more. While potentially
improving efficiency and effectiveness, such algorithms are not inherently free
from issues such as bias, opaqueness, lack of explainability, maleficence, and
the like. Given that the outcomes of these algorithms have significant impacts
on individuals and society and are open to analysis and contestation after
deployment, such issues must be accounted for before deployment. Formal audits
are a way towards ensuring algorithms that are used in public policy meet the
appropriate accountability standards. This work, based on an extensive analysis
of the literature, proposes a unifying framework for system accountability
benchmark for formal audits of artificial intelligence-based decision-aiding
systems in public policy as well as system cards that serve as scorecards
presenting the outcomes of such audits. The benchmark consists of 50 criteria
organized within a four by four matrix consisting of the dimensions of (i)
data, (ii) model, (iii) code, (iv) system and (a) development, (b) assessment,
(c) mitigation, (d) assurance. Each criterion is described and discussed
alongside a suggested measurement scale indicating whether the evaluations are
to be performed by humans or computers and whether the evaluation outcomes are
binary or on an ordinal scale. The proposed system accountability benchmark
reflects the state-of-the-art developments for accountable systems, serves as a
checklist for future algorithm audits, and paves the way for sequential work as
future research.</p>
  </details>
</details>
<details>
  <summary>13. <b>标题：Visibility-Inspired Models of Touch Sensors for Navigation</b></summary>
  <p><b>编号</b>：[74]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04751</p>
  <p><b>作者</b>：Kshitij Tiwari,  Basak Sakcak,  Prasanna Routray,  Manivannan M.,  Steven M. LaValle</p>
  <p><b>备注</b>：Submitted to IEEE IROS 2022</p>
  <p><b>关键词</b>：mobile robot sensor fusion systems, characterizing unique advantages provided, paper introduces mathematical models, models include contact detection, innovative touch sensor designs</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper introduces mathematical models of touch sensors for mobile
robotics based on visibility. Serving a purpose similar to the pinhole camera
model for computer vision, the introduced models are expected to provide a
useful, idealized characterization of task-relevant information that can be
inferred from their outputs or observations. This allows direct comparisons to
be made between traditional depth sensors, highlighting cases in which touch
sensing may be interchangeable with time of flight or vision sensors, and
characterizing unique advantages provided by touch sensing. The models include
contact detection, compression, load bearing, and deflection. The results could
serve as a basic building block for innovative touch sensor designs for mobile
robot sensor fusion systems.</p>
  </details>
</details>
<details>
  <summary>14. <b>标题：SIERRA: A Modular Framework for Research Automation</b></summary>
  <p><b>编号</b>：[77]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04748</p>
  <p><b>作者</b>：John Harwell,  London Lowmanstone,  Maria Gini</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：real robots ), enabling exact experiment replication, thereby eliminating manual experiment configuration, modern intelligent systems researchers employ, sierra provides reproducible automation independent, result processing via throw</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Modern intelligent systems researchers employ the scientific method: they
form hypotheses about system behavior, and then run experiments using one or
more independent variables to test their hypotheses. We present SIERRA, a novel
framework structured around that idea for accelerating research developments
and improving reproducibility of results. SIERRA makes it easy to quickly
specify the independent variable(s) for an experiment, generate experimental
inputs, automatically run the experiment, and process the results to generate
deliverables such as graphs and videos. SIERRA provides reproducible automation
independent of the execution environment (HPC hardware, real robots, etc.) and
targeted platform (arbitrary simulator or real robots), enabling exact
experiment replication (up to the limit of the execution environment and
platform). It employs a deeply modular approach that allows easy customization
and extension of automation for the needs of individual researchers, thereby
eliminating manual experiment configuration and result processing via
throw-away scripts.</p>
  </details>
</details>
<details>
  <summary>15. <b>标题：SkinningNet: Two-Stream Graph Convolutional Neural Network for Skinning  Prediction of Synthetic Characters</b></summary>
  <p><b>编号</b>：[79]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04746</p>
  <p><b>作者</b>：Albert Mosella-Montoro,  Javier Ruiz-Hidalgo</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：stream graph neural network architecture, whereas previous methods pre, skinningnet outperforming current state, aggregator graph convolution, work presents skinningnet</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This work presents SkinningNet, an end-to-end Two-Stream Graph Neural Network
architecture that computes skinning weights from an input mesh and its
associated skeleton, without making any assumptions on shape class and
structure of the provided mesh. Whereas previous methods pre-compute
handcrafted features that relate the mesh and the skeleton or assume a fixed
topology of the skeleton, the proposed method extracts this information in an
end-to-end learnable fashion by jointly learning the best relationship between
mesh vertices and skeleton joints. The proposed method exploits the benefits of
the novel Multi-Aggregator Graph Convolution that combines the results of
different aggregators during the summarizing step of the Message-Passing
scheme, helping the operation to generalize for unseen topologies. Experimental
results demonstrate the effectiveness of the contributions of our novel
architecture, with SkinningNet outperforming current state-of-the-art
alternatives.</p>
  </details>
</details>
<details>
  <summary>16. <b>标题：Modeling and Validating Temporal Rules with Semantic Petri-Net for  Digital Twins</b></summary>
  <p><b>编号</b>：[81]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04741</p>
  <p><b>作者</b>：Han Liu,  Xiaoyu Song,  Ge Gao,  Hehua Zhang,  Yu-Shen Liu,  Ming Gu</p>
  <p><b>备注</b>：Preprint submitted to 29th International Workshop on Intelligent Computing in Engineering (EG-ICE)</p>
  <p><b>关键词</b>：concurrent state changes, combined rule checking, novel temporal modeling, semantic rule checking, semantic rule checking</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Semantic rule checking on RDFS/OWL data has been widely used in the
construction industry. At present, semantic rule checking is mainly performed
on static models. There are still challenges in integrating temporal models and
semantic models for combined rule checking. In this paper, Semantic Petri-Net
(SPN) is proposed as a novel temporal modeling and validating method, which
implements the states and transitions of the Colored Petri-Net directly based
on RDFS and SPARQL, and realizes two-way sharing of knowledge between domain
semantic webs and temporal models in the runtime. Several cases are provided to
demonstrate the possible applications in digital twins with concurrent state
changes and dependencies.</p>
  </details>
</details>
<details>
  <summary>17. <b>标题：Pretrained Domain-Specific Language Model for General Information  Retrieval Tasks in the AEC Domain</b></summary>
  <p><b>编号</b>：[88]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04729</p>
  <p><b>作者</b>：Zhe Zheng,  Xin-Zheng Lu,  Ke-Yin Chen,  Yu-Cheng Zhou,  Jia-Rui Lin</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：based models dramatically outperform traditional methods, including traditional wording embedding models, several widely used dl models, traditional word embedding models, unstructured textual data based</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As an essential task for the architecture, engineering, and construction
(AEC) industry, information retrieval (IR) from unstructured textual data based
on natural language processing (NLP) is gaining increasing attention. Although
various deep learning (DL) models for IR tasks have been investigated in the
AEC domain, it is still unclear how domain corpora and domain-specific
pretrained DL models can improve performance in various IR tasks. To this end,
this work systematically explores the impacts of domain corpora and various
transfer learning techniques on the performance of DL models for IR tasks and
proposes a pretrained domain-specific language model for the AEC domain. First,
both in-domain and close-domain corpora are developed. Then, two types of
pretrained models, including traditional wording embedding models and
BERT-based models, are pretrained based on various domain corpora and transfer
learning strategies. Finally, several widely used DL models for IR tasks are
further trained and tested based on various configurations and pretrained
models. The result shows that domain corpora have opposite effects on
traditional word embedding models for text classification and named entity
recognition tasks but can further improve the performance of BERT-based models
in all tasks. Meanwhile, BERT-based models dramatically outperform traditional
methods in all IR tasks, with maximum improvements of 5.4% and 10.1% in the F1
score, respectively. This research contributes to the body of knowledge in two
ways: 1) demonstrating the advantages of domain corpora and pretrained DL
models and 2) opening the first domain-specific dataset and pretrained language
model for the AEC domain, to the best of our knowledge. Thus, this work sheds
light on the adoption and application of pretrained models in the AEC domain.</p>
  </details>
</details>
<details>
  <summary>18. <b>标题：Language Model-driven Negative Sampling</b></summary>
  <p><b>编号</b>：[96]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04703</p>
  <p><b>作者</b>：Mirza Mohtashim Alam,  Md Rashad Al Hasan Rony,  Semab Ali,  Jens Lehmann,  Sahar Vahdati</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：proposed approach across several benchmark datasets, e ., link prediction, also require negative samples, generating negative sampling considering, generating negative sampling affects</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Knowledge Graph Embeddings (KGEs) encode the entities and relations of a
knowledge graph (KG) into a vector space with a purpose of representation
learning and reasoning for an ultimate downstream task (i.e., link prediction,
question answering). Since KGEs follow closed-world assumption and assume all
the present facts in KGs to be positive (correct), they also require negative
samples as a counterpart for learning process for truthfulness test of existing
triples. Therefore, there are several approaches for creating negative samples
from the existing positive ones through a randomized distribution. This choice
of generating negative sampling affects the performance of the embedding models
as well as their generalization. In this paper, we propose an approach for
generating negative sampling considering the existing rich textual knowledge in
KGs. %The proposed approach is leveraged to cluster other relevant
representations of the entities inside a KG. Particularly, a pre-trained
Language Model (LM) is utilized to obtain the contextual representation of
symbolic entities. Our approach is then capable of generating more meaningful
negative samples in comparison to other state of the art methods. Our
comprehensive evaluations demonstrate the effectiveness of the proposed
approach across several benchmark datasets for like prediction task. In
addition, we show cased our the functionality of our approach on a clustering
task where other methods fall short.</p>
  </details>
</details>
<details>
  <summary>19. <b>标题：ModulE: Module Embedding for Knowledge Graphs</b></summary>
  <p><b>编号</b>：[97]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04702</p>
  <p><b>作者</b>：Jingxuan Chai,  Guangming Shi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：existing methods mainly focus, novel general group theory, build three instantiating models, adopting different module structures, predicting missing links</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Knowledge graph embedding (KGE) has been shown to be a powerful tool for
predicting missing links of a knowledge graph. However, existing methods mainly
focus on modeling relation patterns, while simply embed entities to vector
spaces, such as real field, complex field and quaternion space. To model the
embedding space from a more rigorous and theoretical perspective, we propose a
novel general group theory-based embedding framework for rotation-based models,
in which both entities and relations are embedded as group elements.
Furthermore, in order to explore more available KGE models, we utilize a more
generic group structure, module, a generalization notion of vector space.
Specifically, under our framework, we introduce a more generic embedding
method, ModulE, which projects entities to a module. Following the method of
ModulE, we build three instantiating models: ModulE$_{\mathbb{R},\mathbb{C}}$,
ModulE$_{\mathbb{R},\mathbb{H}}$ and ModulE$_{\mathbb{H},\mathbb{H}}$, by
adopting different module structures. Experimental results show that
ModulE$_{\mathbb{H},\mathbb{H}}$ which embeds entities to a module over
non-commutative ring, achieves state-of-the-art performance on multiple
benchmark datasets.</p>
  </details>
</details>
<details>
  <summary>20. <b>标题：Multi-robot Cooperative Pursuit via Potential Field-Enhanced  Reinforcement Learning</b></summary>
  <p><b>编号</b>：[98]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04700</p>
  <p><b>作者</b>：Zheng Zhang,  Xiaohan Wang,  Qingrui Zhang,  Tianjiang Hu</p>
  <p><b>备注</b>：This paper has been accepted by ICRA 2022</p>
  <p><b>关键词</b>：learning multiple cooperative pursuit strategies, novel hybrid cooperative pursuit algorithm, learn cooperative pursuit policies, pursuit policies either learned, proposed hybrid design outperforms</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>It is of great challenge, though promising, to coordinate collective robots
for hunting an evader in a decentralized manner purely in light of local
observations. In this paper, this challenge is addressed by a novel hybrid
cooperative pursuit algorithm that combines reinforcement learning with the
artificial potential field method. In the proposed algorithm, decentralized
deep reinforcement learning is employed to learn cooperative pursuit policies
that are adaptive to dynamic environments. The artificial potential field
method is integrated into the learning process as predefined rules to improve
the data efficiency and generalization ability. It is shown by numerical
simulations that the proposed hybrid design outperforms the pursuit policies
either learned from vanilla reinforcement learning or designed by the potential
field method. Furthermore, experiments are conducted by transferring the
learned pursuit policies into real-world mobile robots. Experimental results
demonstrate the feasibility and potential of the proposed algorithm in learning
multiple cooperative pursuit strategies.</p>
  </details>
</details>
<details>
  <summary>21. <b>标题：Gym-saturation: an OpenAI Gym environment for saturation provers</b></summary>
  <p><b>编号</b>：[99]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04699</p>
  <p><b>作者</b>：Boris Shminke</p>
  <p><b>备注</b>：6 pages, 1 figure</p>
  <p><b>关键词</b>：non trained agent based, gives different agents opportunities, typical automated theorem prover, e prover )., clausal normal form</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>`gym-saturation` is an OpenAI Gym environment for reinforcement learning (RL)
agents capable of proving theorems. Currently, only theorems written in a
formal language of the Thousands of Problems for Theorem Provers (TPTP) library
in clausal normal form (CNF) are supported. `gym-saturation` implements the
'given clause' algorithm (similar to the one used in Vampire and E Prover).
Being written in Python, `gym-saturation` was inspired by PyRes. In contrast to
the monolithic architecture of a typical Automated Theorem Prover (ATP),
`gym-saturation` gives different agents opportunities to select clauses
themselves and train from their experience. Combined with a particular agent,
`gym-saturation` can work as an ATP. Even with a non trained agent based on
heuristics, `gym-saturation` can find refutations for 688 (of 8257) CNF
problems from TPTP v7.5.0.</p>
  </details>
</details>
<details>
  <summary>22. <b>标题：Align-Deform-Subtract: An Interventional Framework for Explaining Object  Differences</b></summary>
  <p><b>编号</b>：[102]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04694</p>
  <p><b>作者</b>：Cian Eastwood,  Li Nanbo,  Christopher K. I. Williams</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：given two object images, synthetic data illustrate, leveraging semantic alignments, explaining object differences, underlying object properties</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Given two object images, how can we explain their differences in terms of the
underlying object properties? To address this question, we propose
Align-Deform-Subtract (ADS) -- an interventional framework for explaining
object differences. By leveraging semantic alignments in image-space as
counterfactual interventions on the underlying object properties, ADS
iteratively quantifies and removes differences in object properties. The result
is a set of "disentangled" error measures which explain object differences in
terms of their underlying properties. Experiments on real and synthetic data
illustrate the efficacy of the framework.</p>
  </details>
</details>
<details>
  <summary>23. <b>标题：FragmGAN: Generative Adversarial Nets for Fragmentary Data Imputation  and Prediction</b></summary>
  <p><b>编号</b>：[103]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04692</p>
  <p><b>作者</b>：Fang Fang,  Shenliao Bao</p>
  <p><b>备注</b>：17 pages</p>
  <p><b>关键词</b>：linkage mechanism shows significant advantages, generative model based imputation methods, generative adversarial nets, flexible framework based, modern scientific research</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Modern scientific research and applications very often encounter "fragmentary
data" which brings big challenges to imputation and prediction. By leveraging
the structure of response patterns, we propose a unified and flexible framework
based on Generative Adversarial Nets (GAN) to deal with fragmentary data
imputation and label prediction at the same time. Unlike most of the other
generative model based imputation methods that either have no theoretical
guarantee or only consider Missing Completed At Random (MCAR), the proposed
FragmGAN has theoretical guarantees for imputation with data Missing At Random
(MAR) while no hint mechanism is needed. FragmGAN trains a predictor with the
generator and discriminator simultaneously. This linkage mechanism shows
significant advantages for predictive performances in extensive experiments.</p>
  </details>
</details>
<details>
  <summary>24. <b>标题：Memory Efficient Continual Learning for Neural Text Classification</b></summary>
  <p><b>编号</b>：[119]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04640</p>
  <p><b>作者</b>：Beyza Ermis,  Giovanni Zappella,  Martin Wistuba,  Cedric Archambeau</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：algorithm learns new tasks without performance degradation, method requires significantly less model parameters compared, perform text classification using pre, training large neural language models, method suffers little forgetting</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Learning text classifiers based on pre-trained language models has become the
standard practice in natural language processing applications. Unfortunately,
training large neural language models, such as transformers, from scratch is
very costly and requires a vast amount of training data, which might not be
available in the application domain of interest. Moreover, in many real-world
scenarios, classes are uncovered as more data is seen, calling for
class-incremental modelling approaches. In this work we devise a method to
perform text classification using pre-trained models on a sequence of
classification tasks provided in sequence. We formalize the problem as a
continual learning problem where the algorithm learns new tasks without
performance degradation on the previous ones and without re-training the model
from scratch. We empirically demonstrate that our method requires significantly
less model parameters compared to other state of the art methods and that it is
significantly faster at inference time. The tight control on the number of
model parameters, and so the memory, is not only improving efficiency. It is
making possible the usage of the algorithm in real-world applications where
deploying a solution with a constantly increasing memory consumption is just
unrealistic. While our method suffers little forgetting, it retains a
predictive performance on-par with state of the art but less memory efficient
methods.</p>
  </details>
</details>
<details>
  <summary>25. <b>标题：LEBP -- Language Expectation & Binding Policy: A Two-Stream Framework  for Embodied Vision-and-Language Interaction Task Learning Agents</b></summary>
  <p><b>编号</b>：[121]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04637</p>
  <p><b>作者</b>：Haoyu Liu,  Yang Liu,  Hongkai He,  Hangfang Yang</p>
  <p><b>备注</b>：6 pages</p>
  <p><b>关键词</b>：perform complicated daily household tasks following natural language instructions, propose lebp -- language expectation, currently published sota methods, approach achieves comparable performance, language interaction benchmark alfred</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>People always desire an embodied agent that can perform a task by
understanding language instruction. Moreover, they also want to monitor and
expect agents to understand commands the way they expected. But, how to build
such an embodied agent is still unclear. Recently, people can explore this
problem with the Vision-and-Language Interaction benchmark ALFRED, which
requires an agent to perform complicated daily household tasks following
natural language instructions in unseen scenes. In this paper, we propose LEBP
-- Language Expectation and Binding Policy Module to tackle the ALFRED. The
LEBP contains a two-stream process: 1) It first conducts a language expectation
module to generate an expectation describing how to perform tasks by
understanding the language instruction. The expectation consists of a sequence
of sub-steps for the task (e.g., Pick an apple). The expectation allows people
to access and check the understanding results of instructions before the agent
takes actual actions, in case the task might go wrong. 2) Then, it uses the
binding policy module to bind sub-steps in expectation to actual actions to
specific scenarios. Actual actions include navigation and object manipulation.
Experimental results suggest our approach achieves comparable performance to
currently published SOTA methods and can avoid large decay from seen scenarios
to unseen scenarios.</p>
  </details>
</details>
<details>
  <summary>26. <b>标题：PALI-NLP at SemEval-2022 Task 4: Discriminative Fine-tuning of Deep  Transformers for Patronizing and Condescending Language Detection</b></summary>
  <p><b>编号</b>：[125]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04616</p>
  <p><b>作者</b>：Dou Hu,  Mengyuan Zhou,  Xiyang Du,  Mengfei Yuan,  Meizhi Jin,  Lianxin Jiang,  Yang Mo,  Xiaofeng Shi</p>
  <p><b>备注</b>：8 pages, submitted in SemEval-2022 Workshop (co-located with NAACL)</p>
  <p><b>关键词</b>：system achieves remarkable results, large harmful impact, existing nlp systems, diverse linguistic behaviour, capture discriminative features</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Patronizing and condescending language (PCL) has a large harmful impact and
is difficult to detect, both for human judges and existing NLP systems. At
SemEval-2022 Task 4, we propose a novel Transformer-based model and its
ensembles to accurately understand such language context for PCL detection. To
facilitate comprehension of the subtle and subjective nature of PCL, two
fine-tuning strategies are applied to capture discriminative features from
diverse linguistic behaviour and categorical distribution. The system achieves
remarkable results on the official ranking, namely 1st in Subtask 1 and 5th in
Subtask 2. Extensive experiments on the task demonstrate the effectiveness of
our system and its strategies.</p>
  </details>
</details>
<details>
  <summary>27. <b>标题：Representation, learning, and planning algorithms for geometric task and  motion planning</b></summary>
  <p><b>编号</b>：[129]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04605</p>
  <p><b>作者</b>：Beomjoon Kim,  Luke Shimanuki,  Leslie Pack Kaelbling,  Tomás Lozano-Pérez</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：gtamp problems involve hybrid search spaces, target regions among movable obstacles, promising state action pairs, expensive action feasibility checks, extends basic heuristic search</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present a framework for learning to guide geometric task and motion
planning (GTAMP). GTAMP is a subclass of task and motion planning in which the
goal is to move multiple objects to target regions among movable obstacles. A
standard graph search algorithm is not directly applicable, because GTAMP
problems involve hybrid search spaces and expensive action feasibility checks.
To handle this, we introduce a novel planner that extends basic heuristic
search with random sampling and a heuristic function that prioritizes
feasibility checking on promising state action pairs. The main drawback of such
pure planners is that they lack the ability to learn from planning experience
to improve their efficiency. We propose two learning algorithms to address
this. The first is an algorithm for learning a rank function that guides the
discrete task level search, and the second is an algorithm for learning a
sampler that guides the continuous motionlevel search. We propose design
principles for designing data efficient algorithms for learning from planning
experience and representations for effective generalization. We evaluate our
framework in challenging GTAMP problems, and show that we can improve both
planning and data efficiency</p>
  </details>
</details>
<details>
  <summary>28. <b>标题：Domain Generalization using Pretrained Models without Fine-tuning</b></summary>
  <p><b>编号</b>：[130]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04600</p>
  <p><b>作者</b>：Ziyue Li,  Kan Ren,  Xinyang Jiang,  Bo Li,  Haipeng Zhang,  Dongsheng Li</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：linear label space adapter upon fixed pretrained models, achieve decent performance regarding specific domains, sedge achieves significant performance improvements comparing, pretrained models could vary significantly, dynamically dispatch proper pretrained models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Fine-tuning pretrained models is a common practice in domain generalization
(DG) tasks. However, fine-tuning is usually computationally expensive due to
the ever-growing size of pretrained models. More importantly, it may cause
over-fitting on source domain and compromise their generalization ability as
shown in recent works. Generally, pretrained models possess some level of
generalization ability and can achieve decent performance regarding specific
domains and samples. However, the generalization performance of pretrained
models could vary significantly over different test domains even samples, which
raises challenges for us to best leverage pretrained models in DG tasks. In
this paper, we propose a novel domain generalization paradigm to better
leverage various pretrained models, named specialized ensemble learning for
domain generalization (SEDGE). It first trains a linear label space adapter
upon fixed pretrained models, which transforms the outputs of the pretrained
model to the label space of the target domain. Then, an ensemble network aware
of model specialty is proposed to dynamically dispatch proper pretrained models
to predict each test sample. Experimental studies on several benchmarks show
that SEDGE achieves significant performance improvements comparing to strong
baselines including state-of-the-art method in DG tasks and reduces the
trainable parameters by ~99% and the training time by ~99.5%.</p>
  </details>
</details>
<details>
  <summary>29. <b>标题：Mapping global dynamics of benchmark creation and saturation in  artificial intelligence</b></summary>
  <p><b>编号</b>：[133]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04592</p>
  <p><b>作者</b>：Adriano Barbosa-Silva,  Simon Ott,  Kathrin Blagec,  Jan Brauner,  Matthias Samwald</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：benchmarks quickly trended towards near, recent studies raised concerns, mapping benchmark performance gains, benchmark performance gains, scale community collaboration</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Benchmarks are crucial to measuring and steering progress in artificial
intelligence (AI). However, recent studies raised concerns over the state of AI
benchmarking, reporting issues such as benchmark overfitting, benchmark
saturation and increasing centralization of benchmark dataset creation. To
facilitate monitoring of the health of the AI benchmarking ecosystem, we
introduce methodologies for creating condensed maps of the global dynamics of
benchmark creation and saturation. We curated data for 1688 benchmarks covering
the entire domains of computer vision and natural language processing, and show
that a large fraction of benchmarks quickly trended towards near-saturation,
that many benchmarks fail to find widespread utilization, and that benchmark
performance gains for different AI tasks were prone to unforeseen bursts. We
conclude that future work should focus on large-scale community collaboration
and on mapping benchmark performance gains to real-world utility and impact of
AI.</p>
  </details>
</details>
<details>
  <summary>30. <b>标题：Reinforced Meta Active Learning</b></summary>
  <p><b>编号</b>：[138]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04573</p>
  <p><b>作者</b>：Michael Katz,  Eli Kravchik</p>
  <p><b>备注</b>：14 pages, 5 figures</p>
  <p><b>关键词</b>：learn optimal selection strategies directly, based meta active learning method, combines episodic policy search, numerous active learning strategies, informativeness measure directly</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In stream-based active learning, the learning procedure typically has access
to a stream of unlabeled data instances and must decide for each instance
whether to label it and use it for training or to discard it. There are
numerous active learning strategies which try to minimize the number of labeled
samples required for training in this setting by identifying and retaining the
most informative data samples. Most of these schemes are rule-based and rely on
the notion of uncertainty, which captures how small the distance of a data
sample is from the classifier's decision boundary. Recently, there have been
some attempts to learn optimal selection strategies directly from the data, but
many of them are still lacking generality for several reasons: 1) They focus on
specific classification setups, 2) They rely on rule-based metrics, 3) They
require offline pre-training of the active learner on related tasks. In this
work we address the above limitations and present an online stream-based meta
active learning method which learns on the fly an informativeness measure
directly from the data, and is applicable to a general class of classification
problems without any need for pretraining of the active learner on related
tasks. The method is based on reinforcement learning and combines episodic
policy search and a contextual bandits approach which are used to train the
active learner in conjunction with training of the model. We demonstrate on
several real datasets that this method learns to select training samples more
efficiently than existing state-of-the-art methods.</p>
  </details>
</details>
<details>
  <summary>31. <b>标题：A Neuro-vector-symbolic Architecture for Solving Raven's Progressive  Matrices</b></summary>
  <p><b>编号</b>：[139]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04571</p>
  <p><b>作者</b>：Michael Hersche,  Mustafa Zeqiri,  Luca Benini,  Abu Sebastian,  Abbas Rahimi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：width holographic vectorized representations, called binding problem ),, neither deep neural networks, magnitude faster execution, exhaustive rule searches</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Neither deep neural networks nor symbolic AI alone have approached the kind
of intelligence expressed in humans. This is mainly because neural networks are
not able to decompose distinct objects from their joint representation (the
so-called binding problem), while symbolic AI suffers from exhaustive rule
searches, among other problems. These two problems are still pronounced in
neuro-symbolic AI which aims to combine the best of the two paradigms. Here, we
show that the two problems can be addressed with our proposed
neuro-vector-symbolic architecture (NVSA) by exploiting its powerful operators
on fixed-width holographic vectorized representations that serve as a common
language between neural networks and symbolic logical reasoning. The efficacy
of NVSA is demonstrated by solving the Raven's progressive matrices. NVSA
achieves a new record of 97.7% average accuracy in RAVEN, and 98.8% in I-RAVEN
datasets, with two orders of magnitude faster execution than the symbolic
logical reasoning on CPUs.</p>
  </details>
</details>
<details>
  <summary>32. <b>标题：CP-ViT: Cascade Vision Transformer Pruning via Progressive Sparsity  Prediction</b></summary>
  <p><b>编号</b>：[140]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04570</p>
  <p><b>作者</b>：Zhuoran Song,  Yihong Xu,  Zhezhi He,  Li Jiang,  Naifeng Jing,  Xiaoyao Liang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：dynamic pruning ratio adjustment technique based, maintaining accuracy loss within 1 \%., cascade pruning framework named cp, progressively pruning 50 \% patches, 40 \% flops</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Vision transformer (ViT) has achieved competitive accuracy on a variety of
computer vision applications, but its computational cost impedes the deployment
on resource-limited mobile devices.
We explore the sparsity in ViT and observe that informative patches and heads
are sufficient for accurate image recognition.
In this paper, we propose a cascade pruning framework named CP-ViT by
predicting sparsity in ViT models progressively and dynamically to reduce
computational redundancy while minimizing the accuracy loss. Specifically, we
define the cumulative score to reserve the informative patches and heads across
the ViT model for better accuracy. We also propose the dynamic pruning ratio
adjustment technique based on layer-aware attention range. CP-ViT has great
general applicability for practical deployment, which can be applied to a wide
range of ViT models and can achieve superior accuracy with or without
fine-tuning.
Extensive experiments on ImageNet, CIFAR-10, and CIFAR-100 with various
pre-trained models have demonstrated the effectiveness and efficiency of
CP-ViT. By progressively pruning 50\% patches, our CP-ViT method reduces over
40\% FLOPs while maintaining accuracy loss within 1\%.</p>
  </details>
</details>
<details>
  <summary>33. <b>标题：All You Need is LUV: Unsupervised Collection of Labeled Images using  Invisible UV Fluorescent Indicators</b></summary>
  <p><b>编号</b>：[141]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04566</p>
  <p><b>作者</b>：Brijen Thananjeyan,  Justin Kerr,  Huang Huang,  Joseph E. Gonzalez,  Ken Goldberg</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：collecting around 200 semantic segmentation labels, real manipulation environments without human labeling, surgical needle pose estimation task, scale semantic image annotation, keypoints via color segmentation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large-scale semantic image annotation is a significant challenge for
learning-based perception systems in robotics. Current approaches often rely on
human labelers, which can be expensive, or simulation data, which can visually
or physically differ from real data. This paper proposes Labels from
UltraViolet (LUV), a novel framework that enables rapid, labeled data
collection in real manipulation environments without human labeling. LUV uses
transparent, ultraviolet-fluorescent paint with programmable ultraviolet LEDs
to collect paired images of a scene in standard lighting and UV lighting to
autonomously extract segmentation masks and keypoints via color segmentation.
We apply LUV to a suite of diverse robot perception tasks to evaluate its
labeling quality, flexibility, and data collection rate. Results suggest that
LUV is 180-2500 times faster than a human labeler across the tasks. We show
that LUV provides labels consistent with human annotations on unpainted test
images. The networks trained on these labels are used to smooth and fold
crumpled towels with 83% success rate and achieve 1.7mm position error with
respect to human labels on a surgical needle pose estimation task. The low cost
of LUV makes it ideal as a lightweight replacement for human labeling systems,
with the one-time setup costs at $300 equivalent to the cost of collecting
around 200 semantic segmentation labels on Amazon Mechanical Turk. Code,
datasets, visualizations, and supplementary material can be found at
this https URL</p>
  </details>
</details>
<details>
  <summary>34. <b>标题：MLNav: Learning to Safely Navigate on Martian Terrains</b></summary>
  <p><b>编号</b>：[144]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04563</p>
  <p><b>作者</b>：Shreyansh Daftry,  Neil Abcouwer,  Tyler Del Sesto,  Siddarth Venkatraman,  Jialin Song,  Lucas Igel,  Amos Byon,  Ugo Rosolia,  Yisong Yue,  Masahiro Ono</p>
  <p><b>备注</b>：IEEE Robotics and Automation Letters (RA-L) and ICRA 2022</p>
  <p><b>关键词</b>：real martian terrain data collected, successfully navigate highly challenging terrains, navigating real martian terrains, fully respecting safety constraints, mlnav makes judicious use</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present MLNav, a learning-enhanced path planning framework for
safety-critical and resource-limited systems operating in complex environments,
such as rovers navigating on Mars. MLNav makes judicious use of machine
learning to enhance the efficiency of path planning while fully respecting
safety constraints. In particular, the dominant computational cost in such
safety-critical settings is running a model-based safety checker on the
proposed paths. Our learned search heuristic can simultaneously predict the
feasibility for all path options in a single run, and the model-based safety
checker is only invoked on the top-scoring paths. We validate in high-fidelity
simulations using both real Martian terrain data collected by the Perseverance
rover, as well as a suite of challenging synthetic terrains. Our experiments
show that: (i) compared to the baseline ENav path planner on board the
Perserverance rover, MLNav can provide a significant improvement in multiple
key metrics, such as a 10x reduction in collision checks when navigating real
Martian terrains, despite being trained with synthetic terrains; and (ii) MLNav
can successfully navigate highly challenging terrains where the baseline ENav
fails to find a feasible path before timing out.</p>
  </details>
</details>
<details>
  <summary>35. <b>标题：MetaCon: Unified Predictive Segments System with Trillion Concept  Meta-Learning</b></summary>
  <p><b>编号</b>：[152]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04540</p>
  <p><b>作者</b>：Keqian Li,  Yifan Hu,  Logan Palanisamy,  Lisa Jones,  Akshay Gupta,  Jason Grigsby,  Ili Selinger,  Matt Gillingham,  Fei Tan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：leverages principled meta learning approach, public structured learning tasks demonstrate, trillion concepts meta learning, long tail predictive tasks, efficient first order meta</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Accurate understanding of users in terms of predicative segments play an
essential role in the day to day operation of modern internet enterprises.
Nevertheless, there are significant challenges that limit the quality of data,
especially on long tail predictive tasks. In this work, we present MetaCon, our
unified predicative segments system with scalable, trillion concepts meta
learning that addresses these challenges. It builds on top of a flat concept
representation that summarizes entities' heterogeneous digital footprint,
jointly considers the entire spectrum of predicative tasks as a single learning
task, and leverages principled meta learning approach with efficient first
order meta-optimization procedure under a provable performance guarantee in
order to solve the learning task. Experiments on both proprietary production
datasets and public structured learning tasks demonstrate that MetaCon can lead
to substantial improvements over state of the art recommendation and ranking
approaches.</p>
  </details>
</details>
<details>
  <summary>36. <b>标题：Monocular Depth Distribution Alignment with Low Computation</b></summary>
  <p><b>编号</b>：[153]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04538</p>
  <p><b>作者</b>：Fei Sheng,  Feng Xue,  Yicong Chang,  Wenteng Liang,  Anlong Ming</p>
  <p><b>备注</b>：Accepted by ICRA 2022</p>
  <p><b>关键词</b>：monocular depth estimation generally depends, point operations per second, widely used nyudv2 dataset, reasonable scene structure, pyramid scene transformer</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The performance of monocular depth estimation generally depends on the amount
of parameters and computational cost. It leads to a large accuracy contrast
between light-weight networks and heavy-weight networks, which limits their
application in the real world. In this paper, we model the majority of accuracy
contrast between them as the difference of depth distribution, which we call
"Distribution drift". To this end, a distribution alignment network (DANet) is
proposed. We firstly design a pyramid scene transformer (PST) module to capture
inter-region interaction in multiple scales. By perceiving the difference of
depth features between every two regions, DANet tends to predict a reasonable
scene structure, which fits the shape of distribution to ground truth. Then, we
propose a local-global optimization (LGO) scheme to realize the supervision of
global range of scene depth. Thanks to the alignment of depth distribution
shape and scene depth range, DANet sharply alleviates the distribution drift,
and achieves a comparable performance with prior heavy-weight methods, but uses
only 1% floating-point operations per second (FLOPs) of them. The experiments
on two datasets, namely the widely used NYUDv2 dataset and the more challenging
iBims-1 dataset, demonstrate the effectiveness of our method. The source code
is available at this https URL.</p>
  </details>
</details>
<details>
  <summary>37. <b>标题：Fast Road Segmentation via Uncertainty-aware Symmetric Network</b></summary>
  <p><b>编号</b>：[154]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04537</p>
  <p><b>作者</b>：Yicong Chang,  Feng Xue,  Fei Sheng,  Wenteng Liang,  Anlong Ming</p>
  <p><b>备注</b>：Accepted by ICRA 2022</p>
  <p><b>关键词</b>：prior methods cannot achieve high inference speed, instead separately adopt two light, based road segmentation methods contrasts, modal feature fusion operations, time inference speed</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The high performance of RGB-D based road segmentation methods contrasts with
their rare application in commercial autonomous driving, which is owing to two
reasons: 1) the prior methods cannot achieve high inference speed and high
accuracy in both ways; 2) the different properties of RGB and depth data are
not well-exploited, limiting the reliability of predicted road. In this paper,
based on the evidence theory, an uncertainty-aware symmetric network (USNet) is
proposed to achieve a trade-off between speed and accuracy by fully fusing RGB
and depth data. Firstly, cross-modal feature fusion operations, which are
indispensable in the prior RGB-D based methods, are abandoned. We instead
separately adopt two light-weight subnetworks to learn road representations
from RGB and depth inputs. The light-weight structure guarantees the real-time
inference of our method. Moreover, a multiscale evidence collection (MEC)
module is designed to collect evidence in multiple scales for each modality,
which provides sufficient evidence for pixel class determination. Finally, in
uncertainty-aware fusion (UAF) module, the uncertainty of each modality is
perceived to guide the fusion of the two subnetworks. Experimental results
demonstrate that our method achieves a state-of-the-art accuracy with real-time
inference speed of 43+ FPS. The source code is available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>38. <b>标题：Multi-Agent Policy Transfer via Task Relationship Modeling</b></summary>
  <p><b>编号</b>：[170]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04482</p>
  <p><b>作者</b>：Rongjun Qin,  Feng Chen,  Tonghan Wang,  Lei Yuan,  Xiaoran Wu,  Zongzhang Zhang,  Chongjie Zhang,  Yang Yu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：help transfer learned cooperation knowledge, transferred policies help solve tasks, agent transfer learning accommodate teams, exploit common structures among tasks, alternatively fixed training scheme</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Team adaptation to new cooperative tasks is a hallmark of human intelligence,
which has yet to be fully realized in learning agents. Previous work on
multi-agent transfer learning accommodate teams of different sizes, heavily
relying on the generalization ability of neural networks for adapting to unseen
tasks. We believe that the relationship among tasks provides the key
information for policy adaptation. In this paper, we try to discover and
exploit common structures among tasks for more efficient transfer, and propose
to learn effect-based task representations as a common space of tasks, using an
alternatively fixed training scheme. We demonstrate that the task
representation can capture the relationship among tasks, and can generalize to
unseen tasks. As a result, the proposed method can help transfer learned
cooperation knowledge to new tasks after training on a few source tasks. We
also find that fine-tuning the transferred policies help solve tasks that are
hard to learn from scratch.</p>
  </details>
</details>
<details>
  <summary>39. <b>标题：Part-level Action Parsing via a Pose-guided Coarse-to-Fine Framework</b></summary>
  <p><b>编号</b>：[172]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04476</p>
  <p><b>作者</b>：Xiaodong Chen,  Xinchen Liu,  Wu Liu,  Kun Liu,  Dong Wu,  Yongdong Zhang,  Tao Mei</p>
  <p><b>备注</b>：Accepted by IEEE ISCAS 2022, 5 pages, 2 figures</p>
  <p><b>关键词</b>：g ., convolutional neural networks, guided positional embedding method, existing methods usually consider, accurately localize body parts, outperforms existing methods</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Action recognition from videos, i.e., classifying a video into one of the
pre-defined action types, has been a popular topic in the communities of
artificial intelligence, multimedia, and signal processing. However, existing
methods usually consider an input video as a whole and learn models, e.g.,
Convolutional Neural Networks (CNNs), with coarse video-level class labels.
These methods can only output an action class for the video, but cannot provide
fine-grained and explainable cues to answer why the video shows a specific
action. Therefore, researchers start to focus on a new task, Part-level Action
Parsing (PAP), which aims to not only predict the video-level action but also
recognize the frame-level fine-grained actions or interactions of body parts
for each person in the video. To this end, we propose a coarse-to-fine
framework for this challenging task. In particular, our framework first
predicts the video-level class of the input video, then localizes the body
parts and predicts the part-level action. Moreover, to balance the accuracy and
computation in part-level action parsing, we propose to recognize the
part-level actions by segment-level features. Furthermore, to overcome the
ambiguity of body parts, we propose a pose-guided positional embedding method
to accurately localize body parts. Through comprehensive experiments on a
large-scale dataset, i.e., Kinetics-TPS, our framework achieves
state-of-the-art performance and outperforms existing methods over a 31.10% ROC
score.</p>
  </details>
</details>
<details>
  <summary>40. <b>标题：Cooperative Trajectory Planning in Uncertain Environments with Monte  Carlo Tree Search and Risk Metrics</b></summary>
  <p><b>编号</b>：[185]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04452</p>
  <p><b>作者</b>：Philipp Stegmaier,  Karl Kurzer,  J. Marius Zöllner</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：existing cooperative trajectory planning approach based, efficient cooperative trajectory planning method, return distributions using kernel regression, partially observable markov decision process, final selection policy consistently outperforms</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Automated vehicles require the ability to cooperate with humans for a smooth
integration into today's traffic. While the concept of cooperation is well
known, the development of a robust and efficient cooperative trajectory
planning method is still a challenge. One aspect of this challenge is the
uncertainty surrounding the state of the environment due to limited sensor
accuracy. This uncertainty can be represented by a Partially Observable Markov
Decision Process. Our work addresses this problem by extending an existing
cooperative trajectory planning approach based on Monte Carlo Tree Search for
continuous action spaces. It does so by explicitly modeling uncertainties in
the form of a root belief state, from which start states for trees are sampled.
After the trees have been constructed with Monte Carlo Tree Search, their
results are aggregated into return distributions using kernel regression. For
the final selection, we apply two risk metrics, namely a Lower Confidence Bound
and a Conditional Value at Risk. It can be demonstrated that the integration of
risk metrics in the final selection policy consistently outperforms a baseline
in uncertain environments, generating considerably safer trajectories.</p>
  </details>
</details>
<details>
  <summary>41. <b>标题：OpenGridGym: An Open-Source AI-Friendly Toolkit for Distribution Market  Simulation</b></summary>
  <p><b>编号</b>：[209]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04410</p>
  <p><b>作者</b>：Rayan El Helou,  Kiyeob Lee,  Dongqi Wu,  Le Xie,  Srinivas Shakkottai,  Vijay Subramanian</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：helping researchers address key design, several case studies, providing multiple cases, distribution electricity markets, art artificial intelligence</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper presents OpenGridGym, an open-source Python-based package that
allows for seamless integration of distribution market simulation with
state-of-the-art artificial intelligence (AI) decision-making algorithms. We
present the architecture and design choice for the proposed framework,
elaborate on how users interact with OpenGridGym, and highlight its value by
providing multiple cases to demonstrate its use. Four modules are used in any
simulation: (1) the physical grid, (2) market mechanisms, (3) a set of
trainable agents which interact with the former two modules, and (4)
environment module that connects and coordinates the above three. We provide
templates for each of those four, but they are easily interchangeable with
custom alternatives. Several case studies are presented to illustrate the
capability and potential of this toolkit in helping researchers address key
design and operational questions in distribution electricity markets.</p>
  </details>
</details>
<details>
  <summary>42. <b>标题：Model-free feature selection to facilitate automatic discovery of  divergent subgroups in tabular data</b></summary>
  <p><b>编号</b>：[214]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04386</p>
  <p><b>作者</b>：Girmaw Abebe Tadesse,  William Ogallo,  Celia Cintas,  Skyler Speakman</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：automatic discovery techniques often search across potentially exponential combinations, validated safs across two publicly available datasets, claims dataset detected divergent samples similar, objective measures among feature values, tabular data often involve fitting</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Data-centric AI encourages the need of cleaning and understanding of data in
order to achieve trustworthy AI. Existing technologies, such as AutoML, make it
easier to design and train models automatically, but there is a lack of a
similar level of capabilities to extract data-centric insights. Manual
stratification of tabular data per a feature (e.g., gender) is limited to scale
up for higher feature dimension, which could be addressed using automatic
discovery of divergent subgroups. Nonetheless, these automatic discovery
techniques often search across potentially exponential combinations of features
that could be simplified using a preceding feature selection step. Existing
feature selection techniques for tabular data often involve fitting a
particular model in order to select important features. However, such
model-based selection is prone to model-bias and spurious correlations in
addition to requiring extra resource to design, fine-tune and train a model. In
this paper, we propose a model-free and sparsity-based automatic feature
selection (SAFS) framework to facilitate automatic discovery of divergent
subgroups. Different from filter-based selection techniques, we exploit the
sparsity of objective measures among feature values to rank and select
features. We validated SAFS across two publicly available datasets (MIMIC-III
and Allstate Claims) and compared it with six existing feature selection
methods. SAFS achieves a reduction of feature selection time by a factor of 81x
and 104x, averaged cross the existing methods in the MIMIC-III and Claims
datasets respectively. SAFS-selected features are also shown to achieve
competitive detection performance, e.g., 18.3% of features selected by SAFS in
the Claims dataset detected divergent samples similar to those detected by
using the whole features with a Jaccard similarity of 0.95 but with a 16x
reduction in detection time.</p>
  </details>
</details>
<details>
  <summary>43. <b>标题：Regularized Training of Intermediate Layers for Generative Models for  Inverse Problems</b></summary>
  <p><b>编号</b>：[217]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04382</p>
  <p><b>作者</b>：Sean Gunn,  Jorio Cocola,  Paul Hand</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：multiple proposed inversion algorithms reduce representation error, two notable recent inversion algorithms, new regularized gan training algorithm, lower reconstruction errors across, learned generative model results</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Generative Adversarial Networks (GANs) have been shown to be powerful and
flexible priors when solving inverse problems. One challenge of using them is
overcoming representation error, the fundamental limitation of the network in
representing any particular signal. Recently, multiple proposed inversion
algorithms reduce representation error by optimizing over intermediate layer
representations. These methods are typically applied to generative models that
were trained agnostic of the downstream inversion algorithm. In our work, we
introduce a principle that if a generative model is intended for inversion
using an algorithm based on optimization of intermediate layers, it should be
trained in a way that regularizes those intermediate layers. We instantiate
this principle for two notable recent inversion algorithms: Intermediate Layer
Optimization and the Multi-Code GAN prior. For both of these inversion
algorithms, we introduce a new regularized GAN training algorithm and
demonstrate that the learned generative model results in lower reconstruction
errors across a wide range of under sampling ratios when solving compressed
sensing, inpainting, and super-resolution problems.</p>
  </details>
</details>
<details>
  <summary>44. <b>标题：Logic-based AI for Interpretable Board Game Winner Prediction with  Tsetlin Machine</b></summary>
  <p><b>编号</b>：[219]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04378</p>
  <p><b>作者</b>：Charul Giri,  Ole-Christoffer Granmo,  Herke van Hoof,  Christian D. Blakely</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：popular machine learning algorithms like xgboost, resulting interpretability establishes building blocks, board positions using neural networks, losing board game positions, considering various board configurations</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Hex is a turn-based two-player connection game with a high branching factor,
making the game arbitrarily complex with increasing board sizes. As such,
top-performing algorithms for playing Hex rely on accurate evaluation of board
positions using neural networks. However, the limited interpretability of
neural networks is problematic when the user wants to understand the reasoning
behind the predictions made. In this paper, we propose to use propositional
logic expressions to describe winning and losing board game positions,
facilitating precise visual interpretation. We employ a Tsetlin Machine (TM) to
learn these expressions from previously played games, describing where pieces
must be located or not located for a board position to be strong. Extensive
experiments on $6\times6$ boards compare our TM-based solution with popular
machine learning algorithms like XGBoost, InterpretML, decision trees, and
neural networks, considering various board configurations with $2$ to $22$
moves played. On average, the TM testing accuracy is $92.1\%$, outperforming
all the other evaluated algorithms. We further demonstrate the global
interpretation of the logical expressions and map them down to particular board
game configurations to investigate local interpretability. We believe the
resulting interpretability establishes building blocks for accurate assistive
AI and human-AI collaboration, also for more complex prediction tasks.</p>
  </details>
</details>
<details>
  <summary>45. <b>标题：On the Fitness Landscapes of Interdependency Models in the Travelling  Thief Problem</b></summary>
  <p><b>编号</b>：[225]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04363</p>
  <p><b>作者</b>：Mohamed El Yafrani,  Marcella Scoczynski,  Myriam Delgado,  Ricardo Lüders,  Peter Nielsen,  Markus Wagner</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：use local optima networks, simple local search algorithm, multiple interconnected sub, travelling thief problem, travelling time</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Since its inception in 2013, the Travelling Thief Problem (TTP) has been
widely studied as an example of problems with multiple interconnected
sub-problems. The dependency in this model arises when tying the travelling
time of the "thief" to the weight of the knapsack. However, other forms of
dependency as well as combinations of dependencies should be considered for
investigation, as they are often found in complex real-world problems. Our goal
is to study the impact of different forms of dependency in the TTP using a
simple local search algorithm. To achieve this, we use Local Optima Networks, a
technique for analysing the fitness landscape.</p>
  </details>
</details>
<details>
  <summary>46. <b>标题：Cluster Head Detection for Hierarchical UAV Swarm With Graph  Self-supervised Learning</b></summary>
  <p><b>编号</b>：[234]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04311</p>
  <p><b>作者</b>：Zhiyu Mou,  Jun Liu,  Xiang Yun,  Feifei Gao,  Qihui Wu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：gru )- based metric learning scheme, single uav clusters obeying various kinds, level unmanned aerial vehicle, simulation results also show, cluster head detection problem</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we study the cluster head detection problem of a two-level
unmanned aerial vehicle (UAV) swarm network (USNET) with multiple UAV clusters,
where the inherent follow strategy (IFS) of low-level follower UAVs (FUAVs)
with respect to high-level cluster head UAVs (HUAVs) is unknown. We first
propose a graph attention self-supervised learning algorithm (GASSL) to detect
the HUAVs of a single UAV cluster, where the GASSL can fit the IFS at the same
time. Then, to detect the HUAVs in the USNET with multiple UAV clusters, we
develop a multi-cluster graph attention self-supervised learning algorithm
(MC-GASSL) based on the GASSL. The MC-GASSL clusters the USNET with a gated
recurrent unit (GRU)-based metric learning scheme and finds the HUAVs in each
cluster with GASSL. Numerical results show that the GASSL can detect the HUAVs
in single UAV clusters obeying various kinds of IFSs with over 98% average
accuracy. The simulation results also show that the clustering purity of the
USNET with MC-GASSL exceeds that with traditional clustering algorithms by at
least 10% average. Furthermore, the MC-GASSL can efficiently detect all the
HUAVs in USNETs with various IFSs and cluster numbers with low detection
redundancies.</p>
  </details>
</details>
<details>
  <summary>47. <b>标题：Multi-Agent Broad Reinforcement Learning for Intelligent Traffic Light  Control</b></summary>
  <p><b>编号</b>：[235]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04310</p>
  <p><b>作者</b>：Ruijie Zhu,  Lulu Li,  Shuning Wu,  Pei Lv,  Yafai Li,  Mingliang Xu</p>
  <p><b>备注</b>：13 pages, 12 figures</p>
  <p><b>关键词</b>：intelligent traffic light control scenario, intelligent traffic light control system, single agent deep reinforcement learning, agent deep reinforcement learning, agent broad reinforcement learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Intelligent Traffic Light Control System (ITLCS) is a typical Multi-Agent
System (MAS), which comprises multiple roads and traffic lights.Constructing a
model of MAS for ITLCS is the basis to alleviate traffic congestion. Existing
approaches of MAS are largely based on Multi-Agent Deep Reinforcement Learning
(MADRL). Although the Deep Neural Network (DNN) of MABRL is effective, the
training time is long, and the parameters are difficult to trace. Recently,
Broad Learning Systems (BLS) provided a selective way for learning in the deep
neural networks by a flat network. Moreover, Broad Reinforcement Learning (BRL)
extends BLS in Single Agent Deep Reinforcement Learning (SADRL) problem with
promising results. However, BRL does not focus on the intricate structures and
interaction of agents. Motivated by the feature of MADRL and the issue of BRL,
we propose a Multi-Agent Broad Reinforcement Learning (MABRL) framework to
explore the function of BLS in MAS. Firstly, unlike most existing MADRL
approaches, which use a series of deep neural networks structures, we model
each agent with broad networks. Then, we introduce a dynamic self-cycling
interaction mechanism to confirm the "3W" information: When to interact, Which
agents need to consider, What information to transmit. Finally, we do the
experiments based on the intelligent traffic light control scenario. We compare
the MABRL approach with six different approaches, and experimental results on
three datasets verify the effectiveness of MABRL.</p>
  </details>
</details>
<details>
  <summary>48. <b>标题：A Machine Learning Approach to Digital Contact Tracing: TC4TL Challenge</b></summary>
  <p><b>编号</b>：[236]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04307</p>
  <p><b>作者</b>：Badrinath Singhal,  Chris Vorster,  Di Meng,  Gargi Gupta,  Laura Dunne,  Mark Germaine</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：two mobile phone devices using bluetooth low energy, 08 ), significantly outperforming existing models, considered utilising phone sensor data, total ndcf 0, public health organisations</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Contact tracing is a method used by public health organisations to try
prevent the spread of infectious diseases in the community. Traditionally
performed by manual contact tracers, more recently the use of apps have been
considered utilising phone sensor data to determine the distance between two
phones. In this paper, we investigate the development of machine learning
approaches to determine the distance between two mobile phone devices using
Bluetooth Low Energy, sensory data and meta data. We use TableNet architecture
and feature engineering to improve on the existing state of the art (total nDCF
0.21 vs 2.08), significantly outperforming existing models.</p>
  </details>
</details>
<details>
  <summary>49. <b>标题：LSTMSPLIT: Effective SPLIT Learning based LSTM on Sequential Time-Series  Data</b></summary>
  <p><b>编号</b>：[237]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04305</p>
  <p><b>作者</b>：Lianlian Jiang,  Yuexuan Wang,  Wenyi Zheng,  Chao Jin,  Zengxiang Li,  Sin G. Teo</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：many researchers typically use 1d convolutional neural networks, two popular distributed machine learning, distributed across various clients, also achieve good accuracy, human activity recognition dataset</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Federated learning (FL) and split learning (SL) are the two popular
distributed machine learning (ML) approaches that provide some data privacy
protection mechanisms. In the time-series classification problem, many
researchers typically use 1D convolutional neural networks (1DCNNs) based on
the SL approach with a single client to reduce the computational overhead at
the client-side while still preserving data privacy. Another method, recurrent
neural network (RNN), is utilized on sequentially partitioned data where
segments of multiple-segment sequential data are distributed across various
clients. However, to the best of our knowledge, it is still not much work done
in SL with long short-term memory (LSTM) network, even the LSTM network is
practically effective in processing time-series data. In this work, we propose
a new approach, LSTMSPLIT, that uses SL architecture with an LSTM network to
classify time-series data with multiple clients. The differential privacy (DP)
is applied to solve the data privacy leakage. The proposed method, LSTMSPLIT,
has achieved better or reasonable accuracy compared to the Split-1DCNN method
using the electrocardiogram dataset and the human activity recognition dataset.
Furthermore, the proposed method, LSTMSPLIT, can also achieve good accuracy
after applying differential privacy to preserve the user privacy of the cut
layer of the LSTMSPLIT.</p>
  </details>
</details>
<details>
  <summary>50. <b>标题：Policy Regularization for Legible Behavior</b></summary>
  <p><b>编号</b>：[238]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04303</p>
  <p><b>作者</b>：Michele Persiani,  Thomas Hellström</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：reinforcement learning interpretability generally means, may however fall short, interactions prohibits deep inspections, injecting legible behavior inside, policy may produce observations</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In Reinforcement Learning interpretability generally means to provide insight
into the agent's mechanisms such that its decisions are understandable by an
expert upon inspection. This definition, with the resulting methods from the
literature, may however fall short for online settings where the fluency of
interactions prohibits deep inspections of the decision-making algorithm. To
support interpretability in online settings it is useful to borrow from the
Explainable Planning literature methods that focus on the legibility of the
agent, by making its intention easily discernable in an observer model. As we
propose in this paper, injecting legible behavior inside an agent's policy
doesn't require modify components of its learning algorithm. Rather, the
agent's optimal policy can be regularized for legibility by evaluating how the
policy may produce observations that would make an observer infer an incorrect
policy. In our formulation, the decision boundary introduced by legibility
impacts the states in which the agent's policy returns an action that has high
likelihood also in other policies. In these cases, a trade-off between such
action, and legible/sub-optimal action is made.</p>
  </details>
</details>
<details>
  <summary>51. <b>标题：CaSS: A Channel-aware Self-supervised Representation Learning Framework  for Multivariate Time Series Classification</b></summary>
  <p><b>编号</b>：[240]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04298</p>
  <p><b>作者</b>：Yijiang Chen,  Xiangdong Zhou,  Zhen Xing,  Zhidan Liu,  Minyang Xu</p>
  <p><b>备注</b>：16 pages, 4 figures, DASFAA 2022</p>
  <p><b>关键词</b>：combine two novel pretext tasks next trend prediction, several commonly used benchmark datasets, supervised mts representation learning methods, attracts increasing research interests, many previous works focus</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Self-supervised representation learning of Multivariate Time Series (MTS) is
a challenging task and attracts increasing research interests in recent years.
Many previous works focus on the pretext task of self-supervised learning and
usually neglect the complex problem of MTS encoding, leading to unpromising
results. In this paper, we tackle this challenge from two aspects: encoder and
pretext task, and propose a unified channel-aware self-supervised learning
framework CaSS. Specifically, we first design a new Transformer-based encoder
Channel-aware Transformer (CaT) to capture the complex relationships between
different time channels of MTS. Second, we combine two novel pretext tasks Next
Trend Prediction (NTP) and Contextual Similarity (CS) for the self-supervised
representation learning with our proposed encoder. Extensive experiments are
conducted on several commonly used benchmark datasets. The experimental results
show that our framework achieves new state-of-the-art comparing with previous
self-supervised MTS representation learning methods (up to +7.70\% improvement
on LSST dataset) and can be well applied to the downstream MTS classification.</p>
  </details>
</details>
<details>
  <summary>52. <b>标题：Rényi State Entropy for Exploration Acceleration in Reinforcement  Learning</b></summary>
  <p><b>编号</b>：[241]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04297</p>
  <p><b>作者</b>：Mingqi Yuan,  Man-on Pun,  Dong Wang</p>
  <p><b>备注</b>：10 pages, 6 figures</p>
  <p><b>关键词</b>：k $- nearest neighbor estimator, conventional methods incur complex models, k $- value search method, novel intrinsic reward module based, existing state entropy maximization methods</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>One of the most critical challenges in deep reinforcement learning is to
maintain the long-term exploration capability of the agent. To tackle this
problem, it has been recently proposed to provide intrinsic rewards for the
agent to encourage exploration. However, most existing intrinsic reward-based
methods proposed in the literature fail to provide sustainable exploration
incentives, a problem known as vanishing rewards. In addition, these
conventional methods incur complex models and additional memory in their
learning procedures, resulting in high computational complexity and low
robustness. In this work, a novel intrinsic reward module based on the Rényi
entropy is proposed to provide high-quality intrinsic rewards. It is shown that
the proposed method actually generalizes the existing state entropy
maximization methods. In particular, a $k$-nearest neighbor estimator is
introduced for entropy estimation while a $k$-value search method is designed
to guarantee the estimation accuracy. Extensive simulation results demonstrate
that the proposed Rényi entropy-based method can achieve higher performance
as compared to existing schemes.</p>
  </details>
</details>
<details>
  <summary>53. <b>标题：Predicting conversion of mild cognitive impairment to Alzheimer's  disease</b></summary>
  <p><b>编号</b>：[260]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04725</p>
  <p><b>作者</b>：Yiran Wei,  Stephen J. Price,  Carola-Bibiane Schönlieb,  Chao Li</p>
  <p><b>备注</b>：Under review</p>
  <p><b>关键词</b>：recurrent neural networks based approach, classify dementia using deep learning, supervised contrastive learning approach, generate structural brain networks, white matter tracts</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Alzheimer's disease (AD) is the most common age-related dementia. Mild
cognitive impairment (MCI) is the early stage of cognitive decline before AD.
It is crucial to predict the MCI-to-AD conversion for precise management, which
remains challenging due to the diversity of patients. Previous evidence shows
that the brain network generated from diffusion MRI promises to classify
dementia using deep learning. However, the limited availability of diffusion
MRI challenges the model training. In this study, we develop a self-supervised
contrastive learning approach to generate structural brain networks from
routine anatomical MRI under the guidance of diffusion MRI. The generated brain
networks are applied to train a learning framework for predicting the MCI-to-AD
conversion. Instead of directly modelling the AD brain networks, we train a
graph encoder and a variational autoencoder to model the healthy ageing
trajectories from brain networks of healthy controls. To predict the MCI-to-AD
conversion, we further design a recurrent neural networks based approach to
model the longitudinal deviation of patients' brain networks from the healthy
ageing trajectory. Numerical results show that the proposed methods outperform
the benchmarks in the prediction task. We also visualize the model
interpretation to explain the prediction and identify abnormal changes of white
matter tracts.</p>
  </details>
</details>
<details>
  <summary>54. <b>标题：Data Representativity for Machine Learning and AI Systems</b></summary>
  <p><b>编号</b>：[261]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04706</p>
  <p><b>作者</b>：Line H. Clemmensen,  Rune D. Kjærsgaard</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：data representativeness without specific clarification, paper analyzes data representativity, using empirical demonstrations, make better predictions, limited work exists</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Data representativity is crucial when drawing inference from data through
machine learning models. Scholars have increased focus on unraveling the bias
and fairness in the models, also in relation to inherent biases in the input
data. However, limited work exists on the representativity of samples
(datasets) for appropriate inference in AI systems. This paper analyzes data
representativity in scientific literature related to AI and sampling, and gives
a brief overview of statistical sampling methodology from disciplines like
sampling of physical materials, experimental design, survey analysis, and
observational studies. Different notions of a 'representative sample' exist in
past and present literature. In particular, the contrast between the notion of
a representative sample in the sense of coverage of the input space, versus a
representative sample as a miniature of the target population is of relevance
when building AI systems. Using empirical demonstrations on US Census data, we
demonstrate that the first is useful for providing equality and demographic
parity, and is more robust to distribution shifts, whereas the latter notion is
useful in situations where the purpose is to make historical inference or draw
inference about the underlying population in general, or make better
predictions for the majority in the underlying population. We propose a
framework of questions for creating and documenting data, with data
representativity in mind, as an addition to existing datasheets for datasets.
Finally, we will also like to call for caution of implicit, in addition to
explicit, use of a notion of data representativeness without specific
clarification.</p>
  </details>
</details>
<details>
  <summary>55. <b>标题：Design of Detectors at the Electron Ion Collider with Artificial  Intelligence</b></summary>
  <p><b>编号</b>：[279]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04530</p>
  <p><b>作者</b>：Cristiano Fanelli</p>
  <p><b>备注</b>：12 pages, 5 figures</p>
  <p><b>关键词</b>：future high energy nuclear physics experiments, multiple design criteria also called objectives, detector design may include non, solve complex combinatorial problems, research across many disciplines</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Artificial Intelligence (AI) for design is a relatively new but active area
of research across many disciplines. Surprisingly when it comes to designing
detectors with AI this is an area at its infancy. The Electron Ion Collider is
the ultimate machine to study the strong force. The EIC is a large-scale
experiment with an integrated detector that extends for about $\pm$35 meters to
include the central, far-forward, and far-backward regions. The design of the
central detector is made by multiple sub-detectors, each in principle
characterized by a multidimensional design space and multiple design criteria
also called objectives. Simulations with Geant4 are typically compute
intensive, and the optimization of the detector design may include
non-differentiable terms as well as noisy objectives. In this context, AI can
offer state of the art solutions to solve complex combinatorial problems in an
efficient way. In particular, one of the proto-collaborations, ECCE, has
explored during the detector proposal the possibility of using multi-objective
optimization to design the tracking system of the EIC detector. This document
provides an overview of these techniques and recent progress made during the
EIC detector proposal. Future high energy nuclear physics experiments can
leverage AI-based strategies to design more efficient detectors by optimizing
their performance driven by physics criteria and minimizing costs for their
realization.</p>
  </details>
</details>
<details>
  <summary>56. <b>标题：Error-based Knockoffs Inference for Controlled Feature Selection</b></summary>
  <p><b>编号</b>：[283]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04483</p>
  <p><b>作者</b>：Xuebin Zhao,  Hong Chen,  Yingjie Wang,  Weifu Li,  Tieliang Gong,  Yulong Wang,  Feng Zheng</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：controlling false discovery proportion, address controlled feature selection, based feature importance statistics, based knockoff inference method, x knockoffs depends heavily</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recently, the scheme of model-X knockoffs was proposed as a promising
solution to address controlled feature selection under high-dimensional
finite-sample settings. However, the procedure of model-X knockoffs depends
heavily on the coefficient-based feature importance and only concerns the
control of false discovery rate (FDR). To further improve its adaptivity and
flexibility, in this paper, we propose an error-based knockoff inference method
by integrating the knockoff features, the error-based feature importance
statistics, and the stepdown procedure together. The proposed inference
procedure does not require specifying a regression model and can handle feature
selection with theoretical guarantees on controlling false discovery proportion
(FDP), FDR, or k-familywise error rate (k-FWER). Empirical evaluations
demonstrate the competitive performance of our approach on both simulated and
real data.</p>
  </details>
</details>
<details>
  <summary>57. <b>标题：Harmonicity Plays a Critical Role in DNN Based Versus in  Biologically-Inspired Monaural Speech Segregation Systems</b></summary>
  <p><b>编号</b>：[285]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04420</p>
  <p><b>作者</b>：Rahil Parikh (1),  Ilya Kavalerov (2),  Carol Espy-Wilson (1),  Shihab Shamma (1) ((1) Institute for Systems Research, University of Maryland, (2) Google Inc.)</p>
  <p><b>备注</b>：5 pages, IEEE International Conference on Acoustics, Speech, & Signal Processing (ICASSP), 2022</p>
  <p><b>关键词</b>：natural speech versus slightly manipulated inharmonic speech, even slightly harmonically jittered, dnn algorithms deviate markedly, harmonic jitter degrades performance, dnn )- based models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent advancements in deep learning have led to drastic improvements in
speech segregation models. Despite their success and growing applicability, few
efforts have been made to analyze the underlying principles that these networks
learn to perform segregation. Here we analyze the role of harmonicity on two
state-of-the-art Deep Neural Networks (DNN)-based models- Conv-TasNet and
DPT-Net. We evaluate their performance with mixtures of natural speech versus
slightly manipulated inharmonic speech, where harmonics are slightly frequency
jittered. We find that performance deteriorates significantly if one source is
even slightly harmonically jittered, e.g., an imperceptible 3% harmonic jitter
degrades performance of Conv-TasNet from 15.4 dB to 0.70 dB. Training the model
on inharmonic speech does not remedy this sensitivity, instead resulting in
worse performance on natural speech mixtures, making inharmonicity a powerful
adversarial factor in DNN models. Furthermore, additional analyses reveal that
DNN algorithms deviate markedly from biologically inspired algorithms that rely
primarily on timing cues and not harmonicity to segregate speech.</p>
  </details>
</details>
<details>
  <summary>58. <b>标题：MICDIR: Multi-scale Inverse-consistent Deformable Image Registration  using UNetMSS with Self-Constructing Graph Latent</b></summary>
  <p><b>编号</b>：[293]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04317</p>
  <p><b>作者</b>：Soumick Chatterjee,  Himanshi Bajaj,  Istiyak H. Siddiquee,  Nandish Bandi Subbarayappa,  Steve Simon,  Suraj Bangalore Shashidhar,  Oliver Speck,  Andreas Nürnberge</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：tackle various complex medical image processing problems, proposed method achieved significant improvements, deep learning based techniques, proposed using deep learning, including medical image registration</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Image registration is the process of bringing different images into a common
coordinate system - a technique widely used in various applications of computer
vision, such as remote sensing, image retrieval, and most commonly in medical
imaging. Deep Learning based techniques have been applied successfully to
tackle various complex medical image processing problems, including medical
image registration. Over the years, several image registration techniques have
been proposed using deep learning. Deformable image registration techniques
such as Voxelmorph have been successful in capturing finer changes and
providing smoother deformations. However, Voxelmorph, as well as ICNet and
FIRE, do not explicitly encode global dependencies (i.e. the overall anatomical
view of the supplied image) and therefore can not track large deformations. In
order to tackle the aforementioned problems, this paper extends the Voxelmorph
approach in three different ways. To improve the performance in case of small
as well as large deformations, supervision of the model at different
resolutions have been integrated using a multi-scale UNet. To support the
network to learn and encode the minute structural co-relations of the given
image-pairs, a self-constructing graph network (SCGNet) has been used as the
latent of the multi-scale UNet - which can improve the learning process of the
model and help the model to generalise better. And finally, to make the
deformations inverse-consistent, cycle consistency loss has been employed. On
the task of registration of brain MRIs, the proposed method achieved
significant improvements over ANTs and VoxelMorph, obtaining a Dice score of
0.8013$\pm$0.0243 for intramodal and 0.6211$\pm$0.0309 for intermodal, while
VoxelMorph achieved 0.7747$\pm$0.0260 and 0.6071$\pm$0.0510, respectively.</p>
  </details>
</details>
<details>
  <summary>59. <b>标题：Breast cancer detection using artificial intelligence techniques: A  systematic literature review</b></summary>
  <p><b>编号</b>：[296]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04308</p>
  <p><b>作者</b>：Ali Bou Nassif,  Manar Abu Talib,  Qassim Nasir,  Yaman Afadar,  Omar Elgendy</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：systematically reviewed previous work done, breast cancer using genetic sequencing, national breast cancer foundation, important features affecting detection, detected using genes</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Cancer is one of the most dangerous diseases to humans, and yet no permanent
cure has been developed for it. Breast cancer is one of the most common cancer
types. According to the National Breast Cancer foundation, in 2020 alone, more
than 276,000 new cases of invasive breast cancer and more than 48,000
non-invasive cases were diagnosed in the US. To put these figures in
perspective, 64% of these cases are diagnosed early in the disease's cycle,
giving patients a 99% chance of survival. Artificial intelligence and machine
learning have been used effectively in detection and treatment of several
dangerous diseases, helping in early diagnosis and treatment, and thus
increasing the patient's chance of survival. Deep learning has been designed to
analyze the most important features affecting detection and treatment of
serious diseases. For example, breast cancer can be detected using genes or
histopathological imaging. Analysis at the genetic level is very expensive, so
histopathological imaging is the most common approach used to detect breast
cancer. In this research work, we systematically reviewed previous work done on
detection and treatment of breast cancer using genetic sequencing or
histopathological imaging with the help of deep learning and machine learning.
We also provide recommendations to researchers who will work in this field</p>
  </details>
</details>
<details>
  <summary>60. <b>标题：Source-free Domain Adaptation for Multi-site and Lifespan Brain Skull  Stripping</b></summary>
  <p><b>编号</b>：[301]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04299</p>
  <p><b>作者</b>：Yunxiang Li,  Ruilong Dan,  Shuai Wang,  Yifan Cao,  Xiangde Luo,  Chenghao Tan,  Gangyong Jia,  Huiyu Zhou,  Yaqi Wang,  Li Wang</p>
  <p><b>备注</b>：11 page</p>
  <p><b>关键词</b>：accomplish domain adaptation without access, without disclosing private information, although many excellent works, free domain adaptation framework, numerous domain adaptation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Skull stripping is a crucial prerequisite step in the analysis of brain
magnetic resonance (MR) images. Although many excellent works or tools have
been proposed, they suffer from low generalization capability. For instance,
the model trained on a dataset with specific imaging parameters (source domain)
cannot be well applied to other datasets with different imaging parameters
(target domain). Especially, for the lifespan datasets, the model trained on an
adult dataset is not applicable to an infant dataset due to the large domain
difference. To address this issue, numerous domain adaptation (DA) methods have
been proposed to align the extracted features between the source and target
domains, requiring concurrent access to the input images of both domains.
Unfortunately, it is problematic to share the images due to privacy. In this
paper, we design a source-free domain adaptation framework (SDAF) for
multi-site and lifespan skull stripping that can accomplish domain adaptation
without access to source domain images. Our method only needs to share the
source labels as shape dictionaries and the weights trained on the source data,
without disclosing private information from source domain subjects. To deal
with the domain shift between multi-site lifespan datasets, we take advantage
of the brain shape prior which is invariant to imaging parameters and ages.
Experiments demonstrate that our framework can significantly outperform the
state-of-the-art methods on multi-site lifespan datasets.</p>
  </details>
</details>
<details>
  <summary>61. <b>标题：NaviAirway: a bronchiole-sensitive deep learning-based airway  segmentation pipeline for planning of navigation bronchoscopy</b></summary>
  <p><b>编号</b>：[303]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04294</p>
  <p><b>作者</b>：Andong Wang,  Terence Chi Chun Tam,  Ho Ming Poon,  Kun-Chang Yu,  Wei-Ning Lee</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：inspired iterative training strategy, four major novel components, propose two new metrics, naviairway takes five minutes, naviairway outperformed existing methods</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Navigation bronchoscopy is a minimally invasive procedure in which doctors
pass a bronchoscope into a subject's airways to sample the target pulmonary
lesion. A three-dimensional (3D) airway roadmap reconstructed from Computer
Tomography (CT) scans is a prerequisite for this procedure, especially when the
target is distally located. Therefore, an accurate and efficient airway
segmentation algorithm is essential to reduce bronchoscopists' burden of
pre-procedural airway identification as well as patients' discomfort during the
prolonged procedure. However, airway segmentation remains a challenging task
because of the intrinsic complex tree-like structure, imbalanced sizes of
airway branches, potential domain shifts of CT scans, and few available labeled
images. To address these problems, we present a deep learning-based pipeline,
denoted as NaviAirway, which finds finer bronchioles through four major novel
components - feature extractor modules in model architecture design, a
bronchiole-sensitive loss function, a human-vision-inspired iterative training
strategy, and a semi-supervised learning framework to utilize unlabeled CT
images. Experimental results showed that NaviAirway outperformed existing
methods, particularly in identification of higher generation bronchioles and
robustness to new CT scans. On average, NaviAirway takes five minutes to
segment the CT scans of one patient on a GPU-embedded computer. Moreover, we
propose two new metrics to complement conventional ones for a more
comprehensive and fairer evaluation of deep learning-based airway segmentation
approaches. The code is publicly available on
this https URL.</p>
  </details>
</details>
<details>
  <summary>62. <b>标题：Self-supervised learning for analysis of temporal and morphological drug  effects in cancer cell imaging data</b></summary>
  <p><b>编号</b>：[306]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2203.04289</p>
  <p><b>作者</b>：Andrei Dmitrenko,  Mauro M. Masiero,  Nicola Zamboni</p>
  <p><b>备注</b>：Accepted to MIDL 2022 conference. 17 pages, 12 figures, 3 tables</p>
  <p><b>关键词</b>：different experimental conditions using imaging data, identify clusters allowing annotation, 2d cancer cell cultures, morphological phenotypic effects caused, foster transfer learning applications</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this work, we propose two novel methodologies to study temporal and
morphological phenotypic effects caused by different experimental conditions
using imaging data. As a proof of concept, we apply them to analyze drug
effects in 2D cancer cell cultures. We train a convolutional autoencoder on 1M
images dataset with random augmentations and multi-crops to use as feature
extractor. We systematically compare it to the pretrained state-of-the-art
models. We further use the feature extractor in two ways. First, we apply
distance-based analysis and dynamic time warping to cluster temporal patterns
of 31 drugs. We identify clusters allowing annotation of drugs as having
cytotoxic, cytostatic, mixed or no effect. Second, we implement an
adversarial/regularized learning setup to improve classification of 31 drugs
and visualize image regions that contribute to the improvement. We increase
top-3 classification accuracy by 8% on average and mine examples of
morphological feature importance maps. We provide the feature extractor and the
weights to foster transfer learning applications in biology. We also discuss
utility of other pretrained models and applicability of our methods to other
types of biomedical data.</p>
  </details>
</details>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">徐耀彬</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://louishsu.xyz/2022/03/11/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html">http://louishsu.xyz/2022/03/11/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://louishsu.xyz" target="_blank">LOUIS' BLOG</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"></div><div class="post_share"><div class="social-share" data-image="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="next-post pull-full"><a href="/2021/10/22/%E4%B8%AD%E5%9B%BD%E6%B3%95%E5%BE%8B%E6%99%BA%E8%83%BD%E6%8A%80%E6%9C%AF%E8%AF%84%E6%B5%8B(CAIL2021)%EF%BC%9A%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96(Rank2).html"><img class="next-cover" src="http://cail.cipsc.org.cn/img/index_mainpic.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">中国法律智能技术评测(CAIL2021)：信息抽取(Rank2)</div></div></a></div></nav><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="twikoo-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="card-info-avatar is-center"><img class="avatar-img" src="/img/touxiang.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/><div class="author-info__name">徐耀彬</div><div class="author-info__description">做知识的原创者！</div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">11</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">标签</div><div class="length-num">3</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">分类</div><div class="length-num">7</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/isLouisHsu"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/isLouisHsu" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:is.louishsu@foxmail.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>公告</span></div><div class="announcement_content">记录和分享一些学习和开源内容，若有问题可通过邮箱is.louishsu@foxmail.com联系，欢迎交流！！</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">1.</span> <span class="toc-text">统计</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">2.</span> <span class="toc-text">计算机视觉</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">3.</span> <span class="toc-text">自然语言处理</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">4.</span> <span class="toc-text">机器学习</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">5.</span> <span class="toc-text">人工智能</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2022/03/11/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html" title="Arxiv每日速递(2022-03-11)"><img src="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Arxiv每日速递(2022-03-11)"/></a><div class="content"><a class="title" href="/2022/03/11/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html" title="Arxiv每日速递(2022-03-11)">Arxiv每日速递(2022-03-11)</a><time datetime="2022-03-11T00:36:40.477Z" title="发表于 2022-03-11 08:36:40">2022-03-11</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/10/22/%E4%B8%AD%E5%9B%BD%E6%B3%95%E5%BE%8B%E6%99%BA%E8%83%BD%E6%8A%80%E6%9C%AF%E8%AF%84%E6%B5%8B(CAIL2021)%EF%BC%9A%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96(Rank2).html" title="中国法律智能技术评测(CAIL2021)：信息抽取(Rank2)"><img src="http://cail.cipsc.org.cn/img/index_mainpic.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="中国法律智能技术评测(CAIL2021)：信息抽取(Rank2)"/></a><div class="content"><a class="title" href="/2021/10/22/%E4%B8%AD%E5%9B%BD%E6%B3%95%E5%BE%8B%E6%99%BA%E8%83%BD%E6%8A%80%E6%9C%AF%E8%AF%84%E6%B5%8B(CAIL2021)%EF%BC%9A%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96(Rank2).html" title="中国法律智能技术评测(CAIL2021)：信息抽取(Rank2)">中国法律智能技术评测(CAIL2021)：信息抽取(Rank2)</a><time datetime="2021-10-22T14:29:06.000Z" title="发表于 2021-10-22 22:29:06">2021-10-22</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/05/19/%E5%85%A8%E7%90%83%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%8A%80%E6%9C%AF%E5%88%9B%E6%96%B0%E5%A4%A7%E8%B5%9B%E3%80%90%E8%B5%9B%E9%81%93%E4%B8%80%E3%80%91%EF%BC%9A%E5%8C%BB%E5%AD%A6%E5%BD%B1%E5%83%8F%E6%8A%A5%E5%91%8A%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B.html" title="全球人工智能技术创新大赛【赛道一】：医学影像报告异常检测"><img src="https://tianchi-public.oss-cn-hangzhou.aliyuncs.com/public/files/forum/161037709574435991610377095138.jpeg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="全球人工智能技术创新大赛【赛道一】：医学影像报告异常检测"/></a><div class="content"><a class="title" href="/2021/05/19/%E5%85%A8%E7%90%83%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%8A%80%E6%9C%AF%E5%88%9B%E6%96%B0%E5%A4%A7%E8%B5%9B%E3%80%90%E8%B5%9B%E9%81%93%E4%B8%80%E3%80%91%EF%BC%9A%E5%8C%BB%E5%AD%A6%E5%BD%B1%E5%83%8F%E6%8A%A5%E5%91%8A%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B.html" title="全球人工智能技术创新大赛【赛道一】：医学影像报告异常检测">全球人工智能技术创新大赛【赛道一】：医学影像报告异常检测</a><time datetime="2021-05-19T09:57:06.000Z" title="发表于 2021-05-19 17:57:06">2021-05-19</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2020/09/16/%E8%AF%A6%E8%A7%A3%E5%91%BD%E5%90%8D%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB%E6%A8%A1%E5%9E%8B%EF%BC%9ALSTM-CRF.html" title="详解命名实体识别模型：LSTM-CRF"><img src="https://gimg2.baidu.com/image_search/src=http%3A%2F%2Fpic1.zhimg.com%2Fv2-1ed6a10dbb239a148e42df088c5870a6_1440w.jpg%3Fsource%3D172ae18b&amp;refer=http%3A%2F%2Fpic1.zhimg.com&amp;app=2002&amp;size=f9999,10000&amp;q=a80&amp;n=0&amp;g=0n&amp;fmt=jpeg?sec=1638183974&amp;t=4632f13fd487ed1cfcb12d67a6b71e52" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="详解命名实体识别模型：LSTM-CRF"/></a><div class="content"><a class="title" href="/2020/09/16/%E8%AF%A6%E8%A7%A3%E5%91%BD%E5%90%8D%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB%E6%A8%A1%E5%9E%8B%EF%BC%9ALSTM-CRF.html" title="详解命名实体识别模型：LSTM-CRF">详解命名实体识别模型：LSTM-CRF</a><time datetime="2020-09-16T09:26:44.000Z" title="发表于 2020-09-16 17:26:44">2020-09-16</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2020/06/14/%E8%AE%B0%E4%B8%80%E6%AC%A1MySQL%E8%A7%A3%E5%86%B3%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E6%97%B6%E7%9A%84%E5%88%86%E8%A1%A8%E9%97%AE%E9%A2%98.html" title="记一次MySQL解决大数据存储时的分表问题"><img src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="记一次MySQL解决大数据存储时的分表问题"/></a><div class="content"><a class="title" href="/2020/06/14/%E8%AE%B0%E4%B8%80%E6%AC%A1MySQL%E8%A7%A3%E5%86%B3%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E6%97%B6%E7%9A%84%E5%88%86%E8%A1%A8%E9%97%AE%E9%A2%98.html" title="记一次MySQL解决大数据存储时的分表问题">记一次MySQL解决大数据存储时的分表问题</a><time datetime="2020-06-14T15:24:27.000Z" title="发表于 2020-06-14 23:24:27">2020-06-14</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2022 By 徐耀彬</div><div class="footer_custom_text"><p><a style="margin-inline:5px"target="_blank"href="https://hexo.io/"><img src="https://img.shields.io/badge/Frame-Hexo-blue?style=flat&logo=hexo"title="博客框架为Hexo"alt="img"></a><a style="margin-inline:5px"target="_blank"href="https://butterfly.js.org/"><img src="https://img.shields.io/badge/Theme-Butterfly-6513df?style=flat&logo=bitdefender"title="主题采用butterfly"alt="img"></a><a style="margin-inline:5px"target="_blank"href="https://www.jsdelivr.com/"><img src="https://img.shields.io/badge/CDN-jsDelivr-orange?style=flat&logo=jsDelivr"title="本站使用JsDelivr为静态资源提供CDN加速"alt="img"></a><a style="margin-inline:5px"target="_blank"href="https://github.com/"><img src="https://img.shields.io/badge/Source-Github-d021d6?style=flat&logo=GitHub"title="本站项目由Gtihub托管"alt="img"></a><a style="margin-inline:5px"target="_blank"href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img src="https://img.shields.io/badge/Copyright-BY--NC--SA%204.0-d42328?style=flat&logo=Claris"alt="img"title="本站采用知识共享署名-非商业性使用-相同方式共享4.0国际许可协议进行许可"></a></br></p></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="font-plus" type="button" title="放大字体"><i class="fas fa-plus"></i></button><button id="font-minus" type="button" title="缩小字体"><i class="fas fa-minus"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div></div><hr/><div id="local-search-results"></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.css"><script>(() => {
  document.querySelectorAll('#article-container span.katex-display').forEach(item => {
    btf.wrap(item, 'div', '', 'katex-wrap')
  })
})()</script><script>(()=>{
  const $countDom = document.getElementById('twikoo-count')
  const init = () => {
    let initData = {
      el: '#twikoo-wrap',
      envId: 'blog-',
      region: ''
    }

    if (false) {
      const otherData = false
      initData = Object.assign(initData, otherData)
    }
    
    twikoo.init(initData)
  }

  const getCount = () => {
    twikoo.getCommentsCount({
      envId: 'blog-',
      region: '',
      urls: [window.location.pathname],
      includeReply: false
    }).then(function (res) {
      $countDom.innerText = res[0].count
    }).catch(function (err) {
      console.error(err);
    });
  }

  const loadTwikoo = (bool = false) => {
    if (typeof twikoo === 'object') {
      init()
      bool && $countDom && setTimeout(getCount,0)
    } else {
      getScript('https://cdn.jsdelivr.net/npm/twikoo/dist/twikoo.all.min.js').then(()=> {
        init()
        bool && $countDom && setTimeout(getCount,0)
      })
    }
  }

  if ('Twikoo' === 'Twikoo' || !false) {
    if (false) btf.loadComment(document.getElementById('twikoo-wrap'), loadTwikoo)
    else loadTwikoo(true)
  } else {
    window.loadOtherComment = () => {
      loadTwikoo()
    }
  }
})()</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><!-- hexo injector body_end start --> <script data-pjax>if(document.getElementById('recent-posts') && (location.pathname ==='/'|| '/' ==='all')){
    var parent = document.getElementById('recent-posts');
    var child = '<div class="recent-post-item" style="width:100%;height: auto"><div id="catalog_magnet"><div class="magnet_item"><a class="magnet_link" href="http://louishsu.xyz/categories/机器学习/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🐱 机器学习 (1)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://louishsu.xyz/categories/自然语言处理/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">📚 自然语言处理 (1)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://louishsu.xyz/categories/竞赛相关/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🎮 竞赛相关 (2)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://louishsu.xyz/categories/阅读笔记/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🎮 阅读笔记 (1)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><a class="magnet_link_more"  href="http://louishsu.xyz/categories" style="flex:1;text-align: center;margin-bottom: 10px;">查看更多...</a></div></div>';
    console.log('已挂载magnet')
    parent.insertAdjacentHTML("afterbegin",child)}
     </script><style>#catalog_magnet{flex-wrap: wrap;display: flex;width:100%;justify-content:space-between;padding: 10px 10px 0 10px;align-content: flex-start;}.magnet_item{flex-basis: calc(50% - 5px);background: #f2f2f2;margin-bottom: 10px;border-radius: 8px;transition: all 0.2s ease-in-out;}.magnet_item:hover{background: #b30070}.magnet_link_more{color:#555}.magnet_link{color:black}.magnet_link:hover{color:white}@media screen and (max-width: 600px) {.magnet_item {flex-basis: 100%;}}.magnet_link_context{display:flex;padding: 10px;font-size:16px;transition: all 0.2s ease-in-out;}.magnet_link_context:hover{padding: 10px 20px;}</style>
    <style></style>
  <script data-pjax src="https://cdn.jsdelivr.net/gh/Zfour/hexo-github-calendar@1.21/hexo_githubcalendar.js"></script>
  <script data-pjax>
        function GithubCalendarConfig(){
            var git_githubapiurl ="https://python-github-calendar-api.vercel.app/api?isLouisHsu";
            var git_color =['#ebedf0', '#fdcdec', '#fc9bd9', '#fa6ac5', '#f838b2', '#f5089f', '#c4067e', '#92055e', '#540336', '#48022f', '#30021f'];
            var git_user ="isLouisHsu";
            var parent_div_git = document.getElementById('recent-posts');
            var git_div_html = '<div class="recent-post-item" style="width:100%;height:auto;padding:10px;"><div id="github_loading" style="width:10%;height:100%;margin:0 auto;display: block"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"  viewBox="0 0 50 50" style="enable-background:new 0 0 50 50" xml:space="preserve"><path fill="#d0d0d0" d="M25.251,6.461c-10.318,0-18.683,8.365-18.683,18.683h4.068c0-8.071,6.543-14.615,14.615-14.615V6.461z" transform="rotate(275.098 25 25)"><animateTransform attributeType="xml" attributeName="transform" type="rotate" from="0 25 25" to="360 25 25" dur="0.6s" repeatCount="indefinite"></animateTransform></path></svg></div><div id="github_container"></div></div>';
            if(parent_div_git && location.pathname =='/'){
                console.log('已挂载github calendar')
                // parent_div_git.innerHTML=git_div_html+parent_div_git.innerHTML // 无报错，但不影响使用(支持pjax跳转)
                parent_div_git.insertAdjacentHTML("afterbegin",git_div_html) // 有报错，但不影响使用(支持pjax跳转)
            };
            GithubCalendar(git_githubapiurl,git_color,git_user)
        }
        if(document.getElementById('recent-posts')){
            GithubCalendarConfig()
        }
    </script>
    <style>#github_container{min-height:280px}@media screen and (max-width:650px) {#github_container{background-image:;min-height:0px}}</style>
    <style></style><script data-pjax>function electric_clock_injector_config(){
                var parent_div_git = document.getElementsByClassName('sticky_layout')[0];
                var item_html = '<div class="card-widget card-clock"><div class="card-glass"><div class="card-background"><div class="card-content"><div id="hexo_electric_clock"><img id="card-clock-loading" src="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-clock/clock/images/weather/loading.gif" style="height: 120px; width: 100%;" data-ll-status="loading" class="entered loading"></div></div></div></div></div>';
                console.log('已挂载electric_clock')
                // parent_div_git.innerHTML=item_html+parent_div_git.innerHTML // 无报错，但不影响使用(支持pjax跳转)
                parent_div_git.insertAdjacentHTML("afterbegin",item_html) // 有报错，但不影响使用(支持pjax跳转)
            }if( document.getElementsByClassName('sticky_layout')[0] && (location.pathname ==='all'|| 'all' ==='all')){

            electric_clock_injector_config()
        } </script><script src="https://pv.sohu.com/cityjson?ie=utf-8"></script><script data-pjax  src="https://cdn.jsdelivr.net/gh/Zfour/hexo-electric-clock@1.0.6/clock.js"></script><!-- hexo injector body_end end --><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"model":{"jsonPath":"/live2dw/assets/hijiki.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":false},"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body></html>