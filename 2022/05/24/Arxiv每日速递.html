<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Arxiv每日速递(2022-05-24) | LOUIS' BLOG</title><meta name="author" content="徐耀彬"><meta name="copyright" content="徐耀彬"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="本篇博文主要展示每日从Arxiv论文网站获取的最新论文列表，以计算机视觉、自然语言处理、机器学习、人工智能等大方向进行划分。 统计 今日共更新312篇论文，其中：  59篇计算机视觉（cs.CV） 34篇自然语言处理（cs.CL） 149篇机器学习（cs.LG） 82篇人工智能（cs.AI）  计算机视觉    1. 标题：Enriching StyleGAN with Illumination">
<meta property="og:type" content="article">
<meta property="og:title" content="Arxiv每日速递(2022-05-24)">
<meta property="og:url" content="http://louishsu.xyz/2022/05/24/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html">
<meta property="og:site_name" content="LOUIS&#39; BLOG">
<meta property="og:description" content="本篇博文主要展示每日从Arxiv论文网站获取的最新论文列表，以计算机视觉、自然语言处理、机器学习、人工智能等大方向进行划分。 统计 今日共更新312篇论文，其中：  59篇计算机视觉（cs.CV） 34篇自然语言处理（cs.CL） 149篇机器学习（cs.LG） 82篇人工智能（cs.AI）  计算机视觉    1. 标题：Enriching StyleGAN with Illumination">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png">
<meta property="article:published_time" content="2022-05-24T00:46:21.361Z">
<meta property="article:modified_time" content="2022-05-24T00:47:51.067Z">
<meta property="article:author" content="徐耀彬">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://louishsu.xyz/2022/05/24/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2022-05-24 08:47:51'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const fontSizeVal = saveToLocal.get('global-font-size')
    if (fontSizeVal !== undefined) {
      document.documentElement.style.setProperty('--global-font-size', fontSizeVal + 'px')
    }
    })(window)</script><link rel="stylesheet" href="/css/background.css"><script src="https://cdn.jsdelivr.net/npm/echarts@4.7.0/dist/echarts.min.js"></script><!-- hexo injector head_end start --><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Zfour/hexo-electric-clock@1.0.6/clock.css"><!-- hexo injector head_end end --><meta name="generator" content="Hexo 5.4.2"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="author-avatar"><img class="avatar-img" src="/img/touxiang.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">11</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">标签</div><div class="length-num">3</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">分类</div><div class="length-num">7</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/message/"><i class="fa-fw far fa-comment-dots"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa-fw fa fa-book"></i><span> 找文章</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></li><li><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></li><li><a class="site-page" href="/charts/"><i class="fa-fw fa fa-archive"></i><span> 统计</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-tools"></i><span> 工具</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/md_editor/"><i class="fa-fw fas fa-pen"></i><span> 在线markdown</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/isLouisHsu/blog/tree/master/source/_posts"><i class="fa-fw fa fa-star"></i><span> 在线push</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">LOUIS' BLOG</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/message/"><i class="fa-fw far fa-comment-dots"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa-fw fa fa-book"></i><span> 找文章</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></li><li><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></li><li><a class="site-page" href="/charts/"><i class="fa-fw fa fa-archive"></i><span> 统计</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-tools"></i><span> 工具</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/md_editor/"><i class="fa-fw fas fa-pen"></i><span> 在线markdown</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/isLouisHsu/blog/tree/master/source/_posts"><i class="fa-fw fa fa-star"></i><span> 在线push</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Arxiv每日速递(2022-05-24)<a class="post-edit-link" href="https://github.com/isLouisHsu/blog/tree/master/source_posts/Arxiv每日速递.md" title="编辑" target="_blank"><i class="fas fa-pencil-square"></i></a></h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-05-24T00:46:21.361Z" title="发表于 2022-05-24 08:46:21">2022-05-24</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2022-05-24T00:47:51.067Z" title="更新于 2022-05-24 08:47:51">2022-05-24</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">阅读笔记</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">80.9k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>484分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span><span class="post-meta-separator">|</span><span class="post-meta-commentcount"><i class="far fa-comments fa-fw post-meta-icon"></i><span class="post-meta-label">评论数:</span><a href="/2022/05/24/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html#post-comment"><span id="twikoo-count"></span></a></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><p>本篇博文主要展示每日从Arxiv论文网站获取的最新论文列表，以计算机视觉、自然语言处理、机器学习、人工智能等大方向进行划分。</p>
<h1>统计</h1>
<p>今日共更新312篇论文，其中：</p>
<ul>
<li>59篇计算机视觉（<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>）</li>
<li>34篇自然语言处理（<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>）</li>
<li>149篇机器学习（cs.LG）</li>
<li>82篇人工智能（<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>）</li>
</ul>
<h1>计算机视觉</h1>
<details>
  <summary>1. <b>标题：Enriching StyleGAN with Illumination Physics</b></summary>
  <p><b>编号</b>：[1]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10351</p>
  <p><b>作者</b>：Anand Bhattad,  D.A. Forsyth</p>
  <p><b>备注</b>：Project page: this https URL</p>
  <p><b>关键词</b>：impressively disentangled, images, StyleGAN, scene, latent codes</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>StyleGAN generates novel images of a scene from latent codes which are
impressively disentangled. But StyleGAN generates images that are "like" its
training set. This paper shows how to use simple physical properties of images
to enrich StyleGAN's generation capacity. We use an intrinsic image method to
decompose an image, then search the latent space of a pretrained StyleGAN to
find novel directions that fix one component (say, albedo) and vary another
(say, shading). Therefore, we can change the lighting of a complex scene
without changing the scene layout, object colors, and shapes. Or we can change
the colors of objects without changing shading intensity or their scene layout.
Our experiments suggest the proposed method, StyLitGAN, can add and remove
luminaires in the scene and generate images with realistic lighting effects --
cast shadows, soft shadows, inter-reflections, glossy effects -- requiring no
labeled paired relighting data or any other geometric supervision. Qualitative
evaluation confirms that our generated images are realistic and that we can
change or fix components at will. Quantitative evaluation shows that
pre-trained StyleGAN could not produce the images StyLitGAN produces; we can
automatically generate realistic out-of-distribution images, and so can
significantly enrich the range of images StyleGAN can produce.</p>
  </details>
</details>
<details>
  <summary>2. <b>标题：Diverse super-resolution with pretrained deep hiererarchical VAEs</b></summary>
  <p><b>编号</b>：[4]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10347</p>
  <p><b>作者</b>：Jean Prost,  Antoine Houdard,  Nicolas Papadakis,  Andrés Almansa</p>
  <p><b>备注</b>：21 pages , 5 figures</p>
  <p><b>关键词</b>：deep-learning based methods, VD-VAE latent space, deep-learning based, provide one single, latent</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Image super-resolution is a one-to-many problem, but most deep-learning based
methods only provide one single solution to this problem. In this work, we
tackle the problem of diverse super-resolution by reusing VD-VAE, a
state-of-the art variational autoencoder (VAE). We find that the hierarchical
latent representation learned by VD-VAE naturally separates the image
low-frequency information, encoded in the latent groups at the top of the
hierarchy, from the image high-frequency details, determined by the latent
groups at the bottom of the latent hierarchy. Starting from this observation,
we design a super-resolution model exploiting the specific structure of VD-VAE
latent space. Specifically, we train an encoder to encode low-resolution images
in the subset of VD-VAE latent space encoding the low-frequency information,
and we combine this encoder with VD-VAE generative model to sample diverse
super-resolved version of a low-resolution input. We demonstrate the ability of
our method to generate diverse solutions to the super-resolution problem on
face super-resolution with upsampling factors x4, x8, and x16.</p>
  </details>
</details>
<details>
  <summary>3. <b>标题：Efficient visual object representation using a biologically plausible  spike-latency code and winner-take-all inhibition</b></summary>
  <p><b>编号</b>：[6]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10338</p>
  <p><b>作者</b>：Melani Sanchez-Garcia,  Michael Beyeler</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：surpassed human performance, Deep neural networks, key visual challenges, amount of energy, surpassed human</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep neural networks have surpassed human performance in key visual
challenges such as object recognition, but require a large amount of energy,
computation, and memory. In contrast, spiking neural networks (SNNs) have the
potential to improve both the efficiency and biological plausibility of object
recognition systems. Here we present a SNN model that uses spike-latency coding
and winner-take-all inhibition (WTA-I) to efficiently represent visual stimuli
from the Fashion MNIST dataset. Stimuli were preprocessed with center-surround
receptive fields and then fed to a layer of spiking neurons whose synaptic
weights were updated using spike-timing-dependent-plasticity (STDP). We
investigate how the quality of the represented objects changes under different
WTA-I schemes and demonstrate that a network of 150 spiking neurons can
efficiently represent objects with as little as 40 spikes. Studying how core
object recognition may be implemented using biologically plausible learning
rules in SNNs may not only further our understanding of the brain, but also
lead to novel and efficient artificial vision systems.</p>
  </details>
</details>
<details>
  <summary>4. <b>标题：UViM: A Unified Modeling Approach for Vision with Learned Guiding Codes</b></summary>
  <p><b>编号</b>：[7]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10337</p>
  <p><b>作者</b>：Alexander Kolesnikov,  André Susano Pinto,  Lucas Beyer,  Xiaohua Zhai,  Jeremiah Harmsen,  Neil Houlsby</p>
  <p><b>备注</b>：Alexander and Andr\'e share the first authorship, all authors made significant technical contributions to this work</p>
  <p><b>关键词</b>：wide range, vision tasks, unified approach capable, computer vision tasks, tasks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We introduce UViM, a unified approach capable of modeling a wide range of
computer vision tasks. In contrast to previous models, UViM has the same
functional form for all tasks; it requires no task-specific modifications which
require extensive human expertise. The approach involves two components: (I) a
base model (feed-forward) which is trained to directly predict raw vision
outputs, guided by a learned discrete code and (II) a language model
(autoregressive) that is trained to generate the guiding code. These components
complement each other: the language model is well-suited to modeling structured
interdependent data, while the base model is efficient at dealing with
high-dimensional outputs. We demonstrate the effectiveness of UViM on three
diverse and challenging vision tasks: panoptic segmentation, depth prediction
and image colorization, where we achieve competitive and near state-of-the-art
results. Our experimental results suggest that UViM is a promising candidate
for a unified modeling approach in computer vision.</p>
  </details>
</details>
<details>
  <summary>5. <b>标题：UCC: Uncertainty guided Cross-head Co-training for Semi-Supervised  Semantic Segmentation</b></summary>
  <p><b>编号</b>：[8]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10334</p>
  <p><b>作者</b>：Jiashuo Fan,  Bin Gao,  Huan Jin,  Lihui Jiang</p>
  <p><b>备注</b>：10 pages, CVPR2022</p>
  <p><b>关键词</b>：Deep neural networks, witnessed great successes, Uncertainty guided Cross-head, Deep neural, neural networks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep neural networks (DNNs) have witnessed great successes in semantic
segmentation, which requires a large number of labeled data for training. We
present a novel learning framework called Uncertainty guided Cross-head
Co-training (UCC) for semi-supervised semantic segmentation. Our framework
introduces weak and strong augmentations within a shared encoder to achieve
co-training, which naturally combines the benefits of consistency and
self-training. Every segmentation head interacts with its peers and, the weak
augmentation result is used for supervising the strong. The consistency
training samples' diversity can be boosted by Dynamic Cross-Set Copy-Paste
(DCSCP), which also alleviates the distribution mismatch and class imbalance
problems. Moreover, our proposed Uncertainty Guided Re-weight Module (UGRM)
enhances the self-training pseudo labels by suppressing the effect of the
low-quality pseudo labels from its peer via modeling uncertainty. Extensive
experiments on Cityscapes and PASCAL VOC 2012 demonstrate the effectiveness of
our UCC. Our approach significantly outperforms other state-of-the-art
semi-supervised semantic segmentation methods. It achieves 77.17$\%$, 76.49$\%$
mIoU on Cityscapes and PASCAL VOC 2012 datasets respectively under 1/16
protocols, which are +10.1$\%$, +7.91$\%$ better than the supervised baseline.</p>
  </details>
</details>
<details>
  <summary>6. <b>标题：Pre-Train Your Loss: Easy Bayesian Transfer Learning with Informative  Priors</b></summary>
  <p><b>编号</b>：[25]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10279</p>
  <p><b>作者</b>：Ravid Shwartz-Ziv,  Micah Goldblum,  Hossein Souri,  Sanyam Kapoor,  Chen Zhu,  Yann LeCun,  Andrew Gordon Wilson</p>
  <p><b>备注</b>：Code available at this https URL</p>
  <p><b>关键词</b>：large foundation models, source task, transfer learning paradigm, increasingly moving, paradigm whereby large</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep learning is increasingly moving towards a transfer learning paradigm
whereby large foundation models are fine-tuned on downstream tasks, starting
from an initialization learned on the source task. But an initialization
contains relatively little information about the source task. Instead, we show
that we can learn highly informative posteriors from the source task, through
supervised or self-supervised approaches, which then serve as the basis for
priors that modify the whole loss surface on the downstream task. This simple
modular approach enables significant performance gains and more data-efficient
learning on a variety of downstream classification and segmentation tasks,
serving as a drop-in replacement for standard pre-training strategies. These
highly informative priors also can be saved for future use, similar to
pre-trained weights, and stand in contrast to the zero-mean isotropic
uninformative priors that are typically used in Bayesian deep learning.</p>
  </details>
</details>
<details>
  <summary>7. <b>标题：Salient Skin Lesion Segmentation via Dilated Scale-Wise Feature Fusion  Network</b></summary>
  <p><b>编号</b>：[28]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10272</p>
  <p><b>作者</b>：Pourya Shamsolmoali,  Masoumeh Zareapoor,  Eric Granger,  Huiyu Zhou</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Skin lesion, computerized apparatus, dermoscopic images, images is essential, accurate and early</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Skin lesion detection in dermoscopic images is essential in the accurate and
early diagnosis of skin cancer by a computerized apparatus. Current skin lesion
segmentation approaches show poor performance in challenging circumstances such
as indistinct lesion boundaries, low contrast between the lesion and the
surrounding area, or heterogeneous background that causes over/under
segmentation of the skin lesion. To accurately recognize the lesion from the
neighboring regions, we propose a dilated scale-wise feature fusion network
based on convolution factorization. Our network is designed to simultaneously
extract features at different scales which are systematically fused for better
detection. The proposed model has satisfactory accuracy and efficiency. Various
experiments for lesion segmentation are performed along with comparisons with
the state-of-the-art models. Our proposed model consistently showcases
state-of-the-art results.</p>
  </details>
</details>
<details>
  <summary>8. <b>标题：Compression ensembles quantify aesthetic complexity and the evolution of  visual art</b></summary>
  <p><b>编号</b>：[29]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10271</p>
  <p><b>作者</b>：Andres Karjus,  Mar Canet Solà,  Tillmann Ohm,  Sebastian E. Ahnert,  Maximilian Schich</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：long history, previously operationalized, visual, approach, compression</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The quantification of visual aesthetics and complexity have a long history,
the latter previously operationalized via the application of compression
algorithms. Here we generalize and extend the compression approach beyond
simple complexity measures to quantify algorithmic distance in historical and
contemporary visual media. The proposed "ensemble" approach works by
compressing a large number of transformed versions of a given input image,
resulting in a vector of associated compression ratios. This approach is more
efficient than other compression-based algorithmic distances, and is
particularly suited for the quantitative analysis of visual artifacts, because
human creative processes can be understood as algorithms in the broadest sense.
Unlike comparable image embedding methods using machine learning, our approach
is fully explainable through the transformations. We demonstrate that the
method is cognitively plausible and fit for purpose by evaluating it against
human complexity judgments, and on automated detection tasks of authorship and
style. We show how the approach can be used to reveal and quantify trends in
art historical data, both on the scale of centuries and in rapidly evolving
contemporary NFT art markets. We further quantify temporal resemblance to
disambiguate artists outside the documented mainstream from those who are
deeply embedded in Zeitgeist. Finally, we note that compression ensembles
constitute a quantitative representation of the concept of visual family
resemblance, as distinct sets of dimensions correspond to shared visual
characteristics otherwise hard to pin down. Our approach provides a new
perspective for the study of visual art, algorithmic image analysis, and
quantitative aesthetics more generally.</p>
  </details>
</details>
<details>
  <summary>9. <b>标题：B-cos Networks: Alignment is All We Need for Interpretability</b></summary>
  <p><b>编号</b>：[30]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10268</p>
  <p><b>作者</b>：Moritz Böhle,  Mario Fritz,  Bernt Schiele</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：deep neural networks, promoting weight-input alignment, direction for increasing, deep neural, promoting weight-input</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present a new direction for increasing the interpretability of deep neural
networks (DNNs) by promoting weight-input alignment during training. For this,
we propose to replace the linear transforms in DNNs by our B-cos transform. As
we show, a sequence (network) of such transforms induces a single linear
transform that faithfully summarises the full model computations. Moreover, the
B-cos transform introduces alignment pressure on the weights during
optimisation. As a result, those induced linear transforms become highly
interpretable and align with task-relevant features. Importantly, the B-cos
transform is designed to be compatible with existing architectures and we show
that it can easily be integrated into common models such as VGGs, ResNets,
InceptionNets, and DenseNets, whilst maintaining similar performance on
ImageNet. The resulting explanations are of high visual quality and perform
well under quantitative metrics for interpretability. Code available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>10. <b>标题：Analysis of Co-Laughter Gesture Relationship on RGB videos in Dyadic  Conversation Contex</b></summary>
  <p><b>编号</b>：[31]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10266</p>
  <p><b>作者</b>：Hugo Bohy,  Ahmad Hammoudeh,  Antoine Maiorca,  Stéphane Dupont,  Thierry Dutoit</p>
  <p><b>备注</b>：5 pages, 2 figures, 2 tables</p>
  <p><b>关键词</b>：enabled human-avatar interactions, rich and varied, expressive virtual agent, enabled human-avatar, increasingly rich</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The development of virtual agents has enabled human-avatar interactions to
become increasingly rich and varied. Moreover, an expressive virtual agent i.e.
that mimics the natural expression of emotions, enhances social interaction
between a user (human) and an agent (intelligent machine). The set of
non-verbal behaviors of a virtual character is, therefore, an important
component in the context of human-machine interaction. Laughter is not just an
audio signal, but an intrinsic relationship of multimodal non-verbal
communication, in addition to audio, it includes facial expressions and body
movements. Motion analysis often relies on a relevant motion capture dataset,
but the main issue is that the acquisition of such a dataset is expensive and
time-consuming. This work studies the relationship between laughter and body
movements in dyadic conversations. The body movements were extracted from
videos using deep learning based pose estimator model. We found that, in the
explored NDC-ME dataset, a single statistical feature (i.e, the maximum value,
or the maximum of Fourier transform) of a joint movement weakly correlates with
laughter intensity by 30%. However, we did not find a direct correlation
between audio features and body movements. We discuss about the challenges to
use such dataset for the audio-driven co-laughter motion synthesis task.</p>
  </details>
</details>
<details>
  <summary>11. <b>标题：A Demographic Attribute Guided Approach to Age Estimation</b></summary>
  <p><b>编号</b>：[36]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10254</p>
  <p><b>作者</b>：Zhicheng Cao,  Kaituo Zhang,  Liaojun Pang,  Heng Zhao</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：public security surveillance, attracted enormous attention, enormous attention due, human-computer interaction, security surveillance</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Face-based age estimation has attracted enormous attention due to wide
applications to public security surveillance, human-computer interaction, etc.
With vigorous development of deep learning, age estimation based on deep neural
network has become the mainstream practice. However, seeking a more suitable
problem paradigm for age change characteristics, designing the corresponding
loss function and designing a more effective feature extraction module still
needs to be studied. What is more, change of face age is also related to
demographic attributes such as ethnicity and gender, and the dynamics of
different age groups is also quite different. This problem has so far not been
paid enough attention to. How to use demographic attribute information to
improve the performance of age estimation remains to be further explored. In
light of these issues, this research makes full use of auxiliary information of
face attributes and proposes a new age estimation approach with an attribute
guidance module. We first design a multi-scale attention residual convolution
unit (MARCU) to extract robust facial features other than simply using other
standard feature modules such as VGG and ResNet. Then, after being especially
treated through full connection (FC) layers, the facial demographic attributes
are weight-summed by 1*1 convolutional layer and eventually merged with the age
features by a global FC layer. Lastly, we propose a new error compression
ranking (ECR) loss to better converge the age regression value. Experimental
results on three public datasets of UTKFace, LAP2016 and Morph show that our
proposed approach achieves superior performance compared to other
state-of-the-art methods.</p>
  </details>
</details>
<details>
  <summary>12. <b>标题：Mosaic Zonotope Shadow Matching for Risk-Aware Autonomous Localization  in Harsh Urban Environments</b></summary>
  <p><b>编号</b>：[55]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10223</p>
  <p><b>作者</b>：Daniel Neamati,  Sriramya Bhamidipati,  Grace Gao</p>
  <p><b>备注</b>：Submitted to AIJ Special Issue on Risk-Aware Autonomous Systems: Theory and Practice</p>
  <p><b>关键词</b>：Global Navigation Satellite, Global Navigation, Navigation Satellite System, GNSS shadow matching, shadow matching</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Risk-aware urban localization with the Global Navigation Satellite System
(GNSS) remains an unsolved problem with frequent misdetection of the user's
street or side of the street. Significant advances in 3D map-aided GNSS use
grid-based GNSS shadow matching alongside AI-driven line-of-sight (LOS)
classifiers and server-based processing to improve localization accuracy,
especially in the cross-street direction. Our prior work introduces a new
paradigm for shadow matching that proposes set-valued localization with
computationally efficient zonotope set representations. While existing
literature improved accuracy and efficiency, the current state of shadow
matching theory does not address the needs of risk-aware autonomous systems. We
extend our prior work to propose Mosaic Zonotope Shadow Matching (MZSM) that
employs a classifier-agnostic polytope mosaic architecture to provide
risk-awareness and certifiable guarantees on urban positioning. We formulate a
recursively expanding binary tree that refines an initial location estimate
with set operations into smaller polytopes. Together, the smaller polytopes
form a mosaic. We weight the tree branches with the probability that the user
is in line of sight of the satellite and expand the tree with each new
satellite observation. Our method yields an exact shadow matching distribution
from which we guarantee uncertainty bounds on the user localization. We perform
high-fidelity simulations using a 3D building map of San Francisco to validate
our algorithm's risk-aware improvements. We demonstrate that MZSM provides
certifiable guarantees across varied data-driven LOS classifier accuracies and
yields a more precise understanding of the uncertainty over existing methods.
We validate that our tree-based construction is efficient and tractable,
computing a mosaic from 14 satellites in 0.63 seconds and growing quadratically
in the satellite number.</p>
  </details>
</details>
<details>
  <summary>13. <b>标题：Learning Task-relevant Representations for Generalization via  Characteristic Functions of Reward Sequence Distributions</b></summary>
  <p><b>编号</b>：[57]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10218</p>
  <p><b>作者</b>：Rui Yang,  Jie Wang,  Zijie Geng,  Mingxuan Ye,  Shuiwang Ji,  Bin Li,  Feng Wu</p>
  <p><b>备注</b>：Accepted to KDD'22</p>
  <p><b>关键词</b>：visual reinforcement learning, critical for successful, successful applications, visual distractions, real scenarios</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Generalization across different environments with the same tasks is critical
for successful applications of visual reinforcement learning (RL) in real
scenarios. However, visual distractions -- which are common in real scenes --
from high-dimensional observations can be hurtful to the learned
representations in visual RL, thus degrading the performance of generalization.
To tackle this problem, we propose a novel approach, namely Characteristic
Reward Sequence Prediction (CRESP), to extract the task-relevant information by
learning reward sequence distributions (RSDs), as the reward signals are
task-relevant in RL and invariant to visual distractions. Specifically, to
effectively capture the task-relevant information via RSDs, CRESP introduces an
auxiliary task -- that is, predicting the characteristic functions of RSDs --
to learn task-relevant representations, because we can well approximate the
high-dimensional distributions by leveraging the corresponding characteristic
functions. Experiments demonstrate that CRESP significantly improves the
performance of generalization on unseen environments, outperforming several
state-of-the-arts on DeepMind Control tasks with different visual distractions.</p>
  </details>
</details>
<details>
  <summary>14. <b>标题：Test-time Batch Normalization</b></summary>
  <p><b>编号</b>：[58]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10210</p>
  <p><b>作者</b>：Tao Yang,  Shenglong Zhou,  Yuwang Wang,  Yan Lu,  Nanning Zheng</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Deep neural networks, data distribution shift, distribution shift, Deep neural, alleviating distribution shift</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep neural networks often suffer the data distribution shift between
training and testing, and the batch statistics are observed to reflect the
shift. In this paper, targeting of alleviating distribution shift in test time,
we revisit the batch normalization (BN) in the training process and reveals two
key insights benefiting test-time optimization: $(i)$ preserving the same
gradient backpropagation form as training, and $(ii)$ using dataset-level
statistics for robust optimization and inference. Based on the two insights, we
propose a novel test-time BN layer design, GpreBN, which is optimized during
testing by minimizing Entropy loss. We verify the effectiveness of our method
on two typical settings with distribution shift, i.e., domain generalization
and robustness tasks. Our GpreBN significantly improves the test-time
performance and achieves the state of the art results.</p>
  </details>
</details>
<details>
  <summary>15. <b>标题：Learning to Count Anything: Reference-less Class-agnostic Counting with  Weak Supervision</b></summary>
  <p><b>编号</b>：[61]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10203</p>
  <p><b>作者</b>：Michael Hobley,  Victor Prisacariu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：diverse real-world applications, seemingly simple task, real-world applications, counting, seemingly simple</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Object counting is a seemingly simple task with diverse real-world
applications. Most counting methods focus on counting instances of specific,
known classes. While there are class-agnostic counting methods that can
generalise to unseen classes, these methods require reference images to define
the type of object to be counted, as well as instance annotations during
training. We identify that counting is, at its core, a repetition-recognition
task and show that a general feature space, with global context, is sufficient
to enumerate instances in an image without a prior on the object type present.
Specifically, we demonstrate that self-supervised vision transformer features
combined with a lightweight count regression head achieve competitive results
when compared to other class-agnostic counting tasks without the need for
point-level supervision or reference images. Our method thus facilitates
counting on a constantly changing set composition. To the best of our
knowledge, we are both the first reference-less class-agnostic counting method
as well as the first weakly-supervised class-agnostic counting method.</p>
  </details>
</details>
<details>
  <summary>16. <b>标题：How to Guide Adaptive Depth Sampling?</b></summary>
  <p><b>编号</b>：[62]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10202</p>
  <p><b>作者</b>：Ilya Tcenov,  Guy Gilboa</p>
  <p><b>备注</b>：8 pages</p>
  <p><b>关键词</b>：fixed mechanical rotations, fast electronic maneuvering, depth sensing technologies, laser beam, mechanical rotations</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent advances in depth sensing technologies allow fast electronic
maneuvering of the laser beam, as opposed to fixed mechanical rotations. This
will enable future sensors, in principle, to vary in real-time the sampling
pattern. We examine here the abstract problem of whether adapting the sampling
pattern for a given frame can reduce the reconstruction error or allow a
sparser pattern. We propose a constructive generic method to guide adaptive
depth sampling algorithms.
Given a sampling budget B, a depth predictor P and a desired quality measure
M, we propose an Importance Map that highlights important sampling locations.
This map is defined for a given frame as the per-pixel expected value of M
produced by the predictor P, given a pattern of B random samples. This map can
be well estimated in a training phase. We show that a neural network can learn
to produce a highly faithful Importance Map, given an RGB image. We then
suggest an algorithm to produce a sampling pattern for the scene, which is
denser in regions that are harder to reconstruct. The sampling strategy of our
modular framework can be adjusted according to hardware limitations, type of
depth predictor, and any custom reconstruction error measure that should be
minimized. We validate through simulations that our approach outperforms grid
and random sampling patterns as well as recent state-of-the-art adaptive
algorithms.</p>
  </details>
</details>
<details>
  <summary>17. <b>标题：A Novel Underwater Image Enhancement and Improved Underwater Biological  Detection Pipeline</b></summary>
  <p><b>编号</b>：[64]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10199</p>
  <p><b>作者</b>：Zheng Liu,  Yaoming Zhuang,  Pengrun Jia,  Chengdong Wu,  Hongli Xu ang Zhanlin Liu</p>
  <p><b>备注</b>：14 pages,14 figures</p>
  <p><b>关键词</b>：ecological environment monitoring, aquaculture resource evaluation, organisms is critical, aquaculture resource, identification of marine</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>For aquaculture resource evaluation and ecological environment monitoring,
automatic detection and identification of marine organisms is critical.
However, due to the low quality of underwater images and the characteristics of
underwater biological, a lack of abundant features may impede traditional
hand-designed feature extraction approaches or CNN-based object detection
algorithms, particularly in complex underwater environment. Therefore, the goal
of this paper is to perform object detection in the underwater environment.
This paper proposed a novel method for capturing feature information, which
adds the convolutional block attention module (CBAM) to the YOLOv5 backbone.
The interference of underwater creature characteristics on object
characteristics is decreased, and the output of the backbone network to object
information is enhanced. In addition, the self-adaptive global histogram
stretching algorithm (SAGHS) is designed to eliminate the degradation problems
such as low contrast and color loss caused by underwater environmental
information to better restore image quality. Extensive experiments and
comprehensive evaluation on the URPC2021 benchmark dataset demonstrate the
effectiveness and adaptivity of our methods. Beyond that, this paper conducts
an exhaustive analysis of the role of training data on performance.</p>
  </details>
</details>
<details>
  <summary>18. <b>标题：Unsupervised Flow-Aligned Sequence-to-Sequence Learning for Video  Restoration</b></summary>
  <p><b>编号</b>：[65]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10195</p>
  <p><b>作者</b>：Jing Lin,  Xiaowan Hu,  Yuanhao Cai,  Haoqian Wang,  Youliang Yan,  Xueyi Zou,  Yulun Zhang,  Luc Van Gool</p>
  <p><b>备注</b>：ICML 2022; The first sequence-to-sequence model for video restoration</p>
  <p><b>关键词</b>：inter-frame relation, important but unsolved, unsolved challenge, optical flow, model</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>How to properly model the inter-frame relation within the video sequence is
an important but unsolved challenge for video restoration (VR). In this work,
we propose an unsupervised flow-aligned sequence-to-sequence model (S2SVR) to
address this problem. On the one hand, the sequence-to-sequence model, which
has proven capable of sequence modeling in the field of natural language
processing, is explored for the first time in VR. Optimized serialization
modeling shows potential in capturing long-range dependencies among frames. On
the other hand, we equip the sequence-to-sequence model with an unsupervised
optical flow estimator to maximize its potential. The flow estimator is trained
with our proposed unsupervised distillation loss, which can alleviate the data
discrepancy and inaccurate degraded optical flow issues of previous flow-based
methods. With reliable optical flow, we can establish accurate correspondence
among multiple frames, narrowing the domain difference between 1D language and
2D misaligned frames and improving the potential of the sequence-to-sequence
model. S2SVR shows superior performance in multiple VR tasks, including video
deblurring, video super-resolution, and compressed video quality enhancement.
Code and models are publicly available at
this https URL</p>
  </details>
</details>
<details>
  <summary>19. <b>标题：E-Scooter Rider Detection and Classification in Dense Urban Environments</b></summary>
  <p><b>编号</b>：[72]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10184</p>
  <p><b>作者</b>：Shane Gilroy,  Darragh Mullins,  Edward Jones,  Ashkan Parsi,  Martin Glavin</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：safety critical requirement, vulnerable road users, e-scooter rider detection, classification of vulnerable, safety critical</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Accurate detection and classification of vulnerable road users is a safety
critical requirement for the deployment of autonomous vehicles in heterogeneous
traffic. Although similar in physical appearance to pedestrians, e-scooter
riders follow distinctly different characteristics of movement and can reach
speeds of up to 45kmph. The challenge of detecting e-scooter riders is
exacerbated in urban environments where the frequency of partial occlusion is
increased as riders navigate between vehicles, traffic infrastructure and other
road users. This can lead to the non-detection or mis-classification of
e-scooter riders as pedestrians, providing inaccurate information for accident
mitigation and path planning in autonomous vehicle applications. This research
introduces a novel benchmark for partially occluded e-scooter rider detection
to facilitate the objective characterization of detection models. A novel,
occlusion-aware method of e-scooter rider detection is presented that achieves
a 15.93% improvement in detection performance over the current state of the
art.</p>
  </details>
</details>
<details>
  <summary>20. <b>标题：Towards the Generation of Synthetic Images of Palm Vein Patterns: A  Review</b></summary>
  <p><b>编号</b>：[74]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10179</p>
  <p><b>作者</b>：Edwin H. Salazar-Jurado,  Ruber Hernández-García,  Karina Vilches-Ponce,  Ricardo J. Barrientos,  Marco Mora,  Gaurav Jaswal</p>
  <p><b>备注</b>：Under review</p>
  <p><b>关键词</b>：palm vein recognition, automatic personal recognition, palm vein, vein recognition, palm vein images</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>With the recent success of computer vision and deep learning, remarkable
progress has been achieved on automatic personal recognition using vein
biometrics. However, collecting large-scale real-world training data for palm
vein recognition has turned out to be challenging, mainly due to the noise and
irregular variations included at the time of acquisition. Meanwhile, existing
palm vein recognition datasets are usually collected under near-infrared light,
lacking detailed annotations on attributes (e.g., pose), so the influences of
different attributes on vein recognition have been poorly investigated.
Therefore, this paper examines the suitability of synthetic vein images
generated to compensate for the urgent lack of publicly available large-scale
datasets. Firstly, we present an overview of recent research progress on palm
vein recognition, from the basic background knowledge to vein anatomical
structure, data acquisition, public database, and quality assessment
procedures. Then, we focus on the state-of-the-art methods that have allowed
the generation of vascular structures for biometric purposes and the modeling
of biological networks with their respective application domains. In addition,
we review the existing research on the generation of style transfer and
biological nature-based synthetic palm vein image algorithms. Afterward, we
formalize a general flowchart for the creation of a synthetic database
comparing real palm vein images and generated synthetic samples to obtain some
understanding into the development of the realistic vein imaging system.
Ultimately, we conclude by discussing the challenges, insights, and future
perspectives in generating synthetic palm vein images for further works.</p>
  </details>
</details>
<details>
  <summary>21. <b>标题：Swapping Semantic Contents for Mixing Images</b></summary>
  <p><b>编号</b>：[83]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10158</p>
  <p><b>作者</b>：Rémy Sun,  Clément Masson,  Gilles Hénaff,  Nicolas Thome,  Matthieu Cord</p>
  <p><b>备注</b>：Accepted at ICPR 2022, 7 pages, 4 figures, 6 tables</p>
  <p><b>关键词</b>：Deep architecture, architecture have proven, proven capable, capable of solving, solving many tasks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep architecture have proven capable of solving many tasks provided a
sufficient amount of labeled data. In fact, the amount of available labeled
data has become the principal bottleneck in low label settings such as
Semi-Supervised Learning. Mixing Data Augmentations do not typically yield new
labeled samples, as indiscriminately mixing contents creates between-class
samples. In this work, we introduce the SciMix framework that can learn to
generator to embed a semantic style code into image backgrounds, we obtain new
mixing scheme for data augmentation. We then demonstrate that SciMix yields
novel mixed samples that inherit many characteristics from their non-semantic
parents. Afterwards, we verify those samples can be used to improve the
performance semi-supervised frameworks like Mean Teacher or Fixmatch, and even
fully supervised learning on a small labeled dataset.</p>
  </details>
</details>
<details>
  <summary>22. <b>标题：The developmental trajectory of object recognition robustness: children  are like small adults but unlike big deep neural networks</b></summary>
  <p><b>编号</b>：[90]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10144</p>
  <p><b>作者</b>：Lukas S. Huber,  Robert Geirhos,  Felix A. Wichmann</p>
  <p><b>备注</b>：Manuscript under review at Journal of Vision</p>
  <p><b>关键词</b>：Deep Neural Networks, Neural Networks, Deep Neural, unicode, recognition tasks based</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In laboratory object recognition tasks based on undistorted photographs, both
adult humans and Deep Neural Networks (DNNs) perform close to ceiling. Unlike
adults', whose object recognition performance is robust against a wide range of
image distortions, DNNs trained on standard ImageNet (1.3M images) perform
poorly on distorted images. However, the last two years have seen impressive
gains in DNN distortion robustness, predominantly achieved through
ever-increasing large-scale datasets$\unicode{x2014}$orders of magnitude larger
than ImageNet. While this simple brute-force approach is very effective in
achieving human-level robustness in DNNs, it raises the question of whether
human robustness, too, is simply due to extensive experience with (distorted)
visual input during childhood and beyond. Here we investigate this question by
comparing the core object recognition performance of 146 children (aged
4$\unicode{x2013}$15) against adults and against DNNs. We find, first, that
already 4$\unicode{x2013}$6 year-olds showed remarkable robustness to image
distortions and outperform DNNs trained on ImageNet. Second, we estimated the
number of $\unicode{x201C}$images$\unicode{x201D}$ children have been exposed
to during their lifetime. Compared to various DNNs, children's high robustness
requires relatively little data. Third, when recognizing objects
children$\unicode{x2014}$like adults but unlike DNNs$\unicode{x2014}$rely
heavily on shape but not on texture cues. Together our results suggest that the
remarkable robustness to distortions emerges early in the developmental
trajectory of human object recognition and is unlikely the result of a mere
accumulation of experience with distorted visual input. Even though current
DNNs match human performance regarding robustness they seem to rely on
different and more data-hungry strategies to do so.</p>
  </details>
</details>
<details>
  <summary>23. <b>标题：Reliability-based Mesh-to-Grid Image Reconstruction</b></summary>
  <p><b>编号</b>：[92]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10138</p>
  <p><b>作者</b>：Ján Koloda,  Jürgen Seiler,  André Kaup</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：called mesh, non-integer positions, paper presents, samples located, located at non-integer</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper presents a novel method for the reconstruction of images from
samples located at non-integer positions, called mesh. This is a common
scenario for many image processing applications, such as super-resolution,
warping or virtual view generation in multi-camera systems. The proposed method
relies on a set of initial estimates that are later refined by a new
reliability-based content-adaptive framework that employs denoising in order to
reduce the reconstruction error. The reliability of the initial estimate is
computed so stronger denoising is applied to less reliable estimates. The
proposed technique can improve the reconstruction quality by more than 2 dB (in
terms of PSNR) with respect to the initial estimate and it outperforms the
state-of-the-art denoising-based refinement by up to 0.7 dB.</p>
  </details>
</details>
<details>
  <summary>24. <b>标题：Privacy Preserving Image Registration</b></summary>
  <p><b>编号</b>：[105]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10120</p>
  <p><b>作者</b>：Riccardo Taiello,  Melek Önen,  Olivier Humbert,  Marco Lorenzi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：spatial reference frame, Image registration, common spatial reference, registration, allowing to represent</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Image registration is a key task in medical imaging applications, allowing to
represent medical images in a common spatial reference frame. Current
literature on image registration is generally based on the assumption that
images are usually accessible to the researcher, from which the spatial
transformation is subsequently estimated. This common assumption may not be met
in current practical applications, since the sensitive nature of medical images
may ultimately require their analysis under privacy constraints, preventing to
share the image content in clear form. In this work, we formulate the problem
of image registration under a privacy preserving regime, where images are
assumed to be confidential and cannot be disclosed in clear. We derive our
privacy preserving image registration framework by extending classical
registration paradigms to account for advanced cryptographic tools, such as
secure multi-party computation and homomorphic encryption, that enable the
execution of operations without leaking the underlying data. To overcome the
problem of performance and scalability of cryptographic tools in high
dimensions, we first propose to optimize the underlying image registration
operations using gradient approximations. We further revisit the use of
homomorphic encryption and use a packing method to allow the encryption and
multiplication of large matrices more efficiently. We demonstrate our privacy
preserving framework in linear and non-linear registration problems, evaluating
its accuracy and scalability with respect to standard image registration. Our
results show that privacy preserving image registration is feasible and can be
adopted in sensitive medical imaging applications.</p>
  </details>
</details>
<details>
  <summary>25. <b>标题：Degradation-Aware Unfolding Half-Shuffle Transformer for Spectral  Compressive Imaging</b></summary>
  <p><b>编号</b>：[115]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10102</p>
  <p><b>作者</b>：Yuanhao Cai,  Jing Lin,  Haoqian Wang,  Xin Yuan,  Henghui Ding,  Yulun Zhang,  Radu Timofte,  Luc Van Gool</p>
  <p><b>备注</b>：The first Transformer-based deep unfolding method for spectral compressive imaging</p>
  <p><b>关键词</b>：spectral compressive imaging, coded aperture snapshot, aperture snapshot spectral, snapshot spectral compressive, compressive imaging</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In coded aperture snapshot spectral compressive imaging (CASSI) systems,
hyperspectral image (HSI) reconstruction methods are employed to recover the
spatial-spectral signal from a compressed measurement. Among these algorithms,
deep unfolding methods demonstrate promising performance but suffer from two
issues. Firstly, they do not estimate the degradation patterns and
ill-posedness degree from the highly related CASSI to guide the iterative
learning. Secondly, they are mainly CNN-based, showing limitations in capturing
long-range dependencies. In this paper, we propose a principled
Degradation-Aware Unfolding Framework (DAUF) that estimates parameters from the
compressed image and physical mask, and then uses these parameters to control
each iteration. Moreover, we customize a novel Half-Shuffle Transformer (HST)
that simultaneously captures local contents and non-local dependencies. By
plugging HST into DAUF, we establish the first Transformer-based deep unfolding
method, Degradation-Aware Unfolding Half-Shuffle Transformer (DAUHST), for HSI
reconstruction. Experiments show that DAUHST significantly surpasses
state-of-the-art methods while requiring cheaper computational and memory
costs. Code and models will be released to the public.</p>
  </details>
</details>
<details>
  <summary>26. <b>标题：MSTRIQ: No Reference Image Quality Assessment Based on Swin Transformer  with Multi-Stage Fusion</b></summary>
  <p><b>编号</b>：[116]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10101</p>
  <p><b>作者</b>：Jing Wang,  Haotian Fan,  Xiaoxia Hou,  Yitian Xu,  Tao Li,  Xuechao Lu,  Lean Fu</p>
  <p><b>备注</b>：8 pages, 4 figures</p>
  <p><b>关键词</b>：transmission to enhancing, computer vision, essential task, area of computer, Image Quality Assessment</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Measuring the perceptual quality of images automatically is an essential task
in the area of computer vision, as degradations on image quality can exist in
many processes from image acquisition, transmission to enhancing. Many Image
Quality Assessment(IQA) algorithms have been designed to tackle this problem.
However, it still remains un settled due to the various types of image
distortions and the lack of large-scale human-rated datasets. In this paper, we
propose a novel algorithm based on the Swin Transformer [31] with fused
features from multiple stages, which aggregates information from both local and
global features to better predict the quality. To address the issues of
small-scale datasets, relative rankings of images have been taken into account
together with regression loss to simultaneously optimize the model.
Furthermore, effective data augmentation strategies are also used to improve
the performance. In comparisons with previous works, experiments are carried
out on two standard IQA datasets and a challenge dataset. The results
demonstrate the effectiveness of our work. The proposed method outperforms
other methods on standard datasets and ranks 2nd in the no-reference track of
NTIRE 2022 Perceptual Image Quality Assessment Challenge [53]. It verifies that
our method is promising in solving diverse IQA problems and thus can be used to
real-word applications.</p>
  </details>
</details>
<details>
  <summary>27. <b>标题：Visual Concepts Tokenization</b></summary>
  <p><b>编号</b>：[119]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10093</p>
  <p><b>作者</b>：Tao Yang,  Yuwang Wang,  Yan Lu,  Nanning Zheng</p>
  <p><b>备注</b>：Preprint, under review</p>
  <p><b>关键词</b>：human-like perception ability, Visual Concepts Tokenization, abstracting visual concepts, concept tokens, visual concepts</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Obtaining the human-like perception ability of abstracting visual concepts
from concrete pixels has always been a fundamental and important target in
machine learning research fields such as disentangled representation learning
and scene decomposition. Towards this goal, we propose an unsupervised
transformer-based Visual Concepts Tokenization framework, dubbed VCT, to
perceive an image into a set of disentangled visual concept tokens, with each
concept token responding to one type of independent visual concept.
Particularly, to obtain these concept tokens, we only use cross-attention to
extract visual information from the image tokens layer by layer without
self-attention between concept tokens, preventing information leakage across
concept tokens. We further propose a Concept Disentangling Loss to facilitate
that different concept tokens represent independent visual concepts. The
cross-attention and disentangling loss play the role of induction and mutual
exclusion for the concept tokens, respectively. Extensive experiments on
several popular datasets verify the effectiveness of VCT on the tasks of
disentangled representation learning and scene decomposition. VCT achieves the
state of the art results by a large margin.</p>
  </details>
</details>
<details>
  <summary>28. <b>标题：Kernel Normalized Convolutional Networks</b></summary>
  <p><b>编号</b>：[121]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10089</p>
  <p><b>作者</b>：Reza Nasirigerdeh,  Reihaneh Torkzadehmahani,  Daniel Rueckert,  Georgios Kaissis</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：architectures frequently rely, Existing deep convolutional, deep convolutional neural, convolutional neural network, Existing deep</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Existing deep convolutional neural network (CNN) architectures frequently
rely upon batch normalization (BatchNorm) to effectively train the model.
BatchNorm significantly improves model performance, but performs poorly with
smaller batch sizes. To address this limitation, we propose kernel
normalization and kernel normalized convolutional layers, and incorporate them
into kernel normalized convolutional networks (KNConvNets) as the main building
blocks. We implement KNConvNets corresponding to the state-of-the-art CNNs such
as ResNet and DenseNet while forgoing BatchNorm layers. Through extensive
experiments, we illustrate that KNConvNets consistently outperform their batch,
group, and layer normalized counterparts in terms of both accuracy and
convergence rate while maintaining competitive computational efficiency.</p>
  </details>
</details>
<details>
  <summary>29. <b>标题：People Tracking and Re-Identifying in Distributed Contexts: Extension of  PoseTReID</b></summary>
  <p><b>编号</b>：[123]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10086</p>
  <p><b>作者</b>：Ratha Siv,  Matei Mancas,  Bernard Gosselin,  Dona Valy,  Sokchenda Sreng</p>
  <p><b>备注</b>：5 pages, 5 figures, 3 tables, To be submitted to MDMA2022</p>
  <p><b>关键词</b>：distributed interaction spaces, long-term people identities, behavior analysis, distributed interaction, interaction spaces</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In our previous paper, we introduced PoseTReID which is a generic framework
for real-time 2D multi-person tracking in distributed interaction spaces where
long-term people's identities are important for other studies such as behavior
analysis, etc. In this paper, we introduce a further study of PoseTReID
framework in order to give a more complete comprehension of the framework. We
use a well-known bounding box detector YOLO (v4) for the detection to compare
to OpenPose which was used in our last paper, and we use SORT and DeepSORT to
compare to centroid which was also used previously, and most importantly for
the re-identification, we use a bunch of deep leaning methods such as MLFN,
OSNet, and OSNet-AIN with our custom classification layer to compare to FaceNet
which was also used earlier in our last paper. By evaluating on our PoseTReID
datasets, even though those deep learning re-identification methods are
designed for only short-term re-identification across multiple cameras or
videos, it is worth showing that they give impressive results which boost the
overall tracking performance of PoseTReID framework regardless the type of
tracking method. At the same time, we also introduce our research-friendly and
open source Python toolbox pyppbox, which is pure written in Python and
contains all sub-modules which are used this study along with real-time online
and offline evaluations for our PoseTReID datasets. This pyppbox is available
on GitHub this https URL .</p>
  </details>
</details>
<details>
  <summary>30. <b>标题：Emergence of Double-slit Interference by Representing Visual Space in  Artificial Neural Networks</b></summary>
  <p><b>编号</b>：[125]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10081</p>
  <p><b>作者</b>：Xiuxiu Bai,  Zhe Liu,  Yao Gao,  Bin Liu,  Yongqiang Hao</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：realized incredible successes, space representation remains, image recognition, huge mystery, Artificial neural networks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Artificial neural networks have realized incredible successes at image
recognition, but the underlying mechanism of visual space representation
remains a huge mystery. Grid cells (2014 Nobel Prize) in the entorhinal cortex
support a periodic representation as a metric for coding space. Here, we
develop a self-supervised convolutional neural network to perform visual space
location, leading to the emergence of single-slit diffraction and double-slit
interference patterns of waves. Our discoveries reveal the nature of CNN
encoding visual space to a certain extent. CNN is no longer a black box in
terms of visual spatial encoding, it is interpretable. Our findings indicate
that the periodicity property of waves provides a space metric, suggesting a
general role of spatial coordinate frame in artificial neural networks.</p>
  </details>
</details>
<details>
  <summary>31. <b>标题：Unintended memorisation of unique features in neural networks</b></summary>
  <p><b>编号</b>：[127]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10079</p>
  <p><b>作者</b>：John Hartley,  Sotirios A. Tsaftaris</p>
  <p><b>备注</b>：arXiv admin note: substantial text overlap with arXiv:2202.08099</p>
  <p><b>关键词</b>：Neural networks, training data, Neural networks pose, unique feature, unique</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Neural networks pose a privacy risk due to their propensity to memorise and
leak training data. We show that unique features occurring only once in
training data are memorised by discriminative multi-layer perceptrons and
convolutional neural networks trained on benchmark imaging datasets. We design
our method for settings where sensitive training data is not available, for
example medical imaging. Our setting knows the unique feature, but not the
training data, model weights or the unique feature's label. We develop a score
estimating a model's sensitivity to a unique feature by comparing the KL
divergences of the model's output distributions given modified
out-of-distribution images. We find that typical strategies to prevent
overfitting do not prevent unique feature memorisation. And that images
containing a unique feature are highly influential, regardless of the influence
the images's other features. We also find a significant variation in
memorisation with training seed. These results imply that neural networks pose
a privacy risk to rarely occurring private information. This risk is more
pronounced in healthcare applications since sensitive patient information can
be memorised when it remains in training data due to an imperfect data
sanitisation process.</p>
  </details>
</details>
<details>
  <summary>32. <b>标题：Contrastive Learning with Cross-Modal Knowledge Mining for Multimodal  Human Activity Recognition</b></summary>
  <p><b>编号</b>：[132]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10071</p>
  <p><b>作者</b>：Razvan Brinzea,  Bulat Khaertdinov,  Stylianos Asteriadis</p>
  <p><b>备注</b>：to be published in IEEE WCCI 2022 (IJCNN 2022 track)</p>
  <p><b>关键词</b>：field of research, Human Activity Recognition, Human Activity, Human, modalities describes human</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Human Activity Recognition is a field of research where input data can take
many forms. Each of the possible input modalities describes human behaviour in
a different way, and each has its own strengths and weaknesses. We explore the
hypothesis that leveraging multiple modalities can lead to better recognition.
Since manual annotation of input data is expensive and time-consuming, the
emphasis is made on self-supervised methods which can learn useful feature
representations without any ground truth labels. We extend a number of recent
contrastive self-supervised approaches for the task of Human Activity
Recognition, leveraging inertial and skeleton data. Furthermore, we propose a
flexible, general-purpose framework for performing multimodal self-supervised
learning, named Contrastive Multiview Coding with Cross-Modal Knowledge Mining
(CMC-CMKM). This framework exploits modality-specific knowledge in order to
mitigate the limitations of typical self-supervised frameworks. The extensive
experiments on two widely-used datasets demonstrate that the suggested
framework significantly outperforms contrastive unimodal and multimodal
baselines on different scenarios, including fully-supervised fine-tuning,
activity retrieval and semi-supervised learning. Furthermore, it shows
performance competitive even compared to supervised methods.</p>
  </details>
</details>
<details>
  <summary>33. <b>标题：Uniform Masking: Enabling MAE Pre-training for Pyramid-based Vision  Transformers with Locality</b></summary>
  <p><b>编号</b>：[136]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10063</p>
  <p><b>作者</b>：Xiang Li,  Wenhai Wang,  Lingfeng Yang,  Jian Yang</p>
  <p><b>备注</b>：An efficient and effective technique that supports MAE-style MIM Pre-training for popular Pyramid-based Vision Transformers (e.g., PVT, Swin)</p>
  <p><b>关键词</b>：asymmetric encoder-decoder design, elegant asymmetric encoder-decoder, Vanilla Vision Transformer, visual self-supervision area, Pyramid-based ViTs</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Masked AutoEncoder (MAE) has recently led the trends of visual
self-supervision area by an elegant asymmetric encoder-decoder design, which
significantly optimizes both the pre-training efficiency and fine-tuning
accuracy. Notably, the success of the asymmetric structure relies on the
"global" property of Vanilla Vision Transformer (ViT), whose self-attention
mechanism reasons over arbitrary subset of discrete image patches. However, it
is still unclear how the advanced Pyramid-based ViTs (e.g., PVT, Swin) can be
adopted in MAE pre-training as they commonly introduce operators within "local"
windows, making it difficult to handle the random sequence of partial vision
tokens. In this paper, we propose Uniform Masking (UM), successfully enabling
MAE pre-training for Pyramid-based ViTs with locality (termed "UM-MAE" for
short). Specifically, UM includes a Uniform Sampling (US) that strictly samples
$1$ random patch from each $2 \times 2$ grid, and a Secondary Masking (SM)
which randomly masks a portion of (usually $25\%$) the already sampled regions
as learnable tokens. US preserves equivalent elements across multiple
non-overlapped local windows, resulting in the smooth support for popular
Pyramid-based ViTs; whilst SM is designed for better transferable visual
representations since US reduces the difficulty of pixel recovery pre-task that
hinders the semantic learning. We demonstrate that UM-MAE significantly
improves the pre-training efficiency (e.g., it speeds up and reduces the GPU
memory by $\sim 2\times$) of Pyramid-based ViTs, but maintains the competitive
fine-tuning performance across downstream tasks. For example using HTC++
detector, the pre-trained Swin-Large backbone self-supervised under UM-MAE only
in ImageNet-1K can even outperform the one supervised in ImageNet-22K. The
codes are available at this https URL.</p>
  </details>
</details>
<details>
  <summary>34. <b>标题：Assessing Demographic Bias Transfer from Dataset to Model: A Case Study  in Facial Expression Recognition</b></summary>
  <p><b>编号</b>：[142]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10049</p>
  <p><b>作者</b>：Iris Dominguez-Catena,  Daniel Paternain,  Mikel Galar</p>
  <p><b>备注</b>：8 pages excluding appendices, 8 figures</p>
  <p><b>关键词</b>：Artificial Intelligence, applications of Artificial, led researchers, social impact, technologies and evaluate</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The increasing amount of applications of Artificial Intelligence (AI) has led
researchers to study the social impact of these technologies and evaluate their
fairness. Unfortunately, current fairness metrics are hard to apply in
multi-class multi-demographic classification problems, such as Facial
Expression Recognition (FER). We propose a new set of metrics to approach these
problems. Of the three metrics proposed, two focus on the representational and
stereotypical bias of the dataset, and the third one on the residual bias of
the trained model. These metrics combined can potentially be used to study and
compare diverse bias mitigation methods. We demonstrate the usefulness of the
metrics by applying them to a FER problem based on the popular Affectnet
dataset. Like many other datasets for FER, Affectnet is a large
Internet-sourced dataset with 291,651 labeled images. Obtaining images from the
Internet raises some concerns over the fairness of any system trained on this
data and its ability to generalize properly to diverse populations. We first
analyze the dataset and some variants, finding substantial racial bias and
gender stereotypes. We then extract several subsets with different demographic
properties and train a model on each one, observing the amount of residual bias
in the different setups. We also provide a second analysis on a different
dataset, FER+.</p>
  </details>
</details>
<details>
  <summary>35. <b>标题：Constructive Interpretability with CoLabel: Corroborative Integration,  Complementary Features, and Collaborative Learning</b></summary>
  <p><b>编号</b>：[164]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10011</p>
  <p><b>作者</b>：Abhijit Suprem,  Sanjyot Vaidya,  Suma Cherkadi,  Purva Singh,  Joao Eduardo Ferreira,  Calton Pu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：require bias detection, Machine learning models, Machine learning, risk mitigation, increasingly sought</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Machine learning models with explainable predictions are increasingly sought
after, especially for real-world, mission-critical applications that require
bias detection and risk mitigation. Inherent interpretability, where a model is
designed from the ground-up for interpretability, provides intuitive insights
and transparent explanations on model prediction and performance. In this
paper, we present CoLabel, an approach to build interpretable models with
explanations rooted in the ground truth. We demonstrate CoLabel in a vehicle
feature extraction application in the context of vehicle make-model recognition
(VMMR). CoLabel performs VMMR with a composite of interpretable features such
as vehicle color, type, and make, all based on interpretable annotations of the
ground truth labels. First, CoLabel performs corroborative integration to join
multiple datasets that each have a subset of desired annotations of color,
type, and make. Then, CoLabel uses decomposable branches to extract
complementary features corresponding to desired annotations. Finally, CoLabel
fuses them together for final predictions. During feature fusion, CoLabel
harmonizes complementary branches so that VMMR features are compatible with
each other and can be projected to the same semantic space for classification.
With inherent interpretability, CoLabel achieves superior performance to the
state-of-the-art black-box models, with accuracy of 0.98, 0.95, and 0.94 on
CompCars, Cars196, and BoxCars116K, respectively. CoLabel provides intuitive
explanations due to constructive interpretability, and subsequently achieves
high accuracy and usability in mission-critical situations.</p>
  </details>
</details>
<details>
  <summary>36. <b>标题：Action parsing using context features</b></summary>
  <p><b>编号</b>：[166]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10008</p>
  <p><b>作者</b>：Nagita Mehrseresht</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：video sequence, unknown number, action segments, action, sequence</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose an action parsing algorithm to parse a video sequence containing
an unknown number of actions into its action segments. We argue that context
information, particularly the temporal information about other actions in the
video sequence, is valuable for action segmentation. The proposed parsing
algorithm temporally segments the video sequence into action segments. The
optimal temporal segmentation is found using a dynamic programming search
algorithm that optimizes the overall classification confidence score. The
classification score of each segment is determined using local features
calculated from that segment as well as context features calculated from other
candidate action segments of the sequence. Experimental results on the
Breakfast activity data-set showed improved segmentation accuracy compared to
existing state-of-the-art parsing techniques.</p>
  </details>
</details>
<details>
  <summary>37. <b>标题：Self-Supervised Depth Estimation with Isometric-Self-Sample-Based  Learning</b></summary>
  <p><b>编号</b>：[167]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10006</p>
  <p><b>作者</b>：Geonho Cha,  Ho-Deok Jang,  Dongyoon Wee</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：photometric loss formulation, self-supervised depth estimation, dynamic regions, photometric loss, loss formulation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Managing the dynamic regions in the photometric loss formulation has been a
main issue for handling the self-supervised depth estimation problem. Most
previous methods have alleviated this issue by removing the dynamic regions in
the photometric loss formulation based on the masks estimated from another
module, making it difficult to fully utilize the training images. In this
paper, to handle this problem, we propose an isometric self-sample-based
learning (ISSL) method to fully utilize the training images in a simple yet
effective way. The proposed method provides additional supervision during
training using self-generated images that comply with pure static scene
assumption. Specifically, the isometric self-sample generator synthesizes
self-samples for each training image by applying random rigid transformations
on the estimated depth. Thus both the generated self-samples and the
corresponding training image always follow the static scene assumption. We show
that plugging our ISSL module into several existing models consistently
improves the performance by a large margin. In addition, it also boosts the
depth accuracy over different types of scene, i.e., outdoor scenes (KITTI and
Make3D) and indoor scene (NYUv2), validating its high effectiveness.</p>
  </details>
</details>
<details>
  <summary>38. <b>标题：InDistill: Transferring Knowledge From Pruned Intermediate Layers</b></summary>
  <p><b>编号</b>：[169]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10003</p>
  <p><b>作者</b>：Ioannis Sarridis,  Christos Koutlis,  Symeon Papadopoulos,  Ioannis Kompatsiaris</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Deploying deep neural, deep neural networks, great challenge due, Deploying deep, limited resources</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deploying deep neural networks on hardware with limited resources, such as
smartphones and drones, constitutes a great challenge due to their
computational complexity. Knowledge distillation approaches aim at transferring
knowledge from a large model to a lightweight one, also known as teacher and
student respectively, while distilling the knowledge from intermediate layers
provides an additional supervision to that task. The capacity gap between the
models, the information encoding that collapses its architectural alignment,
and the absence of appropriate learning schemes for transferring multiple
layers restrict the performance of existing methods. In this paper, we propose
a novel method, termed InDistill, that can drastically improve the performance
of existing single-layer knowledge distillation methods by leveraging the
properties of channel pruning to both reduce the capacity gap between the
models and retain the architectural alignment. Furthermore, we propose a
curriculum learning based scheme for enhancing the effectiveness of
transferring knowledge from multiple intermediate layers. The proposed method
surpasses state-of-the-art performance on three benchmark image datasets.</p>
  </details>
</details>
<details>
  <summary>39. <b>标题：Mask-guided Vision Transformer (MG-ViT) for Few-Shot Learning</b></summary>
  <p><b>编号</b>：[171]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09995</p>
  <p><b>作者</b>：Yuzhong Chen,  Zhenxiang Xiao,  Lin Zhao,  Lu Zhang,  Haixing Dai,  David Weizhong Liu,  Zihao Wu,  Changhe Li,  Tuo Zhang,  Changying Li,  Dajiang Zhu,  Tianming Liu,  Xi Jiang</p>
  <p><b>备注</b>：11 pages,4 figures, submitted to 36th Conference on Neural Information Processing Systems (NeurIPS 2022)</p>
  <p><b>关键词</b>：data is challenging, labeled data, data is limited, limited and costly, FSL</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Learning with little data is challenging but often inevitable in various
application scenarios where the labeled data is limited and costly. Recently,
few-shot learning (FSL) gained increasing attention because of its
generalizability of prior knowledge to new tasks that contain only a few
samples. However, for data-intensive models such as vision transformer (ViT),
current fine-tuning based FSL approaches are inefficient in knowledge
generalization and thus degenerate the downstream task performances. In this
paper, we propose a novel mask-guided vision transformer (MG-ViT) to achieve an
effective and efficient FSL on ViT model. The key idea is to apply a mask on
image patches to screen out the task-irrelevant ones and to guide the ViT to
focus on task-relevant and discriminative patches during FSL. Particularly,
MG-ViT only introduces an additional mask operation and a residual connection,
enabling the inheritance of parameters from pre-trained ViT without any other
cost. To optimally select representative few-shot samples, we also include an
active learning based sample selection method to further improve the
generalizability of MG-ViT based FSL. We evaluate the proposed MG-ViT on both
Agri-ImageNet classification task and ACFR apple detection task with
gradient-weighted class activation mapping (Grad-CAM) as the mask. The
experimental results show that the MG-ViT model significantly improves the
performance when compared with general fine-tuning based ViT models, providing
novel insights and a concrete approach towards generalizing data-intensive and
large-scale deep learning models for FSL.</p>
  </details>
</details>
<details>
  <summary>40. <b>标题：Few-Shot Font Generation by Learning Fine-Grained Local Styles</b></summary>
  <p><b>编号</b>：[187]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09965</p>
  <p><b>作者</b>：Licheng Tang,  Yiyang Cai,  Jiaming Liu,  Zhibin Hong,  Mingming Gong,  Minhu Fan,  Junyu Han,  Jingtuo Liu,  Errui Ding,  Jingdong Wang</p>
  <p><b>备注</b>：Accepted to CVPR 2022</p>
  <p><b>关键词</b>：gaining increasing attention, increasing attention due, reference glyphs, glyphs, Few-shot font generation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Few-shot font generation (FFG), which aims to generate a new font with a few
examples, is gaining increasing attention due to the significant reduction in
labor cost. A typical FFG pipeline considers characters in a standard font
library as content glyphs and transfers them to a new target font by extracting
style information from the reference glyphs. Most existing solutions explicitly
disentangle content and style of reference glyphs globally or component-wisely.
However, the style of glyphs mainly lies in the local details, i.e. the styles
of radicals, components, and strokes together depict the style of a glyph.
Therefore, even a single character can contain different styles distributed
over spatial locations. In this paper, we propose a new font generation
approach by learning 1) the fine-grained local styles from references, and 2)
the spatial correspondence between the content and reference glyphs. Therefore,
each spatial location in the content glyph can be assigned with the right
fine-grained style. To this end, we adopt cross-attention over the
representation of the content glyphs as the queries and the representations of
the reference glyphs as the keys and values. Instead of explicitly
disentangling global or component-wise modeling, the cross-attention mechanism
can attend to the right local styles in the reference glyphs and aggregate the
reference styles into a fine-grained style representation for the given content
glyphs. The experiments show that the proposed method outperforms the
state-of-the-art methods in FFG. In particular, the user studies also
demonstrate the style consistency of our approach significantly outperforms
previous methods.</p>
  </details>
</details>
<details>
  <summary>41. <b>标题：Advanced Feature Learning on Point Clouds using Multi-resolution  Features and Learnable Pooling</b></summary>
  <p><b>编号</b>：[189]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09962</p>
  <p><b>作者</b>：Kevin Tirta Wijaya,  Dong-Hee Paek,  Seung-Hyun Kong</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：point features, point cloud, point, high-semantic point features, point cloud feature</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Existing point cloud feature learning networks often incorporate sequences of
sampling, neighborhood grouping, neighborhood-wise feature learning, and
feature aggregation to learn high-semantic point features that represent the
global context of a point cloud. Unfortunately, the compounded loss of
information concerning granularity and non-maximum point features due to
sampling and max pooling could adversely affect the high-semantic point
features from existing networks such that they are insufficient to represent
the local context of a point cloud, which in turn may hinder the network in
distinguishing fine shapes. To cope with this problem, we propose a novel point
cloud feature learning network, PointStack, using multi-resolution feature
learning and learnable pooling (LP). The multi-resolution feature learning is
realized by aggregating point features of various resolutions in the multiple
layers, so that the final point features contain both high-semantic and
high-resolution information. On the other hand, the LP is used as a generalized
pooling function that calculates the weighted sum of multi-resolution point
features through the attention mechanism with learnable queries, in order to
extract all possible information from all available point features.
Consequently, PointStack is capable of extracting high-semantic point features
with minimal loss of information concerning granularity and non-maximum point
features. Therefore, the final aggregated point features can effectively
represent both global and local contexts of a point cloud. In addition, both
the global structure and the local shape details of a point cloud can be well
comprehended by the network head, which enables PointStack to advance the
state-of-the-art of feature learning on point clouds. The codes are available
at this https URL.</p>
  </details>
</details>
<details>
  <summary>42. <b>标题：Structured Attention Composition for Temporal Action Localization</b></summary>
  <p><b>编号</b>：[192]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09956</p>
  <p><b>作者</b>：Le Yang,  Junwei Han,  Tao Zhao,  Nian Liu,  Dingwen Zhang</p>
  <p><b>备注</b>：Accepted by T-IP</p>
  <p><b>关键词</b>：localizing action instances, attention, structured attention composition, Temporal action localization, attention composition module</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Temporal action localization aims at localizing action instances from
untrimmed videos. Existing works have designed various effective modules to
precisely localize action instances based on appearance and motion features.
However, by treating these two kinds of features with equal importance,
previous works cannot take full advantage of each modality feature, making the
learned model still sub-optimal. To tackle this issue, we make an early effort
to study temporal action localization from the perspective of multi-modality
feature learning, based on the observation that different actions exhibit
specific preferences to appearance or motion modality. Specifically, we build a
novel structured attention composition module. Unlike conventional attention,
the proposed module would not infer frame attention and modality attention
independently. Instead, by casting the relationship between the modality
attention and the frame attention as an attention assignment process, the
structured attention composition module learns to encode the frame-modality
structure and uses it to regularize the inferred frame attention and modality
attention, respectively, upon the optimal transport theory. The final
frame-modality attention is obtained by the composition of the two individual
attentions. The proposed structured attention composition module can be
deployed as a plug-and-play module into existing action localization
frameworks. Extensive experiments on two widely used benchmarks show that the
proposed structured attention composition consistently improves four
state-of-the-art temporal action localization methods and builds new
state-of-the-art performance on THUMOS14. Code is availabel at
this https URL.</p>
  </details>
</details>
<details>
  <summary>43. <b>标题：Clustering as Attention: Unified Image Segmentation with Hierarchical  Clustering</b></summary>
  <p><b>编号</b>：[193]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09949</p>
  <p><b>作者</b>：Teppei Suzuki</p>
  <p><b>备注</b>：Code: this https URL</p>
  <p><b>关键词</b>：deep neural networks, hierarchical clustering-based image, neural networks, image segmentation scheme, clustering-based image segmentation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose a hierarchical clustering-based image segmentation scheme for deep
neural networks, called HCFormer. We interpret image segmentation, including
semantic, instance, and panoptic segmentation, as a pixel clustering problem,
and accomplish it by bottom-up, hierarchical clustering with deep neural
networks. Our hierarchical clustering removes the pixel decoder from
conventional segmentation models and simplifies the segmentation pipeline,
resulting in improved segmentation accuracies and interpretability. HCFormer
can address semantic, instance, and panoptic segmentation with the same
architecture because the pixel clustering is a common approach for various
image segmentation. In experiments, HCFormer achieves comparable or superior
segmentation accuracies compared to baseline methods on semantic segmentation
(55.5 mIoU on ADE20K), instance segmentation (47.1 AP on COCO), and panoptic
segmentation (55.7 PQ on COCO).</p>
  </details>
</details>
<details>
  <summary>44. <b>标题：PGDP5K: A Diagram Parsing Dataset for Plane Geometry Problems</b></summary>
  <p><b>编号</b>：[195]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09947</p>
  <p><b>作者</b>：Yihan Hao (1 and 2),  Mingliang Zhang (2 and 3),  Fei Yin (2 and 3),  Linlin Huang (1) ((1) Beijing Jiaotong University, (2) Institute of Automation of Chinese Academy of Science, (3) University of Chinese Academy of Sciences)</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：document image understanding, attracting increasing attention, geometry problem solving, attracting increasing, image understanding</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Diagram parsing is an important foundation for geometry problem solving,
attracting increasing attention in the field of intelligent education and
document image understanding. Due to the complex layout and between-primitive
relationship, plane geometry diagram parsing (PGDP) is still a challenging task
deserving further research and exploration. An appropriate dataset is critical
for the research of PGDP. Although some datasets with rough annotations have
been proposed to solve geometric problems, they are either small in scale or
not publicly available. The rough annotations also make them not very useful.
Thus, we propose a new large-scale geometry diagram dataset named PGDP5K and a
novel annotation method. Our dataset consists of 5000 diagram samples composed
of 16 shapes, covering 5 positional relations, 22 symbol types and 6 text
types. Different from previous datasets, our PGDP5K dataset is labeled with
more fine-grained annotations at primitive level, including primitive classes,
locations and relationships. What is more, combined with above annotations and
geometric prior knowledge, it can generate intelligible geometric propositions
automatically and uniquely. We performed experiments on PGDP5K and
IMP-Geometry3K datasets reveal that the state-of-the-art (SOTA) method achieves
only 66.07% F1 value. This shows that PGDP5K presents a challenge for future
research. Our dataset is available at
this http URL.</p>
  </details>
</details>
<details>
  <summary>45. <b>标题：Hyperspectral Unmixing Based on Nonnegative Matrix Factorization: A  Comprehensive Review</b></summary>
  <p><b>编号</b>：[201]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09933</p>
  <p><b>作者</b>：Xin-Ru Feng,  Heng-Chao Li,  Rui Wang,  Qian Du,  Xiuping Jia,  Antonio Plaza</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：technique that estimates, estimates a set, set of endmembers, NMF, Hyperspectral unmixing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Hyperspectral unmixing has been an important technique that estimates a set
of endmembers and their corresponding abundances from a hyperspectral image
(HSI). Nonnegative matrix factorization (NMF) plays an increasingly significant
role in solving this problem. In this article, we present a comprehensive
survey of the NMF-based methods proposed for hyperspectral unmixing. Taking the
NMF model as a baseline, we show how to improve NMF by utilizing the main
properties of HSIs (e.g., spectral, spatial, and structural information). We
categorize three important development directions including constrained NMF,
structured NMF, and generalized NMF. Furthermore, several experiments are
conducted to illustrate the effectiveness of associated algorithms. Finally, we
conclude the article with possible future directions with the purposes of
providing guidelines and inspiration to promote the development of
hyperspectral unmixing.</p>
  </details>
</details>
<details>
  <summary>46. <b>标题：Deep transfer learning for image classification: a survey</b></summary>
  <p><b>编号</b>：[212]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09904</p>
  <p><b>作者</b>：Jo Plested,  Tom Gedeon</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：convolutional neural networks, Deep neural networks, neural networks, transfer learning, image classification</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep neural networks such as convolutional neural networks (CNNs) and
transformers have achieved many successes in image classification in recent
years. It has been consistently demonstrated that best practice for image
classification is when large deep models can be trained on abundant labelled
data. However there are many real world scenarios where the requirement for
large amounts of training data to get the best performance cannot be met. In
these scenarios transfer learning can help improve performance. To date there
have been no surveys that comprehensively review deep transfer learning as it
relates to image classification overall. However, several recent general
surveys of deep transfer learning and ones that relate to particular
specialised target image classification tasks have been published. We believe
it is important for the future progress in the field that all current knowledge
is collated and the overarching patterns analysed and discussed. In this survey
we formally define deep transfer learning and the problem it attempts to solve
in relation to image classification. We survey the current state of the field
and identify where recent progress has been made. We show where the gaps in
current knowledge are and make suggestions for how to progress the field to
fill in these knowledge gaps. We present a new taxonomy of the applications of
transfer learning for image classification. This taxonomy makes it easier to
see overarching patterns of where transfer learning has been effective and,
where it has failed to fulfill its potential. This also allows us to suggest
where the problems lie and how it could be used more effectively. We show that
under this new taxonomy, many of the applications where transfer learning has
been shown to be ineffective or even hinder performance are to be expected when
taking into account the source and target datasets and the techniques used.</p>
  </details>
</details>
<details>
  <summary>47. <b>标题：Beyond Labels: Visual Representations for Bone Marrow Cell Morphology  Recognition</b></summary>
  <p><b>编号</b>：[223]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09880</p>
  <p><b>作者</b>：Shayan Fazeli,  Alireza Samiei,  Thomas D. Lee,  Majid Sarrafzadeh</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：bone marrow cell, marrow cell cytomorphology, marrow cell, Analyzing and inspecting, hematopathology diagnosis</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Analyzing and inspecting bone marrow cell cytomorphology is a critical but
highly complex and time-consuming component of hematopathology diagnosis.
Recent advancements in artificial intelligence have paved the way for the
application of deep learning algorithms to complex medical tasks. Nevertheless,
there are many challenges in applying effective learning algorithms to medical
image analysis, such as the lack of sufficient and reliably annotated training
datasets and the highly class-imbalanced nature of most medical data. Here, we
improve on the state-of-the-art methodologies of bone marrow cell recognition
by deviating from sole reliance on labeled data and leveraging self-supervision
in training our learning models. We investigate our approach's effectiveness in
identifying bone marrow cell types. Our experiments demonstrate significant
performance improvements in conducting different bone marrow cell recognition
tasks compared to the current state-of-the-art methodologies.</p>
  </details>
</details>
<details>
  <summary>48. <b>标题：Real Time Multi-Object Detection for Helmet Safety</b></summary>
  <p><b>编号</b>：[224]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09878</p>
  <p><b>作者</b>：Mrinal Mathur,  Archana Benkkallpalli Chandrashekhar,  Venkata Krishna Chaithanya Nuthalapati</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Amazon Web Services, Web Services teamed, National Football League, League and Amazon, Amazon Web</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The National Football League and Amazon Web Services teamed up to develop the
best sports injury surveillance and mitigation program via the Kaggle
competition. Through which the NFL wants to assign specific players to each
helmet, which would help accurately identify each player's "exposures"
throughout a football play. We are trying to implement a computer vision based
ML algorithms capable of assigning detected helmet impacts to correct players
via tracking information. Our paper will explain the approach to automatically
track player helmets and their collisions. This will also allow them to review
previous plays and explore the trends in exposure over time.</p>
  </details>
</details>
<details>
  <summary>49. <b>标题：Masked Conditional Video Diffusion for Prediction, Generation, and  Interpolation</b></summary>
  <p><b>编号</b>：[235]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09853</p>
  <p><b>作者</b>：Vikram Voleti,  Alexia Jolicoeur-Martineau,  Christopher Pal</p>
  <p><b>备注</b>：9 pages, 4 figures, 7 tables</p>
  <p><b>关键词</b>：frames, future, future frames, Video, past</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Video prediction is a challenging task. The quality of video frames from
current state-of-the-art (SOTA) generative models tends to be poor and
generalization beyond the training data is difficult. Furthermore, existing
prediction frameworks are typically not capable of simultaneously handling
other video-related tasks such as unconditional generation or interpolation. In
this work, we devise a general-purpose framework called Masked Conditional
Video Diffusion (MCVD) for all of these video synthesis tasks using a
probabilistic conditional score-based denoising diffusion model, conditioned on
past and/or future frames. We train the model in a manner where we randomly and
independently mask all the past frames or all the future frames. This novel but
straightforward setup allows us to train a single model that is capable of
executing a broad range of video tasks, specifically: future/past prediction --
when only future/past frames are masked; unconditional generation -- when both
past and future frames are masked; and interpolation -- when neither past nor
future frames are masked. Our experiments show that this approach can generate
high-quality frames for diverse types of videos. Our MCVD models are built from
simple non-recurrent 2D-convolutional architectures, conditioning on blocks of
frames and generating blocks of frames. We generate videos of arbitrary lengths
autoregressively in a block-wise manner. Our approach yields SOTA results
across standard video prediction and interpolation benchmarks, with computation
times for training models measured in 1-12 days using $\le$ 4 GPUs.
this https URL</p>
  </details>
</details>
<details>
  <summary>50. <b>标题：Subcellular Protein Localisation in the Human Protein Atlas using  Ensembles of Diverse Deep Architectures</b></summary>
  <p><b>编号</b>：[240]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09841</p>
  <p><b>作者</b>：Syed Sameed Husain,  Eng-Jon Ong,  Dmitry Minskiy,  Mikel Bober-Irizar,  Amaia Irizar,  Miroslaw Bober</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：health and disease, Automated visual localisation, accelerate our understanding, function in health, Automated visual</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Automated visual localisation of subcellular proteins can accelerate our
understanding of cell function in health and disease. Despite recent advances
in machine learning (ML), humans still attain superior accuracy by using
diverse clues. We show how this gap can be narrowed by addressing three key
aspects: (i) automated improvement of cell annotation quality, (ii) new
Convolutional Neural Network (CNN) architectures supporting unbalanced and
noisy data, and (iii) informed selection and fusion of multiple & diverse
machine learning models. We introduce a new "AI-trains-AI" method for improving
the quality of weak labels and propose novel CNN architectures exploiting
wavelet filters and Weibull activations. We also explore key factors in the
multi-CNN ensembling process by analysing correlations between image-level and
cell-level predictions. Finally, in the context of the Human Protein Atlas, we
demonstrate that our system achieves state-of-the-art performance in the
multi-label single-cell classification of protein localisation patterns. It
also significantly improves generalisation ability.</p>
  </details>
</details>
<details>
  <summary>51. <b>标题：Unsupervised Learning of Depth, Camera Pose and Optical Flow from  Monocular Video</b></summary>
  <p><b>编号</b>：[252]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09821</p>
  <p><b>作者</b>：Dipan Mandal,  Abhilash Jain,  Sreenivas Subramoney</p>
  <p><b>备注</b>：8 pages, 2 figures. arXiv admin note: text overlap with arXiv:1803.02276 by other authors</p>
  <p><b>关键词</b>：joint learning system, propose DFPNet, joint learning, Camera Pose, learning system</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose DFPNet -- an unsupervised, joint learning system for monocular
Depth, Optical Flow and egomotion (Camera Pose) estimation from monocular image
sequences. Due to the nature of 3D scene geometry these three components are
coupled. We leverage this fact to jointly train all the three components in an
end-to-end manner. A single composite loss function -- which involves image
reconstruction-based loss for depth & optical flow, bidirectional consistency
checks and smoothness loss components -- is used to train the network. Using
hyperparameter tuning, we are able to reduce the model size to less than 5%
(8.4M parameters) of state-of-the-art DFP models. Evaluation on KITTI and
Cityscapes driving datasets reveals that our model achieves results comparable
to state-of-the-art in all of the three tasks, even with the significantly
smaller model size.</p>
  </details>
</details>
<details>
  <summary>52. <b>标题：Label-invariant Augmentation for Semi-Supervised Graph Classification</b></summary>
  <p><b>编号</b>：[260]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09802</p>
  <p><b>作者</b>：Han Yue,  Chunhui Zhang,  Chuxu Zhang,  Hongfu Liu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：computer vision domain, contrastiveness-based augmentation surges, graph contrastive learning, including rotation, vision domain</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recently, contrastiveness-based augmentation surges a new climax in the
computer vision domain, where some operations, including rotation, crop, and
flip, combined with dedicated algorithms, dramatically increase the model
generalization and robustness. Following this trend, some pioneering attempts
employ the similar idea to graph data. Nevertheless, unlike images, it is much
more difficult to design reasonable augmentations without changing the nature
of graphs. Although exciting, the current graph contrastive learning does not
achieve as promising performance as visual contrastive learning. We conjecture
the current performance of graph contrastive learning might be limited by the
violation of the label-invariant augmentation assumption. In light of this, we
propose a label-invariant augmentation for graph-structured data to address
this challenge. Different from the node/edge modification and subgraph
extraction, we conduct the augmentation in the representation space and
generate the augmented samples in the most difficult direction while keeping
the label of augmented data the same as the original samples. In the
semi-supervised scenario, we demonstrate our proposed method outperforms the
classical graph neural network based methods and recent graph contrastive
learning on eight benchmark graph-structured data, followed by several in-depth
experiments to further explore the label-invariant augmentation in several
aspects.</p>
  </details>
</details>
<details>
  <summary>53. <b>标题：A Peek at Peak Emotion Recognition</b></summary>
  <p><b>编号</b>：[265]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09791</p>
  <p><b>作者</b>：Tzvi Michelson,  Hillel Aviezer,  Shmuel Peleg</p>
  <p><b>备注</b>：Submitted to HBU Workshop at ICPR, 6 pages, 5 figures</p>
  <p><b>关键词</b>：facial expression recognition, field of facial, facial expression, expression recognition, recognition</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Despite much progress in the field of facial expression recognition, little
attention has been paid to the recognition of peak emotion. Aviezer et al. [1]
showed that humans have trouble discerning between positive and negative peak
emotions. In this work we analyze how deep learning fares on this challenge. We
find that (i) despite using very small datasets, features extracted from deep
learning models can achieve results significantly better than humans. (ii) We
find that deep learning models, even when trained only on datasets tagged by
humans, still outperform humans in this task.</p>
  </details>
</details>
<details>
  <summary>54. <b>标题：Identifying outliers in astronomical images with unsupervised machine  learning</b></summary>
  <p><b>编号</b>：[270]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09760</p>
  <p><b>作者</b>：Yang Han,  Zhiqiang Zou,  Nan Li,  Yanli Chen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：genuinely unforeseen knowledge, KNN, attCAE KNN, objects or phenomena, constantly lead</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Astronomical outliers, such as unusual, rare or unknown types of astronomical
objects or phenomena, constantly lead to the discovery of genuinely unforeseen
knowledge in astronomy. More unpredictable outliers will be uncovered in
principle with the increment of the coverage and quality of upcoming survey
data. However, it is a severe challenge to mine rare and unexpected targets
from enormous data with human inspection due to a significant workload.
Supervised learning is also unsuitable for this purpose since designing proper
training sets for unanticipated signals is unworkable. Motivated by these
challenges, we adopt unsupervised machine learning approaches to identify
outliers in the data of galaxy images to explore the paths for detecting
astronomical outliers. For comparison, we construct three methods, which are
built upon the k-nearest neighbors (KNN), Convolutional Auto-Encoder (CAE)+
KNN, and CAE + KNN + Attention Mechanism (attCAE KNN) separately. Testing sets
are created based on the Galaxy Zoo image data published online to evaluate the
performance of the above methods. Results show that attCAE KNN achieves the
best recall (78%), which is 53% higher than the classical KNN method and 22%
higher than CAE+KNN. The efficiency of attCAE KNN (10 minutes) is also superior
to KNN (4 hours) and equal to CAE+KNN(10 minutes) for accomplishing the same
task. Thus, we believe it is feasible to detect astronomical outliers in the
data of galaxy images in an unsupervised manner. Next, we will apply attCAE KNN
to available survey datasets to assess its applicability and reliability.</p>
  </details>
</details>
<details>
  <summary>55. <b>标题：HDGT: Heterogeneous Driving Graph Transformer for Multi-Agent Trajectory  Prediction via Scene Encoding</b></summary>
  <p><b>编号</b>：[271]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09753</p>
  <p><b>作者</b>：Xiaosong Jia,  Penghao Wu,  Li Chen,  Hongyang Li,  Yu Liu,  Junchi Yan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：driving scene, essential task, downstream task, Driving Graph Transformer, Heterogeneous Driving Graph</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>One essential task for autonomous driving is to encode the information of a
driving scene into vector representations so that the downstream task such as
trajectory prediction could perform well. The driving scene is complicated, and
there exists heterogeneity within elements, where they own diverse types of
information i.e., agent dynamics, map routing, road lines, etc. Meanwhile,
there also exist relativity across elements - meaning they have spatial
relations with each other; such relations should be canonically represented
regarding the relative measurements since the absolute value of the coordinate
is meaningless. Taking these two observations into consideration, we propose a
novel backbone, namely Heterogeneous Driving Graph Transformer (HDGT), which
models the driving scene as a heterogeneous graph with different types of nodes
and edges. For graph construction, each node represents either an agent or a
road element and each edge represents their semantics relations such as
Pedestrian-To-Crosswalk, Lane-To-Left-Lane. As for spatial relation encoding,
instead of setting a fixed global reference, the coordinate information of the
node as well as its in-edges is transformed to the local node-centric
coordinate system. For the aggregation module in the graph neural network
(GNN), we adopt the transformer structure in a hierarchical way to fit the
heterogeneous nature of inputs. Experimental results show that the proposed
method achieves new state-of-the-art on INTERACTION Prediction Challenge and
Waymo Open Motion Challenge, in which we rank 1st and 2nd respectively
regarding the minADE/minFDE metric.</p>
  </details>
</details>
<details>
  <summary>56. <b>标题：Self-supervised 3D anatomy segmentation using self-distilled masked  image transformer (SMIT)</b></summary>
  <p><b>编号</b>：[274]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10342</p>
  <p><b>作者</b>：Jue Jiang,  Neelam Tyagi,  Kathryn Tringale,  Christopher Crane,  Harini Veeraraghavan</p>
  <p><b>备注</b>：This paper has been early accepted by MICCAI 2022</p>
  <p><b>关键词</b>：model long-range context, efficiently model long-range, medical image analysis, impressive accuracy gains, medical image</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Vision transformers, with their ability to more efficiently model long-range
context, have demonstrated impressive accuracy gains in several computer vision
and medical image analysis tasks including segmentation. However, such methods
need large labeled datasets for training, which is hard to obtain for medical
image analysis. Self-supervised learning (SSL) has demonstrated success in
medical image segmentation using convolutional networks. In this work, we
developed a \underline{s}elf-distillation learning with \underline{m}asked
\underline{i}mage modeling method to perform SSL for vision
\underline{t}ransformers (SMIT) applied to 3D multi-organ segmentation from CT
and MRI. Our contribution is a dense pixel-wise regression within masked
patches called masked image prediction, which we combined with masked patch
token distillation as pretext task to pre-train vision transformers. We show
our approach is more accurate and requires fewer fine tuning datasets than
other pretext tasks. Unlike prior medical image methods, which typically used
image sets arising from disease sites and imaging modalities corresponding to
the target tasks, we used 3,643 CT scans (602,708 images) arising from head and
neck, lung, and kidney cancers as well as COVID-19 for pre-training and applied
it to abdominal organs segmentation from MRI pancreatic cancer patients as well
as publicly available 13 different abdominal organs segmentation from CT. Our
method showed clear accuracy improvement (average DSC of 0.875 from MRI and
0.878 from CT) with reduced requirement for fine-tuning datasets over commonly
used pretext tasks. Extensive comparisons against multiple current SSL methods
were done. Code will be made available upon acceptance for publication.</p>
  </details>
</details>
<details>
  <summary>57. <b>标题：User Localization using RF Sensing: A Performance comparison between LIS  and mmWave Radars</b></summary>
  <p><b>编号</b>：[279]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10321</p>
  <p><b>作者</b>：Cristian J. Vaca-Rubio,  Dariush Salami,  Petar Popovski,  Elisabeth de Carvalho,  Zheng-Hua Tan,  Stephan Sigg</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Radio Frequency, universal sensing mechanism, gesture recognition, intrusion detection, signals are omnipresent</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Since electromagnetic signals are omnipresent, Radio Frequency (RF)-sensing
has the potential to become a universal sensing mechanism with applications in
localization, smart-home, retail, gesture recognition, intrusion detection,
etc. Two emerging technologies in RF-sensing, namely sensing through Large
Intelligent Surfaces (LISs) and mmWave Frequency-Modulated Continuous-Wave
(FMCW) radars, have been successfully applied to a wide range of applications.
In this work, we compare LIS and mmWave radars for localization in real-world
and simulated environments. In our experiments, the mmWave radar achieves 0.71
Intersection Over Union (IOU) and 3cm error for bounding boxes, while LIS has
0.56 IOU and 10cm distance error. Although the radar outperforms the LIS in
terms of accuracy, LIS features additional applications in communication in
addition to sensing scenarios.</p>
  </details>
</details>
<details>
  <summary>58. <b>标题：Human Gender Prediction Based on Deep Transfer Learning from Panoramic  Radiograph Images</b></summary>
  <p><b>编号</b>：[302]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09850</p>
  <p><b>作者</b>：I. Atas</p>
  <p><b>备注</b>：8 pages, 11 figures, 10 tables</p>
  <p><b>关键词</b>：Panoramic Dental Radiography, Dental Radiography, forensic medicine, transfer learning method, determination in forensic</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Panoramic Dental Radiography (PDR) image processing is one of the most
extensively used manual methods for gender determination in forensic medicine.
Manual approaches require a wide range of mandibular parameter measurements in
metric units. Besides being time-consuming, these methods also necessitate the
employment of experienced professionals. In this context, deep learning models
are widely utilized in the auto-analysis of radiological images nowadays, owing
to their high processing speed, accuracy, and stability. In our study, a data
set consisting of 24,000 dental panoramic images was prepared for binary
classification, and the transfer learning method was used to accelerate the
training and increase the performance of our proposed DenseNet121 deep learning
model. With the transfer learning method, instead of starting the learning
process from scratch, the existing patterns learned beforehand were used.
Extensive comparisons were made using deep transfer learning (DTL) models
VGG16, ResNet50, and EfficientNetB6 to assess the classification performance of
the proposed model in PDR images. According to the findings of the comparative
analysis, the proposed model outperformed the other approaches by achieving a
success rate of 97.25% in gender classification.</p>
  </details>
</details>
<details>
  <summary>59. <b>标题：Generation of Artificial CT Images using Patch-based Conditional  Generative Adversarial Networks</b></summary>
  <p><b>编号</b>：[303]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09842</p>
  <p><b>作者</b>：Marija Habijan,  Irena Galic</p>
  <p><b>备注</b>：Proceedings of the 7th International Conference on Smart and Sustainable Technologies (SpliTech 2022)</p>
  <p><b>关键词</b>：clinical procedures, Deep learning, alleviate diagnosis, diagnosis and prognosis, image generation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep learning has a great potential to alleviate diagnosis and prognosis for
various clinical procedures. However, the lack of a sufficient number of
medical images is the most common obstacle in conducting image-based analysis
using deep learning. Due to the annotations scarcity, semi-supervised
techniques in the automatic medical analysis are getting high attention.
Artificial data augmentation and generation techniques such as generative
adversarial networks (GANs) may help overcome this obstacle. In this work, we
present an image generation approach that uses generative adversarial networks
with a conditional discriminator where segmentation masks are used as
conditions for image generation. We validate the feasibility of GAN-enhanced
medical image generation on whole heart computed tomography (CT) images and its
seven substructures, namely: left ventricle, right ventricle, left atrium,
right atrium, myocardium, pulmonary arteries, and aorta. Obtained results
demonstrate the suitability of the proposed adversarial approach for the
accurate generation of high-quality CT images. The presented method shows great
potential to facilitate further research in the domain of artificial medical
image generation.</p>
  </details>
</details>
<h1>自然语言处理</h1>
<details>
  <summary>1. <b>标题：Lossless Acceleration for Seq2seq Generation with Aggressive Decoding</b></summary>
  <p><b>编号</b>：[2]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10350</p>
  <p><b>作者</b>：Tao Ge,  Heming Xia,  Xin Sun,  Si-Qing Chen,  Furu Wei</p>
  <p><b>备注</b>：24-page Microsoft Research Technical Report. Content overlap with arXiv:2106.04970 and arXiv:2203.16487</p>
  <p><b>关键词</b>：Aggressive Decoding, decoding, Aggressive, Input-guided Aggressive Decoding, Generalized Aggressive Decoding</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We study lossless acceleration for seq2seq generation with a novel decoding
algorithm -- Aggressive Decoding. Unlike the previous efforts (e.g.,
non-autoregressive decoding) speeding up seq2seq generation at the cost of
quality loss, our approach aims to yield the identical (or better) generation
compared with autoregressive decoding but in a significant speedup, achieved by
innovative cooperation of aggressive decoding and verification that are both
efficient due to parallel computing.
We propose two Aggressive Decoding paradigms for 2 kinds of seq2seq tasks: 1)
For the seq2seq tasks whose inputs and outputs are highly similar (e.g.,
Grammatical Error Correction), we propose Input-guided Aggressive Decoding
(IAD) that aggressively copies from the input sentence as drafted decoded
tokens to verify in parallel; 2) For other general seq2seq tasks (e.g., Machine
Translation), we propose Generalized Aggressive Decoding (GAD) that first
employs an additional non-autoregressive decoding model for aggressive decoding
and then verifies in parallel in the autoregressive manner.
We test Aggressive Decoding on the most popular 6-layer Transformer model on
GPU in multiple seq2seq tasks: 1) For IAD, we show that it can introduce a
7x-9x speedup for the Transformer in Grammatical Error Correction and Text
Simplification tasks with the identical results as greedy decoding; 2) For GAD,
we observe a 3x-5x speedup with the identical or even better quality in two
important seq2seq tasks: Machine Translation and Abstractive Summarization.
Moreover, Aggressive Decoding can benefit even more from stronger computing
devices that are better at parallel computing. Given the lossless quality as
well as significant and promising speedup, we believe Aggressive Decoding may
potentially evolve into a de facto standard for efficient and lossless seq2seq
generation in the near future.</p>
  </details>
</details>
<details>
  <summary>2. <b>标题：ClusterEA: Scalable Entity Alignment with Stochastic Training and  Normalized Mini-batch Similarities</b></summary>
  <p><b>编号</b>：[14]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10312</p>
  <p><b>作者</b>：Yunjun Gao,  Xiaoze Liu,  Junyang Wu,  Tianyi Li,  Pengfei Wang,  Lu Chen</p>
  <p><b>备注</b>：Accepted by ACM SIGKDD 2022 Research Track</p>
  <p><b>关键词</b>：aims at finding, knowledge graphs, finding equivalent entities, Entity alignment, finding equivalent</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Entity alignment (EA) aims at finding equivalent entities in different
knowledge graphs (KGs). Embedding-based approaches have dominated the EA task
in recent years. Those methods face problems that come from the geometric
properties of embedding vectors, including hubness and isolation. To solve
these geometric problems, many normalization approaches have been adopted to
EA. However, the increasing scale of KGs renders it is hard for EA models to
adopt the normalization processes, thus limiting their usage in real-world
applications. To tackle this challenge, we present ClusterEA, a general
framework that is capable of scaling up EA models and enhancing their results
by leveraging normalization methods on mini-batches with a high entity
equivalent rate. ClusterEA contains three components to align entities between
large-scale KGs, including stochastic training, ClusterSampler, and
SparseFusion. It first trains a large-scale Siamese GNN for EA in a stochastic
fashion to produce entity embeddings. Based on the embeddings, a novel
ClusterSampler strategy is proposed for sampling highly overlapped
mini-batches. Finally, ClusterEA incorporates SparseFusion, which normalizes
local and global similarity and then fuses all similarity matrices to obtain
the final similarity matrix. Extensive experiments with real-life datasets on
EA benchmarks offer insight into the proposed framework, and suggest that it is
capable of outperforming the state-of-the-art scalable EA framework by up to 8
times in terms of Hits@1.</p>
  </details>
</details>
<details>
  <summary>3. <b>标题：Heterformer: A Transformer Architecture for Node Representation Learning  on Heterogeneous Text-Rich Networks</b></summary>
  <p><b>编号</b>：[24]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10282</p>
  <p><b>作者</b>：Bowen Jin,  Yu Zhang,  Qi Zhu,  Jiawei Han</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：heterogeneous text-rich networks, study node representation, node representation learning, heterogeneous text-rich, representation learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We study node representation learning on heterogeneous text-rich networks,
where nodes and edges are multi-typed and some types of nodes are associated
with text information. Although recent studies on graph neural networks (GNNs)
and pretrained language models (PLMs) have demonstrated their power in encoding
network and text signals, respectively, less focus has been given to delicately
coupling these two types of models on heterogeneous text-rich networks.
Specifically, existing GNNs rarely model text in each node in a contextualized
way; existing PLMs can hardly be applied to characterize graph structures due
to their sequence architecture. In this paper, we propose Heterformer, a
Heterogeneous GNN-nested transformer that blends GNNs and PLMs into a unified
model. Different from previous "cascaded architectures" that directly add GNN
layers upon a PLM, our Heterformer alternately stacks two modules - a
graph-attention-based neighbor aggregation module and a transformer-based text
and neighbor joint encoding module - to facilitate thorough mutual enhancement
between network and text signals. Meanwhile, Heterformer is capable of
characterizing network heterogeneity and nodes without text information.
Comprehensive experiments on three large-scale datasets from different domains
demonstrate the superiority of Heterformer over state-of-the-art baselines in
link prediction, transductive/inductive node classification, node clustering,
and semantics-based retrieval.</p>
  </details>
</details>
<details>
  <summary>4. <b>标题：Visualizing and Explaining Language Models</b></summary>
  <p><b>编号</b>：[43]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10238</p>
  <p><b>作者</b>：Adrian M.P. Braşoveanu,  Răzvan Andonie</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Natural Language Processing, Natural Language, Language Processing, Deep Learning, Artificial Intelligence</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>During the last decade, Natural Language Processing has become, after
Computer Vision, the second field of Artificial Intelligence that was massively
changed by the advent of Deep Learning. Regardless of the architecture, the
language models of the day need to be able to process or generate text, as well
as predict missing words, sentences or relations depending on the task. Due to
their black-box nature, such models are difficult to interpret and explain to
third parties. Visualization is often the bridge that language model designers
use to explain their work, as the coloring of the salient words and phrases,
clustering or neuron activations can be used to quickly understand the
underlying models. This paper showcases the techniques used in some of the most
popular Deep Learning for NLP visualizations, with a special focus on
interpretability and explainability.</p>
  </details>
</details>
<details>
  <summary>5. <b>标题：M3ED: Multi-modal Multi-scene Multi-label Emotional Dialogue Database</b></summary>
  <p><b>编号</b>：[44]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10237</p>
  <p><b>作者</b>：Jinming Zhao,  Tenggan Zhang,  Jingwen Hu,  Yuchen Liu,  Qin Jin,  Xinchao Wang,  Haizhou Li</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Multi-modal Multi-scene Multi-label, Multi-scene Multi-label Emotional, Multi-label Emotional Dialogue, Emotional Dialogue dataset, interlocutor stimulus</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The emotional state of a speaker can be influenced by many different factors
in dialogues, such as dialogue scene, dialogue topic, and interlocutor
stimulus. The currently available data resources to support such multimodal
affective analysis in dialogues are however limited in scale and diversity. In
this work, we propose a Multi-modal Multi-scene Multi-label Emotional Dialogue
dataset, M3ED, which contains 990 dyadic emotional dialogues from 56 different
TV series, a total of 9,082 turns and 24,449 utterances. M3 ED is annotated
with 7 emotion categories (happy, surprise, sad, disgust, anger, fear, and
neutral) at utterance level, and encompasses acoustic, visual, and textual
modalities. To the best of our knowledge, M3ED is the first multimodal
emotional dialogue dataset in Chinese. It is valuable for cross-culture emotion
analysis and recognition. We apply several state-of-the-art methods on the M3ED
dataset to verify the validity and quality of the dataset. We also propose a
general Multimodal Dialogue-aware Interaction framework, MDI, to model the
dialogue context for emotion recognition, which achieves comparable performance
to the state-of-the-art methods on the M3ED. The full dataset and codes are
available.</p>
  </details>
</details>
<details>
  <summary>6. <b>标题：Federated learning for violence incident prediction in a simulated  cross-institutional psychiatric setting</b></summary>
  <p><b>编号</b>：[47]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10234</p>
  <p><b>作者</b>：Thomas Borger,  Pablo Mosteiro,  Heysem Kaya,  Emil Rijcken,  Albert Ali Salah,  Floortje Scheepers,  Marco Spruit</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Federated Learning, learning, Federated, machine learning models, common and severe</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Inpatient violence is a common and severe problem within psychiatry. Knowing
who might become violent can influence staffing levels and mitigate severity.
Predictive machine learning models can assess each patient's likelihood of
becoming violent based on clinical notes. Yet, while machine learning models
benefit from having more data, data availability is limited as hospitals
typically do not share their data for privacy preservation. Federated Learning
(FL) can overcome the problem of data limitation by training models in a
decentralised manner, without disclosing data between collaborators. However,
although several FL approaches exist, none of these train Natural Language
Processing models on clinical notes. In this work, we investigate the
application of Federated Learning to clinical Natural Language Processing,
applied to the task of Violence Risk Assessment by simulating a
cross-institutional psychiatric setting. We train and compare four models: two
local models, a federated model and a data-centralised model. Our results
indicate that the federated model outperforms the local models and has similar
performance as the data-centralised model. These findings suggest that
Federated Learning can be used successfully in a cross-institutional setting
and is a step towards new applications of Federated Learning based on clinical
notes</p>
  </details>
</details>
<details>
  <summary>7. <b>标题：RigoBERTa: A State-of-the-Art Language Model For Spanish</b></summary>
  <p><b>编号</b>：[48]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10233</p>
  <p><b>作者</b>：Alejandro Vaca Serrano,  Guillem Garcia Subies,  Helena Montoro Zamorano,  Nuria Aldama Garcia,  Doaa Samy,  David Betancur Sanchez,  Antonio Moreno Sandoval,  Marta Guerrero Nieto,  Alvaro Barbero Jimenez</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：paper presents RigoBERTa, paper presents, Spanish language models, BERTIN and BETO, Spanish language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper presents RigoBERTa, a State-of-the-Art Language Model for Spanish.
RigoBERTa is trained over RigoCorpus, a well-curated corpus formed up from
different subcorpora with key features. It follows the DeBERTa architecture,
which has several advantages over other architectures of similar size as BERT
or RoBERTa.
RigoBERTa performance is assessed over 13 NLU tasks in comparison with other
available Spanish language models, namely, MarIA, BERTIN and BETO. RigoBERTa
outperformed the three models in 10 out of the 13 tasks, achieving new
"State-of-the-Art" results.</p>
  </details>
</details>
<details>
  <summary>8. <b>标题：You Don't Know My Favorite Color: Preventing Dialogue Representations  from Revealing Speakers' Private Personas</b></summary>
  <p><b>编号</b>：[51]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10228</p>
  <p><b>作者</b>：Haoran Li,  Yangqiu Song,  Lixin Fan</p>
  <p><b>备注</b>：Conference paper accepted by NAACL 2022</p>
  <p><b>关键词</b>：pretrained language models, evolve rapidly, large pretrained language, large language models, large pretrained</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Social chatbots, also known as chit-chat chatbots, evolve rapidly with large
pretrained language models. Despite the huge progress, privacy concerns have
arisen recently: training data of large language models can be extracted via
model inversion attacks. On the other hand, the datasets used for training
chatbots contain many private conversations between two individuals. In this
work, we further investigate the privacy leakage of the hidden states of
chatbots trained by language modeling which has not been well studied yet. We
show that speakers' personas can be inferred through a simple neural network
with high accuracy. To this end, we propose effective defense objectives to
protect persona leakage from hidden states. We conduct extensive experiments to
demonstrate that our proposed defense objectives can greatly reduce the attack
accuracy from 37.6% to 0.5%. Meanwhile, the proposed objectives preserve
language models' powerful generation ability.</p>
  </details>
</details>
<details>
  <summary>9. <b>标题：Label Anchored Contrastive Learning for Language Understanding</b></summary>
  <p><b>编号</b>：[52]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10227</p>
  <p><b>作者</b>：Zhenyu Zhang,  Yuming Zhao,  Meng Chen,  Xiaodong He</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：achieved astonishing progress, processing fields recently, language processing fields, natural language processing, computer vision</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Contrastive learning (CL) has achieved astonishing progress in computer
vision, speech, and natural language processing fields recently with
self-supervised learning. However, CL approach to the supervised setting is not
fully explored, especially for the natural language understanding
classification task. Intuitively, the class label itself has the intrinsic
ability to perform hard positive/negative mining, which is crucial for CL.
Motivated by this, we propose a novel label anchored contrastive learning
approach (denoted as LaCon) for language understanding. Specifically, three
contrastive objectives are devised, including a multi-head instance-centered
contrastive loss (ICL), a label-centered contrastive loss (LCL), and a label
embedding regularizer (LER). Our approach does not require any specialized
network architecture or any extra data augmentation, thus it can be easily
plugged into existing powerful pre-trained language models. Compared to the
state-of-the-art baselines, LaCon obtains up to 4.1% improvement on the popular
datasets of GLUE and CLUE benchmarks. Besides, LaCon also demonstrates
significant advantages under the few-shot and data imbalance settings, which
obtains up to 9.4% improvement on the FewGLUE and FewCLUE benchmarking tasks.</p>
  </details>
</details>
<details>
  <summary>10. <b>标题：Do Transformer Models Show Similar Attention Patterns to Task-Specific  Human Gaze?</b></summary>
  <p><b>编号</b>：[53]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10226</p>
  <p><b>作者</b>：Stephanie Brandl,  Oliver Eberle,  Jonas Pilot,  Anders Søgaard</p>
  <p><b>备注</b>：Accepted to ACL 2022</p>
  <p><b>关键词</b>：NLP models, Learned self-attention functions, NLP, human, Learned self-attention</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Learned self-attention functions in state-of-the-art NLP models often
correlate with human attention. We investigate whether self-attention in
large-scale pre-trained language models is as predictive of human eye fixation
patterns during task-reading as classical cognitive models of human attention.
We compare attention functions across two task-specific reading datasets for
sentiment analysis and relation extraction. We find the predictiveness of
large-scale pre-trained self-attention for human attention depends on `what is
in the tail', e.g., the syntactic nature of rare contexts. Further, we observe
that task-specific fine-tuning does not increase the correlation with human
task-specific reading. Through an input reduction experiment we give
complementary insights on the sparsity and fidelity trade-off, showing that
lower-entropy attention vectors are more faithful.</p>
  </details>
</details>
<details>
  <summary>11. <b>标题：On the Trade-off between Redundancy and Local Coherence in Summarization</b></summary>
  <p><b>编号</b>：[67]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10192</p>
  <p><b>作者</b>：Ronald Cardenas,  Matthias Galle,  Shay B. Cohen</p>
  <p><b>备注</b>：Under revision</p>
  <p><b>关键词</b>：highly redundant text, produce poorly coherent, Extractive summarization systems, Extractive summarization, unsupervised extractive summarization</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Extractive summarization systems are known to produce poorly coherent and, if
not accounted for, highly redundant text. In this work, we tackle the problem
of summary redundancy in unsupervised extractive summarization of long,
highly-redundant documents. For this, we leverage a psycholinguistic theory of
human reading comprehension which directly models local coherence and
redundancy. Implementing this theory, our system operates at the proposition
level and exploits properties of human memory representations to rank similarly
content units that are coherent and non-redundant, hence encouraging the
extraction of less redundant final summaries. Because of the impact of the
summary length on automatic measures, we control for it by formulating content
selection as an optimization problem with soft constraints in the budget of
information retrieved. Using summarization of scientific articles as a case
study, extensive experiments demonstrate that the proposed systems extract
consistently less redundant summaries across increasing levels of document
redundancy, whilst maintaining comparable performance (in terms of relevancy
and local coherence) against strong unsupervised baselines according to
automated evaluations.</p>
  </details>
</details>
<details>
  <summary>12. <b>标题：Progressive Class Semantic Matching for Semi-supervised Text  Classification</b></summary>
  <p><b>编号</b>：[68]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10189</p>
  <p><b>作者</b>：Hai-Ming Xu,  Lingqiao Liu,  Ehsan Abbasnejad</p>
  <p><b>备注</b>：NAACL2022 (oral)</p>
  <p><b>关键词</b>：cost for text-classification, Semi-supervised learning, reduce the annotation, annotation cost, Semi-supervised</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Semi-supervised learning is a promising way to reduce the annotation cost for
text-classification. Combining with pre-trained language models (PLMs), e.g.,
BERT, recent semi-supervised learning methods achieved impressive performance.
In this work, we further investigate the marriage between semi-supervised
learning and a pre-trained language model. Unlike existing approaches that
utilize PLMs only for model parameter initialization, we explore the inherent
topic matching capability inside PLMs for building a more powerful
semi-supervised learning approach. Specifically, we propose a joint
semi-supervised learning process that can progressively build a standard
$K$-way classifier and a matching network for the input text and the Class
Semantic Representation (CSR). The CSR will be initialized from the given
labeled sentences and progressively updated through the training process. By
means of extensive experiments, we show that our method can not only bring
remarkable improvement to baselines, but also overall be more stable, and
achieves state-of-the-art performance in semi-supervised text classification.</p>
  </details>
</details>
<details>
  <summary>13. <b>标题：Prototypical Calibration for Few-shot Learning of Language Models</b></summary>
  <p><b>编号</b>：[73]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10183</p>
  <p><b>作者</b>：Zhixiong Han,  Yaru Hao,  Li Dong,  Furu Wei</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：In-context learning, learning of GPT-like, GPT-like models, recognized as fragile, hand-crafted templates</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In-context learning of GPT-like models has been recognized as fragile across
different hand-crafted templates, and demonstration permutations. In this work,
we propose prototypical calibration to adaptively learn a more robust decision
boundary for zero- and few-shot classification, instead of greedy decoding.
Concretely, our method first adopts Gaussian mixture distribution to estimate
the prototypical clusters for all categories. Then we assign each cluster to
the corresponding label by solving a weighted bipartite matching problem. Given
an example, its prediction is calibrated by the likelihood of prototypical
clusters. Experimental results show that prototypical calibration yields a 15%
absolute improvement on a diverse set of tasks. Extensive analysis across
different scales also indicates that our method calibrates the decision
boundary as expected, greatly improving the robustness of GPT to templates,
permutations, and class imbalance.</p>
  </details>
</details>
<details>
  <summary>14. <b>标题：Visually-Augmented Language Modeling</b></summary>
  <p><b>编号</b>：[75]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10178</p>
  <p><b>作者</b>：Weizhi Wang,  Li Dong,  Hao Cheng,  Haoyu Song,  Xiaodong Liu,  Xifeng Yan,  Jianfeng Gao,  Furu Wei</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：visual, Human language, knowledge including visual, including visual knowledge, VaLM</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Human language is grounded on multimodal knowledge including visual knowledge
like colors, sizes, and shapes. However, current large-scale pre-trained
language models rely on the text-only self-supervised training with massive
text data, which precludes them from utilizing relevant visual information when
necessary. To address this, we propose a novel pre-training framework, named
VaLM, to Visually-augment text tokens with retrieved relevant images for
Language Modeling. Specifically, VaLM builds on a novel text-vision alignment
method via an image retrieval module to fetch corresponding images given a
textual context. With the visually-augmented context, VaLM uses a visual
knowledge fusion layer to enable multimodal grounded language modeling by
attending on both text context and visual knowledge in images. We evaluate the
proposed model on various multimodal commonsense reasoning tasks, which require
visual information to excel. VaLM outperforms the text-only baseline with
substantial gains of +8.66% and +37.81% accuracy on object color and size
reasoning, respectively.</p>
  </details>
</details>
<details>
  <summary>15. <b>标题：How to keep text private? A systematic review of deep learning methods  for privacy-preserving natural language processing</b></summary>
  <p><b>编号</b>：[118]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10095</p>
  <p><b>作者</b>：Samuel Sousa,  Roman Kern</p>
  <p><b>备注</b>：59 pages, 15 figures</p>
  <p><b>关键词</b>：natural language processing, European Union General, General Data Protection, handle private data, Union General Data</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep learning (DL) models for natural language processing (NLP) tasks often
handle private data, demanding protection against breaches and disclosures.
Data protection laws, such as the European Union's General Data Protection
Regulation (GDPR), thereby enforce the need for privacy. Although many
privacy-preserving NLP methods have been proposed in recent years, no
categories to organize them have been introduced yet, making it hard to follow
the progress of the literature. To close this gap, this article systematically
reviews over sixty DL methods for privacy-preserving NLP published between 2016
and 2020, covering theoretical foundations, privacy-enhancing technologies, and
analysis of their suitability for real-world scenarios. First, we introduce a
novel taxonomy for classifying the existing methods into three categories: data
safeguarding methods, trusted methods, and verification methods. Second, we
present an extensive summary of privacy threats, datasets for applications, and
metrics for privacy evaluation. Third, throughout the review, we describe
privacy issues in the NLP pipeline in a holistic view. Further, we discuss open
challenges in privacy-preserving NLP regarding data traceability, computation
overhead, dataset size, the prevalence of human biases in embeddings, and the
privacy-utility tradeoff. Finally, this review presents future research
directions to guide successive research and development of privacy-preserving
NLP models.</p>
  </details>
</details>
<details>
  <summary>16. <b>标题：Semi-self-supervised Automated ICD Coding</b></summary>
  <p><b>编号</b>：[122]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10088</p>
  <p><b>作者</b>：Hlynur D. Hlynsson,  Steindór Ellertsson,  Jón F. Daðason,  Emil L. Sigurdsson,  Hrafn Loftsson</p>
  <p><b>备注</b>：10 pages</p>
  <p><b>关键词</b>：Clinical Text Notes, free text format, unstructured free text, Text Notes, physicians' reasoning process</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Clinical Text Notes (CTNs) contain physicians' reasoning process, written in
an unstructured free text format, as they examine and interview patients. In
recent years, several studies have been published that provide evidence for the
utility of machine learning for predicting doctors' diagnoses from CTNs, a task
known as ICD coding. Data annotation is time consuming, particularly when a
degree of specialization is needed, as is the case for medical data. This paper
presents a method of augmenting a sparsely annotated dataset of Icelandic CTNs
with a machine-learned imputation in a semi-self-supervised manner. We train a
neural network on a small set of annotated CTNs and use it to extract clinical
features from a set of un-annotated CTNs. These clinical features consist of
answers to about a thousand potential questions that a physician might find the
answers to during a consultation of a patient. The features are then used to
train a classifier for the diagnosis of certain types of diseases. We report
the results of an evaluation of this data augmentation method over three tiers
of data availability to the physician. Our data augmentation method shows a
significant positive effect which is diminished when clinical features from the
examination of the patient and diagnostics are made available. We recommend our
method for augmenting scarce datasets for systems that take decisions based on
clinical features that do not include examinations or tests.</p>
  </details>
</details>
<details>
  <summary>17. <b>标题：Uzbek affix finite state machine for stemming</b></summary>
  <p><b>编号</b>：[128]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10078</p>
  <p><b>作者</b>：Maksud Sharipov,  Ulugbek Salaev</p>
  <p><b>备注</b>：Accepted for publication in the IX International Conference on Computer Processing of Turkic Languages "TurkLang 2021", 15 pages, 12 figures</p>
  <p><b>关键词</b>：Uzbek, Uzbek language, morphological analyzer, finite state, work presents</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This work presents a morphological analyzer for the Uzbek language using a
finite state machine. The proposed methodology is a morphologic analysis of
Uzbek words by using an affix striping to find a root and without including any
lexicon. This method helps to perform morphological analysis of words from a
large amount of text at high speed as well as it is not required using of
memory for keeping vocabulary. According to Uzbek, an agglutinative language
can be designed with finite state machines (FSMs). In contrast to the previous
works, this study modeled the completed FSMs for all word classes by using the
Uzbek language's morphotactic rules in right to left order. This paper shows
the stages of this methodology including the classification of the affixes, the
generation of the FSMs for each affix class, and the combination into a head
machine to make analysis a word.</p>
  </details>
</details>
<details>
  <summary>18. <b>标题：Understanding and Mitigating the Uncertainty in Zero-Shot Translation</b></summary>
  <p><b>编号</b>：[134]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10068</p>
  <p><b>作者</b>：Wenxuan Wang,  Wenxiang Jiao,  Shuo Wang,  Zhaopeng Tu,  Michael R. Lyu</p>
  <p><b>备注</b>：work in progress</p>
  <p><b>关键词</b>：comprehensive multilingual neural, multilingual neural machine, neural machine translation, promising direction, direction for building</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Zero-shot translation is a promising direction for building a comprehensive
multilingual neural machine translation (MNMT) system. However, its quality is
still not satisfactory due to off-target issues. In this paper, we aim to
understand and alleviate the off-target issues from the perspective of
uncertainty in zero-shot translation. By carefully examining the translation
output and model confidence, we identify two uncertainties that are responsible
for the off-target issues, namely, extrinsic data uncertainty and intrinsic
model uncertainty. Based on the observations, we propose two light-weight and
complementary approaches to denoise the training data for model training, and
mask out the vocabulary of the off-target languages in inference. Extensive
experiments on both balanced and unbalanced datasets show that our approaches
significantly improve the performance of zero-shot translation over strong MNMT
baselines. Qualitative analyses provide insights into where our approaches
reduce off-target translations</p>
  </details>
</details>
<details>
  <summary>19. <b>标题：Beyond the Granularity: Multi-Perspective Dialogue Collaborative  Selection for Dialogue State Tracking</b></summary>
  <p><b>编号</b>：[138]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10059</p>
  <p><b>作者</b>：Jinyu Guo,  Kai Shuang,  Jijie Li,  Zihan Wang,  Yixuan Liu</p>
  <p><b>备注</b>：Accepted by ACL 2022 main conference (long paper)</p>
  <p><b>关键词</b>：dialogue history, dialogue, crucial material, utilization varies, history</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In dialogue state tracking, dialogue history is a crucial material, and its
utilization varies between different models. However, no matter how the
dialogue history is used, each existing model uses its own consistent dialogue
history during the entire state tracking process, regardless of which slot is
updated. Apparently, it requires different dialogue history to update different
slots in different turns. Therefore, using consistent dialogue contents may
lead to insufficient or redundant information for different slots, which
affects the overall performance. To address this problem, we devise DiCoS-DST
to dynamically select the relevant dialogue contents corresponding to each slot
for state updating. Specifically, it first retrieves turn-level utterances of
dialogue history and evaluates their relevance to the slot from a combination
of three perspectives: (1) its explicit connection to the slot name; (2) its
relevance to the current turn dialogue; (3) Implicit Mention Oriented
Reasoning. Then these perspectives are combined to yield a decision, and only
the selected dialogue contents are fed into State Generator, which explicitly
minimizes the distracting information passed to the downstream state
prediction. Experimental results show that our approach achieves new
state-of-the-art performance on MultiWOZ 2.1 and MultiWOZ 2.2, and achieves
superior performance on multiple mainstream benchmark datasets (including
Sim-M, Sim-R, and DSTC2).</p>
  </details>
</details>
<details>
  <summary>20. <b>标题：Exploring Extreme Parameter Compression for Pre-trained Language Models</b></summary>
  <p><b>编号</b>：[149]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10036</p>
  <p><b>作者</b>：Yuxin Ren,  Benyou Wang,  Lifeng Shang,  Xin Jiang,  Qun Liu</p>
  <p><b>备注</b>：Accepted at ICLR2022. Code available at this https URL</p>
  <p><b>关键词</b>：Transformer-based pre-trained models, Pre-trained Language Models, large-scale Transformer-based pre-trained, natural language processing, Transformer-based pre-trained</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent work explored the potential of large-scale Transformer-based
pre-trained models, especially Pre-trained Language Models (PLMs) in natural
language processing. This raises many concerns from various perspectives, e.g.,
financial costs and carbon emissions. Compressing PLMs like BERT with
negligible performance loss for faster inference and cheaper deployment has
attracted much attention. In this work, we aim to explore larger compression
ratios for PLMs, among which tensor decomposition is a potential but
under-investigated one. Two decomposition and reconstruction protocols are
further proposed to improve the effectiveness and efficiency during
compression. Our compressed BERT with ${1}/{7}$ parameters in Transformer
layers performs on-par with, sometimes slightly better than the original BERT
in GLUE benchmark. A tiny version achieves $96.7\%$ performance of BERT-base
with $ {1}/{48} $ encoder parameters (i.e., less than 2M parameters excluding
the embedding layer) and $2.7 \times$ faster on inference. To show that the
proposed method is orthogonal to existing compression methods like knowledge
distillation, we also explore the benefit of the proposed method on a distilled
BERT.</p>
  </details>
</details>
<details>
  <summary>21. <b>标题：Transition-based Semantic Role Labeling with Pointer Networks</b></summary>
  <p><b>编号</b>：[154]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10023</p>
  <p><b>作者</b>：Daniel Fernández-González</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Semantic role labeling, Semantic role, role labeling, focuses on recognizing, question answering</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Semantic role labeling (SRL) focuses on recognizing the predicate-argument
structure of a sentence and plays a critical role in many natural language
processing tasks such as machine translation and question answering.
Practically all available methods do not perform full SRL, since they rely on
pre-identified predicates, and most of them follow a pipeline strategy, using
specific models for undertaking one or several SRL subtasks. In addition,
previous approaches have a strong dependence on syntactic information to
achieve state-of-the-art performance, despite being syntactic trees equally
hard to produce. These simplifications and requirements make the majority of
SRL systems impractical for real-world applications. In this article, we
propose the first transition-based SRL approach that is capable of completely
processing an input sentence in a single left-to-right pass, with neither
leveraging syntactic information nor resorting to additional modules. Thanks to
our implementation based on Pointer Networks, full SRL can be accurately and
efficiently done in $O(n^2)$, achieving the best performance to date on the
majority of languages from the CoNLL-2009 shared task.</p>
  </details>
</details>
<details>
  <summary>22. <b>标题：Translating Hanja historical documents to understandable Korean and  English</b></summary>
  <p><b>编号</b>：[158]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10019</p>
  <p><b>作者</b>：Juhee Son,  Jiho Jin,  Haneul Yoo,  JinYeong Bak,  Kyunghyun Cho,  Alice Oh</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Joseon Dynasty, Korean, translation, Korean and English, archaic Korean</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The Annals of Joseon Dynasty (AJD) contain the daily records of the Kings of
Joseon, the 500-year kingdom preceding the modern nation of Korea. The Annals
were originally written in an archaic Korean writing system, `Hanja', and
translated into Korean from 1968 to 1993. However, this translation was literal
and contained many archaic Korean words; thus, a new expert translation effort
began in 2012, completing the records of only one king in a decade. Also,
expert translators are working on an English translation, of which only one
king's records are available because of the high cost and slow progress. Thus,
we propose H2KE, the neural machine translation model that translates Hanja
historical documents to understandable Korean and English. Based on the
multilingual neural machine translation approach, it translates the historical
document written in Hanja, using both the full dataset of outdated Korean
translation and a small dataset of recently translated Korean and English. We
compare our method with two baselines: one is a recent model that
simultaneously learns to restore and translate Hanja historical document and
the other is the transformer that trained on newly translated corpora only. The
results show that our method significantly outperforms the baselines in terms
of BLEU score in both modern Korean and English translations. We also conduct a
human evaluation that shows that our translation is preferred over the original
expert translation.</p>
  </details>
</details>
<details>
  <summary>23. <b>标题：Descartes: Generating Short Descriptions of Wikipedia Articles</b></summary>
  <p><b>编号</b>：[163]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10012</p>
  <p><b>作者</b>：Marija Sakota,  Maxime Peyrard,  Robert West</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Western Europe, Country in Western, short description Country, automatically generating short, description Country</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We introduce and tackle the problem of automatically generating short
descriptions of Wikipedia articles (e.g., Belgium has a short description
Country in Western Europe). We introduce Descartes, a model that can generate
descriptions performing on par with human editors. Our human evaluation results
indicate that Descartes is preferred over editor-written descriptions about 50%
of time. Further manual analysis show that Descartes generates descriptions
considered as "valid" for 91.3% of articles, this is the as same editor-written
descriptions. Such performances are made possible by integrating other signals
naturally existing in Wikipedia: (i) articles about the same entity in
different languages, (ii) existing short descriptions in other languages, and
(iii) structural information from Wikidata. Our work has direct practical
applications in helping Wikipedia editors to provide short descriptions for the
more than 9 million articles still missing one. Finally, our proposed
architecture can easily be re-purposed to address other information gaps in
Wikipedia.</p>
  </details>
</details>
<details>
  <summary>24. <b>标题：SALTED: A Framework for SAlient Long-Tail Translation Error Detection</b></summary>
  <p><b>编号</b>：[176]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09988</p>
  <p><b>作者</b>：Vikas Raunak,  Matt Post,  Arul Menezes</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Traditional machine translation, machine translation, average measure, long tail, Traditional machine</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Traditional machine translation (MT) metrics provide an average measure of
translation quality that is insensitive to the long tail of behavioral problems
in MT. Examples include translation of numbers, physical units, dropped content
and hallucinations. These errors, which occur rarely and unpredictably in
Neural Machine Translation (NMT), greatly undermine the reliability of
state-of-the-art MT systems. Consequently, it is important to have visibility
into these problems during model development. Towards this direction, we
introduce SALTED, a specifications-based framework for behavioral testing of MT
models that provides fine-grained views of salient long-tail errors, permitting
trustworthy visibility into previously invisible problems. At the core of our
approach is the development of high-precision detectors that flag errors (or
alternatively, verify output correctness) between a source sentence and a
system output. We demonstrate that such detectors could be used not just to
identify salient long-tail errors in MT systems, but also for higher-recall
filtering of the training data, fixing targeted errors with model fine-tuning
in NMT and generating novel data for metamorphic testing to elicit further bugs
in models.</p>
  </details>
</details>
<details>
  <summary>25. <b>标题：KERPLE: Kernelized Relative Positional Embedding for Length  Extrapolation</b></summary>
  <p><b>编号</b>：[209]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09921</p>
  <p><b>作者</b>：Ta-Chung Chi,  Ting-Han Fan,  Peter J. Ramadge,  Alexander I. Rudnicky</p>
  <p><b>备注</b>：The first two authors contributed equally to this work</p>
  <p><b>关键词</b>：received considerable attention, RPEs effectively model, received considerable, considerable attention, effectively model</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Relative positional embeddings (RPE) have received considerable attention
since RPEs effectively model the relative distance among tokens and enable
length extrapolation. We propose KERPLE, a framework that generalizes relative
position embedding for extrapolation by kernelizing positional differences. We
achieve this goal using conditionally positive definite (CPD) kernels, a class
of functions known for generalizing distance metrics. To maintain the inner
product interpretation of self-attention, we show that a CPD kernel can be
transformed into a PD kernel by adding a constant offset. This offset is
implicitly absorbed in the Softmax normalization during self-attention. The
diversity of CPD kernels allows us to derive various RPEs that enable length
extrapolation in a principled way. Experiments demonstrate that the logarithmic
variant achieves excellent extrapolation performance on three large language
modeling datasets.</p>
  </details>
</details>
<details>
  <summary>26. <b>标题：Let the Model Decide its Curriculum for Multitask Learning</b></summary>
  <p><b>编号</b>：[214]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09898</p>
  <p><b>作者</b>：Neeraj Varshney,  Swaroop Mishra,  Chitta Baral</p>
  <p><b>备注</b>：NAACL 2022 Deep Learning for Low-Resource NLP Workshop</p>
  <p><b>关键词</b>：prior multi-task learning, human perception, strategies in prior, prior multi-task, exhaustively searching</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Curriculum learning strategies in prior multi-task learning approaches
arrange datasets in a difficulty hierarchy either based on human perception or
by exhaustively searching the optimal arrangement. However, human perception of
difficulty may not always correlate well with machine interpretation leading to
poor performance and exhaustive search is computationally expensive. Addressing
these concerns, we propose two classes of techniques to arrange training
instances into a learning curriculum based on difficulty scores computed via
model-based approaches. The two classes i.e Dataset-level and Instance-level
differ in granularity of arrangement. Through comprehensive experiments with 12
datasets, we show that instance-level and dataset-level techniques result in
strong representations as they lead to an average performance improvement of
4.17% and 3.15% over their respective baselines. Furthermore, we find that most
of this improvement comes from correctly answering the difficult instances,
implying a greater efficacy of our techniques on difficult tasks.</p>
  </details>
</details>
<details>
  <summary>27. <b>标题：Gender Bias in Meta-Embeddings</b></summary>
  <p><b>编号</b>：[230]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09867</p>
  <p><b>作者</b>：Masahiro Kaneko,  Danushka Bollegala,  Naoaki Okazaki</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：source embeddings, multiple source embeddings, source, embeddings, Combining multiple source</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Combining multiple source embeddings to create meta-embeddings is considered
effective to obtain more accurate embeddings. Different methods have been
proposed to develop meta-embeddings from a given set of source embeddings.
However, the source embeddings can contain unfair gender bias, and the bias in
the combination of multiple embeddings and debiasing it effectively have not
been studied yet. In this paper, we investigate the bias in three types of
meta-embeddings: (1) Multi-Source No-Debiasing: meta-embedding from multiple
source embeddings without any debiasing. The experimental results show that
meta-embedding amplifies the gender bias compared to those of input source
embeddings; (2) Multi-Source Single-Debiasing: meta-embedding from multiple
source embeddings debiased by a single method and it can be created in three
ways: debiasing each source embedding, debiasing the learned meta-embeddings,
and debiasing both source embeddings and meta-embeddings. The results show that
debiasing both is the best in two out of three bias evaluation benchmarks; (3)
Single-Source Multi-Debiasing: meta-embedding from the same source embedding
debiased by different methods. It performed more effectively than its source
embeddings debiased with a single method in all three bias evaluation
benchmarks.</p>
  </details>
</details>
<details>
  <summary>28. <b>标题：Table Retrieval May Not Necessitate Table-specific Model Design</b></summary>
  <p><b>编号</b>：[239]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09843</p>
  <p><b>作者</b>：Zhiruo Wang,  Zhengbao Jiang,  Eric Nyberg,  Graham Neubig</p>
  <p><b>备注</b>：11 pages total, 4 figures</p>
  <p><b>关键词</b>：machine readers alike, table retrieval, readers alike, providing answers, important form</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Tables are an important form of structured data for both human and machine
readers alike, providing answers to questions that cannot, or cannot easily, be
found in texts. Recent work has designed special models and training paradigms
for table-related tasks such as table-based question answering and table
retrieval. Though effective, they add complexity in both modeling and data
acquisition compared to generic text solutions and obscure which elements are
truly beneficial. In this work, we focus on the task of table retrieval, and
ask: "is table-specific model design necessary for table retrieval, or can a
simpler text-based model be effectively used to achieve a similar result?"
First, we perform an analysis on a table-based portion of the Natural Questions
dataset (NQ-table), and find that structure plays a negligible role in more
than 70% of the cases. Based on this, we experiment with a general Dense
Passage Retriever (DPR) based on text and a specialized Dense Table Retriever
(DTR) that uses table-specific model designs. We find that DPR performs well
without any table-specific design and training, and even achieves superior
results compared to DTR when fine-tuned on properly linearized tables. We then
experiment with three modules to explicitly encode table structures, namely
auxiliary row/column embeddings, hard attention masks, and soft relation-based
attention biases. However, none of these yielded significant improvements,
suggesting that table-specific model design may not be necessary for table
retrieval.</p>
  </details>
</details>
<details>
  <summary>29. <b>标题：A toolbox for idea generation and evaluation: Machine learning,  data-driven, and contest-driven approaches to support idea generation</b></summary>
  <p><b>编号</b>：[241]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09840</p>
  <p><b>作者</b>：Workneh Yilma Ayele</p>
  <p><b>备注</b>：ISBN 978-91-7911-790-0 ISBN 978-91-7911-791-7 ISSN 1101-8526</p>
  <p><b>关键词</b>：documents published online, growing digital data, digital data generated, scholarly literature, social media</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The significance and abundance of data are increasing due to the growing
digital data generated from social media, sensors, scholarly literature,
patents, different forms of documents published online, databases, product
manuals, etc. Various data sources can be used to generate ideas, yet, in
addition to bias, the size of the available digital data is a major challenge
when it comes to manual analysis. Hence, human-machine interaction is essential
for generating valuable ideas where machine learning and data-driven techniques
generate patterns from data and serve human sense-making. However, the use of
machine learning and data-driven approaches to generate ideas is a relatively
new area. Moreover, it is also possible to stimulate innovation using
contest-driven idea generation and evaluation. The results and contributions of
this thesis can be viewed as a toolbox of idea-generation techniques, including
a list of data-driven and machine learning techniques with corresponding data
sources and models to support idea generation. In addition, the results include
two models, one method and one framework, to better support data-driven and
contest- driven idea generation. The beneficiaries of these artefacts are
practitioners in data and knowledge engineering, data mining project managers,
and innovation agents. Innovation agents include incubators, contest
organizers, consultants, innovation accelerators, and industries. Since the
proposed artefacts consist of process models augmented with AI techniques,
human-centred AI is a promising area of research that can contribute to the
artefacts' further development and promote creativity.</p>
  </details>
</details>
<details>
  <summary>30. <b>标题：Summarization as Indirect Supervision for Relation Extraction</b></summary>
  <p><b>编号</b>：[244]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09837</p>
  <p><b>作者</b>：Keming Lu,  I-Hung Hsu,  Wenxuan Zhou,  Mingyu Derek Ma,  Muhao Chen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：expensive annotations, reliance on training, training data, data with expensive, Relation extraction</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Relation extraction (RE) models have been challenged by their reliance on
training data with expensive annotations. Considering that summarization tasks
aim at acquiring concise expressions of synoptical information from the longer
context, these tasks naturally align with the objective of RE, i.e., extracting
a kind of synoptical information that describes the relation of entity
mentions. We present SuRE, which converts RE into a summarization formulation.
SuRE leads to more precise and resource-efficient RE based on indirect
supervision from summarization tasks. To achieve this goal, we develop sentence
and relation conversion techniques that essentially bridge the formulation of
summarization and RE tasks. We also incorporate constraint decoding techniques
with Trie scoring to further enhance summarization-based RE with robust
inference. Experiments on three RE datasets demonstrate the effectiveness of
SuRE in both full-dataset and low-resource settings, showing that summarization
is a promising source of indirect supervision to improve RE models.</p>
  </details>
</details>
<details>
  <summary>31. <b>标题：Towards Understanding Gender-Seniority Compound Bias in Natural Language  Generation</b></summary>
  <p><b>编号</b>：[249]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09830</p>
  <p><b>作者</b>：Samhita Honnavalli,  Aesha Parekh,  Lily Ou,  Sophie Groenwold,  Sharon Levy,  Vicente Ordonez,  William Yang Wang</p>
  <p><b>备注</b>：6 pages, LREC 2022</p>
  <p><b>关键词</b>：male counterparts, job titles, gender bias, perceived as junior, bias</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Women are often perceived as junior to their male counterparts, even within
the same job titles. While there has been significant progress in the
evaluation of gender bias in natural language processing (NLP), existing
studies seldom investigate how biases toward gender groups change when
compounded with other societal biases. In this work, we investigate how
seniority impacts the degree of gender bias exhibited in pretrained neural
generation models by introducing a novel framework for probing compound bias.
We contribute a benchmark robustness-testing dataset spanning two domains, U.S.
senatorship and professorship, created using a distant-supervision method. Our
dataset includes human-written text with underlying ground truth and paired
counterfactuals. We then examine GPT-2 perplexity and the frequency of gendered
language in generated text. Our results show that GPT-2 amplifies bias by
considering women as junior and men as senior more often than the ground truth
in both domains. These results suggest that NLP applications built using GPT-2
may harm women in professional capacities.</p>
  </details>
</details>
<details>
  <summary>32. <b>标题：MiDAS: Multi-integrated Domain Adaptive Supervision for Fake News  Detection</b></summary>
  <p><b>编号</b>：[254]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09817</p>
  <p><b>作者</b>：Abhijit Suprem,  Calton Pu</p>
  <p><b>备注</b>：We use Lipschitz smoothness and probabilistic Lipschitzness to build a theoretical foundation for effective multi-domain adaptation using randomized perturbations on unseen data</p>
  <p><b>关键词</b>：fake, past few years, dramatically increased, related misinformation, fake news detection</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>COVID-19 related misinformation and fake news, coined an 'infodemic', has
dramatically increased over the past few years. This misinformation exhibits
concept drift, where the distribution of fake news changes over time, reducing
effectiveness of previously trained models for fake news detection. Given a set
of fake news models trained on multiple domains, we propose an adaptive
decision module to select the best-fit model for a new sample. We propose
MiDAS, a multi-domain adaptative approach for fake news detection that ranks
relevancy of existing models to new samples. MiDAS contains 2 components: a
doman-invariant encoder, and an adaptive model selector. MiDAS integrates
multiple pre-trained and fine-tuned models with their training data to create a
domain-invariant representation. Then, MiDAS uses local Lipschitz smoothness of
the invariant embedding space to estimate each model's relevance to a new
sample. Higher ranked models provide predictions, and lower ranked models
abstain. We evaluate MiDAS on generalization to drifted data with 9 fake news
datasets, each obtained from different domains and modalities. MiDAS achieves
new state-of-the-art performance on multi-domain adaptation for
out-of-distribution fake news classification.</p>
  </details>
</details>
<details>
  <summary>33. <b>标题：Towards a Holistic View on Argument Quality Prediction</b></summary>
  <p><b>编号</b>：[259]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09803</p>
  <p><b>作者</b>：Michael Fromm,  Max Berrendorf,  Johanna Reiml,  Isabelle Mayerhofer,  Siddharth Bhargava,  Evgeniy Faerman,  Thomas Seidl</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：society foundational pillars, receives increasing attention, advances in NLP, arguments receives increasing, foundational pillars</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Argumentation is one of society's foundational pillars, and, sparked by
advances in NLP and the vast availability of text data, automated mining of
arguments receives increasing attention. A decisive property of arguments is
their strength or quality. While there are works on the automated estimation of
argument strength, their scope is narrow: they focus on isolated datasets and
neglect the interactions with related argument mining tasks, such as argument
identification, evidence detection, or emotional appeal. In this work, we close
this gap by approaching argument quality estimation from multiple different
angles: Grounded on rich results from thorough empirical evaluations, we assess
the generalization capabilities of argument quality estimation across diverse
domains, the interplay with related argument mining tasks, and the impact of
emotions on perceived argument strength. We find that generalization depends on
a sufficient representation of different domains in the training part. In
zero-shot transfer and multi-task experiments, we reveal that argument quality
is among the more challenging tasks but can improve others. Finally, we show
that emotions play a minor role in argument quality than is often assumed.</p>
  </details>
</details>
<details>
  <summary>34. <b>标题：Local dynamic mode of Cognitive Behavioral Therapy</b></summary>
  <p><b>编号</b>：[272]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09752</p>
  <p><b>作者</b>：Victor Ardulov,  Torrey A. Creed,  David C. Atkins,  Shrikanth Narayanan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：increase mental health, mental health equity, order to increase, increase mental, important to increase</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In order to increase mental health equity among the most vulnerable and
marginalized communities, it is important to increase access to high-quality
therapists. One facet of addressing these needs, is to provide timely feedback
to clinicians as they interact with their clients, in a way that is also
contextualized to specific clients and interactions they have had. Dynamical
systems provide a framework through which to analyze interactions. The present
work applies these methods to the domain of automated psychotherapist
evaluation for Cognitive Behavioral Therapy (CBT). Our methods extract local
dynamic modes from short windows of conversation and learns to correlate the
observed dynamics to CBT competence. The results demonstrate the value of this
paradigm and outlines the way in which these methods can be used to study and
improve therapeutic strategies.</p>
  </details>
</details>
<h1>机器学习</h1>
<details>
  <summary>1. <b>标题：Lossless Acceleration for Seq2seq Generation with Aggressive Decoding</b></summary>
  <p><b>编号</b>：[2]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10350</p>
  <p><b>作者</b>：Tao Ge,  Heming Xia,  Xin Sun,  Si-Qing Chen,  Furu Wei</p>
  <p><b>备注</b>：24-page Microsoft Research Technical Report. Content overlap with arXiv:2106.04970 and arXiv:2203.16487</p>
  <p><b>关键词</b>：Aggressive Decoding, decoding, Aggressive, Input-guided Aggressive Decoding, Generalized Aggressive Decoding</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We study lossless acceleration for seq2seq generation with a novel decoding
algorithm -- Aggressive Decoding. Unlike the previous efforts (e.g.,
non-autoregressive decoding) speeding up seq2seq generation at the cost of
quality loss, our approach aims to yield the identical (or better) generation
compared with autoregressive decoding but in a significant speedup, achieved by
innovative cooperation of aggressive decoding and verification that are both
efficient due to parallel computing.
We propose two Aggressive Decoding paradigms for 2 kinds of seq2seq tasks: 1)
For the seq2seq tasks whose inputs and outputs are highly similar (e.g.,
Grammatical Error Correction), we propose Input-guided Aggressive Decoding
(IAD) that aggressively copies from the input sentence as drafted decoded
tokens to verify in parallel; 2) For other general seq2seq tasks (e.g., Machine
Translation), we propose Generalized Aggressive Decoding (GAD) that first
employs an additional non-autoregressive decoding model for aggressive decoding
and then verifies in parallel in the autoregressive manner.
We test Aggressive Decoding on the most popular 6-layer Transformer model on
GPU in multiple seq2seq tasks: 1) For IAD, we show that it can introduce a
7x-9x speedup for the Transformer in Grammatical Error Correction and Text
Simplification tasks with the identical results as greedy decoding; 2) For GAD,
we observe a 3x-5x speedup with the identical or even better quality in two
important seq2seq tasks: Machine Translation and Abstractive Summarization.
Moreover, Aggressive Decoding can benefit even more from stronger computing
devices that are better at parallel computing. Given the lossless quality as
well as significant and promising speedup, we believe Aggressive Decoding may
potentially evolve into a de facto standard for efficient and lossless seq2seq
generation in the near future.</p>
  </details>
</details>
<details>
  <summary>2. <b>标题：Diverse super-resolution with pretrained deep hiererarchical VAEs</b></summary>
  <p><b>编号</b>：[4]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10347</p>
  <p><b>作者</b>：Jean Prost,  Antoine Houdard,  Nicolas Papadakis,  Andrés Almansa</p>
  <p><b>备注</b>：21 pages , 5 figures</p>
  <p><b>关键词</b>：deep-learning based methods, VD-VAE latent space, deep-learning based, provide one single, latent</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Image super-resolution is a one-to-many problem, but most deep-learning based
methods only provide one single solution to this problem. In this work, we
tackle the problem of diverse super-resolution by reusing VD-VAE, a
state-of-the art variational autoencoder (VAE). We find that the hierarchical
latent representation learned by VD-VAE naturally separates the image
low-frequency information, encoded in the latent groups at the top of the
hierarchy, from the image high-frequency details, determined by the latent
groups at the bottom of the latent hierarchy. Starting from this observation,
we design a super-resolution model exploiting the specific structure of VD-VAE
latent space. Specifically, we train an encoder to encode low-resolution images
in the subset of VD-VAE latent space encoding the low-frequency information,
and we combine this encoder with VD-VAE generative model to sample diverse
super-resolved version of a low-resolution input. We demonstrate the ability of
our method to generate diverse solutions to the super-resolution problem on
face super-resolution with upsampling factors x4, x8, and x16.</p>
  </details>
</details>
<details>
  <summary>3. <b>标题：Towards Understanding Grokking: An Effective Theory of Representation  Learning</b></summary>
  <p><b>编号</b>：[5]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10343</p>
  <p><b>作者</b>：Ziming Liu,  Ouail Kitouni,  Niklas Nolte,  Eric J. Michaud,  Max Tegmark,  Mike Williams</p>
  <p><b>备注</b>：20 pages, 16 figures</p>
  <p><b>关键词</b>：models generalize long, aim to understand, phenomenon where models, models generalize, generalize long</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We aim to understand grokking, a phenomenon where models generalize long
after overfitting their training set. We present both a microscopic analysis
anchored by an effective theory and a macroscopic analysis of phase diagrams
describing learning performance across hyperparameters. We find that
generalization originates from structured representations whose training
dynamics and dependence on training set size can be predicted by our effective
theory in a toy setting. We observe empirically the presence of four learning
phases: comprehension, grokking, memorization, and confusion. We find
representation learning to occur only in a "Goldilocks zone" (including
comprehension and grokking) between memorization and confusion. Compared to the
comprehension phase, the grokking phase stays closer to the memorization phase,
leading to delayed generalization. The Goldilocks phase is reminiscent of
"intelligence from starvation" in Darwinian evolution, where resource
limitations drive discovery of more efficient solutions. This study not only
provides intuitive explanations of the origin of grokking, but also highlights
the usefulness of physics-inspired tools, e.g., effective theories and phase
diagrams, for understanding deep learning.</p>
  </details>
</details>
<details>
  <summary>4. <b>标题：A Review of Safe Reinforcement Learning: Methods, Theory and  Applications</b></summary>
  <p><b>编号</b>：[9]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10330</p>
  <p><b>作者</b>：Shangding Gu,  Long Yang,  Yali Du,  Guang Chen,  Florian Walter,  Jun Wang,  Yaodong Yang,  Alois Knoll</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：decision making tasks, achieved tremendous success, complex decision making, safe reinforcement learning, safe</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Reinforcement learning has achieved tremendous success in many complex
decision making tasks. When it comes to deploying RL in the real world, safety
concerns are usually raised, leading to a growing demand for safe reinforcement
learning algorithms, such as in autonomous driving and robotics scenarios.
While safety control has a long history, the study of safe RL algorithms is
still in the early stages. To establish a good foundation for future research
in this thread, in this paper, we provide a review for safe RL from the
perspectives of methods, theory and applications. Firstly, we review the
progress of safe RL from five dimensions and come up with five problems that
are crucial for safe RL being deployed in real-world applications, coined as
"2H3W". Secondly, we analyze the theory and algorithm progress from the
perspectives of answering the "2H3W" problems. Then, the sample complexity of
safe RL methods is reviewed and discussed, followed by an introduction of the
applications and benchmarks of safe RL algorithms. Finally, we open the
discussion of the challenging problems in safe RL, hoping to inspire more
future research on this thread.
To advance the study of safe RL algorithms, we release a benchmark suite, an
open-sourced repository containing the implementations of major safe RL
algorithms, along with tutorials at the link:
this https URL.</p>
  </details>
</details>
<details>
  <summary>5. <b>标题：Classifying Human Activities using Machine Learning and Deep Learning  Techniques</b></summary>
  <p><b>编号</b>：[11]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10325</p>
  <p><b>作者</b>：Sanku Satya Uday,  Satti Thanuja Pavani,  T.Jaya Lakshmi,  Rohit Chivukula</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：recognize human actions, Gated Recurrent Unit, Deep Learning, Machine Learning, ability to recognize</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Human Activity Recognition (HAR) describes the machines ability to recognize
human actions. Nowadays, most people on earth are health conscious, so people
are more interested in tracking their daily activities using Smartphones or
Smart Watches, which can help them manage their daily routines in a healthy
way. With this objective, Kaggle has conducted a competition to classify 6
different human activities distinctly based on the inertial signals obtained
from 30 volunteers smartphones. The main challenge in HAR is to overcome the
difficulties of separating human activities based on the given data such that
no two activities overlap. In this experimentation, first, Data visualization
is done on expert generated features with the help of t distributed Stochastic
Neighborhood Embedding followed by applying various Machine Learning techniques
like Logistic Regression, Linear SVC, Kernel SVM, Decision trees to better
classify the 6 distinct human activities. Moreover, Deep Learning techniques
like Long Short-Term Memory (LSTM), Bi-Directional LSTM, Recurrent Neural
Network (RNN), and Gated Recurrent Unit (GRU) are trained using raw time series
data. Finally, metrics like Accuracy, Confusion matrix, precision and recall
are used to evaluate the performance of the Machine Learning and Deep Learning
models. Experiment results proved that the Linear Support Vector Classifier in
machine learning and Gated Recurrent Unit in Deep Learning provided better
accuracy for human activity recognition compared to other classifiers.</p>
  </details>
</details>
<details>
  <summary>6. <b>标题：Nothing makes sense in deep learning, except in the light of evolution</b></summary>
  <p><b>编号</b>：[12]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10320</p>
  <p><b>作者</b>：Artem Kaznatcheev,  Konrad Paul Kording</p>
  <p><b>备注</b>：11 pages, 2 figures, 1 table</p>
  <p><b>关键词</b>：surprisingly successful branch, Deep Learning, machine learning, surprisingly successful, successful branch</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep Learning (DL) is a surprisingly successful branch of machine learning.
The success of DL is usually explained by focusing analysis on a particular
recent algorithm and its traits. Instead, we propose that an explanation of the
success of DL must look at the population of all algorithms in the field and
how they have evolved over time. We argue that cultural evolution is a useful
framework to explain the success of DL. In analogy to biology, we use
`development' to mean the process converting the pseudocode or text description
of an algorithm into a fully trained model. This includes writing the
programming code, compiling and running the program, and training the model. If
all parts of the process don't align well then the resultant model will be
useless (if the code runs at all!). This is a constraint. A core component of
evolutionary developmental biology is the concept of deconstraints -- these are
modification to the developmental process that avoid complete failure by
automatically accommodating changes in other components. We suggest that many
important innovations in DL, from neural networks themselves to hyperparameter
optimization and AutoGrad, can be seen as developmental deconstraints. These
deconstraints can be very helpful to both the particular algorithm in how it
handles challenges in implementation and the overall field of DL in how easy it
is for new ideas to be generated. We highlight how our perspective can both
advance DL and lead to new insights for evolutionary biology.</p>
  </details>
</details>
<details>
  <summary>7. <b>标题：Seeking entropy: complex behavior from intrinsic motivation to occupy  action-state path space</b></summary>
  <p><b>编号</b>：[13]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10316</p>
  <p><b>作者</b>：Jorge Ramírez-Ruiz,  Dmytro Grytskyy,  Rubén Moreno-Bote</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Intrinsic motivation generates, motivation generates behaviors, Intrinsic motivation, exploration and learning, motivation generates</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Intrinsic motivation generates behaviors that do not necessarily lead to
immediate reward, but help exploration and learning. Here we show that agents
having the sole goal of maximizing occupancy of future actions and states, that
is, moving and exploring on the long term, are capable of complex behavior
without any reference to external rewards. We find that action-state path
entropy is the only measure consistent with additivity and other intuitive
properties of expected future action-state path occupancy. We provide
analytical expressions that relate the optimal policy with the optimal
state-value function, from where we prove uniqueness of the solution of the
associated Bellman equation and convergence of our algorithm to the optimal
state-value function. Using discrete and continuous state tasks, we show that
`dancing', hide-and-seek and a basic form of altruistic behavior naturally
result from entropy seeking without external rewards. Intrinsically motivated
agents can objectively determine what states constitute rewards, exploiting
them to ultimately maximize action-state path entropy.</p>
  </details>
</details>
<details>
  <summary>8. <b>标题：ClusterEA: Scalable Entity Alignment with Stochastic Training and  Normalized Mini-batch Similarities</b></summary>
  <p><b>编号</b>：[14]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10312</p>
  <p><b>作者</b>：Yunjun Gao,  Xiaoze Liu,  Junyang Wu,  Tianyi Li,  Pengfei Wang,  Lu Chen</p>
  <p><b>备注</b>：Accepted by ACM SIGKDD 2022 Research Track</p>
  <p><b>关键词</b>：aims at finding, knowledge graphs, finding equivalent entities, Entity alignment, finding equivalent</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Entity alignment (EA) aims at finding equivalent entities in different
knowledge graphs (KGs). Embedding-based approaches have dominated the EA task
in recent years. Those methods face problems that come from the geometric
properties of embedding vectors, including hubness and isolation. To solve
these geometric problems, many normalization approaches have been adopted to
EA. However, the increasing scale of KGs renders it is hard for EA models to
adopt the normalization processes, thus limiting their usage in real-world
applications. To tackle this challenge, we present ClusterEA, a general
framework that is capable of scaling up EA models and enhancing their results
by leveraging normalization methods on mini-batches with a high entity
equivalent rate. ClusterEA contains three components to align entities between
large-scale KGs, including stochastic training, ClusterSampler, and
SparseFusion. It first trains a large-scale Siamese GNN for EA in a stochastic
fashion to produce entity embeddings. Based on the embeddings, a novel
ClusterSampler strategy is proposed for sampling highly overlapped
mini-batches. Finally, ClusterEA incorporates SparseFusion, which normalizes
local and global similarity and then fuses all similarity matrices to obtain
the final similarity matrix. Extensive experiments with real-life datasets on
EA benchmarks offer insight into the proposed framework, and suggest that it is
capable of outperforming the state-of-the-art scalable EA framework by up to 8
times in terms of Hits@1.</p>
  </details>
</details>
<details>
  <summary>9. <b>标题：Delator: Automatic Detection of Money Laundering Evidence on Transaction  Graphs via Neural Networks</b></summary>
  <p><b>编号</b>：[20]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10293</p>
  <p><b>作者</b>：Henrique S. Assumpção,  Fabrício Souza,  Leandro Lacerda Campos,  Vinícius T. de Castro Pires,  Paulo M. Laurentys de Almeida,  Fabricio Murai</p>
  <p><b>备注</b>：in Portuguese language. Accepted for publication in the 11th Brazilian Workshop on Social Network Analysis and Mining (BraSNAM)</p>
  <p><b>关键词</b>：massive financial losses, criminal activities today, relevant criminal activities, money laundering activities, detect money laundering</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Money laundering is one of the most relevant criminal activities today, due
to its potential to cause massive financial losses to governments, banks, etc.
We propose DELATOR, a new CAAT (computer-assisted audit technology) to detect
money laundering activities based on neural network models that encode bank
transfers as a large-scale temporal graph. In collaboration with a Brazilian
bank, we design and apply an evaluation strategy to quantify DELATOR's
performance on historic data comprising millions of clients. DELATOR
outperforms an off-the-shelf solution from Amazon AWS by 18.9% with respect to
AUC. We conducted real experiments that led to discovery of 8 new suspicious
among 100 analyzed cases, which would have been reported to the authorities
under the current criteria.</p>
  </details>
</details>
<details>
  <summary>10. <b>标题：On the SDEs and Scaling Rules for Adaptive Gradient Algorithms</b></summary>
  <p><b>编号</b>：[23]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10287</p>
  <p><b>作者</b>：Sadhika Malladi,  Kaifeng Lyu,  Abhishek Panigrahi,  Sanjeev Arora</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Stochastic Gradient Descent, Approximating Stochastic Gradient, Stochastic Differential, Approximating Stochastic, Gradient Descent</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Approximating Stochastic Gradient Descent (SGD) as a Stochastic Differential
Equation (SDE) has allowed researchers to enjoy the benefits of studying a
continuous optimization trajectory while carefully preserving the stochasticity
of SGD. Analogous study of adaptive gradient methods, such as RMSprop and Adam,
has been challenging because there were no rigorously proven SDE approximations
for these methods. This paper derives the SDE approximations for RMSprop and
Adam, giving theoretical guarantees of their correctness as well as
experimental validation of their applicability to common large-scaling vision
and language settings. A key practical result is the derivation of a
$\textit{square root scaling rule}$ to adjust the optimization hyperparameters
of RMSprop and Adam when changing batch size, and its empirical validation in
deep learning settings.</p>
  </details>
</details>
<details>
  <summary>11. <b>标题：Heterformer: A Transformer Architecture for Node Representation Learning  on Heterogeneous Text-Rich Networks</b></summary>
  <p><b>编号</b>：[24]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10282</p>
  <p><b>作者</b>：Bowen Jin,  Yu Zhang,  Qi Zhu,  Jiawei Han</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：heterogeneous text-rich networks, study node representation, node representation learning, heterogeneous text-rich, representation learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We study node representation learning on heterogeneous text-rich networks,
where nodes and edges are multi-typed and some types of nodes are associated
with text information. Although recent studies on graph neural networks (GNNs)
and pretrained language models (PLMs) have demonstrated their power in encoding
network and text signals, respectively, less focus has been given to delicately
coupling these two types of models on heterogeneous text-rich networks.
Specifically, existing GNNs rarely model text in each node in a contextualized
way; existing PLMs can hardly be applied to characterize graph structures due
to their sequence architecture. In this paper, we propose Heterformer, a
Heterogeneous GNN-nested transformer that blends GNNs and PLMs into a unified
model. Different from previous "cascaded architectures" that directly add GNN
layers upon a PLM, our Heterformer alternately stacks two modules - a
graph-attention-based neighbor aggregation module and a transformer-based text
and neighbor joint encoding module - to facilitate thorough mutual enhancement
between network and text signals. Meanwhile, Heterformer is capable of
characterizing network heterogeneity and nodes without text information.
Comprehensive experiments on three large-scale datasets from different domains
demonstrate the superiority of Heterformer over state-of-the-art baselines in
link prediction, transductive/inductive node classification, node clustering,
and semantics-based retrieval.</p>
  </details>
</details>
<details>
  <summary>12. <b>标题：Pre-Train Your Loss: Easy Bayesian Transfer Learning with Informative  Priors</b></summary>
  <p><b>编号</b>：[25]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10279</p>
  <p><b>作者</b>：Ravid Shwartz-Ziv,  Micah Goldblum,  Hossein Souri,  Sanyam Kapoor,  Chen Zhu,  Yann LeCun,  Andrew Gordon Wilson</p>
  <p><b>备注</b>：Code available at this https URL</p>
  <p><b>关键词</b>：large foundation models, source task, transfer learning paradigm, increasingly moving, paradigm whereby large</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep learning is increasingly moving towards a transfer learning paradigm
whereby large foundation models are fine-tuned on downstream tasks, starting
from an initialization learned on the source task. But an initialization
contains relatively little information about the source task. Instead, we show
that we can learn highly informative posteriors from the source task, through
supervised or self-supervised approaches, which then serve as the basis for
priors that modify the whole loss surface on the downstream task. This simple
modular approach enables significant performance gains and more data-efficient
learning on a variety of downstream classification and segmentation tasks,
serving as a drop-in replacement for standard pre-training strategies. These
highly informative priors also can be saved for future use, similar to
pre-trained weights, and stand in contrast to the zero-mean isotropic
uninformative priors that are typically used in Bayesian deep learning.</p>
  </details>
</details>
<details>
  <summary>13. <b>标题：DEMAND: Deep Matrix Approximately NonlinearDecomposition to Identify  Meta, Canonical, and Sub-Spatial Pattern of functional Magnetic Resonance  Imaging in the Human Brain</b></summary>
  <p><b>编号</b>：[32]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10264</p>
  <p><b>作者</b>：Wei Zhang,  Yu Bao</p>
  <p><b>备注</b>：10 pages, 6 figures, an advanced deep nonlinear matrix factorization technique</p>
  <p><b>关键词</b>：Deep Neural Networks, crucial computational approach, Magnetic Resonance Signals, Neural Networks, spatial patterns</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep Neural Networks (DNNs) have already become a crucial computational
approach to revealing the spatial patterns in the human brain; however, there
are three major shortcomings in utilizing DNNs to detect the spatial patterns
in functional Magnetic Resonance Signals: 1). It is a fully connected
architecture that increases the complexity of network structures that is
difficult to optimize and vulnerable to overfitting; 2). The requirement of
large training samples results in erasing the individual/minor patterns in
feature extraction; 3). The hyperparameters are required to be tuned manually,
which is time-consuming. Therefore, we propose a novel deep nonlinear matrix
factorization named Deep Matrix Approximately Nonlinear Decomposition (DEMAND)
in this work to take advantage of the shallow linear model, e.g., Sparse
Dictionary Learning (SDL) and DNNs. At first, the proposed DEMAND employs a
non-fully connected and multilayer-stacked architecture that is easier to be
optimized compared with canonical DNNs; furthermore, due to the efficient
architecture, training DEMAND can avoid overfitting and enables the recognition
of individual/minor features based on a small dataset such as an individual
data; finally, a novel rank estimator technique is introduced to tune all
hyperparameters of DEMAND automatically. Moreover, the proposed DEMAND is
validated by four other peer methodologies via real functional Magnetic
Resonance Imaging data in the human brain. In short, the validation results
demonstrate that DEMAND can reveal the reproducible meta, canonical, and
sub-spatial features of the human brain more efficiently than other peer
methodologies.</p>
  </details>
</details>
<details>
  <summary>14. <b>标题：Explanatory machine learning for sequential human teaching</b></summary>
  <p><b>编号</b>：[37]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10250</p>
  <p><b>作者</b>：Lun Ai,  Johannes Langer,  Stephen H. Muggleton,  Ute Schmid</p>
  <p><b>备注</b>：Submitted to the International Joint Conference on Learning & Reasoning (IJCLR) 2022</p>
  <p><b>关键词</b>：drawn increasing attention, recently drawn increasing, human comprehension, Logic Programming, Inductive Logic Programming</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The topic of comprehensibility of machine-learned theories has recently drawn
increasing attention. Inductive Logic Programming (ILP) uses logic programming
to derive logic theories from small data based on abduction and induction
techniques. Learned theories are represented in the form of rules as
declarative descriptions of obtained knowledge. In earlier work, the authors
provided the first evidence of a measurable increase in human comprehension
based on machine-learned logic rules for simple classification tasks. In a
later study, it was found that the presentation of machine-learned explanations
to humans can produce both beneficial and harmful effects in the context of
game learning. We continue our investigation of comprehensibility by examining
the effects of the ordering of concept presentations on human comprehension. In
this work, we examine the explanatory effects of curriculum order and the
presence of machine-learned explanations for sequential problem-solving. We
show that 1) there exist tasks A and B such that learning A before B has a
better human comprehension with respect to learning B before A and 2) there
exist tasks A and B such that the presence of explanations when learning A
contributes to improved human comprehension when subsequently learning B. We
propose a framework for the effects of sequential teaching on comprehension
based on an existing definition of comprehensibility and provide evidence for
support from data collected in human trials. Empirical results show that
sequential teaching of concepts with increasing complexity a) has a beneficial
effect on human comprehension and b) leads to human re-discovery of
divide-and-conquer problem-solving strategies, and c) studying machine-learned
explanations allows adaptations of human problem-solving strategy with better
performance.</p>
  </details>
</details>
<details>
  <summary>15. <b>标题：SADAM: Stochastic Adam, A Stochastic Operator for First-Order  Gradient-based Optimizer</b></summary>
  <p><b>编号</b>：[39]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10247</p>
  <p><b>作者</b>：Wei Zhang,  Yu Bao</p>
  <p><b>备注</b>：9 pages, 4 figures, an advanced first-order optimizer</p>
  <p><b>关键词</b>：reduce time consumption, gradient descent algorithm, first-order gradient descent, stochastic strategy performed, target accuracy</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this work, to efficiently help escape the stationary and saddle points, we
propose, analyze, and generalize a stochastic strategy performed as an operator
for a first-order gradient descent algorithm in order to increase the target
accuracy and reduce time consumption. Unlike existing algorithms, the proposed
stochastic the strategy does not require any batches and sampling techniques,
enabling efficient implementation and maintaining the initial first-order
optimizer's convergence rate, but provides an incomparable improvement of
target accuracy when optimizing the target functions. In short, the proposed
strategy is generalized, applied to Adam, and validated via the decomposition
of biomedical signals using Deep Matrix Fitting and another four peer
optimizers. The validation results show that the proposed random strategy can
be easily generalized for first-order optimizers and efficiently improve the
target accuracy.</p>
  </details>
</details>
<details>
  <summary>16. <b>标题：EXODUS: Stable and Efficient Training of Spiking Neural Networks</b></summary>
  <p><b>编号</b>：[40]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10242</p>
  <p><b>作者</b>：Felix Christian Bauer (1),  Gregor Lenz (1),  Saeid Haghighatshoar (1),  Sadique Sheik (1) ((1) SynSense)</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Spiking Neural Networks, gaining significant traction, Spiking Neural, Neural Networks, machine learning tasks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Spiking Neural Networks (SNNs) are gaining significant traction in machine
learning tasks where energy-efficiency is of utmost importance. Training such
networks using the state-of-the-art back-propagation through time (BPTT) is,
however, very time-consuming. Previous work by Shrestha and Orchard [2018]
employs an efficient GPU-accelerated back-propagation algorithm called SLAYER,
which speeds up training considerably. SLAYER, however, does not take into
account the neuron reset mechanism while computing the gradients, which we
argue to be the source of numerical instability. To counteract this, SLAYER
introduces a gradient scale hyperparameter across layers, which needs manual
tuning. In this paper, (i) we modify SLAYER and design an algorithm called
EXODUS, that accounts for the neuron reset mechanism and applies the Implicit
Function Theorem (IFT) to calculate the correct gradients (equivalent to those
computed by BPTT), (ii) we eliminate the need for ad-hoc scaling of gradients,
thus, reducing the training complexity tremendously, (iii) we demonstrate, via
computer simulations, that EXODUS is numerically stable and achieves a
comparable or better performance than SLAYER especially in various tasks with
SNNs that rely on temporal features. Our code is available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>17. <b>标题：Visualizing and Explaining Language Models</b></summary>
  <p><b>编号</b>：[43]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10238</p>
  <p><b>作者</b>：Adrian M.P. Braşoveanu,  Răzvan Andonie</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Natural Language Processing, Natural Language, Language Processing, Deep Learning, Artificial Intelligence</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>During the last decade, Natural Language Processing has become, after
Computer Vision, the second field of Artificial Intelligence that was massively
changed by the advent of Deep Learning. Regardless of the architecture, the
language models of the day need to be able to process or generate text, as well
as predict missing words, sentences or relations depending on the task. Due to
their black-box nature, such models are difficult to interpret and explain to
third parties. Visualization is often the bridge that language model designers
use to explain their work, as the coloring of the salient words and phrases,
clustering or neuron activations can be used to quickly understand the
underlying models. This paper showcases the techniques used in some of the most
popular Deep Learning for NLP visualizations, with a special focus on
interpretability and explainability.</p>
  </details>
</details>
<details>
  <summary>18. <b>标题：Federated learning for violence incident prediction in a simulated  cross-institutional psychiatric setting</b></summary>
  <p><b>编号</b>：[47]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10234</p>
  <p><b>作者</b>：Thomas Borger,  Pablo Mosteiro,  Heysem Kaya,  Emil Rijcken,  Albert Ali Salah,  Floortje Scheepers,  Marco Spruit</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Federated Learning, learning, Federated, machine learning models, common and severe</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Inpatient violence is a common and severe problem within psychiatry. Knowing
who might become violent can influence staffing levels and mitigate severity.
Predictive machine learning models can assess each patient's likelihood of
becoming violent based on clinical notes. Yet, while machine learning models
benefit from having more data, data availability is limited as hospitals
typically do not share their data for privacy preservation. Federated Learning
(FL) can overcome the problem of data limitation by training models in a
decentralised manner, without disclosing data between collaborators. However,
although several FL approaches exist, none of these train Natural Language
Processing models on clinical notes. In this work, we investigate the
application of Federated Learning to clinical Natural Language Processing,
applied to the task of Violence Risk Assessment by simulating a
cross-institutional psychiatric setting. We train and compare four models: two
local models, a federated model and a data-centralised model. Our results
indicate that the federated model outperforms the local models and has similar
performance as the data-centralised model. These findings suggest that
Federated Learning can be used successfully in a cross-institutional setting
and is a step towards new applications of Federated Learning based on clinical
notes</p>
  </details>
</details>
<details>
  <summary>19. <b>标题：Exploring the Trade-off between Plausibility, Change Intensity and  Adversarial Power in Counterfactual Explanations using Multi-objective  Optimization</b></summary>
  <p><b>编号</b>：[49]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10232</p>
  <p><b>作者</b>：Javier Del Ser,  Alejandro Barredo-Arrieta,  Natalia Díaz-Rodríguez,  Francisco Herrera,  Andreas Holzinger</p>
  <p><b>备注</b>：52 pages, 14 figures, under review</p>
  <p><b>关键词</b>：deep learning models, involving complex data, tasks involving complex, broad consensus, importance of deep</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>There is a broad consensus on the importance of deep learning models in tasks
involving complex data. Often, an adequate understanding of these models is
required when focusing on the transparency of decisions in human-critical
applications. Besides other explainability techniques, trustworthiness can be
achieved by using counterfactuals, like the way a human becomes familiar with
an unknown process: by understanding the hypothetical circumstances under which
the output changes. In this work we argue that automated counterfactual
generation should regard several aspects of the produced adversarial instances,
not only their adversarial capability. To this end, we present a novel
framework for the generation of counterfactual examples which formulates its
goal as a multi-objective optimization problem balancing three different
objectives: 1) plausibility, i.e., the likeliness of the counterfactual of
being possible as per the distribution of the input data; 2) intensity of the
changes to the original input; and 3) adversarial power, namely, the
variability of the model's output induced by the counterfactual. The framework
departs from a target model to be audited and uses a Generative Adversarial
Network to model the distribution of input data, together with a
multi-objective solver for the discovery of counterfactuals balancing among
these objectives. The utility of the framework is showcased over six
classification tasks comprising image and three-dimensional data. The
experiments verify that the framework unveils counterfactuals that comply with
intuition, increasing the trustworthiness of the user, and leading to further
insights, such as the detection of bias and data misrepresentation.</p>
  </details>
</details>
<details>
  <summary>20. <b>标题：You Don't Know My Favorite Color: Preventing Dialogue Representations  from Revealing Speakers' Private Personas</b></summary>
  <p><b>编号</b>：[51]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10228</p>
  <p><b>作者</b>：Haoran Li,  Yangqiu Song,  Lixin Fan</p>
  <p><b>备注</b>：Conference paper accepted by NAACL 2022</p>
  <p><b>关键词</b>：pretrained language models, evolve rapidly, large pretrained language, large language models, large pretrained</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Social chatbots, also known as chit-chat chatbots, evolve rapidly with large
pretrained language models. Despite the huge progress, privacy concerns have
arisen recently: training data of large language models can be extracted via
model inversion attacks. On the other hand, the datasets used for training
chatbots contain many private conversations between two individuals. In this
work, we further investigate the privacy leakage of the hidden states of
chatbots trained by language modeling which has not been well studied yet. We
show that speakers' personas can be inferred through a simple neural network
with high accuracy. To this end, we propose effective defense objectives to
protect persona leakage from hidden states. We conduct extensive experiments to
demonstrate that our proposed defense objectives can greatly reduce the attack
accuracy from 37.6% to 0.5%. Meanwhile, the proposed objectives preserve
language models' powerful generation ability.</p>
  </details>
</details>
<details>
  <summary>21. <b>标题：Do Transformer Models Show Similar Attention Patterns to Task-Specific  Human Gaze?</b></summary>
  <p><b>编号</b>：[53]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10226</p>
  <p><b>作者</b>：Stephanie Brandl,  Oliver Eberle,  Jonas Pilot,  Anders Søgaard</p>
  <p><b>备注</b>：Accepted to ACL 2022</p>
  <p><b>关键词</b>：NLP models, Learned self-attention functions, NLP, human, Learned self-attention</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Learned self-attention functions in state-of-the-art NLP models often
correlate with human attention. We investigate whether self-attention in
large-scale pre-trained language models is as predictive of human eye fixation
patterns during task-reading as classical cognitive models of human attention.
We compare attention functions across two task-specific reading datasets for
sentiment analysis and relation extraction. We find the predictiveness of
large-scale pre-trained self-attention for human attention depends on `what is
in the tail', e.g., the syntactic nature of rare contexts. Further, we observe
that task-specific fine-tuning does not increase the correlation with human
task-specific reading. Through an input reduction experiment we give
complementary insights on the sparsity and fidelity trade-off, showing that
lower-entropy attention vectors are more faithful.</p>
  </details>
</details>
<details>
  <summary>22. <b>标题：Mosaic Zonotope Shadow Matching for Risk-Aware Autonomous Localization  in Harsh Urban Environments</b></summary>
  <p><b>编号</b>：[55]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10223</p>
  <p><b>作者</b>：Daniel Neamati,  Sriramya Bhamidipati,  Grace Gao</p>
  <p><b>备注</b>：Submitted to AIJ Special Issue on Risk-Aware Autonomous Systems: Theory and Practice</p>
  <p><b>关键词</b>：Global Navigation Satellite, Global Navigation, Navigation Satellite System, GNSS shadow matching, shadow matching</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Risk-aware urban localization with the Global Navigation Satellite System
(GNSS) remains an unsolved problem with frequent misdetection of the user's
street or side of the street. Significant advances in 3D map-aided GNSS use
grid-based GNSS shadow matching alongside AI-driven line-of-sight (LOS)
classifiers and server-based processing to improve localization accuracy,
especially in the cross-street direction. Our prior work introduces a new
paradigm for shadow matching that proposes set-valued localization with
computationally efficient zonotope set representations. While existing
literature improved accuracy and efficiency, the current state of shadow
matching theory does not address the needs of risk-aware autonomous systems. We
extend our prior work to propose Mosaic Zonotope Shadow Matching (MZSM) that
employs a classifier-agnostic polytope mosaic architecture to provide
risk-awareness and certifiable guarantees on urban positioning. We formulate a
recursively expanding binary tree that refines an initial location estimate
with set operations into smaller polytopes. Together, the smaller polytopes
form a mosaic. We weight the tree branches with the probability that the user
is in line of sight of the satellite and expand the tree with each new
satellite observation. Our method yields an exact shadow matching distribution
from which we guarantee uncertainty bounds on the user localization. We perform
high-fidelity simulations using a 3D building map of San Francisco to validate
our algorithm's risk-aware improvements. We demonstrate that MZSM provides
certifiable guarantees across varied data-driven LOS classifier accuracies and
yields a more precise understanding of the uncertainty over existing methods.
We validate that our tree-based construction is efficient and tractable,
computing a mosaic from 14 satellites in 0.63 seconds and growing quadratically
in the satellite number.</p>
  </details>
</details>
<details>
  <summary>23. <b>标题：Learning Task-relevant Representations for Generalization via  Characteristic Functions of Reward Sequence Distributions</b></summary>
  <p><b>编号</b>：[57]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10218</p>
  <p><b>作者</b>：Rui Yang,  Jie Wang,  Zijie Geng,  Mingxuan Ye,  Shuiwang Ji,  Bin Li,  Feng Wu</p>
  <p><b>备注</b>：Accepted to KDD'22</p>
  <p><b>关键词</b>：visual reinforcement learning, critical for successful, successful applications, visual distractions, real scenarios</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Generalization across different environments with the same tasks is critical
for successful applications of visual reinforcement learning (RL) in real
scenarios. However, visual distractions -- which are common in real scenes --
from high-dimensional observations can be hurtful to the learned
representations in visual RL, thus degrading the performance of generalization.
To tackle this problem, we propose a novel approach, namely Characteristic
Reward Sequence Prediction (CRESP), to extract the task-relevant information by
learning reward sequence distributions (RSDs), as the reward signals are
task-relevant in RL and invariant to visual distractions. Specifically, to
effectively capture the task-relevant information via RSDs, CRESP introduces an
auxiliary task -- that is, predicting the characteristic functions of RSDs --
to learn task-relevant representations, because we can well approximate the
high-dimensional distributions by leveraging the corresponding characteristic
functions. Experiments demonstrate that CRESP significantly improves the
performance of generalization on unseen environments, outperforming several
state-of-the-arts on DeepMind Control tasks with different visual distractions.</p>
  </details>
</details>
<details>
  <summary>24. <b>标题：Test-time Batch Normalization</b></summary>
  <p><b>编号</b>：[58]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10210</p>
  <p><b>作者</b>：Tao Yang,  Shenglong Zhou,  Yuwang Wang,  Yan Lu,  Nanning Zheng</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Deep neural networks, data distribution shift, distribution shift, Deep neural, alleviating distribution shift</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep neural networks often suffer the data distribution shift between
training and testing, and the batch statistics are observed to reflect the
shift. In this paper, targeting of alleviating distribution shift in test time,
we revisit the batch normalization (BN) in the training process and reveals two
key insights benefiting test-time optimization: $(i)$ preserving the same
gradient backpropagation form as training, and $(ii)$ using dataset-level
statistics for robust optimization and inference. Based on the two insights, we
propose a novel test-time BN layer design, GpreBN, which is optimized during
testing by minimizing Entropy loss. We verify the effectiveness of our method
on two typical settings with distribution shift, i.e., domain generalization
and robustness tasks. Our GpreBN significantly improves the test-time
performance and achieves the state of the art results.</p>
  </details>
</details>
<details>
  <summary>25. <b>标题：How to Guide Adaptive Depth Sampling?</b></summary>
  <p><b>编号</b>：[62]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10202</p>
  <p><b>作者</b>：Ilya Tcenov,  Guy Gilboa</p>
  <p><b>备注</b>：8 pages</p>
  <p><b>关键词</b>：fixed mechanical rotations, fast electronic maneuvering, depth sensing technologies, laser beam, mechanical rotations</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent advances in depth sensing technologies allow fast electronic
maneuvering of the laser beam, as opposed to fixed mechanical rotations. This
will enable future sensors, in principle, to vary in real-time the sampling
pattern. We examine here the abstract problem of whether adapting the sampling
pattern for a given frame can reduce the reconstruction error or allow a
sparser pattern. We propose a constructive generic method to guide adaptive
depth sampling algorithms.
Given a sampling budget B, a depth predictor P and a desired quality measure
M, we propose an Importance Map that highlights important sampling locations.
This map is defined for a given frame as the per-pixel expected value of M
produced by the predictor P, given a pattern of B random samples. This map can
be well estimated in a training phase. We show that a neural network can learn
to produce a highly faithful Importance Map, given an RGB image. We then
suggest an algorithm to produce a sampling pattern for the scene, which is
denser in regions that are harder to reconstruct. The sampling strategy of our
modular framework can be adjusted according to hardware limitations, type of
depth predictor, and any custom reconstruction error measure that should be
minimized. We validate through simulations that our approach outperforms grid
and random sampling patterns as well as recent state-of-the-art adaptive
algorithms.</p>
  </details>
</details>
<details>
  <summary>26. <b>标题：A Proximal Algorithm for Sampling from Non-convex Potentials</b></summary>
  <p><b>编号</b>：[69]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10188</p>
  <p><b>作者</b>：Jiaming Liang,  Yongxin Chen</p>
  <p><b>备注</b>：21 pages</p>
  <p><b>关键词</b>：study sampling problems, lack smoothness, sampling, Poincaré inequality, algorithm</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We study sampling problems associated with non-convex potentials that
meanwhile lack smoothness. In particular, we consider target distributions that
satisfy either logarithmic-Sobolev inequality or Poincaré inequality. Rather
than smooth, the potentials are assumed to be semi-smooth or the summation of
multiple semi-smooth functions. We develop a sampling algorithm that resembles
proximal algorithms in optimization for this challenging sampling task. Our
algorithm is based on a special case of Gibbs sampling known as the alternating
sampling framework (ASF). The key contribution of this work is a practical
realization of the ASF based on rejection sampling in the non-convex and
semi-smooth setting. This work extends the recent algorithm in
\cite{LiaChe21,LiaChe22} for non-smooth/semi-smooth log-concave distribution to
the setting with non-convex potentials. In almost all the cases of sampling
considered in this work, our proximal sampling algorithm achieves better
complexity than all existing methods.</p>
  </details>
</details>
<details>
  <summary>27. <b>标题：Bayesian Active Learning with Fully Bayesian Gaussian Processes</b></summary>
  <p><b>编号</b>：[71]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10186</p>
  <p><b>作者</b>：Christoffer Riis,  Francisco N. Antunes,  Frederik Boe Hüttel,  Carlos Lima Azevedo,  Francisco Camara Pereira</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：bias-variance trade-off, well-known problem, problem in machine, Gaussian Processes, machine learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The bias-variance trade-off is a well-known problem in machine learning that
only gets more pronounced the less available data there is. In active learning,
where labeled data is scarce or difficult to obtain, neglecting this trade-off
can cause inefficient and non-optimal querying, leading to unnecessary data
labeling. In this paper, we focus on active learning with Gaussian Processes
(GPs). For the GP, the bias-variance trade-off is made by optimization of the
two hyperparameters: the length scale and noise-term. Considering that the
optimal mode of the joint posterior of the hyperparameters is equivalent to the
optimal bias-variance trade-off, we approximate this joint posterior and
utilize it to design two new acquisition functions. The first one is a Bayesian
variant of Query-by-Committee (B-QBC), and the second is an extension that
explicitly minimizes the predictive variance through a Query by Mixture of
Gaussian Processes (QB-MGP) formulation. Across six common simulators, we
empirically show that B-QBC, on average, achieves the best marginal likelihood,
whereas QB-MGP achieves the best predictive performance. We show that
incorporating the bias-variance trade-off in the acquisition functions
mitigates unnecessary and expensive data labeling.</p>
  </details>
</details>
<details>
  <summary>28. <b>标题：Towards the Generation of Synthetic Images of Palm Vein Patterns: A  Review</b></summary>
  <p><b>编号</b>：[74]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10179</p>
  <p><b>作者</b>：Edwin H. Salazar-Jurado,  Ruber Hernández-García,  Karina Vilches-Ponce,  Ricardo J. Barrientos,  Marco Mora,  Gaurav Jaswal</p>
  <p><b>备注</b>：Under review</p>
  <p><b>关键词</b>：palm vein recognition, automatic personal recognition, palm vein, vein recognition, palm vein images</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>With the recent success of computer vision and deep learning, remarkable
progress has been achieved on automatic personal recognition using vein
biometrics. However, collecting large-scale real-world training data for palm
vein recognition has turned out to be challenging, mainly due to the noise and
irregular variations included at the time of acquisition. Meanwhile, existing
palm vein recognition datasets are usually collected under near-infrared light,
lacking detailed annotations on attributes (e.g., pose), so the influences of
different attributes on vein recognition have been poorly investigated.
Therefore, this paper examines the suitability of synthetic vein images
generated to compensate for the urgent lack of publicly available large-scale
datasets. Firstly, we present an overview of recent research progress on palm
vein recognition, from the basic background knowledge to vein anatomical
structure, data acquisition, public database, and quality assessment
procedures. Then, we focus on the state-of-the-art methods that have allowed
the generation of vascular structures for biometric purposes and the modeling
of biological networks with their respective application domains. In addition,
we review the existing research on the generation of style transfer and
biological nature-based synthetic palm vein image algorithms. Afterward, we
formalize a general flowchart for the creation of a synthetic database
comparing real palm vein images and generated synthetic samples to obtain some
understanding into the development of the realistic vein imaging system.
Ultimately, we conclude by discussing the challenges, insights, and future
perspectives in generating synthetic palm vein images for further works.</p>
  </details>
</details>
<details>
  <summary>29. <b>标题：Task Relabelling for Multi-task Transfer using Successor Features</b></summary>
  <p><b>编号</b>：[77]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10175</p>
  <p><b>作者</b>：Martin Balla,  Diego Perez-Liebana</p>
  <p><b>备注</b>：accepted for publication in IEEE Conference on Games (CoG) 2022</p>
  <p><b>关键词</b>：Deep Reinforcement Learning, Deep Reinforcement, Reinforcement Learning, complex domains, successful recently</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep Reinforcement Learning has been very successful recently with various
works on complex domains. Most works are concerned with learning a single
policy that solves the target task, but is fixed in the sense that if the
environment changes the agent is unable to adapt to it. Successor Features
(SFs) proposes a mechanism that allows learning policies that are not tied to
any particular reward function. In this work we investigate how SFs may be
pre-trained without observing any reward in a custom environment that features
resource collection, traps and crafting. After pre-training we expose the SF
agents to various target tasks and see how well they can transfer to new tasks.
Transferring is done without any further training on the SF agents, instead
just by providing a task vector. For training the SFs we propose a task
relabelling method which greatly improves the agent's performance.</p>
  </details>
</details>
<details>
  <summary>30. <b>标题：AutoFedNLP: An efficient FedNLP framework</b></summary>
  <p><b>编号</b>：[80]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10162</p>
  <p><b>作者</b>：Dongqi Cai,  Yaozong Wu,  Shangguang Wang,  Felix Xiaozhu Lin,  Mengwei Xu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Transformer-based pre-trained models, performance and generality, superior performance, Transformer-based pre-trained, pre-trained models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Transformer-based pre-trained models have revolutionized NLP for superior
performance and generality. Fine-tuning pre-trained models for downstream tasks
often require private data, for which federated learning is the de-facto
approach (i.e., FedNLP). However, our measurements show that FedNLP is
prohibitively slow due to the large model sizes and the resultant high
network/computation cost. Towards practical FedNLP, we identify as the key
building blocks adapters, small bottleneck modules inserted at a variety of
model layers. A key challenge is to properly configure the depth and width of
adapters, to which the training speed and efficiency is highly sensitive. No
silver-bullet configuration exists: the optimal choice varies across downstream
NLP tasks, desired model accuracy, and client resources. A silver-bullet
configuration does not exist and a non-optimal configuration could
significantly slow down the training. To automate adapter configuration, we
propose AutoFedNLP, a framework that enhances the existing FedNLP with two
novel designs. First, AutoFedNLP progressively upgrades the adapter
configuration throughout a training session. Second, AutoFedNLP continuously
profiles future adapter configurations by allocating participant devices to
trial groups. To minimize client-side computations, AutoFedNLP exploits the
fact that a FedNLP client trains on the same samples repeatedly between
consecutive changes of adapter configurations, and caches computed activations
on clients. Extensive experiments show that AutoFedNLP can reduce FedNLP's
model convergence delay to no more than several hours, which is up to
155.5$\times$ faster compared to vanilla FedNLP and 48$\times$ faster compared
to strong baselines.</p>
  </details>
</details>
<details>
  <summary>31. <b>标题：Swapping Semantic Contents for Mixing Images</b></summary>
  <p><b>编号</b>：[83]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10158</p>
  <p><b>作者</b>：Rémy Sun,  Clément Masson,  Gilles Hénaff,  Nicolas Thome,  Matthieu Cord</p>
  <p><b>备注</b>：Accepted at ICPR 2022, 7 pages, 4 figures, 6 tables</p>
  <p><b>关键词</b>：Deep architecture, architecture have proven, proven capable, capable of solving, solving many tasks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep architecture have proven capable of solving many tasks provided a
sufficient amount of labeled data. In fact, the amount of available labeled
data has become the principal bottleneck in low label settings such as
Semi-Supervised Learning. Mixing Data Augmentations do not typically yield new
labeled samples, as indiscriminately mixing contents creates between-class
samples. In this work, we introduce the SciMix framework that can learn to
generator to embed a semantic style code into image backgrounds, we obtain new
mixing scheme for data augmentation. We then demonstrate that SciMix yields
novel mixed samples that inherit many characteristics from their non-semantic
parents. Afterwards, we verify those samples can be used to improve the
performance semi-supervised frameworks like Mean Teacher or Fixmatch, and even
fully supervised learning on a small labeled dataset.</p>
  </details>
</details>
<details>
  <summary>32. <b>标题：Machine Learning for Combinatorial Optimisation of Partially-Specified  Problems: Regret Minimisation as a Unifying Lens</b></summary>
  <p><b>编号</b>：[84]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10157</p>
  <p><b>作者</b>：Stefano Teso,  Laurens Bliek,  Andrea Borghesi,  Michele Lombardi,  Neil Yorke-Smith,  Tias Guns,  Andrea Passerini</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：solve combinatorial optimisation, increasingly common, common to solve, combinatorial optimisation problems, optimisation problem</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>It is increasingly common to solve combinatorial optimisation problems that
are partially-specified. We survey the case where the objective function or the
relations between variables are not known or are only partially specified. The
challenge is to learn them from available data, while taking into account a set
of hard constraints that a solution must satisfy, and that solving the
optimisation problem (esp. during learning) is computationally very demanding.
This paper overviews four seemingly unrelated approaches, that can each be
viewed as learning the objective function of a hard combinatorial optimisation
problem: 1) surrogate-based optimisation, 2) empirical model learning, 3)
decision-focused learning (`predict + optimise'), and 4) structured-output
prediction. We formalise each learning paradigm, at first in the ways commonly
found in the literature, and then bring the formalisations together in a
compatible way using regret. We discuss the differences and interactions
between these frameworks, highlight the opportunities for cross-fertilization
and survey open directions.</p>
  </details>
</details>
<details>
  <summary>33. <b>标题：Revisiting GANs by Best-Response Constraint: Perspective, Methodology,  and Application</b></summary>
  <p><b>编号</b>：[89]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10146</p>
  <p><b>作者</b>：Risheng Liu,  Jiaxin Gao,  Xuan Liu,  Xin Fan</p>
  <p><b>备注</b>：11 pages</p>
  <p><b>关键词</b>：Generative Adversarial Networks, address Generative Adversarial, minimax type single-level, Adversarial Networks, Generative Adversarial</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In past years, the minimax type single-level optimization formulation and its
variations have been widely utilized to address Generative Adversarial Networks
(GANs). Unfortunately, it has been proved that these alternating learning
strategies cannot exactly reveal the intrinsic relationship between the
generator and discriminator, thus easily result in a series of issues,
including mode collapse, vanishing gradients and oscillations in the training
phase, etc. In this work, by investigating the fundamental mechanism of GANs
from the perspective of hierarchical optimization, we propose Best-Response
Constraint (BRC), a general learning framework, that can explicitly formulate
the potential dependency of the generator on the discriminator. Rather than
adopting these existing time-consuming bilevel iterations, we design an
implicit gradient scheme with outer-product Hessian approximation as our fast
solution strategy. \emph{Noteworthy, we demonstrate that even with different
motivations and formulations, a variety of existing GANs ALL can be uniformly
improved by our flexible BRC methodology.} Extensive quantitative and
qualitative experimental results verify the effectiveness, flexibility and
stability of our proposed framework.</p>
  </details>
</details>
<details>
  <summary>34. <b>标题：The developmental trajectory of object recognition robustness: children  are like small adults but unlike big deep neural networks</b></summary>
  <p><b>编号</b>：[90]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10144</p>
  <p><b>作者</b>：Lukas S. Huber,  Robert Geirhos,  Felix A. Wichmann</p>
  <p><b>备注</b>：Manuscript under review at Journal of Vision</p>
  <p><b>关键词</b>：Deep Neural Networks, Neural Networks, Deep Neural, unicode, recognition tasks based</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In laboratory object recognition tasks based on undistorted photographs, both
adult humans and Deep Neural Networks (DNNs) perform close to ceiling. Unlike
adults', whose object recognition performance is robust against a wide range of
image distortions, DNNs trained on standard ImageNet (1.3M images) perform
poorly on distorted images. However, the last two years have seen impressive
gains in DNN distortion robustness, predominantly achieved through
ever-increasing large-scale datasets$\unicode{x2014}$orders of magnitude larger
than ImageNet. While this simple brute-force approach is very effective in
achieving human-level robustness in DNNs, it raises the question of whether
human robustness, too, is simply due to extensive experience with (distorted)
visual input during childhood and beyond. Here we investigate this question by
comparing the core object recognition performance of 146 children (aged
4$\unicode{x2013}$15) against adults and against DNNs. We find, first, that
already 4$\unicode{x2013}$6 year-olds showed remarkable robustness to image
distortions and outperform DNNs trained on ImageNet. Second, we estimated the
number of $\unicode{x201C}$images$\unicode{x201D}$ children have been exposed
to during their lifetime. Compared to various DNNs, children's high robustness
requires relatively little data. Third, when recognizing objects
children$\unicode{x2014}$like adults but unlike DNNs$\unicode{x2014}$rely
heavily on shape but not on texture cues. Together our results suggest that the
remarkable robustness to distortions emerges early in the developmental
trajectory of human object recognition and is unlikely the result of a mere
accumulation of experience with distorted visual input. Even though current
DNNs match human performance regarding robustness they seem to rely on
different and more data-hungry strategies to do so.</p>
  </details>
</details>
<details>
  <summary>35. <b>标题：Towards efficient feature sharing in MIMO architectures</b></summary>
  <p><b>编号</b>：[91]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10139</p>
  <p><b>作者</b>：Rémy Sun,  Alexandre Ramé,  Clément Masson,  Nicolas Thome,  Matthieu Cord</p>
  <p><b>备注</b>：7 pages, 6 figures, 1 table</p>
  <p><b>关键词</b>：train multiple subnetworks, ensembling for free, train multiple, base network, predictions to benefit</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Multi-input multi-output architectures propose to train multiple subnetworks
within one base network and then average the subnetwork predictions to benefit
from ensembling for free. Despite some relative success, these architectures
are wasteful in their use of parameters. Indeed, we highlight in this paper
that the learned subnetwork fail to share even generic features which limits
their applicability on smaller mobile and AR/VR devices. We posit this behavior
stems from an ill-posed part of the multi-input multi-output framework. To
solve this issue, we propose a novel unmixing step in MIMO architectures that
allows subnetworks to properly share features. Preliminary experiments on
CIFAR-100 show our adjustments allow feature sharing and improve model
performance for small architectures.</p>
  </details>
</details>
<details>
  <summary>36. <b>标题：Function Regression using Spiking DeepONet</b></summary>
  <p><b>编号</b>：[96]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10130</p>
  <p><b>作者</b>：Adar Kahana,  Qian Zhang,  Leonard Gleyzer,  George Em Karniadakis</p>
  <p><b>备注</b>：15 pages, 5 figures and 4 tables</p>
  <p><b>关键词</b>：main broad applications, main broad, broad applications, applications of deep, modern neural network</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>One of the main broad applications of deep learning is function regression.
However, despite their demonstrated accuracy and robustness, modern neural
network architectures require heavy computational resources to train. One
method to mitigate or even resolve this inefficiency has been to draw further
inspiration from the brain and reformulate the learning process in a more
biologically-plausible way, developing what are known as Spiking Neural
Networks (SNNs), which have been gaining traction in recent years. In this
paper we present an SNN-based method to perform regression, which has been a
challenge due to the inherent difficulty in representing a function's input
domain and continuous output values as spikes. We use a DeepONet - neural
network designed to learn operators - to learn the behavior of spikes. Then, we
use this approach to do function regression. We propose several methods to use
a DeepONet in the spiking framework, and present accuracy and training time for
different benchmarks.</p>
  </details>
</details>
<details>
  <summary>37. <b>标题：Topology-aware Graph Neural Networks for Learning Feasible and Adaptive  ac-OPF Solutions</b></summary>
  <p><b>编号</b>：[97]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10129</p>
  <p><b>作者</b>：Shaohui Liu,  Chengyang Wu,  Hao Zhu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：electricity grid operations, optimal power flow, real-time electricity grid, fundamental task, task to ensure</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Solving the optimal power flow (OPF) problem is a fundamental task to ensure
the system efficiency and reliability in real-time electricity grid operations.
We develop a new topology-informed graph neural network (GNN) approach for
predicting the optimal solutions of real-time ac-OPF problem. To incorporate
grid topology to the NN model, the proposed GNN-for-OPF framework innovatively
exploits the locality property of locational marginal prices and voltage
magnitude. Furthermore, we develop a physics-aware (ac-)flow feasibility
regularization approach for general OPF learning. The advantages of our
proposed designs include reduced model complexity, improved generalizability
and feasibility guarantees. By providing the analytical understanding on the
graph subspace stability under grid topology contingency, we show the proposed
GNN can quickly adapt to varying grid topology by an efficient re-training
strategy. Numerical tests on various test systems of different sizes have
validated the prediction accuracy, improved flow feasibility, and topology
adaptivity capability of our proposed GNN-based learning framework.</p>
  </details>
</details>
<details>
  <summary>38. <b>标题：Neural-Symbolic Models for Logical Queries on Knowledge Graphs</b></summary>
  <p><b>编号</b>：[98]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10128</p>
  <p><b>作者</b>：Zhaocheng Zhu,  Mikhail Galkin,  Zuobai Zhang,  Jian Tang</p>
  <p><b>备注</b>：ICML 2022</p>
  <p><b>关键词</b>：fundamental task, task for multi-hop, Graph Neural Network, knowledge, graph</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Answering complex first-order logic (FOL) queries on knowledge graphs is a
fundamental task for multi-hop reasoning. Traditional symbolic methods traverse
a complete knowledge graph to extract the answers, which provides good
interpretation for each step. Recent neural methods learn geometric embeddings
for complex queries. These methods can generalize to incomplete knowledge
graphs, but their reasoning process is hard to interpret. In this paper, we
propose Graph Neural Network Query Executor (GNN-QE), a neural-symbolic model
that enjoys the advantages of both worlds. GNN-QE decomposes a complex FOL
query into relation projections and logical operations over fuzzy sets, which
provides interpretability for intermediate variables. To reason about the
missing links, GNN-QE adapts a graph neural network from knowledge graph
completion to execute the relation projections, and models the logical
operations with product fuzzy logic. Extensive experiments on 3 datasets show
that GNN-QE significantly improves over previous state-of-the-art models in
answering FOL queries. Meanwhile, GNN-QE can predict the number of answers
without explicit supervision, and provide visualizations for intermediate
variables.</p>
  </details>
</details>
<details>
  <summary>39. <b>标题：The Fellowship of the Dyson Ring: ACT&Friends' Results and Methods for  GTOC 11</b></summary>
  <p><b>编号</b>：[101]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10124</p>
  <p><b>作者</b>：Marcus Märtens,  Dario Izzo,  Emmanuel Blazquez,  Moritz von Looz,  Pablo Gómez,  Anne Mergy,  Giacomo Acciarini,  Chit Hong Yam,  Javier Hernando Ayuso,  Yuri Shimane</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：hypothetical megastructures encircling, megastructures encircling stars, energy output, spheres are hypothetical, hypothetical megastructures</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Dyson spheres are hypothetical megastructures encircling stars in order to
harvest most of their energy output. During the 11th edition of the GTOC
challenge, participants were tasked with a complex trajectory planning related
to the construction of a precursor Dyson structure, a heliocentric ring made of
twelve stations. To this purpose, we developed several new approaches that
synthesize techniques from machine learning, combinatorial optimization,
planning and scheduling, and evolutionary optimization effectively integrated
into a fully automated pipeline. These include a machine learned transfer time
estimator, improving the established Edelbaum approximation and thus better
informing a Lazy Race Tree Search to identify and collect asteroids with high
arrival mass for the stations; a series of optimally-phased low-thrust
transfers to all stations computed by indirect optimization techniques,
exploiting the synodic periodicity of the system; and a modified Hungarian
scheduling algorithm, which utilizes evolutionary techniques to arrange a
mass-balanced arrival schedule out of all transfer possibilities. We describe
the steps of our pipeline in detail with a special focus on how our approaches
mutually benefit from each other. Lastly, we outline and analyze the final
solution of our team, ACT&Friends, which ranked second at the GTOC 11
challenge.</p>
  </details>
</details>
<details>
  <summary>40. <b>标题：Lifelong Personal Context Recognition</b></summary>
  <p><b>编号</b>：[102]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10123</p>
  <p><b>作者</b>：Andrea Bontempelli,  Marcelo Rodas Britez,  Xiaoyue Li,  Haonan Zhao,  Luca Erculiani,  Stefano Teso,  Andrea Passerini,  Fausto Giunchiglia</p>
  <p><b>备注</b>：8 pages</p>
  <p><b>关键词</b>：development of AIs, AIs which live, lifelong symbiosis, performing lifelong context, lifelong context recognition</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We focus on the development of AIs which live in lifelong symbiosis with a
human. The key prerequisite for this task is that the AI understands - at any
moment in time - the personal situational context that the human is in. We
outline the key challenges that this task brings forth, namely (i) handling the
human-like and ego-centric nature of the the user's context, necessary for
understanding and providing useful suggestions, (ii) performing lifelong
context recognition using machine learning in a way that is robust to change,
and (iii) maintaining alignment between the AI's and human's representations of
the world through continual bidirectional interaction. In this short paper, we
summarize our recent attempts at tackling these challenges, discuss the lessons
learned, and highlight directions of future research. The main take-away
message is that pursuing this project requires research which lies at the
intersection of knowledge representation and machine learning. Neither
technology can achieve this goal without the other.</p>
  </details>
</details>
<details>
  <summary>41. <b>标题：Stochastic resonance neurons in artificial neural networks</b></summary>
  <p><b>编号</b>：[103]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10122</p>
  <p><b>作者</b>：Egor Manuylovich,  Diego Argüello Ron,  Morteza Kamalian-Kopae,  Sergei Turitsyn</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：implementations increasingly complex, layers making traditional, making traditional digital, traditional digital implementations, digital implementations increasingly</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Many modern applications of the artificial neural networks ensue large number
of layers making traditional digital implementations increasingly complex.
Optical neural networks offer parallel processing at high bandwidth, but have
the challenge of noise accumulation. We propose here a new type of neural
networks using stochastic resonances as an inherent part of the architecture
and demonstrate a possibility of significant reduction of the required number
of neurons for a given performance accuracy. We also show that such a neural
network is more robust against the impact of noise.</p>
  </details>
</details>
<details>
  <summary>42. <b>标题：Converting Artificial Neural Networks to Spiking Neural Networks via  Parameter Calibration</b></summary>
  <p><b>编号</b>：[104]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10121</p>
  <p><b>作者</b>：Yuhang Li,  Shikuang Deng,  Xin Dong,  Shi Gu</p>
  <p><b>备注</b>：arXiv admin note: text overlap with arXiv:2106.06984</p>
  <p><b>关键词</b>：next-generation neural networks, Spiking Neural Network, neural networks, behavior in biology, neural behavior</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Spiking Neural Network (SNN), originating from the neural behavior in
biology, has been recognized as one of the next-generation neural networks.
Conventionally, SNNs can be obtained by converting from pre-trained Artificial
Neural Networks (ANNs) by replacing the non-linear activation with spiking
neurons without changing the parameters. In this work, we argue that simply
copying and pasting the weights of ANN to SNN inevitably results in activation
mismatch, especially for ANNs that are trained with batch normalization (BN)
layers. To tackle the activation mismatch issue, we first provide a theoretical
analysis by decomposing local conversion error to clipping error and flooring
error, and then quantitatively measure how this error propagates throughout the
layers using the second-order analysis. Motivated by the theoretical results,
we propose a set of layer-wise parameter calibration algorithms, which adjusts
the parameters to minimize the activation mismatch. Extensive experiments for
the proposed algorithms are performed on modern architectures and large-scale
tasks including ImageNet classification and MS COCO detection. We demonstrate
that our method can handle the SNN conversion with batch normalization layers
and effectively preserve the high accuracy even in 32 time steps. For example,
our calibration algorithms can increase up to 65% accuracy when converting
VGG-16 with BN layers.</p>
  </details>
</details>
<details>
  <summary>43. <b>标题：Is explainable AI a race against model complexity?</b></summary>
  <p><b>编号</b>：[106]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10119</p>
  <p><b>作者</b>：Advait Sarkar</p>
  <p><b>备注</b>：Workshop on Transparency and Explanations in Smart Systems (TExSS 2022), at the 27th International Conference on Intelligent User Interfaces (IUI 2022)</p>
  <p><b>关键词</b>：Explaining the behaviour, behaviour of intelligent, intelligent systems, intractably challenging, grow in size</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Explaining the behaviour of intelligent systems will get increasingly and
perhaps intractably challenging as models grow in size and complexity. We may
not be able to expect an explanation for every prediction made by a brain-scale
model, nor can we expect explanations to remain objective or apolitical. Our
functionalist understanding of these models is of less advantage than we might
assume. Models precede explanations, and can be useful even when both model and
explanation are incorrect. Explainability may never win the race against
complexity, but this is less problematic than it seems.</p>
  </details>
</details>
<details>
  <summary>44. <b>标题：An Artificial Neural Network Functionalized by Evolution</b></summary>
  <p><b>编号</b>：[107]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10118</p>
  <p><b>作者</b>：Fabien Furfaro,  Avner Bar-Hen,  Geoffroy Berthelot</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：significant effect, Artificial Intelligence, neural networks, artificial, Characterizing efficient topology</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The topology of artificial neural networks has a significant effect on their
performance. Characterizing efficient topology is a field of promising research
in Artificial Intelligence. However, it is not a trivial task and it is mainly
experimented on through convolutional neural networks. We propose a hybrid
model which combines the tensor calculus of feed-forward neural networks with
Pseudo-Darwinian mechanisms. This allows for finding topologies that are well
adapted for elaboration of strategies, control problems or pattern recognition
tasks. In particular, the model can provide adapted topologies at early
evolutionary stages, and 'structural convergence', which can found applications
in robotics, big-data and artificial life.</p>
  </details>
</details>
<details>
  <summary>45. <b>标题：DDDM: a Brain-Inspired Framework for Robust Classification</b></summary>
  <p><b>编号</b>：[108]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10117</p>
  <p><b>作者</b>：Xiyuan Chen,  Xingyu Li,  Yi Zhou,  Tianming Yang</p>
  <p><b>备注</b>：submitted to IJCAI2022</p>
  <p><b>关键词</b>：deep artificial neural, artificial neural networks, outstanding performance, broad spectrum, spectrum of real-world</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Despite their outstanding performance in a broad spectrum of real-world
tasks, deep artificial neural networks are sensitive to input noises,
particularly adversarial perturbations. On the contrary, human and animal
brains are much less vulnerable. In contrast to the one-shot inference
performed by most deep neural networks, the brain often solves decision-making
with an evidence accumulation mechanism that may trade time for accuracy when
facing noisy inputs. The mechanism is well described by the Drift-Diffusion
Model (DDM). In the DDM, decision-making is modeled as a process in which noisy
evidence is accumulated toward a threshold. Drawing inspiration from the DDM,
we propose the Dropout-based Drift-Diffusion Model (DDDM) that combines
test-phase dropout and the DDM for improving the robustness for arbitrary
neural networks. The dropouts create temporally uncorrelated noises in the
network that counter perturbations, while the evidence accumulation mechanism
guarantees a reasonable decision accuracy. Neural networks enhanced with the
DDDM tested in image, speech, and text classification tasks all significantly
outperform their native counterparts, demonstrating the DDDM as a task-agnostic
defense against adversarial attacks.</p>
  </details>
</details>
<details>
  <summary>46. <b>标题：Evolving SimGANs to Improve Abnormal Electrocardiogram Classification</b></summary>
  <p><b>编号</b>：[109]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10116</p>
  <p><b>作者</b>：Gabriel Wang,  Anish Thite,  Rodd Talebi,  Anthony D'Achille,  Alex Mussa,  Jason Zutty</p>
  <p><b>备注</b>：8 pages, presented at The Genetic and Evolutionary Computation Conference 2022</p>
  <p><b>关键词</b>：Machine Learning models, Machine Learning, machine learning methods, Learning models, data</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Machine Learning models are used in a wide variety of domains. However,
machine learning methods often require a large amount of data in order to be
successful. This is especially troublesome in domains where collecting
real-world data is difficult and/or expensive. Data simulators do exist for
many of these domains, but they do not sufficiently reflect the real world data
due to factors such as a lack of real-world noise. Recently generative
adversarial networks (GANs) have been modified to refine simulated image data
into data that better fits the real world distribution, using the SimGAN
method. While evolutionary computing has been used for GAN evolution, there are
currently no frameworks that can evolve a SimGAN. In this paper we (1) extend
the SimGAN method to refine one-dimensional data, (2) modify Easy Cartesian
Genetic Programming (ezCGP), an evolutionary computing framework, to create
SimGANs that more accurately refine simulated data, and (3) create new
feature-based quantitative metrics to evaluate refined data. We also use our
framework to augment an electrocardiogram (ECG) dataset, a domain that suffers
from the issues previously mentioned. In particular, while healthy ECGs can be
simulated there are no current simulators of abnormal ECGs. We show that by
using an evolved SimGAN to refine simulated healthy ECG data to mimic
real-world abnormal ECGs, we can improve the accuracy of abnormal ECG
classifiers.</p>
  </details>
</details>
<details>
  <summary>47. <b>标题：Evolutionary Multi-Armed Bandits with Genetic Thompson Sampling</b></summary>
  <p><b>编号</b>：[111]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10113</p>
  <p><b>作者</b>：Baihan Lin</p>
  <p><b>备注</b>：Proceeding of IEEE CEC 2022. This work is one of the first works to solve the online learning problems with distributed evolutionary optimizations, and extends our prior work on contextual bandits (e.g. arXiv:2106.15808) by testing against similar simulated and real-world scenarios. Codes at this https URL</p>
  <p><b>关键词</b>：important driving forces, real-world decision making, decision making engines, applications in biomedicine, decision making</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As two popular schools of machine learning, online learning and evolutionary
computations have become two important driving forces behind real-world
decision making engines for applications in biomedicine, economics, and
engineering fields. Although there are prior work that utilizes bandits to
improve evolutionary algorithms' optimization process, it remains a field of
blank on how evolutionary approach can help improve the sequential decision
making tasks of online learning agents such as the multi-armed bandits. In this
work, we propose the Genetic Thompson Sampling, a bandit algorithm that keeps a
population of agents and update them with genetic principles such as elite
selection, crossover and mutations. Empirical results in multi-armed bandit
simulation environments and a practical epidemic control problem suggest that
by incorporating the genetic algorithm into the bandit algorithm, our method
significantly outperforms the baselines in nonstationary settings. Lastly, we
introduce EvoBandit, a web-based interactive visualization to guide the readers
through the entire learning process and perform lightweight evaluations on the
fly. We hope to engage researchers into this growing field of research with
this investigation.</p>
  </details>
</details>
<details>
  <summary>48. <b>标题：FedNoiL: A Simple Two-Level Sampling Method for Federated Learning with  Noisy Labels</b></summary>
  <p><b>编号</b>：[112]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10110</p>
  <p><b>作者</b>：Zhuowei Wang,  Tianyi Zhou,  Guodong Long,  Bo Han,  Jing Jiang</p>
  <p><b>备注</b>：12 pages</p>
  <p><b>关键词</b>：global model, collected and located, noisy labels, global, labels</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Federated learning (FL) aims at training a global model on the server side
while the training data are collected and located at the local devices. Hence,
the labels in practice are usually annotated by clients of varying expertise or
criteria and thus contain different amounts of noises. Local training on noisy
labels can easily result in overfitting to noisy labels, which is devastating
to the global model through aggregation. Although recent robust FL methods take
malicious clients into account, they have not addressed local noisy labels on
each device and the impact to the global model. In this paper, we develop a
simple two-level sampling method "FedNoiL" that (1) selects clients for more
robust global aggregation on the server; and (2) selects clean labels and
correct pseudo-labels at the client end for more robust local training. The
sampling probabilities are built upon clean label detection by the global
model. Moreover, we investigate different schedules changing the local epochs
between aggregations over the course of FL, which notably improves the
communication and computation efficiency in noisy label setting. In experiments
with homogeneous/heterogeneous data distributions and noise ratios, we observed
that direct combinations of SOTA FL methods with SOTA noisy-label learning
methods can easily fail but our method consistently achieves better and robust
performance.</p>
  </details>
</details>
<details>
  <summary>49. <b>标题：LeNSE: Learning To Navigate Subgraph Embeddings for Large-Scale  Combinatorial Optimisation</b></summary>
  <p><b>编号</b>：[113]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10106</p>
  <p><b>作者</b>：David Ireland,  Giovanni Montana</p>
  <p><b>备注</b>：To appear in ICML 2022</p>
  <p><b>关键词</b>：Combinatorial Optimisation problems, Optimisation problems arise, Combinatorial Optimisation, Optimisation problems, application domains</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Combinatorial Optimisation problems arise in several application domains and
are often formulated in terms of graphs. Many of these problems are NP-hard,
but exact solutions are not always needed. Several heuristics have been
developed to provide near-optimal solutions; however, they do not typically
scale well with the size of the graph. We propose a low-complexity approach for
identifying a (possibly much smaller) subgraph of the original graph where the
heuristics can be run in reasonable time and with a high likelihood of finding
a global near-optimal solution. The core component of our approach is LeNSE, a
reinforcement learning algorithm that learns how to navigate the space of
possible subgraphs using an Euclidean subgraph embedding as its map. To solve
CO problems, LeNSE is provided with a discriminative embedding trained using
any existing heuristics using only on a small portion of the original graph.
When tested on three problems (vertex cover, max-cut and influence
maximisation) using real graphs with up to $10$ million edges, LeNSE identifies
small subgraphs yielding solutions comparable to those found by running the
heuristics on the entire graph, but at a fraction of the total run time.</p>
  </details>
</details>
<details>
  <summary>50. <b>标题：Visual Concepts Tokenization</b></summary>
  <p><b>编号</b>：[119]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10093</p>
  <p><b>作者</b>：Tao Yang,  Yuwang Wang,  Yan Lu,  Nanning Zheng</p>
  <p><b>备注</b>：Preprint, under review</p>
  <p><b>关键词</b>：human-like perception ability, Visual Concepts Tokenization, abstracting visual concepts, concept tokens, visual concepts</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Obtaining the human-like perception ability of abstracting visual concepts
from concrete pixels has always been a fundamental and important target in
machine learning research fields such as disentangled representation learning
and scene decomposition. Towards this goal, we propose an unsupervised
transformer-based Visual Concepts Tokenization framework, dubbed VCT, to
perceive an image into a set of disentangled visual concept tokens, with each
concept token responding to one type of independent visual concept.
Particularly, to obtain these concept tokens, we only use cross-attention to
extract visual information from the image tokens layer by layer without
self-attention between concept tokens, preventing information leakage across
concept tokens. We further propose a Concept Disentangling Loss to facilitate
that different concept tokens represent independent visual concepts. The
cross-attention and disentangling loss play the role of induction and mutual
exclusion for the concept tokens, respectively. Extensive experiments on
several popular datasets verify the effectiveness of VCT on the tasks of
disentangled representation learning and scene decomposition. VCT achieves the
state of the art results by a large margin.</p>
  </details>
</details>
<details>
  <summary>51. <b>标题：Kernel Normalized Convolutional Networks</b></summary>
  <p><b>编号</b>：[121]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10089</p>
  <p><b>作者</b>：Reza Nasirigerdeh,  Reihaneh Torkzadehmahani,  Daniel Rueckert,  Georgios Kaissis</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：architectures frequently rely, Existing deep convolutional, deep convolutional neural, convolutional neural network, Existing deep</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Existing deep convolutional neural network (CNN) architectures frequently
rely upon batch normalization (BatchNorm) to effectively train the model.
BatchNorm significantly improves model performance, but performs poorly with
smaller batch sizes. To address this limitation, we propose kernel
normalization and kernel normalized convolutional layers, and incorporate them
into kernel normalized convolutional networks (KNConvNets) as the main building
blocks. We implement KNConvNets corresponding to the state-of-the-art CNNs such
as ResNet and DenseNet while forgoing BatchNorm layers. Through extensive
experiments, we illustrate that KNConvNets consistently outperform their batch,
group, and layer normalized counterparts in terms of both accuracy and
convergence rate while maintaining competitive computational efficiency.</p>
  </details>
</details>
<details>
  <summary>52. <b>标题：Semi-self-supervised Automated ICD Coding</b></summary>
  <p><b>编号</b>：[122]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10088</p>
  <p><b>作者</b>：Hlynur D. Hlynsson,  Steindór Ellertsson,  Jón F. Daðason,  Emil L. Sigurdsson,  Hrafn Loftsson</p>
  <p><b>备注</b>：10 pages</p>
  <p><b>关键词</b>：Clinical Text Notes, free text format, unstructured free text, Text Notes, physicians' reasoning process</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Clinical Text Notes (CTNs) contain physicians' reasoning process, written in
an unstructured free text format, as they examine and interview patients. In
recent years, several studies have been published that provide evidence for the
utility of machine learning for predicting doctors' diagnoses from CTNs, a task
known as ICD coding. Data annotation is time consuming, particularly when a
degree of specialization is needed, as is the case for medical data. This paper
presents a method of augmenting a sparsely annotated dataset of Icelandic CTNs
with a machine-learned imputation in a semi-self-supervised manner. We train a
neural network on a small set of annotated CTNs and use it to extract clinical
features from a set of un-annotated CTNs. These clinical features consist of
answers to about a thousand potential questions that a physician might find the
answers to during a consultation of a patient. The features are then used to
train a classifier for the diagnosis of certain types of diseases. We report
the results of an evaluation of this data augmentation method over three tiers
of data availability to the physician. Our data augmentation method shows a
significant positive effect which is diminished when clinical features from the
examination of the patient and diagnostics are made available. We recommend our
method for augmenting scarce datasets for systems that take decisions based on
clinical features that do not include examinations or tests.</p>
  </details>
</details>
<details>
  <summary>53. <b>标题：A Unified Experiment Design Approach for Cyclic and Acyclic Causal  Models</b></summary>
  <p><b>编号</b>：[124]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10083</p>
  <p><b>作者</b>：Ehsan Mokhtarian,  Saber Salehkaleybar,  AmirEmad Ghassami,  Negar Kiyavash</p>
  <p><b>备注</b>：16 pages, 3 figures</p>
  <p><b>关键词</b>：study experiment design, experiment design, causal graph, experiment design approach, experiment</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We study experiment design for the unique identification of the causal graph
of a system where the graph may contain cycles. The presence of cycles in the
structure introduces major challenges for experiment design. Unlike the case of
acyclic graphs, learning the skeleton of the causal graph from observational
distribution may not be possible. Furthermore, intervening on a variable does
not necessarily lead to orienting all the edges incident to it. In this paper,
we propose an experiment design approach that can learn both cyclic and acyclic
graphs and hence, unifies the task of experiment design for both types of
graphs. We provide a lower bound on the number of experiments required to
guarantee the unique identification of the causal graph in the worst case,
showing that the proposed approach is order-optimal in terms of the number of
experiments up to an additive logarithmic term. Moreover, we extend our result
to the setting where the size of each experiment is bounded by a constant. For
this case, we show that our approach is optimal in terms of the size of the
largest experiment required for the unique identification of the causal graph
in the worst case.</p>
  </details>
</details>
<details>
  <summary>54. <b>标题：Unintended memorisation of unique features in neural networks</b></summary>
  <p><b>编号</b>：[127]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10079</p>
  <p><b>作者</b>：John Hartley,  Sotirios A. Tsaftaris</p>
  <p><b>备注</b>：arXiv admin note: substantial text overlap with arXiv:2202.08099</p>
  <p><b>关键词</b>：Neural networks, training data, Neural networks pose, unique feature, unique</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Neural networks pose a privacy risk due to their propensity to memorise and
leak training data. We show that unique features occurring only once in
training data are memorised by discriminative multi-layer perceptrons and
convolutional neural networks trained on benchmark imaging datasets. We design
our method for settings where sensitive training data is not available, for
example medical imaging. Our setting knows the unique feature, but not the
training data, model weights or the unique feature's label. We develop a score
estimating a model's sensitivity to a unique feature by comparing the KL
divergences of the model's output distributions given modified
out-of-distribution images. We find that typical strategies to prevent
overfitting do not prevent unique feature memorisation. And that images
containing a unique feature are highly influential, regardless of the influence
the images's other features. We also find a significant variation in
memorisation with training seed. These results imply that neural networks pose
a privacy risk to rarely occurring private information. This risk is more
pronounced in healthcare applications since sensitive patient information can
be memorised when it remains in training data due to an imperfect data
sanitisation process.</p>
  </details>
</details>
<details>
  <summary>55. <b>标题：On the Prediction Instability of Graph Neural Networks</b></summary>
  <p><b>编号</b>：[133]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10070</p>
  <p><b>作者</b>：Max Klabunde,  Florian Lemmerich</p>
  <p><b>备注</b>：17 pages, 11 figures</p>
  <p><b>关键词</b>：machine learning systems, random factors, affect reproducibility, learning systems, trust in machine</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Instability of trained models, i.e., the dependence of individual node
predictions on random factors, can affect reproducibility, reliability, and
trust in machine learning systems. In this paper, we systematically assess the
prediction instability of node classification with state-of-the-art Graph
Neural Networks (GNNs). With our experiments, we establish that multiple
instantiations of popular GNN models trained on the same data with the same
model hyperparameters result in almost identical aggregated performance but
display substantial disagreement in the predictions for individual nodes. We
find that up to one third of the incorrectly classified nodes differ across
algorithm runs. We identify correlations between hyperparameters, node
properties, and the size of the training set with the stability of predictions.
In general, maximizing model performance implicitly also reduces model
instability.</p>
  </details>
</details>
<details>
  <summary>56. <b>标题：Understanding and Mitigating the Uncertainty in Zero-Shot Translation</b></summary>
  <p><b>编号</b>：[134]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10068</p>
  <p><b>作者</b>：Wenxuan Wang,  Wenxiang Jiao,  Shuo Wang,  Zhaopeng Tu,  Michael R. Lyu</p>
  <p><b>备注</b>：work in progress</p>
  <p><b>关键词</b>：comprehensive multilingual neural, multilingual neural machine, neural machine translation, promising direction, direction for building</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Zero-shot translation is a promising direction for building a comprehensive
multilingual neural machine translation (MNMT) system. However, its quality is
still not satisfactory due to off-target issues. In this paper, we aim to
understand and alleviate the off-target issues from the perspective of
uncertainty in zero-shot translation. By carefully examining the translation
output and model confidence, we identify two uncertainties that are responsible
for the off-target issues, namely, extrinsic data uncertainty and intrinsic
model uncertainty. Based on the observations, we propose two light-weight and
complementary approaches to denoise the training data for model training, and
mask out the vocabulary of the off-target languages in inference. Extensive
experiments on both balanced and unbalanced datasets show that our approaches
significantly improve the performance of zero-shot translation over strong MNMT
baselines. Qualitative analyses provide insights into where our approaches
reduce off-target translations</p>
  </details>
</details>
<details>
  <summary>57. <b>标题：The Unreasonable Effectiveness of Deep Evidential Regression</b></summary>
  <p><b>编号</b>：[137]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10060</p>
  <p><b>作者</b>：Nis Meinert,  Jakob Gawlikowski,  Alexander Lavin</p>
  <p><b>备注</b>：14 pages, 25 figures</p>
  <p><b>关键词</b>：machine learning systems, principled uncertainty reasoning, safety-critical domains, reasoning in machine, increasingly deployed</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>There is a significant need for principled uncertainty reasoning in machine
learning systems as they are increasingly deployed in safety-critical domains.
A new approach with uncertainty-aware regression-based neural networks (NNs),
based on learning evidential distributions for aleatoric and epistemic
uncertainties, shows promise over traditional deterministic methods and typical
Bayesian NNs, notably with the capabilities to disentangle aleatoric and
epistemic uncertainties. Despite some empirical success of Deep Evidential
Regression (DER), there are important gaps in the mathematical foundation that
raise the question of why the proposed technique seemingly works. We detail the
theoretical shortcomings and analyze the performance on synthetic and
real-world data sets, showing that Deep Evidential Regression is a heuristic
rather than an exact uncertainty quantification. We go on to propose
corrections and redefinitions of how aleatoric and epistemic uncertainties
should be extracted from NNs.</p>
  </details>
</details>
<details>
  <summary>58. <b>标题：Leveraging Relational Information for Learning Weakly Disentangled  Representations</b></summary>
  <p><b>编号</b>：[139]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10056</p>
  <p><b>作者</b>：Andrea Valenti,  Davide Bacciu</p>
  <p><b>备注</b>：Accepted at WCCI2022</p>
  <p><b>关键词</b>：difficult property, property to enforce, neural representations, enforce in neural, relevant factors</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Disentanglement is a difficult property to enforce in neural representations.
This might be due, in part, to a formalization of the disentanglement problem
that focuses too heavily on separating relevant factors of variation of the
data in single isolated dimensions of the neural representation. We argue that
such a definition might be too restrictive and not necessarily beneficial in
terms of downstream tasks. In this work, we present an alternative view over
learning (weakly) disentangled representations, which leverages concepts from
relational learning. We identify the regions of the latent space that
correspond to specific instances of generative factors, and we learn the
relationships among these regions in order to perform controlled changes to the
latent codes. We also introduce a compound generative model that implements
such a weak disentanglement approach. Our experiments shows that the learned
representations can separate the relevant factors of variation in the data,
while preserving the information needed for effectively generating high quality
data samples.</p>
  </details>
</details>
<details>
  <summary>59. <b>标题：MaskGAE: Masked Graph Modeling Meets Graph Autoencoders</b></summary>
  <p><b>编号</b>：[140]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10053</p>
  <p><b>作者</b>：Jintang Li,  Ruofan Wu,  Wangbin Sun,  Liang Chen,  Sheng Tian,  Liang Zhu,  Changhua Meng,  Zibin Zheng,  Weiqiang Wang</p>
  <p><b>备注</b>：Preprint. Code available at this https URL</p>
  <p><b>关键词</b>：masked graph autoencoder, present masked graph, graph-structured data, previous graph autoencoders, framework for graph-structured</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present masked graph autoencoder (MaskGAE), a self-supervised learning
framework for graph-structured data. Different from previous graph autoencoders
(GAEs), MaskGAE adopts masked graph modeling (MGM) as a principled pretext
task: masking a portion of edges and attempting to reconstruct the missing part
with partially visible, unmasked graph structure. To understand whether MGM can
help GAEs learn better representations, we provide both theoretical and
empirical evidence to justify the benefits of this pretext task. Theoretically,
we establish the connections between GAEs and contrastive learning, showing
that MGM significantly improves the self-supervised learning scheme of GAEs.
Empirically, we conduct extensive experiments on a number of benchmark
datasets, demonstrating the superiority of MaskGAE over several
state-of-the-arts on both link prediction and node classification tasks. Our
code is publicly available at \url{this https URL}.</p>
  </details>
</details>
<details>
  <summary>60. <b>标题：Sigmoidally Preconditioned Off-policy Learning:a new exploration method  for reinforcement learning</b></summary>
  <p><b>编号</b>：[143]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10047</p>
  <p><b>作者</b>：Xing Chen,  Dongcui Diao,  Hechang Chen,  Hengshuai Yao,  Jielong Yang,  Haiyin Piao,  Zhixiao Sun,  Bei Jiang,  Yi Chang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：policy, Proximal Policy Optimization, Conservative Policy Iteration, target policy, Preconditioned Proximal Policy</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>One of the major difficulties of reinforcement learning is learning from {\em
off-policy} samples, which are collected by a different policy (behavior
policy) from what the algorithm evaluates (the target policy). Off-policy
learning needs to correct the distribution of the samples from the behavior
policy towards that of the target policy. Unfortunately, important sampling has
an inherent high variance issue which leads to poor gradient estimation in
policy gradient methods. We focus on an off-policy Actor-Critic architecture,
and propose a novel method, called Preconditioned Proximal Policy Optimization
(P3O), which can control the high variance of importance sampling by applying a
preconditioner to the Conservative Policy Iteration (CPI) objective. {\em This
preconditioning uses the sigmoid function in a special way that when there is
no policy change, the gradient is maximal and hence policy gradient will drive
a big parameter update for an efficient exploration of the parameter space}.
This is a novel exploration method that has not been studied before given that
existing exploration methods are based on the novelty of states and actions. We
compare with several best-performing algorithms on both discrete and continuous
tasks and the results confirmed that {\em P3O is more off-policy than PPO}
according to the "off-policyness" measured by the DEON metric, and P3O explores
in a larger policy space than PPO. Results also show that our P3O maximizes the
CPI objective better than PPO during the training process.</p>
  </details>
</details>
<details>
  <summary>61. <b>标题：ExMo: Explainable AI Model using Inverse Frequency Decision Rules</b></summary>
  <p><b>编号</b>：[144]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10045</p>
  <p><b>作者</b>：Pradip Mainali,  Ismini Psychoula,  Fabien A. P. Petitcolas</p>
  <p><b>备注</b>：18 pages, 7 figues, HCI International 2022 Conference</p>
  <p><b>关键词</b>：interpretable machine learning, machine learning model, decision rules, compute decision rules, machine learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we present a novel method to compute decision rules to build a
more accurate interpretable machine learning model, denoted as ExMo. The ExMo
interpretable machine learning model consists of a list of IF...THEN...
statements with a decision rule in the condition. This way, ExMo naturally
provides an explanation for a prediction using the decision rule that was
triggered. ExMo uses a new approach to extract decision rules from the training
data using term frequency-inverse document frequency (TF-IDF) features. With
TF-IDF, decision rules with feature values that are more relevant to each class
are extracted. Hence, the decision rules obtained by ExMo can distinguish the
positive and negative classes better than the decision rules used in the
existing Bayesian Rule List (BRL) algorithm, obtained using the frequent
pattern mining approach. The paper also shows that ExMo learns a qualitatively
better model than BRL. Furthermore, ExMo demonstrates that the textual
explanation can be provided in a human-friendly way so that the explanation can
be easily understood by non-expert users. We validate ExMo on several datasets
with different sizes to evaluate its efficacy. Experimental validation on a
real-world fraud detection application shows that ExMo is 20% more accurate
than BRL and that it achieves accuracy similar to those of deep learning
models.</p>
  </details>
</details>
<details>
  <summary>62. <b>标题：Towards biologically plausible Dreaming and Planning</b></summary>
  <p><b>编号</b>：[145]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10044</p>
  <p><b>作者</b>：Cristiano Capone,  Pier Stanislao Paolucci</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：achieve good performances, Humans and animals, large amount, amount of data, data to achieve</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Humans and animals can learn new skills after practicing for a few hours,
while current reinforcement learning algorithms require a large amount of data
to achieve good performances. Recent model-based approaches show promising
results by reducing the number of necessary interactions with the environment
to learn a desirable policy. However, these methods require biological
implausible ingredients, such as the detailed storage of older experiences, and
long periods of offline learning. The optimal way to learn and exploit
word-models is still an open question. Taking inspiration from biology, we
suggest that dreaming might be an efficient expedient to use an inner model. We
propose a two-module (agent and model) neural network in which "dreaming"
(living new experiences in a model-based simulated environment) significantly
boosts learning. We also explore "planning", an online alternative to dreaming,
that shows comparable performances. Importantly, our model does not require the
detailed storage of experiences, and learns online the world-model. This is a
key ingredient for biological plausibility and implementability (e.g., in
neuromorphic hardware). Our network is composed of spiking neurons, further
increasing the energetic efficiency and the plausibility of the model. To our
knowledge, there are no previous works proposing biologically plausible
model-based reinforcement learning in recurrent spiking networks. Our work is a
step toward building efficient neuromorphic systems for autonomous robots,
capable of learning new skills in real-world environments. Even when the
environment is no longer accessible, the robot optimizes learning by
"reasoning" in its own "mind". These approaches are of great relevance when the
acquisition from the environment is slow, expensive (robotics) or unsafe
(autonomous driving).</p>
  </details>
</details>
<details>
  <summary>63. <b>标题：Posterior Refinement Improves Sample Efficiency in Bayesian Neural  Networks</b></summary>
  <p><b>编号</b>：[147]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10041</p>
  <p><b>作者</b>：Agustinus Kristiadi,  Runa Eschenhagen,  Philipp Hennig</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Bayesian neural networks, Bayesian neural, neural networks, Monte Carlo, Hamiltonian Monte Carlo</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Monte Carlo (MC) integration is the de facto method for approximating the
predictive distribution of Bayesian neural networks (BNNs). But, even with many
MC samples, Gaussian-based BNNs could still yield bad predictive performance
due to the posterior approximation's error. Meanwhile, alternatives to MC
integration tend to be more expensive or biased. In this work, we
experimentally show that the key to good MC-approximated predictive
distributions is the quality of the approximate posterior itself. However,
previous methods for obtaining accurate posterior approximations are expensive
and non-trivial to implement. We, therefore, propose to refine Gaussian
approximate posteriors with normalizing flows. When applied to last-layer BNNs,
it yields a simple \emph{post hoc} method for improving pre-existing parametric
approximations. We show that the resulting posterior approximation is
competitive with even the gold-standard full-batch Hamiltonian Monte Carlo.</p>
  </details>
</details>
<details>
  <summary>64. <b>标题：Exploring Extreme Parameter Compression for Pre-trained Language Models</b></summary>
  <p><b>编号</b>：[149]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10036</p>
  <p><b>作者</b>：Yuxin Ren,  Benyou Wang,  Lifeng Shang,  Xin Jiang,  Qun Liu</p>
  <p><b>备注</b>：Accepted at ICLR2022. Code available at this https URL</p>
  <p><b>关键词</b>：Transformer-based pre-trained models, Pre-trained Language Models, large-scale Transformer-based pre-trained, natural language processing, Transformer-based pre-trained</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent work explored the potential of large-scale Transformer-based
pre-trained models, especially Pre-trained Language Models (PLMs) in natural
language processing. This raises many concerns from various perspectives, e.g.,
financial costs and carbon emissions. Compressing PLMs like BERT with
negligible performance loss for faster inference and cheaper deployment has
attracted much attention. In this work, we aim to explore larger compression
ratios for PLMs, among which tensor decomposition is a potential but
under-investigated one. Two decomposition and reconstruction protocols are
further proposed to improve the effectiveness and efficiency during
compression. Our compressed BERT with ${1}/{7}$ parameters in Transformer
layers performs on-par with, sometimes slightly better than the original BERT
in GLUE benchmark. A tiny version achieves $96.7\%$ performance of BERT-base
with $ {1}/{48} $ encoder parameters (i.e., less than 2M parameters excluding
the embedding layer) and $2.7 \times$ faster on inference. To show that the
proposed method is orthogonal to existing compression methods like knowledge
distillation, we also explore the benefit of the proposed method on a distilled
BERT.</p>
  </details>
</details>
<details>
  <summary>65. <b>标题：Survey on Fair Reinforcement Learning: Theory and Practice</b></summary>
  <p><b>编号</b>：[151]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10032</p>
  <p><b>作者</b>：Pratik Gajane,  Akrati Saxena,  Maryam Tavakol,  George Fletcher,  Mykola Pechenizkiy</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：usual performance criteria, machine learning techniques, data-driven machine learning, Fairness-aware learning aims, aims at satisfying</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Fairness-aware learning aims at satisfying various fairness constraints in
addition to the usual performance criteria via data-driven machine learning
techniques. Most of the research in fairness-aware learning employs the setting
of fair-supervised learning. However, many dynamic real-world applications can
be better modeled using sequential decision-making problems and fair
reinforcement learning provides a more suitable alternative for addressing
these problems. In this article, we provide an extensive overview of fairness
approaches that have been implemented via a reinforcement learning (RL)
framework. We discuss various practical applications in which RL methods have
been applied to achieve a fair solution with high accuracy. We further include
various facets of the theory of fair reinforcement learning, organizing them
into single-agent RL, multi-agent RL, long-term fairness via RL, and offline
learning. Moreover, we highlight a few major issues to explore in order to
advance the field of fair-RL, namely - i) correcting societal biases, ii)
feasibility of group fairness or individual fairness, and iii) explainability
in RL. Our work is beneficial for both researchers and practitioners as we
discuss articles providing mathematical guarantees as well as articles with
empirical studies on real-world problems.</p>
  </details>
</details>
<details>
  <summary>66. <b>标题：Towards Consistency in Adversarial Classification</b></summary>
  <p><b>编号</b>：[155]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10022</p>
  <p><b>作者</b>：Laurent Meunier,  Raphaël Ettedgui,  Rafael Pinot,  Yann Chevaleyre,  Jamal Atif</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：adversarial, surrogate loss, surrogate, problem, consistency</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we study the problem of consistency in the context of
adversarial examples. Specifically, we tackle the following question: can
surrogate losses still be used as a proxy for minimizing the $0/1$ loss in the
presence of an adversary that alters the inputs at test-time? Different from
the standard classification task, this question cannot be reduced to a
point-wise minimization problem, and calibration needs not to be sufficient to
ensure consistency. In this paper, we expose some pathological behaviors
specific to the adversarial problem, and show that no convex surrogate loss can
be consistent or calibrated in this context. It is therefore necessary to
design another class of surrogate functions that can be used to solve the
adversarial consistency issue. As a first step towards designing such a class,
we identify sufficient and necessary conditions for a surrogate loss to be
calibrated in both the adversarial and standard settings. Finally, we give some
directions for building a class of losses that could be consistent in the
adversarial framework.</p>
  </details>
</details>
<details>
  <summary>67. <b>标题：Predicting electrode array impedance after one month from cochlear  implantation surgery</b></summary>
  <p><b>编号</b>：[156]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10021</p>
  <p><b>作者</b>：Yousef A. Alohali,  Yassin Abdelsamad,  Tamer Mesallam,  Fida Almuhawas,  Abdulrahman Hagr,  Mahmoud S. Fayed</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Sensorineural hearing loss, electrode impedance, electrode, impedance, electrode array</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Sensorineural hearing loss can be treated using Cochlear implantation. After
this surgery using the electrode array impedance measurements, we can check the
stability of the impedance value and the dynamic range. Deterioration of speech
recognition scores could happen because of increased impedance values.
Medicines used to do these measures many times during a year after the surgery.
Predicting the electrode impedance could help in taking decisions to help the
patient get better hearing. In this research we used a dataset of 80 patients
of children who did cochlear implantation using MED-EL FLEX28 electrode array
of 12 channels. We predicted the electrode impedance on each channel after 1
month from the surgery date. We used different machine learning algorithms like
neural networks and decision trees. Our results indicates that the electrode
impedance can be predicted, and the best algorithm is different based on the
electrode channel. Also, the accuracy level varies between 66% and 100% based
on the electrode channel when accepting an error range between 0 and 3 KO.
Further research is required to predict the electrode impedance after three
months, six months and one year.</p>
  </details>
</details>
<details>
  <summary>68. <b>标题：Neural Additive Models for Nowcasting</b></summary>
  <p><b>编号</b>：[157]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10020</p>
  <p><b>作者</b>：Wonkeun Jo,  Dongil Kim</p>
  <p><b>备注</b>：12 pages, 8 figures</p>
  <p><b>关键词</b>：highlighted methods, Deep neural networks, machine learning, Deep neural, additive models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep neural networks (DNNs) are one of the most highlighted methods in
machine learning. However, as DNNs are black-box models, they lack explanatory
power for their predictions. Recently, neural additive models (NAMs) have been
proposed to provide this power while maintaining high prediction performance.
In this paper, we propose a novel NAM approach for multivariate nowcasting (NC)
problems, which comprise an important focus area of machine learning. For the
multivariate time-series data used in NC problems, explanations should be
considered for every input value to the variables at distinguishable time
steps. By employing generalized additive models, the proposed NAM-NC
successfully explains each input value's importance for multiple variables and
time steps. Experimental results involving a toy example and two real-world
datasets show that the NAM-NC predicts multivariate time-series data as
accurately as state-of-the-art neural networks, while also providing the
explanatory importance of each input value. We also examine parameter-sharing
networks using NAM-NC to decrease their complexity, and NAM-MC's hard-tied
feature net extracted explanations with good performance.</p>
  </details>
</details>
<details>
  <summary>69. <b>标题：Translating Hanja historical documents to understandable Korean and  English</b></summary>
  <p><b>编号</b>：[158]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10019</p>
  <p><b>作者</b>：Juhee Son,  Jiho Jin,  Haneul Yoo,  JinYeong Bak,  Kyunghyun Cho,  Alice Oh</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Joseon Dynasty, Korean, translation, Korean and English, archaic Korean</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The Annals of Joseon Dynasty (AJD) contain the daily records of the Kings of
Joseon, the 500-year kingdom preceding the modern nation of Korea. The Annals
were originally written in an archaic Korean writing system, `Hanja', and
translated into Korean from 1968 to 1993. However, this translation was literal
and contained many archaic Korean words; thus, a new expert translation effort
began in 2012, completing the records of only one king in a decade. Also,
expert translators are working on an English translation, of which only one
king's records are available because of the high cost and slow progress. Thus,
we propose H2KE, the neural machine translation model that translates Hanja
historical documents to understandable Korean and English. Based on the
multilingual neural machine translation approach, it translates the historical
document written in Hanja, using both the full dataset of outdated Korean
translation and a small dataset of recently translated Korean and English. We
compare our method with two baselines: one is a recent model that
simultaneously learns to restore and translate Hanja historical document and
the other is the transformer that trained on newly translated corpora only. The
results show that our method significantly outperforms the baselines in terms
of BLEU score in both modern Korean and English translations. We also conduct a
human evaluation that shows that our translation is preferred over the original
expert translation.</p>
  </details>
</details>
<details>
  <summary>70. <b>标题：Self-Paced Multi-Agent Reinforcement Learning</b></summary>
  <p><b>编号</b>：[161]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10016</p>
  <p><b>作者</b>：Wenshuai Zhao,  Joni Pajarinen</p>
  <p><b>备注</b>：13 pages, 9 figures</p>
  <p><b>关键词</b>：number of agents, Curriculum reinforcement learning, reinforcement learning, multi-agent reinforcement learning, aims to speed</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Curriculum reinforcement learning (CRL) aims to speed up learning of a task
by changing gradually the difficulty of the task from easy to hard through
control of factors such as initial state or environment dynamics. While
automating CRL is well studied in the single-agent setting, in multi-agent
reinforcement learning (MARL) an open question is whether control of the number
of agents with other factors in a principled manner is beneficial, prior
approaches typically relying on hand-crafted heuristics. In addition, how the
tasks evolve as the number of agents changes remains understudied, which is
critical for scaling to more challenging tasks. We introduce self-paced MARL
(SPMARL) that enables optimizing the number of agents with other environment
factors in a principled way, and, show that usual assumptions such as that
fewer agents make the task always easier are not generally valid. The
curriculum induced by SPMARL reveals the evolution of tasks w.r.t. number of
agents and experiments show that SPMARL improves the performance when the
number of agents sufficiently influences task difficulty.</p>
  </details>
</details>
<details>
  <summary>71. <b>标题：A Survey of Trustworthy Graph Learning: Reliability, Explainability, and  Privacy Protection</b></summary>
  <p><b>编号</b>：[162]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10014</p>
  <p><b>作者</b>：Bingzhe Wu,  Jintang Li,  Junchi Yu,  Yatao Bian,  Hengtong Zhang,  CHaochao Chen,  Chengbin Hou,  Guoji Fu,  Liang Chen,  Tingyang Xu,  Yu Rong,  Xiaolin Zheng,  Junzhou Huang,  Ran He,  Baoyuan Wu,  GUangyu Sun,  Peng Cui,  Zibin Zheng,  Zhe Liu,  Peilin Zhao</p>
  <p><b>备注</b>：Preprint; Work in progress. arXiv admin note: substantial text overlap with arXiv:2202.07114</p>
  <p><b>关键词</b>：advanced material discovery, scientific areas ranging, Deep graph learning, achieved remarkable progresses, graph learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep graph learning has achieved remarkable progresses in both business and
scientific areas ranging from finance and e-commerce, to drug and advanced
material discovery. Despite these progresses, how to ensure various deep graph
learning algorithms behave in a socially responsible manner and meet regulatory
compliance requirements becomes an emerging problem, especially in
risk-sensitive domains. Trustworthy graph learning (TwGL) aims to solve the
above problems from a technical viewpoint. In contrast to conventional graph
learning research which mainly cares about model performance, TwGL considers
various reliability and safety aspects of the graph learning framework
including but not limited to robustness, explainability, and privacy. In this
survey, we provide a comprehensive review of recent leading approaches in the
TwGL field from three dimensions, namely, reliability, explainability, and
privacy protection. We give a general categorization for existing work and
review typical work for each category. To give further insights for TwGL
research, we provide a unified view to inspect previous works and build the
connection between them. We also point out some important open problems
remaining to be solved in the future developments of TwGL.</p>
  </details>
</details>
<details>
  <summary>72. <b>标题：Constructive Interpretability with CoLabel: Corroborative Integration,  Complementary Features, and Collaborative Learning</b></summary>
  <p><b>编号</b>：[164]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10011</p>
  <p><b>作者</b>：Abhijit Suprem,  Sanjyot Vaidya,  Suma Cherkadi,  Purva Singh,  Joao Eduardo Ferreira,  Calton Pu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：require bias detection, Machine learning models, Machine learning, risk mitigation, increasingly sought</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Machine learning models with explainable predictions are increasingly sought
after, especially for real-world, mission-critical applications that require
bias detection and risk mitigation. Inherent interpretability, where a model is
designed from the ground-up for interpretability, provides intuitive insights
and transparent explanations on model prediction and performance. In this
paper, we present CoLabel, an approach to build interpretable models with
explanations rooted in the ground truth. We demonstrate CoLabel in a vehicle
feature extraction application in the context of vehicle make-model recognition
(VMMR). CoLabel performs VMMR with a composite of interpretable features such
as vehicle color, type, and make, all based on interpretable annotations of the
ground truth labels. First, CoLabel performs corroborative integration to join
multiple datasets that each have a subset of desired annotations of color,
type, and make. Then, CoLabel uses decomposable branches to extract
complementary features corresponding to desired annotations. Finally, CoLabel
fuses them together for final predictions. During feature fusion, CoLabel
harmonizes complementary branches so that VMMR features are compatible with
each other and can be projected to the same semantic space for classification.
With inherent interpretability, CoLabel achieves superior performance to the
state-of-the-art black-box models, with accuracy of 0.98, 0.95, and 0.94 on
CompCars, Cars196, and BoxCars116K, respectively. CoLabel provides intuitive
explanations due to constructive interpretability, and subsequently achieves
high accuracy and usability in mission-critical situations.</p>
  </details>
</details>
<details>
  <summary>73. <b>标题：The price of ignorance: how much does it cost to forget noise structure  in low-rank matrix estimation?</b></summary>
  <p><b>编号</b>：[165]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10009</p>
  <p><b>作者</b>：Jean Barbier,  TianQi Hou,  Marco Mondelli,  Manuel Sáenz</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：structured rotationally invariant, rotationally invariant noise, inference algorithms perform, corrupted by structured, structured rotationally</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We consider the problem of estimating a rank-1 signal corrupted by structured
rotationally invariant noise, and address the following question: how well do
inference algorithms perform when the noise statistics is unknown and hence
Gaussian noise is assumed? While the matched Bayes-optimal setting with
unstructured noise is well understood, the analysis of this mismatched problem
is only at its premises. In this paper, we make a step towards understanding
the effect of the strong source of mismatch which is the noise statistics. Our
main technical contribution is the rigorous analysis of a Bayes estimator and
of an approximate message passing (AMP) algorithm, both of which incorrectly
assume a Gaussian setup. The first result exploits the theory of spherical
integrals and of low-rank matrix perturbations; the idea behind the second one
is to design and analyze an artificial AMP which, by taking advantage of the
flexibility in the denoisers, is able to "correct" the mismatch. Armed with
these sharp asymptotic characterizations, we unveil a rich and often unexpected
phenomenology. For example, despite AMP is in principle designed to efficiently
compute the Bayes estimator, the former is outperformed by the latter in terms
of mean-square error. We show that this performance gap is due to an incorrect
estimation of the signal norm. In fact, when the SNR is large enough, the
overlaps of the AMP and the Bayes estimator coincide, and they even match those
of optimal estimators taking into account the structure of the noise.</p>
  </details>
</details>
<details>
  <summary>74. <b>标题：Self-Supervised Depth Estimation with Isometric-Self-Sample-Based  Learning</b></summary>
  <p><b>编号</b>：[167]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10006</p>
  <p><b>作者</b>：Geonho Cha,  Ho-Deok Jang,  Dongyoon Wee</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：photometric loss formulation, self-supervised depth estimation, dynamic regions, photometric loss, loss formulation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Managing the dynamic regions in the photometric loss formulation has been a
main issue for handling the self-supervised depth estimation problem. Most
previous methods have alleviated this issue by removing the dynamic regions in
the photometric loss formulation based on the masks estimated from another
module, making it difficult to fully utilize the training images. In this
paper, to handle this problem, we propose an isometric self-sample-based
learning (ISSL) method to fully utilize the training images in a simple yet
effective way. The proposed method provides additional supervision during
training using self-generated images that comply with pure static scene
assumption. Specifically, the isometric self-sample generator synthesizes
self-samples for each training image by applying random rigid transformations
on the estimated depth. Thus both the generated self-samples and the
corresponding training image always follow the static scene assumption. We show
that plugging our ISSL module into several existing models consistently
improves the performance by a large margin. In addition, it also boosts the
depth accuracy over different types of scene, i.e., outdoor scenes (KITTI and
Make3D) and indoor scene (NYUv2), validating its high effectiveness.</p>
  </details>
</details>
<details>
  <summary>75. <b>标题：RiskLoc: Localization of Multi-dimensional Root Causes by Weighted Risk</b></summary>
  <p><b>编号</b>：[168]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10004</p>
  <p><b>作者</b>：Marcus Kalander</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：large-scale software systems, Failures and anomalies, unavoidable incidents, anomalies in large-scale, large-scale software</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Failures and anomalies in large-scale software systems are unavoidable
incidents. When an issue is detected, operators need to quickly and correctly
identify its location to facilitate a swift repair. In this work, we consider
the problem of identifying the root cause set that best explains an anomaly in
multi-dimensional time series with categorical attributes. The huge search
space is the main challenge, even for a small number of attributes and small
value sets, the number of theoretical combinations is too large to brute force.
Previous approaches have thus focused on reducing the search space, but they
all suffer from various issues, requiring extensive manual parameter tuning,
being too slow and thus impractical, or being incapable of finding more complex
root causes. We propose RiskLoc to solve the problem of multidimensional root
cause localization. RiskLoc applies a 2-way partitioning scheme and assigns
element weights that linearly increase with the distance from the partitioning
point. A risk score is assigned to each element that integrates two factors, 1)
its weighted proportion within the abnormal partition, and 2) the relative
change in the deviation score adjusted for the ripple effect property.
Extensive experiments on multiple datasets verify the effectiveness and
efficiency of RiskLoc, and for a comprehensive evaluation, we introduce three
synthetically generated datasets that complement existing datasets. We
demonstrate that RiskLoc consistently outperforms state-of-the-art baselines,
especially in more challenging root cause scenarios, with gains in F1-score up
to 57% over the second-best approach with comparable running times.</p>
  </details>
</details>
<details>
  <summary>76. <b>标题：Planning with Diffusion for Flexible Behavior Synthesis</b></summary>
  <p><b>编号</b>：[174]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09991</p>
  <p><b>作者</b>：Michael Janner,  Yilun Du,  Joshua B. Tenenbaum,  Sergey Levine</p>
  <p><b>备注</b>：ICML 2022 (long talk). Project page and code at this https URL</p>
  <p><b>关键词</b>：Model-based reinforcement learning, classical trajectory optimizers, approximate dynamics model, reinforcement learning methods, reinforcement learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Model-based reinforcement learning methods often use learning only for the
purpose of estimating an approximate dynamics model, offloading the rest of the
decision-making work to classical trajectory optimizers. While conceptually
simple, this combination has a number of empirical shortcomings, suggesting
that learned models may not be well-suited to standard trajectory optimization.
In this paper, we consider what it would look like to fold as much of the
trajectory optimization pipeline as possible into the modeling problem, such
that sampling from the model and planning with it become nearly identical. The
core of our technical approach lies in a diffusion probabilistic model that
plans by iteratively denoising trajectories. We show how classifier-guided
sampling and image inpainting can be reinterpreted as coherent planning
strategies, explore the unusual and useful properties of diffusion-based
planning methods, and demonstrate the effectiveness of our framework in control
settings that emphasize long-horizon decision-making and test-time flexibility.</p>
  </details>
</details>
<details>
  <summary>77. <b>标题：Set-based Meta-Interpolation for Few-Task Meta-Learning</b></summary>
  <p><b>编号</b>：[175]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09990</p>
  <p><b>作者</b>：Seanie Lee,  Bruno Andreis,  Kenji Kawaguchi,  Juho Lee,  Sung Ju Hwang</p>
  <p><b>备注</b>：First two authors contributed equally. Name order decided by a coin toss</p>
  <p><b>关键词</b>：Meta-learning approaches enable, approaches enable machine, enable machine learning, machine learning systems, Meta-learning approaches</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Meta-learning approaches enable machine learning systems to adapt to new
tasks given few examples by leveraging knowledge from related tasks. However, a
large number of meta-training tasks are still required for generalization to
unseen tasks during meta-testing, which introduces a critical bottleneck for
real-world problems that come with only few tasks, due to various reasons
including the difficulty and cost of constructing tasks. Recently, several task
augmentation methods have been proposed to tackle this issue using
domain-specific knowledge to design augmentation techniques to densify the
meta-training task distribution. However, such reliance on domain-specific
knowledge renders these methods inapplicable to other domains. While Manifold
Mixup based task augmentation methods are domain-agnostic, we empirically find
them ineffective on non-image domains. To tackle these limitations, we propose
a novel domain-agnostic task augmentation method, Meta-Interpolation, which
utilizes expressive neural set functions to densify the meta-training task
distribution using bilevel optimization. We empirically validate the efficacy
of Meta-Interpolation on eight datasets spanning across various domains such as
image classification, molecule property prediction, text classification and
speech recognition. Experimentally, we show that Meta-Interpolation
consistently outperforms all the relevant baselines. Theoretically, we prove
that task interpolation with the set function regularizes the meta-learner to
improve generalization.</p>
  </details>
</details>
<details>
  <summary>78. <b>标题：SafeNet: Mitigating Data Poisoning Attacks on Private Machine Learning</b></summary>
  <p><b>编号</b>：[178]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09986</p>
  <p><b>作者</b>：Harsh Chaudhari,  Matthew Jagielski,  Alina Oprea</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Secure multiparty computation, distrustful data owners, mutually distrustful data, multiple mutually distrustful, jointly train machine</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Secure multiparty computation (MPC) has been proposed to allow multiple
mutually distrustful data owners to jointly train machine learning (ML) models
on their combined data. However, the datasets used for training ML models might
be under the control of an adversary mounting a data poisoning attack, and MPC
prevents inspecting training sets to detect poisoning. We show that multiple
MPC frameworks for private ML training are susceptible to backdoor and targeted
poisoning attacks. To mitigate this, we propose SafeNet, a framework for
building ensemble models in MPC with formal guarantees of robustness to data
poisoning attacks. We extend the security definition of private ML training to
account for poisoning and prove that our SafeNet design satisfies the
definition. We demonstrate SafeNet's efficiency, accuracy, and resilience to
poisoning on several machine learning datasets and models. For instance,
SafeNet reduces backdoor attack success from 100% to 0% for a neural network
model, while achieving 39x faster training and 36x less communication than the
four-party MPC framework of Dalskov et al.</p>
  </details>
</details>
<details>
  <summary>79. <b>标题：HeadText: Exploring Hands-free Text Entry using Head Gestures by Motion  Sensing on a Smart Earpiece</b></summary>
  <p><b>编号</b>：[180]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09978</p>
  <p><b>作者</b>：Songlin Xu,  Guanjie Wang,  Ziyuan Fang,  Guangwei Zhang,  Guangzhu Shang,  Rongde Lu,  Liqun He</p>
  <p><b>备注</b>：23 pages</p>
  <p><b>关键词</b>：Dynamic Time Warping, text entry, text, smart earpiece, motion sensing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present HeadText, a hands-free technique on a smart earpiece for text
entry by motion sensing. Users input text utilizing only 7 head gestures for
key selection, word selection, word commitment and word cancelling tasks. Head
gesture recognition is supported by motion sensing on a smart earpiece to
capture head moving signals and machine learning algorithms (K-Nearest-Neighbor
(KNN) with a Dynamic Time Warping (DTW) distance measurement). A 10-participant
user study proved that HeadText could recognize 7 head gestures at an accuracy
of 94.29%. After that, the second user study presented that HeadText could
achieve a maximum accuracy of 10.65 WPM and an average accuracy of 9.84 WPM for
text entry. Finally, we demonstrate potential applications of HeadText in
hands-free scenarios for (a). text entry of people with motor impairments, (b).
private text entry, and (c). socially acceptable text entry.</p>
  </details>
</details>
<details>
  <summary>80. <b>标题：FairNorm: Fair and Fast Graph Neural Network Training</b></summary>
  <p><b>编号</b>：[181]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09977</p>
  <p><b>作者</b>：O. Deniz Kose,  Yanning Shen</p>
  <p><b>备注</b>：23 pages, 1 figures, 6 tables</p>
  <p><b>关键词</b>：Graph neural networks, Graph neural, demonstrated to achieve, graph-based learning tasks, learning tasks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Graph neural networks (GNNs) have been demonstrated to achieve
state-of-the-art for a number of graph-based learning tasks, which leads to a
rise in their employment in various domains. However, it has been shown that
GNNs may inherit and even amplify bias within training data, which leads to
unfair results towards certain sensitive groups. Meanwhile, training of GNNs
introduces additional challenges, such as slow convergence and possible
instability. Faced with these limitations, this work proposes FairNorm, a
unified normalization framework that reduces the bias in GNN-based learning
while also providing provably faster convergence. Specifically, FairNorm
employs fairness-aware normalization operators over different sensitive groups
with learnable parameters to reduce the bias in GNNs. The design of FairNorm is
built upon analyses that illuminate the sources of bias in graph-based
learning. Experiments on node classification over real-world networks
demonstrate the efficiency of the proposed scheme in improving fairness in
terms of statistical parity and equal opportunity compared to fairness-aware
baselines. In addition, it is empirically shown that the proposed framework
leads to faster convergence compared to the naive baseline where no
normalization is employed.</p>
  </details>
</details>
<details>
  <summary>81. <b>标题：A New Feature Selection Method for LogNNet and its Application for  Diagnosis and Prognosis of COVID-19 Disease Using Routine Blood Values</b></summary>
  <p><b>编号</b>：[182]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09974</p>
  <p><b>作者</b>：Mehmet Tahir Huyut,  Andrei Velichko</p>
  <p><b>备注</b>：22 pages, 6 figures, 11 Tables</p>
  <p><b>关键词</b>：world has embarked, intense struggle, disease, diagnosis, features</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Since February-2020, the world has embarked on an intense struggle with the
COVID-19 disease, and health systems have come under a tragic pressure as the
disease turned into a pandemic. The aim of this study is to determine the most
effective routine-blood-values (RBV) in the diagnosis/prognosis of COVID-19
using new feature selection method for LogNNet reservoir neural network. First
dataset in this study consists of a total of 5296-patients with a same number
of negative and positive covid test. Second dataset consists of a total of
3899-patients with a diagnosis of COVID-19, who were treated in hospital with
severe-infected (203) and mildly-infected (3696). The most important RBVs that
affect the diagnosis of the disease from the first dataset were
mean-corpuscular-hemoglobin-concentration (MCHC), mean-corpuscular-hemoglobin
(MCH) and activated-partial-prothrombin-time (aPTT). The most effective
features in the prognosis of the disease were erythrocyte-sedimentation-rate
(ESR), neutrophil-count (NEU), C-reactive-protein (CRP). LogNNet-model achieved
an accuracy rate of A46 = 99.5% in the diagnosis of the disease with 46
features and A3 = 99.17% with only MCHC, MCH, and aPTT features. Model reached
an accuracy rate of A48 = 94.4% in determining the prognosis of the disease
with 48 features and A3 = 82.7% with only ESR, NEU, and CRP features. LogNNet
model demonstrated a very high disease diagnosis/prognosis of COVID-19
performance without knowing about the symptoms or history of the patients. The
model is suitable for devices with low resources (3-14 kB of RAM used on the
Arduino microcontroller), and is promising to create mobile health monitoring
systems in the Internet of Things. Our method will reduce the negative
pressures on the health sector and help doctors understand pathogenesis of
COVID-19 through key futures and contribute positively to the treatment
processes.</p>
  </details>
</details>
<details>
  <summary>82. <b>标题：On Tackling Explanation Redundancy in Decision Trees</b></summary>
  <p><b>编号</b>：[184]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09971</p>
  <p><b>作者</b>：Yacine Izza,  Alexey Ignatiev,  Joao Marques-Silva</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Decision trees, Decision, trees, epitomize the ideal, explanation redundancy</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Decision trees (DTs) epitomize the ideal of interpretability of machine
learning (ML) models. The interpretability of decision trees motivates
explainability approaches by so-called intrinsic interpretability, and it is at
the core of recent proposals for applying interpretable ML models in high-risk
applications. The belief in DT interpretability is justified by the fact that
explanations for DT predictions are generally expected to be succinct. Indeed,
in the case of DTs, explanations correspond to DT paths. Since decision trees
are ideally shallow, and so paths contain far fewer features than the total
number of features, explanations in DTs are expected to be succinct, and hence
interpretable. This paper offers both theoretical and experimental arguments
demonstrating that, as long as interpretability of decision trees equates with
succinctness of explanations, then decision trees ought not be deemed
interpretable. The paper introduces logically rigorous path explanations and
path explanation redundancy, and proves that there exist functions for which
decision trees must exhibit paths with arbitrarily large explanation
redundancy. The paper also proves that only a very restricted class of
functions can be represented with DTs that exhibit no explanation redundancy.
In addition, the paper includes experimental results substantiating that path
explanation redundancy is observed ubiquitously in decision trees, including
those obtained using different tree learning algorithms, but also in a wide
range of publicly available decision trees. The paper also proposes
polynomial-time algorithms for eliminating path explanation redundancy, which
in practice require negligible time to compute. Thus, these algorithms serve to
indirectly attain irreducible, and so succinct, explanations for decision
trees.</p>
  </details>
</details>
<details>
  <summary>83. <b>标题：A General Framework for quantifying Aleatoric and Epistemic uncertainty  in Graph Neural Networks</b></summary>
  <p><b>编号</b>：[185]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09968</p>
  <p><b>作者</b>：Sai Munikoti,  Deepesh Agarwal,  Laya Das,  Balasubramaniam Natarajan</p>
  <p><b>备注</b>：10 pages, 1 figure, 6 Tables</p>
  <p><b>关键词</b>：Graph Neural Networks, Neural Networks, elegantly integrates Graph, integrates Graph theory, Graph Neural</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Graph Neural Networks (GNN) provide a powerful framework that elegantly
integrates Graph theory with Machine learning for modeling and analysis of
networked data. We consider the problem of quantifying the uncertainty in
predictions of GNN stemming from modeling errors and measurement uncertainty.
We consider aleatoric uncertainty in the form of probabilistic links and noise
in feature vector of nodes, while epistemic uncertainty is incorporated via a
probability distribution over the model parameters. We propose a unified
approach to treat both sources of uncertainty in a Bayesian framework, where
Assumed Density Filtering is used to quantify aleatoric uncertainty and Monte
Carlo dropout captures uncertainty in model parameters. Finally, the two
sources of uncertainty are aggregated to estimate the total uncertainty in
predictions of a GNN. Results in the real-world datasets demonstrate that the
Bayesian model performs at par with a frequentist model and provides additional
information about predictions uncertainty that are sensitive to uncertainties
in the data and model.</p>
  </details>
</details>
<details>
  <summary>84. <b>标题：A Fully Controllable Agent in the Path Planning using Goal-Conditioned  Reinforcement Learning</b></summary>
  <p><b>编号</b>：[186]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09967</p>
  <p><b>作者</b>：GyeongTaek Lee</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：path planning, agent, starting point, point by searching, reach</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The aim of path planning is to reach the goal from starting point by
searching for the route of an agent. In the path planning, the routes may vary
depending on the number of variables such that it is important for the agent to
reach various goals. Numerous studies, however, have dealt with a single goal
that is predefined by the user. In the present study, I propose a novel
reinforcement learning framework for a fully controllable agent in the path
planning. To do this, I propose a bi-directional memory editing to obtain
various bi-directional trajectories of the agent, in which the behavior of the
agent and sub-goals are trained on the goal-conditioned RL. As for moving the
agent in various directions, I utilize the sub-goals dedicated network,
separated from a policy network. Lastly, I present the reward shaping to
shorten the number of steps for the agent to reach the goal. In the
experimental result, the agent was able to reach the various goals that have
never been visited by the agent in the training. We confirmed that the agent
could perform difficult missions such as a round trip and the agent used the
shorter route with the reward shaping.</p>
  </details>
</details>
<details>
  <summary>85. <b>标题：Sample Complexity of Learning Heuristic Functions for Greedy-Best-First  and A* Search</b></summary>
  <p><b>编号</b>：[188]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09963</p>
  <p><b>作者</b>：Shinsaku Sakaue,  Taihei Oki</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Greedy best-first search, heuristic functions, learning heuristic functions, best-first search, GBFS</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Greedy best-first search (GBFS) and A* search (A*) are popular algorithms for
path-finding on large graphs. Both use so-called heuristic functions, which
estimate how close a vertex is to the goal. While heuristic functions have been
handcrafted using domain knowledge, recent studies demonstrate that learning
heuristic functions from data is effective in many applications. Motivated by
this emerging approach, we study the sample complexity of learning heuristic
functions for GBFS and A*. We build on a recent framework called
\textit{data-driven algorithm design} and evaluate the
\textit{pseudo-dimension} of a class of utility functions that measure the
performance of parameterized algorithms. Assuming that a vertex set of size $n$
is fixed, we present $\mathrm{O}(n\lg n)$ and $\mathrm{O}(n^2\lg n)$ upper
bounds on the pseudo-dimensions for GBFS and A*, respectively, parameterized by
heuristic function values. The upper bound for A* can be improved to
$\mathrm{O}(n^2\lg d)$ if every vertex has a degree of at most $d$ and to
$\mathrm{O}(n \lg n)$ if edge weights are integers bounded by
$\mathrm{poly}(n)$. We also give $\Omega(n)$ lower bounds for GBFS and A*,
which imply that our bounds for GBFS and A* under the integer-weight condition
are tight up to a $\lg n$ factor. Finally, we discuss a case where the
performance of A* is measured by the suboptimality and show that we can
sometimes obtain a better guarantee by combining a parameter-dependent
worst-case bound with a sample complexity bound.</p>
  </details>
</details>
<details>
  <summary>86. <b>标题：Discrete-Convex-Analysis-Based Framework for Warm-Starting Algorithms  with Predictions</b></summary>
  <p><b>编号</b>：[190]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09961</p>
  <p><b>作者</b>：Shinsaku Sakaue,  Taihei Oki</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Augmenting algorithms, promising approach, perfect bipartite matching, algorithms with learned, time complexity</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Augmenting algorithms with learned predictions is a promising approach for
going beyond worst-case bounds. Dinitz, Im, Lavastida, Moseley, and
Vassilvitskii~(2021) have demonstrated that a warm start with learned dual
solutions can improve the time complexity of the Hungarian method for weighted
perfect bipartite matching. We extend and improve their framework in a
principled manner via \textit{discrete convex analysis} (DCA), a discrete
analog of convex analysis. We show the usefulness of our DCA-based framework by
applying it to weighted perfect bipartite matching, weighted matroid
intersection, and discrete energy minimization for computer vision. Our
DCA-based framework yields time complexity bounds that depend on the
$\ell_\infty$-distance from a predicted solution to an optimal solution, which
has two advantages relative to the previous $\ell_1$-distance-dependent bounds:
time complexity bounds are smaller, and learning of predictions is more sample
efficient. We also discuss whether to learn primal or dual solutions from the
DCA perspective.</p>
  </details>
</details>
<details>
  <summary>87. <b>标题：Explainable Supervised Domain Adaptation</b></summary>
  <p><b>编号</b>：[198]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09943</p>
  <p><b>作者</b>：Vidhya Kamakshi,  Narayanan C Krishnan</p>
  <p><b>备注</b>：Accepted as a Poster presentation at IJCNN at IEEE-WCCI 2022</p>
  <p><b>关键词</b>：Domain adaptation, success of deep, Domain, Domain adaptation techniques, deep learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Domain adaptation techniques have contributed to the success of deep
learning. Leveraging knowledge from an auxiliary source domain for learning in
labeled data-scarce target domain is fundamental to domain adaptation. While
these techniques result in increasing accuracy, the adaptation process,
particularly the knowledge leveraged from the source domain, remains unclear.
This paper proposes an explainable by design supervised domain adaptation
framework - XSDA-Net. We integrate a case-based reasoning mechanism into the
XSDA-Net to explain the prediction of a test instance in terms of
similar-looking regions in the source and target train images. We empirically
demonstrate the utility of the proposed framework by curating the domain
adaptation settings on datasets popularly known to exhibit part-based
explainability.</p>
  </details>
</details>
<details>
  <summary>88. <b>标题：Towards Explanation for Unsupervised Graph-Level Representation Learning</b></summary>
  <p><b>编号</b>：[200]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09934</p>
  <p><b>作者</b>：Qinghua Zheng,  Jihong Wang,  Minnan Luo,  Yaoliang Yu,  Jundong Li,  Lina Yao,  Xiaojun Chang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Graph Neural Networks, Existing explanation methods, Neural Networks, GNN explanation problem, graph-level representation learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Due to the superior performance of Graph Neural Networks (GNNs) in various
domains, there is an increasing interest in the GNN explanation problem
"\emph{which fraction of the input graph is the most crucial to decide the
model's decision?}" Existing explanation methods focus on the supervised
settings, \eg, node classification and graph classification, while the
explanation for unsupervised graph-level representation learning is still
unexplored. The opaqueness of the graph representations may lead to unexpected
risks when deployed for high-stake decision-making scenarios. In this paper, we
advance the Information Bottleneck principle (IB) to tackle the proposed
explanation problem for unsupervised graph representations, which leads to a
novel principle, \textit{Unsupervised Subgraph Information Bottleneck} (USIB).
We also theoretically analyze the connection between graph representations and
explanatory subgraphs on the label space, which reveals that the expressiveness
and robustness of representations benefit the fidelity of explanatory
subgraphs. Experimental results on both synthetic and real-world datasets
demonstrate the superiority of our developed explainer and the validity of our
theoretical analysis.</p>
  </details>
</details>
<details>
  <summary>89. <b>标题：BayesPCN: A Continually Learnable Predictive Coding Associative Memory</b></summary>
  <p><b>编号</b>：[203]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09930</p>
  <p><b>作者</b>：Jason Yoo,  Frank Wood</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：machine learning, plays an important, important role, role in human, human intelligence</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Associative memory plays an important role in human intelligence and its
mechanisms have been linked to attention in machine learning. While the machine
learning community's interest in associative memories has recently been
rekindled, most work has focused on memory recall ($read$) over memory learning
($write$). In this paper, we present BayesPCN, a hierarchical associative
memory capable of performing continual one-shot memory writes without
meta-learning. Moreover, BayesPCN is able to gradually forget past observations
($forget$) to free its memory. Experiments show that BayesPCN can recall
corrupted i.i.d. high-dimensional data observed hundreds of "timesteps" ago
without a significant drop in recall ability compared to the state-of-the-art
offline-learned associative memory models.</p>
  </details>
</details>
<details>
  <summary>90. <b>标题：Cross Reconstruction Transformer for Self-Supervised Time Series  Representation Learning</b></summary>
  <p><b>编号</b>：[204]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09928</p>
  <p><b>作者</b>：Wenrui Zhang,  Ling Yang,  Shijia Geng,  Shenda Hong</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：time series, real-world scenarios, self-supervised representation learning, critical since labeled, labeled samples</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Unsupervised/self-supervised representation learning in time series is
critical since labeled samples are usually scarce in real-world scenarios.
Existing approaches mainly leverage the contrastive learning framework, which
automatically learns to understand the similar and dissimilar data pairs.
Nevertheless, they are restricted to the prior knowledge of constructing pairs,
cumbersome sampling policy, and unstable performances when encountering
sampling bias. Also, few works have focused on effectively modeling across
temporal-spectral relations to extend the capacity of representations. In this
paper, we aim at learning representations for time series from a new
perspective and propose Cross Reconstruction Transformer (CRT) to solve the
aforementioned problems in a unified way. CRT achieves time series
representation learning through a cross-domain dropping-reconstruction task.
Specifically, we transform time series into the frequency domain and randomly
drop certain parts in both time and frequency domains. Dropping can maximally
preserve the global context compared to cropping and masking. Then a
transformer architecture is utilized to adequately capture the cross-domain
correlations between temporal and spectral information through reconstructing
data in both domains, which is called Dropped Temporal-Spectral Modeling. To
discriminate the representations in global latent space, we propose Instance
Discrimination Constraint to reduce the mutual information between different
time series and sharpen the decision boundaries. Additionally, we propose a
specified curriculum learning strategy to optimize the CRT, which progressively
increases the dropping ratio in the training process.</p>
  </details>
</details>
<details>
  <summary>91. <b>标题：CertiFair: A Framework for Certified Global Fairness of Neural Networks</b></summary>
  <p><b>编号</b>：[205]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09927</p>
  <p><b>作者</b>：Haitham Khedr,  Yasser Shoukry</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Neural Network, global individual fairness, individual fairness, similar individuals, satisfies global individual</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We consider the problem of whether a Neural Network (NN) model satisfies
global individual fairness. Individual Fairness suggests that similar
individuals with respect to a certain task are to be treated similarly by the
decision model. In this work, we have two main objectives. The first is to
construct a verifier which checks whether the fairness property holds for a
given NN in a classification task or provide a counterexample if it is
violated, i.e., the model is fair if all similar individuals are classified the
same, and unfair if a pair of similar individuals are classified differently.
To that end, We construct a sound and complete verifier that verifies global
individual fairness properties of ReLU NN classifiers using distance-based
similarity metrics. The second objective of this paper is to provide a method
for training provably fair NN classifiers from unfair (biased) data. We propose
a fairness loss that can be used during training to enforce fair outcomes for
similar individuals. We then provide provable bounds on the fairness of the
resulting NN. We run experiments on commonly used fairness datasets that are
publicly available and we show that global individual fairness can be improved
by 96 % without significant drop in test accuracy.</p>
  </details>
</details>
<details>
  <summary>92. <b>标题：On Jointly Optimizing Partial Offloading and SFC Mapping: A Cooperative  Dual-agent Deep Reinforcement Learning Approach</b></summary>
  <p><b>编号</b>：[206]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09925</p>
  <p><b>作者</b>：Xinhan Wang,  Huanlai Xing,  Fuhong Song,  Shouxi Luo,  Penglin Dai,  Bowen Zhao</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：support emerging IoT, network function virtualization, emerging IoT applications, Multi-access edge computing, MEC</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Multi-access edge computing (MEC) and network function virtualization (NFV)
are promising technologies to support emerging IoT applications, especially
those computation-intensive. In NFV-enabled MEC environment, service function
chain (SFC), i.e., a set of ordered virtual network functions (VNFs), can be
mapped on MEC servers. Mobile devices (MDs) can offload computation-intensive
applications, which can be represented by SFCs, fully or partially to MEC
servers for remote execution. This paper studies the partial offloading and SFC
mapping joint optimization (POSMJO) problem in an NFV-enabled MEC system, where
an incoming task can be partitioned into two parts, one for local execution and
the other for remote execution. The objective is to minimize the average cost
in the long term which is a combination of execution delay, MD's energy
consumption, and usage charge for edge computing. This problem consists of two
closely related decision-making steps, namely task partition and VNF placement,
which is highly complex and quite challenging. To address this, we propose a
cooperative dual-agent deep reinforcement learning (CDADRL) algorithm, where we
design a framework enabling interaction between two agents. Simulation results
show that the proposed algorithm outperforms three combinations of deep
reinforcement learning algorithms in terms of cumulative and average episodic
rewards and it overweighs a number of baseline algorithms with respect to
execution delay, energy consumption, and usage charge.</p>
  </details>
</details>
<details>
  <summary>93. <b>标题：Anomaly Detection for Multivariate Time Series on Large-scale Fluid  Handling Plant Using Two-stage Autoencoder</b></summary>
  <p><b>编号</b>：[207]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09924</p>
  <p><b>作者</b>：Susumu Naito,  Yasunori Taguchi,  Kouta Nakata,  Yuichi Kato</p>
  <p><b>备注</b>：The 2nd Workshop on Large-scale Industrial Time Series Analysis at the 21st IEEE International Conference on Data Mining (ICDM), 2021</p>
  <p><b>关键词</b>：multivariate time series, time series data, large-scale fluid handling, fluid handling plants, anomaly detection</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper focuses on anomaly detection for multivariate time series data in
large-scale fluid handling plants with dynamic components, such as power
generation, water treatment, and chemical plants, where signals from various
physical phenomena are observed simultaneously. In these plants, the need for
anomaly detection techniques is increasing in order to reduce the cost of
operation and maintenance, in view of a decline in the number of skilled
engineers and a shortage of manpower. However, considering the complex behavior
of high-dimensional signals and the demand for interpretability, the techniques
constitute a major challenge. We introduce a Two-Stage AutoEncoder (TSAE) as an
anomaly detection method suitable for such plants. This is a simple autoencoder
architecture that makes anomaly detection more interpretable and more accurate,
in which based on the premise that plant signals can be separated into two
behaviors that have almost no correlation with each other, the signals are
separated into long-term and short-term components in a stepwise manner, and
the two components are trained independently to improve the inference
capability for normal signals. Through experiments on two publicly available
datasets of water treatment systems, we have confirmed the high detection
performance, the validity of the premise, and that the model behavior was as
intended, i.e., the technical effectiveness of TSAE.</p>
  </details>
</details>
<details>
  <summary>94. <b>标题：KERPLE: Kernelized Relative Positional Embedding for Length  Extrapolation</b></summary>
  <p><b>编号</b>：[209]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09921</p>
  <p><b>作者</b>：Ta-Chung Chi,  Ting-Han Fan,  Peter J. Ramadge,  Alexander I. Rudnicky</p>
  <p><b>备注</b>：The first two authors contributed equally to this work</p>
  <p><b>关键词</b>：received considerable attention, RPEs effectively model, received considerable, considerable attention, effectively model</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Relative positional embeddings (RPE) have received considerable attention
since RPEs effectively model the relative distance among tokens and enable
length extrapolation. We propose KERPLE, a framework that generalizes relative
position embedding for extrapolation by kernelizing positional differences. We
achieve this goal using conditionally positive definite (CPD) kernels, a class
of functions known for generalizing distance metrics. To maintain the inner
product interpretation of self-attention, we show that a CPD kernel can be
transformed into a PD kernel by adding a constant offset. This offset is
implicitly absorbed in the Softmax normalization during self-attention. The
diversity of CPD kernels allows us to derive various RPEs that enable length
extrapolation in a principled way. Experiments demonstrate that the logarithmic
variant achieves excellent extrapolation performance on three large language
modeling datasets.</p>
  </details>
</details>
<details>
  <summary>95. <b>标题：Can Foundation Models Wrangle Your Data?</b></summary>
  <p><b>编号</b>：[210]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09911</p>
  <p><b>作者</b>：Avanika Narayan,  Ines Chami,  Laurel Orr,  Christopher Ré</p>
  <p><b>备注</b>：12 pages, 5 figures</p>
  <p><b>关键词</b>：task-specific finetuning, Models, tasks, Foundation Models, cleaning and integration</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Foundation Models (FMs) are models trained on large corpora of data that, at
very large scale, can generalize to new tasks without any task-specific
finetuning. As these models continue to grow in size, innovations continue to
push the boundaries of what these models can do on language and image tasks.
This paper aims to understand an underexplored area of FMs: classical data
tasks like cleaning and integration. As a proof-of-concept, we cast three data
cleaning and integration tasks as prompting tasks and evaluate the performance
of FMs on these tasks. We find that large FMs generalize and achieve SoTA
performance on data cleaning and integration tasks, even though they are not
trained for these data tasks. We identify specific research challenges and
opportunities that these models present, including challenges with private and
temporal data, and opportunities to make data driven systems more accessible to
non-experts. We make our code and experiments publicly available at:
this https URL.</p>
  </details>
</details>
<details>
  <summary>96. <b>标题：Minimal Explanations for Neural Network Predictions</b></summary>
  <p><b>编号</b>：[213]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09901</p>
  <p><b>作者</b>：Ouns El Harzli,  Bernardo Cuenca Grau,  Ian Horrocks</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Explaining neural network, neural model predictions, model prediction, neural, neural model</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Explaining neural network predictions is known to be a challenging problem.
In this paper, we propose a novel approach which can be effectively exploited,
either in isolation or in combination with other methods, to enhance the
interpretability of neural model predictions. For a given input to a trained
neural model, our aim is to compute a smallest set of input features so that
the model prediction changes when these features are disregarded by setting
them to an uninformative baseline value. While computing such minimal
explanations is computationally intractable in general for fully-connected
neural networks, we show that the problem becomes solvable in polynomial time
by a greedy algorithm under mild assumptions on the network's activation
functions. We then show that our tractability result extends seamlessly to more
advanced neural architectures such as convolutional and graph neural networks.
We conduct experiments to showcase the capability of our method for identifying
the input features that are essential to the model's prediction.</p>
  </details>
</details>
<details>
  <summary>97. <b>标题：Let the Model Decide its Curriculum for Multitask Learning</b></summary>
  <p><b>编号</b>：[214]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09898</p>
  <p><b>作者</b>：Neeraj Varshney,  Swaroop Mishra,  Chitta Baral</p>
  <p><b>备注</b>：NAACL 2022 Deep Learning for Low-Resource NLP Workshop</p>
  <p><b>关键词</b>：prior multi-task learning, human perception, strategies in prior, prior multi-task, exhaustively searching</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Curriculum learning strategies in prior multi-task learning approaches
arrange datasets in a difficulty hierarchy either based on human perception or
by exhaustively searching the optimal arrangement. However, human perception of
difficulty may not always correlate well with machine interpretation leading to
poor performance and exhaustive search is computationally expensive. Addressing
these concerns, we propose two classes of techniques to arrange training
instances into a learning curriculum based on difficulty scores computed via
model-based approaches. The two classes i.e Dataset-level and Instance-level
differ in granularity of arrangement. Through comprehensive experiments with 12
datasets, we show that instance-level and dataset-level techniques result in
strong representations as they lead to an average performance improvement of
4.17% and 3.15% over their respective baselines. Furthermore, we find that most
of this improvement comes from correctly answering the difficult instances,
implying a greater efficacy of our techniques on difficult tasks.</p>
  </details>
</details>
<details>
  <summary>98. <b>标题：Interpolating Compressed Parameter Subspaces</b></summary>
  <p><b>编号</b>：[218]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09891</p>
  <p><b>作者</b>：Siddhartha Datta,  Nigel Shadbolt</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：interpolatable input distributions, revisit parameter subspace, parameter subspace sampling, Inspired by recent, recent work</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Inspired by recent work on neural subspaces and mode connectivity, we revisit
parameter subspace sampling for shifted and/or interpolatable input
distributions (instead of a single, unshifted distribution). We enforce a
compressed geometric structure upon a set of trained parameters mapped to a set
of train-time distributions, denoting the resulting subspaces as Compressed
Parameter Subspaces (CPS). We show the success and failure modes of the types
of shifted distributions whose optimal parameters reside in the CPS. We find
that ensembling point-estimates within a CPS can yield a high average accuracy
across a range of test-time distributions, including backdoor, adversarial,
permutation, stylization and rotation perturbations. We also find that the CPS
can contain low-loss point-estimates for various task shifts (albeit
interpolated, perturbed, unseen or non-identical coarse labels). We further
demonstrate this property in a continual learning setting with CIFAR100.</p>
  </details>
</details>
<details>
  <summary>99. <b>标题：Time Series Anomaly Detection via Reinforcement Learning-Based Model  Selection</b></summary>
  <p><b>编号</b>：[221]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09884</p>
  <p><b>作者</b>：Jiuqi Elise Zhang,  Di Wu,  Benoit Boulet</p>
  <p><b>备注</b>：6 pages, 3 figures, submitted to IEEE Canadian Conference on Electrical and Computer Engineering (CCECE) 2022</p>
  <p><b>关键词</b>：anomaly detection, critical importance, reliable and efficient, efficient operation, anomaly detection models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Time series anomaly detection is of critical importance for the reliable and
efficient operation of real-world systems. Many anomaly detection models have
been developed throughout the years based on various assumptions regarding
anomaly characteristics. However, due to the complex nature of real-world data,
different anomalies within a time series usually have diverse profiles
supporting different anomaly assumptions, making it difficult to find a single
anomaly detector that can consistently beat all other models. In this work, to
harness the benefits of different base models, we assume that a pool of anomaly
detection models is accessible and propose to utilize reinforcement learning to
dynamically select a candidate model from these base models. Experiments on
real-world data have been implemented. It is demonstrated that the proposed
strategy can outperforms all baseline models in terms of overall performance.</p>
  </details>
</details>
<details>
  <summary>100. <b>标题：A Rule Search Framework for the Early Identification of Chronic  Emergency Homeless Shelter Clients</b></summary>
  <p><b>编号</b>：[222]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09883</p>
  <p><b>作者</b>：Caleb John,  Geoffrey G. Messier</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：emergency homeless shelter, North American shelter, rule search techniques, chronic shelter users, major North American</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper uses rule search techniques for the early identification of
emergency homeless shelter clients who are at risk of becoming long term or
chronic shelter users. Using a data set from a major North American shelter
containing 12 years of service interactions with over 40,000 individuals, the
optimized pruning for unordered search (OPUS) algorithm is used to develop
rules that are both intuitive and effective. The rules are evaluated within a
framework compatible with the real-time delivery of a housing program meant to
transition high risk clients to supportive housing. Results demonstrate that
the median time to identification of clients at risk of chronic shelter use
drops from 297 days to 162 days when the methods in this paper are applied.</p>
  </details>
</details>
<details>
  <summary>101. <b>标题：Beyond Labels: Visual Representations for Bone Marrow Cell Morphology  Recognition</b></summary>
  <p><b>编号</b>：[223]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09880</p>
  <p><b>作者</b>：Shayan Fazeli,  Alireza Samiei,  Thomas D. Lee,  Majid Sarrafzadeh</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：bone marrow cell, marrow cell cytomorphology, marrow cell, Analyzing and inspecting, hematopathology diagnosis</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Analyzing and inspecting bone marrow cell cytomorphology is a critical but
highly complex and time-consuming component of hematopathology diagnosis.
Recent advancements in artificial intelligence have paved the way for the
application of deep learning algorithms to complex medical tasks. Nevertheless,
there are many challenges in applying effective learning algorithms to medical
image analysis, such as the lack of sufficient and reliably annotated training
datasets and the highly class-imbalanced nature of most medical data. Here, we
improve on the state-of-the-art methodologies of bone marrow cell recognition
by deviating from sole reliance on labeled data and leveraging self-supervision
in training our learning models. We investigate our approach's effectiveness in
identifying bone marrow cell types. Our experiments demonstrate significant
performance improvements in conducting different bone marrow cell recognition
tasks compared to the current state-of-the-art methodologies.</p>
  </details>
</details>
<details>
  <summary>102. <b>标题：Real Time Multi-Object Detection for Helmet Safety</b></summary>
  <p><b>编号</b>：[224]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09878</p>
  <p><b>作者</b>：Mrinal Mathur,  Archana Benkkallpalli Chandrashekhar,  Venkata Krishna Chaithanya Nuthalapati</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Amazon Web Services, Web Services teamed, National Football League, League and Amazon, Amazon Web</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The National Football League and Amazon Web Services teamed up to develop the
best sports injury surveillance and mitigation program via the Kaggle
competition. Through which the NFL wants to assign specific players to each
helmet, which would help accurately identify each player's "exposures"
throughout a football play. We are trying to implement a computer vision based
ML algorithms capable of assigning detected helmet impacts to correct players
via tracking information. Our paper will explain the approach to automatically
track player helmets and their collisions. This will also allow them to review
previous plays and explore the trends in exposure over time.</p>
  </details>
</details>
<details>
  <summary>103. <b>标题：Incremental Learning with Differentiable Architecture and Forgetting  Search</b></summary>
  <p><b>编号</b>：[226]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09875</p>
  <p><b>作者</b>：James Seale Smith,  Zachary Seymour,  Han-Pang Chiu</p>
  <p><b>备注</b>：Accepted by the 2022 International Joint Conference on Neural Networks (IJCNN 2022)</p>
  <p><b>关键词</b>：incrementally expanding classification, training machine learning, machine learning models, incremental learning, industry expectations</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As progress is made on training machine learning models on incrementally
expanding classification tasks (i.e., incremental learning), a next step is to
translate this progress to industry expectations. One technique missing from
incremental learning is automatic architecture design via Neural Architecture
Search (NAS). In this paper, we show that leveraging NAS for incremental
learning results in strong performance gains for classification tasks.
Specifically, we contribute the following: first, we create a strong baseline
approach for incremental learning based on Differentiable Architecture Search
(DARTS) and state-of-the-art incremental learning strategies, outperforming
many existing strategies trained with similar-sized popular architectures;
second, we extend the idea of architecture search to regularize architecture
forgetting, boosting performance past our proposed baseline. We evaluate our
method on both RF signal and image classification tasks, and demonstrate we can
achieve up to a 10% performance increase over state-of-the-art methods. Most
importantly, our contribution enables learning from continuous distributions on
real-world application data for which the complexity of the data distribution
is unknown, or the modality less explored (such as RF signal classification).</p>
  </details>
</details>
<details>
  <summary>104. <b>标题：Transformer with Memory Replay</b></summary>
  <p><b>编号</b>：[228]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09869</p>
  <p><b>作者</b>：Rui Liu,  Barzan Mozafari</p>
  <p><b>备注</b>：Accepted to AAAI 2022</p>
  <p><b>关键词</b>：large-scale text corpora, natural language processing, language processing tasks, Memory replay, performance for natural</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Transformers achieve state-of-the-art performance for natural language
processing tasks by pre-training on large-scale text corpora. They are
extremely compute-intensive and have very high sample complexity. Memory replay
is a mechanism that remembers and reuses past examples by saving to and
replaying from a memory buffer. It has been successfully used in reinforcement
learning and GANs due to better sample efficiency. In this paper, we propose
\emph{Transformer with Memory Replay} (TMR), which integrates memory replay
with transformer, making transformer more sample-efficient. Experiments on GLUE
and SQuAD benchmark datasets show that Transformer with Memory Replay achieves
at least $1\%$ point increase compared to the baseline transformer model when
pretrained with the same number of examples. Further, by adopting a careful
design that reduces the wall-clock time overhead of memory replay, we also
empirically achieve a better runtime efficiency.</p>
  </details>
</details>
<details>
  <summary>105. <b>标题：Service Delay Minimization for Federated Learning over Mobile Devices</b></summary>
  <p><b>编号</b>：[229]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09868</p>
  <p><b>作者</b>：Rui Chen,  Dian Shi,  Xiaoqi Qin,  Dongjie Liu,  Miao Pan,  Shuguang Cui</p>
  <p><b>备注</b>：15 pages, 9 figures</p>
  <p><b>关键词</b>：numerous intriguing applications, fostered numerous intriguing, service delay, delay, Federated learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Federated learning (FL) over mobile devices has fostered numerous intriguing
applications/services, many of which are delay-sensitive. In this paper, we
propose a service delay efficient FL (SDEFL) scheme over mobile devices. Unlike
traditional communication efficient FL, which regards wireless communications
as the bottleneck, we find that under many situations, the local computing
delay is comparable to the communication delay during the FL training process,
given the development of high-speed wireless transmission techniques. Thus, the
service delay in FL should be computing delay + communication delay over
training rounds. To minimize the service delay of FL, simply reducing local
computing/communication delay independently is not enough. The delay trade-off
between local computing and wireless communications must be considered.
Besides, we empirically study the impacts of local computing control and
compression strategies (i.e., the number of local updates, weight quantization,
and gradient quantization) on computing, communication and service delays.
Based on those trade-off observation and empirical studies, we develop an
optimization scheme to minimize the service delay of FL over heterogeneous
devices. We establish testbeds and conduct extensive emulations/experiments to
verify our theoretical analysis. The results show that SDEFL reduces notable
service delay with a small accuracy drop compared to peer designs.</p>
  </details>
</details>
<details>
  <summary>106. <b>标题：Automated Scoring for Reading Comprehension via In-context BERT Tuning</b></summary>
  <p><b>编号</b>：[231]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09864</p>
  <p><b>作者</b>：Nigel Fernandez,  Aritra Ghosh,  Naiming Liu,  Zichao Wang,  Benoît Choffin,  Richard Baraniuk,  Andrew Lan</p>
  <p><b>备注</b>：Published as a conference paper at AIED 2022. A grand prize-winner for the NAEP AS Challenge. Code available at: this https URL</p>
  <p><b>关键词</b>：human grader effort, open-ended student responses, significantly reduce human, reduce human grader, grader effort</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Automated scoring of open-ended student responses has the potential to
significantly reduce human grader effort. Recent advances in automated scoring
often leverage textual representations based on pre-trained language models
such as BERT and GPT as input to scoring models. Most existing approaches train
a separate model for each item/question, which is suitable for scenarios such
as essay scoring where items can be quite different from one another. However,
these approaches have two limitations: 1) they fail to leverage item linkage
for scenarios such as reading comprehension where multiple items may share a
reading passage; 2) they are not scalable since storing one model per item
becomes difficult when models have a large number of parameters. In this paper,
we report our (grand prize-winning) solution to the National Assessment of
Education Progress (NAEP) automated scoring challenge for reading
comprehension. Our approach, in-context BERT fine-tuning, produces a single
shared scoring model for all items with a carefully-designed input structure to
provide contextual information on each item. We demonstrate the effectiveness
of our approach via local evaluations using the training dataset provided by
the challenge. We also discuss the biases, common error types, and limitations
of our approach.</p>
  </details>
</details>
<details>
  <summary>107. <b>标题：Recurrent segmentation meets block models in temporal networks</b></summary>
  <p><b>编号</b>：[232]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09862</p>
  <p><b>作者</b>：{Chamalee Wickrama Arachchi,  Nikolaj Tatti</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：temporal networks, networks, interactions, model, popular approach</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A popular approach to model interactions is to represent them as a network
with nodes being the agents and the interactions being the edges. Interactions
are often timestamped, which leads to having timestamped edges. Many real-world
temporal networks have a recurrent or possibly cyclic behaviour. For example,
social network activity may be heightened during certain hours of day. In this
paper, our main interest is to model recurrent activity in such temporal
networks. As a starting point we use stochastic block model, a popular choice
for modelling static networks, where nodes are split into $R$ groups. We extend
this model to temporal networks by modelling the edges with a Poisson process.
We make the parameters of the process dependent on time by segmenting the time
line into $K$ segments. To enforce the recurring activity we require that only
$H < K$ different set of parameters can be used, that is, several, not
necessarily consecutive, segments must share their parameters. We prove that
the searching for optimal blocks and segmentation is an NP-hard problem.
Consequently, we split the problem into 3 subproblems where we optimize blocks,
model parameters, and segmentation in turn while keeping the remaining
structures fixed. We propose an iterative algorithm that requires $O(KHm + Rn +
R^2H)$ time per iteration, where $n$ and $m$ are the number of nodes and edges
in the network. We demonstrate experimentally that the number of required
iterations is typically low, the algorithm is able to discover the ground truth
from synthetic datasets, and show that certain real-world networks exhibit
recurrent behaviour as the likelihood does not deteriorate when $H$ is lowered.</p>
  </details>
</details>
<details>
  <summary>108. <b>标题：Mean-Field Analysis of Two-Layer Neural Networks: Global Optimality with  Linear Convergence Rates</b></summary>
  <p><b>编号</b>：[233]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09860</p>
  <p><b>作者</b>：Jingwei Zhang,  Xunpeng Huang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：two-layer neural networks, mean-field regime, optimizing two-layer neural, weight parameters, two-layer neural</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We consider optimizing two-layer neural networks in the mean-field regime
where the learning dynamics of network weights can be approximated by the
evolution in the space of probability measures over the weight parameters
associated with the neurons. The mean-field regime is a theoretically
attractive alternative to the NTK (lazy training) regime which is only
restricted locally in the so-called neural tangent kernel space around
specialized initializations. Several prior works (\cite{mei2018mean,
chizat2018global}) establish the asymptotic global optimality of the mean-field
regime, but it is still challenging to obtain a quantitative convergence rate
due to the complicated nonlinearity of the training dynamics. This work
establishes a new linear convergence result for two-layer neural networks
trained by continuous-time noisy gradient descent in the mean-field regime. Our
result relies on a novelty logarithmic Sobolev inequality for two-layer neural
networks, and uniform upper bounds on the logarithmic Sobolev constants for a
family of measures determined by the evolving distribution of hidden neurons.</p>
  </details>
</details>
<details>
  <summary>109. <b>标题：Masked Conditional Video Diffusion for Prediction, Generation, and  Interpolation</b></summary>
  <p><b>编号</b>：[235]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09853</p>
  <p><b>作者</b>：Vikram Voleti,  Alexia Jolicoeur-Martineau,  Christopher Pal</p>
  <p><b>备注</b>：9 pages, 4 figures, 7 tables</p>
  <p><b>关键词</b>：frames, future, future frames, Video, past</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Video prediction is a challenging task. The quality of video frames from
current state-of-the-art (SOTA) generative models tends to be poor and
generalization beyond the training data is difficult. Furthermore, existing
prediction frameworks are typically not capable of simultaneously handling
other video-related tasks such as unconditional generation or interpolation. In
this work, we devise a general-purpose framework called Masked Conditional
Video Diffusion (MCVD) for all of these video synthesis tasks using a
probabilistic conditional score-based denoising diffusion model, conditioned on
past and/or future frames. We train the model in a manner where we randomly and
independently mask all the past frames or all the future frames. This novel but
straightforward setup allows us to train a single model that is capable of
executing a broad range of video tasks, specifically: future/past prediction --
when only future/past frames are masked; unconditional generation -- when both
past and future frames are masked; and interpolation -- when neither past nor
future frames are masked. Our experiments show that this approach can generate
high-quality frames for diverse types of videos. Our MCVD models are built from
simple non-recurrent 2D-convolutional architectures, conditioning on blocks of
frames and generating blocks of frames. We generate videos of arbitrary lengths
autoregressively in a block-wise manner. Our approach yields SOTA results
across standard video prediction and interpolation benchmarks, with computation
times for training models measured in 1-12 days using $\le$ 4 GPUs.
this https URL</p>
  </details>
</details>
<details>
  <summary>110. <b>标题：Deconfounding Actor-Critic Network with Policy Adaptation for Dynamic  Treatment Regimes</b></summary>
  <p><b>编号</b>：[236]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09852</p>
  <p><b>作者</b>：Changchang Yin,  Ruoqi Liu,  Jeffrey Caterino,  Ping Zhang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：learned DTR policies, critically ill patients, ill patients remains, DTR policies, major challenge</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Despite intense efforts in basic and clinical research, an individualized
ventilation strategy for critically ill patients remains a major challenge.
Recently, dynamic treatment regime (DTR) with reinforcement learning (RL) on
electronic health records (EHR) has attracted interest from both the healthcare
industry and machine learning research community. However, most learned DTR
policies might be biased due to the existence of confounders. Although some
treatment actions non-survivors received may be helpful, if confounders cause
the mortality, the training of RL models guided by long-term outcomes (e.g.,
90-day mortality) would punish those treatment actions causing the learned DTR
policies to be suboptimal. In this study, we develop a new deconfounding
actor-critic network (DAC) to learn optimal DTR policies for patients. To
alleviate confounding issues, we incorporate a patient resampling module and a
confounding balance module into our actor-critic framework. To avoid punishing
the effective treatment actions non-survivors received, we design a short-term
reward to capture patients' immediate health state changes. Combining
short-term with long-term rewards could further improve the model performance.
Moreover, we introduce a policy adaptation method to successfully transfer the
learned model to new-source small-scale datasets. The experimental results on
one semi-synthetic and two different real-world datasets show the proposed
model outperforms the state-of-the-art models. The proposed model provides
individualized treatment decisions for mechanical ventilation that could
improve patient outcomes.</p>
  </details>
</details>
<details>
  <summary>111. <b>标题：Confident Clustering via PCA Compression Ratio and Its Application to  Single-cell RNA-seq Analysis</b></summary>
  <p><b>编号</b>：[237]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09849</p>
  <p><b>作者</b>：Yingcong Li,  Chandra Sekhar Mukherjee,  Jiapeng Zhang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Unsupervised clustering algorithms, clustering, machine learning, clustering algorithms, Unsupervised clustering</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Unsupervised clustering algorithms for vectors has been widely used in the
area of machine learning. Many applications, including the biological data we
studied in this paper, contain some boundary datapoints which show combination
properties of two underlying clusters and could lower the performance of the
traditional clustering algorithms. We develop a confident clustering method
aiming to diminish the influence of these datapoints and improve the clustering
results. Concretely, for a list of datapoints, we give two clustering results.
The first-round clustering attempts to classify only pure vectors with high
confidence. Based on it, we classify more vectors with less confidence in the
second round. We validate our algorithm on single-cell RNA-seq data, which is a
powerful and widely used tool in biology area. Our confident clustering shows a
high accuracy on our tested datasets. In addition, unlike traditional
clustering methods in single-cell analysis, the confident clustering shows high
stability under different choices of parameters.</p>
  </details>
</details>
<details>
  <summary>112. <b>标题：A toolbox for idea generation and evaluation: Machine learning,  data-driven, and contest-driven approaches to support idea generation</b></summary>
  <p><b>编号</b>：[241]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09840</p>
  <p><b>作者</b>：Workneh Yilma Ayele</p>
  <p><b>备注</b>：ISBN 978-91-7911-790-0 ISBN 978-91-7911-791-7 ISSN 1101-8526</p>
  <p><b>关键词</b>：documents published online, growing digital data, digital data generated, scholarly literature, social media</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The significance and abundance of data are increasing due to the growing
digital data generated from social media, sensors, scholarly literature,
patents, different forms of documents published online, databases, product
manuals, etc. Various data sources can be used to generate ideas, yet, in
addition to bias, the size of the available digital data is a major challenge
when it comes to manual analysis. Hence, human-machine interaction is essential
for generating valuable ideas where machine learning and data-driven techniques
generate patterns from data and serve human sense-making. However, the use of
machine learning and data-driven approaches to generate ideas is a relatively
new area. Moreover, it is also possible to stimulate innovation using
contest-driven idea generation and evaluation. The results and contributions of
this thesis can be viewed as a toolbox of idea-generation techniques, including
a list of data-driven and machine learning techniques with corresponding data
sources and models to support idea generation. In addition, the results include
two models, one method and one framework, to better support data-driven and
contest- driven idea generation. The beneficiaries of these artefacts are
practitioners in data and knowledge engineering, data mining project managers,
and innovation agents. Innovation agents include incubators, contest
organizers, consultants, innovation accelerators, and industries. Since the
proposed artefacts consist of process models augmented with AI techniques,
human-centred AI is a promising area of research that can contribute to the
artefacts' further development and promote creativity.</p>
  </details>
</details>
<details>
  <summary>113. <b>标题：HyBNN and FedHyBNN: (Federated) Hybrid Binary Neural Networks</b></summary>
  <p><b>编号</b>：[242]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09839</p>
  <p><b>作者</b>：Kinshuk Dua</p>
  <p><b>备注</b>：11 pages, 7 figures, submitted to neurips</p>
  <p><b>关键词</b>：resource constrained devices, lower memory consumption, Neural Networks, Binary Neural Networks, Binary Neural</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Binary Neural Networks (BNNs), neural networks with weights and activations
constrained to -1(0) and +1, are an alternative to deep neural networks which
offer faster training, lower memory consumption and lightweight models, ideal
for use in resource constrained devices while being able to utilize the
architecture of their deep neural network counterpart. However, the input
binarization step used in BNNs causes a severe accuracy loss. In this paper, we
introduce a novel hybrid neural network architecture, Hybrid Binary Neural
Network (HyBNN), consisting of a task-independent, general, full-precision
variational autoencoder with a binary latent space and a task specific binary
neural network that is able to greatly limit the accuracy loss due to input
binarization by using the full precision variational autoencoder as a feature
extractor. We use it to combine the state-of-the-art accuracy of deep neural
networks with the much faster training time, quicker test-time inference and
power efficiency of binary neural networks. We show that our proposed system is
able to very significantly outperform a vanilla binary neural network with
input binarization. We also introduce FedHyBNN, a highly communication
efficient federated counterpart to HyBNN and demonstrate that it is able to
reach the same accuracy as its non-federated equivalent. We make our source
code, experimental parameters and models available at:
https://anonymous.4open.science/r/HyBNN.</p>
  </details>
</details>
<details>
  <summary>114. <b>标题：Why GANs are overkill for NLP</b></summary>
  <p><b>编号</b>：[243]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09838</p>
  <p><b>作者</b>：David Alvarez-Melis,  Vikas Garg,  Adam Tauman Kalai</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Natural Language Generation, Natural Language, Language Generation, generation tasks, numerous attempts</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This work offers a novel theoretical perspective on why, despite numerous
attempts, adversarial approaches to generative modeling (e.g., GANs) have not
been as popular for certain generation tasks, particularly sequential tasks
such as Natural Language Generation, as they have in others, such as Computer
Vision. In particular, on sequential data such as text, maximum-likelihood
approaches are significantly more utilized than GANs. We show that, while it
may seem that maximizing likelihood is inherently different than minimizing
distinguishability, this distinction is largely artificial and only holds for
limited models. We argue that minimizing KL-divergence (i.e., maximizing
likelihood) is a more efficient approach to effectively minimizing the same
distinguishability criteria that adversarial models seek to optimize.
Reductions show that minimizing distinguishability can be seen as simply
boosting likelihood for certain families of models including n-gram models and
neural networks with a softmax output layer. To achieve a full polynomial-time
reduction, a novel next-token distinguishability model is considered.</p>
  </details>
</details>
<details>
  <summary>115. <b>标题：Summarization as Indirect Supervision for Relation Extraction</b></summary>
  <p><b>编号</b>：[244]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09837</p>
  <p><b>作者</b>：Keming Lu,  I-Hung Hsu,  Wenxuan Zhou,  Mingyu Derek Ma,  Muhao Chen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：expensive annotations, reliance on training, training data, data with expensive, Relation extraction</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Relation extraction (RE) models have been challenged by their reliance on
training data with expensive annotations. Considering that summarization tasks
aim at acquiring concise expressions of synoptical information from the longer
context, these tasks naturally align with the objective of RE, i.e., extracting
a kind of synoptical information that describes the relation of entity
mentions. We present SuRE, which converts RE into a summarization formulation.
SuRE leads to more precise and resource-efficient RE based on indirect
supervision from summarization tasks. To achieve this goal, we develop sentence
and relation conversion techniques that essentially bridge the formulation of
summarization and RE tasks. We also incorporate constraint decoding techniques
with Trie scoring to further enhance summarization-based RE with robust
inference. Experiments on three RE datasets demonstrate the effectiveness of
SuRE in both full-dataset and low-resource settings, showing that summarization
is a promising source of indirect supervision to improve RE models.</p>
  </details>
</details>
<details>
  <summary>116. <b>标题：Concurrent Policy Blending and System Identification for Generalized  Assistive Control</b></summary>
  <p><b>编号</b>：[245]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09836</p>
  <p><b>作者</b>：Luke Bhan,  Marcos Quinones-Grueiro,  Gautam Biswas</p>
  <p><b>备注</b>：Accepted to ICRA 2022</p>
  <p><b>关键词</b>：multiple varying parameters, solving complex collaborative, complex collaborative robotic, robotic tasks subject, address the problem</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this work, we address the problem of solving complex collaborative robotic
tasks subject to multiple varying parameters. Our approach combines
simultaneous policy blending with system identification to create generalized
policies that are robust to changes in system parameters. We employ a blending
network whose state space relies solely on parameter estimates from a system
identification technique. As a result, this blending network learns how to
handle parameter changes instead of trying to learn how to solve the task for a
generalized parameter set simultaneously. We demonstrate our scheme's ability
on a collaborative robot and human itching task in which the human has motor
impairments. We then showcase our approach's efficiency with a variety of
system identification techniques when compared to standard domain
randomization.</p>
  </details>
</details>
<details>
  <summary>117. <b>标题：Classification of Intra-Pulse Modulation of Radar Signals by Feature  Fusion Based Convolutional Neural Networks</b></summary>
  <p><b>编号</b>：[246]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09834</p>
  <p><b>作者</b>：Fatih Cagatay Akyon,  Yasar Kemal Alp,  Gokhan Gok,  Orhan Arikan</p>
  <p><b>备注</b>：Published at EUSIPCO2018</p>
  <p><b>关键词</b>：electronic warfare systems, Detection and classification, warfare systems, pulses they transmit, important application</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Detection and classification of radars based on pulses they transmit is an
important application in electronic warfare systems. In this work, we propose a
novel deep-learning based technique that automatically recognizes intra-pulse
modulation types of radar signals. Re-assigned spectrogram of measured radar
signal and detected outliers of its instantaneous phases filtered by a special
function are used for training multiple convolutional neural networks.
Automatically extracted features from the networks are fused to distinguish
frequency and phase modulated signals. Simulation results show that the
proposed FF-CNN (Feature Fusion based Convolutional Neural Network) technique
outperforms the current state-of-the-art alternatives and is easily scalable
among broad range of modulation types.</p>
  </details>
</details>
<details>
  <summary>118. <b>标题：Learning Interface Conditions in Domain Decomposition Solvers</b></summary>
  <p><b>编号</b>：[247]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09833</p>
  <p><b>作者</b>：Ali Taghibakhshi,  Nicolas Nytko,  Tareq Zaman,  Scott MacLachlan,  Luke Olson,  Matthew West</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：partial differential equations, differential equations, Domain decomposition methods, approximation of solutions, solutions to partial</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Domain decomposition methods are widely used and effective in the
approximation of solutions to partial differential equations. Yet the optimal
construction of these methods requires tedious analysis and is often available
only in simplified, structured-grid settings, limiting their use for more
complex problems. In this work, we generalize optimized Schwarz domain
decomposition methods to unstructured-grid problems, using Graph Convolutional
Neural Networks (GCNNs) and unsupervised learning to learn optimal
modifications at subdomain interfaces. A key ingredient in our approach is an
improved loss function, enabling effective training on relatively small
problems, but robust performance on arbitrarily large problems, with
computational cost linear in problem size. The performance of the learned
linear solvers is compared with both classical and optimized domain
decomposition algorithms, for both structured- and unstructured-grid problems.</p>
  </details>
</details>
<details>
  <summary>119. <b>标题：A Learning-Based Approach to Approximate Coded Computation</b></summary>
  <p><b>编号</b>：[253]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09818</p>
  <p><b>作者</b>：Navneet Agrawal,  Yuqin Qiu,  Matthias Frey,  Igor Bjelakovic,  Setareh Maghsudi,  Slawomir Stanczak,  Jingge Zhu</p>
  <p><b>备注</b>：Submitted to IEEE Information Theory Workshop (ITW) 2022</p>
  <p><b>关键词</b>：coded distributed fashion, distributed fashion, Lagrange coded computation, essential to solving, matrix polynomials</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Lagrange coded computation (LCC) is essential to solving problems about
matrix polynomials in a coded distributed fashion; nevertheless, it can only
solve the problems that are representable as matrix polynomials. In this paper,
we propose AICC, an AI-aided learning approach that is inspired by LCC but also
uses deep neural networks (DNNs). It is appropriate for coded computation of
more general functions. Numerical simulations demonstrate the suitability of
the proposed approach for the coded computation of different matrix functions
that are often utilized in digital signal processing.</p>
  </details>
</details>
<details>
  <summary>120. <b>标题：MiDAS: Multi-integrated Domain Adaptive Supervision for Fake News  Detection</b></summary>
  <p><b>编号</b>：[254]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09817</p>
  <p><b>作者</b>：Abhijit Suprem,  Calton Pu</p>
  <p><b>备注</b>：We use Lipschitz smoothness and probabilistic Lipschitzness to build a theoretical foundation for effective multi-domain adaptation using randomized perturbations on unseen data</p>
  <p><b>关键词</b>：fake, past few years, dramatically increased, related misinformation, fake news detection</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>COVID-19 related misinformation and fake news, coined an 'infodemic', has
dramatically increased over the past few years. This misinformation exhibits
concept drift, where the distribution of fake news changes over time, reducing
effectiveness of previously trained models for fake news detection. Given a set
of fake news models trained on multiple domains, we propose an adaptive
decision module to select the best-fit model for a new sample. We propose
MiDAS, a multi-domain adaptative approach for fake news detection that ranks
relevancy of existing models to new samples. MiDAS contains 2 components: a
doman-invariant encoder, and an adaptive model selector. MiDAS integrates
multiple pre-trained and fine-tuned models with their training data to create a
domain-invariant representation. Then, MiDAS uses local Lipschitz smoothness of
the invariant embedding space to estimate each model's relevance to a new
sample. Higher ranked models provide predictions, and lower ranked models
abstain. We evaluate MiDAS on generalization to drifted data with 9 fake news
datasets, each obtained from different domains and modalities. MiDAS achieves
new state-of-the-art performance on multi-domain adaptation for
out-of-distribution fake news classification.</p>
  </details>
</details>
<details>
  <summary>121. <b>标题：A Novel Weighted Ensemble Learning Based Agent for the Werewolf Game</b></summary>
  <p><b>编号</b>：[255]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09813</p>
  <p><b>作者</b>：Mohiuddeen Khan,  Claus Aranha</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Werewolf game, popular party game, Werewolf, recent years, popular party</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Werewolf is a popular party game throughout the world, and research on its
significance has progressed in recent years. The Werewolf game is based on
conversation, and in order to win, participants must use all of their cognitive
abilities. This communication game requires the playing agents to be very
sophisticated to win. In this research, we generated a sophisticated agent to
play the Werewolf game using a complex weighted ensemble learning approach.
This research work aimed to estimate what other agents/players think of us in
the game. The agent was developed by aggregating strategies of different
participants in the AI Wolf competition and thereby learning from them using
machine learning. Moreover, the agent created was able to perform much better
than other competitors using very basic strategies to show the approach's
effectiveness in the Werewolf game. The machine learning technique used here is
not restricted to the Werewolf game but may be extended to any game that
requires communication and action depending on other participants.</p>
  </details>
</details>
<details>
  <summary>122. <b>标题：Calibration Matters: Tackling Maximization Bias in Large-scale  Advertising Recommendation Systems</b></summary>
  <p><b>编号</b>：[256]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09809</p>
  <p><b>作者</b>：Yewen Fan,  Nian Si,  Kun Zhang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：true click rate, predicted click rate, click rate, average predicted click, maximization bias</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Calibration is defined as the ratio of the average predicted click rate to
the true click rate. The optimization of calibration is essential to many
online advertising recommendation systems because it directly affects the
downstream bids in ads auctions and the amount of money charged to advertisers.
Despite its importance, calibration optimization often suffers from a problem
called "maximization bias". Maximization bias refers to the phenomenon that the
maximum of predicted values overestimates the true maximum. The problem is
introduced because the calibration is computed on the set selected by the
prediction model itself. It persists even if unbiased predictions can be
achieved on every datapoint and worsens when covariate shifts exist between the
training and test sets. To mitigate this problem, we theorize the
quantification of maximization bias and propose a variance-adjusting debiasing
(VAD) meta-algorithm in this paper. The algorithm is efficient, robust, and
practical as it is able to mitigate maximization bias problems under covariate
shifts, neither incurring additional online serving costs nor compromising the
ranking performance. We demonstrate the effectiveness of the proposed algorithm
using a state-of-the-art recommendation neural network model on a large-scale
real-world dataset.</p>
  </details>
</details>
<details>
  <summary>123. <b>标题：Estimation of Entropy in Constant Space with Improved Sample Complexity</b></summary>
  <p><b>编号</b>：[258]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09804</p>
  <p><b>作者</b>：Maryam Aliakbarpour,  Andrew McGregor,  Jelani Nelson,  Erik Waingarten</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：epsilon, text, polylog, work of Acharya, Recent work</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent work of Acharya et al. (NeurIPS 2019) showed how to estimate the
entropy of a distribution $\mathcal D$ over an alphabet of size $k$ up to
$\pm\epsilon$ additive error by streaming over $(k/\epsilon^3) \cdot
\text{polylog}(1/\epsilon)$ i.i.d. samples and using only $O(1)$ words of
memory. In this work, we give a new constant memory scheme that reduces the
sample complexity to $(k/\epsilon^2)\cdot \text{polylog}(1/\epsilon)$. We
conjecture that this is optimal up to $\text{polylog}(1/\epsilon)$ factors.</p>
  </details>
</details>
<details>
  <summary>124. <b>标题：Towards a Holistic View on Argument Quality Prediction</b></summary>
  <p><b>编号</b>：[259]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09803</p>
  <p><b>作者</b>：Michael Fromm,  Max Berrendorf,  Johanna Reiml,  Isabelle Mayerhofer,  Siddharth Bhargava,  Evgeniy Faerman,  Thomas Seidl</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：society foundational pillars, receives increasing attention, advances in NLP, arguments receives increasing, foundational pillars</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Argumentation is one of society's foundational pillars, and, sparked by
advances in NLP and the vast availability of text data, automated mining of
arguments receives increasing attention. A decisive property of arguments is
their strength or quality. While there are works on the automated estimation of
argument strength, their scope is narrow: they focus on isolated datasets and
neglect the interactions with related argument mining tasks, such as argument
identification, evidence detection, or emotional appeal. In this work, we close
this gap by approaching argument quality estimation from multiple different
angles: Grounded on rich results from thorough empirical evaluations, we assess
the generalization capabilities of argument quality estimation across diverse
domains, the interplay with related argument mining tasks, and the impact of
emotions on perceived argument strength. We find that generalization depends on
a sufficient representation of different domains in the training part. In
zero-shot transfer and multi-task experiments, we reveal that argument quality
is among the more challenging tasks but can improve others. Finally, we show
that emotions play a minor role in argument quality than is often assumed.</p>
  </details>
</details>
<details>
  <summary>125. <b>标题：Label-invariant Augmentation for Semi-Supervised Graph Classification</b></summary>
  <p><b>编号</b>：[260]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09802</p>
  <p><b>作者</b>：Han Yue,  Chunhui Zhang,  Chuxu Zhang,  Hongfu Liu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：computer vision domain, contrastiveness-based augmentation surges, graph contrastive learning, including rotation, vision domain</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recently, contrastiveness-based augmentation surges a new climax in the
computer vision domain, where some operations, including rotation, crop, and
flip, combined with dedicated algorithms, dramatically increase the model
generalization and robustness. Following this trend, some pioneering attempts
employ the similar idea to graph data. Nevertheless, unlike images, it is much
more difficult to design reasonable augmentations without changing the nature
of graphs. Although exciting, the current graph contrastive learning does not
achieve as promising performance as visual contrastive learning. We conjecture
the current performance of graph contrastive learning might be limited by the
violation of the label-invariant augmentation assumption. In light of this, we
propose a label-invariant augmentation for graph-structured data to address
this challenge. Different from the node/edge modification and subgraph
extraction, we conduct the augmentation in the representation space and
generate the augmented samples in the most difficult direction while keeping
the label of augmented data the same as the original samples. In the
semi-supervised scenario, we demonstrate our proposed method outperforms the
classical graph neural network based methods and recent graph contrastive
learning on eight benchmark graph-structured data, followed by several in-depth
experiments to further explore the label-invariant augmentation in several
aspects.</p>
  </details>
</details>
<details>
  <summary>126. <b>标题：Graph Neural Networks Are More Powerful Than we Think</b></summary>
  <p><b>编号</b>：[261]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09801</p>
  <p><b>作者</b>：Charilaos I. Kanatsoulis,  Alejandro Ribeiro</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Graph Neural Networks, Neural Networks, shown remarkable performance, powerful convolutional architectures, Graph Neural</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Graph Neural Networks (GNNs) are powerful convolutional architectures that
have shown remarkable performance in various node-level and graph-level tasks.
Despite their success, the common belief is that the expressive power of GNNs
is limited and that they are at most as discriminative as the Weisfeiler-Lehman
(WL) algorithm. In this paper we argue the opposite and show that the WL
algorithm is the upper bound only when the input to the GNN is the vector of
all ones. In this direction, we derive an alternative analysis that employs
linear algebraic tools and characterize the representational power of GNNs with
respect to the eigenvalue decomposition of the graph operators. We show that
GNNs can distinguish between any graphs that differ in at least one eigenvalue
and design simple GNN architectures that are provably more expressive than the
WL algorithm. Thorough experimental analysis on graph isomorphism and graph
classification datasets corroborates our theoretical results and demonstrates
the effectiveness of the proposed architectures.</p>
  </details>
</details>
<details>
  <summary>127. <b>标题：Improving Multi-Task Generalization via Regularizing Spurious  Correlation</b></summary>
  <p><b>编号</b>：[263]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09797</p>
  <p><b>作者</b>：Ziniu Hu,  Zhe Zhao,  Xinyang Yi,  Tiansheng Yao,  Lichan Hong,  Yizhou Sun,  Ed H. Chi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：powerful learning paradigm, MTL, paradigm to improve, spurious, knowledge</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Multi-Task Learning (MTL) is a powerful learning paradigm to improve
generalization performance via knowledge sharing. However, existing studies
find that MTL could sometimes hurt generalization, especially when two tasks
are less correlated. One possible reason that hurts generalization is spurious
correlation, i.e., some knowledge is spurious and not causally related to task
labels, but the model could mistakenly utilize them and thus fail when such
correlation changes. In MTL setup, there exist several unique challenges of
spurious correlation. First, the risk of having non-causal knowledge is higher,
as the shared MTL model needs to encode all knowledge from different tasks, and
causal knowledge for one task could be potentially spurious to the other.
Second, the confounder between task labels brings in a different type of
spurious correlation to MTL. We theoretically prove that MTL is more prone to
taking non-causal knowledge from other tasks than single-task learning, and
thus generalize worse. To solve this problem, we propose Multi-Task Causal
Representation Learning framework, aiming to represent multi-task knowledge via
disentangled neural modules, and learn which module is causally related to each
task via MTL-specific invariant regularization. Experiments show that it could
enhance MTL model's performance by 5.5% on average over Multi-MNIST, MovieLens,
Taskonomy, CityScape, and NYUv2, via alleviating spurious correlation problem.</p>
  </details>
</details>
<details>
  <summary>128. <b>标题：Causal Discovery and Injection for Feed-Forward Neural Networks</b></summary>
  <p><b>编号</b>：[267]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09787</p>
  <p><b>作者</b>：Fabrizio Russo,  Francesca Toni</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：meaningful causal relationship, neural network models, high-stakes decisions, Neural networks, feed-forward neural networks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Neural networks have proven to be effective at solving a wide range of
problems but it is often unclear whether they learn any meaningful causal
relationship: this poses a problem for the robustness of neural network models
and their use for high-stakes decisions. We propose a novel method overcoming
this issue by injecting knowledge in the form of (possibly partial) causal
graphs into feed-forward neural networks, so that the learnt model is
guaranteed to conform to the graph, hence adhering to expert knowledge. This
knowledge may be given up-front or during the learning process, to improve the
model through human-AI collaboration. We apply our method to synthetic and real
(tabular) data showing that it is robust against noise and can improve causal
discovery and prediction performance in low data regimes.</p>
  </details>
</details>
<details>
  <summary>129. <b>标题：HDGT: Heterogeneous Driving Graph Transformer for Multi-Agent Trajectory  Prediction via Scene Encoding</b></summary>
  <p><b>编号</b>：[271]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09753</p>
  <p><b>作者</b>：Xiaosong Jia,  Penghao Wu,  Li Chen,  Hongyang Li,  Yu Liu,  Junchi Yan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：driving scene, essential task, downstream task, Driving Graph Transformer, Heterogeneous Driving Graph</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>One essential task for autonomous driving is to encode the information of a
driving scene into vector representations so that the downstream task such as
trajectory prediction could perform well. The driving scene is complicated, and
there exists heterogeneity within elements, where they own diverse types of
information i.e., agent dynamics, map routing, road lines, etc. Meanwhile,
there also exist relativity across elements - meaning they have spatial
relations with each other; such relations should be canonically represented
regarding the relative measurements since the absolute value of the coordinate
is meaningless. Taking these two observations into consideration, we propose a
novel backbone, namely Heterogeneous Driving Graph Transformer (HDGT), which
models the driving scene as a heterogeneous graph with different types of nodes
and edges. For graph construction, each node represents either an agent or a
road element and each edge represents their semantics relations such as
Pedestrian-To-Crosswalk, Lane-To-Left-Lane. As for spatial relation encoding,
instead of setting a fixed global reference, the coordinate information of the
node as well as its in-edges is transformed to the local node-centric
coordinate system. For the aggregation module in the graph neural network
(GNN), we adopt the transformer structure in a hierarchical way to fit the
heterogeneous nature of inputs. Experimental results show that the proposed
method achieves new state-of-the-art on INTERACTION Prediction Challenge and
Waymo Open Motion Challenge, in which we rank 1st and 2nd respectively
regarding the minADE/minFDE metric.</p>
  </details>
</details>
<details>
  <summary>130. <b>标题：What's the Harm? Sharp Bounds on the Fraction Negatively Affected by  Treatment</b></summary>
  <p><b>编号</b>：[275]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10327</p>
  <p><b>作者</b>：Nathan Kallus</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：observe counterfactuals, proposed intervention, fundamental problem, problem of causal, negatively affected</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The fundamental problem of causal inference -- that we never observe
counterfactuals -- prevents us from identifying how many might be negatively
affected by a proposed intervention. If, in an A/B test, half of users click
(or buy, or watch, or renew, etc.), whether exposed to the standard experience
A or a new one B, hypothetically it could be because the change affects no one,
because the change positively affects half the user population to go from
no-click to click while negatively affecting the other half, or something in
between. While unknowable, this impact is clearly of material importance to the
decision to implement a change or not, whether due to fairness, long-term,
systemic, or operational considerations. We therefore derive the
tightest-possible (i.e., sharp) bounds on the fraction negatively affected (and
other related estimands) given data with only factual observations, whether
experimental or observational. Naturally, the more we can stratify individuals
by observable covariates, the tighter the sharp bounds. Since these bounds
involve unknown functions that must be learned from data, we develop a robust
inference algorithm that is efficient almost regardless of how and how fast
these functions are learned, remains consistent when some are mislearned, and
still gives valid conservative bounds when most are mislearned. Our methodology
altogether therefore strongly supports credible conclusions: it avoids
spuriously point-identifying this unknowable impact, focusing on the best
bounds instead, and it permits exceedingly robust inference on these. We
demonstrate our method in simulation studies and in a case study of career
counseling for the unemployed.</p>
  </details>
</details>
<details>
  <summary>131. <b>标题：User Localization using RF Sensing: A Performance comparison between LIS  and mmWave Radars</b></summary>
  <p><b>编号</b>：[279]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10321</p>
  <p><b>作者</b>：Cristian J. Vaca-Rubio,  Dariush Salami,  Petar Popovski,  Elisabeth de Carvalho,  Zheng-Hua Tan,  Stephan Sigg</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Radio Frequency, universal sensing mechanism, gesture recognition, intrusion detection, signals are omnipresent</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Since electromagnetic signals are omnipresent, Radio Frequency (RF)-sensing
has the potential to become a universal sensing mechanism with applications in
localization, smart-home, retail, gesture recognition, intrusion detection,
etc. Two emerging technologies in RF-sensing, namely sensing through Large
Intelligent Surfaces (LISs) and mmWave Frequency-Modulated Continuous-Wave
(FMCW) radars, have been successfully applied to a wide range of applications.
In this work, we compare LIS and mmWave radars for localization in real-world
and simulated environments. In our experiments, the mmWave radar achieves 0.71
Intersection Over Union (IOU) and 3cm error for bounding boxes, while LIS has
0.56 IOU and 10cm distance error. Although the radar outperforms the LIS in
terms of accuracy, LIS features additional applications in communication in
addition to sensing scenarios.</p>
  </details>
</details>
<details>
  <summary>132. <b>标题：Memorization and Optimization in Deep Neural Networks with Minimum  Over-parameterization</b></summary>
  <p><b>编号</b>：[285]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10217</p>
  <p><b>作者</b>：Simone Bombari,  Mohammad Hossein Amani,  Marco Mondelli</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Neural Tangent Kernel, Tangent Kernel, Neural Tangent, deep neural networks, neural networks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The Neural Tangent Kernel (NTK) has emerged as a powerful tool to provide
memorization, optimization and generalization guarantees in deep neural
networks. A line of work has studied the NTK spectrum for two-layer and deep
networks with at least a layer with $\Omega(N)$ neurons, $N$ being the number
of training samples. Furthermore, there is increasing evidence suggesting that
deep networks with sub-linear layer widths are powerful memorizers and
optimizers, as long as the number of parameters exceeds the number of samples.
Thus, a natural open question is whether the NTK is well conditioned in such a
challenging sub-linear setup. In this paper, we answer this question in the
affirmative. Our key technical contribution is a lower bound on the smallest
NTK eigenvalue for deep networks with the minimum possible
over-parameterization: the number of parameters is roughly $\Omega(N)$ and,
hence, the number of neurons is as little as $\Omega(\sqrt{N})$. To showcase
the applicability of our NTK bounds, we provide two results concerning
memorization capacity and optimization guarantees for gradient descent
training.</p>
  </details>
</details>
<details>
  <summary>133. <b>标题：The Fairness of Credit Scoring Models</b></summary>
  <p><b>编号</b>：[287]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10200</p>
  <p><b>作者</b>：Christophe Hurlin,  Christophe Pérignon,  Sébastien Saurin</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：screening algorithms aim, credit markets, screening algorithms, bad-type borrowers, algorithms aim</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In credit markets, screening algorithms aim to discriminate between good-type
and bad-type borrowers. However, when doing so, they also often discriminate
between individuals sharing a protected attribute (e.g. gender, age, racial
origin) and the rest of the population. In this paper, we show how (1) to test
whether there exists a statistically significant difference between protected
and unprotected groups, which we call lack of fairness and (2) to identify the
variables that cause the lack of fairness. We then use these variables to
optimize the fairness-performance trade-off. Our framework provides guidance on
how algorithmic fairness can be monitored by lenders, controlled by their
regulators, and improved for the benefit of protected groups.</p>
  </details>
</details>
<details>
  <summary>134. <b>标题：On Calibration of Ensemble-Based Credal Predictors</b></summary>
  <p><b>编号</b>：[290]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10082</p>
  <p><b>作者</b>：Thomas Mortier,  Viktor Bengs,  Eyke Hüllermeier,  Stijn Luca,  Willem Waegeman</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：quantify epistemic uncertainty, credal predictors, recent years, epistemic uncertainty, classification methods</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In recent years, several classification methods that intend to quantify
epistemic uncertainty have been proposed, either by producing predictions in
the form of second-order distributions or sets of probability distributions. In
this work, we focus on the latter, also called credal predictors, and address
the question of how to evaluate them: What does it mean that a credal predictor
represents epistemic uncertainty in a faithful manner? To answer this question,
we refer to the notion of calibration of probabilistic predictors and extend it
to credal predictors. Broadly speaking, we call a credal predictor calibrated
if it returns sets that cover the true conditional probability distribution. To
verify this property for the important case of ensemble-based credal
predictors, we propose a novel nonparametric calibration test that generalizes
an existing test for probabilistic predictors to the case of credal predictors.
Making use of this test, we empirically show that credal predictors based on
deep neural networks are often not well calibrated.</p>
  </details>
</details>
<details>
  <summary>135. <b>标题：A Case of Exponential Convergence Rates for SVM</b></summary>
  <p><b>编号</b>：[291]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10055</p>
  <p><b>作者</b>：Vivien Cabannes,  Stefano Vigogna</p>
  <p><b>备注</b>：16 pages, 6 figures</p>
  <p><b>关键词</b>：machine learning classes, introductory machine learning, learning classes, introductory machine, machine learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Classification is often the first problem described in introductory machine
learning classes. Generalization guarantees of classification have historically
been offered by Vapnik-Chervonenkis theory. Yet those guarantees are based on
intractable algorithms, which has led to the theory of surrogate methods in
classification. Guarantees offered by surrogate methods are based on
calibration inequalities, which have been shown to be highly sub-optimal under
some margin conditions, failing short to capture exponential convergence
phenomena. Those "super" fast rates are becoming to be well understood for
smooth surrogates, but the picture remains blurry for non-smooth losses such as
the hinge loss, associated with the renowned support vector machines. In this
paper, we present a simple mechanism to obtain fast convergence rates and we
investigate its usage for SVM. In particular, we show that SVM can exhibit
exponential convergence rates even without assuming the hard Tsybakov margin
condition.</p>
  </details>
</details>
<details>
  <summary>136. <b>标题：Towards Extremely Fast Bilevel Optimization with Self-governed  Convergence Guarantees</b></summary>
  <p><b>编号</b>：[292]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10054</p>
  <p><b>作者</b>：Risheng Liu,  Xuan Liu,  Wei Yao,  Shangzhi Zeng,  Jin Zhang</p>
  <p><b>备注</b>：11 pages</p>
  <p><b>关键词</b>：Bi-Level Optimization, vision fields, mainstream techniques, techniques for Bi-Level, learning and vision</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Gradient methods have become mainstream techniques for Bi-Level Optimization
(BLO) in learning and vision fields. The validity of existing works heavily
relies on solving a series of approximation subproblems with extraordinarily
high accuracy. Unfortunately, to achieve the approximation accuracy requires
executing a large quantity of time-consuming iterations and computational
burden is naturally caused. This paper is thus devoted to address this critical
computational issue. In particular, we propose a single-level formulation to
uniformly understand existing explicit and implicit Gradient-based BLOs
(GBLOs). This together with our designed counter-example can clearly illustrate
the fundamental numerical and theoretical issues of GBLOs and their naive
accelerations. By introducing the dual multipliers as a new variable, we then
establish Bilevel Alternating Gradient with Dual Correction (BAGDC), a general
framework, which significantly accelerates different categories of existing
methods by taking specific settings. A striking feature of our convergence
result is that, compared to those original unaccelerated GBLO versions, the
fast BAGDC admits a unified non-asymptotic convergence theory towards
stationarity. A variety of numerical experiments have also been conducted to
demonstrate the superiority of the proposed algorithmic framework.</p>
  </details>
</details>
<details>
  <summary>137. <b>标题：Trend analysis and forecasting air pollution in Rwanda</b></summary>
  <p><b>编号</b>：[293]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10024</p>
  <p><b>作者</b>：Paterne Gahungu,  Jean Remy Kubwimana</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：middle income countries, major public health, public health problem, health problem worldwide, income countries</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Air pollution is a major public health problem worldwide although the lack of
data is a global issue for most low and middle income countries. Ambient air
pollution in the form of fine particulate matter (PM2.5) exceeds the World
Health Organization guidelines in Rwanda with a daily average of around 42.6
microgram per meter cube. Monitoring and mitigation strategies require an
expensive investment in equipment to collect pollution data. Low-cost sensor
technology and machine learning methods have appeared as an alternative
solution to get reliable information for decision making. This paper analyzes
the trend of air pollution in Rwanda and proposes forecasting models suitable
to data collected by a network of low-cost sensors deployed in Rwanda.</p>
  </details>
</details>
<details>
  <summary>138. <b>标题：Conformal Prediction with Temporal Quantile Adjustments</b></summary>
  <p><b>编号</b>：[294]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09940</p>
  <p><b>作者</b>：Zhen Lin,  Shubhendu Trivedi,  Jimeng Sun</p>
  <p><b>备注</b>：12 pages (main paper, including references) + 11 pages (supplementary material)</p>
  <p><b>关键词</b>：Temporal Quantile Adjustment, valid prediction intervals, Quantile Adjustment, develop Temporal Quantile, time series</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We develop Temporal Quantile Adjustment (TQA), a general method to construct
efficient and valid prediction intervals (PIs) for regression on
cross-sectional time series data. Such data is common in many domains,
including econometrics and healthcare. A canonical example in healthcare is
predicting patient outcomes using physiological time-series data, where a
population of patients composes a cross-section. Reliable PI estimators in this
setting must address two distinct notions of coverage: cross-sectional coverage
across a cross-sectional slice, and longitudinal coverage along the temporal
dimension for each time series. Recent works have explored adapting Conformal
Prediction (CP) to obtain PIs in the time series context. However, none handles
both notions of coverage simultaneously. CP methods typically query a
pre-specified quantile from the distribution of nonconformity scores on a
calibration set. TQA adjusts the quantile to query in CP at each time $t$,
accounting for both cross-sectional and longitudinal coverage in a
theoretically-grounded manner. The post-hoc nature of TQA facilitates its use
as a general wrapper around any time series regression model. We validate TQA's
performance through extensive experimentation: TQA generally obtains efficient
PIs and improves longitudinal coverage while preserving cross-sectional
coverage.</p>
  </details>
</details>
<details>
  <summary>139. <b>标题：Robust Expected Information Gain for Optimal Bayesian Experimental  Design Using Ambiguity Sets</b></summary>
  <p><b>编号</b>：[295]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09914</p>
  <p><b>作者</b>：Jinwoo Go,  Tobin Isaac</p>
  <p><b>备注</b>：The 38th Conference on Uncertainty in Artificial Intelligence, 2022</p>
  <p><b>关键词</b>：Bayesian experimental design, expected information gain, Bayesian experimental, model prior distribution, information gain</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The ranking of experiments by expected information gain (EIG) in Bayesian
experimental design is sensitive to changes in the model's prior distribution,
and the approximation of EIG yielded by sampling will have errors similar to
the use of a perturbed prior. We define and analyze \emph{robust expected
information gain} (REIG), a modification of the objective in EIG maximization
by minimizing an affine relaxation of EIG over an ambiguity set of
distributions that are close to the original prior in KL-divergence. We show
that, when combined with a sampling-based approach to estimating EIG, REIG
corresponds to a `log-sum-exp' stabilization of the samples used to estimate
EIG, meaning that it can be efficiently implemented in practice. Numerical
tests combining REIG with variational nested Monte Carlo (VNMC), adaptive
contrastive estimation (ACE) and mutual information neural estimation (MINE)
suggest that in practice REIG also compensates for the variability of
under-sampled estimators.</p>
  </details>
</details>
<details>
  <summary>140. <b>标题：Sparse Infinite Random Feature Latent Variable Modeling</b></summary>
  <p><b>编号</b>：[296]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09909</p>
  <p><b>作者</b>：Michael Minyi Zhang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Bayesian non-parametric latent, Indian buffet process, Bayesian non-parametric, Indian buffet, latent space</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose a non-linear, Bayesian non-parametric latent variable model where
the latent space is assumed to be sparse and infinite dimensional a priori
using an Indian buffet process prior. A posteriori, the number of instantiated
dimensions in the latent space is guaranteed to be finite. The purpose of
placing the Indian buffet process on the latent variables is to: 1.)
Automatically and probabilistically select the number of latent dimensions. 2.)
Impose sparsity in the latent space, where the Indian buffet process will
select which elements are exactly zero. Our proposed model allows for sparse,
non-linear latent variable modeling where the number of latent dimensions is
selected automatically. Inference is made tractable using the random Fourier
approximation and we can easily implement posterior inference through Markov
chain Monte Carlo sampling. This approach is amenable to many observation
models beyond the Gaussian setting. We demonstrate the utility of our method on
a variety of synthetic, biological and text datasets and show that we can
obtain superior test set performance compared to previous latent variable
models.</p>
  </details>
</details>
<details>
  <summary>141. <b>标题：Data Augmentation for Compositional Data: Advancing Predictive Models of  the Microbiome</b></summary>
  <p><b>编号</b>：[297]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09906</p>
  <p><b>作者</b>：Elliott Gordon-Rodriguez,  Thomas P. Quinn,  John P. Cunningham</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：modern machine learning, Data, Data augmentation plays, role in modern, modern machine</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Data augmentation plays a key role in modern machine learning pipelines.
While numerous augmentation strategies have been studied in the context of
computer vision and natural language processing, less is known for other data
modalities. Our work extends the success of data augmentation to compositional
data, i.e., simplex-valued data, which is of particular interest in the context
of the human microbiome. Drawing on key principles from compositional data
analysis, such as the Aitchison geometry of the simplex and subcompositions, we
define novel augmentation strategies for this data modality. Incorporating our
data augmentations into standard supervised learning pipelines results in
consistent performance gains across a wide range of standard benchmark
datasets. In particular, we set a new state-of-the-art for key disease
prediction tasks including colorectal cancer, type 2 diabetes, and Crohn's
disease. In addition, our data augmentations enable us to define a novel
contrastive learning model, which improves on previous representation learning
approaches for microbiome compositional data. Our code is available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>142. <b>标题：Estimating the frame potential of large-scale quantum circuit sampling  using tensor networks up to 50 qubits</b></summary>
  <p><b>编号</b>：[298]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09900</p>
  <p><b>作者</b>：Minzhao Liu,  Junyu Liu,  Yuri Alexeev,  Liang Jiang</p>
  <p><b>备注</b>：11 pages, many figures</p>
  <p><b>关键词</b>：develop numerical protocols, exact Haar randomness, develop numerical, numerical protocols, protocols for estimating</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We develop numerical protocols for estimating the frame potential, the 2-norm
distance between a given ensemble and the exact Haar randomness, using the
\texttt{QTensor} platform. Our tensor-network-based algorithm has polynomial
complexity for shallow circuits and is high performing using CPU and GPU
parallelism. We apply the above methods to two problems: the Brown-Susskind
conjecture, with local and parallel random circuits in terms of the Haar
distance and the approximate $k$-design properties of the hardware efficient
ans{ä}tze in quantum machine learning, which induce the barren plateau
problem. We estimate frame potentials with these ensembles up to 50 qubits and
$k=5$, examine the Haar distance of the hardware-efficient ans{ä}tze, and
verify the Brown-Susskind conjecture numerically. Our work shows that
large-scale tensor network simulations could provide important hints toward
open problems in quantum information science.</p>
  </details>
</details>
<details>
  <summary>143. <b>标题：Breaking the $\sqrt{T}$ Barrier: Instance-Independent Logarithmic Regret  in Stochastic Contextual Linear Bandits</b></summary>
  <p><b>编号</b>：[299]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09899</p>
  <p><b>作者</b>：Avishek Ghosh,  Abishek Sankararaman</p>
  <p><b>备注</b>：To appear in ICML 2022</p>
  <p><b>关键词</b>：stochastic contextual bandits, stochastic contexts, contextual linear bandit, linear contextual bandit, instance independent</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We prove an instance independent (poly) logarithmic regret for stochastic
contextual bandits with linear payoff. Previously, in \cite{chu2011contextual},
a lower bound of $\mathcal{O}(\sqrt{T})$ is shown for the contextual linear
bandit problem with arbitrary (adversarily chosen) contexts. In this paper, we
show that stochastic contexts indeed help to reduce the regret from $\sqrt{T}$
to $\polylog(T)$. We propose Low Regret Stochastic Contextual Bandits
(\texttt{LR-SCB}), which takes advantage of the stochastic contexts and
performs parameter estimation (in $\ell_2$ norm) and regret minimization
simultaneously. \texttt{LR-SCB} works in epochs, where the parameter estimation
of the previous epoch is used to reduce the regret of the current epoch. The
(poly) logarithmic regret of \texttt{LR-SCB} stems from two crucial facts: (a)
the application of a norm adaptive algorithm to exploit the parameter
estimation and (b) an analysis of the shifted linear contextual bandit
algorithm, showing that shifting results in increasing regret. We have also
shown experimentally that stochastic contexts indeed incurs a regret that
scales with $\polylog(T)$.</p>
  </details>
</details>
<details>
  <summary>144. <b>标题：Content-Context Factorized Representations for Automated Speech  Recognition</b></summary>
  <p><b>编号</b>：[301]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09872</p>
  <p><b>作者</b>：David M. Chan,  Shalini Ghosh</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：automated speech recognition, input audio frames, Deep neural networks, perform automated speech, extracting meaningful features</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep neural networks have largely demonstrated their ability to perform
automated speech recognition (ASR) by extracting meaningful features from input
audio frames. Such features, however, may consist not only of information about
the spoken language content, but also may contain information about unnecessary
contexts such as background noise and sounds or speaker identity, accent, or
protected attributes. Such information can directly harm generalization
performance, by introducing spurious correlations between the spoken words and
the context in which such words were spoken. In this work, we introduce an
unsupervised, encoder-agnostic method for factoring speech-encoder
representations into explicit content-encoding representations and spurious
context-encoding representations. By doing so, we demonstrate improved
performance on standard ASR benchmarks, as well as improved performance in both
real-world and artificially noisy ASR scenarios.</p>
  </details>
</details>
<details>
  <summary>145. <b>标题：Capturing cross-session neural population variability through  self-supervised identification of consistent neuron ensembles</b></summary>
  <p><b>编号</b>：[304]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09829</p>
  <p><b>作者</b>：Justin Jude,  Matthew G. Perich,  Lee E. Miller,  Matthias H. Hennig</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：interrogate brain function, function in research, essential part, part of brain-computer, brain-computer and brain-machine</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Decoding stimuli or behaviour from recorded neural activity is a common
approach to interrogate brain function in research, and an essential part of
brain-computer and brain-machine interfaces. Reliable decoding even from small
neural populations is possible because high dimensional neural population
activity typically occupies low dimensional manifolds that are discoverable
with suitable latent variable models. Over time however, drifts in activity of
individual neurons and instabilities in neural recording devices can be
substantial, making stable decoding over days and weeks impractical. While this
drift cannot be predicted on an individual neuron level, population level
variations over consecutive recording sessions such as differing sets of
neurons and varying permutations of consistent neurons in recorded data may be
learnable when the underlying manifold is stable over time. Classification of
consistent versus unfamiliar neurons across sessions and accounting for
deviations in the order of consistent recording neurons in recording datasets
over sessions of recordings may then maintain decoding performance. In this
work we show that self-supervised training of a deep neural network can be used
to compensate for this inter-session variability. As a result, a sequential
autoencoding model can maintain state-of-the-art behaviour decoding performance
for completely unseen recording sessions several days into the future. Our
approach only requires a single recording session for training the model, and
is a step towards reliable, recalibration-free brain computer interfaces.</p>
  </details>
</details>
<details>
  <summary>146. <b>标题：Algorithms for Weak Optimal Transport with an Application to Economics</b></summary>
  <p><b>编号</b>：[305]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09825</p>
  <p><b>作者</b>：François-Pierre Paty,  Philippe Choné,  Francis Kramarz</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：weak optimal transport, classic Monge-Kantorovich framework, WOT, optimal transport, generalizes the classic</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The theory of weak optimal transport (WOT), introduced by [Gozlan et al.,
2017], generalizes the classic Monge-Kantorovich framework by allowing the
transport cost between one point and the points it is matched with to be
nonlinear. In the so-called barycentric version of WOT, the cost for
transporting a point $x$ only depends on $x$ and on the barycenter of the
points it is matched with. This aggregation property of WOT is appealing in
machine learning, economics and finance. Yet algorithms to compute WOT have
only been developed for the special case of quadratic barycentric WOT, or
depend on neural networks with no guarantee on the computed value and matching.
The main difficulty lies in the transportation constraints which are costly to
project onto. In this paper, we propose to use mirror descent algorithms to
solve the primal and dual versions of the WOT problem. We also apply our
algorithms to the variant of WOT introduced by [Choné et al., 2022] where
mass is distributed from one space to another through unnormalized kernels
(WOTUK). We empirically compare the solutions of WOT and WOTUK with classical
OT. We illustrate our numerical methods to the economic framework of [Choné
and Kramarz, 2021], namely the matching between workers and firms on labor
markets.</p>
  </details>
</details>
<details>
  <summary>147. <b>标题：Deep Learning Methods for Proximal Inference via Maximum Moment  Restriction</b></summary>
  <p><b>编号</b>：[306]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09824</p>
  <p><b>作者</b>：Benjamin Kompa,  David R. Bellamy,  Thomas Kolokotrones,  James M. Robins,  Andrew L. Beam</p>
  <p><b>备注</b>：44 pages, 20 figures</p>
  <p><b>关键词</b>：Unmeasured Confounding Assumption, Assumption is widely, Confounding Assumption, observational studies, identify causal effects</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The No Unmeasured Confounding Assumption is widely used to identify causal
effects in observational studies. Recent work on proximal inference has
provided alternative identification results that succeed even in the presence
of unobserved confounders, provided that one has measured a sufficiently rich
set of proxy variables, satisfying specific structural conditions. However,
proximal inference requires solving an ill-posed integral equation. Previous
approaches have used a variety of machine learning techniques to estimate a
solution to this integral equation, commonly referred to as the bridge
function. However, prior work has often been limited by relying on
pre-specified kernel functions, which are not data adaptive and struggle to
scale to large datasets. In this work, we introduce a flexible and scalable
method based on a deep neural network to estimate causal effects in the
presence of unmeasured confounding using proximal inference. Our method
achieves state of the art performance on two well-established proximal
inference benchmarks. Finally, we provide theoretical consistency guarantees
for our method.</p>
  </details>
</details>
<details>
  <summary>148. <b>标题：Residual Dynamic Mode Decomposition: Robust and verified Koopmanism</b></summary>
  <p><b>编号</b>：[309]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09779</p>
  <p><b>作者</b>：Matthew J. Colbrook,  Lorna J. Ayton,  Máté Szőke</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Dynamic Mode Decomposition, simpler coherent features, Koopman operators, describes complex dynamic, complex dynamic processes</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Dynamic Mode Decomposition (DMD) describes complex dynamic processes through
a hierarchy of simpler coherent features. DMD is regularly used to understand
the fundamental characteristics of turbulence and is closely related to Koopman
operators. However, verifying the decomposition, equivalently the computed
spectral features of Koopman operators, remains a major challenge due to the
infinite-dimensional nature of Koopman operators. Challenges include spurious
(unphysical) modes, and dealing with continuous spectra, both of which occur
regularly in turbulent flows. Residual Dynamic Mode Decomposition (ResDMD),
introduced by (Colbrook & Townsend 2021), overcomes some of these challenges
through the data-driven computation of residuals associated with the full
infinite-dimensional Koopman operator. ResDMD computes spectra and
pseudospectra of general Koopman operators with error control, and computes
smoothed approximations of spectral measures (including continuous spectra)
with explicit high-order convergence theorems. ResDMD thus provides robust and
verified Koopmanism. We implement ResDMD and demonstrate its application in a
variety of fluid dynamic situations, at varying Reynolds numbers, arising from
both numerical and experimental data. Examples include: vortex shedding behind
a cylinder; hot-wire data acquired in a turbulent boundary layer; particle
image velocimetry data focusing on a wall-jet flow; and acoustic pressure
signals of laser-induced plasma. We present some advantages of ResDMD, namely,
the ability to verifiably resolve non-linear, transient modes, and spectral
calculation with reduced broadening effects. We also discuss how a new modal
ordering based on residuals enables greater accuracy with a smaller dictionary
than the traditional modulus ordering. This paves the way for greater dynamic
compression of large datasets without sacrificing accuracy.</p>
  </details>
</details>
<details>
  <summary>149. <b>标题：Deep electric field predictions by drift-reduced Braginskii theory with  plasma-neutral interactions based upon experimental images of boundary  turbulence</b></summary>
  <p><b>编号</b>：[312]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2204.11689</p>
  <p><b>作者</b>：Abhilash Mathews,  Jerry Hughes,  James Terry,  Seung-Gyou Baek</p>
  <p><b>备注</b>：7 pages, 3 figures, 2 tables</p>
  <p><b>关键词</b>：Alcator C-Mod tokamak, drift-reduced Braginskii theory, physics-informed deep learning, deep learning consistent, gas puff imaging</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present 2-dimensional turbulent electric field calculations via
physics-informed deep learning consistent with (i) drift-reduced Braginskii
theory under the framework of an axisymmetric fusion plasma with purely
toroidal field and (ii) experimental estimates of the fluctuating electron
density and temperature obtained from analysis of gas puff imaging of a
discharge on the Alcator C-Mod tokamak. The inclusion of effects from the
locally puffed atomic helium on particle and energy sources within the reduced
plasma turbulence model are found to strengthen correlations between the
electric field and electron pressure. The neutrals are also directly associated
with an observed broadening in the distribution of turbulent field amplitudes
and increased ${\bf E \times B}$ shearing rates.</p>
  </details>
</details>
<h1>人工智能</h1>
<details>
  <summary>1. <b>标题：Towards Understanding Grokking: An Effective Theory of Representation  Learning</b></summary>
  <p><b>编号</b>：[5]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10343</p>
  <p><b>作者</b>：Ziming Liu,  Ouail Kitouni,  Niklas Nolte,  Eric J. Michaud,  Max Tegmark,  Mike Williams</p>
  <p><b>备注</b>：20 pages, 16 figures</p>
  <p><b>关键词</b>：models generalize long, aim to understand, phenomenon where models, models generalize, generalize long</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We aim to understand grokking, a phenomenon where models generalize long
after overfitting their training set. We present both a microscopic analysis
anchored by an effective theory and a macroscopic analysis of phase diagrams
describing learning performance across hyperparameters. We find that
generalization originates from structured representations whose training
dynamics and dependence on training set size can be predicted by our effective
theory in a toy setting. We observe empirically the presence of four learning
phases: comprehension, grokking, memorization, and confusion. We find
representation learning to occur only in a "Goldilocks zone" (including
comprehension and grokking) between memorization and confusion. Compared to the
comprehension phase, the grokking phase stays closer to the memorization phase,
leading to delayed generalization. The Goldilocks phase is reminiscent of
"intelligence from starvation" in Darwinian evolution, where resource
limitations drive discovery of more efficient solutions. This study not only
provides intuitive explanations of the origin of grokking, but also highlights
the usefulness of physics-inspired tools, e.g., effective theories and phase
diagrams, for understanding deep learning.</p>
  </details>
</details>
<details>
  <summary>2. <b>标题：A Review of Safe Reinforcement Learning: Methods, Theory and  Applications</b></summary>
  <p><b>编号</b>：[9]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10330</p>
  <p><b>作者</b>：Shangding Gu,  Long Yang,  Yali Du,  Guang Chen,  Florian Walter,  Jun Wang,  Yaodong Yang,  Alois Knoll</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：decision making tasks, achieved tremendous success, complex decision making, safe reinforcement learning, safe</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Reinforcement learning has achieved tremendous success in many complex
decision making tasks. When it comes to deploying RL in the real world, safety
concerns are usually raised, leading to a growing demand for safe reinforcement
learning algorithms, such as in autonomous driving and robotics scenarios.
While safety control has a long history, the study of safe RL algorithms is
still in the early stages. To establish a good foundation for future research
in this thread, in this paper, we provide a review for safe RL from the
perspectives of methods, theory and applications. Firstly, we review the
progress of safe RL from five dimensions and come up with five problems that
are crucial for safe RL being deployed in real-world applications, coined as
"2H3W". Secondly, we analyze the theory and algorithm progress from the
perspectives of answering the "2H3W" problems. Then, the sample complexity of
safe RL methods is reviewed and discussed, followed by an introduction of the
applications and benchmarks of safe RL algorithms. Finally, we open the
discussion of the challenging problems in safe RL, hoping to inspire more
future research on this thread.
To advance the study of safe RL algorithms, we release a benchmark suite, an
open-sourced repository containing the implementations of major safe RL
algorithms, along with tutorials at the link:
this https URL.</p>
  </details>
</details>
<details>
  <summary>3. <b>标题：Nothing makes sense in deep learning, except in the light of evolution</b></summary>
  <p><b>编号</b>：[12]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10320</p>
  <p><b>作者</b>：Artem Kaznatcheev,  Konrad Paul Kording</p>
  <p><b>备注</b>：11 pages, 2 figures, 1 table</p>
  <p><b>关键词</b>：surprisingly successful branch, Deep Learning, machine learning, surprisingly successful, successful branch</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep Learning (DL) is a surprisingly successful branch of machine learning.
The success of DL is usually explained by focusing analysis on a particular
recent algorithm and its traits. Instead, we propose that an explanation of the
success of DL must look at the population of all algorithms in the field and
how they have evolved over time. We argue that cultural evolution is a useful
framework to explain the success of DL. In analogy to biology, we use
`development' to mean the process converting the pseudocode or text description
of an algorithm into a fully trained model. This includes writing the
programming code, compiling and running the program, and training the model. If
all parts of the process don't align well then the resultant model will be
useless (if the code runs at all!). This is a constraint. A core component of
evolutionary developmental biology is the concept of deconstraints -- these are
modification to the developmental process that avoid complete failure by
automatically accommodating changes in other components. We suggest that many
important innovations in DL, from neural networks themselves to hyperparameter
optimization and AutoGrad, can be seen as developmental deconstraints. These
deconstraints can be very helpful to both the particular algorithm in how it
handles challenges in implementation and the overall field of DL in how easy it
is for new ideas to be generated. We highlight how our perspective can both
advance DL and lead to new insights for evolutionary biology.</p>
  </details>
</details>
<details>
  <summary>4. <b>标题：Seeking entropy: complex behavior from intrinsic motivation to occupy  action-state path space</b></summary>
  <p><b>编号</b>：[13]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10316</p>
  <p><b>作者</b>：Jorge Ramírez-Ruiz,  Dmytro Grytskyy,  Rubén Moreno-Bote</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Intrinsic motivation generates, motivation generates behaviors, Intrinsic motivation, exploration and learning, motivation generates</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Intrinsic motivation generates behaviors that do not necessarily lead to
immediate reward, but help exploration and learning. Here we show that agents
having the sole goal of maximizing occupancy of future actions and states, that
is, moving and exploring on the long term, are capable of complex behavior
without any reference to external rewards. We find that action-state path
entropy is the only measure consistent with additivity and other intuitive
properties of expected future action-state path occupancy. We provide
analytical expressions that relate the optimal policy with the optimal
state-value function, from where we prove uniqueness of the solution of the
associated Bellman equation and convergence of our algorithm to the optimal
state-value function. Using discrete and continuous state tasks, we show that
`dancing', hide-and-seek and a basic form of altruistic behavior naturally
result from entropy seeking without external rewards. Intrinsically motivated
agents can objectively determine what states constitute rewards, exploiting
them to ultimately maximize action-state path entropy.</p>
  </details>
</details>
<details>
  <summary>5. <b>标题：ClusterEA: Scalable Entity Alignment with Stochastic Training and  Normalized Mini-batch Similarities</b></summary>
  <p><b>编号</b>：[14]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10312</p>
  <p><b>作者</b>：Yunjun Gao,  Xiaoze Liu,  Junyang Wu,  Tianyi Li,  Pengfei Wang,  Lu Chen</p>
  <p><b>备注</b>：Accepted by ACM SIGKDD 2022 Research Track</p>
  <p><b>关键词</b>：aims at finding, knowledge graphs, finding equivalent entities, Entity alignment, finding equivalent</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Entity alignment (EA) aims at finding equivalent entities in different
knowledge graphs (KGs). Embedding-based approaches have dominated the EA task
in recent years. Those methods face problems that come from the geometric
properties of embedding vectors, including hubness and isolation. To solve
these geometric problems, many normalization approaches have been adopted to
EA. However, the increasing scale of KGs renders it is hard for EA models to
adopt the normalization processes, thus limiting their usage in real-world
applications. To tackle this challenge, we present ClusterEA, a general
framework that is capable of scaling up EA models and enhancing their results
by leveraging normalization methods on mini-batches with a high entity
equivalent rate. ClusterEA contains three components to align entities between
large-scale KGs, including stochastic training, ClusterSampler, and
SparseFusion. It first trains a large-scale Siamese GNN for EA in a stochastic
fashion to produce entity embeddings. Based on the embeddings, a novel
ClusterSampler strategy is proposed for sampling highly overlapped
mini-batches. Finally, ClusterEA incorporates SparseFusion, which normalizes
local and global similarity and then fuses all similarity matrices to obtain
the final similarity matrix. Extensive experiments with real-life datasets on
EA benchmarks offer insight into the proposed framework, and suggest that it is
capable of outperforming the state-of-the-art scalable EA framework by up to 8
times in terms of Hits@1.</p>
  </details>
</details>
<details>
  <summary>6. <b>标题：Low-cost Relevance Generation and Evaluation Metrics for Entity  Resolution in AI</b></summary>
  <p><b>编号</b>：[18]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10298</p>
  <p><b>作者</b>：Venkat Varada,  Mina Ghashami,  Jitesh Mehta,  Haotian Jiang,  Kurtis Voris</p>
  <p><b>备注</b>：6 pages, 3 figures</p>
  <p><b>关键词</b>：real world entities, Entity Resolution, resolves entities, world entities, voice assistants</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Entity Resolution (ER) in voice assistants is a prime component during run
time that resolves entities in users request to real world entities. ER
involves two major functionalities 1. Relevance generation and 2. Ranking. In
this paper we propose a low cost relevance generation framework by generating
features using customer implicit and explicit feedback signals. The generated
relevance datasets can serve as test sets to measure ER performance. We also
introduce a set of metrics that accurately measures the performance of ER
systems in various dimensions. They provide great interpretability to deep dive
and identifying root cause of ER issues, whether the problem is in relevance
generation or ranking.</p>
  </details>
</details>
<details>
  <summary>7. <b>标题：Explanatory machine learning for sequential human teaching</b></summary>
  <p><b>编号</b>：[37]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10250</p>
  <p><b>作者</b>：Lun Ai,  Johannes Langer,  Stephen H. Muggleton,  Ute Schmid</p>
  <p><b>备注</b>：Submitted to the International Joint Conference on Learning & Reasoning (IJCLR) 2022</p>
  <p><b>关键词</b>：drawn increasing attention, recently drawn increasing, human comprehension, Logic Programming, Inductive Logic Programming</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The topic of comprehensibility of machine-learned theories has recently drawn
increasing attention. Inductive Logic Programming (ILP) uses logic programming
to derive logic theories from small data based on abduction and induction
techniques. Learned theories are represented in the form of rules as
declarative descriptions of obtained knowledge. In earlier work, the authors
provided the first evidence of a measurable increase in human comprehension
based on machine-learned logic rules for simple classification tasks. In a
later study, it was found that the presentation of machine-learned explanations
to humans can produce both beneficial and harmful effects in the context of
game learning. We continue our investigation of comprehensibility by examining
the effects of the ordering of concept presentations on human comprehension. In
this work, we examine the explanatory effects of curriculum order and the
presence of machine-learned explanations for sequential problem-solving. We
show that 1) there exist tasks A and B such that learning A before B has a
better human comprehension with respect to learning B before A and 2) there
exist tasks A and B such that the presence of explanations when learning A
contributes to improved human comprehension when subsequently learning B. We
propose a framework for the effects of sequential teaching on comprehension
based on an existing definition of comprehensibility and provide evidence for
support from data collected in human trials. Empirical results show that
sequential teaching of concepts with increasing complexity a) has a beneficial
effect on human comprehension and b) leads to human re-discovery of
divide-and-conquer problem-solving strategies, and c) studying machine-learned
explanations allows adaptations of human problem-solving strategy with better
performance.</p>
  </details>
</details>
<details>
  <summary>8. <b>标题：Sampling Is All You Need on Modeling Long-Term User Behaviors for CTR  Prediction</b></summary>
  <p><b>编号</b>：[38]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10249</p>
  <p><b>作者</b>：Yue Cao,  XiaoJiang Zhou,  Jiaqi Feng,  Peihao Huang,  Yao Xiao,  Dayao Chen,  Sheng Chen</p>
  <p><b>备注</b>：Under review, 11 pages</p>
  <p><b>关键词</b>：long-term user behaviors, user behaviors, Rich user behavior, user behavior data, user</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Rich user behavior data has been proven to be of great value for
Click-Through Rate (CTR) prediction applications, especially in industrial
recommender, search, or advertising systems. However, it's non-trivial for
real-world systems to make full use of long-term user behaviors due to the
strict requirements of online serving time. Most previous works adopt the
retrieval-based strategy, where a small number of user behaviors are retrieved
first for subsequent attention. However, the retrieval-based methods are
sub-optimal and would cause more or less information losses, and it's difficult
to balance the effectiveness and efficiency of the retrieval algorithm.
In this paper, we propose \textbf{SDIM} (\textbf{S}ampling-based
\textbf{D}eep \textbf{I}nterest \textbf{M}odeling), a simple yet effective
sampling-based end-to-end approach for modeling long-term user behaviors. We
sample from multiple hash functions to generate hash signatures of the
candidate item and each item in the user behavior sequence, and obtain the user
interest by directly gathering behavior items associated with the candidate
item with the same hash signature. We show theoretically and experimentally
that the proposed method performs on par with standard attention-based models
on modeling long-term user behaviors, while being sizable times faster. We also
introduce the deployment of SDIM in our system. Specifically, we decouple the
behavior sequence hashing, which is the most time-consuming part, from the CTR
model by designing a separate module named BSE (behavior Sequence Encoding).
BSE is latency-free for the CTR server, enabling us to model extremely long
user behaviors. Both offline and online experiments are conducted to
demonstrate the effectiveness of SDIM. SDIM now has been deployed online in the
search system of Meituan APP.</p>
  </details>
</details>
<details>
  <summary>9. <b>标题：M3ED: Multi-modal Multi-scene Multi-label Emotional Dialogue Database</b></summary>
  <p><b>编号</b>：[44]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10237</p>
  <p><b>作者</b>：Jinming Zhao,  Tenggan Zhang,  Jingwen Hu,  Yuchen Liu,  Qin Jin,  Xinchao Wang,  Haizhou Li</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Multi-modal Multi-scene Multi-label, Multi-scene Multi-label Emotional, Multi-label Emotional Dialogue, Emotional Dialogue dataset, interlocutor stimulus</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The emotional state of a speaker can be influenced by many different factors
in dialogues, such as dialogue scene, dialogue topic, and interlocutor
stimulus. The currently available data resources to support such multimodal
affective analysis in dialogues are however limited in scale and diversity. In
this work, we propose a Multi-modal Multi-scene Multi-label Emotional Dialogue
dataset, M3ED, which contains 990 dyadic emotional dialogues from 56 different
TV series, a total of 9,082 turns and 24,449 utterances. M3 ED is annotated
with 7 emotion categories (happy, surprise, sad, disgust, anger, fear, and
neutral) at utterance level, and encompasses acoustic, visual, and textual
modalities. To the best of our knowledge, M3ED is the first multimodal
emotional dialogue dataset in Chinese. It is valuable for cross-culture emotion
analysis and recognition. We apply several state-of-the-art methods on the M3ED
dataset to verify the validity and quality of the dataset. We also propose a
general Multimodal Dialogue-aware Interaction framework, MDI, to model the
dialogue context for emotion recognition, which achieves comparable performance
to the state-of-the-art methods on the M3ED. The full dataset and codes are
available.</p>
  </details>
</details>
<details>
  <summary>10. <b>标题：Exploring the Trade-off between Plausibility, Change Intensity and  Adversarial Power in Counterfactual Explanations using Multi-objective  Optimization</b></summary>
  <p><b>编号</b>：[49]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10232</p>
  <p><b>作者</b>：Javier Del Ser,  Alejandro Barredo-Arrieta,  Natalia Díaz-Rodríguez,  Francisco Herrera,  Andreas Holzinger</p>
  <p><b>备注</b>：52 pages, 14 figures, under review</p>
  <p><b>关键词</b>：deep learning models, involving complex data, tasks involving complex, broad consensus, importance of deep</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>There is a broad consensus on the importance of deep learning models in tasks
involving complex data. Often, an adequate understanding of these models is
required when focusing on the transparency of decisions in human-critical
applications. Besides other explainability techniques, trustworthiness can be
achieved by using counterfactuals, like the way a human becomes familiar with
an unknown process: by understanding the hypothetical circumstances under which
the output changes. In this work we argue that automated counterfactual
generation should regard several aspects of the produced adversarial instances,
not only their adversarial capability. To this end, we present a novel
framework for the generation of counterfactual examples which formulates its
goal as a multi-objective optimization problem balancing three different
objectives: 1) plausibility, i.e., the likeliness of the counterfactual of
being possible as per the distribution of the input data; 2) intensity of the
changes to the original input; and 3) adversarial power, namely, the
variability of the model's output induced by the counterfactual. The framework
departs from a target model to be audited and uses a Generative Adversarial
Network to model the distribution of input data, together with a
multi-objective solver for the discovery of counterfactuals balancing among
these objectives. The utility of the framework is showcased over six
classification tasks comprising image and three-dimensional data. The
experiments verify that the framework unveils counterfactuals that comply with
intuition, increasing the trustworthiness of the user, and leading to further
insights, such as the detection of bias and data misrepresentation.</p>
  </details>
</details>
<details>
  <summary>11. <b>标题：Mosaic Zonotope Shadow Matching for Risk-Aware Autonomous Localization  in Harsh Urban Environments</b></summary>
  <p><b>编号</b>：[55]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10223</p>
  <p><b>作者</b>：Daniel Neamati,  Sriramya Bhamidipati,  Grace Gao</p>
  <p><b>备注</b>：Submitted to AIJ Special Issue on Risk-Aware Autonomous Systems: Theory and Practice</p>
  <p><b>关键词</b>：Global Navigation Satellite, Global Navigation, Navigation Satellite System, GNSS shadow matching, shadow matching</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Risk-aware urban localization with the Global Navigation Satellite System
(GNSS) remains an unsolved problem with frequent misdetection of the user's
street or side of the street. Significant advances in 3D map-aided GNSS use
grid-based GNSS shadow matching alongside AI-driven line-of-sight (LOS)
classifiers and server-based processing to improve localization accuracy,
especially in the cross-street direction. Our prior work introduces a new
paradigm for shadow matching that proposes set-valued localization with
computationally efficient zonotope set representations. While existing
literature improved accuracy and efficiency, the current state of shadow
matching theory does not address the needs of risk-aware autonomous systems. We
extend our prior work to propose Mosaic Zonotope Shadow Matching (MZSM) that
employs a classifier-agnostic polytope mosaic architecture to provide
risk-awareness and certifiable guarantees on urban positioning. We formulate a
recursively expanding binary tree that refines an initial location estimate
with set operations into smaller polytopes. Together, the smaller polytopes
form a mosaic. We weight the tree branches with the probability that the user
is in line of sight of the satellite and expand the tree with each new
satellite observation. Our method yields an exact shadow matching distribution
from which we guarantee uncertainty bounds on the user localization. We perform
high-fidelity simulations using a 3D building map of San Francisco to validate
our algorithm's risk-aware improvements. We demonstrate that MZSM provides
certifiable guarantees across varied data-driven LOS classifier accuracies and
yields a more precise understanding of the uncertainty over existing methods.
We validate that our tree-based construction is efficient and tractable,
computing a mosaic from 14 satellites in 0.63 seconds and growing quadratically
in the satellite number.</p>
  </details>
</details>
<details>
  <summary>12. <b>标题：Learning Task-relevant Representations for Generalization via  Characteristic Functions of Reward Sequence Distributions</b></summary>
  <p><b>编号</b>：[57]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10218</p>
  <p><b>作者</b>：Rui Yang,  Jie Wang,  Zijie Geng,  Mingxuan Ye,  Shuiwang Ji,  Bin Li,  Feng Wu</p>
  <p><b>备注</b>：Accepted to KDD'22</p>
  <p><b>关键词</b>：visual reinforcement learning, critical for successful, successful applications, visual distractions, real scenarios</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Generalization across different environments with the same tasks is critical
for successful applications of visual reinforcement learning (RL) in real
scenarios. However, visual distractions -- which are common in real scenes --
from high-dimensional observations can be hurtful to the learned
representations in visual RL, thus degrading the performance of generalization.
To tackle this problem, we propose a novel approach, namely Characteristic
Reward Sequence Prediction (CRESP), to extract the task-relevant information by
learning reward sequence distributions (RSDs), as the reward signals are
task-relevant in RL and invariant to visual distractions. Specifically, to
effectively capture the task-relevant information via RSDs, CRESP introduces an
auxiliary task -- that is, predicting the characteristic functions of RSDs --
to learn task-relevant representations, because we can well approximate the
high-dimensional distributions by leveraging the corresponding characteristic
functions. Experiments demonstrate that CRESP significantly improves the
performance of generalization on unseen environments, outperforming several
state-of-the-arts on DeepMind Control tasks with different visual distractions.</p>
  </details>
</details>
<details>
  <summary>13. <b>标题：Measuring algorithmic interpretability: A human-learning-based framework  and the corresponding cognitive complexity score</b></summary>
  <p><b>编号</b>：[59]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10207</p>
  <p><b>作者</b>：John P. Lalor,  Hong Guo</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：ensure fairness, Algorithmic interpretability, track accountability, measuring algorithmic interpretability, measurement framework</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Algorithmic interpretability is necessary to build trust, ensure fairness,
and track accountability. However, there is no existing formal measurement
method for algorithmic interpretability. In this work, we build upon
programming language theory and cognitive load theory to develop a framework
for measuring algorithmic interpretability. The proposed measurement framework
reflects the process of a human learning an algorithm. We show that the
measurement framework and the resulting cognitive complexity score have the
following desirable properties - universality, computability, uniqueness, and
monotonicity. We illustrate the measurement framework through a toy example,
describe the framework and its conceptual underpinnings, and demonstrate the
benefits of the framework, in particular for managers considering tradeoffs
when selecting algorithms.</p>
  </details>
</details>
<details>
  <summary>14. <b>标题：On the Decentralization of Blockchain-enabled Asynchronous Federated  Learning</b></summary>
  <p><b>编号</b>：[63]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10201</p>
  <p><b>作者</b>：Francesc Wilhelmi,  Elia Guerra,  Paolo Dini</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：edge computing paradigm, enable true real-time, true real-time applications, Federated learning, computing paradigm</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Federated learning (FL), thanks in part to the emergence of the edge
computing paradigm, is expected to enable true real-time applications in
production environments. However, its original dependence on a central server
for orchestration raises several concerns in terms of security, privacy, and
scalability. To solve some of these worries, blockchain technology is expected
to bring decentralization, robustness, and enhanced trust to FL. The
empowerment of FL through blockchain (also referred to as FLchain), however,
has some implications in terms of ledger inconsistencies and age of information
(AoI), which are naturally inherited from the blockchain's fully decentralized
operation. Such issues stem from the fact that, given the temporary ledger
versions in the blockchain, FL devices may use different models for training,
and that, given the asynchronicity of the FL operation, stale local updates
(computed using outdated models) may be generated. In this paper, we shed light
on the implications of the FLchain setting and study the effect that both the
AoI and ledger inconsistencies have on the FL performance. To that end, we
provide a faithful simulation tool that allows capturing the decentralized and
asynchronous nature of the FLchain operation.</p>
  </details>
</details>
<details>
  <summary>15. <b>标题：A Novel Underwater Image Enhancement and Improved Underwater Biological  Detection Pipeline</b></summary>
  <p><b>编号</b>：[64]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10199</p>
  <p><b>作者</b>：Zheng Liu,  Yaoming Zhuang,  Pengrun Jia,  Chengdong Wu,  Hongli Xu ang Zhanlin Liu</p>
  <p><b>备注</b>：14 pages,14 figures</p>
  <p><b>关键词</b>：ecological environment monitoring, aquaculture resource evaluation, organisms is critical, aquaculture resource, identification of marine</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>For aquaculture resource evaluation and ecological environment monitoring,
automatic detection and identification of marine organisms is critical.
However, due to the low quality of underwater images and the characteristics of
underwater biological, a lack of abundant features may impede traditional
hand-designed feature extraction approaches or CNN-based object detection
algorithms, particularly in complex underwater environment. Therefore, the goal
of this paper is to perform object detection in the underwater environment.
This paper proposed a novel method for capturing feature information, which
adds the convolutional block attention module (CBAM) to the YOLOv5 backbone.
The interference of underwater creature characteristics on object
characteristics is decreased, and the output of the backbone network to object
information is enhanced. In addition, the self-adaptive global histogram
stretching algorithm (SAGHS) is designed to eliminate the degradation problems
such as low contrast and color loss caused by underwater environmental
information to better restore image quality. Extensive experiments and
comprehensive evaluation on the URPC2021 benchmark dataset demonstrate the
effectiveness and adaptivity of our methods. Beyond that, this paper conducts
an exhaustive analysis of the role of training data on performance.</p>
  </details>
</details>
<details>
  <summary>16. <b>标题：Progressive Class Semantic Matching for Semi-supervised Text  Classification</b></summary>
  <p><b>编号</b>：[68]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10189</p>
  <p><b>作者</b>：Hai-Ming Xu,  Lingqiao Liu,  Ehsan Abbasnejad</p>
  <p><b>备注</b>：NAACL2022 (oral)</p>
  <p><b>关键词</b>：cost for text-classification, Semi-supervised learning, reduce the annotation, annotation cost, Semi-supervised</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Semi-supervised learning is a promising way to reduce the annotation cost for
text-classification. Combining with pre-trained language models (PLMs), e.g.,
BERT, recent semi-supervised learning methods achieved impressive performance.
In this work, we further investigate the marriage between semi-supervised
learning and a pre-trained language model. Unlike existing approaches that
utilize PLMs only for model parameter initialization, we explore the inherent
topic matching capability inside PLMs for building a more powerful
semi-supervised learning approach. Specifically, we propose a joint
semi-supervised learning process that can progressively build a standard
$K$-way classifier and a matching network for the input text and the Class
Semantic Representation (CSR). The CSR will be initialized from the given
labeled sentences and progressively updated through the training process. By
means of extensive experiments, we show that our method can not only bring
remarkable improvement to baselines, but also overall be more stable, and
achieves state-of-the-art performance in semi-supervised text classification.</p>
  </details>
</details>
<details>
  <summary>17. <b>标题：Adversarial Body Shape Search for Legged Robots</b></summary>
  <p><b>编号</b>：[70]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10187</p>
  <p><b>作者</b>：Takaaki Azakami,  Hiroshi Kera,  Kazuhiko Kawamoto</p>
  <p><b>备注</b>：6 pages, 7 figures</p>
  <p><b>关键词</b>：deep reinforcement learning, adversarial body shape, evolutionary computation method, adversarial body, body shape</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose an evolutionary computation method for an adversarial attack on
the length and thickness of parts of legged robots by deep reinforcement
learning. This attack changes the robot body shape and interferes with
walking-we call the attacked body as adversarial body shape. The evolutionary
computation method searches adversarial body shape by minimizing the expected
cumulative reward earned through walking simulation. To evaluate the
effectiveness of the proposed method, we perform experiments with three-legged
robots, Walker2d, Ant-v2, and Humanoid-v2 in OpenAI Gym. The experimental
results reveal that Walker2d and Ant-v2 are more vulnerable to the attack on
the length than the thickness of the body parts, whereas Humanoid-v2 is
vulnerable to the attack on both of the length and thickness. We further
identify that the adversarial body shapes break left-right symmetry or shift
the center of gravity of the legged robots. Finding adversarial body shape can
be used to proactively diagnose the vulnerability of legged robot walking.</p>
  </details>
</details>
<details>
  <summary>18. <b>标题：Task Relabelling for Multi-task Transfer using Successor Features</b></summary>
  <p><b>编号</b>：[77]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10175</p>
  <p><b>作者</b>：Martin Balla,  Diego Perez-Liebana</p>
  <p><b>备注</b>：accepted for publication in IEEE Conference on Games (CoG) 2022</p>
  <p><b>关键词</b>：Deep Reinforcement Learning, Deep Reinforcement, Reinforcement Learning, complex domains, successful recently</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep Reinforcement Learning has been very successful recently with various
works on complex domains. Most works are concerned with learning a single
policy that solves the target task, but is fixed in the sense that if the
environment changes the agent is unable to adapt to it. Successor Features
(SFs) proposes a mechanism that allows learning policies that are not tied to
any particular reward function. In this work we investigate how SFs may be
pre-trained without observing any reward in a custom environment that features
resource collection, traps and crafting. After pre-training we expose the SF
agents to various target tasks and see how well they can transfer to new tasks.
Transferring is done without any further training on the SF agents, instead
just by providing a task vector. For training the SFs we propose a task
relabelling method which greatly improves the agent's performance.</p>
  </details>
</details>
<details>
  <summary>19. <b>标题：The developmental trajectory of object recognition robustness: children  are like small adults but unlike big deep neural networks</b></summary>
  <p><b>编号</b>：[90]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10144</p>
  <p><b>作者</b>：Lukas S. Huber,  Robert Geirhos,  Felix A. Wichmann</p>
  <p><b>备注</b>：Manuscript under review at Journal of Vision</p>
  <p><b>关键词</b>：Deep Neural Networks, Neural Networks, Deep Neural, unicode, recognition tasks based</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In laboratory object recognition tasks based on undistorted photographs, both
adult humans and Deep Neural Networks (DNNs) perform close to ceiling. Unlike
adults', whose object recognition performance is robust against a wide range of
image distortions, DNNs trained on standard ImageNet (1.3M images) perform
poorly on distorted images. However, the last two years have seen impressive
gains in DNN distortion robustness, predominantly achieved through
ever-increasing large-scale datasets$\unicode{x2014}$orders of magnitude larger
than ImageNet. While this simple brute-force approach is very effective in
achieving human-level robustness in DNNs, it raises the question of whether
human robustness, too, is simply due to extensive experience with (distorted)
visual input during childhood and beyond. Here we investigate this question by
comparing the core object recognition performance of 146 children (aged
4$\unicode{x2013}$15) against adults and against DNNs. We find, first, that
already 4$\unicode{x2013}$6 year-olds showed remarkable robustness to image
distortions and outperform DNNs trained on ImageNet. Second, we estimated the
number of $\unicode{x201C}$images$\unicode{x201D}$ children have been exposed
to during their lifetime. Compared to various DNNs, children's high robustness
requires relatively little data. Third, when recognizing objects
children$\unicode{x2014}$like adults but unlike DNNs$\unicode{x2014}$rely
heavily on shape but not on texture cues. Together our results suggest that the
remarkable robustness to distortions emerges early in the developmental
trajectory of human object recognition and is unlikely the result of a mere
accumulation of experience with distorted visual input. Even though current
DNNs match human performance regarding robustness they seem to rely on
different and more data-hungry strategies to do so.</p>
  </details>
</details>
<details>
  <summary>20. <b>标题：Agent-Based modeling in Medical Research. Example in Health Economics</b></summary>
  <p><b>编号</b>：[95]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10131</p>
  <p><b>作者</b>：Philippe Saint-Pierre,  Romain Demeulemeester,  Nadège Costa,  Nicolas Savy</p>
  <p><b>备注</b>：30 pages, 16 figures</p>
  <p><b>关键词</b>：agent based modeling, medical research, main lines, lines of agent, agent based</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This chapter presents the main lines of agent based modeling in the field of
medical research. The general diagram consists of a cohort of patients (virtual
or real) whose evolution is observed by means of so-called evolution models.
Scenarios can then be explored by varying the parameters of the different
models. This chapter presents techniques for virtual patient generation and
examples of execution models. The advantages and disadvantages of these models
are discussed as well as the pitfalls to be avoided. Finally, an application to
the medico-economic study of the impact of the penetration rate of generic
versions of treatments on the costs associated with HIV treatment is presented.</p>
  </details>
</details>
<details>
  <summary>21. <b>标题：Neural-Symbolic Models for Logical Queries on Knowledge Graphs</b></summary>
  <p><b>编号</b>：[98]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10128</p>
  <p><b>作者</b>：Zhaocheng Zhu,  Mikhail Galkin,  Zuobai Zhang,  Jian Tang</p>
  <p><b>备注</b>：ICML 2022</p>
  <p><b>关键词</b>：fundamental task, task for multi-hop, Graph Neural Network, knowledge, graph</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Answering complex first-order logic (FOL) queries on knowledge graphs is a
fundamental task for multi-hop reasoning. Traditional symbolic methods traverse
a complete knowledge graph to extract the answers, which provides good
interpretation for each step. Recent neural methods learn geometric embeddings
for complex queries. These methods can generalize to incomplete knowledge
graphs, but their reasoning process is hard to interpret. In this paper, we
propose Graph Neural Network Query Executor (GNN-QE), a neural-symbolic model
that enjoys the advantages of both worlds. GNN-QE decomposes a complex FOL
query into relation projections and logical operations over fuzzy sets, which
provides interpretability for intermediate variables. To reason about the
missing links, GNN-QE adapts a graph neural network from knowledge graph
completion to execute the relation projections, and models the logical
operations with product fuzzy logic. Extensive experiments on 3 datasets show
that GNN-QE significantly improves over previous state-of-the-art models in
answering FOL queries. Meanwhile, GNN-QE can predict the number of answers
without explicit supervision, and provide visualizations for intermediate
variables.</p>
  </details>
</details>
<details>
  <summary>22. <b>标题：Construction of Rough graph to handle uncertain pattern from an  Information System</b></summary>
  <p><b>编号</b>：[99]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10127</p>
  <p><b>作者</b>：R. Aruna Devi,  K. Anitha</p>
  <p><b>备注</b>：13 pages, 11 figures</p>
  <p><b>关键词</b>：membership function defines, Rough membership function, membership function, defines the measurement, measurement of relationship</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Rough membership function defines the measurement of relationship between
conditional and decision attribute from an Information system. In this paper we
propose a new method to construct rough graph through rough membership function
$\omega_{G}^F(f)$. Rough graph identifies the pattern between the objects with
imprecise and uncertain information. We explore the operations and properties
of rough graph in various stages of its structure.</p>
  </details>
</details>
<details>
  <summary>23. <b>标题：On Evaluating Power Loss with HATSGA Algorithm for Power Network  Reconfiguration in the Smart Grid</b></summary>
  <p><b>编号</b>：[100]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10126</p>
  <p><b>作者</b>：Flavio Galvao Calhau,  Alysson Pezzutti,  Joberto S. B. Martins</p>
  <p><b>备注</b>：7 pp</p>
  <p><b>关键词</b>：Smart Grid context, Smart Grid, Grid context, reconfiguration algorithm HATSGA, network reconfiguration algorithm</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper presents the power network reconfiguration algorithm HATSGA with a
"R" modeling approach and evaluates its behavior in computing new
reconfiguration topologies for the power network in the Smart Grid context. The
modeling of the power distribution network with the language "R" is used to
represent the network and support the computation of distinct algorithm
configurations towards the evaluation of new reconfiguration topologies. The
HATSGA algorithm adopts a hybrid Tabu Search and Genetic Algorithm strategy and
can be configured in different ways to compute network reconfiguration
solutions. The evaluation of power loss with HATSGA uses the IEEE 14-Bus
topology as the power test scenario. The evaluation of reconfiguration
topologies with minimum power loss with HATSGA indicates that an efficient
solution can be reached with a feasible computational time. This suggests that
HATSGA can be potentially used for computing reconfiguration network topologies
and, beyond that, it can be used for autonomic self-healing management
approaches where a feasible computational time is required.</p>
  </details>
</details>
<details>
  <summary>24. <b>标题：The Fellowship of the Dyson Ring: ACT&Friends' Results and Methods for  GTOC 11</b></summary>
  <p><b>编号</b>：[101]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10124</p>
  <p><b>作者</b>：Marcus Märtens,  Dario Izzo,  Emmanuel Blazquez,  Moritz von Looz,  Pablo Gómez,  Anne Mergy,  Giacomo Acciarini,  Chit Hong Yam,  Javier Hernando Ayuso,  Yuri Shimane</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：hypothetical megastructures encircling, megastructures encircling stars, energy output, spheres are hypothetical, hypothetical megastructures</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Dyson spheres are hypothetical megastructures encircling stars in order to
harvest most of their energy output. During the 11th edition of the GTOC
challenge, participants were tasked with a complex trajectory planning related
to the construction of a precursor Dyson structure, a heliocentric ring made of
twelve stations. To this purpose, we developed several new approaches that
synthesize techniques from machine learning, combinatorial optimization,
planning and scheduling, and evolutionary optimization effectively integrated
into a fully automated pipeline. These include a machine learned transfer time
estimator, improving the established Edelbaum approximation and thus better
informing a Lazy Race Tree Search to identify and collect asteroids with high
arrival mass for the stations; a series of optimally-phased low-thrust
transfers to all stations computed by indirect optimization techniques,
exploiting the synodic periodicity of the system; and a modified Hungarian
scheduling algorithm, which utilizes evolutionary techniques to arrange a
mass-balanced arrival schedule out of all transfer possibilities. We describe
the steps of our pipeline in detail with a special focus on how our approaches
mutually benefit from each other. Lastly, we outline and analyze the final
solution of our team, ACT&Friends, which ranked second at the GTOC 11
challenge.</p>
  </details>
</details>
<details>
  <summary>25. <b>标题：Lifelong Personal Context Recognition</b></summary>
  <p><b>编号</b>：[102]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10123</p>
  <p><b>作者</b>：Andrea Bontempelli,  Marcelo Rodas Britez,  Xiaoyue Li,  Haonan Zhao,  Luca Erculiani,  Stefano Teso,  Andrea Passerini,  Fausto Giunchiglia</p>
  <p><b>备注</b>：8 pages</p>
  <p><b>关键词</b>：development of AIs, AIs which live, lifelong symbiosis, performing lifelong context, lifelong context recognition</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We focus on the development of AIs which live in lifelong symbiosis with a
human. The key prerequisite for this task is that the AI understands - at any
moment in time - the personal situational context that the human is in. We
outline the key challenges that this task brings forth, namely (i) handling the
human-like and ego-centric nature of the the user's context, necessary for
understanding and providing useful suggestions, (ii) performing lifelong
context recognition using machine learning in a way that is robust to change,
and (iii) maintaining alignment between the AI's and human's representations of
the world through continual bidirectional interaction. In this short paper, we
summarize our recent attempts at tackling these challenges, discuss the lessons
learned, and highlight directions of future research. The main take-away
message is that pursuing this project requires research which lies at the
intersection of knowledge representation and machine learning. Neither
technology can achieve this goal without the other.</p>
  </details>
</details>
<details>
  <summary>26. <b>标题：Privacy Preserving Image Registration</b></summary>
  <p><b>编号</b>：[105]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10120</p>
  <p><b>作者</b>：Riccardo Taiello,  Melek Önen,  Olivier Humbert,  Marco Lorenzi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：spatial reference frame, Image registration, common spatial reference, registration, allowing to represent</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Image registration is a key task in medical imaging applications, allowing to
represent medical images in a common spatial reference frame. Current
literature on image registration is generally based on the assumption that
images are usually accessible to the researcher, from which the spatial
transformation is subsequently estimated. This common assumption may not be met
in current practical applications, since the sensitive nature of medical images
may ultimately require their analysis under privacy constraints, preventing to
share the image content in clear form. In this work, we formulate the problem
of image registration under a privacy preserving regime, where images are
assumed to be confidential and cannot be disclosed in clear. We derive our
privacy preserving image registration framework by extending classical
registration paradigms to account for advanced cryptographic tools, such as
secure multi-party computation and homomorphic encryption, that enable the
execution of operations without leaking the underlying data. To overcome the
problem of performance and scalability of cryptographic tools in high
dimensions, we first propose to optimize the underlying image registration
operations using gradient approximations. We further revisit the use of
homomorphic encryption and use a packing method to allow the encryption and
multiplication of large matrices more efficiently. We demonstrate our privacy
preserving framework in linear and non-linear registration problems, evaluating
its accuracy and scalability with respect to standard image registration. Our
results show that privacy preserving image registration is feasible and can be
adopted in sensitive medical imaging applications.</p>
  </details>
</details>
<details>
  <summary>27. <b>标题：Is explainable AI a race against model complexity?</b></summary>
  <p><b>编号</b>：[106]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10119</p>
  <p><b>作者</b>：Advait Sarkar</p>
  <p><b>备注</b>：Workshop on Transparency and Explanations in Smart Systems (TExSS 2022), at the 27th International Conference on Intelligent User Interfaces (IUI 2022)</p>
  <p><b>关键词</b>：Explaining the behaviour, behaviour of intelligent, intelligent systems, intractably challenging, grow in size</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Explaining the behaviour of intelligent systems will get increasingly and
perhaps intractably challenging as models grow in size and complexity. We may
not be able to expect an explanation for every prediction made by a brain-scale
model, nor can we expect explanations to remain objective or apolitical. Our
functionalist understanding of these models is of less advantage than we might
assume. Models precede explanations, and can be useful even when both model and
explanation are incorrect. Explainability may never win the race against
complexity, but this is less problematic than it seems.</p>
  </details>
</details>
<details>
  <summary>28. <b>标题：An Artificial Neural Network Functionalized by Evolution</b></summary>
  <p><b>编号</b>：[107]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10118</p>
  <p><b>作者</b>：Fabien Furfaro,  Avner Bar-Hen,  Geoffroy Berthelot</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：significant effect, Artificial Intelligence, neural networks, artificial, Characterizing efficient topology</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The topology of artificial neural networks has a significant effect on their
performance. Characterizing efficient topology is a field of promising research
in Artificial Intelligence. However, it is not a trivial task and it is mainly
experimented on through convolutional neural networks. We propose a hybrid
model which combines the tensor calculus of feed-forward neural networks with
Pseudo-Darwinian mechanisms. This allows for finding topologies that are well
adapted for elaboration of strategies, control problems or pattern recognition
tasks. In particular, the model can provide adapted topologies at early
evolutionary stages, and 'structural convergence', which can found applications
in robotics, big-data and artificial life.</p>
  </details>
</details>
<details>
  <summary>29. <b>标题：Evolving SimGANs to Improve Abnormal Electrocardiogram Classification</b></summary>
  <p><b>编号</b>：[109]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10116</p>
  <p><b>作者</b>：Gabriel Wang,  Anish Thite,  Rodd Talebi,  Anthony D'Achille,  Alex Mussa,  Jason Zutty</p>
  <p><b>备注</b>：8 pages, presented at The Genetic and Evolutionary Computation Conference 2022</p>
  <p><b>关键词</b>：Machine Learning models, Machine Learning, machine learning methods, Learning models, data</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Machine Learning models are used in a wide variety of domains. However,
machine learning methods often require a large amount of data in order to be
successful. This is especially troublesome in domains where collecting
real-world data is difficult and/or expensive. Data simulators do exist for
many of these domains, but they do not sufficiently reflect the real world data
due to factors such as a lack of real-world noise. Recently generative
adversarial networks (GANs) have been modified to refine simulated image data
into data that better fits the real world distribution, using the SimGAN
method. While evolutionary computing has been used for GAN evolution, there are
currently no frameworks that can evolve a SimGAN. In this paper we (1) extend
the SimGAN method to refine one-dimensional data, (2) modify Easy Cartesian
Genetic Programming (ezCGP), an evolutionary computing framework, to create
SimGANs that more accurately refine simulated data, and (3) create new
feature-based quantitative metrics to evaluate refined data. We also use our
framework to augment an electrocardiogram (ECG) dataset, a domain that suffers
from the issues previously mentioned. In particular, while healthy ECGs can be
simulated there are no current simulators of abnormal ECGs. We show that by
using an evolved SimGAN to refine simulated healthy ECG data to mimic
real-world abnormal ECGs, we can improve the accuracy of abnormal ECG
classifiers.</p>
  </details>
</details>
<details>
  <summary>30. <b>标题：Testing predictive automated driving systems: lessons learned and future  recommendations</b></summary>
  <p><b>编号</b>：[110]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10115</p>
  <p><b>作者</b>：Rubén Izquierdo Gonzalo,  Carlota Salinas Maldonado,  Javier Alonso Ruiz,  Ignacio Parra Alonso,  David Fernández Llorca,  Miguel Á. Sotelo</p>
  <p><b>备注</b>：This work has been accepted to the IEEE Intelligent Transportation Systems Magazine for publication. Copyright may be transferred without notice, after which this version may no longer be accessible</p>
  <p><b>关键词</b>：required safety levels, assess required safety, certified through classical, tracks to assess, assess required</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Conventional vehicles are certified through classical approaches, where
different physical certification tests are set up on test tracks to assess
required safety levels. These approaches are well suited for vehicles with
limited complexity and limited interactions with other entities as last-second
resources. However, these approaches do not allow to evaluate safety with real
behaviors for critical and edge cases, nor to evaluate the ability to
anticipate them in the mid or long term. This is particularly relevant for
automated and autonomous driving functions that make use of advanced predictive
systems to anticipate future actions and motions to be considered in the path
planning layer. In this paper, we present and analyze the results of physical
tests on proving grounds of several predictive systems in automated driving
functions developed within the framework of the BRAVE project. Based on our
experience in testing predictive automated driving functions, we identify the
main limitations of current physical testing approaches when dealing with
predictive systems, analyze the main challenges ahead, and provide a set of
practical actions and recommendations to consider in future physical testing
procedures for automated and autonomous driving functions.</p>
  </details>
</details>
<details>
  <summary>31. <b>标题：Evolutionary Multi-Armed Bandits with Genetic Thompson Sampling</b></summary>
  <p><b>编号</b>：[111]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10113</p>
  <p><b>作者</b>：Baihan Lin</p>
  <p><b>备注</b>：Proceeding of IEEE CEC 2022. This work is one of the first works to solve the online learning problems with distributed evolutionary optimizations, and extends our prior work on contextual bandits (e.g. arXiv:2106.15808) by testing against similar simulated and real-world scenarios. Codes at this https URL</p>
  <p><b>关键词</b>：important driving forces, real-world decision making, decision making engines, applications in biomedicine, decision making</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As two popular schools of machine learning, online learning and evolutionary
computations have become two important driving forces behind real-world
decision making engines for applications in biomedicine, economics, and
engineering fields. Although there are prior work that utilizes bandits to
improve evolutionary algorithms' optimization process, it remains a field of
blank on how evolutionary approach can help improve the sequential decision
making tasks of online learning agents such as the multi-armed bandits. In this
work, we propose the Genetic Thompson Sampling, a bandit algorithm that keeps a
population of agents and update them with genetic principles such as elite
selection, crossover and mutations. Empirical results in multi-armed bandit
simulation environments and a practical epidemic control problem suggest that
by incorporating the genetic algorithm into the bandit algorithm, our method
significantly outperforms the baselines in nonstationary settings. Lastly, we
introduce EvoBandit, a web-based interactive visualization to guide the readers
through the entire learning process and perform lightweight evaluations on the
fly. We hope to engage researchers into this growing field of research with
this investigation.</p>
  </details>
</details>
<details>
  <summary>32. <b>标题：LeNSE: Learning To Navigate Subgraph Embeddings for Large-Scale  Combinatorial Optimisation</b></summary>
  <p><b>编号</b>：[113]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10106</p>
  <p><b>作者</b>：David Ireland,  Giovanni Montana</p>
  <p><b>备注</b>：To appear in ICML 2022</p>
  <p><b>关键词</b>：Combinatorial Optimisation problems, Optimisation problems arise, Combinatorial Optimisation, Optimisation problems, application domains</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Combinatorial Optimisation problems arise in several application domains and
are often formulated in terms of graphs. Many of these problems are NP-hard,
but exact solutions are not always needed. Several heuristics have been
developed to provide near-optimal solutions; however, they do not typically
scale well with the size of the graph. We propose a low-complexity approach for
identifying a (possibly much smaller) subgraph of the original graph where the
heuristics can be run in reasonable time and with a high likelihood of finding
a global near-optimal solution. The core component of our approach is LeNSE, a
reinforcement learning algorithm that learns how to navigate the space of
possible subgraphs using an Euclidean subgraph embedding as its map. To solve
CO problems, LeNSE is provided with a discriminative embedding trained using
any existing heuristics using only on a small portion of the original graph.
When tested on three problems (vertex cover, max-cut and influence
maximisation) using real graphs with up to $10$ million edges, LeNSE identifies
small subgraphs yielding solutions comparable to those found by running the
heuristics on the entire graph, but at a fraction of the total run time.</p>
  </details>
</details>
<details>
  <summary>33. <b>标题：Adversarial joint attacks on legged robots</b></summary>
  <p><b>编号</b>：[117]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10098</p>
  <p><b>作者</b>：Takuto Otomo,  Hiroshi Kera,  Kazuhiko Kawamoto</p>
  <p><b>备注</b>：6 pages, 8 figures</p>
  <p><b>关键词</b>：address adversarial attacks, deep reinforcement learning, black-box adversarial attacks, adversarial attacks, legged robots</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We address adversarial attacks on the actuators at the joints of legged
robots trained by deep reinforcement learning. The vulnerability to the joint
attacks can significantly impact the safety and robustness of legged robots. In
this study, we demonstrate that the adversarial perturbations to the torque
control signals of the actuators can significantly reduce the rewards and cause
walking instability in robots. To find the adversarial torque perturbations, we
develop black-box adversarial attacks, where, the adversary cannot access the
neural networks trained by deep reinforcement learning. The black box attack
can be applied to legged robots regardless of the architecture and algorithms
of deep reinforcement learning. We employ three search methods for the
black-box adversarial attacks: random search, differential evolution, and
numerical gradient descent methods. In experiments with the quadruped robot
Ant-v2 and the bipedal robot Humanoid-v2, in OpenAI Gym environments, we find
that differential evolution can efficiently find the strongest torque
perturbations among the three methods. In addition, we realize that the
quadruped robot Ant-v2 is vulnerable to the adversarial perturbations, whereas
the bipedal robot Humanoid-v2 is robust to the perturbations. Consequently, the
joint attacks can be used for proactive diagnosis of robot walking instability.</p>
  </details>
</details>
<details>
  <summary>34. <b>标题：A Unified Experiment Design Approach for Cyclic and Acyclic Causal  Models</b></summary>
  <p><b>编号</b>：[124]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10083</p>
  <p><b>作者</b>：Ehsan Mokhtarian,  Saber Salehkaleybar,  AmirEmad Ghassami,  Negar Kiyavash</p>
  <p><b>备注</b>：16 pages, 3 figures</p>
  <p><b>关键词</b>：study experiment design, experiment design, causal graph, experiment design approach, experiment</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We study experiment design for the unique identification of the causal graph
of a system where the graph may contain cycles. The presence of cycles in the
structure introduces major challenges for experiment design. Unlike the case of
acyclic graphs, learning the skeleton of the causal graph from observational
distribution may not be possible. Furthermore, intervening on a variable does
not necessarily lead to orienting all the edges incident to it. In this paper,
we propose an experiment design approach that can learn both cyclic and acyclic
graphs and hence, unifies the task of experiment design for both types of
graphs. We provide a lower bound on the number of experiments required to
guarantee the unique identification of the causal graph in the worst case,
showing that the proposed approach is order-optimal in terms of the number of
experiments up to an additive logarithmic term. Moreover, we extend our result
to the setting where the size of each experiment is bounded by a constant. For
this case, we show that our approach is optimal in terms of the size of the
largest experiment required for the unique identification of the causal graph
in the worst case.</p>
  </details>
</details>
<details>
  <summary>35. <b>标题：Contrastive Learning with Cross-Modal Knowledge Mining for Multimodal  Human Activity Recognition</b></summary>
  <p><b>编号</b>：[132]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10071</p>
  <p><b>作者</b>：Razvan Brinzea,  Bulat Khaertdinov,  Stylianos Asteriadis</p>
  <p><b>备注</b>：to be published in IEEE WCCI 2022 (IJCNN 2022 track)</p>
  <p><b>关键词</b>：field of research, Human Activity Recognition, Human Activity, Human, modalities describes human</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Human Activity Recognition is a field of research where input data can take
many forms. Each of the possible input modalities describes human behaviour in
a different way, and each has its own strengths and weaknesses. We explore the
hypothesis that leveraging multiple modalities can lead to better recognition.
Since manual annotation of input data is expensive and time-consuming, the
emphasis is made on self-supervised methods which can learn useful feature
representations without any ground truth labels. We extend a number of recent
contrastive self-supervised approaches for the task of Human Activity
Recognition, leveraging inertial and skeleton data. Furthermore, we propose a
flexible, general-purpose framework for performing multimodal self-supervised
learning, named Contrastive Multiview Coding with Cross-Modal Knowledge Mining
(CMC-CMKM). This framework exploits modality-specific knowledge in order to
mitigate the limitations of typical self-supervised frameworks. The extensive
experiments on two widely-used datasets demonstrate that the suggested
framework significantly outperforms contrastive unimodal and multimodal
baselines on different scenarios, including fully-supervised fine-tuning,
activity retrieval and semi-supervised learning. Furthermore, it shows
performance competitive even compared to supervised methods.</p>
  </details>
</details>
<details>
  <summary>36. <b>标题：Understanding and Mitigating the Uncertainty in Zero-Shot Translation</b></summary>
  <p><b>编号</b>：[134]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10068</p>
  <p><b>作者</b>：Wenxuan Wang,  Wenxiang Jiao,  Shuo Wang,  Zhaopeng Tu,  Michael R. Lyu</p>
  <p><b>备注</b>：work in progress</p>
  <p><b>关键词</b>：comprehensive multilingual neural, multilingual neural machine, neural machine translation, promising direction, direction for building</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Zero-shot translation is a promising direction for building a comprehensive
multilingual neural machine translation (MNMT) system. However, its quality is
still not satisfactory due to off-target issues. In this paper, we aim to
understand and alleviate the off-target issues from the perspective of
uncertainty in zero-shot translation. By carefully examining the translation
output and model confidence, we identify two uncertainties that are responsible
for the off-target issues, namely, extrinsic data uncertainty and intrinsic
model uncertainty. Based on the observations, we propose two light-weight and
complementary approaches to denoise the training data for model training, and
mask out the vocabulary of the off-target languages in inference. Extensive
experiments on both balanced and unbalanced datasets show that our approaches
significantly improve the performance of zero-shot translation over strong MNMT
baselines. Qualitative analyses provide insights into where our approaches
reduce off-target translations</p>
  </details>
</details>
<details>
  <summary>37. <b>标题：MaskGAE: Masked Graph Modeling Meets Graph Autoencoders</b></summary>
  <p><b>编号</b>：[140]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10053</p>
  <p><b>作者</b>：Jintang Li,  Ruofan Wu,  Wangbin Sun,  Liang Chen,  Sheng Tian,  Liang Zhu,  Changhua Meng,  Zibin Zheng,  Weiqiang Wang</p>
  <p><b>备注</b>：Preprint. Code available at this https URL</p>
  <p><b>关键词</b>：masked graph autoencoder, present masked graph, graph-structured data, previous graph autoencoders, framework for graph-structured</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present masked graph autoencoder (MaskGAE), a self-supervised learning
framework for graph-structured data. Different from previous graph autoencoders
(GAEs), MaskGAE adopts masked graph modeling (MGM) as a principled pretext
task: masking a portion of edges and attempting to reconstruct the missing part
with partially visible, unmasked graph structure. To understand whether MGM can
help GAEs learn better representations, we provide both theoretical and
empirical evidence to justify the benefits of this pretext task. Theoretically,
we establish the connections between GAEs and contrastive learning, showing
that MGM significantly improves the self-supervised learning scheme of GAEs.
Empirically, we conduct extensive experiments on a number of benchmark
datasets, demonstrating the superiority of MaskGAE over several
state-of-the-arts on both link prediction and node classification tasks. Our
code is publicly available at \url{this https URL}.</p>
  </details>
</details>
<details>
  <summary>38. <b>标题：ExMo: Explainable AI Model using Inverse Frequency Decision Rules</b></summary>
  <p><b>编号</b>：[144]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10045</p>
  <p><b>作者</b>：Pradip Mainali,  Ismini Psychoula,  Fabien A. P. Petitcolas</p>
  <p><b>备注</b>：18 pages, 7 figues, HCI International 2022 Conference</p>
  <p><b>关键词</b>：interpretable machine learning, machine learning model, decision rules, compute decision rules, machine learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we present a novel method to compute decision rules to build a
more accurate interpretable machine learning model, denoted as ExMo. The ExMo
interpretable machine learning model consists of a list of IF...THEN...
statements with a decision rule in the condition. This way, ExMo naturally
provides an explanation for a prediction using the decision rule that was
triggered. ExMo uses a new approach to extract decision rules from the training
data using term frequency-inverse document frequency (TF-IDF) features. With
TF-IDF, decision rules with feature values that are more relevant to each class
are extracted. Hence, the decision rules obtained by ExMo can distinguish the
positive and negative classes better than the decision rules used in the
existing Bayesian Rule List (BRL) algorithm, obtained using the frequent
pattern mining approach. The paper also shows that ExMo learns a qualitatively
better model than BRL. Furthermore, ExMo demonstrates that the textual
explanation can be provided in a human-friendly way so that the explanation can
be easily understood by non-expert users. We validate ExMo on several datasets
with different sizes to evaluate its efficacy. Experimental validation on a
real-world fraud detection application shows that ExMo is 20% more accurate
than BRL and that it achieves accuracy similar to those of deep learning
models.</p>
  </details>
</details>
<details>
  <summary>39. <b>标题：SE-MoE: A Scalable and Efficient Mixture-of-Experts Distributed Training  and Inference System</b></summary>
  <p><b>编号</b>：[150]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10034</p>
  <p><b>作者</b>：Liang Shen,  Zhihua Wu,  WeiBao Gong,  Hongxiang Hao,  Yangfan Bai,  HuaChao Wu,  Xinxuan Wu,  Haoyi Xiong,  Dianhai Yu,  Yanjun Ma</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：heterogeneous computing systems, increasing diversity, desired to facilitate, facilitate the production, production of big</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>With the increasing diversity of ML infrastructures nowadays, distributed
training over heterogeneous computing systems is desired to facilitate the
production of big models. Mixture-of-Experts (MoE) models have been proposed to
lower the cost of training subject to the overall size of models/data through
gating and parallelism in a divide-and-conquer fashion. While DeepSpeed has
made efforts in carrying out large-scale MoE training over heterogeneous
infrastructures, the efficiency of training and inference could be further
improved from several system aspects, including load balancing,
communication/computation efficiency, and memory footprint limits. In this
work, we present SE-MoE that proposes Elastic MoE training with 2D prefetch and
Fusion communication over Hierarchical storage, so as to enjoy efficient
parallelisms in various types. For scalable inference in a single node,
especially when the model size is larger than GPU memory, SE-MoE forms the
CPU-GPU memory jointly into a ring of sections to load the model, and executes
the computation tasks across the memory sections in a round-robin manner for
efficient inference. We carried out extensive experiments to evaluate SE-MoE,
where SE-MoE successfully trains a Unified Feature Optimization (UFO) model
with a Sparsely-Gated Mixture-of-Experts model of 12B parameters in 8 days on
48 A100 GPU cards. The comparison against the state-of-the-art shows that
SE-MoE outperformed DeepSpeed with 33% higher throughput (tokens per second) in
training and 13% higher throughput in inference in general. Particularly, under
unbalanced MoE Tasks, e.g., UFO, SE-MoE achieved 64% higher throughput with 18%
lower memory footprints. The code of the framework will be released on:
this https URL.</p>
  </details>
</details>
<details>
  <summary>40. <b>标题：Predicting electrode array impedance after one month from cochlear  implantation surgery</b></summary>
  <p><b>编号</b>：[156]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10021</p>
  <p><b>作者</b>：Yousef A. Alohali,  Yassin Abdelsamad,  Tamer Mesallam,  Fida Almuhawas,  Abdulrahman Hagr,  Mahmoud S. Fayed</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Sensorineural hearing loss, electrode impedance, electrode, impedance, electrode array</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Sensorineural hearing loss can be treated using Cochlear implantation. After
this surgery using the electrode array impedance measurements, we can check the
stability of the impedance value and the dynamic range. Deterioration of speech
recognition scores could happen because of increased impedance values.
Medicines used to do these measures many times during a year after the surgery.
Predicting the electrode impedance could help in taking decisions to help the
patient get better hearing. In this research we used a dataset of 80 patients
of children who did cochlear implantation using MED-EL FLEX28 electrode array
of 12 channels. We predicted the electrode impedance on each channel after 1
month from the surgery date. We used different machine learning algorithms like
neural networks and decision trees. Our results indicates that the electrode
impedance can be predicted, and the best algorithm is different based on the
electrode channel. Also, the accuracy level varies between 66% and 100% based
on the electrode channel when accepting an error range between 0 and 3 KO.
Further research is required to predict the electrode impedance after three
months, six months and one year.</p>
  </details>
</details>
<details>
  <summary>41. <b>标题：Neural Additive Models for Nowcasting</b></summary>
  <p><b>编号</b>：[157]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10020</p>
  <p><b>作者</b>：Wonkeun Jo,  Dongil Kim</p>
  <p><b>备注</b>：12 pages, 8 figures</p>
  <p><b>关键词</b>：highlighted methods, Deep neural networks, machine learning, Deep neural, additive models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep neural networks (DNNs) are one of the most highlighted methods in
machine learning. However, as DNNs are black-box models, they lack explanatory
power for their predictions. Recently, neural additive models (NAMs) have been
proposed to provide this power while maintaining high prediction performance.
In this paper, we propose a novel NAM approach for multivariate nowcasting (NC)
problems, which comprise an important focus area of machine learning. For the
multivariate time-series data used in NC problems, explanations should be
considered for every input value to the variables at distinguishable time
steps. By employing generalized additive models, the proposed NAM-NC
successfully explains each input value's importance for multiple variables and
time steps. Experimental results involving a toy example and two real-world
datasets show that the NAM-NC predicts multivariate time-series data as
accurately as state-of-the-art neural networks, while also providing the
explanatory importance of each input value. We also examine parameter-sharing
networks using NAM-NC to decrease their complexity, and NAM-MC's hard-tied
feature net extracted explanations with good performance.</p>
  </details>
</details>
<details>
  <summary>42. <b>标题：Translating Hanja historical documents to understandable Korean and  English</b></summary>
  <p><b>编号</b>：[158]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10019</p>
  <p><b>作者</b>：Juhee Son,  Jiho Jin,  Haneul Yoo,  JinYeong Bak,  Kyunghyun Cho,  Alice Oh</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Joseon Dynasty, Korean, translation, Korean and English, archaic Korean</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The Annals of Joseon Dynasty (AJD) contain the daily records of the Kings of
Joseon, the 500-year kingdom preceding the modern nation of Korea. The Annals
were originally written in an archaic Korean writing system, `Hanja', and
translated into Korean from 1968 to 1993. However, this translation was literal
and contained many archaic Korean words; thus, a new expert translation effort
began in 2012, completing the records of only one king in a decade. Also,
expert translators are working on an English translation, of which only one
king's records are available because of the high cost and slow progress. Thus,
we propose H2KE, the neural machine translation model that translates Hanja
historical documents to understandable Korean and English. Based on the
multilingual neural machine translation approach, it translates the historical
document written in Hanja, using both the full dataset of outdated Korean
translation and a small dataset of recently translated Korean and English. We
compare our method with two baselines: one is a recent model that
simultaneously learns to restore and translate Hanja historical document and
the other is the transformer that trained on newly translated corpora only. The
results show that our method significantly outperforms the baselines in terms
of BLEU score in both modern Korean and English translations. We also conduct a
human evaluation that shows that our translation is preferred over the original
expert translation.</p>
  </details>
</details>
<details>
  <summary>43. <b>标题：NMA: Neural Multi-slot Auctions with Externalities for Online  Advertising</b></summary>
  <p><b>编号</b>：[159]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10018</p>
  <p><b>作者</b>：Guogang Liao,  Xuejian Li,  Ze Wang,  Fan Yang,  Muzhi Guan,  Bingqi Zhu,  Yongkang Wang,  Xingxing Wang,  Dong Wang</p>
  <p><b>备注</b>：10 pages, 3figures</p>
  <p><b>关键词</b>：auctions brings billions, social networking services, Online advertising driven, advertising driven, brings billions</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Online advertising driven by auctions brings billions of dollars in revenue
for social networking services and e-commerce platforms. GSP auction, which is
simple and easy to understand for advertisers, has almost become the benchmark
for ad auction mechanisms in the industry. However, the allocation stability of
GSP depends on the separable CTR assumption, which means that GSP considers
neither position-dependent externalities nor ad-dependent externalities in
multi-slot scenario, leading to suboptimal performance. Some GSP-based deep
auctions (e.g., DeepGSP, DNA) have attempted to upgrade GSP with deep neural
networks, while only modeling local externalities and thus still suboptimal. On
the other hand, although VCG-based multi-slot auctions (e.g., VCG, WVCG) take
externalities into consideration, they lack an efficient balance of both
revenue and social welfare. In this paper, we propose a novel auction named
Neural Multi-slot Auction (NMA) to tackle the above-mentioned challenges.
Specifically, we model the global externalities effectively with a
context-aware list-wise prediction module to achieve better performance. We
design a list-wise deep rank module to guarantee incentive compatibility in
end-to-end learning. Furthermore, we propose an auxiliary loss for social
welfare to effectively reduce the decline of social welfare while maximizing
revenue. Experiment results on both offline large-scale datasets and online A/B
tests demonstrate that NMA obtains higher revenue with balanced social welfare
than other existing auction mechanisms (i.e., GSP, DNA, WVCG) in industrial
practice, and we have successfully deployed NMA on Meituan food delivery
platform.</p>
  </details>
</details>
<details>
  <summary>44. <b>标题：Self-Paced Multi-Agent Reinforcement Learning</b></summary>
  <p><b>编号</b>：[161]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10016</p>
  <p><b>作者</b>：Wenshuai Zhao,  Joni Pajarinen</p>
  <p><b>备注</b>：13 pages, 9 figures</p>
  <p><b>关键词</b>：number of agents, Curriculum reinforcement learning, reinforcement learning, multi-agent reinforcement learning, aims to speed</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Curriculum reinforcement learning (CRL) aims to speed up learning of a task
by changing gradually the difficulty of the task from easy to hard through
control of factors such as initial state or environment dynamics. While
automating CRL is well studied in the single-agent setting, in multi-agent
reinforcement learning (MARL) an open question is whether control of the number
of agents with other factors in a principled manner is beneficial, prior
approaches typically relying on hand-crafted heuristics. In addition, how the
tasks evolve as the number of agents changes remains understudied, which is
critical for scaling to more challenging tasks. We introduce self-paced MARL
(SPMARL) that enables optimizing the number of agents with other environment
factors in a principled way, and, show that usual assumptions such as that
fewer agents make the task always easier are not generally valid. The
curriculum induced by SPMARL reveals the evolution of tasks w.r.t. number of
agents and experiments show that SPMARL improves the performance when the
number of agents sufficiently influences task difficulty.</p>
  </details>
</details>
<details>
  <summary>45. <b>标题：A Survey of Trustworthy Graph Learning: Reliability, Explainability, and  Privacy Protection</b></summary>
  <p><b>编号</b>：[162]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10014</p>
  <p><b>作者</b>：Bingzhe Wu,  Jintang Li,  Junchi Yu,  Yatao Bian,  Hengtong Zhang,  CHaochao Chen,  Chengbin Hou,  Guoji Fu,  Liang Chen,  Tingyang Xu,  Yu Rong,  Xiaolin Zheng,  Junzhou Huang,  Ran He,  Baoyuan Wu,  GUangyu Sun,  Peng Cui,  Zibin Zheng,  Zhe Liu,  Peilin Zhao</p>
  <p><b>备注</b>：Preprint; Work in progress. arXiv admin note: substantial text overlap with arXiv:2202.07114</p>
  <p><b>关键词</b>：advanced material discovery, scientific areas ranging, Deep graph learning, achieved remarkable progresses, graph learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep graph learning has achieved remarkable progresses in both business and
scientific areas ranging from finance and e-commerce, to drug and advanced
material discovery. Despite these progresses, how to ensure various deep graph
learning algorithms behave in a socially responsible manner and meet regulatory
compliance requirements becomes an emerging problem, especially in
risk-sensitive domains. Trustworthy graph learning (TwGL) aims to solve the
above problems from a technical viewpoint. In contrast to conventional graph
learning research which mainly cares about model performance, TwGL considers
various reliability and safety aspects of the graph learning framework
including but not limited to robustness, explainability, and privacy. In this
survey, we provide a comprehensive review of recent leading approaches in the
TwGL field from three dimensions, namely, reliability, explainability, and
privacy protection. We give a general categorization for existing work and
review typical work for each category. To give further insights for TwGL
research, we provide a unified view to inspect previous works and build the
connection between them. We also point out some important open problems
remaining to be solved in the future developments of TwGL.</p>
  </details>
</details>
<details>
  <summary>46. <b>标题：Self-Supervised Depth Estimation with Isometric-Self-Sample-Based  Learning</b></summary>
  <p><b>编号</b>：[167]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10006</p>
  <p><b>作者</b>：Geonho Cha,  Ho-Deok Jang,  Dongyoon Wee</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：photometric loss formulation, self-supervised depth estimation, dynamic regions, photometric loss, loss formulation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Managing the dynamic regions in the photometric loss formulation has been a
main issue for handling the self-supervised depth estimation problem. Most
previous methods have alleviated this issue by removing the dynamic regions in
the photometric loss formulation based on the masks estimated from another
module, making it difficult to fully utilize the training images. In this
paper, to handle this problem, we propose an isometric self-sample-based
learning (ISSL) method to fully utilize the training images in a simple yet
effective way. The proposed method provides additional supervision during
training using self-generated images that comply with pure static scene
assumption. Specifically, the isometric self-sample generator synthesizes
self-samples for each training image by applying random rigid transformations
on the estimated depth. Thus both the generated self-samples and the
corresponding training image always follow the static scene assumption. We show
that plugging our ISSL module into several existing models consistently
improves the performance by a large margin. In addition, it also boosts the
depth accuracy over different types of scene, i.e., outdoor scenes (KITTI and
Make3D) and indoor scene (NYUv2), validating its high effectiveness.</p>
  </details>
</details>
<details>
  <summary>47. <b>标题：Planning with Diffusion for Flexible Behavior Synthesis</b></summary>
  <p><b>编号</b>：[174]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09991</p>
  <p><b>作者</b>：Michael Janner,  Yilun Du,  Joshua B. Tenenbaum,  Sergey Levine</p>
  <p><b>备注</b>：ICML 2022 (long talk). Project page and code at this https URL</p>
  <p><b>关键词</b>：Model-based reinforcement learning, classical trajectory optimizers, approximate dynamics model, reinforcement learning methods, reinforcement learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Model-based reinforcement learning methods often use learning only for the
purpose of estimating an approximate dynamics model, offloading the rest of the
decision-making work to classical trajectory optimizers. While conceptually
simple, this combination has a number of empirical shortcomings, suggesting
that learned models may not be well-suited to standard trajectory optimization.
In this paper, we consider what it would look like to fold as much of the
trajectory optimization pipeline as possible into the modeling problem, such
that sampling from the model and planning with it become nearly identical. The
core of our technical approach lies in a diffusion probabilistic model that
plans by iteratively denoising trajectories. We show how classifier-guided
sampling and image inpainting can be reinterpreted as coherent planning
strategies, explore the unusual and useful properties of diffusion-based
planning methods, and demonstrate the effectiveness of our framework in control
settings that emphasize long-horizon decision-making and test-time flexibility.</p>
  </details>
</details>
<details>
  <summary>48. <b>标题：Set-based Meta-Interpolation for Few-Task Meta-Learning</b></summary>
  <p><b>编号</b>：[175]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09990</p>
  <p><b>作者</b>：Seanie Lee,  Bruno Andreis,  Kenji Kawaguchi,  Juho Lee,  Sung Ju Hwang</p>
  <p><b>备注</b>：First two authors contributed equally. Name order decided by a coin toss</p>
  <p><b>关键词</b>：Meta-learning approaches enable, approaches enable machine, enable machine learning, machine learning systems, Meta-learning approaches</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Meta-learning approaches enable machine learning systems to adapt to new
tasks given few examples by leveraging knowledge from related tasks. However, a
large number of meta-training tasks are still required for generalization to
unseen tasks during meta-testing, which introduces a critical bottleneck for
real-world problems that come with only few tasks, due to various reasons
including the difficulty and cost of constructing tasks. Recently, several task
augmentation methods have been proposed to tackle this issue using
domain-specific knowledge to design augmentation techniques to densify the
meta-training task distribution. However, such reliance on domain-specific
knowledge renders these methods inapplicable to other domains. While Manifold
Mixup based task augmentation methods are domain-agnostic, we empirically find
them ineffective on non-image domains. To tackle these limitations, we propose
a novel domain-agnostic task augmentation method, Meta-Interpolation, which
utilizes expressive neural set functions to densify the meta-training task
distribution using bilevel optimization. We empirically validate the efficacy
of Meta-Interpolation on eight datasets spanning across various domains such as
image classification, molecule property prediction, text classification and
speech recognition. Experimentally, we show that Meta-Interpolation
consistently outperforms all the relevant baselines. Theoretically, we prove
that task interpolation with the set function regularizes the meta-learner to
improve generalization.</p>
  </details>
</details>
<details>
  <summary>49. <b>标题：SALTED: A Framework for SAlient Long-Tail Translation Error Detection</b></summary>
  <p><b>编号</b>：[176]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09988</p>
  <p><b>作者</b>：Vikas Raunak,  Matt Post,  Arul Menezes</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Traditional machine translation, machine translation, average measure, long tail, Traditional machine</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Traditional machine translation (MT) metrics provide an average measure of
translation quality that is insensitive to the long tail of behavioral problems
in MT. Examples include translation of numbers, physical units, dropped content
and hallucinations. These errors, which occur rarely and unpredictably in
Neural Machine Translation (NMT), greatly undermine the reliability of
state-of-the-art MT systems. Consequently, it is important to have visibility
into these problems during model development. Towards this direction, we
introduce SALTED, a specifications-based framework for behavioral testing of MT
models that provides fine-grained views of salient long-tail errors, permitting
trustworthy visibility into previously invisible problems. At the core of our
approach is the development of high-precision detectors that flag errors (or
alternatively, verify output correctness) between a source sentence and a
system output. We demonstrate that such detectors could be used not just to
identify salient long-tail errors in MT systems, but also for higher-recall
filtering of the training data, fixing targeted errors with model fine-tuning
in NMT and generating novel data for metamorphic testing to elicit further bugs
in models.</p>
  </details>
</details>
<details>
  <summary>50. <b>标题：A New Feature Selection Method for LogNNet and its Application for  Diagnosis and Prognosis of COVID-19 Disease Using Routine Blood Values</b></summary>
  <p><b>编号</b>：[182]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09974</p>
  <p><b>作者</b>：Mehmet Tahir Huyut,  Andrei Velichko</p>
  <p><b>备注</b>：22 pages, 6 figures, 11 Tables</p>
  <p><b>关键词</b>：world has embarked, intense struggle, disease, diagnosis, features</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Since February-2020, the world has embarked on an intense struggle with the
COVID-19 disease, and health systems have come under a tragic pressure as the
disease turned into a pandemic. The aim of this study is to determine the most
effective routine-blood-values (RBV) in the diagnosis/prognosis of COVID-19
using new feature selection method for LogNNet reservoir neural network. First
dataset in this study consists of a total of 5296-patients with a same number
of negative and positive covid test. Second dataset consists of a total of
3899-patients with a diagnosis of COVID-19, who were treated in hospital with
severe-infected (203) and mildly-infected (3696). The most important RBVs that
affect the diagnosis of the disease from the first dataset were
mean-corpuscular-hemoglobin-concentration (MCHC), mean-corpuscular-hemoglobin
(MCH) and activated-partial-prothrombin-time (aPTT). The most effective
features in the prognosis of the disease were erythrocyte-sedimentation-rate
(ESR), neutrophil-count (NEU), C-reactive-protein (CRP). LogNNet-model achieved
an accuracy rate of A46 = 99.5% in the diagnosis of the disease with 46
features and A3 = 99.17% with only MCHC, MCH, and aPTT features. Model reached
an accuracy rate of A48 = 94.4% in determining the prognosis of the disease
with 48 features and A3 = 82.7% with only ESR, NEU, and CRP features. LogNNet
model demonstrated a very high disease diagnosis/prognosis of COVID-19
performance without knowing about the symptoms or history of the patients. The
model is suitable for devices with low resources (3-14 kB of RAM used on the
Arduino microcontroller), and is promising to create mobile health monitoring
systems in the Internet of Things. Our method will reduce the negative
pressures on the health sector and help doctors understand pathogenesis of
COVID-19 through key futures and contribute positively to the treatment
processes.</p>
  </details>
</details>
<details>
  <summary>51. <b>标题：On Tackling Explanation Redundancy in Decision Trees</b></summary>
  <p><b>编号</b>：[184]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09971</p>
  <p><b>作者</b>：Yacine Izza,  Alexey Ignatiev,  Joao Marques-Silva</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Decision trees, Decision, trees, epitomize the ideal, explanation redundancy</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Decision trees (DTs) epitomize the ideal of interpretability of machine
learning (ML) models. The interpretability of decision trees motivates
explainability approaches by so-called intrinsic interpretability, and it is at
the core of recent proposals for applying interpretable ML models in high-risk
applications. The belief in DT interpretability is justified by the fact that
explanations for DT predictions are generally expected to be succinct. Indeed,
in the case of DTs, explanations correspond to DT paths. Since decision trees
are ideally shallow, and so paths contain far fewer features than the total
number of features, explanations in DTs are expected to be succinct, and hence
interpretable. This paper offers both theoretical and experimental arguments
demonstrating that, as long as interpretability of decision trees equates with
succinctness of explanations, then decision trees ought not be deemed
interpretable. The paper introduces logically rigorous path explanations and
path explanation redundancy, and proves that there exist functions for which
decision trees must exhibit paths with arbitrarily large explanation
redundancy. The paper also proves that only a very restricted class of
functions can be represented with DTs that exhibit no explanation redundancy.
In addition, the paper includes experimental results substantiating that path
explanation redundancy is observed ubiquitously in decision trees, including
those obtained using different tree learning algorithms, but also in a wide
range of publicly available decision trees. The paper also proposes
polynomial-time algorithms for eliminating path explanation redundancy, which
in practice require negligible time to compute. Thus, these algorithms serve to
indirectly attain irreducible, and so succinct, explanations for decision
trees.</p>
  </details>
</details>
<details>
  <summary>52. <b>标题：A Fully Controllable Agent in the Path Planning using Goal-Conditioned  Reinforcement Learning</b></summary>
  <p><b>编号</b>：[186]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09967</p>
  <p><b>作者</b>：GyeongTaek Lee</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：path planning, agent, starting point, point by searching, reach</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The aim of path planning is to reach the goal from starting point by
searching for the route of an agent. In the path planning, the routes may vary
depending on the number of variables such that it is important for the agent to
reach various goals. Numerous studies, however, have dealt with a single goal
that is predefined by the user. In the present study, I propose a novel
reinforcement learning framework for a fully controllable agent in the path
planning. To do this, I propose a bi-directional memory editing to obtain
various bi-directional trajectories of the agent, in which the behavior of the
agent and sub-goals are trained on the goal-conditioned RL. As for moving the
agent in various directions, I utilize the sub-goals dedicated network,
separated from a policy network. Lastly, I present the reward shaping to
shorten the number of steps for the agent to reach the goal. In the
experimental result, the agent was able to reach the various goals that have
never been visited by the agent in the training. We confirmed that the agent
could perform difficult missions such as a round trip and the agent used the
shorter route with the reward shaping.</p>
  </details>
</details>
<details>
  <summary>53. <b>标题：Explainable Supervised Domain Adaptation</b></summary>
  <p><b>编号</b>：[198]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09943</p>
  <p><b>作者</b>：Vidhya Kamakshi,  Narayanan C Krishnan</p>
  <p><b>备注</b>：Accepted as a Poster presentation at IJCNN at IEEE-WCCI 2022</p>
  <p><b>关键词</b>：Domain adaptation, success of deep, Domain, Domain adaptation techniques, deep learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Domain adaptation techniques have contributed to the success of deep
learning. Leveraging knowledge from an auxiliary source domain for learning in
labeled data-scarce target domain is fundamental to domain adaptation. While
these techniques result in increasing accuracy, the adaptation process,
particularly the knowledge leveraged from the source domain, remains unclear.
This paper proposes an explainable by design supervised domain adaptation
framework - XSDA-Net. We integrate a case-based reasoning mechanism into the
XSDA-Net to explain the prediction of a test instance in terms of
similar-looking regions in the source and target train images. We empirically
demonstrate the utility of the proposed framework by curating the domain
adaptation settings on datasets popularly known to exhibit part-based
explainability.</p>
  </details>
</details>
<details>
  <summary>54. <b>标题：Towards Explanation for Unsupervised Graph-Level Representation Learning</b></summary>
  <p><b>编号</b>：[200]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09934</p>
  <p><b>作者</b>：Qinghua Zheng,  Jihong Wang,  Minnan Luo,  Yaoliang Yu,  Jundong Li,  Lina Yao,  Xiaojun Chang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Graph Neural Networks, Existing explanation methods, Neural Networks, GNN explanation problem, graph-level representation learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Due to the superior performance of Graph Neural Networks (GNNs) in various
domains, there is an increasing interest in the GNN explanation problem
"\emph{which fraction of the input graph is the most crucial to decide the
model's decision?}" Existing explanation methods focus on the supervised
settings, \eg, node classification and graph classification, while the
explanation for unsupervised graph-level representation learning is still
unexplored. The opaqueness of the graph representations may lead to unexpected
risks when deployed for high-stake decision-making scenarios. In this paper, we
advance the Information Bottleneck principle (IB) to tackle the proposed
explanation problem for unsupervised graph representations, which leads to a
novel principle, \textit{Unsupervised Subgraph Information Bottleneck} (USIB).
We also theoretically analyze the connection between graph representations and
explanatory subgraphs on the label space, which reveals that the expressiveness
and robustness of representations benefit the fidelity of explanatory
subgraphs. Experimental results on both synthetic and real-world datasets
demonstrate the superiority of our developed explainer and the validity of our
theoretical analysis.</p>
  </details>
</details>
<details>
  <summary>55. <b>标题：BayesPCN: A Continually Learnable Predictive Coding Associative Memory</b></summary>
  <p><b>编号</b>：[203]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09930</p>
  <p><b>作者</b>：Jason Yoo,  Frank Wood</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：machine learning, plays an important, important role, role in human, human intelligence</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Associative memory plays an important role in human intelligence and its
mechanisms have been linked to attention in machine learning. While the machine
learning community's interest in associative memories has recently been
rekindled, most work has focused on memory recall ($read$) over memory learning
($write$). In this paper, we present BayesPCN, a hierarchical associative
memory capable of performing continual one-shot memory writes without
meta-learning. Moreover, BayesPCN is able to gradually forget past observations
($forget$) to free its memory. Experiments show that BayesPCN can recall
corrupted i.i.d. high-dimensional data observed hundreds of "timesteps" ago
without a significant drop in recall ability compared to the state-of-the-art
offline-learned associative memory models.</p>
  </details>
</details>
<details>
  <summary>56. <b>标题：On Jointly Optimizing Partial Offloading and SFC Mapping: A Cooperative  Dual-agent Deep Reinforcement Learning Approach</b></summary>
  <p><b>编号</b>：[206]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09925</p>
  <p><b>作者</b>：Xinhan Wang,  Huanlai Xing,  Fuhong Song,  Shouxi Luo,  Penglin Dai,  Bowen Zhao</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：support emerging IoT, network function virtualization, emerging IoT applications, Multi-access edge computing, MEC</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Multi-access edge computing (MEC) and network function virtualization (NFV)
are promising technologies to support emerging IoT applications, especially
those computation-intensive. In NFV-enabled MEC environment, service function
chain (SFC), i.e., a set of ordered virtual network functions (VNFs), can be
mapped on MEC servers. Mobile devices (MDs) can offload computation-intensive
applications, which can be represented by SFCs, fully or partially to MEC
servers for remote execution. This paper studies the partial offloading and SFC
mapping joint optimization (POSMJO) problem in an NFV-enabled MEC system, where
an incoming task can be partitioned into two parts, one for local execution and
the other for remote execution. The objective is to minimize the average cost
in the long term which is a combination of execution delay, MD's energy
consumption, and usage charge for edge computing. This problem consists of two
closely related decision-making steps, namely task partition and VNF placement,
which is highly complex and quite challenging. To address this, we propose a
cooperative dual-agent deep reinforcement learning (CDADRL) algorithm, where we
design a framework enabling interaction between two agents. Simulation results
show that the proposed algorithm outperforms three combinations of deep
reinforcement learning algorithms in terms of cumulative and average episodic
rewards and it overweighs a number of baseline algorithms with respect to
execution delay, energy consumption, and usage charge.</p>
  </details>
</details>
<details>
  <summary>57. <b>标题：Can Foundation Models Wrangle Your Data?</b></summary>
  <p><b>编号</b>：[210]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09911</p>
  <p><b>作者</b>：Avanika Narayan,  Ines Chami,  Laurel Orr,  Christopher Ré</p>
  <p><b>备注</b>：12 pages, 5 figures</p>
  <p><b>关键词</b>：task-specific finetuning, Models, tasks, Foundation Models, cleaning and integration</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Foundation Models (FMs) are models trained on large corpora of data that, at
very large scale, can generalize to new tasks without any task-specific
finetuning. As these models continue to grow in size, innovations continue to
push the boundaries of what these models can do on language and image tasks.
This paper aims to understand an underexplored area of FMs: classical data
tasks like cleaning and integration. As a proof-of-concept, we cast three data
cleaning and integration tasks as prompting tasks and evaluate the performance
of FMs on these tasks. We find that large FMs generalize and achieve SoTA
performance on data cleaning and integration tasks, even though they are not
trained for these data tasks. We identify specific research challenges and
opportunities that these models present, including challenges with private and
temporal data, and opportunities to make data driven systems more accessible to
non-experts. We make our code and experiments publicly available at:
this https URL.</p>
  </details>
</details>
<details>
  <summary>58. <b>标题：Deep transfer learning for image classification: a survey</b></summary>
  <p><b>编号</b>：[212]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09904</p>
  <p><b>作者</b>：Jo Plested,  Tom Gedeon</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：convolutional neural networks, Deep neural networks, neural networks, transfer learning, image classification</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep neural networks such as convolutional neural networks (CNNs) and
transformers have achieved many successes in image classification in recent
years. It has been consistently demonstrated that best practice for image
classification is when large deep models can be trained on abundant labelled
data. However there are many real world scenarios where the requirement for
large amounts of training data to get the best performance cannot be met. In
these scenarios transfer learning can help improve performance. To date there
have been no surveys that comprehensively review deep transfer learning as it
relates to image classification overall. However, several recent general
surveys of deep transfer learning and ones that relate to particular
specialised target image classification tasks have been published. We believe
it is important for the future progress in the field that all current knowledge
is collated and the overarching patterns analysed and discussed. In this survey
we formally define deep transfer learning and the problem it attempts to solve
in relation to image classification. We survey the current state of the field
and identify where recent progress has been made. We show where the gaps in
current knowledge are and make suggestions for how to progress the field to
fill in these knowledge gaps. We present a new taxonomy of the applications of
transfer learning for image classification. This taxonomy makes it easier to
see overarching patterns of where transfer learning has been effective and,
where it has failed to fulfill its potential. This also allows us to suggest
where the problems lie and how it could be used more effectively. We show that
under this new taxonomy, many of the applications where transfer learning has
been shown to be ineffective or even hinder performance are to be expected when
taking into account the source and target datasets and the techniques used.</p>
  </details>
</details>
<details>
  <summary>59. <b>标题：Incremental Learning with Differentiable Architecture and Forgetting  Search</b></summary>
  <p><b>编号</b>：[226]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09875</p>
  <p><b>作者</b>：James Seale Smith,  Zachary Seymour,  Han-Pang Chiu</p>
  <p><b>备注</b>：Accepted by the 2022 International Joint Conference on Neural Networks (IJCNN 2022)</p>
  <p><b>关键词</b>：incrementally expanding classification, training machine learning, machine learning models, incremental learning, industry expectations</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As progress is made on training machine learning models on incrementally
expanding classification tasks (i.e., incremental learning), a next step is to
translate this progress to industry expectations. One technique missing from
incremental learning is automatic architecture design via Neural Architecture
Search (NAS). In this paper, we show that leveraging NAS for incremental
learning results in strong performance gains for classification tasks.
Specifically, we contribute the following: first, we create a strong baseline
approach for incremental learning based on Differentiable Architecture Search
(DARTS) and state-of-the-art incremental learning strategies, outperforming
many existing strategies trained with similar-sized popular architectures;
second, we extend the idea of architecture search to regularize architecture
forgetting, boosting performance past our proposed baseline. We evaluate our
method on both RF signal and image classification tasks, and demonstrate we can
achieve up to a 10% performance increase over state-of-the-art methods. Most
importantly, our contribution enables learning from continuous distributions on
real-world application data for which the complexity of the data distribution
is unknown, or the modality less explored (such as RF signal classification).</p>
  </details>
</details>
<details>
  <summary>60. <b>标题：Automated Scoring for Reading Comprehension via In-context BERT Tuning</b></summary>
  <p><b>编号</b>：[231]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09864</p>
  <p><b>作者</b>：Nigel Fernandez,  Aritra Ghosh,  Naiming Liu,  Zichao Wang,  Benoît Choffin,  Richard Baraniuk,  Andrew Lan</p>
  <p><b>备注</b>：Published as a conference paper at AIED 2022. A grand prize-winner for the NAEP AS Challenge. Code available at: this https URL</p>
  <p><b>关键词</b>：human grader effort, open-ended student responses, significantly reduce human, reduce human grader, grader effort</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Automated scoring of open-ended student responses has the potential to
significantly reduce human grader effort. Recent advances in automated scoring
often leverage textual representations based on pre-trained language models
such as BERT and GPT as input to scoring models. Most existing approaches train
a separate model for each item/question, which is suitable for scenarios such
as essay scoring where items can be quite different from one another. However,
these approaches have two limitations: 1) they fail to leverage item linkage
for scenarios such as reading comprehension where multiple items may share a
reading passage; 2) they are not scalable since storing one model per item
becomes difficult when models have a large number of parameters. In this paper,
we report our (grand prize-winning) solution to the National Assessment of
Education Progress (NAEP) automated scoring challenge for reading
comprehension. Our approach, in-context BERT fine-tuning, produces a single
shared scoring model for all items with a carefully-designed input structure to
provide contextual information on each item. We demonstrate the effectiveness
of our approach via local evaluations using the training dataset provided by
the challenge. We also discuss the biases, common error types, and limitations
of our approach.</p>
  </details>
</details>
<details>
  <summary>61. <b>标题：Masked Conditional Video Diffusion for Prediction, Generation, and  Interpolation</b></summary>
  <p><b>编号</b>：[235]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09853</p>
  <p><b>作者</b>：Vikram Voleti,  Alexia Jolicoeur-Martineau,  Christopher Pal</p>
  <p><b>备注</b>：9 pages, 4 figures, 7 tables</p>
  <p><b>关键词</b>：frames, future, future frames, Video, past</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Video prediction is a challenging task. The quality of video frames from
current state-of-the-art (SOTA) generative models tends to be poor and
generalization beyond the training data is difficult. Furthermore, existing
prediction frameworks are typically not capable of simultaneously handling
other video-related tasks such as unconditional generation or interpolation. In
this work, we devise a general-purpose framework called Masked Conditional
Video Diffusion (MCVD) for all of these video synthesis tasks using a
probabilistic conditional score-based denoising diffusion model, conditioned on
past and/or future frames. We train the model in a manner where we randomly and
independently mask all the past frames or all the future frames. This novel but
straightforward setup allows us to train a single model that is capable of
executing a broad range of video tasks, specifically: future/past prediction --
when only future/past frames are masked; unconditional generation -- when both
past and future frames are masked; and interpolation -- when neither past nor
future frames are masked. Our experiments show that this approach can generate
high-quality frames for diverse types of videos. Our MCVD models are built from
simple non-recurrent 2D-convolutional architectures, conditioning on blocks of
frames and generating blocks of frames. We generate videos of arbitrary lengths
autoregressively in a block-wise manner. Our approach yields SOTA results
across standard video prediction and interpolation benchmarks, with computation
times for training models measured in 1-12 days using $\le$ 4 GPUs.
this https URL</p>
  </details>
</details>
<details>
  <summary>62. <b>标题：Deconfounding Actor-Critic Network with Policy Adaptation for Dynamic  Treatment Regimes</b></summary>
  <p><b>编号</b>：[236]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09852</p>
  <p><b>作者</b>：Changchang Yin,  Ruoqi Liu,  Jeffrey Caterino,  Ping Zhang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：learned DTR policies, critically ill patients, ill patients remains, DTR policies, major challenge</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Despite intense efforts in basic and clinical research, an individualized
ventilation strategy for critically ill patients remains a major challenge.
Recently, dynamic treatment regime (DTR) with reinforcement learning (RL) on
electronic health records (EHR) has attracted interest from both the healthcare
industry and machine learning research community. However, most learned DTR
policies might be biased due to the existence of confounders. Although some
treatment actions non-survivors received may be helpful, if confounders cause
the mortality, the training of RL models guided by long-term outcomes (e.g.,
90-day mortality) would punish those treatment actions causing the learned DTR
policies to be suboptimal. In this study, we develop a new deconfounding
actor-critic network (DAC) to learn optimal DTR policies for patients. To
alleviate confounding issues, we incorporate a patient resampling module and a
confounding balance module into our actor-critic framework. To avoid punishing
the effective treatment actions non-survivors received, we design a short-term
reward to capture patients' immediate health state changes. Combining
short-term with long-term rewards could further improve the model performance.
Moreover, we introduce a policy adaptation method to successfully transfer the
learned model to new-source small-scale datasets. The experimental results on
one semi-synthetic and two different real-world datasets show the proposed
model outperforms the state-of-the-art models. The proposed model provides
individualized treatment decisions for mechanical ventilation that could
improve patient outcomes.</p>
  </details>
</details>
<details>
  <summary>63. <b>标题：A toolbox for idea generation and evaluation: Machine learning,  data-driven, and contest-driven approaches to support idea generation</b></summary>
  <p><b>编号</b>：[241]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09840</p>
  <p><b>作者</b>：Workneh Yilma Ayele</p>
  <p><b>备注</b>：ISBN 978-91-7911-790-0 ISBN 978-91-7911-791-7 ISSN 1101-8526</p>
  <p><b>关键词</b>：documents published online, growing digital data, digital data generated, scholarly literature, social media</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The significance and abundance of data are increasing due to the growing
digital data generated from social media, sensors, scholarly literature,
patents, different forms of documents published online, databases, product
manuals, etc. Various data sources can be used to generate ideas, yet, in
addition to bias, the size of the available digital data is a major challenge
when it comes to manual analysis. Hence, human-machine interaction is essential
for generating valuable ideas where machine learning and data-driven techniques
generate patterns from data and serve human sense-making. However, the use of
machine learning and data-driven approaches to generate ideas is a relatively
new area. Moreover, it is also possible to stimulate innovation using
contest-driven idea generation and evaluation. The results and contributions of
this thesis can be viewed as a toolbox of idea-generation techniques, including
a list of data-driven and machine learning techniques with corresponding data
sources and models to support idea generation. In addition, the results include
two models, one method and one framework, to better support data-driven and
contest- driven idea generation. The beneficiaries of these artefacts are
practitioners in data and knowledge engineering, data mining project managers,
and innovation agents. Innovation agents include incubators, contest
organizers, consultants, innovation accelerators, and industries. Since the
proposed artefacts consist of process models augmented with AI techniques,
human-centred AI is a promising area of research that can contribute to the
artefacts' further development and promote creativity.</p>
  </details>
</details>
<details>
  <summary>64. <b>标题：HyBNN and FedHyBNN: (Federated) Hybrid Binary Neural Networks</b></summary>
  <p><b>编号</b>：[242]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09839</p>
  <p><b>作者</b>：Kinshuk Dua</p>
  <p><b>备注</b>：11 pages, 7 figures, submitted to neurips</p>
  <p><b>关键词</b>：resource constrained devices, lower memory consumption, Neural Networks, Binary Neural Networks, Binary Neural</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Binary Neural Networks (BNNs), neural networks with weights and activations
constrained to -1(0) and +1, are an alternative to deep neural networks which
offer faster training, lower memory consumption and lightweight models, ideal
for use in resource constrained devices while being able to utilize the
architecture of their deep neural network counterpart. However, the input
binarization step used in BNNs causes a severe accuracy loss. In this paper, we
introduce a novel hybrid neural network architecture, Hybrid Binary Neural
Network (HyBNN), consisting of a task-independent, general, full-precision
variational autoencoder with a binary latent space and a task specific binary
neural network that is able to greatly limit the accuracy loss due to input
binarization by using the full precision variational autoencoder as a feature
extractor. We use it to combine the state-of-the-art accuracy of deep neural
networks with the much faster training time, quicker test-time inference and
power efficiency of binary neural networks. We show that our proposed system is
able to very significantly outperform a vanilla binary neural network with
input binarization. We also introduce FedHyBNN, a highly communication
efficient federated counterpart to HyBNN and demonstrate that it is able to
reach the same accuracy as its non-federated equivalent. We make our source
code, experimental parameters and models available at:
https://anonymous.4open.science/r/HyBNN.</p>
  </details>
</details>
<details>
  <summary>65. <b>标题：Concurrent Policy Blending and System Identification for Generalized  Assistive Control</b></summary>
  <p><b>编号</b>：[245]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09836</p>
  <p><b>作者</b>：Luke Bhan,  Marcos Quinones-Grueiro,  Gautam Biswas</p>
  <p><b>备注</b>：Accepted to ICRA 2022</p>
  <p><b>关键词</b>：multiple varying parameters, solving complex collaborative, complex collaborative robotic, robotic tasks subject, address the problem</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this work, we address the problem of solving complex collaborative robotic
tasks subject to multiple varying parameters. Our approach combines
simultaneous policy blending with system identification to create generalized
policies that are robust to changes in system parameters. We employ a blending
network whose state space relies solely on parameter estimates from a system
identification technique. As a result, this blending network learns how to
handle parameter changes instead of trying to learn how to solve the task for a
generalized parameter set simultaneously. We demonstrate our scheme's ability
on a collaborative robot and human itching task in which the human has motor
impairments. We then showcase our approach's efficiency with a variety of
system identification techniques when compared to standard domain
randomization.</p>
  </details>
</details>
<details>
  <summary>66. <b>标题：DPER: Dynamic Programming for Exist-Random Stochastic SAT</b></summary>
  <p><b>编号</b>：[250]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09826</p>
  <p><b>作者</b>：Vu H. N. Phan,  Moshe Y. Vardi</p>
  <p><b>备注</b>：arXiv admin note: substantial text overlap with arXiv:2205.08632</p>
  <p><b>关键词</b>：Bayesian inference, maximum a posteriori, probable explanation, MPE, MAR</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In Bayesian inference, the maximum a posteriori (MAP) problem combines the
most probable explanation (MPE) and marginalization (MAR) problems. The
counterpart in propositional logic is the exist-random stochastic
satisfiability (ER-SSAT) problem, which combines the satisfiability (SAT) and
weighted model counting (WMC) problems. Both MAP and ER-SSAT have the form
$\operatorname{argmax}_X \sum_Y f(X, Y)$, where $f$ is a real-valued function
over disjoint sets $X$ and $Y$ of variables. These two optimization problems
request a value assignment for the $X$ variables that maximizes the weighted
sum of $f(X, Y)$ over all value assignments for the $Y$ variables. ER-SSAT has
been shown to be a promising approach to formally verify fairness in supervised
learning. Recently, dynamic programming on graded project-join trees has been
proposed to solve weighted projected model counting (WPMC), a related problem
that has the form $\sum_X \max_Y f(X, Y)$. We extend this WPMC framework to
exactly solve ER-SSAT and implement a dynamic-programming solver named DPER.
Our empirical evaluation indicates that DPER contributes to the portfolio of
state-of-the-art ER-SSAT solvers (DC-SSAT and erSSAT) through competitive
performance on low-width problem instances.</p>
  </details>
</details>
<details>
  <summary>67. <b>标题：Unsupervised Learning of Depth, Camera Pose and Optical Flow from  Monocular Video</b></summary>
  <p><b>编号</b>：[252]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09821</p>
  <p><b>作者</b>：Dipan Mandal,  Abhilash Jain,  Sreenivas Subramoney</p>
  <p><b>备注</b>：8 pages, 2 figures. arXiv admin note: text overlap with arXiv:1803.02276 by other authors</p>
  <p><b>关键词</b>：joint learning system, propose DFPNet, joint learning, Camera Pose, learning system</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose DFPNet -- an unsupervised, joint learning system for monocular
Depth, Optical Flow and egomotion (Camera Pose) estimation from monocular image
sequences. Due to the nature of 3D scene geometry these three components are
coupled. We leverage this fact to jointly train all the three components in an
end-to-end manner. A single composite loss function -- which involves image
reconstruction-based loss for depth & optical flow, bidirectional consistency
checks and smoothness loss components -- is used to train the network. Using
hyperparameter tuning, we are able to reduce the model size to less than 5%
(8.4M parameters) of state-of-the-art DFP models. Evaluation on KITTI and
Cityscapes driving datasets reveals that our model achieves results comparable
to state-of-the-art in all of the three tasks, even with the significantly
smaller model size.</p>
  </details>
</details>
<details>
  <summary>68. <b>标题：Towards a Holistic View on Argument Quality Prediction</b></summary>
  <p><b>编号</b>：[259]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09803</p>
  <p><b>作者</b>：Michael Fromm,  Max Berrendorf,  Johanna Reiml,  Isabelle Mayerhofer,  Siddharth Bhargava,  Evgeniy Faerman,  Thomas Seidl</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：society foundational pillars, receives increasing attention, advances in NLP, arguments receives increasing, foundational pillars</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Argumentation is one of society's foundational pillars, and, sparked by
advances in NLP and the vast availability of text data, automated mining of
arguments receives increasing attention. A decisive property of arguments is
their strength or quality. While there are works on the automated estimation of
argument strength, their scope is narrow: they focus on isolated datasets and
neglect the interactions with related argument mining tasks, such as argument
identification, evidence detection, or emotional appeal. In this work, we close
this gap by approaching argument quality estimation from multiple different
angles: Grounded on rich results from thorough empirical evaluations, we assess
the generalization capabilities of argument quality estimation across diverse
domains, the interplay with related argument mining tasks, and the impact of
emotions on perceived argument strength. We find that generalization depends on
a sufficient representation of different domains in the training part. In
zero-shot transfer and multi-task experiments, we reveal that argument quality
is among the more challenging tasks but can improve others. Finally, we show
that emotions play a minor role in argument quality than is often assumed.</p>
  </details>
</details>
<details>
  <summary>69. <b>标题：Label-invariant Augmentation for Semi-Supervised Graph Classification</b></summary>
  <p><b>编号</b>：[260]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09802</p>
  <p><b>作者</b>：Han Yue,  Chunhui Zhang,  Chuxu Zhang,  Hongfu Liu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：computer vision domain, contrastiveness-based augmentation surges, graph contrastive learning, including rotation, vision domain</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recently, contrastiveness-based augmentation surges a new climax in the
computer vision domain, where some operations, including rotation, crop, and
flip, combined with dedicated algorithms, dramatically increase the model
generalization and robustness. Following this trend, some pioneering attempts
employ the similar idea to graph data. Nevertheless, unlike images, it is much
more difficult to design reasonable augmentations without changing the nature
of graphs. Although exciting, the current graph contrastive learning does not
achieve as promising performance as visual contrastive learning. We conjecture
the current performance of graph contrastive learning might be limited by the
violation of the label-invariant augmentation assumption. In light of this, we
propose a label-invariant augmentation for graph-structured data to address
this challenge. Different from the node/edge modification and subgraph
extraction, we conduct the augmentation in the representation space and
generate the augmented samples in the most difficult direction while keeping
the label of augmented data the same as the original samples. In the
semi-supervised scenario, we demonstrate our proposed method outperforms the
classical graph neural network based methods and recent graph contrastive
learning on eight benchmark graph-structured data, followed by several in-depth
experiments to further explore the label-invariant augmentation in several
aspects.</p>
  </details>
</details>
<details>
  <summary>70. <b>标题：Graph Neural Networks Are More Powerful Than we Think</b></summary>
  <p><b>编号</b>：[261]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09801</p>
  <p><b>作者</b>：Charilaos I. Kanatsoulis,  Alejandro Ribeiro</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Graph Neural Networks, Neural Networks, shown remarkable performance, powerful convolutional architectures, Graph Neural</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Graph Neural Networks (GNNs) are powerful convolutional architectures that
have shown remarkable performance in various node-level and graph-level tasks.
Despite their success, the common belief is that the expressive power of GNNs
is limited and that they are at most as discriminative as the Weisfeiler-Lehman
(WL) algorithm. In this paper we argue the opposite and show that the WL
algorithm is the upper bound only when the input to the GNN is the vector of
all ones. In this direction, we derive an alternative analysis that employs
linear algebraic tools and characterize the representational power of GNNs with
respect to the eigenvalue decomposition of the graph operators. We show that
GNNs can distinguish between any graphs that differ in at least one eigenvalue
and design simple GNN architectures that are provably more expressive than the
WL algorithm. Thorough experimental analysis on graph isomorphism and graph
classification datasets corroborates our theoretical results and demonstrates
the effectiveness of the proposed architectures.</p>
  </details>
</details>
<details>
  <summary>71. <b>标题：Improving Multi-Task Generalization via Regularizing Spurious  Correlation</b></summary>
  <p><b>编号</b>：[263]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09797</p>
  <p><b>作者</b>：Ziniu Hu,  Zhe Zhao,  Xinyang Yi,  Tiansheng Yao,  Lichan Hong,  Yizhou Sun,  Ed H. Chi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：powerful learning paradigm, MTL, paradigm to improve, spurious, knowledge</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Multi-Task Learning (MTL) is a powerful learning paradigm to improve
generalization performance via knowledge sharing. However, existing studies
find that MTL could sometimes hurt generalization, especially when two tasks
are less correlated. One possible reason that hurts generalization is spurious
correlation, i.e., some knowledge is spurious and not causally related to task
labels, but the model could mistakenly utilize them and thus fail when such
correlation changes. In MTL setup, there exist several unique challenges of
spurious correlation. First, the risk of having non-causal knowledge is higher,
as the shared MTL model needs to encode all knowledge from different tasks, and
causal knowledge for one task could be potentially spurious to the other.
Second, the confounder between task labels brings in a different type of
spurious correlation to MTL. We theoretically prove that MTL is more prone to
taking non-causal knowledge from other tasks than single-task learning, and
thus generalize worse. To solve this problem, we propose Multi-Task Causal
Representation Learning framework, aiming to represent multi-task knowledge via
disentangled neural modules, and learn which module is causally related to each
task via MTL-specific invariant regularization. Experiments show that it could
enhance MTL model's performance by 5.5% on average over Multi-MNIST, MovieLens,
Taskonomy, CityScape, and NYUv2, via alleviating spurious correlation problem.</p>
  </details>
</details>
<details>
  <summary>72. <b>标题：Causal Discovery and Injection for Feed-Forward Neural Networks</b></summary>
  <p><b>编号</b>：[267]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09787</p>
  <p><b>作者</b>：Fabrizio Russo,  Francesca Toni</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：meaningful causal relationship, neural network models, high-stakes decisions, Neural networks, feed-forward neural networks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Neural networks have proven to be effective at solving a wide range of
problems but it is often unclear whether they learn any meaningful causal
relationship: this poses a problem for the robustness of neural network models
and their use for high-stakes decisions. We propose a novel method overcoming
this issue by injecting knowledge in the form of (possibly partial) causal
graphs into feed-forward neural networks, so that the learnt model is
guaranteed to conform to the graph, hence adhering to expert knowledge. This
knowledge may be given up-front or during the learning process, to improve the
model through human-AI collaboration. We apply our method to synthetic and real
(tabular) data showing that it is robust against noise and can improve causal
discovery and prediction performance in low data regimes.</p>
  </details>
</details>
<details>
  <summary>73. <b>标题：HDGT: Heterogeneous Driving Graph Transformer for Multi-Agent Trajectory  Prediction via Scene Encoding</b></summary>
  <p><b>编号</b>：[271]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09753</p>
  <p><b>作者</b>：Xiaosong Jia,  Penghao Wu,  Li Chen,  Hongyang Li,  Yu Liu,  Junchi Yan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：driving scene, essential task, downstream task, Driving Graph Transformer, Heterogeneous Driving Graph</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>One essential task for autonomous driving is to encode the information of a
driving scene into vector representations so that the downstream task such as
trajectory prediction could perform well. The driving scene is complicated, and
there exists heterogeneity within elements, where they own diverse types of
information i.e., agent dynamics, map routing, road lines, etc. Meanwhile,
there also exist relativity across elements - meaning they have spatial
relations with each other; such relations should be canonically represented
regarding the relative measurements since the absolute value of the coordinate
is meaningless. Taking these two observations into consideration, we propose a
novel backbone, namely Heterogeneous Driving Graph Transformer (HDGT), which
models the driving scene as a heterogeneous graph with different types of nodes
and edges. For graph construction, each node represents either an agent or a
road element and each edge represents their semantics relations such as
Pedestrian-To-Crosswalk, Lane-To-Left-Lane. As for spatial relation encoding,
instead of setting a fixed global reference, the coordinate information of the
node as well as its in-edges is transformed to the local node-centric
coordinate system. For the aggregation module in the graph neural network
(GNN), we adopt the transformer structure in a hierarchical way to fit the
heterogeneous nature of inputs. Experimental results show that the proposed
method achieves new state-of-the-art on INTERACTION Prediction Challenge and
Waymo Open Motion Challenge, in which we rank 1st and 2nd respectively
regarding the minADE/minFDE metric.</p>
  </details>
</details>
<details>
  <summary>74. <b>标题：Local dynamic mode of Cognitive Behavioral Therapy</b></summary>
  <p><b>编号</b>：[272]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09752</p>
  <p><b>作者</b>：Victor Ardulov,  Torrey A. Creed,  David C. Atkins,  Shrikanth Narayanan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：increase mental health, mental health equity, order to increase, increase mental, important to increase</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In order to increase mental health equity among the most vulnerable and
marginalized communities, it is important to increase access to high-quality
therapists. One facet of addressing these needs, is to provide timely feedback
to clinicians as they interact with their clients, in a way that is also
contextualized to specific clients and interactions they have had. Dynamical
systems provide a framework through which to analyze interactions. The present
work applies these methods to the domain of automated psychotherapist
evaluation for Cognitive Behavioral Therapy (CBT). Our methods extract local
dynamic modes from short windows of conversation and learns to correlate the
observed dynamics to CBT competence. The results demonstrate the value of this
paradigm and outlines the way in which these methods can be used to study and
improve therapeutic strategies.</p>
  </details>
</details>
<details>
  <summary>75. <b>标题：Taylor Genetic Programming for Symbolic Regression</b></summary>
  <p><b>编号</b>：[273]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09751</p>
  <p><b>作者</b>：Baihe He,  Qiang Lu,  Qingyun Yang,  Jake Luo,  Zhiguang Wang</p>
  <p><b>备注</b>：9 pages, 6 figures, conference</p>
  <p><b>关键词</b>：solve symbolic regression, Taylor genetic programming, Taylor polynomial, commonly used approach, approach to solve</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Genetic programming (GP) is a commonly used approach to solve symbolic
regression (SR) problems. Compared with the machine learning or deep learning
methods that depend on the pre-defined model and the training dataset for
solving SR problems, GP is more focused on finding the solution in a search
space. Although GP has good performance on large-scale benchmarks, it randomly
transforms individuals to search results without taking advantage of the
characteristics of the dataset. So, the search process of GP is usually slow,
and the final results could be this http URL guide GP by these characteristics,
we propose a new method for SR, called Taylor genetic programming (TaylorGP)
(Code and appendix at this https URL). TaylorGP leverages
a Taylor polynomial to approximate the symbolic equation that fits the dataset.
It also utilizes the Taylor polynomial to extract the features of the symbolic
equation: low order polynomial discrimination, variable separability, boundary,
monotonic, and parity. GP is enhanced by these Taylor polynomial techniques.
Experiments are conducted on three kinds of benchmarks: classical SR, machine
learning, and physics. The experimental results show that TaylorGP not only has
higher accuracy than the nine baseline methods, but also is faster in finding
stable results.</p>
  </details>
</details>
<details>
  <summary>76. <b>标题：Self-supervised deep learning MRI reconstruction with Noisier2Noise</b></summary>
  <p><b>编号</b>：[281]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10278</p>
  <p><b>作者</b>：Charles Millard,  Mark Chiew</p>
  <p><b>备注</b>：Submitted to IEEE TMI on 20th May 2022</p>
  <p><b>关键词</b>：statistical modeling capabilities, Magnetic Resonance Imaging, recent years, attention on leveraging, leveraging the statistical</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In recent years, there has been attention on leveraging the statistical
modeling capabilities of neural networks for reconstructing sub-sampled
Magnetic Resonance Imaging (MRI) data. Most proposed methods assume the
existence of a representative fully-sampled dataset and use fully-supervised
training. However, for many applications, fully sampled training data is not
available, and may be highly impractical to acquire. The development of
self-supervised methods, which use only sub-sampled data for training, are
therefore highly desirable. This work extends the Noisier2Noise framework,
which was originally constructed for self-supervised denoising tasks, to
variable density sub-sampled MRI data. Further, we use the Noisier2Noise
framework to analytically explain the performance of Self-Supervised Learning
via Data Undersampling (SSDU), a recently proposed method that performs well in
practice but until now lacked theoretical justification. We also use
Noisier2Noise to propose a modification of SSDU that we find substantially
improves its reconstruction quality and robustness, offering a test set
mean-squared-error within 1% of fully supervised training on the fastMRI brain
dataset.</p>
  </details>
</details>
<details>
  <summary>77. <b>标题：Some neighborhood-related fuzzy covering-based rough set models and  their applications for decision making</b></summary>
  <p><b>编号</b>：[289]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10125</p>
  <p><b>作者</b>：Gongao Qi,  Bin Yang,  Wei Li</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：fuzzy neighborhood operators, FRS theory, data mining processes, neighborhood operators based, neighborhood operators</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Fuzzy rough set (FRS) has a great effect on data mining processes and the
fuzzy logical operators play a key role in the development of FRS theory. In
order to further generalize the FRS theory to more complicated data
environments, we firstly propose four types of fuzzy neighborhood operators
based on fuzzy covering by overlap functions and their implicators in this
paper. Meanwhile, the derived fuzzy coverings from an original fuzzy covering
are defined and the equalities among overlap function-based fuzzy neighborhood
operators based on a finite fuzzy covering are also investigated. Secondly, we
prove that new operators can be divided into seventeen groups according to
equivalence relations, and the partial order relations among these seventeen
classes of operators are discussed, as well. Go further, the comparisons with $
t$-norm-based fuzzy neighborhood operators given by D'eer et al. are also made
and two types of neighborhood-related fuzzy covering-based rough set models,
which are defined via different fuzzy neighborhood operators that are on the
basis of diverse kinds of fuzzy logical operators proposed. Furthermore, the
groupings and partially order relations are also discussed. Finally, a novel
fuzzy TOPSIS methodology is put forward to solve a biosynthetic nanomaterials
select issue, and the rationality and enforceability of our new approach is
verified by comparing its results with nine different methods.</p>
  </details>
</details>
<details>
  <summary>78. <b>标题：A Case of Exponential Convergence Rates for SVM</b></summary>
  <p><b>编号</b>：[291]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.10055</p>
  <p><b>作者</b>：Vivien Cabannes,  Stefano Vigogna</p>
  <p><b>备注</b>：16 pages, 6 figures</p>
  <p><b>关键词</b>：machine learning classes, introductory machine learning, learning classes, introductory machine, machine learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Classification is often the first problem described in introductory machine
learning classes. Generalization guarantees of classification have historically
been offered by Vapnik-Chervonenkis theory. Yet those guarantees are based on
intractable algorithms, which has led to the theory of surrogate methods in
classification. Guarantees offered by surrogate methods are based on
calibration inequalities, which have been shown to be highly sub-optimal under
some margin conditions, failing short to capture exponential convergence
phenomena. Those "super" fast rates are becoming to be well understood for
smooth surrogates, but the picture remains blurry for non-smooth losses such as
the hinge loss, associated with the renowned support vector machines. In this
paper, we present a simple mechanism to obtain fast convergence rates and we
investigate its usage for SVM. In particular, we show that SVM can exhibit
exponential convergence rates even without assuming the hard Tsybakov margin
condition.</p>
  </details>
</details>
<details>
  <summary>79. <b>标题：Robust Expected Information Gain for Optimal Bayesian Experimental  Design Using Ambiguity Sets</b></summary>
  <p><b>编号</b>：[295]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09914</p>
  <p><b>作者</b>：Jinwoo Go,  Tobin Isaac</p>
  <p><b>备注</b>：The 38th Conference on Uncertainty in Artificial Intelligence, 2022</p>
  <p><b>关键词</b>：Bayesian experimental design, expected information gain, Bayesian experimental, model prior distribution, information gain</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The ranking of experiments by expected information gain (EIG) in Bayesian
experimental design is sensitive to changes in the model's prior distribution,
and the approximation of EIG yielded by sampling will have errors similar to
the use of a perturbed prior. We define and analyze \emph{robust expected
information gain} (REIG), a modification of the objective in EIG maximization
by minimizing an affine relaxation of EIG over an ambiguity set of
distributions that are close to the original prior in KL-divergence. We show
that, when combined with a sampling-based approach to estimating EIG, REIG
corresponds to a `log-sum-exp' stabilization of the samples used to estimate
EIG, meaning that it can be efficiently implemented in practice. Numerical
tests combining REIG with variational nested Monte Carlo (VNMC), adaptive
contrastive estimation (ACE) and mutual information neural estimation (MINE)
suggest that in practice REIG also compensates for the variability of
under-sampled estimators.</p>
  </details>
</details>
<details>
  <summary>80. <b>标题：Sparse Infinite Random Feature Latent Variable Modeling</b></summary>
  <p><b>编号</b>：[296]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09909</p>
  <p><b>作者</b>：Michael Minyi Zhang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Bayesian non-parametric latent, Indian buffet process, Bayesian non-parametric, Indian buffet, latent space</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose a non-linear, Bayesian non-parametric latent variable model where
the latent space is assumed to be sparse and infinite dimensional a priori
using an Indian buffet process prior. A posteriori, the number of instantiated
dimensions in the latent space is guaranteed to be finite. The purpose of
placing the Indian buffet process on the latent variables is to: 1.)
Automatically and probabilistically select the number of latent dimensions. 2.)
Impose sparsity in the latent space, where the Indian buffet process will
select which elements are exactly zero. Our proposed model allows for sparse,
non-linear latent variable modeling where the number of latent dimensions is
selected automatically. Inference is made tractable using the random Fourier
approximation and we can easily implement posterior inference through Markov
chain Monte Carlo sampling. This approach is amenable to many observation
models beyond the Gaussian setting. We demonstrate the utility of our method on
a variety of synthetic, biological and text datasets and show that we can
obtain superior test set performance compared to previous latent variable
models.</p>
  </details>
</details>
<details>
  <summary>81. <b>标题：Breaking the $\sqrt{T}$ Barrier: Instance-Independent Logarithmic Regret  in Stochastic Contextual Linear Bandits</b></summary>
  <p><b>编号</b>：[299]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09899</p>
  <p><b>作者</b>：Avishek Ghosh,  Abishek Sankararaman</p>
  <p><b>备注</b>：To appear in ICML 2022</p>
  <p><b>关键词</b>：stochastic contextual bandits, stochastic contexts, contextual linear bandit, linear contextual bandit, instance independent</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We prove an instance independent (poly) logarithmic regret for stochastic
contextual bandits with linear payoff. Previously, in \cite{chu2011contextual},
a lower bound of $\mathcal{O}(\sqrt{T})$ is shown for the contextual linear
bandit problem with arbitrary (adversarily chosen) contexts. In this paper, we
show that stochastic contexts indeed help to reduce the regret from $\sqrt{T}$
to $\polylog(T)$. We propose Low Regret Stochastic Contextual Bandits
(\texttt{LR-SCB}), which takes advantage of the stochastic contexts and
performs parameter estimation (in $\ell_2$ norm) and regret minimization
simultaneously. \texttt{LR-SCB} works in epochs, where the parameter estimation
of the previous epoch is used to reduce the regret of the current epoch. The
(poly) logarithmic regret of \texttt{LR-SCB} stems from two crucial facts: (a)
the application of a norm adaptive algorithm to exploit the parameter
estimation and (b) an analysis of the shifted linear contextual bandit
algorithm, showing that shifting results in increasing regret. We have also
shown experimentally that stochastic contexts indeed incurs a regret that
scales with $\polylog(T)$.</p>
  </details>
</details>
<details>
  <summary>82. <b>标题：Explainable Graph Theory-Based Identification of Meter-Transformer  Mapping</b></summary>
  <p><b>编号</b>：[300]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.09874</p>
  <p><b>作者</b>：Bilal Saleem,  Yang Weng</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Distributed energy resources, provide situational awareness, recovering meter-transformer mapping, recovering meter-transformer, Distributed energy</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Distributed energy resources are better for the environment but may cause
transformer overload in distribution grids, calling for recovering
meter-transformer mapping to provide situational awareness, i.e., the
transformer loading. The challenge lies in recovering meter-transformer (M.T.)
mapping for two common scenarios, e.g., large distances between a meter and its
parent transformer or high similarity of a meter's consumption pattern to a
non-parent transformer's meters. Past methods either assume a variety of data
as in the transmission grid or ignore the two common scenarios mentioned above.
Therefore, we propose to utilize the above observation via spectral embedding
by using the property that inter-transformer meter consumptions are not the
same and that the noise in data is limited so that all the k smallest
eigenvalues of the voltage-based Laplacian matrix are smaller than the next
smallest eigenvalue of the ideal Laplacian matrix. We also provide a guarantee
based on this understanding. Furthermore, we partially relax the assumption by
utilizing location information to aid voltage information for areas
geographically far away but with similar voltages. Numerical simulations on the
IEEE test systems and real feeders from our partner utility show that the
proposed method correctly identifies M.T. mapping.</p>
  </details>
</details>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">徐耀彬</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://louishsu.xyz/2022/05/24/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html">http://louishsu.xyz/2022/05/24/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://louishsu.xyz" target="_blank">LOUIS' BLOG</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"></div><div class="post_share"><div class="social-share" data-image="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="next-post pull-full"><a href="/2021/10/22/%E4%B8%AD%E5%9B%BD%E6%B3%95%E5%BE%8B%E6%99%BA%E8%83%BD%E6%8A%80%E6%9C%AF%E8%AF%84%E6%B5%8B(CAIL2021)%EF%BC%9A%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96(Rank2).html"><img class="next-cover" src="http://cail.cipsc.org.cn/img/index_mainpic.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">中国法律智能技术评测(CAIL2021)：信息抽取(Rank2)</div></div></a></div></nav><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="twikoo-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="card-info-avatar is-center"><img class="avatar-img" src="/img/touxiang.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/><div class="author-info__name">徐耀彬</div><div class="author-info__description">做知识的原创者！</div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">11</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">标签</div><div class="length-num">3</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">分类</div><div class="length-num">7</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/isLouisHsu"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/isLouisHsu" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:is.louishsu@foxmail.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>公告</span></div><div class="announcement_content">记录和分享一些学习和开源内容，若有问题可通过邮箱is.louishsu@foxmail.com联系，欢迎交流！！</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">1.</span> <span class="toc-text">统计</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">2.</span> <span class="toc-text">计算机视觉</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">3.</span> <span class="toc-text">自然语言处理</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">4.</span> <span class="toc-text">机器学习</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">5.</span> <span class="toc-text">人工智能</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2022/05/24/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html" title="Arxiv每日速递(2022-05-24)"><img src="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Arxiv每日速递(2022-05-24)"/></a><div class="content"><a class="title" href="/2022/05/24/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html" title="Arxiv每日速递(2022-05-24)">Arxiv每日速递(2022-05-24)</a><time datetime="2022-05-24T00:46:21.361Z" title="发表于 2022-05-24 08:46:21">2022-05-24</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/10/22/%E4%B8%AD%E5%9B%BD%E6%B3%95%E5%BE%8B%E6%99%BA%E8%83%BD%E6%8A%80%E6%9C%AF%E8%AF%84%E6%B5%8B(CAIL2021)%EF%BC%9A%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96(Rank2).html" title="中国法律智能技术评测(CAIL2021)：信息抽取(Rank2)"><img src="http://cail.cipsc.org.cn/img/index_mainpic.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="中国法律智能技术评测(CAIL2021)：信息抽取(Rank2)"/></a><div class="content"><a class="title" href="/2021/10/22/%E4%B8%AD%E5%9B%BD%E6%B3%95%E5%BE%8B%E6%99%BA%E8%83%BD%E6%8A%80%E6%9C%AF%E8%AF%84%E6%B5%8B(CAIL2021)%EF%BC%9A%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96(Rank2).html" title="中国法律智能技术评测(CAIL2021)：信息抽取(Rank2)">中国法律智能技术评测(CAIL2021)：信息抽取(Rank2)</a><time datetime="2021-10-22T14:29:06.000Z" title="发表于 2021-10-22 22:29:06">2021-10-22</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/05/19/%E5%85%A8%E7%90%83%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%8A%80%E6%9C%AF%E5%88%9B%E6%96%B0%E5%A4%A7%E8%B5%9B%E3%80%90%E8%B5%9B%E9%81%93%E4%B8%80%E3%80%91%EF%BC%9A%E5%8C%BB%E5%AD%A6%E5%BD%B1%E5%83%8F%E6%8A%A5%E5%91%8A%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B.html" title="全球人工智能技术创新大赛【赛道一】：医学影像报告异常检测"><img src="https://tianchi-public.oss-cn-hangzhou.aliyuncs.com/public/files/forum/161037709574435991610377095138.jpeg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="全球人工智能技术创新大赛【赛道一】：医学影像报告异常检测"/></a><div class="content"><a class="title" href="/2021/05/19/%E5%85%A8%E7%90%83%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%8A%80%E6%9C%AF%E5%88%9B%E6%96%B0%E5%A4%A7%E8%B5%9B%E3%80%90%E8%B5%9B%E9%81%93%E4%B8%80%E3%80%91%EF%BC%9A%E5%8C%BB%E5%AD%A6%E5%BD%B1%E5%83%8F%E6%8A%A5%E5%91%8A%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B.html" title="全球人工智能技术创新大赛【赛道一】：医学影像报告异常检测">全球人工智能技术创新大赛【赛道一】：医学影像报告异常检测</a><time datetime="2021-05-19T09:57:06.000Z" title="发表于 2021-05-19 17:57:06">2021-05-19</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2020/09/16/%E8%AF%A6%E8%A7%A3%E5%91%BD%E5%90%8D%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB%E6%A8%A1%E5%9E%8B%EF%BC%9ALSTM-CRF.html" title="详解命名实体识别模型：LSTM-CRF"><img src="https://gimg2.baidu.com/image_search/src=http%3A%2F%2Fpic1.zhimg.com%2Fv2-1ed6a10dbb239a148e42df088c5870a6_1440w.jpg%3Fsource%3D172ae18b&amp;refer=http%3A%2F%2Fpic1.zhimg.com&amp;app=2002&amp;size=f9999,10000&amp;q=a80&amp;n=0&amp;g=0n&amp;fmt=jpeg?sec=1638183974&amp;t=4632f13fd487ed1cfcb12d67a6b71e52" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="详解命名实体识别模型：LSTM-CRF"/></a><div class="content"><a class="title" href="/2020/09/16/%E8%AF%A6%E8%A7%A3%E5%91%BD%E5%90%8D%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB%E6%A8%A1%E5%9E%8B%EF%BC%9ALSTM-CRF.html" title="详解命名实体识别模型：LSTM-CRF">详解命名实体识别模型：LSTM-CRF</a><time datetime="2020-09-16T09:26:44.000Z" title="发表于 2020-09-16 17:26:44">2020-09-16</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2020/06/14/%E8%AE%B0%E4%B8%80%E6%AC%A1MySQL%E8%A7%A3%E5%86%B3%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E6%97%B6%E7%9A%84%E5%88%86%E8%A1%A8%E9%97%AE%E9%A2%98.html" title="记一次MySQL解决大数据存储时的分表问题"><img src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="记一次MySQL解决大数据存储时的分表问题"/></a><div class="content"><a class="title" href="/2020/06/14/%E8%AE%B0%E4%B8%80%E6%AC%A1MySQL%E8%A7%A3%E5%86%B3%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E6%97%B6%E7%9A%84%E5%88%86%E8%A1%A8%E9%97%AE%E9%A2%98.html" title="记一次MySQL解决大数据存储时的分表问题">记一次MySQL解决大数据存储时的分表问题</a><time datetime="2020-06-14T15:24:27.000Z" title="发表于 2020-06-14 23:24:27">2020-06-14</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2022 By 徐耀彬</div><div class="footer_custom_text"><p><a style="margin-inline:5px"target="_blank"href="https://hexo.io/"><img src="https://img.shields.io/badge/Frame-Hexo-blue?style=flat&logo=hexo"title="博客框架为Hexo"alt="img"></a><a style="margin-inline:5px"target="_blank"href="https://butterfly.js.org/"><img src="https://img.shields.io/badge/Theme-Butterfly-6513df?style=flat&logo=bitdefender"title="主题采用butterfly"alt="img"></a><a style="margin-inline:5px"target="_blank"href="https://www.jsdelivr.com/"><img src="https://img.shields.io/badge/CDN-jsDelivr-orange?style=flat&logo=jsDelivr"title="本站使用JsDelivr为静态资源提供CDN加速"alt="img"></a><a style="margin-inline:5px"target="_blank"href="https://github.com/"><img src="https://img.shields.io/badge/Source-Github-d021d6?style=flat&logo=GitHub"title="本站项目由Gtihub托管"alt="img"></a><a style="margin-inline:5px"target="_blank"href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img src="https://img.shields.io/badge/Copyright-BY--NC--SA%204.0-d42328?style=flat&logo=Claris"alt="img"title="本站采用知识共享署名-非商业性使用-相同方式共享4.0国际许可协议进行许可"></a></br></p></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="font-plus" type="button" title="放大字体"><i class="fas fa-plus"></i></button><button id="font-minus" type="button" title="缩小字体"><i class="fas fa-minus"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div></div><hr/><div id="local-search-results"></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.css"><script>(() => {
  document.querySelectorAll('#article-container span.katex-display').forEach(item => {
    btf.wrap(item, 'div', '', 'katex-wrap')
  })
})()</script><script>(()=>{
  const $countDom = document.getElementById('twikoo-count')
  const init = () => {
    let initData = {
      el: '#twikoo-wrap',
      envId: 'blog-',
      region: ''
    }

    if (false) {
      const otherData = false
      initData = Object.assign(initData, otherData)
    }
    
    twikoo.init(initData)
  }

  const getCount = () => {
    twikoo.getCommentsCount({
      envId: 'blog-',
      region: '',
      urls: [window.location.pathname],
      includeReply: false
    }).then(function (res) {
      $countDom.innerText = res[0].count
    }).catch(function (err) {
      console.error(err);
    });
  }

  const loadTwikoo = (bool = false) => {
    if (typeof twikoo === 'object') {
      init()
      bool && $countDom && setTimeout(getCount,0)
    } else {
      getScript('https://cdn.jsdelivr.net/npm/twikoo/dist/twikoo.all.min.js').then(()=> {
        init()
        bool && $countDom && setTimeout(getCount,0)
      })
    }
  }

  if ('Twikoo' === 'Twikoo' || !false) {
    if (false) btf.loadComment(document.getElementById('twikoo-wrap'), loadTwikoo)
    else loadTwikoo(true)
  } else {
    window.loadOtherComment = () => {
      loadTwikoo()
    }
  }
})()</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><!-- hexo injector body_end start --> <script data-pjax>if(document.getElementById('recent-posts') && (location.pathname ==='/'|| '/' ==='all')){
    var parent = document.getElementById('recent-posts');
    var child = '<div class="recent-post-item" style="width:100%;height: auto"><div id="catalog_magnet"><div class="magnet_item"><a class="magnet_link" href="http://louishsu.xyz/categories/机器学习/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🐱 机器学习 (1)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://louishsu.xyz/categories/自然语言处理/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">📚 自然语言处理 (1)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://louishsu.xyz/categories/竞赛相关/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🎮 竞赛相关 (2)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://louishsu.xyz/categories/阅读笔记/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🎮 阅读笔记 (1)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><a class="magnet_link_more"  href="http://louishsu.xyz/categories" style="flex:1;text-align: center;margin-bottom: 10px;">查看更多...</a></div></div>';
    console.log('已挂载magnet')
    parent.insertAdjacentHTML("afterbegin",child)}
     </script><style>#catalog_magnet{flex-wrap: wrap;display: flex;width:100%;justify-content:space-between;padding: 10px 10px 0 10px;align-content: flex-start;}.magnet_item{flex-basis: calc(50% - 5px);background: #f2f2f2;margin-bottom: 10px;border-radius: 8px;transition: all 0.2s ease-in-out;}.magnet_item:hover{background: #b30070}.magnet_link_more{color:#555}.magnet_link{color:black}.magnet_link:hover{color:white}@media screen and (max-width: 600px) {.magnet_item {flex-basis: 100%;}}.magnet_link_context{display:flex;padding: 10px;font-size:16px;transition: all 0.2s ease-in-out;}.magnet_link_context:hover{padding: 10px 20px;}</style>
    <style></style>
  <script data-pjax src="https://cdn.jsdelivr.net/gh/Zfour/hexo-github-calendar@1.21/hexo_githubcalendar.js"></script>
  <script data-pjax>
        function GithubCalendarConfig(){
            var git_githubapiurl ="https://python-github-calendar-api.vercel.app/api?isLouisHsu";
            var git_color =['#ebedf0', '#fdcdec', '#fc9bd9', '#fa6ac5', '#f838b2', '#f5089f', '#c4067e', '#92055e', '#540336', '#48022f', '#30021f'];
            var git_user ="isLouisHsu";
            var parent_div_git = document.getElementById('recent-posts');
            var git_div_html = '<div class="recent-post-item" style="width:100%;height:auto;padding:10px;"><div id="github_loading" style="width:10%;height:100%;margin:0 auto;display: block"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"  viewBox="0 0 50 50" style="enable-background:new 0 0 50 50" xml:space="preserve"><path fill="#d0d0d0" d="M25.251,6.461c-10.318,0-18.683,8.365-18.683,18.683h4.068c0-8.071,6.543-14.615,14.615-14.615V6.461z" transform="rotate(275.098 25 25)"><animateTransform attributeType="xml" attributeName="transform" type="rotate" from="0 25 25" to="360 25 25" dur="0.6s" repeatCount="indefinite"></animateTransform></path></svg></div><div id="github_container"></div></div>';
            if(parent_div_git && location.pathname =='/'){
                console.log('已挂载github calendar')
                // parent_div_git.innerHTML=git_div_html+parent_div_git.innerHTML // 无报错，但不影响使用(支持pjax跳转)
                parent_div_git.insertAdjacentHTML("afterbegin",git_div_html) // 有报错，但不影响使用(支持pjax跳转)
            };
            GithubCalendar(git_githubapiurl,git_color,git_user)
        }
        if(document.getElementById('recent-posts')){
            GithubCalendarConfig()
        }
    </script>
    <style>#github_container{min-height:280px}@media screen and (max-width:650px) {#github_container{background-image:;min-height:0px}}</style>
    <style></style><script data-pjax>function electric_clock_injector_config(){
                var parent_div_git = document.getElementsByClassName('sticky_layout')[0];
                var item_html = '<div class="card-widget card-clock"><div class="card-glass"><div class="card-background"><div class="card-content"><div id="hexo_electric_clock"><img id="card-clock-loading" src="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-clock/clock/images/weather/loading.gif" style="height: 120px; width: 100%;" data-ll-status="loading" class="entered loading"></div></div></div></div></div>';
                console.log('已挂载electric_clock')
                // parent_div_git.innerHTML=item_html+parent_div_git.innerHTML // 无报错，但不影响使用(支持pjax跳转)
                parent_div_git.insertAdjacentHTML("afterbegin",item_html) // 有报错，但不影响使用(支持pjax跳转)
            }if( document.getElementsByClassName('sticky_layout')[0] && (location.pathname ==='all'|| 'all' ==='all')){

            electric_clock_injector_config()
        } </script><script src="https://pv.sohu.com/cityjson?ie=utf-8"></script><script data-pjax  src="https://cdn.jsdelivr.net/gh/Zfour/hexo-electric-clock@1.0.6/clock.js"></script><!-- hexo injector body_end end --><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"model":{"jsonPath":"/live2dw/assets/hijiki.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":false},"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body></html>