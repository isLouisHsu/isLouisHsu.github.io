<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Arxiv每日速递(2022-05-26) | LOUIS' BLOG</title><meta name="author" content="徐耀彬"><meta name="copyright" content="徐耀彬"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="本篇博文主要展示每日从Arxiv论文网站获取的最新论文列表，以计算机视觉、自然语言处理、机器学习、人工智能等大方向进行划分。 统计 今日共更新353篇论文，其中：  65篇计算机视觉（cs.CV） 109篇自然语言处理（cs.CL） 112篇机器学习（cs.LG） 65篇人工智能（cs.AI）  计算机视觉    1. 标题：Inception Transformer   编号：[1]   链接：">
<meta property="og:type" content="article">
<meta property="og:title" content="Arxiv每日速递(2022-05-26)">
<meta property="og:url" content="http://louishsu.xyz/2022/05/26/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html">
<meta property="og:site_name" content="LOUIS&#39; BLOG">
<meta property="og:description" content="本篇博文主要展示每日从Arxiv论文网站获取的最新论文列表，以计算机视觉、自然语言处理、机器学习、人工智能等大方向进行划分。 统计 今日共更新353篇论文，其中：  65篇计算机视觉（cs.CV） 109篇自然语言处理（cs.CL） 112篇机器学习（cs.LG） 65篇人工智能（cs.AI）  计算机视觉    1. 标题：Inception Transformer   编号：[1]   链接：">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png">
<meta property="article:published_time" content="2022-05-26T00:44:07.818Z">
<meta property="article:modified_time" content="2022-05-26T00:46:00.646Z">
<meta property="article:author" content="徐耀彬">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://louishsu.xyz/2022/05/26/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2022-05-26 08:46:00'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const fontSizeVal = saveToLocal.get('global-font-size')
    if (fontSizeVal !== undefined) {
      document.documentElement.style.setProperty('--global-font-size', fontSizeVal + 'px')
    }
    })(window)</script><link rel="stylesheet" href="/css/background.css"><script src="https://cdn.jsdelivr.net/npm/echarts@4.7.0/dist/echarts.min.js"></script><!-- hexo injector head_end start --><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Zfour/hexo-electric-clock@1.0.6/clock.css"><!-- hexo injector head_end end --><meta name="generator" content="Hexo 5.4.2"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="author-avatar"><img class="avatar-img" src="/img/touxiang.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">11</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">标签</div><div class="length-num">3</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">分类</div><div class="length-num">7</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/message/"><i class="fa-fw far fa-comment-dots"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa-fw fa fa-book"></i><span> 找文章</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></li><li><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></li><li><a class="site-page" href="/charts/"><i class="fa-fw fa fa-archive"></i><span> 统计</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-tools"></i><span> 工具</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/md_editor/"><i class="fa-fw fas fa-pen"></i><span> 在线markdown</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/isLouisHsu/blog/tree/master/source/_posts"><i class="fa-fw fa fa-star"></i><span> 在线push</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">LOUIS' BLOG</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/message/"><i class="fa-fw far fa-comment-dots"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa-fw fa fa-book"></i><span> 找文章</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></li><li><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></li><li><a class="site-page" href="/charts/"><i class="fa-fw fa fa-archive"></i><span> 统计</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-tools"></i><span> 工具</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/md_editor/"><i class="fa-fw fas fa-pen"></i><span> 在线markdown</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/isLouisHsu/blog/tree/master/source/_posts"><i class="fa-fw fa fa-star"></i><span> 在线push</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Arxiv每日速递(2022-05-26)<a class="post-edit-link" href="https://github.com/isLouisHsu/blog/tree/master/source_posts/Arxiv每日速递.md" title="编辑" target="_blank"><i class="fas fa-pencil-square"></i></a></h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-05-26T00:44:07.818Z" title="发表于 2022-05-26 08:44:07">2022-05-26</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2022-05-26T00:46:00.646Z" title="更新于 2022-05-26 08:46:00">2022-05-26</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">阅读笔记</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">38.1k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>227分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span><span class="post-meta-separator">|</span><span class="post-meta-commentcount"><i class="far fa-comments fa-fw post-meta-icon"></i><span class="post-meta-label">评论数:</span><a href="/2022/05/26/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html#post-comment"><span id="twikoo-count"></span></a></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><p>本篇博文主要展示每日从Arxiv论文网站获取的最新论文列表，以计算机视觉、自然语言处理、机器学习、人工智能等大方向进行划分。</p>
<h1>统计</h1>
<p>今日共更新353篇论文，其中：</p>
<ul>
<li>65篇计算机视觉（<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>）</li>
<li>109篇自然语言处理（<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>）</li>
<li>112篇机器学习（cs.LG）</li>
<li>65篇人工智能（<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>）</li>
</ul>
<h1>计算机视觉</h1>
<details>
  <summary>1. <b>标题：Inception Transformer</b></summary>
  <p><b>编号</b>：[1]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12956</p>
  <p><b>作者</b>：Chenyang Si,  Weihao Yu,  Pan Zhou,  Yichen Zhou,  Xinchao Wang,  Shuicheng Yan</p>
  <p><b>备注</b>：Code and models will be released at this https URL</p>
  <p><b>关键词</b>：building long-range dependencies, predominantly convey local, convey local information, Recent studies show, general-purpose Inception Transformer</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent studies show that Transformer has strong capability of building
long-range dependencies, yet is incompetent in capturing high frequencies that
predominantly convey local information. To tackle this issue, we present a
novel and general-purpose Inception Transformer, or iFormer for short, that
effectively learns comprehensive features with both high- and low-frequency
information in visual data. Specifically, we design an Inception mixer to
explicitly graft the advantages of convolution and max-pooling for capturing
the high-frequency information to Transformers. Different from recent hybrid
frameworks, the Inception mixer brings greater efficiency through a channel
splitting mechanism to adopt parallel convolution/max-pooling path and
self-attention path as high- and low-frequency mixers, while having the
flexibility to model discriminative information scattered within a wide
frequency range. Considering that bottom layers play more roles in capturing
high-frequency details while top layers more in modeling low-frequency global
information, we further introduce a frequency ramp structure, i.e. gradually
decreasing the dimensions fed to the high-frequency mixer and increasing those
to the low-frequency mixer, which can effectively trade-off high- and
low-frequency components across different layers. We benchmark the iFormer on a
series of vision tasks, and showcase that it achieves impressive performance on
image classification, COCO detection and ADE20K segmentation. For example, our
iFormer-S hits the top-1 accuracy of 83.4% on ImageNet-1K, much higher than
DeiT-S by 3.6%, and even slightly better than much bigger model Swin-B (83.3%)
with only 1/4 parameters and 1/3 FLOPs. Code and models will be released at
this https URL.</p>
  </details>
</details>
<details>
  <summary>2. <b>标题：Neural 3D Reconstruction in the Wild</b></summary>
  <p><b>编号</b>：[2]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12955</p>
  <p><b>作者</b>：Jiaming Sun,  Xi Chen,  Qianqian Wang,  Zhengqi Li,  Hadar Averbuch-Elor,  Xiaowei Zhou,  Noah Snavely</p>
  <p><b>备注</b>：Accepted to SIGGRAPH 2022 (Conference Proceedings). Project page: this https URL</p>
  <p><b>关键词</b>：neural implicit representations, vision and graphics, witnessing an explosion, implicit representations, representations in computer</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We are witnessing an explosion of neural implicit representations in computer
vision and graphics. Their applicability has recently expanded beyond tasks
such as shape generation and image-based rendering to the fundamental problem
of image-based 3D reconstruction. However, existing methods typically assume
constrained 3D environments with constant illumination captured by a small set
of roughly uniformly distributed cameras. We introduce a new method that
enables efficient and accurate surface reconstruction from Internet photo
collections in the presence of varying illumination. To achieve this, we
propose a hybrid voxel- and surface-guided sampling technique that allows for
more efficient ray sampling around surfaces and leads to significant
improvements in reconstruction quality. Further, we present a new benchmark and
protocol for evaluating reconstruction performance on such in-the-wild scenes.
We perform extensive experiments, demonstrating that our approach surpasses
both classical and neural reconstruction methods on a wide variety of metrics.</p>
  </details>
</details>
<details>
  <summary>3. <b>标题：Pretraining is All You Need for Image-to-Image Translation</b></summary>
  <p><b>编号</b>：[3]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12952</p>
  <p><b>作者</b>：Tengfei Wang,  Ting Zhang,  Bo Zhang,  Hao Ouyang,  Dong Chen,  Qifeng Chen,  Fang Wen</p>
  <p><b>备注</b>：Project Page: this https URL</p>
  <p><b>关键词</b>：boost general, pretraining to boost, translation, diffusion model, general</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose to use pretraining to boost general image-to-image translation.
Prior image-to-image translation methods usually need dedicated architectural
design and train individual translation models from scratch, struggling for
high-quality generation of complex scenes, especially when paired training data
are not abundant. In this paper, we regard each image-to-image translation
problem as a downstream task and introduce a simple and generic framework that
adapts a pretrained diffusion model to accommodate various kinds of
image-to-image translation. We also propose adversarial training to enhance the
texture synthesis in the diffusion model training, in conjunction with
normalized guidance sampling to improve the generation quality. We present
extensive empirical comparison across various tasks on challenging benchmarks
such as ADE20K, COCO-Stuff, and DIODE, showing the proposed pretraining-based
image-to-image translation (PITI) is capable of synthesizing images of
unprecedented realism and faithfulness.</p>
  </details>
</details>
<details>
  <summary>4. <b>标题：Domain Adaptation for Object Detection using SE Adaptors and Center Loss</b></summary>
  <p><b>编号</b>：[9]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12923</p>
  <p><b>作者</b>：Sushruth Nagesh,  Shreyas Rajesh,  Asfiya Baig,  Savitha Srinivasan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：extremely practical problem, object detection, automative applications, growing interest, interest in object</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Despite growing interest in object detection, very few works address the
extremely practical problem of cross-domain robustness especially for
automative applications. In order to prevent drops in performance due to domain
shift, we introduce an unsupervised domain adaptation method built on the
foundation of faster-RCNN with two domain adaptation components addressing the
shift at the instance and image levels respectively and apply a consistency
regularization between them. We also introduce a family of adaptation layers
that leverage the squeeze excitation mechanism called SE Adaptors to improve
domain attention and thus improves performance without any prior requirement of
knowledge of the new target domain. Finally, we incorporate a center loss in
the instance and image level representations to improve the intra-class
variance. We report all results with Cityscapes as our source domain and Foggy
Cityscapes as the target domain outperforming previous baselines.</p>
  </details>
</details>
<details>
  <summary>5. <b>标题：DH-GAN: A Physics-driven Untrained Generative Adversarial Network for 3D  Microscopic Imaging using Digital Holography</b></summary>
  <p><b>编号</b>：[10]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12920</p>
  <p><b>作者</b>：Xiwen Chen,  Hao Wang,  Abofazl Razi,  Michael Kozicki,  Christopher Mann</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Digital holography, imaging technique, diffracted waveform, technique by emitting, emitting a laser</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Digital holography is a 3D imaging technique by emitting a laser beam with a
plane wavefront to an object and measuring the intensity of the diffracted
waveform, called holograms. The object's 3D shape can be obtained by numerical
analysis of the captured holograms and recovering the incurred phase. Recently,
deep learning (DL) methods have been used for more accurate holographic
processing. However, most supervised methods require large datasets to train
the model, which is rarely available in most DH applications due to the
scarcity of samples or privacy concerns. A few one-shot DL-based recovery
methods exist with no reliance on large datasets of paired images. Still, most
of these methods often neglect the underlying physics law that governs wave
propagation. These methods offer a black-box operation, which is not
explainable, generalizable, and transferrable to other samples and
applications. In this work, we propose a new DL architecture based on
generative adversarial networks that uses a discriminative network for
realizing a semantic measure for reconstruction quality while using a
generative network as a function approximator to model the inverse of hologram
formation. We impose smoothness on the background part of the recovered image
using a progressive masking module powered by simulated annealing to enhance
the reconstruction quality. The proposed method is one of its kind that
exhibits high transferability to similar samples, which facilitates its fast
deployment in time-sensitive applications without the need for retraining the
network. The results show a considerable improvement to competitor methods in
reconstruction quality (about 5 dB PSNR gain) and robustness to noise (about
50% reduction in PSNR vs noise increase rate).</p>
  </details>
</details>
<details>
  <summary>6. <b>标题：A Low Memory Footprint Quantized Neural Network for Depth Completion of  Very Sparse Time-of-Flight Depth Maps</b></summary>
  <p><b>编号</b>：[11]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12918</p>
  <p><b>作者</b>：Xiaowen Jiang,  Valerio Cambareri,  Gianluca Agresti,  Cynthia Ifeyinwa Ugwu,  Adriano Simonetto,  Fabien Cardinaux,  Pietro Zanuttigh</p>
  <p><b>备注</b>：In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops 2022. Presented at the 5th Efficient Deep Learning for Computer Vision Workshop</p>
  <p><b>关键词</b>：illumination enables precise, Sparse active illumination, active illumination enables, low power budgets, Sparse active</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Sparse active illumination enables precise time-of-flight depth sensing as it
maximizes signal-to-noise ratio for low power budgets. However, depth
completion is required to produce dense depth maps for 3D perception. We
address this task with realistic illumination and sensor resolution constraints
by simulating ToF datasets for indoor 3D perception with challenging sparsity
levels. We propose a quantized convolutional encoder-decoder network for this
task. Our model achieves optimal depth map quality by means of input
pre-processing and carefully tuned training with a geometry-preserving loss
function. We also achieve low memory footprint for weights and activations by
means of mixed precision quantization-at-training techniques. The resulting
quantized models are comparable to the state of the art in terms of quality,
but they require very low GPU times and achieve up to 14-fold memory size
reduction for the weights w.r.t. their floating point counterpart with minimal
impact on quality metrics.</p>
  </details>
</details>
<details>
  <summary>7. <b>标题：Context-Aware Video Reconstruction for Rolling Shutter Cameras</b></summary>
  <p><b>编号</b>：[13]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12912</p>
  <p><b>作者</b>：Bin Fan,  Yuchao Dai,  Zhiyuan Zhang,  Qi Liu,  Mingyi He</p>
  <p><b>备注</b>：Accepted to IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR 2022)</p>
  <p><b>关键词</b>：latent global shutter, rolling shutter, global shutter, demand on realism, ubiquity of rolling</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>With the ubiquity of rolling shutter (RS) cameras, it is becoming
increasingly attractive to recover the latent global shutter (GS) video from
two consecutive RS frames, which also places a higher demand on realism.
Existing solutions, using deep neural networks or optimization, achieve
promising performance. However, these methods generate intermediate GS frames
through image warping based on the RS model, which inevitably result in black
holes and noticeable motion artifacts. In this paper, we alleviate these issues
by proposing a context-aware GS video reconstruction architecture. It
facilitates the advantages such as occlusion reasoning, motion compensation,
and temporal abstraction. Specifically, we first estimate the bilateral motion
field so that the pixels of the two RS frames are warped to a common GS frame
accordingly. Then, a refinement scheme is proposed to guide the GS frame
synthesis along with bilateral occlusion masks to produce high-fidelity GS
video frames at arbitrary times. Furthermore, we derive an approximated
bilateral motion field model, which can serve as an alternative to provide a
simple but effective GS frame initialization for related tasks. Experiments on
synthetic and real data show that our approach achieves superior performance
over state-of-the-art methods in terms of objective metrics and subjective
visual quality. Code is available at \url{this https URL}.</p>
  </details>
</details>
<details>
  <summary>8. <b>标题：You Need to Read Again: Multi-granularity Perception Network for Moment  Retrieval in Videos</b></summary>
  <p><b>编号</b>：[27]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12886</p>
  <p><b>作者</b>：Xin Sun,  Xuan Wang,  Jialin Gao,  Qiong Liu,  Xi Zhou</p>
  <p><b>备注</b>：in SIGIR 2022</p>
  <p><b>关键词</b>：relevant video moment, sentence description, aims to retrieve, relevant video, untrimmed video</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Moment retrieval in videos is a challenging task that aims to retrieve the
most relevant video moment in an untrimmed video given a sentence description.
Previous methods tend to perform self-modal learning and cross-modal
interaction in a coarse manner, which neglect fine-grained clues contained in
video content, query context, and their alignment. To this end, we propose a
novel Multi-Granularity Perception Network (MGPN) that perceives intra-modality
and inter-modality information at a multi-granularity level. Specifically, we
formulate moment retrieval as a multi-choice reading comprehension task and
integrate human reading strategies into our framework. A coarse-grained feature
encoder and a co-attention mechanism are utilized to obtain a preliminary
perception of intra-modality and inter-modality information. Then a
fine-grained feature encoder and a conditioned interaction module are
introduced to enhance the initial perception inspired by how humans address
reading comprehension problems. Moreover, to alleviate the huge computation
burden of some existing methods, we further design an efficient choice
comparison module and reduce the hidden size with imperceptible quality loss.
Extensive experiments on Charades-STA, TACoS, and ActivityNet Captions datasets
demonstrate that our solution outperforms existing state-of-the-art methods.</p>
  </details>
</details>
<details>
  <summary>9. <b>标题：Open-Domain Sign Language Translation Learned from Online Video</b></summary>
  <p><b>编号</b>：[31]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12870</p>
  <p><b>作者</b>：Bowen Shi,  Diane Brentari,  Greg Shakhnarovich,  Karen Livescu</p>
  <p><b>备注</b>：17 pages</p>
  <p><b>关键词</b>：controlled environment, limits the applicability, applicability to real-world, sign language translation, sign language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Existing work on sign language translation--that is, translation from sign
language videos into sentences in a written language--has focused mainly on (1)
data collected in a controlled environment or (2) data in a specific domain,
which limits the applicability to real-world settings. In this paper, we
introduce OpenASL, a large-scale ASL-English dataset collected from online
video sites (e.g., YouTube). OpenASL contains 288 hours of ASL videos in
various domains (news, VLOGs, etc.) from over 200 signers and is the largest
publicly available ASL translation dataset to date. To tackle the challenges of
sign language translation in realistic settings and without glosses, we propose
a set of techniques including sign search as a pretext task for pre-training
and fusion of mouthing and handshape features. The proposed techniques produce
consistent and large improvements in translation quality, over baseline models
based on prior work. Our data, code and model will be publicly available at
this https URL</p>
  </details>
</details>
<details>
  <summary>10. <b>标题：Image Colorization using U-Net with Skip Connections and Fusion Layer on  Landscape Images</b></summary>
  <p><b>编号</b>：[33]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12867</p>
  <p><b>作者</b>：Muhammad Hisyam Zayd,  Novanto Yudistira,  Randy Cahya Wihandika</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：automatically colorize grayscale, Fusion Layer features, colorize grayscale images, technique to automatically, automatically colorize</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present a novel technique to automatically colorize grayscale images that
combine the U-Net model and Fusion Layer features. This approach allows the
model to learn the colorization of images from pre-trained U-Net. Moreover, the
Fusion layer is applied to merge local information results dependent on small
image patches with global priors of an entire image on each class, forming
visually more compelling colorization results. Finally, we validate our
approach with a user study evaluation and compare it against state-of-the-art,
resulting in improvements.</p>
  </details>
</details>
<details>
  <summary>11. <b>标题：Deep Gradient Learning for Efficient Camouflaged Object Detection</b></summary>
  <p><b>编号</b>：[37]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12853</p>
  <p><b>作者</b>：Ge-Peng Ji,  Deng-Ping Fan,  Yu-Cheng Chou,  Dengxin Dai,  Alexander Liniger,  Luc Van Gool</p>
  <p><b>备注</b>：Technical Report</p>
  <p><b>关键词</b>：paper introduces DGNet, exploits object gradient, object gradient supervision, paper introduces, gradient supervision</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper introduces DGNet, a novel deep framework that exploits object
gradient supervision for camouflaged object detection (COD). It decouples the
task into two connected branches, i.e., a context and a texture encoder. The
essential connection is the gradient-induced transition, representing a soft
grouping between context and texture features. Benefiting from the simple but
efficient framework, DGNet outperforms existing state-of-the-art COD models by
a large margin. Notably, our efficient version, DGNet-S, runs in real-time (80
fps) and achieves comparable results to the cutting-edge model
JCSOD-CVPR$_{21}$ with only 6.82% parameters. Application results also show
that the proposed DGNet performs well in polyp segmentation, defect detection,
and transparent object segmentation tasks. Codes will be made available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>12. <b>标题：DistillAdapt: Source-Free Active Visual Domain Adaptation</b></summary>
  <p><b>编号</b>：[39]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12840</p>
  <p><b>作者</b>：Divya Kothandaraman,  Sumit Shekhar,  Abhilasha Sancheti,  Manoj Ghuhan,  Tripti Shukla,  Dinesh Manocha</p>
  <p><b>备注</b>：22 pages</p>
  <p><b>关键词</b>：Guided Attention Transfer, Active Domain Adaptation, network, DistillAdapt, target domain</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present a novel method, DistillAdapt, for the challenging problem of
Source-Free Active Domain Adaptation (SF-ADA). The problem requires adapting a
pretrained source domain network to a target domain, within a provided budget
for acquiring labels in the target domain, while assuming that the source data
is not available for adaptation due to privacy concerns or otherwise.
DistillAdapt is one of the first approaches for SF-ADA, and holistically
addresses the challenges of SF-ADA via a novel Guided Attention Transfer
Network (GATN) and an active learning heuristic, H_AL. The GATN enables
selective distillation of features from the pre-trained network to the target
network using a small subset of annotated target samples mined by H_AL. H_AL
acquires samples at batch-level and balances transfer-ability from the
pre-trained network and uncertainty of the target network. DistillAdapt is
task-agnostic, and can be applied across visual tasks such as classification,
segmentation and detection. Moreover, DistillAdapt can handle shifts in output
label space. We conduct experiments and extensive ablation studies across 3
visual tasks, viz. digits classification (MNIST, SVHN), synthetic (GTA5) to
real (CityScapes) image segmentation, and document layout detection (PubLayNet
to DSSE). We show that our source-free approach, DistillAdapt, results in an
improvement of 0.5% - 31.3% (across datasets and tasks) over prior adaptation
methods that assume access to large amounts of annotated source data for
adaptation.</p>
  </details>
</details>
<details>
  <summary>13. <b>标题：Non-rigid Point Cloud Registration with Neural Deformation Pyramid</b></summary>
  <p><b>编号</b>：[51]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12796</p>
  <p><b>作者</b>：Yang Li,  Tatsuya Harada</p>
  <p><b>备注</b>：Code: this https URL</p>
  <p><b>关键词</b>：computer graphics applications, computer vision, computer graphics, graphics applications, key component</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Non-rigid point cloud registration is a key component in many computer vision
and computer graphics applications. The high complexity of the unknown
non-rigid motion make this task a challenging problem. In this paper, we break
down this problem via hierarchical motion decomposition. Our method called
Neural Deformation Pyramid (NDP) represents non-rigid motion using a pyramid
architecture. Each pyramid level, denoted by a Multi-Layer Perception (MLP),
takes as input a sinusoidally encoded 3D point and outputs its motion
increments from the previous level. The sinusoidal function starts with a low
input frequency and gradually increases when the pyramid level goes down. This
allows a multi-level rigid to nonrigid motion decomposition and also speeds up
the solving by 50 times compared to the existing MLP-based approach. Our method
achieves advanced partialto-partial non-rigid point cloud registration results
on the 4DMatch/4DLoMatch benchmark under both no-learned and supervised
settings.</p>
  </details>
</details>
<details>
  <summary>14. <b>标题：AO2-DETR: Arbitrary-Oriented Object Detection Transformer</b></summary>
  <p><b>编号</b>：[53]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12785</p>
  <p><b>作者</b>：Linhui Dai,  Hong Liu,  Hao Tang,  Zhiwei Wu,  Pinhao Song</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Arbitrary-oriented object detection, cluttered arrangements, wild with arbitrary, arbitrary orientations, orientations and cluttered</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Arbitrary-oriented object detection (AOOD) is a challenging task to detect
objects in the wild with arbitrary orientations and cluttered arrangements.
Existing approaches are mainly based on anchor-based boxes or dense points,
which rely on complicated hand-designed processing steps and inductive bias,
such as anchor generation, transformation, and non-maximum suppression
reasoning. Recently, the emerging transformer-based approaches view object
detection as a direct set prediction problem that effectively removes the need
for hand-designed components and inductive biases. In this paper, we propose an
Arbitrary-Oriented Object DEtection TRansformer framework, termed AO2-DETR,
which comprises three dedicated components. More precisely, an oriented
proposal generation mechanism is proposed to explicitly generate oriented
proposals, which provides better positional priors for pooling features to
modulate the cross-attention in the transformer decoder. An adaptive oriented
proposal refinement module is introduced to extract rotation-invariant region
features and eliminate the misalignment between region features and objects.
And a rotation-aware set matching loss is used to ensure the one-to-one
matching process for direct set prediction without duplicate predictions. Our
method considerably simplifies the overall pipeline and presents a new AOOD
paradigm. Comprehensive experiments on several challenging datasets show that
our method achieves superior performance on the AOOD task.</p>
  </details>
</details>
<details>
  <summary>15. <b>标题：An Evolutionary Approach to Dynamic Introduction of Tasks in Large-scale  Multitask Learning Systems</b></summary>
  <p><b>编号</b>：[66]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12755</p>
  <p><b>作者</b>：Andrea Gesmundo,  Jeff Dean</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Multitask learning assumes, quality and efficiency, key feature, feature of human, learning assumes</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Multitask learning assumes that models capable of learning from multiple
tasks can achieve better quality and efficiency via knowledge transfer, a key
feature of human learning. Though, state of the art ML models rely on high
customization for each task and leverage size and data scale rather than
scaling the number of tasks. Also, continual learning, that adds the temporal
aspect to multitask, is often focused to the study of common pitfalls such as
catastrophic forgetting instead of being studied at a large scale as a critical
component to build the next generation artificial intelligence. We propose an
evolutionary method that can generate a large scale multitask model, and can
support the dynamic and continuous addition of new tasks. The generated
multitask model is sparsely activated and integrates a task-based routing that
guarantees bounded compute cost and fewer added parameters per task as the
model expands. The proposed method relies on a knowledge compartmentalization
technique to achieve immunity against catastrophic forgetting and other common
pitfalls such as gradient interference and negative transfer. We empirically
show that the proposed method can jointly solve and achieve competitive results
on 69image classification tasks, for example achieving the best test accuracy
reported fora model trained only on public data for competitive tasks such as
cifar10: 99.43%.</p>
  </details>
</details>
<details>
  <summary>16. <b>标题：An Empirical Study on Distribution Shift Robustness From the Perspective  of Pre-Training and Data Augmentation</b></summary>
  <p><b>编号</b>：[67]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12753</p>
  <p><b>作者</b>：Ziquan Liu,  Yi Xu,  Yuanhong Xu,  Qi Qian,  Hao Li,  Rong Jin,  Xiangyang Ji,  Antoni B. Chan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：distribution shift, data augmentation, distribution, recent years, data</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The performance of machine learning models under distribution shift has been
the focus of the community in recent years. Most of current methods have been
proposed to improve the robustness to distribution shift from the algorithmic
perspective, i.e., designing better training algorithms to help the
generalization in shifted test distributions. This paper studies the
distribution shift problem from the perspective of pre-training and data
augmentation, two important factors in the practice of deep learning that have
not been systematically investigated by existing work. By evaluating seven
pre-trained models, including ResNets and ViT's with self-supervision and
supervision mode, on five important distribution-shift datasets, from WILDS and
DomainBed benchmarks, with five different learning algorithms, we provide the
first comprehensive empirical study focusing on pre-training and data
augmentation. With our empirical result obtained from 1,330 models, we provide
the following main observations: 1) ERM combined with data augmentation can
achieve state-of-the-art performance if we choose a proper pre-trained model
respecting the data property; 2) specialized algorithms further improve the
robustness on top of ERM when handling a specific type of distribution shift,
e.g., GroupDRO for spurious correlation and CORAL for large-scale
out-of-distribution data; 3) Comparing different pre-training modes,
architectures and data sizes, we provide novel observations about pre-training
on distribution shift, which sheds light on designing or selecting pre-training
strategy for different kinds of distribution shifts. In summary, our empirical
study provides a comprehensive baseline for a wide range of pre-training models
fine-tuned with data augmentation, which potentially inspires research
exploiting the power of pre-training and data augmentation in the future of
distribution shift study.</p>
  </details>
</details>
<details>
  <summary>17. <b>标题：SIoU Loss: More Powerful Learning for Bounding Box Regression</b></summary>
  <p><b>编号</b>：[72]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12740</p>
  <p><b>作者</b>：Zhora Gevorgyan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：computer vision tasks, object detection loss, Conventional object detection, detection loss functions, Object Detection</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The effectiveness of Object Detection, one of the central problems in
computer vision tasks, highly depends on the definition of the loss function -
a measure of how accurately your ML model can predict the expected outcome.
Conventional object detection loss functions depend on aggregation of metrics
of bounding box regression such as the distance, overlap area and aspect ratio
of the predicted and ground truth boxes (i.e. GIoU, CIoU, ICIoU etc). However,
none of the methods proposed and used to date considers the direction of the
mismatch between the desired ground box and the predicted, "experimental" box.
This shortage results in slower and less effective convergence as the predicted
box can "wander around" during the training process and eventually end up
producing a worse model. In this paper a new loss function SIoU was suggested,
where penalty metrics were redefined considering the angle of the vector
between the desired regression. Applied to conventional Neural Networks and
datasets it is shown that SIoU improves both the speed of training and the
accuracy of the inference. The effectiveness of the proposed loss function was
revealed in a number of simulations and tests.</p>
  </details>
</details>
<details>
  <summary>18. <b>标题：Contrastive Learning with Boosted Memorization</b></summary>
  <p><b>编号</b>：[94]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12693</p>
  <p><b>作者</b>：Zhihan Zhou,  Jiangchao Yao,  Yanfeng Wang,  Bo Han,  Ya Zhang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：self-supervised long-tailed learning, long-tailed learning, achieved a great, great success, visual and textual</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Self-supervised learning has achieved a great success in the representation
learning of visual and textual data. However, the current methods are mainly
validated on the well-curated datasets, which do not exhibit the real-world
long-tailed distribution. Recent attempts to consider self-supervised
long-tailed learning are made by rebalancing in the loss perspective or the
model perspective, resembling the paradigms in the supervised long-tailed
learning. Nevertheless, without the aid of labels, these explorations have not
shown the expected significant promise due to the limitation in tail sample
discovery or the heuristic structure design. Different from previous works, we
explore this direction from an alternative perspective, i.e., the data
perspective, and propose a novel Boosted Contrastive Learning (BCL) method.
Specifically, BCL leverages the memorization effect of deep neural networks to
automatically drive the information discrepancy of the sample views in
contrastive learning, which is more efficient to enhance the long-tailed
learning in the label-unaware context. Extensive experiments on a range of
benchmark datasets demonstrate the effectiveness of BCL over several
state-of-the-art methods. Our code is available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>19. <b>标题：UniInst: Unique Representation for End-to-End Instance Segmentation</b></summary>
  <p><b>编号</b>：[119]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12646</p>
  <p><b>作者</b>：Yimin Ou,  Rui Yang,  Lufan Ma,  Yong Liu,  Jiangpeng Yan,  Shang Xu,  Chengjie Wang,  Xiu Li</p>
  <p><b>备注</b>：This work is in the revision phase of the journal Neurocomputing. Codes will be available upon publication</p>
  <p><b>关键词</b>：multiple duplicated predictions, Existing instance segmentation, achieved impressive performance, multiple boxes, multiple duplicated</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Existing instance segmentation methods have achieved impressive performance
but still suffer from a common dilemma: redundant representations (e.g.,
multiple boxes, grids, and anchor points) are inferred for one instance, which
leads to multiple duplicated predictions. Thus, mainstream methods usually rely
on a hand-designed non-maximum suppression (NMS) post-processing to select the
optimal prediction result, which hinders end-to-end training. To address this
issue, we propose a box-free and NMS-free end-to-end instance segmentation
framework, termed UniInst, that yields only one unique representation for each
instance. Specifically, we design an instance-aware one-to-one assignment
scheme, namely Only Yield One Representation (OYOR), which dynamically assigns
one unique representation to one instance according to the matching quality
between predictions and ground truths. Then, a novel prediction re-ranking
strategy is elegantly integrated into the framework to address the misalignment
between the classification score and the mask quality, enabling the learned
representation to be more discriminative. With these techniques, our UniInst,
the first FCN-based end-to-end instance segmentation framework, achieves
competitive performance, e.g., 39.0 mask AP with ResNet-50-FPN and 40.2 mask AP
with ResNet-101-FPN, against mainstream methods on the COCO benchmark.
Moreover, the proposed instance-aware method is robust to occlusion scenes,
outperforming common baselines by remarkable mask AP on the heavily-occluded
OCHuman benchmark. Our codes will be available upon publication.</p>
  </details>
</details>
<details>
  <summary>20. <b>标题：TreEnhance: An Automatic Tree-Search Based Method for Low-Light Image  Enhancement</b></summary>
  <p><b>编号</b>：[123]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12639</p>
  <p><b>作者</b>：Marco Cotogni,  Claudio Cusano</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Monte Carlo Tree, Carlo Tree Search, tree search theory, combines tree search, tree search</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper we present TreEnhance, an automatic method for low-light image
enhancement capable of improving the quality of digital images. The method
combines tree search theory, and in particular the Monte Carlo Tree Search
(MCTS) algorithm, with deep reinforcement learning. Given as input a low-light
image, TreEnhance produces as output its enhanced version together with the
sequence of image editing operations used to obtain it. The method repeatedly
alternates two main phases. In the generation phase a modified version of MCTS
explores the space of image editing operations and selects the most promising
sequence. In the optimization phase the parameters of a neural network,
implementing the enhancement policy, are updated. After training, two different
inference solutions are proposed for the enhancement of new images: one is
based on MCTS and is more accurate but more time and memory consuming; the
other directly applies the learned policy and is faster but slightly less
precise. Unlike other methods from the state of the art, TreEnhance does not
pose any constraint on the image resolution and can be used in a variety of
scenarios with minimal tuning. We tested the method on two datasets: the
Low-Light dataset and the Adobe Five-K dataset obtaining good results from both
a qualitative and a quantitative point of view.</p>
  </details>
</details>
<details>
  <summary>21. <b>标题：MoCoViT: Mobile Convolutional Vision Transformer</b></summary>
  <p><b>编号</b>：[125]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12635</p>
  <p><b>作者</b>：Hailong Ma,  Xin Xia,  Xing Wang,  Xuefeng Xiao,  Jiashi Li,  Min Zheng</p>
  <p><b>备注</b>：arXiv admin note: text overlap with arXiv:2108.05895, arXiv:1911.11907 by other authors</p>
  <p><b>关键词</b>：achieved impressive results, mobile, achieved impressive, impressive results, Transformer</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recently, Transformer networks have achieved impressive results on a variety
of vision tasks. However, most of them are computationally expensive and not
suitable for real-world mobile applications. In this work, we present Mobile
Convolutional Vision Transformer (MoCoViT), which improves in performance and
efficiency by introducing transformer into mobile convolutional networks to
leverage the benefits of both architectures. Different from recent works on
vision transformer, the mobile transformer block in MoCoViT is carefully
designed for mobile devices and is very lightweight, accomplished through two
primary modifications: the Mobile Self-Attention (MoSA) module and the Mobile
Feed Forward Network (MoFFN). MoSA simplifies the calculation of the attention
map through Branch Sharing scheme while MoFFN serves as a mobile version of MLP
in the transformer, further reducing the computation by a large margin.
Comprehensive experiments verify that our proposed MoCoViT family outperform
state-of-the-art portable CNNs and transformer neural architectures on various
vision tasks. On ImageNet classification, it achieves 74.5% top-1 accuracy at
147M FLOPs, gaining 1.2% over MobileNetV3 with less computations. And on the
COCO object detection task, MoCoViT outperforms GhostNet by 2.1 AP in RetinaNet
framework.</p>
  </details>
</details>
<details>
  <summary>22. <b>标题：Real-Time Video Deblurring via Lightweight Motion Compensation</b></summary>
  <p><b>编号</b>：[126]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12634</p>
  <p><b>作者</b>：Hyeongseok Son,  Junyong Lee,  Sunghyun Cho,  Seungyong Lee</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：huge computational overhead, demands huge computational, separately performing motion, greatly improves video, compensation greatly improves</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>While motion compensation greatly improves video deblurring quality,
separately performing motion compensation and video deblurring demands huge
computational overhead. This paper proposes a real-time video deblurring
framework consisting of a lightweight multi-task unit that supports both video
deblurring and motion compensation in an efficient way. The multi-task unit is
specifically designed to handle large portions of the two tasks using a single
shared network, and consists of a multi-task detail network and simple networks
for deblurring and motion compensation. The multi-task unit minimizes the cost
of incorporating motion compensation into video deblurring and enables
real-time deblurring. Moreover, by stacking multiple multi-task units, our
framework provides flexible control between the cost and deblurring quality. We
experimentally validate the state-of-the-art deblurring quality of our
approach, which runs at a much faster speed compared to previous methods, and
show practical real-time performance (30.99dB@30fps measured in the DVD
dataset).</p>
  </details>
</details>
<details>
  <summary>23. <b>标题：NTIRE 2022 Challenge on High Dynamic Range Imaging: Methods and Results</b></summary>
  <p><b>编号</b>：[127]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12633</p>
  <p><b>作者</b>：Eduardo Pérez-Pellitero,  Sibi Catley-Chandar,  Richard Shaw,  Aleš Leonardis,  Radu Timofte,  Zexin Zhang,  Cen Liu,  Yunbo Peng,  Yue Lin,  Gaocheng Yu,  Jin Zhang,  Zhe Ma,  Hongbin Wang,  Xiangyu Chen,  Xintao Wang,  Haiwei Wu,  Lin Liu,  Chao Dong,  Jiantao Zhou,  Qingsen Yan,  Song Zhang,  Weiye Chen,  Yuhang Liu,  Zhen Zhang,  Yanning Zhang,  Javen Qinfeng Shi,  Dong Gong,  Dan Zhu,  Mengdi Sun,  Guannan Chen,  Yang Hu,  Haowei Li,  Baozhu Zou,  Zhen Liu,  Wenjie Lin,  Ting Jiang,  Chengzhi Jiang,  Xinpeng Li,  Mingyan Han,  Haoqiang Fan,  Jian Sun,  Shuaicheng Liu,  Juan Marín-Vega,  Michael Sloth,  Peter Schneider-Kamp,  Richard Röttger,  Chunyang Li,  Long Bao,  Gang He,  Ziyao Xu,  Li Xu,  Gen Zhan,  Ming Sun,  Xing Wen,  Junlin Li,  Jinjing Li,  Chenghua Li,  Ruipeng Gang,  Fangya Li,  Chenming Liu,  Shuang Feng,  Fei Lei,  et al. (31 additional authors not shown)</p>
  <p><b>备注</b>：CVPR Workshops 2022. 15 pages, 21 figures, 2 tables</p>
  <p><b>关键词</b>：Restoration and Enhancement, conjunction with CVPR, constrained high dynamic, high dynamic range, Image Restoration</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper reviews the challenge on constrained high dynamic range (HDR)
imaging that was part of the New Trends in Image Restoration and Enhancement
(NTIRE) workshop, held in conjunction with CVPR 2022. This manuscript focuses
on the competition set-up, datasets, the proposed methods and their results.
The challenge aims at estimating an HDR image from multiple respective low
dynamic range (LDR) observations, which might suffer from under- or
over-exposed regions and different sources of noise. The challenge is composed
of two tracks with an emphasis on fidelity and complexity constraints: In Track
1, participants are asked to optimize objective fidelity scores while imposing
a low-complexity constraint (i.e. solutions can not exceed a given number of
operations). In Track 2, participants are asked to minimize the complexity of
their solutions while imposing a constraint on fidelity scores (i.e. solutions
are required to obtain a higher fidelity score than the prescribed baseline).
Both tracks use the same data and metrics: Fidelity is measured by means of
PSNR with respect to a ground-truth HDR image (computed both directly and with
a canonical tonemapping operation), while complexity metrics include the number
of Multiply-Accumulate (MAC) operations and runtime (in seconds).</p>
  </details>
</details>
<details>
  <summary>24. <b>标题：Multimodal Knowledge Alignment with Reinforcement Learning</b></summary>
  <p><b>编号</b>：[128]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12630</p>
  <p><b>作者</b>：Youngjae Yu,  Jiwan Chung,  Heeseung Yun,  Jack Hessel,  JaeSung Park,  Ximing Lu,  Prithviraj Ammanabrolu,  Rowan Zellers,  Ronan Le Bras,  Gunhee Kim,  Yejin Choi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：task-specific training data, models readily adapt, readily adapt, task-specific training, Large language models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large language models readily adapt to novel settings, even without
task-specific training data. Can their zero-shot capacity be extended to
multimodal inputs? In this work, we propose ESPER which extends language-only
zero-shot models to unseen multimodal tasks, like image and audio captioning.
Our key novelty is to use reinforcement learning to align multimodal inputs to
language model generations without direct supervision: for example, in the
image case our reward optimization relies only on cosine similarity derived
from CLIP, and thus requires no additional explicitly paired (image, caption)
data. Because the parameters of the language model are left unchanged, the
model maintains its capacity for zero-shot generalization. Experiments
demonstrate that ESPER outperforms baselines and prior work on a variety of
zero-shot tasks; these include a new benchmark we collect+release, ESP dataset,
which tasks models with generating several diversely-styled captions for each
image.</p>
  </details>
</details>
<details>
  <summary>25. <b>标题：Primitive3D: 3D Object Dataset Synthesis from Randomly Assembled  Primitives</b></summary>
  <p><b>编号</b>：[130]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12627</p>
  <p><b>作者</b>：Xinke Li,  Henghui Ding,  Zekun Tong,  Yuwei Wu,  Yeow Meng Chee</p>
  <p><b>备注</b>：CVPR 2022</p>
  <p><b>关键词</b>：Numerous advancements, access to large-scale, large-scale and well-annotated, dataset, well-annotated datasets</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Numerous advancements in deep learning can be attributed to the access to
large-scale and well-annotated datasets. However, such a dataset is
prohibitively expensive in 3D computer vision due to the substantial collection
cost. To alleviate this issue, we propose a cost-effective method for
automatically generating a large amount of 3D objects with annotations. In
particular, we synthesize objects simply by assembling multiple random
primitives. These objects are thus auto-annotated with part labels originating
from primitives. This allows us to perform multi-task learning by combining the
supervised segmentation with unsupervised reconstruction. Considering the large
overhead of learning on the generated dataset, we further propose a dataset
distillation strategy to remove redundant samples regarding a target dataset.
We conduct extensive experiments for the downstream tasks of 3D object
classification. The results indicate that our dataset, together with multi-task
pretraining on its annotations, achieves the best performance compared to other
commonly used datasets. Further study suggests that our strategy can improve
the model performance by pretraining and fine-tuning scheme, especially for the
dataset with a small scale. In addition, pretraining with the proposed dataset
distillation method can save 86\% of the pretraining time with negligible
performance degradation. We expect that our attempt provides a new data-centric
perspective for training 3D deep models.</p>
  </details>
</details>
<details>
  <summary>26. <b>标题：Location-free Human Pose Estimation</b></summary>
  <p><b>编号</b>：[133]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12619</p>
  <p><b>作者</b>：Xixia Xu,  Yingguo Gao,  Ke Yan,  Xue Lin,  Qi Zou</p>
  <p><b>备注</b>：Beijing Jiaotong University, Tencent Toutu Lab</p>
  <p><b>关键词</b>：requires large-scale training, large-scale training data, reach high performance, Human pose estimation, requires large-scale</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Human pose estimation (HPE) usually requires large-scale training data to
reach high performance. However, it is rather time-consuming to collect
high-quality and fine-grained annotations for human body. To alleviate this
issue, we revisit HPE and propose a location-free framework without supervision
of keypoint locations. We reformulate the regression-based HPE from the
perspective of classification. Inspired by the CAM-based weakly-supervised
object localization, we observe that the coarse keypoint locations can be
acquired through the part-aware CAMs but unsatisfactory due to the gap between
the fine-grained HPE and the object-level localization. To this end, we propose
a customized transformer framework to mine the fine-grained representation of
human context, equipped with the structural relation to capture subtle
differences among keypoints. Concretely, we design a Multi-scale Spatial-guided
Context Encoder to fully capture the global human context while focusing on the
part-aware regions and a Relation-encoded Pose Prototype Generation module to
encode the structural relations. All these works together for strengthening the
weak supervision from image-level category labels on locations. Our model
achieves competitive performance on three datasets when only supervised at a
category-level and importantly, it can achieve comparable results with
fully-supervised methods with only 25\% location labels on MS-COCO and MPII.</p>
  </details>
</details>
<details>
  <summary>27. <b>标题：DisinfoMeme: A Multimodal Dataset for Detecting Meme Intentionally  Spreading Out Disinformation</b></summary>
  <p><b>编号</b>：[135]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12617</p>
  <p><b>作者</b>：Jingnong Qu,  Liunian Harold Li,  Jieyu Zhao,  Sunipa Dev,  Kai-Wei Chang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：social media, problem on social, Black Lives Matter, Lives Matter movement, Disinformation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Disinformation has become a serious problem on social media. In particular,
given their short format, visual attraction, and humorous nature, memes have a
significant advantage in dissemination among online communities, making them an
effective vehicle for the spread of disinformation. We present DisinfoMeme to
help detect disinformation memes. The dataset contains memes mined from Reddit
covering three current topics: the COVID-19 pandemic, the Black Lives Matter
movement, and veganism/vegetarianism. The dataset poses multiple unique
challenges: limited data and label imbalance, reliance on external knowledge,
multimodal reasoning, layout dependency, and noise from OCR. We test multiple
widely-used unimodal and multimodal models on this dataset. The experiments
show that the room for improvement is still huge for current models.</p>
  </details>
</details>
<details>
  <summary>28. <b>标题：Guiding Visual Question Answering with Attention Priors</b></summary>
  <p><b>编号</b>：[136]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12616</p>
  <p><b>作者</b>：Thao Minh Le,  Vuong Le,  Sunil Gupta,  Svetha Venkatesh,  Truyen Tran</p>
  <p><b>备注</b>：Preprint, 10 pages</p>
  <p><b>关键词</b>：visual reasoning systems, modern visual reasoning, cross-modality attention mechanisms, attention, current success</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The current success of modern visual reasoning systems is arguably attributed
to cross-modality attention mechanisms. However, in deliberative reasoning such
as in VQA, attention is unconstrained at each step, and thus may serve as a
statistical pooling mechanism rather than a semantic operation intended to
select information relevant to inference. This is because at training time,
attention is only guided by a very sparse signal (i.e. the answer label) at the
end of the inference chain. This causes the cross-modality attention weights to
deviate from the desired visual-language bindings. To rectify this deviation,
we propose to guide the attention mechanism using explicit linguistic-visual
grounding. This grounding is derived by connecting structured linguistic
concepts in the query to their referents among the visual objects. Here we
learn the grounding from the pairing of questions and images alone, without the
need for answer annotation or external grounding supervision. This grounding
guides the attention mechanism inside VQA models through a duality of
mechanisms: pre-training attention weight calculation and directly guiding the
weights at inference time on a case-by-case basis. The resultant algorithm is
capable of probing attention-based reasoning models, injecting relevant
associative knowledge, and regulating the core reasoning process. This scalable
enhancement improves the performance of VQA models, fortifies their robustness
to limited access to supervised data, and increases interpretability.</p>
  </details>
</details>
<details>
  <summary>29. <b>标题：Deep Aesthetic Assessment and Retrieval of Breast Cancer Treatment  Outcomes</b></summary>
  <p><b>编号</b>：[138]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12611</p>
  <p><b>作者</b>：Wilson Silva,  Maria Carvalho,  Carlos Mavioso,  Maria J. Cardoso,  Jaime S. Cardoso</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：breast cancer treatments, breast cancer, cancer treatments, recent years, continued to evolve</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Treatments for breast cancer have continued to evolve and improve in recent
years, resulting in a substantial increase in survival rates, with
approximately 80\% of patients having a 10-year survival period. Given the
serious impact that breast cancer treatments can have on a patient's body
image, consequently affecting her self-confidence and sexual and intimate
relationships, it is paramount to ensure that women receive the treatment that
optimizes both survival and aesthetic outcomes. Currently, there is no gold
standard for evaluating the aesthetic outcome of breast cancer treatment. In
addition, there is no standard way to show patients the potential outcome of
surgery. The presentation of similar cases from the past would be extremely
important to manage women's expectations of the possible outcome. In this work,
we propose a deep neural network to perform the aesthetic evaluation. As a
proof-of-concept, we focus on a binary aesthetic evaluation. Besides its use
for classification, this deep neural network can also be used to find the most
similar past cases by searching for nearest neighbours in the highly semantic
space before classification. We performed the experiments on a dataset
consisting of 143 photos of women after conservative treatment for breast
cancer. The results for accuracy and balanced accuracy showed the superior
performance of our proposed model compared to the state of the art in aesthetic
evaluation of breast cancer treatments. In addition, the model showed a good
ability to retrieve similar previous cases, with the retrieved cases having the
same or adjacent class (in the 4-class setting) and having similar types of
asymmetry. Finally, a qualitative interpretability assessment was also
performed to analyse the robustness and trustworthiness of the model.</p>
  </details>
</details>
<details>
  <summary>30. <b>标题：ReSmooth: Detecting and Utilizing OOD Samples when Training with Data  Augmentation</b></summary>
  <p><b>编号</b>：[140]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12606</p>
  <p><b>作者</b>：Chenyang Wang,  Junjun Jiang,  Xiong Zhou,  Xianming Liu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：deep neural networks, OOD samples, samples, OOD, neural networks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Data augmentation (DA) is a widely used technique for enhancing the training
of deep neural networks. Recent DA techniques which achieve state-of-the-art
performance always meet the need for diversity in augmented training samples.
However, an augmentation strategy that has a high diversity usually introduces
out-of-distribution (OOD) augmented samples and these samples consequently
impair the performance. To alleviate this issue, we propose ReSmooth, a
framework that firstly detects OOD samples in augmented samples and then
leverages them. To be specific, we first use a Gaussian mixture model to fit
the loss distribution of both the original and augmented samples and
accordingly split these samples into in-distribution (ID) samples and OOD
samples. Then we start a new training where ID and OOD samples are incorporated
with different smooth labels. By treating ID samples and OOD samples unequally,
we can make better use of the diverse augmented data. Further, we incorporate
our ReSmooth framework with negative data augmentation strategies. By properly
handling their intentionally created ODD samples, the classification
performance of negative data augmentations is largely ameliorated. Experiments
on several classification benchmarks show that ReSmooth can be easily extended
to existing augmentation strategies (such as RandAugment, rotate, and jigsaw)
and improve on them.</p>
  </details>
</details>
<details>
  <summary>31. <b>标题：VTP: Volumetric Transformer for Multi-view Multi-person 3D Pose  Estimation</b></summary>
  <p><b>编号</b>：[142]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12602</p>
  <p><b>作者</b>：Yuxing Chen,  Renshu Gu,  Ouhan Huang,  Gangyong Jia</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：human pose estimation, Transformer Pose estimator, Volumetric Transformer Pose, paper presents Volumetric, Pose estimator</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper presents Volumetric Transformer Pose estimator (VTP), the first 3D
volumetric transformer framework for multi-view multi-person 3D human pose
estimation. VTP aggregates features from 2D keypoints in all camera views and
directly learns the spatial relationships in the 3D voxel space in an
end-to-end fashion. The aggregated 3D features are passed through 3D
convolutions before being flattened into sequential embeddings and fed into a
transformer. A residual structure is designed to further improve the
performance. In addition, the sparse Sinkhorn attention is empowered to reduce
the memory cost, which is a major bottleneck for volumetric representations,
while also achieving excellent performance. The output of the transformer is
again concatenated with 3D convolutional features by a residual design. The
proposed VTP framework integrates the high performance of the transformer with
volumetric representations, which can be used as a good alternative to the
convolutional backbones. Experiments on the Shelf, Campus and CMU Panoptic
benchmarks show promising results in terms of both Mean Per Joint Position
Error (MPJPE) and Percentage of Correctly estimated Parts (PCP). Our code will
be available.</p>
  </details>
</details>
<details>
  <summary>32. <b>标题：Deniable Steganography</b></summary>
  <p><b>编号</b>：[153]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12587</p>
  <p><b>作者</b>：Yong Xu,  Zhihua Xia,  Zichi Wang,  Xinpeng Zhang,  Jian Weng</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：secret message, message, drawing suspicion, transmitted on public, public channels</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Steganography conceals the secret message into the cover media, generating a
stego media which can be transmitted on public channels without drawing
suspicion. As its countermeasure, steganalysis mainly aims to detect whether
the secret message is hidden in a given media. Although the steganography
techniques are improving constantly, the sophisticated steganalysis can always
break a known steganographic method to some extent. With a stego media
discovered, the adversary could find out the sender or receiver and coerce them
to disclose the secret message, which we name as coercive attack in this paper.
Inspired by the idea of deniable encryption, we build up the concepts of
deniable steganography for the first time and discuss the feasible
constructions for it. As an example, we propose a receiver-deniable
steganographic scheme to deal with the receiver-side coercive attack using deep
neural networks (DNN). Specifically, besides the real secret message, a piece
of fake message is also embedded into the cover. On the receiver side, the real
message can be extracted with an extraction module; while once the receiver has
to surrender a piece of secret message under coercive attack, he can extract
the fake message to deceive the adversary with another extraction module.
Experiments demonstrate the scalability and sensitivity of the DNN-based
receiver-deniable steganographic scheme.</p>
  </details>
</details>
<details>
  <summary>33. <b>标题：MUG: Multi-human Graph Network for 3D Mesh Reconstruction from 2D Pose</b></summary>
  <p><b>编号</b>：[156]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12583</p>
  <p><b>作者</b>：Chenyan Wu,  Yandong Li,  Xianfeng Tang,  James Wang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：computer vision problem, challenging computer vision, vision problem, single monocular image, important but challenging</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Reconstructing multi-human body mesh from a single monocular image is an
important but challenging computer vision problem. In addition to the
individual body mesh models, we need to estimate relative 3D positions among
subjects to generate a coherent representation. In this work, through a single
graph neural network, named MUG (Multi-hUman Graph network), we construct
coherent multi-human meshes using only multi-human 2D pose as input. Compared
with existing methods, which adopt a detection-style pipeline (i.e., extracting
image features and then locating human instances and recovering body meshes
from that) and suffer from the significant domain gap between lab-collected
training datasets and in-the-wild testing datasets, our method benefits from
the 2D pose which has a relatively consistent geometric property across
datasets. Our method works like the following: First, to model the multi-human
environment, it processes multi-human 2D poses and builds a novel heterogeneous
graph, where nodes from different people and within one person are connected to
capture inter-human interactions and draw the body geometry (i.e., skeleton and
mesh structure). Second, it employs a dual-branch graph neural network
structure -- one for predicting inter-human depth relation and the other one
for predicting root-joint-relative mesh coordinates. Finally, the entire
multi-human 3D meshes are constructed by combining the output from both
branches. Extensive experiments demonstrate that MUG outperforms previous
multi-human mesh estimation methods on standard 3D human benchmarks --
Panoptic, MuPoTS-3D and 3DPW.</p>
  </details>
</details>
<details>
  <summary>34. <b>标题：From Pedestrian Detection to Crosswalk Estimation: An EM Algorithm and  Analysis on Diverse Datasets</b></summary>
  <p><b>编号</b>：[159]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12579</p>
  <p><b>作者</b>：Ross Greer,  Mohan Trivedi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：processed LiDAR point, LiDAR point clouds, linear crossing segments, camera images, processed LiDAR</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this work, we contribute an EM algorithm for estimation of corner points
and linear crossing segments for both marked and unmarked pedestrian crosswalks
using the detections of pedestrians from processed LiDAR point clouds or camera
images. We demonstrate the algorithmic performance by analyzing three
real-world datasets containing multiple periods of data collection for
four-corner and two-corner intersections with marked and unmarked crosswalks.
Additionally, we include a Python video tool to visualize the crossing
parameter estimation, pedestrian trajectories, and phase intervals in our
public source code.</p>
  </details>
</details>
<details>
  <summary>35. <b>标题：Spotlights: Probing Shapes from Spherical Viewpoints</b></summary>
  <p><b>编号</b>：[164]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12564</p>
  <p><b>作者</b>：Jiaxin Wei,  Lige Liu,  Ran Cheng,  Wenqing Jiang,  Minghao Xu,  Xinyu Jiang,  Tao Sun,  Soren Schwertfeger,  Laurent Kneip</p>
  <p><b>备注</b>：17 pages</p>
  <p><b>关键词</b>：Recent years, years have witnessed, witnessed the surge, surge of learned, directly build</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent years have witnessed the surge of learned representations that
directly build upon point clouds. Though becoming increasingly expressive, most
existing representations still struggle to generate ordered point sets.
Inspired by spherical multi-view scanners, we propose a novel sampling model
called Spotlights to represent a 3D shape as a compact 1D array of depth
values. It simulates the configuration of cameras evenly distributed on a
sphere, where each virtual camera casts light rays from its principal point
through sample points on a small concentric spherical cap to probe for the
possible intersections with the object surrounded by the sphere. The structured
point cloud is hence given implicitly as a function of depths. We provide a
detailed geometric analysis of this new sampling scheme and prove its
effectiveness in the context of the point cloud completion task. Experimental
results on both synthetic and real data demonstrate that our method achieves
competitive accuracy and consistency while having a significantly reduced
computational cost. Furthermore, we show superior performance on the downstream
point cloud registration task over state-of-the-art completion methods.</p>
  </details>
</details>
<details>
  <summary>36. <b>标题：Breaking the Chain of Gradient Leakage in Vision Transformers</b></summary>
  <p><b>编号</b>：[170]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12551</p>
  <p><b>作者</b>：Yahui Liu,  Bin Ren,  Yue Song,  Wei Bi,  Nicu Sebe,  Wei Wang</p>
  <p><b>备注</b>：18 pages, 9 figures</p>
  <p><b>关键词</b>：Federated Learning, concern in Federated, great concern, Learning, Vision</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>User privacy is of great concern in Federated Learning, while Vision
Transformers (ViTs) have been revealed to be vulnerable to gradient-based
inversion attacks. We show that the learned low-dimensional spatial prior in
position embeddings (PEs) accelerates the training of ViTs. As a side effect,
it makes the ViTs tend to be position sensitive and at high risk of privacy
leakage. We observe that enhancing the position-insensitive property of a ViT
model is a promising way to protect data privacy against these gradient
attacks. However, simply removing the PEs may not only harm the convergence and
accuracy of ViTs but also places the model at more severe privacy risk. To deal
with the aforementioned contradiction, we propose a simple yet efficient Masked
Jigsaw Puzzle (MJP) method to break the chain of gradient leakage in ViTs. MJP
can be easily plugged into existing ViTs and their derived variants. Extensive
experiments demonstrate that our proposed MJP method not only boosts the
performance on large-scale datasets (i.e., ImageNet-1K), but can also improve
the privacy preservation capacity in the typical gradient attacks by a large
margin. Our code is available at: this https URL.</p>
  </details>
</details>
<details>
  <summary>37. <b>标题：Some equivalence relation between persistent homology and morphological  dynamics</b></summary>
  <p><b>编号</b>：[174]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12546</p>
  <p><b>作者</b>：Nicolas Boutry (LRDE),  Laurent Najman (LIGM),  Thierry Géraud (LRDE)</p>
  <p><b>备注</b>：Journal of Mathematical Imaging and Vision, Springer Verlag, In press</p>
  <p><b>关键词</b>：connected filters based, connected filters, filters based, Morse function, Morse Theory</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In Mathematical Morphology (MM), connected filters based on dynamics are used
to filter the extrema of an image. Similarly, persistence is a concept coming
from Persistent Homology (PH) and Morse Theory (MT) that represents the
stability of the extrema of a Morse function. Since these two concepts seem to
be closely related, in this paper we examine their relationship, and we prove
that they are equal on n-D Morse functions, n $\ge$ 1. More exactly, pairing a
minimum with a 1-saddle by dynamics or pairing the same 1-saddle with a minimum
by persistence leads exactly to the same pairing, assuming that the critical
values of the studied Morse function are unique. This result is a step further
to show how much topological data analysis and mathematical morphology are
related, paving the way for a more in-depth study of the relations between
these two research fields.</p>
  </details>
</details>
<details>
  <summary>38. <b>标题：Deep Dense Local Feature Matching and Vehicle Removal for Indoor Visual  Localization</b></summary>
  <p><b>编号</b>：[175]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12544</p>
  <p><b>作者</b>：Kyung Ho Park</p>
  <p><b>备注</b>：8 pages, 12 figures, 2 tables</p>
  <p><b>关键词</b>：enabling broad applications, intelligent transportation systems, transportation systems, enabling broad, essential component</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Visual localization is an essential component of intelligent transportation
systems, enabling broad applications that require understanding one's self
location when other sensors are not available. It is mostly tackled by image
retrieval such that the location of a query image is determined by its closest
match in the previously collected images. Existing approaches focus on large
scale localization where landmarks are helpful in finding the location.
However, visual localization becomes challenging in small scale environments
where objects are hardly recognizable. In this paper, we propose a visual
localization framework that robustly finds the match for a query among the
images collected from indoor parking lots. It is a challenging problem when the
vehicles in the images share similar appearances and are frequently replaced
such as parking lots. We propose to employ a deep dense local feature matching
that resembles human perception to find correspondences and eliminating matches
from vehicles automatically with a vehicle detector. The proposed solution is
robust to the scenes with low textures and invariant to false matches caused by
vehicles. We compare our framework with alternatives to validate our
superiority on a benchmark dataset containing 267 pre-collected images and 99
query images taken from 34 sections of a parking lot. Our method achieves 86.9
percent accuracy, outperforming the alternatives.</p>
  </details>
</details>
<details>
  <summary>39. <b>标题：Misleading Deep-Fake Detection with GAN Fingerprints</b></summary>
  <p><b>编号</b>：[176]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12543</p>
  <p><b>作者</b>：Vera Wesselkamp,  Konrad Rieck,  Daniel Arp,  Erwin Quiring</p>
  <p><b>备注</b>：In IEEE Deep Learning and Security Workshop (DLS) 2022</p>
  <p><b>关键词</b>：Generative adversarial networks, made remarkable progress, synthesizing realistic-looking images, Generative adversarial, adversarial networks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Generative adversarial networks (GANs) have made remarkable progress in
synthesizing realistic-looking images that effectively outsmart even humans.
Although several detection methods can recognize these deep fakes by checking
for image artifacts from the generation process, multiple counterattacks have
demonstrated their limitations. These attacks, however, still require certain
conditions to hold, such as interacting with the detection method or adjusting
the GAN directly. In this paper, we introduce a novel class of simple
counterattacks that overcomes these limitations. In particular, we show that an
adversary can remove indicative artifacts, the GAN fingerprint, directly from
the frequency spectrum of a generated image. We explore different realizations
of this removal, ranging from filtering high frequencies to more nuanced
frequency-peak cleansing. We evaluate the performance of our attack with
different detection methods, GAN architectures, and datasets. Our results show
that an adversary can often remove GAN fingerprints and thus evade the
detection of generated images.</p>
  </details>
</details>
<details>
  <summary>40. <b>标题：Structured Uncertainty in the Observation Space of Variational  Autoencoders</b></summary>
  <p><b>编号</b>：[181]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12533</p>
  <p><b>作者</b>：James Langley,  Miguel Monteiro,  Charles Jones,  Nick Pawlowski,  Ben Glocker</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：deep generative models, Variational autoencoders, range of applications, popular class, class of deep</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Variational autoencoders (VAEs) are a popular class of deep generative models
with many variants and a wide range of applications. Improvements upon the
standard VAE mostly focus on the modelling of the posterior distribution over
the latent space and the properties of the neural network decoder. In contrast,
improving the model for the observational distribution is rarely considered and
typically defaults to a pixel-wise independent categorical or normal
distribution. In image synthesis, sampling from such distributions produces
spatially-incoherent results with uncorrelated pixel noise, resulting in only
the sample mean being somewhat useful as an output prediction. In this paper,
we aim to stay true to VAE theory by improving the samples from the
observational distribution. We propose an alternative model for the observation
space, encoding spatial dependencies via a low-rank parameterisation. We
demonstrate that this new observational distribution has the ability to capture
relevant covariance between pixels, resulting in spatially-coherent samples. In
contrast to pixel-wise independent distributions, our samples seem to contain
semantically meaningful variations from the mean allowing the prediction of
multiple plausible outputs with a single forward pass.</p>
  </details>
</details>
<details>
  <summary>41. <b>标题：Accelerating Diffusion Models via Early Stop of the Diffusion Process</b></summary>
  <p><b>编号</b>：[185]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12524</p>
  <p><b>作者</b>：Zhaoyang Lyu,  Xudong XU,  Ceyuan Yang,  Dahua Lin,  Bo Dai</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Diffusion Probabilistic Models, Denoising Diffusion Probabilistic, Probabilistic Models, Diffusion Probabilistic, pre-trained generative model</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Denoising Diffusion Probabilistic Models (DDPMs) have achieved impressive
performance on various generation tasks. By modeling the reverse process of
gradually diffusing the data distribution into a Gaussian distribution,
generating a sample in DDPMs can be regarded as iteratively denoising a
randomly sampled Gaussian noise. However, in practice DDPMs often need hundreds
even thousands of denoising steps to obtain a high-quality sample from the
Gaussian noise, leading to extremely low inference efficiency. In this work, we
propose a principled acceleration strategy, referred to as Early-Stopped DDPM
(ES-DDPM), for DDPMs. The key idea is to stop the diffusion process early where
only the few initial diffusing steps are considered and the reverse denoising
process starts from a non-Gaussian distribution. By further adopting a powerful
pre-trained generative model, such as GAN and VAE, in ES-DDPM, sampling from
the target non-Gaussian distribution can be efficiently achieved by diffusing
samples obtained from the pre-trained generative model. In this way, the number
of required denoising steps is significantly reduced. In the meantime, the
sample quality of ES-DDPM also improves substantially, outperforming both the
vanilla DDPM and the adopted pre-trained generative model. On extensive
experiments across CIFAR-10, CelebA, ImageNet, LSUN-Bedroom and LSUN-Cat,
ES-DDPM obtains promising acceleration effect and performance improvement over
representative baseline methods. Moreover, ES-DDPM also demonstrates several
attractive properties, including being orthogonal to existing acceleration
methods, as well as simultaneously enabling both global semantic and local
pixel-level control in image generation.</p>
  </details>
</details>
<details>
  <summary>42. <b>标题：Crossmodal-3600: A Massively Multilingual Multimodal Evaluation Dataset</b></summary>
  <p><b>编号</b>：[187]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12522</p>
  <p><b>作者</b>：Ashish V. Thapliyal,  Jordi Pont-Tuset,  Xi Chen,  Radu Soricut</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：high-quality evaluation datasets, massively multilingual image, multilingual image captioning, severely hampered, lack of high-quality</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Research in massively multilingual image captioning has been severely
hampered by a lack of high-quality evaluation datasets. In this paper we
present the Crossmodal-3600 dataset (XM3600 in short), a geographically diverse
set of 3600 images annotated with human-generated reference captions in 36
languages. The images were selected from across the world, covering regions
where the 36 languages are spoken, and annotated with captions that achieve
consistency in terms of style across all languages, while avoiding annotation
artifacts due to direct translation. We apply this benchmark to model selection
for massively multilingual image captioning models, and show superior
correlation results with human evaluations when using XM3600 as golden
references for automatic metrics.</p>
  </details>
</details>
<details>
  <summary>43. <b>标题：Structure Aware and Class Balanced 3D Object Detection on nuScenes  Dataset</b></summary>
  <p><b>编号</b>：[189]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12519</p>
  <p><b>作者</b>：Sushruth Nagesh,  Asfiya Baig,  Savitha Srinivasan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：object detection, autonomous driving, pivotal for autonomous, detection is pivotal, auxiliary network</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>3-D object detection is pivotal for autonomous driving. Point cloud based
methods have become increasingly popular for 3-D object detection, owing to
their accurate depth information. NuTonomy's nuScenes dataset greatly extends
commonly used datasets such as KITTI in size, sensor modalities, categories,
and annotation numbers. However, it suffers from severe class imbalance. The
Class-balanced Grouping and Sampling paper addresses this issue and suggests
augmentation and sampling strategy. However, the localization precision of this
model is affected by the loss of spatial information in the downscaled feature
maps. We propose to enhance the performance of the CBGS model by designing an
auxiliary network, that makes full use of the structure information of the 3D
point cloud, in order to improve the localization accuracy. The detachable
auxiliary network is jointly optimized by two point-level supervisions, namely
foreground segmentation and center estimation. The auxiliary network does not
introduce any extra computation during inference, since it can be detached at
test time.</p>
  </details>
</details>
<details>
  <summary>44. <b>标题：Text-to-Face Generation with StyleGAN2</b></summary>
  <p><b>编号</b>：[192]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12512</p>
  <p><b>作者</b>：D. M. A. Ayanthi,  Sarasi Munasinghe</p>
  <p><b>备注</b>：16 pages, 5 figures, for conference, this https URL</p>
  <p><b>关键词</b>：Generative Adversarial Networks, Adversarial Networks, Generative Adversarial, advent of Generative, active research area</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Synthesizing images from text descriptions has become an active research area
with the advent of Generative Adversarial Networks. The main goal here is to
generate photo-realistic images that are aligned with the input descriptions.
Text-to-Face generation (T2F) is a sub-domain of Text-to-Image generation (T2I)
that is more challenging due to the complexity and variation of facial
attributes. It has a number of applications mainly in the domain of public
safety. Even though several models are available for T2F, there is still the
need to improve the image quality and the semantic alignment. In this research,
we propose a novel framework, to generate facial images that are well-aligned
with the input descriptions. Our framework utilizes the high-resolution face
generator, StyleGAN2, and explores the possibility of using it in T2F. Here, we
embed text in the input latent space of StyleGAN2 using BERT embeddings and
oversee the generation of facial images using text descriptions. We trained our
framework on attribute-based descriptions to generate images of 1024x1024 in
resolution. The images generated exhibit a 57% similarity to the ground truth
images, with a face semantic distance of 0.92, outperforming
state-of-the-artwork. The generated images have a FID score of 118.097 and the
experimental results show that our model generates promising images.</p>
  </details>
</details>
<details>
  <summary>45. <b>标题：The Dialog Must Go On: Improving Visual Dialog via Generative  Self-Training</b></summary>
  <p><b>编号</b>：[199]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12502</p>
  <p><b>作者</b>：Gi-Cheon Kang,  Sungdong Kim,  Jin-Hwa Kim,  Donghyun Kwak,  Byoung-Tak Zhang</p>
  <p><b>备注</b>：16 pages, 4 figures</p>
  <p><b>关键词</b>：history as context, task of answering, answering a sequence, sequence of questions, questions grounded</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Visual dialog (VisDial) is a task of answering a sequence of questions
grounded in an image, using the dialog history as context. Prior work has
trained the dialog agents solely on VisDial data via supervised learning or
leveraged pre-training on related vision-and-language datasets. This paper
presents a semi-supervised learning approach for visually-grounded dialog,
called Generative Self-Training (GST), to leverage unlabeled images on the Web.
Specifically, GST first retrieves in-domain images through out-of-distribution
detection and generates synthetic dialogs regarding the images via multimodal
conditional text generation. GST then trains a dialog agent on the synthetic
and the original VisDial data. As a result, GST scales the amount of training
data up to an order of magnitude that of VisDial (1.2M to 12.9M QA data). For
robust training of the generated dialogs, we also propose perplexity-based data
selection and multimodal consistency regularization. Evaluation on VisDial v1.0
and v0.9 datasets shows that GST achieves new state-of-the-art results on both
datasets. We further observe strong performance gains in the low-data regime
(up to 9.35 absolute points on NDCG).</p>
  </details>
</details>
<details>
  <summary>46. <b>标题：Efficient Textured Mesh Recovery from Multiple Views with Differentiable  Rendering</b></summary>
  <p><b>编号</b>：[218]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12468</p>
  <p><b>作者</b>：Lixiang Lin,  Yisu Zhang,  Jianke Zhu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：multi-layer perceptrons-based methods, deep neural network, neural network due, recovery using self-supervision, multi-layer perceptrons-based</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Despite of the promising results on shape and color recovery using
self-supervision, the multi-layer perceptrons-based methods usually costs hours
to train the deep neural network due to the implicit surface representation.
Moreover, it is quite computational intensive to render a single image, since a
forward network inference is required for each pixel. To tackle these
challenges, in this paper, we propose an efficient coarse-to-fine approach to
recover the textured mesh from multi-view images. Specifically, we take
advantage of a differentiable Poisson Solver to represent the shape, which is
able to produce topology-agnostic and watertight surfaces. To account for the
depth information, we optimize the shape geometry by minimizing the difference
between the rendered mesh with the depth predicted by the learning-based
multi-view stereo algorithm. In contrast to the implicit neural representation
on shape and color, we introduce a physically based inverse rendering scheme to
jointly estimate the lighting and reflectance of the objects, which is able to
render the high resolution image at real-time. Additionally, we fine-tune the
extracted mesh by inverse rendering to obtain the mesh with fine details and
high fidelity image. We have conducted the extensive experiments on several
multi-view stereo datasets, whose promising results demonstrate the efficacy of
our proposed approach. We will make our full implementation publicly available.</p>
  </details>
</details>
<details>
  <summary>47. <b>标题：Eye-gaze-guided Vision Transformer for Rectifying Shortcut Learning</b></summary>
  <p><b>编号</b>：[220]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12466</p>
  <p><b>作者</b>：Chong Ma,  Lin Zhao,  Yuzhong Chen,  Lu Zhang,  Zhenxiang Xiao,  Haixing Dai,  David Liu,  Zihao Wu,  Zhengliang Liu,  Sheng Wang,  Jiaxing Gao,  Changhe Li,  Xi Jiang,  Tuo Zhang,  Qian Wang,  Dinggang Shen,  Dajiang Zhu,  Tianming Liu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：deep neural networks, biases prevents deep, prevents deep neural, learned representation, Learning harmful shortcuts</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Learning harmful shortcuts such as spurious correlations and biases prevents
deep neural networks from learning the meaningful and useful representations,
thus jeopardizing the generalizability and interpretability of the learned
representation. The situation becomes even more serious in medical imaging,
where the clinical data (e.g., MR images with pathology) are limited and scarce
while the reliability, generalizability and transparency of the learned model
are highly required. To address this problem, we propose to infuse human
experts' intelligence and domain knowledge into the training of deep neural
networks. The core idea is that we infuse the visual attention information from
expert radiologists to proactively guide the deep model to focus on regions
with potential pathology and avoid being trapped in learning harmful shortcuts.
To do so, we propose a novel eye-gaze-guided vision transformer (EG-ViT) for
diagnosis with limited medical image data. We mask the input image patches that
are out of the radiologists' interest and add an additional residual connection
in the last encoder layer of EG-ViT to maintain the correlations of all
patches. The experiments on two public datasets of INbreast and SIIM-ACR
demonstrate our EG-ViT model can effectively learn/transfer experts' domain
knowledge and achieve much better performance than baselines. Meanwhile, it
successfully rectifies the harmful shortcut learning and significantly improves
the EG-ViT model's interpretability. In general, EG-ViT takes the advantages of
both human expert's prior knowledge and the power of deep neural networks. This
work opens new avenues for advancing current artificial intelligence paradigms
by infusing human intelligence.</p>
  </details>
</details>
<details>
  <summary>48. <b>标题：sat2pc: Estimating Point Cloud of Building Roofs from 2D Satellite  Images</b></summary>
  <p><b>编号</b>：[222]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12464</p>
  <p><b>作者</b>：Yoones Rezaei,  Stephen Lee</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：virtual reality, urban planning, gained interest, planning and virtual, urban</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Three-dimensional (3D) urban models have gained interest because of their
applications in many use-cases such as urban planning and virtual reality.
However, generating these 3D representations requires LiDAR data, which are not
always readily available. Thus, the applicability of automated 3D model
generation algorithms is limited to a few locations. In this paper, we propose
sat2pc, a deep learning architecture that predicts the point cloud of a
building roof from a single 2D satellite image. Our architecture combines
Chamfer distance and EMD loss, resulting in better 2D to 3D performance. We
extensively evaluate our model and perform ablation studies on a building roof
dataset. Our results show that sat2pc was able to outperform existing baselines
by at least 18.6%. Further, we show that the predicted point cloud captures
more detail and geometric characteristics than other baselines.</p>
  </details>
</details>
<details>
  <summary>49. <b>标题：A CNN with Noise Inclined Module and Denoise Framework for Hyperspectral  Image Classification</b></summary>
  <p><b>编号</b>：[225]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12459</p>
  <p><b>作者</b>：Zhiqiang Gong,  Ping Zhong,  Jiahao Qi,  Panhe Hu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Deep Neural Networks, Neural Networks, hyperspectral image classification, hyperspectral image, Deep Neural</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep Neural Networks have been successfully applied in hyperspectral image
classification. However, most of prior works adopt general deep architectures
while ignore the intrinsic structure of the hyperspectral image, such as the
physical noise generation. This would make these deep models unable to generate
discriminative features and provide impressive classification performance. To
leverage such intrinsic information, this work develops a novel deep learning
framework with the noise inclined module and denoise framework for
hyperspectral image classification. First, we model the spectral signature of
hyperspectral image with the physical noise model to describe the high
intraclass variance of each class and great overlapping between different
classes in the image. Then, a noise inclined module is developed to capture the
physical noise within each object and a denoise framework is then followed to
remove such noise from the object. Finally, the CNN with noise inclined module
and the denoise framework is developed to obtain discriminative features and
provides good classification performance of hyperspectral image. Experiments
are conducted over two commonly used real-world datasets and the experimental
results show the effectiveness of the proposed method. The implementation of
the proposed method and other compared methods could be accessed at
this https URL.</p>
  </details>
</details>
<details>
  <summary>50. <b>标题：A Lightweight NMS-free Framework for Real-time Visual Fault Detection  System of Freight Trains</b></summary>
  <p><b>编号</b>：[226]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12458</p>
  <p><b>作者</b>：Guodong Sun,  Yang Zhou,  Huilin Pan,  Bo Wu,  Ye Hu,  Yang Zhang</p>
  <p><b>备注</b>：11 pages, 5 figures, accepted by IEEE Transactions on Instrumentation and Measurement</p>
  <p><b>关键词</b>：railway transportation safety, ensuring railway transportation, Real-time vision-based system, transportation safety, freight trains</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Real-time vision-based system of fault detection (RVBS-FD) for freight trains
is an essential part of ensuring railway transportation safety. Most existing
vision-based methods still have high computational costs based on convolutional
neural networks. The computational cost is mainly reflected in the backbone,
neck, and post-processing, i.e., non-maximum suppression (NMS). In this paper,
we propose a lightweight NMS-free framework to achieve real-time detection and
high accuracy simultaneously. First, we use a lightweight backbone for feature
extraction and design a fault detection pyramid to process features. This fault
detection pyramid includes three novel individual modules using attention
mechanism, bottleneck, and dilated convolution for feature enhancement and
computation reduction. Instead of using NMS, we calculate different loss
functions, including classification and location costs in the detection head,
to further reduce computation. Experimental results show that our framework
achieves over 83 frames per second speed with a smaller model size and higher
accuracy than the state-of-the-art detectors. Meanwhile, the hardware resource
requirements of our method are low during the training and testing process.</p>
  </details>
</details>
<details>
  <summary>51. <b>标题：Region-aware Knowledge Distillation for Efficient Image-to-Image  Translation</b></summary>
  <p><b>编号</b>：[231]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12451</p>
  <p><b>作者</b>：Linfeng Zhang,  Xin Chen,  Runpei Dong,  Kaisheng Ma</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：generative adversarial networks, Recent progress, adversarial networks, witnessed the success, success of generative</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent progress in image-to-image translation has witnessed the success of
generative adversarial networks (GANs). However, GANs usually contain a huge
number of parameters, which lead to intolerant memory and computation
consumption and limit their deployment on edge devices. To address this issue,
knowledge distillation is proposed to transfer the knowledge from a cumbersome
teacher model to an efficient student model. However, most previous knowledge
distillation methods are designed for image classification and lead to limited
performance in image-to-image translation. In this paper, we propose
Region-aware Knowledge Distillation ReKo to compress image-to-image translation
models. Firstly, ReKo adaptively finds the crucial regions in the images with
an attention module. Then, patch-wise contrastive learning is adopted to
maximize the mutual information between students and teachers in these crucial
regions. Experiments with eight comparison methods on nine datasets demonstrate
the substantial effectiveness of ReKo on both paired and unpaired
image-to-image translation. For instance, our 7.08X compressed and 6.80X
accelerated CycleGAN student outperforms its teacher by 1.33 and 1.04 FID
scores on Horse to Zebra and Zebra to Horse, respectively. Codes will be
released on GitHub.</p>
  </details>
</details>
<details>
  <summary>52. <b>标题：Cross-Domain Style Mixing for Face Cartoonization</b></summary>
  <p><b>编号</b>：[232]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12450</p>
  <p><b>作者</b>：Seungkwon Kim,  Chaeheon Gwak,  Dohyun Kim,  Kwangho Lee,  Jihye Back,  Namhyuk Ahn,  Daesik Kim</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：gained increasing popularity, recently gained increasing, increasing popularity, number of training, gained increasing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Cartoon domain has recently gained increasing popularity. Previous studies
have attempted quality portrait stylization into the cartoon domain; however,
this poses a great challenge since they have not properly addressed the
critical constraints, such as requiring a large number of training images or
the lack of support for abstract cartoon faces. Recently, a layer swapping
method has been used for stylization requiring only a limited number of
training images; however, its use cases are still narrow as it inherits the
remaining issues. In this paper, we propose a novel method called Cross-domain
Style mixing, which combines two latent codes from two different domains. Our
method effectively stylizes faces into multiple cartoon characters at various
face abstraction levels using only a single generator without even using a
large number of training images.</p>
  </details>
</details>
<details>
  <summary>53. <b>标题：Convolutional Neural Processes for Inpainting Satellite Images</b></summary>
  <p><b>编号</b>：[251]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12407</p>
  <p><b>作者</b>：Alexander Pondaven,  Märt Bakler,  Donghu Guo,  Hamzah Hashim,  Martin Ignatov,  Harrison Zhu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：model complex systems, disease dynamics, widespread availability, allowed researchers, complex systems</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The widespread availability of satellite images has allowed researchers to
model complex systems such as disease dynamics. However, many satellite images
have missing values due to measurement defects, which render them unusable
without data imputation. For example, the scanline corrector for the LANDSAT 7
satellite broke down in 2003, resulting in a loss of around 20\% of its data.
Inpainting involves predicting what is missing based on the known pixels and is
an old problem in image processing, classically based on PDEs or interpolation
methods, but recent deep learning approaches have shown promise. However, many
of these methods do not explicitly take into account the inherent
spatiotemporal structure of satellite images. In this work, we cast satellite
image inpainting as a natural meta-learning problem, and propose using
convolutional neural processes (ConvNPs) where we frame each satellite image as
its own task or 2D regression problem. We show ConvNPs can outperform classical
methods and state-of-the-art deep learning inpainting models on a scanline
inpainting problem for LANDSAT 7 satellite images, assessed on a variety of in
and out-of-distribution images.</p>
  </details>
</details>
<details>
  <summary>54. <b>标题：Jointly Optimizing Color Rendition and In-Camera Backgrounds in an RGB  Virtual Production Stage</b></summary>
  <p><b>编号</b>：[254]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12403</p>
  <p><b>作者</b>：Chloe LeGendre,  Lukas Lepicovsky,  Paul Debevec</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：display vibrant imagery, peaky spectral output, virtual production systems, wide color gamut, produce problematic color</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>While the LED panels used in virtual production systems can display vibrant
imagery with a wide color gamut, they produce problematic color shifts when
used as lighting due to their peaky spectral output from narrow-band red,
green, and blue LEDs. In this work, we present an improved color calibration
process for virtual production stages which ameliorates this color rendition
problem while also passing through accurate in-camera background colors. We do
this by optimizing linear color correction transformations for 1) the LED panel
pixels visible in the field of view of the camera, 2) the pixels outside the
field of view of the camera illuminating the subjects, and, as a post-process,
3) the pixel values recorded by the camera. The result is that footage shot in
an RGB LED panel virtual production stage can exhibit more accurate skin tones
and costume colors while still reproducing the desired colors of the in-camera
background.</p>
  </details>
</details>
<details>
  <summary>55. <b>标题：A Benchmark and Asymmetrical-Similarity Learning for Practical Image  Copy Detection</b></summary>
  <p><b>编号</b>：[278]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12358</p>
  <p><b>作者</b>：Wenhao Wang,  Yifan Sun,  Yi Yang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：ICD, edited copy, hard negative queries, Image copy detection, aims to determine</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Image copy detection (ICD) aims to determine whether a query image is an
edited copy of any image from a reference set. Currently, there are very
limited public benchmarks for ICD, while all overlook a critical challenge in
real-world applications, i.e., the distraction from hard negative queries.
Specifically, some queries are not edited copies but are inherently similar to
some reference images. These hard negative queries are easily false recognized
as edited copies, significantly compromising the ICD accuracy. This observation
motivates us to build the first ICD benchmark featuring this characteristic.
Based on existing ICD datasets, this paper constructs a new dataset by
additionally adding 100, 000 and 24, 252 hard negative pairs into the training
and test set, respectively. Moreover, this paper further reveals a unique
difficulty for solving the hard negative problem in ICD, i.e., there is a
fundamental conflict between current metric learning and ICD. This conflict is:
the metric learning adopts symmetric distance while the edited copy is an
asymmetric (unidirectional) process, e.g., a partial crop is close to its
holistic reference image and is an edited copy, while the latter cannot be the
edited copy of the former (in spite the distance is equally small). This
insight results in an Asymmetrical-Similarity Learning (ASL) method, which
allows the similarity in two directions (the query <-> the reference image) to
be different from each other. Experimental results show that ASL outperforms
state-of-the-art methods by a clear margin, confirming that solving the
symmetric-asymmetric conflict is critical for ICD.</-></p>
  </details>
</details>
<details>
  <summary>56. <b>标题：Face2Text revisited: Improved data set and baseline results</b></summary>
  <p><b>编号</b>：[283]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12342</p>
  <p><b>作者</b>：Marc Tanti,  Shaun Abdilla,  Adrian Muscat,  Claudia Borg,  Reuben A. Farrugia,  Albert Gatt</p>
  <p><b>备注</b>：7 pages, 5 figures, 4 tables, to appear in LREC 2022 (P-VLAM workshop)</p>
  <p><b>关键词</b>：Current image description, data set, image description generation, task of describing, description generation models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Current image description generation models do not transfer well to the task
of describing human faces. To encourage the development of more human-focused
descriptions, we developed a new data set of facial descriptions based on the
CelebA image data set. We describe the properties of this data set, and present
results from a face description generator trained on it, which explores the
feasibility of using transfer learning from VGGFace/ResNet CNNs. Comparisons
are drawn through both automated metrics and human evaluation by 76
English-speaking participants. The descriptions generated by the VGGFace-LSTM +
Attention model are closest to the ground truth according to human evaluation
whilst the ResNet-LSTM + Attention model obtained the highest CIDEr and CIDEr-D
results (1.252 and 0.686 respectively). Together, the new data set and these
experimental results provide data and baselines for future work in this area.</p>
  </details>
</details>
<details>
  <summary>57. <b>标题：Trajectory Optimization for Physics-Based Reconstruction of 3d Human  Pose from Monocular Video</b></summary>
  <p><b>编号</b>：[300]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12292</p>
  <p><b>作者</b>：Erik Gärtner,  Mykhaylo Andriluka,  Hongyi Xu,  Cristian Sminchisescu</p>
  <p><b>备注</b>：Accepted to CVPR 2022</p>
  <p><b>关键词</b>：physically plausible articulated, plausible articulated human, task of estimating, estimating a physically, physically plausible</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We focus on the task of estimating a physically plausible articulated human
motion from monocular video. Existing approaches that do not consider physics
often produce temporally inconsistent output with motion artifacts, while
state-of-the-art physics-based approaches have either been shown to work only
in controlled laboratory conditions or consider simplified body-ground contact
limited to feet. This paper explores how these shortcomings can be addressed by
directly incorporating a fully-featured physics engine into the pose estimation
process. Given an uncontrolled, real-world scene as input, our approach
estimates the ground-plane location and the dimensions of the physical body
model. It then recovers the physical motion by performing trajectory
optimization. The advantage of our formulation is that it readily generalizes
to a variety of scenes that might have diverse ground properties and supports
any form of self-contact and contact between the articulated body and scene
geometry. We show that our approach achieves competitive results with respect
to existing physics-based methods on the Human3.6M benchmark, while being
directly applicable without re-training to more complex dynamic motions from
the AIST benchmark and to uncontrolled internet videos.</p>
  </details>
</details>
<details>
  <summary>58. <b>标题：Wavelet Feature Maps Compression for Image-to-Image CNNs</b></summary>
  <p><b>编号</b>：[302]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12268</p>
  <p><b>作者</b>：Shahaf E. Finder,  Yair Zohav,  Maor Ashkenazi,  Eran Treister</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Convolutional Neural Networks, Neural Networks, Convolutional Neural, extensive computational resources, requiring extensive computational</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Convolutional Neural Networks (CNNs) are known for requiring extensive
computational resources, and quantization is among the best and most common
methods for compressing them. While aggressive quantization (i.e., less than
4-bits) performs well for classification, it may cause severe performance
degradation in image-to-image tasks such as semantic segmentation and depth
estimation. In this paper, we propose Wavelet Compressed Convolution (WCC) -- a
novel approach for high-resolution activation maps compression integrated with
point-wise convolutions, which are the main computational cost of modern
architectures. To this end, we use an efficient and hardware-friendly
Haar-wavelet transform, known for its effectiveness in image compression, and
define the convolution on the compressed activation map. We experiment on
various tasks, that benefit from high-resolution input, and by combining WCC
with light quantization, we achieve compression rates equivalent to 1-4bit
activation quantization with relatively small and much more graceful
degradation in performance.</p>
  </details>
</details>
<details>
  <summary>59. <b>标题：Action Recognition for American Sign Language</b></summary>
  <p><b>编号</b>：[308]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12261</p>
  <p><b>作者</b>：Nguyen Huu Phong,  Bernardete Ribeiro</p>
  <p><b>备注</b>：2 pages</p>
  <p><b>关键词</b>：American Sign Language, recognize American Sign, recognize American, Language from series, hand gestures</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this research, we present our findings to recognize American Sign Language
from series of hand gestures. While most researches in literature focus only on
static handshapes, our work target dynamic hand gestures. Since dynamic signs
dataset are very few, we collect an initial dataset of 150 videos for 10 signs
and an extension of 225 videos for 15 signs. We apply transfer learning models
in combination with deep neural networks and background subtraction for videos
in different temporal settings. Our primarily results show that we can get an
accuracy of $0.86$ and $0.71$ using DenseNet201, LSTM with video sequence of 12
frames accordingly.</p>
  </details>
</details>
<details>
  <summary>60. <b>标题：RADNet: Ensemble Model for Robust Glaucoma Classification in Color  Fundus Images</b></summary>
  <p><b>编号</b>：[316]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12902</p>
  <p><b>作者</b>：Dmitrii Medvedev,  Rand Muhtaseb,  Ahmed Al Mahrooqi</p>
  <p><b>备注</b>：Keywords: Glaucoma Classification, Color Fundus Images. Computer Aided Diagnosis</p>
  <p><b>关键词</b>：severe eye diseases, characterized by rapid, irreversible blindness, severe eye, rapid progression</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Glaucoma is one of the most severe eye diseases, characterized by rapid
progression and leading to irreversible blindness. It is often the case that
pathology diagnostics is carried out when the one's sight has already
significantly degraded due to the lack of noticeable symptoms at early stage of
the disease. Regular glaucoma screenings of the population shall improve
early-stage detection, however the desirable frequency of etymological checkups
is often not feasible due to excessive load imposed by manual diagnostics on
limited number of specialists. Considering the basic methodology to detect
glaucoma is to analyze fundus images for the \textit{optic-disc-to-optic-cup
ratio}, Machine Learning domain can offer sophisticated tooling for image
processing and classification. In our work, we propose an advanced image
pre-processing technique combined with an ensemble of deep classification
networks. Our \textit{Retinal Auto Detection (RADNet)} model has been
successfully tested on Rotterdam EyePACS AIROGS train dataset with AUC of 0.92,
and then additionally finetuned and tested on a fraction of RIM-ONE DL dataset
with AUC of 0.91.</p>
  </details>
</details>
<details>
  <summary>61. <b>标题：Structure Unbiased Adversarial Model for Medical Image Segmentation</b></summary>
  <p><b>编号</b>：[319]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12857</p>
  <p><b>作者</b>：Tianyang Zhang,  Shaoming Zheng,  Jun Cheng,  Xi Jia,  Joseph Bartlett,  Huazhu Fu,  Zhaowen Qiu,  Jiang Liu,  Jinming Duan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Medical Image Segmentation, structure, recognition to generate, Unbiased Adversarial Model, image</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Generative models have been widely proposed in image recognition to generate
more images where the distribution is similar to that of the real images. It
often introduces a discriminator network to discriminate original real data and
generated data.
However, such discriminator often considers the distribution of the data and
did not pay enough attention to the intrinsic gap due to structure.
In this paper, we reformulate a new image to image translation problem to
reduce structural gap, in addition to the typical intensity distribution gap.
We further propose a simple yet important Structure Unbiased Adversarial Model
for Medical Image Segmentation (SUAM) with learnable inverse structural
deformation for medical image segmentation. It consists of a structure
extractor, an attention diffeomorphic registration and a structure \& intensity
distribution rendering module. The structure extractor aims to extract the
dominant structure of the input image. The attention diffeomorphic registration
is proposed to reduce the structure gap with an inverse deformation field to
warp the prediction masks back to their original form. The structure rendering
module is to render the deformed structure to an image with targeted intensity
distribution. We apply the proposed SUAM on both optical coherence tomography
(OCT), magnetic resonance imaging (MRI) and computerized tomography (CT) data.
Experimental results show that the proposed method has the capability to
transfer both intensity and structure distributions.</p>
  </details>
</details>
<details>
  <summary>62. <b>标题：A Comparative Study of Gastric Histopathology Sub-size Image  Classification: from Linear Regression to Visual Transformer</b></summary>
  <p><b>编号</b>：[320]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12843</p>
  <p><b>作者</b>：Weiming Hu,  Haoyuan Chen,  Wanli Liu,  Xiaoyan Li,  Hongzan Sun,  Xinyu Huang,  Marcin Grzegorzek,  Chen Li</p>
  <p><b>备注</b>：arXiv admin note: text overlap with arXiv:2106.02473</p>
  <p><b>关键词</b>：learning, Gastric cancer, classical machine learning, cancer, machine learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Gastric cancer is the fifth most common cancer in the world. At the same
time, it is also the fourth most deadly cancer. Early detection of cancer
exists as a guide for the treatment of gastric cancer. Nowadays, computer
technology has advanced rapidly to assist physicians in the diagnosis of
pathological pictures of gastric cancer. Ensemble learning is a way to improve
the accuracy of algorithms, and finding multiple learning models with
complementarity types is the basis of ensemble learning. The complementarity of
sub-size pathology image classifiers when machine performance is insufficient
is explored in this experimental platform. We choose seven classical machine
learning classifiers and four deep learning classifiers for classification
experiments on the GasHisSDB database. Among them, classical machine learning
algorithms extract five different image virtual features to match multiple
classifier algorithms. For deep learning, we choose three convolutional neural
network classifiers. In addition, we also choose a novel Transformer-based
classifier. The experimental platform, in which a large number of classical
machine learning and deep learning methods are performed, demonstrates that
there are differences in the performance of different classifiers on GasHisSDB.
Classical machine learning models exist for classifiers that classify Abnormal
categories very well, while classifiers that excel in classifying Normal
categories also exist. Deep learning models also exist with multiple models
that can be complementarity. Suitable classifiers are selected for ensemble
learning, when machine performance is insufficient. This experimental platform
demonstrates that multiple classifiers are indeed complementarity and can
improve the efficiency of ensemble learning. This can better assist doctors in
diagnosis, improve the detection of gastric cancer, and increase the cure rate.</p>
  </details>
</details>
<details>
  <summary>63. <b>标题：COVID-19 Severity Classification on Chest X-ray Images</b></summary>
  <p><b>编号</b>：[330]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12705</p>
  <p><b>作者</b>：Aditi Sagar,  Aman Swaraj,  Karan Verma</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Biomedical imaging analysis, imaging analysis combined, Biomedical imaging, artificial intelligence, methods has proven</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Biomedical imaging analysis combined with artificial intelligence (AI)
methods has proven to be quite valuable in order to diagnose COVID-19. So far,
various classification models have been used for diagnosing COVID-19. However,
classification of patients based on their severity level is not yet analyzed.
In this work, we classify covid images based on the severity of the infection.
First, we pre-process the X-ray images using a median filter and histogram
equalization. Enhanced X-ray images are then augmented using SMOTE technique
for achieving a balanced dataset. Pre-trained Resnet50, VGG16 model and SVM
classifier are then used for feature extraction and classification. The result
of the classification model confirms that compared with the alternatives, with
chest X-Ray images, the ResNet-50 model produced remarkable classification
results in terms of accuracy (95%), recall (0.94), and F1-Score (0.92), and
precision (0.91).</p>
  </details>
</details>
<details>
  <summary>64. <b>标题：Skin Cancer Diagnostics with an All-Inclusive Smartphone Application</b></summary>
  <p><b>编号</b>：[344]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12438</p>
  <p><b>作者</b>：Upender Kalwa,  Christopher Legner,  Taejoon Kong,  Santosh Pandey</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：difficult to treat, treat at advanced, advanced stages, skin cancer, melanoma</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Among the different types of skin cancer, melanoma is considered to be the
deadliest and is difficult to treat at advanced stages. Detection of melanoma
at earlier stages can lead to reduced mortality rates. Desktop-based
computer-aided systems have been developed to assist dermatologists with early
diagnosis. However, there is significant interest in developing portable,
at-home melanoma diagnostic systems which can assess the risk of cancerous skin
lesions. Here, we present a smartphone application that combines image capture
capabilities with preprocessing and segmentation to extract the Asymmetry,
Border irregularity, Color variegation, and Diameter (ABCD) features of a skin
lesion. Using the feature sets, classification of malignancy is achieved
through support vector machine classifiers. By using adaptive algorithms in the
individual data-processing stages, our approach is made computationally light,
user friendly, and reliable in discriminating melanoma cases from benign ones.
Images of skin lesions are either captured with the smartphone camera or
imported from public datasets. The entire process from image capture to
classification runs on an Android smartphone equipped with a detachable 10x
lens, and processes an image in less than a second. The overall performance
metrics are evaluated on a public database of 200 images with Synthetic
Minority Over-sampling Technique (SMOTE) (80% sensitivity, 90% specificity, 88%
accuracy, and 0.85 area under curve (AUC)) and without SMOTE (55% sensitivity,
95% specificity, 90% accuracy, and 0.75 AUC). The evaluated performance metrics
and computation times are comparable or better than previous methods. This
all-inclusive smartphone application is designed to be easy-to-download and
easy-to-navigate for the end user, which is imperative for the eventual
democratization of such medical diagnostic systems.</p>
  </details>
</details>
<details>
  <summary>65. <b>标题：Interaction of a priori Anatomic Knowledge with Self-Supervised  Contrastive Learning in Cardiac Magnetic Resonance Imaging</b></summary>
  <p><b>编号</b>：[345]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12429</p>
  <p><b>作者</b>：Makiya Nakashima,  Inyeop Jang,  Ramesh Basnet,  Mitchel Benovoy,  W.H. Wilson Tang,  Christopher Nguyen,  Deborah Kwon,  Tae Hyun Hwang,  David Chen</p>
  <p><b>备注</b>：Under review at Machine Learning in Healthcare</p>
  <p><b>关键词</b>：cardiac magnetic resonance, expert generated labels, deep learning models, magnetic resonance imaging, models on cardiac</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Training deep learning models on cardiac magnetic resonance imaging (CMR) can
be a challenge due to the small amount of expert generated labels and inherent
complexity of data source. Self-supervised contrastive learning (SSCL) has
recently been shown to boost performance in several medical imaging tasks.
However, it is unclear how much the pre-trained representation reflects the
primary organ of interest compared to spurious surrounding tissue. In this
work, we evaluate the optimal method of incorporating prior knowledge of
anatomy into a SSCL training paradigm. Specifically, we evaluate using a
segmentation network to explicitly local the heart in CMR images, followed by
SSCL pretraining in multiple diagnostic tasks. We find that using a priori
knowledge of anatomy can greatly improve the downstream diagnostic performance.
Furthermore, SSCL pre-training with in-domain data generally improved
downstream performance and more human-like saliency compared to end-to-end
training and ImageNet pre-trained networks. However, introducing anatomic
knowledge to pre-training generally does not have significant impact.</p>
  </details>
</details>
<h1>自然语言处理</h1>
<details>
  <summary>1. <b>标题：New Intent Discovery with Pre-training and Contrastive Learning</b></summary>
  <p><b>编号</b>：[12]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12914</p>
  <p><b>作者</b>：Yuwei Zhang,  Haode Zhang,  Li-Ming Zhan,  Xiao-Ming Wu,  Albert Y.S. Lam</p>
  <p><b>备注</b>：Accepted to ACL 2022</p>
  <p><b>关键词</b>：supported intent classes, aims to uncover, categories from user, expand the set, set of supported</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>New intent discovery aims to uncover novel intent categories from user
utterances to expand the set of supported intent classes. It is a critical task
for the development and service expansion of a practical dialogue system.
Despite its importance, this problem remains under-explored in the literature.
Existing approaches typically rely on a large amount of labeled utterances and
employ pseudo-labeling methods for representation learning and clustering,
which are label-intensive, inefficient, and inaccurate. In this paper, we
provide new solutions to two important research questions for new intent
discovery: (1) how to learn semantic utterance representations and (2) how to
better cluster utterances. Particularly, we first propose a multi-task
pre-training strategy to leverage rich unlabeled data along with external
labeled data for representation learning. Then, we design a new contrastive
loss to exploit self-supervisory signals in unlabeled data for clustering.
Extensive experiments on three intent recognition benchmarks demonstrate the
high effectiveness of our proposed method, which outperforms state-of-the-art
methods by a large margin in both unsupervised and semi-supervised scenarios.
The source code will be available at
\url{this https URL}.</p>
  </details>
</details>
<details>
  <summary>2. <b>标题：NaturalProver: Grounded Mathematical Proof Generation with Language  Models</b></summary>
  <p><b>编号</b>：[15]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12910</p>
  <p><b>作者</b>：Sean Welleck,  Jiacheng Liu,  Ximing Lu,  Hannaneh Hajishirzi,  Yejin Choi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：natural mathematical language, plays a central, advances and education, core to intelligence, mixture of symbolic</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Theorem proving in natural mathematical language - the mixture of symbolic
and natural language used by humans - plays a central role in mathematical
advances and education, and tests aspects of reasoning that are core to
intelligence. Yet it has remained underexplored with modern generative models.
We study large-scale language models on two new generation tasks: suggesting
the next step in a mathematical proof, and full proof generation. Naively
applying language models to these problems yields proofs riddled with
hallucinations and logical incoherence. We develop NaturalProver, a language
model that generates proofs by conditioning on background references (e.g.
theorems and definitions that are either retrieved or human-provided), and
optionally enforces their presence with constrained decoding. On theorems from
the NaturalProofs benchmark, NaturalProver improves the quality of next-step
suggestions and generated proofs over fine-tuned GPT-3, according to human
evaluations from university-level mathematics students. NaturalProver is
capable of proving some theorems that require short (2-6 step) proofs, and
providing next-step suggestions that are rated as correct and useful over 40%
of the time, which is to our knowledge the first demonstration of these
capabilities using neural language models.</p>
  </details>
</details>
<details>
  <summary>3. <b>标题：Reasoning over Logically Interacted Conditions for Question Answering</b></summary>
  <p><b>编号</b>：[21]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12898</p>
  <p><b>作者</b>：Haitian Sun,  William W. Cohen,  Ruslan Salakhutdinov</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：answers, conditions, equally correct, multiple answers, challenging</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Some questions have multiple answers that are not equally correct, i.e.
answers are different under different conditions. Conditions are used to
distinguish answers as well as to provide additional information to support
them. In this paper, we study a more challenging task where answers are
constrained by a list of conditions that logically interact, which requires
performing logical reasoning over the conditions to determine the correctness
of the answers. Even more challenging, we only provide evidences for a subset
of the conditions, so some questions may not have deterministic answers. In
such cases, models are asked to find probable answers and identify conditions
that need to be satisfied to make the answers correct. We propose a new model,
TReasoner, for this challenging reasoning task. TReasoner consists of an
entailment module, a reasoning module, and a generation module (if the answers
are free-form text spans). TReasoner achieves state-of-the-art performance on
two benchmark conditional QA datasets, outperforming the previous
state-of-the-art by 3-10 points.</p>
  </details>
</details>
<details>
  <summary>4. <b>标题：Open-Domain Sign Language Translation Learned from Online Video</b></summary>
  <p><b>编号</b>：[31]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12870</p>
  <p><b>作者</b>：Bowen Shi,  Diane Brentari,  Greg Shakhnarovich,  Karen Livescu</p>
  <p><b>备注</b>：17 pages</p>
  <p><b>关键词</b>：controlled environment, limits the applicability, applicability to real-world, sign language translation, sign language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Existing work on sign language translation--that is, translation from sign
language videos into sentences in a written language--has focused mainly on (1)
data collected in a controlled environment or (2) data in a specific domain,
which limits the applicability to real-world settings. In this paper, we
introduce OpenASL, a large-scale ASL-English dataset collected from online
video sites (e.g., YouTube). OpenASL contains 288 hours of ASL videos in
various domains (news, VLOGs, etc.) from over 200 signers and is the largest
publicly available ASL translation dataset to date. To tackle the challenges of
sign language translation in realistic settings and without glosses, we propose
a set of techniques including sign search as a pretext task for pre-training
and fusion of mouthing and handshape features. The proposed techniques produce
consistent and large improvements in translation quality, over baseline models
based on prior work. Our data, code and model will be publicly available at
this https URL</p>
  </details>
</details>
<details>
  <summary>5. <b>标题：Understanding Factual Errors in Summarization: Errors, Summarizers,  Datasets, Error Detectors</b></summary>
  <p><b>编号</b>：[36]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12854</p>
  <p><b>作者</b>：Liyan Tang,  Tanya Goyal,  Alexander R. Fabbri,  Philippe Laban,  Jiacheng Xu,  Semih Yahvuz,  Wojciech Kryściński,  Justin F. Rousseau,  Greg Durrett</p>
  <p><b>备注</b>：11 pages (15 with references and appendix), 4 figures, 8 Tables</p>
  <p><b>关键词</b>：detect factual errors, current systems' outputs, make factual errors, abstractive summarization systems, detect factual</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The propensity of abstractive summarization systems to make factual errors
has been the subject of significant study, including work on models to detect
factual errors and annotation of errors in current systems' outputs. However,
the ever-evolving nature of summarization systems, error detectors, and
annotated benchmarks make factuality evaluation a moving target; it is hard to
get a clear picture of how techniques compare. In this work, we collect labeled
factuality errors from across nine datasets of annotated summary outputs and
stratify them in a new way, focusing on what kind of base summarization model
was used. To support finer-grained analysis, we unify the labeled error types
into a single taxonomy and project each of the datasets' errors into this
shared labeled space. We then contrast five state-of-the-art error detection
methods on this benchmark. Our findings show that benchmarks built on modern
summary outputs (those from pre-trained models) show significantly different
results than benchmarks using pre-Transformer models. Furthermore, no one
factuality technique is superior in all settings or for all error types,
suggesting that system developers should take care to choose the right system
for their task at hand.</p>
  </details>
</details>
<details>
  <summary>6. <b>标题：A Paradigm Change for Formal Syntax: Computational Algorithms in the  Grammar of English</b></summary>
  <p><b>编号</b>：[42]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12825</p>
  <p><b>作者</b>：Anat Ninio</p>
  <p><b>备注</b>：54 pages</p>
  <p><b>关键词</b>：Language sciences rely, sciences rely, formal syntax, Object Oriented Programming, syntax</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Language sciences rely less and less on formal syntax as their base. The
reason is probably its lack of psychological reality, knowingly avoided.
Philosophers of science call for a paradigm shift in which explanations are by
mechanisms, as in biology. We turned to programming languages as heuristic
models for a process-based syntax of English. The combination of a functional
word and a content word was chosen as the topic of modeling. Such combinations
are very frequent, and their output is the important immediate constituents of
sentences. We found their parallel in Object Oriented Programming where an
all-methods element serves as an interface, and the content-full element serves
as its implementation, defining computational objects. The fit of the model was
tested by deriving three functional characteristics crucial for the algorithm
and checking their presence in English grammar. We tested the reality of the
interface-implementation mechanism on psycholinguistic and neurolinguistic
evidence concerning processing, development and loss of syntax. The close fit
and psychological reality of the mechanism suggests that a paradigm shift to an
algorithmic theory of syntax is a possibility.</p>
  </details>
</details>
<details>
  <summary>7. <b>标题：On Building Spoken Language Understanding Systems for Low Resourced  Languages</b></summary>
  <p><b>编号</b>：[45]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12818</p>
  <p><b>作者</b>：Akshat Gupta</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：human experience due, Spoken dialog systems, SLU systems, Spoken dialog, SLU</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Spoken dialog systems are slowly becoming and integral part of the human
experience due to their various advantages over textual interfaces. Spoken
language understanding (SLU) systems are fundamental building blocks of spoken
dialog systems. But creating SLU systems for low resourced languages is still a
challenge. In a large number of low resourced language, we don't have access to
enough data to build automatic speech recognition (ASR) technologies, which are
fundamental to any SLU system. Also, ASR based SLU systems do not generalize to
unwritten languages. In this paper, we present a series of experiments to
explore extremely low-resourced settings where we perform intent classification
with systems trained on as low as one data-point per intent and with only one
speaker in the dataset. We also work in a low-resourced setting where we do not
use language specific ASR systems to transcribe input speech, which compounds
the challenge of building SLU systems to simulate a true low-resourced setting.
We test our system on Belgian Dutch (Flemish) and English and find that using
phonetic transcriptions to make intent classification systems in such
low-resourced setting performs significantly better than using speech features.
Specifically, when using a phonetic transcription based system over a feature
based system, we see average improvements of 12.37% and 13.08% for binary and
four-class classification problems respectively, when averaged over 49
different experimental settings.</p>
  </details>
</details>
<details>
  <summary>8. <b>标题：Automatic question generation based on sentence structure analysis using  machine learning approach</b></summary>
  <p><b>编号</b>：[47]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12811</p>
  <p><b>作者</b>：Miroslav Blšták,  Viera Rozinajová</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Natural Language Generation, Natural Language Understanding, Natural Language, Automatic question generation, Language Processing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Automatic question generation is one of the most challenging tasks of Natural
Language Processing. It requires "bidirectional" language processing: firstly,
the system has to understand the input text (Natural Language Understanding)
and it then has to generate questions also in the form of text (Natural
Language Generation). In this article, we introduce our framework for
generating the factual questions from unstructured text in the English
language. It uses a combination of traditional linguistic approaches based on
sentence patterns with several machine learning methods. We firstly obtain
lexical, syntactic and semantic information from an input text and we then
construct a hierarchical set of patterns for each sentence. The set of features
is extracted from the patterns and it is then used for automated learning of
new transformation rules. Our learning process is totally data-driven because
the transformation rules are obtained from a set of initial sentence-question
pairs. The advantages of this approach lie in a simple expansion of new
transformation rules which allows us to generate various types of questions and
also in the continuous improvement of the system by reinforcement learning. The
framework also includes a question evaluation module which estimates the
quality of generated questions. It serves as a filter for selecting the best
questions and eliminating incorrect ones or duplicates. We have performed
several experiments to evaluate the correctness of generated questions and we
have also compared our system with several state-of-the-art systems. Our
results indicate that the quality of generated questions outperforms the
state-of-the-art systems and our questions are also comparable to questions
created by humans. We have also created and published an interface with all
created datasets and evaluated questions, so it is possible to follow up on our
work.</p>
  </details>
</details>
<details>
  <summary>9. <b>标题：Does Moral Code Have a Moral Code? Probing Delphi's Moral Philosophy</b></summary>
  <p><b>编号</b>：[58]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12771</p>
  <p><b>作者</b>：Kathleen C. Fraser,  Svetlana Kiritchenko,  Esma Balkir</p>
  <p><b>备注</b>：To appear at TrustNLP Workshop @ NAACL 2022</p>
  <p><b>关键词</b>：machine learning model, learning model outputs, model outputs conform, explicitly training models, recent work</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In an effort to guarantee that machine learning model outputs conform with
human moral values, recent work has begun exploring the possibility of
explicitly training models to learn the difference between right and wrong.
This is typically done in a bottom-up fashion, by exposing the model to
different scenarios, annotated with human moral judgements. One question,
however, is whether the trained models actually learn any consistent,
higher-level ethical principles from these datasets -- and if so, what? Here,
we probe the Allen AI Delphi model with a set of standardized morality
questionnaires, and find that, despite some inconsistencies, Delphi tends to
mirror the moral principles associated with the demographic groups involved in
the annotation process. We question whether this is desirable and discuss how
we might move forward with this knowledge.</p>
  </details>
</details>
<details>
  <summary>10. <b>标题：Would You Ask it that Way? Measuring and Improving Question Naturalness  for Knowledge Graph Question Answering</b></summary>
  <p><b>编号</b>：[60]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12768</p>
  <p><b>作者</b>：Trond Linjordet,  Krisztian Balog</p>
  <p><b>备注</b>：9 pages, 3 figures. Accepted for publication as a resource paper in Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR '22), July 11-15, 2022, Madrid, Spain. For test collection, see this https URL</p>
  <p><b>关键词</b>：leveraging structured data, facilitates information access, query language expertise, requiring formal query, Knowledge graph question</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Knowledge graph question answering (KGQA) facilitates information access by
leveraging structured data without requiring formal query language expertise
from the user. Instead, users can express their information needs by simply
asking their questions in natural language (NL). Datasets used to train KGQA
models that would provide such a service are expensive to construct, both in
terms of expert and crowdsourced labor. Typically, crowdsourced labor is used
to improve template-based pseudo-natural questions generated from formal
queries. However, the resulting datasets often fall short of representing
genuinely natural and fluent language. In the present work, we investigate ways
to characterize and remedy these shortcomings. We create the IQN-KGQA test
collection by sampling questions from existing KGQA datasets and evaluating
them with regards to five different aspects of naturalness. Then, the questions
are rewritten to improve their fluency. Finally, the performance of existing
KGQA models is compared on the original and rewritten versions of the NL
questions. We find that some KGQA systems fare worse when presented with more
realistic formulations of NL questions. The IQN-KGQA test collection is a
resource to help evaluate KGQA systems in a more realistic setting. The
construction of this test collection also sheds light on the challenges of
constructing large-scale KGQA datasets with genuinely NL questions.</p>
  </details>
</details>
<details>
  <summary>11. <b>标题：Detecting Label Errors using Pre-Trained Language Models</b></summary>
  <p><b>编号</b>：[87]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12702</p>
  <p><b>作者</b>：Derek Chong,  Jenny Hong,  Christopher D. Manning</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：loss significantly outperforms, natural language datasets, large pre-trained language, pre-trained language models, simply verifying data</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We show that large pre-trained language models are extremely capable of
identifying label errors in datasets: simply verifying data points in
descending order of out-of-distribution loss significantly outperforms more
complex mechanisms for detecting label errors on natural language datasets. We
contribute a novel method to produce highly realistic, human-originated label
noise from crowdsourced data, and demonstrate the effectiveness of this method
on TweetNLP, providing an otherwise difficult to obtain measure of realistic
recall.</p>
  </details>
</details>
<details>
  <summary>12. <b>标题：Eliciting Transferability in Multi-task Learning with Task-level  Mixture-of-Experts</b></summary>
  <p><b>编号</b>：[88]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12701</p>
  <p><b>作者</b>：Qinyuan Ye,  Juan Zha,  Xiang Ren</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Recent work suggests, diverse NLP tasks, Recent work, work suggests, capable of multi-task</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent work suggests that transformer models are capable of multi-task
learning on diverse NLP tasks. However, the potential of these models may be
limited as they use the same set of parameters for all tasks. In contrast,
humans tackle tasks in a more flexible way, by making proper presumptions on
what skills and knowledge are relevant and executing only the necessary
computations. Inspired by this, we propose to use task-level mixture-of-expert
models, which has a collection of transformer layers (i.e., experts) and a
router component to choose among these experts dynamically and flexibly. We
show that the learned routing decisions and experts partially rediscover human
categorization of NLP tasks -- certain experts are strongly associated with
extractive tasks, some with classification tasks, and some with tasks requiring
world knowledge.</p>
  </details>
</details>
<details>
  <summary>13. <b>标题：Textual Backdoor Attacks with Iterative Trigger Injection</b></summary>
  <p><b>编号</b>：[89]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12700</p>
  <p><b>作者</b>：Jun Yan,  Vansh Gupta,  Xiang Ren</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Natural Language, Language, Natural, threat for Natural, backdoor</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The backdoor attack has become an emerging threat for Natural Language
Processing (NLP) systems. A victim model trained on poisoned data can be
embedded with a "backdoor", making it predict the adversary-specified output
(e.g., the positive sentiment label) on inputs satisfying the trigger pattern
(e.g., containing a certain keyword). In this paper, we demonstrate that it's
possible to design an effective and stealthy backdoor attack by iteratively
injecting "triggers" into a small set of training data. While all triggers are
common words that fit into the context, our poisoning process strongly
associates them with the target label, forming the model backdoor. Experiments
on sentiment analysis and hate speech detection show that our proposed attack
is both stealthy and effective, raising alarm on the usage of untrusted
training data. We further propose a defense method to combat this threat.</p>
  </details>
</details>
<details>
  <summary>14. <b>标题：Empathic Conversations: A Multi-level Dataset of Contextualized  Conversations</b></summary>
  <p><b>编号</b>：[90]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12698</p>
  <p><b>作者</b>：Damilola Omitaomu,  Shabnam Tafreshi,  Tingting Liu,  Sven Buechel,  Chris Callison-Burch,  Johannes Eichstaedt,  Lyle Ungar,  João Sedoc</p>
  <p><b>备注</b>：21 pages</p>
  <p><b>关键词</b>：cognitive and emotional, emotional reaction, observed situation, Empathy, Empathic Conversations</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Empathy is a cognitive and emotional reaction to an observed situation of
others. Empathy has recently attracted interest because it has numerous
applications in psychology and AI, but it is unclear how different forms of
empathy (e.g., self-report vs counterpart other-report, concern vs. distress)
interact with other affective phenomena or demographics like gender and age. To
better understand this, we created the {\it Empathic Conversations} dataset of
annotated negative, empathy-eliciting dialogues in which pairs of participants
converse about news articles. People differ in their perception of the empathy
of others. These differences are associated with certain characteristics such
as personality and demographics. Hence, we collected detailed characterization
of the participants' traits, their self-reported empathetic response to news
articles, their conversational partner other-report, and turn-by-turn
third-party assessments of the level of self-disclosure, emotion, and empathy
expressed. This dataset is the first to present empathy in multiple forms along
with personal distress, emotion, personality characteristics, and person-level
demographic information. We present baseline models for predicting some of
these features from conversations.</p>
  </details>
</details>
<details>
  <summary>15. <b>标题：PLOG: Table-to-Logic Pretraining for Logical Table-to-Text Generation</b></summary>
  <p><b>编号</b>：[91]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12697</p>
  <p><b>作者</b>：Ao Liu,  Haoyu Dong,  Naoaki Okazaki,  Shi Han,  Dongmei Zhang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：involves generating logically, generating logically faithful, logically faithful sentences, derive logical level, logical level facts</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Logical table-to-text generation is a task that involves generating logically
faithful sentences from tables, which requires models to derive logical level
facts from table records via logical inference. It raises a new challenge on
the logical-level content planning of table-to-text models. However, directly
learning the logical inference knowledge from table-text pairs is very
difficult for neural models because of the ambiguity of natural language and
the scarcity of parallel data. Hence even large-scale pre-trained language
models present low logical fidelity on logical table-to-text. In this work, we
propose a PLOG (Pretrained Logical Form Generator) framework to improve the
generation fidelity. Specifically, PLOG is first pretrained on a
table-to-logic-form generation (table-to-logic) task, then finetuned on
downstream table-to-text tasks. The formal definition of logical forms enables
us to collect large amount of accurate logical forms from tables without human
annotation. In addition, PLOG can learn logical inference from table-logic
pairs much more definitely than from table-text pairs. To evaluate our model,
we further collect a controlled logical table-to-text dataset CONTLOG based on
an existing dataset. On two benchmarks, LOGICNLG and CONTLOG, PLOG outperforms
strong baselines by a large margin on the logical fidelity, demonstrating the
effectiveness of table-to-logic pretraining.</p>
  </details>
</details>
<details>
  <summary>16. <b>标题：Revisiting DocRED -- Addressing the Overlooked False Negative Problem in  Relation Extraction</b></summary>
  <p><b>编号</b>：[92]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12696</p>
  <p><b>作者</b>：Qingyu Tan,  Lu Xu,  Lidong Bing,  Hwee Tou Ng</p>
  <p><b>备注</b>：15 pages, 1 figure, 17 tables</p>
  <p><b>关键词</b>：DocRED dataset, popular and widely, widely used benchmarks, DocRED, document-level relation extraction</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The DocRED dataset is one of the most popular and widely used benchmarks for
document-level relation extraction (RE). It adopts a recommend-revise
annotation scheme so as to have a large-scale annotated dataset. However, we
find that the annotation of DocRED is incomplete, i.e., the false negative
samples are prevalent. We analyze the causes and effects of the overwhelming
false negative problem in the DocRED dataset. To address the shortcoming, we
re-annotate 4,053 documents in the DocRED dataset by adding the missed relation
triples back to the original DocRED. We name our revised DocRED dataset
Re-DocRED. We conduct extensive experiments with state-of-the-art neural models
on both datasets, and the experimental results show that the models trained and
evaluated on our Re-DocRED achieve performance improvements of around 13 F1
points. Moreover, we propose different metrics to comprehensively evaluate the
document-level RE task. We make our data publicly available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>17. <b>标题：Train Flat, Then Compress: Sharpness-Aware Minimization Learns More  Compressible Models</b></summary>
  <p><b>编号</b>：[93]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12694</p>
  <p><b>作者</b>：Clara Na,  Sanket Vaibhav Mehta,  Emma Strubell</p>
  <p><b>备注</b>：12 pages</p>
  <p><b>关键词</b>：recently gained popularity, modern deep neural, deep neural network, neural network models, recently gained</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Model compression by way of parameter pruning, quantization, or distillation
has recently gained popularity as an approach for reducing the computational
requirements of modern deep neural network models for NLP. Pruning unnecessary
parameters has emerged as a simple and effective method for compressing large
models that is compatible with a wide variety of contemporary off-the-shelf
hardware (unlike quantization), and that requires little additional training
(unlike distillation). Pruning approaches typically take a large, accurate
model as input, then attempt to discover a smaller subnetwork of that model
capable of achieving end-task accuracy comparable to the full model. Inspired
by previous work suggesting a connection between simpler, more generalizable
models and those that lie within flat basins in the loss landscape, we propose
to directly optimize for flat minima while performing task-specific pruning,
which we hypothesize should lead to simpler parameterizations and thus more
compressible models. In experiments combining sharpness-aware minimization with
both iterative magnitude pruning and structured pruning approaches, we show
that optimizing for flat minima consistently leads to greater compressibility
of parameters compared to standard Adam optimization when fine-tuning BERT
models, leading to higher rates of compression with little to no loss in
accuracy on the GLUE classification benchmark.</p>
  </details>
</details>
<details>
  <summary>18. <b>标题：Understanding Natural Language in Context</b></summary>
  <p><b>编号</b>：[95]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12691</p>
  <p><b>作者</b>：Avichai Levy,  Erez Karpas</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Google Assistant, personal assistants, Recent years, increasing number, form of chatbots</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent years have seen an increasing number of applications that have a
natural language interface, either in the form of chatbots or via personal
assistants such as Alexa (Amazon), Google Assistant, Siri (Apple), and Cortana
(Microsoft). To use these applications, a basic dialog between the robot and
the human is required.
While this kind of dialog exists today mainly within "static" robots that do
not make any movement in the household space, the challenge of reasoning about
the information conveyed by the environment increases significantly when
dealing with robots that can move and manipulate objects in our home
environment.
In this paper, we focus on cognitive robots, which have some knowledge-based
models of the world and operate by reasoning and planning with this model.
Thus, when the robot and the human communicate, there is already some formalism
they can use - the robot's knowledge representation formalism.
Our goal in this research is to translate natural language utterances into
this robot's formalism, allowing much more complicated household tasks to be
completed. We do so by combining off-the-shelf SOTA language models, planning
tools, and the robot's knowledge-base for better communication. In addition, we
analyze different directive types and illustrate the contribution of the
world's context to the translation process.</p>
  </details>
</details>
<details>
  <summary>19. <b>标题：Large Language Models are Zero-Shot Clinical Information Extractors</b></summary>
  <p><b>编号</b>：[96]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12689</p>
  <p><b>作者</b>：Monica Agrawal,  Stefan Hegselmann,  Hunter Lang,  Yoon Kim,  David Sontag</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：large language models, language model outputs, trained specifically, language model, clinical text</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We show that large language models, such as GPT-3, perform well at zero-shot
information extraction from clinical text despite not being trained
specifically for the clinical domain. We present several examples showing how
to use these models as tools for the diverse tasks of (i) concept
disambiguation, (ii) evidence extraction, (iii) coreference resolution, and
(iv) concept extraction, all on clinical text. The key to good performance is
the use of simple task-specific programs that map from the language model
outputs to the label space of the task. We refer to these programs as
resolvers, a generalization of the verbalizer, which defines a mapping between
output tokens and a discrete label space. We show in our examples that good
resolvers share common components (e.g., "safety checks" that ensure the
language model outputs faithfully match the input data), and that the common
patterns across tasks make resolvers lightweight and easy to create. To better
evaluate these systems, we also introduce two new datasets for benchmarking
zero-shot clinical information extraction based on manual relabeling of the
CASI dataset (Moon et al., 2014) with labels for new tasks. On the clinical
extraction tasks we studied, the GPT-3 + resolver systems significantly
outperform existing zero- and few-shot baselines.</p>
  </details>
</details>
<details>
  <summary>20. <b>标题：ProsocialDialog: A Prosocial Backbone for Conversational Agents</b></summary>
  <p><b>编号</b>：[97]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12688</p>
  <p><b>作者</b>：Hyunwoo Kim,  Youngjae Yu,  Liwei Jiang,  Ximing Lu,  Daniel Khashabi,  Gunhee Kim,  Yejin Choi,  Maarten Sap</p>
  <p><b>备注</b>：25 pages, 10 figures</p>
  <p><b>关键词</b>：potentially unsafe user, unsafe user utterances, existing dialogue systems, dialogue systems fail, systems fail</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Most existing dialogue systems fail to respond properly to potentially unsafe
user utterances by either ignoring or passively agreeing with them. To address
this issue, we introduce ProsocialDialog, the first large-scale multi-turn
dialogue dataset to teach conversational agents to respond to problematic
content following social norms. Covering diverse unethical, problematic,
biased, and toxic situations, ProsocialDialog contains responses that encourage
prosocial behavior, grounded in commonsense social rules (i.e., rules-of-thumb,
RoTs). Created via a human-AI collaborative framework, ProsocialDialog consists
of 58K dialogues, with 331K utterances, 160K RoTs, and 497K dialogue safety
labels accompanied by free-form rationales.
With this dataset, we introduce a dialogue safety detection module, Canary,
capable of generating RoTs given conversational context, and a
socially-informed dialogue agent, Prost. Empirical results show that Prost
generates more socially acceptable dialogues compared to other state-of-the-art
language and dialogue models in both in-domain and out-of-domain settings.
Additionally, Canary effectively guides conversational agents and off-the-shelf
language models to generate significantly more prosocial responses. Our work
highlights the promise and importance of creating and steering conversational
AI to be socially responsible.</p>
  </details>
</details>
<details>
  <summary>21. <b>标题：Ground-Truth Labels Matter: A Deeper Look into Input-Label  Demonstrations</b></summary>
  <p><b>编号</b>：[99]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12685</p>
  <p><b>作者</b>：Junyeob Kim,  Hyuhng Joon Kim,  Hyunsoo Cho,  Hwiyeol Jo,  Sang-Woo Lee,  Sang-goo Lee,  Kang Min Yoo,  Taeuk Kim</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：demonstrations remain elusive, in-context learning, research interests, remain elusive, recent explosion</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Despite recent explosion in research interests, in-context learning and the
precise impact of the quality of demonstrations remain elusive. While, based on
current literature, it is expected that in-context learning shares a similar
mechanism to supervised learning, Min et al. (2022) recently reported that,
surprisingly, input-label correspondence is less important than other aspects
of prompt demonstrations. Inspired by this counter-intuitive observation, we
re-examine the importance of ground truth labels on in-context learning from
diverse and statistical points of view. With the aid of the newly introduced
metrics, i.e., Ground-truth Label Effect Ratio (GLER), demo-gain, and label
sensitivity, we find that the impact of the correct input-label matching can
vary according to different configurations. Expanding upon the previous key
finding on the role of demonstrations, the complementary and contrastive
results suggest that one might need to take more care when estimating the
impact of each component in in-context learning demonstrations.</p>
  </details>
</details>
<details>
  <summary>22. <b>标题：Refining Query Representations for Dense Retrieval at Test Time</b></summary>
  <p><b>编号</b>：[102]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12680</p>
  <p><b>作者</b>：Mujeen Sung,  Jungsoo Park,  Jaewoo Kang,  Danqi Chen,  Jinhyuk Lee</p>
  <p><b>备注</b>：12 pages, 4 figures</p>
  <p><b>关键词</b>：learn dense representations, contrastive learning framework, learn dense, contrastive learning, retrieval</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Dense retrieval uses a contrastive learning framework to learn dense
representations of queries and contexts. Trained encoders are directly used for
each test query, but they often fail to accurately represent out-of-domain
queries. In this paper, we introduce a framework that refines instance-level
query representations at test time, with only the signals coming from the
intermediate retrieval results. We optimize the query representation based on
the retrieval result similar to pseudo relevance feedback (PRF) in information
retrieval. Specifically, we adopt a cross-encoder labeler to provide pseudo
labels over the retrieval result and iteratively refine the query
representation with a gradient descent method, treating each test query as a
single data point to train on. Our theoretical analysis reveals that our
framework can be viewed as a generalization of the classical Rocchio's
algorithm for PRF, which leads us to propose interesting variants of our
method. We show that our test-time query refinement strategy improves the
performance of phrase retrieval (+8.1% Acc@1) and passage retrieval (+3.7%
Acc@20) for open-domain QA with large improvements on out-of-domain queries.</p>
  </details>
</details>
<details>
  <summary>23. <b>标题：ZeroGen$^+$: Self-Guided High-Quality Data Generation in Efficient  Zero-Shot Learning</b></summary>
  <p><b>编号</b>：[103]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12679</p>
  <p><b>作者</b>：Jiahui Gao,  Renjie Pi,  Yong Lin,  Hang Xu,  Jiacheng Ye,  Zhiyong Wu,  Xiaodan Liang,  Zhenguo Li,  Lingpeng Kong</p>
  <p><b>备注</b>：9 pages</p>
  <p><b>关键词</b>：natural language processing, large pre-trained language, pre-trained language models, PLM-based zero-shot learning, language processing tasks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Nowadays, owing to the superior capacity of the large pre-trained language
models (PLM), the PLM-based zero-shot learning has shown promising performances
on various natural language processing tasks. There are emerging interests in
further exploring the zero-shot learning potential of PLMs. Among them, ZeroGen
attempts to purely use PLM to generate data and train a tiny model without
relying on any task-specific annotation. Despite its remarkable results, we
observe that the synthesized data from PLM contains a significant portion of
samples with low quality, overfitting on such data greatly hampers the
performance of the trained model and makes it unreliable for deployment.Since
no gold data is accessible in zero-shot scenario, it is hard to perform
model/data selection to prevent overfitting to the low-quality data. To address
this problem, we propose a noise-robust bi-level re-weighting framework which
is able to learn the per-sample weights measuring the data quality without
requiring any gold data. With the learnt weights, clean subsets of different
sizes can then be sampled to train the task model. We theoretically and
empirically verify our method is able to construct synthetic dataset with good
quality. Our method yeilds a 7.1% relative improvement than ZeroGen on average
accuracy across five different established text classification tasks.</p>
  </details>
</details>
<details>
  <summary>24. <b>标题：Language Anisotropic Cross-Lingual Model Editing</b></summary>
  <p><b>编号</b>：[104]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12677</p>
  <p><b>作者</b>：Yang Xu,  Yutai Hou,  Wanxiang Che</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：learn large amounts, editing, Model editing, Model, Pre-trained language models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Pre-trained language models learn large amounts of knowledge from their
training corpus, while the memorized facts could become outdated over a few
years. Model editing aims to make post-hoc updates on specific facts in a model
while leaving irrelevant knowledge unchanged. However, existing work studies
only the monolingual scenario. In this paper, we focus on cross-lingual model
editing. Firstly, we propose the definition and metrics of the cross-lingual
model editing, where updates in a single language should take effect in the
others as well. Next, we propose a simple framework to convert a monolingual
model editing approach to its cross-lingual variant using the parallel corpus.
Experiments show that such an approach outperforms monolingual baselines by a
large margin. Furthermore, we propose language anisotropic editing to improve
cross-lingual editing by estimating parameter importance for each language.
Experiments reveal that language anisotropic editing decreases the editing
failing rate by another $26\%$ relatively.</p>
  </details>
</details>
<details>
  <summary>25. <b>标题：Evaluating Inclusivity, Equity, and Accessibility of NLP Technology: A  Case Study for Indian Languages</b></summary>
  <p><b>编号</b>：[105]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12676</p>
  <p><b>作者</b>：Simran Khanuja,  Sebastian Ruder,  Partha Talukdar</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：NLP technology, constraints are common, widely applicable, unduly biased, low-resource settings</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In order for NLP technology to be widely applicable and useful, it needs to
be inclusive of users across the world's languages, equitable, i.e., not unduly
biased towards any particular language, and accessible to users, particularly
in low-resource settings where compute constraints are common. In this paper,
we propose an evaluation paradigm that assesses NLP technologies across all
three dimensions, hence quantifying the diversity of users they can serve.
While inclusion and accessibility have received attention in recent literature,
equity is currently unexplored. We propose to address this gap using the Gini
coefficient, a well-established metric used for estimating societal wealth
inequality. Using our paradigm, we highlight the distressed state of diversity
of current technologies for Indian (IN) languages, motivated by their
linguistic diversity and large, varied speaker population. To improve upon
these metrics, we demonstrate the importance of region-specific choices in
model building and dataset creation and also propose a novel approach to
optimal resource allocation during fine-tuning. Finally, we discuss steps that
must be taken to mitigate these biases and call upon the community to
incorporate our evaluation paradigm when building linguistically diverse
technologies.</p>
  </details>
</details>
<details>
  <summary>26. <b>标题：Training Language Models with Memory Augmentation</b></summary>
  <p><b>编号</b>：[106]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12674</p>
  <p><b>作者</b>：Zexuan Zhong,  Tao Lei,  Danqi Chen</p>
  <p><b>备注</b>：Our code and models will be available at this https URL</p>
  <p><b>关键词</b>：non-parametric memory component, remarkably by equipping, language models remarkably, improved language models, language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent work has improved language models remarkably by equipping them with a
non-parametric memory component. However, most existing approaches only
introduce memories at testing time, or represent them using a separately
trained encoder -- resulting in sub-optimal training of the language model. In
this work, we present TRIME, a novel yet simple training approach designed for
training language models with memory augmentation. Our approach uses a training
objective that directly takes in-batch examples as accessible memory. We also
present new methods for memory construction and data batching, which are used
for adapting to different sets of memories -- local, long-term, and external
memory -- at testing time. We evaluate our approach on multiple language
modeling and machine translation benchmarks. We find that simply replacing the
vanilla language modeling objective by ours greatly reduces the perplexity,
without modifying the model architecture or incorporating extra context (e.g.,
18.70 $\to$ 17.76 on WikiText-103). We further augment language models with
long-range contexts and external knowledge and demonstrate significant gains
over previous memory-augmented approaches.</p>
  </details>
</details>
<details>
  <summary>27. <b>标题：Improving Zero and Few-shot Generalization in Dialogue through  Instruction Tuning</b></summary>
  <p><b>编号</b>：[107]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12673</p>
  <p><b>作者</b>：Prakhar Gupta,  Cathy Jiao,  Yi-Ting Yeh,  Shikib Mehri,  Maxine Eskenazi,  Jeffrey P. Bigham</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：paradigm in NLP, tasks, Instruction tuning, emergent paradigm, NLP wherein natural</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Instruction tuning is an emergent paradigm in NLP wherein natural language
instructions are leveraged with language models to induce zero-shot performance
on unseen tasks. Instructions have been shown to enable good performance on
unseen tasks and datasets in both large and small language models. Dialogue is
an especially interesting area to explore instruction tuning because dialogue
systems perform multiple kinds of tasks related to language (e.g., natural
language understanding and generation, domain-specific interaction), yet
instruction tuning has not been systematically explored for dialogue-related
tasks. We introduce InstructDial, an instruction tuning framework for dialogue,
which consists of a repository of 48 diverse dialogue tasks in a unified
text-to-text format created from 59 openly available dialogue datasets. Next,
we explore cross-task generalization ability on models tuned on InstructDial
across diverse dialogue tasks. Our analysis reveals that InstructDial enables
good zero-shot performance on unseen datasets and tasks such as dialogue
evaluation and intent detection, and even better performance in a few-shot
setting. To ensure that models adhere to instructions, we introduce novel
meta-tasks. We establish benchmark zero-shot and few-shot performance of models
trained using the proposed framework on multiple dialogue tasks.</p>
  </details>
</details>
<details>
  <summary>28. <b>标题：Discovering Language-neutral Sub-networks in Multilingual Language  Models</b></summary>
  <p><b>编号</b>：[108]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12672</p>
  <p><b>作者</b>：Negar Foroutan,  Mohammadreza Banaei,  Remi Lebret,  Antoine Bosselut,  Karl Aberer</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：models perform remarkably, perform remarkably, transfer for downstream, pre-trained language models, language models perform</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Multilingual pre-trained language models perform remarkably well on
cross-lingual transfer for downstream tasks. Despite their impressive
performance, our understanding of their language neutrality (i.e., the extent
to which they use shared representations to encode similar phenomena across
languages) and its role in achieving such performance remain open questions. In
this work, we conceptualize language neutrality of multilingual models as a
function of the overlap between language-encoding sub-networks of these models.
Using mBERT as a foundation, we employ the lottery ticket hypothesis to
discover sub-networks that are individually optimized for various languages and
tasks. Using three distinct tasks and eleven typologically-diverse languages in
our evaluation, we show that the sub-networks found for different languages are
in fact quite similar, supporting the idea that mBERT jointly encodes multiple
languages in shared parameters. We conclude that mBERT is comprised of a
language-neutral sub-network shared among many languages, along with multiple
ancillary language-specific sub-networks, with the former playing a more
prominent role in mBERT's impressive cross-lingual performance.</p>
  </details>
</details>
<details>
  <summary>29. <b>标题：QAMPARI: : An Open-domain Question Answering Benchmark for Questions  with Many Answers from Multiple Paragraphs</b></summary>
  <p><b>编号</b>：[109]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12665</p>
  <p><b>作者</b>：Samuel Joseph Amouyal Ohad Rubin,  Ori Yoran,  Tomer Wolfson,  Jonathan Herzig,  Jonathan Berant</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：typically focus, ODQA, questions, open-domain question answering, answers</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Existing benchmarks for open-domain question answering (ODQA) typically focus
on questions whose answers can be extracted from a single paragraph. By
contrast, many natural questions, such as "What players were drafted by the
Brooklyn Nets?" have a list of answers. Answering such questions requires
retrieving and reading from many passages, in a large corpus. We introduce
QAMPARI, an ODQA benchmark, where question answers are lists of entities,
spread across many paragraphs. We created QAMPARI by (a) generating questions
with multiple answers from Wikipedia's knowledge graph and tables, (b)
automatically pairing answers with supporting evidence in Wikipedia paragraphs,
and (c) manually paraphrasing questions and validating each answer. We train
ODQA models from the retrieve-and-read family and find that QAMPARI is
challenging in terms of both passage retrieval and answer generation, reaching
an F1 score of 26.6 at best. Our results highlight the need for developing ODQA
models that handle a broad range of question types, including single and
multi-answer questions.</p>
  </details>
</details>
<details>
  <summary>30. <b>标题：DialogZoo: Large-Scale Dialog-Oriented Task Learning</b></summary>
  <p><b>编号</b>：[110]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12662</p>
  <p><b>作者</b>：Zhi Chen,  Jijia Bao,  Lu Chen,  Yuncong Liu,  Da Ma,  Bei Chen,  Mengyue Wu,  Su Zhu,  Jian-Guang Lou,  Kai Yu</p>
  <p><b>备注</b>：Work in Progress</p>
  <p><b>关键词</b>：Building unified conversational, dialogue research community, unified conversational agents, research community, conversational agents</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Building unified conversational agents has been a long-standing goal of the
dialogue research community. Most previous works only focus on a subset of
various dialogue tasks. In this work, we aim to build a unified foundation
model which can solve massive diverse dialogue tasks. To achieve this goal, we
first collect a large-scale well-labeled dialogue dataset from 73 publicly
available datasets. In addition to this dataset, we further propose two
dialogue-oriented self-supervised tasks, and finally use the mixture of
supervised and self-supervised datasets to train our foundation model. The
supervised examples make the model learn task-specific skills, while the
self-supervised examples make the model learn more general skills. We evaluate
our model on various downstream dialogue tasks. The experimental results show
that our method not only improves the ability of dialogue generation and
knowledge distillation, but also the representation ability of models.</p>
  </details>
</details>
<details>
  <summary>31. <b>标题：Bitext Mining Using Distilled Sentence Representations for Low-Resource  Languages</b></summary>
  <p><b>编号</b>：[114]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12654</p>
  <p><b>作者</b>：Kevin Heffernan,  Onur Çelebi,  Holger Schwenk</p>
  <p><b>备注</b>：12 pages</p>
  <p><b>关键词</b>：Scaling multilingual representation, hundred most frequent, cover the long, long tail, Scaling multilingual</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Scaling multilingual representation learning beyond the hundred most frequent
languages is challenging, in particular to cover the long tail of low-resource
languages. A promising approach has been to train one-for-all multilingual
models capable of cross-lingual transfer, but these models often suffer from
insufficient capacity and interference between unrelated languages. Instead, we
move away from this approach and focus on training multiple language (family)
specific representations, but most prominently enable all languages to still be
encoded in the same representational space. To achieve this, we focus on
teacher-student training, allowing all encoders to be mutually compatible for
bitext mining, and enabling fast learning of new languages. We introduce a new
teacher-student training scheme which combines supervised and self-supervised
training, allowing encoders to take advantage of monolingual training data,
which is valuable in the low-resource setting.
Our approach significantly outperforms the original LASER encoder. We study
very low-resource languages and handle 50 African languages, many of which are
not covered by any other model. For these languages, we train sentence
encoders, mine bitexts, and validate the bitexts by training NMT systems.</p>
  </details>
</details>
<details>
  <summary>32. <b>标题：LEPUS: Prompt-based Unsupervised Multi-hop Reranking for Open-domain QA</b></summary>
  <p><b>编号</b>：[115]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12650</p>
  <p><b>作者</b>：Muhammad Khalifa,  Lajanugen Logeswaran,  Moontae Lee,  Honglak Lee,  Lu Wang</p>
  <p><b>备注</b>：14 pages, 3 figures</p>
  <p><b>关键词</b>：MQA requires piecing, open-domain questions, study unsupervised multi-hop, MQA requires, MQA</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We study unsupervised multi-hop reranking for multi-hop QA (MQA) with
open-domain questions. Since MQA requires piecing information from multiple
documents, the main challenge thus resides in retrieving and reranking chains
of passages that support the reasoning process. Our approach relies on LargE
models with Prompt-Utilizing reranking Strategy (LEPUS): we construct an
instruction-like prompt based on a candidate document path and compute a
relevance score of the path as the probability of generating a given question,
according to a pre-trained language model. Though unsupervised, LEPUS yields
competitive reranking performance against state-of-the-art methods that are
trained on thousands of examples. Adding a small number of samples (e.g., $2$),
we demonstrate further performance gain using in-context learning. Finally, we
show that when integrated with a reader module, LEPUS can obtain competitive
multi-hop QA performance, e.g., outperforming fully-supervised QA systems.
Code will be released at this https URL</p>
  </details>
</details>
<details>
  <summary>33. <b>标题：Investigating Lexical Replacements for Arabic-English Code-Switched Data  Augmentation</b></summary>
  <p><b>编号</b>：[116]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12649</p>
  <p><b>作者</b>：Injy Hamed,  Nizar Habash,  Slim Abdennadher,  Ngoc Thang Vu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：main problem hindering, NLP systems, NLP, NLP tasks, poses several challenges</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Code-switching (CS) poses several challenges to NLP tasks, where data
sparsity is a main problem hindering the development of CS NLP systems. In this
paper, we investigate data augmentation techniques for synthesizing Dialectal
Arabic-English CS text. We perform lexical replacements using parallel corpora
and alignments where CS points are either randomly chosen or learnt using a
sequence-to-sequence model. We evaluate the effectiveness of data augmentation
on language modeling (LM), machine translation (MT), and automatic speech
recognition (ASR) tasks. Results show that in the case of using 1-1 alignments,
using trained predictive models produces more natural CS sentences, as
reflected in perplexity. By relying on grow-diag-final alignments, we then
identify aligning segments and perform replacements accordingly. By replacing
segments instead of words, the quality of synthesized data is greatly improved.
With this improvement, random-based approach outperforms using trained
predictive models on all extrinsic tasks. Our best models achieve 33.6%
improvement in perplexity, +3.2-5.6 BLEU points on MT task, and 7% relative
improvement on WER for ASR task. We also contribute in filling the gap in
resources by collecting and publishing the first Arabic English CS-English
parallel corpus.</p>
  </details>
</details>
<details>
  <summary>34. <b>标题：Overcoming Catastrophic Forgetting in Zero-Shot Cross-Lingual Generation</b></summary>
  <p><b>编号</b>：[118]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12647</p>
  <p><b>作者</b>：Tu Vu,  Aditya Barua,  Brian Lester,  Daniel Cer,  Mohit Iyyer,  Noah Constant</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：challenging problem, problem of performing, performing a generative, English, labeled data</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we explore the challenging problem of performing a generative
task (i.e., summarization) in a target language when labeled data is only
available in English. We assume a strict setting with no access to parallel
data or machine translation. Prior work has shown, and we confirm, that
standard transfer learning techniques struggle in this setting, as a generative
multilingual model fine-tuned purely on English catastrophically forgets how to
generate non-English. Given the recent rise of parameter-efficient adaptation
techniques (e.g., prompt tuning), we conduct the first investigation into how
well these methods can overcome catastrophic forgetting to enable zero-shot
cross-lingual generation. We find that parameter-efficient adaptation provides
gains over standard fine-tuning when transferring between less-related
languages, e.g., from English to Thai. However, a significant gap still remains
between these methods and fully-supervised baselines. To improve cross-lingual
transfer further, we explore three approaches: (1) mixing in unlabeled
multilingual data, (2) pre-training prompts on target language data, and (3)
explicitly factoring prompts into recombinable language and task components.
Our methods can provide further quality gains, suggesting that robust zero-shot
cross-lingual generation is within reach.</p>
  </details>
</details>
<details>
  <summary>35. <b>标题：LingMess: Linguistically Informed Multi Expert Scorers for Coreference  Resolution</b></summary>
  <p><b>编号</b>：[120]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12644</p>
  <p><b>作者</b>：Shon Otmazgin,  Arie Cattan,  Yoav Goldberg</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：resolution typically involves, coreference resolution typically, linguistic challenges, types of pairs, single pairwise scorer</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>While coreference resolution typically involves various linguistic
challenges, recent models are based on a single pairwise scorer for all types
of pairs. We present LingMess, a new coreference model that defines different
categories of coreference cases and optimize multiple pairwise scorers, where
each scorer learns a specific set of linguistic challenges. Our model
substantially improves pairwise scores for most categories and outperforms
cluster-level performance on Ontonotes. Our model is available in
this https URL</p>
  </details>
</details>
<details>
  <summary>36. <b>标题：Asking the Right Questions in Low Resource Template Extraction</b></summary>
  <p><b>编号</b>：[121]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12643</p>
  <p><b>作者</b>：Nils Holzenberger,  Yunmo Chen,  Benjamin Van Durme</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Information Extraction, mapping tasks, Extraction, questions, improve data efficiency</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Information Extraction (IE) researchers are mapping tasks to Question
Answering (QA) in order to leverage existing large QA resources, and thereby
improve data efficiency. Especially in template extraction (TE), mapping an
ontology to a set of questions can be more time-efficient than collecting
labeled examples. We ask whether end users of TE systems can design these
questions, and whether it is beneficial to involve an NLP practitioner in the
process. We compare questions to other ways of phrasing natural language
prompts for TE. We propose a novel model to perform TE with prompts, and find
it benefits from questions over other styles of prompts, and that they do not
require an NLP background to author.</p>
  </details>
</details>
<details>
  <summary>37. <b>标题：Does Your Model Classify Entities Reasonably? Diagnosing and Mitigating  Spurious Correlations in Entity Typing</b></summary>
  <p><b>编号</b>：[122]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12640</p>
  <p><b>作者</b>：Nan Xu,  Fei Wang,  Bangzheng Li,  Mingtao Dong,  Muhao Chen</p>
  <p><b>备注</b>：work in progress</p>
  <p><b>关键词</b>：typing task aims, entity typing, entity typing task, entity typing models, task aims</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The entity typing task aims at predicting one or more words or phrases that
describe the type(s) of a specific mention in a sentence. Due to shortcuts from
surface patterns to annotated entity labels and biased training, existing
entity typing models are subject to the problem of spurious correlations. To
comprehensively investigate the faithfulness and reliability of entity typing
methods, we first systematically define distinct kinds of model biases that are
reflected mainly from spurious correlations. Particularly, we identify six
types of existing model biases, including mention-context bias, lexical
overlapping bias, named entity bias, pronoun bias, dependency bias, and
overgeneralization bias. To mitigate these model biases, we then introduce a
counterfactual data augmentation method. By augmenting the original training
set with their bias-free counterparts, models are forced to fully comprehend
the sentences and discover the fundamental cues for entity typing, rather than
relying on spurious correlations for shortcuts. Experimental results on the
UFET dataset show that our counterfactual data augmentation approach helps
improve generalization of different entity typing models with consistently
better performance on both in- and out-of-distribution test sets.</p>
  </details>
</details>
<details>
  <summary>38. <b>标题：Exploring industrial safety knowledge via Zipf law</b></summary>
  <p><b>编号</b>：[124]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12636</p>
  <p><b>作者</b>：Zhenhua Wang,  Ming Ren,  Dong Gao,  Zhuang Li</p>
  <p><b>备注</b>：Expert Systems with Applications</p>
  <p><b>关键词</b>：ISK, operability analysis, report contains precious, process nature, hazard and operability</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The hazard and operability analysis (HAZOP) report contains precious
industrial safety knowledge (ISK) with expert experience and process nature,
which is of great significance to the development of industrial intelligence.
Subject to the attributes of ISK, existing researches mine them through
sequence labeling in deep learning. Yet, there are two thorny issues: (1)
Uneven distribution of ISK and (2) Consistent importance of ISK: for safety
review. In this study, we propose a novel generative mining strategy called
CRGM to explore ISK. Inspired Zipf law in linguistics, CRGM consists of
common-rare discriminator, induction-extension generator and ISK extractor.
Firstly, the common-rare discriminator divides HAZOP descriptions into common
words and rare words, and obtains the common description and the rare
description, where the latter contains more industrial substances. Then, they
are operated by the induction-extension generator in the way of deep text
generation, the common description is induced and the rare description is
extended, the material knowledge and the equipment knowledge can be enriched.
Finally, the ISK extractor processes the material knowledge and equipment
knowledge from the generated description through the rule template method, the
additional ISK is regarded as the supplement of the training set to train the
proposed sequence labeling model. We conduct multiple evaluation experiments on
two industrial safety datasets. The results show that CRGM has promising and
gratifying aptitudes, greatly improves the performance of the model, and is
efficient and generalized. Our sequence labeling model also shows the expected
performance, which is better than the existing research. Our research provides
a new perspective for exploring ISK, we hope it can contribute support for the
intelligent progress of industrial safety.</p>
  </details>
</details>
<details>
  <summary>39. <b>标题：Multimodal Knowledge Alignment with Reinforcement Learning</b></summary>
  <p><b>编号</b>：[128]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12630</p>
  <p><b>作者</b>：Youngjae Yu,  Jiwan Chung,  Heeseung Yun,  Jack Hessel,  JaeSung Park,  Ximing Lu,  Prithviraj Ammanabrolu,  Rowan Zellers,  Ronan Le Bras,  Gunhee Kim,  Yejin Choi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：task-specific training data, models readily adapt, readily adapt, task-specific training, Large language models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large language models readily adapt to novel settings, even without
task-specific training data. Can their zero-shot capacity be extended to
multimodal inputs? In this work, we propose ESPER which extends language-only
zero-shot models to unseen multimodal tasks, like image and audio captioning.
Our key novelty is to use reinforcement learning to align multimodal inputs to
language model generations without direct supervision: for example, in the
image case our reward optimization relies only on cosine similarity derived
from CLIP, and thus requires no additional explicitly paired (image, caption)
data. Because the parameters of the language model are left unchanged, the
model maintains its capacity for zero-shot generalization. Experiments
demonstrate that ESPER outperforms baselines and prior work on a variety of
zero-shot tasks; these include a new benchmark we collect+release, ESP dataset,
which tasks models with generating several diversely-styled captions for each
image.</p>
  </details>
</details>
<details>
  <summary>40. <b>标题：Are Large Pre-Trained Language Models Leaking Your Personal Information?</b></summary>
  <p><b>编号</b>：[129]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12628</p>
  <p><b>作者</b>：Jie Huang,  Hanyin Shao,  Kevin Chen-Chuan Chang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Large Pre-Trained Language, Pre-Trained Language Models, Pre-Trained Language, Language Models, Large Pre-Trained</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large Pre-Trained Language Models (PLMs) have facilitated and dominated many
NLP tasks in recent years. However, despite the great success of PLMs, there
are also privacy concerns brought with PLMs. For example, recent studies show
that PLMs memorize a lot of training data, including sensitive information,
while the information may be leaked unintentionally and be utilized by
malicious attackers.
In this paper, we propose to measure whether PLMs are prone to leaking
personal information. Specifically, we attempt to query PLMs for email
addresses with contexts of the email address or prompts containing the owner's
name. We find that PLMs do leak personal information due to memorization.
However, the risk of specific personal information being extracted by attackers
is low because the models are weak at associating the personal information with
its owner. We hope this work could help the community to better understand the
privacy risk of PLMs and bring new insights to make PLMs safe.</p>
  </details>
</details>
<details>
  <summary>41. <b>标题：Unbiased and Efficient Sampling of Dependency Trees</b></summary>
  <p><b>编号</b>：[132]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12621</p>
  <p><b>作者</b>：Miloš Stanojević</p>
  <p><b>备注</b>：15 pages, 4 algorithms, 6 figures</p>
  <p><b>关键词</b>：spanning trees, trees, dependency syntax, dependency tree, dependency</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Distributions over spanning trees are the most common way of computational
modeling of dependency syntax. However, most treebanks require that every valid
dependency tree has a single edge coming out of the ROOT node, a constraint
that is not part of the definition of spanning trees. For this reason all
standard inference algorithms for spanning trees are sub-optimal for modeling
dependency trees.
Zmigrod et al. (2021b) have recently proposed algorithms for sampling with
and without replacement from the single-root dependency tree distribution. In
this paper we show that their fastest algorithm for sampling with replacement,
Wilson-RC, is in fact producing biased samples and we provide two alternatives
that are unbiased. Additionally, we propose two algorithms (one incremental,
one parallel) that reduce the asymptotic runtime of their algorithm for
sampling $k$ trees without replacement to $\mathcal{O}(kn^3)$. These algorithms
are both asymptotically and practically more efficient.</p>
  </details>
</details>
<details>
  <summary>42. <b>标题：DisinfoMeme: A Multimodal Dataset for Detecting Meme Intentionally  Spreading Out Disinformation</b></summary>
  <p><b>编号</b>：[135]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12617</p>
  <p><b>作者</b>：Jingnong Qu,  Liunian Harold Li,  Jieyu Zhao,  Sunipa Dev,  Kai-Wei Chang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：social media, problem on social, Black Lives Matter, Lives Matter movement, Disinformation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Disinformation has become a serious problem on social media. In particular,
given their short format, visual attraction, and humorous nature, memes have a
significant advantage in dissemination among online communities, making them an
effective vehicle for the spread of disinformation. We present DisinfoMeme to
help detect disinformation memes. The dataset contains memes mined from Reddit
covering three current topics: the COVID-19 pandemic, the Black Lives Matter
movement, and veganism/vegetarianism. The dataset poses multiple unique
challenges: limited data and label imbalance, reliance on external knowledge,
multimodal reasoning, layout dependency, and noise from OCR. We test multiple
widely-used unimodal and multimodal models on this dataset. The experiments
show that the room for improvement is still huge for current models.</p>
  </details>
</details>
<details>
  <summary>43. <b>标题：Towards More Realistic Generation of Information-Seeking Conversations</b></summary>
  <p><b>编号</b>：[139]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12609</p>
  <p><b>作者</b>：Gangwoo Kim,  Sungdong Kim,  Kang Min Yoo,  Jaewoo Kang</p>
  <p><b>备注</b>：10 pages preprint</p>
  <p><b>关键词</b>：framework SimSeek, compare two variants, provide a deeper, deeper perspective, simulating information-seeking conversation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we introduce a novel framework SimSeek (simulating
information-seeking conversation from unlabeled documents) and compare two
variants of it to provide a deeper perspective into the information-seeking
behavior. We first introduce a strong simulator for information-symmetric
conversation, SimSeek-sym, where questioner and answerer share all knowledge
when conversing with one another. Although it simulates reasonable
conversations, we take a further step toward more realistic information-seeking
conversation. Hence, we propose SimSeek-asym that assumes information asymmetry
between two agents, which encourages the questioner to seek new information
from an inaccessible document. In our experiments, we demonstrate that
SimSeek-asym successfully generates information-seeking conversations for two
downstream tasks, CQA and conversational search. In particular, SimSeek-asym
improves baseline models by 1.1-1.9 F1 score in QuAC, and by 1.1 of MRR in
OR-QuAC. Moreover, we thoroughly analyze our synthetic datasets to identify
crucial factors for realistic information-seeking conversation.</p>
  </details>
</details>
<details>
  <summary>44. <b>标题：Intermediate Training on Question Answering Datasets Improves Generative  Data Augmentation</b></summary>
  <p><b>编号</b>：[141]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12604</p>
  <p><b>作者</b>：Dheeraj Mekala,  Tu Vu,  Jingbo Shang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Manually annotating datasets, Manually annotating, experts to read, documents and carefully, carefully label</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Manually annotating datasets requires domain experts to read through many
documents and carefully label them, which is often expensive. Recently,
pre-trained generative language models (GLMs) have demonstrated exceptional
abilities in generating text which motivates to leverage them for generative
data augmentation. We improve generative data augmentation by formulating the
data generation as context generation task and use question answering (QA)
datasets for intermediate training. Specifically, we view QA to be more as a
format than of a task and train GLMs as context generators for a given question
and its respective answer. Then, we cast downstream tasks into question
answering format and adapt the fine-tuned context generators to the target task
domain. Finally, we use the fine-tuned GLM to generate relevant contexts, which
is further used as synthetic training data for their corresponding tasks. We
perform extensive experiments, case studies, and ablation studies on multiple
sentiment and topic classification datasets and demonstrate substantial
improvements in performance in few-shot, zero-shot settings. Remarkably, on the
SST-2 dataset, intermediate training on SocialIQA dataset achieves an
improvement of 40% on Macro-F1 score. Through thorough analyses, we observe
that QA datasets that requires high-level reasoning abilities (e.g.,
abstractive and common-sense QA datasets) tend to give the best boost in
performance in both few-shot and zero-shot settings.</p>
  </details>
</details>
<details>
  <summary>45. <b>标题：ORCA: Interpreting Prompted Language Models via Locating Supporting Data  Evidence in the Ocean of Pretraining Data</b></summary>
  <p><b>编号</b>：[144]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12600</p>
  <p><b>作者</b>：Xiaochuang Han,  Yulia Tsvetkov</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Large pretrained language, pretrained language models, Large pretrained, performing increasingly, supporting data evidence</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large pretrained language models have been performing increasingly well in a
variety of downstream tasks via prompting. However, it remains unclear from
where the model learns the task-specific knowledge, especially in a zero-shot
setup. In this work, we want to find evidence of the model's task-specific
competence from pretraining and are specifically interested in locating a very
small subset of pretraining data that directly supports the model in the task.
We call such a subset supporting data evidence and propose a novel method ORCA
to effectively identify it, by iteratively using gradient information related
to the downstream task. This supporting data evidence offers interesting
insights about the prompted language models: in the tasks of sentiment analysis
and textual entailment, BERT shows a substantial reliance on BookCorpus, the
smaller corpus of BERT's two pretraining corpora, as well as on pretraining
examples that mask out synonyms to the task verbalizers.</p>
  </details>
</details>
<details>
  <summary>46. <b>标题：RobustLR: Evaluating Robustness to Logical Perturbation in Deductive  Reasoning</b></summary>
  <p><b>编号</b>：[145]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12598</p>
  <p><b>作者</b>：Soumya Sanyal,  Zeyi Liao,  Xiang Ren</p>
  <p><b>备注</b>：13 pages</p>
  <p><b>关键词</b>：English natural language, written in English, English natural, rules and statements, statements written</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Transformers have been shown to be able to perform deductive reasoning on a
logical rulebase containing rules and statements written in English natural
language. While the progress is promising, it is currently unclear if these
models indeed perform logical reasoning by understanding the underlying logical
semantics in the language. To this end, we propose RobustLR, a suite of
evaluation datasets that evaluate the robustness of these models to minimal
logical edits in rulebases and some standard logical equivalence conditions. In
our experiments with RoBERTa and T5, we find that the models trained in prior
works do not perform consistently on the different perturbations in RobustLR,
thus showing that the models are not robust to the proposed logical
perturbations. Further, we find that the models find it especially hard to
learn logical negation and disjunction operators. Overall, using our evaluation
sets, we demonstrate some shortcomings of the deductive reasoning-based
language models, which can eventually help towards designing better models for
logical reasoning over natural language.</p>
  </details>
</details>
<details>
  <summary>47. <b>标题：Less Learn Shortcut: Analyzing and Mitigating Learning of Spurious  Feature-Label Correlation</b></summary>
  <p><b>编号</b>：[150]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12593</p>
  <p><b>作者</b>：Yanrui Du,  Jing Yan,  Yan Chen,  Jing Liu,  Sendong Zhao,  Hua Wu,  Haifeng Wang,  Bing Qin</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：deep neural networks, neural networks tend, biased, biased words make, real-world applications</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Many recent works indicate that the deep neural networks tend to take dataset
biases as shortcuts to make decision, rather than understand the tasks, which
results in failures on the real-world applications. In this work, we focus on
the spurious correlation between feature and label, which derive from the
biased data distribution in the training data, and analyze it concretely. In
particular, we define the word highly co-occurring with a specific label as
biased word, and the example containing biased word as biased example. Our
analysis reveals that the biased examples with spurious correlations are easier
for models to learn, and when predicting, the biased words make significantly
higher contributions to models' predictions than other words, and the models
tend to assign the labels over-relying on the spurious correlation between
words and labels. To mitigate the model's over-reliance on the shortcut, we
propose a training strategy Less-Learn-Shortcut (LLS): we quantify the biased
degree of the biased examples, and down-weight them with the biased degree.
Experimental results on QM and NLI tasks show that the models improve the
performances both on in-domain and adversarial data (1.57% on DuQM and 2.12% on
HANS) with our LLS.</p>
  </details>
</details>
<details>
  <summary>48. <b>标题：RSTGen: Imbuing Fine-Grained Interpretable Control into Long-FormText  Generators</b></summary>
  <p><b>编号</b>：[152]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12590</p>
  <p><b>作者</b>：Rilwan A. Adewoyin,  Ritabrata Dutta,  Yulan He</p>
  <p><b>备注</b>：NAACL 2022</p>
  <p><b>关键词</b>：Rhetorical Structure Theory, improving the cohesion, cohesion and coherence, utilises Rhetorical Structure, classical language theory</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we study the task of improving the cohesion and coherence of
long-form text generated by language models. To this end, we propose RSTGen, a
framework that utilises Rhetorical Structure Theory (RST), a classical language
theory, to control the discourse structure, semantics and topics of generated
text. Firstly, we demonstrate our model's ability to control structural
discourse and semantic features of generated text in open generation
evaluation. Then we experiment on the two challenging long-form text tasks of
argument generation and story generation. Evaluation using automated metrics
and a metric with high correlation to human evaluation, shows that our model
performs competitively against existing models, while offering significantly
more controls over generated text than alternative methods.</p>
  </details>
</details>
<details>
  <summary>49. <b>标题：Perturbation Augmentation for Fairer NLP</b></summary>
  <p><b>编号</b>：[154]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12586</p>
  <p><b>作者</b>：Rebecca Qian,  Candace Ross,  Jude Fernandes,  Eric Smith,  Douwe Kiela,  Adina Williams</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：harmful social biases, harmful social, social biases, language models, models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Unwanted and often harmful social biases are becoming ever more salient in
NLP research, affecting both models and datasets. In this work, we ask: does
training on demographically perturbed data lead to more fair language models?
We collect a large dataset of human annotated text perturbations and train an
automatic perturber on it, which we show to outperform heuristic alternatives.
We find: (i) Language models (LMs) pre-trained on demographically perturbed
corpora are more fair, at least, according to our current best metrics for
measuring model fairness, and (ii) LMs finetuned on perturbed GLUE datasets
exhibit less demographic bias on downstream tasks. We find that improved
fairness does not come at the expense of accuracy. Although our findings appear
promising, there are still some limitations, as well as outstanding questions
about how best to evaluate the (un)fairness of large language models. We hope
that this initial exploration of neural demographic perturbation will help
drive more improvement towards fairer NLP.</p>
  </details>
</details>
<details>
  <summary>50. <b>标题：A Simple and Unified Tagging Model with Priming for Relational Structure  Predictions</b></summary>
  <p><b>编号</b>：[155]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12585</p>
  <p><b>作者</b>：I-Hung Hsu,  Kuan-Hao Huang,  Shuning Zhang,  Wenxin Cheng,  Premkumar Natarajan,  Kai-Wei Chang,  Nanyun Peng</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：natural language processing, covers a wide, wide range, plays an important, important role</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Relational structure extraction covers a wide range of tasks and plays an
important role in natural language processing. Recently, many approaches tend
to design sophisticated graphical models to capture the complex relations
between objects that are described in a sentence. In this work, we demonstrate
that simple tagging models can surprisingly achieve competitive performances
with a small trick -- priming. Tagging models with priming append information
about the operated objects to the input sequence of pretrained language model.
Making use of the contextualized nature of pretrained language model, the
priming approach help the contextualized representation of the sentence better
embed the information about the operated objects, hence, becomes more suitable
for addressing relational structure extraction. We conduct extensive
experiments on three different tasks that span ten datasets across five
different languages, and show that our model is a general and effective model,
despite its simplicity. We further carry out comprehensive analysis to
understand our model and propose an efficient approximation to our method,
which can perform almost the same performance but with faster inference speed.</p>
  </details>
</details>
<details>
  <summary>51. <b>标题：EDIN: An End-to-end Benchmark and Pipeline for Unknown Entity Discovery  and Indexing</b></summary>
  <p><b>编号</b>：[161]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12570</p>
  <p><b>作者</b>：Nora Kassner,  Fabio Petroni,  Mikhail Plekhanov,  Sebastian Riedel,  Nicola Cancedda</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：reference knowledge base, Entity Linking, knowledge base, Entity, Unknown Entity Discovery</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Existing work on Entity Linking mostly assumes that the reference knowledge
base is complete, and therefore all mentions can be linked. In practice this is
hardly ever the case, as knowledge bases are incomplete and because novel
concepts arise constantly. This paper created the Unknown Entity Discovery and
Indexing (EDIN) benchmark where unknown entities, that is entities without a
description in the knowledge base and labeled mentions, have to be integrated
into an existing entity linking system. By contrasting EDIN with zero-shot
entity linking, we provide insight on the additional challenges it poses.
Building on dense-retrieval based entity linking, we introduce the end-to-end
EDIN pipeline that detects, clusters, and indexes mentions of unknown entities
in context. Experiments show that indexing a single embedding per entity
unifying the information of multiple mentions works better than indexing
mentions independently.</p>
  </details>
</details>
<details>
  <summary>52. <b>标题：Constrained Sampling from Language Models via Langevin Dynamics in  Embedding Spaces</b></summary>
  <p><b>编号</b>：[167]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12558</p>
  <p><b>作者</b>：Sachin Kumar,  Biswajit Paria,  Yulia Tsvetkov</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Large pre-trained language, text seemingly indistinguishable, pre-trained language models, Large pre-trained, indistinguishable from humans</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large pre-trained language models are well-established for their ability to
generate text seemingly indistinguishable from humans. In this work, we study
the problem of constrained sampling from such language models. That is,
generating text that satisfies user-defined constraints. Typical decoding
strategies which generate samples left-to-right are not always conducive to
imposing such constraints globally. Instead, we propose MuCoLa -- a sampling
procedure that combines the log-likelihood of the language model with arbitrary
differentiable constraints into a single energy function; and generates samples
by initializing the entire output sequence with noise and following a Markov
chain defined by Langevin Dynamics using the gradients of this energy. We
evaluate our approach on different text generation tasks with soft and hard
constraints as well as their combinations with competitive results for toxicity
avoidance, sentiment control, and keyword-guided generation.</p>
  </details>
</details>
<details>
  <summary>53. <b>标题：Helpfulness and Fairness of Task-Oriented Dialogue Systems</b></summary>
  <p><b>编号</b>：[169]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12554</p>
  <p><b>作者</b>：Jiao Sun,  Yu Hou,  Jiin Kim,  Nanyun Peng</p>
  <p><b>备注</b>：16 pages, 5 figures and 8 tables</p>
  <p><b>关键词</b>：dialogue systems, dialogue, aim to answer, users and provide, Task-oriented dialogue systems</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Task-oriented dialogue systems aim to answer questions from users and provide
immediate help. Therefore, how humans perceive their helpfulness is important.
However, neither the human-perceived helpfulness of task-oriented dialogue
systems nor its fairness implication has been studied yet. In this paper, we
define a dialogue response as helpful if it is relevant & coherent, useful, and
informative to a query and study computational measurements of helpfulness.
Then, we propose utilizing the helpfulness level of different groups to gauge
the fairness of a dialogue system. To study this, we collect human annotations
for the helpfulness of dialogue responses and build a classifier that can
automatically determine the helpfulness of a response. We design experiments
under 3 information-seeking scenarios and collect instances for each from
Wikipedia. With collected instances, we use carefully-constructed questions to
query the state-of-the-art dialogue systems. Through analysis, we find that
dialogue systems tend to be more helpful for highly-developed countries than
less-developed countries, uncovering a fairness issue underlying these dialogue
systems.</p>
  </details>
</details>
<details>
  <summary>54. <b>标题：RLPrompt: Optimizing Discrete Text Prompts With Reinforcement Learning</b></summary>
  <p><b>编号</b>：[173]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12548</p>
  <p><b>作者</b>：Mingkai Deng,  Jianyu Wang,  Cheng-Ping Hsieh,  Yihan Wang,  Han Guo,  Tianmin Shu,  Meng Song,  Eric P. Xing,  Zhiting Hu</p>
  <p><b>备注</b>：Code available at this https URL</p>
  <p><b>关键词</b>：perform diverse NLP, diverse NLP tasks, shown impressive success, diverse NLP, NLP tasks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Prompting has shown impressive success in enabling large pretrained language
models (LMs) to perform diverse NLP tasks, especially when only few downstream
data are available. Automatically finding the optimal prompt for each task,
however, is challenging. Most existing work resorts to tuning soft prompt
(e.g., embeddings) which falls short of interpretability, reusability across
LMs, and applicability when gradients are not accessible. Discrete prompt, on
the other hand, is difficult to optimize, and is often created by "enumeration
(e.g., paraphrasing)-then-selection" heuristics that do not explore the prompt
space systematically. This paper proposes RLPrompt, an efficient discrete
prompt optimization approach with reinforcement learning (RL). RLPrompt
formulates a parameter-efficient policy network that generates the desired
discrete prompt after training with reward. To overcome the complexity and
stochasticity of reward signals by the large LM environment, we incorporate
effective reward stabilization that substantially enhances the training
efficiency. RLPrompt is flexibly applicable to different types of LMs, such as
masked (e.g., BERT) and left-to-right models (e.g., GPTs), for both
classification and generation tasks. Experiments on few-shot classification and
unsupervised text style transfer show superior performance over a wide range of
existing finetuning or prompting methods. Interestingly, the resulting
optimized prompts are often ungrammatical gibberish text; and surprisingly,
those gibberish prompts are transferrable between different LMs to retain
significant performance, indicating LM prompting may not follow human language
patterns.</p>
  </details>
</details>
<details>
  <summary>55. <b>标题：ER-TEST: Evaluating Explanation Regularization Methods for NLP Models</b></summary>
  <p><b>编号</b>：[177]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12542</p>
  <p><b>作者</b>：Brihi Joshi,  Aaron Chan,  Ziyi Liu,  Shaoliang Nie,  Maziar Sanjabi,  Hamed Firooz,  Xiang Ren</p>
  <p><b>备注</b>：19 pages, 10 figures</p>
  <p><b>关键词</b>：NLMs reasoning processes, improve NLM behavior, NLM behavior, Neural language models', improve NLM</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Neural language models' (NLMs') reasoning processes are notoriously hard to
explain. Recently, there has been much progress in automatically generating
machine rationales of NLM behavior, but less in utilizing the rationales to
improve NLM behavior. For the latter, explanation regularization (ER) aims to
improve NLM generalization by pushing the machine rationales to align with
human rationales. Whereas prior works primarily evaluate such ER models via
in-distribution (ID) generalization, ER's impact on out-of-distribution (OOD)
is largely underexplored. Plus, little is understood about how ER model
performance is affected by the choice of ER criteria or by the number/choice of
training instances with human rationales. In light of this, we propose ER-TEST,
a protocol for evaluating ER models' OOD generalization along three dimensions:
(1) unseen datasets, (2) contrast set tests, and (3) functional tests. Using
ER-TEST, we study three key questions: (A) Which ER criteria are most effective
for the given OOD setting? (B) How is ER affected by the number/choice of
training instances with human rationales? (C) Is ER effective with distantly
supervised human rationales? ER-TEST enables comprehensive analysis of these
questions by considering a diverse range of tasks and datasets. Through
ER-TEST, we show that ER has little impact on ID performance, but can yield
large gains on OOD performance w.r.t. (1)-(3). Also, we find that the best ER
criterion is task-dependent, while ER can improve OOD performance even with
limited and distantly-supervised human rationales.</p>
  </details>
</details>
<details>
  <summary>56. <b>标题：Is a Question Decomposition Unit All We Need?</b></summary>
  <p><b>编号</b>：[179]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12538</p>
  <p><b>作者</b>：Pruthvi Patel,  Swaroop Mishra,  Mihir Parmar,  Chitta Baral</p>
  <p><b>备注</b>：16 pages</p>
  <p><b>关键词</b>：Natural Language Processing, Language Processing, Natural Language, Large Language Models, Language Models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large Language Models (LMs) have achieved state-of-the-art performance on
many Natural Language Processing (NLP) benchmarks. With the growing number of
new benchmarks, we build bigger and more complex LMs. However, building new LMs
may not be an ideal option owing to the cost, time and environmental impact
associated with it. We explore an alternative route: can we modify data by
expressing it in terms of the model's strengths, so that a question becomes
easier for models to answer? We investigate if humans can decompose a hard
question into a set of simpler questions that are relatively easier for models
to solve. We analyze a range of datasets involving various forms of reasoning
and find that it is indeed possible to significantly improve model performance
(24% for GPT3 and 29% for RoBERTa-SQuAD along with a symbolic calculator) via
decomposition. Our approach provides a viable option to involve people in NLP
research in a meaningful way. Our findings indicate that Human-in-the-loop
Question Decomposition (HQD) can potentially provide an alternate path to
building large LMs.</p>
  </details>
</details>
<details>
  <summary>57. <b>标题：LOPS: Learning Order Inspired Pseudo-Label Selection for Weakly  Supervised Text Classification</b></summary>
  <p><b>编号</b>：[183]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12528</p>
  <p><b>作者</b>：Dheeraj Mekala,  Chengyu Dong,  Jingbo Shang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Weakly supervised text, methods typically train, Weakly supervised, typically train, neural classifier based</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Weakly supervised text classification methods typically train a deep neural
classifier based on pseudo-labels. The quality of pseudo-labels is crucial to
final performance but they are inevitably noisy due to their heuristic nature,
so selecting the correct ones has a huge potential for performance boost. One
straightforward solution is to select samples based on the softmax probability
scores in the neural classifier corresponding to their pseudo-labels. However,
we show through our experiments that such solutions are ineffective and
unstable due to the erroneously high-confidence predictions from poorly
calibrated models. Recent studies on the memorization effects of deep neural
models suggest that these models first memorize training samples with clean
labels and then those with noisy labels. Inspired by this observation, we
propose a novel pseudo-label selection method LOPS that takes learning order of
samples into consideration. We hypothesize that the learning order reflects the
probability of wrong annotation in terms of ranking, and therefore, propose to
select the samples that are learnt earlier. LOPS can be viewed as a strong
performance-boost plug-in to most of existing weakly-supervised text
classification methods, as confirmed in extensive experiments on four
real-world datasets.</p>
  </details>
</details>
<details>
  <summary>58. <b>标题：Segmenting Numerical Substitution Ciphers</b></summary>
  <p><b>编号</b>：[184]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12527</p>
  <p><b>作者</b>：Nada Aldarrab,  Jonathan May</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Deciphering historical substitution, Byte Pair Encoding, ciphers, substitution, Deciphering historical</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deciphering historical substitution ciphers is a challenging problem. Example
problems that have been previously studied include detecting cipher type,
detecting plaintext language, and acquiring the substitution key for segmented
ciphers. However, attacking unsegmented, space-free ciphers is still a
challenging task. Segmentation (i.e. finding substitution units) is the first
step towards cracking those ciphers. In this work, we propose the first
automatic methods to segment those ciphers using Byte Pair Encoding (BPE) and
unigram language models. Our methods achieve an average segmentation error of
2\% on 100 randomly-generated monoalphabetic ciphers and 27\% on 3 real
homophonic ciphers. We also propose a method for solving non-deterministic
ciphers with existing keys using a lattice and a pretrained language model. Our
method leads to the full solution of the IA cipher; a real historical cipher
that has not been fully solved until this work.</p>
  </details>
</details>
<details>
  <summary>59. <b>标题：TranSpeech: Speech-to-Speech Translation With Bilateral Perturbation</b></summary>
  <p><b>编号</b>：[186]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12523</p>
  <p><b>作者</b>：Rongjie Huang,  Zhou Zhao,  Jinglin Liu,  Huadai Liu,  Yi Ren,  Lichao Zhang,  Jinzheng He</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：systems leverage recent, sequence previously generated, leverage recent progress, discrete units derived, systems utilize autoregressive</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Direct speech-to-speech translation (S2ST) systems leverage recent progress
in speech representation learning, where a sequence of discrete representations
(units) derived in a self-supervised manner, are predicted from the model and
passed to a vocoder for speech synthesis, still facing the following
challenges: 1) Acoustic multimodality: the discrete units derived from speech
with same content could be indeterministic due to the acoustic property (e.g.,
rhythm, pitch, and energy), which causes deterioration of translation accuracy;
2) high latency: current S2ST systems utilize autoregressive models which
predict each unit conditioned on the sequence previously generated, failing to
take full advantage of parallelism. In this work, we propose TranSpeech, a
speech-to-speech translation model with bilateral perturbation. To alleviate
the acoustic multimodal problem, we propose bilateral perturbation, which
consists of the style normalization and information enhancement stages, to
learn only the linguistic information from speech samples and generate more
deterministic representations. With reduced multimodality, we step forward and
become the first to establish a non-autoregressive S2ST technique, which
repeatedly masks and predicts unit choices and produces high-accuracy results
in just a few cycles. Experimental results on three language pairs demonstrate
the state-of-the-art results by up to 2.5 BLEU points over the best
publicly-available textless S2ST baseline. Moreover, TranSpeech shows a
significant improvement in inference latency, enabling speedup up to 21.4x than
autoregressive technique. Audio samples are available at
\url{this https URL}</p>
  </details>
</details>
<details>
  <summary>60. <b>标题：Crossmodal-3600: A Massively Multilingual Multimodal Evaluation Dataset</b></summary>
  <p><b>编号</b>：[187]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12522</p>
  <p><b>作者</b>：Ashish V. Thapliyal,  Jordi Pont-Tuset,  Xi Chen,  Radu Soricut</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：high-quality evaluation datasets, massively multilingual image, multilingual image captioning, severely hampered, lack of high-quality</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Research in massively multilingual image captioning has been severely
hampered by a lack of high-quality evaluation datasets. In this paper we
present the Crossmodal-3600 dataset (XM3600 in short), a geographically diverse
set of 3600 images annotated with human-generated reference captions in 36
languages. The images were selected from across the world, covering regions
where the 36 languages are spoken, and annotated with captions that achieve
consistency in terms of style across all languages, while avoiding annotation
artifacts due to direct translation. We apply this benchmark to model selection
for massively multilingual image captioning models, and show superior
correlation results with human evaluations when using XM3600 as golden
references for automatic metrics.</p>
  </details>
</details>
<details>
  <summary>61. <b>标题：Machine Translation Robustness to Natural Asemantic Variation</b></summary>
  <p><b>编号</b>：[191]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12514</p>
  <p><b>作者</b>：Jacob Bremerman,  Xiang Ren,  Jonathan May</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：under-studied linguistic phenomenon, Natural Asemantic Variation, phenomenon we call, introduce and formalize, formalize an under-studied</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We introduce and formalize an under-studied linguistic phenomenon we call
Natural Asemantic Variation (NAV) and investigate it in the context of Machine
Translation (MT) robustness. Standard MT models are shown to be less robust to
rarer, nuanced language forms, and current robustness techniques do not account
for this kind of perturbation despite their prevalence in "real world" data.
Experiment results provide more insight into the nature of NAV and we
demonstrate strategies to improve performance on NAV. We also show that NAV
robustness can be transferred across languages and fine that synthetic
perturbations can achieve some but not all of the benefits of human-generated
NAV data.</p>
  </details>
</details>
<details>
  <summary>62. <b>标题：Revisiting Calibration for Question Answering</b></summary>
  <p><b>编号</b>：[194]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12507</p>
  <p><b>作者</b>：Chenglei Si,  Chen Zhao,  Sewon Min,  Jordan Boyd-Graber</p>
  <p><b>备注</b>：Preprint; Feedback is welcome</p>
  <p><b>关键词</b>：match expected accuracy, aims to adjust, calibration, Model calibration aims, expected accuracy</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Model calibration aims to adjust (calibrate) models' confidence so that they
match expected accuracy. We argue that the traditional evaluation of
calibration (expected calibration error; ECE) does not reflect usefulness of
the model confidence. For example, after conventional temperature scaling,
confidence scores become similar for all predictions, which makes it hard for
users to distinguish correct predictions from wrong ones, even though it
achieves low ECE. Building on those observations, we propose a new calibration
metric, MacroCE, that better captures whether the model assigns low confidence
to wrong predictions and high confidence to correct predictions. We examine
various conventional calibration methods including temperature scaling,
feature-based classifier, neural answer reranking, and label smoothing, all of
which do not bring significant gains under our new MacroCE metric. Towards more
effective calibration, we propose a new calibration method based on the model's
prediction consistency along the training trajectory. This new method, which we
name as consistency calibration, shows promise for better calibration.</p>
  </details>
</details>
<details>
  <summary>63. <b>标题：Memorization in NLP Fine-tuning Methods</b></summary>
  <p><b>编号</b>：[195]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12506</p>
  <p><b>作者</b>：Fatemehsadat Mireshghallah,  Archit Uniyal,  Tianhao Wang,  David Evans,  Taylor Berg-Kirkpatrick</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Large language models, present privacy risks, Large language, training data, recent works</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large language models are shown to present privacy risks through memorization
of training data, and several recent works have studied such risks for the
pre-training phase. Little attention, however, has been given to the
fine-tuning phase and it is not well understood how different fine-tuning
methods (such as fine-tuning the full model, the model head, and adapter)
compare in terms of memorization risk. This presents increasing concern as the
"pre-train and fine-tune" paradigm proliferates. In this paper, we empirically
study memorization of fine-tuning methods using membership inference and
extraction attacks, and show that their susceptibility to attacks is very
different. We observe that fine-tuning the head of the model has the highest
susceptibility to attacks, whereas fine-tuning smaller adapters appears to be
less vulnerable to known extraction attacks.</p>
  </details>
</details>
<details>
  <summary>64. <b>标题：GENEVA: Pushing the Limit of Generalizability for Event Argument  Extraction with 100+ Event Types</b></summary>
  <p><b>编号</b>：[196]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12505</p>
  <p><b>作者</b>：Tanmay Parekh,  I-Hung Hsu,  Kuan-Hao Huang,  Kai-Wei Chang,  Nanyun Peng</p>
  <p><b>备注</b>：13 pages, 10 figures</p>
  <p><b>关键词</b>：Numerous events occur, events occur worldwide, social media, EAE models, occur worldwide</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Numerous events occur worldwide and are documented in the news, social media,
and various online platforms in raw text. Extracting useful and succinct
information about these events is crucial to various downstream applications.
Event Argument Extraction (EAE) deals with the task of extracting
event-specific information from natural language text. In order to cater to new
events and domains in a realistic low-data setting, there is a growing urgency
for EAE models to be generalizable. Consequentially, there is a necessity for
benchmarking setups to evaluate the generalizability of EAE models. But most
existing benchmarking datasets like ACE and ERE have limited coverage in terms
of events and cannot adequately evaluate the generalizability of EAE models. To
alleviate this issue, we introduce a new dataset GENEVA covering a diverse
range of 115 events and 187 argument roles. Using this dataset, we create four
benchmarking test suites to assess the model's generalization capability from
different perspectives. We benchmark various representative models on these
test suites and compare their generalizability relatively. Finally, we propose
a new model SCAD that outperforms the previous models and serves as a strong
benchmark for these test suites.</p>
  </details>
</details>
<details>
  <summary>65. <b>标题：The Dialog Must Go On: Improving Visual Dialog via Generative  Self-Training</b></summary>
  <p><b>编号</b>：[199]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12502</p>
  <p><b>作者</b>：Gi-Cheon Kang,  Sungdong Kim,  Jin-Hwa Kim,  Donghyun Kwak,  Byoung-Tak Zhang</p>
  <p><b>备注</b>：16 pages, 4 figures</p>
  <p><b>关键词</b>：history as context, task of answering, answering a sequence, sequence of questions, questions grounded</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Visual dialog (VisDial) is a task of answering a sequence of questions
grounded in an image, using the dialog history as context. Prior work has
trained the dialog agents solely on VisDial data via supervised learning or
leveraged pre-training on related vision-and-language datasets. This paper
presents a semi-supervised learning approach for visually-grounded dialog,
called Generative Self-Training (GST), to leverage unlabeled images on the Web.
Specifically, GST first retrieves in-domain images through out-of-distribution
detection and generates synthetic dialogs regarding the images via multimodal
conditional text generation. GST then trains a dialog agent on the synthetic
and the original VisDial data. As a result, GST scales the amount of training
data up to an order of magnitude that of VisDial (1.2M to 12.9M QA data). For
robust training of the generated dialogs, we also propose perplexity-based data
selection and multimodal consistency regularization. Evaluation on VisDial v1.0
and v0.9 datasets shows that GST achieves new state-of-the-art results on both
datasets. We further observe strong performance gains in the low-data regime
(up to 9.35 absolute points on NDCG).</p>
  </details>
</details>
<details>
  <summary>66. <b>标题：Teaching Broad Reasoning Skills via Decomposition-Guided Contexts</b></summary>
  <p><b>编号</b>：[201]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12496</p>
  <p><b>作者</b>：Harsh Trivedi,  Niranjan Balasubramanian,  Tushar Khot,  Ashish Sabharwal</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Question-answering datasets require, reasoning, skills, multihop, contexts</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Question-answering datasets require a broad set of reasoning skills. We show
how to use question decompositions to teach language models these broad
reasoning skills in a robust fashion. Specifically, we use widely available
QDMR representations to programmatically create synthetic contexts for real
questions in six multihop reasoning datasets. These contexts are carefully
designed to avoid common reasoning shortcuts prevalent in real contexts that
prevent models from learning the right skills. This results in a pretraining
dataset, named TeaBReaC, containing 525K multihop questions (with associated
formal programs) covering about 900 reasoning patterns. We show that
pretraining standard language models (LMs) on TeaBReaC before fine-tuning them
on target datasets improves their performance by up to 13 EM points across 3
multihop QA datasets, with a 30 point gain on more complex questions. The
resulting models also demonstrate higher robustness, with a 6-11 point
improvement on two contrast sets. Furthermore, TeaBReaC pretraining
substantially improves model performance and robustness even when starting with
numeracy-aware LMs pretrained using recent methods (e.g., PReasM). Our work
thus shows how one can effectively use decomposition-guided contexts to
robustly teach multihop reasoning.</p>
  </details>
</details>
<details>
  <summary>67. <b>标题：ToKen: Task Decomposition and Knowledge Infusion for Few-Shot Hate  Speech Detection</b></summary>
  <p><b>编号</b>：[202]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12495</p>
  <p><b>作者</b>：Badr AlKhamissi,  Faisal Ladhak,  Srini Iyer,  Ves Stoyanov,  Zornitsa Kozareva,  Xian Li,  Pascale Fung,  Lambert Mathias,  Asli Celikyilmaz,  Mona Diab</p>
  <p><b>备注</b>：Preprint</p>
  <p><b>关键词</b>：Hate speech detection, detection is complex, hate speech annotated, large-scale hate speech, Hate speech</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Hate speech detection is complex; it relies on commonsense reasoning,
knowledge of stereotypes, and an understanding of social nuance that differs
from one culture to the next. It is also difficult to collect a large-scale
hate speech annotated dataset. In this work, we frame this problem as a
few-shot learning task, and show significant gains with decomposing the task
into its "constituent" parts. In addition, we see that infusing knowledge from
reasoning datasets (e.g. Atomic2020) improves the performance even further.
Moreover, we observe that the trained models generalize to out-of-distribution
datasets, showing the superiority of task decomposition and knowledge infusion
compared to previously used methods. Concretely, our method outperforms the
baseline by 17.83% absolute gain in the 16-shot case.</p>
  </details>
</details>
<details>
  <summary>68. <b>标题：Fine-grained Contrastive Learning for Relation Extraction</b></summary>
  <p><b>编号</b>：[205]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12491</p>
  <p><b>作者</b>：William Hogan,  Jiacheng Li,  Jingbo Shang</p>
  <p><b>备注</b>：8 pages, 4 figures</p>
  <p><b>关键词</b>：shown encouraging improvements, Recent relation extraction, silver labels, conducting contrastive learning, silver labels generated</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent relation extraction (RE) works have shown encouraging improvements by
conducting contrastive learning on silver labels generated by distant
supervision before fine-tuning on gold labels. Existing methods typically
assume all these silver labels are accurate and therefore treat them equally in
contrastive learning; however, distant supervision is inevitably noisy -- some
silver labels are more reliable than others. In this paper, we first assess the
quality of silver labels via a simple and automatic approach we call "learning
order denoising," where we train a language model to learn these relations and
record the order of learned training instances. We show that learning order
largely corresponds to label accuracy -- early learned silver labels have, on
average, more accurate labels compared to later learned silver labels. We then
propose a novel fine-grained contrastive learning (FineCL) for RE, which
leverages this additional, fine-grained information about which silver labels
are and are not noisy to improve the quality of learned relationship
representations for RE. Experiments on many RE benchmarks show consistent,
significant performance gains of FineCL over state-of-the-art methods.</p>
  </details>
</details>
<details>
  <summary>69. <b>标题：Improve Event Extraction via Self-Training with Gradient Guidance</b></summary>
  <p><b>编号</b>：[206]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12490</p>
  <p><b>作者</b>：Zhiyang Xu,  Lifu Huang</p>
  <p><b>备注</b>：9 pages, 4 figures</p>
  <p><b>关键词</b>：base event extraction, Abstract Meaning Representation, event extraction, event extraction model, event</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Data scarcity and imbalance have been the main factors that hinder the
progress of event extraction (EE). In this work, we propose a self-training
with gradient guidance (STGG) framework which consists of (1) a base event
extraction model which is firstly trained on existing event annotations and
then applied to large-scale unlabeled corpora to predict new event mentions,
and (2) a scoring model that takes in each predicted event trigger and argument
as well as their path in the Abstract Meaning Representation (AMR) graph to
estimate a probability score indicating the correctness of the event
prediction. The new event predictions along with their correctness scores are
then used as pseudo labeled examples to improve the base event extraction model
while the magnitude and direction of its gradients are guided by the
correctness scores. Experimental results on three benchmark datasets, including
ACE05-E, ACE05-E+ and ERE-EN, demonstrate the effectiveness of the STGG
framework on event extraction task with up to 1.9 F-score improvement over the
base event extraction models. Our experimental analysis further shows that STGG
is a general framework as it can be applied to any base event extraction models
and improve their performance by leveraging broad unlabeled data, even when the
high-quality AMR graph annotations are not available.</p>
  </details>
</details>
<details>
  <summary>70. <b>标题：End-to-End Multimodal Fact-Checking and Explanation Generation: A  Challenging Dataset and Models</b></summary>
  <p><b>编号</b>：[207]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12487</p>
  <p><b>作者</b>：Barry Menglong Yao (1),  Aditya Shah (2),  Lichao Sun (3),  Jin-Hee Cho (2),  Lifu Huang (2) ((1) University at Buffalo, (2) Virginia Tech, (3) Lehigh University)</p>
  <p><b>备注</b>：12 pages, 4 figures</p>
  <p><b>关键词</b>：retrieving relevant evidence, truthfulness label, multimodal fact-checking, including articles, web sources</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose the end-to-end multimodal fact-checking and explanation
generation, where the input is a claim and a large collection of web sources,
including articles, images, videos, and tweets, and the goal is to assess the
truthfulness of the claim by retrieving relevant evidence and predicting a
truthfulness label (i.e., support, refute and not enough information), and
generate a rationalization statement to explain the reasoning and ruling
process. To support this research, we construct Mocheg, a large-scale dataset
that consists of 21,184 claims where each claim is assigned with a truthfulness
label and ruling statement, with 58,523 evidence in the form of text and
images. To establish baseline performances on Mocheg, we experiment with
several state-of-the-art neural architectures on the three pipelined subtasks:
multimodal evidence retrieval, claim verification, and explanation generation,
and demonstrate the current state-of-the-art performance of end-to-end
multimodal fact-checking is still far from satisfying. To the best of our
knowledge, we are the first to build the benchmark dataset and solutions for
end-to-end multimodal fact-checking and justification.</p>
  </details>
</details>
<details>
  <summary>71. <b>标题：Factorizing Content and Budget Decisions in Abstractive Summarization of  Long Documents by Sampling Summary Views</b></summary>
  <p><b>编号</b>：[208]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12486</p>
  <p><b>作者</b>：Marcio Fonseca,  Yftah Ziser,  Shay B. Cohen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：salient content improves, cover salient content, argue that disentangling, cover salient, abstractive summarizers</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We argue that disentangling content selection from the budget used to cover
salient content improves the performance and applicability of abstractive
summarizers. Our method, FactorSum, does this disentanglement by factorizing
summarization into two steps through an energy function: (1) generation of
abstractive summary views; (2) combination of these views into a final summary,
following a budget and content guidance. This guidance may come from different
sources, including from an advisor model such as BART or BigBird, or in oracle
mode -- from the reference. This factorization achieves significantly higher
ROUGE scores on multiple benchmarks for long document summarization, namely
PubMed, arXiv, and GovReport. Most notably, our model is effective for domain
adaptation. When trained only on PubMed samples, it achieves a 46.29 ROUGE-1
score on arXiv, which indicates a strong performance due to more flexible
budget adaptation and content selection less dependent on domain-specific
textual structure.</p>
  </details>
</details>
<details>
  <summary>72. <b>标题：Conditional set generation using Seq2seq models</b></summary>
  <p><b>编号</b>：[209]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12485</p>
  <p><b>作者</b>：Aman Madaan,  Dheeraj Rajagopal,  Niket Tandon,  Yiming Yang,  Antoine Bosselut</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Conditional set generation, set generation learns, set generation, learns a mapping, set</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Conditional set generation learns a mapping from an input sequence of tokens
to a set. Several NLP tasks, such as entity typing and dialogue emotion
tagging, are instances of set generation. Sequence-to-sequence~(Seq2seq) models
are a popular choice to model set generation, but they treat a set as a
sequence and do not fully leverage its key properties, namely order-invariance
and cardinality. We propose a novel algorithm for effectively sampling
informative orders over the combinatorial space of label orders. Further, we
jointly model the set cardinality and output by adding the set size as the
first element and taking advantage of the autoregressive factorization used by
Seq2seq models. Our method is a model-independent data augmentation approach
that endows any Seq2seq model with the signals of order-invariance and
cardinality. Training a Seq2seq model on this new augmented data~(without any
additional annotations) gets an average relative improvement of 20% for four
benchmarks datasets across models spanning from BART-base, T5-xxl, and GPT-3.</p>
  </details>
</details>
<details>
  <summary>73. <b>标题：GisPy: A Tool for Measuring Gist Inference Score in Text</b></summary>
  <p><b>编号</b>：[210]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12484</p>
  <p><b>作者</b>：Pedram Hosseini,  Christopher R. Wolfe,  Mona Diab,  David A. Broniatowski</p>
  <p><b>备注</b>：Accepted to the 4th Workshop on Narrative Understanding @ NAACL 2022</p>
  <p><b>关键词</b>：Decision making theories, Fuzzy-Trace Theory, suggest that individuals, bottom-line meaning, Gist Inference Score</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Decision making theories such as Fuzzy-Trace Theory (FTT) suggest that
individuals tend to rely on gist, or bottom-line meaning, in the text when
making decisions. In this work, we delineate the process of developing GisPy,
an open-source tool in Python for measuring the Gist Inference Score (GIS) in
text. Evaluation of GisPy on documents in three benchmarks from the news and
scientific text domains demonstrates that scores generated by our tool
significantly distinguish low vs. high gist documents. Our tool is publicly
available to use at: this https URL.</p>
  </details>
</details>
<details>
  <summary>74. <b>标题：Leveraging Locality in Abstractive Text Summarization</b></summary>
  <p><b>编号</b>：[211]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12476</p>
  <p><b>作者</b>：Yixin Liu,  Ansong Ni,  Linyong Nan,  Budhaditya Deb,  Chenguang Zhu,  Ahmed H. Awadallah,  Dragomir Radev</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：language generation tasks, natural language generation, quadratic memory complexity, input length hinders, neural attention models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Despite the successes of neural attention models for natural language
generation tasks, the quadratic memory complexity of the self-attention module
with respect to the input length hinders their applications in long text
summarization. Instead of designing more efficient attention modules, we
approach this problem by investigating if models with a restricted context can
have competitive performance compared with the memory-efficient attention
models that maintain a global context by treating the input as an entire
sequence. Our model is applied to individual pages, which contain parts of
inputs grouped by the principle of locality, during both encoding and decoding
stages. We empirically investigated three kinds of localities in text
summarization at different levels, ranging from sentences to documents. Our
experimental results show that our model can have better performance compared
with strong baseline models with efficient attention modules, and our analysis
provides further insights of our locality-aware modeling strategy.</p>
  </details>
</details>
<details>
  <summary>75. <b>标题：Low Resource Style Transfer via Domain Adaptive Meta Learning</b></summary>
  <p><b>编号</b>：[212]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12475</p>
  <p><b>作者</b>：Xiangyang Li,  Xiang Long,  Yu Xia,  Sujian Li</p>
  <p><b>备注</b>：Accept in NAACL 2022(oral)</p>
  <p><b>关键词</b>：Text style transfer, style transfer, Adversarial Transfer Model, practical success, Text style</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Text style transfer (TST) without parallel data has achieved some practical
success. However, most of the existing unsupervised text style transfer methods
suffer from (i) requiring massive amounts of non-parallel data to guide
transferring different text styles. (ii) colossal performance degradation when
fine-tuning the model in new domains. In this work, we propose DAML-ATM (Domain
Adaptive Meta-Learning with Adversarial Transfer Model), which consists of two
parts: DAML and ATM. DAML is a domain adaptive meta-learning approach to learn
general knowledge in multiple heterogeneous source domains, capable of adapting
to new unseen domains with a small amount of data. Moreover, we propose a new
unsupervised TST approach Adversarial Transfer Model (ATM), composed of a
sequence-to-sequence pre-trained language model and uses adversarial style
training for better content preservation and style transfer. Results on
multi-domain datasets demonstrate that our approach generalizes well on unseen
low-resource domains, achieving state-of-the-art results against ten strong
baselines.</p>
  </details>
</details>
<details>
  <summary>76. <b>标题：Learning a Better Initialization for Soft Prompts via Meta-Learning</b></summary>
  <p><b>编号</b>：[215]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12471</p>
  <p><b>作者</b>：Yukun Huang,  Kun Qian,  Zhou Yu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：adapting pre-trained language, pre-trained language models, Prompt tuning, effective approach, approach to adapting</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Prompt tuning (PT) is an effective approach to adapting pre-trained language
models to downstream tasks. Without a good initialization, prompt tuning
doesn't perform well under few-shot settings. So pre-trained prompt tuning
(PPT) is proposed to initialize prompts by leveraging pre-training data. We
propose MetaPT (Meta-learned Prompt Tuning) to further improve PPT's
initialization by considering latent structure within the pre-training data.
Specifically, we introduce the structure by first clustering pre-training data
into different auxiliary tasks with unsupervised methods. Then we use these
tasks to pre-train prompts with a meta-learning algorithm. Such a process can
make prompts learn a better initialization by discovering commonalities among
these auxiliary tasks. We evaluate our method on seven downstream tasks. Our
MetaPT achieves better and more stable performance than the state-of-the-art
method.</p>
  </details>
</details>
<details>
  <summary>77. <b>标题：Logical Satisfiability of Counterfactuals for Faithful Explanations in  NLI</b></summary>
  <p><b>编号</b>：[217]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12469</p>
  <p><b>作者</b>：Suzanna Sia,  Anton Belyy,  Amjad Almahairi,  Madian Khabsa,  Luke Zettlemoyer,  Lambert Mathias</p>
  <p><b>备注</b>：Under Review</p>
  <p><b>关键词</b>：interpretability and diagnosing, faithfulness is desired, diagnosing the sources, model errors, explanation faithfulness</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Evaluating an explanation's faithfulness is desired for many reasons such as
trust, interpretability and diagnosing the sources of model's errors. In this
work, which focuses on the NLI task, we introduce the methodology of
Faithfulness-through-Counterfactuals, which first generates a counterfactual
hypothesis based on the logical predicates expressed in the explanation, and
then evaluates if the model's prediction on the counterfactual is consistent
with that expressed logic (i.e. if the new formula is \textit{logically
satisfiable}). In contrast to existing approaches, this does not require any
explanations for training a separate verification model. We first validate the
efficacy of automatic counterfactual hypothesis generation, leveraging on the
few-shot priming paradigm. Next, we show that our proposed metric distinguishes
between human-model agreement and disagreement on new counterfactual input. In
addition, we conduct a sensitivity analysis to validate that our metric is
sensitive to unfaithful explanations.</p>
  </details>
</details>
<details>
  <summary>78. <b>标题：R2D2: Robust Data-to-Text with Replacement Detection</b></summary>
  <p><b>编号</b>：[219]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12467</p>
  <p><b>作者</b>：Linyong Nan,  Lorenzo Jaime Yu Flores,  Yilun Zhao,  Yixin Liu,  Luke Benson,  Weijin Zou,  Dragomir Radev</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Unfaithful text generation, common problem, text generation, text, Unfaithful text</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Unfaithful text generation is a common problem for text generation systems.
In the case of Data-to-Text (D2T) systems, the factuality of the generated text
is particularly crucial for any real-world applications. We introduce R2D2, a
training framework that addresses unfaithful Data-to-Text generation by
training a system both as a generator and a faithfulness discriminator with
additional replacement detection and unlikelihood learning tasks. To facilitate
such training, we propose two methods for sampling unfaithful sentences. We
argue that the poor entity retrieval capability of D2T systems is one of the
primary sources of unfaithfulness, so in addition to the existing metrics, we
further propose NER-based metrics to evaluate the fidelity of D2T generations.
Our experimental results show that R2D2 systems could effectively mitigate the
unfaithful text generation, and they achieve new state-of-the-art results on
FeTaQA, LogicNLG, and ToTTo, all with significant improvements.</p>
  </details>
</details>
<details>
  <summary>79. <b>标题：Improving CTC-based ASR Models with Gated Interlayer Collaboration</b></summary>
  <p><b>编号</b>：[223]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12462</p>
  <p><b>作者</b>：Yuting Yang,  Yuke Li,  Binbin Du</p>
  <p><b>备注</b>：Submitted to INTERSPEECH2022</p>
  <p><b>关键词</b>：Automatic Speech Recognition, Speech Recognition, Automatic Speech, non-autoregressive inference manner, dominant paradigm due</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>For Automatic Speech Recognition (ASR), the CTC-based methods have become a
dominant paradigm due to its simple architecture and efficient
non-autoregressive inference manner. However, these methods without external
language models usually lack the capacity of modeling the conditional
dependencies and the textual interaction. In this work, we present a Gated
Interlayer Collaboration (GIC) mechanism which introduces the contextual
information into the models and relaxes the conditional independence assumption
of the CTC-based models. Specifically, we train the model with intermediate CTC
losses calculated by the interlayer outputs of the model, in which the
probability distributions of the intermediate layers naturally serve as soft
label sequences. The GIC block consists of an embedding layer to obtain the
textual embedding of the soft label at each position, and a gate unit to fuse
the textual embedding and the acoustic features. Experiments on AISHELL-1 and
AIDATATANG benchmarks show that the proposed method outperforms the recently
published CTC-based ASR models. Specifically, our method achieves CER of
4.0%/4.4% on AISHELL-1 dev/test sets and CER of 3.8%/4.4% on AIDATATANG
dev/test sets using CTC greedy search decoding without external language
models.</p>
  </details>
</details>
<details>
  <summary>80. <b>标题：Investigating Information Inconsistency in Multilingual Open-Domain  Question Answering</b></summary>
  <p><b>编号</b>：[227]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12456</p>
  <p><b>作者</b>：Shramay Palta,  Haozhe An,  Yifan Yang,  Shuaiyi Huang,  Maharshi Gor</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：find best-answer candidates, best-answer candidates, retrieved documents, answer-span selection, find best-answer</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Retrieval based open-domain QA systems use retrieved documents and
answer-span selection over retrieved documents to find best-answer candidates.
We hypothesize that multilingual Question Answering (QA) systems are prone to
information inconsistency when it comes to documents written in different
languages, because these documents tend to provide a model with varying
information about the same topic. To understand the effects of the biased
availability of information and cultural influence, we analyze the behavior of
multilingual open-domain question answering models with a focus on retrieval
bias. We analyze if different retriever models present different passages given
the same question in different languages on TyDi QA and XOR-TyDi QA, two
multilingualQA datasets. We speculate that the content differences in documents
across languages might reflect cultural divergences and/or social biases.</p>
  </details>
</details>
<details>
  <summary>81. <b>标题：Know Where You're Going: Meta-Learning for Parameter-Efficient  Fine-tuning</b></summary>
  <p><b>编号</b>：[229]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12453</p>
  <p><b>作者</b>：Mozhdeh Gheini,  Xuezhe Ma,  Jonathan May</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：facilitates parameter-efficient transfer, language model frozen, parameter-efficient transfer learning, lightweight fine-tuning methods, additional parameters</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A recent family of techniques, dubbed as lightweight fine-tuning methods,
facilitates parameter-efficient transfer learning by updating only a small set
of additional parameters while keeping the parameters of the pretrained
language model frozen. While proven to be an effective method, there are no
existing studies on if and how such knowledge of the downstream fine-tuning
approach should affect the pretraining stage. In this work, we show that taking
the ultimate choice of fine-tuning method into consideration boosts the
performance of parameter-efficient fine-tuning. By relying on
optimization-based meta-learning using MAML with certain modifications for our
distinct purpose, we prime the pretrained model specifically for
parameter-efficient fine-tuning, resulting in gains of up to 1.7 points on
cross-lingual NER fine-tuning. Our ablation settings and analyses further
reveal that the tweaks we introduce in MAML are crucial for the attained gains.</p>
  </details>
</details>
<details>
  <summary>82. <b>标题：Sparse*BERT: Sparse Models are Robust</b></summary>
  <p><b>编号</b>：[230]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12452</p>
  <p><b>作者</b>：Daniel Campos,  Alexandre Marques,  Tuan Nguyen,  Mark Kurtz,  ChengXiang Zhai</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：natural language processing, modern natural language, Large Language Models, systems build, modern natural</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large Language Models have become the core architecture upon which most
modern natural language processing (NLP) systems build. These models can
consistently deliver impressive accuracy and robustness across tasks and
domains, but their high computational overhead can make inference difficult and
expensive. To make the usage of these models less costly recent work has
explored leveraging structured and unstructured pruning, quantization, and
distillation as ways to improve inference speed and decrease size. This paper
studies how models pruned using Gradual Unstructured Magnitude Pruning can
transfer between domains and tasks. Our experimentation shows that models that
are pruned during pretraining using general domain masked language models can
transfer to novel domains and tasks without extensive hyperparameter
exploration or specialized approaches. We demonstrate that our general sparse
model Sparse*BERT can become SparseBioBERT simply by pretraining the compressed
architecture on unstructured biomedical text. Moreover, we show that
SparseBioBERT can match the quality of BioBERT with only 10\% of the
parameters.</p>
  </details>
</details>
<details>
  <summary>83. <b>标题：FLEURS: Few-shot Learning Evaluation of Universal Representations of  Speech</b></summary>
  <p><b>编号</b>：[234]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12446</p>
  <p><b>作者</b>：Alexis Conneau,  Min Ma,  Simran Khanuja,  Yu Zhang,  Vera Axelrod,  Siddharth Dalmia,  Jason Riesa,  Clara Rivera,  Ankur Bapna</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Few-shot Learning Evaluation, Evaluation of Universal, Few-shot Learning, Learning Evaluation, Speech</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We introduce FLEURS, the Few-shot Learning Evaluation of Universal
Representations of Speech benchmark. FLEURS is an n-way parallel speech dataset
in 102 languages built on top of the machine translation FLoRes-101 benchmark,
with approximately 12 hours of speech supervision per language. FLEURS can be
used for a variety of speech tasks, including Automatic Speech Recognition
(ASR), Speech Language Identification (Speech LangID), Translation and
Retrieval. In this paper, we provide baselines for the tasks based on
multilingual pre-trained models like mSLAM. The goal of FLEURS is to enable
speech technology in more languages and catalyze research in low-resource
speech understanding.</p>
  </details>
</details>
<details>
  <summary>84. <b>标题：Generating Natural Language Proofs with Verifier-Guided Search</b></summary>
  <p><b>编号</b>：[235]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12443</p>
  <p><b>作者</b>：Kaiyu Yang,  Jia Deng,  Danqi Chen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：problem in NLP, Deductive reasoning, drawing conclusions, conclusions from assumptions, natural language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deductive reasoning (drawing conclusions from assumptions) is a challenging
problem in NLP. In this work, we focus on proof generation: given a hypothesis
and a set of supporting facts in natural language, the model generates a proof
tree indicating how to deduce the hypothesis from supporting facts. Instead of
generating the entire proof in one shot, prior work has demonstrated the
promise of stepwise generation but achieved limited success on real-world data.
Existing stepwise methods struggle to generate proof steps that are both valid
and relevant. In this paper, we present a novel stepwise method NLProofS
(Natural Language Proof Search), which learns to generate relevant steps
conditioning on the hypothesis. At the core of our approach, we train an
independent verifier to check the validity of proof steps. Instead of
generating steps greedily, we search for proofs maximizing a global proof score
judged by the verifier. NLProofS achieves state-of-the-art performance on
EntailmentBank and RuleTaker. For example, it improves the percentage of
correctly predicted proofs from 20.9% to 33.3% in the distractor setting of
EntailmentBank. This is the first time stepwise methods have led to better
generation of challenging human-authored proofs.</p>
  </details>
</details>
<details>
  <summary>85. <b>标题：Towards Understanding Label Regularization for Fine-tuning Pre-trained  Language Models</b></summary>
  <p><b>编号</b>：[237]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12428</p>
  <p><b>作者</b>：Ivan Kobyzev,  Aref Jafari,  Mehdi Rezagholizadeh,  Tianda Li,  Alan Do-Omri,  Peng Lu,  Ali Ghodsi,  Pascal Poupart</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：neural model compression, prominent neural model, Knowledge Distillation, teacher network predictions, model compression technique</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Knowledge Distillation (KD) is a prominent neural model compression technique
which heavily relies on teacher network predictions to guide the training of a
student model. Considering the ever-growing size of pre-trained language models
(PLMs), KD is often adopted in many NLP tasks involving PLMs. However, it is
evident that in KD, deploying the teacher network during training adds to the
memory and computational requirements of training. In the computer vision
literature, the necessity of the teacher network is put under scrutiny by
showing that KD is a label regularization technique that can be replaced with
lighter teacher-free variants such as the label-smoothing technique. However,
to the best of our knowledge, this issue is not investigated in NLP. Therefore,
this work concerns studying different label regularization techniques and
whether we actually need the teacher labels to fine-tune smaller PLM student
networks on downstream tasks. In this regard, we did a comprehensive set of
experiments on different PLMs such as BERT, RoBERTa, and GPT with more than 600
distinct trials and ran each configuration five times. This investigation led
to a surprising observation that KD and other label regularization techniques
do not play any meaningful role over regular fine-tuning when the student model
is pre-trained. We further explore this phenomenon in different settings of NLP
and computer vision tasks and demonstrate that pre-training itself acts as a
kind of regularization, and additional label regularization is unnecessary.</p>
  </details>
</details>
<details>
  <summary>86. <b>标题：Active Programming by Example with a Natural Language Prior</b></summary>
  <p><b>编号</b>：[242]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12422</p>
  <p><b>作者</b>：Ruiqi Zhong,  Charlie Snell,  Dan Klein,  Jason Eisner</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：executable meaning representations, indirectly annotate natural, annotate natural language, introduce APEL, natural language utterances</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We introduce APEL, a new framework that enables non-programmers to indirectly
annotate natural language utterances with executable meaning representations,
such as SQL programs. Based on a natural language utterance, we first run a
seed semantic parser to generate a prior over a list of candidate programs. To
obtain information about which candidate is correct, we synthesize an input on
which the more likely programs tend to produce different outputs, and ask an
annotator which output is appropriate for the utterance. Hence, the annotator
does not have to directly inspect the programs. To further reduce effort
required from annotators, we aim to synthesize simple input databases that
nonetheless have high information gain. With human annotators and Bayesian
inference to handle annotation errors, we outperform Codex's top-1 performance
(59%) and achieve the same accuracy as the original expert annotators (75%), by
soliciting answers for each utterance on only 2 databases with an average of 9
records each. In contrast, it would be impractical to solicit outputs on the
original 30K-record databases provided by SPIDER</p>
  </details>
</details>
<details>
  <summary>87. <b>标题：Learning Action Conditions from Instructional Manuals for Instruction  Understanding</b></summary>
  <p><b>编号</b>：[244]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12420</p>
  <p><b>作者</b>：Te-Lin Wu,  Caiqi Zhang,  Qingyuan Hu,  Alex Spangher,  Nanyun Peng</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：autonomous instruction-guided agents, perform physical tasks, comprehending complex instructions, vital for comprehending, comprehending complex</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The ability to infer pre- and postconditions of an action is vital for
comprehending complex instructions, and is essential for applications such as
autonomous instruction-guided agents and assistive AI that supports humans to
perform physical tasks. In this work, we propose a task dubbed action condition
inference, and collecting a high-quality, human annotated dataset of
preconditions and postconditions of actions in instructional manuals. We
propose a weakly supervised approach to automatically construct large-scale
training instances from online instructional manuals, and curate a densely
human-annotated and validated dataset to study how well the current NLP models
can infer action-condition dependencies in the instruction texts. We design two
types of models differ by whether contextualized and global information is
leveraged, as well as various combinations of heuristics to construct the weak
supervisions. Our experimental results show a >20% F1-score improvement with
considering the entire instruction contexts and a >6% F1-score benefit with the
proposed heuristics.</p>
  </details>
</details>
<details>
  <summary>88. <b>标题：Counterfactual Data Augmentation improves Factuality of Abstractive  Summarization</b></summary>
  <p><b>编号</b>：[246]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12416</p>
  <p><b>作者</b>：Dheeraj Rajagopal,  Siamak Shakeri,  Cicero Nogueira dos Santos,  Eduard Hovy,  Chung-Ching Chang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：factually inconsistent sentences, pretrained language models, Abstractive summarization systems, inconsistent sentences, pretrained language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Abstractive summarization systems based on pretrained language models often
generate coherent but factually inconsistent sentences. In this paper, we
present a counterfactual data augmentation approach where we augment data with
perturbed summaries that increase the training data diversity. Specifically, we
present three augmentation approaches based on replacing (i) entities from
other and the same category and (ii) nouns with their corresponding WordNet
hypernyms. We show that augmenting the training data with our approach improves
the factual correctness of summaries without significantly affecting the ROUGE
score. We show that in two commonly used summarization datasets (CNN/Dailymail
and XSum), we improve the factual correctness by about 2.5 points on average</p>
  </details>
</details>
<details>
  <summary>89. <b>标题：Linear Connectivity Reveals Generalization Strategies</b></summary>
  <p><b>编号</b>：[248]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12411</p>
  <p><b>作者</b>：Jeevesh Juneja,  Rachit Bansal,  Kyunghyun Cho,  João Sedoc,  Naomi Saphra</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：mode connectivity literature, test set accuracy, accuracy is maintained, widely accepted, mode connectivity</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>It is widely accepted in the mode connectivity literature that when two
neural networks are trained similarly on the same data, they are connected by a
path through parameter space over which test set accuracy is maintained. Under
some circumstances, including transfer learning from pretrained models, these
paths are presumed to be linear. In contrast to existing results, we find that
among text classifiers (trained on MNLI, QQP, and CoLA), some pairs of
finetuned models have large barriers of increasing loss on the linear paths
between them. On each task, we find distinct clusters of models which are
linearly connected on the test loss surface, but are disconnected from models
outside the cluster -- models that occupy separate basins on the surface. By
measuring performance on specially-crafted diagnostic datasets, we find that
these clusters correspond to different generalization strategies: one cluster
behaves like a bag of words model under domain shift, while another cluster
uses syntactic heuristics. Our work demonstrates how the geometry of the loss
surface can guide models towards different heuristic functions.</p>
  </details>
</details>
<details>
  <summary>90. <b>标题：AdaMix: Mixture-of-Adapter for Parameter-efficient Tuning of Large  Language Models</b></summary>
  <p><b>编号</b>：[249]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12410</p>
  <p><b>作者</b>：Yaqing Wang,  Subhabrata Mukherjee,  Xiaodong Liu,  Jing Gao,  Ahmed Hassan Awadallah,  Jianfeng Gao</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：require updating hundreds, downstream tasks require, tasks require updating, adapter, require updating</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Fine-tuning large-scale pre-trained language models to downstream tasks
require updating hundreds of millions of parameters. This not only increases
the serving cost to store a large copy of the model weights for every task, but
also exhibits instability during few-shot task adaptation. Parameter-efficient
techniques have been developed that tune small trainable components (e.g.,
adapters) injected in the large model while keeping most of the model weights
frozen. The prevalent mechanism to increase adapter capacity is to increase the
bottleneck dimension which increases the adapter parameters. In this work, we
introduce a new mechanism to improve adapter capacity without increasing
parameters or computational cost by two key techniques. (i) We introduce
multiple shared adapter components in each layer of the Transformer
architecture. We leverage sparse learning via random routing to update the
adapter parameters (encoder is kept frozen) resulting in the same amount of
computational cost (FLOPs) as that of training a single adapter. (ii) We
propose a simple merging mechanism to average the weights of multiple adapter
components to collapse to a single adapter in each Transformer layer, thereby,
keeping the overall parameters also the same but with significant performance
improvement. We demonstrate these techniques to work well across multiple task
settings including fully supervised and few-shot Natural Language Understanding
tasks. By only tuning 0.23% of a pre-trained language model's parameters, our
model outperforms the full model fine-tuning performance and several competing
methods.</p>
  </details>
</details>
<details>
  <summary>91. <b>标题：FLUTE: Figurative Language Understanding and Textual Explanations</b></summary>
  <p><b>编号</b>：[253]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12404</p>
  <p><b>作者</b>：Tuhin Chakrabarty,  Arkadiy Saakyan,  Debanjan Ghosh,  Smaranda Muresan</p>
  <p><b>备注</b>：Work in progress</p>
  <p><b>关键词</b>：transformer-based models struggle, struggle to demonstrate, figurative language, language, figurative</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In spite of the prevalence of figurative language, transformer-based models
struggle to demonstrate an understanding of it. Meanwhile, even classical
natural language inference (NLI) tasks have been plagued by spurious
correlations and annotation artifacts. Datasets like eSNLI have been released,
allowing to probe whether language models are right for the right reasons. Yet
no such data exists for figurative language, making it harder to asses genuine
understanding of such expressions. In light of the above, we release FLUTE, a
dataset of 8,000 figurative NLI instances with explanations, spanning three
categories: Sarcasm, Simile, and Metaphor. We collect the data through the
Human-AI collaboration framework based on GPT-3, crowdworkers, and expert
annotation. We show how utilizing GPT-3 in conjunction with human experts can
aid in scaling up the creation of datasets even for such complex linguistic
phenomena as figurative language. Baseline performance of the T5 model shows
our dataset is a challenging testbed for figurative language understanding.</p>
  </details>
</details>
<details>
  <summary>92. <b>标题：Sparse Mixers: Combining MoE and Mixing to build a more efficient BERT</b></summary>
  <p><b>编号</b>：[257]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12399</p>
  <p><b>作者</b>：James Lee-Thorp,  Joshua Ainslie</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Sparse Mixer, Fast Sparse Mixer, sparsely gated, Sparse, Sparse Mixer slightly</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We combine the capacity of sparsely gated Mixture-of-Experts (MoE) with the
speed and stability of linear, mixing transformations to design the Sparse
Mixer encoder model. The Sparse Mixer slightly outperforms (<1%) bert on glue and superglue, but more importantly trains 65% faster runs inference 61% faster. we also present a variant, prosaically named fast sparse mixer, that marginally underperforms (<0.2%) nearly twice as fast: 89% training 98% inference. justify the design of these two models by carefully ablating through various mixing mechanisms, moe configurations model hyperparameters. mixer overcomes many latency stability concerns offers prospect serving student models, without resorting to distilling them dense variants.< p>
  </1%)></p></details>
</details>
<details>
  <summary>93. <b>标题：Recipe2Vec: Multi-modal Recipe Representation Learning with Graph Neural  Networks</b></summary>
  <p><b>编号</b>：[259]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12396</p>
  <p><b>作者</b>：Yijun Tian,  Chuxu Zhang,  Zhichun Guo,  Yihong Ma,  Ronald Metoyer,  Nitesh V. Chawla</p>
  <p><b>备注</b>：Accepted by IJCAI 2022</p>
  <p><b>关键词</b>：effective recipe representations, recipe, Learning effective recipe, Learning, multi-modal recipe representation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Learning effective recipe representations is essential in food studies.
Unlike what has been developed for image-based recipe retrieval or learning
structural text embeddings, the combined effect of multi-modal information
(i.e., recipe images, text, and relation data) receives less attention. In this
paper, we formalize the problem of multi-modal recipe representation learning
to integrate the visual, textual, and relational information into recipe
embeddings. In particular, we first present Large-RG, a new recipe graph data
with over half a million nodes, making it the largest recipe graph to date. We
then propose Recipe2Vec, a novel graph neural network based recipe embedding
model to capture multi-modal information. Additionally, we introduce an
adversarial attack strategy to ensure stable learning and improve performance.
Finally, we design a joint objective function of node classification and
adversarial learning to optimize the model. Extensive experiments demonstrate
that Recipe2Vec outperforms state-of-the-art baselines on two classic food
study tasks, i.e., cuisine category classification and region prediction.
Dataset and codes are available at this https URL.</p>
  </details>
</details>
<details>
  <summary>94. <b>标题：MaskEval: Weighted MLM-Based Evaluation for Text Summarization and  Simplification</b></summary>
  <p><b>编号</b>：[260]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12394</p>
  <p><b>作者</b>：Yu Lu Liu,  Rachel Bawden,  Thomas Scaliom,  Benoît Sagot,  Jackie Chi Kit Cheung</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：factual consistency, system outputs, evaluated along multiple, wide range, text summarization</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In text summarization and simplification, system outputs must be evaluated
along multiple dimensions such as relevance, factual consistency, fluency, and
grammaticality, and a wide range of possible outputs could be of high quality.
These properties make the development of an adaptable, reference-less
evaluation metric both necessary and challenging. We introduce MaskEval, a
reference-less metric for text summarization and simplification that operates
by performing masked language modeling (MLM) on the concatenation of the
candidate and the source texts. It features an attention-like weighting
mechanism to modulate the relative importance of each MLM step, which crucially
allows MaskEval to be adapted to evaluate different quality dimensions. We
demonstrate its effectiveness on English summarization and on multilingual text
simplification in terms of correlations with human judgments.</p>
  </details>
</details>
<details>
  <summary>95. <b>标题：Continual-T0: Progressively Instructing 50+ Tasks to Language Models  Without Forgetting</b></summary>
  <p><b>编号</b>：[261]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12393</p>
  <p><b>作者</b>：Thomas Scialom,  Tuhin Chakrabarty,  Smaranda Muresan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：natural language processing, natural language, natural language instructions, Recent work, language models relies</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent work on large language models relies on the intuition that most
natural language processing tasks can be described via natural language
instructions. Language models trained on these instructions show strong
zero-shot performance on several standard datasets. However, these models even
though impressive still perform poorly on a wide range of tasks outside of
their respective training and evaluation sets. To address this limitation, we
argue that a model should be able to keep extending its knowledge and
abilities, without forgetting previous skills. In spite of the limited success
of Continual Learning we show that Language Models can be continual learners.
We empirically investigate the reason for this success and conclude that
Continual Learning emerges from self-supervision pre-training. Our resulting
model Continual-T0 (CT0) is able to learn diverse new tasks, while still
maintaining good performance on previous tasks, spanning remarkably through 70
datasets in total. Finally, we show that CT0 is able to combine instructions in
ways it was never trained for, demonstrating some compositionality.</p>
  </details>
</details>
<details>
  <summary>96. <b>标题：Emergent Communication through Metropolis-Hastings Naming Game with Deep  Generative Models</b></summary>
  <p><b>编号</b>：[262]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12392</p>
  <p><b>作者</b>：Tadahiro Taniguchi,  Yuto Yoshida,  Akira Taniguchi,  Yoshinobu Hagiwara</p>
  <p><b>备注</b>：17 pages, 12 figures</p>
  <p><b>关键词</b>：explain human language, human language evolution, investigate computational models, seeks to investigate, investigate computational</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Emergent communication, also known as symbol emergence, seeks to investigate
computational models that can better explain human language evolution and the
creation of symbol systems. This study aims to provide a new model for emergent
communication, which is based on a probabilistic generative model. We define
the Metropolis-Hastings (MH) naming game by generalizing a model proposed by
Hagiwara et al. \cite{hagiwara2019symbol}. The MH naming game is a sort of MH
algorithm for an integrative probabilistic generative model that combines two
agents playing the naming game. From this viewpoint, symbol emergence is
regarded as decentralized Bayesian inference, and semiotic communication is
regarded as inter-personal cross-modal inference. We also offer Inter-GMM+VAE,
a deep generative model for simulating emergent communication, in which two
agents create internal representations and categories and share signs (i.e.,
names of objects) from raw visual images observed from different viewpoints.
The model has been validated on MNIST and Fruits 360 datasets. Experiment
findings show that categories are formed from real images observed by agents,
and signs are correctly shared across agents by successfully utilizing both of
the agents' views via the MH naming game. Furthermore, it has been verified
that the visual images were recalled from the signs uttered by the agents.
Notably, emergent communication without supervision and reward feedback
improved the performance of unsupervised representation learning.</p>
  </details>
</details>
<details>
  <summary>97. <b>标题：Toward Understanding Bias Correlations for Mitigation in NLP</b></summary>
  <p><b>编号</b>：[263]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12391</p>
  <p><b>作者</b>：Lu Cheng,  Suyu Ge,  Huan Liu</p>
  <p><b>备注</b>：11 pages, 5 figures</p>
  <p><b>关键词</b>：Natural Language Processing, Language Processing, Natural Language, found discriminative, Processing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Natural Language Processing (NLP) models have been found discriminative
against groups of different social identities such as gender and race. With the
negative consequences of these undesired biases, researchers have responded
with unprecedented effort and proposed promising approaches for bias
mitigation. In spite of considerable practical importance, current algorithmic
fairness literature lacks an in-depth understanding of the relations between
different forms of biases. Social bias is complex by nature. Numerous studies
in social psychology identify the "generalized prejudice", i.e., generalized
devaluing sentiments across different groups. For example, people who devalue
ethnic minorities are also likely to devalue women and gays. Therefore, this
work aims to provide a first systematic study toward understanding bias
correlations in mitigation. In particular, we examine bias mitigation in two
common NLP tasks -- toxicity detection and word embeddings -- on three social
identities, i.e., race, gender, and religion. Our findings suggest that biases
are correlated and present scenarios in which independent debiasing approaches
dominant in current literature may be insufficient. We further investigate
whether jointly mitigating correlated biases is more desired than independent
and individual debiasing. Lastly, we shed light on the inherent issue of
debiasing-accuracy trade-off in bias mitigation. This study serves to motivate
future research on joint bias mitigation that accounts for correlated biases.</p>
  </details>
</details>
<details>
  <summary>98. <b>标题：Toxicity Detection with Generative Prompt-based Inference</b></summary>
  <p><b>编号</b>：[264]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12390</p>
  <p><b>作者</b>：Yau-Shian Wang,  Yingshan Chang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：detecting undesirable content, nuanced difficulty, interpretations perceived, detecting undesirable, undesirable content</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Due to the subtleness, implicity, and different possible interpretations
perceived by different people, detecting undesirable content from text is a
nuanced difficulty. It is a long-known risk that language models (LMs), once
trained on corpus containing undesirable content, have the power to manifest
biases and toxicity. However, recent studies imply that, as a remedy, LMs are
also capable of identifying toxic content without additional fine-tuning.
Prompt-methods have been shown to effectively harvest this surprising
self-diagnosing capability. However, existing prompt-based methods usually
specify an instruction to a language model in a discriminative way. In this
work, we explore the generative variant of zero-shot prompt-based toxicity
detection with comprehensive trials on prompt engineering. We evaluate on three
datasets with toxicity labels annotated on social media posts. Our analysis
highlights the strengths of our generative classification approach both
quantitatively and qualitatively. Interesting aspects of self-diagnosis and its
ethical implications are discussed.</p>
  </details>
</details>
<details>
  <summary>99. <b>标题：PLAtE: A Large-scale Dataset for List Page Web Extraction</b></summary>
  <p><b>编号</b>：[266]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12386</p>
  <p><b>作者</b>：Aidan San,  Jan Bakus,  Colin Lockard,  David Ciemiewicz,  Yangfeng Ji,  Sandeep Atluri,  Kevin Small,  Heba Elfardy</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：semi-structured websites, leveraged to significantly, significantly improve, extraction, neural models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recently, neural models have been leveraged to significantly improve the
performance of information extraction from semi-structured websites. However, a
barrier for continued progress is the small number of datasets large enough to
train these models. In this work, we introduce the PLAtE (Pages of Lists
Attribute Extraction) dataset as a challenging new web extraction task. PLAtE
focuses on shopping data, specifically extractions from product review pages
with multiple items. PLAtE encompasses both the tasks of: (1) finding
product-list segmentation boundaries and (2) extracting attributes for each
product. PLAtE is composed of 53, 905 items from 6, 810 pages, making it the
first large-scale list page web extraction dataset. We construct PLAtE by
collecting list pages from Common Crawl, then annotating them on Mechanical
Turk. Quantitative and qualitative analyses are performed to demonstrate PLAtE
has high-quality annotations. We establish strong baseline performance on PLAtE
with a SOTA model achieving an F1-score of 0.750 for attribute classification
and 0.915 for segmentation, indicating opportunities for future research
innovations in web extraction.</p>
  </details>
</details>
<details>
  <summary>100. <b>标题：VoynaSlov: A Data Set of Russian Social Media Activity during the 2022  Ukraine-Russia War</b></summary>
  <p><b>编号</b>：[267]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12382</p>
  <p><b>作者</b>：Chan Young Park,  Julia Mendelsohn,  Anjalie Field,  Yulia Tsvetkov</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Russian-language social media, Russian media outlets, Russian social media, social media activities, Russian-language social</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this report, we describe a new data set called VoynaSlov which contains
21M+ Russian-language social media activities (i.e. tweets, posts, comments)
made by Russian media outlets and by the general public during the time of war
between Ukraine and Russia. We scraped the data from two major platforms that
are widely used in Russia: Twitter and VKontakte (VK), a Russian social media
platform based in Saint Petersburg commonly referred to as "Russian Facebook".
We provide descriptions of our data collection process and data statistics that
compare state-affiliated and independent Russian media, and also the two
platforms, VK and Twitter. The main differences that distinguish our data from
previously released data related to the ongoing war are its focus on Russian
media and consideration of state-affiliation as well as the inclusion of data
from VK, which is more suitable than Twitter for understanding Russian public
sentiment considering its wide use within Russia. We hope our data set can
facilitate future research on information warfare and ultimately enable the
reduction and prevention of disinformation and opinion manipulation campaigns.
The data set is available at this https URL and will be
regularly updated as we continuously collect more data.</p>
  </details>
</details>
<details>
  <summary>101. <b>标题：Learning to Model Editing Processes</b></summary>
  <p><b>编号</b>：[273]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12374</p>
  <p><b>作者</b>：Machel Reid,  Graham Neubig</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：existing sequence generation, generation models produce, models produce outputs, produce outputs, sequence generation models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Most existing sequence generation models produce outputs in one pass, usually
left-to-right. However, this is in contrast with a more natural approach that
humans use in generating content; iterative refinement and editing. Recent work
has introduced edit-based models for various tasks (such as neural machine
translation and text style transfer), but these generally model a single edit
step. In this work, we propose modeling editing processes, modeling the whole
process of iteratively generating sequences. We form a conceptual framework to
describe the likelihood of multi-step edits, and describe neural models that
can learn a generative model of sequences based on these multistep edits. We
introduce baseline results and metrics on this task, finding that modeling
editing processes improves performance on a variety of axes on both our
proposed task and related downstream tasks compared to previous single-step
models of edits.</p>
  </details>
</details>
<details>
  <summary>102. <b>标题：Medical Scientific Table-to-Text Generation with Human-in-the-Loop under  the Data Sparsity Constraint</b></summary>
  <p><b>编号</b>：[276]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12368</p>
  <p><b>作者</b>：Heng-Yi Wu,  Jingqing Zhang,  Julia Ive,  Tong Li,  Narges Tabari,  Bingyuan Chen,  Vibhor Gupta,  Yike Guo</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：drastically reduce manual, reduce manual efforts, preclinical and clinical, clinical domains, domains contains valuable</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Structured (tabular) data in the preclinical and clinical domains contains
valuable information about individuals and an efficient table-to-text
summarization system can drastically reduce manual efforts to condense this
data into reports. However, in practice, the problem is heavily impeded by the
data paucity, data sparsity and inability of the state-of-the-art natural
language generation models (including T5, PEGASUS and GPT-Neo) to produce
accurate and reliable outputs. In this paper, we propose a novel table-to-text
approach and tackle these problems with a novel two-step architecture which is
enhanced by auto-correction, copy mechanism and synthetic data augmentation.
The study shows that the proposed approach selects salient biomedical entities
and values from structured data with improved precision (up to 0.13 absolute
increase) of copying the tabular values to generate coherent and accurate text
for assay validation reports and toxicology reports. Moreover, we also
demonstrate a light-weight adaptation of the proposed system to new datasets by
fine-tuning with as little as 40\% training examples. The outputs of our model
are validated by human experts in the Human-in-the-Loop scenario.</p>
  </details>
</details>
<details>
  <summary>103. <b>标题：K-12BERT: BERT for K-12 education</b></summary>
  <p><b>编号</b>：[285]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12335</p>
  <p><b>作者</b>：Vasu Goel,  Dhruv Sahnan,  Venktesh V,  Gaurav Sharma,  Deep Dwivedi,  Mukesh Mohania</p>
  <p><b>备注</b>：4 pages</p>
  <p><b>关键词</b>：NLP pipelines, Online education platforms, content curation, platforms are powered, aid in content</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Online education platforms are powered by various NLP pipelines, which
utilize models like BERT to aid in content curation. Since the inception of the
pre-trained language models like BERT, there have also been many efforts toward
adapting these pre-trained models to specific domains. However, there has not
been a model specifically adapted for the education domain (particularly K-12)
across subjects to the best of our knowledge. In this work, we propose to train
a language model on a corpus of data curated by us across multiple subjects
from various sources for K-12 education. We also evaluate our model, K12-BERT,
on downstream tasks like hierarchical taxonomy tagging.</p>
  </details>
</details>
<details>
  <summary>104. <b>标题：Certified Robustness Against Natural Language Attacks by Causal  Intervention</b></summary>
  <p><b>编号</b>：[287]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12331</p>
  <p><b>作者</b>：Haiteng Zhao,  Chang Ma,  Xinshuai Dong,  Anh Tuan Luu,  Zhi-Hong Deng,  Hanwang Zhang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：achieved great success, Deep learning models, learning models, models have achieved, achieved great</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep learning models have achieved great success in many fields, yet they are
vulnerable to adversarial examples. This paper follows a causal perspective to
look into the adversarial vulnerability and proposes Causal Intervention by
Semantic Smoothing (CISS), a novel framework towards robustness against natural
language attacks. Instead of merely fitting observational data, CISS learns
causal effects p(y|do(x)) by smoothing in the latent semantic space to make
robust predictions, which scales to deep architectures and avoids tedious
construction of noise customized for specific attacks. CISS is provably robust
against word substitution attacks, as well as empirically robust even when
perturbations are strengthened by unknown attack algorithms. For example, on
YELP, CISS surpasses the runner-up by 6.7% in terms of certified robustness
against word substitutions, and achieves 79.4% empirical robustness when
syntactic attacks are integrated.</p>
  </details>
</details>
<details>
  <summary>105. <b>标题：Multilevel sentiment analysis in arabic</b></summary>
  <p><b>编号</b>：[288]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12328</p>
  <p><b>作者</b>：Ahmed Nassar,  Ebru Sezer</p>
  <p><b>备注</b>：10 pages, 3 figures, Published in: 2019 IEEE 7th Palestinian International Conference on Electrical and Computer Engineering (PICECE), Date of Conference: 26-27 March 2019</p>
  <p><b>关键词</b>：Arabic sentiment analysis, aimed to improve, improve the performance, sentiment analysis, level sentiment analysis</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this study, we aimed to improve the performance results of Arabic
sentiment analysis. This can be achieved by investigating the most successful
machine learning method and the most useful feature vector to classify
sentiments in both term and document levels into two (positive or negative)
categories. Moreover, specification of one polarity degree for the term that
has more than one is investigated. Also to handle the negations and
intensifications, some rules are developed. According to the obtained results,
Artificial Neural Network classifier is nominated as the best classifier in
both term and document level sentiment analysis (SA) for Arabic Language.
Furthermore, the average F-score achieved in the term level SA for both
positive and negative testing classes is 0.92. In the document level SA, the
average F-score for positive testing classes is 0.94, while for negative
classes is 0.93.</p>
  </details>
</details>
<details>
  <summary>106. <b>标题：Scoring Coreference Chains with Split-Antecedent Anaphors</b></summary>
  <p><b>编号</b>：[291]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12323</p>
  <p><b>作者</b>：Silviu Paun,  Juntao Yu,  Nafise Sadat Moosavi,  Massimo Poesio</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：nominal expressions covered, incarnation in ONTONOTES, ONTONOTES and similar, Anaphoric reference, language interpretation covering</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Anaphoric reference is an aspect of language interpretation covering a
variety of types of interpretation beyond the simple case of identity reference
to entities introduced via nominal expressions covered by the traditional
coreference task in its most recent incarnation in ONTONOTES and similar
datasets. One of these cases that go beyond simple coreference is anaphoric
reference to entities that must be added to the discourse model via
accommodation, and in particular split-antecedent references to entities
constructed out of other entities, as in split-antecedent plurals and in some
cases of discourse deixis. Although this type of anaphoric reference is now
annotated in many datasets, systems interpreting such references cannot be
evaluated using the Reference coreference scorer Pradhan et al. (2014). As part
of the work towards a new scorer for anaphoric reference able to evaluate all
aspects of anaphoric interpretation in the coverage of the Universal Anaphora
initiative, we propose in this paper a solution to the technical problem of
generalizing existing metrics for identity anaphora so that they can also be
used to score cases of split-antecedents. This is the first such proposal in
the literature on anaphora or coreference, and has been successfully used to
score both split-antecedent plural references and discourse deixis in the
recent CODI/CRAC anaphora resolution in dialogue shared tasks.</p>
  </details>
</details>
<details>
  <summary>107. <b>标题：Structured Prompt Tuning</b></summary>
  <p><b>编号</b>：[294]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12309</p>
  <p><b>作者</b>：Chi-Liang Liu,  Hung-yi Lee,  Wen-tau Yih</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：prompt tuning, improve prompt tuning, propose structured prompt, simple and effective, effective method</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose structured prompt tuning, a simple and effective method to improve
prompt tuning. Instead of prepending a sequence of tunable embeddings to the
input, we generate the soft prompt embeddings through a hypernetwork. Our
approach subsumes the standard prompt tuning, allows more flexibility in model
design and can be applied to both single-task and multi-task training settings.
Empirically, structured prompt tuning shows a gain of +1.2$~1.5 points on the
GLUE benchmark and is less sensitive to the change of learning rate, compared
to standard prompt tuning.</p>
  </details>
</details>
<details>
  <summary>108. <b>标题：Adaptive multilingual speech recognition with pretrained models</b></summary>
  <p><b>编号</b>：[296]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12304</p>
  <p><b>作者</b>：Ngoc-Quan Pham,  Alex Waibel,  Jan Niehues</p>
  <p><b>备注</b>：Submitted to INTERSPEECH 2022</p>
  <p><b>关键词</b>：achieved great results, Multilingual speech recognition, recent research, achieved great, great results</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Multilingual speech recognition with supervised learning has achieved great
results as reflected in recent research. With the development of pretraining
methods on audio and text data, it is imperative to transfer the knowledge from
unsupervised multilingual models to facilitate recognition, especially in many
languages with limited data. Our work investigated the effectiveness of using
two pretrained models for two modalities: wav2vec 2.0 for audio and MBART50 for
text, together with the adaptive weight techniques to massively improve the
recognition quality on the public datasets containing CommonVoice and Europarl.
Overall, we noticed an 44% improvement over purely supervised learning, and
more importantly, each technique provides a different reinforcement in
different languages. We also explore other possibilities to potentially obtain
the best model by slightly adding either depth or relative attention to the
architecture.</p>
  </details>
</details>
<details>
  <summary>109. <b>标题：Garden-Path Traversal within GPT-2</b></summary>
  <p><b>编号</b>：[297]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12302</p>
  <p><b>作者</b>：William Jurayj,  William Rudman,  Carsten Eickhoff</p>
  <p><b>备注</b>：7 pages, 6 figures, preprint</p>
  <p><b>关键词</b>：massive language models, recent years, GPT-x family, massive language, transformer decoders</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In recent years, massive language models consisting exclusively of
transformer decoders, led by the GPT-x family, have become increasingly
popular. While studies have examined the behavior of these models, they tend to
only focus on the output of the language model, avoiding analyzing their
internal states despite such analyses being popular tools used within BERTology
to study transformer encoders. We present a collection of methods for analyzing
GPT-2's hidden states, and use the model's navigation of garden path sentences
as a case study to demonstrate the utility of studying this model's behavior
beyond its output alone. To support this analysis, we introduce a novel dataset
consisting of 3 different types of garden path sentences, along with scripts to
manipulate them. We find that measuring Manhattan distances and cosine
similarities between hidden states shows that GPT-2 navigates these sentences
more intuitively than conventional methods that predict from the model's output
alone.</p>
  </details>
</details>
<h1>机器学习</h1>
<details>
  <summary>1. <b>标题：Inception Transformer</b></summary>
  <p><b>编号</b>：[1]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12956</p>
  <p><b>作者</b>：Chenyang Si,  Weihao Yu,  Pan Zhou,  Yichen Zhou,  Xinchao Wang,  Shuicheng Yan</p>
  <p><b>备注</b>：Code and models will be released at this https URL</p>
  <p><b>关键词</b>：building long-range dependencies, predominantly convey local, convey local information, Recent studies show, general-purpose Inception Transformer</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent studies show that Transformer has strong capability of building
long-range dependencies, yet is incompetent in capturing high frequencies that
predominantly convey local information. To tackle this issue, we present a
novel and general-purpose Inception Transformer, or iFormer for short, that
effectively learns comprehensive features with both high- and low-frequency
information in visual data. Specifically, we design an Inception mixer to
explicitly graft the advantages of convolution and max-pooling for capturing
the high-frequency information to Transformers. Different from recent hybrid
frameworks, the Inception mixer brings greater efficiency through a channel
splitting mechanism to adopt parallel convolution/max-pooling path and
self-attention path as high- and low-frequency mixers, while having the
flexibility to model discriminative information scattered within a wide
frequency range. Considering that bottom layers play more roles in capturing
high-frequency details while top layers more in modeling low-frequency global
information, we further introduce a frequency ramp structure, i.e. gradually
decreasing the dimensions fed to the high-frequency mixer and increasing those
to the low-frequency mixer, which can effectively trade-off high- and
low-frequency components across different layers. We benchmark the iFormer on a
series of vision tasks, and showcase that it achieves impressive performance on
image classification, COCO detection and ADE20K segmentation. For example, our
iFormer-S hits the top-1 accuracy of 83.4% on ImageNet-1K, much higher than
DeiT-S by 3.6%, and even slightly better than much bigger model Swin-B (83.3%)
with only 1/4 parameters and 1/3 FLOPs. Code and models will be released at
this https URL.</p>
  </details>
</details>
<details>
  <summary>2. <b>标题：Learning Mean Field Games: A Survey</b></summary>
  <p><b>编号</b>：[4]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12944</p>
  <p><b>作者</b>：Mathieu Laurière,  Sarah Perrin,  Matthieu Geist,  Olivier Pietquin</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：remain generally intractable, number of players, Non-cooperative and cooperative, applications but remain, Lasry and Lions</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Non-cooperative and cooperative games with a very large number of players
have many applications but remain generally intractable when the number of
players increases. Introduced by Lasry and Lions, and Huang, Caines and
Malhamé, Mean Field Games (MFGs) rely on a mean-field approximation to allow
the number of players to grow to infinity. Traditional methods for solving
these games generally rely on solving partial or stochastic differential
equations with a full knowledge of the model. Recently, Reinforcement Learning
(RL) has appeared promising to solve complex problems. By combining MFGs and
RL, we hope to solve games at a very large scale both in terms of population
size and environment complexity. In this survey, we review the quickly growing
recent literature on RL methods to learn Nash equilibria in MFGs. We first
identify the most common settings (static, stationary, and evolutive). We then
present a general framework for classical iterative methods (based on
best-response computation or policy evaluation) to solve MFGs in an exact way.
Building on these algorithms and the connection with Markov Decision Processes,
we explain how RL can be used to learn MFG solutions in a model-free way. Last,
we present numerical illustrations on a benchmark problem, and conclude with
some perspectives.</p>
  </details>
</details>
<details>
  <summary>3. <b>标题：Amortized Inference for Causal Structure Learning</b></summary>
  <p><b>编号</b>：[7]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12934</p>
  <p><b>作者</b>：Lars Lorch,  Scott Sussex,  Jonas Rothfuss,  Andreas Krause,  Bernhard Schölkopf</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：typically involves evaluating, involves evaluating structures, causal structure poses, poses a combinatorial, typically involves</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Learning causal structure poses a combinatorial search problem that typically
involves evaluating structures using a score or independence test. The
resulting search is costly, and designing suitable scores or tests that capture
prior knowledge is difficult. In this work, we propose to amortize the process
of causal structure learning. Rather than searching over causal structures
directly, we train a variational inference model to predict the causal
structure from observational/interventional data. Our inference model acquires
domain-specific inductive bias for causal discovery solely from data generated
by a simulator. This allows us to bypass both the search over graphs and the
hand-engineering of suitable score functions. Moreover, the architecture of our
inference model is permutation invariant w.r.t. the data points and permutation
equivariant w.r.t. the variables, facilitating generalization to significantly
larger problem instances than seen during training. On synthetic data and
semi-synthetic gene expression data, our models exhibit robust generalization
capabilities under substantial distribution shift and significantly outperform
existing algorithms, especially in the challenging genomics domain.</p>
  </details>
</details>
<details>
  <summary>4. <b>标题：Analytics of Business Time Series Using Machine Learning and Bayesian  Inference</b></summary>
  <p><b>编号</b>：[17]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12905</p>
  <p><b>作者</b>：Bohdan M. Pavlyshenko</p>
  <p><b>备注</b>：Survey article. arXiv admin note: text overlap with arXiv:2201.02034, arXiv:2201.02058, arXiv:2201.02729, arXiv:2201.02049, arXiv:2004.01489</p>
  <p><b>关键词</b>：time trend correction, sales time series, non-stationary time series, time series forecasting, forecasting non-stationary time</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In the survey we consider the case studies on sales time series forecasting,
the deep learning approach for forecasting non-stationary time series using
time trend correction, dynamic price and supply optimization using Q-learning,
Bitcoin price modeling, COVID-19 spread impact on stock market, using social
networks signals in analytics. The use of machine learning and Bayesian
inference in predictive analytics has been analyzed.</p>
  </details>
</details>
<details>
  <summary>5. <b>标题：A Neural Tangent Kernel Formula for Ensembles of Soft Trees with  Arbitrary Architectures</b></summary>
  <p><b>编号</b>：[18]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12904</p>
  <p><b>作者</b>：Ryuichi Kanoh,  Mahito Sugiyama</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：actively studied variant, updates splitting rules, Neural Tangent Kernel, gradient method, actively studied</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A soft tree is an actively studied variant of a decision tree that updates
splitting rules using the gradient method. Although it can have various tree
architectures, the theoretical properties of their impact are not well known.
In this paper, we formulate and analyze the Neural Tangent Kernel (NTK) induced
by soft tree ensembles for arbitrary tree architectures. This kernel leads to
the remarkable finding that only the number of leaves at each depth is relevant
for the tree architecture in ensemble learning with infinitely many trees. In
other words, if the number of leaves at each depth is fixed, the training
behavior in function space and the generalization performance are exactly the
same across different tree architectures, even if they are not isomorphic. We
also show that the NTK of asymmetric trees like decision lists does not
degenerate when they get infinitely deep. This is in contrast to the perfect
binary trees, whose NTK is known to degenerate and leads to worse
generalization performance for deeper trees.</p>
  </details>
</details>
<details>
  <summary>6. <b>标题：Robust Reinforcement Learning on Graphs for Logistics optimization</b></summary>
  <p><b>编号</b>：[25]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12888</p>
  <p><b>作者</b>：Zangir Iklassov,  Dmitrii Medvedev</p>
  <p><b>备注</b>：Keywords: Graph Neural Network (GNN), Logistics optimization, Reinforcement Learning</p>
  <p><b>关键词</b>：Logistics optimization nowadays, reinforcement learning, apply reinforcement learning, reinforcement, graph</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Logistics optimization nowadays is becoming one of the hottest areas in the
AI community. In the past year, significant advancements in the domain were
achieved by representing the problem in a form of graph. Another promising area
of research was to apply reinforcement learning algorithms to the above task.
In our work, we made advantage of using both approaches and apply reinforcement
learning on a graph. To do that, we have analyzed the most recent results in
both fields and selected SOTA algorithms both from graph neural networks and
reinforcement learning. Then, we combined selected models on the problem of
AMOD systems optimization for the transportation network of New York city. Our
team compared three algorithms - GAT, Pro-CNN and PTDNet - to bring to the fore
the important nodes on a graph representation. Finally, we achieved SOTA
results on AMOD systems optimization problem employing PTDNet with GNN and
training them in reinforcement fashion.
Keywords: Graph Neural Network (GNN), Logistics optimization, Reinforcement
Learning</p>
  </details>
</details>
<details>
  <summary>7. <b>标题：Trust-based Consensus in Multi-Agent Reinforcement Learning Systems</b></summary>
  <p><b>编号</b>：[29]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12880</p>
  <p><b>作者</b>：Ho Long Fung,  Victor-Alexandru Darvariu,  Stephen Hailes,  Mirco Musolesi</p>
  <p><b>备注</b>：18 pages, 17 figures</p>
  <p><b>关键词</b>：multi-agent reinforcement learning, intended tasks, unreliable agents, neglected issue, potential presence</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>An often neglected issue in multi-agent reinforcement learning (MARL) is the
potential presence of unreliable agents in the environment whose deviations
from expected behavior can prevent a system from accomplishing its intended
tasks. In particular, consensus is a fundamental underpinning problem of
cooperative distributed multi-agent systems. Consensus requires different
agents, situated in a decentralized communication network, to reach an
agreement out of a set of initial proposals that they put forward.
Learning-based agents should adopt a protocol that allows them to reach
consensus despite having one or more unreliable agents in the system. This
paper investigates the problem of unreliable agents in MARL, considering
consensus as case study. Echoing established results in the distributed systems
literature, our experiments show that even a moderate fraction of such agents
can greatly impact the ability of reaching consensus in a networked
environment. We propose Reinforcement Learning-based Trusted Consensus (RLTC),
a decentralized trust mechanism, in which agents can independently decide which
neighbors to communicate with. We empirically demonstrate that our trust
mechanism is able to deal with unreliable agents effectively, as evidenced by
higher consensus success rates.</p>
  </details>
</details>
<details>
  <summary>8. <b>标题：Understanding Programmatic Weak Supervision via Source-aware Influence  Function</b></summary>
  <p><b>编号</b>：[30]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12879</p>
  <p><b>作者</b>：Jieyu Zhang,  Haonan Wang,  Cheng-Yu Hsieh,  Alexander Ratner</p>
  <p><b>备注</b>：21 pages</p>
  <p><b>关键词</b>：Programmatic Weak Supervision, weak supervision sources, multiple weak supervision, Weak Supervision, Programmatic Weak</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Programmatic Weak Supervision (PWS) aggregates the source votes of multiple
weak supervision sources into probabilistic training labels, which are in turn
used to train an end model. With its increasing popularity, it is critical to
have some tool for users to understand the influence of each component (e.g.,
the source vote or training data) in the pipeline and interpret the end model
behavior. To achieve this, we build on Influence Function (IF) and propose
source-aware IF, which leverages the generation process of the probabilistic
labels to decompose the end model's training objective and then calculate the
influence associated with each (data, source, class) tuple. These primitive
influence score can then be used to estimate the influence of individual
component of PWS, such as source vote, supervision source, and training data.
On datasets of diverse domains, we demonstrate multiple use cases: (1)
interpreting incorrect predictions from multiple angles that reveals insights
for debugging the PWS pipeline, (2) identifying mislabeling of sources with a
gain of 9%-37% over baselines, and (3) improving the end model's generalization
performance by removing harmful components in the training objective (13%-24%
better than ordinary IF).</p>
  </details>
</details>
<details>
  <summary>9. <b>标题：Image Colorization using U-Net with Skip Connections and Fusion Layer on  Landscape Images</b></summary>
  <p><b>编号</b>：[33]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12867</p>
  <p><b>作者</b>：Muhammad Hisyam Zayd,  Novanto Yudistira,  Randy Cahya Wihandika</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：automatically colorize grayscale, Fusion Layer features, colorize grayscale images, technique to automatically, automatically colorize</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present a novel technique to automatically colorize grayscale images that
combine the U-Net model and Fusion Layer features. This approach allows the
model to learn the colorization of images from pre-trained U-Net. Moreover, the
Fusion layer is applied to merge local information results dependent on small
image patches with global priors of an entire image on each class, forming
visually more compelling colorization results. Finally, we validate our
approach with a user study evaluation and compare it against state-of-the-art,
resulting in improvements.</p>
  </details>
</details>
<details>
  <summary>10. <b>标题：Stochastic Second-Order Methods Provably Beat SGD For Gradient-Dominated  Functions</b></summary>
  <p><b>编号</b>：[35]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12856</p>
  <p><b>作者</b>：Saeed Masiha,  Saber Salehkaleybar,  Niao He,  Negar Kiyavash,  Patrick Thiran</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Cubic Regularized Newton, Stochastic Cubic Regularized, Regularized Newton, Cubic Regularized, functions satisfying gradient</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We study the performance of Stochastic Cubic Regularized Newton (SCRN) on a
class of functions satisfying gradient dominance property which holds in a wide
range of applications in machine learning and signal processing. This condition
ensures that any first-order stationary point is a global optimum. We prove
that SCRN improves the best-known sample complexity of stochastic gradient
descent in achieving $\epsilon$-global optimum by a factor of
$\mathcal{O}(\epsilon^{-1/2})$. Even under a weak version of gradient dominance
property, which is applicable to policy-based reinforcement learning (RL), SCRN
achieves the same improvement over stochastic policy gradient methods.
Additionally, we show that the sample complexity of SCRN can be improved by a
factor of ${\mathcal{O}}(\epsilon^{-1/2})$ using a variance reduction method
with time-varying batch sizes. Experimental results in various RL settings
showcase the remarkable performance of SCRN compared to first-order methods.</p>
  </details>
</details>
<details>
  <summary>11. <b>标题：A Universal Error Measure for Input Predictions Applied to Online Graph  Problems</b></summary>
  <p><b>编号</b>：[38]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12850</p>
  <p><b>作者</b>：Giulia Bernardini,  Alexander Lindermayr,  Alberto Marchetti-Spaccamela,  Nicole Megow,  Leen Stougie,  Michelle Sweering</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：measure captures errors, quantifying the error, minimum-cost hyperedge cover, suitably defined hypergraph, measure for quantifying</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We introduce a novel measure for quantifying the error in input predictions.
The error is based on a minimum-cost hyperedge cover in a suitably defined
hypergraph and provides a general template which we apply to online graph
problems. The measure captures errors due to absent predicted requests as well
as unpredicted actual requests; hence, predicted and actual inputs can be of
arbitrary size. We achieve refined performance guarantees for previously
studied network design problems in the online-list model, such as Steiner tree
and facility location. Further, we initiate the study of learning-augmented
algorithms for online routing problems, such as the traveling salesperson
problem and dial-a-ride problem, where (transportation) requests arrive over
time (online-time model). We provide a general algorithmic framework and we
give error-dependent performance bounds that improve upon known worst-case
barriers, when given accurate predictions, at the cost of slightly increased
worst-case bounds when given predictions of arbitrary quality.</p>
  </details>
</details>
<details>
  <summary>12. <b>标题：Mirror Descent Maximizes Generalized Margin and Can Be Implemented  Efficiently</b></summary>
  <p><b>编号</b>：[48]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12808</p>
  <p><b>作者</b>：Haoyuan Sun,  Kwangjun Ahn,  Christos Thrampoulidis,  Navid Azizan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：increasingly popular question, empirical success, success and wide, increasingly popular, deep neural networks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Driven by the empirical success and wide use of deep neural networks,
understanding the generalization performance of overparameterized models has
become an increasingly popular question. To this end, there has been
substantial effort to characterize the implicit bias of the optimization
algorithms used, such as gradient descent (GD), and the structural properties
of their preferred solutions. This paper answers an open question in this
literature: For the classification setting, what solution does mirror descent
(MD) converge to? Specifically, motivated by its efficient implementation, we
consider the family of mirror descent algorithms with potential function chosen
as the $p$-th power of the $\ell_p$-norm, which is an important generalization
of GD. We call this algorithm $p$-$\textsf{GD}$. For this family, we
characterize the solutions it obtains and show that it converges in direction
to a generalized maximum-margin solution with respect to the $\ell_p$-norm for
linearly separable classification. While the MD update rule is in general
expensive to compute and perhaps not suitable for deep learning,
$p$-$\textsf{GD}$ is fully parallelizable in the same manner as SGD and can be
used to train deep neural networks with virtually no additional computational
overhead. Using comprehensive experiments with both linear and deep neural
network models, we demonstrate that $p$-$\textsf{GD}$ can noticeably affect the
structure and the generalization performance of the learned models.</p>
  </details>
</details>
<details>
  <summary>13. <b>标题：Gradient-based explanations for Gaussian Process regression and  classification models</b></summary>
  <p><b>编号</b>：[50]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12797</p>
  <p><b>作者</b>：Sarem Seitz</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Gaussian Processes, Machine Learning, probabilistic Machine Learning, Learning, reliable and effective</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Gaussian Processes (GPs) have proven themselves as a reliable and effective
method in probabilistic Machine Learning. Thanks to recent and current
advances, modeling complex data with GPs is becoming more and more feasible.
Thus, these types of models are, nowadays, an interesting alternative to Neural
and Deep Learning methods, which are arguably the current state-of-the-art in
Machine Learning. For the latter, we see an increasing interest in so-called
explainable approaches - in essence methods that aim to make a Machine Learning
model's decision process transparent to humans. Such methods are particularly
needed when illogical or biased reasoning can lead to actual disadvantageous
consequences for humans. Ideally, explainable Machine Learning should help
detect such flaws in a model and aid a subsequent debugging process. One active
line of research in Machine Learning explainability are gradient-based methods,
which have been successfully applied to complex neural networks. Given that GPs
are closed under differentiation, gradient-based explainability for GPs appears
as a promising field of research. This paper is primarily focused on explaining
GP classifiers via gradients where, contrary to GP regression, derivative GPs
are not straightforward to obtain.</p>
  </details>
</details>
<details>
  <summary>14. <b>标题：Impartial Games: A Challenge for Reinforcement Learning</b></summary>
  <p><b>编号</b>：[52]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12787</p>
  <p><b>作者</b>：Bei Zhou,  Søren Riis</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：successor MuZero, MuZero have revolutionised, revolutionised several competitive, competitive strategy games, AlphaZero</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The AlphaZero algorithm and its successor MuZero have revolutionised several
competitive strategy games, including chess, Go, and shogi and video games like
Atari, by learning to play these games better than any human and any
specialised computer program. Aside from knowing the rules, AlphaZero had no
prior knowledge of each game. This dramatically advanced progress on a
long-standing AI challenge to create programs that can learn for themselves
from first principles.
Theoretically, there are well-known limits to the power of deep learning for
strategy games like chess, Go, and shogi, as they are known to be NEXPTIME
hard. Some papers have argued that the AlphaZero methodology has limitations
and is unsuitable for general AI. However, none of these works has suggested
any specific limits for any particular game.
In this paper, we provide more powerful bottlenecks than previously
suggested. We present the first concrete example of a game - namely the
(children) game of nim - and other impartial games that seem to be a stumbling
block for AlphaZero and similar reinforcement learning algorithms. We show
experimentally that the bottlenecks apply to both the policy and value
networks. Since solving nim can be done in linear time using logarithmic space
i.e. has very low-complexity, our experimental results supersede known
theoretical limits based on many games' PSPACE (and NEXPTIME) completeness.
We show that nim can be learned on small boards, but when the board size
increases, AlphaZero style algorithms rapidly fail to improve.
We quantify the difficulties for various setups, parameter settings and
computational resources. Our results might help expand the AlphaZero self-play
paradigm by allowing it to use meta-actions during training and/or actual game
play like applying abstract transformations, or reading and writing to an
external memory.</p>
  </details>
</details>
<details>
  <summary>15. <b>标题：TrustGNN: Graph Neural Network based Trust Evaluation via Learnable  Propagative and Composable Nature</b></summary>
  <p><b>编号</b>：[54]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12784</p>
  <p><b>作者</b>：Cuiying Huo,  Di Jin,  Chundong Liang,  Dongxiao He,  Tie Qiu,  Lingfei Wu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Trust, cyber security, social communication, recommender systems, Trust evaluation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Trust evaluation is critical for many applications such as cyber security,
social communication and recommender systems. Users and trust relationships
among them can be seen as a graph. Graph neural networks (GNNs) show their
powerful ability for analyzing graph-structural data. Very recently, existing
work attempted to introduce the attributes and asymmetry of edges into GNNs for
trust evaluation, while failed to capture some essential properties (e.g., the
propagative and composable nature) of trust graphs. In this work, we propose a
new GNN based trust evaluation method named TrustGNN, which integrates smartly
the propagative and composable nature of trust graphs into a GNN framework for
better trust evaluation. Specifically, TrustGNN designs specific propagative
patterns for different propagative processes of trust, and distinguishes the
contribution of different propagative processes to create new trust. Thus,
TrustGNN can learn comprehensive node embeddings and predict trust
relationships based on these embeddings. Experiments on some widely-used
real-world datasets indicate that TrustGNN significantly outperforms the
state-of-the-art methods. We further perform analytical experiments to
demonstrate the effectiveness of the key designs in TrustGNN.</p>
  </details>
</details>
<details>
  <summary>16. <b>标题：Ultra-compact Binary Neural Networks for Human Activity Recognition on  RISC-V Processors</b></summary>
  <p><b>编号</b>：[55]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12781</p>
  <p><b>作者</b>：Francesco Daghero,  Chen Xie,  Daniele Jahier Pagliari,  Alessio Burrello,  Marco Castellano,  Luca Gandolfi,  Andrea Calimera,  Enrico Macii,  Massimo Poncino</p>
  <p><b>备注</b>：Published in: 2021 18th ACM International Conference on Computing Frontiers (CF)</p>
  <p><b>关键词</b>：Human Activity Recognition, Activity Recognition, Human Activity, Binary Neural Networks, mobile applications</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Human Activity Recognition (HAR) is a relevant inference task in many mobile
applications. State-of-the-art HAR at the edge is typically achieved with
lightweight machine learning models such as decision trees and Random Forests
(RFs), whereas deep learning is less common due to its high computational
complexity. In this work, we propose a novel implementation of HAR based on
deep neural networks, and precisely on Binary Neural Networks (BNNs), targeting
low-power general purpose processors with a RISC-V instruction set. BNNs yield
very small memory footprints and low inference complexity, thanks to the
replacement of arithmetic operations with bit-wise ones. However, existing BNN
implementations on general purpose processors impose constraints tailored to
complex computer vision tasks, which result in over-parametrized models for
simpler problems like HAR. Therefore, we also introduce a new BNN inference
library, which targets ultra-compact models explicitly. With experiments on a
single-core RISC-V processor, we show that BNNs trained on two HAR datasets
obtain higher classification accuracy compared to a state-of-the-art baseline
based on RFs. Furthermore, our BNN reaches the same accuracy of a RF with
either less memory (up to 91%) or more energy-efficiency (up to 70%), depending
on the complexity of the features extracted by the RF.</p>
  </details>
</details>
<details>
  <summary>17. <b>标题：Residual-Concatenate Neural Network with Deep Regularization Layers for  Binary Classification</b></summary>
  <p><b>编号</b>：[56]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12775</p>
  <p><b>作者</b>：Abhishek Gupta,  Sruthi Nair,  Raunak Joshi,  Vidya Chitre</p>
  <p><b>备注</b>：7 pages, 5 figures. To appear in the proceedings of 6th International Conference on Intelligent Computing and Control Systems (ICICCS 2022)</p>
  <p><b>关键词</b>：complex Deep Learning, Deep Learning models, Polycystic Ovary Syndrome, Ovary Syndrome Diagnosis, higher learning parameters</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Many complex Deep Learning models are used with different variations for
various prognostication tasks. The higher learning parameters not necessarily
ensure great accuracy. This can be solved by considering changes in very deep
models with many regularization based techniques. In this paper we train a deep
neural network that uses many regularization layers with residual and
concatenation process for best fit with Polycystic Ovary Syndrome Diagnosis
prognostication. The network was built with improvements from every step of
failure to meet the needs of the data and achieves an accuracy of 99.3%
seamlessly.</p>
  </details>
</details>
<details>
  <summary>18. <b>标题：An Experimental Comparison Between Temporal Difference and Residual  Gradient with Neural Network Approximation</b></summary>
  <p><b>编号</b>：[59]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12770</p>
  <p><b>作者</b>：Shuyu Yin,  Tao Luo,  Peilin Liu,  Zhi-Qin John Xu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Gradient descent, incomplete gradient descent, gradient descent method, small Bellman residual, Bellman residual</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Gradient descent or its variants are popular in training neural networks.
However, in deep Q-learning with neural network approximation, a type of
reinforcement learning, gradient descent (also known as Residual Gradient (RG))
is barely used to solve Bellman residual minimization problem. On the contrary,
Temporal Difference (TD), an incomplete gradient descent method prevails. In
this work, we perform extensive experiments to show that TD outperforms RG,
that is, when the training leads to a small Bellman residual error, the
solution found by TD has a better policy and is more robust against the
perturbation of neural network parameters. We further use experiments to reveal
a key difference between reinforcement learning and supervised learning, that
is, a small Bellman residual error can correspond to a bad policy in
reinforcement learning while the test loss function in supervised learning is a
standard index to indicate the performance. We also empirically examine that
the missing term in TD is a key reason why RG performs badly. Our work shows
that the performance of a deep Q-learning solution is closely related to the
training dynamics and how an incomplete gradient descent method can find a good
policy is interesting for future study.</p>
  </details>
</details>
<details>
  <summary>19. <b>标题：An Evolutionary Approach to Dynamic Introduction of Tasks in Large-scale  Multitask Learning Systems</b></summary>
  <p><b>编号</b>：[66]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12755</p>
  <p><b>作者</b>：Andrea Gesmundo,  Jeff Dean</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Multitask learning assumes, quality and efficiency, key feature, feature of human, learning assumes</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Multitask learning assumes that models capable of learning from multiple
tasks can achieve better quality and efficiency via knowledge transfer, a key
feature of human learning. Though, state of the art ML models rely on high
customization for each task and leverage size and data scale rather than
scaling the number of tasks. Also, continual learning, that adds the temporal
aspect to multitask, is often focused to the study of common pitfalls such as
catastrophic forgetting instead of being studied at a large scale as a critical
component to build the next generation artificial intelligence. We propose an
evolutionary method that can generate a large scale multitask model, and can
support the dynamic and continuous addition of new tasks. The generated
multitask model is sparsely activated and integrates a task-based routing that
guarantees bounded compute cost and fewer added parameters per task as the
model expands. The proposed method relies on a knowledge compartmentalization
technique to achieve immunity against catastrophic forgetting and other common
pitfalls such as gradient interference and negative transfer. We empirically
show that the proposed method can jointly solve and achieve competitive results
on 69image classification tasks, for example achieving the best test accuracy
reported fora model trained only on public data for competitive tasks such as
cifar10: 99.43%.</p>
  </details>
</details>
<details>
  <summary>20. <b>标题：An Empirical Study on Distribution Shift Robustness From the Perspective  of Pre-Training and Data Augmentation</b></summary>
  <p><b>编号</b>：[67]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12753</p>
  <p><b>作者</b>：Ziquan Liu,  Yi Xu,  Yuanhong Xu,  Qi Qian,  Hao Li,  Rong Jin,  Xiangyang Ji,  Antoni B. Chan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：distribution shift, data augmentation, distribution, recent years, data</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The performance of machine learning models under distribution shift has been
the focus of the community in recent years. Most of current methods have been
proposed to improve the robustness to distribution shift from the algorithmic
perspective, i.e., designing better training algorithms to help the
generalization in shifted test distributions. This paper studies the
distribution shift problem from the perspective of pre-training and data
augmentation, two important factors in the practice of deep learning that have
not been systematically investigated by existing work. By evaluating seven
pre-trained models, including ResNets and ViT's with self-supervision and
supervision mode, on five important distribution-shift datasets, from WILDS and
DomainBed benchmarks, with five different learning algorithms, we provide the
first comprehensive empirical study focusing on pre-training and data
augmentation. With our empirical result obtained from 1,330 models, we provide
the following main observations: 1) ERM combined with data augmentation can
achieve state-of-the-art performance if we choose a proper pre-trained model
respecting the data property; 2) specialized algorithms further improve the
robustness on top of ERM when handling a specific type of distribution shift,
e.g., GroupDRO for spurious correlation and CORAL for large-scale
out-of-distribution data; 3) Comparing different pre-training modes,
architectures and data sizes, we provide novel observations about pre-training
on distribution shift, which sheds light on designing or selecting pre-training
strategy for different kinds of distribution shifts. In summary, our empirical
study provides a comprehensive baseline for a wide range of pre-training models
fine-tuned with data augmentation, which potentially inspires research
exploiting the power of pre-training and data augmentation in the future of
distribution shift study.</p>
  </details>
</details>
<details>
  <summary>21. <b>标题：NECA: Network-Embedded Deep Representation Learning for Categorical Data</b></summary>
  <p><b>编号</b>：[68]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12752</p>
  <p><b>作者</b>：Xiaonan Gao,  Sen Wu,  Wenjun Zhou</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：representation learning method, deep representation learning, representation learning, propose NECA, learning method</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose NECA, a deep representation learning method for categorical data.
Built upon the foundations of network embedding and deep unsupervised
representation learning, NECA deeply embeds the intrinsic relationship among
attribute values and explicitly expresses data objects with numeric vector
representations. Designed specifically for categorical data, NECA can support
important downstream data mining tasks, such as clustering. Extensive
experimental analysis demonstrated the effectiveness of NECA.</p>
  </details>
</details>
<details>
  <summary>22. <b>标题：Uncertainty Quantification for Transport in Porous media using  Parameterized Physics Informed neural Networks</b></summary>
  <p><b>编号</b>：[76]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12730</p>
  <p><b>作者</b>：Cedric Fraces Gasmi,  Hamdi Tchelepi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Physics Informed Neural, Informed Neural Network, Physics Informed, Informed Neural, present a Parametrization</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present a Parametrization of the Physics Informed Neural Network (P-PINN)
approach to tackle the problem of uncertainty quantification in reservoir
engineering problems. We demonstrate the approach with the immiscible two phase
flow displacement (Buckley-Leverett problem) in heterogeneous porous medium.
The reservoir properties (porosity, permeability) are treated as random
variables. The distribution of these properties can affect dynamic properties
such as the fluids saturation, front propagation speed or breakthrough time. We
explore and use to our advantage the ability of networks to interpolate complex
high dimensional functions. We observe that the additional dimensions resulting
from a stochastic treatment of the partial differential equations tend to
produce smoother solutions on quantities of interest (distributions parameters)
which is shown to improve the performance of PINNS. We show that provided a
proper parameterization of the uncertainty space, PINN can produce solutions
that match closely both the ensemble realizations and the stochastic moments.
We demonstrate applications for both homogeneous and heterogeneous fields of
properties. We are able to solve problems that can be challenging for classical
methods. This approach gives rise to trained models that are both more robust
to variations in the input space and can compete in performance with
traditional stochastic sampling methods.</p>
  </details>
</details>
<details>
  <summary>23. <b>标题：Interpretable Feature Engineering for Time Series Predictors using  Attention Networks</b></summary>
  <p><b>编号</b>：[78]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12723</p>
  <p><b>作者</b>：Tianjie Wang,  Jie Chen,  Joel Vaughan,  Vijayan N. Nair</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Regression problems, areas of application, problems with time-series, time-series predictors, predictors are common</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Regression problems with time-series predictors are common in banking and
many other areas of application. In this paper, we use multi-head attention
networks to develop interpretable features and use them to achieve good
predictive performance. The customized attention layer explicitly uses
multiplicative interactions and builds feature-engineering heads that capture
temporal dynamics in a parsimonious manner. Convolutional layers are used to
combine multivariate time series. We also discuss methods for handling static
covariates in the modeling process. Visualization and explanation tools are
used to interpret the results and explain the relationship between the inputs
and the extracted features. Both simulation and real dataset are used to
illustrate the usefulness of the methodology. Keyword: Attention heads, Deep
neural networks, Interpretable feature engineering</p>
  </details>
</details>
<details>
  <summary>24. <b>标题：Mathematical Models of Human Drivers Using Artificial Risk Fields</b></summary>
  <p><b>编号</b>：[79]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12722</p>
  <p><b>作者</b>：Emily Jensen,  Maya Luster,  Hansol Yoon,  Brandon Pitts,  Sriram Sankaranarayanan</p>
  <p><b>备注</b>：8 pages, 4 figures, submitted to Intelligent Transportation Systems Conference</p>
  <p><b>关键词</b>：upcoming road situations, artificial risk fields, risk fields, human operators control, concept of artificial</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we use the concept of artificial risk fields to predict how
human operators control a vehicle in response to upcoming road situations. A
risk field assigns a non-negative risk measure to the state of the system in
order to model how close that state is to violating a safety property, such as
hitting an obstacle or exiting the road. Using risk fields, we construct a
stochastic model of the operator that maps from states to likely actions. We
demonstrate our approach on a driving task wherein human subjects are asked to
drive a car inside a realistic driving simulator while avoiding obstacles
placed on the road. We show that the most likely risk field given the driving
data is obtained by solving a convex optimization problem. Next, we apply the
inferred risk fields to generate distinct driving behaviors while comparing
predicted trajectories against ground truth measurements. We observe that the
risk fields are excellent at predicting future trajectory distributions with
high prediction accuracy for up to twenty seconds prediction horizons. At the
same time, we observe some challenges such as the inability to account for how
drivers choose to accelerate/decelerate based on the road conditions.</p>
  </details>
</details>
<details>
  <summary>25. <b>标题：DPSNN: A Differentially Private Spiking Neural Network</b></summary>
  <p><b>编号</b>：[81]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12718</p>
  <p><b>作者</b>：Jihang Wang,  Dongcheng Zhao,  Guobin Shen,  Qian Zhang,  Yi Zeng</p>
  <p><b>备注</b>：12 pages, 6 figures</p>
  <p><b>关键词</b>：privacy protection, machine learning algorithm, Spiking neural network, SNN, neural network</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Privacy-preserving is a key problem for the machine learning algorithm.
Spiking neural network (SNN) plays an important role in many domains, such as
image classification, object detection, and speech recognition, but the study
on the privacy protection of SNN is urgently needed. This study combines the
differential privacy (DP) algorithm and SNN and proposes differentially private
spiking neural network (DPSNN). DP injects noise into the gradient, and SNN
transmits information in discrete spike trains so that our differentially
private SNN can maintain strong privacy protection while still ensuring high
accuracy. We conducted experiments on MNIST, Fashion-MNIST, and the face
recognition dataset Extended YaleB. When the privacy protection is improved,
the accuracy of the artificial neural network(ANN) drops significantly, but our
algorithm shows little change in performance. Meanwhile, we analyzed different
factors that affect the privacy protection of SNN. Firstly, the less precise
the surrogate gradient is, the better the privacy protection of the SNN.
Secondly, the Integrate-And-Fire (IF) neurons perform better than leaky
Integrate-And-Fire (LIF) neurons. Thirdly, a large time window contributes more
to privacy protection and performance.</p>
  </details>
</details>
<details>
  <summary>26. <b>标题：Service Discovery in Social Internet of Things using Graph Neural  Networks</b></summary>
  <p><b>编号</b>：[83]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12711</p>
  <p><b>作者</b>：Aymen Hamrouni,  Hakim Ghazzai,  Yehia Massoud</p>
  <p><b>备注</b>：Accepted for publications in the 65 IEEE International Midwest Symposium on Circuits and Systems (MWSCAS'22) 7 figures, 1 table, 5 pages</p>
  <p><b>关键词</b>：intelligently connect thousands, networks intelligently connect, large-scale IoT networks, intelligently connect, connect thousands</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Internet-of-Things (IoT) networks intelligently connect thousands of physical
entities to provide various services for the community. It is witnessing an
exponential expansion, which is complicating the process of discovering IoT
devices existing in the network and requesting corresponding services from
them. As the highly dynamic nature of the IoT environment hinders the use of
traditional solutions of service discovery, we aim, in this paper, to address
this issue by proposing a scalable resource allocation neural model adequate
for heterogeneous large-scale IoT networks. We devise a Graph Neural Network
(GNN) approach that utilizes the social relationships formed between the
devices in the IoT network to reduce the search space of any entity lookup and
acquire a service from another device in the network. This proposed resource
allocation approach surpasses standardization issues and embeds the structure
and characteristics of the social IoT graph, by the means of GNNs, for eventual
clustering analysis process. Simulation results applied on a real-world dataset
illustrate the performance of this solution and its significant efficiency to
operate on large-scale IoT networks.</p>
  </details>
</details>
<details>
  <summary>27. <b>标题：VeriFi: Towards Verifiable Federated Unlearning</b></summary>
  <p><b>编号</b>：[84]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12709</p>
  <p><b>作者</b>：Xiangshan Gao,  Xingjun Ma,  Jingyi Wang,  Youcheng Sun,  Bo Li,  Shouling Ji,  Peng Cheng,  Jiming Chen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：participants jointly train, unlearning, federated unlearning, collaborative learning paradigm, verifiable federated unlearning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Federated learning (FL) is a collaborative learning paradigm where
participants jointly train a powerful model without sharing their private data.
One desirable property for FL is the implementation of the right to be
forgotten (RTBF), i.e., a leaving participant has the right to request to
delete its private data from the global model. However, unlearning itself may
not be enough to implement RTBF unless the unlearning effect can be
independently verified, an important aspect that has been overlooked in the
current literature. In this paper, we prompt the concept of verifiable
federated unlearning, and propose VeriFi, a unified framework integrating
federated unlearning and verification that allows systematic analysis of the
unlearning and quantification of its effect, with different combinations of
multiple unlearning and verification methods. In VeriFi, the leaving
participant is granted the right to verify (RTV), that is, the participant
notifies the server before leaving, then actively verifies the unlearning
effect in the next few communication rounds. The unlearning is done at the
server side immediately after receiving the leaving notification, while the
verification is done locally by the leaving participant via two steps: marking
(injecting carefully-designed markers to fingerprint the leaver) and checking
(examining the change of the global model's performance on the markers). Based
on VeriFi, we conduct the first systematic and large-scale study for verifiable
federated unlearning, considering 7 unlearning methods and 5 verification
methods. Particularly, we propose a more efficient and FL-friendly unlearning
method, and two more effective and robust non-invasive-verification methods. We
extensively evaluate VeriFi on 7 datasets and 4 types of deep learning models.
Our analysis establishes important empirical understandings for more
trustworthy federated unlearning.</p>
  </details>
</details>
<details>
  <summary>28. <b>标题：Scalable Online Change Detection for High-dimensional Data Streams</b></summary>
  <p><b>编号</b>：[85]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12706</p>
  <p><b>作者</b>：Florian Kalinke,  Marco Heyden,  Edouard Fouché,  Klemens Böhm</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：predictive maintenance, core objective, Maximum Mean Discrepancy, data streams, fraud detection</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Detecting changes in data streams is a core objective in their analysis and
has applications in, say, predictive maintenance, fraud detection, and
medicine. A principled approach to detect changes is to compare distributions
observed within the stream to each other. However, data streams often are
high-dimensional, and changes can be complex, e.g., only manifest themselves in
higher moments. The streaming setting also imposes heavy memory and computation
restrictions. We propose an algorithm, Maximum Mean Discrepancy Adaptive
Windowing (MMDAW), which leverages the well-known Maximum Mean Discrepancy
(MMD) two-sample test, and facilitates its efficient online computation on
windows whose size it flexibly adapts. As MMD is sensitive to any change in the
underlying distribution, our algorithm is a general-purpose non-parametric
change detector that fulfills the requirements imposed by the streaming
setting. Our experiments show that MMDAW achieves better detection quality than
state-of-the-art competitors.</p>
  </details>
</details>
<details>
  <summary>29. <b>标题：Eliciting Transferability in Multi-task Learning with Task-level  Mixture-of-Experts</b></summary>
  <p><b>编号</b>：[88]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12701</p>
  <p><b>作者</b>：Qinyuan Ye,  Juan Zha,  Xiang Ren</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Recent work suggests, diverse NLP tasks, Recent work, work suggests, capable of multi-task</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent work suggests that transformer models are capable of multi-task
learning on diverse NLP tasks. However, the potential of these models may be
limited as they use the same set of parameters for all tasks. In contrast,
humans tackle tasks in a more flexible way, by making proper presumptions on
what skills and knowledge are relevant and executing only the necessary
computations. Inspired by this, we propose to use task-level mixture-of-expert
models, which has a collection of transformer layers (i.e., experts) and a
router component to choose among these experts dynamically and flexibly. We
show that the learned routing decisions and experts partially rediscover human
categorization of NLP tasks -- certain experts are strongly associated with
extractive tasks, some with classification tasks, and some with tasks requiring
world knowledge.</p>
  </details>
</details>
<details>
  <summary>30. <b>标题：Train Flat, Then Compress: Sharpness-Aware Minimization Learns More  Compressible Models</b></summary>
  <p><b>编号</b>：[93]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12694</p>
  <p><b>作者</b>：Clara Na,  Sanket Vaibhav Mehta,  Emma Strubell</p>
  <p><b>备注</b>：12 pages</p>
  <p><b>关键词</b>：recently gained popularity, modern deep neural, deep neural network, neural network models, recently gained</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Model compression by way of parameter pruning, quantization, or distillation
has recently gained popularity as an approach for reducing the computational
requirements of modern deep neural network models for NLP. Pruning unnecessary
parameters has emerged as a simple and effective method for compressing large
models that is compatible with a wide variety of contemporary off-the-shelf
hardware (unlike quantization), and that requires little additional training
(unlike distillation). Pruning approaches typically take a large, accurate
model as input, then attempt to discover a smaller subnetwork of that model
capable of achieving end-task accuracy comparable to the full model. Inspired
by previous work suggesting a connection between simpler, more generalizable
models and those that lie within flat basins in the loss landscape, we propose
to directly optimize for flat minima while performing task-specific pruning,
which we hypothesize should lead to simpler parameterizations and thus more
compressible models. In experiments combining sharpness-aware minimization with
both iterative magnitude pruning and structured pruning approaches, we show
that optimizing for flat minima consistently leads to greater compressibility
of parameters compared to standard Adam optimization when fine-tuning BERT
models, leading to higher rates of compression with little to no loss in
accuracy on the GLUE classification benchmark.</p>
  </details>
</details>
<details>
  <summary>31. <b>标题：Ground-Truth Labels Matter: A Deeper Look into Input-Label  Demonstrations</b></summary>
  <p><b>编号</b>：[99]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12685</p>
  <p><b>作者</b>：Junyeob Kim,  Hyuhng Joon Kim,  Hyunsoo Cho,  Hwiyeol Jo,  Sang-Woo Lee,  Sang-goo Lee,  Kang Min Yoo,  Taeuk Kim</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：demonstrations remain elusive, in-context learning, research interests, remain elusive, recent explosion</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Despite recent explosion in research interests, in-context learning and the
precise impact of the quality of demonstrations remain elusive. While, based on
current literature, it is expected that in-context learning shares a similar
mechanism to supervised learning, Min et al. (2022) recently reported that,
surprisingly, input-label correspondence is less important than other aspects
of prompt demonstrations. Inspired by this counter-intuitive observation, we
re-examine the importance of ground truth labels on in-context learning from
diverse and statistical points of view. With the aid of the newly introduced
metrics, i.e., Ground-truth Label Effect Ratio (GLER), demo-gain, and label
sensitivity, we find that the impact of the correct input-label matching can
vary according to different configurations. Expanding upon the previous key
finding on the role of demonstrations, the complementary and contrastive
results suggest that one might need to take more care when estimating the
impact of each component in in-context learning demonstrations.</p>
  </details>
</details>
<details>
  <summary>32. <b>标题：Rethinking Fano's Inequality in Ensemble Learning</b></summary>
  <p><b>编号</b>：[100]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12683</p>
  <p><b>作者</b>：Terufumi Morishita,  Gaku Morio,  Shota Horiguchi,  Hiroaki Ozaki,  Nobuo Nukaga</p>
  <p><b>备注</b>：To appear in ICML 2022</p>
  <p><b>关键词</b>：propose a fundamental, well-grounded set, Fano inequality, original Fano inequality, fundamental theory</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose a fundamental theory on ensemble learning that evaluates a given
ensemble system by a well-grounded set of metrics. Previous studies used a
variant of Fano's inequality of information theory and derived a lower bound of
the classification error rate on the basis of the accuracy and diversity of
models. We revisit the original Fano's inequality and argue that the studies
did not take into account the information lost when multiple model predictions
are combined into a final prediction. To address this issue, we generalize the
previous theory to incorporate the information loss. Further, we empirically
validate and demonstrate the proposed theory through extensive experiments on
actual systems. The theory reveals the strengths and weaknesses of systems on
each metric, which will push the theoretical understanding of ensemble learning
and give us insights into designing systems.</p>
  </details>
</details>
<details>
  <summary>33. <b>标题：Training Language Models with Memory Augmentation</b></summary>
  <p><b>编号</b>：[106]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12674</p>
  <p><b>作者</b>：Zexuan Zhong,  Tao Lei,  Danqi Chen</p>
  <p><b>备注</b>：Our code and models will be available at this https URL</p>
  <p><b>关键词</b>：non-parametric memory component, remarkably by equipping, language models remarkably, improved language models, language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent work has improved language models remarkably by equipping them with a
non-parametric memory component. However, most existing approaches only
introduce memories at testing time, or represent them using a separately
trained encoder -- resulting in sub-optimal training of the language model. In
this work, we present TRIME, a novel yet simple training approach designed for
training language models with memory augmentation. Our approach uses a training
objective that directly takes in-batch examples as accessible memory. We also
present new methods for memory construction and data batching, which are used
for adapting to different sets of memories -- local, long-term, and external
memory -- at testing time. We evaluate our approach on multiple language
modeling and machine translation benchmarks. We find that simply replacing the
vanilla language modeling objective by ours greatly reduces the perplexity,
without modifying the model architecture or incorporating extra context (e.g.,
18.70 $\to$ 17.76 on WikiText-103). We further augment language models with
long-range contexts and external knowledge and demonstrate significant gains
over previous memory-augmented approaches.</p>
  </details>
</details>
<details>
  <summary>34. <b>标题：MAPLE-X: Latency Prediction with Explicit Microprocessor Prior Knowledge</b></summary>
  <p><b>编号</b>：[112]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12660</p>
  <p><b>作者</b>：Saad Abbasi,  Alexander Wong,  Mohammad Javad Shafiee</p>
  <p><b>备注</b>：6 pages, 4 figures</p>
  <p><b>关键词</b>：adds significant cost, Neural Architecture Search, efficient convolutional neural, Architecture Search, processes when searching</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep neural network (DNN) latency characterization is a time-consuming
process and adds significant cost to Neural Architecture Search (NAS) processes
when searching for efficient convolutional neural networks for embedded vision
applications. DNN Latency is a hardware dependent metric and requires direct
measurement or inference on target hardware. A recently introduced latency
estimation technique known as MAPLE predicts DNN execution time on previously
unseen hardware devices by using hardware performance counters. Leveraging
these hardware counters in the form of an implicit prior, MAPLE achieves
state-of-the-art performance in latency prediction. Here, we propose MAPLE-X
which extends MAPLE by incorporating explicit prior knowledge of hardware
devices and DNN architecture latency to better account for model stability and
robustness. First, by identifying DNN architectures that exhibit a similar
latency to each other, we can generate multiple virtual examples to
significantly improve the accuracy over MAPLE. Secondly, the hardware
specifications are used to determine the similarity between training and test
hardware to emphasize training samples captured from comparable devices
(domains) and encourages improved domain alignment. Experimental results using
a convolution neural network NAS benchmark across different types of devices,
including an Intel processor that is now used for embedded vision applications,
demonstrate a 5% improvement over MAPLE and 9% over HELP. Furthermore, we
include ablation studies to independently assess the benefits of virtual
examples and hardware-based sample importance.</p>
  </details>
</details>
<details>
  <summary>35. <b>标题：Fast Inference and Transfer of Compositional Task Structures for  Few-shot Task Generalization</b></summary>
  <p><b>编号</b>：[117]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12648</p>
  <p><b>作者</b>：Sungryull Sohn,  Hyunjae Woo,  Jongwook Choi,  lyubing qiang,  Izzeddin Gur,  Aleksandra Faust,  Honglak Lee</p>
  <p><b>备注</b>：Accepted to UAI 2022 as an oral presentation</p>
  <p><b>关键词</b>：tackle real-world problems, game or simulator, tackle real-world, pixel-based game, reinforcement learning problem</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We tackle real-world problems with complex structures beyond the pixel-based
game or simulator. We formulate it as a few-shot reinforcement learning problem
where a task is characterized by a subtask graph that defines a set of subtasks
and their dependencies that are unknown to the agent. Different from the
previous meta-rl methods trying to directly infer the unstructured task
embedding, our multi-task subtask graph inferencer (MTSGI) first infers the
common high-level task structure in terms of the subtask graph from the
training tasks, and use it as a prior to improve the task inference in testing.
Our experiment results on 2D grid-world and complex web navigation domains show
that the proposed method can learn and leverage the common underlying structure
of the tasks for faster adaptation to the unseen tasks than various existing
algorithms such as meta reinforcement learning, hierarchical reinforcement
learning, and other heuristic agents.</p>
  </details>
</details>
<details>
  <summary>36. <b>标题：Autoformalization with Large Language Models</b></summary>
  <p><b>编号</b>：[137]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12615</p>
  <p><b>作者</b>：Yuhuai Wu,  Albert Q. Jiang,  Wenda Li,  Markus N. Rabe,  Charles Staats,  Mateja Jamnik,  Christian Szegedy</p>
  <p><b>备注</b>：44 pages</p>
  <p><b>关键词</b>：natural language mathematics, automatically translating, translating from natural, formal specifications, natural language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Autoformalization is the process of automatically translating from natural
language mathematics to formal specifications and proofs. A successful
autoformalization system could advance the fields of formal verification,
program synthesis, and artificial intelligence. While the long-term goal of
autoformalization seemed elusive for a long time, we show large language models
provide new prospects towards this goal. We make the surprising observation
that LLMs can correctly translate a significant portion ($25.3\%$) of
mathematical competition problems perfectly to formal specifications in
Isabelle/HOL. We demonstrate the usefulness of this process by improving a
previously introduced neural theorem prover via training on these
autoformalized theorems. Our methodology results in a new state-of-the-art
result on the MiniF2F theorem proving benchmark, improving the proof rate from
$29.6\%$ to $35.2\%$.</p>
  </details>
</details>
<details>
  <summary>37. <b>标题：Deep Aesthetic Assessment and Retrieval of Breast Cancer Treatment  Outcomes</b></summary>
  <p><b>编号</b>：[138]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12611</p>
  <p><b>作者</b>：Wilson Silva,  Maria Carvalho,  Carlos Mavioso,  Maria J. Cardoso,  Jaime S. Cardoso</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：breast cancer treatments, breast cancer, cancer treatments, recent years, continued to evolve</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Treatments for breast cancer have continued to evolve and improve in recent
years, resulting in a substantial increase in survival rates, with
approximately 80\% of patients having a 10-year survival period. Given the
serious impact that breast cancer treatments can have on a patient's body
image, consequently affecting her self-confidence and sexual and intimate
relationships, it is paramount to ensure that women receive the treatment that
optimizes both survival and aesthetic outcomes. Currently, there is no gold
standard for evaluating the aesthetic outcome of breast cancer treatment. In
addition, there is no standard way to show patients the potential outcome of
surgery. The presentation of similar cases from the past would be extremely
important to manage women's expectations of the possible outcome. In this work,
we propose a deep neural network to perform the aesthetic evaluation. As a
proof-of-concept, we focus on a binary aesthetic evaluation. Besides its use
for classification, this deep neural network can also be used to find the most
similar past cases by searching for nearest neighbours in the highly semantic
space before classification. We performed the experiments on a dataset
consisting of 143 photos of women after conservative treatment for breast
cancer. The results for accuracy and balanced accuracy showed the superior
performance of our proposed model compared to the state of the art in aesthetic
evaluation of breast cancer treatments. In addition, the model showed a good
ability to retrieve similar previous cases, with the retrieved cases having the
same or adjacent class (in the 4-class setting) and having similar types of
asymmetry. Finally, a qualitative interpretability assessment was also
performed to analyse the robustness and trustworthiness of the model.</p>
  </details>
</details>
<details>
  <summary>38. <b>标题：Learning Distributions by Generative Adversarial Networks: Approximation  and Generalization</b></summary>
  <p><b>编号</b>：[143]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12601</p>
  <p><b>作者</b>：Yunfei Yang</p>
  <p><b>备注</b>：PhD Thesis. The contents are mainly from our previous works: arXiv:2105.13010, arXiv:2101.12353, arXiv:2201.09418 and arXiv:2005.11949</p>
  <p><b>关键词</b>：generative adversarial networks, generative adversarial, finite samples, samples by analyzing, error</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We study how well generative adversarial networks (GAN) learn probability
distributions from finite samples by analyzing the convergence rates of these
models. Our analysis is based on a new oracle inequality that decomposes the
estimation error of GAN into the discriminator and generator approximation
errors, generalization error and optimization error. To estimate the
discriminator approximation error, we establish error bounds on approximating
Hölder functions by ReLU neural networks, with explicit upper bounds on the
Lipschitz constant of the network or norm constraint on the weights. For
generator approximation error, we show that neural network can approximately
transform a low-dimensional source distribution to a high-dimensional target
distribution and bound such approximation error by the width and depth of
neural network. Combining the approximation results with generalization bounds
of neural networks from statistical learning theory, we establish the
convergence rates of GANs in various settings, when the error is measured by a
collection of integral probability metrics defined through Hölder classes,
including the Wasserstein distance as a special case. In particular, for
distributions concentrated around a low-dimensional set, we show that the
convergence rates of GANs do not depend on the high ambient dimension, but on
the lower intrinsic dimension.</p>
  </details>
</details>
<details>
  <summary>39. <b>标题：ORCA: Interpreting Prompted Language Models via Locating Supporting Data  Evidence in the Ocean of Pretraining Data</b></summary>
  <p><b>编号</b>：[144]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12600</p>
  <p><b>作者</b>：Xiaochuang Han,  Yulia Tsvetkov</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Large pretrained language, pretrained language models, Large pretrained, performing increasingly, supporting data evidence</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large pretrained language models have been performing increasingly well in a
variety of downstream tasks via prompting. However, it remains unclear from
where the model learns the task-specific knowledge, especially in a zero-shot
setup. In this work, we want to find evidence of the model's task-specific
competence from pretraining and are specifically interested in locating a very
small subset of pretraining data that directly supports the model in the task.
We call such a subset supporting data evidence and propose a novel method ORCA
to effectively identify it, by iteratively using gradient information related
to the downstream task. This supporting data evidence offers interesting
insights about the prompted language models: in the tasks of sentiment analysis
and textual entailment, BERT shows a substantial reliance on BookCorpus, the
smaller corpus of BERT's two pretraining corpora, as well as on pretraining
examples that mask out synonyms to the task verbalizers.</p>
  </details>
</details>
<details>
  <summary>40. <b>标题：RobustLR: Evaluating Robustness to Logical Perturbation in Deductive  Reasoning</b></summary>
  <p><b>编号</b>：[145]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12598</p>
  <p><b>作者</b>：Soumya Sanyal,  Zeyi Liao,  Xiang Ren</p>
  <p><b>备注</b>：13 pages</p>
  <p><b>关键词</b>：English natural language, written in English, English natural, rules and statements, statements written</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Transformers have been shown to be able to perform deductive reasoning on a
logical rulebase containing rules and statements written in English natural
language. While the progress is promising, it is currently unclear if these
models indeed perform logical reasoning by understanding the underlying logical
semantics in the language. To this end, we propose RobustLR, a suite of
evaluation datasets that evaluate the robustness of these models to minimal
logical edits in rulebases and some standard logical equivalence conditions. In
our experiments with RoBERTa and T5, we find that the models trained in prior
works do not perform consistently on the different perturbations in RobustLR,
thus showing that the models are not robust to the proposed logical
perturbations. Further, we find that the models find it especially hard to
learn logical negation and disjunction operators. Overall, using our evaluation
sets, we demonstrate some shortcomings of the deductive reasoning-based
language models, which can eventually help towards designing better models for
logical reasoning over natural language.</p>
  </details>
</details>
<details>
  <summary>41. <b>标题：Heterogeneous Reservoir Computing Models for Persian Speech Recognition</b></summary>
  <p><b>编号</b>：[149]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12594</p>
  <p><b>作者</b>：Zohreh Ansari,  Farzin Pourhoseini,  Fatemeh Hadaeghi</p>
  <p><b>备注</b>：This paper was accepted for oral presentation in IEEE WCCI 2022 + IJCNN 2022, special session on Reservoir Computing: algorithms, implementations and applications</p>
  <p><b>关键词</b>：deep-learning methods, gradually incorporated, automatic speech recognition, models, ASR applications</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Over the last decade, deep-learning methods have been gradually incorporated
into conventional automatic speech recognition (ASR) frameworks to create
acoustic, pronunciation, and language models. Although it led to significant
improvements in ASRs' recognition accuracy, due to their hard constraints
related to hardware requirements (e.g., computing power and memory usage), it
is unclear if such approaches are the most computationally- and
energy-efficient options for embedded ASR applications. Reservoir computing
(RC) models (e.g., echo state networks (ESNs) and liquid state machines
(LSMs)), on the other hand, have been proven inexpensive to train, have vastly
fewer parameters, and are compatible with emergent hardware technologies.
However, their performance in speech processing tasks is relatively inferior to
that of the deep-learning-based models. To enhance the accuracy of the RC in
ASR applications, we propose heterogeneous single and multi-layer ESNs to
create non-linear transformations of the inputs that capture temporal context
at different scales. To test our models, we performed a speech recognition task
on the Farsdat Persian dataset. Since, to the best of our knowledge, standard
RC has not yet been employed to conduct any Persian ASR tasks, we also trained
conventional single-layer and deep ESNs to provide baselines for comparison.
Besides, we compared the RC performance with a standard long-short-term memory
(LSTM) model. Heterogeneous RC models (1) show improved performance to the
standard RC models; (2) perform on par in terms of recognition accuracy with
the LSTM, and (3) reduce the training time considerably.</p>
  </details>
</details>
<details>
  <summary>42. <b>标题：Towards a Fair Comparison and Realistic Design and Evaluation Framework  of Android Malware Detectors</b></summary>
  <p><b>编号</b>：[162]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12569</p>
  <p><b>作者</b>：Borja Molina-Coronado,  Usue Mori,  Alexander Mendiburu,  Jose Miguel-Alonso</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：detect Android malware, Android malware detection, machine learning, Android malware, cybersecurity areas</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As in other cybersecurity areas, machine learning (ML) techniques have
emerged as a promising solution to detect Android malware. In this sense, many
proposals employing a variety of algorithms and feature sets have been
presented to date, often reporting impresive detection performances. However,
the lack of reproducibility and the absence of a standard evaluation framework
make these proposals difficult to compare. In this paper, we perform an
analysis of 10 influential research works on Android malware detection using a
common evaluation framework. We have identified five factors that, if not taken
into account when creating datasets and designing detectors, significantly
affect the trained ML models and their performances. In particular, we analyze
the effect of (1) the presence of duplicated samples, (2) label
(goodware/greyware/malware) attribution, (3) class imbalance, (4) the presence
of apps that use evasion techniques and, (5) the evolution of apps. Based on
this extensive experimentation, we conclude that the studied ML-based detectors
have been evaluated optimistically, which justifies the good published results.
Our findings also highlight that it is imperative to generate realistic
datasets, taking into account the factors mentioned above, to enable the design
and evaluation of better solutions for Android malware detection.</p>
  </details>
</details>
<details>
  <summary>43. <b>标题：Learning dynamics from partial observations with structured neural ODEs</b></summary>
  <p><b>编号</b>：[171]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12550</p>
  <p><b>作者</b>：Mona Buisson-Fenet,  Valery Morgenthaler,  Sebastian Trimpe,  Florent Di Meglio</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：notably difficult task, Identifying dynamical systems, Identifying dynamical, difficult task, notably difficult</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Identifying dynamical systems from experimental data is a notably difficult
task. Prior knowledge generally helps, but the extent of this knowledge varies
with the application, and customized models are often needed. We propose a
flexible framework to incorporate a broad spectrum of physical insight into
neural ODE-based system identification, giving physical interpretability to the
resulting latent space. This insight is either enforced through hard
constraints in the optimization problem or added in its cost function. In order
to link the partial and possibly noisy observations to the latent state, we
rely on tools from nonlinear observer theory to build a recognition model. We
demonstrate the performance of the proposed approach on numerical simulations
and on an experimental dataset from a robotic exoskeleton.</p>
  </details>
</details>
<details>
  <summary>44. <b>标题：Learning from time-dependent streaming data with online stochastic  algorithms</b></summary>
  <p><b>编号</b>：[172]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12549</p>
  <p><b>作者</b>：Antoine Godichon-Baggioni (LPSM (UMR\_8001)),  Nicklas Werge (LPSM (UMR\_8001)),  Olivier Wintenberger (LPSM (UMR\_8001))</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：study stochastic algorithms, stochastic gradient descent, well-known stochastic gradient, Stochastic Gradient, trained on samples</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We study stochastic algorithms in a streaming framework, trained on samples
coming from a dependent data source. In this streaming framework, we analyze
the convergence of Stochastic Gradient (SG) methods in a non-asymptotic manner;
this includes various SG methods such as the well-known stochastic gradient
descent (i.e., Robbins-Monro algorithm), mini-batch SG methods, together with
their averaged estimates (i.e., Polyak-Ruppert averaged). Our results form a
heuristic by linking the level of dependency and convexity to the rest of the
model parameters. This heuristic provides new insights into choosing the
optimal learning rate, which can help increase the stability of SGbased
methods; these investigations suggest large streaming batches with slow
decaying learning rates for highly dependent data sources.</p>
  </details>
</details>
<details>
  <summary>45. <b>标题：RLPrompt: Optimizing Discrete Text Prompts With Reinforcement Learning</b></summary>
  <p><b>编号</b>：[173]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12548</p>
  <p><b>作者</b>：Mingkai Deng,  Jianyu Wang,  Cheng-Ping Hsieh,  Yihan Wang,  Han Guo,  Tianmin Shu,  Meng Song,  Eric P. Xing,  Zhiting Hu</p>
  <p><b>备注</b>：Code available at this https URL</p>
  <p><b>关键词</b>：perform diverse NLP, diverse NLP tasks, shown impressive success, diverse NLP, NLP tasks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Prompting has shown impressive success in enabling large pretrained language
models (LMs) to perform diverse NLP tasks, especially when only few downstream
data are available. Automatically finding the optimal prompt for each task,
however, is challenging. Most existing work resorts to tuning soft prompt
(e.g., embeddings) which falls short of interpretability, reusability across
LMs, and applicability when gradients are not accessible. Discrete prompt, on
the other hand, is difficult to optimize, and is often created by "enumeration
(e.g., paraphrasing)-then-selection" heuristics that do not explore the prompt
space systematically. This paper proposes RLPrompt, an efficient discrete
prompt optimization approach with reinforcement learning (RL). RLPrompt
formulates a parameter-efficient policy network that generates the desired
discrete prompt after training with reward. To overcome the complexity and
stochasticity of reward signals by the large LM environment, we incorporate
effective reward stabilization that substantially enhances the training
efficiency. RLPrompt is flexibly applicable to different types of LMs, such as
masked (e.g., BERT) and left-to-right models (e.g., GPTs), for both
classification and generation tasks. Experiments on few-shot classification and
unsupervised text style transfer show superior performance over a wide range of
existing finetuning or prompting methods. Interestingly, the resulting
optimized prompts are often ungrammatical gibberish text; and surprisingly,
those gibberish prompts are transferrable between different LMs to retain
significant performance, indicating LM prompting may not follow human language
patterns.</p>
  </details>
</details>
<details>
  <summary>46. <b>标题：Misleading Deep-Fake Detection with GAN Fingerprints</b></summary>
  <p><b>编号</b>：[176]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12543</p>
  <p><b>作者</b>：Vera Wesselkamp,  Konrad Rieck,  Daniel Arp,  Erwin Quiring</p>
  <p><b>备注</b>：In IEEE Deep Learning and Security Workshop (DLS) 2022</p>
  <p><b>关键词</b>：Generative adversarial networks, made remarkable progress, synthesizing realistic-looking images, Generative adversarial, adversarial networks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Generative adversarial networks (GANs) have made remarkable progress in
synthesizing realistic-looking images that effectively outsmart even humans.
Although several detection methods can recognize these deep fakes by checking
for image artifacts from the generation process, multiple counterattacks have
demonstrated their limitations. These attacks, however, still require certain
conditions to hold, such as interacting with the detection method or adjusting
the GAN directly. In this paper, we introduce a novel class of simple
counterattacks that overcomes these limitations. In particular, we show that an
adversary can remove indicative artifacts, the GAN fingerprint, directly from
the frequency spectrum of a generated image. We explore different realizations
of this removal, ranging from filtering high frequencies to more nuanced
frequency-peak cleansing. We evaluate the performance of our attack with
different detection methods, GAN architectures, and datasets. Our results show
that an adversary can often remove GAN fingerprints and thus evade the
detection of generated images.</p>
  </details>
</details>
<details>
  <summary>47. <b>标题：Is a Question Decomposition Unit All We Need?</b></summary>
  <p><b>编号</b>：[179]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12538</p>
  <p><b>作者</b>：Pruthvi Patel,  Swaroop Mishra,  Mihir Parmar,  Chitta Baral</p>
  <p><b>备注</b>：16 pages</p>
  <p><b>关键词</b>：Natural Language Processing, Language Processing, Natural Language, Large Language Models, Language Models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large Language Models (LMs) have achieved state-of-the-art performance on
many Natural Language Processing (NLP) benchmarks. With the growing number of
new benchmarks, we build bigger and more complex LMs. However, building new LMs
may not be an ideal option owing to the cost, time and environmental impact
associated with it. We explore an alternative route: can we modify data by
expressing it in terms of the model's strengths, so that a question becomes
easier for models to answer? We investigate if humans can decompose a hard
question into a set of simpler questions that are relatively easier for models
to solve. We analyze a range of datasets involving various forms of reasoning
and find that it is indeed possible to significantly improve model performance
(24% for GPT3 and 29% for RoBERTa-SQuAD along with a symbolic calculator) via
decomposition. Our approach provides a viable option to involve people in NLP
research in a meaningful way. Our findings indicate that Human-in-the-loop
Question Decomposition (HQD) can potentially provide an alternate path to
building large LMs.</p>
  </details>
</details>
<details>
  <summary>48. <b>标题：Structured Uncertainty in the Observation Space of Variational  Autoencoders</b></summary>
  <p><b>编号</b>：[181]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12533</p>
  <p><b>作者</b>：James Langley,  Miguel Monteiro,  Charles Jones,  Nick Pawlowski,  Ben Glocker</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：deep generative models, Variational autoencoders, range of applications, popular class, class of deep</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Variational autoencoders (VAEs) are a popular class of deep generative models
with many variants and a wide range of applications. Improvements upon the
standard VAE mostly focus on the modelling of the posterior distribution over
the latent space and the properties of the neural network decoder. In contrast,
improving the model for the observational distribution is rarely considered and
typically defaults to a pixel-wise independent categorical or normal
distribution. In image synthesis, sampling from such distributions produces
spatially-incoherent results with uncorrelated pixel noise, resulting in only
the sample mean being somewhat useful as an output prediction. In this paper,
we aim to stay true to VAE theory by improving the samples from the
observational distribution. We propose an alternative model for the observation
space, encoding spatial dependencies via a low-rank parameterisation. We
demonstrate that this new observational distribution has the ability to capture
relevant covariance between pixels, resulting in spatially-coherent samples. In
contrast to pixel-wise independent distributions, our samples seem to contain
semantically meaningful variations from the mean allowing the prediction of
multiple plausible outputs with a single forward pass.</p>
  </details>
</details>
<details>
  <summary>49. <b>标题：Skill Machines: Temporal Logic Composition in Reinforcement Learning</b></summary>
  <p><b>编号</b>：[182]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12532</p>
  <p><b>作者</b>：Geraud Nangue Tasse,  Devon Jarvis,  Steven James,  Benjamin Rosman</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：interpretable and verifiable, major challenge, machines, agent, reward machines</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A major challenge in reinforcement learning is specifying tasks in a manner
that is both interpretable and verifiable. One common approach is to specify
tasks through reward machines -- finite state machines that encode the task to
be solved. We introduce skill machines, a representation that can be learned
directly from these reward machines that encode the solution to such tasks. We
propose a framework where an agent first learns a set of base skills in a
reward-free setting, and then combines these skills with the learned skill
machine to produce composite behaviours specified by any regular language, such
as linear temporal logics. This provides the agent with the ability to map from
complex logical task specifications to near-optimal behaviours zero-shot. We
demonstrate our approach in both a tabular and high-dimensional video game
environment, where an agent is faced with several of these complex,
long-horizon tasks. Our results indicate that the agent is capable of
satisfying extremely complex task specifications, producing near optimal
performance with no further learning. Finally, we demonstrate that the
performance of skill machines can be improved with regular offline
reinforcement learning algorithms when optimal behaviours are desired.</p>
  </details>
</details>
<details>
  <summary>50. <b>标题：Toward Discovering Options that Achieve Faster Planning</b></summary>
  <p><b>编号</b>：[190]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12515</p>
  <p><b>作者</b>：Yi Wan,  Richard S. Sutton</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：options, objective, discovery that emphasizes, emphasizes the computational, computational advantage</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose a new objective for option discovery that emphasizes the
computational advantage of using options in planning. For a given set of
episodic tasks and a given number of options, the objective prefers options
that can be used to achieve a high return by composing few options. By
composing few options, fast planning can be achieved. When faced with new tasks
similar to the given ones, the discovered options are also expected to
accelerate planning. Our objective extends the objective proposed by Harb et
al. (2018) for the single-task setting to the multi-task setting. A closer look
at Harb et al.'s objective shows that the best options discovered given one
task are not likely to be useful for future unseen tasks and that the
multi-task setting is indeed necessary for this purpose. In the same paper,
Harb et al. also proposed an algorithm to optimize their objective, and the
algorithm can be naturally extended to the multi-task setting. We empirically
show that in the four-room domain the extension does not achieve a high
objective value and propose a new algorithm that better optimizes the proposed
objective. In the same four-room domain, we show that 1) a higher objective
value is typically associated with options with which fewer planning iterations
are needed to achieve near-optimal performance, 2) our new algorithm achieves a
high objective value, which is close to the value achieved by a set of
human-designed options, 3) the best number of planning iterations given the
discovered options is much smaller and matches it obtained given human-designed
options, and 4) the options produced by our algorithm also make intuitive sense
because they move to and terminate at cells near hallways connecting two
neighbor rooms.</p>
  </details>
</details>
<details>
  <summary>51. <b>标题：Exact Phase Transitions in Deep Learning</b></summary>
  <p><b>编号</b>：[193]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12510</p>
  <p><b>作者</b>：Liu Ziyin,  Masahito Ueda</p>
  <p><b>备注</b>：preprint</p>
  <p><b>关键词</b>：second-order phase transitions, first-order phase transition, phase transition, second-order phase, work reports</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This work reports deep-learning-unique first-order and second-order phase
transitions, whose phenomenology closely follows that in statistical physics.
In particular, we prove that the competition between prediction error and model
complexity in the training loss leads to the second-order phase transition for
nets with one hidden layer and the first-order phase transition for nets with
more than one hidden layer. The proposed theory is directly relevant to the
optimization of neural networks and points to an origin of the posterior
collapse problem in Bayesian deep learning.</p>
  </details>
</details>
<details>
  <summary>52. <b>标题：Memorization in NLP Fine-tuning Methods</b></summary>
  <p><b>编号</b>：[195]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12506</p>
  <p><b>作者</b>：Fatemehsadat Mireshghallah,  Archit Uniyal,  Tianhao Wang,  David Evans,  Taylor Berg-Kirkpatrick</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Large language models, present privacy risks, Large language, training data, recent works</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large language models are shown to present privacy risks through memorization
of training data, and several recent works have studied such risks for the
pre-training phase. Little attention, however, has been given to the
fine-tuning phase and it is not well understood how different fine-tuning
methods (such as fine-tuning the full model, the model head, and adapter)
compare in terms of memorization risk. This presents increasing concern as the
"pre-train and fine-tune" paradigm proliferates. In this paper, we empirically
study memorization of fine-tuning methods using membership inference and
extraction attacks, and show that their susceptibility to attacks is very
different. We observe that fine-tuning the head of the model has the highest
susceptibility to attacks, whereas fine-tuning smaller adapters appears to be
less vulnerable to known extraction attacks.</p>
  </details>
</details>
<details>
  <summary>53. <b>标题：The Dialog Must Go On: Improving Visual Dialog via Generative  Self-Training</b></summary>
  <p><b>编号</b>：[199]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12502</p>
  <p><b>作者</b>：Gi-Cheon Kang,  Sungdong Kim,  Jin-Hwa Kim,  Donghyun Kwak,  Byoung-Tak Zhang</p>
  <p><b>备注</b>：16 pages, 4 figures</p>
  <p><b>关键词</b>：history as context, task of answering, answering a sequence, sequence of questions, questions grounded</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Visual dialog (VisDial) is a task of answering a sequence of questions
grounded in an image, using the dialog history as context. Prior work has
trained the dialog agents solely on VisDial data via supervised learning or
leveraged pre-training on related vision-and-language datasets. This paper
presents a semi-supervised learning approach for visually-grounded dialog,
called Generative Self-Training (GST), to leverage unlabeled images on the Web.
Specifically, GST first retrieves in-domain images through out-of-distribution
detection and generates synthetic dialogs regarding the images via multimodal
conditional text generation. GST then trains a dialog agent on the synthetic
and the original VisDial data. As a result, GST scales the amount of training
data up to an order of magnitude that of VisDial (1.2M to 12.9M QA data). For
robust training of the generated dialogs, we also propose perplexity-based data
selection and multimodal consistency regularization. Evaluation on VisDial v1.0
and v0.9 datasets shows that GST achieves new state-of-the-art results on both
datasets. We further observe strong performance gains in the low-data regime
(up to 9.35 absolute points on NDCG).</p>
  </details>
</details>
<details>
  <summary>54. <b>标题：Federated Self-supervised Learning for Heterogeneous Clients</b></summary>
  <p><b>编号</b>：[204]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12493</p>
  <p><b>作者</b>：Disha Makhija,  Nhat Ho,  Joydeep Ghosh</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：important learning paradigm, learning paradigm due, computational benefits, paradigm due, privacy and computational</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Federated Learning has become an important learning paradigm due to its
privacy and computational benefits. As the field advances, two key challenges
that still remain to be addressed are: (1) system heterogeneity - variability
in the compute and/or data resources present on each client, and (2) lack of
labeled data in certain federated settings. Several recent developments have
tried to overcome these challenges independently. In this work, we propose a
unified and systematic framework, \emph{Heterogeneous Self-supervised Federated
Learning} (Hetero-SSFL) for enabling self-supervised learning with federation
on heterogeneous clients. The proposed framework allows collaborative
representation learning across all the clients without imposing architectural
constraints or requiring presence of labeled data. The key idea in Hetero-SSFL
is to let each client train its unique self-supervised model and enable the
joint learning across clients by aligning the lower dimensional representations
on a common dataset. The entire training procedure could be viewed as self and
peer-supervised as both the local training and the alignment procedures do not
require presence of any labeled data. As in conventional self-supervised
learning, the obtained client models are task independent and can be used for
varied end-tasks. We provide a convergence guarantee of the proposed framework
for non-convex objectives in heterogeneous settings and also empirically
demonstrate that our proposed approach outperforms the state of the art methods
by a significant margin.</p>
  </details>
</details>
<details>
  <summary>55. <b>标题：FBNETGEN: Task-aware GNN-based fMRI Analysis via Functional Brain  Network Generation</b></summary>
  <p><b>编号</b>：[221]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12465</p>
  <p><b>作者</b>：Xuan Kan,  Hejie Cui,  Joshua Lukemire,  Ying Guo,  Carl Yang</p>
  <p><b>备注</b>：This paper has been accepted for presentation in MIDL 2022</p>
  <p><b>关键词</b>：common imaging modalities, magnetic resonance imaging, investigate brain functions, Functional magnetic resonance, functional brain networks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Functional magnetic resonance imaging (fMRI) is one of the most common
imaging modalities to investigate brain functions. Recent studies in
neuroscience stress the great potential of functional brain networks
constructed from fMRI data for clinical predictions. Traditional functional
brain networks, however, are noisy and unaware of downstream prediction tasks,
while also incompatible with the deep graph neural network (GNN) models. In
order to fully unleash the power of GNNs in network-based fMRI analysis, we
develop FBNETGEN, a task-aware and interpretable fMRI analysis framework via
deep brain network generation. In particular, we formulate (1) prominent region
of interest (ROI) features extraction, (2) brain networks generation, and (3)
clinical predictions with GNNs, in an end-to-end trainable model under the
guidance of particular prediction tasks. Along with the process, the key novel
component is the graph generator which learns to transform raw time-series
features into task-oriented brain networks. Our learnable graphs also provide
unique interpretations by highlighting prediction-related brain regions.
Comprehensive experiments on two datasets, i.e., the recently released and
currently largest publicly available fMRI dataset Adolescent Brain Cognitive
Development (ABCD), and the widely-used fMRI dataset PNC, prove the superior
effectiveness and interpretability of FBNETGEN. The implementation is available
at this https URL.}</p>
  </details>
</details>
<details>
  <summary>56. <b>标题：sat2pc: Estimating Point Cloud of Building Roofs from 2D Satellite  Images</b></summary>
  <p><b>编号</b>：[222]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12464</p>
  <p><b>作者</b>：Yoones Rezaei,  Stephen Lee</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：virtual reality, urban planning, gained interest, planning and virtual, urban</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Three-dimensional (3D) urban models have gained interest because of their
applications in many use-cases such as urban planning and virtual reality.
However, generating these 3D representations requires LiDAR data, which are not
always readily available. Thus, the applicability of automated 3D model
generation algorithms is limited to a few locations. In this paper, we propose
sat2pc, a deep learning architecture that predicts the point cloud of a
building roof from a single 2D satellite image. Our architecture combines
Chamfer distance and EMD loss, resulting in better 2D to 3D performance. We
extensively evaluate our model and perform ablation studies on a building roof
dataset. Our results show that sat2pc was able to outperform existing baselines
by at least 18.6%. Further, we show that the predicted point cloud captures
more detail and geometric characteristics than other baselines.</p>
  </details>
</details>
<details>
  <summary>57. <b>标题：Augmentation-induced Consistency Regularization for Classification</b></summary>
  <p><b>编号</b>：[224]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12461</p>
  <p><b>作者</b>：Jianhan Wu,  Shijing Si,  Jianzong Wang,  Jing Xiao</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Deep neural networks, supervised learning tasks, data augmentation, Deep neural, supervised learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep neural networks have become popular in many supervised learning tasks,
but they may suffer from overfitting when the training dataset is limited. To
mitigate this, many researchers use data augmentation, which is a widely used
and effective method for increasing the variety of datasets. However, the
randomness introduced by data augmentation causes inevitable inconsistency
between training and inference, which leads to poor improvement. In this paper,
we propose a consistency regularization framework based on data augmentation,
called CR-Aug, which forces the output distributions of different sub models
generated by data augmentation to be consistent with each other. Specifically,
CR-Aug evaluates the discrepancy between the output distributions of two
augmented versions of each sample, and it utilizes a stop-gradient operation to
minimize the consistency loss. We implement CR-Aug to image and audio
classification tasks and conduct extensive experiments to verify its
effectiveness in improving the generalization ability of classifiers. Our
CR-Aug framework is ready-to-use, it can be easily adapted to many
state-of-the-art network architectures. Our empirical results show that CR-Aug
outperforms baseline methods by a significant margin.</p>
  </details>
</details>
<details>
  <summary>58. <b>标题：Investigating Information Inconsistency in Multilingual Open-Domain  Question Answering</b></summary>
  <p><b>编号</b>：[227]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12456</p>
  <p><b>作者</b>：Shramay Palta,  Haozhe An,  Yifan Yang,  Shuaiyi Huang,  Maharshi Gor</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：find best-answer candidates, best-answer candidates, retrieved documents, answer-span selection, find best-answer</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Retrieval based open-domain QA systems use retrieved documents and
answer-span selection over retrieved documents to find best-answer candidates.
We hypothesize that multilingual Question Answering (QA) systems are prone to
information inconsistency when it comes to documents written in different
languages, because these documents tend to provide a model with varying
information about the same topic. To understand the effects of the biased
availability of information and cultural influence, we analyze the behavior of
multilingual open-domain question answering models with a focus on retrieval
bias. We analyze if different retriever models present different passages given
the same question in different languages on TyDi QA and XOR-TyDi QA, two
multilingualQA datasets. We speculate that the content differences in documents
across languages might reflect cultural divergences and/or social biases.</p>
  </details>
</details>
<details>
  <summary>59. <b>标题：Recipe for a General, Powerful, Scalable Graph Transformer</b></summary>
  <p><b>编号</b>：[228]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12454</p>
  <p><b>作者</b>：Ladislav Rampášek,  Mikhail Galkin,  Vijay Prakash Dwivedi,  Anh Tuan Luu,  Guy Wolf,  Dominique Beaini</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：textit, structural encoding, powerful, scalable, GPS</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose a recipe on how to build a general, powerful, scalable (GPS) graph
Transformer with linear complexity and state-of-the-art results on a diverse
set of benchmarks. Graph Transformers (GTs) have gained popularity in the field
of graph representation learning with a variety of recent publications but they
lack a common foundation about what constitutes a good positional or structural
encoding, and what differentiates them. In this paper, we summarize the
different types of encodings with a clearer definition and categorize them as
being $\textit{local}$, $\textit{global}$ or $\textit{relative}$. Further, GTs
remain constrained to small graphs with few hundred nodes, and we propose the
first architecture with a complexity linear to the number of nodes and edges
$O(N+E)$ by decoupling the local real-edge aggregation from the fully-connected
Transformer. We argue that this decoupling does not negatively affect the
expressivity, with our architecture being a universal function approximator for
graphs. Our GPS recipe consists of choosing 3 main ingredients: (i)
positional/structural encoding, (ii) local message-passing mechanism, and (iii)
global attention mechanism. We build and open-source a modular framework
$\textit{GraphGPS}$ that supports multiple types of encodings and that provides
efficiency and scalability both in small and large graphs. We test our
architecture on 11 benchmarks and show very competitive results on all of them,
show-casing the empirical benefits gained by the modularity and the combination
of different strategies.</p>
  </details>
</details>
<details>
  <summary>60. <b>标题：MAVIPER: Learning Decision Tree Policies for Interpretable Multi-Agent  Reinforcement Learning</b></summary>
  <p><b>编号</b>：[233]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12449</p>
  <p><b>作者</b>：Stephanie Milani,  Zhicheng Zhang,  Nicholay Topin,  Zheyuan Ryan Shi,  Charles Kamhoua,  Evangelos E. Papalexakis,  Fei Fang</p>
  <p><b>备注</b>：25 pages</p>
  <p><b>关键词</b>：multi-agent reinforcement learning, deep neural networks, reinforcement learning, interpret and understand, challenging for human</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Many recent breakthroughs in multi-agent reinforcement learning (MARL)
require the use of deep neural networks, which are challenging for human
experts to interpret and understand. On the other hand, existing work on
interpretable RL has shown promise in extracting more interpretable decision
tree-based policies, but only in the single-agent setting. To fill this gap, we
propose the first set of interpretable MARL algorithms that extract
decision-tree policies from neural networks trained with MARL. The first
algorithm, IVIPER, extends VIPER, a recent method for single-agent
interpretable RL, to the multi-agent setting. We demonstrate that IVIPER can
learn high-quality decision-tree policies for each agent. To better capture
coordination between agents, we propose a novel centralized decision-tree
training algorithm, MAVIPER. MAVIPER jointly grows the trees of each agent by
predicting the behavior of the other agents using their anticipated trees, and
uses resampling to focus on states that are critical for its interactions with
other agents. We show that both algorithms generally outperform the baselines
and that MAVIPER-trained agents achieve better-coordinated performance than
IVIPER-trained agents on three different multi-agent particle-world
environments.</p>
  </details>
</details>
<details>
  <summary>61. <b>标题：FLEURS: Few-shot Learning Evaluation of Universal Representations of  Speech</b></summary>
  <p><b>编号</b>：[234]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12446</p>
  <p><b>作者</b>：Alexis Conneau,  Min Ma,  Simran Khanuja,  Yu Zhang,  Vera Axelrod,  Siddharth Dalmia,  Jason Riesa,  Clara Rivera,  Ankur Bapna</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Few-shot Learning Evaluation, Evaluation of Universal, Few-shot Learning, Learning Evaluation, Speech</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We introduce FLEURS, the Few-shot Learning Evaluation of Universal
Representations of Speech benchmark. FLEURS is an n-way parallel speech dataset
in 102 languages built on top of the machine translation FLoRes-101 benchmark,
with approximately 12 hours of speech supervision per language. FLEURS can be
used for a variety of speech tasks, including Automatic Speech Recognition
(ASR), Speech Language Identification (Speech LangID), Translation and
Retrieval. In this paper, we provide baselines for the tasks based on
multilingual pre-trained models like mSLAM. The goal of FLEURS is to enable
speech technology in more languages and catalyze research in low-resource
speech understanding.</p>
  </details>
</details>
<details>
  <summary>62. <b>标题：Generating Natural Language Proofs with Verifier-Guided Search</b></summary>
  <p><b>编号</b>：[235]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12443</p>
  <p><b>作者</b>：Kaiyu Yang,  Jia Deng,  Danqi Chen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：problem in NLP, Deductive reasoning, drawing conclusions, conclusions from assumptions, natural language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deductive reasoning (drawing conclusions from assumptions) is a challenging
problem in NLP. In this work, we focus on proof generation: given a hypothesis
and a set of supporting facts in natural language, the model generates a proof
tree indicating how to deduce the hypothesis from supporting facts. Instead of
generating the entire proof in one shot, prior work has demonstrated the
promise of stepwise generation but achieved limited success on real-world data.
Existing stepwise methods struggle to generate proof steps that are both valid
and relevant. In this paper, we present a novel stepwise method NLProofS
(Natural Language Proof Search), which learns to generate relevant steps
conditioning on the hypothesis. At the core of our approach, we train an
independent verifier to check the validity of proof steps. Instead of
generating steps greedily, we search for proofs maximizing a global proof score
judged by the verifier. NLProofS achieves state-of-the-art performance on
EntailmentBank and RuleTaker. For example, it improves the percentage of
correctly predicted proofs from 20.9% to 33.3% in the distractor setting of
EntailmentBank. This is the first time stepwise methods have led to better
generation of challenging human-authored proofs.</p>
  </details>
</details>
<details>
  <summary>63. <b>标题：Additive Logistic Mechanism for Privacy-Preserving Self-Supervised  Learning</b></summary>
  <p><b>编号</b>：[236]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12430</p>
  <p><b>作者</b>：Yunhao Yang,  Parham Gohari,  Ufuk Topcu</p>
  <p><b>备注</b>：15 pages, 2 figures</p>
  <p><b>关键词</b>：neural network weights, self-supervised learning algorithms, network weights, training a neural, self-supervised learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We study the privacy risks that are associated with training a neural
network's weights with self-supervised learning algorithms. Through empirical
evidence, we show that the fine-tuning stage, in which the network weights are
updated with an informative and often private dataset, is vulnerable to privacy
attacks. To address the vulnerabilities, we design a post-training
privacy-protection algorithm that adds noise to the fine-tuned weights and
propose a novel differential privacy mechanism that samples noise from the
logistic distribution. Compared to the two conventional additive noise
mechanisms, namely the Laplace and the Gaussian mechanisms, the proposed
mechanism uses a bell-shaped distribution that resembles the distribution of
the Gaussian mechanism, and it satisfies pure $\epsilon$-differential privacy
similar to the Laplace mechanism. We apply membership inference attacks on both
unprotected and protected models to quantify the trade-off between the models'
privacy and performance. We show that the proposed protection algorithm can
effectively reduce the attack accuracy to roughly 50\%-equivalent to random
guessing-while maintaining a performance loss below 5\%.</p>
  </details>
</details>
<details>
  <summary>64. <b>标题：Towards Understanding Label Regularization for Fine-tuning Pre-trained  Language Models</b></summary>
  <p><b>编号</b>：[237]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12428</p>
  <p><b>作者</b>：Ivan Kobyzev,  Aref Jafari,  Mehdi Rezagholizadeh,  Tianda Li,  Alan Do-Omri,  Peng Lu,  Ali Ghodsi,  Pascal Poupart</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：neural model compression, prominent neural model, Knowledge Distillation, teacher network predictions, model compression technique</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Knowledge Distillation (KD) is a prominent neural model compression technique
which heavily relies on teacher network predictions to guide the training of a
student model. Considering the ever-growing size of pre-trained language models
(PLMs), KD is often adopted in many NLP tasks involving PLMs. However, it is
evident that in KD, deploying the teacher network during training adds to the
memory and computational requirements of training. In the computer vision
literature, the necessity of the teacher network is put under scrutiny by
showing that KD is a label regularization technique that can be replaced with
lighter teacher-free variants such as the label-smoothing technique. However,
to the best of our knowledge, this issue is not investigated in NLP. Therefore,
this work concerns studying different label regularization techniques and
whether we actually need the teacher labels to fine-tune smaller PLM student
networks on downstream tasks. In this regard, we did a comprehensive set of
experiments on different PLMs such as BERT, RoBERTa, and GPT with more than 600
distinct trials and ran each configuration five times. This investigation led
to a surprising observation that KD and other label regularization techniques
do not play any meaningful role over regular fine-tuning when the student model
is pre-trained. We further explore this phenomenon in different settings of NLP
and computer vision tasks and demonstrate that pre-training itself acts as a
kind of regularization, and additional label regularization is unnecessary.</p>
  </details>
</details>
<details>
  <summary>65. <b>标题：Non-stationary Bandits with Knapsacks</b></summary>
  <p><b>编号</b>：[238]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12427</p>
  <p><b>作者</b>：Shang Liu,  Jiashuo Jiang,  Xiaocheng Li</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：BwK problem, BwK problem generalizes, problem, BwK, non-stationarity</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we study the problem of bandits with knapsacks (BwK) in a
non-stationary environment. The BwK problem generalizes the multi-arm bandit
(MAB) problem to model the resource consumption associated with playing each
arm. At each time, the decision maker/player chooses to play an arm, and s/he
will receive a reward and consume certain amount of resource from each of the
multiple resource types. The objective is to maximize the cumulative reward
over a finite horizon subject to some knapsack constraints on the resources.
Existing works study the BwK problem under either a stochastic or adversarial
environment. Our paper considers a non-stationary environment which
continuously interpolates between these two extremes. We first show that the
traditional notion of variation budget is insufficient to characterize the
non-stationarity of the BwK problem for a sublinear regret due to the presence
of the constraints, and then we propose a new notion of global non-stationarity
measure. We employ both non-stationarity measures to derive upper and lower
bounds for the problem. Our results are based on a primal-dual analysis of the
underlying linear programs and highlight the interplay between the constraints
and the non-stationarity. Finally, we also extend the non-stationarity measure
to the problem of online convex optimization with constraints and obtain new
regret bounds accordingly.</p>
  </details>
</details>
<details>
  <summary>66. <b>标题：VulBERTa: Simplified Source Code Pre-Training for Vulnerability  Detection</b></summary>
  <p><b>编号</b>：[240]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12424</p>
  <p><b>作者</b>：Hazim Hanif,  Sergio Maffeis</p>
  <p><b>备注</b>：Accepted as a conference paper at IJCNN 2022</p>
  <p><b>关键词</b>：detect security vulnerabilities, paper presents VulBERTa, deep learning approach, paper presents, detect security</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper presents VulBERTa, a deep learning approach to detect security
vulnerabilities in source code. Our approach pre-trains a RoBERTa model with a
custom tokenisation pipeline on real-world code from open-source C/C++
projects. The model learns a deep knowledge representation of the code syntax
and semantics, which we leverage to train vulnerability detection classifiers.
We evaluate our approach on binary and multi-class vulnerability detection
tasks across several datasets (Vuldeepecker, Draper, REVEAL and muVuldeepecker)
and benchmarks (CodeXGLUE and D2A). The evaluation results show that VulBERTa
achieves state-of-the-art performance and outperforms existing approaches
across different datasets, despite its conceptual simplicity, and limited cost
in terms of size of training data and number of model parameters.</p>
  </details>
</details>
<details>
  <summary>67. <b>标题：Deletion and Insertion Tests in Regression Models</b></summary>
  <p><b>编号</b>：[241]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12423</p>
  <p><b>作者</b>：Naofumi Hama,  Masayoshi Mase,  Art B. Owen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：black box function, basic task, task in explainable, prediction made, black box</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A basic task in explainable AI (XAI) is to identify the most important
features behind a prediction made by a black box function $f$. The insertion
and deletion tests of \cite{petsiuk2018rise} are used to judge the quality of
algorithms that rank pixels from most to least important for a classification.
Motivated by regression problems we establish a formula for their area under
the curve (AUC) criteria in terms of certain main effects and interactions in
an anchored decomposition of $f$. We find an expression for the expected value
of the AUC under a random ordering of inputs to $f$ and propose an alternative
area above a straight line for the regression setting. We use this criterion to
compare feature importances computed by integrated gradients (IG) to those
computed by Kernel SHAP (KS). Exact computation of KS grows exponentially with
dimension, while that of IG grows linearly with dimension. In two data sets
including binary variables we find that KS is superior to IG in insertion and
deletion tests, but only by a very small amount. Our comparison problems
include some binary inputs that pose a challenge to IG because it must use
values between the possible variable levels.
We show that IG will match KS when $f$ is an additive function plus a
multilinear function of the variables. This includes a multilinear
interpolation over the binary variables that would cause IG to have exponential
cost in a naive implementation.</p>
  </details>
</details>
<details>
  <summary>68. <b>标题：Tiered Reinforcement Learning: Pessimism in the Face of Uncertainty and  Constant Regret</b></summary>
  <p><b>编号</b>：[245]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12418</p>
  <p><b>作者</b>：Jiawei Huang,  Li Zhao,  Tao Qin,  Wei Chen,  Nan Jiang,  Tie-Yan Liu</p>
  <p><b>备注</b>：38 pages</p>
  <p><b>关键词</b>：real-world user-interaction applications, text, risk-averse users, user-interaction applications, treated separately</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose a new learning framework that captures the tiered structure of
many real-world user-interaction applications, where the users can be divided
into two groups based on their different tolerance on exploration risks and
should be treated separately. In this setting, we simultaneously maintain two
policies $\pi^{\text{O}}$ and $\pi^{\text{E}}$: $\pi^{\text{O}}$ ("O" for
"online") interacts with more risk-tolerant users from the first tier and
minimizes regret by balancing exploration and exploitation as usual, while
$\pi^{\text{E}}$ ("E" for "exploit") exclusively focuses on exploitation for
risk-averse users from the second tier utilizing the data collected so far. An
important question is whether such a separation yields advantages over the
standard online setting (i.e., $\pi^{\text{E}}=\pi^{\text{O}}$) for the
risk-averse users. We individually consider the gap-independent
vs.~gap-dependent settings. For the former, we prove that the separation is
indeed not beneficial from a minimax perspective. For the latter, we show that
if choosing Pessimistic Value Iteration as the exploitation algorithm to
produce $\pi^{\text{E}}$, we can achieve a constant regret for risk-averse
users independent of the number of episodes $K$, which is in sharp contrast to
the $\Omega(\log K)$ regret for any online RL algorithms in the same setting,
while the regret of $\pi^{\text{O}}$ (almost) maintains its online regret
optimality and does not need to compromise for the success of $\pi^{\text{E}}$.</p>
  </details>
</details>
<details>
  <summary>69. <b>标题：Differentially Private AUC Computation in Vertical Federated Learning</b></summary>
  <p><b>编号</b>：[247]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12412</p>
  <p><b>作者</b>：Jiankai Sun,  Xin Yang,  Yuanshun Yao,  Junyuan Xie,  Di Wu,  Chong Wang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：gained great attention, great attention recently, gained great, great attention, attention recently</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Federated learning has gained great attention recently as a privacy-enhancing
tool to jointly train a machine learning model by multiple parties. As a
sub-category, vertical federated learning (vFL) focuses on the scenario where
features and labels are split into different parties. The prior work on vFL has
mostly studied how to protect label privacy during model training. However,
model evaluation in vFL might also lead to potential leakage of private label
information. One mitigation strategy is to apply label differential privacy
(DP) but it gives bad estimations of the true (non-private) metrics. In this
work, we propose two evaluation algorithms that can more accurately compute the
widely used AUC (area under curve) metric when using label DP in vFL. Through
extensive experiments, we show our algorithms can achieve more accurate AUCs
compared to the baselines.</p>
  </details>
</details>
<details>
  <summary>70. <b>标题：Linear Connectivity Reveals Generalization Strategies</b></summary>
  <p><b>编号</b>：[248]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12411</p>
  <p><b>作者</b>：Jeevesh Juneja,  Rachit Bansal,  Kyunghyun Cho,  João Sedoc,  Naomi Saphra</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：mode connectivity literature, test set accuracy, accuracy is maintained, widely accepted, mode connectivity</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>It is widely accepted in the mode connectivity literature that when two
neural networks are trained similarly on the same data, they are connected by a
path through parameter space over which test set accuracy is maintained. Under
some circumstances, including transfer learning from pretrained models, these
paths are presumed to be linear. In contrast to existing results, we find that
among text classifiers (trained on MNLI, QQP, and CoLA), some pairs of
finetuned models have large barriers of increasing loss on the linear paths
between them. On each task, we find distinct clusters of models which are
linearly connected on the test loss surface, but are disconnected from models
outside the cluster -- models that occupy separate basins on the surface. By
measuring performance on specially-crafted diagnostic datasets, we find that
these clusters correspond to different generalization strategies: one cluster
behaves like a bag of words model under domain shift, while another cluster
uses syntactic heuristics. Our work demonstrates how the geometry of the loss
surface can guide models towards different heuristic functions.</p>
  </details>
</details>
<details>
  <summary>71. <b>标题：AdaMix: Mixture-of-Adapter for Parameter-efficient Tuning of Large  Language Models</b></summary>
  <p><b>编号</b>：[249]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12410</p>
  <p><b>作者</b>：Yaqing Wang,  Subhabrata Mukherjee,  Xiaodong Liu,  Jing Gao,  Ahmed Hassan Awadallah,  Jianfeng Gao</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：require updating hundreds, downstream tasks require, tasks require updating, adapter, require updating</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Fine-tuning large-scale pre-trained language models to downstream tasks
require updating hundreds of millions of parameters. This not only increases
the serving cost to store a large copy of the model weights for every task, but
also exhibits instability during few-shot task adaptation. Parameter-efficient
techniques have been developed that tune small trainable components (e.g.,
adapters) injected in the large model while keeping most of the model weights
frozen. The prevalent mechanism to increase adapter capacity is to increase the
bottleneck dimension which increases the adapter parameters. In this work, we
introduce a new mechanism to improve adapter capacity without increasing
parameters or computational cost by two key techniques. (i) We introduce
multiple shared adapter components in each layer of the Transformer
architecture. We leverage sparse learning via random routing to update the
adapter parameters (encoder is kept frozen) resulting in the same amount of
computational cost (FLOPs) as that of training a single adapter. (ii) We
propose a simple merging mechanism to average the weights of multiple adapter
components to collapse to a single adapter in each Transformer layer, thereby,
keeping the overall parameters also the same but with significant performance
improvement. We demonstrate these techniques to work well across multiple task
settings including fully supervised and few-shot Natural Language Understanding
tasks. By only tuning 0.23% of a pre-trained language model's parameters, our
model outperforms the full model fine-tuning performance and several competing
methods.</p>
  </details>
</details>
<details>
  <summary>72. <b>标题：Convolutional Neural Processes for Inpainting Satellite Images</b></summary>
  <p><b>编号</b>：[251]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12407</p>
  <p><b>作者</b>：Alexander Pondaven,  Märt Bakler,  Donghu Guo,  Hamzah Hashim,  Martin Ignatov,  Harrison Zhu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：model complex systems, disease dynamics, widespread availability, allowed researchers, complex systems</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The widespread availability of satellite images has allowed researchers to
model complex systems such as disease dynamics. However, many satellite images
have missing values due to measurement defects, which render them unusable
without data imputation. For example, the scanline corrector for the LANDSAT 7
satellite broke down in 2003, resulting in a loss of around 20\% of its data.
Inpainting involves predicting what is missing based on the known pixels and is
an old problem in image processing, classically based on PDEs or interpolation
methods, but recent deep learning approaches have shown promise. However, many
of these methods do not explicitly take into account the inherent
spatiotemporal structure of satellite images. In this work, we cast satellite
image inpainting as a natural meta-learning problem, and propose using
convolutional neural processes (ConvNPs) where we frame each satellite image as
its own task or 2D regression problem. We show ConvNPs can outperform classical
methods and state-of-the-art deep learning inpainting models on a scanline
inpainting problem for LANDSAT 7 satellite images, assessed on a variety of in
and out-of-distribution images.</p>
  </details>
</details>
<details>
  <summary>73. <b>标题：Multi-Head Online Learning for Delayed Feedback Modeling</b></summary>
  <p><b>编号</b>：[252]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12406</p>
  <p><b>作者</b>：Hui Gao,  Yihan Yang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：highly important, important to predict, predict the probability, day, online advertising</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In online advertising, it is highly important to predict the probability and
the value of a conversion (e.g., a purchase). It not only impacts user
experience by showing relevant ads, but also affects ROI of advertisers and
revenue of marketplaces. Unlike clicks, which often occur within minutes after
impressions, conversions are expected to happen over a long period of time
(e.g., 30 days for online shopping). It creates a challenge, as the true labels
are only available after the long delays. Either inaccurate labels (partial
conversions) are used, or models are trained on stale data (e.g., from 30 days
ago). The problem is more eminent in online learning, which focuses on the live
performance on the latest data. In this paper, a novel solution is presented to
address this challenge using multi-head modeling. Unlike traditional methods,
it directly quantizes conversions into multiple windows, such as day 1, day 2,
day 3-7, and day 8-30. A sub-model is trained specifically on conversions
within each window. Label freshness is maximally preserved in early models
(e.g., day 1 and day 2), while late conversions are accurately utilized in
models with longer delays (e.g., day 8-30). It is shown to greatly exceed the
performance of known methods in online learning experiments for both conversion
rate (CVR) and value per click (VPC) predictions. Lastly, as a general method
for delayed feedback modeling, it can be combined with any advanced ML
techniques to further improve the performance.</p>
  </details>
</details>
<details>
  <summary>74. <b>标题：Reward Uncertainty for Exploration in Preference-based Reinforcement  Learning</b></summary>
  <p><b>编号</b>：[256]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12401</p>
  <p><b>作者</b>：Xinran Liang,  Katherine Shu,  Kimin Lee,  Pieter Abbeel</p>
  <p><b>备注</b>：ICLR 2022. Last two authors advised equally</p>
  <p><b>关键词</b>：meticulous reward engineering, Conveying complex objectives, requires meticulous reward, reinforcement learning, agents often requires</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Conveying complex objectives to reinforcement learning (RL) agents often
requires meticulous reward engineering. Preference-based RL methods are able to
learn a more flexible reward model based on human preferences by actively
incorporating human feedback, i.e. teacher's preferences between two clips of
behaviors. However, poor feedback-efficiency still remains a problem in current
preference-based RL algorithms, as tailored human feedback is very expensive.
To handle this issue, previous methods have mainly focused on improving query
selection and policy initialization. At the same time, recent exploration
methods have proven to be a recipe for improving sample-efficiency in RL. We
present an exploration method specifically for preference-based RL algorithms.
Our main idea is to design an intrinsic reward by measuring the novelty based
on learned reward. Specifically, we utilize disagreement across ensemble of
learned reward models. Our intuition is that disagreement in learned reward
model reflects uncertainty in tailored human feedback and could be useful for
exploration. Our experiments show that exploration bonus from uncertainty in
learned reward improves both feedback- and sample-efficiency of
preference-based RL algorithms on complex robot manipulation tasks from
MetaWorld benchmarks, compared with other existing exploration methods that
measure the novelty of state visitation.</p>
  </details>
</details>
<details>
  <summary>75. <b>标题：Sparse Mixers: Combining MoE and Mixing to build a more efficient BERT</b></summary>
  <p><b>编号</b>：[257]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12399</p>
  <p><b>作者</b>：James Lee-Thorp,  Joshua Ainslie</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Sparse Mixer, Fast Sparse Mixer, sparsely gated, Sparse, Sparse Mixer slightly</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We combine the capacity of sparsely gated Mixture-of-Experts (MoE) with the
speed and stability of linear, mixing transformations to design the Sparse
Mixer encoder model. The Sparse Mixer slightly outperforms (<1%) bert on glue and superglue, but more importantly trains 65% faster runs inference 61% faster. we also present a variant, prosaically named fast sparse mixer, that marginally underperforms (<0.2%) nearly twice as fast: 89% training 98% inference. justify the design of these two models by carefully ablating through various mixing mechanisms, moe configurations model hyperparameters. mixer overcomes many latency stability concerns offers prospect serving student models, without resorting to distilling them dense variants.< p>
  </1%)></p></details>
</details>
<details>
  <summary>76. <b>标题：Recipe2Vec: Multi-modal Recipe Representation Learning with Graph Neural  Networks</b></summary>
  <p><b>编号</b>：[259]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12396</p>
  <p><b>作者</b>：Yijun Tian,  Chuxu Zhang,  Zhichun Guo,  Yihong Ma,  Ronald Metoyer,  Nitesh V. Chawla</p>
  <p><b>备注</b>：Accepted by IJCAI 2022</p>
  <p><b>关键词</b>：effective recipe representations, recipe, Learning effective recipe, Learning, multi-modal recipe representation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Learning effective recipe representations is essential in food studies.
Unlike what has been developed for image-based recipe retrieval or learning
structural text embeddings, the combined effect of multi-modal information
(i.e., recipe images, text, and relation data) receives less attention. In this
paper, we formalize the problem of multi-modal recipe representation learning
to integrate the visual, textual, and relational information into recipe
embeddings. In particular, we first present Large-RG, a new recipe graph data
with over half a million nodes, making it the largest recipe graph to date. We
then propose Recipe2Vec, a novel graph neural network based recipe embedding
model to capture multi-modal information. Additionally, we introduce an
adversarial attack strategy to ensure stable learning and improve performance.
Finally, we design a joint objective function of node classification and
adversarial learning to optimize the model. Extensive experiments demonstrate
that Recipe2Vec outperforms state-of-the-art baselines on two classic food
study tasks, i.e., cuisine category classification and region prediction.
Dataset and codes are available at this https URL.</p>
  </details>
</details>
<details>
  <summary>77. <b>标题：PLAtE: A Large-scale Dataset for List Page Web Extraction</b></summary>
  <p><b>编号</b>：[266]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12386</p>
  <p><b>作者</b>：Aidan San,  Jan Bakus,  Colin Lockard,  David Ciemiewicz,  Yangfeng Ji,  Sandeep Atluri,  Kevin Small,  Heba Elfardy</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：semi-structured websites, leveraged to significantly, significantly improve, extraction, neural models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recently, neural models have been leveraged to significantly improve the
performance of information extraction from semi-structured websites. However, a
barrier for continued progress is the small number of datasets large enough to
train these models. In this work, we introduce the PLAtE (Pages of Lists
Attribute Extraction) dataset as a challenging new web extraction task. PLAtE
focuses on shopping data, specifically extractions from product review pages
with multiple items. PLAtE encompasses both the tasks of: (1) finding
product-list segmentation boundaries and (2) extracting attributes for each
product. PLAtE is composed of 53, 905 items from 6, 810 pages, making it the
first large-scale list page web extraction dataset. We construct PLAtE by
collecting list pages from Common Crawl, then annotating them on Mechanical
Turk. Quantitative and qualitative analyses are performed to demonstrate PLAtE
has high-quality annotations. We establish strong baseline performance on PLAtE
with a SOTA model achieving an F1-score of 0.750 for attribute classification
and 0.915 for segmentation, indicating opportunities for future research
innovations in web extraction.</p>
  </details>
</details>
<details>
  <summary>78. <b>标题：First Contact: Unsupervised Human-Machine Co-Adaptation via Mutual  Information Maximization</b></summary>
  <p><b>编号</b>：[268]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12381</p>
  <p><b>作者</b>：Siddharth Reddy,  Sergey Levine,  Anca D. Dragan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：electromyography-based limb prosthesis, assistive human-machine interface, user raw command, raw command signals, mutual information</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>How can we train an assistive human-machine interface (e.g., an
electromyography-based limb prosthesis) to translate a user's raw command
signals into the actions of a robot or computer when there is no prior mapping,
we cannot ask the user for supervision in the form of action labels or reward
feedback, and we do not have prior knowledge of the tasks the user is trying to
accomplish? The key idea in this paper is that, regardless of the task, when an
interface is more intuitive, the user's commands are less noisy. We formalize
this idea as a completely unsupervised objective for optimizing interfaces: the
mutual information between the user's command signals and the induced state
transitions in the environment. To evaluate whether this mutual information
score can distinguish between effective and ineffective interfaces, we conduct
an observational study on 540K examples of users operating various keyboard and
eye gaze interfaces for typing, controlling simulated robots, and playing video
games. The results show that our mutual information scores are predictive of
the ground-truth task completion metrics in a variety of domains, with an
average Spearman's rank correlation of 0.43. In addition to offline evaluation
of existing interfaces, we use our unsupervised objective to learn an interface
from scratch: we randomly initialize the interface, have the user attempt to
perform their desired tasks using the interface, measure the mutual information
score, and update the interface to maximize mutual information through
reinforcement learning. We evaluate our method through a user study with 12
participants who perform a 2D cursor control task using a perturbed mouse, and
an experiment with one user playing the Lunar Lander game using hand gestures.
The results show that we can learn an interface from scratch, without any user
supervision or prior knowledge of tasks, in under 30 minutes.</p>
  </details>
</details>
<details>
  <summary>79. <b>标题：Imposing Gaussian Pre-Activations in a Neural Network</b></summary>
  <p><b>编号</b>：[269]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12379</p>
  <p><b>作者</b>：Pierre Wolinski,  Julyan Arbel</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：activation functions span, Gaussian pre-activations, initialization distribution, neural network, present work</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The goal of the present work is to propose a way to modify both the
initialization distribution of the weights of a neural network and its
activation function, such that all pre-activations are Gaussian. We propose a
family of pairs initialization/activation, where the activation functions span
a continuum from bounded functions (such as Heaviside or tanh) to the identity
function.
This work is motivated by the contradiction between existing works dealing
with Gaussian pre-activations: on one side, the works in the line of the Neural
Tangent Kernels and the Edge of Chaos are assuming it, while on the other side,
theoretical and experimental results challenge this hypothesis.
The family of pairs initialization/activation we are proposing will help us
to answer this hot question: is it desirable to have Gaussian pre-activations
in a neural network?</p>
  </details>
</details>
<details>
  <summary>80. <b>标题：Hardness of Maximum Likelihood Learning of DPPs</b></summary>
  <p><b>编号</b>：[271]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12377</p>
  <p><b>作者</b>：Elena Grigorescu,  Brendan Juba,  Karl Wimmer,  Ning Xie</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Determinantal Point Processes, Point Processes, Determinantal Point, negatively correlated sets, widely used probabilistic</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Determinantal Point Processes (DPPs) are a widely used probabilistic model
for negatively correlated sets. DPPs have been successfully employed in Machine
Learning applications to select a diverse, yet representative subset of data.
In seminal work on DPPs in Machine Learning, Kulesza conjectured in his PhD
Thesis (2011) that the problem is NP-complete. The lack of a formal proof
prompted Brunel, Moitra, Rigollet and Urschel (COLT 2017) to conjecture that,
in opposition to Kulesza's conjecture, there exists a polynomial-time algorithm
for computing a maximum-likelihood DPP. They also presented some preliminary
evidence supporting their conjecture.
In this work we prove Kulesza's conjecture. In fact, we prove the following
stronger hardness of approximation result: even computing a
$\left(1-O(\frac{1}{\log^9{N}})\right)$-approximation to the maximum
log-likelihood of a DPP on a ground set of $N$ elements is NP-complete. At the
same time, we also obtain the first polynomial-time algorithm that achieves a
nontrivial worst-case approximation to the optimal log-likelihood: the
approximation factor is $\frac{1}{(1+o(1))\log{m}}$ unconditionally (for data
sets that consist of $m$ subsets), and can be improved to $1-\frac{1+o(1)}{\log
N}$ if all $N$ elements appear in a $O(1/N)$-fraction of the subsets.
In terms of techniques, we reduce approximating the maximum log-likelihood of
DPPs on a data set to solving a gap instance of a "vector coloring" problem on
a hypergraph. Such a hypergraph is built on a bounded-degree graph construction
of Bogdanov, Obata and Trevisan (FOCS 2002), and is further enhanced by the
strong expanders of Alon and Capalbo (FOCS 2007) to serve our purposes.</p>
  </details>
</details>
<details>
  <summary>81. <b>标题：Learning to Model Editing Processes</b></summary>
  <p><b>编号</b>：[273]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12374</p>
  <p><b>作者</b>：Machel Reid,  Graham Neubig</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：existing sequence generation, generation models produce, models produce outputs, produce outputs, sequence generation models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Most existing sequence generation models produce outputs in one pass, usually
left-to-right. However, this is in contrast with a more natural approach that
humans use in generating content; iterative refinement and editing. Recent work
has introduced edit-based models for various tasks (such as neural machine
translation and text style transfer), but these generally model a single edit
step. In this work, we propose modeling editing processes, modeling the whole
process of iteratively generating sequences. We form a conceptual framework to
describe the likelihood of multi-step edits, and describe neural models that
can learn a generative model of sequences based on these multistep edits. We
introduce baseline results and metrics on this task, finding that modeling
editing processes improves performance on a variety of axes on both our
proposed task and related downstream tasks compared to previous single-step
models of edits.</p>
  </details>
</details>
<details>
  <summary>82. <b>标题：TorchNTK: A Library for Calculation of Neural Tangent Kernels of PyTorch  Models</b></summary>
  <p><b>编号</b>：[274]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12372</p>
  <p><b>作者</b>：Andrew Engel,  Zhichao Wang,  Anand D. Sarwate,  Sutanay Choudhury,  Tony Chiang</p>
  <p><b>备注</b>：19 pages, 5 figures</p>
  <p><b>关键词</b>：neural tangent kernel, empirical neural tangent, neural network models, empirical neural, neural tangent</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We introduce torchNTK, a python library to calculate the empirical neural
tangent kernel (NTK) of neural network models in the PyTorch framework. We
provide an efficient method to calculate the NTK of multilayer perceptrons. We
compare the explicit differentiation implementation against autodifferentiation
implementations, which have the benefit of extending the utility of the library
to any architecture supported by PyTorch, such as convolutional networks. A
feature of the library is that we expose the user to layerwise NTK components,
and show that in some regimes a layerwise calculation is more memory efficient.
We conduct preliminary experiments to demonstrate use cases for the software
and probe the NTK.</p>
  </details>
</details>
<details>
  <summary>83. <b>标题：Women, artificial intelligence, and key positions in collaboration  networks: Towards a more equal scientific ecosystem</b></summary>
  <p><b>编号</b>：[284]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12339</p>
  <p><b>作者</b>：Anahita Hajibabaei,  Andrea Schiffauerova,  Ashkan Ebadi</p>
  <p><b>备注</b>：20 pages, 6 figures</p>
  <p><b>关键词</b>：sharing knowledge, pooled resources, Scientific collaboration, artificial intelligence, Scientific</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Scientific collaboration in almost every discipline is mainly driven by the
need of sharing knowledge, expertise, and pooled resources. Science is becoming
more complex which has encouraged scientists to involve more in collaborative
research projects in order to better address the challenges. As a highly
interdisciplinary field with a rapidly evolving scientific landscape,
artificial intelligence calls for researchers with special profiles covering a
diverse set of skills and expertise. Understanding gender aspects of scientific
collaboration is of paramount importance, especially in a field such as
artificial intelligence that has been attracting large investments. Using
social network analysis, natural language processing, and machine learning and
focusing on artificial intelligence publications for the period from 2000 to
2019, in this work, we comprehensively investigated the effects of several
driving factors on acquiring key positions in scientific collaboration networks
through a gender lens. It was found that, regardless of gender, scientific
performance in terms of quantity and impact plays a crucial in possessing the
"social researcher" in the network. However, subtle differences were observed
between female and male researchers in acquiring the "local influencer" role.</p>
  </details>
</details>
<details>
  <summary>84. <b>标题：K-12BERT: BERT for K-12 education</b></summary>
  <p><b>编号</b>：[285]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12335</p>
  <p><b>作者</b>：Vasu Goel,  Dhruv Sahnan,  Venktesh V,  Gaurav Sharma,  Deep Dwivedi,  Mukesh Mohania</p>
  <p><b>备注</b>：4 pages</p>
  <p><b>关键词</b>：NLP pipelines, Online education platforms, content curation, platforms are powered, aid in content</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Online education platforms are powered by various NLP pipelines, which
utilize models like BERT to aid in content curation. Since the inception of the
pre-trained language models like BERT, there have also been many efforts toward
adapting these pre-trained models to specific domains. However, there has not
been a model specifically adapted for the education domain (particularly K-12)
across subjects to the best of our knowledge. In this work, we propose to train
a language model on a corpus of data curated by us across multiple subjects
from various sources for K-12 education. We also evaluate our model, K12-BERT,
on downstream tasks like hierarchical taxonomy tagging.</p>
  </details>
</details>
<details>
  <summary>85. <b>标题：Certified Robustness Against Natural Language Attacks by Causal  Intervention</b></summary>
  <p><b>编号</b>：[287]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12331</p>
  <p><b>作者</b>：Haiteng Zhao,  Chang Ma,  Xinshuai Dong,  Anh Tuan Luu,  Zhi-Hong Deng,  Hanwang Zhang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：achieved great success, Deep learning models, learning models, models have achieved, achieved great</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep learning models have achieved great success in many fields, yet they are
vulnerable to adversarial examples. This paper follows a causal perspective to
look into the adversarial vulnerability and proposes Causal Intervention by
Semantic Smoothing (CISS), a novel framework towards robustness against natural
language attacks. Instead of merely fitting observational data, CISS learns
causal effects p(y|do(x)) by smoothing in the latent semantic space to make
robust predictions, which scales to deep architectures and avoids tedious
construction of noise customized for specific attacks. CISS is provably robust
against word substitution attacks, as well as empirically robust even when
perturbations are strengthened by unknown attack algorithms. For example, on
YELP, CISS surpasses the runner-up by 6.7% in terms of certified robustness
against word substitutions, and achieves 79.4% empirical robustness when
syntactic attacks are integrated.</p>
  </details>
</details>
<details>
  <summary>86. <b>标题：Beyond Impossibility: Balancing Sufficiency, Separation and Accuracy</b></summary>
  <p><b>编号</b>：[289]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12327</p>
  <p><b>作者</b>：Limor Gultchin,  Vincent Cohen-Addad,  Sophie Giffard-Roisin,  Varun Kanade,  Frederik Mallmann-Trenn</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：false negative rates, algorithmic fairness studied, false positive, false negative, negative rates</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Among the various aspects of algorithmic fairness studied in recent years,
the tension between satisfying both \textit{sufficiency} and
\textit{separation} -- e.g. the ratios of positive or negative predictive
values, and false positive or false negative rates across groups -- has
received much attention. Following a debate sparked by COMPAS, a criminal
justice predictive system, the academic community has responded by laying out
important theoretical understanding, showing that one cannot achieve both with
an imperfect predictor when there is no equal distribution of labels across the
groups. In this paper, we shed more light on what might be still possible
beyond the impossibility -- the existence of a trade-off means we should aim to
find a good balance within it. After refining the existing theoretical result,
we propose an objective that aims to balance \textit{sufficiency} and
\textit{separation} measures, while maintaining similar accuracy levels. We
show the use of such an objective in two empirical case studies, one involving
a multi-objective framework, and the other fine-tuning of a model pre-trained
for accuracy. We show promising results, where better trade-offs are achieved
compared to existing alternatives.</p>
  </details>
</details>
<details>
  <summary>87. <b>标题：ColdGuess: A General and Effective Relational Graph Convolutional  Network to Tackle Cold Start Cases</b></summary>
  <p><b>编号</b>：[292]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12318</p>
  <p><b>作者</b>：Bo He,  Xiang Song,  Vincent Gao,  Christos Faloutsos</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：erode customer trust, online retail websites, retail websites threatens, sub-optimal buying experience, websites threatens e-commerce</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Low-quality listings and bad actor behavior in online retail websites
threatens e-commerce business as these result in sub-optimal buying experience
and erode customer trust. When a new listing is created, how to tell it has
good-quality? Is the method effective, fast, and scalable? Previous approaches
often have three limitations/challenges: (1) unable to handle cold start
problems where new sellers/listings lack sufficient selling histories. (2)
inability of scoring hundreds of millions of listings at scale, or compromise
performance for scalability. (3) has space challenges from large-scale graph
with giant e-commerce business size. To overcome these limitations/challenges,
we proposed ColdGuess, an inductive graph-based risk predictor built upon a
heterogeneous seller product graph, which effectively identifies risky
seller/product/listings at scale. ColdGuess tackles the large-scale graph by
consolidated nodes, and addresses the cold start problems using homogeneous
influence1. The evaluation on real data demonstrates that ColdGuess has stable
performance as the number of unknown features increases. It outperforms the
lightgbm2 by up to 34 pcp ROC-AUC in a cold start case when a new seller sells
a new product . The resulting system, ColdGuess, is effective, adaptable to
changing risky seller behavior, and is already in production</p>
  </details>
</details>
<details>
  <summary>88. <b>标题：Fast & Furious: Modelling Malware Detection as Evolving Data Streams</b></summary>
  <p><b>编号</b>：[293]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12311</p>
  <p><b>作者</b>：Fabrício Ceschin,  Marcus Botacin,  Heitor Murilo Gomes,  Felipe Pinagé,  Luiz S. Oliveira,  André Grégio</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：cyber security, imposes many challenges, challenges to cyber, major threat, Malware</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Malware is a major threat to computer systems and imposes many challenges to
cyber security. Targeted threats, such as ransomware, cause millions of dollars
in losses every year. The constant increase of malware infections has been
motivating popular antiviruses (AVs) to develop dedicated detection strategies,
which include meticulously crafted machine learning (ML) pipelines. However,
malware developers unceasingly change their samples features to bypass
detection. This constant evolution of malware samples causes changes to the
data distribution (i.e., concept drifts) that directly affect ML model
detection rates. In this work, we evaluate the impact of concept drift on
malware classifiers for two Android datasets: DREBIN (~130K apps) and AndroZoo
(~350K apps). Android is a ubiquitous operating system for smartphones, which
stimulates attackers to regularly create and update malware to the platform. We
conducted a longitudinal evaluation by (i) classifying malware samples
collected over nine years (2009-2018), (ii) reviewing concept drift detection
algorithms to attest its pervasiveness, (iii) comparing distinct ML approaches
to mitigate the issue, and (iv) proposing an ML data stream pipeline that
outperformed literature approaches. As a result, we observed that updating
every component of the pipeline in response to concept drifts allows the
classification model to achieve increasing detection rates as the data
representation (extracted features) is updated. Furthermore, we discuss the
impact of the changes on the classification models by comparing the variations
in the extracted features.</p>
  </details>
</details>
<details>
  <summary>89. <b>标题：FreDo: Frequency Domain-based Long-Term Time Series Forecasting</b></summary>
  <p><b>编号</b>：[298]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12301</p>
  <p><b>作者</b>：Fan-Keng Sun,  Duane S. Boning</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：energy consumption, limited to climatology, ability to forecast, highly beneficial, model</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The ability to forecast far into the future is highly beneficial to many
applications, including but not limited to climatology, energy consumption, and
logistics. However, due to noise or measurement error, it is questionable how
far into the future one can reasonably predict. In this paper, we first
mathematically show that due to error accumulation, sophisticated models might
not outperform baseline models for long-term forecasting. To demonstrate, we
show that a non-parametric baseline model based on periodicity can actually
achieve comparable performance to a state-of-the-art Transformer-based model on
various datasets. We further propose FreDo, a frequency domain-based neural
network model that is built on top of the baseline model to enhance its
performance and which greatly outperforms the state-of-the-art model. Finally,
we validate that the frequency domain is indeed better by comparing univariate
models trained in the frequency v.s. time domain.</p>
  </details>
</details>
<details>
  <summary>90. <b>标题：lpSpikeCon: Enabling Low-Precision Spiking Neural Network Processing for  Efficient Unsupervised Continual Learning on Autonomous Agents</b></summary>
  <p><b>编号</b>：[299]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12295</p>
  <p><b>作者</b>：Rachmad Vidya Wicaksana Putra,  Muhammad Shafique</p>
  <p><b>备注</b>：To appear at the 2022 International Joint Conference on Neural Networks (IJCNN), the 2022 IEEE World Congress on Computational Intelligence (WCCI), July 2022, Padova, Italy</p>
  <p><b>关键词</b>：unsupervised continual learning, bio-plausible learning rule, efficiently perform unsupervised, unsupervised continual, continual learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent advances have shown that SNN-based systems can efficiently perform
unsupervised continual learning due to their bio-plausible learning rule, e.g.,
Spike-Timing-Dependent Plasticity (STDP). Such learning capabilities are
especially beneficial for use cases like autonomous agents (e.g., robots and
UAVs) that need to continuously adapt to dynamically changing
scenarios/environments, where new data gathered directly from the environment
may have novel features that should be learned online. Current state-of-the-art
works employ high-precision weights (i.e., 32 bit) for both training and
inference phases, which pose high memory and energy costs thereby hindering
efficient embedded implementations of such systems for battery-driven mobile
autonomous systems. On the other hand, precision reduction may jeopardize the
quality of unsupervised continual learning due to information loss. Towards
this, we propose lpSpikeCon, a novel methodology to enable low-precision SNN
processing for efficient unsupervised continual learning on
resource-constrained autonomous agents/systems. Our lpSpikeCon methodology
employs the following key steps: (1) analyzing the impacts of training the SNN
model under unsupervised continual learning settings with reduced weight
precision on the inference accuracy; (2) leveraging this study to identify SNN
parameters that have a significant impact on the inference accuracy; and (3)
developing an algorithm for searching the respective SNN parameter values that
improve the quality of unsupervised continual learning. The experimental
results show that our lpSpikeCon can reduce weight memory of the SNN model by
8x (i.e., by judiciously employing 4-bit weights) for performing online
training with unsupervised continual learning and achieve no accuracy loss in
the inference phase, as compared to the baseline model with 32-bit weights
across different network sizes.</p>
  </details>
</details>
<details>
  <summary>91. <b>标题：Wavelet Feature Maps Compression for Image-to-Image CNNs</b></summary>
  <p><b>编号</b>：[302]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12268</p>
  <p><b>作者</b>：Shahaf E. Finder,  Yair Zohav,  Maor Ashkenazi,  Eran Treister</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Convolutional Neural Networks, Neural Networks, Convolutional Neural, extensive computational resources, requiring extensive computational</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Convolutional Neural Networks (CNNs) are known for requiring extensive
computational resources, and quantization is among the best and most common
methods for compressing them. While aggressive quantization (i.e., less than
4-bits) performs well for classification, it may cause severe performance
degradation in image-to-image tasks such as semantic segmentation and depth
estimation. In this paper, we propose Wavelet Compressed Convolution (WCC) -- a
novel approach for high-resolution activation maps compression integrated with
point-wise convolutions, which are the main computational cost of modern
architectures. To this end, we use an efficient and hardware-friendly
Haar-wavelet transform, known for its effectiveness in image compression, and
define the convolution on the compressed activation map. We experiment on
various tasks, that benefit from high-resolution input, and by combining WCC
with light quantization, we achieve compression rates equivalent to 1-4bit
activation quantization with relatively small and much more graceful
degradation in performance.</p>
  </details>
</details>
<details>
  <summary>92. <b>标题：Action Recognition for American Sign Language</b></summary>
  <p><b>编号</b>：[308]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12261</p>
  <p><b>作者</b>：Nguyen Huu Phong,  Bernardete Ribeiro</p>
  <p><b>备注</b>：2 pages</p>
  <p><b>关键词</b>：American Sign Language, recognize American Sign, recognize American, Language from series, hand gestures</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this research, we present our findings to recognize American Sign Language
from series of hand gestures. While most researches in literature focus only on
static handshapes, our work target dynamic hand gestures. Since dynamic signs
dataset are very few, we collect an initial dataset of 150 videos for 10 signs
and an extension of 225 videos for 15 signs. We apply transfer learning models
in combination with deep neural networks and background subtraction for videos
in different temporal settings. Our primarily results show that we can get an
accuracy of $0.86$ and $0.71$ using DenseNet201, LSTM with video sequence of 12
frames accordingly.</p>
  </details>
</details>
<details>
  <summary>93. <b>标题：Conformal Prediction Intervals with Temporal Dependence</b></summary>
  <p><b>编号</b>：[310]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12940</p>
  <p><b>作者</b>：Zhen Lin,  Shubhendu Trivedi,  Jimeng Sun</p>
  <p><b>备注</b>：15 pages (main paper, including references) + 4 pages (supplementary material)</p>
  <p><b>关键词</b>：electronic health records, including forecasting tasks, including forecasting, health records, electronic health</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Cross-sectional prediction is common in many domains such as healthcare,
including forecasting tasks using electronic health records, where different
patients form a cross-section. We focus on the task of constructing valid
prediction intervals (PIs) in time-series regression with a cross-section. A
prediction interval is considered valid if it covers the true response with (a
pre-specified) high probability. We first distinguish between two notions of
validity in such a setting: cross-sectional and longitudinal. Cross-sectional
validity is concerned with validity across the cross-section of the time series
data, while longitudinal validity accounts for the temporal dimension. Coverage
guarantees along both these dimensions are ideally desirable; however, we show
that distribution-free longitudinal validity is theoretically impossible.
Despite this limitation, we propose Conformal Prediction with Temporal
Dependence (CPTD), a procedure which is able to maintain strict cross-sectional
validity while improving longitudinal coverage. CPTD is post-hoc and
light-weight, and can easily be used in conjunction with any prediction model
as long as a calibration set is available. We focus on neural networks due to
their ability to model complicated data such as diagnosis codes for time-series
regression, and perform extensive experimental validation to verify the
efficacy of our approach. We find that CPTD outperforms baselines on a variety
of datasets by improving longitudinal coverage and often providing more
efficient (narrower) PIs.</p>
  </details>
</details>
<details>
  <summary>94. <b>标题：Mitigating multiple descents: A model-agnostic framework for risk  monotonization</b></summary>
  <p><b>编号</b>：[311]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12937</p>
  <p><b>作者</b>：Pratik Patil,  Arun Kumar Kuchibhotla,  Yuting Wei,  Alessandro Rinaldo</p>
  <p><b>备注</b>：110 pages, 15 figures</p>
  <p><b>关键词</b>：limiting aspect ratio, peculiar risk behavior, prediction procedures reveal, limiting aspect, multiple descent</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent empirical and theoretical analyses of several commonly used prediction
procedures reveal a peculiar risk behavior in high dimensions, referred to as
double/multiple descent, in which the asymptotic risk is a non-monotonic
function of the limiting aspect ratio of the number of features or parameters
to the sample size. To mitigate this undesirable behavior, we develop a general
framework for risk monotonization based on cross-validation that takes as input
a generic prediction procedure and returns a modified procedure whose
out-of-sample prediction risk is, asymptotically, monotonic in the limiting
aspect ratio. As part of our framework, we propose two data-driven
methodologies, namely zero- and one-step, that are akin to bagging and
boosting, respectively, and show that, under very mild assumptions, they
provably achieve monotonic asymptotic risk behavior. Our results are applicable
to a broad variety of prediction procedures and loss functions, and do not
require a well-specified (parametric) model. We exemplify our framework with
concrete analyses of the minimum $\ell_2$, $\ell_1$-norm least squares
prediction procedures. As one of the ingredients in our analysis, we also
derive novel additive and multiplicative forms of oracle risk inequalities for
split cross-validation that are of independent interest.</p>
  </details>
</details>
<details>
  <summary>95. <b>标题：Boosting Tail Neural Network for Realtime Custom Keyword Spotting</b></summary>
  <p><b>编号</b>：[312]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12933</p>
  <p><b>作者</b>：Sihao Xue,  Qianyao Shen,  Guoqing Li</p>
  <p><b>备注</b>：4 pages, 8 figures, 2 tables</p>
  <p><b>关键词</b>：Tail Neural Network, Custom Keyword Spotting, Boosting Tail Neural, Realtime Custom Keyword, Neural Network</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we propose a Boosting Tail Neural Network (BTNN) for improving
the performance of Realtime Custom Keyword Spotting (RCKS) that is still an
industrial challenge for demanding powerful classification ability with limited
computation resources. Inspired by Brain Science that a brain is only partly
activated for a nerve simulation and numerous machine learning algorithms are
developed to use a batch of weak classifiers to resolve arduous problems, which
are often proved to be effective. We show that this method is helpful to the
RCKS problem. The proposed approach achieve better performances in terms of
wakeup rate and false alarm.
In our experiments compared with those traditional algorithms that use only
one strong classifier, it gets 18\% relative improvement. We also point out
that this approach may be promising in future ASR exploration.</p>
  </details>
</details>
<details>
  <summary>96. <b>标题：RADNet: Ensemble Model for Robust Glaucoma Classification in Color  Fundus Images</b></summary>
  <p><b>编号</b>：[316]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12902</p>
  <p><b>作者</b>：Dmitrii Medvedev,  Rand Muhtaseb,  Ahmed Al Mahrooqi</p>
  <p><b>备注</b>：Keywords: Glaucoma Classification, Color Fundus Images. Computer Aided Diagnosis</p>
  <p><b>关键词</b>：severe eye diseases, characterized by rapid, irreversible blindness, severe eye, rapid progression</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Glaucoma is one of the most severe eye diseases, characterized by rapid
progression and leading to irreversible blindness. It is often the case that
pathology diagnostics is carried out when the one's sight has already
significantly degraded due to the lack of noticeable symptoms at early stage of
the disease. Regular glaucoma screenings of the population shall improve
early-stage detection, however the desirable frequency of etymological checkups
is often not feasible due to excessive load imposed by manual diagnostics on
limited number of specialists. Considering the basic methodology to detect
glaucoma is to analyze fundus images for the \textit{optic-disc-to-optic-cup
ratio}, Machine Learning domain can offer sophisticated tooling for image
processing and classification. In our work, we propose an advanced image
pre-processing technique combined with an ensemble of deep classification
networks. Our \textit{Retinal Auto Detection (RADNet)} model has been
successfully tested on Rotterdam EyePACS AIROGS train dataset with AUC of 0.92,
and then additionally finetuned and tested on a fraction of RIM-ONE DL dataset
with AUC of 0.91.</p>
  </details>
</details>
<details>
  <summary>97. <b>标题：Differentially Private Data Generation Needs Better Features</b></summary>
  <p><b>编号</b>：[317]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12900</p>
  <p><b>作者</b>：Fredrik Harder,  Milad Jalali Asadabadi,  Danica J. Sutherland,  Mijung Park</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：stochastic gradient descent, differentially-private stochastic gradient, required level, reasonable levels, levels of privacy</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Training even moderately-sized generative models with differentially-private
stochastic gradient descent (DP-SGD) is difficult: the required level of noise
for reasonable levels of privacy is simply too large. We advocate instead
building off a good, relevant representation on public data, then using private
data only for "transfer learning." In particular, we minimize the maximum mean
discrepancy (MMD) between private target data and the generated distribution,
using a kernel based on perceptual features from a public dataset. With the
MMD, we can simply privatize the data-dependent term once and for all, rather
than introducing noise at each step of optimization as in DP-SGD. Our algorithm
allows us to generate CIFAR10-level images faithfully with $\varepsilon \approx
2$, far surpassing the current state of the art, which only models MNIST and
FashionMNIST at $\varepsilon \approx 10$. Our work introduces simple yet
powerful foundations for reducing the gap between private and non-private deep
generative models.</p>
  </details>
</details>
<details>
  <summary>98. <b>标题：Removing the fat from your posterior samples with margarine</b></summary>
  <p><b>编号</b>：[321]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12841</p>
  <p><b>作者</b>：Harry T. J. Bevins,  William J. Handley,  Pablo Lemos,  Peter H. Sims,  Eloy de Lera Acedo,  Anastasia Fialkov,  Justin Alsing</p>
  <p><b>备注</b>：Submitted to NeurIPS</p>
  <p><b>关键词</b>：core science modelling, nuisance parameters, workflows often require, require the introduction, introduction of nuisance</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Bayesian workflows often require the introduction of nuisance parameters, yet
for core science modelling one needs access to a marginal posterior density. In
this work we use masked autoregressive flows and kernel density estimators to
encapsulate the marginal posterior, allowing us to compute marginal
Kullback-Leibler divergences and marginal Bayesian model dimensionalities in
addition to generating samples and computing marginal log probabilities. We
demonstrate this in application to topical cosmological examples of the Dark
Energy Survey, and global 21cm signal experiments. In addition to the
computation of marginal Bayesian statistics, this work is important for further
applications in Bayesian experimental design, complex prior modelling and
likelihood emulation. This technique is made publicly available in the
pip-installable code margarine.</p>
  </details>
</details>
<details>
  <summary>99. <b>标题：Fast Stochastic Composite Minimization and an Accelerated Frank-Wolfe  Algorithm under Parallelization</b></summary>
  <p><b>编号</b>：[323]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12751</p>
  <p><b>作者</b>：Benjamin Dubois-Taine,  Francis Bach,  Quentin Berthet,  Adrien Taylor</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：epsilon, Lipschitz-continuous gradients, function, provide a Bregman-type, Bregman-type algorithm</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We consider the problem of minimizing the sum of two convex functions. One of
those functions has Lipschitz-continuous gradients, and can be accessed via
stochastic oracles, whereas the other is "simple". We provide a Bregman-type
algorithm with accelerated convergence in function values to a ball containing
the minimum. The radius of this ball depends on problem-dependent constants,
including the variance of the stochastic oracle. We further show that this
algorithmic setup naturally leads to a variant of Frank-Wolfe achieving
acceleration under parallelization. More precisely, when minimizing a smooth
convex function on a bounded domain, we show that one can achieve an $\epsilon$
primal-dual gap (in expectation) in $\tilde{O}(1/ \sqrt{\epsilon})$ iterations,
by only accessing gradients of the original function and a linear maximization
oracle with $O(1/\sqrt{\epsilon})$ computing units in parallel. We illustrate
this fast convergence on synthetic numerical experiments.</p>
  </details>
</details>
<details>
  <summary>100. <b>标题：Machine learning method for return direction forecasting of Exchange  Traded Funds using classification and regression models</b></summary>
  <p><b>编号</b>：[324]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12746</p>
  <p><b>作者</b>：Raphael P. B. Piovezan,  Pedro Paulo de Andrade Junior</p>
  <p><b>备注</b>：21 pages, 8 figures and 12 tables</p>
  <p><b>关键词</b>：Exchange Traded Funds, Traded Funds, Exchange Traded, make investment strategy, investment strategy decisions</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This article aims to propose and apply a machine learning method to analyze
the direction of returns from Exchange Traded Funds (ETFs) using the historical
return data of its components, helping to make investment strategy decisions
through a trading algorithm. In methodological terms, regression and
classification models were applied, using standard datasets from Brazilian and
American markets, in addition to algorithmic error metrics. In terms of
research results, they were analyzed and compared to those of the Naïve
forecast and the returns obtained by the buy & hold technique in the same
period of time. In terms of risk and return, the models mostly performed better
than the control metrics, with emphasis on the linear regression model and the
classification models by logistic regression, support vector machine (using the
LinearSVC model), Gaussian Naive Bayes and K-Nearest Neighbors, where in
certain datasets the returns exceeded by two times and the Sharpe ratio by up
to four times those of the buy & hold control model.</p>
  </details>
</details>
<details>
  <summary>101. <b>标题：Global geomagnetic perturbation forecasting using Deep Learning</b></summary>
  <p><b>编号</b>：[325]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12734</p>
  <p><b>作者</b>：Vishal Upendran,  Panagiotis Tigas,  Banafsheh Ferdousi,  Teo Bloch,  Mark C. M. Cheung,  Siddha Ganju,  Asti Bhatt,  Ryan M. McGranaghan,  Yarin Gal</p>
  <p><b>备注</b>：23 pages, 8 figures, 5 tables; accepted for publication in AGU: Spaceweather</p>
  <p><b>关键词</b>：Geomagnetically Induced Currents, Induced Currents, Geomagnetically Induced, Currents, arise from spatio-temporal</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Geomagnetically Induced Currents (GICs) arise from spatio-temporal changes to
Earth's magnetic field which arise from the interaction of the solar wind with
Earth's magnetosphere, and drive catastrophic destruction to our
technologically dependent society. Hence, computational models to forecast GICs
globally with large forecast horizon, high spatial resolution and temporal
cadence are of increasing importance to perform prompt necessary mitigation.
Since GIC data is proprietary, the time variability of horizontal component of
the magnetic field perturbation (dB/dt) is used as a proxy for GICs. In this
work, we develop a fast, global dB/dt forecasting model, which forecasts 30
minutes into the future using only solar wind measurements as input. The model
summarizes 2 hours of solar wind measurement using a Gated Recurrent Unit, and
generates forecasts of coefficients which are folded with a spherical harmonic
basis to enable global forecasts. When deployed, our model produces results in
under a second, and generates global forecasts for horizontal magnetic
perturbation components at 1-minute cadence. We evaluate our model across
models in literature for two specific storms of 5 August 2011 and 17 March
2015, while having a self-consistent benchmark model set. Our model
outperforms, or has consistent performance with state-of-the-practice high time
cadence local and low time cadence global models, while also
outperforming/having comparable performance with the benchmark models. Such
quick inferences at high temporal cadence and arbitrary spatial resolutions may
ultimately enable accurate forewarning of dB/dt for any place on Earth,
resulting in precautionary measures to be taken in an informed manner.</p>
  </details>
</details>
<details>
  <summary>102. <b>标题：Machine learning methods for Schlieren imaging of a plasma channel in  tenuous atomic vapor</b></summary>
  <p><b>编号</b>：[326]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12731</p>
  <p><b>作者</b>：Gábor Bíró,  Mihály Pocsai,  Imre Ferenc Barna,  Joshua T. Moody,  Gábor Demeter</p>
  <p><b>备注</b>：26 pages, 13 figures, 1 table</p>
  <p><b>关键词</b>：Schlieren imaging setup, plasma channel, Deep Neural Networks, investigate the usage, imaging setup</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We investigate the usage of a Schlieren imaging setup to measure the
geometrical dimensions of a plasma channel in atomic vapor. Near resonant probe
light is used to image the plasma channel in a tenuous vapor and machine
learning techniques are tested for extracting quantitative information from the
images. By building a database of simulated signals with a range of plasma
parameters for training Deep Neural Networks, we demonstrate that they can
extract from the Schlieren images reliably and with high accuracy the location,
the radius and the maximum ionization fraction of the plasma channel as well as
the width of the transition region between the core of the plasma channel and
the unionized vapor. We test several different neural network architectures
with supervised learning and show that the parameter estimations supplied by
the networks are resilient with respect to slight changes of the experimental
parameters that may occur in the course of a measurement.</p>
  </details>
</details>
<details>
  <summary>103. <b>标题：Deep interpretable ensembles</b></summary>
  <p><b>编号</b>：[327]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12729</p>
  <p><b>作者</b>：Lucas Kook,  Andrea Götschi,  Philipp FM Baumann,  Torsten Hothorn,  Beate Sick</p>
  <p><b>备注</b>：22 pages main text, 8 figures</p>
  <p><b>关键词</b>：quantification by aggregating, Ensembles, transformation, models, Transformation ensembles</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Ensembles improve prediction performance and allow uncertainty quantification
by aggregating predictions from multiple models. In deep ensembling, the
individual models are usually black box neural networks, or recently, partially
interpretable semi-structured deep transformation models. However,
interpretability of the ensemble members is generally lost upon aggregation.
This is a crucial drawback of deep ensembles in high-stake decision fields, in
which interpretable models are desired. We propose a novel transformation
ensemble which aggregates probabilistic predictions with the guarantee to
preserve interpretability and yield uniformly better predictions than the
ensemble members on average. Transformation ensembles are tailored towards
interpretable deep transformation models but are applicable to a wider range of
probabilistic neural networks. In experiments on several publicly available
data sets, we demonstrate that transformation ensembles perform on par with
classical deep ensembles in terms of prediction performance, discrimination,
and calibration. In addition, we demonstrate how transformation ensembles
quantify both aleatoric and epistemic uncertainty, and produce minimax optimal
predictions under certain conditions.</p>
  </details>
</details>
<details>
  <summary>104. <b>标题：Surprises in adversarially-trained linear regression</b></summary>
  <p><b>编号</b>：[331]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12695</p>
  <p><b>作者</b>：Antônio H. Ribeiro,  Dave Zachariah,  Thomas B. Schön</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：machine learning models, machine learning, adversarially constructed, small input perturbations, input perturbations</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>State-of-the-art machine learning models can be vulnerable to very small
input perturbations that are adversarially constructed. Adversarial training is
one of the most effective approaches to defend against such examples. We show
that for linear regression problems, adversarial training can be formulated as
a convex problem. This fact is then used to show that $\ell_\infty$-adversarial
training produces sparse solutions and has many similarities to the lasso
method. Similarly, $\ell_2$-adversarial training has similarities with ridge
regression. We use a robust regression framework to analyze and understand
these similarities and also point to some differences. Finally, we show how
adversarial training behaves differently from other regularization methods when
estimating overparameterized models (i.e., models with more parameters than
datapoints). It minimizes a sum of three terms which regularizes the solution,
but unlike lasso and ridge regression, it can sharply transition into an
interpolation mode. We show that for sufficiently many features or sufficiently
small regularization parameters, the learned model perfectly interpolates the
training data while still exhibiting good out-of-sample performance.</p>
  </details>
</details>
<details>
  <summary>105. <b>标题：On the Interpretability of Regularisation for Neural Networks Through  Model Gradient Similarity</b></summary>
  <p><b>编号</b>：[333]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12642</p>
  <p><b>作者</b>：Vincent Szolnoky,  Viktor Andersson,  Balazs Kulcsar,  Rebecka Jörnsten</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：complex machine learning, subsequently generalise poorly, future data, complex machine, machine learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Most complex machine learning and modelling techniques are prone to
over-fitting and may subsequently generalise poorly to future data. Artificial
neural networks are no different in this regard and, despite having a level of
implicit regularisation when trained with gradient descent, often require the
aid of explicit regularisers. We introduce a new framework, Model Gradient
Similarity (MGS), that (1) serves as a metric of regularisation, which can be
used to monitor neural network training, (2) adds insight into how explicit
regularisers, while derived from widely different principles, operate via the
same mechanism underneath by increasing MGS, and (3) provides the basis for a
new regularisation scheme which exhibits excellent performance, especially in
challenging settings such as high levels of label noise or limited sample
sizes.</p>
  </details>
</details>
<details>
  <summary>106. <b>标题：A Convergence Theory for Over-parameterized Variational Quantum  Eigensolvers</b></summary>
  <p><b>编号</b>：[336]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12481</p>
  <p><b>作者</b>：Xuchen You,  Shouvanik Chakrabarti,  Xiaodi Wu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Variational Quantum Eigensolver, Noisy Intermediate-Scale Quantum, near-term Noisy Intermediate-Scale, Quantum Eigensolver, Variational Quantum</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The Variational Quantum Eigensolver (VQE) is a promising candidate for
quantum applications on near-term Noisy Intermediate-Scale Quantum (NISQ)
computers. Despite a lot of empirical studies and recent progress in
theoretical understanding of VQE's optimization landscape, the convergence for
optimizing VQE is far less understood. We provide the first rigorous analysis
of the convergence of VQEs in the over-parameterization regime. By connecting
the training dynamics with the Riemannian Gradient Flow on the unit-sphere, we
establish a threshold on the sufficient number of parameters for efficient
convergence, which depends polynomially on the system dimension and the
spectral ratio, a property of the problem Hamiltonian, and could be resilient
to gradient noise to some extent. We further illustrate that this
overparameterization threshold could be vastly reduced for specific VQE
instances by establishing an ansatz-dependent threshold paralleling our main
result. We showcase that our ansatz-dependent threshold could serve as a proxy
of the trainability of different VQE ansatzes without performing empirical
experiments, which hence leads to a principled way of evaluating ansatz design.
Finally, we conclude with a comprehensive empirical study that supports our
theoretical findings.</p>
  </details>
</details>
<details>
  <summary>107. <b>标题：Linear Algorithms for Nonparametric Multiclass Probability Estimation</b></summary>
  <p><b>编号</b>：[338]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12460</p>
  <p><b>作者</b>：Liyun Zeng,  Hao Helen Zhang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：data point belonging, estimating conditional probabilities, Support Vector Machines, covariate information, Multiclass probability estimation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Multiclass probability estimation is the problem of estimating conditional
probabilities of a data point belonging to a class given its covariate
information. It has broad applications in statistical analysis and data
science. Recently a class of weighted Support Vector Machines (wSVMs) have been
developed to estimate class probabilities through ensemble learning for
$K$-class problems (Wang, Shen and Liu, 2008; Wang, Zhang and Wu, 2019), where
$K$ is the number of classes. The estimators are robust and achieve high
accuracy for probability estimation, but their learning is implemented through
pairwise coupling, which demand polynomial time in $K$. In this paper, we
propose two new learning schemes, the baseline learning and the One-vs-All
(OVA) learning, to further improve wSVMs in terms of computational efficiency
and estimation accuracy. In particular, the baseline learning has optimal
computational complexity in the sense that it is linear in $K$. The resulting
estimators are distribution-free and shown to be consistent. We further conduct
extensive numerical experiments to demonstrate finite sample performance.</p>
  </details>
</details>
<details>
  <summary>108. <b>标题：Transportation-Inequalities, Lyapunov Stability and Sampling for  Dynamical Systems on Continuous State Space</b></summary>
  <p><b>编号</b>：[340]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12448</p>
  <p><b>作者</b>：Muhammad Abdullah Naeem,  Miroslav Pajic</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：unbounded state space, exponential concentration inequalities, discrete-time random dynamical, state space, concentration inequalities</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We study the concentration phenomenon for discrete-time random dynamical
systems with an unbounded state space. We develop a heuristic approach towards
obtaining exponential concentration inequalities for dynamical systems using an
entirely functional analytic framework. We also show that existence of
exponential-type Lyapunov function, compared to the purely deterministic
setting, not only implies stability but also exponential concentration
inequalities for sampling from the stationary distribution, via
\emph{transport-entropy inequality} (T-E). These results have significant
impact in \emph{reinforcement learning} (RL) and \emph{controls}, leading to
exponential concentration inequalities even for unbounded observables, while
neither assuming reversibility nor exact knowledge of random dynamical system
(assumptions at heart of concentration inequalities in statistical mechanics
and Markov diffusion processes).</p>
  </details>
</details>
<details>
  <summary>109. <b>标题：Over-the-Air Design of GAN Training for mmWave MIMO Channel Estimation</b></summary>
  <p><b>编号</b>：[342]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12445</p>
  <p><b>作者</b>：Akash Doshi,  Manan Gupta,  Jeffrey G. Andrews</p>
  <p><b>备注</b>：34 pages, 12 figures, 5 tables. Under review for publication in IEEE Journal of Sel. Areas in Information Theory</p>
  <p><b>关键词</b>：Future wireless systems, higher carrier frequencies, offer larger communication, larger communication bandwidth, large antenna arrays</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Future wireless systems are trending towards higher carrier frequencies that
offer larger communication bandwidth but necessitate the use of large antenna
arrays. Existing signal processing techniques for channel estimation do not
scale well to this "high-dimensional" regime in terms of performance and pilot
overhead. Meanwhile, training deep learning based approaches for channel
estimation requires large labeled datasets mapping pilot measurements to clean
channel realizations, which can only be generated offline using simulated
channels. In this paper, we develop a novel unsupervised over-the-air (OTA)
algorithm that utilizes noisy received pilot measurements to train a deep
generative model to output beamspace MIMO channel realizations. Our approach
leverages Generative Adversarial Networks (GAN), while using a conditional
input to distinguish between Line-of-Sight (LOS) and Non-Line-of-Sight (NLOS)
channel realizations. We also present a federated implementation of the OTA
algorithm that distributes the GAN training over multiple users and greatly
reduces the user side computation. We then formulate channel estimation from a
limited number of pilot measurements as an inverse problem and reconstruct the
channel by optimizing the input vector of the trained generative model. Our
proposed approach significantly outperforms Orthogonal Matching Pursuit on both
LOS and NLOS channel models, and EM-GM-AMP -- an Approximate Message Passing
algorithm -- on LOS channel models, while achieving comparable performance on
NLOS channel models in terms of the normalized channel reconstruction error.
More importantly, our proposed framework has the potential to be trained online
using real noisy pilot measurements, is not restricted to a specific channel
model and can even be utilized for a federated OTA design of a dataset
generator from noisy data.</p>
  </details>
</details>
<details>
  <summary>110. <b>标题：Lyapunov function approach for approximation algorithm design and  analysis: with applications in submodular maximization</b></summary>
  <p><b>编号</b>：[343]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12442</p>
  <p><b>作者</b>：Donglei Du</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：two-phase systematical framework, Lyapunov function, propose a two-phase, two-phase systematical, Lyapunov</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose a two-phase systematical framework for approximation algorithm
design and analysis via Lyapunov function. The first phase consists of using
Lyapunov function as a guideline to design a continuous-time algorithm with
provable approximation ratio. The second phase then converts the
continuous-time algorithm to a discrete-time algorithm with the same
approximation ratio and a provable time complexity. Some immediate benefits of
the Lyapunov function approach include: (i) unifying many existing algorithms;
(ii) providing a guideline to design and analyze new algorithms; and (iii)
offer new perspectives to potentially improve existing algorithms. We use
various submodular maximization problems as running examples to illustrate our
framework.</p>
  </details>
</details>
<details>
  <summary>111. <b>标题：Physics Guided Machine Learning for Variational Multiscale Reduced Order  Modeling</b></summary>
  <p><b>编号</b>：[346]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12419</p>
  <p><b>作者</b>：Shady E. Ahmed,  Omer San,  Adil Rasheed,  Traian Iliescu,  Alessandro Veneziani</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：reduced order models, physics guided machine, VMS framework enable, VMS framework, unresolved ROM scales</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose a new physics guided machine learning (PGML) paradigm that
leverages the variational multiscale (VMS) framework and available data to
dramatically increase the accuracy of reduced order models (ROMs) at a modest
computational cost. The hierarchical structure of the ROM basis and the VMS
framework enable a natural separation of the resolved and unresolved ROM
spatial scales. Modern PGML algorithms are used to construct novel models for
the interaction among the resolved and unresolved ROM scales. Specifically, the
new framework builds ROM operators that are closest to the true interaction
terms in the VMS framework. Finally, machine learning is used to reduce the
projection error and further increase the ROM accuracy. Our numerical
experiments for a two-dimensional vorticity transport problem show that the
novel PGML-VMS-ROM paradigm maintains the low computational cost of current
ROMs, while significantly increasing the ROM accuracy.</p>
  </details>
</details>
<details>
  <summary>112. <b>标题：Low-rank Optimal Transport: Approximation, Statistics and Debiasing</b></summary>
  <p><b>编号</b>：[347]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12365</p>
  <p><b>作者</b>：Meyer Scetbon,  Marco Cuturi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：increasingly important role, machine learning, self-supervised learning, single-cell genomics, play an increasingly</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The matching principles behind optimal transport (OT) play an increasingly
important role in machine learning, a trend which can be observed when OT is
used to disambiguate datasets in applications (e.g. single-cell genomics) or
used to improve more complex methods (e.g. balanced attention in transformers
or self-supervised learning). To scale to more challenging problems, there is a
growing consensus that OT requires solvers that can operate on millions, not
thousands, of points. The low-rank optimal transport (LOT) approach advocated
in \cite{scetbon2021lowrank} holds several promises in that regard, and was
shown to complement more established entropic regularization approaches, being
able to insert itself in more complex pipelines, such as quadratic OT. LOT
restricts the search for low-cost couplings to those that have a
low-nonnegative rank, yielding linear time algorithms in cases of interest.
However, these promises can only be fulfilled if the LOT approach is seen as a
legitimate contender to entropic regularization when compared on properties of
interest, where the scorecard typically includes theoretical properties
(statistical bounds, relation to other methods) or practical aspects
(debiasing, hyperparameter tuning, initialization). We target each of these
areas in this paper in order to cement the impact of low-rank approaches in
computational OT.</p>
  </details>
</details>
<h1>人工智能</h1>
<details>
  <summary>1. <b>标题：Inception Transformer</b></summary>
  <p><b>编号</b>：[1]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12956</p>
  <p><b>作者</b>：Chenyang Si,  Weihao Yu,  Pan Zhou,  Yichen Zhou,  Xinchao Wang,  Shuicheng Yan</p>
  <p><b>备注</b>：Code and models will be released at this https URL</p>
  <p><b>关键词</b>：building long-range dependencies, predominantly convey local, convey local information, Recent studies show, general-purpose Inception Transformer</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent studies show that Transformer has strong capability of building
long-range dependencies, yet is incompetent in capturing high frequencies that
predominantly convey local information. To tackle this issue, we present a
novel and general-purpose Inception Transformer, or iFormer for short, that
effectively learns comprehensive features with both high- and low-frequency
information in visual data. Specifically, we design an Inception mixer to
explicitly graft the advantages of convolution and max-pooling for capturing
the high-frequency information to Transformers. Different from recent hybrid
frameworks, the Inception mixer brings greater efficiency through a channel
splitting mechanism to adopt parallel convolution/max-pooling path and
self-attention path as high- and low-frequency mixers, while having the
flexibility to model discriminative information scattered within a wide
frequency range. Considering that bottom layers play more roles in capturing
high-frequency details while top layers more in modeling low-frequency global
information, we further introduce a frequency ramp structure, i.e. gradually
decreasing the dimensions fed to the high-frequency mixer and increasing those
to the low-frequency mixer, which can effectively trade-off high- and
low-frequency components across different layers. We benchmark the iFormer on a
series of vision tasks, and showcase that it achieves impressive performance on
image classification, COCO detection and ADE20K segmentation. For example, our
iFormer-S hits the top-1 accuracy of 83.4% on ImageNet-1K, much higher than
DeiT-S by 3.6%, and even slightly better than much bigger model Swin-B (83.3%)
with only 1/4 parameters and 1/3 FLOPs. Code and models will be released at
this https URL.</p>
  </details>
</details>
<details>
  <summary>2. <b>标题：Learning Mean Field Games: A Survey</b></summary>
  <p><b>编号</b>：[4]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12944</p>
  <p><b>作者</b>：Mathieu Laurière,  Sarah Perrin,  Matthieu Geist,  Olivier Pietquin</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：remain generally intractable, number of players, Non-cooperative and cooperative, applications but remain, Lasry and Lions</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Non-cooperative and cooperative games with a very large number of players
have many applications but remain generally intractable when the number of
players increases. Introduced by Lasry and Lions, and Huang, Caines and
Malhamé, Mean Field Games (MFGs) rely on a mean-field approximation to allow
the number of players to grow to infinity. Traditional methods for solving
these games generally rely on solving partial or stochastic differential
equations with a full knowledge of the model. Recently, Reinforcement Learning
(RL) has appeared promising to solve complex problems. By combining MFGs and
RL, we hope to solve games at a very large scale both in terms of population
size and environment complexity. In this survey, we review the quickly growing
recent literature on RL methods to learn Nash equilibria in MFGs. We first
identify the most common settings (static, stationary, and evolutive). We then
present a general framework for classical iterative methods (based on
best-response computation or policy evaluation) to solve MFGs in an exact way.
Building on these algorithms and the connection with Markov Decision Processes,
we explain how RL can be used to learn MFG solutions in a model-free way. Last,
we present numerical illustrations on a benchmark problem, and conclude with
some perspectives.</p>
  </details>
</details>
<details>
  <summary>3. <b>标题：SoK: Cross-border Criminal Investigations and Digital Evidence</b></summary>
  <p><b>编号</b>：[14]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12911</p>
  <p><b>作者</b>：Fran Casino,  Claudia Pina,  Pablo López-Aguilar,  Edgar Batista,  Agusti Solanas,  Constantinos Patsakis</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Digital evidence underpin, Digital evidence, underpin the majority, majority of crimes, integral part</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Digital evidence underpin the majority of crimes as their analysis is an
integral part of almost every criminal investigation. Even if we temporarily
disregard the numerous challenges in the collection and analysis of digital
evidence, the exchange of the evidence among the different stakeholders has
many thorny issues. Of specific interest are cross-border criminal
investigations as the complexity is significantly high due to the heterogeneity
of legal frameworks which beyond time bottlenecks can also become prohibiting.
The aim of this article is to analyse the current state of practice of
cross-border investigations considering the efficacy of current collaboration
protocols along with the challenges and drawbacks to be overcome. Further to
performing a legally-oriented research treatise, we recall all the challenges
raised in the literature and discuss them from a more practical yet global
perspective. Thus, this article paves the way to enabling practitioners and
stakeholders to leverage horizontal strategies to fill in the identified gaps
timely and accurately.</p>
  </details>
</details>
<details>
  <summary>4. <b>标题：NaturalProver: Grounded Mathematical Proof Generation with Language  Models</b></summary>
  <p><b>编号</b>：[15]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12910</p>
  <p><b>作者</b>：Sean Welleck,  Jiacheng Liu,  Ximing Lu,  Hannaneh Hajishirzi,  Yejin Choi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：natural mathematical language, plays a central, advances and education, core to intelligence, mixture of symbolic</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Theorem proving in natural mathematical language - the mixture of symbolic
and natural language used by humans - plays a central role in mathematical
advances and education, and tests aspects of reasoning that are core to
intelligence. Yet it has remained underexplored with modern generative models.
We study large-scale language models on two new generation tasks: suggesting
the next step in a mathematical proof, and full proof generation. Naively
applying language models to these problems yields proofs riddled with
hallucinations and logical incoherence. We develop NaturalProver, a language
model that generates proofs by conditioning on background references (e.g.
theorems and definitions that are either retrieved or human-provided), and
optionally enforces their presence with constrained decoding. On theorems from
the NaturalProofs benchmark, NaturalProver improves the quality of next-step
suggestions and generated proofs over fine-tuned GPT-3, according to human
evaluations from university-level mathematics students. NaturalProver is
capable of proving some theorems that require short (2-6 step) proofs, and
providing next-step suggestions that are rated as correct and useful over 40%
of the time, which is to our knowledge the first demonstration of these
capabilities using neural language models.</p>
  </details>
</details>
<details>
  <summary>5. <b>标题：Reasoning over Logically Interacted Conditions for Question Answering</b></summary>
  <p><b>编号</b>：[21]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12898</p>
  <p><b>作者</b>：Haitian Sun,  William W. Cohen,  Ruslan Salakhutdinov</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：answers, conditions, equally correct, multiple answers, challenging</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Some questions have multiple answers that are not equally correct, i.e.
answers are different under different conditions. Conditions are used to
distinguish answers as well as to provide additional information to support
them. In this paper, we study a more challenging task where answers are
constrained by a list of conditions that logically interact, which requires
performing logical reasoning over the conditions to determine the correctness
of the answers. Even more challenging, we only provide evidences for a subset
of the conditions, so some questions may not have deterministic answers. In
such cases, models are asked to find probable answers and identify conditions
that need to be satisfied to make the answers correct. We propose a new model,
TReasoner, for this challenging reasoning task. TReasoner consists of an
entailment module, a reasoning module, and a generation module (if the answers
are free-form text spans). TReasoner achieves state-of-the-art performance on
two benchmark conditional QA datasets, outperforming the previous
state-of-the-art by 3-10 points.</p>
  </details>
</details>
<details>
  <summary>6. <b>标题：Robust Reinforcement Learning on Graphs for Logistics optimization</b></summary>
  <p><b>编号</b>：[25]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12888</p>
  <p><b>作者</b>：Zangir Iklassov,  Dmitrii Medvedev</p>
  <p><b>备注</b>：Keywords: Graph Neural Network (GNN), Logistics optimization, Reinforcement Learning</p>
  <p><b>关键词</b>：Logistics optimization nowadays, reinforcement learning, apply reinforcement learning, reinforcement, graph</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Logistics optimization nowadays is becoming one of the hottest areas in the
AI community. In the past year, significant advancements in the domain were
achieved by representing the problem in a form of graph. Another promising area
of research was to apply reinforcement learning algorithms to the above task.
In our work, we made advantage of using both approaches and apply reinforcement
learning on a graph. To do that, we have analyzed the most recent results in
both fields and selected SOTA algorithms both from graph neural networks and
reinforcement learning. Then, we combined selected models on the problem of
AMOD systems optimization for the transportation network of New York city. Our
team compared three algorithms - GAT, Pro-CNN and PTDNet - to bring to the fore
the important nodes on a graph representation. Finally, we achieved SOTA
results on AMOD systems optimization problem employing PTDNet with GNN and
training them in reinforcement fashion.
Keywords: Graph Neural Network (GNN), Logistics optimization, Reinforcement
Learning</p>
  </details>
</details>
<details>
  <summary>7. <b>标题：You Need to Read Again: Multi-granularity Perception Network for Moment  Retrieval in Videos</b></summary>
  <p><b>编号</b>：[27]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12886</p>
  <p><b>作者</b>：Xin Sun,  Xuan Wang,  Jialin Gao,  Qiong Liu,  Xi Zhou</p>
  <p><b>备注</b>：in SIGIR 2022</p>
  <p><b>关键词</b>：relevant video moment, sentence description, aims to retrieve, relevant video, untrimmed video</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Moment retrieval in videos is a challenging task that aims to retrieve the
most relevant video moment in an untrimmed video given a sentence description.
Previous methods tend to perform self-modal learning and cross-modal
interaction in a coarse manner, which neglect fine-grained clues contained in
video content, query context, and their alignment. To this end, we propose a
novel Multi-Granularity Perception Network (MGPN) that perceives intra-modality
and inter-modality information at a multi-granularity level. Specifically, we
formulate moment retrieval as a multi-choice reading comprehension task and
integrate human reading strategies into our framework. A coarse-grained feature
encoder and a co-attention mechanism are utilized to obtain a preliminary
perception of intra-modality and inter-modality information. Then a
fine-grained feature encoder and a conditioned interaction module are
introduced to enhance the initial perception inspired by how humans address
reading comprehension problems. Moreover, to alleviate the huge computation
burden of some existing methods, we further design an efficient choice
comparison module and reduce the hidden size with imperceptible quality loss.
Extensive experiments on Charades-STA, TACoS, and ActivityNet Captions datasets
demonstrate that our solution outperforms existing state-of-the-art methods.</p>
  </details>
</details>
<details>
  <summary>8. <b>标题：Trust-based Consensus in Multi-Agent Reinforcement Learning Systems</b></summary>
  <p><b>编号</b>：[29]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12880</p>
  <p><b>作者</b>：Ho Long Fung,  Victor-Alexandru Darvariu,  Stephen Hailes,  Mirco Musolesi</p>
  <p><b>备注</b>：18 pages, 17 figures</p>
  <p><b>关键词</b>：multi-agent reinforcement learning, intended tasks, unreliable agents, neglected issue, potential presence</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>An often neglected issue in multi-agent reinforcement learning (MARL) is the
potential presence of unreliable agents in the environment whose deviations
from expected behavior can prevent a system from accomplishing its intended
tasks. In particular, consensus is a fundamental underpinning problem of
cooperative distributed multi-agent systems. Consensus requires different
agents, situated in a decentralized communication network, to reach an
agreement out of a set of initial proposals that they put forward.
Learning-based agents should adopt a protocol that allows them to reach
consensus despite having one or more unreliable agents in the system. This
paper investigates the problem of unreliable agents in MARL, considering
consensus as case study. Echoing established results in the distributed systems
literature, our experiments show that even a moderate fraction of such agents
can greatly impact the ability of reaching consensus in a networked
environment. We propose Reinforcement Learning-based Trusted Consensus (RLTC),
a decentralized trust mechanism, in which agents can independently decide which
neighbors to communicate with. We empirically demonstrate that our trust
mechanism is able to deal with unreliable agents effectively, as evidenced by
higher consensus success rates.</p>
  </details>
</details>
<details>
  <summary>9. <b>标题：Understanding Factual Errors in Summarization: Errors, Summarizers,  Datasets, Error Detectors</b></summary>
  <p><b>编号</b>：[36]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12854</p>
  <p><b>作者</b>：Liyan Tang,  Tanya Goyal,  Alexander R. Fabbri,  Philippe Laban,  Jiacheng Xu,  Semih Yahvuz,  Wojciech Kryściński,  Justin F. Rousseau,  Greg Durrett</p>
  <p><b>备注</b>：11 pages (15 with references and appendix), 4 figures, 8 Tables</p>
  <p><b>关键词</b>：detect factual errors, current systems' outputs, make factual errors, abstractive summarization systems, detect factual</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The propensity of abstractive summarization systems to make factual errors
has been the subject of significant study, including work on models to detect
factual errors and annotation of errors in current systems' outputs. However,
the ever-evolving nature of summarization systems, error detectors, and
annotated benchmarks make factuality evaluation a moving target; it is hard to
get a clear picture of how techniques compare. In this work, we collect labeled
factuality errors from across nine datasets of annotated summary outputs and
stratify them in a new way, focusing on what kind of base summarization model
was used. To support finer-grained analysis, we unify the labeled error types
into a single taxonomy and project each of the datasets' errors into this
shared labeled space. We then contrast five state-of-the-art error detection
methods on this benchmark. Our findings show that benchmarks built on modern
summary outputs (those from pre-trained models) show significantly different
results than benchmarks using pre-Transformer models. Furthermore, no one
factuality technique is superior in all settings or for all error types,
suggesting that system developers should take care to choose the right system
for their task at hand.</p>
  </details>
</details>
<details>
  <summary>10. <b>标题：On Building Spoken Language Understanding Systems for Low Resourced  Languages</b></summary>
  <p><b>编号</b>：[45]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12818</p>
  <p><b>作者</b>：Akshat Gupta</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：human experience due, Spoken dialog systems, SLU systems, Spoken dialog, SLU</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Spoken dialog systems are slowly becoming and integral part of the human
experience due to their various advantages over textual interfaces. Spoken
language understanding (SLU) systems are fundamental building blocks of spoken
dialog systems. But creating SLU systems for low resourced languages is still a
challenge. In a large number of low resourced language, we don't have access to
enough data to build automatic speech recognition (ASR) technologies, which are
fundamental to any SLU system. Also, ASR based SLU systems do not generalize to
unwritten languages. In this paper, we present a series of experiments to
explore extremely low-resourced settings where we perform intent classification
with systems trained on as low as one data-point per intent and with only one
speaker in the dataset. We also work in a low-resourced setting where we do not
use language specific ASR systems to transcribe input speech, which compounds
the challenge of building SLU systems to simulate a true low-resourced setting.
We test our system on Belgian Dutch (Flemish) and English and find that using
phonetic transcriptions to make intent classification systems in such
low-resourced setting performs significantly better than using speech features.
Specifically, when using a phonetic transcription based system over a feature
based system, we see average improvements of 12.37% and 13.08% for binary and
four-class classification problems respectively, when averaged over 49
different experimental settings.</p>
  </details>
</details>
<details>
  <summary>11. <b>标题：Automatic question generation based on sentence structure analysis using  machine learning approach</b></summary>
  <p><b>编号</b>：[47]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12811</p>
  <p><b>作者</b>：Miroslav Blšták,  Viera Rozinajová</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Natural Language Generation, Natural Language Understanding, Natural Language, Automatic question generation, Language Processing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Automatic question generation is one of the most challenging tasks of Natural
Language Processing. It requires "bidirectional" language processing: firstly,
the system has to understand the input text (Natural Language Understanding)
and it then has to generate questions also in the form of text (Natural
Language Generation). In this article, we introduce our framework for
generating the factual questions from unstructured text in the English
language. It uses a combination of traditional linguistic approaches based on
sentence patterns with several machine learning methods. We firstly obtain
lexical, syntactic and semantic information from an input text and we then
construct a hierarchical set of patterns for each sentence. The set of features
is extracted from the patterns and it is then used for automated learning of
new transformation rules. Our learning process is totally data-driven because
the transformation rules are obtained from a set of initial sentence-question
pairs. The advantages of this approach lie in a simple expansion of new
transformation rules which allows us to generate various types of questions and
also in the continuous improvement of the system by reinforcement learning. The
framework also includes a question evaluation module which estimates the
quality of generated questions. It serves as a filter for selecting the best
questions and eliminating incorrect ones or duplicates. We have performed
several experiments to evaluate the correctness of generated questions and we
have also compared our system with several state-of-the-art systems. Our
results indicate that the quality of generated questions outperforms the
state-of-the-art systems and our questions are also comparable to questions
created by humans. We have also created and published an interface with all
created datasets and evaluated questions, so it is possible to follow up on our
work.</p>
  </details>
</details>
<details>
  <summary>12. <b>标题：Impartial Games: A Challenge for Reinforcement Learning</b></summary>
  <p><b>编号</b>：[52]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12787</p>
  <p><b>作者</b>：Bei Zhou,  Søren Riis</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：successor MuZero, MuZero have revolutionised, revolutionised several competitive, competitive strategy games, AlphaZero</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The AlphaZero algorithm and its successor MuZero have revolutionised several
competitive strategy games, including chess, Go, and shogi and video games like
Atari, by learning to play these games better than any human and any
specialised computer program. Aside from knowing the rules, AlphaZero had no
prior knowledge of each game. This dramatically advanced progress on a
long-standing AI challenge to create programs that can learn for themselves
from first principles.
Theoretically, there are well-known limits to the power of deep learning for
strategy games like chess, Go, and shogi, as they are known to be NEXPTIME
hard. Some papers have argued that the AlphaZero methodology has limitations
and is unsuitable for general AI. However, none of these works has suggested
any specific limits for any particular game.
In this paper, we provide more powerful bottlenecks than previously
suggested. We present the first concrete example of a game - namely the
(children) game of nim - and other impartial games that seem to be a stumbling
block for AlphaZero and similar reinforcement learning algorithms. We show
experimentally that the bottlenecks apply to both the policy and value
networks. Since solving nim can be done in linear time using logarithmic space
i.e. has very low-complexity, our experimental results supersede known
theoretical limits based on many games' PSPACE (and NEXPTIME) completeness.
We show that nim can be learned on small boards, but when the board size
increases, AlphaZero style algorithms rapidly fail to improve.
We quantify the difficulties for various setups, parameter settings and
computational resources. Our results might help expand the AlphaZero self-play
paradigm by allowing it to use meta-actions during training and/or actual game
play like applying abstract transformations, or reading and writing to an
external memory.</p>
  </details>
</details>
<details>
  <summary>13. <b>标题：An Experimental Comparison Between Temporal Difference and Residual  Gradient with Neural Network Approximation</b></summary>
  <p><b>编号</b>：[59]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12770</p>
  <p><b>作者</b>：Shuyu Yin,  Tao Luo,  Peilin Liu,  Zhi-Qin John Xu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Gradient descent, incomplete gradient descent, gradient descent method, small Bellman residual, Bellman residual</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Gradient descent or its variants are popular in training neural networks.
However, in deep Q-learning with neural network approximation, a type of
reinforcement learning, gradient descent (also known as Residual Gradient (RG))
is barely used to solve Bellman residual minimization problem. On the contrary,
Temporal Difference (TD), an incomplete gradient descent method prevails. In
this work, we perform extensive experiments to show that TD outperforms RG,
that is, when the training leads to a small Bellman residual error, the
solution found by TD has a better policy and is more robust against the
perturbation of neural network parameters. We further use experiments to reveal
a key difference between reinforcement learning and supervised learning, that
is, a small Bellman residual error can correspond to a bad policy in
reinforcement learning while the test loss function in supervised learning is a
standard index to indicate the performance. We also empirically examine that
the missing term in TD is a key reason why RG performs badly. Our work shows
that the performance of a deep Q-learning solution is closely related to the
training dynamics and how an incomplete gradient descent method can find a good
policy is interesting for future study.</p>
  </details>
</details>
<details>
  <summary>14. <b>标题：An Evolutionary Approach to Dynamic Introduction of Tasks in Large-scale  Multitask Learning Systems</b></summary>
  <p><b>编号</b>：[66]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12755</p>
  <p><b>作者</b>：Andrea Gesmundo,  Jeff Dean</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Multitask learning assumes, quality and efficiency, key feature, feature of human, learning assumes</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Multitask learning assumes that models capable of learning from multiple
tasks can achieve better quality and efficiency via knowledge transfer, a key
feature of human learning. Though, state of the art ML models rely on high
customization for each task and leverage size and data scale rather than
scaling the number of tasks. Also, continual learning, that adds the temporal
aspect to multitask, is often focused to the study of common pitfalls such as
catastrophic forgetting instead of being studied at a large scale as a critical
component to build the next generation artificial intelligence. We propose an
evolutionary method that can generate a large scale multitask model, and can
support the dynamic and continuous addition of new tasks. The generated
multitask model is sparsely activated and integrates a task-based routing that
guarantees bounded compute cost and fewer added parameters per task as the
model expands. The proposed method relies on a knowledge compartmentalization
technique to achieve immunity against catastrophic forgetting and other common
pitfalls such as gradient interference and negative transfer. We empirically
show that the proposed method can jointly solve and achieve competitive results
on 69image classification tasks, for example achieving the best test accuracy
reported fora model trained only on public data for competitive tasks such as
cifar10: 99.43%.</p>
  </details>
</details>
<details>
  <summary>15. <b>标题：NECA: Network-Embedded Deep Representation Learning for Categorical Data</b></summary>
  <p><b>编号</b>：[68]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12752</p>
  <p><b>作者</b>：Xiaonan Gao,  Sen Wu,  Wenjun Zhou</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：representation learning method, deep representation learning, representation learning, propose NECA, learning method</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose NECA, a deep representation learning method for categorical data.
Built upon the foundations of network embedding and deep unsupervised
representation learning, NECA deeply embeds the intrinsic relationship among
attribute values and explicitly expresses data objects with numeric vector
representations. Designed specifically for categorical data, NECA can support
important downstream data mining tasks, such as clustering. Extensive
experimental analysis demonstrated the effectiveness of NECA.</p>
  </details>
</details>
<details>
  <summary>16. <b>标题：A Human-Centric Assessment Framework for AI</b></summary>
  <p><b>编号</b>：[69]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12749</p>
  <p><b>作者</b>：Sascha Saralajew,  Ammar Shaker,  Zhao Xu,  Kiril Gashteovski,  Bhushan Kotnis,  Wiem Ben-Rim,  Jürgen Quittek,  Carolin Lawrence</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：real-world applications, reliable and trustworthy, system, Turing test, domain expert</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>With the rise of AI systems in real-world applications comes the need for
reliable and trustworthy AI. An important aspect for this are explainable AI
systems. However, there is no agreed standard on how explainable AI systems
should be assessed. Inspired by the Turing test, we introduce a human-centric
assessment framework where a leading domain expert accepts or rejects the
solutions of an AI system and another domain expert. By comparing the
acceptance rates of provided solutions, we can assess how the AI system
performs in comparison to the domain expert, and in turn whether or not the AI
system's explanations (if provided) are human understandable. This setup --
comparable to the Turing test -- can serve as framework for a wide range of
human-centric AI system assessments. We demonstrate this by presenting two
instantiations: (1) an assessment that measures the classification accuracy of
a system with the option to incorporate label uncertainties; (2) an assessment
where the usefulness of provided explanations is determined in a human-centric
manner.</p>
  </details>
</details>
<details>
  <summary>17. <b>标题：SIoU Loss: More Powerful Learning for Bounding Box Regression</b></summary>
  <p><b>编号</b>：[72]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12740</p>
  <p><b>作者</b>：Zhora Gevorgyan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：computer vision tasks, object detection loss, Conventional object detection, detection loss functions, Object Detection</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The effectiveness of Object Detection, one of the central problems in
computer vision tasks, highly depends on the definition of the loss function -
a measure of how accurately your ML model can predict the expected outcome.
Conventional object detection loss functions depend on aggregation of metrics
of bounding box regression such as the distance, overlap area and aspect ratio
of the predicted and ground truth boxes (i.e. GIoU, CIoU, ICIoU etc). However,
none of the methods proposed and used to date considers the direction of the
mismatch between the desired ground box and the predicted, "experimental" box.
This shortage results in slower and less effective convergence as the predicted
box can "wander around" during the training process and eventually end up
producing a worse model. In this paper a new loss function SIoU was suggested,
where penalty metrics were redefined considering the angle of the vector
between the desired regression. Applied to conventional Neural Networks and
datasets it is shown that SIoU improves both the speed of training and the
accuracy of the inference. The effectiveness of the proposed loss function was
revealed in a number of simulations and tests.</p>
  </details>
</details>
<details>
  <summary>18. <b>标题：Inductive Learning of Complex Knowledge from Raw Data</b></summary>
  <p><b>编号</b>：[75]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12735</p>
  <p><b>作者</b>：Daniel Cunnington,  Mark Law,  Jorge Lobo,  Alessandra Russo</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Artificial Intelligence, goals of Artificial, ultimate goals, generalised and human-interpretable, raw data</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>One of the ultimate goals of Artificial Intelligence is to learn generalised
and human-interpretable knowledge from raw data. Neuro-symbolic reasoning
approaches partly tackle this problem by improving the training of a neural
network using a manually engineered symbolic knowledge base. In the case where
symbolic knowledge is learned from raw data, this knowledge lacks the
expressivity required to solve complex problems. In this paper, we introduce
Neuro-Symbolic Inductive Learner (NSIL), an approach that trains a neural
network to extract latent concepts from raw data, whilst learning symbolic
knowledge that solves complex problems, defined in terms of these latent
concepts. The novelty of our approach is a method for biasing a symbolic
learner to learn improved knowledge, based on the in-training performance of
both neural and symbolic components. We evaluate NSIL on two problem domains
that require learning knowledge with different levels of complexity, and
demonstrate that NSIL learns knowledge that is not possible to learn with other
neuro-symbolic systems, whilst outperforming baseline models in terms of
accuracy and data efficiency.</p>
  </details>
</details>
<details>
  <summary>19. <b>标题：DPSNN: A Differentially Private Spiking Neural Network</b></summary>
  <p><b>编号</b>：[81]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12718</p>
  <p><b>作者</b>：Jihang Wang,  Dongcheng Zhao,  Guobin Shen,  Qian Zhang,  Yi Zeng</p>
  <p><b>备注</b>：12 pages, 6 figures</p>
  <p><b>关键词</b>：privacy protection, machine learning algorithm, Spiking neural network, SNN, neural network</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Privacy-preserving is a key problem for the machine learning algorithm.
Spiking neural network (SNN) plays an important role in many domains, such as
image classification, object detection, and speech recognition, but the study
on the privacy protection of SNN is urgently needed. This study combines the
differential privacy (DP) algorithm and SNN and proposes differentially private
spiking neural network (DPSNN). DP injects noise into the gradient, and SNN
transmits information in discrete spike trains so that our differentially
private SNN can maintain strong privacy protection while still ensuring high
accuracy. We conducted experiments on MNIST, Fashion-MNIST, and the face
recognition dataset Extended YaleB. When the privacy protection is improved,
the accuracy of the artificial neural network(ANN) drops significantly, but our
algorithm shows little change in performance. Meanwhile, we analyzed different
factors that affect the privacy protection of SNN. Firstly, the less precise
the surrogate gradient is, the better the privacy protection of the SNN.
Secondly, the Integrate-And-Fire (IF) neurons perform better than leaky
Integrate-And-Fire (LIF) neurons. Thirdly, a large time window contributes more
to privacy protection and performance.</p>
  </details>
</details>
<details>
  <summary>20. <b>标题：Train Flat, Then Compress: Sharpness-Aware Minimization Learns More  Compressible Models</b></summary>
  <p><b>编号</b>：[93]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12694</p>
  <p><b>作者</b>：Clara Na,  Sanket Vaibhav Mehta,  Emma Strubell</p>
  <p><b>备注</b>：12 pages</p>
  <p><b>关键词</b>：recently gained popularity, modern deep neural, deep neural network, neural network models, recently gained</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Model compression by way of parameter pruning, quantization, or distillation
has recently gained popularity as an approach for reducing the computational
requirements of modern deep neural network models for NLP. Pruning unnecessary
parameters has emerged as a simple and effective method for compressing large
models that is compatible with a wide variety of contemporary off-the-shelf
hardware (unlike quantization), and that requires little additional training
(unlike distillation). Pruning approaches typically take a large, accurate
model as input, then attempt to discover a smaller subnetwork of that model
capable of achieving end-task accuracy comparable to the full model. Inspired
by previous work suggesting a connection between simpler, more generalizable
models and those that lie within flat basins in the loss landscape, we propose
to directly optimize for flat minima while performing task-specific pruning,
which we hypothesize should lead to simpler parameterizations and thus more
compressible models. In experiments combining sharpness-aware minimization with
both iterative magnitude pruning and structured pruning approaches, we show
that optimizing for flat minima consistently leads to greater compressibility
of parameters compared to standard Adam optimization when fine-tuning BERT
models, leading to higher rates of compression with little to no loss in
accuracy on the GLUE classification benchmark.</p>
  </details>
</details>
<details>
  <summary>21. <b>标题：Large Language Models are Zero-Shot Clinical Information Extractors</b></summary>
  <p><b>编号</b>：[96]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12689</p>
  <p><b>作者</b>：Monica Agrawal,  Stefan Hegselmann,  Hunter Lang,  Yoon Kim,  David Sontag</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：large language models, language model outputs, trained specifically, language model, clinical text</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We show that large language models, such as GPT-3, perform well at zero-shot
information extraction from clinical text despite not being trained
specifically for the clinical domain. We present several examples showing how
to use these models as tools for the diverse tasks of (i) concept
disambiguation, (ii) evidence extraction, (iii) coreference resolution, and
(iv) concept extraction, all on clinical text. The key to good performance is
the use of simple task-specific programs that map from the language model
outputs to the label space of the task. We refer to these programs as
resolvers, a generalization of the verbalizer, which defines a mapping between
output tokens and a discrete label space. We show in our examples that good
resolvers share common components (e.g., "safety checks" that ensure the
language model outputs faithfully match the input data), and that the common
patterns across tasks make resolvers lightweight and easy to create. To better
evaluate these systems, we also introduce two new datasets for benchmarking
zero-shot clinical information extraction based on manual relabeling of the
CASI dataset (Moon et al., 2014) with labels for new tasks. On the clinical
extraction tasks we studied, the GPT-3 + resolver systems significantly
outperform existing zero- and few-shot baselines.</p>
  </details>
</details>
<details>
  <summary>22. <b>标题：Ground-Truth Labels Matter: A Deeper Look into Input-Label  Demonstrations</b></summary>
  <p><b>编号</b>：[99]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12685</p>
  <p><b>作者</b>：Junyeob Kim,  Hyuhng Joon Kim,  Hyunsoo Cho,  Hwiyeol Jo,  Sang-Woo Lee,  Sang-goo Lee,  Kang Min Yoo,  Taeuk Kim</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：demonstrations remain elusive, in-context learning, research interests, remain elusive, recent explosion</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Despite recent explosion in research interests, in-context learning and the
precise impact of the quality of demonstrations remain elusive. While, based on
current literature, it is expected that in-context learning shares a similar
mechanism to supervised learning, Min et al. (2022) recently reported that,
surprisingly, input-label correspondence is less important than other aspects
of prompt demonstrations. Inspired by this counter-intuitive observation, we
re-examine the importance of ground truth labels on in-context learning from
diverse and statistical points of view. With the aid of the newly introduced
metrics, i.e., Ground-truth Label Effect Ratio (GLER), demo-gain, and label
sensitivity, we find that the impact of the correct input-label matching can
vary according to different configurations. Expanding upon the previous key
finding on the role of demonstrations, the complementary and contrastive
results suggest that one might need to take more care when estimating the
impact of each component in in-context learning demonstrations.</p>
  </details>
</details>
<details>
  <summary>23. <b>标题：Rethinking Fano's Inequality in Ensemble Learning</b></summary>
  <p><b>编号</b>：[100]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12683</p>
  <p><b>作者</b>：Terufumi Morishita,  Gaku Morio,  Shota Horiguchi,  Hiroaki Ozaki,  Nobuo Nukaga</p>
  <p><b>备注</b>：To appear in ICML 2022</p>
  <p><b>关键词</b>：propose a fundamental, well-grounded set, Fano inequality, original Fano inequality, fundamental theory</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose a fundamental theory on ensemble learning that evaluates a given
ensemble system by a well-grounded set of metrics. Previous studies used a
variant of Fano's inequality of information theory and derived a lower bound of
the classification error rate on the basis of the accuracy and diversity of
models. We revisit the original Fano's inequality and argue that the studies
did not take into account the information lost when multiple model predictions
are combined into a final prediction. To address this issue, we generalize the
previous theory to incorporate the information loss. Further, we empirically
validate and demonstrate the proposed theory through extensive experiments on
actual systems. The theory reveals the strengths and weaknesses of systems on
each metric, which will push the theoretical understanding of ensemble learning
and give us insights into designing systems.</p>
  </details>
</details>
<details>
  <summary>24. <b>标题：MAPLE-X: Latency Prediction with Explicit Microprocessor Prior Knowledge</b></summary>
  <p><b>编号</b>：[112]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12660</p>
  <p><b>作者</b>：Saad Abbasi,  Alexander Wong,  Mohammad Javad Shafiee</p>
  <p><b>备注</b>：6 pages, 4 figures</p>
  <p><b>关键词</b>：adds significant cost, Neural Architecture Search, efficient convolutional neural, Architecture Search, processes when searching</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep neural network (DNN) latency characterization is a time-consuming
process and adds significant cost to Neural Architecture Search (NAS) processes
when searching for efficient convolutional neural networks for embedded vision
applications. DNN Latency is a hardware dependent metric and requires direct
measurement or inference on target hardware. A recently introduced latency
estimation technique known as MAPLE predicts DNN execution time on previously
unseen hardware devices by using hardware performance counters. Leveraging
these hardware counters in the form of an implicit prior, MAPLE achieves
state-of-the-art performance in latency prediction. Here, we propose MAPLE-X
which extends MAPLE by incorporating explicit prior knowledge of hardware
devices and DNN architecture latency to better account for model stability and
robustness. First, by identifying DNN architectures that exhibit a similar
latency to each other, we can generate multiple virtual examples to
significantly improve the accuracy over MAPLE. Secondly, the hardware
specifications are used to determine the similarity between training and test
hardware to emphasize training samples captured from comparable devices
(domains) and encourages improved domain alignment. Experimental results using
a convolution neural network NAS benchmark across different types of devices,
including an Intel processor that is now used for embedded vision applications,
demonstrate a 5% improvement over MAPLE and 9% over HELP. Furthermore, we
include ablation studies to independently assess the benefits of virtual
examples and hardware-based sample importance.</p>
  </details>
</details>
<details>
  <summary>25. <b>标题：Fast Inference and Transfer of Compositional Task Structures for  Few-shot Task Generalization</b></summary>
  <p><b>编号</b>：[117]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12648</p>
  <p><b>作者</b>：Sungryull Sohn,  Hyunjae Woo,  Jongwook Choi,  lyubing qiang,  Izzeddin Gur,  Aleksandra Faust,  Honglak Lee</p>
  <p><b>备注</b>：Accepted to UAI 2022 as an oral presentation</p>
  <p><b>关键词</b>：tackle real-world problems, game or simulator, tackle real-world, pixel-based game, reinforcement learning problem</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We tackle real-world problems with complex structures beyond the pixel-based
game or simulator. We formulate it as a few-shot reinforcement learning problem
where a task is characterized by a subtask graph that defines a set of subtasks
and their dependencies that are unknown to the agent. Different from the
previous meta-rl methods trying to directly infer the unstructured task
embedding, our multi-task subtask graph inferencer (MTSGI) first infers the
common high-level task structure in terms of the subtask graph from the
training tasks, and use it as a prior to improve the task inference in testing.
Our experiment results on 2D grid-world and complex web navigation domains show
that the proposed method can learn and leverage the common underlying structure
of the tasks for faster adaptation to the unseen tasks than various existing
algorithms such as meta reinforcement learning, hierarchical reinforcement
learning, and other heuristic agents.</p>
  </details>
</details>
<details>
  <summary>26. <b>标题：UniInst: Unique Representation for End-to-End Instance Segmentation</b></summary>
  <p><b>编号</b>：[119]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12646</p>
  <p><b>作者</b>：Yimin Ou,  Rui Yang,  Lufan Ma,  Yong Liu,  Jiangpeng Yan,  Shang Xu,  Chengjie Wang,  Xiu Li</p>
  <p><b>备注</b>：This work is in the revision phase of the journal Neurocomputing. Codes will be available upon publication</p>
  <p><b>关键词</b>：multiple duplicated predictions, Existing instance segmentation, achieved impressive performance, multiple boxes, multiple duplicated</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Existing instance segmentation methods have achieved impressive performance
but still suffer from a common dilemma: redundant representations (e.g.,
multiple boxes, grids, and anchor points) are inferred for one instance, which
leads to multiple duplicated predictions. Thus, mainstream methods usually rely
on a hand-designed non-maximum suppression (NMS) post-processing to select the
optimal prediction result, which hinders end-to-end training. To address this
issue, we propose a box-free and NMS-free end-to-end instance segmentation
framework, termed UniInst, that yields only one unique representation for each
instance. Specifically, we design an instance-aware one-to-one assignment
scheme, namely Only Yield One Representation (OYOR), which dynamically assigns
one unique representation to one instance according to the matching quality
between predictions and ground truths. Then, a novel prediction re-ranking
strategy is elegantly integrated into the framework to address the misalignment
between the classification score and the mask quality, enabling the learned
representation to be more discriminative. With these techniques, our UniInst,
the first FCN-based end-to-end instance segmentation framework, achieves
competitive performance, e.g., 39.0 mask AP with ResNet-50-FPN and 40.2 mask AP
with ResNet-101-FPN, against mainstream methods on the COCO benchmark.
Moreover, the proposed instance-aware method is robust to occlusion scenes,
outperforming common baselines by remarkable mask AP on the heavily-occluded
OCHuman benchmark. Our codes will be available upon publication.</p>
  </details>
</details>
<details>
  <summary>27. <b>标题：Are Large Pre-Trained Language Models Leaking Your Personal Information?</b></summary>
  <p><b>编号</b>：[129]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12628</p>
  <p><b>作者</b>：Jie Huang,  Hanyin Shao,  Kevin Chen-Chuan Chang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Large Pre-Trained Language, Pre-Trained Language Models, Pre-Trained Language, Language Models, Large Pre-Trained</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large Pre-Trained Language Models (PLMs) have facilitated and dominated many
NLP tasks in recent years. However, despite the great success of PLMs, there
are also privacy concerns brought with PLMs. For example, recent studies show
that PLMs memorize a lot of training data, including sensitive information,
while the information may be leaked unintentionally and be utilized by
malicious attackers.
In this paper, we propose to measure whether PLMs are prone to leaking
personal information. Specifically, we attempt to query PLMs for email
addresses with contexts of the email address or prompts containing the owner's
name. We find that PLMs do leak personal information due to memorization.
However, the risk of specific personal information being extracted by attackers
is low because the models are weak at associating the personal information with
its owner. We hope this work could help the community to better understand the
privacy risk of PLMs and bring new insights to make PLMs safe.</p>
  </details>
</details>
<details>
  <summary>28. <b>标题：DisinfoMeme: A Multimodal Dataset for Detecting Meme Intentionally  Spreading Out Disinformation</b></summary>
  <p><b>编号</b>：[135]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12617</p>
  <p><b>作者</b>：Jingnong Qu,  Liunian Harold Li,  Jieyu Zhao,  Sunipa Dev,  Kai-Wei Chang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：social media, problem on social, Black Lives Matter, Lives Matter movement, Disinformation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Disinformation has become a serious problem on social media. In particular,
given their short format, visual attraction, and humorous nature, memes have a
significant advantage in dissemination among online communities, making them an
effective vehicle for the spread of disinformation. We present DisinfoMeme to
help detect disinformation memes. The dataset contains memes mined from Reddit
covering three current topics: the COVID-19 pandemic, the Black Lives Matter
movement, and veganism/vegetarianism. The dataset poses multiple unique
challenges: limited data and label imbalance, reliance on external knowledge,
multimodal reasoning, layout dependency, and noise from OCR. We test multiple
widely-used unimodal and multimodal models on this dataset. The experiments
show that the room for improvement is still huge for current models.</p>
  </details>
</details>
<details>
  <summary>29. <b>标题：Autoformalization with Large Language Models</b></summary>
  <p><b>编号</b>：[137]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12615</p>
  <p><b>作者</b>：Yuhuai Wu,  Albert Q. Jiang,  Wenda Li,  Markus N. Rabe,  Charles Staats,  Mateja Jamnik,  Christian Szegedy</p>
  <p><b>备注</b>：44 pages</p>
  <p><b>关键词</b>：natural language mathematics, automatically translating, translating from natural, formal specifications, natural language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Autoformalization is the process of automatically translating from natural
language mathematics to formal specifications and proofs. A successful
autoformalization system could advance the fields of formal verification,
program synthesis, and artificial intelligence. While the long-term goal of
autoformalization seemed elusive for a long time, we show large language models
provide new prospects towards this goal. We make the surprising observation
that LLMs can correctly translate a significant portion ($25.3\%$) of
mathematical competition problems perfectly to formal specifications in
Isabelle/HOL. We demonstrate the usefulness of this process by improving a
previously introduced neural theorem prover via training on these
autoformalized theorems. Our methodology results in a new state-of-the-art
result on the MiniF2F theorem proving benchmark, improving the proof rate from
$29.6\%$ to $35.2\%$.</p>
  </details>
</details>
<details>
  <summary>30. <b>标题：Perturbation Augmentation for Fairer NLP</b></summary>
  <p><b>编号</b>：[154]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12586</p>
  <p><b>作者</b>：Rebecca Qian,  Candace Ross,  Jude Fernandes,  Eric Smith,  Douwe Kiela,  Adina Williams</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：harmful social biases, harmful social, social biases, language models, models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Unwanted and often harmful social biases are becoming ever more salient in
NLP research, affecting both models and datasets. In this work, we ask: does
training on demographically perturbed data lead to more fair language models?
We collect a large dataset of human annotated text perturbations and train an
automatic perturber on it, which we show to outperform heuristic alternatives.
We find: (i) Language models (LMs) pre-trained on demographically perturbed
corpora are more fair, at least, according to our current best metrics for
measuring model fairness, and (ii) LMs finetuned on perturbed GLUE datasets
exhibit less demographic bias on downstream tasks. We find that improved
fairness does not come at the expense of accuracy. Although our findings appear
promising, there are still some limitations, as well as outstanding questions
about how best to evaluate the (un)fairness of large language models. We hope
that this initial exploration of neural demographic perturbation will help
drive more improvement towards fairer NLP.</p>
  </details>
</details>
<details>
  <summary>31. <b>标题：A Simple and Unified Tagging Model with Priming for Relational Structure  Predictions</b></summary>
  <p><b>编号</b>：[155]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12585</p>
  <p><b>作者</b>：I-Hung Hsu,  Kuan-Hao Huang,  Shuning Zhang,  Wenxin Cheng,  Premkumar Natarajan,  Kai-Wei Chang,  Nanyun Peng</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：natural language processing, covers a wide, wide range, plays an important, important role</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Relational structure extraction covers a wide range of tasks and plays an
important role in natural language processing. Recently, many approaches tend
to design sophisticated graphical models to capture the complex relations
between objects that are described in a sentence. In this work, we demonstrate
that simple tagging models can surprisingly achieve competitive performances
with a small trick -- priming. Tagging models with priming append information
about the operated objects to the input sequence of pretrained language model.
Making use of the contextualized nature of pretrained language model, the
priming approach help the contextualized representation of the sentence better
embed the information about the operated objects, hence, becomes more suitable
for addressing relational structure extraction. We conduct extensive
experiments on three different tasks that span ten datasets across five
different languages, and show that our model is a general and effective model,
despite its simplicity. We further carry out comprehensive analysis to
understand our model and propose an efficient approximation to our method,
which can perform almost the same performance but with faster inference speed.</p>
  </details>
</details>
<details>
  <summary>32. <b>标题：From Pedestrian Detection to Crosswalk Estimation: An EM Algorithm and  Analysis on Diverse Datasets</b></summary>
  <p><b>编号</b>：[159]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12579</p>
  <p><b>作者</b>：Ross Greer,  Mohan Trivedi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：processed LiDAR point, LiDAR point clouds, linear crossing segments, camera images, processed LiDAR</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this work, we contribute an EM algorithm for estimation of corner points
and linear crossing segments for both marked and unmarked pedestrian crosswalks
using the detections of pedestrians from processed LiDAR point clouds or camera
images. We demonstrate the algorithmic performance by analyzing three
real-world datasets containing multiple periods of data collection for
four-corner and two-corner intersections with marked and unmarked crosswalks.
Additionally, we include a Python video tool to visualize the crossing
parameter estimation, pedestrian trajectories, and phase intervals in our
public source code.</p>
  </details>
</details>
<details>
  <summary>33. <b>标题：Spotlights: Probing Shapes from Spherical Viewpoints</b></summary>
  <p><b>编号</b>：[164]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12564</p>
  <p><b>作者</b>：Jiaxin Wei,  Lige Liu,  Ran Cheng,  Wenqing Jiang,  Minghao Xu,  Xinyu Jiang,  Tao Sun,  Soren Schwertfeger,  Laurent Kneip</p>
  <p><b>备注</b>：17 pages</p>
  <p><b>关键词</b>：Recent years, years have witnessed, witnessed the surge, surge of learned, directly build</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent years have witnessed the surge of learned representations that
directly build upon point clouds. Though becoming increasingly expressive, most
existing representations still struggle to generate ordered point sets.
Inspired by spherical multi-view scanners, we propose a novel sampling model
called Spotlights to represent a 3D shape as a compact 1D array of depth
values. It simulates the configuration of cameras evenly distributed on a
sphere, where each virtual camera casts light rays from its principal point
through sample points on a small concentric spherical cap to probe for the
possible intersections with the object surrounded by the sphere. The structured
point cloud is hence given implicitly as a function of depths. We provide a
detailed geometric analysis of this new sampling scheme and prove its
effectiveness in the context of the point cloud completion task. Experimental
results on both synthetic and real data demonstrate that our method achieves
competitive accuracy and consistency while having a significantly reduced
computational cost. Furthermore, we show superior performance on the downstream
point cloud registration task over state-of-the-art completion methods.</p>
  </details>
</details>
<details>
  <summary>34. <b>标题：Helpfulness and Fairness of Task-Oriented Dialogue Systems</b></summary>
  <p><b>编号</b>：[169]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12554</p>
  <p><b>作者</b>：Jiao Sun,  Yu Hou,  Jiin Kim,  Nanyun Peng</p>
  <p><b>备注</b>：16 pages, 5 figures and 8 tables</p>
  <p><b>关键词</b>：dialogue systems, dialogue, aim to answer, users and provide, Task-oriented dialogue systems</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Task-oriented dialogue systems aim to answer questions from users and provide
immediate help. Therefore, how humans perceive their helpfulness is important.
However, neither the human-perceived helpfulness of task-oriented dialogue
systems nor its fairness implication has been studied yet. In this paper, we
define a dialogue response as helpful if it is relevant & coherent, useful, and
informative to a query and study computational measurements of helpfulness.
Then, we propose utilizing the helpfulness level of different groups to gauge
the fairness of a dialogue system. To study this, we collect human annotations
for the helpfulness of dialogue responses and build a classifier that can
automatically determine the helpfulness of a response. We design experiments
under 3 information-seeking scenarios and collect instances for each from
Wikipedia. With collected instances, we use carefully-constructed questions to
query the state-of-the-art dialogue systems. Through analysis, we find that
dialogue systems tend to be more helpful for highly-developed countries than
less-developed countries, uncovering a fairness issue underlying these dialogue
systems.</p>
  </details>
</details>
<details>
  <summary>35. <b>标题：Deep Dense Local Feature Matching and Vehicle Removal for Indoor Visual  Localization</b></summary>
  <p><b>编号</b>：[175]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12544</p>
  <p><b>作者</b>：Kyung Ho Park</p>
  <p><b>备注</b>：8 pages, 12 figures, 2 tables</p>
  <p><b>关键词</b>：enabling broad applications, intelligent transportation systems, transportation systems, enabling broad, essential component</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Visual localization is an essential component of intelligent transportation
systems, enabling broad applications that require understanding one's self
location when other sensors are not available. It is mostly tackled by image
retrieval such that the location of a query image is determined by its closest
match in the previously collected images. Existing approaches focus on large
scale localization where landmarks are helpful in finding the location.
However, visual localization becomes challenging in small scale environments
where objects are hardly recognizable. In this paper, we propose a visual
localization framework that robustly finds the match for a query among the
images collected from indoor parking lots. It is a challenging problem when the
vehicles in the images share similar appearances and are frequently replaced
such as parking lots. We propose to employ a deep dense local feature matching
that resembles human perception to find correspondences and eliminating matches
from vehicles automatically with a vehicle detector. The proposed solution is
robust to the scenes with low textures and invariant to false matches caused by
vehicles. We compare our framework with alternatives to validate our
superiority on a benchmark dataset containing 267 pre-collected images and 99
query images taken from 34 sections of a parking lot. Our method achieves 86.9
percent accuracy, outperforming the alternatives.</p>
  </details>
</details>
<details>
  <summary>36. <b>标题：Apport des ontologies pour le calcul de la similarité sémantique au  sein d'un système de recommandation</b></summary>
  <p><b>编号</b>：[178]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12539</p>
  <p><b>作者</b>：Le Ngoc Luyen,  Marie-Hélène Abel,  Philippe Gouspillou</p>
  <p><b>备注</b>：in French language</p>
  <p><b>关键词</b>：natural language processing, text data plays, likeness between terms, language processing, text data</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Measurement of the semantic relatedness or likeness between terms, words, or
text data plays an important role in different applications dealing with
textual data such as knowledge acquisition, recommender system, and natural
language processing. Over the past few years, many ontologies have been
developed and used as a form of structured representation of knowledge bases
for information systems. The calculation of semantic similarity from ontology
has developed and depending on the context is complemented by other similarity
calculation methods. In this paper, we propose and carry on an approach for the
calculation of ontology-based semantic similarity using in the context of a
recommender system.</p>
  </details>
</details>
<details>
  <summary>37. <b>标题：Is a Question Decomposition Unit All We Need?</b></summary>
  <p><b>编号</b>：[179]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12538</p>
  <p><b>作者</b>：Pruthvi Patel,  Swaroop Mishra,  Mihir Parmar,  Chitta Baral</p>
  <p><b>备注</b>：16 pages</p>
  <p><b>关键词</b>：Natural Language Processing, Language Processing, Natural Language, Large Language Models, Language Models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large Language Models (LMs) have achieved state-of-the-art performance on
many Natural Language Processing (NLP) benchmarks. With the growing number of
new benchmarks, we build bigger and more complex LMs. However, building new LMs
may not be an ideal option owing to the cost, time and environmental impact
associated with it. We explore an alternative route: can we modify data by
expressing it in terms of the model's strengths, so that a question becomes
easier for models to answer? We investigate if humans can decompose a hard
question into a set of simpler questions that are relatively easier for models
to solve. We analyze a range of datasets involving various forms of reasoning
and find that it is indeed possible to significantly improve model performance
(24% for GPT3 and 29% for RoBERTa-SQuAD along with a symbolic calculator) via
decomposition. Our approach provides a viable option to involve people in NLP
research in a meaningful way. Our findings indicate that Human-in-the-loop
Question Decomposition (HQD) can potentially provide an alternate path to
building large LMs.</p>
  </details>
</details>
<details>
  <summary>38. <b>标题：Toward Discovering Options that Achieve Faster Planning</b></summary>
  <p><b>编号</b>：[190]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12515</p>
  <p><b>作者</b>：Yi Wan,  Richard S. Sutton</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：options, objective, discovery that emphasizes, emphasizes the computational, computational advantage</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose a new objective for option discovery that emphasizes the
computational advantage of using options in planning. For a given set of
episodic tasks and a given number of options, the objective prefers options
that can be used to achieve a high return by composing few options. By
composing few options, fast planning can be achieved. When faced with new tasks
similar to the given ones, the discovered options are also expected to
accelerate planning. Our objective extends the objective proposed by Harb et
al. (2018) for the single-task setting to the multi-task setting. A closer look
at Harb et al.'s objective shows that the best options discovered given one
task are not likely to be useful for future unseen tasks and that the
multi-task setting is indeed necessary for this purpose. In the same paper,
Harb et al. also proposed an algorithm to optimize their objective, and the
algorithm can be naturally extended to the multi-task setting. We empirically
show that in the four-room domain the extension does not achieve a high
objective value and propose a new algorithm that better optimizes the proposed
objective. In the same four-room domain, we show that 1) a higher objective
value is typically associated with options with which fewer planning iterations
are needed to achieve near-optimal performance, 2) our new algorithm achieves a
high objective value, which is close to the value achieved by a set of
human-designed options, 3) the best number of planning iterations given the
discovered options is much smaller and matches it obtained given human-designed
options, and 4) the options produced by our algorithm also make intuitive sense
because they move to and terminate at cells near hallways connecting two
neighbor rooms.</p>
  </details>
</details>
<details>
  <summary>39. <b>标题：Deadlock-Free Method for Multi-Agent Pickup and Delivery Problem Using  Priority Inheritance with Temporary Priority</b></summary>
  <p><b>编号</b>：[197]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12504</p>
  <p><b>作者</b>：Yukita Fujitani,  Tomoki Yamauchi,  Yuki Miyashita,  Toshiharu Sugawara</p>
  <p><b>备注</b>：The paper was accepted at 26th International Conference on Knowledge-Based and Intelligent Information & Engineering Systems (KES 2022)</p>
  <p><b>关键词</b>：PIBT, MAPD problem, inheritance with backtracking, paper proposes, proposes a control</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper proposes a control method for the multi-agent pickup and delivery
problem (MAPD problem) by extending the priority inheritance with backtracking
(PIBT) method to make it applicable to more general environments. PIBT is an
effective algorithm that introduces a priority to each agent, and at each
timestep, the agents, in descending order of priority, decide their next
neighboring locations in the next timestep through communications only with the
local agents. Unfortunately, PIBT is only applicable to environments that are
modeled as a bi-connected area, and if it contains dead-ends, such as
tree-shaped paths, PIBT may cause deadlocks. However, in the real-world
environment, there are many dead-end paths to locations such as the shelves
where materials are stored as well as loading/unloading locations to
transportation trucks. Our proposed method enables MAPD tasks to be performed
in environments with some tree-shaped paths without deadlock while preserving
the PIBT feature; it does this by allowing the agents to have temporary
priorities and restricting agents' movements in the trees. First, we
demonstrate that agents can always reach their delivery without deadlock. Our
experiments indicate that the proposed method is very efficient, even in
environments where PIBT is not applicable, by comparing them with those
obtained using the well-known token passing method as a baseline.</p>
  </details>
</details>
<details>
  <summary>40. <b>标题：Teaching Broad Reasoning Skills via Decomposition-Guided Contexts</b></summary>
  <p><b>编号</b>：[201]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12496</p>
  <p><b>作者</b>：Harsh Trivedi,  Niranjan Balasubramanian,  Tushar Khot,  Ashish Sabharwal</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Question-answering datasets require, reasoning, skills, multihop, contexts</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Question-answering datasets require a broad set of reasoning skills. We show
how to use question decompositions to teach language models these broad
reasoning skills in a robust fashion. Specifically, we use widely available
QDMR representations to programmatically create synthetic contexts for real
questions in six multihop reasoning datasets. These contexts are carefully
designed to avoid common reasoning shortcuts prevalent in real contexts that
prevent models from learning the right skills. This results in a pretraining
dataset, named TeaBReaC, containing 525K multihop questions (with associated
formal programs) covering about 900 reasoning patterns. We show that
pretraining standard language models (LMs) on TeaBReaC before fine-tuning them
on target datasets improves their performance by up to 13 EM points across 3
multihop QA datasets, with a 30 point gain on more complex questions. The
resulting models also demonstrate higher robustness, with a 6-11 point
improvement on two contrast sets. Furthermore, TeaBReaC pretraining
substantially improves model performance and robustness even when starting with
numeracy-aware LMs pretrained using recent methods (e.g., PReasM). Our work
thus shows how one can effectively use decomposition-guided contexts to
robustly teach multihop reasoning.</p>
  </details>
</details>
<details>
  <summary>41. <b>标题：Improve Event Extraction via Self-Training with Gradient Guidance</b></summary>
  <p><b>编号</b>：[206]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12490</p>
  <p><b>作者</b>：Zhiyang Xu,  Lifu Huang</p>
  <p><b>备注</b>：9 pages, 4 figures</p>
  <p><b>关键词</b>：base event extraction, Abstract Meaning Representation, event extraction, event extraction model, event</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Data scarcity and imbalance have been the main factors that hinder the
progress of event extraction (EE). In this work, we propose a self-training
with gradient guidance (STGG) framework which consists of (1) a base event
extraction model which is firstly trained on existing event annotations and
then applied to large-scale unlabeled corpora to predict new event mentions,
and (2) a scoring model that takes in each predicted event trigger and argument
as well as their path in the Abstract Meaning Representation (AMR) graph to
estimate a probability score indicating the correctness of the event
prediction. The new event predictions along with their correctness scores are
then used as pseudo labeled examples to improve the base event extraction model
while the magnitude and direction of its gradients are guided by the
correctness scores. Experimental results on three benchmark datasets, including
ACE05-E, ACE05-E+ and ERE-EN, demonstrate the effectiveness of the STGG
framework on event extraction task with up to 1.9 F-score improvement over the
base event extraction models. Our experimental analysis further shows that STGG
is a general framework as it can be applied to any base event extraction models
and improve their performance by leveraging broad unlabeled data, even when the
high-quality AMR graph annotations are not available.</p>
  </details>
</details>
<details>
  <summary>42. <b>标题：Conditional set generation using Seq2seq models</b></summary>
  <p><b>编号</b>：[209]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12485</p>
  <p><b>作者</b>：Aman Madaan,  Dheeraj Rajagopal,  Niket Tandon,  Yiming Yang,  Antoine Bosselut</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Conditional set generation, set generation learns, set generation, learns a mapping, set</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Conditional set generation learns a mapping from an input sequence of tokens
to a set. Several NLP tasks, such as entity typing and dialogue emotion
tagging, are instances of set generation. Sequence-to-sequence~(Seq2seq) models
are a popular choice to model set generation, but they treat a set as a
sequence and do not fully leverage its key properties, namely order-invariance
and cardinality. We propose a novel algorithm for effectively sampling
informative orders over the combinatorial space of label orders. Further, we
jointly model the set cardinality and output by adding the set size as the
first element and taking advantage of the autoregressive factorization used by
Seq2seq models. Our method is a model-independent data augmentation approach
that endows any Seq2seq model with the signals of order-invariance and
cardinality. Training a Seq2seq model on this new augmented data~(without any
additional annotations) gets an average relative improvement of 20% for four
benchmarks datasets across models spanning from BART-base, T5-xxl, and GPT-3.</p>
  </details>
</details>
<details>
  <summary>43. <b>标题：GisPy: A Tool for Measuring Gist Inference Score in Text</b></summary>
  <p><b>编号</b>：[210]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12484</p>
  <p><b>作者</b>：Pedram Hosseini,  Christopher R. Wolfe,  Mona Diab,  David A. Broniatowski</p>
  <p><b>备注</b>：Accepted to the 4th Workshop on Narrative Understanding @ NAACL 2022</p>
  <p><b>关键词</b>：Decision making theories, Fuzzy-Trace Theory, suggest that individuals, bottom-line meaning, Gist Inference Score</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Decision making theories such as Fuzzy-Trace Theory (FTT) suggest that
individuals tend to rely on gist, or bottom-line meaning, in the text when
making decisions. In this work, we delineate the process of developing GisPy,
an open-source tool in Python for measuring the Gist Inference Score (GIS) in
text. Evaluation of GisPy on documents in three benchmarks from the news and
scientific text domains demonstrates that scores generated by our tool
significantly distinguish low vs. high gist documents. Our tool is publicly
available to use at: this https URL.</p>
  </details>
</details>
<details>
  <summary>44. <b>标题：Low Resource Style Transfer via Domain Adaptive Meta Learning</b></summary>
  <p><b>编号</b>：[212]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12475</p>
  <p><b>作者</b>：Xiangyang Li,  Xiang Long,  Yu Xia,  Sujian Li</p>
  <p><b>备注</b>：Accept in NAACL 2022(oral)</p>
  <p><b>关键词</b>：Text style transfer, style transfer, Adversarial Transfer Model, practical success, Text style</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Text style transfer (TST) without parallel data has achieved some practical
success. However, most of the existing unsupervised text style transfer methods
suffer from (i) requiring massive amounts of non-parallel data to guide
transferring different text styles. (ii) colossal performance degradation when
fine-tuning the model in new domains. In this work, we propose DAML-ATM (Domain
Adaptive Meta-Learning with Adversarial Transfer Model), which consists of two
parts: DAML and ATM. DAML is a domain adaptive meta-learning approach to learn
general knowledge in multiple heterogeneous source domains, capable of adapting
to new unseen domains with a small amount of data. Moreover, we propose a new
unsupervised TST approach Adversarial Transfer Model (ATM), composed of a
sequence-to-sequence pre-trained language model and uses adversarial style
training for better content preservation and style transfer. Results on
multi-domain datasets demonstrate that our approach generalizes well on unseen
low-resource domains, achieving state-of-the-art results against ten strong
baselines.</p>
  </details>
</details>
<details>
  <summary>45. <b>标题：sat2pc: Estimating Point Cloud of Building Roofs from 2D Satellite  Images</b></summary>
  <p><b>编号</b>：[222]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12464</p>
  <p><b>作者</b>：Yoones Rezaei,  Stephen Lee</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：virtual reality, urban planning, gained interest, planning and virtual, urban</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Three-dimensional (3D) urban models have gained interest because of their
applications in many use-cases such as urban planning and virtual reality.
However, generating these 3D representations requires LiDAR data, which are not
always readily available. Thus, the applicability of automated 3D model
generation algorithms is limited to a few locations. In this paper, we propose
sat2pc, a deep learning architecture that predicts the point cloud of a
building roof from a single 2D satellite image. Our architecture combines
Chamfer distance and EMD loss, resulting in better 2D to 3D performance. We
extensively evaluate our model and perform ablation studies on a building roof
dataset. Our results show that sat2pc was able to outperform existing baselines
by at least 18.6%. Further, we show that the predicted point cloud captures
more detail and geometric characteristics than other baselines.</p>
  </details>
</details>
<details>
  <summary>46. <b>标题：Augmentation-induced Consistency Regularization for Classification</b></summary>
  <p><b>编号</b>：[224]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12461</p>
  <p><b>作者</b>：Jianhan Wu,  Shijing Si,  Jianzong Wang,  Jing Xiao</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Deep neural networks, supervised learning tasks, data augmentation, Deep neural, supervised learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep neural networks have become popular in many supervised learning tasks,
but they may suffer from overfitting when the training dataset is limited. To
mitigate this, many researchers use data augmentation, which is a widely used
and effective method for increasing the variety of datasets. However, the
randomness introduced by data augmentation causes inevitable inconsistency
between training and inference, which leads to poor improvement. In this paper,
we propose a consistency regularization framework based on data augmentation,
called CR-Aug, which forces the output distributions of different sub models
generated by data augmentation to be consistent with each other. Specifically,
CR-Aug evaluates the discrepancy between the output distributions of two
augmented versions of each sample, and it utilizes a stop-gradient operation to
minimize the consistency loss. We implement CR-Aug to image and audio
classification tasks and conduct extensive experiments to verify its
effectiveness in improving the generalization ability of classifiers. Our
CR-Aug framework is ready-to-use, it can be easily adapted to many
state-of-the-art network architectures. Our empirical results show that CR-Aug
outperforms baseline methods by a significant margin.</p>
  </details>
</details>
<details>
  <summary>47. <b>标题：Investigating Information Inconsistency in Multilingual Open-Domain  Question Answering</b></summary>
  <p><b>编号</b>：[227]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12456</p>
  <p><b>作者</b>：Shramay Palta,  Haozhe An,  Yifan Yang,  Shuaiyi Huang,  Maharshi Gor</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：find best-answer candidates, best-answer candidates, retrieved documents, answer-span selection, find best-answer</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Retrieval based open-domain QA systems use retrieved documents and
answer-span selection over retrieved documents to find best-answer candidates.
We hypothesize that multilingual Question Answering (QA) systems are prone to
information inconsistency when it comes to documents written in different
languages, because these documents tend to provide a model with varying
information about the same topic. To understand the effects of the biased
availability of information and cultural influence, we analyze the behavior of
multilingual open-domain question answering models with a focus on retrieval
bias. We analyze if different retriever models present different passages given
the same question in different languages on TyDi QA and XOR-TyDi QA, two
multilingualQA datasets. We speculate that the content differences in documents
across languages might reflect cultural divergences and/or social biases.</p>
  </details>
</details>
<details>
  <summary>48. <b>标题：Sparse*BERT: Sparse Models are Robust</b></summary>
  <p><b>编号</b>：[230]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12452</p>
  <p><b>作者</b>：Daniel Campos,  Alexandre Marques,  Tuan Nguyen,  Mark Kurtz,  ChengXiang Zhai</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：natural language processing, modern natural language, Large Language Models, systems build, modern natural</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large Language Models have become the core architecture upon which most
modern natural language processing (NLP) systems build. These models can
consistently deliver impressive accuracy and robustness across tasks and
domains, but their high computational overhead can make inference difficult and
expensive. To make the usage of these models less costly recent work has
explored leveraging structured and unstructured pruning, quantization, and
distillation as ways to improve inference speed and decrease size. This paper
studies how models pruned using Gradual Unstructured Magnitude Pruning can
transfer between domains and tasks. Our experimentation shows that models that
are pruned during pretraining using general domain masked language models can
transfer to novel domains and tasks without extensive hyperparameter
exploration or specialized approaches. We demonstrate that our general sparse
model Sparse*BERT can become SparseBioBERT simply by pretraining the compressed
architecture on unstructured biomedical text. Moreover, we show that
SparseBioBERT can match the quality of BioBERT with only 10\% of the
parameters.</p>
  </details>
</details>
<details>
  <summary>49. <b>标题：VulBERTa: Simplified Source Code Pre-Training for Vulnerability  Detection</b></summary>
  <p><b>编号</b>：[240]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12424</p>
  <p><b>作者</b>：Hazim Hanif,  Sergio Maffeis</p>
  <p><b>备注</b>：Accepted as a conference paper at IJCNN 2022</p>
  <p><b>关键词</b>：detect security vulnerabilities, paper presents VulBERTa, deep learning approach, paper presents, detect security</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper presents VulBERTa, a deep learning approach to detect security
vulnerabilities in source code. Our approach pre-trains a RoBERTa model with a
custom tokenisation pipeline on real-world code from open-source C/C++
projects. The model learns a deep knowledge representation of the code syntax
and semantics, which we leverage to train vulnerability detection classifiers.
We evaluate our approach on binary and multi-class vulnerability detection
tasks across several datasets (Vuldeepecker, Draper, REVEAL and muVuldeepecker)
and benchmarks (CodeXGLUE and D2A). The evaluation results show that VulBERTa
achieves state-of-the-art performance and outperforms existing approaches
across different datasets, despite its conceptual simplicity, and limited cost
in terms of size of training data and number of model parameters.</p>
  </details>
</details>
<details>
  <summary>50. <b>标题：Deletion and Insertion Tests in Regression Models</b></summary>
  <p><b>编号</b>：[241]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12423</p>
  <p><b>作者</b>：Naofumi Hama,  Masayoshi Mase,  Art B. Owen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：black box function, basic task, task in explainable, prediction made, black box</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A basic task in explainable AI (XAI) is to identify the most important
features behind a prediction made by a black box function $f$. The insertion
and deletion tests of \cite{petsiuk2018rise} are used to judge the quality of
algorithms that rank pixels from most to least important for a classification.
Motivated by regression problems we establish a formula for their area under
the curve (AUC) criteria in terms of certain main effects and interactions in
an anchored decomposition of $f$. We find an expression for the expected value
of the AUC under a random ordering of inputs to $f$ and propose an alternative
area above a straight line for the regression setting. We use this criterion to
compare feature importances computed by integrated gradients (IG) to those
computed by Kernel SHAP (KS). Exact computation of KS grows exponentially with
dimension, while that of IG grows linearly with dimension. In two data sets
including binary variables we find that KS is superior to IG in insertion and
deletion tests, but only by a very small amount. Our comparison problems
include some binary inputs that pose a challenge to IG because it must use
values between the possible variable levels.
We show that IG will match KS when $f$ is an additive function plus a
multilinear function of the variables. This includes a multilinear
interpolation over the binary variables that would cause IG to have exponential
cost in a naive implementation.</p>
  </details>
</details>
<details>
  <summary>51. <b>标题：Active Programming by Example with a Natural Language Prior</b></summary>
  <p><b>编号</b>：[242]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12422</p>
  <p><b>作者</b>：Ruiqi Zhong,  Charlie Snell,  Dan Klein,  Jason Eisner</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：executable meaning representations, indirectly annotate natural, annotate natural language, introduce APEL, natural language utterances</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We introduce APEL, a new framework that enables non-programmers to indirectly
annotate natural language utterances with executable meaning representations,
such as SQL programs. Based on a natural language utterance, we first run a
seed semantic parser to generate a prior over a list of candidate programs. To
obtain information about which candidate is correct, we synthesize an input on
which the more likely programs tend to produce different outputs, and ask an
annotator which output is appropriate for the utterance. Hence, the annotator
does not have to directly inspect the programs. To further reduce effort
required from annotators, we aim to synthesize simple input databases that
nonetheless have high information gain. With human annotators and Bayesian
inference to handle annotation errors, we outperform Codex's top-1 performance
(59%) and achieve the same accuracy as the original expert annotators (75%), by
soliciting answers for each utterance on only 2 databases with an average of 9
records each. In contrast, it would be impractical to solicit outputs on the
original 30K-record databases provided by SPIDER</p>
  </details>
</details>
<details>
  <summary>52. <b>标题：Tiered Reinforcement Learning: Pessimism in the Face of Uncertainty and  Constant Regret</b></summary>
  <p><b>编号</b>：[245]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12418</p>
  <p><b>作者</b>：Jiawei Huang,  Li Zhao,  Tao Qin,  Wei Chen,  Nan Jiang,  Tie-Yan Liu</p>
  <p><b>备注</b>：38 pages</p>
  <p><b>关键词</b>：real-world user-interaction applications, text, risk-averse users, user-interaction applications, treated separately</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose a new learning framework that captures the tiered structure of
many real-world user-interaction applications, where the users can be divided
into two groups based on their different tolerance on exploration risks and
should be treated separately. In this setting, we simultaneously maintain two
policies $\pi^{\text{O}}$ and $\pi^{\text{E}}$: $\pi^{\text{O}}$ ("O" for
"online") interacts with more risk-tolerant users from the first tier and
minimizes regret by balancing exploration and exploitation as usual, while
$\pi^{\text{E}}$ ("E" for "exploit") exclusively focuses on exploitation for
risk-averse users from the second tier utilizing the data collected so far. An
important question is whether such a separation yields advantages over the
standard online setting (i.e., $\pi^{\text{E}}=\pi^{\text{O}}$) for the
risk-averse users. We individually consider the gap-independent
vs.~gap-dependent settings. For the former, we prove that the separation is
indeed not beneficial from a minimax perspective. For the latter, we show that
if choosing Pessimistic Value Iteration as the exploitation algorithm to
produce $\pi^{\text{E}}$, we can achieve a constant regret for risk-averse
users independent of the number of episodes $K$, which is in sharp contrast to
the $\Omega(\log K)$ regret for any online RL algorithms in the same setting,
while the regret of $\pi^{\text{O}}$ (almost) maintains its online regret
optimality and does not need to compromise for the success of $\pi^{\text{E}}$.</p>
  </details>
</details>
<details>
  <summary>53. <b>标题：AdaMix: Mixture-of-Adapter for Parameter-efficient Tuning of Large  Language Models</b></summary>
  <p><b>编号</b>：[249]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12410</p>
  <p><b>作者</b>：Yaqing Wang,  Subhabrata Mukherjee,  Xiaodong Liu,  Jing Gao,  Ahmed Hassan Awadallah,  Jianfeng Gao</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：require updating hundreds, downstream tasks require, tasks require updating, adapter, require updating</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Fine-tuning large-scale pre-trained language models to downstream tasks
require updating hundreds of millions of parameters. This not only increases
the serving cost to store a large copy of the model weights for every task, but
also exhibits instability during few-shot task adaptation. Parameter-efficient
techniques have been developed that tune small trainable components (e.g.,
adapters) injected in the large model while keeping most of the model weights
frozen. The prevalent mechanism to increase adapter capacity is to increase the
bottleneck dimension which increases the adapter parameters. In this work, we
introduce a new mechanism to improve adapter capacity without increasing
parameters or computational cost by two key techniques. (i) We introduce
multiple shared adapter components in each layer of the Transformer
architecture. We leverage sparse learning via random routing to update the
adapter parameters (encoder is kept frozen) resulting in the same amount of
computational cost (FLOPs) as that of training a single adapter. (ii) We
propose a simple merging mechanism to average the weights of multiple adapter
components to collapse to a single adapter in each Transformer layer, thereby,
keeping the overall parameters also the same but with significant performance
improvement. We demonstrate these techniques to work well across multiple task
settings including fully supervised and few-shot Natural Language Understanding
tasks. By only tuning 0.23% of a pre-trained language model's parameters, our
model outperforms the full model fine-tuning performance and several competing
methods.</p>
  </details>
</details>
<details>
  <summary>54. <b>标题：Multi-Head Online Learning for Delayed Feedback Modeling</b></summary>
  <p><b>编号</b>：[252]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12406</p>
  <p><b>作者</b>：Hui Gao,  Yihan Yang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：highly important, important to predict, predict the probability, day, online advertising</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In online advertising, it is highly important to predict the probability and
the value of a conversion (e.g., a purchase). It not only impacts user
experience by showing relevant ads, but also affects ROI of advertisers and
revenue of marketplaces. Unlike clicks, which often occur within minutes after
impressions, conversions are expected to happen over a long period of time
(e.g., 30 days for online shopping). It creates a challenge, as the true labels
are only available after the long delays. Either inaccurate labels (partial
conversions) are used, or models are trained on stale data (e.g., from 30 days
ago). The problem is more eminent in online learning, which focuses on the live
performance on the latest data. In this paper, a novel solution is presented to
address this challenge using multi-head modeling. Unlike traditional methods,
it directly quantizes conversions into multiple windows, such as day 1, day 2,
day 3-7, and day 8-30. A sub-model is trained specifically on conversions
within each window. Label freshness is maximally preserved in early models
(e.g., day 1 and day 2), while late conversions are accurately utilized in
models with longer delays (e.g., day 8-30). It is shown to greatly exceed the
performance of known methods in online learning experiments for both conversion
rate (CVR) and value per click (VPC) predictions. Lastly, as a general method
for delayed feedback modeling, it can be combined with any advanced ML
techniques to further improve the performance.</p>
  </details>
</details>
<details>
  <summary>55. <b>标题：Reward Uncertainty for Exploration in Preference-based Reinforcement  Learning</b></summary>
  <p><b>编号</b>：[256]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12401</p>
  <p><b>作者</b>：Xinran Liang,  Katherine Shu,  Kimin Lee,  Pieter Abbeel</p>
  <p><b>备注</b>：ICLR 2022. Last two authors advised equally</p>
  <p><b>关键词</b>：meticulous reward engineering, Conveying complex objectives, requires meticulous reward, reinforcement learning, agents often requires</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Conveying complex objectives to reinforcement learning (RL) agents often
requires meticulous reward engineering. Preference-based RL methods are able to
learn a more flexible reward model based on human preferences by actively
incorporating human feedback, i.e. teacher's preferences between two clips of
behaviors. However, poor feedback-efficiency still remains a problem in current
preference-based RL algorithms, as tailored human feedback is very expensive.
To handle this issue, previous methods have mainly focused on improving query
selection and policy initialization. At the same time, recent exploration
methods have proven to be a recipe for improving sample-efficiency in RL. We
present an exploration method specifically for preference-based RL algorithms.
Our main idea is to design an intrinsic reward by measuring the novelty based
on learned reward. Specifically, we utilize disagreement across ensemble of
learned reward models. Our intuition is that disagreement in learned reward
model reflects uncertainty in tailored human feedback and could be useful for
exploration. Our experiments show that exploration bonus from uncertainty in
learned reward improves both feedback- and sample-efficiency of
preference-based RL algorithms on complex robot manipulation tasks from
MetaWorld benchmarks, compared with other existing exploration methods that
measure the novelty of state visitation.</p>
  </details>
</details>
<details>
  <summary>56. <b>标题：Emergent Communication through Metropolis-Hastings Naming Game with Deep  Generative Models</b></summary>
  <p><b>编号</b>：[262]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12392</p>
  <p><b>作者</b>：Tadahiro Taniguchi,  Yuto Yoshida,  Akira Taniguchi,  Yoshinobu Hagiwara</p>
  <p><b>备注</b>：17 pages, 12 figures</p>
  <p><b>关键词</b>：explain human language, human language evolution, investigate computational models, seeks to investigate, investigate computational</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Emergent communication, also known as symbol emergence, seeks to investigate
computational models that can better explain human language evolution and the
creation of symbol systems. This study aims to provide a new model for emergent
communication, which is based on a probabilistic generative model. We define
the Metropolis-Hastings (MH) naming game by generalizing a model proposed by
Hagiwara et al. \cite{hagiwara2019symbol}. The MH naming game is a sort of MH
algorithm for an integrative probabilistic generative model that combines two
agents playing the naming game. From this viewpoint, symbol emergence is
regarded as decentralized Bayesian inference, and semiotic communication is
regarded as inter-personal cross-modal inference. We also offer Inter-GMM+VAE,
a deep generative model for simulating emergent communication, in which two
agents create internal representations and categories and share signs (i.e.,
names of objects) from raw visual images observed from different viewpoints.
The model has been validated on MNIST and Fruits 360 datasets. Experiment
findings show that categories are formed from real images observed by agents,
and signs are correctly shared across agents by successfully utilizing both of
the agents' views via the MH naming game. Furthermore, it has been verified
that the visual images were recalled from the signs uttered by the agents.
Notably, emergent communication without supervision and reward feedback
improved the performance of unsupervised representation learning.</p>
  </details>
</details>
<details>
  <summary>57. <b>标题：Toward Understanding Bias Correlations for Mitigation in NLP</b></summary>
  <p><b>编号</b>：[263]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12391</p>
  <p><b>作者</b>：Lu Cheng,  Suyu Ge,  Huan Liu</p>
  <p><b>备注</b>：11 pages, 5 figures</p>
  <p><b>关键词</b>：Natural Language Processing, Language Processing, Natural Language, found discriminative, Processing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Natural Language Processing (NLP) models have been found discriminative
against groups of different social identities such as gender and race. With the
negative consequences of these undesired biases, researchers have responded
with unprecedented effort and proposed promising approaches for bias
mitigation. In spite of considerable practical importance, current algorithmic
fairness literature lacks an in-depth understanding of the relations between
different forms of biases. Social bias is complex by nature. Numerous studies
in social psychology identify the "generalized prejudice", i.e., generalized
devaluing sentiments across different groups. For example, people who devalue
ethnic minorities are also likely to devalue women and gays. Therefore, this
work aims to provide a first systematic study toward understanding bias
correlations in mitigation. In particular, we examine bias mitigation in two
common NLP tasks -- toxicity detection and word embeddings -- on three social
identities, i.e., race, gender, and religion. Our findings suggest that biases
are correlated and present scenarios in which independent debiasing approaches
dominant in current literature may be insufficient. We further investigate
whether jointly mitigating correlated biases is more desired than independent
and individual debiasing. Lastly, we shed light on the inherent issue of
debiasing-accuracy trade-off in bias mitigation. This study serves to motivate
future research on joint bias mitigation that accounts for correlated biases.</p>
  </details>
</details>
<details>
  <summary>58. <b>标题：Toxicity Detection with Generative Prompt-based Inference</b></summary>
  <p><b>编号</b>：[264]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12390</p>
  <p><b>作者</b>：Yau-Shian Wang,  Yingshan Chang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：detecting undesirable content, nuanced difficulty, interpretations perceived, detecting undesirable, undesirable content</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Due to the subtleness, implicity, and different possible interpretations
perceived by different people, detecting undesirable content from text is a
nuanced difficulty. It is a long-known risk that language models (LMs), once
trained on corpus containing undesirable content, have the power to manifest
biases and toxicity. However, recent studies imply that, as a remedy, LMs are
also capable of identifying toxic content without additional fine-tuning.
Prompt-methods have been shown to effectively harvest this surprising
self-diagnosing capability. However, existing prompt-based methods usually
specify an instruction to a language model in a discriminative way. In this
work, we explore the generative variant of zero-shot prompt-based toxicity
detection with comprehensive trials on prompt engineering. We evaluate on three
datasets with toxicity labels annotated on social media posts. Our analysis
highlights the strengths of our generative classification approach both
quantitatively and qualitatively. Interesting aspects of self-diagnosis and its
ethical implications are discussed.</p>
  </details>
</details>
<details>
  <summary>59. <b>标题：Women, artificial intelligence, and key positions in collaboration  networks: Towards a more equal scientific ecosystem</b></summary>
  <p><b>编号</b>：[284]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12339</p>
  <p><b>作者</b>：Anahita Hajibabaei,  Andrea Schiffauerova,  Ashkan Ebadi</p>
  <p><b>备注</b>：20 pages, 6 figures</p>
  <p><b>关键词</b>：sharing knowledge, pooled resources, Scientific collaboration, artificial intelligence, Scientific</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Scientific collaboration in almost every discipline is mainly driven by the
need of sharing knowledge, expertise, and pooled resources. Science is becoming
more complex which has encouraged scientists to involve more in collaborative
research projects in order to better address the challenges. As a highly
interdisciplinary field with a rapidly evolving scientific landscape,
artificial intelligence calls for researchers with special profiles covering a
diverse set of skills and expertise. Understanding gender aspects of scientific
collaboration is of paramount importance, especially in a field such as
artificial intelligence that has been attracting large investments. Using
social network analysis, natural language processing, and machine learning and
focusing on artificial intelligence publications for the period from 2000 to
2019, in this work, we comprehensively investigated the effects of several
driving factors on acquiring key positions in scientific collaboration networks
through a gender lens. It was found that, regardless of gender, scientific
performance in terms of quantity and impact plays a crucial in possessing the
"social researcher" in the network. However, subtle differences were observed
between female and male researchers in acquiring the "local influencer" role.</p>
  </details>
</details>
<details>
  <summary>60. <b>标题：Multilevel sentiment analysis in arabic</b></summary>
  <p><b>编号</b>：[288]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12328</p>
  <p><b>作者</b>：Ahmed Nassar,  Ebru Sezer</p>
  <p><b>备注</b>：10 pages, 3 figures, Published in: 2019 IEEE 7th Palestinian International Conference on Electrical and Computer Engineering (PICECE), Date of Conference: 26-27 March 2019</p>
  <p><b>关键词</b>：Arabic sentiment analysis, aimed to improve, improve the performance, sentiment analysis, level sentiment analysis</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this study, we aimed to improve the performance results of Arabic
sentiment analysis. This can be achieved by investigating the most successful
machine learning method and the most useful feature vector to classify
sentiments in both term and document levels into two (positive or negative)
categories. Moreover, specification of one polarity degree for the term that
has more than one is investigated. Also to handle the negations and
intensifications, some rules are developed. According to the obtained results,
Artificial Neural Network classifier is nominated as the best classifier in
both term and document level sentiment analysis (SA) for Arabic Language.
Furthermore, the average F-score achieved in the term level SA for both
positive and negative testing classes is 0.92. In the document level SA, the
average F-score for positive testing classes is 0.94, while for negative
classes is 0.93.</p>
  </details>
</details>
<details>
  <summary>61. <b>标题：ColdGuess: A General and Effective Relational Graph Convolutional  Network to Tackle Cold Start Cases</b></summary>
  <p><b>编号</b>：[292]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12318</p>
  <p><b>作者</b>：Bo He,  Xiang Song,  Vincent Gao,  Christos Faloutsos</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：erode customer trust, online retail websites, retail websites threatens, sub-optimal buying experience, websites threatens e-commerce</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Low-quality listings and bad actor behavior in online retail websites
threatens e-commerce business as these result in sub-optimal buying experience
and erode customer trust. When a new listing is created, how to tell it has
good-quality? Is the method effective, fast, and scalable? Previous approaches
often have three limitations/challenges: (1) unable to handle cold start
problems where new sellers/listings lack sufficient selling histories. (2)
inability of scoring hundreds of millions of listings at scale, or compromise
performance for scalability. (3) has space challenges from large-scale graph
with giant e-commerce business size. To overcome these limitations/challenges,
we proposed ColdGuess, an inductive graph-based risk predictor built upon a
heterogeneous seller product graph, which effectively identifies risky
seller/product/listings at scale. ColdGuess tackles the large-scale graph by
consolidated nodes, and addresses the cold start problems using homogeneous
influence1. The evaluation on real data demonstrates that ColdGuess has stable
performance as the number of unknown features increases. It outperforms the
lightgbm2 by up to 34 pcp ROC-AUC in a cold start case when a new seller sells
a new product . The resulting system, ColdGuess, is effective, adaptable to
changing risky seller behavior, and is already in production</p>
  </details>
</details>
<details>
  <summary>62. <b>标题：FreDo: Frequency Domain-based Long-Term Time Series Forecasting</b></summary>
  <p><b>编号</b>：[298]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12301</p>
  <p><b>作者</b>：Fan-Keng Sun,  Duane S. Boning</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：energy consumption, limited to climatology, ability to forecast, highly beneficial, model</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The ability to forecast far into the future is highly beneficial to many
applications, including but not limited to climatology, energy consumption, and
logistics. However, due to noise or measurement error, it is questionable how
far into the future one can reasonably predict. In this paper, we first
mathematically show that due to error accumulation, sophisticated models might
not outperform baseline models for long-term forecasting. To demonstrate, we
show that a non-parametric baseline model based on periodicity can actually
achieve comparable performance to a state-of-the-art Transformer-based model on
various datasets. We further propose FreDo, a frequency domain-based neural
network model that is built on top of the baseline model to enhance its
performance and which greatly outperforms the state-of-the-art model. Finally,
we validate that the frequency domain is indeed better by comparing univariate
models trained in the frequency v.s. time domain.</p>
  </details>
</details>
<details>
  <summary>63. <b>标题：lpSpikeCon: Enabling Low-Precision Spiking Neural Network Processing for  Efficient Unsupervised Continual Learning on Autonomous Agents</b></summary>
  <p><b>编号</b>：[299]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12295</p>
  <p><b>作者</b>：Rachmad Vidya Wicaksana Putra,  Muhammad Shafique</p>
  <p><b>备注</b>：To appear at the 2022 International Joint Conference on Neural Networks (IJCNN), the 2022 IEEE World Congress on Computational Intelligence (WCCI), July 2022, Padova, Italy</p>
  <p><b>关键词</b>：unsupervised continual learning, bio-plausible learning rule, efficiently perform unsupervised, unsupervised continual, continual learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent advances have shown that SNN-based systems can efficiently perform
unsupervised continual learning due to their bio-plausible learning rule, e.g.,
Spike-Timing-Dependent Plasticity (STDP). Such learning capabilities are
especially beneficial for use cases like autonomous agents (e.g., robots and
UAVs) that need to continuously adapt to dynamically changing
scenarios/environments, where new data gathered directly from the environment
may have novel features that should be learned online. Current state-of-the-art
works employ high-precision weights (i.e., 32 bit) for both training and
inference phases, which pose high memory and energy costs thereby hindering
efficient embedded implementations of such systems for battery-driven mobile
autonomous systems. On the other hand, precision reduction may jeopardize the
quality of unsupervised continual learning due to information loss. Towards
this, we propose lpSpikeCon, a novel methodology to enable low-precision SNN
processing for efficient unsupervised continual learning on
resource-constrained autonomous agents/systems. Our lpSpikeCon methodology
employs the following key steps: (1) analyzing the impacts of training the SNN
model under unsupervised continual learning settings with reduced weight
precision on the inference accuracy; (2) leveraging this study to identify SNN
parameters that have a significant impact on the inference accuracy; and (3)
developing an algorithm for searching the respective SNN parameter values that
improve the quality of unsupervised continual learning. The experimental
results show that our lpSpikeCon can reduce weight memory of the SNN model by
8x (i.e., by judiciously employing 4-bit weights) for performing online
training with unsupervised continual learning and achieve no accuracy loss in
the inference phase, as compared to the baseline model with 32-bit weights
across different network sizes.</p>
  </details>
</details>
<details>
  <summary>64. <b>标题：RADNet: Ensemble Model for Robust Glaucoma Classification in Color  Fundus Images</b></summary>
  <p><b>编号</b>：[316]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12902</p>
  <p><b>作者</b>：Dmitrii Medvedev,  Rand Muhtaseb,  Ahmed Al Mahrooqi</p>
  <p><b>备注</b>：Keywords: Glaucoma Classification, Color Fundus Images. Computer Aided Diagnosis</p>
  <p><b>关键词</b>：severe eye diseases, characterized by rapid, irreversible blindness, severe eye, rapid progression</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Glaucoma is one of the most severe eye diseases, characterized by rapid
progression and leading to irreversible blindness. It is often the case that
pathology diagnostics is carried out when the one's sight has already
significantly degraded due to the lack of noticeable symptoms at early stage of
the disease. Regular glaucoma screenings of the population shall improve
early-stage detection, however the desirable frequency of etymological checkups
is often not feasible due to excessive load imposed by manual diagnostics on
limited number of specialists. Considering the basic methodology to detect
glaucoma is to analyze fundus images for the \textit{optic-disc-to-optic-cup
ratio}, Machine Learning domain can offer sophisticated tooling for image
processing and classification. In our work, we propose an advanced image
pre-processing technique combined with an ensemble of deep classification
networks. Our \textit{Retinal Auto Detection (RADNet)} model has been
successfully tested on Rotterdam EyePACS AIROGS train dataset with AUC of 0.92,
and then additionally finetuned and tested on a fraction of RIM-ONE DL dataset
with AUC of 0.91.</p>
  </details>
</details>
<details>
  <summary>65. <b>标题：Lyapunov function approach for approximation algorithm design and  analysis: with applications in submodular maximization</b></summary>
  <p><b>编号</b>：[343]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2205.12442</p>
  <p><b>作者</b>：Donglei Du</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：two-phase systematical framework, Lyapunov function, propose a two-phase, two-phase systematical, Lyapunov</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose a two-phase systematical framework for approximation algorithm
design and analysis via Lyapunov function. The first phase consists of using
Lyapunov function as a guideline to design a continuous-time algorithm with
provable approximation ratio. The second phase then converts the
continuous-time algorithm to a discrete-time algorithm with the same
approximation ratio and a provable time complexity. Some immediate benefits of
the Lyapunov function approach include: (i) unifying many existing algorithms;
(ii) providing a guideline to design and analyze new algorithms; and (iii)
offer new perspectives to potentially improve existing algorithms. We use
various submodular maximization problems as running examples to illustrate our
framework.</p>
  </details>
</details>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">徐耀彬</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://louishsu.xyz/2022/05/26/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html">http://louishsu.xyz/2022/05/26/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://louishsu.xyz" target="_blank">LOUIS' BLOG</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"></div><div class="post_share"><div class="social-share" data-image="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="next-post pull-full"><a href="/2021/10/22/%E4%B8%AD%E5%9B%BD%E6%B3%95%E5%BE%8B%E6%99%BA%E8%83%BD%E6%8A%80%E6%9C%AF%E8%AF%84%E6%B5%8B(CAIL2021)%EF%BC%9A%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96(Rank2).html"><img class="next-cover" src="http://cail.cipsc.org.cn/img/index_mainpic.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">中国法律智能技术评测(CAIL2021)：信息抽取(Rank2)</div></div></a></div></nav><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="twikoo-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="card-info-avatar is-center"><img class="avatar-img" src="/img/touxiang.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/><div class="author-info__name">徐耀彬</div><div class="author-info__description">做知识的原创者！</div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">11</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">标签</div><div class="length-num">3</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">分类</div><div class="length-num">7</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/isLouisHsu"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/isLouisHsu" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:is.louishsu@foxmail.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>公告</span></div><div class="announcement_content">记录和分享一些学习和开源内容，若有问题可通过邮箱is.louishsu@foxmail.com联系，欢迎交流！！</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">1.</span> <span class="toc-text">统计</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">2.</span> <span class="toc-text">计算机视觉</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">3.</span> <span class="toc-text">自然语言处理</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">4.</span> <span class="toc-text">机器学习</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">5.</span> <span class="toc-text">人工智能</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2022/05/26/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html" title="Arxiv每日速递(2022-05-26)"><img src="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Arxiv每日速递(2022-05-26)"/></a><div class="content"><a class="title" href="/2022/05/26/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html" title="Arxiv每日速递(2022-05-26)">Arxiv每日速递(2022-05-26)</a><time datetime="2022-05-26T00:44:07.818Z" title="发表于 2022-05-26 08:44:07">2022-05-26</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/10/22/%E4%B8%AD%E5%9B%BD%E6%B3%95%E5%BE%8B%E6%99%BA%E8%83%BD%E6%8A%80%E6%9C%AF%E8%AF%84%E6%B5%8B(CAIL2021)%EF%BC%9A%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96(Rank2).html" title="中国法律智能技术评测(CAIL2021)：信息抽取(Rank2)"><img src="http://cail.cipsc.org.cn/img/index_mainpic.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="中国法律智能技术评测(CAIL2021)：信息抽取(Rank2)"/></a><div class="content"><a class="title" href="/2021/10/22/%E4%B8%AD%E5%9B%BD%E6%B3%95%E5%BE%8B%E6%99%BA%E8%83%BD%E6%8A%80%E6%9C%AF%E8%AF%84%E6%B5%8B(CAIL2021)%EF%BC%9A%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96(Rank2).html" title="中国法律智能技术评测(CAIL2021)：信息抽取(Rank2)">中国法律智能技术评测(CAIL2021)：信息抽取(Rank2)</a><time datetime="2021-10-22T14:29:06.000Z" title="发表于 2021-10-22 22:29:06">2021-10-22</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/05/19/%E5%85%A8%E7%90%83%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%8A%80%E6%9C%AF%E5%88%9B%E6%96%B0%E5%A4%A7%E8%B5%9B%E3%80%90%E8%B5%9B%E9%81%93%E4%B8%80%E3%80%91%EF%BC%9A%E5%8C%BB%E5%AD%A6%E5%BD%B1%E5%83%8F%E6%8A%A5%E5%91%8A%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B.html" title="全球人工智能技术创新大赛【赛道一】：医学影像报告异常检测"><img src="https://tianchi-public.oss-cn-hangzhou.aliyuncs.com/public/files/forum/161037709574435991610377095138.jpeg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="全球人工智能技术创新大赛【赛道一】：医学影像报告异常检测"/></a><div class="content"><a class="title" href="/2021/05/19/%E5%85%A8%E7%90%83%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%8A%80%E6%9C%AF%E5%88%9B%E6%96%B0%E5%A4%A7%E8%B5%9B%E3%80%90%E8%B5%9B%E9%81%93%E4%B8%80%E3%80%91%EF%BC%9A%E5%8C%BB%E5%AD%A6%E5%BD%B1%E5%83%8F%E6%8A%A5%E5%91%8A%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B.html" title="全球人工智能技术创新大赛【赛道一】：医学影像报告异常检测">全球人工智能技术创新大赛【赛道一】：医学影像报告异常检测</a><time datetime="2021-05-19T09:57:06.000Z" title="发表于 2021-05-19 17:57:06">2021-05-19</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2020/09/16/%E8%AF%A6%E8%A7%A3%E5%91%BD%E5%90%8D%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB%E6%A8%A1%E5%9E%8B%EF%BC%9ALSTM-CRF.html" title="详解命名实体识别模型：LSTM-CRF"><img src="https://gimg2.baidu.com/image_search/src=http%3A%2F%2Fpic1.zhimg.com%2Fv2-1ed6a10dbb239a148e42df088c5870a6_1440w.jpg%3Fsource%3D172ae18b&amp;refer=http%3A%2F%2Fpic1.zhimg.com&amp;app=2002&amp;size=f9999,10000&amp;q=a80&amp;n=0&amp;g=0n&amp;fmt=jpeg?sec=1638183974&amp;t=4632f13fd487ed1cfcb12d67a6b71e52" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="详解命名实体识别模型：LSTM-CRF"/></a><div class="content"><a class="title" href="/2020/09/16/%E8%AF%A6%E8%A7%A3%E5%91%BD%E5%90%8D%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB%E6%A8%A1%E5%9E%8B%EF%BC%9ALSTM-CRF.html" title="详解命名实体识别模型：LSTM-CRF">详解命名实体识别模型：LSTM-CRF</a><time datetime="2020-09-16T09:26:44.000Z" title="发表于 2020-09-16 17:26:44">2020-09-16</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2020/06/14/%E8%AE%B0%E4%B8%80%E6%AC%A1MySQL%E8%A7%A3%E5%86%B3%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E6%97%B6%E7%9A%84%E5%88%86%E8%A1%A8%E9%97%AE%E9%A2%98.html" title="记一次MySQL解决大数据存储时的分表问题"><img src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="记一次MySQL解决大数据存储时的分表问题"/></a><div class="content"><a class="title" href="/2020/06/14/%E8%AE%B0%E4%B8%80%E6%AC%A1MySQL%E8%A7%A3%E5%86%B3%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E6%97%B6%E7%9A%84%E5%88%86%E8%A1%A8%E9%97%AE%E9%A2%98.html" title="记一次MySQL解决大数据存储时的分表问题">记一次MySQL解决大数据存储时的分表问题</a><time datetime="2020-06-14T15:24:27.000Z" title="发表于 2020-06-14 23:24:27">2020-06-14</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2022 By 徐耀彬</div><div class="footer_custom_text"><p><a style="margin-inline:5px"target="_blank"href="https://hexo.io/"><img src="https://img.shields.io/badge/Frame-Hexo-blue?style=flat&logo=hexo"title="博客框架为Hexo"alt="img"></a><a style="margin-inline:5px"target="_blank"href="https://butterfly.js.org/"><img src="https://img.shields.io/badge/Theme-Butterfly-6513df?style=flat&logo=bitdefender"title="主题采用butterfly"alt="img"></a><a style="margin-inline:5px"target="_blank"href="https://www.jsdelivr.com/"><img src="https://img.shields.io/badge/CDN-jsDelivr-orange?style=flat&logo=jsDelivr"title="本站使用JsDelivr为静态资源提供CDN加速"alt="img"></a><a style="margin-inline:5px"target="_blank"href="https://github.com/"><img src="https://img.shields.io/badge/Source-Github-d021d6?style=flat&logo=GitHub"title="本站项目由Gtihub托管"alt="img"></a><a style="margin-inline:5px"target="_blank"href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img src="https://img.shields.io/badge/Copyright-BY--NC--SA%204.0-d42328?style=flat&logo=Claris"alt="img"title="本站采用知识共享署名-非商业性使用-相同方式共享4.0国际许可协议进行许可"></a></br></p></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="font-plus" type="button" title="放大字体"><i class="fas fa-plus"></i></button><button id="font-minus" type="button" title="缩小字体"><i class="fas fa-minus"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div></div><hr/><div id="local-search-results"></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.css"><script>(() => {
  document.querySelectorAll('#article-container span.katex-display').forEach(item => {
    btf.wrap(item, 'div', '', 'katex-wrap')
  })
})()</script><script>(()=>{
  const $countDom = document.getElementById('twikoo-count')
  const init = () => {
    let initData = {
      el: '#twikoo-wrap',
      envId: 'blog-',
      region: ''
    }

    if (false) {
      const otherData = false
      initData = Object.assign(initData, otherData)
    }
    
    twikoo.init(initData)
  }

  const getCount = () => {
    twikoo.getCommentsCount({
      envId: 'blog-',
      region: '',
      urls: [window.location.pathname],
      includeReply: false
    }).then(function (res) {
      $countDom.innerText = res[0].count
    }).catch(function (err) {
      console.error(err);
    });
  }

  const loadTwikoo = (bool = false) => {
    if (typeof twikoo === 'object') {
      init()
      bool && $countDom && setTimeout(getCount,0)
    } else {
      getScript('https://cdn.jsdelivr.net/npm/twikoo/dist/twikoo.all.min.js').then(()=> {
        init()
        bool && $countDom && setTimeout(getCount,0)
      })
    }
  }

  if ('Twikoo' === 'Twikoo' || !false) {
    if (false) btf.loadComment(document.getElementById('twikoo-wrap'), loadTwikoo)
    else loadTwikoo(true)
  } else {
    window.loadOtherComment = () => {
      loadTwikoo()
    }
  }
})()</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><!-- hexo injector body_end start --> <script data-pjax>if(document.getElementById('recent-posts') && (location.pathname ==='/'|| '/' ==='all')){
    var parent = document.getElementById('recent-posts');
    var child = '<div class="recent-post-item" style="width:100%;height: auto"><div id="catalog_magnet"><div class="magnet_item"><a class="magnet_link" href="http://louishsu.xyz/categories/机器学习/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🐱 机器学习 (1)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://louishsu.xyz/categories/自然语言处理/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">📚 自然语言处理 (1)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://louishsu.xyz/categories/竞赛相关/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🎮 竞赛相关 (2)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://louishsu.xyz/categories/阅读笔记/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🎮 阅读笔记 (1)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><a class="magnet_link_more"  href="http://louishsu.xyz/categories" style="flex:1;text-align: center;margin-bottom: 10px;">查看更多...</a></div></div>';
    console.log('已挂载magnet')
    parent.insertAdjacentHTML("afterbegin",child)}
     </script><style>#catalog_magnet{flex-wrap: wrap;display: flex;width:100%;justify-content:space-between;padding: 10px 10px 0 10px;align-content: flex-start;}.magnet_item{flex-basis: calc(50% - 5px);background: #f2f2f2;margin-bottom: 10px;border-radius: 8px;transition: all 0.2s ease-in-out;}.magnet_item:hover{background: #b30070}.magnet_link_more{color:#555}.magnet_link{color:black}.magnet_link:hover{color:white}@media screen and (max-width: 600px) {.magnet_item {flex-basis: 100%;}}.magnet_link_context{display:flex;padding: 10px;font-size:16px;transition: all 0.2s ease-in-out;}.magnet_link_context:hover{padding: 10px 20px;}</style>
    <style></style>
  <script data-pjax src="https://cdn.jsdelivr.net/gh/Zfour/hexo-github-calendar@1.21/hexo_githubcalendar.js"></script>
  <script data-pjax>
        function GithubCalendarConfig(){
            var git_githubapiurl ="https://python-github-calendar-api.vercel.app/api?isLouisHsu";
            var git_color =['#ebedf0', '#fdcdec', '#fc9bd9', '#fa6ac5', '#f838b2', '#f5089f', '#c4067e', '#92055e', '#540336', '#48022f', '#30021f'];
            var git_user ="isLouisHsu";
            var parent_div_git = document.getElementById('recent-posts');
            var git_div_html = '<div class="recent-post-item" style="width:100%;height:auto;padding:10px;"><div id="github_loading" style="width:10%;height:100%;margin:0 auto;display: block"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"  viewBox="0 0 50 50" style="enable-background:new 0 0 50 50" xml:space="preserve"><path fill="#d0d0d0" d="M25.251,6.461c-10.318,0-18.683,8.365-18.683,18.683h4.068c0-8.071,6.543-14.615,14.615-14.615V6.461z" transform="rotate(275.098 25 25)"><animateTransform attributeType="xml" attributeName="transform" type="rotate" from="0 25 25" to="360 25 25" dur="0.6s" repeatCount="indefinite"></animateTransform></path></svg></div><div id="github_container"></div></div>';
            if(parent_div_git && location.pathname =='/'){
                console.log('已挂载github calendar')
                // parent_div_git.innerHTML=git_div_html+parent_div_git.innerHTML // 无报错，但不影响使用(支持pjax跳转)
                parent_div_git.insertAdjacentHTML("afterbegin",git_div_html) // 有报错，但不影响使用(支持pjax跳转)
            };
            GithubCalendar(git_githubapiurl,git_color,git_user)
        }
        if(document.getElementById('recent-posts')){
            GithubCalendarConfig()
        }
    </script>
    <style>#github_container{min-height:280px}@media screen and (max-width:650px) {#github_container{background-image:;min-height:0px}}</style>
    <style></style><script data-pjax>function electric_clock_injector_config(){
                var parent_div_git = document.getElementsByClassName('sticky_layout')[0];
                var item_html = '<div class="card-widget card-clock"><div class="card-glass"><div class="card-background"><div class="card-content"><div id="hexo_electric_clock"><img id="card-clock-loading" src="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-clock/clock/images/weather/loading.gif" style="height: 120px; width: 100%;" data-ll-status="loading" class="entered loading"></div></div></div></div></div>';
                console.log('已挂载electric_clock')
                // parent_div_git.innerHTML=item_html+parent_div_git.innerHTML // 无报错，但不影响使用(支持pjax跳转)
                parent_div_git.insertAdjacentHTML("afterbegin",item_html) // 有报错，但不影响使用(支持pjax跳转)
            }if( document.getElementsByClassName('sticky_layout')[0] && (location.pathname ==='all'|| 'all' ==='all')){

            electric_clock_injector_config()
        } </script><script src="https://pv.sohu.com/cityjson?ie=utf-8"></script><script data-pjax  src="https://cdn.jsdelivr.net/gh/Zfour/hexo-electric-clock@1.0.6/clock.js"></script><!-- hexo injector body_end end --><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"model":{"jsonPath":"/live2dw/assets/hijiki.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":false},"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body></html>