<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Arxiv每日速递(2022-06-16) | LOUIS' BLOG</title><meta name="author" content="徐耀彬"><meta name="copyright" content="徐耀彬"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="本篇博文主要展示每日从Arxiv论文网站获取的最新论文列表，以计算机视觉、自然语言处理、机器学习、人工智能等大方向进行划分。 统计 今日共更新348篇论文，其中：  79篇计算机视觉（cs.CV） 35篇自然语言处理（cs.CL） 145篇机器学习（cs.LG） 71篇人工智能（cs.AI）  计算机视觉    1. 标题：PlanarRecon: Real-time 3D Plane Detec">
<meta property="og:type" content="article">
<meta property="og:title" content="Arxiv每日速递(2022-06-16)">
<meta property="og:url" content="http://louishsu.xyz/2022/06/16/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html">
<meta property="og:site_name" content="LOUIS&#39; BLOG">
<meta property="og:description" content="本篇博文主要展示每日从Arxiv论文网站获取的最新论文列表，以计算机视觉、自然语言处理、机器学习、人工智能等大方向进行划分。 统计 今日共更新348篇论文，其中：  79篇计算机视觉（cs.CV） 35篇自然语言处理（cs.CL） 145篇机器学习（cs.LG） 71篇人工智能（cs.AI）  计算机视觉    1. 标题：PlanarRecon: Real-time 3D Plane Detec">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png">
<meta property="article:published_time" content="2022-06-16T00:43:54.705Z">
<meta property="article:modified_time" content="2022-06-16T00:46:03.335Z">
<meta property="article:author" content="徐耀彬">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://louishsu.xyz/2022/06/16/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2022-06-16 08:46:03'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const fontSizeVal = saveToLocal.get('global-font-size')
    if (fontSizeVal !== undefined) {
      document.documentElement.style.setProperty('--global-font-size', fontSizeVal + 'px')
    }
    })(window)</script><link rel="stylesheet" href="/css/background.css"><script src="https://cdn.jsdelivr.net/npm/echarts@4.7.0/dist/echarts.min.js"></script><!-- hexo injector head_end start --><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Zfour/hexo-electric-clock@1.0.6/clock.css"><!-- hexo injector head_end end --><meta name="generator" content="Hexo 5.4.2"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="author-avatar"><img class="avatar-img" src="/img/touxiang.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">11</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">标签</div><div class="length-num">3</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">分类</div><div class="length-num">7</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/message/"><i class="fa-fw far fa-comment-dots"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa-fw fa fa-book"></i><span> 找文章</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></li><li><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></li><li><a class="site-page" href="/charts/"><i class="fa-fw fa fa-archive"></i><span> 统计</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-tools"></i><span> 工具</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/md_editor/"><i class="fa-fw fas fa-pen"></i><span> 在线markdown</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/isLouisHsu/blog/tree/master/source/_posts"><i class="fa-fw fa fa-star"></i><span> 在线push</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">LOUIS' BLOG</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/message/"><i class="fa-fw far fa-comment-dots"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa-fw fa fa-book"></i><span> 找文章</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></li><li><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></li><li><a class="site-page" href="/charts/"><i class="fa-fw fa fa-archive"></i><span> 统计</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-tools"></i><span> 工具</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/md_editor/"><i class="fa-fw fas fa-pen"></i><span> 在线markdown</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/isLouisHsu/blog/tree/master/source/_posts"><i class="fa-fw fa fa-star"></i><span> 在线push</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Arxiv每日速递(2022-06-16)<a class="post-edit-link" href="https://github.com/isLouisHsu/blog/tree/master/source_posts/Arxiv每日速递.md" title="编辑" target="_blank"><i class="fas fa-pencil-square"></i></a></h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-06-16T00:43:54.705Z" title="发表于 2022-06-16 08:43:54">2022-06-16</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2022-06-16T00:46:03.335Z" title="更新于 2022-06-16 08:46:03">2022-06-16</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">阅读笔记</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">76.6k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>457分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span><span class="post-meta-separator">|</span><span class="post-meta-commentcount"><i class="far fa-comments fa-fw post-meta-icon"></i><span class="post-meta-label">评论数:</span><a href="/2022/06/16/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html#post-comment"><span id="twikoo-count"></span></a></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><p>本篇博文主要展示每日从Arxiv论文网站获取的最新论文列表，以计算机视觉、自然语言处理、机器学习、人工智能等大方向进行划分。</p>
<h1>统计</h1>
<p>今日共更新348篇论文，其中：</p>
<ul>
<li>79篇计算机视觉（<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>）</li>
<li>35篇自然语言处理（<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>）</li>
<li>145篇机器学习（cs.LG）</li>
<li>71篇人工智能（<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>）</li>
</ul>
<h1>计算机视觉</h1>
<details>
  <summary>1. <b>标题：PlanarRecon: Real-time 3D Plane Detection and Reconstruction from Posed  Monocular Videos</b></summary>
  <p><b>编号</b>：[2]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07710</p>
  <p><b>作者</b>：Yiming Xie,  Matheus Gadelha,  Fengting Yang,  Xiaowei Zhou,  Huaizu Jiang</p>
  <p><b>备注</b>：CVPR 2022. Project page: this https URL</p>
  <p><b>关键词</b>：posed monocular video, globally coherent detection, framework for globally, posed monocular, monocular video</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present PlanarRecon -- a novel framework for globally coherent detection
and reconstruction of 3D planes from a posed monocular video. Unlike previous
works that detect planes in 2D from a single image, PlanarRecon incrementally
detects planes in 3D for each video fragment, which consists of a set of key
frames, from a volumetric representation of the scene using neural networks. A
learning-based tracking and fusion module is designed to merge planes from
previous fragments to form a coherent global plane reconstruction. Such design
allows PlanarRecon to integrate observations from multiple views within each
fragment and temporal information across different ones, resulting in an
accurate and coherent reconstruction of the scene abstraction with
low-polygonal geometry. Experiments show that the proposed approach achieves
state-of-the-art performances on the ScanNet dataset while being real-time.</p>
  </details>
</details>
<details>
  <summary>2. <b>标题：Variable Bitrate Neural Fields</b></summary>
  <p><b>编号</b>：[4]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07707</p>
  <p><b>作者</b>：Towaki Takikawa,  Alex Evans,  Jonathan Tremblay,  Thomas Müller,  Morgan McGuire,  Alec Jacobson,  Sanja Fidler</p>
  <p><b>备注</b>：SIGGRAPH 2022. Project Page: this https URL</p>
  <p><b>关键词</b>：signed distance functions, vector fields, radiance fields, emerged as accurate, scalar and vector</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Neural approximations of scalar and vector fields, such as signed distance
functions and radiance fields, have emerged as accurate, high-quality
representations. State-of-the-art results are obtained by conditioning a neural
approximation with a lookup from trainable feature grids that take on part of
the learning task and allow for smaller, more efficient neural networks.
Unfortunately, these feature grids usually come at the cost of significantly
increased memory consumption compared to stand-alone neural network models. We
present a dictionary method for compressing such feature grids, reducing their
memory consumption by up to 100x and permitting a multiresolution
representation which can be useful for out-of-core streaming. We formulate the
dictionary optimization as a vector-quantized auto-decoder problem which lets
us learn end-to-end discrete neural representations in a space where no direct
supervision is available and with dynamic topology and structure. Our source
code will be available at this https URL.</p>
  </details>
</details>
<details>
  <summary>3. <b>标题：Masked Frequency Modeling for Self-Supervised Visual Pre-Training</b></summary>
  <p><b>编号</b>：[5]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07706</p>
  <p><b>作者</b>：Jiahao Xie,  Wei Li,  Xiaohang Zhan,  Ziwei Liu,  Yew Soon Ong,  Chen Change Loy</p>
  <p><b>备注</b>：Project page: this https URL</p>
  <p><b>关键词</b>：present Masked Frequency, Masked Frequency Modeling, self-supervised pre-training, pre-training of visual, Frequency</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present Masked Frequency Modeling (MFM), a unified frequency-domain-based
approach for self-supervised pre-training of visual models. Instead of randomly
inserting mask tokens to the input embeddings in the spatial domain, in this
paper, we shift the perspective to the frequency domain. Specifically, MFM
first masks out a portion of frequency components of the input image and then
predicts the missing frequencies on the frequency spectrum. Our key insight is
that predicting masked components in the frequency domain is more ideal to
reveal underlying image patterns rather than predicting masked patches in the
spatial domain, due to the heavy spatial redundancy. Our findings suggest that
with the right configuration of mask-and-predict strategy, both the structural
information within high-frequency components and the low-level statistics among
low-frequency counterparts are useful in learning good representations. For the
first time, MFM demonstrates that, for both ViT and CNN, a simple non-Siamese
framework can learn meaningful representations even using none of the
following: (i) extra data, (ii) extra model, (iii) mask token. Experimental
results on ImageNet and several robustness benchmarks show the competitive
performance and advanced robustness of MFM compared with recent masked image
modeling approaches. Furthermore, we also comprehensively investigate the
effectiveness of classical image restoration tasks for representation learning
from a unified frequency perspective and reveal their intriguing relations with
our MFM approach. Project page:
this https URL.</p>
  </details>
</details>
<details>
  <summary>4. <b>标题：LET-3D-AP: Longitudinal Error Tolerant 3D Average Precision for  Camera-Only 3D Detection</b></summary>
  <p><b>编号</b>：[6]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07705</p>
  <p><b>作者</b>：Wei-Chih Hung,  Henrik Kretzschmar,  Vincent Casser,  Jyh-Jing Hwang,  Dragomir Anguelov</p>
  <p><b>备注</b>：Find the primary metrics for the 2022 Waymo Open Dataset 3D Camera-Only Detection Challenge at this https URL . Find the code at this https URL</p>
  <p><b>关键词</b>：Average Precision, ground truth bounding, truth bounding boxes, intersection over union, ground truth</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The popular object detection metric 3D Average Precision (3D AP) relies on
the intersection over union between predicted bounding boxes and ground truth
bounding boxes. However, depth estimation based on cameras has limited
accuracy, which may cause otherwise reasonable predictions that suffer from
such longitudinal localization errors to be treated as false positives and
false negatives. We therefore propose variants of the popular 3D AP metric that
are designed to be more permissive with respect to depth estimation errors.
Specifically, our novel longitudinal error tolerant metrics, LET-3D-AP and
LET-3D-APL, allow longitudinal localization errors of the predicted bounding
boxes up to a given tolerance. The proposed metrics have been used in the Waymo
Open Dataset 3D Camera-Only Detection Challenge. We believe that they will
facilitate advances in the field of camera-only 3D detection by providing more
informative performance signals.</p>
  </details>
</details>
<details>
  <summary>5. <b>标题：Waymo Open Dataset: Panoramic Video Panoptic Segmentation</b></summary>
  <p><b>编号</b>：[7]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07704</p>
  <p><b>作者</b>：Jieru Mei,  Alex Zihao Zhu,  Xinchen Yan,  Hang Yan,  Siyuan Qiao,  Yukun Zhu,  Liang-Chieh Chen,  Henrik Kretzschmar,  Dragomir Anguelov</p>
  <p><b>备注</b>：Our dataset can be found at this https URL</p>
  <p><b>关键词</b>：object instance identifiers, Video Panoptic Segmentation, panoptic segmentation, Panoramic Video Panoptic, panoptic segmentation labels</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Panoptic image segmentation is the computer vision task of finding groups of
pixels in an image and assigning semantic classes and object instance
identifiers to them. Research in image segmentation has become increasingly
popular due to its critical applications in robotics and autonomous driving.
The research community thereby relies on publicly available benchmark dataset
to advance the state-of-the-art in computer vision. Due to the high costs of
densely labeling the images, however, there is a shortage of publicly available
ground truth labels that are suitable for panoptic segmentation. The high
labeling costs also make it challenging to extend existing datasets to the
video domain and to multi-camera setups. We therefore present the Waymo Open
Dataset: Panoramic Video Panoptic Segmentation Dataset, a large-scale dataset
that offers high-quality panoptic segmentation labels for autonomous driving.
We generate our dataset using the publicly available Waymo Open Dataset,
leveraging the diverse set of camera images. Our labels are consistent over
time for video processing and consistent across multiple cameras mounted on the
vehicles for full panoramic scene understanding. Specifically, we offer labels
for 28 semantic categories and 2,860 temporal sequences that were captured by
five cameras mounted on autonomous vehicles driving in three different
geographical locations, leading to a total of 100k labeled camera images. To
the best of our knowledge, this makes our dataset an order of magnitude larger
than existing datasets that offer video panoptic segmentation labels. We
further propose a new benchmark for Panoramic Video Panoptic Segmentation and
establish a number of strong baselines based on the DeepLab family of models.
We will make the benchmark and the code publicly available. Find the dataset at
this https URL.</p>
  </details>
</details>
<details>
  <summary>6. <b>标题：Masked Siamese ConvNets</b></summary>
  <p><b>编号</b>：[8]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07700</p>
  <p><b>作者</b>：Li Jing,  Jiachen Zhu,  Yann LeCun</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：shown superior performances, shown superior, superior performances, performances over supervised, Self-supervised learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Self-supervised learning has shown superior performances over supervised
methods on various vision benchmarks. The siamese network, which encourages
embeddings to be invariant to distortions, is one of the most successful
self-supervised visual representation learning approaches. Among all the
augmentation methods, masking is the most general and straightforward method
that has the potential to be applied to all kinds of input and requires the
least amount of domain knowledge. However, masked siamese networks require
particular inductive bias and practically only work well with Vision
Transformers. This work empirically studies the problems behind masked siamese
networks with ConvNets. We propose several empirical designs to overcome these
problems gradually. Our method performs competitively on low-shot image
classification and outperforms previous methods on object detection benchmarks.
We discuss several remaining issues and hope this work can provide useful data
points for future general-purpose self-supervised learning.</p>
  </details>
</details>
<details>
  <summary>7. <b>标题：Prefix Language Models are Unified Modal Learners</b></summary>
  <p><b>编号</b>：[9]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07699</p>
  <p><b>作者</b>：Shizhe Diao,  Wangchunshu Zhou,  Xinsong Zhang,  Jiawei Wang</p>
  <p><b>备注</b>：22 pages, 3 figures</p>
  <p><b>关键词</b>：pushed on multi-modal, generation, COCO image generation, pre-training, pre-training paradigm</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>With the success of vision-language pre-training, we have witnessed the
state-of-the-art has been pushed on multi-modal understanding and generation.
However, the current pre-training paradigm is either incapable of targeting all
modalities at once (e.g., text generation and image generation), or requires
multi-fold well-designed tasks which significantly limits the scalability. We
demonstrate that a unified modal model could be learned with a prefix language
modeling objective upon text and image sequences. Thanks to the simple but
powerful pre-training paradigm, our proposed model, DaVinci, is simple to
train, scalable to huge data, and adaptable to a variety of downstream tasks
across modalities (language / vision / vision+language), types (understanding /
generation) and settings (e.g., zero-shot, fine-tuning, linear evaluation) with
a single unified architecture. DaVinci achieves the competitive performance on
a wide range of 26 understanding / generation tasks, and outperforms previous
unified vision-language models on most tasks, including ImageNet classification
(+1.6%), VQAv2 (+1.4%), COCO caption generation (BLEU@4 +1.1%, CIDEr +1.5%) and
COCO image generation (IS +0.9%, FID -1.0%), at the comparable model and data
scale. Furthermore, we offer a well-defined benchmark for future research by
reporting the performance on different scales of the pre-training dataset on a
heterogeneous and wide distribution coverage. Our results establish new,
stronger baselines for future comparisons at different data scales and shed
light on the difficulties of comparing VLP models more generally.</p>
  </details>
</details>
<details>
  <summary>8. <b>标题：Neural Deformable Voxel Grid for Fast Optimization of Dynamic View  Synthesis</b></summary>
  <p><b>编号</b>：[10]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07698</p>
  <p><b>作者</b>：Xiang Guo,  Guanying Chen,  Yuchao Dai,  Xiaoqing Ye,  Jiadai Sun,  Xiao Tan,  Errui Ding</p>
  <p><b>备注</b>：Technical Report: 29 pages; project page: this https URL</p>
  <p><b>关键词</b>：Neural Radiance Fields, Neural Radiance, revolutionizing the task, radiance field method, NVS</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recently, Neural Radiance Fields (NeRF) is revolutionizing the task of novel
view synthesis (NVS) for its superior performance. However, NeRF and its
variants generally require a lengthy per-scene training procedure, where a
multi-layer perceptron (MLP) is fitted to the captured images. To remedy the
challenge, the voxel-grid representation has been proposed to significantly
speed up the training. However, these existing methods can only deal with
static scenes. How to develop an efficient and accurate dynamic view synthesis
method remains an open problem. Extending the methods for static scenes to
dynamic scenes is not straightforward as both the scene geometry and appearance
change over time. In this paper, built on top of the recent advances in
voxel-grid optimization, we propose a fast deformable radiance field method to
handle dynamic scenes. Our method consists of two modules. The first module
adopts a deformation grid to store 3D dynamic features, and a light-weight MLP
for decoding the deformation that maps a 3D point in observation space to the
canonical space using the interpolated features. The second module contains a
density and a color grid to model the geometry and density of the scene. The
occlusion is explicitly modeled to further improve the rendering quality.
Experimental results show that our method achieves comparable performance to
D-NeRF using only 20 minutes for training, which is more than 70x faster than
D-NeRF, clearly demonstrating the efficiency of our proposed method.</p>
  </details>
</details>
<details>
  <summary>9. <b>标题：Diffusion Models for Video Prediction and Infilling</b></summary>
  <p><b>编号</b>：[11]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07696</p>
  <p><b>作者</b>：Tobias Höppe,  Arash Mehrjou,  Stefan Bauer,  Didrik Nielsen,  Andrea Dittadi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：make intelligent decisions, anticipate future outcomes, intelligent decisions, predict and anticipate, anticipate future</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>To predict and anticipate future outcomes or reason about missing information
in a sequence is a key ability for agents to be able to make intelligent
decisions. This requires strong temporally coherent generative capabilities.
Diffusion models have shown huge success in several generative tasks lately,
but have not been extensively explored in the video domain. We present
Random-Mask Video Diffusion (RaMViD), which extends image diffusion models to
videos using 3D convolutions, and introduces a new conditioning technique
during training. By varying the mask we condition on, the model is able to
perform video prediction, infilling and upsampling. Since we do not use
concatenation to condition on a mask, as done in most conditionally trained
diffusion models, we are able to decrease the memory footprint. We evaluated
the model on two benchmark datasets for video prediction and one for video
generation on which we achieved competitive results. On Kinetics-600 we
achieved state-of-the-art for video prediction.</p>
  </details>
</details>
<details>
  <summary>10. <b>标题：VoxGRAF: Fast 3D-Aware Image Synthesis with Sparse Voxel Grids</b></summary>
  <p><b>编号</b>：[12]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07695</p>
  <p><b>作者</b>：Katja Schwarz,  Axel Sauer,  Michael Niemeyer,  Yiyi Liao,  Andreas Geiger</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：radiance fields, rely on coordinate-based, generative models rely, coordinate-based MLPs, results</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>State-of-the-art 3D-aware generative models rely on coordinate-based MLPs to
parameterize 3D radiance fields. While demonstrating impressive results,
querying an MLP for every sample along each ray leads to slow rendering.
Therefore, existing approaches often render low-resolution feature maps and
process them with an upsampling network to obtain the final image. Albeit
efficient, neural rendering often entangles viewpoint and content such that
changing the camera pose results in unwanted changes of geometry or appearance.
Motivated by recent results in voxel-based novel view synthesis, we investigate
the utility of sparse voxel grid representations for fast and 3D-consistent
generative modeling in this paper. Our results demonstrate that monolithic MLPs
can indeed be replaced by 3D convolutions when combining sparse voxel grids
with progressive growing, free space pruning and appropriate regularization. To
obtain a compact representation of the scene and allow for scaling to higher
voxel resolutions, our model disentangles the foreground object (modeled in 3D)
from the background (modeled in 2D). In contrast to existing approaches, our
method requires only a single forward pass to generate a full 3D scene. It
hence allows for efficient rendering from arbitrary viewpoints while yielding
3D consistent results with high visual fidelity.</p>
  </details>
</details>
<details>
  <summary>11. <b>标题：A Simple Data Mixing Prior for Improving Self-Supervised Learning</b></summary>
  <p><b>编号</b>：[14]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07692</p>
  <p><b>作者</b>：Sucheng Ren,  Huiyu Wang,  Zhengqi Gao,  Shengfeng He,  Alan Yuille,  Yuyin Zhou,  Cihang Xie</p>
  <p><b>备注</b>：CVPR2022</p>
  <p><b>关键词</b>：advancing recognition models, textbf, recognition models, component for advancing, advancing recognition</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Data mixing (e.g., Mixup, Cutmix, ResizeMix) is an essential component for
advancing recognition models. In this paper, we focus on studying its
effectiveness in the self-supervised setting. By noticing the mixed images that
share the same source images are intrinsically related to each other, we hereby
propose SDMP, short for $\textbf{S}$imple $\textbf{D}$ata $\textbf{M}$ixing
$\textbf{P}$rior, to capture this straightforward yet essential prior, and
position such mixed images as additional $\textbf{positive pairs}$ to
facilitate self-supervised representation learning. Our experiments verify that
the proposed SDMP enables data mixing to help a set of self-supervised learning
frameworks (e.g., MoCo) achieve better accuracy and out-of-distribution
robustness. More notably, our SDMP is the first method that successfully
leverages data mixing to improve (rather than hurt) the performance of Vision
Transformers in the self-supervised setting. Code is publicly available at
this https URL</p>
  </details>
</details>
<details>
  <summary>12. <b>标题：ELUDE: Generating interpretable explanations via a decomposition into  labelled and unlabelled features</b></summary>
  <p><b>编号</b>：[15]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07690</p>
  <p><b>作者</b>：Vikram V. Ramaswamy,  Sunnie S. Y. Kim,  Nicole Meister,  Ruth Fong,  Olga Russakovsky</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：achieved remarkable success, Deep learning models, machine learning, past decade, difficult to understand</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep learning models have achieved remarkable success in different areas of
machine learning over the past decade; however, the size and complexity of
these models make them difficult to understand. In an effort to make them more
interpretable, several recent works focus on explaining parts of a deep neural
network through human-interpretable, semantic attributes. However, it may be
impossible to completely explain complex models using only semantic attributes.
In this work, we propose to augment these attributes with a small set of
uninterpretable features. Specifically, we develop a novel explanation
framework ELUDE (Explanation via Labelled and Unlabelled DEcomposition) that
decomposes a model's prediction into two parts: one that is explainable through
a linear combination of the semantic attributes, and another that is dependent
on the set of uninterpretable features. By identifying the latter, we are able
to analyze the "unexplained" portion of the model, obtaining insights into the
information used by the model. We show that the set of unlabelled features can
generalize to multiple models trained with the same feature space and compare
our work to two popular attribute-oriented methods, Interpretable Basis
Decomposition and Concept Bottleneck, and discuss the additional insights ELUDE
provides.</p>
  </details>
</details>
<details>
  <summary>13. <b>标题：Structured Video Tokens @ Ego4D PNR Temporal Localization Challenge 2022</b></summary>
  <p><b>编号</b>：[16]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07689</p>
  <p><b>作者</b>：Elad Ben-Avraham,  Roei Herzig,  Karttikeya Mangalam,  Amir Bar,  Anna Rohrbach,  Leonid Karlinsky,  Trevor Darrell,  Amir Globerson</p>
  <p><b>备注</b>：Ego4D CVPR22 Object State Localization challenge. arXiv admin note: substantial text overlap with arXiv:2206.06346</p>
  <p><b>关键词</b>：technical report describes, technical report, report describes, Point, Temporal Localization</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This technical report describes the SViT approach for the Ego4D Point of No
Return (PNR) Temporal Localization Challenge. We propose a learning framework
StructureViT (SViT for short), which demonstrates how utilizing the structure
of a small number of images only available during training can improve a video
model. SViT relies on two key insights. First, as both images and videos
contain structured information, we enrich a transformer model with a set of
\emph{object tokens} that can be used across images and videos. Second, the
scene representations of individual frames in video should "align" with those
of still images. This is achieved via a "Frame-Clip Consistency" loss, which
ensures the flow of structured information between images and videos. SViT
obtains strong performance on the challenge test set with 0.656 absolute
temporal localization error.</p>
  </details>
</details>
<details>
  <summary>14. <b>标题：Residual Sparsity Connection Learning for Efficient Video  Super-Resolution</b></summary>
  <p><b>编号</b>：[17]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07687</p>
  <p><b>作者</b>：Bin Xia,  Jingwen He,  Yulun Zhang,  Yucheng Hang,  Wenming Yang,  Luc Van Gool</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：resource-limited devices, wearable devices, Lighter and faster, video super-resolution, smartphones and wearable</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Lighter and faster models are crucial for the deployment of video
super-resolution (VSR) on resource-limited devices, e.g., smartphones and
wearable devices. In this paper, we develop Residual Sparsity Connection
Learning (RSCL), a structured pruning scheme, to reduce the redundancy of
convolution kernels and obtain a compact VSR network with a minor performance
drop. However, residual blocks require the pruned filter indices of skip and
residual connections to be the same, which is tricky for pruning. Thus, to
mitigate the pruning restrictions of residual blocks, we design a Residual
Sparsity Connection (RSC) scheme by preserving the feature channels and only
operating on the important channels. Moreover, for the pixel-shuffle operation,
we design a special pruning scheme by grouping several filters as pruning units
to guarantee the accuracy of feature channel-space conversion after pruning. In
addition, we introduce Temporal Finetuning (TF) to reduce the pruning error
amplification of hidden states with temporal propagation. Extensive experiments
show that the proposed RSCL significantly outperforms recent methods
quantitatively and qualitatively. Codes and models will be released.</p>
  </details>
</details>
<details>
  <summary>15. <b>标题：AVATAR: Unconstrained Audiovisual Speech Recognition</b></summary>
  <p><b>编号</b>：[19]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07684</p>
  <p><b>作者</b>：Valentin Gabeur,  Paul Hongsuck Seo,  Arsha Nagrani,  Chen Sun,  Karteek Alahari,  Cordelia Schmid</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：automatic speech recognition, Audio-visual automatic speech, incorporates visual cues, Audio-visual automatic, speech recognition</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Audio-visual automatic speech recognition (AV-ASR) is an extension of ASR
that incorporates visual cues, often from the movements of a speaker's mouth.
Unlike works that simply focus on the lip motion, we investigate the
contribution of entire visual frames (visual actions, objects, background
etc.). This is particularly useful for unconstrained videos, where the speaker
is not necessarily visible. To solve this task, we propose a new
sequence-to-sequence AudioVisual ASR TrAnsformeR (AVATAR) which is trained
end-to-end from spectrograms and full-frame RGB. To prevent the audio stream
from dominating training, we propose different word-masking strategies, thereby
encouraging our model to pay attention to the visual stream. We demonstrate the
contribution of the visual modality on the How2 AV-ASR benchmark, especially in
the presence of simulated noise, and show that our model outperforms all other
prior work by a large margin. Finally, we also create a new, real-world test
bed for AV-ASR called VisSpeech, which demonstrates the contribution of the
visual modality under challenging audio conditions.</p>
  </details>
</details>
<details>
  <summary>16. <b>标题：A Unified Sequence Interface for Vision Tasks</b></summary>
  <p><b>编号</b>：[25]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07669</p>
  <p><b>作者</b>：Ting Chen,  Saurabh Saxena,  Lala Li,  Tsung-Yi Lin,  David J. Fleet,  Geoffrey Hinton</p>
  <p><b>备注</b>：The first three authors contributed equally</p>
  <p><b>关键词</b>：modeling framework, naturally expressed, computer vision tasks, computer vision, vision tasks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>While language tasks are naturally expressed in a single, unified, modeling
framework, i.e., generating sequences of tokens, this has not been the case in
computer vision. As a result, there is a proliferation of distinct
architectures and loss functions for different vision tasks. In this work we
show that a diverse set of "core" computer vision tasks can also be unified if
formulated in terms of a shared pixel-to-sequence interface. We focus on four
tasks, namely, object detection, instance segmentation, keypoint detection, and
image captioning, all with diverse types of outputs, e.g., bounding boxes or
dense masks. Despite that, by formulating the output of each task as a sequence
of discrete tokens with a unified interface, we show that one can train a
neural network with a single model architecture and loss function on all these
tasks, with no task-specific customization. To solve a specific task, we use a
short prompt as task description, and the sequence output adapts to the prompt
so it can produce task-specific output. We show that such a model can achieve
competitive performance compared to well-established task-specific models.</p>
  </details>
</details>
<details>
  <summary>17. <b>标题：SP-ViT: Learning 2D Spatial Priors for Vision Transformers</b></summary>
  <p><b>编号</b>：[29]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07662</p>
  <p><b>作者</b>：Yuxuan Zhou,  Wangmeng Xiang,  Chao Li,  Biao Wang,  Xihan Wei,  Lei Zhang,  Margret Keuper,  Xiansheng Hua</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：shown great potential, classification and established, ImageNet benchmark, shown great, great potential</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recently, transformers have shown great potential in image classification and
established state-of-the-art results on the ImageNet benchmark. However,
compared to CNNs, transformers converge slowly and are prone to overfitting in
low-data regimes due to the lack of spatial inductive biases. Such spatial
inductive biases can be especially beneficial since the 2D structure of an
input image is not well preserved in transformers. In this work, we present
Spatial Prior-enhanced Self-Attention (SP-SA), a novel variant of vanilla
Self-Attention (SA) tailored for vision transformers. Spatial Priors (SPs) are
our proposed family of inductive biases that highlight certain groups of
spatial relations. Unlike convolutional inductive biases, which are forced to
focus exclusively on hard-coded local regions, our proposed SPs are learned by
the model itself and take a variety of spatial relations into account.
Specifically, the attention score is calculated with emphasis on certain kinds
of spatial relations at each head, and such learned spatial foci can be
complementary to each other. Based on SP-SA we propose the SP-ViT family, which
consistently outperforms other ViT models with similar GFlops or parameters.
Our largest model SP-ViT-L achieves a record-breaking 86.3% Top-1 accuracy with
a reduction in the number of parameters by almost 50% compared to previous
state-of-the-art model (150M for SP-ViT-L vs 271M for CaiT-M-36) among all
ImageNet-1K models trained on 224x224 and fine-tuned on 384x384 resolution w/o
extra data.</p>
  </details>
</details>
<details>
  <summary>18. <b>标题：Coarse-to-Fine Vision-Language Pre-training with Fusion in the Backbone</b></summary>
  <p><b>编号</b>：[33]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07643</p>
  <p><b>作者</b>：Zi-Yi Dou,  Aishwarya Kamath,  Zhe Gan,  Pengchuan Zhang,  Jianfeng Wang,  Linjie Li,  Zicheng Liu,  Ce Liu,  Yann LeCun,  Nanyun Peng,  Jianfeng Gao,  Lijuan Wang</p>
  <p><b>备注</b>：Project Website: this https URL</p>
  <p><b>关键词</b>：received considerable attention, recently received considerable, considerable attention, recently received, received considerable</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Vision-language (VL) pre-training has recently received considerable
attention. However, most existing end-to-end pre-training approaches either
only aim to tackle VL tasks such as image-text retrieval, visual question
answering (VQA) and image captioning that test high-level understanding of
images, or only target region-level understanding for tasks such as phrase
grounding and object detection. We present FIBER (Fusion-In-the-Backbone-based
transformER), a new VL model architecture that can seamlessly handle both these
types of tasks. Instead of having dedicated transformer layers for fusion after
the uni-modal backbones, FIBER pushes multimodal fusion deep into the model by
inserting cross-attention into the image and text backbones, bringing gains in
terms of memory and performance. In addition, unlike previous work that is
either only pre-trained on image-text data or on fine-grained data with
box-level annotations, we present a two-stage pre-training strategy that uses
both these kinds of data efficiently: (i) coarse-grained pre-training based on
image-text data; followed by (ii) fine-grained pre-training based on
image-text-box data. We conduct comprehensive experiments on a wide range of VL
tasks, ranging from VQA, image captioning, and retrieval, to phrase grounding,
referring expression comprehension, and object detection. Using deep multimodal
fusion coupled with the two-stage pre-training, FIBER provides consistent
performance improvements over strong baselines across all tasks, often
outperforming methods using magnitudes more data. Code is available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>19. <b>标题：Real3D-Aug: Point Cloud Augmentation by Placing Real Objects with  Occlusion Handling for 3D Detection and Segmentation</b></summary>
  <p><b>编号</b>：[38]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07634</p>
  <p><b>作者</b>：Petr Šebek,  Šimon Pokorný,  Patrik Vacek,  Tomáš Svoboda</p>
  <p><b>备注</b>：Submitted on 15th June 2022 to IEEE RA-L journal</p>
  <p><b>关键词</b>：require expensive annotation, cloud data require, data require expensive, point cloud data, expensive annotation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Object detection and semantic segmentation with the 3D lidar point cloud data
require expensive annotation. We propose a data augmentation method that takes
advantage of already annotated data multiple times. We propose an augmentation
framework that reuses real data, automatically finds suitable placements in the
scene to be augmented, and handles occlusions explicitly. Due to the usage of
the real data, the scan points of newly inserted objects in augmentation
sustain the physical characteristics of the lidar, such as intensity and
raydrop. The pipeline proves competitive in training top-performing models for
3D object detection and semantic segmentation. The new augmentation provides a
significant performance gain in rare and essential classes, notably 6.65%
average precision gain for "Hard" pedestrian class in KITTI object detection or
2.14 mean IoU gain in the SemanticKITTI segmentation challenge over the state
of the art.</p>
  </details>
</details>
<details>
  <summary>20. <b>标题：Evaluating object detector ensembles for improving the robustness of  artifact detection in endoscopic video streams</b></summary>
  <p><b>编号</b>：[53]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07580</p>
  <p><b>作者</b>：Pedro Esteban Chavarrias-Solano,  Carlos Axel Garcia-Vega,  Francisco Javier Lopez-Tiro,  Gilberto Ochoa-Ruiz,  Thomas Bazin,  Dominique Lamarque,  Christian Daul</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：individual one-stage detectors, ensemble deep-learning method, Endoscopic Artifact Detection, individual models, Artifact Detection Challenge</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this contribution we use an ensemble deep-learning method for combining
the prediction of two individual one-stage detectors (i.e., YOLOv4 and Yolact)
with the aim to detect artefacts in endoscopic images. This ensemble strategy
enabled us to improve the robustness of the individual models without harming
their real-time computation capabilities. We demonstrated the effectiveness of
our approach by training and testing the two individual models and various
ensemble configurations on the "Endoscopic Artifact Detection Challenge"
dataset. Extensive experiments show the superiority, in terms of mean average
precision, of the ensemble approach over the individual models and previous
works in the state of the art.</p>
  </details>
</details>
<details>
  <summary>21. <b>标题：A Meta-Analysis of Distributionally-Robust Models</b></summary>
  <p><b>编号</b>：[61]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07565</p>
  <p><b>作者</b>：Benjamin Feuer,  Ameya Joshi,  Chinmay Hegde</p>
  <p><b>备注</b>：To be presented at ICML Workshop on Principles of Distribution Shift 2022. Copyright 2022 by the author(s)</p>
  <p><b>关键词</b>：image classifiers trained, massive datasets, trained on massive, image classifiers, classifiers trained</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>State-of-the-art image classifiers trained on massive datasets (such as
ImageNet) have been shown to be vulnerable to a range of both intentional and
incidental distribution shifts. On the other hand, several recent classifiers
with favorable out-of-distribution (OOD) robustness properties have emerged,
achieving high accuracy on their target tasks while maintaining their
in-distribution accuracy on challenging benchmarks. We present a meta-analysis
on a wide range of publicly released models, most of which have been published
over the last twelve months. Through this meta-analysis, we empirically
identify four main commonalities for all the best-performing OOD-robust models,
all of which illuminate the considerable promise of vision-language
pre-training.</p>
  </details>
</details>
<details>
  <summary>22. <b>标题：How to Reduce Change Detection to Semantic Segmentation</b></summary>
  <p><b>编号</b>：[64]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07557</p>
  <p><b>作者</b>：Guo-Hua Wang,  Bin-Bin Gao,  Chengjie Wang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：aims to identify, image pair, segmentation, general segmentation problems, semantic segmentation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Change detection (CD) aims to identify changes that occur in an image pair
taken different times. Prior methods devise specific networks from scratch to
predict change masks in pixel-level, and struggle with general segmentation
problems. In this paper, we propose a new paradigm that reduces CD to semantic
segmentation which means tailoring an existing and powerful semantic
segmentation network to solve CD. This new paradigm conveniently enjoys the
mainstream semantic segmentation techniques to deal with general segmentation
problems in CD. Hence we can concentrate on studying how to detect changes. We
propose a novel and importance insight that different change types exist in CD
and they should be learned separately. Based on it, we devise a module named
MTF to extract the change information and fuse temporal features. MTF enjoys
high interpretability and reveals the essential characteristic of CD. And most
segmentation networks can be adapted to solve the CD problems with our MTF
module. Finally, we propose C-3PO, a network to detect changes at pixel-level.
C-3PO achieves state-of-the-art performance without bells and whistles. It is
simple but effective and can be considered as a new baseline in this field. Our
code will be available.</p>
  </details>
</details>
<details>
  <summary>23. <b>标题：Body Gesture Recognition to Control a Social Robot</b></summary>
  <p><b>编号</b>：[72]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07538</p>
  <p><b>作者</b>：Javier Laplaza,  Joan Jaume Oliver,  Ramón Romero,  Alberto Sanfeliu,  Anaís Garrell</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：gesture based language, based language, gesture based, body gesture communication, compare body gesture</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this work, we propose a gesture based language to allow humans to interact
with robots using their body in a natural way. We have created a new gesture
detection model using neural networks and a custom dataset of humans performing
a set of body gestures to train our network. Furthermore, we compare body
gesture communication with other communication channels to acknowledge the
importance of adding this knowledge to robots. The presented approach is
extensively validated in diverse simulations and real-life experiments with
non-trained volunteers. This attains remarkable results and shows that it is a
valuable framework for social robotics applications, such as human robot
collaboration or human-robot interaction.</p>
  </details>
</details>
<details>
  <summary>24. <b>标题：Deep Multi-Task Networks For Occluded Pedestrian Pose Estimation</b></summary>
  <p><b>编号</b>：[80]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07510</p>
  <p><b>作者</b>：Arindam Das,  Sudip Das,  Ganesh Sistu,  Jonathan Horgan,  Ujjwal Bhattacharya,  Edward Jones,  Martin Glavin,  Ciarán Eising</p>
  <p><b>备注</b>：4 pages, 5 tables, 2 figures</p>
  <p><b>关键词</b>：occluded parts, relevant automotive datasets, pose, occluded, pedestrian</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Most of the existing works on pedestrian pose estimation do not consider
estimating the pose of an occluded pedestrians, as the annotations of the
occluded parts are not available in relevant automotive datasets. For example,
CityPersons, a well-known dataset for pedestrian detection in automotive scenes
does not provide pose annotations, whereas MS-COCO, a non-automotive dataset,
contains human pose estimation. In this work, we propose a multi-task framework
to extract pedestrian features through detection and instance segmentation
tasks performed separately on these two distributions. Thereafter, an encoder
learns pose specific features using an unsupervised instance-level domain
adaptation method for the pedestrian instances from both distributions. The
proposed framework has improved state-of-the-art performances of pose
estimation, pedestrian detection, and instance segmentation.</p>
  </details>
</details>
<details>
  <summary>25. <b>标题：PolyU-BPCoMa: A Dataset and Benchmark Towards Mobile Colorized Mapping  Using a Backpack Multisensorial System</b></summary>
  <p><b>编号</b>：[96]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07468</p>
  <p><b>作者</b>：Wenzhong Shi,  Pengxin Chen,  Muyang Wang,  Sheng Bao,  Haodong Xiang,  Yue Yu,  Daping Yang</p>
  <p><b>备注</b>：13 pages</p>
  <p><b>关键词</b>：scanning and images, fundamental work, work in surveying, Constructing colorized point, mobile laser scanning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Constructing colorized point clouds from mobile laser scanning and images is
a fundamental work in surveying and mapping. It is also an essential
prerequisite for building digital twins for smart cities. However, existing
public datasets are either in relatively small scales or lack accurate
geometrical and color ground truth. This paper documents a multisensorial
dataset named PolyU-BPCoMA which is distinctively positioned towards mobile
colorized mapping. The dataset incorporates resources of 3D LiDAR, spherical
imaging, GNSS and IMU on a backpack platform. Color checker boards are pasted
in each surveyed area as targets and ground truth data are collected by an
advanced terrestrial laser scanner (TLS). 3D geometrical and color information
can be recovered in the colorized point clouds produced by the backpack system
and the TLS, respectively. Accordingly, we provide an opportunity to benchmark
the mapping and colorization accuracy simultaneously for a mobile
multisensorial system. The dataset is approximately 800 GB in size covering
both indoor and outdoor environments. The dataset and development kits are
available at this https URL.</p>
  </details>
</details>
<details>
  <summary>26. <b>标题：Coarse-to-fine Deep Video Coding with Hyperprior-guided Mode Prediction</b></summary>
  <p><b>编号</b>：[98]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07460</p>
  <p><b>作者</b>：Zhihao Hu,  Guo Lu,  Jinyang Guo,  Shan Liu,  Wei Jiang,  Dong Xu</p>
  <p><b>备注</b>：CVPR2022</p>
  <p><b>关键词</b>：deep video compression, single scale motion, previous deep video, video compression approaches, video compression framework</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The previous deep video compression approaches only use the single scale
motion compensation strategy and rarely adopt the mode prediction technique
from the traditional standards like H.264/H.265 for both motion and residual
compression. In this work, we first propose a coarse-to-fine (C2F) deep video
compression framework for better motion compensation, in which we perform
motion estimation, compression and compensation twice in a coarse to fine
manner. Our C2F framework can achieve better motion compensation results
without significantly increasing bit costs. Observing hyperprior information
(i.e., the mean and variance values) from the hyperprior networks contains
discriminant statistical information of different patches, we also propose two
efficient hyperprior-guided mode prediction methods. Specifically, using
hyperprior information as the input, we propose two mode prediction networks to
respectively predict the optimal block resolutions for better motion coding and
decide whether to skip residual information from each block for better residual
coding without introducing additional bit cost while bringing negligible extra
computation cost. Comprehensive experimental results demonstrate our proposed
C2F video compression framework equipped with the new hyperprior-guided mode
prediction methods achieves the state-of-the-art performance on HEVC, UVG and
MCL-JCV datasets.</p>
  </details>
</details>
<details>
  <summary>27. <b>标题：READ: Aggregating Reconstruction Error into Out-of-distribution  Detection</b></summary>
  <p><b>编号</b>：[99]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07459</p>
  <p><b>作者</b>：Wenyu Jiang,  Hao Cheng,  Mingcai Chen,  Shuai Feng,  Yuxin Ge,  Chongjun Wang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：reconstruction error, samples is crucial, real world, safe deployment, OOD</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Detecting out-of-distribution (OOD) samples is crucial to the safe deployment
of a classifier in the real world. However, deep neural networks are known to
be overconfident for abnormal data. Existing works directly design score
function by mining the inconsistency from classifier for in-distribution (ID)
and OOD. In this paper, we further complement this inconsistency with
reconstruction error, based on the assumption that an autoencoder trained on ID
data can not reconstruct OOD as well as ID. We propose a novel method, READ
(Reconstruction Error Aggregated Detector), to unify inconsistencies from
classifier and autoencoder. Specifically, the reconstruction error of raw
pixels is transformed to latent space of classifier. We show that the
transformed reconstruction error bridges the semantic gap and inherits
detection performance from the original. Moreover, we propose an adjustment
strategy to alleviate the overconfidence problem of autoencoder according to a
fine-grained characterization of OOD data. Under two scenarios of pre-training
and retraining, we respectively present two variants of our method, namely
READ-MD (Mahalanobis Distance) only based on pre-trained classifier and READ-ED
(Euclidean Distance) which retrains the classifier. Our methods do not require
access to test time OOD data for fine-tuning hyperparameters. Finally, we
demonstrate the effectiveness of the proposed methods through extensive
comparisons with state-of-the-art OOD detection algorithms. On a CIFAR-10
pre-trained WideResNet, our method reduces the average FPR@95TPR by up to 9.8%
compared with previous state-of-the-art.</p>
  </details>
</details>
<details>
  <summary>28. <b>标题：VisageSynTalk: Unseen Speaker Video-to-Speech Synthesis via  Speech-Visage Feature Selection</b></summary>
  <p><b>编号</b>：[100]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07458</p>
  <p><b>作者</b>：Joanna Hong,  Minsu Kim,  Yong Man Ro</p>
  <p><b>备注</b>：Submitted to ECCV 2022</p>
  <p><b>关键词</b>：silent talking face, talking face video, talking face, silent talking, face video</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The goal of this work is to reconstruct speech from a silent talking face
video. Recent studies have shown impressive performance on synthesizing speech
from silent talking face videos. However, they have not explicitly considered
on varying identity characteristics of different speakers, which place a
challenge in the video-to-speech synthesis, and this becomes more critical in
unseen-speaker settings. Distinct from the previous methods, our approach is to
separate the speech content and the visage-style from a given silent talking
face video. By guiding the model to independently focus on modeling the two
representations, we can obtain the speech of high intelligibility from the
model even when the input video of an unseen subject is given. To this end, we
introduce speech-visage selection module that separates the speech content and
the speaker identity from the visual features of the input video. The
disentangled representations are jointly incorporated to synthesize speech
through visage-style based synthesizer which generates speech by coating the
visage-styles while maintaining the speech content. Thus, the proposed
framework brings the advantage of synthesizing the speech containing the right
content even when the silent talking face video of an unseen subject is given.
We validate the effectiveness of the proposed framework on the GRID, TCD-TIMIT
volunteer, and LRW datasets. The synthesized speech can be heard in
supplementary materials.</p>
  </details>
</details>
<details>
  <summary>29. <b>标题：Forecasting of depth and ego-motion with transformers and  self-supervision</b></summary>
  <p><b>编号</b>：[106]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07435</p>
  <p><b>作者</b>：Houssem Boulahbal,  Adrian Voicila,  Andrew Comport</p>
  <p><b>备注</b>：Accepted in ICPR 2022</p>
  <p><b>关键词</b>：paper addresses, ego motion, depth, raw images, supervised photometric loss</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper addresses the problem of end-to-end self-supervised forecasting of
depth and ego motion. Given a sequence of raw images, the aim is to forecast
both the geometry and ego-motion using a self supervised photometric loss. The
architecture is designed using both convolution and transformer modules. This
leverages the benefits of both modules: Inductive bias of CNN, and the
multi-head attention of transformers, thus enabling a rich spatio-temporal
representation that enables accurate depth forecasting. Prior work attempts to
solve this problem using multi-modal input/output with supervised ground-truth
data which is not practical since a large annotated dataset is required.
Alternatively to prior methods, this paper forecasts depth and ego motion using
only self-supervised raw images as input. The approach performs significantly
well on the KITTI dataset benchmark with several performance criteria being
even comparable to prior non-forecasting self-supervised monocular depth
inference methods.</p>
  </details>
</details>
<details>
  <summary>30. <b>标题：Self-Supervised Implicit Attention: Guided Attention by The Model Itself</b></summary>
  <p><b>编号</b>：[107]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07434</p>
  <p><b>作者</b>：Jinyi Wu,  Xun Gong,  Zhemin Zhang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Self-Supervised Implicit Attention, propose Self-Supervised Implicit, adaptively guides deep, Implicit Attention, Self-Supervised Implicit</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose Self-Supervised Implicit Attention (SSIA), a new approach that
adaptively guides deep neural network models to gain attention by exploiting
the properties of the models themselves. SSIA is a novel attention mechanism
that does not require any extra parameters, computation, or memory access costs
during inference, which is in contrast to existing attention mechanism. In
short, by considering attention weights as higher-level semantic information,
we reconsidered the implementation of existing attention mechanisms and further
propose generating supervisory signals from higher network layers to guide
lower network layers for parameter updates. We achieved this by building a
self-supervised learning task using the hierarchical features of the network
itself, which only works at the training stage. To verify the effectiveness of
SSIA, we performed a particular implementation (called an SSIA block) in
convolutional neural network models and validated it on several image
classification datasets. The experimental results show that an SSIA block can
significantly improve the model performance, even outperforms many popular
attention methods that require additional parameters and computation costs,
such as Squeeze-and-Excitation and Convolutional Block Attention Module. Our
implementation will be available on GitHub.</p>
  </details>
</details>
<details>
  <summary>31. <b>标题：Physically-admissible polarimetric data augmentation for road-scene  analysis</b></summary>
  <p><b>编号</b>：[108]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07431</p>
  <p><b>作者</b>：Cyprien Ruffino,  Rachel Blin,  Samia Ainouz,  Gilles Gasso,  Romain Hérault,  Fabrice Meriaudeau,  Stéphane Canu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：including scene analysis, shown improved performances, shown improved, tasks including scene, deep learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Polarimetric imaging, along with deep learning, has shown improved
performances on different tasks including scene analysis. However, its
robustness may be questioned because of the small size of the training
datasets. Though the issue could be solved by data augmentation, polarization
modalities are subject to physical feasibility constraints unaddressed by
classical data augmentation techniques. To address this issue, we propose to
use CycleGAN, an image translation technique based on deep generative models
that solely relies on unpaired data, to transfer large labeled road scene
datasets to the polarimetric domain. We design several auxiliary loss terms
that, alongside the CycleGAN losses, deal with the physical constraints of
polarimetric images. The efficiency of this solution is demonstrated on road
scene object detection tasks where generated realistic polarimetric images
allow to improve performances on cars and pedestrian detection up to 9%. The
resulting constrained CycleGAN is publicly released, allowing anyone to
generate their own polarimetric images.</p>
  </details>
</details>
<details>
  <summary>32. <b>标题：Zero-shot object goal visual navigation</b></summary>
  <p><b>编号</b>：[113]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07423</p>
  <p><b>作者</b>：Qianfan Zhao,  Lu Zhang,  Bin He,  Hong Qiao,  Zhiyong Liu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：training stage, Object goal visual, goal visual navigation, target object, classes</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Object goal visual navigation is a challenging task that aims to guide a
robot to find the target object only based on its visual observation, and the
target is limited to the classes specified in the training stage. However, in
real households, there may exist numerous object classes that the robot needs
to deal with, and it is hard for all of these classes to be contained in the
training stage. To address this challenge, we propose a zero-shot object
navigation task by combining zero-shot learning with object goal visual
navigation, which aims at guiding robots to find objects belonging to novel
classes without any training samples. This task gives rise to the need to
generalize the learned policy to novel classes, which is a less addressed issue
of object navigation using deep reinforcement learning. To address this issue,
we utilize "class-unrelated" data as input to alleviate the overfitting of the
classes specified in the training stage. The class-unrelated input consists of
detection results and cosine similarity of word embeddings, and does not
contain any class-related visual features or knowledge graphs. Extensive
experiments on the AI2-THOR platform show that our model outperforms the
baseline models in both seen and unseen classes, which proves that our model is
less class-sensitive and generalizes better. Our code is available at
this https URL</p>
  </details>
</details>
<details>
  <summary>33. <b>标题：Efficient Adaptive Ensembling for Image Classification</b></summary>
  <p><b>编号</b>：[120]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07394</p>
  <p><b>作者</b>：Antonio Bruno,  Davide Moroni,  Massimo Martinelli</p>
  <p><b>备注</b>：Submitted for consideration in Pattern Recognition Letters</p>
  <p><b>关键词</b>：Computer Vision, achieve minor improvements, trend in Computer, sporadic cases, achieve minor</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In recent times, except for sporadic cases, the trend in Computer Vision is
to achieve minor improvements over considerable increases in complexity.
To reverse this tendency, we propose a novel method to boost image
classification performances without an increase in complexity.
To this end, we revisited ensembling, a powerful approach, not often
adequately used due to its nature of increased complexity and training time,
making it viable by specific design choices. First, we trained end-to-end two
EfficientNet-b0 models (known to be the architecture with the best overall
accuracy/complexity trade-off in image classification) on disjoint subsets of
data (i.e. bagging). Then, we made an efficient adaptive ensemble by performing
fine-tuning of a trainable combination layer. In this way, we were able to
outperform the state-of-the-art by an average of 0.5\% on the accuracy with
restrained complexity both in terms of number of parameters (by 5-60 times),
and FLoating point Operations Per Second (by 10-100 times) on several major
benchmark datasets, fully embracing the green AI.</p>
  </details>
</details>
<details>
  <summary>34. <b>标题：Ultra Fast Deep Lane Detection with Hybrid Anchor Driven Ordinal  Classification</b></summary>
  <p><b>编号</b>：[124]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07389</p>
  <p><b>作者</b>：Zequn Qin,  Pengyi Zhang,  Xi Li</p>
  <p><b>备注</b>：TPAMI 2022</p>
  <p><b>关键词</b>：extreme lighting conditions, occlusions and extreme, extreme lighting, severe occlusions, lighting conditions</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Modern methods mainly regard lane detection as a problem of pixel-wise
segmentation, which is struggling to address the problems of efficiency and
challenging scenarios like severe occlusions and extreme lighting conditions.
Inspired by human perception, the recognition of lanes under severe occlusions
and extreme lighting conditions is mainly based on contextual and global
information. Motivated by this observation, we propose a novel, simple, yet
effective formulation aiming at ultra fast speed and the problem of challenging
scenarios. Specifically, we treat the process of lane detection as an
anchor-driven ordinal classification problem using global features. First, we
represent lanes with sparse coordinates on a series of hybrid (row and column)
anchors. With the help of the anchor-driven representation, we then reformulate
the lane detection task as an ordinal classification problem to get the
coordinates of lanes. Our method could significantly reduce the computational
cost with the anchor-driven representation. Using the large receptive field
property of the ordinal classification formulation, we could also handle
challenging scenarios. Extensive experiments on four lane detection datasets
show that our method could achieve state-of-the-art performance in terms of
both speed and accuracy. A lightweight version could even achieve 300+ frames
per second(FPS). Our code is at
this https URL.</p>
  </details>
</details>
<details>
  <summary>35. <b>标题：The Manifold Hypothesis for Gradient-Based Explanations</b></summary>
  <p><b>编号</b>：[125]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07387</p>
  <p><b>作者</b>：Sebastian Bordt,  Uddeshya Upadhyay,  Zeynep Akata,  Ulrike von Luxburg</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：data manifold, provide meaningful explanations, algorithms provide meaningful, gradient-based explanation algorithms, data</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>When do gradient-based explanation algorithms provide meaningful
explanations? We propose a necessary criterion: their feature attributions need
to be aligned with the tangent space of the data manifold. To provide evidence
for this hypothesis, we introduce a framework based on variational autoencoders
that allows to estimate and generate image manifolds. Through experiments
across a range of different datasets -- MNIST, EMNIST, CIFAR10, X-ray pneumonia
and Diabetic Retinopathy detection -- we demonstrate that the more a feature
attribution is aligned with the tangent space of the data, the more structured
and explanatory it tends to be. In particular, the attributions provided by
popular post-hoc methods such as Integrated Gradients, SmoothGrad and Input
$\times$ Gradient tend to be more strongly aligned with the data manifold than
the raw gradient. As a consequence, we suggest that explanation algorithms
should actively strive to align their explanations with the data manifold. In
part, this can be achieved by adversarial training, which leads to better
alignment across all datasets. Some form of adjustment to the model
architecture or training algorithm is necessary, since we show that
generalization of neural networks alone does not imply the alignment of model
gradients with the data manifold.</p>
  </details>
</details>
<details>
  <summary>36. <b>标题：MonoGround: Detecting Monocular 3D Objects from the Ground</b></summary>
  <p><b>编号</b>：[132]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07372</p>
  <p><b>作者</b>：Zequn Qin,  Xi Li</p>
  <p><b>备注</b>：CVPR22</p>
  <p><b>关键词</b>：attracted great attention, ground plane prior, ground plane, object detection, object detection suffers</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Monocular 3D object detection has attracted great attention for its
advantages in simplicity and cost. Due to the ill-posed 2D to 3D mapping
essence from the monocular imaging process, monocular 3D object detection
suffers from inaccurate depth estimation and thus has poor 3D detection
results. To alleviate this problem, we propose to introduce the ground plane as
a prior in the monocular 3d object detection. The ground plane prior serves as
an additional geometric condition to the ill-posed mapping and an extra source
in depth estimation. In this way, we can get a more accurate depth estimation
from the ground. Meanwhile, to take full advantage of the ground plane prior,
we propose a depth-align training strategy and a precise two-stage depth
inference method tailored for the ground plane prior. It is worth noting that
the introduced ground plane prior requires no extra data sources like LiDAR,
stereo images, and depth information. Extensive experiments on the KITTI
benchmark show that our method could achieve state-of-the-art results compared
with other methods while maintaining a very fast speed. Our code and models are
available at this https URL.</p>
  </details>
</details>
<details>
  <summary>37. <b>标题：Robust SAR ATR on MSTAR with Deep Learning Models trained on Full  Synthetic MOCEM data</b></summary>
  <p><b>编号</b>：[141]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07352</p>
  <p><b>作者</b>：Benjamin Camus,  Corentin Le Barbu,  Eric Monteux</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Automatic Target Recognition, Synthetic Aperture Radar, Target Recognition, Aperture Radar, Deep Learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The promising potential of Deep Learning for Automatic Target Recognition
(ATR) on Synthetic Aperture Radar (SAR) images vanishes when considering the
complexity of collecting training datasets measurements. Simulation can
overcome this issue by producing synthetic training datasets. However, because
of the limited representativeness of simulation, models trained in a classical
way with synthetic images have limited generalization abilities when dealing
with real measurement at test time. Previous works identified a set of equally
promising deep-learning algorithms to tackle this issue. However, these
approaches have been evaluated in a very favorable scenario with a synthetic
training dataset that overfits the ground truth of the measured test data. In
this work, we study the ATR problem outside of this ideal condition, which is
unlikely to occur in real operational contexts. Our contribution is threefold.
(1) Using the MOCEM simulator (developed by SCALIAN DS for the French MoD/DGA),
we produce a synthetic MSTAR training dataset that differs significantly from
the real measurements. (2) We experimentally demonstrate the limits of the
state-of-the-art. (3) We show that domain randomization techniques and
adversarial training can be combined to overcome this issue. We demonstrate
that this approach is more robust than the state-of-the-art, with an accuracy
of 75 %, while having a limited impact on computing performance during
training.</p>
  </details>
</details>
<details>
  <summary>38. <b>标题：XMorpher: Full Transformer for Deformable Medical Image Registration via  Cross Attention</b></summary>
  <p><b>编号</b>：[144]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07349</p>
  <p><b>作者</b>：Jiacheng Shi,  Yuting He,  Youyong Kong,  Jean-Louis Coatrieux,  Huazhong Shu,  Guanyu Yang,  Shuo Li</p>
  <p><b>备注</b>：accepted by MICCAI 2022</p>
  <p><b>关键词</b>：deep learning-based Deformable, DMIR, Registration, images, learning-based Deformable</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>An effective backbone network is important to deep learning-based Deformable
Medical Image Registration (DMIR), because it extracts and matches the features
between two images to discover the mutual correspondence for fine registration.
However, the existing deep networks focus on single image situation and are
limited in registration task which is performed on paired images. Therefore, we
advance a novel backbone network, XMorpher, for the effective corresponding
feature representation in DMIR. 1) It proposes a novel full transformer
architecture including dual parallel feature extraction networks which exchange
information through cross attention, thus discovering multi-level semantic
correspondence while extracting respective features gradually for final
effective registration. 2) It advances the Cross Attention Transformer (CAT)
blocks to establish the attention mechanism between images which is able to
find the correspondence automatically and prompts the features to fuse
efficiently in the network. 3) It constrains the attention computation between
base windows and searching windows with different sizes, and thus focuses on
the local transformation of deformable registration and enhances the computing
efficiency at the same time. Without any bells and whistles, our XMorpher gives
Voxelmorph 2.8% improvement on DSC , demonstrating its effective representation
of the features from the paired images in DMIR. We believe that our XMorpher
has great application potential in more paired medical images. Our XMorpher is
open on this https URL</p>
  </details>
</details>
<details>
  <summary>39. <b>标题：Unsupervised Capsule Networks of High-Dimension Point Clouds  classification</b></summary>
  <p><b>编号</b>：[145]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07348</p>
  <p><b>作者</b>：Quanfeng Xu,  Yi Tang,  Yan Yang,  Yumei She,  Zuo Jiang</p>
  <p><b>备注</b>：24 pages</p>
  <p><b>关键词</b>：point clouds, high-dimensional point clouds, clouds, point, point clouds classification</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Three-dimensional point clouds learning is widely applied, but the point
clouds are still unable to deal with classification and recognition tasks
satisfactorily in the cases of irregular geometric structures and
high-dimensional space. In 3D space, point clouds tend to have regular
Euclidean structure because of their density. On the contrary, due to the high
dimensionality, the spatial structure of high-dimensional space is more
complex, and point clouds are mostly presented in non-European structure.
Furthermore, among current 3D point clouds classification algorithms, Canonical
Capsules algorithm based on Euclidean distance is difficult to decompose and
identify non-Euclidean structures effectively. Thus, aiming at the point clouds
classification task of non-Euclidean structure in 3D and high-dimensional
space, this paper refers to the LLE algorithm based on geodesic distance for
optimizing and proposes the unsupervised algorithm of high-dimensional point
clouds capsule. In this paper, the geometric features of point clouds are
considered in the extraction process, so as to transform the high-dimensional
non-Euclidean structure into a lower-dimensional Euclidean structure with
retaining spatial geometric features. To verify the feasibility of the
unsupervised algorithm of high-dimensional point clouds capsule, experiments
are conducted in Swiss Roll dataset, point clouds MNIST dataset and point
clouds LFW dataset. The results show that (1) non-Euclidean structures can be
can effectively identified by this model in Swiss Roll dataset; (2) a
significant unsupervised learning effect is realized in point clouds MNIST
dataset. In conclusion, the high-dimensional point clouds capsule unsupervised
algorithm proposed in this paper is conducive to expand the application
scenarios of current point clouds classification and recognition tasks.</p>
  </details>
</details>
<details>
  <summary>40. <b>标题：Automatic Detection of Rice Disease in Images of Various Leaf Sizes</b></summary>
  <p><b>编号</b>：[147]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07344</p>
  <p><b>作者</b>：Kantip Kiratiratanapruk,  Pitchayagan Temniranrat,  Wasin Sinthupinyo,  Sanparith Marukatat,  Sujin Patarapuwadol</p>
  <p><b>备注</b>：28 pages, 13 figures</p>
  <p><b>关键词</b>：expertise shortages problems, farmers tackling equipment, rice, accurate and affordable, method is required</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Fast, accurate and affordable rice disease detection method is required to
assist rice farmers tackling equipment and expertise shortages problems. In
this paper, we focused on the solution using computer vision technique to
detect rice diseases from rice field photograph images. Dealing with images
took in real-usage situation by general farmers is quite challenging due to
various environmental factors, and rice leaf object size variation is one major
factor caused performance gradation. To solve this problem, we presented a
technique combining a CNN object detection with image tiling technique, based
on automatically estimated width size of rice leaves in the images as a size
reference for dividing the original input image. A model to estimate leaf width
was created by small size CNN such as 18 layer ResNet architecture model. A new
divided tiled sub-image set with uniformly sized object was generated and used
as input for training a rice disease prediction model. Our technique was
evaluated on 4,960 images of eight different types of rice leaf diseases,
including blast, blight, brown spot, narrow brown spot, orange, red stripe,
rice grassy stunt virus, and streak disease. The mean absolute percentage error
(MAPE) for leaf width prediction task evaluated on all eight classes was 11.18%
in the experiment, indicating that the leaf width prediction model performed
well. The mean average precision (mAP) of the prediction performance on YOLOv4
architecture was enhanced from 87.56% to 91.14% when trained and tested with
the tiled dataset. According to our study, the proposed image tiling technique
improved rice disease detection efficiency.</p>
  </details>
</details>
<details>
  <summary>41. <b>标题：Recent Advances in Scene Image Representation and Classification</b></summary>
  <p><b>编号</b>：[155]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07326</p>
  <p><b>作者</b>：Chiranjibi Sitaula,  Tej Bahadur Shahi,  Faezeh Marzbanrad</p>
  <p><b>备注</b>：This paper is under review in Computer Science Review (Elsevier) journal. This article may be deleted or updated based on the polices of the journal</p>
  <p><b>关键词</b>：scene image representation, significant performance boost, image representation, image representation methods, learning algorithms nowadays</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>With the rise of deep learning algorithms nowadays, scene image
representation methods on big data (e.g., SUN-397) have achieved a significant
performance boost in classification. However, the performance is still limited
because the scene images are mostly complex in nature having higher intra-class
dissimilarity and inter-class similarity problems. To deal with such problems,
there are several methods proposed in the literature with their own advantages
and limitations. A detailed study of previous works is necessary to understand
their pros and cons in image representation and classification. In this paper,
we review the existing scene image representation methods that are being used
widely for image classification. For this, we, first, devise the taxonomy using
the seminal existing methods proposed in the literature to this date. Next, we
compare their performance both qualitatively (e.g., quality of outputs,
pros/cons, etc.) and quantitatively (e.g., accuracy). Last, we speculate the
prominent research directions in scene image representation tasks. Overall,
this survey provides in-depth insights and applications of recent scene image
representation methods for traditional Computer Vision (CV)-based methods, Deep
Learning (DL)-based methods, and Search Engine (SE)-based methods.</p>
  </details>
</details>
<details>
  <summary>42. <b>标题：VCT: A Video Compression Transformer</b></summary>
  <p><b>编号</b>：[166]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07307</p>
  <p><b>作者</b>：Fabian Mentzer,  George Toderici,  David Minnen,  Sung-Jin Hwang,  Sergi Caelles,  Mario Lucic,  Eirikur Agustsson</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：vastly simplify neural, simplify neural video, neural video compression, vastly simplify, simplify neural</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We show how transformers can be used to vastly simplify neural video
compression. Previous methods have been relying on an increasing number of
architectural biases and priors, including motion prediction and warping
operations, resulting in complex models. Instead, we independently map input
frames to representations and use a transformer to model their dependencies,
letting it predict the distribution of future representations given the past.
The resulting video compression transformer outperforms previous methods on
standard video compression data sets. Experiments on synthetic data show that
our model learns to handle complex motion patterns such as panning, blurring
and fading purely from data. Our approach is easy to implement, and we release
code to facilitate future research.</p>
  </details>
</details>
<details>
  <summary>43. <b>标题：S\textsuperscript{2}-FPN: Scale-ware Strip Attention Guided Feature  Pyramid Network for Real-time Semantic Segmentation</b></summary>
  <p><b>编号</b>：[170]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07298</p>
  <p><b>作者</b>：Mohammed A. M. Elhassan,  Chenhui Yang,  Chenxi Huang,  Tewodros Legesse Munea,  Xin Hong</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Modern high-performance semantic, Modern high-performance, APF, heavy backbone, backbone and dilated</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Modern high-performance semantic segmentation methods employ a heavy backbone
and dilated convolution to extract the relevant feature. Although extracting
features with both contextual and semantic information is critical for the
segmentation tasks, it brings a memory footprint and high computation cost for
real-time applications. This paper presents a new model to achieve a trade-off
between accuracy/speed for real-time road scene semantic segmentation.
Specifically, we proposed a lightweight model named Scale-aware Strip Attention
Guided Feature Pyramid Network (S\textsuperscript{2}-FPN). Our network consists
of three main modules: Attention Pyramid Fusion (APF) module, Scale-aware Strip
Attention Module (SSAM), and Global Feature Upsample (GFU) module. APF adopts
an attention mechanisms to learn discriminative multi-scale features and help
close the semantic gap between different levels. APF uses the scale-aware
attention to encode global context with vertical stripping operation and models
the long-range dependencies, which helps relate pixels with similar semantic
label. In addition, APF employs channel-wise reweighting block (CRB) to
emphasize the channel features. Finally, the decoder of
S\textsuperscript{2}-FPN then adopts GFU, which is used to fuse features from
APF and the encoder. Extensive experiments have been conducted on two
challenging semantic segmentation benchmarks, which demonstrate that our
approach achieves better accuracy/speed trade-off with different model
settings. The proposed models have achieved a results of 76.2\%mIoU/87.3FPS,
77.4\%mIoU/67FPS, and 77.8\%mIoU/30.5FPS on Cityscapes dataset, and
69.6\%mIoU,71.0\% mIoU, and 74.2\% mIoU on Camvid dataset. The code for this
work will be made available at \url{this https URL</p>
  </details>
</details>
<details>
  <summary>44. <b>标题：Differentiable Top-k Classification Learning</b></summary>
  <p><b>编号</b>：[174]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07290</p>
  <p><b>作者</b>：Felix Petersen,  Hilde Kuehne,  Christian Borgelt,  Oliver Deussen</p>
  <p><b>备注</b>：Published at ICML 2022, Code @ this https URL</p>
  <p><b>关键词</b>：machine learning, core metrics, metrics in machine, learning, training</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The top-k classification accuracy is one of the core metrics in machine
learning. Here, k is conventionally a positive integer, such as 1 or 5, leading
to top-1 or top-5 training objectives. In this work, we relax this assumption
and optimize the model for multiple k simultaneously instead of using a single
k. Leveraging recent advances in differentiable sorting and ranking, we propose
a differentiable top-k cross-entropy classification loss. This allows training
the network while not only considering the top-1 prediction, but also, e.g.,
the top-2 and top-5 predictions. We evaluate the proposed loss function for
fine-tuning on state-of-the-art architectures, as well as for training from
scratch. We find that relaxing k does not only produce better top-5 accuracies,
but also leads to top-1 accuracy improvements. When fine-tuning publicly
available ImageNet models, we achieve a new state-of-the-art for these models.</p>
  </details>
</details>
<details>
  <summary>45. <b>标题：Human Eyes Inspired Recurrent Neural Networks are More Robust Against  Adversarial Noises</b></summary>
  <p><b>编号</b>：[179]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07282</p>
  <p><b>作者</b>：Minkyu Choi,  Yizhen Zhang,  Kuan Han,  Xiaokai Wang,  Zhongming Liu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：computer vision based, convolutional neural networks, computer vision, based on convolutional, neural networks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Compared to human vision, computer vision based on convolutional neural
networks (CNN) are more vulnerable to adversarial noises. This difference is
likely attributable to how the eyes sample visual input and how the brain
processes retinal samples through its dorsal and ventral visual pathways, which
are under-explored for computer vision. Inspired by the brain, we design
recurrent neural networks, including an input sampler that mimics the human
retina, a dorsal network that guides where to look next, and a ventral network
that represents the retinal samples. Taking these modules together, the models
learn to take multiple glances at an image, attend to a salient part at each
glance, and accumulate the representation over time to recognize the image. We
test such models for their robustness against a varying level of adversarial
noises with a special focus on the effect of different input sampling
strategies. Our findings suggest that retinal foveation and sampling renders a
model more robust against adversarial noises, and the model may correct itself
from an attack when it is given a longer time to take more glances at an image.
In conclusion, robust visual recognition can benefit from the combined use of
three brain-inspired mechanisms: retinal transformation, attention guided eye
movement, and recurrent processing, as opposed to feedforward-only CNNs.</p>
  </details>
</details>
<details>
  <summary>46. <b>标题：Machine vision for vial positioning detection toward the safe automation  of material synthesis</b></summary>
  <p><b>编号</b>：[184]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07272</p>
  <p><b>作者</b>：Leslie Ching Ow Tiong,  Hyuk Jun Yoo,  Na Yeon Kim,  Kwan-Young Lee,  Sang Soo Han,  Donghun Kim</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：machine control errors, dangerous accidents primarily, accidents primarily due, material development process, development process</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Although robot-based automation in chemistry laboratories can accelerate the
material development process, surveillance-free environments may lead to
dangerous accidents primarily due to machine control errors. Object detection
techniques can play vital roles in addressing these safety issues; however,
state-of-the-art detectors, including single-shot detector (SSD) models, suffer
from insufficient accuracy in environments involving complex and noisy scenes.
With the aim of improving safety in a surveillance-free laboratory, we report a
novel deep learning (DL)-based object detector, namely, DenseSSD. For the
foremost and frequent problem of detecting vial positions, DenseSSD achieved a
mean average precision (mAP) over 95% based on a complex dataset involving both
empty and solution-filled vials, greatly exceeding those of conventional
detectors; such high precision is critical to minimizing failure-induced
accidents. Additionally, DenseSSD was observed to be highly insensitive to the
environmental changes, maintaining its high precision under the variations of
solution colors or testing view angles. The robustness of DenseSSD would allow
the utilized equipment settings to be more flexible. This work demonstrates
that DenseSSD is useful for enhancing safety in an automated material synthesis
environment, and it can be extended to various applications where high
detection accuracy and speed are both needed.</p>
  </details>
</details>
<details>
  <summary>47. <b>标题：Rethinking Generalization in Few-Shot Classification</b></summary>
  <p><b>编号</b>：[187]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07267</p>
  <p><b>作者</b>：Markus Hiller,  Rongkai Ma,  Mehrtash Harandi,  Tom Drummond</p>
  <p><b>备注</b>：Preprint</p>
  <p><b>关键词</b>：complex real-world scenes, scenes are depicted, correctly describe, small subset, complex real-world</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Single image-level annotations only correctly describe an often small subset
of an image's content, particularly when complex real-world scenes are
depicted. While this might be acceptable in many classification scenarios, it
poses a significant challenge for applications where the set of classes differs
significantly between training and test time. In this paper, we take a closer
look at the implications in the context of $\textit{few-shot learning}$.
Splitting the input samples into patches and encoding these via the help of
Vision Transformers allows us to establish semantic correspondences between
local regions across images and independent of their respective class. The most
informative patch embeddings for the task at hand are then determined as a
function of the support set via online optimization at inference time,
additionally providing visual interpretability of `$\textit{what matters
most}$' in the image. We build on recent advances in unsupervised training of
networks via masked image modelling to overcome the lack of fine-grained labels
and learn the more general statistical structure of the data while avoiding
negative image-level annotation influence, $\textit{aka}$ supervision collapse.
Experimental results show the competitiveness of our approach, achieving new
state-of-the-art results on four popular few-shot classification benchmarks for
$5$-shot and $1$-shot scenarios.</p>
  </details>
</details>
<details>
  <summary>48. <b>标题：On Enforcing Better Conditioned Meta-Learning for Rapid Few-Shot  Adaptation</b></summary>
  <p><b>编号</b>：[190]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07260</p>
  <p><b>作者</b>：Markus Hiller,  Mehrtash Harandi,  Tom Drummond</p>
  <p><b>备注</b>：Preprint</p>
  <p><b>关键词</b>：incurring extra parameters, increase adaptation speed, gradient-based meta-learning methods, concept of preconditioning, speed for gradient-based</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Inspired by the concept of preconditioning, we propose a novel method to
increase adaptation speed for gradient-based meta-learning methods without
incurring extra parameters. We demonstrate that recasting the optimization
problem to a non-linear least-squares formulation provides a principled way to
actively enforce a $\textit{well-conditioned}$ parameter space for
meta-learning models based on the concepts of the condition number and local
curvature. Our comprehensive evaluations show that the proposed method
significantly outperforms its unconstrained counterpart especially during
initial adaptation steps, while achieving comparable or better overall results
on several few-shot classification tasks -- creating the possibility of
dynamically choosing the number of adaptation steps at inference time.</p>
  </details>
</details>
<details>
  <summary>49. <b>标题：Self-Supervised Learning of Image Scale and Orientation</b></summary>
  <p><b>编号</b>：[191]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07259</p>
  <p><b>作者</b>：Jongmin Lee,  Yoonwoo Jeong,  Minsu Cho</p>
  <p><b>备注</b>：Presented in BMVC 2021, code is available on this https URL</p>
  <p><b>关键词</b>：assign a characteristic, study the problem, characteristic pose, image, region of interest</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We study the problem of learning to assign a characteristic pose, i.e., scale
and orientation, for an image region of interest. Despite its apparent
simplicity, the problem is non-trivial; it is hard to obtain a large-scale set
of image regions with explicit pose annotations that a model directly learns
from. To tackle the issue, we propose a self-supervised learning framework with
a histogram alignment technique. It generates pairs of image patches by random
rescaling/rotating and then train an estimator to predict their
scale/orientation values so that their relative difference is consistent with
the rescaling/rotating used. The estimator learns to predict a non-parametric
histogram distribution of scale/orientation without any supervision.
Experiments show that it significantly outperforms previous methods in
scale/orientation estimation and also improves image matching and 6 DoF camera
pose estimation by incorporating our patch poses into a matching process.</p>
  </details>
</details>
<details>
  <summary>50. <b>标题：GRAM-HD: 3D-Consistent Image Generation at High Resolution with  Generative Radiance Manifolds</b></summary>
  <p><b>编号</b>：[193]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07255</p>
  <p><b>作者</b>：Jianfeng Xiang,  Jiaolong Yang,  Yu Deng,  Xin Tong</p>
  <p><b>备注</b>：Project page: this https URL</p>
  <p><b>关键词</b>：unstructured single image, single image collections, works have shown, trained on unstructured, unstructured single</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent works have shown that 3D-aware GANs trained on unstructured single
image collections can generate multiview images of novel instances. The key
underpinnings to achieve this are a 3D radiance field generator and a volume
rendering process. However, existing methods either cannot generate
high-resolution images (e.g., up to 256X256) due to the high computation cost
of neural volume rendering, or rely on 2D CNNs for image-space upsampling which
jeopardizes the 3D consistency across different views. This paper proposes a
novel 3D-aware GAN that can generate high resolution images (up to 1024X1024)
while keeping strict 3D consistency as in volume rendering. Our motivation is
to achieve super-resolution directly in the 3D space to preserve 3D
consistency. We avoid the otherwise prohibitively-expensive computation cost by
applying 2D convolutions on a set of 2D radiance manifolds defined in the
recent generative radiance manifold (GRAM) approach, and apply dedicated loss
functions for effective GAN training at high resolution. Experiments on FFHQ
and AFHQv2 datasets show that our method can produce high-quality 3D-consistent
results that significantly outperform existing methods.</p>
  </details>
</details>
<details>
  <summary>51. <b>标题：Test-Time Adaptation for Visual Document Understanding</b></summary>
  <p><b>编号</b>：[202]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07240</p>
  <p><b>作者</b>：Sayna Ebrahimi,  Sercan O. Arik,  Tomas Pfister</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：produce transferable representations, produce transferable, visual document understanding, transferable representations, document understanding</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Self-supervised pretraining has been able to produce transferable
representations for various visual document understanding (VDU) tasks. However,
the ability of such representations to adapt to new distribution shifts at
test-time has not been studied yet. We propose DocTTA, a novel test-time
adaptation approach for documents that leverages cross-modality self-supervised
learning via masked visual language modeling as well as pseudo labeling to
adapt models learned on a \textit{source} domain to an unlabeled
\textit{target} domain at test time. We also introduce new benchmarks using
existing public datasets for various VDU tasks including entity recognition,
key-value extraction, and document visual question answering tasks where DocTTA
improves the source model performance up to 1.79\% in (F1 score), 3.43\% (F1
score), and 17.68\% (ANLS score), respectively while drastically reducing
calibration error on target data.</p>
  </details>
</details>
<details>
  <summary>52. <b>标题：Multimodal Event Graphs: Towards Event Centric Understanding of  Multimodal World</b></summary>
  <p><b>编号</b>：[215]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07207</p>
  <p><b>作者</b>：Hammad A. Ayyubi,  Christopher Thomas,  Lovish Chum,  Rahul Lokesh,  Yulei Niu,  Xudong Lin,  Long Chen,  Jaywon Koo,  Sounak Ray,  Shih-Fu Chang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：multimedia content relate, developing robust artificially, robust artificially intelligent, artificially intelligent systems, real-world media</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Understanding how events described or shown in multimedia content relate to
one another is a critical component to developing robust artificially
intelligent systems which can reason about real-world media. While much
research has been devoted to event understanding in the text, image, and video
domains, none have explored the complex relations that events experience across
domains. For example, a news article may describe a `protest' event while a
video shows an `arrest' event. Recognizing that the visual `arrest' event is a
subevent of the broader `protest' event is a challenging, yet important problem
that prior work has not explored. In this paper, we propose the novel task of
MultiModal Event Event Relations to recognize such cross-modal event relations.
We contribute a large-scale dataset consisting of 100k video-news article
pairs, as well as a benchmark of densely annotated data. We also propose a
weakly supervised multimodal method which integrates commonsense knowledge from
an external knowledge base (KB) to predict rich multimodal event hierarchies.
Experiments show that our model outperforms a number of competitive baselines
on our proposed benchmark. We also perform a detailed analysis of our model's
performance and suggest directions for future research.</p>
  </details>
</details>
<details>
  <summary>53. <b>标题：Surgical Phase Recognition in Laparoscopic Cholecystectomy</b></summary>
  <p><b>编号</b>：[219]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07198</p>
  <p><b>作者</b>：Yunfan Li,  Vinayak Shenoy,  Prateek Prasanna,  I.V. Ramakrishnan,  Haibin Ling,  Himanshu Gupta</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：surgical workflow analysis, Automatic recognition, workflow analysis, surgical phases, surgical videos</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Automatic recognition of surgical phases in surgical videos is a fundamental
task in surgical workflow analysis. In this report, we propose a
Transformer-based method that utilizes calibrated confidence scores for a
2-stage inference pipeline, which dynamically switches between a baseline model
and a separately trained transition model depending on the calibrated
confidence level. Our method outperforms the baseline model on the Cholec80
dataset, and can be applied to a variety of action segmentation methods.</p>
  </details>
</details>
<details>
  <summary>54. <b>标题：Proximal Splitting Adversarial Attacks for Semantic Segmentation</b></summary>
  <p><b>编号</b>：[230]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07179</p>
  <p><b>作者</b>：Jérôme Rony,  Jean-Christophe Pesquet,  Ismail Ben Ayed</p>
  <p><b>备注</b>：Code available at: this https URL</p>
  <p><b>关键词</b>：investigate methods suited, denser prediction tasks, works investigate methods, focal point, point of research</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Classification has been the focal point of research on adversarial attacks,
but only a few works investigate methods suited to denser prediction tasks,
such as semantic segmentation. The methods proposed in these works do not
accurately solve the adversarial segmentation problem and, therefore, are
overoptimistic in terms of size of the perturbations required to fool models.
Here, we propose a white-box attack for these models based on a proximal
splitting to produce adversarial perturbations with much smaller $\ell_1$,
$\ell_2$, or $\ell_\infty$ norms. Our attack can handle large numbers of
constraints within a nonconvex minimization framework via an Augmented
Lagrangian approach, coupled with adaptive constraint scaling and masking
strategies. We demonstrate that our attack significantly outperforms previously
proposed ones, as well as classification attacks that we adapted for
segmentation, providing a first comprehensive benchmark for this dense task.
Our results push current limits concerning robustness evaluations in
segmentation tasks.</p>
  </details>
</details>
<details>
  <summary>55. <b>标题：Measuring Representational Harms in Image Captioning</b></summary>
  <p><b>编号</b>：[232]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07173</p>
  <p><b>作者</b>：Angelina Wang,  Solon Barocas,  Kristen Laird,  Hanna Wallach</p>
  <p><b>备注</b>：ACM Conference on Fairness, Accountability, and Transparency (FAccT) 2022</p>
  <p><b>关键词</b>：image captioning system, image captioning, captioning system, image captioning datasets, popular image captioning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Previous work has largely considered the fairness of image captioning systems
through the underspecified lens of "bias." In contrast, we present a set of
techniques for measuring five types of representational harms, as well as the
resulting measurements obtained for two of the most popular image captioning
datasets using a state-of-the-art image captioning system. Our goal was not to
audit this image captioning system, but rather to develop normatively grounded
measurement techniques, in turn providing an opportunity to reflect on the many
challenges involved. We propose multiple measurement techniques for each type
of harm. We argue that by doing so, we are better able to capture the
multi-faceted nature of each type of harm, in turn improving the (collective)
validity of the resulting measurements. Throughout, we discuss the assumptions
underlying our measurement approach and point out when they do not hold.</p>
  </details>
</details>
<details>
  <summary>56. <b>标题：Automated image analysis in large-scale cellular electron microscopy: A  literature survey</b></summary>
  <p><b>编号</b>：[234]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07171</p>
  <p><b>作者</b>：Anusha Aswatha,  Ahmad Alsahaf,  Ben N. G. Giepmans,  George Azzopardi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Large-scale electron microscopy, Large-scale electron, electron microscopy, analysis, automated microscopes</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large-scale electron microscopy (EM) datasets generated using (semi-)
automated microscopes are becoming the standard in EM. Given the vast amounts
of data, manual analysis of all data is not feasible, thus automated analysis
is crucial. The main challenges in automated analysis include the annotation
that is needed to analyse and interpret biomedical images, coupled with
achieving high-throughput. Here, we review the current state-of-the-art of
automated computer techniques and major challenges for the analysis of
structures in cellular EM. The advanced computer vision, deep learning and
software tools that have been developed in the last five years for automatic
biomedical image analysis are discussed with respect to annotation,
segmentation and scalability for EM data. Integration of automatic image
acquisition and analysis will allow for high-throughput analysis of
millimeter-range datasets with nanometer resolution.</p>
  </details>
</details>
<details>
  <summary>57. <b>标题：DeepRecon: Joint 2D Cardiac Segmentation and 3D Volume Reconstruction  via A Structure-Specific Generative Method</b></summary>
  <p><b>编号</b>：[239]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07163</p>
  <p><b>作者</b>：Qi Chang,  Zhennan Yan,  Mu Zhou,  Di Liu,  Khalid Sawalha,  Meng Ye,  Qilong Zhangli,  Mikael Kanski,  Subhi Al Aref,  Leon Axel,  Dimitris Metaxas</p>
  <p><b>备注</b>：MICCAI2022</p>
  <p><b>关键词</b>：understanding functional mechanisms, building statistical cardiac, statistical cardiac anatomy, fundamental to building, building statistical</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Joint 2D cardiac segmentation and 3D volume reconstruction are fundamental to
building statistical cardiac anatomy models and understanding functional
mechanisms from motion patterns. However, due to the low through-plane
resolution of cine MR and high inter-subject variance, accurately segmenting
cardiac images and reconstructing the 3D volume are challenging. In this study,
we propose an end-to-end latent-space-based framework, DeepRecon, that
generates multiple clinically essential outcomes, including accurate image
segmentation, synthetic high-resolution 3D image, and 3D reconstructed volume.
Our method identifies the optimal latent representation of the cine image that
contains accurate semantic information for cardiac structures. In particular,
our model jointly generates synthetic images with accurate semantic information
and segmentation of the cardiac structures using the optimal latent
representation. We further explore downstream applications of 3D shape
reconstruction and 4D motion pattern adaptation by the different latent-space
manipulation strategies.The simultaneously generated high-resolution images
present a high interpretable value to assess the cardiac shape and
motion.Experimental results demonstrate the effectiveness of our approach on
multiple fronts including 2D segmentation, 3D reconstruction, downstream 4D
motion pattern adaption performance.</p>
  </details>
</details>
<details>
  <summary>58. <b>标题：Category-Agnostic 6D Pose Estimation with Conditional Neural Processes</b></summary>
  <p><b>编号</b>：[240]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07162</p>
  <p><b>作者</b>：Yumeng Li,  Ning Gao,  Hanna Ziesche,  Gerhard Neumann</p>
  <p><b>备注</b>：Accepted at CVPR2022 workshop: Women in Computer Vision (WiCV)</p>
  <p><b>关键词</b>：pose estimation methods, pose estimation, meta-learning approach, pose, unknown objects</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present a novel meta-learning approach for 6D pose estimation on unknown
objects. In contrast to "instance-level" pose estimation methods, our algorithm
learns object representation in a category-agnostic way, which endows it with
strong generalization capabilities within and across object categories.
Specifically, we employ a conditional neural process-based meta-learning
approach to train an encoder to capture texture and geometry of an object in a
latent representation, based on very few RGB-D images and ground-truth
keypoints. The latent representation is then used by a simultaneously
meta-trained decoder to predict the 6D pose of the object in new images. To
evaluate our algorithm, experiments are conducted on our new fully-annotated
synthetic datasets generated from Multiple Categories in Multiple Scenes
(MCMS). Experimental results demonstrate that our model performs well on unseen
objects with various shapes and appearances.</p>
  </details>
</details>
<details>
  <summary>59. <b>标题：LAVENDER: Unifying Video-Language Understanding as Masked Language  Modeling</b></summary>
  <p><b>编号</b>：[242]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07160</p>
  <p><b>作者</b>：Linjie Li,  Zhe Gan,  Kevin Lin,  Chung-Ching Lin,  Zicheng Liu,  Ce Liu,  Lijuan Wang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：unify image-text tasks, recent years, greatly advanced, advanced in recent, adopt an encoder-decoder</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Unified vision-language frameworks have greatly advanced in recent years,
most of which adopt an encoder-decoder architecture to unify image-text tasks
as sequence-to-sequence generation. However, existing video-language (VidL)
models still require task-specific designs in model architecture and training
objectives for each task. In this work, we explore a unified VidL framework
LAVENDER, where Masked Language Modeling (MLM) is used as the common interface
for all pre-training and downstream tasks. Such unification leads to a
simplified model architecture, where only a lightweight MLM head, instead of a
decoder with much more parameters, is needed on top of the multimodal encoder.
Surprisingly, experimental results show that this unified framework achieves
competitive performance on 14 VidL benchmarks, covering video question
answering, text-to-video retrieval and video captioning. Extensive analyses
further demonstrate the advantage of LAVENDER over existing VidL methods in:
(i) supporting all downstream tasks with just a single set of parameter values
when multi-task finetuned; (ii) few-shot generalization on various downstream
tasks; and (iii) enabling zero-shot evaluation on video question answering
tasks. Code is available at this https URL.</p>
  </details>
</details>
<details>
  <summary>60. <b>标题：Self-Supervision on Images and Text Reduces Reliance on Visual Shortcut  Features</b></summary>
  <p><b>编号</b>：[243]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07155</p>
  <p><b>作者</b>：Anil Palepu,  Andrew L Beam</p>
  <p><b>备注</b>：4 pages, 2 figures, accepted at SCIS workshop, ICML 2022</p>
  <p><b>关键词</b>：Deep learning models, Shortcut features, Deep learning, rely on so-called, learning models trained</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep learning models trained in a fully supervised manner have been shown to
rely on so-called "shortcut" features. Shortcut features are inputs that are
associated with the outcome of interest in the training data, but are either no
longer associated or not present in testing or deployment settings. Here we
provide experiments that show recent self-supervised models trained on images
and text provide more robust image representations and reduce the model's
reliance on visual shortcut features on a realistic medical imaging example.
Additionally, we find that these self-supervised models "forget" shortcut
features more quickly than fully supervised ones when fine-tuned on labeled
data. Though not a complete solution, our experiments provide compelling
evidence that self-supervised models trained on images and text provide some
resilience to visual shortcut features.</p>
  </details>
</details>
<details>
  <summary>61. <b>标题：It's Time for Artistic Correspondence in Music and Video</b></summary>
  <p><b>编号</b>：[246]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07148</p>
  <p><b>作者</b>：Didac Suris,  Carl Vondrick,  Bryan Russell,  Justin Salamon</p>
  <p><b>备注</b>：CVPR 2022</p>
  <p><b>关键词</b>：vice versa, artistic level, temporal alignment, music track, temporal context</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present an approach for recommending a music track for a given video, and
vice versa, based on both their temporal alignment and their correspondence at
an artistic level. We propose a self-supervised approach that learns this
correspondence directly from data, without any need of human annotations. In
order to capture the high-level concepts that are required to solve the task,
we propose modeling the long-term temporal context of both the video and the
music signals, using Transformer networks for each modality. Experiments show
that this approach strongly outperforms alternatives that do not exploit the
temporal context. The combination of our contributions improve retrieval
accuracy up to 10x over prior state of the art. This strong improvement allows
us to introduce a wide range of analyses and applications. For instance, we can
condition music retrieval based on visually defined attributes.</p>
  </details>
</details>
<details>
  <summary>62. <b>标题：Automatic Clipping: Differentially Private Deep Learning Made Easier and  Stronger</b></summary>
  <p><b>编号</b>：[251]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07136</p>
  <p><b>作者</b>：Zhiqi Bu,  Yu-Xiang Wang,  Sheng Zha,  George Karypis</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：deep learning models, key algorithmic step, enables practical differential, Per-example gradient clipping, practical differential private</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Per-example gradient clipping is a key algorithmic step that enables
practical differential private (DP) training for deep learning models. The
choice of clipping norm $R$, however, is shown to be vital for achieving high
accuracy under DP. We propose an easy-to-use replacement, called AutoClipping,
that eliminates the need to tune $R$ for any DP optimizers, including DP-SGD,
DP-Adam, DP-LAMB and many others. The automatic variants are as private and
computationally efficient as existing DP optimizers, but require no DP-specific
hyperparameters and thus make DP training as amenable as the standard
non-private training. We give a rigorous convergence analysis of automatic
DP-SGD in the non-convex setting, which shows that it enjoys an asymptotic
convergence rate that matches the standard SGD. We also demonstrate on various
language and vision tasks that automatic clipping outperforms or matches the
state-of-the-art, and can be easily employed with minimal changes to existing
codebases.</p>
  </details>
</details>
<details>
  <summary>63. <b>标题：Self-Supervised Pretraining for Differentially Private Learning</b></summary>
  <p><b>编号</b>：[254]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07125</p>
  <p><b>作者</b>：Arash Asadian,  Evan Weidner,  Lei Jiang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：demonstrate self-supervised pretraining, self-supervised pretraining, demonstrate self-supervised, scalable solution, solution to deep</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We demonstrate self-supervised pretraining (SSP) is a scalable solution to
deep learning with differential privacy (DP) regardless of the size of
available public datasets in image classification. When facing the lack of
public datasets, we show the features generated by SSP on only one single image
enable a private classifier to obtain much better utility than the non-learned
handcrafted features under the same privacy budget. When a moderate or large
size public dataset is available, the features produced by SSP greatly
outperform the features trained with labels on various complex private datasets
under the same private budget. We also compared multiple DP-enabled training
frameworks to train a private classifier on the features generated by SSP.
Finally, we report a non-trivial utility 25.3\% of a private ImageNet-1K
dataset when $\epsilon=3$.</p>
  </details>
</details>
<details>
  <summary>64. <b>标题：TriHorn-Net: A Model for Accurate Depth-Based 3D Hand Pose Estimation</b></summary>
  <p><b>编号</b>：[255]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07117</p>
  <p><b>作者</b>：Mohammad Rezaei,  Razieh Rastgoo,  Vassilis Athitsos</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：significant progress recently, made significant progress, hand pose estimation, pose estimation, progress recently</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>3D hand pose estimation methods have made significant progress recently.
However, estimation accuracy is often far from sufficient for specific
real-world applications, and thus there is significant room for improvement.
This paper proposes TriHorn-Net, a novel model that uses specific innovations
to improve hand pose estimation accuracy on depth images. The first innovation
is the decomposition of the 3D hand pose estimation into the estimation of 2D
joint locations in the depth image space (UV), and the estimation of their
corresponding depths aided by two complementary attention maps. This
decomposition prevents depth estimation, which is a more difficult task, from
interfering with the UV estimations at both the prediction and feature levels.
The second innovation is PixDropout, which is, to the best of our knowledge,
the first appearance-based data augmentation method for hand depth images.
Experimental results demonstrate that the proposed model outperforms the
state-of-the-art methods on three public benchmark datasets.</p>
  </details>
</details>
<details>
  <summary>65. <b>标题：Applications of Generative Adversarial Networks in Neuroimaging and  Clinical Neuroscience</b></summary>
  <p><b>编号</b>：[276]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07081</p>
  <p><b>作者</b>：Rongguang Wang,  Vishnu Bashyam,  Zhijian Yang,  Fanyang Yu,  Vasiliki Tassopoulou,  Lasya P. Sreepada,  Sai Spandana Chintapalli,  Dushyant Sahoo,  Ioanna Skampardoni,  Konstantina Nikita,  Ahmed Abdulkadir,  Junhao Wen,  Christos Davatzikos</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Generative adversarial networks, adversarial networks, numerous fields, powerful type, successfully utilized</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Generative adversarial networks (GANs) are one powerful type of deep learning
models that have been successfully utilized in numerous fields. They belong to
a broader family called generative methods, which generate new data with a
probabilistic model by learning sample distribution from real examples. In the
clinical context, GANs have shown enhanced capabilities in capturing spatially
complex, nonlinear, and potentially subtle disease effects compared to
traditional generative methods. This review appraises the existing literature
on the applications of GANs in imaging studies of various neurological
conditions, including Alzheimer's disease, brain tumors, brain aging, and
multiple sclerosis. We provide an intuitive explanation of various GAN methods
for each application and further discuss the main challenges, open questions,
and promising future directions of leveraging GANs in neuroimaging. We aim to
bridge the gap between advanced deep learning methods and neurology research by
highlighting how GANs can be leveraged to support clinical decision making and
contribute to a better understanding of the structural and functional patterns
of brain diseases.</p>
  </details>
</details>
<details>
  <summary>66. <b>标题：CRISP - Reliable Uncertainty Estimation for Medical Image Segmentation</b></summary>
  <p><b>编号</b>：[284]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07664</p>
  <p><b>作者</b>：Thierry Judge,  Olivier Bernard,  Mihaela Porumb,  Agis Chartsias,  Arian Beqiri,  Pierre-Marc Jodoin</p>
  <p><b>备注</b>：9 pages</p>
  <p><b>关键词</b>：medical imaging community, Accurate uncertainty estimation, imaging community, Accurate uncertainty, uncertainty estimations techniques</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Accurate uncertainty estimation is a critical need for the medical imaging
community. A variety of methods have been proposed, all direct extensions of
classification uncertainty estimations techniques. The independent pixel-wise
uncertainty estimates, often based on the probabilistic interpretation of
neural networks, do not take into account anatomical prior knowledge and
consequently provide sub-optimal results to many segmentation tasks. For this
reason, we propose CRISP a ContRastive Image Segmentation for uncertainty
Prediction method. At its core, CRISP implements a contrastive method to learn
a joint latent space which encodes a distribution of valid segmentations and
their corresponding images. We use this joint latent space to compare
predictions to thousands of latent vectors and provide anatomically consistent
uncertainty maps. Comprehensive studies performed on four medical image
databases involving different modalities and organs underlines the superiority
of our method compared to state-of-the-art approaches.</p>
  </details>
</details>
<details>
  <summary>67. <b>标题：How GNNs Facilitate CNNs in Mining Geometric Information from  Large-Scale Medical Images</b></summary>
  <p><b>编号</b>：[298]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07599</p>
  <p><b>作者</b>：Yiqing Shen,  Bingxin Zhou,  Xinye Xiong,  Ruitian Gao,  Yu Guang Wang</p>
  <p><b>备注</b>：21 pages</p>
  <p><b>关键词</b>：provide massive data, images provide massive, Gigapixel medical images, medical images provide, provide massive</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Gigapixel medical images provide massive data, both morphological textures
and spatial information, to be mined. Due to the large data scale in histology,
deep learning methods play an increasingly significant role as feature
extractors. Existing solutions heavily rely on convolutional neural networks
(CNNs) for global pixel-level analysis, leaving the underlying local geometric
structure such as the interaction between cells in the tumor microenvironment
unexplored. The topological structure in medical images, as proven to be
closely related to tumor evolution, can be well characterized by graphs. To
obtain a more comprehensive representation for downstream oncology tasks, we
propose a fusion framework for enhancing the global image-level representation
captured by CNNs with the geometry of cell-level spatial information learned by
graph neural networks (GNN). The fusion layer optimizes an integration between
collaborative features of global images and cell graphs. Two fusion strategies
have been developed: one with MLP which is simple but turns out efficient
through fine-tuning, and the other with Transformer gains a champion in fusing
multiple networks. We evaluate our fusion strategies on histology datasets
curated from large patient cohorts of colorectal and gastric cancers for three
biomarker prediction tasks. Both two models outperform plain CNNs or GNNs,
reaching a consistent AUC improvement of more than 5% on various network
backbones. The experimental results yield the necessity for combining
image-level morphological features with cell spatial relations in medical image
analysis. Codes are available at this https URL.</p>
  </details>
</details>
<details>
  <summary>68. <b>标题：BIO-CXRNET: A Robust Multimodal Stacking Machine Learning Technique for  Mortality Risk Prediction of COVID-19 Patients using Chest X-Ray Images and  Clinical Data</b></summary>
  <p><b>编号</b>：[299]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07595</p>
  <p><b>作者</b>：Tawsifur Rahman,  Muhammad E. H. Chowdhury,  Amith Khandakar,  Zaid Bin Mahbub,  Md Sakib Abrar Hossain,  Abraham Alhatou,  Eynas Abdalla,  Sreekumar Muthiyal,  Khandaker Farzana Islam,  Saad Bin Abul Kashem,  Muhammad Salman Khan,  Susu M. Zughaier,  Maqsud Hossain</p>
  <p><b>备注</b>：25 pages, 8 Tables, 10 Figures</p>
  <p><b>关键词</b>：high-risk patients, Fast and accurate, accurate detection, disease can significantly, reducing the strain</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Fast and accurate detection of the disease can significantly help in reducing
the strain on the healthcare facility of any country to reduce the mortality
during any pandemic. The goal of this work is to create a multimodal system
using a novel machine learning framework that uses both Chest X-ray (CXR)
images and clinical data to predict severity in COVID-19 patients. In addition,
the study presents a nomogram-based scoring technique for predicting the
likelihood of death in high-risk patients. This study uses 25 biomarkers and
CXR images in predicting the risk in 930 COVID-19 patients admitted during the
first wave of COVID-19 (March-June 2020) in Italy. The proposed multimodal
stacking technique produced the precision, sensitivity, and F1-score, of
89.03%, 90.44%, and 89.03%, respectively to identify low or high-risk patients.
This multimodal approach improved the accuracy by 6% in comparison to the CXR
image or clinical data alone. Finally, nomogram scoring system using
multivariate logistic regression -- was used to stratify the mortality risk
among the high-risk patients identified in the first stage. Lactate
Dehydrogenase (LDH), O2 percentage, White Blood Cells (WBC) Count, Age, and
C-reactive protein (CRP) were identified as useful predictor using random
forest feature selection model. Five predictors parameters and a CXR image
based nomogram score was developed for quantifying the probability of death and
categorizing them into two risk groups: survived (<50%), and death (>=50%),
respectively. The multi-modal technique was able to predict the death
probability of high-risk patients with an F1 score of 92.88 %. The area under
the curves for the development and validation cohorts are 0.981 and 0.939,
respectively.</50%),></p>
  </details>
</details>
<details>
  <summary>69. <b>标题：A Deep Generative Model of Neonatal Cortical Surface Development</b></summary>
  <p><b>编号</b>：[305]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07542</p>
  <p><b>作者</b>：Abdulah Fawaz,  Logan Z. Williams,  Emma Robinson,  A. David Edwards</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：poorer neurodevelopmental outcomes, neonatal cortical surface, neurodevelopmental outcomes, cortical surface, poorer neurodevelopmental</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The neonatal cortical surface is known to be affected by preterm birth, and
the subsequent changes to cortical organisation have been associated with
poorer neurodevelopmental outcomes. Deep Generative models have the potential
to lead to clinically interpretable models of disease, but developing these on
the cortical surface is challenging since established techniques for learning
convolutional filters are inappropriate on non-flat topologies. To close this
gap, we implement a surface-based CycleGAN using mixture model CNNs (MoNet) to
translate sphericalised neonatal cortical surface features (curvature and
T1w/T2w cortical myelin) between different stages of cortical maturity. Results
show our method is able to reliably predict changes in individual patterns of
cortical organisation at later stages of gestation, validated by comparison to
longitudinal data; and translate appearance between preterm and term gestation
(> 37 weeks gestation), validated through comparison with a trained
term/preterm classifier. Simulated differences in cortical maturation are
consistent with observations in the literature.</p>
  </details>
</details>
<details>
  <summary>70. <b>标题：A Survey of Detection Methods for Die Attachment and Wire Bonding  Defects in Integrated Circuit Manufacturing</b></summary>
  <p><b>编号</b>：[314]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07481</p>
  <p><b>作者</b>：Lamia Alam,  Nasser Kehtarnavaz</p>
  <p><b>备注</b>：13 pages, 9 figures, 8 tables</p>
  <p><b>关键词</b>：manufacturing process, integrated circuits, plays a vital, vital role, Defect detection plays</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Defect detection plays a vital role in the manufacturing process of
integrated circuits (ICs). Die attachment and wire bonding are two steps of the
manufacturing process that determine the quality and reliability of the power
and signal transmission in an IC. This paper presents a survey or literature
review of the methods used for detecting these defects based on different
sensing modalities used including optical, radiological, acoustical, and
infrared thermography. A discussion of the detection methods used is provided
in this survey. Both conventional and deep learning approaches for detecting
die attachment and wire bonding defects are considered along with challenges
and future research directions.</p>
  </details>
</details>
<details>
  <summary>71. <b>标题：Deep Neural Network Pruning for Nuclei Instance Segmentation in  Hematoxylin & Eosin-Stained Histological Images</b></summary>
  <p><b>编号</b>：[319]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07422</p>
  <p><b>作者</b>：Amirreza Mahbod,  Rahim Entezari,  Isabella Ellinger,  Olga Saukh</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：reducing network size, increasing inference speed, deep neural networks, reducing network, network size</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recently, pruning deep neural networks (DNNs) has received a lot of attention
for improving accuracy and generalization power, reducing network size, and
increasing inference speed on specialized hardwares. Although pruning was
mainly tested on computer vision tasks, its application in the context of
medical image analysis has hardly been explored. This work investigates the
impact of well-known pruning techniques, namely layer-wise and network-wide
magnitude pruning, on the nuclei instance segmentation performance in
histological images. Our utilized instance segmentation model consists of two
main branches: (1) a semantic segmentation branch, and (2) a deep regression
branch. We investigate the impact of weight pruning on the performance of both
branches separately and on the final nuclei instance segmentation result.
Evaluated on two publicly available datasets, our results show that layer-wise
pruning delivers slightly better performance than networkwide pruning for small
compression ratios (CRs) while for large CRs, network-wide pruning yields
superior performance. For semantic segmentation, deep regression and final
instance segmentation, 93.75 %, 95 %, and 80 % of the model weights can be
pruned by layer-wise pruning with less than 2 % reduction in the performance of
respective models.</p>
  </details>
</details>
<details>
  <summary>72. <b>标题：Interpretable differential diagnosis for Alzheimer's disease and  Frontotemporal dementia</b></summary>
  <p><b>编号</b>：[320]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07417</p>
  <p><b>作者</b>：Huy-Dung Nguyen,  Michaël Clément,  Boris Mansencal,  Pierrick Coupé</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Frontotemporal dementia, dementia, major types, Alzheimer disease, Frontotemporal</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Alzheimer's disease and Frontotemporal dementia are two major types of
dementia. Their accurate diagnosis and differentiation is crucial for
determining specific intervention and treatment. However, differential
diagnosis of these two types of dementia remains difficult at the early stage
of disease due to similar patterns of clinical symptoms. Therefore, the
automatic classification of multiple types of dementia has an important
clinical value. So far, this challenge has not been actively explored. Recent
development of deep learning in the field of medical image has demonstrated
high performance for various classification tasks. In this paper, we propose to
take advantage of two types of biomarkers: structure grading and structure
atrophy. To this end, we propose first to train a large ensemble of 3D U-Nets
to locally discriminate healthy versus dementia anatomical patterns. The result
of these models is an interpretable 3D grading map capable of indicating
abnormal brain regions. This map can also be exploited in various
classification tasks using graph convolutional neural network. Finally, we
propose to combine deep grading and atrophy-based classifications to improve
dementia type discrimination. The proposed framework showed competitive
performance compared to state-of-the-art methods for different tasks of disease
detection and differential diagnosis.</p>
  </details>
</details>
<details>
  <summary>73. <b>标题：Subsurface Depths Structure Maps Reconstruction with Generative  Adversarial Networks</b></summary>
  <p><b>编号</b>：[321]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07388</p>
  <p><b>作者</b>：Dmitry Ivlev</p>
  <p><b>备注</b>：12 pages, 12 figures, 1 table</p>
  <p><b>关键词</b>：detailed-resolution depth structure, seismic surveys, seismic depth maps, seismic maps, depth structure maps</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper described a method for reconstruction of detailed-resolution depth
structure maps, usually obtained after the 3D seismic surveys, using the data
from 2D seismic depth maps. The method uses two algorithms based on the
generative-adversarial neural network architecture. The first algorithm
StyleGAN2-ADA accumulates in the hidden space of the neural network the
semantic images of mountainous terrain forms first, and then with help of
transfer learning, in the ideal case - the structure geometry of stratigraphic
horizons. The second algorithm, the Pixel2Style2Pixel encoder, using the
semantic level of generalization of the first algorithm, learns to reconstruct
the original high-resolution images from their degraded copies
(super-resolution technology). There was demonstrated a methodological approach
to transferring knowledge on the structural forms of stratigraphic horizon
boundaries from the well-studied areas to the underexplored ones. Using the
multimodal synthesis of Pixel2Style2Pixel encoder, it is proposed to create a
probabilistic depth space, where each point of the project area is represented
by the density of probabilistic depth distribution of equally probable
reconstructed geological forms of structural images. Assessment of the
reconstruction quality was carried out for two blocks. Using this method,
credible detailed depth reconstructions comparable with the quality of 3D
seismic maps have been obtained from 2D seismic maps.</p>
  </details>
</details>
<details>
  <summary>74. <b>标题：Seeking Common Ground While Reserving Differences: Multiple Anatomy  Collaborative Framework for Undersampled MRI Reconstruction</b></summary>
  <p><b>编号</b>：[325]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07364</p>
  <p><b>作者</b>：Yan Jiangpeng,  Yu Chenghui,  Chen Hanbo,  Xu Zhe,  Huang Junzhou,  Li Xiu,  Yao Jianhua</p>
  <p><b>备注</b>：submitted to an IEEE journal</p>
  <p><b>关键词</b>：advanced undersampled Magnetic, greatly advanced undersampled, undersampled Magnetic, greatly advanced, advanced undersampled</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recently, deep neural networks have greatly advanced undersampled Magnetic
Resonance Image (MRI) reconstruction, wherein most studies follow the
one-anatomy-one-network fashion, i.e., each expert network is trained and
evaluated for a specific anatomy. Apart from inefficiency in training multiple
independent models, such convention ignores the shared de-aliasing knowledge
across various anatomies which can benefit each other. To explore the shared
knowledge, one naive way is to combine all the data from various anatomies to
train an all-round network. Unfortunately, despite the existence of the shared
de-aliasing knowledge, we reveal that the exclusive knowledge across different
anatomies can deteriorate specific reconstruction targets, yielding overall
performance degradation. Observing this, in this study, we present a novel deep
MRI reconstruction framework with both anatomy-shared and anatomy-specific
parameterized learners, aiming to "seek common ground while reserving
differences" across different anatomies.Particularly, the primary
anatomy-shared learners are exposed to different anatomies to model flourishing
shared knowledge, while the efficient anatomy-specific learners are trained
with their target anatomy for exclusive knowledge. Four different
implementations of anatomy-specific learners are presented and explored on the
top of our framework in two MRI reconstruction networks. Comprehensive
experiments on brain, knee and cardiac MRI datasets demonstrate that three of
these learners are able to enhance reconstruction performance via multiple
anatomy collaborative learning.</p>
  </details>
</details>
<details>
  <summary>75. <b>标题：Super-resolution image display using diffractive decoders</b></summary>
  <p><b>编号</b>：[329]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07281</p>
  <p><b>作者</b>：Cagatay Isil,  Deniz Mengu,  Yifan Zhao,  Anika Tabassum,  Jingxi Li,  Yi Luo,  Mona Jarrahi,  Aydogan Ozcan</p>
  <p><b>备注</b>：26 Pages, 9 Figures</p>
  <p><b>关键词</b>：SBP wavefront modulator, wavefront modulators, low-resolution wavefront modulators, diffractive, low SBP wavefront</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>High-resolution synthesis/projection of images over a large field-of-view
(FOV) is hindered by the restricted space-bandwidth-product (SBP) of wavefront
modulators. We report a deep learning-enabled diffractive display design that
is based on a jointly-trained pair of an electronic encoder and a diffractive
optical decoder to synthesize/project super-resolved images using
low-resolution wavefront modulators. The digital encoder, composed of a trained
convolutional neural network (CNN), rapidly pre-processes the high-resolution
images of interest so that their spatial information is encoded into
low-resolution (LR) modulation patterns, projected via a low SBP wavefront
modulator. The diffractive decoder processes this LR encoded information using
thin transmissive layers that are structured using deep learning to
all-optically synthesize and project super-resolved images at its output FOV.
Our results indicate that this diffractive image display can achieve a
super-resolution factor of ~4, demonstrating a ~16-fold increase in SBP. We
also experimentally validate the success of this diffractive super-resolution
display using 3D-printed diffractive decoders that operate at the THz spectrum.
This diffractive image decoder can be scaled to operate at visible wavelengths
and inspire the design of large FOV and high-resolution displays that are
compact, low-power, and computationally efficient.</p>
  </details>
</details>
<details>
  <summary>76. <b>标题：ERNAS: An Evolutionary Neural Architecture Search for Magnetic Resonance  Image Reconstructions</b></summary>
  <p><b>编号</b>：[330]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07280</p>
  <p><b>作者</b>：Samira Vafay Eslahi,  Jian Tao,  Jim Ji</p>
  <p><b>备注</b>：11 pages, 9 figures, and 4 tables</p>
  <p><b>关键词</b>：Magnetic resonance imaging, noninvasive imaging modalities, Magnetic resonance, MRI, resonance imaging</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Magnetic resonance imaging (MRI) is one of the noninvasive imaging modalities
that can produce high-quality images. However, the scan procedure is relatively
slow, which causes patient discomfort and motion artifacts in images.
Accelerating MRI hardware is constrained by physical and physiological
limitations. A popular alternative approach to accelerated MRI is to
undersample the k-space data. While undersampling speeds up the scan procedure,
it generates artifacts in the images, and advanced reconstruction algorithms
are needed to produce artifact-free images. Recently deep learning has emerged
as a promising MRI reconstruction method to address this problem. However,
straightforward adoption of the existing deep learning neural network
architectures in MRI reconstructions is not usually optimal in terms of
efficiency and reconstruction quality. In this work, MRI reconstruction from
undersampled data was carried out using an optimized neural network using a
novel evolutionary neural architecture search algorithm. Brain and knee MRI
datasets show that the proposed algorithm outperforms manually designed neural
network-based MR reconstruction models.</p>
  </details>
</details>
<details>
  <summary>77. <b>标题：A Projection-Based K-space Transformer Network for Undersampled Radial  MRI Reconstruction with Limited Training Subjects</b></summary>
  <p><b>编号</b>：[337]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07219</p>
  <p><b>作者</b>：Chang Gao,  Shu-Fu Shih,  J. Paul Finn,  Xiaodong Zhong</p>
  <p><b>备注</b>：Accepted at MICCAI 2022</p>
  <p><b>关键词</b>：compressed sensing enables, enables fast reconstruction, sensing enables fast, Cartesian k-space trajectories, deep learning combined</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The recent development of deep learning combined with compressed sensing
enables fast reconstruction of undersampled MR images and has achieved
state-of-the-art performance for Cartesian k-space trajectories. However,
non-Cartesian trajectories such as the radial trajectory need to be transformed
onto a Cartesian grid in each iteration of the network training, slowing down
the training process and posing inconvenience and delay during training.
Multiple iterations of nonuniform Fourier transform in the networks offset the
deep learning advantage of fast inference. Current approaches typically either
work on image-to-image networks or grid the non-Cartesian trajectories before
the network training to avoid the repeated gridding process. However, the
image-to-image networks cannot ensure the k-space data consistency in the
reconstructed images and the pre-processing of non-Cartesian k-space leads to
gridding errors which cannot be compensated by the network training. Inspired
by the Transformer network to handle long-range dependencies in sequence
transduction tasks, we propose to rearrange the radial spokes to sequential
data based on the chronological order of acquisition and use the Transformer to
predict unacquired radial spokes from acquired ones. We propose novel data
augmentation methods to generate a large amount of training data from a limited
number of subjects. The network can be generated to different anatomical
structures. Experimental results show superior performance of the proposed
framework compared to state-of-the-art deep neural networks.</p>
  </details>
</details>
<details>
  <summary>78. <b>标题：Federated Multi-organ Segmentation with Partially Labeled Data</b></summary>
  <p><b>编号</b>：[339]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07156</p>
  <p><b>作者</b>：Xuanang Xu,  Pingkun Yan</p>
  <p><b>备注</b>：10 pages, 5 figures</p>
  <p><b>关键词</b>：medical image analysis, emerging paradigm allowing, paradigm allowing large-scale, allowing large-scale decentralized, large-scale decentralized learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Federated learning is an emerging paradigm allowing large-scale decentralized
learning without sharing data across different data owners, which helps address
the concern of data privacy in medical image analysis. However, the requirement
for label consistency across clients by the existing methods largely narrows
its application scope. In practice, each clinical site may only annotate
certain organs of interest with partial or no overlap with other sites.
Incorporating such partially labeled data into a unified federation is an
unexplored problem with clinical significance and urgency. This work tackles
the challenge by using a novel federated multi-encoding U-Net (Fed-MENU) method
for multi-organ segmentation. In our method, a multi-encoding U-Net (MENU-Net)
is proposed to extract organ-specific features through different encoding
sub-networks. Each sub-network can be seen as an expert of a specific organ and
trained for that client. Moreover, to encourage the organ-specific features
extracted by different sub-networks to be informative and distinctive, we
regularize the training of the MENU-Net by designing an auxiliary generic
decoder (AGD). Extensive experiments on four public datasets show that our
Fed-MENU method can effectively obtain a federated learning model using the
partially labeled datasets with superior performance to other models trained by
either localized or centralized learning methods. Source code will be made
publicly available at the time of paper publication.</p>
  </details>
</details>
<details>
  <summary>79. <b>标题：Loss Functions for Classification using Structured Entropy</b></summary>
  <p><b>编号</b>：[341]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07122</p>
  <p><b>作者</b>：Brian Lucena</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：train classification models, gradient boosting, models in deep, deep learning, learning and gradient</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Cross-entropy loss is the standard metric used to train classification models
in deep learning and gradient boosting. It is well-known that this loss
function fails to account for similarities between the different values of the
target. We propose a generalization of entropy called {\em structured entropy}
which uses a random partition to incorporate the structure of the target
variable in a manner which retains many theoretical properties of standard
entropy. We show that a structured cross-entropy loss yields better results on
several classification problems where the target variable has an a priori known
structure. The approach is simple, flexible, easily computable, and does not
rely on a hierarchically defined notion of structure.</p>
  </details>
</details>
<h1>自然语言处理</h1>
<details>
  <summary>1. <b>标题：Prefix Language Models are Unified Modal Learners</b></summary>
  <p><b>编号</b>：[9]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07699</p>
  <p><b>作者</b>：Shizhe Diao,  Wangchunshu Zhou,  Xinsong Zhang,  Jiawei Wang</p>
  <p><b>备注</b>：22 pages, 3 figures</p>
  <p><b>关键词</b>：pushed on multi-modal, generation, COCO image generation, pre-training, pre-training paradigm</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>With the success of vision-language pre-training, we have witnessed the
state-of-the-art has been pushed on multi-modal understanding and generation.
However, the current pre-training paradigm is either incapable of targeting all
modalities at once (e.g., text generation and image generation), or requires
multi-fold well-designed tasks which significantly limits the scalability. We
demonstrate that a unified modal model could be learned with a prefix language
modeling objective upon text and image sequences. Thanks to the simple but
powerful pre-training paradigm, our proposed model, DaVinci, is simple to
train, scalable to huge data, and adaptable to a variety of downstream tasks
across modalities (language / vision / vision+language), types (understanding /
generation) and settings (e.g., zero-shot, fine-tuning, linear evaluation) with
a single unified architecture. DaVinci achieves the competitive performance on
a wide range of 26 understanding / generation tasks, and outperforms previous
unified vision-language models on most tasks, including ImageNet classification
(+1.6%), VQAv2 (+1.4%), COCO caption generation (BLEU@4 +1.1%, CIDEr +1.5%) and
COCO image generation (IS +0.9%, FID -1.0%), at the comparable model and data
scale. Furthermore, we offer a well-defined benchmark for future research by
reporting the performance on different scales of the pre-training dataset on a
heterogeneous and wide distribution coverage. Our results establish new,
stronger baselines for future comparisons at different data scales and shed
light on the difficulties of comparing VLP models more generally.</p>
  </details>
</details>
<details>
  <summary>2. <b>标题：DIRECTOR: Generator-Classifiers For Supervised Language Modeling</b></summary>
  <p><b>编号</b>：[13]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07694</p>
  <p><b>作者</b>：Kushal Arora,  Kurt Shuster,  Sainbayar Sukhbaatar,  Jason Weston</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：achieve low perplexity, repetitiveness and contradictions, models achieve low, toxic responses, Current language models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Current language models achieve low perplexity but their resulting
generations still suffer from toxic responses, repetitiveness and
contradictions. The standard language modeling setup fails to address these
issues. In this paper, we introduce a new architecture, {\sc Director}, that
consists of a unified generator-classifier with both a language modeling and a
classification head for each output token. Training is conducted jointly using
both standard language modeling data, and data labeled with desirable and
undesirable sequences. Experiments in several settings show that the model has
competitive training and decoding speed compared to standard language models
while yielding superior results, alleviating known issues while maintaining
generation quality. It also outperforms existing model guiding approaches in
terms of both accuracy and efficiency.</p>
  </details>
</details>
<details>
  <summary>3. <b>标题：Emergent Abilities of Large Language Models</b></summary>
  <p><b>编号</b>：[20]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07682</p>
  <p><b>作者</b>：Jason Wei,  Yi Tay,  Rishi Bommasani,  Colin Raffel,  Barret Zoph,  Sebastian Borgeaud,  Dani Yogatama,  Maarten Bosma,  Denny Zhou,  Donald Metzler,  Ed H. Chi,  Tatsunori Hashimoto,  Oriol Vinyals,  Percy Liang,  Jeff Dean,  William Fedus</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：predictably improve performance, downstream tasks, shown to predictably, predictably improve, sample efficiency</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Scaling up language models has been shown to predictably improve performance
and sample efficiency on a wide range of downstream tasks. This paper instead
discusses an unpredictable phenomenon that we refer to as emergent abilities of
large language models. We consider an ability to be emergent if it is not
present in smaller models but is present in larger models. Thus, emergent
abilities cannot be predicted simply by extrapolating the performance of
smaller models. The existence of such emergence implies that additional scaling
could further expand the range of capabilities of language models.</p>
  </details>
</details>
<details>
  <summary>4. <b>标题：A Unified Sequence Interface for Vision Tasks</b></summary>
  <p><b>编号</b>：[25]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07669</p>
  <p><b>作者</b>：Ting Chen,  Saurabh Saxena,  Lala Li,  Tsung-Yi Lin,  David J. Fleet,  Geoffrey Hinton</p>
  <p><b>备注</b>：The first three authors contributed equally</p>
  <p><b>关键词</b>：modeling framework, naturally expressed, computer vision tasks, computer vision, vision tasks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>While language tasks are naturally expressed in a single, unified, modeling
framework, i.e., generating sequences of tokens, this has not been the case in
computer vision. As a result, there is a proliferation of distinct
architectures and loss functions for different vision tasks. In this work we
show that a diverse set of "core" computer vision tasks can also be unified if
formulated in terms of a shared pixel-to-sequence interface. We focus on four
tasks, namely, object detection, instance segmentation, keypoint detection, and
image captioning, all with diverse types of outputs, e.g., bounding boxes or
dense masks. Despite that, by formulating the output of each task as a sequence
of discrete tokens with a unified interface, we show that one can train a
neural network with a single model architecture and loss function on all these
tasks, with no task-specific customization. To solve a specific task, we use a
short prompt as task description, and the sequence output adapts to the prompt
so it can produce task-specific output. We show that such a model can achieve
competitive performance compared to well-established task-specific models.</p>
  </details>
</details>
<details>
  <summary>5. <b>标题：Transformer-based Automatic Speech Recognition of Formal and Colloquial  Czech in MALACH Project</b></summary>
  <p><b>编号</b>：[27]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07666</p>
  <p><b>作者</b>：Jan Lehečka,  Josef V. Psutka,  Josef Psutka</p>
  <p><b>备注</b>：to be published in Proceedings of TSD 2022</p>
  <p><b>关键词</b>：specific language due, large differences, colloquial speech, colloquial, ASR systems</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Czech is a very specific language due to its large differences between the
formal and the colloquial form of speech. While the formal (written) form is
used mainly in official documents, literature, and public speeches, the
colloquial (spoken) form is used widely among people in casual speeches. This
gap introduces serious problems for ASR systems, especially when training or
evaluating ASR models on datasets containing a lot of colloquial speech, such
as the MALACH project. In this paper, we are addressing this problem in the
light of a new paradigm in end-to-end ASR systems -- recently introduced
self-supervised audio Transformers. Specifically, we are investigating the
influence of colloquial speech on the performance of Wav2Vec 2.0 models and
their ability to transcribe colloquial speech directly into formal transcripts.
We are presenting results with both formal and colloquial forms in the training
transcripts, language models, and evaluation transcripts.</p>
  </details>
</details>
<details>
  <summary>6. <b>标题：Coarse-to-Fine Vision-Language Pre-training with Fusion in the Backbone</b></summary>
  <p><b>编号</b>：[33]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07643</p>
  <p><b>作者</b>：Zi-Yi Dou,  Aishwarya Kamath,  Zhe Gan,  Pengchuan Zhang,  Jianfeng Wang,  Linjie Li,  Zicheng Liu,  Ce Liu,  Yann LeCun,  Nanyun Peng,  Jianfeng Gao,  Lijuan Wang</p>
  <p><b>备注</b>：Project Website: this https URL</p>
  <p><b>关键词</b>：received considerable attention, recently received considerable, considerable attention, recently received, received considerable</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Vision-language (VL) pre-training has recently received considerable
attention. However, most existing end-to-end pre-training approaches either
only aim to tackle VL tasks such as image-text retrieval, visual question
answering (VQA) and image captioning that test high-level understanding of
images, or only target region-level understanding for tasks such as phrase
grounding and object detection. We present FIBER (Fusion-In-the-Backbone-based
transformER), a new VL model architecture that can seamlessly handle both these
types of tasks. Instead of having dedicated transformer layers for fusion after
the uni-modal backbones, FIBER pushes multimodal fusion deep into the model by
inserting cross-attention into the image and text backbones, bringing gains in
terms of memory and performance. In addition, unlike previous work that is
either only pre-trained on image-text data or on fine-grained data with
box-level annotations, we present a two-stage pre-training strategy that uses
both these kinds of data efficiently: (i) coarse-grained pre-training based on
image-text data; followed by (ii) fine-grained pre-training based on
image-text-box data. We conduct comprehensive experiments on a wide range of VL
tasks, ranging from VQA, image captioning, and retrieval, to phrase grounding,
referring expression comprehension, and object detection. Using deep multimodal
fusion coupled with the two-stage pre-training, FIBER provides consistent
performance improvements over strong baselines across all tasks, often
outperforming methods using magnitudes more data. Code is available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>7. <b>标题：Exploring Capabilities of Monolingual Audio Transformers using Large  Datasets in Automatic Speech Recognition of Czech</b></summary>
  <p><b>编号</b>：[41]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07627</p>
  <p><b>作者</b>：Jan Lehečka,  Jan Švec,  Aleš Pražák,  Josef V. Psutka</p>
  <p><b>备注</b>：to be published in Proceedings of INTERSPEECH 2022</p>
  <p><b>关键词</b>：thousand hours, pretraining Czech monolingual, Czech monolingual audio, automatic speech recognition, pretraining Czech</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we present our progress in pretraining Czech monolingual audio
transformers from a large dataset containing more than 80 thousand hours of
unlabeled speech, and subsequently fine-tuning the model on automatic speech
recognition tasks using a combination of in-domain data and almost 6 thousand
hours of out-of-domain transcribed speech. We are presenting a large palette of
experiments with various fine-tuning setups evaluated on two public datasets
(CommonVoice and VoxPopuli) and one extremely challenging dataset from the
MALACH project. Our results show that monolingual Wav2Vec 2.0 models are robust
ASR systems, which can take advantage of large labeled and unlabeled datasets
and successfully compete with state-of-the-art LVCSR systems. Moreover, Wav2Vec
models proved to be good zero-shot learners when no training data are available
for the target ASR task.</p>
  </details>
</details>
<details>
  <summary>8. <b>标题：The SIGMORPHON 2022 Shared Task on Morpheme Segmentation</b></summary>
  <p><b>编号</b>：[44]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07615</p>
  <p><b>作者</b>：Khuyagbaatar Batsuren,  Gábor Bella,  Aryaman Arora,  Viktor Martinović,  Kyle Gorman,  Zdeněk Žabokrtský,  Amarsanaa Ganbold,  Šárka Dohnalová,  Magda Ševčíková,  Kateřina Pelegrinová,  Fausto Giunchiglia,  Ryan Cotterell,  Ekaterina Vylomova</p>
  <p><b>备注</b>：The 19th SIGMORPHON Workshop on Computational Research in Phonetics, Phonology, and Morphology</p>
  <p><b>关键词</b>：morpheme segmentation challenged, shared task, segmentation challenged systems, morpheme segmentation, word-level morpheme segmentation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The SIGMORPHON 2022 shared task on morpheme segmentation challenged systems
to decompose a word into a sequence of morphemes and covered most types of
morphology: compounds, derivations, and inflections. Subtask 1, word-level
morpheme segmentation, covered 5 million words in 9 languages (Czech, English,
Spanish, Hungarian, French, Italian, Russian, Latin, Mongolian) and received 13
system submissions from 7 teams and the best system averaged 97.29% F1 score
across all languages, ranging English (93.84%) to Latin (99.38%). Subtask 2,
sentence-level morpheme segmentation, covered 18,735 sentences in 3 languages
(Czech, English, Mongolian), received 10 system submissions from 3 teams, and
the best systems outperformed all three state-of-the-art subword tokenization
methods (BPE, ULM, Morfessor2) by 30.71% absolute. To facilitate error analysis
and support any type of future studies, we released all system predictions, the
evaluation script, and all gold standard datasets.</p>
  </details>
</details>
<details>
  <summary>9. <b>标题：HICEM: A High-Coverage Emotion Model for Artificial Emotional  Intelligence</b></summary>
  <p><b>编号</b>：[47]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07593</p>
  <p><b>作者</b>：Benjamin Wortman,  James Z. Wang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：artificial emotional intelligence, intelligent machines enter, taking center stage, address users' desire, meaningful human-machine interaction</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As social robots and other intelligent machines enter the home, artificial
emotional intelligence (AEI) is taking center stage to address users' desire
for deeper, more meaningful human-machine interaction. To accomplish such
efficacious interaction, the next-generation AEI need comprehensive human
emotion models for training. Unlike theory of emotion, which has been the
historical focus in psychology, emotion models are a descriptive tools. In
practice, the strongest models need robust coverage, which means defining the
smallest core set of emotions from which all others can be derived. To achieve
the desired coverage, we turn to word embeddings from natural language
processing. Using unsupervised clustering techniques, our experiments show that
with as few as 15 discrete emotion categories, we can provide maximum coverage
across six major languages--Arabic, Chinese, English, French, Spanish, and
Russian. In support of our findings, we also examine annotations from two
large-scale emotion recognition datasets to assess the validity of existing
emotion models compared to human perception at scale. Because robust,
comprehensive emotion models are foundational for developing real-world
affective computing applications, this work has broad implications in social
robotics, human-machine interaction, mental healthcare, and computational
psychology.</p>
  </details>
</details>
<details>
  <summary>10. <b>标题：AMR Alignment: Paying Attention to Cross-Attention</b></summary>
  <p><b>编号</b>：[49]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07587</p>
  <p><b>作者</b>：Pere-Lluís Huguet Cabot,  Abelardo Carlos Martínez Lorenzo,  Roberto Navigli</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：surge of Transformer, Transformer models, Abstract Meaning Representation, attention acts, learned representations</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>With the surge of Transformer models, many have investigated how attention
acts on the learned representations. However, attention is still overlooked for
specific tasks, such as Semantic Parsing. A popular approach to the formal
representation of a sentence's meaning is Abstract Meaning Representation
(AMR). Until now, the alignment between a sentence and its AMR representation
has been explored in different ways, such as through rules or via the
Expectation Maximization (EM) algorithm. In this paper, we investigate the
ability of Transformer-based parsing models to yield effective alignments
without ad-hoc strategies. We present the first in-depth exploration of
cross-attention for AMR by proxy of alignment between the sentence spans and
the semantic units in the graph. We show how current Transformer-based parsers
implicitly encode the alignment information in the cross-attention weights and
how to leverage it to extract such alignment. Furthermore, we supervise and
guide cross-attention using alignment, dropping the need for English- and
AMR-specific rules.</p>
  </details>
</details>
<details>
  <summary>11. <b>标题：Contextualization and Generalization in Entity and Relation Extraction</b></summary>
  <p><b>编号</b>：[63]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07558</p>
  <p><b>作者</b>：Bruno Taillé</p>
  <p><b>备注</b>：PhD Thesis, 122 pages</p>
  <p><b>关键词</b>：prominent in Natural, past decade, neural networks, Natural, Models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>During the past decade, neural networks have become prominent in Natural
Language Processing (NLP), notably for their capacity to learn relevant word
representations from large unlabeled corpora. These word embeddings can then be
transferred and finetuned for diverse end applications during a supervised
training phase. More recently, in 2018, the transfer of entire pretrained
Language Models and the preservation of their contextualization capacities
enabled to reach unprecedented performance on virtually every NLP benchmark,
sometimes even outperforming human baselines. However, as models reach such
impressive scores, their comprehension abilities still appear as shallow, which
reveal limitations of benchmarks to provide useful insights on their factors of
performance and to accurately measure understanding capabilities.
In this thesis, we study the behaviour of state-of-the-art models regarding
generalization to facts unseen during training in two important Information
Extraction tasks: Named Entity Recognition (NER) and Relation Extraction (RE).
Indeed, traditional benchmarks present important lexical overlap between
mentions and relations used for training and evaluating models, whereas the
main interest of Information Extraction is to extract previously unknown
information. We propose empirical studies to separate performance based on
mention and relation overlap with the training set and find that pretrained
Language Models are mainly beneficial to detect unseen mentions, in particular
out-of-domain. While this makes them suited for real use cases, there is still
a gap in performance between seen and unseen mentions that hurts generalization
to new facts. In particular, even state-of-the-art ERE models rely on a shallow
retention heuristic, basing their prediction more on arguments surface forms
than context.</p>
  </details>
</details>
<details>
  <summary>12. <b>标题：KGEA: A Knowledge Graph Enhanced Article Quality Identification Dataset</b></summary>
  <p><b>编号</b>：[65]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07556</p>
  <p><b>作者</b>：Chunhui Ai,  Derui Wang,  Yang Xu,  Wenrui Xie,  Ziqiang Cao</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：social media, urgent task, task to screen, screen this data, quality</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>With so many articles of varying quality being produced at every moment, it
is a very urgent task to screen this data for quality articles and commit them
out to social media. It is worth noting that high quality articles have many
characteristics, such as relevance, text quality, straightforward, multi-sided,
background, novelty and sentiment. Thus, it would be inadequate to purely use
the content of an article to identify its quality. Therefore, we plan to use
the external knowledge interaction to refine the performance and propose a
knowledge graph enhanced article quality identification dataset (KGEA) based on
Baidu Encyclopedia. We quantified the articles through 7 dimensions and use
co-occurrence of the entities between the articles and the Baidu encyclopedia
to construct the knowledge graph for every article. We also compared some text
classification baselines and found that external knowledge can guide the
articles to a more competitive classification with the graph neural networks.</p>
  </details>
</details>
<details>
  <summary>13. <b>标题：MPI: Evaluating and Inducing Personality in Pre-trained Language Models</b></summary>
  <p><b>编号</b>：[70]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07550</p>
  <p><b>作者</b>：Guangyuan Jiang,  Manjie Xu,  Song-Chun Zhu,  Wenjuan Han,  Chi Zhang,  Yixin Zhu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：personality, philosophical quest, terms of thinking, discerns how individuals, individuals differ</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Originated as a philosophical quest, personality discerns how individuals
differ from each other in terms of thinking, feeling, and behaving. Towards
building social machines that work with humans on a daily basis, we are
motivated to ask: (1) Do existing pre-trained language models possess
personality, akin to their human counterpart? If so, (2) how can we evaluate
them? Further, given this evaluation framework, (3) how can we induce a certain
personality in a fully controllable fashion? To tackle these three questions,
we propose the Machine Personality Inventory (MPI) dataset for evaluating the
machine personality; MPI follows standardized personality tests, built upon the
Big Five Personality Factors (Big Five) theory and personality assessment
inventories. By evaluating models with MPI, we provide the first piece of
evidence showing the existence of personality in pre-trained language models.
We further devise a Chain Prompting method to induce the language model with a
specific personality in a controllable manner, capable of producing diversified
behaviors. We hope to shed light on future studies by adopting personality as
the essential psychological guidance for various downstream tasks, building
more human-like and in situ dialogue agents.</p>
  </details>
</details>
<details>
  <summary>14. <b>标题：BaIT: Barometer for Information Trustworthiness</b></summary>
  <p><b>编号</b>：[74]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07535</p>
  <p><b>作者</b>：Oisín Nolan,  Jeroen van Mourik,  Callum Tilbury</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：similar NLP tasks, natural language inference, pre-trained encoder models, neural network architectures, involves employing pre-trained</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper presents a new approach to the FNC-1 fake news classification task
which involves employing pre-trained encoder models from similar NLP tasks,
namely sentence similarity and natural language inference, and two neural
network architectures using this approach are proposed. Methods in data
augmentation are explored as a means of tackling class imbalance in the
dataset, employing common pre-existing methods and proposing a method for
sample generation in the under-represented class using a novel sentence
negation algorithm. Comparable overall performance with existing baselines is
achieved, while significantly increasing accuracy on an under-represented but
nonetheless important class for FNC-1.</p>
  </details>
</details>
<details>
  <summary>15. <b>标题：Estimating Confidence of Predictions of Individual Classifiers and Their  Ensembles for the Genre Classification Task</b></summary>
  <p><b>编号</b>：[111]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07427</p>
  <p><b>作者</b>：Mikhail Lepekhin,  Serge Sharoff</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Genre identification, non-topical text classification, including non-topical classification, demonstrate SOTA results, classification</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Genre identification is a subclass of non-topical text classification. The
main difference between this task and topical classification is that genres,
unlike topics, usually do not correspond to simple keywords, and thus they need
to be defined in terms of their functions in communication. Neural models based
on pre-trained transformers, such as BERT or XLM-RoBERTa, demonstrate SOTA
results in many NLP tasks, including non-topical classification. However, in
many cases, their downstream application to very large corpora, such as those
extracted from social media, can lead to unreliable results because of dataset
shifts, when some raw texts do not match the profile of the training set. To
mitigate this problem, we experiment with individual models as well as with
their ensembles. To evaluate the robustness of all models we use a prediction
confidence metric, which estimates the reliability of a prediction in the
absence of a gold standard label. We can evaluate robustness via the confidence
gap between the correctly classified texts and the misclassified ones on a
labeled test corpus, higher gaps make it easier to improve our confidence that
our classifier made the right decision. Our results show that for all of the
classifiers tested in this study, there is a confidence gap, but for the
ensembles, the gap is bigger, meaning that ensembles are more robust than their
individual models.</p>
  </details>
</details>
<details>
  <summary>16. <b>标题：Sparse Structure Search for Parameter-Efficient Tuning</b></summary>
  <p><b>编号</b>：[127]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07382</p>
  <p><b>作者</b>：Shengding Hu,  Zhen Zhang,  Ning Ding,  Yadao Wang,  Yasheng Wang,  Zhiyuan Liu,  Maosong Sun</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：large pre-trained models, Adapting large pre-trained, imposes prohibitive computational, fine-tuning imposes prohibitive, PET</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Adapting large pre-trained models (PTMs) through fine-tuning imposes
prohibitive computational and storage burdens. Recent studies of
parameter-efficient tuning (PET) find that only optimizing a small portion of
parameters conditioned on PTMs could yield on-par performance compared to
conventional fine-tuning. Generally, PET methods exquisitely design
parameter-efficient modules (PET modules) which could be applied to arbitrary
fine-grained positions inside PTMs. However, the effectiveness of these
fine-grained positions largely relies on sophisticated manual designation,
thereby usually producing sub-optimal results. In contrast to the manual
designation, we explore constructing PET modules in an automatic manner. We
automatically \textbf{S}earch for the \textbf{S}parse \textbf{S}tructure of
\textbf{P}arameter-\textbf{E}fficient \textbf{T}uning (S$^3$PET). Based on a
unified framework of various PET methods, S$^3$PET conducts the differentiable
PET structure search through bi-level optimization and proposes shifted global
sigmoid method to explicitly control the number of trainable parameters.
Extensive experiments show that S$^3$PET surpasses manual and random structures
with less trainable parameters. The searched structures preserve more than 99\%
fine-tuning performance with 0.01\% trainable parameters. Moreover, the
advantage of S$^3$PET is amplified with extremely low trainable parameters
budgets (0.0009\%$\sim$0.01\%). The searched structures are transferable and
explainable, providing suggestions and guidance for the future design of PET
methods.</p>
  </details>
</details>
<details>
  <summary>17. <b>标题：NatiQ: An End-to-end Text-to-Speech System for Arabic</b></summary>
  <p><b>编号</b>：[131]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07373</p>
  <p><b>作者</b>：Ahmed Abdelali,  Nadir Durrani,  Cenk Demiroglu,  Fahim Dalvi,  Hamdy Mubarak,  Kareem Darwish</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Arabic, system for Arabic, vocoder, Opinion Score, WER and CER</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>NatiQ is end-to-end text-to-speech system for Arabic. Our speech synthesizer
uses an encoder-decoder architecture with attention. We used both
tacotron-based models (tacotron-1 and tacotron-2) and the faster transformer
model for generating mel-spectrograms from characters. We concatenated
Tacotron1 with the WaveRNN vocoder, Tacotron2 with the WaveGlow vocoder and
ESPnet transformer with the parallel wavegan vocoder to synthesize waveforms
from the spectrograms. We used in-house speech data for two voices: 1) neutral
male "Hamza"- narrating general content and news, and 2) expressive female
"Amina"- narrating children story books to train our models. Our best systems
achieve an average Mean Opinion Score (MOS) of 4.21 and 4.40 for Amina and
Hamza respectively. The objective evaluation of the systems using word and
character error rate (WER and CER) as well as the response time measured by
real-time factor favored the end-to-end architecture ESPnet. NatiQ demo is
available on-line at this https URL</p>
  </details>
</details>
<details>
  <summary>18. <b>标题：SciTweets -- A Dataset and Annotation Framework for Detecting Scientific  Online Discourse</b></summary>
  <p><b>编号</b>：[137]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07360</p>
  <p><b>作者</b>：Salim Hafid,  Sebastian Schellhammer,  Sandra Bringay,  Konstantin Todorov,  Stefan Dietze</p>
  <p><b>备注</b>：submitted to CIKM 2022</p>
  <p><b>关键词</b>：include discourse related, online discourse, resources are increasingly, increasingly debated, prominent examples include</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Scientific topics, claims and resources are increasingly debated as part of
online discourse, where prominent examples include discourse related to
COVID-19 or climate change. This has led to both significant societal impact
and increased interest in scientific online discourse from various disciplines.
For instance, communication studies aim at a deeper understanding of biases,
quality or spreading pattern of scientific information whereas computational
methods have been proposed to extract, classify or verify scientific claims
using NLP and IR techniques. However, research across disciplines currently
suffers from both a lack of robust definitions of the various forms of
science-relatedness as well as appropriate ground truth data for distinguishing
them. In this work, we contribute (a) an annotation framework and corresponding
definitions for different forms of scientific relatedness of online discourse
in Tweets, (b) an expert-annotated dataset of 1261 tweets obtained through our
labeling framework reaching an average Fleiss Kappa $\kappa$ of 0.63, (c) a
multi-label classifier trained on our data able to detect science-relatedness
with 89% F1 and also able to detect distinct forms of scientific knowledge
(claims, references). With this work we aim to lay the foundation for
developing and evaluating robust methods for analysing science as part of
large-scale online discourse.</p>
  </details>
</details>
<details>
  <summary>19. <b>标题：The Emotion is Not One-hot Encoding: Learning with Grayscale Label for  Emotion Recognition in Conversation</b></summary>
  <p><b>编号</b>：[138]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07359</p>
  <p><b>作者</b>：Joosung Lee</p>
  <p><b>备注</b>：Accepted by INTERSPEECH 2022</p>
  <p><b>关键词</b>：natural language processing, language processing tasks, current utterance, utterance is predicted, natural language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In emotion recognition in conversation (ERC), the emotion of the current
utterance is predicted by considering the previous context, which can be
utilized in many natural language processing tasks. Although multiple emotions
can coexist in a given sentence, most previous approaches take the perspective
of a classification task to predict only a given label. However, it is
expensive and difficult to label the emotion of a sentence with confidence or
multi-label. In this paper, we automatically construct a grayscale label
considering the correlation between emotions and use it for learning. That is,
instead of using a given label as a one-hot encoding, we construct a grayscale
label by measuring scores for different emotions. We introduce several methods
for constructing grayscale labels and confirm that each method improves the
emotion recognition performance. Our method is simple, effective, and
universally applicable to previous systems. The experiments show a significant
improvement in the performance of baselines.</p>
  </details>
</details>
<details>
  <summary>20. <b>标题：A Survey : Neural Networks for AMR-to-Text</b></summary>
  <p><b>编号</b>：[154]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07328</p>
  <p><b>作者</b>：Hongyu Hao,  Guangtong Li,  Zhiming Hu,  Huafeng Wang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Abstract Meaning Representation, Meaning Representation, Abstract Meaning, NLP community, community that aims</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>AMR-to-text is one of the key techniques in the NLP community that aims at
generating sentences from the Abstract Meaning Representation (AMR) graphs.
Since AMR was proposed in 2013, the study on AMR-to-Text has become
increasingly prevalent as an essential branch of structured data to text
because of the unique advantages of AMR as a high-level semantic description of
natural language. In this paper, we provide a brief survey of AMR-to-Text.
Firstly, we introduce the current scenario of this technique and point out its
difficulties. Secondly, based on the methods used in previous studies, we
roughly divided them into five categories according to their respective
mechanisms, i.e., Rules-based, Seq-to-Seq-based, Graph-to-Seq-based,
Transformer-based, and Pre-trained Language Model (PLM)-based. In particular,
we detail the neural network-based method and present the latest progress of
AMR-to-Text, which refers to AMR reconstruction, Decoder optimization, etc.
Furthermore, we present the benchmarks and evaluation methods of AMR-to-Text.
Eventually, we provide a summary of current techniques and the outlook for
future research.</p>
  </details>
</details>
<details>
  <summary>21. <b>标题：CMNEROne at SemEval-2022 Task 11: Code-Mixed Named Entity Recognition by  leveraging multilingual data</b></summary>
  <p><b>编号</b>：[160]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07318</p>
  <p><b>作者</b>：Suman Dowlagar,  Radhika Mamidi</p>
  <p><b>备注</b>：SemEval 2022 Task 11: MultiCoNER Multilingual Complex Named Entity Recognition, NAACL, 2022</p>
  <p><b>关键词</b>：Natural Language Processing, Language Processing, Natural Language, Named Entity Recognition, field of Natural</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Identifying named entities is, in general, a practical and challenging task
in the field of Natural Language Processing. Named Entity Recognition on the
code-mixed text is further challenging due to the linguistic complexity
resulting from the nature of the mixing. This paper addresses the submission of
team CMNEROne to the SEMEVAL 2022 shared task 11 MultiCoNER. The Code-mixed NER
task aimed to identify named entities on the code-mixed dataset. Our work
consists of Named Entity Recognition (NER) on the code-mixed dataset by
leveraging the multilingual data. We achieved a weighted average F1 score of
0.7044, i.e., 6% greater than the baseline.</p>
  </details>
</details>
<details>
  <summary>22. <b>标题：Knowledge Management System with NLP-Assisted Annotations: A Brief  Survey and Outlook</b></summary>
  <p><b>编号</b>：[167]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07304</p>
  <p><b>作者</b>：Baihan Lin</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：industrial researchers, high demand, demand for industrial, evidence-based decision making, decision making</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Knowledge management systems are in high demand for industrial researchers,
chemical or research enterprises, or evidence-based decision making. However,
existing systems have limitations in categorizing and organizing paper insights
or relationships. Traditional databases are usually disjoint with logging
systems, which limit its utility in generating concise, collated overviews. In
this work, we briefly survey existing approaches of this problem space and
propose a unified framework that utilizes relational databases to log
hierarchical information to facilitate the research and writing process, or
generate useful knowledge from references or insights from connected concepts.
This framework of knowledge management system enables novel functionalities
encompassing improved hierarchical notetaking, AI-assisted brainstorming, and
multi-directional relationships. Potential applications include managing
inventories and changes for manufacture or research enterprises, or generating
analytic reports with evidence-based decision making.</p>
  </details>
</details>
<details>
  <summary>23. <b>标题：Enhanced Knowledge Selection for Grounded Dialogues via Document  Semantic Graphs</b></summary>
  <p><b>编号</b>：[171]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07296</p>
  <p><b>作者</b>：Sha Li,  Madhi Namazifar,  Di Jin,  Mohit Bansal,  Heng Ji,  Yang Liu,  Dilek Hakkani-Tur</p>
  <p><b>备注</b>：NAACL 2022. Please refer to this https URL for code and resources</p>
  <p><b>关键词</b>：make open-domain dialogues, Providing conversation models, Providing conversation, informative and engaging, shown to make</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Providing conversation models with background knowledge has been shown to
make open-domain dialogues more informative and engaging. Existing models treat
knowledge selection as a sentence ranking or classification problem where each
sentence is handled individually, ignoring the internal semantic connection
among sentences in the background document. In this work, we propose to
automatically convert the background knowledge documents into document semantic
graphs and then perform knowledge selection over such graphs. Our document
semantic graphs preserve sentence-level information through the use of sentence
nodes and provide concept connections between sentences. We jointly apply
multi-task learning for sentence-level and concept-level knowledge selection
and show that it improves sentence-level selection. Our experiments show that
our semantic graph-based knowledge selection improves over sentence selection
baselines for both the knowledge selection task and the end-to-end response
generation task on HollE and improves generalization on unseen topics in WoW.</p>
  </details>
</details>
<details>
  <summary>24. <b>标题：Human Heuristics for AI-Generated Language Are Flawed</b></summary>
  <p><b>编号</b>：[185]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07271</p>
  <p><b>作者</b>：Maurice Jakesch,  Jeffrey Hancock,  Mor Naaman</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：language, communication is increasingly, increasingly intermixed, Human, generated</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Human communication is increasingly intermixed with language generated by AI.
Across chat, email, and social media, AI systems produce smart replies,
autocompletes, and translations. AI-generated language is often not identified
as such but poses as human language, raising concerns about novel forms of
deception and manipulation. Here, we study how humans discern whether one of
the most personal and consequential forms of language - a self-presentation -
was generated by AI. Across six experiments, participants (N = 4,650) tried to
identify self-presentations generated by state-of-the-art language models.
Across professional, hospitality, and romantic settings, we find that humans
are unable to identify AI-generated self-presentations. Combining qualitative
analyses with language feature engineering, we find that human judgments of
AI-generated language are handicapped by intuitive but flawed heuristics such
as associating first-person pronouns, authentic words, or family topics with
humanity. We show that these heuristics make human judgment of generated
language predictable and manipulable, allowing AI systems to produce language
perceived as more human than human. We conclude by discussing solutions - such
as AI accents or fair use policies - to reduce the deceptive potential of
generated language, limiting the subversion of human intuition.</p>
  </details>
</details>
<details>
  <summary>25. <b>标题：Born for Auto-Tagging: Faster and better with new objective functions</b></summary>
  <p><b>编号</b>：[189]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07264</p>
  <p><b>作者</b>：Chiung-ju Liu,  Huang-Ting Shieh</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Keyword extraction, text mining, task of text, SEO and ads, scores</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Keyword extraction is a task of text mining. It is applied to increase search
volume in SEO and ads. Implemented in auto-tagging, it makes tagging on a mass
scale of online articles and photos efficiently and accurately. BAT is invented
for auto-tagging which served as awoo's AI marketing platform (AMP). awoo AMP
not only provides service as a customized recommender system but also increases
the converting rate in E-commerce. The strength of BAT converges faster and
better than other SOTA models, as its 4-layer structure achieves the best F
scores at 50 epochs. In other words, it performs better than other models which
require deeper layers at 100 epochs. To generate rich and clean tags, awoo
creates new objective functions to maintain similar ${\rm F_1}$ scores with
cross-entropy while enhancing ${\rm F_2}$ scores simultaneously. To assure the
even better performance of F scores awoo revamps the learning rate strategy
proposed by Transformer \cite{Transformer} to increase ${\rm F_1}$ and ${\rm
F_2}$ scores at the same time.</p>
  </details>
</details>
<details>
  <summary>26. <b>标题：TeKo: Text-Rich Graph Neural Networks with External Knowledge</b></summary>
  <p><b>编号</b>：[194]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07253</p>
  <p><b>作者</b>：Zhizhi Yu,  Di Jin,  Jianguo Wei,  Ziyang Liu,  Yue Shang,  Yun Xiao,  Jiawei Han,  Lingfei Wu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：gained great popularity, textual semantics, graph-structured data, network, gained great</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Graph Neural Networks (GNNs) have gained great popularity in tackling various
analytical tasks on graph-structured data (i.e., networks). Typical GNNs and
their variants follow a message-passing manner that obtains network
representations by the feature propagation process along network topology,
which however ignore the rich textual semantics (e.g., local word-sequence)
that exist in many real-world networks. Existing methods for text-rich networks
integrate textual semantics by mainly utilizing internal information such as
topics or phrases/words, which often suffer from an inability to
comprehensively mine the text semantics, limiting the reciprocal guidance
between network structure and text semantics. To address these problems, we
propose a novel text-rich graph neural network with external knowledge (TeKo),
in order to take full advantage of both structural and textual information
within text-rich networks. Specifically, we first present a flexible
heterogeneous semantic network that incorporates high-quality entities and
interactions among documents and entities. We then introduce two types of
external knowledge, that is, structured triplets and unstructured entity
description, to gain a deeper insight into textual semantics. We further design
a reciprocal convolutional mechanism for the constructed heterogeneous semantic
network, enabling network structure and textual semantics to collaboratively
enhance each other and learn high-level network representations. Extensive
experimental results on four public text-rich networks as well as a large-scale
e-commerce searching dataset illustrate the superior performance of TeKo over
state-of-the-art baselines.</p>
  </details>
</details>
<details>
  <summary>27. <b>标题：Location-based Twitter Filtering for the Creation of Low-Resource  Language Datasets in Indonesian Local Languages</b></summary>
  <p><b>编号</b>：[203]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07238</p>
  <p><b>作者</b>：Mukhlis Amien,  Chong Feng,  Heyan Huang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：real world, abundance of linguistic, linguistic data, local Indonesian, Indonesian</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Twitter contains an abundance of linguistic data from the real world. We
examine Twitter for user-generated content in low-resource languages such as
local Indonesian. For NLP to work in Indonesian, it must consider local
dialects, geographic context, and regional culture influence Indonesian
languages. This paper identifies the problems we faced when constructing a
Local Indonesian NLP dataset. Furthermore, we are developing a framework for
creating, collecting, and classifying Local Indonesian datasets for NLP. Using
twitter's geolocation tool for automatic annotating.</p>
  </details>
</details>
<details>
  <summary>28. <b>标题：Multimodal Event Graphs: Towards Event Centric Understanding of  Multimodal World</b></summary>
  <p><b>编号</b>：[215]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07207</p>
  <p><b>作者</b>：Hammad A. Ayyubi,  Christopher Thomas,  Lovish Chum,  Rahul Lokesh,  Yulei Niu,  Xudong Lin,  Long Chen,  Jaywon Koo,  Sounak Ray,  Shih-Fu Chang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：multimedia content relate, developing robust artificially, robust artificially intelligent, artificially intelligent systems, real-world media</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Understanding how events described or shown in multimedia content relate to
one another is a critical component to developing robust artificially
intelligent systems which can reason about real-world media. While much
research has been devoted to event understanding in the text, image, and video
domains, none have explored the complex relations that events experience across
domains. For example, a news article may describe a `protest' event while a
video shows an `arrest' event. Recognizing that the visual `arrest' event is a
subevent of the broader `protest' event is a challenging, yet important problem
that prior work has not explored. In this paper, we propose the novel task of
MultiModal Event Event Relations to recognize such cross-modal event relations.
We contribute a large-scale dataset consisting of 100k video-news article
pairs, as well as a benchmark of densely annotated data. We also propose a
weakly supervised multimodal method which integrates commonsense knowledge from
an external knowledge base (KB) to predict rich multimodal event hierarchies.
Experiments show that our model outperforms a number of competitive baselines
on our proposed benchmark. We also perform a detailed analysis of our model's
performance and suggest directions for future research.</p>
  </details>
</details>
<details>
  <summary>29. <b>标题：Codec at SemEval-2022 Task 5: Multi-Modal Multi-Transformer Misogynous  Meme Classification Framework</b></summary>
  <p><b>编号</b>：[224]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07190</p>
  <p><b>作者</b>：Ahmed Mahran,  Carlo Alessandro Borella,  Konstantinos Perifanos</p>
  <p><b>备注</b>：Accepted for publication at the 16th International Workshop on Semantic Evaluation, Task 5: MAMI - Multimedia Automatic Misogyny Identification co-located with NAACL 2022</p>
  <p><b>关键词</b>：Multimedia Automatic Misogyny, Automatic Misogyny Identification, Multimedia Automatic, Misogyny Identification, Automatic Misogyny</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper we describe our work towards building a generic framework for
both multi-modal embedding and multi-label binary classification tasks, while
participating in task 5 (Multimedia Automatic Misogyny Identification) of
SemEval 2022 competition.
Since pretraining deep models from scratch is a resource and data hungry
task, our approach is based on three main strategies. We combine different
state-of-the-art architectures to capture a wide spectrum of semantic signals
from the multi-modal input. We employ a multi-task learning scheme to be able
to use multiple datasets from the same knowledge domain to help increase the
model's performance. We also use multiple objectives to regularize and fine
tune different system components.</p>
  </details>
</details>
<details>
  <summary>30. <b>标题：Frequency-centroid features for word recognition of non-native English  speakers</b></summary>
  <p><b>编号</b>：[231]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07176</p>
  <p><b>作者</b>：Pierre Berjon,  Rajib Sharma,  Avishek Nag,  Soumyabrata Dev</p>
  <p><b>备注</b>：Published in IEEE Irish Signals & Systems Conference (ISSC), 2022</p>
  <p><b>关键词</b>：quintessential Mel frequency, Mel frequency cepstral, frequency cepstral coefficients, non-native English speakers, limited set word</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The objective of this work is to investigate complementary features which can
aid the quintessential Mel frequency cepstral coefficients (MFCCs) in the task
of closed, limited set word recognition for non-native English speakers of
different mother-tongues. Unlike the MFCCs, which are derived from the spectral
energy of the speech signal, the proposed frequency-centroids (FCs) encapsulate
the spectral centres of the different bands of the speech spectrum, with the
bands defined by the Mel filterbank. These features, in combination with the
MFCCs, are observed to provide relative performance improvement in English word
recognition, particularly under varied noisy conditions. A two-stage
Convolution Neural Network (CNN) is used to model the features of the English
words uttered with Arabic, French and Spanish accents.</p>
  </details>
</details>
<details>
  <summary>31. <b>标题：Understanding Narratives through Dimensions of Analogy</b></summary>
  <p><b>编号</b>：[236]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07167</p>
  <p><b>作者</b>：Thiloshon Nagarajah,  Filip Ilievski,  Jay Pujara</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：powerful qualitative reasoning, qualitative reasoning tool, Cognitive Science research, Analogical reasoning, Cognitive Science</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Analogical reasoning is a powerful qualitative reasoning tool that enables
humans to connect two situations, and to generalize their knowledge from
familiar to novel situations. Cognitive Science research provides valuable
insights into the richness and complexity of analogical reasoning, together
with implementations of expressive analogical reasoners with limited
scalability. Modern scalable AI techniques with the potential to reason by
analogy have been only applied to the special case of proportional analogy, and
not to understanding higher-order analogies. In this paper, we aim to bridge
the gap by: 1) formalizing six dimensions of analogy based on mature insights
from Cognitive Science research, 2) annotating a corpus of fables with each of
these dimensions, and 3) defining four tasks with increasing complexity that
enable scalable evaluation of AI techniques. Experiments with language models
and neuro-symbolic AI reasoners on these tasks reveal that state-of-the-art
methods can be applied to reason by analogy with a limited success, motivating
the need for further research towards comprehensive and scalable analogical
reasoning by AI. We make all our code and data available.</p>
  </details>
</details>
<details>
  <summary>32. <b>标题：Automatic Clipping: Differentially Private Deep Learning Made Easier and  Stronger</b></summary>
  <p><b>编号</b>：[251]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07136</p>
  <p><b>作者</b>：Zhiqi Bu,  Yu-Xiang Wang,  Sheng Zha,  George Karypis</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：deep learning models, key algorithmic step, enables practical differential, Per-example gradient clipping, practical differential private</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Per-example gradient clipping is a key algorithmic step that enables
practical differential private (DP) training for deep learning models. The
choice of clipping norm $R$, however, is shown to be vital for achieving high
accuracy under DP. We propose an easy-to-use replacement, called AutoClipping,
that eliminates the need to tune $R$ for any DP optimizers, including DP-SGD,
DP-Adam, DP-LAMB and many others. The automatic variants are as private and
computationally efficient as existing DP optimizers, but require no DP-specific
hyperparameters and thus make DP training as amenable as the standard
non-private training. We give a rigorous convergence analysis of automatic
DP-SGD in the non-convex setting, which shows that it enjoys an asymptotic
convergence rate that matches the standard SGD. We also demonstrate on various
language and vision tasks that automatic clipping outperforms or matches the
state-of-the-art, and can be easily employed with minimal changes to existing
codebases.</p>
  </details>
</details>
<details>
  <summary>33. <b>标题：If it Bleeds, it Leads: A Computational Approach to Covering Crime in  Los Angeles</b></summary>
  <p><b>编号</b>：[257]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07115</p>
  <p><b>作者</b>：Alexander Spangher,  Divya Choudhary</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：improving computational approaches, Los Angeles Police, increase journalistic output, Los Angeles, Developing and improving</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Developing and improving computational approaches to covering news can
increase journalistic output and improve the way stories are covered. In this
work we approach the problem of covering crime stories in Los Angeles. We
present a machine-in-the-loop system that covers individual crimes by (1)
learning the prototypical coverage archetypes from classical news articles on
crime to learn their structure and (2) using output from the Los Angeles Police
department to generate "lede paragraphs", first structural unit of
crime-articles. We introduce a probabilistic graphical model for learning
article structure and a rule-based system for generating ledes. We hope our
work can lead to systems that use these components together to form the
skeletons of news articles covering crime.
This work was done for a class project in Jonathan May's Advanced Natural
Language Processing Course, Fall, 2019.</p>
  </details>
</details>
<details>
  <summary>34. <b>标题：NewsEdits: A News Article Revision Dataset and a Document-Level  Reasoning Challenge</b></summary>
  <p><b>编号</b>：[258]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07106</p>
  <p><b>作者</b>：Alexander Spangher,  Xiang Ren,  Jonathan May,  Nanyun Peng</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：article revision histories, histories provide clues, revision histories, revision histories provide, edit actions</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>News article revision histories provide clues to narrative and factual
evolution in news articles. To facilitate analysis of this evolution, we
present the first publicly available dataset of news revision histories,
NewsEdits. Our dataset is large-scale and multilingual; it contains 1.2 million
articles with 4.6 million versions from over 22 English- and French-language
newspaper sources based in three countries, spanning 15 years of coverage
(2006-2021).
We define article-level edit actions: Addition, Deletion, Edit and Refactor,
and develop a high-accuracy extraction algorithm to identify these actions. To
underscore the factual nature of many edit actions, we conduct analyses showing
that added and deleted sentences are more likely to contain updating events,
main content and quotes than unchanged sentences.
Finally, to explore whether edit actions are predictable, we introduce three
novel tasks aimed at predicting actions performed during version updates. We
show that these tasks are possible for expert humans but are challenging for
large NLP models. We hope this can spur research in narrative framing and help
provide predictive tools for journalists chasing breaking news.</p>
  </details>
</details>
<details>
  <summary>35. <b>标题：A smile is all you need: Predicting limiting activity coefficients from  SMILES with natural language processing</b></summary>
  <p><b>编号</b>：[347]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07048</p>
  <p><b>作者</b>：Benedikt Winter,  Clemens Winter,  Johannes Schilling,  André Bardow</p>
  <p><b>备注</b>：Code available at: this https URL; Data available at: this https URL</p>
  <p><b>关键词</b>：mixtures' phase equilibria, activity coefficients, Knowledge of mixtures', technical chemistry, activity</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Knowledge of mixtures' phase equilibria is crucial in nature and technical
chemistry. Phase equilibria calculations of mixtures require activity
coefficients. However, experimental data on activity coefficients is often
limited due to high cost of experiments. For an accurate and efficient
prediction of activity coefficients, machine learning approaches have been
recently developed. However, current machine learning approaches still
extrapolate poorly for activity coefficients of unknown molecules. In this
work, we introduce the SMILES-to-Properties-Transformer (SPT), a natural
language processing network to predict binary limiting activity coefficients
from SMILES codes. To overcome the limitations of available experimental data,
we initially train our network on a large dataset of synthetic data sampled
from COSMO-RS (10 Million data points) and then fine-tune the model on
experimental data (20 870 data points). This training strategy enables SPT to
accurately predict limiting activity coefficients even for unknown molecules,
cutting the mean prediction error in half compared to state-of-the-art models
for activity coefficient predictions such as COSMO-RS, UNIFAC, and improving on
recent machine learning approaches.</p>
  </details>
</details>
<h1>机器学习</h1>
<details>
  <summary>1. <b>标题：Variable Bitrate Neural Fields</b></summary>
  <p><b>编号</b>：[4]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07707</p>
  <p><b>作者</b>：Towaki Takikawa,  Alex Evans,  Jonathan Tremblay,  Thomas Müller,  Morgan McGuire,  Alec Jacobson,  Sanja Fidler</p>
  <p><b>备注</b>：SIGGRAPH 2022. Project Page: this https URL</p>
  <p><b>关键词</b>：signed distance functions, vector fields, radiance fields, emerged as accurate, scalar and vector</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Neural approximations of scalar and vector fields, such as signed distance
functions and radiance fields, have emerged as accurate, high-quality
representations. State-of-the-art results are obtained by conditioning a neural
approximation with a lookup from trainable feature grids that take on part of
the learning task and allow for smaller, more efficient neural networks.
Unfortunately, these feature grids usually come at the cost of significantly
increased memory consumption compared to stand-alone neural network models. We
present a dictionary method for compressing such feature grids, reducing their
memory consumption by up to 100x and permitting a multiresolution
representation which can be useful for out-of-core streaming. We formulate the
dictionary optimization as a vector-quantized auto-decoder problem which lets
us learn end-to-end discrete neural representations in a space where no direct
supervision is available and with dynamic topology and structure. Our source
code will be available at this https URL.</p>
  </details>
</details>
<details>
  <summary>2. <b>标题：Masked Frequency Modeling for Self-Supervised Visual Pre-Training</b></summary>
  <p><b>编号</b>：[5]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07706</p>
  <p><b>作者</b>：Jiahao Xie,  Wei Li,  Xiaohang Zhan,  Ziwei Liu,  Yew Soon Ong,  Chen Change Loy</p>
  <p><b>备注</b>：Project page: this https URL</p>
  <p><b>关键词</b>：present Masked Frequency, Masked Frequency Modeling, self-supervised pre-training, pre-training of visual, Frequency</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present Masked Frequency Modeling (MFM), a unified frequency-domain-based
approach for self-supervised pre-training of visual models. Instead of randomly
inserting mask tokens to the input embeddings in the spatial domain, in this
paper, we shift the perspective to the frequency domain. Specifically, MFM
first masks out a portion of frequency components of the input image and then
predicts the missing frequencies on the frequency spectrum. Our key insight is
that predicting masked components in the frequency domain is more ideal to
reveal underlying image patterns rather than predicting masked patches in the
spatial domain, due to the heavy spatial redundancy. Our findings suggest that
with the right configuration of mask-and-predict strategy, both the structural
information within high-frequency components and the low-level statistics among
low-frequency counterparts are useful in learning good representations. For the
first time, MFM demonstrates that, for both ViT and CNN, a simple non-Siamese
framework can learn meaningful representations even using none of the
following: (i) extra data, (ii) extra model, (iii) mask token. Experimental
results on ImageNet and several robustness benchmarks show the competitive
performance and advanced robustness of MFM compared with recent masked image
modeling approaches. Furthermore, we also comprehensively investigate the
effectiveness of classical image restoration tasks for representation learning
from a unified frequency perspective and reveal their intriguing relations with
our MFM approach. Project page:
this https URL.</p>
  </details>
</details>
<details>
  <summary>3. <b>标题：Masked Siamese ConvNets</b></summary>
  <p><b>编号</b>：[8]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07700</p>
  <p><b>作者</b>：Li Jing,  Jiachen Zhu,  Yann LeCun</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：shown superior performances, shown superior, superior performances, performances over supervised, Self-supervised learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Self-supervised learning has shown superior performances over supervised
methods on various vision benchmarks. The siamese network, which encourages
embeddings to be invariant to distortions, is one of the most successful
self-supervised visual representation learning approaches. Among all the
augmentation methods, masking is the most general and straightforward method
that has the potential to be applied to all kinds of input and requires the
least amount of domain knowledge. However, masked siamese networks require
particular inductive bias and practically only work well with Vision
Transformers. This work empirically studies the problems behind masked siamese
networks with ConvNets. We propose several empirical designs to overcome these
problems gradually. Our method performs competitively on low-shot image
classification and outperforms previous methods on object detection benchmarks.
We discuss several remaining issues and hope this work can provide useful data
points for future general-purpose self-supervised learning.</p>
  </details>
</details>
<details>
  <summary>4. <b>标题：Prefix Language Models are Unified Modal Learners</b></summary>
  <p><b>编号</b>：[9]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07699</p>
  <p><b>作者</b>：Shizhe Diao,  Wangchunshu Zhou,  Xinsong Zhang,  Jiawei Wang</p>
  <p><b>备注</b>：22 pages, 3 figures</p>
  <p><b>关键词</b>：pushed on multi-modal, generation, COCO image generation, pre-training, pre-training paradigm</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>With the success of vision-language pre-training, we have witnessed the
state-of-the-art has been pushed on multi-modal understanding and generation.
However, the current pre-training paradigm is either incapable of targeting all
modalities at once (e.g., text generation and image generation), or requires
multi-fold well-designed tasks which significantly limits the scalability. We
demonstrate that a unified modal model could be learned with a prefix language
modeling objective upon text and image sequences. Thanks to the simple but
powerful pre-training paradigm, our proposed model, DaVinci, is simple to
train, scalable to huge data, and adaptable to a variety of downstream tasks
across modalities (language / vision / vision+language), types (understanding /
generation) and settings (e.g., zero-shot, fine-tuning, linear evaluation) with
a single unified architecture. DaVinci achieves the competitive performance on
a wide range of 26 understanding / generation tasks, and outperforms previous
unified vision-language models on most tasks, including ImageNet classification
(+1.6%), VQAv2 (+1.4%), COCO caption generation (BLEU@4 +1.1%, CIDEr +1.5%) and
COCO image generation (IS +0.9%, FID -1.0%), at the comparable model and data
scale. Furthermore, we offer a well-defined benchmark for future research by
reporting the performance on different scales of the pre-training dataset on a
heterogeneous and wide distribution coverage. Our results establish new,
stronger baselines for future comparisons at different data scales and shed
light on the difficulties of comparing VLP models more generally.</p>
  </details>
</details>
<details>
  <summary>5. <b>标题：Diffusion Models for Video Prediction and Infilling</b></summary>
  <p><b>编号</b>：[11]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07696</p>
  <p><b>作者</b>：Tobias Höppe,  Arash Mehrjou,  Stefan Bauer,  Didrik Nielsen,  Andrea Dittadi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：make intelligent decisions, anticipate future outcomes, intelligent decisions, predict and anticipate, anticipate future</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>To predict and anticipate future outcomes or reason about missing information
in a sequence is a key ability for agents to be able to make intelligent
decisions. This requires strong temporally coherent generative capabilities.
Diffusion models have shown huge success in several generative tasks lately,
but have not been extensively explored in the video domain. We present
Random-Mask Video Diffusion (RaMViD), which extends image diffusion models to
videos using 3D convolutions, and introduces a new conditioning technique
during training. By varying the mask we condition on, the model is able to
perform video prediction, infilling and upsampling. Since we do not use
concatenation to condition on a mask, as done in most conditionally trained
diffusion models, we are able to decrease the memory footprint. We evaluated
the model on two benchmark datasets for video prediction and one for video
generation on which we achieved competitive results. On Kinetics-600 we
achieved state-of-the-art for video prediction.</p>
  </details>
</details>
<details>
  <summary>6. <b>标题：ELUDE: Generating interpretable explanations via a decomposition into  labelled and unlabelled features</b></summary>
  <p><b>编号</b>：[15]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07690</p>
  <p><b>作者</b>：Vikram V. Ramaswamy,  Sunnie S. Y. Kim,  Nicole Meister,  Ruth Fong,  Olga Russakovsky</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：achieved remarkable success, Deep learning models, machine learning, past decade, difficult to understand</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep learning models have achieved remarkable success in different areas of
machine learning over the past decade; however, the size and complexity of
these models make them difficult to understand. In an effort to make them more
interpretable, several recent works focus on explaining parts of a deep neural
network through human-interpretable, semantic attributes. However, it may be
impossible to completely explain complex models using only semantic attributes.
In this work, we propose to augment these attributes with a small set of
uninterpretable features. Specifically, we develop a novel explanation
framework ELUDE (Explanation via Labelled and Unlabelled DEcomposition) that
decomposes a model's prediction into two parts: one that is explainable through
a linear combination of the semantic attributes, and another that is dependent
on the set of uninterpretable features. By identifying the latter, we are able
to analyze the "unexplained" portion of the model, obtaining insights into the
information used by the model. We show that the set of unlabelled features can
generalize to multiple models trained with the same feature space and compare
our work to two popular attribute-oriented methods, Interpretable Basis
Decomposition and Concept Bottleneck, and discuss the additional insights ELUDE
provides.</p>
  </details>
</details>
<details>
  <summary>7. <b>标题：Learning to Accelerate Partial Differential Equations via Latent Global  Evolution</b></summary>
  <p><b>编号</b>：[21]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07681</p>
  <p><b>作者</b>：Tailin Wu,  Takashi Maruyama,  Jure Leskovec</p>
  <p><b>备注</b>：25 pages, 13 figures</p>
  <p><b>关键词</b>：Partial Differential Equations, Differential Equations, Partial Differential, inverse optimization problems, weather forecasting</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Simulating the time evolution of Partial Differential Equations (PDEs) of
large-scale systems is crucial in many scientific and engineering domains such
as fluid dynamics, weather forecasting and their inverse optimization problems.
However, both classical solvers and recent deep learning-based surrogate models
are typically extremely computationally intensive, because of their local
evolution: they need to update the state of each discretized cell at each time
step during inference. Here we develop Latent Evolution of PDEs (LE-PDE), a
simple, fast and scalable method to accelerate the simulation and inverse
optimization of PDEs. LE-PDE learns a compact, global representation of the
system and efficiently evolves it fully in the latent space with learned latent
evolution models. LE-PDE achieves speed-up by having a much smaller latent
dimension to update during long rollout as compared to updating in the input
space. We introduce new learning objectives to effectively learn such latent
dynamics to ensure long-term stability. We further introduce techniques for
speeding-up inverse optimization of boundary conditions for PDEs via
backpropagation through time in latent space, and an annealing technique to
address the non-differentiability and sparse interaction of boundary
conditions. We test our method in a 1D benchmark of nonlinear PDEs, 2D
Navier-Stokes flows into turbulent phase and an inverse optimization of
boundary conditions in 2D Navier-Stokes flow. Compared to state-of-the-art deep
learning-based surrogate models and other strong baselines, we demonstrate up
to 128x reduction in the dimensions to update, and up to 15x improvement in
speed, while achieving competitive accuracy.</p>
  </details>
</details>
<details>
  <summary>8. <b>标题：Learning Large-scale Subsurface Simulations with a Hybrid Graph Network  Simulator</b></summary>
  <p><b>编号</b>：[22]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07680</p>
  <p><b>作者</b>：Tailin Wu,  Qinchen Wang,  Yinan Zhang,  Rex Ying,  Kaidi Cao,  Rok Sosič,  Ridwan Jalali,  Hassan Hamam,  Marko Maucec,  Jure Leskovec</p>
  <p><b>备注</b>：SIGKDD 2022; 11 pages, 6 figures</p>
  <p><b>关键词</b>：porous media, models, model, model complex reservoir, HGNS</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Subsurface simulations use computational models to predict the flow of fluids
(e.g., oil, water, gas) through porous media. These simulations are pivotal in
industrial applications such as petroleum production, where fast and accurate
models are needed for high-stake decision making, for example, for well
placement optimization and field development planning. Classical finite
difference numerical simulators require massive computational resources to
model large-scale real-world reservoirs. Alternatively, streamline simulators
and data-driven surrogate models are computationally more efficient by relying
on approximate physics models, however they are insufficient to model complex
reservoir dynamics at scale. Here we introduce Hybrid Graph Network Simulator
(HGNS), which is a data-driven surrogate model for learning reservoir
simulations of 3D subsurface fluid flows. To model complex reservoir dynamics
at both local and global scale, HGNS consists of a subsurface graph neural
network (SGNN) to model the evolution of fluid flows, and a 3D-U-Net to model
the evolution of pressure. HGNS is able to scale to grids with millions of
cells per time step, two orders of magnitude higher than previous surrogate
models, and can accurately predict the fluid flow for tens of time steps (years
into the future). Using an industry-standard subsurface flow dataset (SPE-10)
with 1.1 million cells, we demonstrate that HGNS is able to reduce the
inference time up to 18 times compared to standard subsurface simulators, and
that it outperforms other learning-based models by reducing long-term
prediction errors by up to 21%.</p>
  </details>
</details>
<details>
  <summary>9. <b>标题：A Unified Sequence Interface for Vision Tasks</b></summary>
  <p><b>编号</b>：[25]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07669</p>
  <p><b>作者</b>：Ting Chen,  Saurabh Saxena,  Lala Li,  Tsung-Yi Lin,  David J. Fleet,  Geoffrey Hinton</p>
  <p><b>备注</b>：The first three authors contributed equally</p>
  <p><b>关键词</b>：modeling framework, naturally expressed, computer vision tasks, computer vision, vision tasks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>While language tasks are naturally expressed in a single, unified, modeling
framework, i.e., generating sequences of tokens, this has not been the case in
computer vision. As a result, there is a proliferation of distinct
architectures and loss functions for different vision tasks. In this work we
show that a diverse set of "core" computer vision tasks can also be unified if
formulated in terms of a shared pixel-to-sequence interface. We focus on four
tasks, namely, object detection, instance segmentation, keypoint detection, and
image captioning, all with diverse types of outputs, e.g., bounding boxes or
dense masks. Despite that, by formulating the output of each task as a sequence
of discrete tokens with a unified interface, we show that one can train a
neural network with a single model architecture and loss function on all these
tasks, with no task-specific customization. To solve a specific task, we use a
short prompt as task description, and the sequence output adapts to the prompt
so it can produce task-specific output. We show that such a model can achieve
competitive performance compared to well-established task-specific models.</p>
  </details>
</details>
<details>
  <summary>10. <b>标题：Model-based RL with Optimistic Posterior Sampling: Structural Conditions  and Sample Complexity</b></summary>
  <p><b>编号</b>：[30]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07659</p>
  <p><b>作者</b>：Alekh Agarwal,  Tong Zhang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：posterior sampling methods, Hellinger distance, Hellinger distance based, posterior sampling, sampling methods</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose a general framework to design posterior sampling methods for
model-based RL. We show that the proposed algorithms can be analyzed by
reducing regret to Hellinger distance based conditional probability estimation.
We further show that optimistic posterior sampling can control this Hellinger
distance, when we measure model error via data likelihood. This technique
allows us to design and analyze unified posterior sampling algorithms with
state-of-the-art sample complexity guarantees for many model-based RL settings.
We illustrate our general result in many special cases, demonstrating the
versatility of our framework.</p>
  </details>
</details>
<details>
  <summary>11. <b>标题：Experimental Validation of Spectral-Spatial Power Evolution Design Using  Raman Amplifiers</b></summary>
  <p><b>编号</b>：[31]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07658</p>
  <p><b>作者</b>：Mehran Soltani,  Francesco Da Ros,  Andrea Carena,  Darko Zibar</p>
  <p><b>备注</b>：4 pages, 5 figures</p>
  <p><b>关键词</b>：signal power evolution, machine learning-enabled Raman, Raman amplification framework, learning-enabled Raman amplification, capable of jointly</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We experimentally validate a machine learning-enabled Raman amplification
framework, capable of jointly shaping the signal power evolution in two
domains: frequency and fiber distance. The proposed experiment addresses the
amplification in the whole C-band, by optimizing four first-order
counter-propagating Raman pumps.</p>
  </details>
</details>
<details>
  <summary>12. <b>标题：Hyperparameter Sensitivity in Deep Outlier Detection: Analysis and a  Scalable Hyper-Ensemble Solution</b></summary>
  <p><b>编号</b>：[32]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07647</p>
  <p><b>作者</b>：Xueying Ding,  Lingxiao Zhao,  Leman Akoglu</p>
  <p><b>备注</b>：19 pages, 11 figures, 9 tables</p>
  <p><b>关键词</b>：exhibits numerous algorithms, literature exhibits numerous, diverse domains, exhibits numerous, applies to diverse</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Outlier detection (OD) literature exhibits numerous algorithms as it applies
to diverse domains. However, given a new detection task, it is unclear how to
choose an algorithm to use, nor how to set its hyperparameter(s) (HPs) in
unsupervised settings. HP tuning is an ever-growing problem with the arrival of
many new detectors based on deep learning. While they have appealing properties
such as task- driven representation learning and end-to-end optimization, deep
models come with a long list of HPs. Surprisingly, the issue of model selection
in the outlier mining literature has been "the elephant in the room"; a
significant factor in unlocking the utmost potential of deep methods, yet
little said or done to systematically tackle the issue. In the first part of
this paper, we conduct the first large-scale analysis on the HP sensitivity of
deep OD methods, and through more than 35,000 trained models, quantitatively
demonstrate that model selection is inevitable. Next, we design a HP-robust and
scalable deep hyper-ensemble model called ROBOD that assembles models with
varying HP configurations, bypassing the choice paralysis. Importantly, we
introduce novel strategies to speed up ensemble training, such as parameter
sharing, batch/simultaneous training, and data subsampling, that allow us to
train fewer models with fewer parameters. Extensive experiments on both image
and tabular datasets show that ROBOD achieves and retains robust,
state-of-the-art detection performance as compared to its modern counterparts,
while taking only 2-10% of the time by the naive hyper-ensemble with
independent training.</p>
  </details>
</details>
<details>
  <summary>13. <b>标题：Coarse-to-Fine Vision-Language Pre-training with Fusion in the Backbone</b></summary>
  <p><b>编号</b>：[33]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07643</p>
  <p><b>作者</b>：Zi-Yi Dou,  Aishwarya Kamath,  Zhe Gan,  Pengchuan Zhang,  Jianfeng Wang,  Linjie Li,  Zicheng Liu,  Ce Liu,  Yann LeCun,  Nanyun Peng,  Jianfeng Gao,  Lijuan Wang</p>
  <p><b>备注</b>：Project Website: this https URL</p>
  <p><b>关键词</b>：received considerable attention, recently received considerable, considerable attention, recently received, received considerable</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Vision-language (VL) pre-training has recently received considerable
attention. However, most existing end-to-end pre-training approaches either
only aim to tackle VL tasks such as image-text retrieval, visual question
answering (VQA) and image captioning that test high-level understanding of
images, or only target region-level understanding for tasks such as phrase
grounding and object detection. We present FIBER (Fusion-In-the-Backbone-based
transformER), a new VL model architecture that can seamlessly handle both these
types of tasks. Instead of having dedicated transformer layers for fusion after
the uni-modal backbones, FIBER pushes multimodal fusion deep into the model by
inserting cross-attention into the image and text backbones, bringing gains in
terms of memory and performance. In addition, unlike previous work that is
either only pre-trained on image-text data or on fine-grained data with
box-level annotations, we present a two-stage pre-training strategy that uses
both these kinds of data efficiently: (i) coarse-grained pre-training based on
image-text data; followed by (ii) fine-grained pre-training based on
image-text-box data. We conduct comprehensive experiments on a wide range of VL
tasks, ranging from VQA, image captioning, and retrieval, to phrase grounding,
referring expression comprehension, and object detection. Using deep multimodal
fusion coupled with the two-stage pre-training, FIBER provides consistent
performance improvements over strong baselines across all tasks, often
outperforming methods using magnitudes more data. Code is available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>14. <b>标题：Convergence and Price of Anarchy Guarantees of the Softmax Policy  Gradient in Markov Potential Games</b></summary>
  <p><b>编号</b>：[34]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07642</p>
  <p><b>作者</b>：Dingyang Chen,  Qi Zhang,  Thinh T. Doan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：policy gradient, policy gradient methods, Markov potential games, policy, POA</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We study the performance of policy gradient methods for the subclass of
Markov games known as Markov potential games (MPGs), which extends the notion
of normal-form potential games to the stateful setting and includes the
important special case of the fully cooperative setting where the agents share
an identical reward function. Our focus in this paper is to study the
convergence of the policy gradient method for solving MPGs under softmax policy
parameterization, both tabular and parameterized with general function
approximators such as neural networks. We first show the asymptotic convergence
of this method to a Nash equilibrium of MPGs for tabular softmax policies.
Second, we derive the finite-time performance of the policy gradient in two
settings: 1) using the log-barrier regularization, and 2) using the natural
policy gradient under the best-response dynamics (NPG-BR). Finally, extending
the notion of price of anarchy (POA) and smoothness in normal-form games, we
introduce the POA for MPGs and provide a POA bound for NPG-BR. To our
knowledge, this is the first POA bound for solving MPGs. To support our
theoretical results, we empirically compare the convergence rates and POA of
policy gradient variants for both tabular and neural softmax policies.</p>
  </details>
</details>
<details>
  <summary>15. <b>标题：Sublinear Algorithms for Hierarchical Clustering</b></summary>
  <p><b>编号</b>：[39]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07633</p>
  <p><b>作者</b>：Arpit Agarwal,  Sanjeev Khanna,  Huan Li,  Prathamesh Patil</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：social network analysis, Hierarchical clustering, social network, network analysis, information retrieval</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Hierarchical clustering over graphs is a fundamental task in data mining and
machine learning with applications in domains such as phylogenetics, social
network analysis, and information retrieval. Specifically, we consider the
recently popularized objective function for hierarchical clustering due to
Dasgupta. Previous algorithms for (approximately) minimizing this objective
function require linear time/space complexity. In many applications the
underlying graph can be massive in size making it computationally challenging
to process the graph even using a linear time/space algorithm. As a result,
there is a strong interest in designing algorithms that can perform global
computation using only sublinear resources. The focus of this work is to study
hierarchical clustering for massive graphs under three well-studied models of
sublinear computation which focus on space, time, and communication,
respectively, as the primary resources to optimize: (1) (dynamic) streaming
model where edges are presented as a stream, (2) query model where the graph is
queried using neighbor and degree queries, (3) MPC model where the graph edges
are partitioned over several machines connected via a communication channel.
We design sublinear algorithms for hierarchical clustering in all three
models above. At the heart of our algorithmic results is a view of the
objective in terms of cuts in the graph, which allows us to use a relaxed
notion of cut sparsifiers to do hierarchical clustering while introducing only
a small distortion in the objective function. Our main algorithmic
contributions are then to show how cut sparsifiers of the desired form can be
efficiently constructed in the query model and the MPC model. We complement our
algorithmic results by establishing nearly matching lower bounds that rule out
the possibility of designing better algorithms in each of these models.</p>
  </details>
</details>
<details>
  <summary>16. <b>标题：Clustered Scheduling and Communication Pipelining For Efficient Resource  Management Of Wireless Federated Learning</b></summary>
  <p><b>编号</b>：[40]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07631</p>
  <p><b>作者</b>：Cihat Keçeci,  Mohammad Shaqfeh,  Fawaz Al-Qahtani,  Muhammad Ismail,  Erchin Serpedin</p>
  <p><b>备注</b>：31 pages, 4 figures</p>
  <p><b>关键词</b>：edge computing applications, spectrum utilization efficiency, mobile edge computing, wireless spectrum utilization, federated learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper proposes using communication pipelining to enhance the wireless
spectrum utilization efficiency and convergence speed of federated learning in
mobile edge computing applications. Due to limited wireless sub-channels, a
subset of the total clients is scheduled in each iteration of federated
learning algorithms. On the other hand, the scheduled clients wait for the
slowest client to finish its computation. We propose to first cluster the
clients based on the time they need per iteration to compute the local
gradients of the federated learning model. Then, we schedule a mixture of
clients from all clusters to send their local updates in a pipelined manner. In
this way, instead of just waiting for the slower clients to finish their
computation, more clients can participate in each iteration. While the time
duration of a single iteration does not change, the proposed method can
significantly reduce the number of required iterations to achieve a target
accuracy. We provide a generic formulation for optimal client clustering under
different settings, and we analytically derive an efficient algorithm for
obtaining the optimal solution. We also provide numerical results to
demonstrate the gains of the proposed method for different datasets and deep
learning architectures.</p>
  </details>
</details>
<details>
  <summary>17. <b>标题：Epistemic Deep Learning</b></summary>
  <p><b>编号</b>：[45]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07609</p>
  <p><b>作者</b>：Shireen Kudukkil Manchingal,  Fabio Cuzzolin</p>
  <p><b>备注</b>：Accepted at ICML 2022 Workshop on Distribution-Free Uncertainty Quantification</p>
  <p><b>关键词</b>：quantification as proposed, uncertainty quantification, epistemic, learning, belief functions</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The belief function approach to uncertainty quantification as proposed in the
Demspter-Shafer theory of evidence is established upon the general mathematical
models for set-valued observations, called random sets. Set-valued predictions
are the most natural representations of uncertainty in machine learning. In
this paper, we introduce a concept called epistemic deep learning based on the
random-set interpretation of belief functions to model epistemic learning in
deep neural networks. We propose a novel random-set convolutional neural
network for classification that produces scores for sets of classes by learning
set-valued ground truth representations. We evaluate different formulations of
entropy and distance measures for belief functions as viable loss functions for
these random-set networks. We also discuss methods for evaluating the quality
of epistemic predictions and the performance of epistemic random-set neural
networks. We demonstrate through experiments that the epistemic approach
produces better performance results when compared to traditional approaches of
estimating uncertainty.</p>
  </details>
</details>
<details>
  <summary>18. <b>标题：ARES: Locally Adaptive Reconstruction-based Anomaly Scoring</b></summary>
  <p><b>编号</b>：[46]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07604</p>
  <p><b>作者</b>：Adam Goodge,  Bryan Hooi,  See Kiong Ng,  Wee Siong Ng</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：significantly differ, set of high-dimensional, images or sensor, high-dimensional data, sensor data</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>How can we detect anomalies: that is, samples that significantly differ from
a given set of high-dimensional data, such as images or sensor data? This is a
practical problem with numerous applications and is also relevant to the goal
of making learning algorithms more robust to unexpected inputs. Autoencoders
are a popular approach, partly due to their simplicity and their ability to
perform dimension reduction. However, the anomaly scoring function is not
adaptive to the natural variation in reconstruction error across the range of
normal samples, which hinders their ability to detect real anomalies. In this
paper, we empirically demonstrate the importance of local adaptivity for
anomaly scoring in experiments with real data. We then propose our novel
Adaptive Reconstruction Error-based Scoring approach, which adapts its scoring
based on the local behaviour of reconstruction error over the latent space. We
show that this improves anomaly detection performance over relevant baselines
in a wide variety of benchmark datasets.</p>
  </details>
</details>
<details>
  <summary>19. <b>标题：Machine Learning is Abduction Inference</b></summary>
  <p><b>编号</b>：[50]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07586</p>
  <p><b>作者</b>：Marina Sapir</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Peirce abduction inference, Gradated Contradictions, form of Peirce, Peirce abduction, abduction inference</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Concept of Abduction with Gradated Contradictions is introduced here as a
form of Peirce's abduction inference. The general form of abduction criterion
is formalized in the proposed Logic of Gradated Contradictions and Logic of
Recursive Aggregation. Common steps of an abduction procedure as minimization
of such a criterion are specified as well. It is demonstrated on examples of 14
popular textbook learners (from hierarchical clustering to k-NN and SVR) that
each of them performs AGC. The proposed theory explains real life learners, yet
it avoids any mention of statistics, so it can be considered as a logical
alternative to the statistical learning theory.</p>
  </details>
</details>
<details>
  <summary>20. <b>标题：NatGen: Generative pre-training by "Naturalizing" source code</b></summary>
  <p><b>编号</b>：[51]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07585</p>
  <p><b>作者</b>：Saikat Chakraborty,  Toufique Ahmed,  Yangruibo Ding,  Premkumar Devanbu,  Baishakhi Ray</p>
  <p><b>备注</b>：Accepted to be published in ESEC/FSE 2022</p>
  <p><b>关键词</b>：yielded strong results, code yielded strong, code, Pre-trained Generative Language, past few years</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Pre-trained Generative Language models (e.g. PLBART, CodeT5, SPT-Code) for
source code yielded strong results on several tasks in the past few years,
including code generation and translation. These models have adopted varying
pre-training objectives to learn statistics of code construction from very
large-scale corpora in a self-supervised fashion; the success of pre-trained
models largely hinges on these pre-training objectives. This paper proposes a
new pre-training objective, "Naturalizing" of source code, exploiting code's
bimodal, dual-channel (formal & natural channels) nature. Unlike natural
language, code's bimodal, dual-channel nature allows us to generate
semantically equivalent code at scale. We introduce six classes of semantic
preserving transformations to introduce un-natural forms of code, and then
force our model to produce more natural original programs written by
developers. Learning to generate equivalent, but more natural code, at scale,
over large corpora of open-source code, without explicit manual supervision,
helps the model learn to both ingest & generate code. We fine-tune our model in
three generative Software Engineering tasks: code generation, code translation,
and code refinement with limited human-curated labeled data and achieve
state-of-the-art performance rivaling CodeT5. We show that our pre-trained
model is especially competitive at zero-shot and few-shot learning, and better
at learning code properties (e.g., syntax, data flow).</p>
  </details>
</details>
<details>
  <summary>21. <b>标题：A Comprehensive Survey on Deep Clustering: Taxonomy, Challenges, and  Future Directions</b></summary>
  <p><b>编号</b>：[54]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07579</p>
  <p><b>作者</b>：Sheng Zhou,  Hongjia Xu,  Zhuonan Zheng,  Jiawei Chen,  Zhao li,  Jiajun Bu,  Jia Wu,  Xin Wang,  Wenwu Zhu,  Martin Ester</p>
  <p><b>备注</b>：Github Repo: this https URL</p>
  <p><b>关键词</b>：Deep Clustering, Clustering, representation learning, representation learning techniques, learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Clustering is a fundamental machine learning task which has been widely
studied in the literature. Classic clustering methods follow the assumption
that data are represented as features in a vectorized form through various
representation learning techniques. As the data become increasingly complicated
and complex, the shallow (traditional) clustering methods can no longer handle
the high-dimensional data type. With the huge success of deep learning,
especially the deep unsupervised learning, many representation learning
techniques with deep architectures have been proposed in the past decade.
Recently, the concept of Deep Clustering, i.e., jointly optimizing the
representation learning and clustering, has been proposed and hence attracted
growing attention in the community. Motivated by the tremendous success of deep
learning in clustering, one of the most fundamental machine learning tasks, and
the large number of recent advances in this direction, in this paper we conduct
a comprehensive survey on deep clustering by proposing a new taxonomy of
different state-of-the-art approaches. We summarize the essential components of
deep clustering and categorize existing methods by the ways they design
interactions between deep representation learning and clustering. Moreover,
this survey also provides the popular benchmark datasets, evaluation metrics
and open-source implementations to clearly illustrate various experimental
settings. Last but not least, we discuss the practical applications of deep
clustering and suggest challenging topics deserving further investigations as
future directions.</p>
  </details>
</details>
<details>
  <summary>22. <b>标题：Calibrating Agent-based Models to Microdata with Graph Neural Networks</b></summary>
  <p><b>编号</b>：[58]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07570</p>
  <p><b>作者</b>：Joel Dyer,  Patrick Cannon,  J. Doyne Farmer,  Sebastian M. Schmon</p>
  <p><b>备注</b>：Accepted for a Spotlight presentation at the ICML 2022 Artificial Intelligence for Agent-based Modelling (AI4ABM) Workshop</p>
  <p><b>关键词</b>：Calibrating agent-based models, Calibrating agent-based, desired purpose, fundamental requirements, requirements to ensure</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Calibrating agent-based models (ABMs) to data is among the most fundamental
requirements to ensure the model fulfils its desired purpose. In recent years,
simulation-based inference methods have emerged as powerful tools for
performing this task when the model likelihood function is intractable, as is
often the case for ABMs. In some real-world use cases of ABMs, both the
observed data and the ABM output consist of the agents' states and their
interactions over time. In such cases, there is a tension between the desire to
make full use of the rich information content of such granular data on the one
hand, and the need to reduce the dimensionality of the data to prevent
difficulties associated with high-dimensional learning tasks on the other. A
possible resolution is to construct lower-dimensional time-series through the
use of summary statistics describing the macrostate of the system at each time
point. However, a poor choice of summary statistics can result in an
unacceptable loss of information from the original dataset, dramatically
reducing the quality of the resulting calibration. In this work, we instead
propose to learn parameter posteriors associated with granular microdata
directly using temporal graph neural networks. We will demonstrate that such an
approach offers highly compelling inductive biases for Bayesian inference using
the raw ABM microstates as output.</p>
  </details>
</details>
<details>
  <summary>23. <b>标题：Contrastive Learning as Goal-Conditioned Reinforcement Learning</b></summary>
  <p><b>编号</b>：[59]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07568</p>
  <p><b>作者</b>：Benjamin Eysenbach,  Tianjun Zhang,  Ruslan Salakhutdinov,  Sergey Levine</p>
  <p><b>备注</b>：Code is available on the website: this https URL</p>
  <p><b>关键词</b>：representation learning, easier to solve, learning, representation learning parts, good representations</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In reinforcement learning (RL), it is easier to solve a task if given a good
representation. While deep RL should automatically acquire such good
representations, prior work often finds that learning representations in an
end-to-end fashion is unstable and instead equip RL algorithms with additional
representation learning parts (e.g., auxiliary losses, data augmentation). How
can we design RL algorithms that directly acquire good representations? In this
paper, instead of adding representation learning parts to an existing RL
algorithm, we show (contrastive) representation learning methods can be cast as
RL algorithms in their own right. To do this, we build upon prior work and
apply contrastive representation learning to action-labeled trajectories, in
such a way that the (inner product of) learned representations exactly
corresponds to a goal-conditioned value function. We use this idea to
reinterpret a prior RL method as performing contrastive learning, and then use
the idea to propose a much simpler method that achieves similar performance.
Across a range of goal-conditioned RL tasks, we demonstrate that contrastive RL
methods achieve higher success rates than prior non-contrastive methods,
including in the offline RL setting. We also show that contrastive RL
outperforms prior methods on image-based tasks, without using data augmentation
or auxiliary objectives.</p>
  </details>
</details>
<details>
  <summary>24. <b>标题：A Meta-Analysis of Distributionally-Robust Models</b></summary>
  <p><b>编号</b>：[61]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07565</p>
  <p><b>作者</b>：Benjamin Feuer,  Ameya Joshi,  Chinmay Hegde</p>
  <p><b>备注</b>：To be presented at ICML Workshop on Principles of Distribution Shift 2022. Copyright 2022 by the author(s)</p>
  <p><b>关键词</b>：image classifiers trained, massive datasets, trained on massive, image classifiers, classifiers trained</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>State-of-the-art image classifiers trained on massive datasets (such as
ImageNet) have been shown to be vulnerable to a range of both intentional and
incidental distribution shifts. On the other hand, several recent classifiers
with favorable out-of-distribution (OOD) robustness properties have emerged,
achieving high accuracy on their target tasks while maintaining their
in-distribution accuracy on challenging benchmarks. We present a meta-analysis
on a wide range of publicly released models, most of which have been published
over the last twelve months. Through this meta-analysis, we empirically
identify four main commonalities for all the best-performing OOD-robust models,
all of which illuminate the considerable promise of vision-language
pre-training.</p>
  </details>
</details>
<details>
  <summary>25. <b>标题：Bayesian Federated Learning via Predictive Distribution Distillation</b></summary>
  <p><b>编号</b>：[62]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07562</p>
  <p><b>作者</b>：Shrey Bhatt,  Aishwarya Gupta,  Piyush Rai</p>
  <p><b>备注</b>：15 pages(9 pages of main content, 2 pages of references, and 4 pages of supplementary content)</p>
  <p><b>关键词</b>：federated learning, Bayesian federated learning, client, federated learning algorithms, federated</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>For most existing federated learning algorithms, each round consists of
minimizing a loss function at each client to learn an optimal model at the
client, followed by aggregating these client models at the server. Point
estimation of the model parameters at the clients does not take into account
the uncertainty in the models estimated at each client. In many situations,
however, especially in limited data settings, it is beneficial to take into
account the uncertainty in the client models for more accurate and robust
predictions. Uncertainty also provides useful information for other important
tasks, such as active learning and out-of-distribution (OOD) detection. We
present a framework for Bayesian federated learning where each client infers
the posterior predictive distribution using its training data and present
various ways to aggregate these client-specific predictive distributions at the
server. Since communicating and aggregating predictive distributions can be
challenging and expensive, our approach is based on distilling each client's
predictive distribution into a single deep neural network. This enables us to
leverage advances in standard federated learning to Bayesian federated learning
as well. Unlike some recent works that have tried to estimate model uncertainty
of each client, our work also does not make any restrictive assumptions, such
as the form of the client's posterior distribution. We evaluate our approach on
classification in federated setting, as well as active learning and OOD
detection in federated settings, on which our approach outperforms various
existing federated learning baselines.</p>
  </details>
</details>
<details>
  <summary>26. <b>标题：On the fast convergence of minibatch heavy ball momentum</b></summary>
  <p><b>编号</b>：[68]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07553</p>
  <p><b>作者</b>：Raghu Bollapragada,  Tyler Chen,  Rachel Ward</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：good practical performance, machine learning optimization, Simple stochastic momentum, stochastic momentum methods, methods are widely</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Simple stochastic momentum methods are widely used in machine learning
optimization, but their good practical performance is at odds with an absence
of theoretical guarantees of acceleration in the literature. In this work, we
aim to close the gap between theory and practice by showing that stochastic
heavy ball momentum, which can be interpreted as a randomized Kaczmarz
algorithm with momentum, retains the fast linear rate of (deterministic) heavy
ball momentum on quadratic optimization problems, at least when minibatching
with a sufficiently large batch size is used. The analysis relies on carefully
decomposing the momentum transition matrix, and using new spectral norm
concentration bounds for products of independent random matrices. We provide
numerical experiments to demonstrate that our bounds are reasonably sharp.</p>
  </details>
</details>
<details>
  <summary>27. <b>标题：Unknown-Aware Domain Adversarial Learning for Open-Set Domain Adaptation</b></summary>
  <p><b>编号</b>：[69]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07551</p>
  <p><b>作者</b>：JoonHo Jang,  Byeonghu Na,  DongHyeok Shin,  Mingi Ji,  Kyungwoo Song,  Il-Chul Moon</p>
  <p><b>备注</b>：9 pages, preprint</p>
  <p><b>关键词</b>：Open-Set Domain Adaptation, textit, Domain Adaptation, domain adversarial learning, domain adversarial</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Open-Set Domain Adaptation (OSDA) assumes that a target domain contains
unknown classes, which are not discovered in a source domain. Existing domain
adversarial learning methods are not suitable for OSDA because distribution
matching with \textit{unknown} classes leads to the negative transfer. Previous
OSDA methods have focused on matching the source and the target distribution by
only utilizing \textit{known} classes. However, this \textit{known}-only
matching may fail to learn the target-\textit{unknown} feature space.
Therefore, we propose Unknown-Aware Domain Adversarial Learning (UADAL), which
\textit{aligns} the source and the targe-\textit{known} distribution while
simultaneously \textit{segregating} the target-\textit{unknown} distribution in
the feature alignment procedure. We provide theoretical analyses on the
optimized state of the proposed \textit{unknown-aware} feature alignment, so we
can guarantee both \textit{alignment} and \textit{segregation} theoretically.
Empirically, we evaluate UADAL on the benchmark datasets, which shows that
UADAL outperforms other methods with better feature alignments by reporting the
state-of-the-art performances.</p>
  </details>
</details>
<details>
  <summary>28. <b>标题：MPI: Evaluating and Inducing Personality in Pre-trained Language Models</b></summary>
  <p><b>编号</b>：[70]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07550</p>
  <p><b>作者</b>：Guangyuan Jiang,  Manjie Xu,  Song-Chun Zhu,  Wenjuan Han,  Chi Zhang,  Yixin Zhu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：personality, philosophical quest, terms of thinking, discerns how individuals, individuals differ</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Originated as a philosophical quest, personality discerns how individuals
differ from each other in terms of thinking, feeling, and behaving. Towards
building social machines that work with humans on a daily basis, we are
motivated to ask: (1) Do existing pre-trained language models possess
personality, akin to their human counterpart? If so, (2) how can we evaluate
them? Further, given this evaluation framework, (3) how can we induce a certain
personality in a fully controllable fashion? To tackle these three questions,
we propose the Machine Personality Inventory (MPI) dataset for evaluating the
machine personality; MPI follows standardized personality tests, built upon the
Big Five Personality Factors (Big Five) theory and personality assessment
inventories. By evaluating models with MPI, we provide the first piece of
evidence showing the existence of personality in pre-trained language models.
We further devise a Chain Prompting method to induce the language model with a
specific personality in a controllable manner, capable of producing diversified
behaviors. We hope to shed light on future studies by adopting personality as
the essential psychological guidance for various downstream tasks, building
more human-like and in situ dialogue agents.</p>
  </details>
</details>
<details>
  <summary>29. <b>标题：Body Gesture Recognition to Control a Social Robot</b></summary>
  <p><b>编号</b>：[72]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07538</p>
  <p><b>作者</b>：Javier Laplaza,  Joan Jaume Oliver,  Ramón Romero,  Alberto Sanfeliu,  Anaís Garrell</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：gesture based language, based language, gesture based, body gesture communication, compare body gesture</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this work, we propose a gesture based language to allow humans to interact
with robots using their body in a natural way. We have created a new gesture
detection model using neural networks and a custom dataset of humans performing
a set of body gestures to train our network. Furthermore, we compare body
gesture communication with other communication channels to acknowledge the
importance of adding this knowledge to robots. The presented approach is
extensively validated in diverse simulations and real-life experiments with
non-trained volunteers. This attains remarkable results and shows that it is a
valuable framework for social robotics applications, such as human robot
collaboration or human-robot interaction.</p>
  </details>
</details>
<details>
  <summary>30. <b>标题：Autonomous Platoon Control with Integrated Deep Reinforcement Learning  and Dynamic Programming</b></summary>
  <p><b>编号</b>：[73]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07536</p>
  <p><b>作者</b>：Tong Liu,  Lei Lei,  Kan Zheng,  Kuan Zhang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Deep Reinforcement Learning, Reinforcement Learning, Deep Reinforcement, Deep Deterministic Policy, potential method</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep Reinforcement Learning (DRL) is regarded as a potential method for
car-following control and has been mostly studied to support a single following
vehicle. However, it is more challenging to learn a stable and efficient
car-following policy when there are multiple following vehicles in a platoon,
especially with unpredictable leading vehicle behavior. In this context, we
adopt an integrated DRL and Dynamic Programming (DP) approach to learn
autonomous platoon control policies, which embeds the Deep Deterministic Policy
Gradient (DDPG) algorithm into a finite-horizon value iteration framework.
Although the DP framework can improve the stability and performance of DDPG, it
has the limitations of lower sampling and training efficiency. In this paper,
we propose an algorithm, namely Finite-Horizon-DDPG with Sweeping through
reduced state space using Stationary approximation (FH-DDPG-SS), which uses
three key ideas to overcome the above limitations, i.e., transferring network
weights backward in time, stationary policy approximation for earlier time
steps, and sweeping through reduced state space. In order to verify the
effectiveness of FH-DDPG-SS, simulation using real driving data is performed,
where the performance of FH-DDPG-SS is compared with those of the benchmark
algorithms. Finally, platoon safety and string stability for FH-DDPG-SS are
demonstrated.</p>
  </details>
</details>
<details>
  <summary>31. <b>标题：BaIT: Barometer for Information Trustworthiness</b></summary>
  <p><b>编号</b>：[74]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07535</p>
  <p><b>作者</b>：Oisín Nolan,  Jeroen van Mourik,  Callum Tilbury</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：similar NLP tasks, natural language inference, pre-trained encoder models, neural network architectures, involves employing pre-trained</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper presents a new approach to the FNC-1 fake news classification task
which involves employing pre-trained encoder models from similar NLP tasks,
namely sentence similarity and natural language inference, and two neural
network architectures using this approach are proposed. Methods in data
augmentation are explored as a means of tackling class imbalance in the
dataset, employing common pre-existing methods and proposing a method for
sample generation in the under-represented class using a novel sentence
negation algorithm. Comparable overall performance with existing baselines is
achieved, while significantly increasing accuracy on an under-represented but
nonetheless important class for FNC-1.</p>
  </details>
</details>
<details>
  <summary>32. <b>标题：Corruption-Robust Contextual Search through Density Updates</b></summary>
  <p><b>编号</b>：[76]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07528</p>
  <p><b>作者</b>：Renato Paes Leme,  Chara Podimata,  Jon Schneider</p>
  <p><b>备注</b>：Extended abstract accepted at COLT22</p>
  <p><b>关键词</b>：adversarial noise model, contextual search, noise model, study the problem, adversarial noise</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We study the problem of contextual search in the adversarial noise model. Let
$d$ be the dimension of the problem, $T$ be the time horizon and $C$ be the
total amount of noise in the system. For the $\eps$-ball loss, we give a tight
regret bound of $O(C + d \log(1/\eps))$ improving over the $O(d^3 \log(1/\eps))
\log^2(T) + C \log(T) \log(1/\eps))$ bound of Krishnamurthy et al (STOC21). For
the symmetric loss, we give an efficient algorithm with regret $O(C+d \log T)$.
Our techniques are a significant departure from prior approaches.
Specifically, we keep track of density functions over the candidate vectors
instead of a knowledge set consisting of the candidate vectors consistent with
the feedback obtained.</p>
  </details>
</details>
<details>
  <summary>33. <b>标题：QONNX: Representing Arbitrary-Precision Quantized Neural Networks</b></summary>
  <p><b>编号</b>：[77]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07527</p>
  <p><b>作者</b>：Alessandro Pappalardo,  Yaman Umuroglu,  Michaela Blott,  Jovan Mitrevski,  Ben Hawks,  Nhan Tran,  Vladimir Loncar,  Sioni Summers,  Hendrik Borras,  Jules Muhizi,  Matthew Trahms,  Shih-Chieh Hsu,  Javier Duarte</p>
  <p><b>备注</b>：9 pages, 5 figures, Contribution to 4th Workshop on Accelerated Machine Learning (AccML) at HiPEAC 2022 Conference</p>
  <p><b>关键词</b>：Neural Network Exchange, Open Neural Network, Network Exchange, Open Neural, intermediate representation format</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present extensions to the Open Neural Network Exchange (ONNX) intermediate
representation format to represent arbitrary-precision quantized neural
networks. We first introduce support for low precision quantization in existing
ONNX-based quantization formats by leveraging integer clipping, resulting in
two new backward-compatible variants: the quantized operator format with
clipping and quantize-clip-dequantize (QCDQ) format. We then introduce a novel
higher-level ONNX format called quantized ONNX (QONNX) that introduces three
new operators -- Quant, BipolarQuant, and Trunc -- in order to represent
uniform quantization. By keeping the QONNX IR high-level and flexible, we
enable targeting a wider variety of platforms. We also present utilities for
working with QONNX, as well as examples of its usage in the FINN and hls4ml
toolchains. Finally, we introduce the QONNX model zoo to share low-precision
quantized neural networks.</p>
  </details>
</details>
<details>
  <summary>34. <b>标题：Principal Trade-off Analysis</b></summary>
  <p><b>编号</b>：[78]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07520</p>
  <p><b>作者</b>：Alexander Strang,  David SeWell,  Alexander Kim,  Kevin Alcedo,  David Rosenbluth</p>
  <p><b>备注</b>：17 pages, 8 figures</p>
  <p><b>关键词</b>：Principal Component Analysis, Principal Trade-off Analysis, paper develops Principal, Component Analysis, Principal Component</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper develops Principal Trade-off Analysis (PTA), a decomposition
method, analogous to Principal Component Analysis (PCA), which permits the
representation of any game as the weighted sum of disc games (continuous R-P-S
games). Applying PTA to empirically generated tournament graphs produces a
sequence of embeddings into orthogonal 2D feature planes representing
independent strategic trade-offs. Each trade-off generates a mode of cyclic
competition. Like PCA, PTA provides optimal low rank estimates of the
tournament graphs that can be truncated for approximation. The complexity of
cyclic competition can be quantified by computing the number of significant
cyclic modes. We illustrate the PTA via application to a pair of games (Blotto,
Pokemon). The resulting 2D disc game representations are shown to be well
suited for visualization and are easily interpretable. In Blotto, PTA
identifies game symmetries, and specifies strategic trade-offs associated with
distinct win conditions. For Pokemon, PTA embeddings produce clusters in the
embedding space that naturally correspond to Pokemon types, a design in the
game that produces cyclic trade offs.</p>
  </details>
</details>
<details>
  <summary>35. <b>标题：Investigating Multi-Feature Selection and Ensembling for Audio  Classification</b></summary>
  <p><b>编号</b>：[79]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07511</p>
  <p><b>作者</b>：Muhammad Turab,  Teerath Kumar,  Malika Bendechache,  Takfarinas Saber</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Deep Learning, Frequency Cepstral Coefficients, Mel Frequency Cepstral, shown impressive performance, algorithms have shown</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep Learning (DL) algorithms have shown impressive performance in diverse
domains. Among them, audio has attracted many researchers over the last couple
of decades due to some interesting patterns--particularly in classification of
audio data. For better performance of audio classification, feature selection
and combination play a key role as they have the potential to make or break the
performance of any DL model. To investigate this role, we conduct an extensive
evaluation of the performance of several cutting-edge DL models (i.e.,
Convolutional Neural Network, EfficientNet, MobileNet, Supper Vector Machine
and Multi-Perceptron) with various state-of-the-art audio features (i.e., Mel
Spectrogram, Mel Frequency Cepstral Coefficients, and Zero Crossing Rate)
either independently or as a combination (i.e., through ensembling) on three
different datasets (i.e., Free Spoken Digits Dataset, Audio Urdu Digits
Dataset, and Audio Gujarati Digits Dataset). Overall, results suggest feature
selection depends on both the dataset and the model. However, feature
combinations should be restricted to the only features that already achieve
good performances when used individually (i.e., mostly Mel Spectrogram, Mel
Frequency Cepstral Coefficients). Such feature combination/ensembling enabled
us to outperform the previous state-of-the-art results irrespective of our
choice of DL model.</p>
  </details>
</details>
<details>
  <summary>36. <b>标题：Deep Multi-Task Networks For Occluded Pedestrian Pose Estimation</b></summary>
  <p><b>编号</b>：[80]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07510</p>
  <p><b>作者</b>：Arindam Das,  Sudip Das,  Ganesh Sistu,  Jonathan Horgan,  Ujjwal Bhattacharya,  Edward Jones,  Martin Glavin,  Ciarán Eising</p>
  <p><b>备注</b>：4 pages, 5 tables, 2 figures</p>
  <p><b>关键词</b>：occluded parts, relevant automotive datasets, pose, occluded, pedestrian</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Most of the existing works on pedestrian pose estimation do not consider
estimating the pose of an occluded pedestrians, as the annotations of the
occluded parts are not available in relevant automotive datasets. For example,
CityPersons, a well-known dataset for pedestrian detection in automotive scenes
does not provide pose annotations, whereas MS-COCO, a non-automotive dataset,
contains human pose estimation. In this work, we propose a multi-task framework
to extract pedestrian features through detection and instance segmentation
tasks performed separately on these two distributions. Thereafter, an encoder
learns pose specific features using an unsupervised instance-level domain
adaptation method for the pedestrian instances from both distributions. The
proposed framework has improved state-of-the-art performances of pose
estimation, pedestrian detection, and instance segmentation.</p>
  </details>
</details>
<details>
  <summary>37. <b>标题：VisageSynTalk: Unseen Speaker Video-to-Speech Synthesis via  Speech-Visage Feature Selection</b></summary>
  <p><b>编号</b>：[100]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07458</p>
  <p><b>作者</b>：Joanna Hong,  Minsu Kim,  Yong Man Ro</p>
  <p><b>备注</b>：Submitted to ECCV 2022</p>
  <p><b>关键词</b>：silent talking face, talking face video, talking face, silent talking, face video</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The goal of this work is to reconstruct speech from a silent talking face
video. Recent studies have shown impressive performance on synthesizing speech
from silent talking face videos. However, they have not explicitly considered
on varying identity characteristics of different speakers, which place a
challenge in the video-to-speech synthesis, and this becomes more critical in
unseen-speaker settings. Distinct from the previous methods, our approach is to
separate the speech content and the visage-style from a given silent talking
face video. By guiding the model to independently focus on modeling the two
representations, we can obtain the speech of high intelligibility from the
model even when the input video of an unseen subject is given. To this end, we
introduce speech-visage selection module that separates the speech content and
the speaker identity from the visual features of the input video. The
disentangled representations are jointly incorporated to synthesize speech
through visage-style based synthesizer which generates speech by coating the
visage-styles while maintaining the speech content. Thus, the proposed
framework brings the advantage of synthesizing the speech containing the right
content even when the silent talking face video of an unseen subject is given.
We validate the effectiveness of the proposed framework on the GRID, TCD-TIMIT
volunteer, and LRW datasets. The synthesized speech can be heard in
supplementary materials.</p>
  </details>
</details>
<details>
  <summary>38. <b>标题：Understanding and Optimizing Deep Learning Cold-Start Latency on Edge  Devices</b></summary>
  <p><b>编号</b>：[102]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07446</p>
  <p><b>作者</b>：Rongjie Yi,  Ting Cao,  Ao Zhou,  Xiao Ma,  Shangguang Wang,  Mengwei Xu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：edge devices nowadays, devices nowadays, DNN, inference, ubiquitous on edge</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>DNNs are ubiquitous on edge devices nowadays. With its increasing importance
and use cases, it's not likely to pack all DNNs into device memory and expect
that each inference has been warmed up. Therefore, cold inference, the process
to read, initialize, and execute a DNN model, is becoming commonplace and its
performance is urgently demanded to be optimized. To this end, we present
NNV12, the first on-device inference engine that optimizes for cold inference
NNV12 is built atop 3 novel optimization knobs: selecting a proper kernel
(implementation) for each DNN operator, bypassing the weights transformation
process by caching the post-transformed weights on disk, and pipelined
execution of many kernels on asymmetric processors. To tackle with the huge
search space, NNV12 employs a heuristic-based scheme to obtain a near-optimal
kernel scheduling plan. We fully implement a prototype of NNV12 and evaluate
its performance across extensive experiments. It shows that NNV12 achieves up
to 15.2x and 401.5x compared to the state-of-the-art DNN engines on edge CPUs
and GPUs, respectively.</p>
  </details>
</details>
<details>
  <summary>39. <b>标题：Predicting Gender via Eye Movements</b></summary>
  <p><b>编号</b>：[103]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07442</p>
  <p><b>作者</b>：Rishabh Vallabh Varsha Haria,  Sahar Mahdie Klim Al Zaidawi,  Sebastian Maneth</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：eye movements, gender prediction, stable results, Random Forests, Logistic Regression</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we report the first stable results on gender prediction via
eye movements. We use a dataset with images of faces as stimuli and with a
large number of 370 participants. Stability has two meanings for us: first that
we are able to estimate the standard deviation (SD) of a single prediction
experiment (it is around 4.1 %); this is achieved by varying the number of
participants. And second, we are able to provide a mean accuracy with a very
low standard error (SEM): our accuracy is 65.2 %, and the SEM is 0.80 %; this
is achieved through many runs of randomly selecting training and test sets for
the prediction. Our study shows that two particular classifiers achieve the
best accuracies: Random Forests and Logistic Regression. Our results reconfirm
previous findings that females are more biased towards the left eyes of the
stimuli.</p>
  </details>
</details>
<details>
  <summary>40. <b>标题：Multi-Objective Hyperparameter Optimization -- An Overview</b></summary>
  <p><b>编号</b>：[105]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07438</p>
  <p><b>作者</b>：Florian Karl,  Tobias Pielok,  Julia Moosbauer,  Florian Pfisterer,  Stefan Coors,  Martin Binder,  Lennart Schneider,  Janek Thomas,  Jakob Richter,  Michel Lang,  Eduardo C. Garrido-Merchán,  Juergen Branke,  Bernd Bischl</p>
  <p><b>备注</b>：56 pages, 11 figures, submitted to ACM TELO</p>
  <p><b>关键词</b>：typical modern machine, machine learning workflows, modern machine learning, machine learning, constitutes a large</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Hyperparameter optimization constitutes a large part of typical modern
machine learning workflows. This arises from the fact that machine learning
methods and corresponding preprocessing steps often only yield optimal
performance when hyperparameters are properly tuned. But in many applications,
we are not only interested in optimizing ML pipelines solely for predictive
accuracy; additional metrics or constraints must be considered when determining
an optimal configuration, resulting in a multi-objective optimization problem.
This is often neglected in practice, due to a lack of knowledge and readily
available software implementations for multi-objective hyperparameter
optimization. In this work, we introduce the reader to the basics of multi-
objective hyperparameter optimization and motivate its usefulness in applied
ML. Furthermore, we provide an extensive survey of existing optimization
strategies, both from the domain of evolutionary algorithms and Bayesian
optimization. We illustrate the utility of MOO in several specific ML
applications, considering objectives such as operating conditions, prediction
time, sparseness, fairness, interpretability and robustness.</p>
  </details>
</details>
<details>
  <summary>41. <b>标题：Hardening DNNs against Transfer Attacks during Network Compression using  Greedy Adversarial Pruning</b></summary>
  <p><b>编号</b>：[117]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07406</p>
  <p><b>作者</b>：Jonah O'Brien Weiss,  Tiago Alves,  Sandip Kundu</p>
  <p><b>备注</b>：4 pages, 2 figures</p>
  <p><b>关键词</b>：Deep Neural Network, Neural Network, Deep Neural, success of Deep, applications in recent</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The prevalence and success of Deep Neural Network (DNN) applications in
recent years have motivated research on DNN compression, such as pruning and
quantization. These techniques accelerate model inference, reduce power
consumption, and reduce the size and complexity of the hardware necessary to
run DNNs, all with little to no loss in accuracy. However, since DNNs are
vulnerable to adversarial inputs, it is important to consider the relationship
between compression and adversarial robustness. In this work, we investigate
the adversarial robustness of models produced by several irregular pruning
schemes and by 8-bit quantization. Additionally, while conventional pruning
removes the least important parameters in a DNN, we investigate the effect of
an unconventional pruning method: removing the most important model parameters
based on the gradient on adversarial inputs. We call this method Greedy
Adversarial Pruning (GAP) and we find that this pruning method results in
models that are resistant to transfer attacks from their uncompressed
counterparts.</p>
  </details>
</details>
<details>
  <summary>42. <b>标题：Automating the resolution of flight conflicts: Deep reinforcement  learning in service of air traffic controllers</b></summary>
  <p><b>编号</b>：[118]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07403</p>
  <p><b>作者</b>：George Vouros,  George Papadopoulos,  Alevizos Bastas,  Jose Manuel Cordero,  Ruben Rodrigez Rodrigez</p>
  <p><b>备注</b>：20 pages, 5 figures, 3 tables</p>
  <p><b>关键词</b>：tactical conflict detection, scenarios require higher, require higher levels, complex air traffic, air traffic scenarios</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Dense and complex air traffic scenarios require higher levels of automation
than those exhibited by tactical conflict detection and resolution (CD\&R)
tools that air traffic controllers (ATCO) use today. However, the air traffic
control (ATC) domain, being safety critical, requires AI systems to which
operators are comfortable to relinquishing control, guaranteeing operational
integrity and automation adoption. Two major factors towards this goal are
quality of solutions, and transparency in decision making. This paper proposes
using a graph convolutional reinforcement learning method operating in a
multiagent setting where each agent (flight) performs a CD\&R task, jointly
with other agents. We show that this method can provide high-quality solutions
with respect to stakeholders interests (air traffic controllers and airspace
users), addressing operational transparency issues.</p>
  </details>
</details>
<details>
  <summary>43. <b>标题："Why Here and Not There?" -- Diverse Contrasting Explanations of  Dimensionality Reduction</b></summary>
  <p><b>编号</b>：[123]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07391</p>
  <p><b>作者</b>：André Artelt,  Alexander Schulz,  Barbara Hammer</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：popular preprocessing, Dimensionality reduction, data mining tools, data mining, Dimensionality</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Dimensionality reduction is a popular preprocessing and a widely used tool in
data mining. Transparency, which is usually achieved by means of explanations,
is nowadays a widely accepted and crucial requirement of machine learning based
systems like classifiers and recommender systems. However, transparency of
dimensionality reduction and other data mining tools have not been considered
much yet, still it is crucial to understand their behavior -- in particular
practitioners might want to understand why a specific sample got mapped to a
specific location. In order to (locally) understand the behavior of a given
dimensionality reduction method, we introduce the abstract concept of
contrasting explanations for dimensionality reduction, and apply a realization
of this concept to the specific application of explaining two dimensional data
visualization.</p>
  </details>
</details>
<details>
  <summary>44. <b>标题：The Manifold Hypothesis for Gradient-Based Explanations</b></summary>
  <p><b>编号</b>：[125]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07387</p>
  <p><b>作者</b>：Sebastian Bordt,  Uddeshya Upadhyay,  Zeynep Akata,  Ulrike von Luxburg</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：data manifold, provide meaningful explanations, algorithms provide meaningful, gradient-based explanation algorithms, data</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>When do gradient-based explanation algorithms provide meaningful
explanations? We propose a necessary criterion: their feature attributions need
to be aligned with the tangent space of the data manifold. To provide evidence
for this hypothesis, we introduce a framework based on variational autoencoders
that allows to estimate and generate image manifolds. Through experiments
across a range of different datasets -- MNIST, EMNIST, CIFAR10, X-ray pneumonia
and Diabetic Retinopathy detection -- we demonstrate that the more a feature
attribution is aligned with the tangent space of the data, the more structured
and explanatory it tends to be. In particular, the attributions provided by
popular post-hoc methods such as Integrated Gradients, SmoothGrad and Input
$\times$ Gradient tend to be more strongly aligned with the data manifold than
the raw gradient. As a consequence, we suggest that explanation algorithms
should actively strive to align their explanations with the data manifold. In
part, this can be achieved by adversarial training, which leads to better
alignment across all datasets. Some form of adjustment to the model
architecture or training algorithm is necessary, since we show that
generalization of neural networks alone does not imply the alignment of model
gradients with the data manifold.</p>
  </details>
</details>
<details>
  <summary>45. <b>标题：Mean-Semivariance Policy Optimization via Risk-Averse Reinforcement  Learning</b></summary>
  <p><b>编号</b>：[129]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07376</p>
  <p><b>作者</b>：Xiaoteng Ma,  Shuai Ma,  Li Xia,  Qianchuan Zhao</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：real-world decision-making situations, maximizing expected reward, autonomous driving, decision-making situations, crucial than maximizing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Keeping risk under control is often more crucial than maximizing expected
reward in real-world decision-making situations, such as finance, robotics,
autonomous driving, etc. The most natural choice of risk measures is variance,
while it penalizes the upside volatility as much as the downside part. Instead,
the (downside) semivariance, which captures negative deviation of a random
variable under its mean, is more suitable for risk-averse proposes. This paper
aims at optimizing the mean-semivariance (MSV) criterion in reinforcement
learning w.r.t. steady rewards. Since semivariance is time-inconsistent and
does not satisfy the standard Bellman equation, the traditional dynamic
programming methods are inapplicable to MSV problems directly. To tackle this
challenge, we resort to the Perturbation Analysis (PA) theory and establish the
performance difference formula for MSV. We reveal that the MSV problem can be
solved by iteratively solving a sequence of RL problems with a policy-dependent
reward function. Further, we propose two on-policy algorithms based on the
policy gradient theory and the trust region method. Finally, we conduct diverse
experiments from simple bandit problems to continuous control tasks in MuJoCo,
which demonstrate the effectiveness of our proposed methods.</p>
  </details>
</details>
<details>
  <summary>46. <b>标题：DiffWire: Inductive Graph Rewiring via the Lovász Bound</b></summary>
  <p><b>编号</b>：[134]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07369</p>
  <p><b>作者</b>：Adrián Arnaiz-Rodríguez,  Ahmed Begga,  Francisco Escolano,  Nuria Oliver</p>
  <p><b>备注</b>：22 pages, 6 figures and 5 tables. Preprint under review</p>
  <p><b>关键词</b>：Graph Neural Networks, achieve competitive results, Graph Neural, tackle graph-related tasks, Neural Networks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Graph Neural Networks (GNNs) have been shown to achieve competitive results
to tackle graph-related tasks, such as node and graph classification, link
prediction and node and graph clustering in a variety of domains. Most GNNs use
a message passing framework and hence are called MPNNs. Despite their promising
results, MPNNs have been reported to suffer from over-smoothing, over-squashing
and under-reaching. Graph rewiring and graph pooling have been proposed in the
literature as solutions to address these limitations. However, most
state-of-the-art graph rewiring methods fail to preserve the global topology of
the graph, are not differentiable (inductive) and require the tuning of
hyper-parameters. In this paper, we propose DiffWire, a novel framework for
graph rewiring in MPNNs that is principled, fully differentiable and
parameter-free by leveraging the Lovász bound. Our approach provides a
unified theory for graph rewiring by proposing two new, complementary layers in
MPNNs: first, CTLayer, a layer that learns the commute times and uses them as a
relevance function for edge re-weighting; second, GAPLayer, a layer to optimize
the spectral gap, depending on the nature of the network and the task at hand.
We empirically validate the value of our proposed approach and each of these
layers separately with benchmark datasets for graph classification. DiffWire
brings together the learnability of commute times to related definitions of
curvature, opening the door to the development of more expressive MPNNs.</p>
  </details>
</details>
<details>
  <summary>47. <b>标题：Modern Machine-Learning Predictive Models for Diagnosing Infectious  Diseases</b></summary>
  <p><b>编号</b>：[136]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07365</p>
  <p><b>作者</b>：Eman Yahia Alqaissi,  Fahd Saleh Alotaibi,  Muhammad Sher Ramzan</p>
  <p><b>备注</b>：13 pages, 4 figures, 6 tables</p>
  <p><b>关键词</b>：major health priority, Controlling infectious diseases, infect humans, epidemics or pandemics, infectious diseases</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Controlling infectious diseases is a major health priority because they can
spread and infect humans, thus evolving into epidemics or pandemics. Therefore,
early detection of infectious diseases is a significant need, and many
researchers have developed models to diagnose them in the early stages. This
paper reviewed research articles for recent machine-learning (ML) algorithms
applied to infectious disease diagnosis. We searched the Web of Science,
ScienceDirect, PubMed, Springer, and IEEE databases from 2015 to 2022,
identified the pros and cons of the reviewed ML models, and discussed the
possible recommendations to advance the studies in this field. We found that
most of the articles used small datasets, and few of them used real-time data.
Our results demonstrated that a suitable ML technique depends on the nature of
the dataset and the desired goal.</p>
  </details>
</details>
<details>
  <summary>48. <b>标题：Automatic Detection of Rice Disease in Images of Various Leaf Sizes</b></summary>
  <p><b>编号</b>：[147]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07344</p>
  <p><b>作者</b>：Kantip Kiratiratanapruk,  Pitchayagan Temniranrat,  Wasin Sinthupinyo,  Sanparith Marukatat,  Sujin Patarapuwadol</p>
  <p><b>备注</b>：28 pages, 13 figures</p>
  <p><b>关键词</b>：expertise shortages problems, farmers tackling equipment, rice, accurate and affordable, method is required</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Fast, accurate and affordable rice disease detection method is required to
assist rice farmers tackling equipment and expertise shortages problems. In
this paper, we focused on the solution using computer vision technique to
detect rice diseases from rice field photograph images. Dealing with images
took in real-usage situation by general farmers is quite challenging due to
various environmental factors, and rice leaf object size variation is one major
factor caused performance gradation. To solve this problem, we presented a
technique combining a CNN object detection with image tiling technique, based
on automatically estimated width size of rice leaves in the images as a size
reference for dividing the original input image. A model to estimate leaf width
was created by small size CNN such as 18 layer ResNet architecture model. A new
divided tiled sub-image set with uniformly sized object was generated and used
as input for training a rice disease prediction model. Our technique was
evaluated on 4,960 images of eight different types of rice leaf diseases,
including blast, blight, brown spot, narrow brown spot, orange, red stripe,
rice grassy stunt virus, and streak disease. The mean absolute percentage error
(MAPE) for leaf width prediction task evaluated on all eight classes was 11.18%
in the experiment, indicating that the leaf width prediction model performed
well. The mean average precision (mAP) of the prediction performance on YOLOv4
architecture was enhanced from 87.56% to 91.14% when trained and tested with
the tiled dataset. According to our study, the proposed image tiling technique
improved rice disease detection efficiency.</p>
  </details>
</details>
<details>
  <summary>49. <b>标题：Cautious Learning of Multiattribute Preferences</b></summary>
  <p><b>编号</b>：[148]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07341</p>
  <p><b>作者</b>：Hugo Gilbert (LAMSADE),  Mohamed Ouaguenouni,  Meltem Ozturk,  Olivier Spanjaard</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：cautious learning methodology, binary attributes, paper is dedicated, learning methodology, methodology for predicting</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper is dedicated to a cautious learning methodology for predicting
preferences between alternatives characterized by binary attributes (formally,
each alternative is seen as a subset of attributes). By "cautious", we mean
that the model learned to represent the multi-attribute preferences is general
enough to be compatible with any strict weak order on the alternatives, and
that we allow ourselves not to predict some preferences if the data collected
are not compatible with a reliable prediction. A predicted preference will be
considered reliable if all the simplest models (following Occam's razor
principle) explaining the training data agree on it. Predictions are based on
an ordinal dominance relation between alternatives [Fishburn and LaValle,
1996]. The dominance relation relies on an uncertainty set encompassing the
possible values of the parameters of the multi-attribute utility function.
Numerical tests are provided to evaluate the richness and the reliability of
the predictions made.</p>
  </details>
</details>
<details>
  <summary>50. <b>标题：On Numerical Integration in Neural Ordinary Differential Equations</b></summary>
  <p><b>编号</b>：[150]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07335</p>
  <p><b>作者</b>：Aiqing Zhu,  Pengzhan Jin,  Beibei Zhu,  Yifa Tang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：ordinary differential equations, Neural ODE, neural ordinary differential, Neural ODE models, ODE</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The combination of ordinary differential equations and neural networks, i.e.,
neural ordinary differential equations (Neural ODE), has been widely studied
from various angles. However, deciphering the numerical integration in Neural
ODE is still an open challenge, as many researches demonstrated that numerical
integration significantly affects the performance of the model. In this paper,
we propose the inverse modified differential equations (IMDE) to clarify the
influence of numerical integration on training Neural ODE models. IMDE is
determined by the learning task and the employed ODE solver. It is shown that
training a Neural ODE model actually returns a close approximation of the IMDE,
rather than the true ODE. With the help of IMDE, we deduce that (i) the
discrepancy between the learned model and the true ODE is bounded by the sum of
discretization error and learning loss; (ii) Neural ODE using non-symplectic
numerical integration fail to learn conservation laws theoretically. Several
experiments are performed to numerically verify our theoretical analysis.</p>
  </details>
</details>
<details>
  <summary>51. <b>标题：A Survey : Neural Networks for AMR-to-Text</b></summary>
  <p><b>编号</b>：[154]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07328</p>
  <p><b>作者</b>：Hongyu Hao,  Guangtong Li,  Zhiming Hu,  Huafeng Wang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Abstract Meaning Representation, Meaning Representation, Abstract Meaning, NLP community, community that aims</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>AMR-to-text is one of the key techniques in the NLP community that aims at
generating sentences from the Abstract Meaning Representation (AMR) graphs.
Since AMR was proposed in 2013, the study on AMR-to-Text has become
increasingly prevalent as an essential branch of structured data to text
because of the unique advantages of AMR as a high-level semantic description of
natural language. In this paper, we provide a brief survey of AMR-to-Text.
Firstly, we introduce the current scenario of this technique and point out its
difficulties. Secondly, based on the methods used in previous studies, we
roughly divided them into five categories according to their respective
mechanisms, i.e., Rules-based, Seq-to-Seq-based, Graph-to-Seq-based,
Transformer-based, and Pre-trained Language Model (PLM)-based. In particular,
we detail the neural network-based method and present the latest progress of
AMR-to-Text, which refers to AMR reconstruction, Decoder optimization, etc.
Furthermore, we present the benchmarks and evaluation methods of AMR-to-Text.
Eventually, we provide a summary of current techniques and the outlook for
future research.</p>
  </details>
</details>
<details>
  <summary>52. <b>标题：Morphence-2.0: Evasion-Resilient Moving Target Defense Powered by  Out-of-Distribution Detection</b></summary>
  <p><b>编号</b>：[158]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07321</p>
  <p><b>作者</b>：Abderrahmen Amich,  Ata Kaboudi,  Birhanu Eshete</p>
  <p><b>备注</b>：13 pages, 6 figures, 2 tables. arXiv admin note: substantial text overlap with arXiv:2108.13952</p>
  <p><b>关键词</b>：machine learning models, machine learning, iterative probing, fixed target model, model</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Evasion attacks against machine learning models often succeed via iterative
probing of a fixed target model, whereby an attack that succeeds once will
succeed repeatedly. One promising approach to counter this threat is making a
model a moving target against adversarial inputs. To this end, we introduce
Morphence-2.0, a scalable moving target defense (MTD) powered by
out-of-distribution (OOD) detection to defend against adversarial examples. By
regularly moving the decision function of a model, Morphence-2.0 makes it
significantly challenging for repeated or correlated attacks to succeed.
Morphence-2.0 deploys a pool of models generated from a base model in a manner
that introduces sufficient randomness when it responds to prediction queries.
Via OOD detection, Morphence-2.0 is equipped with a scheduling approach that
assigns adversarial examples to robust decision functions and benign samples to
an undefended accurate models. To ensure repeated or correlated attacks fail,
the deployed pool of models automatically expires after a query budget is
reached and the model pool is seamlessly replaced by a new model pool generated
in advance. We evaluate Morphence-2.0 on two benchmark image classification
datasets (MNIST and CIFAR10) against 4 reference attacks (3 white-box and 1
black-box). Morphence-2.0 consistently outperforms prior defenses while
preserving accuracy on clean data and reducing attack transferability. We also
show that, when powered by OOD detection, Morphence-2.0 is able to precisely
make an input-based movement of the model's decision function that leads to
higher prediction accuracy on both adversarial and benign queries.</p>
  </details>
</details>
<details>
  <summary>53. <b>标题：Online Contextual Decision-Making with a Smart Predict-then-Optimize  Method</b></summary>
  <p><b>编号</b>：[161]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07316</p>
  <p><b>作者</b>：Heyuan Liu,  Paul Grigas</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：resource constraints, contextual decision-making problem, resource, resource consumption, resource consumption matrix</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We study an online contextual decision-making problem with resource
constraints. At each time period, the decision-maker first predicts a reward
vector and resource consumption matrix based on a given context vector and then
solves a downstream optimization problem to make a decision. The final goal of
the decision-maker is to maximize the summation of the reward and the utility
from resource consumption, while satisfying the resource constraints. We
propose an algorithm that mixes a prediction step based on the "Smart
Predict-then-Optimize (SPO)" method with a dual update step based on mirror
descent. We prove regret bounds and demonstrate that the overall convergence
rate of our method depends on the $\mathcal{O}(T^{-1/2})$ convergence of online
mirror descent as well as risk bounds of the surrogate loss function used to
learn the prediction model. Our algorithm and regret bounds apply to a general
convex feasible region for the resource constraints, including both hard and
soft resource constraint cases, and they apply to a wide class of prediction
models in contrast to the traditional settings of linear contextual models or
finite policy spaces. We also conduct numerical experiments to empirically
demonstrate the strength of our proposed SPO-type methods, as compared to
traditional prediction-error-only methods, on multi-dimensional knapsack and
longest path instances.</p>
  </details>
</details>
<details>
  <summary>54. <b>标题：Fast and Reliable Evaluation of Adversarial Robustness with  Minimum-Margin Attack</b></summary>
  <p><b>编号</b>：[162]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07314</p>
  <p><b>作者</b>：Ruize Gao,  Jiongxiao Wang,  Kaiwen Zhou,  Feng Liu,  Binghui Xie,  Gang Niu,  Bo Han,  James Cheng</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：considerable computational resources, evaluate adversarial robustness, adversarial robustness, adversarial, computational resources</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The AutoAttack (AA) has been the most reliable method to evaluate adversarial
robustness when considerable computational resources are available. However,
the high computational cost (e.g., 100 times more than that of the project
gradient descent attack) makes AA infeasible for practitioners with limited
computational resources, and also hinders applications of AA in the adversarial
training (AT). In this paper, we propose a novel method, minimum-margin (MM)
attack, to fast and reliably evaluate adversarial robustness. Compared with AA,
our method achieves comparable performance but only costs 3% of the
computational time in extensive experiments. The reliability of our method lies
in that we evaluate the quality of adversarial examples using the margin
between two targets that can precisely identify the most adversarial example.
The computational efficiency of our method lies in an effective Sequential
TArget Ranking Selection (STARS) method, ensuring that the cost of the MM
attack is independent of the number of classes. The MM attack opens a new way
for evaluating adversarial robustness and provides a feasible and reliable way
to generate high-quality adversarial examples in AT.</p>
  </details>
</details>
<details>
  <summary>55. <b>标题：Can pruning improve certified robustness of neural networks?</b></summary>
  <p><b>编号</b>：[163]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07311</p>
  <p><b>作者</b>：Zhangheng Li,  Tianlong Chen,  Linyi Li,  Bo Li,  Zhangyang Wang</p>
  <p><b>备注</b>：arXiv admin note: text overlap with arXiv:2011.13824 by other authors</p>
  <p><b>关键词</b>：neural networks, deep neural networks, neural network pruning, trained neural networks, hardware resources</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>With the rapid development of deep learning, the sizes of neural networks
become larger and larger so that the training and inference often overwhelm the
hardware resources. Given the fact that neural networks are often
over-parameterized, one effective way to reduce such computational overhead is
neural network pruning, by removing redundant parameters from trained neural
networks. It has been recently observed that pruning can not only reduce
computational overhead but also can improve empirical robustness of deep neural
networks (NNs), potentially owing to removing spurious correlations while
preserving the predictive accuracies. This paper for the first time
demonstrates that pruning can generally improve certified robustness for
ReLU-based NNs under the complete verification setting. Using the popular
Branch-and-Bound (BaB) framework, we find that pruning can enhance the
estimated bound tightness of certified robustness verification, by alleviating
linear relaxation and sub-domain split problems. We empirically verify our
findings with off-the-shelf pruning methods and further present a new
stability-based pruning method tailored for reducing neuron instability, that
outperforms existing pruning methods in enhancing certified robustness. Our
experiments show that by appropriately pruning an NN, its certified accuracy
can be boosted up to 8.2% under standard training, and up to 24.5% under
adversarial training on the CIFAR10 dataset. We additionally observe the
existence of certified lottery tickets that can match both standard and
certified robust accuracies of the original dense models across different
datasets. Our findings offer a new angle to study the intriguing interaction
between sparsity and robustness, i.e. interpreting the interaction of sparsity
and certified robustness via neuron stability. Codes are available at:
this https URL.</p>
  </details>
</details>
<details>
  <summary>56. <b>标题：Estimating the Optimal Covariance with Imperfect Mean in Diffusion  Probabilistic Models</b></summary>
  <p><b>编号</b>：[164]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07309</p>
  <p><b>作者</b>：Fan Bao,  Chongxuan Li,  Jiacheng Sun,  Jun Zhu,  Bo Zhang</p>
  <p><b>备注</b>：Accepted in ICML 2022</p>
  <p><b>关键词</b>：Diffusion probabilistic models, deep generative models, powerful deep generative, probabilistic models, generative models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Diffusion probabilistic models (DPMs) are a class of powerful deep generative
models (DGMs). Despite their success, the iterative generation process over the
full timesteps is much less efficient than other DGMs such as GANs. Thus, the
generation performance on a subset of timesteps is crucial, which is greatly
influenced by the covariance design in DPMs. In this work, we consider diagonal
and full covariances to improve the expressive power of DPMs. We derive the
optimal result for such covariances, and then correct it when the mean of DPMs
is imperfect. Both the optimal and the corrected ones can be decomposed into
terms of conditional expectations over functions of noise. Building upon it, we
propose to estimate the optimal covariance and its correction given imperfect
mean by learning these conditional expectations. Our method can be applied to
DPMs with both discrete and continuous timesteps. We consider the diagonal
covariance in our implementation for computational efficiency. For an efficient
practical implementation, we adopt a parameter sharing scheme and a two-stage
training process. Empirically, our method outperforms a wide variety of
covariance design on likelihood results, and improves the sample quality
especially on a small number of timesteps.</p>
  </details>
</details>
<details>
  <summary>57. <b>标题：VCT: A Video Compression Transformer</b></summary>
  <p><b>编号</b>：[166]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07307</p>
  <p><b>作者</b>：Fabian Mentzer,  George Toderici,  David Minnen,  Sung-Jin Hwang,  Sergi Caelles,  Mario Lucic,  Eirikur Agustsson</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：vastly simplify neural, simplify neural video, neural video compression, vastly simplify, simplify neural</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We show how transformers can be used to vastly simplify neural video
compression. Previous methods have been relying on an increasing number of
architectural biases and priors, including motion prediction and warping
operations, resulting in complex models. Instead, we independently map input
frames to representations and use a transformer to model their dependencies,
letting it predict the distribution of future representations given the past.
The resulting video compression transformer outperforms previous methods on
standard video compression data sets. Experiments on synthetic data show that
our model learns to handle complex motion patterns such as panning, blurring
and fading purely from data. Our approach is easy to implement, and we release
code to facilitate future research.</p>
  </details>
</details>
<details>
  <summary>58. <b>标题：Knowledge Management System with NLP-Assisted Annotations: A Brief  Survey and Outlook</b></summary>
  <p><b>编号</b>：[167]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07304</p>
  <p><b>作者</b>：Baihan Lin</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：industrial researchers, high demand, demand for industrial, evidence-based decision making, decision making</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Knowledge management systems are in high demand for industrial researchers,
chemical or research enterprises, or evidence-based decision making. However,
existing systems have limitations in categorizing and organizing paper insights
or relationships. Traditional databases are usually disjoint with logging
systems, which limit its utility in generating concise, collated overviews. In
this work, we briefly survey existing approaches of this problem space and
propose a unified framework that utilizes relational databases to log
hierarchical information to facilitate the research and writing process, or
generate useful knowledge from references or insights from connected concepts.
This framework of knowledge management system enables novel functionalities
encompassing improved hierarchical notetaking, AI-assisted brainstorming, and
multi-directional relationships. Potential applications include managing
inventories and changes for manufacture or research enterprises, or generating
analytic reports with evidence-based decision making.</p>
  </details>
</details>
<details>
  <summary>59. <b>标题：FOLD-TR: A Scalable and Efficient Inductive Learning Algorithm for  Learning To Rank</b></summary>
  <p><b>编号</b>：[172]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07295</p>
  <p><b>作者</b>：Huaduo Wang,  Gopal Gupta</p>
  <p><b>备注</b>：arXiv admin note: substantial text overlap with arXiv:2202.06913. text overlap with arXiv:2110.07843</p>
  <p><b>关键词</b>：binary classification tasks, inductive learning algorithm, classification tasks, inductive learning, binary classification</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>FOLD-R++ is a new inductive learning algorithm for binary classification
tasks. It generates an (explainable) normal logic program for mixed type
(numerical and categorical) data. We present a customized FOLD-R++ algorithm
with the ranking framework, called FOLD-TR, that aims to rank new items
following the ranking pattern in the training data. Like FOLD-R++, the FOLD-TR
algorithm is able to handle mixed-type data directly and provide native
justification to explain the comparison between a pair of items.</p>
  </details>
</details>
<details>
  <summary>60. <b>标题：Differentiable Top-k Classification Learning</b></summary>
  <p><b>编号</b>：[174]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07290</p>
  <p><b>作者</b>：Felix Petersen,  Hilde Kuehne,  Christian Borgelt,  Oliver Deussen</p>
  <p><b>备注</b>：Published at ICML 2022, Code @ this https URL</p>
  <p><b>关键词</b>：machine learning, core metrics, metrics in machine, learning, training</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The top-k classification accuracy is one of the core metrics in machine
learning. Here, k is conventionally a positive integer, such as 1 or 5, leading
to top-1 or top-5 training objectives. In this work, we relax this assumption
and optimize the model for multiple k simultaneously instead of using a single
k. Leveraging recent advances in differentiable sorting and ranking, we propose
a differentiable top-k cross-entropy classification loss. This allows training
the network while not only considering the top-1 prediction, but also, e.g.,
the top-2 and top-5 predictions. We evaluate the proposed loss function for
fine-tuning on state-of-the-art architectures, as well as for training from
scratch. We find that relaxing k does not only produce better top-5 accuracies,
but also leads to top-1 accuracy improvements. When fine-tuning publicly
available ImageNet models, we achieve a new state-of-the-art for these models.</p>
  </details>
</details>
<details>
  <summary>61. <b>标题：A Survey on Gradient Inversion: Attacks, Defenses and Future Directions</b></summary>
  <p><b>编号</b>：[178]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07284</p>
  <p><b>作者</b>：Rui Zhang,  Song Guo,  Junxiao Wang,  Xin Xie,  Dacheng Tao</p>
  <p><b>备注</b>：Accepted by IJCAI-ECAI 2022</p>
  <p><b>关键词</b>：called Gradient Inversion, Gradient Inversion, studies have shown, Inversion, Recent studies</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent studies have shown that the training samples can be recovered from
gradients, which are called Gradient Inversion (GradInv) attacks. However,
there remains a lack of extensive surveys covering recent advances and thorough
analysis of this issue. In this paper, we present a comprehensive survey on
GradInv, aiming to summarize the cutting-edge research and broaden the horizons
for different domains. Firstly, we propose a taxonomy of GradInv attacks by
characterizing existing attacks into two paradigms: iteration- and
recursion-based attacks. In particular, we dig out some critical ingredients
from the iteration-based attacks, including data initialization, model training
and gradient matching. Second, we summarize emerging defense strategies against
GradInv attacks. We find these approaches focus on three perspectives covering
data obscuration, model improvement and gradient protection. Finally, we
discuss some promising directions and open problems for further research.</p>
  </details>
</details>
<details>
  <summary>62. <b>标题：Global Convergence of Federated Learning for Mixed Regression</b></summary>
  <p><b>编号</b>：[180]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07279</p>
  <p><b>作者</b>：Lili Su,  Jiaming Xu,  Pengkun Yang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Federated Learning, training under Federated, exhibit cluster structure, paper studies, Federated</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper studies the problem of model training under Federated Learning
when clients exhibit cluster structure. We contextualize this problem in mixed
regression, where each client has limited local data generated from one of $k$
unknown regression models. We design an algorithm that achieves global
convergence from any initialization, and works even when local data volume is
highly unbalanced -- there could exist clients that contain $O(1)$ data points
only. Our algorithm first runs moment descent on a few anchor clients (each
with $\tilde{\Omega}(k)$ data points) to obtain coarse model estimates. Then
each client alternately estimates its cluster labels and refines the model
estimates based on FedAvg or FedProx. A key innovation in our analysis is a
uniform estimate on the clustering errors, which we prove by bounding the VC
dimension of general polynomial concept classes based on the theory of
algebraic geometry.</p>
  </details>
</details>
<details>
  <summary>63. <b>标题：ALASCA: Rethinking Label Smoothing for Deep Learning Under Label Noise</b></summary>
  <p><b>编号</b>：[182]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07277</p>
  <p><b>作者</b>：Jongwoo Ko,  Bongsoo Yi,  Se-Young Yun</p>
  <p><b>备注</b>：ICML Workshop on Principles of Distribution Shift 2022</p>
  <p><b>关键词</b>：severely degrades deep, modern deep learning, popular distribution shifts, networks' generalization performance, degrades deep neural</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As label noise, one of the most popular distribution shifts, severely
degrades deep neural networks' generalization performance, robust training with
noisy labels is becoming an important task in modern deep learning. In this
paper, we propose our framework, coined as Adaptive LAbel smoothing on
Sub-ClAssifier (ALASCA), that provides a robust feature extractor with
theoretical guarantee and negligible additional computation. First, we derive
that the label smoothing (LS) incurs implicit Lipschitz regularization (LR).
Furthermore, based on these derivations, we apply the adaptive LS (ALS) on
sub-classifiers architectures for the practical application of adaptive LR on
intermediate layers. We conduct extensive experiments for ALASCA and combine it
with previous noise-robust methods on several datasets and show our framework
consistently outperforms corresponding baselines.</p>
  </details>
</details>
<details>
  <summary>64. <b>标题：Resource-Constrained Edge AI with Early Exit Prediction</b></summary>
  <p><b>编号</b>：[186]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07269</p>
  <p><b>作者</b>：Rongkang Dong,  Yuyi Mao,  Jun Zhang</p>
  <p><b>备注</b>：25 pages, 16 figures, 6 tables. This paper is accepted by Journal of Communications and Information Networks</p>
  <p><b>关键词</b>：early exit prediction, network recently emerges, neural network architecture, prominent neural network, data sample diversity</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>By leveraging the data sample diversity, the early-exit network recently
emerges as a prominent neural network architecture to accelerate the deep
learning inference process. However, intermediate classifiers of the early
exits introduce additional computation overhead, which is unfavorable for
resource-constrained edge artificial intelligence (AI). In this paper, we
propose an early exit prediction mechanism to reduce the on-device computation
overhead in a device-edge co-inference system supported by early-exit networks.
Specifically, we design a low-complexity module, namely the Exit Predictor, to
guide some distinctly "hard" samples to bypass the computation of the early
exits. Besides, considering the varying communication bandwidth, we extend the
early exit prediction mechanism for latency-aware edge inference, which adapts
the prediction thresholds of the Exit Predictor and the confidence thresholds
of the early-exit network via a few simple regression models. Extensive
experiment results demonstrate the effectiveness of the Exit Predictor in
achieving a better tradeoff between accuracy and on-device computation overhead
for early-exit networks. Besides, compared with the baseline methods, the
proposed method for latency-aware edge inference attains higher inference
accuracy under different bandwidth conditions.</p>
  </details>
</details>
<details>
  <summary>65. <b>标题：On Enforcing Better Conditioned Meta-Learning for Rapid Few-Shot  Adaptation</b></summary>
  <p><b>编号</b>：[190]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07260</p>
  <p><b>作者</b>：Markus Hiller,  Mehrtash Harandi,  Tom Drummond</p>
  <p><b>备注</b>：Preprint</p>
  <p><b>关键词</b>：incurring extra parameters, increase adaptation speed, gradient-based meta-learning methods, concept of preconditioning, speed for gradient-based</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Inspired by the concept of preconditioning, we propose a novel method to
increase adaptation speed for gradient-based meta-learning methods without
incurring extra parameters. We demonstrate that recasting the optimization
problem to a non-linear least-squares formulation provides a principled way to
actively enforce a $\textit{well-conditioned}$ parameter space for
meta-learning models based on the concepts of the condition number and local
curvature. Our comprehensive evaluations show that the proposed method
significantly outperforms its unconstrained counterpart especially during
initial adaptation steps, while achieving comparable or better overall results
on several few-shot classification tasks -- creating the possibility of
dynamically choosing the number of adaptation steps at inference time.</p>
  </details>
</details>
<details>
  <summary>66. <b>标题：CLNode: Curriculum Learning for Node Classification</b></summary>
  <p><b>编号</b>：[192]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07258</p>
  <p><b>作者</b>：Xiaowen Wei,  Weiwei Liu,  Yibing Zhan,  Du Bo,  Wenbin Hu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：fundamental graph-based task, Graph Neural Networks, Graph Neural, Neural Networks, fundamental graph-based</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Node classification is a fundamental graph-based task that aims to predict
the classes of unlabeled nodes, for which Graph Neural Networks (GNNs) are the
state-of-the-art methods. In current GNNs, training nodes (or training samples)
are treated equally throughout training. The quality of the samples, however,
varies greatly according to the graph structure. Consequently, the performance
of GNNs could be harmed by two types of low-quality samples: (1) Inter-class
nodes situated near class boundaries that connect neighboring classes. These
nodes' representations lack the typical characteristics of their corresponding
classes. Because GNNs are data-driven approaches, training on these nodes could
degrade the accuracy. (2) Mislabeled nodes. In real-world graphs, nodes are
often mislabeled, which can significantly degrade the robustness of GNNs. To
mitigate the detrimental effect of the low-quality samples, we present CLNode
(Curriculum Learning for Node Classification), which automatically adjusts the
weights of samples during training based on their quality. Specifically, we
first design a neighborhood-based difficulty measurer to accurately measure the
quality of samples. Subsequently, based on these measurements, we employ a
training scheduler to adjust the sample weights in each training epoch. To
evaluate the effectiveness of CLNode, we conduct extensive experiments by
applying it to four representative backbone GNNs. Experimental results on six
real-world networks demonstrate that CLNode is a general framework that can be
combined with various GNNs to improve their accuracy and robustness.</p>
  </details>
</details>
<details>
  <summary>67. <b>标题：TeKo: Text-Rich Graph Neural Networks with External Knowledge</b></summary>
  <p><b>编号</b>：[194]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07253</p>
  <p><b>作者</b>：Zhizhi Yu,  Di Jin,  Jianguo Wei,  Ziyang Liu,  Yue Shang,  Yun Xiao,  Jiawei Han,  Lingfei Wu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：gained great popularity, textual semantics, graph-structured data, network, gained great</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Graph Neural Networks (GNNs) have gained great popularity in tackling various
analytical tasks on graph-structured data (i.e., networks). Typical GNNs and
their variants follow a message-passing manner that obtains network
representations by the feature propagation process along network topology,
which however ignore the rich textual semantics (e.g., local word-sequence)
that exist in many real-world networks. Existing methods for text-rich networks
integrate textual semantics by mainly utilizing internal information such as
topics or phrases/words, which often suffer from an inability to
comprehensively mine the text semantics, limiting the reciprocal guidance
between network structure and text semantics. To address these problems, we
propose a novel text-rich graph neural network with external knowledge (TeKo),
in order to take full advantage of both structural and textual information
within text-rich networks. Specifically, we first present a flexible
heterogeneous semantic network that incorporates high-quality entities and
interactions among documents and entities. We then introduce two types of
external knowledge, that is, structured triplets and unstructured entity
description, to gain a deeper insight into textual semantics. We further design
a reciprocal convolutional mechanism for the constructed heterogeneous semantic
network, enabling network structure and textual semantics to collaboratively
enhance each other and learn high-level network representations. Extensive
experimental results on four public text-rich networks as well as a large-scale
e-commerce searching dataset illustrate the superior performance of TeKo over
state-of-the-art baselines.</p>
  </details>
</details>
<details>
  <summary>68. <b>标题：Fair Ranking as Fair Division: Impact-Based Individual Fairness in  Ranking</b></summary>
  <p><b>编号</b>：[197]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07247</p>
  <p><b>作者</b>：Yuta Saito,  Thorsten Joachims</p>
  <p><b>备注</b>：accepted at KDD2022</p>
  <p><b>关键词</b>：two-sided online markets, online markets, primary interface, interface in two-sided, two-sided online</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Rankings have become the primary interface in two-sided online markets. Many
have noted that the rankings not only affect the satisfaction of the users
(e.g., customers, listeners, employers, travelers), but that the position in
the ranking allocates exposure -- and thus economic opportunity -- to the
ranked items (e.g., articles, products, songs, job seekers, restaurants,
hotels). This has raised questions of fairness to the items, and most existing
works have addressed fairness by explicitly linking item exposure to item
relevance. However, we argue that any particular choice of such a link function
may be difficult to defend, and we show that the resulting rankings can still
be unfair. To avoid these shortcomings, we develop a new axiomatic approach
that is rooted in principles of fair division. This not only avoids the need to
choose a link function, but also more meaningfully quantifies the impact on the
items beyond exposure. Our axioms of envy-freeness and dominance over uniform
ranking postulate that for a fair ranking policy every item should prefer their
own rank allocation over that of any other item, and that no item should be
actively disadvantaged by the rankings. To compute ranking policies that are
fair according to these axioms, we propose a new ranking objective related to
the Nash Social Welfare. We show that the solution has guarantees regarding its
envy-freeness, its dominance over uniform rankings for every item, and its
Pareto optimality. In contrast, we show that conventional exposure-based
fairness can produce large amounts of envy and have a highly disparate impact
on the items. Beyond these theoretical results, we illustrate empirically how
our framework controls the trade-off between impact-based individual item
fairness and user utility.</p>
  </details>
</details>
<details>
  <summary>69. <b>标题：Test-Time Adaptation for Visual Document Understanding</b></summary>
  <p><b>编号</b>：[202]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07240</p>
  <p><b>作者</b>：Sayna Ebrahimi,  Sercan O. Arik,  Tomas Pfister</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：produce transferable representations, produce transferable, visual document understanding, transferable representations, document understanding</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Self-supervised pretraining has been able to produce transferable
representations for various visual document understanding (VDU) tasks. However,
the ability of such representations to adapt to new distribution shifts at
test-time has not been studied yet. We propose DocTTA, a novel test-time
adaptation approach for documents that leverages cross-modality self-supervised
learning via masked visual language modeling as well as pseudo labeling to
adapt models learned on a \textit{source} domain to an unlabeled
\textit{target} domain at test time. We also introduce new benchmarks using
existing public datasets for various VDU tasks including entity recognition,
key-value extraction, and document visual question answering tasks where DocTTA
improves the source model performance up to 1.79\% in (F1 score), 3.43\% (F1
score), and 17.68\% (ANLS score), respectively while drastically reducing
calibration error on target data.</p>
  </details>
</details>
<details>
  <summary>70. <b>标题：Location-based Twitter Filtering for the Creation of Low-Resource  Language Datasets in Indonesian Local Languages</b></summary>
  <p><b>编号</b>：[203]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07238</p>
  <p><b>作者</b>：Mukhlis Amien,  Chong Feng,  Heyan Huang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：real world, abundance of linguistic, linguistic data, local Indonesian, Indonesian</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Twitter contains an abundance of linguistic data from the real world. We
examine Twitter for user-generated content in low-resource languages such as
local Indonesian. For NLP to work in Indonesian, it must consider local
dialects, geographic context, and regional culture influence Indonesian
languages. This paper identifies the problems we faced when constructing a
Local Indonesian NLP dataset. Furthermore, we are developing a framework for
creating, collecting, and classifying Local Indonesian datasets for NLP. Using
twitter's geolocation tool for automatic annotating.</p>
  </details>
</details>
<details>
  <summary>71. <b>标题：Training Discrete Deep Generative Models via Gapped Straight-Through  Estimator</b></summary>
  <p><b>编号</b>：[204]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07235</p>
  <p><b>作者</b>：Ting-Han Fan,  Ta-Chung Chi,  Alexander I. Rudnicky,  Peter J. Ramadge</p>
  <p><b>备注</b>：Accepted at the International Conference on Machine Learning (ICML) 2022. The first two authors contributed equally</p>
  <p><b>关键词</b>：natural language processing, gradient estimation process, random variables remains, variables remains challenging, remains challenging due</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>While deep generative models have succeeded in image processing, natural
language processing, and reinforcement learning, training that involves
discrete random variables remains challenging due to the high variance of its
gradient estimation process. Monte Carlo is a common solution used in most
variance reduction approaches. However, this involves time-consuming resampling
and multiple function evaluations. We propose a Gapped Straight-Through (GST)
estimator to reduce the variance without incurring resampling overhead. This
estimator is inspired by the essential properties of Straight-Through
Gumbel-Softmax. We determine these properties and show via an ablation study
that they are essential. Experiments demonstrate that the proposed GST
estimator enjoys better performance compared to strong baselines on two
discrete deep generative modeling tasks, MNIST-VAE and ListOps.</p>
  </details>
</details>
<details>
  <summary>72. <b>标题：Brownian Noise Reduction: Maximizing Privacy Subject to Accuracy  Constraints</b></summary>
  <p><b>编号</b>：[205]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07234</p>
  <p><b>作者</b>：Justin Whitehouse,  Zhiwei Steven Wu,  Aaditya Ramdas,  Ryan Rogers</p>
  <p><b>备注</b>：18 pages, 4 figures</p>
  <p><b>关键词</b>：handle privacy-utility tradeoffs, practitioners handle privacy-utility, privacy-utility tradeoffs, handle privacy-utility, Brownian mechanism</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>There is a disconnect between how researchers and practitioners handle
privacy-utility tradeoffs. Researchers primarily operate from a privacy first
perspective, setting strict privacy requirements and minimizing risk subject to
these constraints. Practitioners often desire an accuracy first perspective,
possibly satisfied with the greatest privacy they can get subject to obtaining
sufficiently small error. Ligett et al. have introduced a "noise reduction"
algorithm to address the latter perspective. The authors show that by adding
correlated Laplace noise and progressively reducing it on demand, it is
possible to produce a sequence of increasingly accurate estimates of a private
parameter while only paying a privacy cost for the least noisy iterate
released. In this work, we generalize noise reduction to the setting of
Gaussian noise, introducing the Brownian mechanism. The Brownian mechanism
works by first adding Gaussian noise of high variance corresponding to the
final point of a simulated Brownian motion. Then, at the practitioner's
discretion, noise is gradually decreased by tracing back along the Brownian
path to an earlier time. Our mechanism is more naturally applicable to the
common setting of bounded $\ell_2$-sensitivity, empirically outperforms
existing work on common statistical tasks, and provides customizable control of
privacy loss over the entire interaction with the practitioner. We complement
our Brownian mechanism with ReducedAboveThreshold, a generalization of the
classical AboveThreshold algorithm that provides adaptive privacy guarantees.
Overall, our results demonstrate that one can meet utility constraints while
still maintaining strong levels of privacy.</p>
  </details>
</details>
<details>
  <summary>73. <b>标题：Accurate Emotion Strength Assessment for Seen and Unseen Speech Based on  Data-Driven Deep Learning</b></summary>
  <p><b>编号</b>：[208]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07229</p>
  <p><b>作者</b>：Rui Liu,  Berrak Sisman,  Björn Schuller,  Guanglai Gao,  Haizhou Li</p>
  <p><b>备注</b>：To appear in INTERSPEECH 2022. 5 pages, 4 figures. Substantial text overlap with arXiv:2110.03156</p>
  <p><b>关键词</b>：Support Vector Machine, voice conversion, Vector Machine, Support Vector, emotion strength</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Emotion classification of speech and assessment of the emotion strength are
required in applications such as emotional text-to-speech and voice conversion.
The emotion attribute ranking function based on Support Vector Machine (SVM)
was proposed to predict emotion strength for emotional speech corpus. However,
the trained ranking function doesn't generalize to new domains, which limits
the scope of applications, especially for out-of-domain or unseen speech. In
this paper, we propose a data-driven deep learning model, i.e. StrengthNet, to
improve the generalization of emotion strength assessment for seen and unseen
speech. This is achieved by the fusion of emotional data from various domains.
We follow a multi-task learning network architecture that includes an acoustic
encoder, a strength predictor, and an auxiliary emotion predictor. Experiments
show that the predicted emotion strength of the proposed StrengthNet is highly
correlated with ground truth scores for both seen and unseen speech. We release
the source codes at: this https URL.</p>
  </details>
</details>
<details>
  <summary>74. <b>标题：Explainable expected goal models for performance analysis in football  analytics</b></summary>
  <p><b>编号</b>：[212]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07212</p>
  <p><b>作者</b>：Mustafa Cavus,  Przemysław Biecek</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：expected goal model, expected goal, goal model, model, accurate expected goal</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The expected goal provides a more representative measure of the team and
player performance which also suit the low-scoring nature of football instead
of score in modern football. The score of a match involves randomness and often
may not represent the performance of the teams and players, therefore it has
been popular to use the alternative statistics in recent years such as shots on
target, ball possessions, and drills. To measure the probability of a shot
being a goal by the expected goal, several features are used to train an
expected goal model which is based on the event and tracking football data. The
selection of these features, the size and date of the data, and the model which
are used as the parameters that may affect the performance of the model. Using
black-box machine learning models for increasing the predictive performance of
the model decreases its interpretability that causes the loss of information
that can be gathered from the model. This paper proposes an accurate expected
goal model trained consisting of 315,430 shots from seven seasons between
2014-15 and 2020-21 of the top-five European football leagues. Moreover, this
model is explained by using explainable artificial intelligence tool to obtain
an explainable expected goal model for evaluating a team or player performance.
To best of our knowledge, this is the first paper that demonstrates a practical
application of an explainable artificial intelligence tool aggregated profiles
to explain a group of observations on an accurate expected goal model for
monitoring the team and player performance. Moreover, these methods can be
generalized to other sports branches.</p>
  </details>
</details>
<details>
  <summary>75. <b>标题：Attributions Beyond Neural Networks: The Linear Program Case</b></summary>
  <p><b>编号</b>：[216]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07203</p>
  <p><b>作者</b>：Florian Peter Busch,  Matej Zečević,  Kristian Kersting,  Devendra Singh Dhami</p>
  <p><b>备注</b>：Main paper: 9.5 pages, References: 2 pages, Supplement: 2.5 pages. Main paper: 5 figures, 2 tables, Supplement: 1 figure</p>
  <p><b>关键词</b>：championed recent strides, Linear Programs, building blocks, blocks in machine, championed recent</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Linear Programs (LPs) have been one of the building blocks in machine
learning and have championed recent strides in differentiable optimizers for
learning systems. While there exist solvers for even high-dimensional LPs,
understanding said high-dimensional solutions poses an orthogonal and
unresolved problem. We introduce an approach where we consider neural encodings
for LPs that justify the application of attribution methods from explainable
artificial intelligence (XAI) designed for neural learning systems. The several
encoding functions we propose take into account aspects such as feasibility of
the decision space, the cost attached to each input, or the distance to special
points of interest. We investigate the mathematical consequences of several XAI
methods on said neural LP encodings. We empirically show that the attribution
methods Saliency and LIME reveal indistinguishable results up to perturbation
levels, and we propose the property of Directedness as the main discriminative
criterion between Saliency and LIME on one hand, and a perturbation-based
Feature Permutation approach on the other hand. Directedness indicates whether
an attribution method gives feature attributions with respect to an increase of
that feature. We further notice the baseline selection problem beyond the
classical computer vision setting for Integrated Gradients.</p>
  </details>
</details>
<details>
  <summary>76. <b>标题：Using Machine Learning to Augment Dynamic Time Warping Based Signal  Classification</b></summary>
  <p><b>编号</b>：[218]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07200</p>
  <p><b>作者</b>：Arvind Seshan</p>
  <p><b>备注</b>：Presented at Regeneron International Science and Engineering Fair (ISEF) 2022</p>
  <p><b>关键词</b>：voice recognition rely, Dynamic Time Warping, voice recognition, recognition rely, ability to compare</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Modern applications such as voice recognition rely on the ability to compare
signals to pre-recorded ones to classify them. However, this comparison
typically needs to ignore differences due to signal noise, temporal offset,
signal magnitude, and other external factors. The Dynamic Time Warping (DTW)
algorithm quantifies this similarity by finding corresponding regions between
the signals and non-linearly warping one signal by stretching and shrinking it.
Unfortunately, searching through all "warps" of a signal to find the best
corresponding regions is computationally expensive. The FastDTW algorithm
improves performance, but sacrifices accuracy by only considering small signal
warps.
My goal is to improve the speed of DTW while maintaining high accuracy. My
key insight is that in any particular application domain, signals exhibit
specific types of variation. For example, the accelerometer signal measured for
two different people would differ based on their stride length and weight. My
system, called Machine Learning DTW (MLDTW), uses machine learning to learn the
types of warps that are common in a particular domain. It then uses the learned
model to improve DTW performance by limiting the search of potential warps
appropriately. My results show that compared to FastDTW, MLDTW is at least as
fast and reduces errors by 60% on average across four different data sets.
These improvements will significantly impact a wide variety of applications
(e.g. health monitoring) and enable more scalable processing of multivariate,
higher frequency, and longer signal recordings.</p>
  </details>
</details>
<details>
  <summary>77. <b>标题：Improving Solar Flare Prediction by Time Series Outlier Detection</b></summary>
  <p><b>编号</b>：[220]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07197</p>
  <p><b>作者</b>：Junzhi Wen,  Md Reazul Islam,  Azim Ahmadzadeh,  Rafal A. Angryk</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：outer space technologies, lives highly depend, interconnected infrastructure, pose risks, risks to outer</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Solar flares not only pose risks to outer space technologies and astronauts'
well being, but also cause disruptions on earth to our hight-tech,
interconnected infrastructure our lives highly depend on. While a number of
machine-learning methods have been proposed to improve flare prediction, none
of them, to the best of our knowledge, have investigated the impact of outliers
on the reliability and those models' performance. In this study, we investigate
the impact of outliers in a multivariate time series benchmark dataset, namely
SWAN-SF, on flare prediction models, and test our hypothesis. That is, there
exist outliers in SWAN-SF, removal of which enhances the performance of the
prediction models on unseen datasets. We employ Isolation Forest to detect the
outliers among the weaker flare instances. Several experiments are carried out
using a large range of contamination rates which determine the percentage of
present outliers. We asses the quality of each dataset in terms of its actual
contamination using TimeSeriesSVC. In our best finding, we achieve a 279%
increase in True Skill Statistic and 68% increase in Heidke Skill Score. The
results show that overall a significant improvement can be achieved to flare
prediction if outliers are detected and removed properly.</p>
  </details>
</details>
<details>
  <summary>78. <b>标题：Towards a Solution to Bongard Problems: A Causal Approach</b></summary>
  <p><b>编号</b>：[221]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07196</p>
  <p><b>作者</b>：Salahedine Youssef,  Matej Zečević,  Devendra Singh Dhami,  Kristian Kersting</p>
  <p><b>备注</b>：Main paper: 5.5 pages, References: 1 page, Supplement: 1 page. Main paper: 5 figures, Supplement: 3 figures</p>
  <p><b>关键词</b>：Bongard Problems, current era, powerful models, Bongard, Problems</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>To date, Bongard Problems (BP) remain one of the few fortresses of AI history
yet to be raided by the powerful models of the current era. We present a
systematic analysis using modern techniques from the intersection of causality
and AI/ML in a humble effort of reviving research around BPs. Specifically, we
first compile the BPs into a Markov decision process, then secondly pose causal
assumptions on the data generating process arguing for their applicability to
BPs, and finally apply reinforcement learning techniques for solving the BPs
subject to the causal assumptions.</p>
  </details>
</details>
<details>
  <summary>79. <b>标题：Tearing Apart NOTEARS: Controlling the Graph Prediction via Variance  Manipulation</b></summary>
  <p><b>编号</b>：[222]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07195</p>
  <p><b>作者</b>：Jonas Seng,  Matej Zečević,  Devendra Singh Dhami,  Kristian Kersting</p>
  <p><b>备注</b>：Main paper: 5.5 pages, References: 1 page, Supplement: 2 pages. Main paper: 3 figures, Supplement: 1 figure, 1 table</p>
  <p><b>关键词</b>：Directed Acyclic Graphs, ubiquitous in machine, machine learning, Directed Acyclic, graph learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Simulations are ubiquitous in machine learning. Especially in graph learning,
simulations of Directed Acyclic Graphs (DAG) are being deployed for evaluating
new algorithms. In the literature, it was recently argued that
continuous-optimization approaches to structure discovery such as NOTEARS might
be exploiting the sortability of the variable's variances in the available data
due to their use of least square losses. Specifically, since structure
discovery is a key problem in science and beyond, we want to be invariant to
the scale being used for measuring our data (e.g. meter versus centimeter
should not affect the causal direction inferred by the algorithm). In this
work, we further strengthen this initial, negative empirical suggestion by both
proving key results in the multivariate case and corroborating with further
empirical evidence. In particular, we show that we can control the resulting
graph with our targeted variance attacks, even in the case where we can only
partially manipulate the variances of the data.</p>
  </details>
</details>
<details>
  <summary>80. <b>标题：Machines Explaining Linear Programs</b></summary>
  <p><b>编号</b>：[223]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07194</p>
  <p><b>作者</b>：David Steinmann,  Matej Zečević,  Devendra Singh Dhami,  Kristian Kersting</p>
  <p><b>备注</b>：Main paper: 9.5 pages, References: 2.5 pages, Supplement: 6 pages. Main paper: 5 figures, 4 tables, Supplement: 3 figures, 6 tables</p>
  <p><b>关键词</b>：making machine learning, machine learning, methods, machine learning models, linear</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>There has been a recent push in making machine learning models more
interpretable so that their performance can be trusted. Although successful,
these methods have mostly focused on the deep learning methods while the
fundamental optimization methods in machine learning such as linear programs
(LP) have been left out. Even if LPs can be considered as whitebox or clearbox
models, they are not easy to understand in terms of relationships between
inputs and outputs. As a linear program only provides the optimal solution to
an optimization problem, further explanations are often helpful. In this work,
we extend the attribution methods for explaining neural networks to linear
programs. These methods explain the model by providing relevance scores for the
model inputs, to show the influence of each input on the output. Alongside
using classical gradient-based attribution methods we also propose a way to
adapt perturbation-based attribution methods to LPs. Our evaluations of several
different linear and integer problems showed that attribution methods can
generate useful explanations for linear programs. However, we also demonstrate
that using a neural attribution method directly might come with some drawbacks,
as the properties of these methods on neural networks do not necessarily
transfer to linear programs. The methods can also struggle if a linear program
has more than one optimal solution, as a solver just returns one possible
solution. Our results can hopefully be used as a good starting point for
further research in this direction.</p>
  </details>
</details>
<details>
  <summary>81. <b>标题：Codec at SemEval-2022 Task 5: Multi-Modal Multi-Transformer Misogynous  Meme Classification Framework</b></summary>
  <p><b>编号</b>：[224]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07190</p>
  <p><b>作者</b>：Ahmed Mahran,  Carlo Alessandro Borella,  Konstantinos Perifanos</p>
  <p><b>备注</b>：Accepted for publication at the 16th International Workshop on Semantic Evaluation, Task 5: MAMI - Multimedia Automatic Misogyny Identification co-located with NAACL 2022</p>
  <p><b>关键词</b>：Multimedia Automatic Misogyny, Automatic Misogyny Identification, Multimedia Automatic, Misogyny Identification, Automatic Misogyny</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper we describe our work towards building a generic framework for
both multi-modal embedding and multi-label binary classification tasks, while
participating in task 5 (Multimedia Automatic Misogyny Identification) of
SemEval 2022 competition.
Since pretraining deep models from scratch is a resource and data hungry
task, our approach is based on three main strategies. We combine different
state-of-the-art architectures to capture a wide spectrum of semantic signals
from the multi-modal input. We employ a multi-task learning scheme to be able
to use multiple datasets from the same knowledge domain to help increase the
model's performance. We also use multiple objectives to regularize and fine
tune different system components.</p>
  </details>
</details>
<details>
  <summary>82. <b>标题：Defending Observation Attacks in Deep Reinforcement Learning via  Detection and Denoising</b></summary>
  <p><b>编号</b>：[225]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07188</p>
  <p><b>作者</b>：Zikang Xiong,  Joe Eappen,  He Zhu,  Suresh Jagannathan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Deep Reinforcement Learning, Reinforcement Learning, Deep Reinforcement, trained using Deep, network policies trained</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Neural network policies trained using Deep Reinforcement Learning (DRL) are
well-known to be susceptible to adversarial attacks. In this paper, we consider
attacks manifesting as perturbations in the observation space managed by the
external environment. These attacks have been shown to downgrade policy
performance significantly. We focus our attention on well-trained deterministic
and stochastic neural network policies in the context of continuous control
benchmarks subject to four well-studied observation space adversarial attacks.
To defend against these attacks, we propose a novel defense strategy using a
detect-and-denoise schema. Unlike previous adversarial training approaches that
sample data in adversarial scenarios, our solution does not require sampling
data in an environment under attack, thereby greatly reducing risk during
training. Detailed experimental results show that our technique is comparable
with state-of-the-art adversarial training approaches.</p>
  </details>
</details>
<details>
  <summary>83. <b>标题：To Aggregate or Not? Learning with Separate Noisy Labels</b></summary>
  <p><b>编号</b>：[228]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07181</p>
  <p><b>作者</b>：Jiaheng Wei,  Zhaowei Zhu,  Tianyi Luo,  Ehsan Amid,  Abhishek Kumar,  Yang Liu</p>
  <p><b>备注</b>：Paper under Review</p>
  <p><b>关键词</b>：multiple imperfect annotators, rawly collected training, collected training data, separate noisy labels, noisy labels collected</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The rawly collected training data often comes with separate noisy labels
collected from multiple imperfect annotators (e.g., via crowdsourcing).
Typically one would first aggregate the separate noisy labels into one and
apply standard training methods. The literature has also studied extensively on
effective aggregation approaches. This paper revisits this choice and aims to
provide an answer to the question of whether one should aggregate separate
noisy labels into single ones or use them separately as given. We theoretically
analyze the performance of both approaches under the empirical risk
minimization framework for a number of popular loss functions, including the
ones designed specifically for the problem of learning with noisy labels. Our
theorems conclude that label separation is preferred over label aggregation
when the noise rates are high, or the number of labelers/annotations is
insufficient. Extensive empirical results validate our conclusion.</p>
  </details>
</details>
<details>
  <summary>84. <b>标题：Proximal Splitting Adversarial Attacks for Semantic Segmentation</b></summary>
  <p><b>编号</b>：[230]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07179</p>
  <p><b>作者</b>：Jérôme Rony,  Jean-Christophe Pesquet,  Ismail Ben Ayed</p>
  <p><b>备注</b>：Code available at: this https URL</p>
  <p><b>关键词</b>：investigate methods suited, denser prediction tasks, works investigate methods, focal point, point of research</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Classification has been the focal point of research on adversarial attacks,
but only a few works investigate methods suited to denser prediction tasks,
such as semantic segmentation. The methods proposed in these works do not
accurately solve the adversarial segmentation problem and, therefore, are
overoptimistic in terms of size of the perturbations required to fool models.
Here, we propose a white-box attack for these models based on a proximal
splitting to produce adversarial perturbations with much smaller $\ell_1$,
$\ell_2$, or $\ell_\infty$ norms. Our attack can handle large numbers of
constraints within a nonconvex minimization framework via an Augmented
Lagrangian approach, coupled with adaptive constraint scaling and masking
strategies. We demonstrate that our attack significantly outperforms previously
proposed ones, as well as classification attacks that we adapted for
segmentation, providing a first comprehensive benchmark for this dense task.
Our results push current limits concerning robustness evaluations in
segmentation tasks.</p>
  </details>
</details>
<details>
  <summary>85. <b>标题：Towards Goal, Feasibility, and Diversity-Oriented Deep Generative Models  in Design</b></summary>
  <p><b>编号</b>：[235]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07170</p>
  <p><b>作者</b>：Lyle Regenwetter,  Faez Ahmed</p>
  <p><b>备注</b>：arXiv admin note: substantial text overlap with arXiv:2205.03005</p>
  <p><b>关键词</b>：Generative Machine Learning, Machine Learning Models, Machine Learning, Deep Generative Machine, Generative Machine</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep Generative Machine Learning Models (DGMs) have been growing in
popularity across the design community thanks to their ability to learn and
mimic complex data distributions. DGMs are conventionally trained to minimize
statistical divergence between the distribution over generated data and
distribution over the dataset on which they are trained. While sufficient for
the task of generating "realistic" fake data, this objective is typically
insufficient for design synthesis tasks. Instead, design problems typically
call for adherence to design requirements, such as performance targets and
constraints. Advancing DGMs in engineering design requires new training
objectives which promote engineering design objectives. In this paper, we
present the first Deep Generative Model that simultaneously optimizes for
performance, feasibility, diversity, and target achievement. We benchmark
performance of the proposed method against several Deep Generative Models over
eight evaluation metrics that focus on feasibility, diversity, and satisfaction
of design performance targets. Methods are tested on a challenging
multi-objective bicycle frame design problem with skewed, multimodal data of
different datatypes. The proposed framework was found to outperform all Deep
Generative Models in six of eight metrics.</p>
  </details>
</details>
<details>
  <summary>86. <b>标题：Regularizing a Model-based Policy Stationary Distribution to Stabilize  Offline Reinforcement Learning</b></summary>
  <p><b>编号</b>：[237]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07166</p>
  <p><b>作者</b>：Shentao Yang,  Yihao Feng,  Shujian Zhang,  Mingyuan Zhou</p>
  <p><b>备注</b>：International Conference on Machine Learning (ICML) 2022</p>
  <p><b>关键词</b>：Offline reinforcement learning, reinforcement learning, purely learning, extends the paradigm, undiscounted stationary distribution</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Offline reinforcement learning (RL) extends the paradigm of classical RL
algorithms to purely learning from static datasets, without interacting with
the underlying environment during the learning process. A key challenge of
offline RL is the instability of policy training, caused by the mismatch
between the distribution of the offline data and the undiscounted stationary
state-action distribution of the learned policy. To avoid the detrimental
impact of distribution mismatch, we regularize the undiscounted stationary
distribution of the current policy towards the offline data during the policy
optimization process. Further, we train a dynamics model to both implement this
regularization and better estimate the stationary distribution of the current
policy, reducing the error induced by distribution mismatch. On a wide range of
continuous-control offline RL datasets, our method indicates competitive
performance, which validates our algorithm. The code is publicly available.</p>
  </details>
</details>
<details>
  <summary>87. <b>标题：DeepRecon: Joint 2D Cardiac Segmentation and 3D Volume Reconstruction  via A Structure-Specific Generative Method</b></summary>
  <p><b>编号</b>：[239]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07163</p>
  <p><b>作者</b>：Qi Chang,  Zhennan Yan,  Mu Zhou,  Di Liu,  Khalid Sawalha,  Meng Ye,  Qilong Zhangli,  Mikael Kanski,  Subhi Al Aref,  Leon Axel,  Dimitris Metaxas</p>
  <p><b>备注</b>：MICCAI2022</p>
  <p><b>关键词</b>：understanding functional mechanisms, building statistical cardiac, statistical cardiac anatomy, fundamental to building, building statistical</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Joint 2D cardiac segmentation and 3D volume reconstruction are fundamental to
building statistical cardiac anatomy models and understanding functional
mechanisms from motion patterns. However, due to the low through-plane
resolution of cine MR and high inter-subject variance, accurately segmenting
cardiac images and reconstructing the 3D volume are challenging. In this study,
we propose an end-to-end latent-space-based framework, DeepRecon, that
generates multiple clinically essential outcomes, including accurate image
segmentation, synthetic high-resolution 3D image, and 3D reconstructed volume.
Our method identifies the optimal latent representation of the cine image that
contains accurate semantic information for cardiac structures. In particular,
our model jointly generates synthetic images with accurate semantic information
and segmentation of the cardiac structures using the optimal latent
representation. We further explore downstream applications of 3D shape
reconstruction and 4D motion pattern adaptation by the different latent-space
manipulation strategies.The simultaneously generated high-resolution images
present a high interpretable value to assess the cardiac shape and
motion.Experimental results demonstrate the effectiveness of our approach on
multiple fronts including 2D segmentation, 3D reconstruction, downstream 4D
motion pattern adaption performance.</p>
  </details>
</details>
<details>
  <summary>88. <b>标题：Category-Agnostic 6D Pose Estimation with Conditional Neural Processes</b></summary>
  <p><b>编号</b>：[240]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07162</p>
  <p><b>作者</b>：Yumeng Li,  Ning Gao,  Hanna Ziesche,  Gerhard Neumann</p>
  <p><b>备注</b>：Accepted at CVPR2022 workshop: Women in Computer Vision (WiCV)</p>
  <p><b>关键词</b>：pose estimation methods, pose estimation, meta-learning approach, pose, unknown objects</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present a novel meta-learning approach for 6D pose estimation on unknown
objects. In contrast to "instance-level" pose estimation methods, our algorithm
learns object representation in a category-agnostic way, which endows it with
strong generalization capabilities within and across object categories.
Specifically, we employ a conditional neural process-based meta-learning
approach to train an encoder to capture texture and geometry of an object in a
latent representation, based on very few RGB-D images and ground-truth
keypoints. The latent representation is then used by a simultaneously
meta-trained decoder to predict the 6D pose of the object in new images. To
evaluate our algorithm, experiments are conducted on our new fully-annotated
synthetic datasets generated from Multiple Categories in Multiple Scenes
(MCMS). Experimental results demonstrate that our model performs well on unseen
objects with various shapes and appearances.</p>
  </details>
</details>
<details>
  <summary>89. <b>标题：GraphFM: Improving Large-Scale GNN Training via Feature Momentum</b></summary>
  <p><b>编号</b>：[241]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07161</p>
  <p><b>作者</b>：Haiyang Yu,  Limei Wang,  Bokun Wang,  Meng Liu,  Tianbao Yang,  Shuiwang Ji</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：graph neural networks, neural networks, classification is challenging, node classification, large-scale node classification</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Training of graph neural networks (GNNs) for large-scale node classification
is challenging. A key difficulty lies in obtaining accurate hidden node
representations while avoiding the neighborhood explosion problem. Here, we
propose a new technique, named as feature momentum (FM), that uses a momentum
step to incorporate historical embeddings when updating feature
representations. We develop two specific algorithms, known as GraphFM-IB and
GraphFM-OB, that consider in-batch and out-of-batch data, respectively.
GraphFM-IB applies FM to in-batch sampled data, while GraphFM-OB applies FM to
out-of-batch data that are 1-hop neighborhood of in-batch data. We provide a
rigorous convergence analysis for GraphFM-IB and theoretical insight of
GraphFM-OB for the estimation error of feature embeddings. Empirically, we
observe that GraphFM-IB can effectively alleviate the neighborhood explosion
problem of existing methods. In addition, GraphFM-OB achieves promising
performance on multiple large-scale graph datasets.</p>
  </details>
</details>
<details>
  <summary>90. <b>标题：Self-Supervision on Images and Text Reduces Reliance on Visual Shortcut  Features</b></summary>
  <p><b>编号</b>：[243]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07155</p>
  <p><b>作者</b>：Anil Palepu,  Andrew L Beam</p>
  <p><b>备注</b>：4 pages, 2 figures, accepted at SCIS workshop, ICML 2022</p>
  <p><b>关键词</b>：Deep learning models, Shortcut features, Deep learning, rely on so-called, learning models trained</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep learning models trained in a fully supervised manner have been shown to
rely on so-called "shortcut" features. Shortcut features are inputs that are
associated with the outcome of interest in the training data, but are either no
longer associated or not present in testing or deployment settings. Here we
provide experiments that show recent self-supervised models trained on images
and text provide more robust image representations and reduce the model's
reliance on visual shortcut features on a realistic medical imaging example.
Additionally, we find that these self-supervised models "forget" shortcut
features more quickly than fully supervised ones when fine-tuned on labeled
data. Though not a complete solution, our experiments provide compelling
evidence that self-supervised models trained on images and text provide some
resilience to visual shortcut features.</p>
  </details>
</details>
<details>
  <summary>91. <b>标题：An Intelligent Assistant for Converting City Requirements to Formal  Specification</b></summary>
  <p><b>编号</b>：[244]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07152</p>
  <p><b>作者</b>：Zirong Chen,  Isaac Li,  Haoxiang Zhang,  Sarah Preum,  John Stankovic,  Meiyi Ma</p>
  <p><b>备注</b>：This demo paper is accepted by SMARTCOMP 2022</p>
  <p><b>关键词</b>：higher demand, demand for converting, converting new human-specified, smart cities, formal specifications automatically</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As more and more monitoring systems have been deployed to smart cities, there
comes a higher demand for converting new human-specified requirements to
machine-understandable formal specifications automatically. However, these
human-specific requirements are often written in English and bring missing,
inaccurate, or ambiguous information. In this paper, we present CitySpec, an
intelligent assistant system for requirement specification in smart cities.
CitySpec not only helps overcome the language differences brought by English
requirements and formal specifications, but also offers solutions to those
missing, inaccurate, or ambiguous information. The goal of this paper is to
demonstrate how CitySpec works. Specifically, we present three demos: (1)
interactive completion of requirements in CitySpec; (2) human-in-the-loop
correction while CitySepc encounters exceptions; (3) online learning in
CitySpec.</p>
  </details>
</details>
<details>
  <summary>92. <b>标题：Flatten the Curve: Efficiently Training Low-Curvature Neural Networks</b></summary>
  <p><b>编号</b>：[248]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07144</p>
  <p><b>作者</b>：Suraj Srinivas,  Kyle Matoba,  Himabindu Lakkaraju,  Francois Fleuret</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：highly non-linear nature, hinders interpretability, highly non-linear, non-linear nature, nature of deep</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The highly non-linear nature of deep neural networks causes them to be
susceptible to adversarial examples and have unstable gradients which hinders
interpretability. However, existing methods to solve these issues, such as
adversarial training, are expensive and often sacrifice predictive accuracy.
In this work, we consider curvature, which is a mathematical quantity which
encodes the degree of non-linearity. Using this, we demonstrate low-curvature
neural networks (LCNNs) that obtain drastically lower curvature than standard
models while exhibiting similar predictive performance, which leads to improved
robustness and stable gradients, with only a marginally increased training
time. To achieve this, we minimize a data-independent upper bound on the
curvature of a neural network, which decomposes overall curvature in terms of
curvatures and slopes of its constituent layers. To efficiently minimize this
bound, we introduce two novel architectural components: first, a non-linearity
called centered-softplus that is a stable variant of the softplus
non-linearity, and second, a Lipschitz-constrained batch normalization layer.
Our experiments show that LCNNs have lower curvature, more stable gradients
and increased off-the-shelf adversarial robustness when compared to their
standard high-curvature counterparts, all without affecting predictive
performance. Our approach is easy to use and can be readily incorporated into
existing neural network models.</p>
  </details>
</details>
<details>
  <summary>93. <b>标题：MBGDT:Robust Mini-Batch Gradient Descent</b></summary>
  <p><b>编号</b>：[249]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07139</p>
  <p><b>作者</b>：Hanming Wang,  Haozheng Luo,  Yue Wang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：mini-batch gradient descent, gradient descent, machine learning method, learning method perform, method perform fragile</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In high dimensions, most machine learning method perform fragile even there
are a little outliers. To address this, we hope to introduce a new method with
the base learner, such as Bayesian regression or stochastic gradient descent to
solve the problem of the vulnerability in the model. Because the mini-batch
gradient descent allows for a more robust convergence than the batch gradient
descent, we work a method with the mini-batch gradient descent, called
Mini-Batch Gradient Descent with Trimming (MBGDT). Our method show state-of-art
performance and have greater robustness than several baselines when we apply
our method in designed dataset.</p>
  </details>
</details>
<details>
  <summary>94. <b>标题：Prioritized Training on Points that are Learnable, Worth Learning, and  Not Yet Learnt</b></summary>
  <p><b>编号</b>：[250]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07137</p>
  <p><b>作者</b>：Sören Mindermann,  Jan Brauner,  Muhammed Razzak,  Mrinank Sharma,  Andreas Kirsch,  Winnie Xu,  Benedikt Höltgen,  Aidan N. Gomez,  Adrien Morisot,  Sebastian Farquhar,  Yarin Gal</p>
  <p><b>备注</b>：ICML 2022. follow up to workshop version arXiv:2107.02565</p>
  <p><b>关键词</b>：Reducible Holdout Loss, points, Holdout Loss Selection, RHO-LOSS, introduce Reducible Holdout</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Training on web-scale data can take months. But much computation and time is
wasted on redundant and noisy points that are already learnt or not learnable.
To accelerate training, we introduce Reducible Holdout Loss Selection
(RHO-LOSS), a simple but principled technique which selects approximately those
points for training that most reduce the model's generalization loss. As a
result, RHO-LOSS mitigates the weaknesses of existing data selection methods:
techniques from the optimization literature typically select 'hard' (e.g. high
loss) points, but such points are often noisy (not learnable) or less
task-relevant. Conversely, curriculum learning prioritizes 'easy' points, but
such points need not be trained on once learned. In contrast, RHO-LOSS selects
points that are learnable, worth learning, and not yet learnt. RHO-LOSS trains
in far fewer steps than prior art, improves accuracy, and speeds up training on
a wide range of datasets, hyperparameters, and architectures (MLPs, CNNs, and
BERT). On the large web-scraped image dataset Clothing-1M, RHO-LOSS trains in
18x fewer steps and reaches 2% higher final accuracy than uniform data
shuffling.</p>
  </details>
</details>
<details>
  <summary>95. <b>标题：Automatic Clipping: Differentially Private Deep Learning Made Easier and  Stronger</b></summary>
  <p><b>编号</b>：[251]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07136</p>
  <p><b>作者</b>：Zhiqi Bu,  Yu-Xiang Wang,  Sheng Zha,  George Karypis</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：deep learning models, key algorithmic step, enables practical differential, Per-example gradient clipping, practical differential private</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Per-example gradient clipping is a key algorithmic step that enables
practical differential private (DP) training for deep learning models. The
choice of clipping norm $R$, however, is shown to be vital for achieving high
accuracy under DP. We propose an easy-to-use replacement, called AutoClipping,
that eliminates the need to tune $R$ for any DP optimizers, including DP-SGD,
DP-Adam, DP-LAMB and many others. The automatic variants are as private and
computationally efficient as existing DP optimizers, but require no DP-specific
hyperparameters and thus make DP training as amenable as the standard
non-private training. We give a rigorous convergence analysis of automatic
DP-SGD in the non-convex setting, which shows that it enjoys an asymptotic
convergence rate that matches the standard SGD. We also demonstrate on various
language and vision tasks that automatic clipping outperforms or matches the
state-of-the-art, and can be easily employed with minimal changes to existing
codebases.</p>
  </details>
</details>
<details>
  <summary>96. <b>标题：Lazy Queries Can Reduce Variance in Zeroth-order Optimization</b></summary>
  <p><b>编号</b>：[253]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07126</p>
  <p><b>作者</b>：Quan Xiao,  Qing Ling,  Tianyi Chen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：applying zeroth-order, LAZO, major challenge, challenge of applying, high query complexity</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A major challenge of applying zeroth-order (ZO) methods is the high query
complexity, especially when queries are costly. We propose a novel gradient
estimation technique for ZO methods based on adaptive lazy queries that we term
as LAZO. Different from the classic one-point or two-point gradient estimation
methods, LAZO develops two alternative ways to check the usefulness of old
queries from previous iterations, and then adaptively reuses them to construct
the low-variance gradient estimates. We rigorously establish that through
judiciously reusing the old queries, LAZO can reduce the variance of stochastic
gradient estimates so that it not only saves queries per iteration but also
achieves the regret bound for the symmetric two-point method. We evaluate the
numerical performance of LAZO, and demonstrate the low-variance property and
the performance gain of LAZO in both regret and query complexity relative to
several existing ZO methods. The idea of LAZO is general, and can be applied to
other variants of ZO methods.</p>
  </details>
</details>
<details>
  <summary>97. <b>标题：A Collaboration Strategy in the Mining Pool for  Proof-of-Neural-Architecture Consensus</b></summary>
  <p><b>编号</b>：[269]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07089</p>
  <p><b>作者</b>：Boyang Li,  Qing Lu,  Weiwen Jiang,  Taeho Jung,  Yiyu Shi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：accessible cryptocurrency systems, public accessible cryptocurrency, popular public accessible, mining pool, mining pool plays</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In most popular public accessible cryptocurrency systems, the mining pool
plays a key role because mining cryptocurrency with the mining pool turns the
non-profitable situation into profitable for individual miners. In many recent
novel blockchain consensuses, the deep learning training procedure becomes the
task for miners to prove their workload, thus the computation power of miners
will not purely be spent on the hash puzzle. In this way, the hardware and
energy will support the blockchain service and deep learning training
simultaneously. While the incentive of miners is to earn tokens, individual
miners are motivated to join mining pools to become more competitive. In this
paper, we are the first to demonstrate a mining pool solution for novel
consensuses based on deep learning.
The mining pool manager partitions the full searching space into subspaces
and all miners are scheduled to collaborate on the Neural Architecture Search
(NAS) tasks in the assigned subspace. Experiments demonstrate that the
performance of this type of mining pool is more competitive than an individual
miner. Due to the uncertainty of miners' behaviors, the mining pool manager
checks the standard deviation of the performance of high reward miners and
prepares backup miners to ensure the completion of the tasks of high reward
miners.</p>
  </details>
</details>
<details>
  <summary>98. <b>标题：Combining Counterfactuals With Shapley Values To Explain Image Models</b></summary>
  <p><b>编号</b>：[271]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07087</p>
  <p><b>作者</b>：Aditya Lahiri,  Kamran Alipour,  Ehsan Adeli,  Babak Salimi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：sophisticated machine learning, machine learning models, sensitive applications, understanding their decision-making, sophisticated machine</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>With the widespread use of sophisticated machine learning models in sensitive
applications, understanding their decision-making has become an essential task.
Models trained on tabular data have witnessed significant progress in
explanations of their underlying decision making processes by virtue of having
a small number of discrete features. However, applying these methods to
high-dimensional inputs such as images is not a trivial task. Images are
composed of pixels at an atomic level and do not carry any interpretability by
themselves. In this work, we seek to use annotated high-level interpretable
features of images to provide explanations. We leverage the Shapley value
framework from Game Theory, which has garnered wide acceptance in general XAI
problems. By developing a pipeline to generate counterfactuals and subsequently
using it to estimate Shapley values, we obtain contrastive and interpretable
explanations with strong axiomatic guarantees.</p>
  </details>
</details>
<details>
  <summary>99. <b>标题：Understanding the Generalization Benefit of Normalization Layers:  Sharpness Reduction</b></summary>
  <p><b>编号</b>：[273]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07085</p>
  <p><b>作者</b>：Kaifeng Lyu,  Zhiyuan Li,  Sanjeev Arora</p>
  <p><b>备注</b>：68 pages, many figures</p>
  <p><b>关键词</b>：Batch Normalization, optimization difficulties, Normalization layers, Layer Normalization, Normalization</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Normalization layers (e.g., Batch Normalization, Layer Normalization) were
introduced to help with optimization difficulties in very deep nets, but they
clearly also help generalization, even in not-so-deep nets. Motivated by the
long-held belief that flatter minima lead to better generalization, this paper
gives mathematical analysis and supporting experiments suggesting that
normalization (together with accompanying weight-decay) encourages GD to reduce
the sharpness of loss surface. Here "sharpness" is carefully defined given that
the loss is scale-invariant, a known consequence of normalization.
Specifically, for a fairly broad class of neural nets with normalization, our
theory explains how GD with a finite learning rate enters the so-called Edge of
Stability (EoS) regime, and characterizes the trajectory of GD in this regime
via a continuous sharpness-reduction flow.</p>
  </details>
</details>
<details>
  <summary>100. <b>标题：Applications of Generative Adversarial Networks in Neuroimaging and  Clinical Neuroscience</b></summary>
  <p><b>编号</b>：[276]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07081</p>
  <p><b>作者</b>：Rongguang Wang,  Vishnu Bashyam,  Zhijian Yang,  Fanyang Yu,  Vasiliki Tassopoulou,  Lasya P. Sreepada,  Sai Spandana Chintapalli,  Dushyant Sahoo,  Ioanna Skampardoni,  Konstantina Nikita,  Ahmed Abdulkadir,  Junhao Wen,  Christos Davatzikos</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Generative adversarial networks, adversarial networks, numerous fields, powerful type, successfully utilized</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Generative adversarial networks (GANs) are one powerful type of deep learning
models that have been successfully utilized in numerous fields. They belong to
a broader family called generative methods, which generate new data with a
probabilistic model by learning sample distribution from real examples. In the
clinical context, GANs have shown enhanced capabilities in capturing spatially
complex, nonlinear, and potentially subtle disease effects compared to
traditional generative methods. This review appraises the existing literature
on the applications of GANs in imaging studies of various neurological
conditions, including Alzheimer's disease, brain tumors, brain aging, and
multiple sclerosis. We provide an intuitive explanation of various GAN methods
for each application and further discuss the main challenges, open questions,
and promising future directions of leveraging GANs in neuroimaging. We aim to
bridge the gap between advanced deep learning methods and neurology research by
highlighting how GANs can be leveraged to support clinical decision making and
contribute to a better understanding of the structural and functional patterns
of brain diseases.</p>
  </details>
</details>
<details>
  <summary>101. <b>标题：MACE: Higher Order Equivariant Message Passing Neural Networks for Fast  and Accurate Force Fields</b></summary>
  <p><b>编号</b>：[281]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07697</p>
  <p><b>作者</b>：Ilyes Batatia,  Dávid Péter Kovács,  Gregor N. C. Simm,  Christoph Ortner,  Gábor Csányi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：accurate force fields, materials science, accurate force, force fields, long-standing challenge</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Creating fast and accurate force fields is a long-standing challenge in
computational chemistry and materials science. Recently, several equivariant
message passing neural networks (MPNNs) have been shown to outperform models
built using other approaches in terms of accuracy. However, most MPNNs suffer
from high computational cost and poor scalability. We propose that these
limitations arise because MPNNs only pass two-body messages leading to a direct
relationship between the number of layers and the expressivity of the network.
In this work, we introduce MACE, a new equivariant MPNN model that uses higher
body order messages. In particular, we show that using four-body messages
reduces the required number of message passing iterations to just \emph{two},
resulting in a fast and highly parallelizable model, reaching or exceeding
state-of-the-art accuracy on the rMD17, 3BPA, and AcAc benchmark tasks. We also
demonstrate that using higher order messages leads to an improved steepness of
the learning curves.</p>
  </details>
</details>
<details>
  <summary>102. <b>标题：Wide Bayesian neural networks have a simple weight posterior: theory and  accelerated sampling</b></summary>
  <p><b>编号</b>：[283]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07673</p>
  <p><b>作者</b>：Jiri Hron,  Roman Novak,  Jeffrey Pennington,  Jascha Sohl-Dickstein</p>
  <p><b>备注</b>：ICML 2022</p>
  <p><b>关键词</b>：Bayesian neural network, BNN prior vanishes, transforms a Bayesian, neural network Gaussian, Bayesian neural</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We introduce repriorisation, a data-dependent reparameterisation which
transforms a Bayesian neural network (BNN) posterior to a distribution whose KL
divergence to the BNN prior vanishes as layer widths grow. The repriorisation
map acts directly on parameters, and its analytic simplicity complements the
known neural network Gaussian process (NNGP) behaviour of wide BNNs in function
space. Exploiting the repriorisation, we develop a Markov chain Monte Carlo
(MCMC) posterior sampling algorithm which mixes faster the wider the BNN. This
contrasts with the typically poor performance of MCMC in high dimensions. We
observe up to 50x higher effective sample size relative to no reparametrisation
for both fully-connected and residual networks. Improvements are achieved at
all widths, with the margin between reparametrised and standard BNNs growing
with layer width.</p>
  </details>
</details>
<details>
  <summary>103. <b>标题：Analysis of Augmentations for Contrastive ECG Representation Learning</b></summary>
  <p><b>编号</b>：[285]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07656</p>
  <p><b>作者</b>：Sahar Soltanieh,  Ali Etemad,  Javad Hashemi</p>
  <p><b>备注</b>：This paper has been accepted to IJCNN 2022 conference</p>
  <p><b>关键词</b>：paper systematically investigates, paper systematically, systematically investigates, investigates the effectiveness, self-supervised contrastive learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper systematically investigates the effectiveness of various
augmentations for contrastive self-supervised learning of electrocardiogram
(ECG) signals and identifies the best parameters. The baseline of our proposed
self-supervised framework consists of two main parts: the contrastive learning
and the downstream task. In the first stage, we train an encoder using a number
of augmentations to extract generalizable ECG signal representations. We then
freeze the encoder and finetune a few linear layers with different amounts of
labelled data for downstream arrhythmia detection. We then experiment with
various augmentations techniques and explore a range of parameters. Our
experiments are done on PTB-XL, a large and publicly available 12-lead ECG
dataset. The results show that applying augmentations in a specific range of
complexities works better for self-supervised contrastive learning. For
instance, when adding Gaussian noise, a sigma in the range of 0.1 to 0.2
achieves better results, while poor training occurs when the added noise is too
small or too large (outside of the specified range). A similar trend is
observed with other augmentations, demonstrating the importance of selecting
the optimum level of difficulty for the added augmentations, as augmentations
that are too simple will not result in effective training, while augmentations
that are too difficult will also prevent the model from effective learning of
generalized representations. Our work can influence future research on
self-supervised contrastive learning on bio-signals and aid in selecting
optimum parameters for different augmentations.</p>
  </details>
</details>
<details>
  <summary>104. <b>标题：Classification of EEG Motor Imagery Using Deep Learning for  Brain-Computer Interface Systems</b></summary>
  <p><b>编号</b>：[286]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07655</p>
  <p><b>作者</b>：Alessandro Gallo,  Manh Duong Phung</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Convolutional Neural Network, class Convolutional Neural, Neural Network, fed pre-processed electroencephalography, Convolutional Neural</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A trained T1 class Convolutional Neural Network (CNN) model will be used to
examine its ability to successfully identify motor imagery when fed
pre-processed electroencephalography (EEG) data. In theory, and if the model
has been trained accurately, it should be able to identify a class and label it
accordingly. The CNN model will then be restored and used to try and identify
the same class of motor imagery data using much smaller sampled data in an
attempt to simulate live data.</p>
  </details>
</details>
<details>
  <summary>105. <b>标题：Human Activity Recognition on Time Series Accelerometer Sensor Data  using LSTM Recurrent Neural Networks</b></summary>
  <p><b>编号</b>：[287]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07654</p>
  <p><b>作者</b>：Chrisogonas O. Odhiambo,  Sanjoy Saha,  Corby K. Martin,  Homayoun Valafar</p>
  <p><b>备注</b>：8 pages, Accepted for publication at 2022 CSCE Conference (SPRINGER NATURE - Research Book Series)</p>
  <p><b>关键词</b>：pervaded everyday life, applications including human, human activity monitoring, including human activity, social networks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The use of sensors available through smart devices has pervaded everyday life
in several applications including human activity monitoring, healthcare, and
social networks. In this study, we focus on the use of smartwatch accelerometer
sensors to recognize eating activity. More specifically, we collected sensor
data from 10 participants while consuming pizza. Using this information, and
other comparable data available for similar events such as smoking and
medication-taking, and dissimilar activities of jogging, we developed a
LSTM-ANN architecture that has demonstrated 90% success in identifying
individual bites compared to a puff, medication-taking or jogging activities.</p>
  </details>
</details>
<details>
  <summary>106. <b>标题：Two-stage Human Activity Recognition on Microcontrollers with Decision  Trees and CNNs</b></summary>
  <p><b>编号</b>：[288]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07652</p>
  <p><b>作者</b>：Francesco Daghero,  Daniele Jahier Pagliari,  Massimo Poncino</p>
  <p><b>备注</b>：Accepted as a conference paper at the 2022 IEEE International Conference on Ph. D. Research in Microelectronics and Electronics (PRIME)</p>
  <p><b>关键词</b>：Human Activity Recognition, Activity Recognition, increasingly popular task, Human Activity, classic Machine Learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Human Activity Recognition (HAR) has become an increasingly popular task for
embedded devices such as smartwatches. Most HAR systems for ultra-low power
devices are based on classic Machine Learning (ML) models, whereas Deep
Learning (DL), although reaching state-of-the-art accuracy, is less popular due
to its high energy consumption, which poses a significant challenge for
battery-operated and resource-constrained devices. In this work, we bridge the
gap between on-device HAR and DL thanks to a hierarchical architecture composed
of a decision tree (DT) and a one dimensional Convolutional Neural Network (1D
CNN). The two classifiers operate in a cascaded fashion on two different
sub-tasks: the DT classifies only the easiest activities, while the CNN deals
with more complex ones. With experiments on a state-of-the-art dataset and
targeting a single-core RISC-V MCU, we show that this approach allows to save
up to 67.7% energy w.r.t. a "stand-alone" DL architecture at iso-accuracy.
Additionally, the two-stage system either introduces a negligible memory
overhead (up to 200 B) or on the contrary, reduces the total memory occupation.</p>
  </details>
</details>
<details>
  <summary>107. <b>标题：Flexible Raman Amplifier Optimization Based on Machine Learning-aided  Physical Stimulated Raman Scattering Model</b></summary>
  <p><b>编号</b>：[289]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07650</p>
  <p><b>作者</b>：Metodi Plamenov Yankov,  Francesco Da Ros,  Uiara Celine de Moura,  Andrea Carena,  Darko Zibar</p>
  <p><b>备注</b>：submitted to Journal of Lightwave Technology. Extended version of the previous conference paper M. Yankov, D. Zibar, A. Carena, and F. Da Ros, "Forward Raman amplifier optimization using machine learning-aided physical modeling," accepted, Optoelectronics and Communications Conference (OECC), 2022</p>
  <p><b>关键词</b>：Raman amplifier optimization, Raman amplifier, forward-propagating Raman pumps, Raman, Raman gain coefficient</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The problem of Raman amplifier optimization is studied. A differentiable
interpolation function is obtained for the Raman gain coefficient using machine
learning (ML), which allows for the gradient descent optimization of
forward-propagating Raman pumps. Both the frequency and power of an arbitrary
number of pumps in a forward pumping configuration are then optimized for an
arbitrary data channel load and span length. The forward propagation model is
combined with an experimentally-trained ML model of a backward-pumping Raman
amplifier to jointly optimize the frequency and power of the forward
amplifier's pumps and the powers of the backward amplifier's pumps. The joint
forward and backward amplifier optimization is demonstrated for an unrepeatered
transmission of 250 km. A gain flatness of $<$ 4 1~db over thz is achieved. the optimized amplifiers are validated using a numerical simulator.< p>
  </$></p></details>
</details>
<details>
  <summary>108. <b>标题：Atrial Fibrillation Detection Using Weight-Pruned, Log-Quantised  Convolutional Neural Networks</b></summary>
  <p><b>编号</b>：[290]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07649</p>
  <p><b>作者</b>：Xiu Qi Chang,  Ann Feng Chew,  Benjamin Chen Ming Choong,  Shuhui Wang,  Rui Han,  Wang He,  Li Xiaolin,  Rajesh C. Panicker,  Deepu John</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Deep neural networks, medical applications, promising tool, tool in medical, Deep neural</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep neural networks (DNN) are a promising tool in medical applications.
However, the implementation of complex DNNs on battery-powered devices is
challenging due to high energy costs for communication. In this work, a
convolutional neural network model is developed for detecting atrial
fibrillation from electrocardiogram (ECG) signals. The model demonstrates high
performance despite being trained on limited, variable-length input data.
Weight pruning and logarithmic quantisation are combined to introduce sparsity
and reduce model size, which can be exploited for reduced data movement and
lower computational complexity. The final model achieved a 91.1% model
compression ratio while maintaining high model accuracy of 91.7% and less than
1% loss.</p>
  </details>
</details>
<details>
  <summary>109. <b>标题：Classification of ECG based on Hybrid Features using CNNs for Wearable  Applications</b></summary>
  <p><b>编号</b>：[291]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07648</p>
  <p><b>作者</b>：Li Xiaolin,  Fang Xiang,  Rajesh C. Panicker,  Barry Cardiff,  Deepu John</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Sudden cardiac death, deaths worldwide, cardiac death, Sudden cardiac, large percentage</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Sudden cardiac death and arrhythmia account for a large percentage of all
deaths worldwide. Electrocardiography (ECG) is the most widely used screening
tool for cardiovascular diseases. Traditionally, ECG signals are classified
manually, requiring experience and great skill, while being time-consuming and
prone to error. Thus machine learning algorithms have been widely adopted
because of their ability to perform complex data analysis. Features derived
from the points of interest in ECG - mainly Q, R, and S, are widely used for
arrhythmia detection. In this work, we demonstrate improved performance for ECG
classification using hybrid features and three different models, building on a
1-D convolutional neural network (CNN) model that we had proposed in the past.
An RR interval features based model proposed in this work achieved an accuracy
of 98.98%, which is an improvement over the baseline model. To make the model
immune to noise, we updated the model using frequency features and achieved
good sustained performance in presence of noise with a slightly lower accuracy
of 98.69%. Further, another model combining the frequency features and the RR
interval features was developed, which achieved a high accuracy of 99% with
good sustained performance in noisy environments. Due to its high accuracy and
noise immunity, the proposed model which combines multiple hybrid features, is
well suited for ambulatory wearable sensing applications.</p>
  </details>
</details>
<details>
  <summary>110. <b>标题：Statistical and Computational Phase Transitions in Group Testing</b></summary>
  <p><b>编号</b>：[293]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07640</p>
  <p><b>作者</b>：Amin Coja-Oghlan,  Oliver Gebhard,  Max Hahn-Klimroth,  Alexander S. Wein,  Ilias Zadik</p>
  <p><b>备注</b>：Accepted for presentation at the Conference on Learning Theory (COLT) 2022</p>
  <p><b>关键词</b>：infected individuals carrying, Bernoulli design, infected individuals, carrying a rare, rare disease</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We study the group testing problem where the goal is to identify a set of k
infected individuals carrying a rare disease within a population of size n,
based on the outcomes of pooled tests which return positive whenever there is
at least one infected individual in the tested group. We consider two different
simple random procedures for assigning individuals to tests: the
constant-column design and Bernoulli design. Our first set of results concerns
the fundamental statistical limits. For the constant-column design, we give a
new information-theoretic lower bound which implies that the proportion of
correctly identifiable infected individuals undergoes a sharp "all-or-nothing"
phase transition when the number of tests crosses a particular threshold. For
the Bernoulli design, we determine the precise number of tests required to
solve the associated detection problem (where the goal is to distinguish
between a group testing instance and pure noise), improving both the upper and
lower bounds of Truong, Aldridge, and Scarlett (2020). For both group testing
models, we also study the power of computationally efficient (polynomial-time)
inference procedures. We determine the precise number of tests required for the
class of low-degree polynomial algorithms to solve the detection problem. This
provides evidence for an inherent computational-statistical gap in both the
detection and recovery problems at small sparsity levels. Notably, our evidence
is contrary to that of Iliopoulos and Zadik (2021), who predicted the absence
of a computational-statistical gap in the Bernoulli design.</p>
  </details>
</details>
<details>
  <summary>111. <b>标题：Asynchronous SGD Beats Minibatch SGD Under Arbitrary Delays</b></summary>
  <p><b>编号</b>：[294]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07638</p>
  <p><b>作者</b>：Konstantin Mishchenko,  Francis Bach,  Mathieu Even,  Blake Woodworth</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：performance depends primarily, stochastic gradient descent, asynchronous stochastic gradient, asynchronous SGD algorithm, asynchronous SGD</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The existing analysis of asynchronous stochastic gradient descent (SGD)
degrades dramatically when any delay is large, giving the impression that
performance depends primarily on the delay. On the contrary, we prove much
better guarantees for the same asynchronous SGD algorithm regardless of the
delays in the gradients, depending instead just on the number of parallel
devices used to implement the algorithm. Our guarantees are strictly better
than the existing analyses, and we also argue that asynchronous SGD outperforms
synchronous minibatch SGD in the settings we consider. For our analysis, we
introduce a novel recursion based on "virtual iterates" and delay-adaptive
stepsizes, which allow us to derive state-of-the-art guarantees for both convex
and non-convex objectives.</p>
  </details>
</details>
<details>
  <summary>112. <b>标题：Exploring Chemical Space with Score-based Out-of-distribution Generation</b></summary>
  <p><b>编号</b>：[295]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07632</p>
  <p><b>作者</b>：Seul Lee,  Jaehyeong Jo,  Sung Ju Hwang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：generated molecules highly, molecules highly resemble, well-known limitation, highly resemble, molecules</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A well-known limitation of existing works on molecule generation is that the
generated molecules highly resemble those in the training set. To generate
truly novel molecules with completely different structures that may have even
better properties than known molecules for de novo drug discovery, more
powerful exploration in the chemical space is necessary. To this end, we
propose Molecular Out-Of-distribution Diffusion (MOOD), a novel score-based
diffusion scheme that incorporates out-of-distribution (OOD) control in the
generative stochastic differential equation (SDE) with simple control of a
hyperparameter, thus requires no additional computational costs unlike existing
methods (e.g., RL-based methods). However, some novel molecules may be
chemically implausible, or may not meet the basic requirements of real-world
drugs. Thus, MOOD performs conditional generation by utilizing the gradients
from a property prediction network that guides the reverse-time diffusion to
high-scoring regions according to multiple target properties such as
protein-ligand interactions, drug-likeness, and synthesizability. This allows
MOOD to search for novel and meaningful molecules rather than generating unseen
yet trivial ones. We experimentally validate that MOOD is able to explore the
chemical space beyond the training distribution, generating molecules that
outscore ones found with existing methods, and even the top 0.01% of the
original training pool.</p>
  </details>
</details>
<details>
  <summary>113. <b>标题：Rethinking Initialization of the Sinkhorn Algorithm</b></summary>
  <p><b>编号</b>：[296]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07630</p>
  <p><b>作者</b>：James Thornton,  Marco Cuturi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：increasingly important role, Computing an optimal, optimal transport, coupling between distributions, machine learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Computing an optimal transport (OT) coupling between distributions plays an
increasingly important role in machine learning. While OT problems can be
solved as linear programs, adding an entropic smoothing term is known to result
in solvers that are faster and more robust to outliers, differentiable and
easier to parallelize. The Sinkhorn fixed point algorithm is the cornerstone of
these approaches, and, as a result, multiple attempts have been made to shorten
its runtime using, for instance, annealing, momentum or acceleration. The
premise of this paper is that \textit{initialization} of the Sinkhorn algorithm
has received comparatively little attention, possibly due to two
preconceptions: as the regularized OT problem is convex, it may not be worth
crafting a tailored initialization as \textit{any} is guaranteed to work;
secondly, because the Sinkhorn algorithm is often differentiated in end-to-end
pipelines, data-dependent initializations could potentially bias gradient
estimates obtained by unrolling iterations. We challenge this conventional
wisdom and show that carefully chosen initializations can result in dramatic
speed-ups, and will not bias gradients which are computed with implicit
differentiation. We detail how initializations can be recovered from
closed-form or approximate OT solutions, using known results in the 1D or
Gaussian settings. We show empirically that these initializations can be used
off-the-shelf, with little to no tuning, and result in consistent speed-ups for
a variety of OT problems.</p>
  </details>
</details>
<details>
  <summary>114. <b>标题：Sparse Subspace Clustering in Diverse Multiplex Network Model</b></summary>
  <p><b>编号</b>：[297]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07602</p>
  <p><b>作者</b>：Majid Noroozi,  Marianna Pensky</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Stochastic Block Models, Multilayer Stochastic Block, block connection probabilities, Stochastic Block, Pensky and Wang</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The paper considers the DIverse MultiPLEx (DIMPLE) network model, introduced
in Pensky and Wang (2021), where all layers of the network have the same
collection of nodes and are equipped with the Stochastic Block Models. In
addition, all layers can be partitioned into groups with the same community
structures, although the layers in the same group may have different matrices
of block connection probabilities. The DIMPLE model generalizes a multitude of
papers that study multilayer networks with the same community structures in all
layers, as well as the Mixture Multilayer Stochastic Block Model (MMLSBM),
where the layers in the same group have identical matrices of block connection
probabilities. While Pensky and Wang (2021) applied spectral clustering to the
proxy of the adjacency tensor, the present paper uses Sparse Subspace
Clustering (SSC) for identifying groups of layers with identical community
structures. Under mild conditions, the latter leads to the strongly consistent
between-layer clustering. In addition, SSC allows to handle much larger
networks than methodology of Pensky and Wang (2021), and is perfectly suitable
for application of parallel computing.</p>
  </details>
</details>
<details>
  <summary>115. <b>标题：BIO-CXRNET: A Robust Multimodal Stacking Machine Learning Technique for  Mortality Risk Prediction of COVID-19 Patients using Chest X-Ray Images and  Clinical Data</b></summary>
  <p><b>编号</b>：[299]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07595</p>
  <p><b>作者</b>：Tawsifur Rahman,  Muhammad E. H. Chowdhury,  Amith Khandakar,  Zaid Bin Mahbub,  Md Sakib Abrar Hossain,  Abraham Alhatou,  Eynas Abdalla,  Sreekumar Muthiyal,  Khandaker Farzana Islam,  Saad Bin Abul Kashem,  Muhammad Salman Khan,  Susu M. Zughaier,  Maqsud Hossain</p>
  <p><b>备注</b>：25 pages, 8 Tables, 10 Figures</p>
  <p><b>关键词</b>：high-risk patients, Fast and accurate, accurate detection, disease can significantly, reducing the strain</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Fast and accurate detection of the disease can significantly help in reducing
the strain on the healthcare facility of any country to reduce the mortality
during any pandemic. The goal of this work is to create a multimodal system
using a novel machine learning framework that uses both Chest X-ray (CXR)
images and clinical data to predict severity in COVID-19 patients. In addition,
the study presents a nomogram-based scoring technique for predicting the
likelihood of death in high-risk patients. This study uses 25 biomarkers and
CXR images in predicting the risk in 930 COVID-19 patients admitted during the
first wave of COVID-19 (March-June 2020) in Italy. The proposed multimodal
stacking technique produced the precision, sensitivity, and F1-score, of
89.03%, 90.44%, and 89.03%, respectively to identify low or high-risk patients.
This multimodal approach improved the accuracy by 6% in comparison to the CXR
image or clinical data alone. Finally, nomogram scoring system using
multivariate logistic regression -- was used to stratify the mortality risk
among the high-risk patients identified in the first stage. Lactate
Dehydrogenase (LDH), O2 percentage, White Blood Cells (WBC) Count, Age, and
C-reactive protein (CRP) were identified as useful predictor using random
forest feature selection model. Five predictors parameters and a CXR image
based nomogram score was developed for quantifying the probability of death and
categorizing them into two risk groups: survived (<50%), and death (>=50%),
respectively. The multi-modal technique was able to predict the death
probability of high-risk patients with an F1 score of 92.88 %. The area under
the curves for the development and validation cohorts are 0.981 and 0.939,
respectively.</50%),></p>
  </details>
</details>
<details>
  <summary>116. <b>标题：Robust and Sparse Estimation of Linear Regression Coefficients with  Heavy-tailed Noises and Covariates</b></summary>
  <p><b>编号</b>：[300]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07594</p>
  <p><b>作者</b>：Takeyuki Sasai</p>
  <p><b>备注</b>：22 pages</p>
  <p><b>关键词</b>：linear regression coefficients, Robust and sparse, coefficients is investigated, linear regression, regression coefficients</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Robust and sparse estimation of linear regression coefficients is
investigated. The situation addressed by the present paper is that covariates
and noises are sampled from heavy-tailed distributions, and the covariates and
noises are contaminated by malicious outliers. Our estimator can be computed
efficiently. Further, our estimation error bound is sharp.</p>
  </details>
</details>
<details>
  <summary>117. <b>标题：Characteristic kernels on Hilbert spaces, Banach spaces, and on sets of  measures</b></summary>
  <p><b>编号</b>：[301]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07588</p>
  <p><b>作者</b>：Johanna Ziegel,  David Ginsbourger,  Lutz Dümbgen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：strictly positive definite, integrally strictly positive, positive definite kernels, positive definite, strictly positive</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present new classes of positive definite kernels on non-standard spaces
that are integrally strictly positive definite or characteristic. In
particular, we discuss radial kernels on separable Hilbert spaces, and
introduce broad classes of kernels on Banach spaces and on metric spaces of
strong negative type. The general results are used to give explicit classes of
kernels on separable $L^p$ spaces and on sets of measures.</p>
  </details>
</details>
<details>
  <summary>118. <b>标题：A Deep Generative Model of Neonatal Cortical Surface Development</b></summary>
  <p><b>编号</b>：[305]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07542</p>
  <p><b>作者</b>：Abdulah Fawaz,  Logan Z. Williams,  Emma Robinson,  A. David Edwards</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：poorer neurodevelopmental outcomes, neonatal cortical surface, neurodevelopmental outcomes, cortical surface, poorer neurodevelopmental</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The neonatal cortical surface is known to be affected by preterm birth, and
the subsequent changes to cortical organisation have been associated with
poorer neurodevelopmental outcomes. Deep Generative models have the potential
to lead to clinically interpretable models of disease, but developing these on
the cortical surface is challenging since established techniques for learning
convolutional filters are inappropriate on non-flat topologies. To close this
gap, we implement a surface-based CycleGAN using mixture model CNNs (MoNet) to
translate sphericalised neonatal cortical surface features (curvature and
T1w/T2w cortical myelin) between different stages of cortical maturity. Results
show our method is able to reliably predict changes in individual patterns of
cortical organisation at later stages of gestation, validated by comparison to
longitudinal data; and translate appearance between preterm and term gestation
(> 37 weeks gestation), validated through comparison with a trained
term/preterm classifier. Simulated differences in cortical maturation are
consistent with observations in the literature.</p>
  </details>
</details>
<details>
  <summary>119. <b>标题：Smart Meter Data Anomaly Detection using Variational Recurrent  Autoencoders with Attention</b></summary>
  <p><b>编号</b>：[306]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07519</p>
  <p><b>作者</b>：Wenjing Dai,  Xiufeng Liu,  Alfred Heller,  Per Sieverts Nielsen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：smart meter data, operation and demand, monitor production, smart meters, meter data</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In the digitization of energy systems, sensors and smart meters are
increasingly being used to monitor production, operation and demand. Detection
of anomalies based on smart meter data is crucial to identify potential risks
and unusual events at an early stage, which can serve as a reference for timely
initiation of appropriate actions and improving management. However, smart
meter data from energy systems often lack labels and contain noise and various
patterns without distinctively cyclical. Meanwhile, the vague definition of
anomalies in different energy scenarios and highly complex temporal
correlations pose a great challenge for anomaly detection. Many traditional
unsupervised anomaly detection algorithms such as cluster-based or
distance-based models are not robust to noise and not fully exploit the
temporal dependency in a time series as well as other dependencies amongst
multiple variables (sensors). This paper proposes an unsupervised anomaly
detection method based on a Variational Recurrent Autoencoder with attention
mechanism. with "dirty" data from smart meters, our method pre-detects missing
values and global anomalies to shrink their contribution while training. This
paper makes a quantitative comparison with the VAE-based baseline approach and
four other unsupervised learning methods, demonstrating its effectiveness and
superiority. This paper further validates the proposed method by a real case
study of detecting the anomalies of water supply temperature from an industrial
heating plant.</p>
  </details>
</details>
<details>
  <summary>120. <b>标题：Binary Single-dimensional Convolutional Neural Network for Seizure  Prediction</b></summary>
  <p><b>编号</b>：[307]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07518</p>
  <p><b>作者</b>：Shiqi Zhao,  Jie Yang,  Yankun Xu,  Mohamad Sawan</p>
  <p><b>备注</b>：2020 IEEE International Symposium on Circuits and Systems (ISCAS)</p>
  <p><b>关键词</b>：deep learning methods, deep learning, epileptic seizure prediction, seizure prediction, learning methods</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Nowadays, several deep learning methods are proposed to tackle the challenge
of epileptic seizure prediction. However, these methods still cannot be
implemented as part of implantable or efficient wearable devices due to their
large hardware and corresponding high-power consumption. They usually require
complex feature extraction process, large memory for storing high precision
parameters and complex arithmetic computation, which greatly increases required
hardware resources. Moreover, available yield poor prediction performance,
because they adopt network architecture directly from image recognition
applications fails to accurately consider the characteristics of EEG signals.
We propose in this paper a hardware-friendly network called Binary
Single-dimensional Convolutional Neural Network (BSDCNN) intended for epileptic
seizure prediction. BSDCNN utilizes 1D convolutional kernels to improve
prediction performance. All parameters are binarized to reduce the required
computation and storage, except the first layer. Overall area under curve,
sensitivity, and false prediction rate reaches 0.915, 89.26%, 0.117/h and
0.970, 94.69%, 0.095/h on American Epilepsy Society Seizure Prediction
Challenge (AES) dataset and the CHB-MIT one respectively. The proposed
architecture outperforms recent works while offering 7.2 and 25.5 times
reductions on the size of parameter and computation, respectively.</p>
  </details>
</details>
<details>
  <summary>121. <b>标题：A Deep Learning Network for the Classification of Intracardiac  Electrograms in Atrial Tachycardia</b></summary>
  <p><b>编号</b>：[308]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07515</p>
  <p><b>作者</b>：Zerui Chen,  Sonia Xhyn Teo,  Andrie Ochtman,  Shier Nee Saw,  Nicholas Cheng,  Eric Tien Siang Lim,  Murphy Lyu,  Hwee Kuan Lee</p>
  <p><b>备注</b>：34 pages, 10 figures</p>
  <p><b>关键词</b>：acquired intracardiac electrogram, key technology enabling, catheter ablation treatment, local activation time, EGM signals</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A key technology enabling the success of catheter ablation treatment for
atrial tachycardia is activation mapping, which relies on manual local
activation time (LAT) annotation of all acquired intracardiac electrogram (EGM)
signals. This is a time-consuming and error-prone procedure, due to the
difficulty in identifying the signal activation peaks for fractionated signals.
This work presents a Deep Learning approach for the automated classification of
EGM signals into three different types: normal, abnormal, and unclassified,
which forms part of the LAT annotation pipeline, and contributes towards
bypassing the need for manual annotations of the LAT. The Deep Learning
network, the CNN-LSTM model, is a hybrid network architecture which combines
convolutional neural network (CNN) layers with long short-term memory (LSTM)
layers. 1452 EGM signals from a total of 9 patients undergoing
clinically-indicated 3D cardiac mapping were used for the training, validation
and testing of our models. From our findings, the CNN-LSTM model achieved an
accuracy of 81% for the balanced dataset. For comparison, we separately
developed a rule-based Decision Trees model which attained an accuracy of 67%
for the same balanced dataset. Our work elucidates that analysing the EGM
signals using a set of explicitly specified rules as proposed by the Decision
Trees model is not suitable as EGM signals are complex. The CNN-LSTM model, on
the other hand, has the ability to learn the complex, intrinsic features within
the signals and identify useful features to differentiate the EGM signals.</p>
  </details>
</details>
<details>
  <summary>122. <b>标题：Preliminary study on the impact of EEG density on TMS-EEG classification  in Alzheimer's disease</b></summary>
  <p><b>编号</b>：[309]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07492</p>
  <p><b>作者</b>：Alexandra-Maria Tautan,  Elias Casula,  Ilaria Borghi,  Michele Maiella,  Sonia Bonni,  Marilena Minei,  Martina Assogna,  Bogdan Ionescu,  Giacomo Koch,  Emiliano Santernacchi</p>
  <p><b>备注</b>：4 pages, 4 figures, accepted to the 44th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC), 11-15 July 2022, Glasgow, Scotland, UK</p>
  <p><b>关键词</b>：Transcranial magnetic stimulation, magnetic stimulation co-registered, Alzheimer disease, study of Alzheimer, Transcranial magnetic</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Transcranial magnetic stimulation co-registered with electroencephalographic
(TMS-EEG) has previously proven a helpful tool in the study of Alzheimer's
disease (AD). In this work, we investigate the use of TMS-evoked EEG responses
to classify AD patients from healthy controls (HC). By using a dataset
containing 17AD and 17HC, we extract various time domain features from
individual TMS responses and average them over a low, medium and high density
EEG electrode set. Within a leave-one-subject-out validation scenario, the best
classification performance for AD vs. HC was obtained using a high-density
electrode with a Random Forest classifier. The accuracy, sensitivity and
specificity were of 92.7%, 96.58% and 88.2% respectively.</p>
  </details>
</details>
<details>
  <summary>123. <b>标题：Topological Simplification of Signals for Inference and Approximate  Reconstruction</b></summary>
  <p><b>编号</b>：[311]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07486</p>
  <p><b>作者</b>：Gary Koplik,  Nathan Borggren,  Sam Voisin,  Gabrielle Angeloro,  Jay Hineman,  Tessa Johnson,  Paul Bendich</p>
  <p><b>备注</b>：10 pages, 12 figures</p>
  <p><b>关键词</b>：Internet of Things, increasingly finding solutions, computationally feasible, finding solutions, scientific curiosities</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As Internet of Things (IoT) devices become both cheaper and more powerful,
researchers are increasingly finding solutions to their scientific curiosities
both financially and computationally feasible. When operating with restricted
power or communications budgets, however, devices can only send
highly-compressed data. Such circumstances are common for devices placed away
from electric grids that can only communicate via satellite, a situation
particularly plausible for environmental sensor networks. These restrictions
can be further complicated by potential variability in the communications
budget, for example a solar-powered device needing to expend less energy when
transmitting data on a cloudy day. We propose a novel, topology-based, lossy
compression method well-equipped for these restrictive yet variable
circumstances. This technique, Topological Signal Compression, allows sending
compressed signals that utilize the entirety of a variable communications
budget. To demonstrate our algorithm's capabilities, we perform entropy
calculations as well as a classification exercise on increasingly topologically
simplified signals from the Free-Spoken Digit Dataset and explore the stability
of the resulting performance against common baselines.</p>
  </details>
</details>
<details>
  <summary>124. <b>标题：Intelligent analysis of EEG signals to assess consumer decisions: A  Study on Neuromarketing</b></summary>
  <p><b>编号</b>：[312]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07484</p>
  <p><b>作者</b>：Nikunj Phutela,  Abhilash P,  Kaushik Sreevathsan,  B N Krupa</p>
  <p><b>备注</b>：7 pages, 6 figures</p>
  <p><b>关键词</b>：influence consumer decisions, emerging field, field that combines, combines neuroscience, neuroscience and marketing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Neuromarketing is an emerging field that combines neuroscience and marketing
to understand the factors that influence consumer decisions better. The study
proposes a method to understand consumers' positive and negative reactions to
advertisements (ads) and products by analysing electroencephalogram (EEG)
signals. These signals are recorded using a low-cost single electrode headset
from volunteers belonging to the ages 18-22. A detailed subject dependent (SD)
and subject independent (SI) analysis was performed employing machine learning
methods like Naive Bayes (NB), Support Vector Machine (SVM), k-nearest
neighbour and Decision Tree and the proposed deep learning (DL) model. SVM and
NB yielded an accuracy (Acc.) of 0.63 for the SD analysis. In SI analysis, SVM
performed better for the advertisement, product and gender-based analysis.
Furthermore, the performance of the DL model was on par with that of SVM,
especially, in product and ads-based analysis.</p>
  </details>
</details>
<details>
  <summary>125. <b>标题：Blind Estimation of a Doubly Selective OFDM Channel: A Deep Learning  Algorithm and Theory</b></summary>
  <p><b>编号</b>：[313]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07483</p>
  <p><b>作者</b>：Tilahun M. Getu,  Nada T. Golmie,  David W. Griffith</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：frequency division multiplexing, orthogonal frequency division, doubly selective channel, doubly selective, division multiplexing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We provide a new generation solution to the fundamental old problem of a
doubly selective fading channel estimation for orthogonal frequency division
multiplexing (OFDM) systems. For systems based on OFDM, we propose a deep
learning (DL)-based blind doubly selective channel estimator. This estimator
does require no pilot symbols, unlike the corresponding state-of-the-art
estimators, even during the estimation of a deep fading doubly selective
channel. We also provide the first of its kind theory on the testing mean
squared error (MSE) performance of our investigated blind OFDM channel
estimator based on over-parameterized ReLU FNNs.</p>
  </details>
</details>
<details>
  <summary>126. <b>标题：A Survey of Detection Methods for Die Attachment and Wire Bonding  Defects in Integrated Circuit Manufacturing</b></summary>
  <p><b>编号</b>：[314]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07481</p>
  <p><b>作者</b>：Lamia Alam,  Nasser Kehtarnavaz</p>
  <p><b>备注</b>：13 pages, 9 figures, 8 tables</p>
  <p><b>关键词</b>：manufacturing process, integrated circuits, plays a vital, vital role, Defect detection plays</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Defect detection plays a vital role in the manufacturing process of
integrated circuits (ICs). Die attachment and wire bonding are two steps of the
manufacturing process that determine the quality and reliability of the power
and signal transmission in an IC. This paper presents a survey or literature
review of the methods used for detecting these defects based on different
sensing modalities used including optical, radiological, acoustical, and
infrared thermography. A discussion of the detection methods used is provided
in this survey. Both conventional and deep learning approaches for detecting
die attachment and wire bonding defects are considered along with challenges
and future research directions.</p>
  </details>
</details>
<details>
  <summary>127. <b>标题：Subsurface Depths Structure Maps Reconstruction with Generative  Adversarial Networks</b></summary>
  <p><b>编号</b>：[321]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07388</p>
  <p><b>作者</b>：Dmitry Ivlev</p>
  <p><b>备注</b>：12 pages, 12 figures, 1 table</p>
  <p><b>关键词</b>：detailed-resolution depth structure, seismic surveys, seismic depth maps, seismic maps, depth structure maps</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper described a method for reconstruction of detailed-resolution depth
structure maps, usually obtained after the 3D seismic surveys, using the data
from 2D seismic depth maps. The method uses two algorithms based on the
generative-adversarial neural network architecture. The first algorithm
StyleGAN2-ADA accumulates in the hidden space of the neural network the
semantic images of mountainous terrain forms first, and then with help of
transfer learning, in the ideal case - the structure geometry of stratigraphic
horizons. The second algorithm, the Pixel2Style2Pixel encoder, using the
semantic level of generalization of the first algorithm, learns to reconstruct
the original high-resolution images from their degraded copies
(super-resolution technology). There was demonstrated a methodological approach
to transferring knowledge on the structural forms of stratigraphic horizon
boundaries from the well-studied areas to the underexplored ones. Using the
multimodal synthesis of Pixel2Style2Pixel encoder, it is proposed to create a
probabilistic depth space, where each point of the project area is represented
by the density of probabilistic depth distribution of equally probable
reconstructed geological forms of structural images. Assessment of the
reconstruction quality was carried out for two blocks. Using this method,
credible detailed depth reconstructions comparable with the quality of 3D
seismic maps have been obtained from 2D seismic maps.</p>
  </details>
</details>
<details>
  <summary>128. <b>标题：Finite-Sample Guarantees for High-Dimensional DML</b></summary>
  <p><b>编号</b>：[322]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07386</p>
  <p><b>作者</b>：Victor Quintas-Martinez</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Debiased machine learning, estimate treatment effects, Debiased machine, machine learning, offers an attractive</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Debiased machine learning (DML) offers an attractive way to estimate
treatment effects in observational settings, where identification of causal
parameters requires a conditional independence or unconfoundedness assumption,
since it allows to control flexibly for a potentially very large number of
covariates. This paper gives novel finite-sample guarantees for joint inference
on high-dimensional DML, bounding how far the finite-sample distribution of the
estimator is from its asymptotic Gaussian approximation. These guarantees are
useful to applied researchers, as they are informative about how far off the
coverage of joint confidence bands can be from the nominal level. There are
many settings where high-dimensional causal parameters may be of interest, such
as the ATE of many treatment profiles, or the ATE of a treatment on many
outcomes. We also cover infinite-dimensional parameters, such as impacts on the
entire marginal distribution of potential outcomes. The finite-sample
guarantees in this paper complement the existing results on consistency and
asymptotic normality of DML estimators, which are either asymptotic or treat
only the one-dimensional case.</p>
  </details>
</details>
<details>
  <summary>129. <b>标题：Lattice Convolutional Networks for Learning Ground States of Quantum  Many-Body Systems</b></summary>
  <p><b>编号</b>：[324]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07370</p>
  <p><b>作者</b>：Cong Fu,  Xuan Zhang,  Huixin Zhang,  Hongyi Ling,  Shenglong Xu,  Shuiwang Ji</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：quantum many-body systems, representing ground-state wave, ground-state wave functions, Deep learning methods, Deep learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep learning methods have been shown to be effective in representing
ground-state wave functions of quantum many-body systems. Existing methods use
convolutional neural networks (CNNs) for square lattices due to their
image-like structures. For non-square lattices, existing method uses graph
neural network (GNN) in which structure information is not precisely captured,
thereby requiring additional hand-crafted sublattice encoding. In this work, we
propose lattice convolutions in which a set of proposed operations are used to
convert non-square lattices into grid-like augmented lattices on which regular
convolution can be applied. Based on the proposed lattice convolutions, we
design lattice convolutional networks (LCN) that use self-gating and attention
mechanisms. Experimental results show that our method achieves performance on
par or better than existing methods on spin 1/2 $J_1$-$J_2$ Heisenberg model
over the square, honeycomb, triangular, and kagome lattices while without using
hand-crafted encoding.</p>
  </details>
</details>
<details>
  <summary>130. <b>标题：Detection of magnetohydrodynamic waves by using machine learning</b></summary>
  <p><b>编号</b>：[326]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07334</p>
  <p><b>作者</b>：Fang Chen,  Ravi Samtaney</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：MHD wave detection, MHD wave, inclined density interface, MHD wave types, MHD</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Nonlinear wave interactions, such as shock refraction at an inclined density
interface, in magnetohydrodynamic (MHD) lead to a plethora of wave patterns
with myriad wave types. Identification of different types of MHD waves is an
important and challenging task in such complex wave patterns. Moreover, owing
to the multiplicity of solutions and their admissibility for different systems,
especially for intermediate-type MHD shock waves, the identification of MHD
wave types is complicated if one solely relies on the Rankine-Hugoniot jump
conditions. MHD wave detection is further exacerbated by the unphysical
smearing of discontinuous shock waves in numerical simulations. We present two
MHD wave detection methods based on a convolutional neural network (CNN) which
enables the classification of waves and identification of their locations. The
first method separates the output into a regression (location prediction) and a
classification problem assuming the number of waves for each training data is
fixed. In the second method, the number of waves is not specified a priori and
the algorithm, using only regression, predicts the waves' locations and
classifies their types. The first fixed output model efficiently provides high
precision and recall, the accuracy of the entire neural network achieved is up
to 0.99, and the classification accuracy of some waves approaches unity. The
second detection model has relatively lower performance, with more sensitivity
to the setting of parameters, such as the number of grid cells N_{grid} and the
thresholds of confidence score and class probability, etc. The proposed two
methods demonstrate very strong potential to be applied for MHD wave detection
in some complex wave structures and interactions.</p>
  </details>
</details>
<details>
  <summary>131. <b>标题：Diffusion Transport Alignment</b></summary>
  <p><b>编号</b>：[328]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07305</p>
  <p><b>作者</b>：Andres F. Duque,  Guy Wolf,  Kevin R. Moon</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：conditions generates distinct, presents a challenge, instruments or conditions, conditions generates, generates distinct</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The integration of multimodal data presents a challenge in cases when the
study of a given phenomena by different instruments or conditions generates
distinct but related domains. Many existing data integration methods assume a
known one-to-one correspondence between domains of the entire dataset, which
may be unrealistic. Furthermore, existing manifold alignment methods are not
suited for cases where the data contains domain-specific regions, i.e., there
is not a counterpart for a certain portion of the data in the other domain. We
propose Diffusion Transport Alignment (DTA), a semi-supervised manifold
alignment method that exploits prior correspondence knowledge between only a
few points to align the domains. By building a diffusion process, DTA finds a
transportation plan between data measured from two heterogeneous domains with
different feature spaces, which by assumption, share a similar geometrical
structure coming from the same underlying data generating process. DTA can also
compute a partial alignment in a data-driven fashion, resulting in accurate
alignments when some data are measured in only one domain. We empirically
demonstrate that DTA outperforms other methods in aligning multimodal data in
this semisupervised setting. We also empirically show that the alignment
obtained by DTA can improve the performance of machine learning tasks, such as
domain adaptation, inter-domain feature mapping, and exploratory data analysis,
while outperforming competing methods.</p>
  </details>
</details>
<details>
  <summary>132. <b>标题：CARD: Classification and Regression Diffusion Models</b></summary>
  <p><b>编号</b>：[331]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07275</p>
  <p><b>作者</b>：Xizewen Han,  Huangjie Zheng,  Mingyuan Zhou</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：categorical response variable, boldsymbol, response variable, continuous or categorical, categorical response</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Learning the distribution of a continuous or categorical response variable
$\boldsymbol y$ given its covariates $\boldsymbol x$ is a fundamental problem
in statistics and machine learning. Deep neural network-based supervised
learning algorithms have made great progress in predicting the mean of
$\boldsymbol y$ given $\boldsymbol x$, but they are often criticized for their
ability to accurately capture the uncertainty of their predictions. In this
paper, we introduce classification and regression diffusion (CARD) models,
which combine a denoising diffusion-based conditional generative model and a
pre-trained conditional mean estimator, to accurately predict the distribution
of $\boldsymbol y$ given $\boldsymbol x$. We demonstrate the outstanding
ability of CARD in conditional distribution prediction with both toy examples
and real-world datasets, the experimental results on which show that CARD in
general outperforms state-of-the-art methods, including Bayesian neural
network-based ones that are designed for uncertainty estimation, especially
when the conditional distribution of $\boldsymbol y$ given $\boldsymbol x$ is
multi-modal.</p>
  </details>
</details>
<details>
  <summary>133. <b>标题：Latency Control for Keyword Spotting</b></summary>
  <p><b>编号</b>：[332]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07261</p>
  <p><b>作者</b>：Christin Jose,  Joseph Wang,  Grant P. Strimel,  Mohammad Omar Khursheed,  Yuriy Mishchenko,  Brian Kulis</p>
  <p><b>备注</b>：Proceedings of INTERSPEECH</p>
  <p><b>关键词</b>：Conversational agents commonly, agents commonly utilize, initiate voice interaction, utilize keyword spotting, commonly utilize keyword</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Conversational agents commonly utilize keyword spotting (KWS) to initiate
voice interaction with the user. For user experience and privacy
considerations, existing approaches to KWS largely focus on accuracy, which can
often come at the expense of introduced latency. To address this tradeoff, we
propose a novel approach to control KWS model latency and which generalizes to
any loss function without explicit knowledge of the keyword endpoint. Through a
single, tunable hyperparameter, our approach enables one to balance detection
latency and accuracy for the targeted application. Empirically, we show that
our approach gives superior performance under latency constraints when compared
to existing methods. Namely, we make a substantial 25\% relative false accepts
improvement for a fixed latency target when compared to the baseline
state-of-the-art. We also show that when our approach is used in conjunction
with a max-pooling loss, we are able to improve relative false accepts by 25 %
at a fixed latency when compared to cross entropy loss.</p>
  </details>
</details>
<details>
  <summary>134. <b>标题：Implicit Regularization or Implicit Conditioning? Exact Risk  Trajectories of SGD in High Dimensions</b></summary>
  <p><b>编号</b>：[333]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07252</p>
  <p><b>作者</b>：Courtney Paquette,  Elliot Paquette,  Ben Adlam,  Jeffrey Pennington</p>
  <p><b>备注</b>：arXiv admin note: text overlap with arXiv:2205.07069</p>
  <p><b>关键词</b>：go-to optimization algorithm, Stochastic gradient descent, SGD, modern machine learning, gradient descent</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Stochastic gradient descent (SGD) is a pillar of modern machine learning,
serving as the go-to optimization algorithm for a diverse array of problems.
While the empirical success of SGD is often attributed to its computational
efficiency and favorable generalization behavior, neither effect is well
understood and disentangling them remains an open problem. Even in the simple
setting of convex quadratic problems, worst-case analyses give an asymptotic
convergence rate for SGD that is no better than full-batch gradient descent
(GD), and the purported implicit regularization effects of SGD lack a precise
explanation. In this work, we study the dynamics of multi-pass SGD on
high-dimensional convex quadratics and establish an asymptotic equivalence to a
stochastic differential equation, which we call homogenized stochastic gradient
descent (HSGD), whose solutions we characterize explicitly in terms of a
Volterra integral equation. These results yield precise formulas for the
learning and risk trajectories, which reveal a mechanism of implicit
conditioning that explains the efficiency of SGD relative to GD. We also prove
that the noise from SGD negatively impacts generalization performance, ruling
out the possibility of any type of implicit regularization in this context.
Finally, we show how to adapt the HSGD formalism to include streaming SGD,
which allows us to produce an exact prediction for the excess risk of
multi-pass SGD relative to that of streaming SGD (bootstrap risk).</p>
  </details>
</details>
<details>
  <summary>135. <b>标题：A Multiple kernel testing procedure for non-proportional hazards in  factorial designs</b></summary>
  <p><b>编号</b>：[335]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07239</p>
  <p><b>作者</b>：Marc Ditzhaus,  Tamara Fernández,  Nicolás Rivera</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：medical history, treatment groups, interest simultaneously, infer survival data, paper we propose</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper we propose a Multiple kernel testing procedure to infer
survival data when several factors (e.g. different treatment groups, gender,
medical history) and their interaction are of interest simultaneously. Our
method is able to deal with complex data and can be seen as an alternative to
the omnipresent Cox model when assumptions such as proportionality cannot be
justified. Our methodology combines well-known concepts from Survival Analysis,
Machine Learning and Multiple Testing: differently weighted log-rank tests,
kernel methods and multiple contrast tests. By that, complex hazard
alternatives beyond the classical proportional hazard set-up can be detected.
Moreover, multiple comparisons are performed by fully exploiting the dependence
structure of the single testing procedures to avoid a loss of power. In all,
this leads to a flexible and powerful procedure for factorial survival designs
whose theoretical validity is proven by martingale arguments and the theory for
$V$-statistics. We evaluate the performance of our method in an extensive
simulation study and illustrate it by a real data analysis.</p>
  </details>
</details>
<details>
  <summary>136. <b>标题：Query-Adaptive Predictive Inference with Partial Labels</b></summary>
  <p><b>编号</b>：[336]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07236</p>
  <p><b>作者</b>：Maxime Cauchois,  John Duchi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：statistical machine learning, machine learning encourage, fully supervised labels, partially labeled data, accessible alternative</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The cost and scarcity of fully supervised labels in statistical machine
learning encourage using partially labeled data for model validation as a
cheaper and more accessible alternative. Effectively collecting and leveraging
weakly supervised data for large-space structured prediction tasks thus becomes
an important part of an end-to-end learning system. We propose a new
computationally-friendly methodology to construct predictive sets using only
partially labeled data on top of black-box predictive models. To do so, we
introduce "probe" functions as a way to describe weakly supervised instances
and define a false discovery proportion-type loss, both of which seamlessly
adapt to partial supervision and structured prediction -- ranking, matching,
segmentation, multilabel or multiclass classification. Our experiments
highlight the validity of our predictive set construction as well as the
attractiveness of a more flexible user-dependent loss framework.</p>
  </details>
</details>
<details>
  <summary>137. <b>标题：A Projection-Based K-space Transformer Network for Undersampled Radial  MRI Reconstruction with Limited Training Subjects</b></summary>
  <p><b>编号</b>：[337]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07219</p>
  <p><b>作者</b>：Chang Gao,  Shu-Fu Shih,  J. Paul Finn,  Xiaodong Zhong</p>
  <p><b>备注</b>：Accepted at MICCAI 2022</p>
  <p><b>关键词</b>：compressed sensing enables, enables fast reconstruction, sensing enables fast, Cartesian k-space trajectories, deep learning combined</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The recent development of deep learning combined with compressed sensing
enables fast reconstruction of undersampled MR images and has achieved
state-of-the-art performance for Cartesian k-space trajectories. However,
non-Cartesian trajectories such as the radial trajectory need to be transformed
onto a Cartesian grid in each iteration of the network training, slowing down
the training process and posing inconvenience and delay during training.
Multiple iterations of nonuniform Fourier transform in the networks offset the
deep learning advantage of fast inference. Current approaches typically either
work on image-to-image networks or grid the non-Cartesian trajectories before
the network training to avoid the repeated gridding process. However, the
image-to-image networks cannot ensure the k-space data consistency in the
reconstructed images and the pre-processing of non-Cartesian k-space leads to
gridding errors which cannot be compensated by the network training. Inspired
by the Transformer network to handle long-range dependencies in sequence
transduction tasks, we propose to rearrange the radial spokes to sequential
data based on the chronological order of acquisition and use the Transformer to
predict unacquired radial spokes from acquired ones. We propose novel data
augmentation methods to generate a large amount of training data from a limited
number of subjects. The network can be generated to different anatomical
structures. Experimental results show superior performance of the proposed
framework compared to state-of-the-art deep neural networks.</p>
  </details>
</details>
<details>
  <summary>138. <b>标题：Benefits of Additive Noise in Composing Classes with Bounded Capacity</b></summary>
  <p><b>编号</b>：[338]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07199</p>
  <p><b>作者</b>：Alireza Fathollah Pour,  Hassan Ashtiani</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：mathcal, composition class, prohibitively large, uniform covering numbers, Gaussian noise</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We observe that given two (compatible) classes of functions $\mathcal{F}$ and
$\mathcal{H}$ with small capacity as measured by their uniform covering
numbers, the capacity of the composition class $\mathcal{H} \circ \mathcal{F}$
can become prohibitively large or even unbounded. We then show that adding a
small amount of Gaussian noise to the output of $\mathcal{F}$ before composing
it with $\mathcal{H}$ can effectively control the capacity of $\mathcal{H}
\circ \mathcal{F}$, offering a general recipe for modular design. To prove our
results, we define new notions of uniform covering number of random functions
with respect to the total variation and Wasserstein distances. We instantiate
our results for the case of multi-layer sigmoid neural networks. Preliminary
empirical results on MNIST dataset indicate that the amount of noise required
to improve over existing uniform bounds can be numerically negligible (i.e.,
element-wise i.i.d. Gaussian noise with standard deviation $10^{-240}$). The
source codes are available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>139. <b>标题：Stability of image reconstruction algorithms</b></summary>
  <p><b>编号</b>：[340]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07128</p>
  <p><b>作者</b>：Pol del Aguila Pla,  Sebastian Neumayer,  Michael Unser</p>
  <p><b>备注</b>：11 pages, 6 figures, 1 appendix</p>
  <p><b>关键词</b>：image reconstruction algorithms, image reconstruction, reconstruction algorithms, algorithms have recently, ell</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Robustness and stability of image reconstruction algorithms have recently
come under scrutiny. Their importance to medical imaging cannot be overstated.
We review the known results for the topical variational regularization
strategies ($\ell_2$ and $\ell_1$ regularization), and present new stability
results for $\ell_p$ regularized linear inverse problems for $p\in(1,\infty)$.
Our results generalize well to the respective $L_p(\Omega)$ function spaces.</p>
  </details>
</details>
<details>
  <summary>140. <b>标题：Loss Functions for Classification using Structured Entropy</b></summary>
  <p><b>编号</b>：[341]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07122</p>
  <p><b>作者</b>：Brian Lucena</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：train classification models, gradient boosting, models in deep, deep learning, learning and gradient</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Cross-entropy loss is the standard metric used to train classification models
in deep learning and gradient boosting. It is well-known that this loss
function fails to account for similarities between the different values of the
target. We propose a generalization of entropy called {\em structured entropy}
which uses a random partition to incorporate the structure of the target
variable in a manner which retains many theoretical properties of standard
entropy. We show that a structured cross-entropy loss yields better results on
several classification problems where the target variable has an a priori known
structure. The approach is simple, flexible, easily computable, and does not
rely on a hierarchically defined notion of structure.</p>
  </details>
</details>
<details>
  <summary>141. <b>标题：Inverse design of nano-photonic wavelength demultiplexer with a deep  neural network approach</b></summary>
  <p><b>编号</b>：[342]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07114</p>
  <p><b>作者</b>：Mengwei Yuan,  Gang Yang,  Shijie Song,  Luping Zhou,  Robert Minasian,  Xiaoke Yi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：integrated photonic circuit, PTCN model, neural network, PTCN model shows, photonic circuit</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we propose a pre-trained-combined neural network (PTCN) as a
comprehensive solution to the inverse design of an integrated photonic circuit.
By utilizing both the initially pre-trained inverse and forward model with a
joint training process, our PTCN model shows remarkable tolerance to the
quantity and quality of the training data. As a proof of concept demonstration,
the inverse design of a wavelength demultiplexer is used to verify the
effectiveness of the PTCN model. The correlation coefficient of the prediction
by the presented PTCN model remains greater than 0.974 even when the size of
training data is decreased to 17%. The experimental results show a good
agreement with predictions, and demonstrate a wavelength demultiplexer with an
ultra-compact footprint, a high transmission efficiency with a transmission
loss of -2dB, a low reflection of -10dB, and low crosstalk around -7dB
simultaneously.</p>
  </details>
</details>
<details>
  <summary>142. <b>标题：Learning the Structure of Large Networked Systems Obeying Conservation  Laws</b></summary>
  <p><b>编号</b>：[344]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07083</p>
  <p><b>作者</b>：Anirudh Rayas,  Rajasekhar Anguluri,  Gautam Dasarathy</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：obey conservation laws, electric networks, social networks, conservation laws, node potentials</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Many networked systems such as electric networks, the brain, and social
networks of opinion dynamics are known to obey conservation laws. Examples of
this phenomenon include the Kirchoff laws in electric networks and opinion
consensus in social networks. Conservation laws in networked systems may be
modeled as balance equations of the form $X = B^{*} Y$, where the sparsity
pattern of $B^{*}$ captures the connectivity of the network, and $Y, X \in
\mathbb{R}^p$ are vectors of "potentials" and "injected flows" at the nodes
respectively. The node potentials $Y$ cause flows across edges and the flows
$X$ injected at the nodes are extraneous to the network dynamics. In several
practical systems, the network structure is often unknown and needs to be
estimated from data. Towards this, one has access to samples of the node
potentials $Y$, but only the statistics of the node injections $X$. Motivated
by this important problem, we study the estimation of the sparsity structure of
the matrix $B^{*}$ from $n$ samples of $Y$ under the assumption that the node
injections $X$ follow a Gaussian distribution with a known covariance
$\Sigma_X$. We propose a new $\ell_{1}$-regularized maximum likelihood
estimator for this problem in the high-dimensional regime where the size of the
network $p$ is larger than sample size $n$. We show that this optimization
problem is convex in the objective and admits a unique solution. Under a new
mutual incoherence condition, we establish sufficient conditions on the triple
$(n,p,d)$ for which exact sparsity recovery of $B^{*}$ is possible with high
probability; $d$ is the degree of the graph. We also establish guarantees for
the recovery of $B^{*}$ in the element-wise maximum, Frobenius, and operator
norms. Finally, we complement these theoretical results with experimental
validation of the performance of the proposed estimator on synthetic and
real-world data.</p>
  </details>
</details>
<details>
  <summary>143. <b>标题：Near-Exact Recovery for Tomographic Inverse Problems via Deep Learning</b></summary>
  <p><b>编号</b>：[346]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07050</p>
  <p><b>作者</b>：Martin Genzel,  Ingo Gühring,  Jan Macdonald,  Maximilian März</p>
  <p><b>备注</b>：ICML 2022 (long talk). Code available at this https URL arXiv admin note: text overlap with arXiv:2106.00280</p>
  <p><b>关键词</b>：scientific machine learning, methods solve noise-free, solve noise-free inverse, machine learning, methods solve</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This work is concerned with the following fundamental question in scientific
machine learning: Can deep-learning-based methods solve noise-free inverse
problems to near-perfect accuracy? Positive evidence is provided for the first
time, focusing on a prototypical computed tomography (CT) setup. We demonstrate
that an iterative end-to-end network scheme enables reconstructions close to
numerical precision, comparable to classical compressed sensing strategies. Our
results build on our winning submission to the recent AAPM DL-Sparse-View CT
Challenge. Its goal was to identify the state-of-the-art in solving the
sparse-view CT inverse problem with data-driven techniques. A specific
difficulty of the challenge setup was that the precise forward model remained
unknown to the participants. Therefore, a key feature of our approach was to
initially estimate the unknown fanbeam geometry in a data-driven calibration
step. Apart from an in-depth analysis of our methodology, we also demonstrate
its state-of-the-art performance on the open-access real-world dataset LoDoPaB
CT.</p>
  </details>
</details>
<details>
  <summary>144. <b>标题：A smile is all you need: Predicting limiting activity coefficients from  SMILES with natural language processing</b></summary>
  <p><b>编号</b>：[347]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07048</p>
  <p><b>作者</b>：Benedikt Winter,  Clemens Winter,  Johannes Schilling,  André Bardow</p>
  <p><b>备注</b>：Code available at: this https URL; Data available at: this https URL</p>
  <p><b>关键词</b>：mixtures' phase equilibria, activity coefficients, Knowledge of mixtures', technical chemistry, activity</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Knowledge of mixtures' phase equilibria is crucial in nature and technical
chemistry. Phase equilibria calculations of mixtures require activity
coefficients. However, experimental data on activity coefficients is often
limited due to high cost of experiments. For an accurate and efficient
prediction of activity coefficients, machine learning approaches have been
recently developed. However, current machine learning approaches still
extrapolate poorly for activity coefficients of unknown molecules. In this
work, we introduce the SMILES-to-Properties-Transformer (SPT), a natural
language processing network to predict binary limiting activity coefficients
from SMILES codes. To overcome the limitations of available experimental data,
we initially train our network on a large dataset of synthetic data sampled
from COSMO-RS (10 Million data points) and then fine-tune the model on
experimental data (20 870 data points). This training strategy enables SPT to
accurately predict limiting activity coefficients even for unknown molecules,
cutting the mean prediction error in half compared to state-of-the-art models
for activity coefficient predictions such as COSMO-RS, UNIFAC, and improving on
recent machine learning approaches.</p>
  </details>
</details>
<details>
  <summary>145. <b>标题：Unbiased Recommender Learning from Missing-Not-At-Random Implicit  Feedback</b></summary>
  <p><b>编号</b>：[348]</p>
  <p><b>链接</b>：https://arxiv.org/abs/1909.03601</p>
  <p><b>作者</b>：Yuta Saito,  Suguru Yaginuma,  Yuta Nishino,  Hayato Sakata,  Kazuhide Nakata</p>
  <p><b>备注</b>：accepted at WSDM'20</p>
  <p><b>关键词</b>：general availability, Recommender systems widely, implicit feedback, proposed method, unbiased estimator</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recommender systems widely use implicit feedback such as click data because
of its general availability. Although the presence of clicks signals the users'
preference to some extent, the lack of such clicks does not necessarily
indicate a negative response from the users, as it is possible that the users
were not exposed to the items (positive-unlabeled problem). This leads to a
difficulty in predicting the users' preferences from implicit feedback.
Previous studies addressed the positive-unlabeled problem by uniformly
upweighting the loss for the positive feedback data or estimating the
confidence of each data having relevance information via the EM-algorithm.
However, these methods failed to address the missing-not-at-random problem in
which popular or frequently recommended items are more likely to be clicked
than other items even if a user does not have a considerable interest in them.
To overcome these limitations, we first define an ideal loss function to be
optimized to realize recommendations that maximize the relevance and propose an
unbiased estimator for the ideal loss. Subsequently, we analyze the variance of
the proposed unbiased estimator and further propose a clipped estimator that
includes the unbiased estimator as a special case. We demonstrate that the
clipped estimator is expected to improve the performance of the recommender
system, by considering the bias-variance trade-off. We conduct semi-synthetic
and real-world experiments and demonstrate that the proposed method largely
outperforms the baselines. In particular, the proposed method works better for
rare items that are less frequently observed in the training data. The findings
indicate that the proposed method can better achieve the objective of
recommending items with the highest relevance.</p>
  </details>
</details>
<h1>人工智能</h1>
<details>
  <summary>1. <b>标题：On the Eve of True Explainability for OWL Ontologies: Description Logic  Proofs with Evee and Evonne (Extended Version)</b></summary>
  <p><b>编号</b>：[1]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07711</p>
  <p><b>作者</b>：Christian Alrabbaa,  Stefan Borgwardt,  Tom Friese,  Patrick Koopmann,  Julián Méndez,  Alexej Popovič</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：description logic ontologies, understanding entailments derived, description logic reasoner, description logic, logic ontologies</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>When working with description logic ontologies, understanding entailments
derived by a description logic reasoner is not always straightforward. So far,
the standard ontology editor Protégé offers two services to help:
(black-box) justifications for OWL 2 DL ontologies, and (glass-box) proofs for
lightweight OWL EL ontologies, where the latter exploits the proof facilities
of reasoner ELK. Since justifications are often insufficient in explaining
inferences, there is thus only little tool support for explaining inferences in
more expressive DLs. In this paper, we introduce EVEE-LIBS, a Java library for
computing proofs for DLs up to ALCH, and EVEE-PROTEGE, a collection of
Protégé plugins for displaying those proofs in Protégé. We also give a
short glimpse of the latest version of EVONNE, a more advanced standalone
application for displaying and interacting with proofs computed with EVEE-LIBS.</p>
  </details>
</details>
<details>
  <summary>2. <b>标题：Masked Siamese ConvNets</b></summary>
  <p><b>编号</b>：[8]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07700</p>
  <p><b>作者</b>：Li Jing,  Jiachen Zhu,  Yann LeCun</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：shown superior performances, shown superior, superior performances, performances over supervised, Self-supervised learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Self-supervised learning has shown superior performances over supervised
methods on various vision benchmarks. The siamese network, which encourages
embeddings to be invariant to distortions, is one of the most successful
self-supervised visual representation learning approaches. Among all the
augmentation methods, masking is the most general and straightforward method
that has the potential to be applied to all kinds of input and requires the
least amount of domain knowledge. However, masked siamese networks require
particular inductive bias and practically only work well with Vision
Transformers. This work empirically studies the problems behind masked siamese
networks with ConvNets. We propose several empirical designs to overcome these
problems gradually. Our method performs competitively on low-shot image
classification and outperforms previous methods on object detection benchmarks.
We discuss several remaining issues and hope this work can provide useful data
points for future general-purpose self-supervised learning.</p>
  </details>
</details>
<details>
  <summary>3. <b>标题：Region-enhanced Deep Graph Convolutional Networks for Rumor Detection</b></summary>
  <p><b>编号</b>：[28]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07665</p>
  <p><b>作者</b>：Ge Wang,  Li Tan,  Tianbao Song,  Wei Wang,  Ziliang Shang</p>
  <p><b>备注</b>：submitted to Neural Computing and Applications</p>
  <p><b>关键词</b>：public sphere due, Social media, rapidly developing, public sphere, sphere due</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Social media has been rapidly developing in the public sphere due to its ease
of spreading new information, which leads to the circulation of rumors.
However, detecting rumors from such a massive amount of information is becoming
an increasingly arduous challenge. Previous work generally obtained valuable
features from propagation information. It should be noted that most methods
only target the propagation structure while ignoring the rumor transmission
pattern. This limited focus severely restricts the collection of spread data.
To solve this problem, the authors of the present study are motivated to
explore the regionalized propagation patterns of rumors. Specifically, a novel
region-enhanced deep graph convolutional network (RDGCN) that enhances the
propagation features of rumors by learning regionalized propagation patterns
and trains to learn the propagation patterns by unsupervised learning is
proposed. In addition, a source-enhanced residual graph convolution layer
(SRGCL) is designed to improve the graph neural network (GNN) oversmoothness
and increase the depth limit of the rumor detection methods-based GNN.
Experiments on Twitter15 and Twitter16 show that the proposed model performs
better than the baseline approach on rumor detection and early rumor detection.</p>
  </details>
</details>
<details>
  <summary>4. <b>标题：Model-based RL with Optimistic Posterior Sampling: Structural Conditions  and Sample Complexity</b></summary>
  <p><b>编号</b>：[30]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07659</p>
  <p><b>作者</b>：Alekh Agarwal,  Tong Zhang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：posterior sampling methods, Hellinger distance, Hellinger distance based, posterior sampling, sampling methods</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose a general framework to design posterior sampling methods for
model-based RL. We show that the proposed algorithms can be analyzed by
reducing regret to Hellinger distance based conditional probability estimation.
We further show that optimistic posterior sampling can control this Hellinger
distance, when we measure model error via data likelihood. This technique
allows us to design and analyze unified posterior sampling algorithms with
state-of-the-art sample complexity guarantees for many model-based RL settings.
We illustrate our general result in many special cases, demonstrating the
versatility of our framework.</p>
  </details>
</details>
<details>
  <summary>5. <b>标题：Hyperparameter Sensitivity in Deep Outlier Detection: Analysis and a  Scalable Hyper-Ensemble Solution</b></summary>
  <p><b>编号</b>：[32]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07647</p>
  <p><b>作者</b>：Xueying Ding,  Lingxiao Zhao,  Leman Akoglu</p>
  <p><b>备注</b>：19 pages, 11 figures, 9 tables</p>
  <p><b>关键词</b>：exhibits numerous algorithms, literature exhibits numerous, diverse domains, exhibits numerous, applies to diverse</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Outlier detection (OD) literature exhibits numerous algorithms as it applies
to diverse domains. However, given a new detection task, it is unclear how to
choose an algorithm to use, nor how to set its hyperparameter(s) (HPs) in
unsupervised settings. HP tuning is an ever-growing problem with the arrival of
many new detectors based on deep learning. While they have appealing properties
such as task- driven representation learning and end-to-end optimization, deep
models come with a long list of HPs. Surprisingly, the issue of model selection
in the outlier mining literature has been "the elephant in the room"; a
significant factor in unlocking the utmost potential of deep methods, yet
little said or done to systematically tackle the issue. In the first part of
this paper, we conduct the first large-scale analysis on the HP sensitivity of
deep OD methods, and through more than 35,000 trained models, quantitatively
demonstrate that model selection is inevitable. Next, we design a HP-robust and
scalable deep hyper-ensemble model called ROBOD that assembles models with
varying HP configurations, bypassing the choice paralysis. Importantly, we
introduce novel strategies to speed up ensemble training, such as parameter
sharing, batch/simultaneous training, and data subsampling, that allow us to
train fewer models with fewer parameters. Extensive experiments on both image
and tabular datasets show that ROBOD achieves and retains robust,
state-of-the-art detection performance as compared to its modern counterparts,
while taking only 2-10% of the time by the naive hyper-ensemble with
independent training.</p>
  </details>
</details>
<details>
  <summary>6. <b>标题：Convergence and Price of Anarchy Guarantees of the Softmax Policy  Gradient in Markov Potential Games</b></summary>
  <p><b>编号</b>：[34]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07642</p>
  <p><b>作者</b>：Dingyang Chen,  Qi Zhang,  Thinh T. Doan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：policy gradient, policy gradient methods, Markov potential games, policy, POA</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We study the performance of policy gradient methods for the subclass of
Markov games known as Markov potential games (MPGs), which extends the notion
of normal-form potential games to the stateful setting and includes the
important special case of the fully cooperative setting where the agents share
an identical reward function. Our focus in this paper is to study the
convergence of the policy gradient method for solving MPGs under softmax policy
parameterization, both tabular and parameterized with general function
approximators such as neural networks. We first show the asymptotic convergence
of this method to a Nash equilibrium of MPGs for tabular softmax policies.
Second, we derive the finite-time performance of the policy gradient in two
settings: 1) using the log-barrier regularization, and 2) using the natural
policy gradient under the best-response dynamics (NPG-BR). Finally, extending
the notion of price of anarchy (POA) and smoothness in normal-form games, we
introduce the POA for MPGs and provide a POA bound for NPG-BR. To our
knowledge, this is the first POA bound for solving MPGs. To support our
theoretical results, we empirically compare the convergence rates and POA of
policy gradient variants for both tabular and neural softmax policies.</p>
  </details>
</details>
<details>
  <summary>7. <b>标题：AI Ethics Issues in Real World: Evidence from AI Incident Database</b></summary>
  <p><b>编号</b>：[37]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07635</p>
  <p><b>作者</b>：Mengyi Wei,  Zhixuan Zhou</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Artificial Intelligence, performance of Artificial, prevalent ethical issues, powerful performance, ethical issues</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>With the powerful performance of Artificial Intelligence (AI) also comes
prevalent ethical issues. Though governments and corporations have curated
multiple AI ethics guidelines to curb unethical behavior of AI, the effect has
been limited, probably due to the vagueness of the guidelines. In this paper,
we take a closer look at how AI ethics issues take place in real world, in
order to have a more in-depth and nuanced understanding of different ethical
issues as well as their social impact. With a content analysis of AI Incident
Database, which is an effort to prevent repeated real world AI failures by
cataloging incidents, we identified 13 application areas which often see
unethical use of AI, with intelligent service robots, language/vision models
and autonomous driving taking the lead. Ethical issues appear in 8 different
forms, from inappropriate use and racial discrimination, to physical safety and
unfair algorithm. With this taxonomy of AI ethics issues, we aim to provide AI
practitioners with a practical guideline when trying to deploy AI applications
ethically.</p>
  </details>
</details>
<details>
  <summary>8. <b>标题：Real3D-Aug: Point Cloud Augmentation by Placing Real Objects with  Occlusion Handling for 3D Detection and Segmentation</b></summary>
  <p><b>编号</b>：[38]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07634</p>
  <p><b>作者</b>：Petr Šebek,  Šimon Pokorný,  Patrik Vacek,  Tomáš Svoboda</p>
  <p><b>备注</b>：Submitted on 15th June 2022 to IEEE RA-L journal</p>
  <p><b>关键词</b>：require expensive annotation, cloud data require, data require expensive, point cloud data, expensive annotation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Object detection and semantic segmentation with the 3D lidar point cloud data
require expensive annotation. We propose a data augmentation method that takes
advantage of already annotated data multiple times. We propose an augmentation
framework that reuses real data, automatically finds suitable placements in the
scene to be augmented, and handles occlusions explicitly. Due to the usage of
the real data, the scan points of newly inserted objects in augmentation
sustain the physical characteristics of the lidar, such as intensity and
raydrop. The pipeline proves competitive in training top-performing models for
3D object detection and semantic segmentation. The new augmentation provides a
significant performance gain in rare and essential classes, notably 6.65%
average precision gain for "Hard" pedestrian class in KITTI object detection or
2.14 mean IoU gain in the SemanticKITTI segmentation challenge over the state
of the art.</p>
  </details>
</details>
<details>
  <summary>9. <b>标题：ARES: Locally Adaptive Reconstruction-based Anomaly Scoring</b></summary>
  <p><b>编号</b>：[46]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07604</p>
  <p><b>作者</b>：Adam Goodge,  Bryan Hooi,  See Kiong Ng,  Wee Siong Ng</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：significantly differ, set of high-dimensional, images or sensor, high-dimensional data, sensor data</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>How can we detect anomalies: that is, samples that significantly differ from
a given set of high-dimensional data, such as images or sensor data? This is a
practical problem with numerous applications and is also relevant to the goal
of making learning algorithms more robust to unexpected inputs. Autoencoders
are a popular approach, partly due to their simplicity and their ability to
perform dimension reduction. However, the anomaly scoring function is not
adaptive to the natural variation in reconstruction error across the range of
normal samples, which hinders their ability to detect real anomalies. In this
paper, we empirically demonstrate the importance of local adaptivity for
anomaly scoring in experiments with real data. We then propose our novel
Adaptive Reconstruction Error-based Scoring approach, which adapts its scoring
based on the local behaviour of reconstruction error over the latent space. We
show that this improves anomaly detection performance over relevant baselines
in a wide variety of benchmark datasets.</p>
  </details>
</details>
<details>
  <summary>10. <b>标题：Machine Learning is Abduction Inference</b></summary>
  <p><b>编号</b>：[50]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07586</p>
  <p><b>作者</b>：Marina Sapir</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Peirce abduction inference, Gradated Contradictions, form of Peirce, Peirce abduction, abduction inference</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Concept of Abduction with Gradated Contradictions is introduced here as a
form of Peirce's abduction inference. The general form of abduction criterion
is formalized in the proposed Logic of Gradated Contradictions and Logic of
Recursive Aggregation. Common steps of an abduction procedure as minimization
of such a criterion are specified as well. It is demonstrated on examples of 14
popular textbook learners (from hierarchical clustering to k-NN and SVR) that
each of them performs AGC. The proposed theory explains real life learners, yet
it avoids any mention of statistics, so it can be considered as a logical
alternative to the statistical learning theory.</p>
  </details>
</details>
<details>
  <summary>11. <b>标题：NatGen: Generative pre-training by "Naturalizing" source code</b></summary>
  <p><b>编号</b>：[51]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07585</p>
  <p><b>作者</b>：Saikat Chakraborty,  Toufique Ahmed,  Yangruibo Ding,  Premkumar Devanbu,  Baishakhi Ray</p>
  <p><b>备注</b>：Accepted to be published in ESEC/FSE 2022</p>
  <p><b>关键词</b>：yielded strong results, code yielded strong, code, Pre-trained Generative Language, past few years</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Pre-trained Generative Language models (e.g. PLBART, CodeT5, SPT-Code) for
source code yielded strong results on several tasks in the past few years,
including code generation and translation. These models have adopted varying
pre-training objectives to learn statistics of code construction from very
large-scale corpora in a self-supervised fashion; the success of pre-trained
models largely hinges on these pre-training objectives. This paper proposes a
new pre-training objective, "Naturalizing" of source code, exploiting code's
bimodal, dual-channel (formal & natural channels) nature. Unlike natural
language, code's bimodal, dual-channel nature allows us to generate
semantically equivalent code at scale. We introduce six classes of semantic
preserving transformations to introduce un-natural forms of code, and then
force our model to produce more natural original programs written by
developers. Learning to generate equivalent, but more natural code, at scale,
over large corpora of open-source code, without explicit manual supervision,
helps the model learn to both ingest & generate code. We fine-tune our model in
three generative Software Engineering tasks: code generation, code translation,
and code refinement with limited human-curated labeled data and achieve
state-of-the-art performance rivaling CodeT5. We show that our pre-trained
model is especially competitive at zero-shot and few-shot learning, and better
at learning code properties (e.g., syntax, data flow).</p>
  </details>
</details>
<details>
  <summary>12. <b>标题：A Comprehensive Survey on Deep Clustering: Taxonomy, Challenges, and  Future Directions</b></summary>
  <p><b>编号</b>：[54]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07579</p>
  <p><b>作者</b>：Sheng Zhou,  Hongjia Xu,  Zhuonan Zheng,  Jiawei Chen,  Zhao li,  Jiajun Bu,  Jia Wu,  Xin Wang,  Wenwu Zhu,  Martin Ester</p>
  <p><b>备注</b>：Github Repo: this https URL</p>
  <p><b>关键词</b>：Deep Clustering, Clustering, representation learning, representation learning techniques, learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Clustering is a fundamental machine learning task which has been widely
studied in the literature. Classic clustering methods follow the assumption
that data are represented as features in a vectorized form through various
representation learning techniques. As the data become increasingly complicated
and complex, the shallow (traditional) clustering methods can no longer handle
the high-dimensional data type. With the huge success of deep learning,
especially the deep unsupervised learning, many representation learning
techniques with deep architectures have been proposed in the past decade.
Recently, the concept of Deep Clustering, i.e., jointly optimizing the
representation learning and clustering, has been proposed and hence attracted
growing attention in the community. Motivated by the tremendous success of deep
learning in clustering, one of the most fundamental machine learning tasks, and
the large number of recent advances in this direction, in this paper we conduct
a comprehensive survey on deep clustering by proposing a new taxonomy of
different state-of-the-art approaches. We summarize the essential components of
deep clustering and categorize existing methods by the ways they design
interactions between deep representation learning and clustering. Moreover,
this survey also provides the popular benchmark datasets, evaluation metrics
and open-source implementations to clearly illustrate various experimental
settings. Last but not least, we discuss the practical applications of deep
clustering and suggest challenging topics deserving further investigations as
future directions.</p>
  </details>
</details>
<details>
  <summary>13. <b>标题：E2V-SDE: From Asynchronous Events to Fast and Continuous Video  Reconstruction via Neural Stochastic Differential Equations</b></summary>
  <p><b>编号</b>：[55]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07578</p>
  <p><b>作者</b>：Jongwan Kim,  DongJin Lee,  Byunggook Na,  Seongsik Park,  Jeonghee Jo,  Sungroh Yoon</p>
  <p><b>备注</b>：2022 CVPR oral</p>
  <p><b>关键词</b>：Event cameras respond, respond to brightness, scene asynchronously, asynchronously and independently, cameras respond</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Event cameras respond to brightness changes in the scene asynchronously and
independently for every pixel. Due to the properties, these cameras have
distinct features: high dynamic range (HDR), high temporal resolution, and low
power consumption. However, the results of event cameras should be processed
into an alternative representation for computer vision tasks. Also, they are
usually noisy and cause poor performance in areas with few events. In recent
years, numerous researchers have attempted to reconstruct videos from events.
However, they do not provide good quality videos due to a lack of temporal
information from irregular and discontinuous data. To overcome these
difficulties, we introduce an E2V-SDE whose dynamics are governed in a latent
space by Stochastic differential equations (SDE). Therefore, E2V-SDE can
rapidly reconstruct images at arbitrary time steps and make realistic
predictions on unseen data. In addition, we successfully adopted a variety of
image composition techniques for improving image clarity and temporal
consistency. By conducting extensive experiments on simulated and real-scene
datasets, we verify that our model outperforms state-of-the-art approaches
under various video reconstruction settings. In terms of image quality, the
LPIPS score improves by up to 12% and the reconstruction speed is 87% higher
than that of ET-Net.</p>
  </details>
</details>
<details>
  <summary>14. <b>标题：AI and Pathology: Steering Treatment and Predicting Outcomes</b></summary>
  <p><b>编号</b>：[56]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07573</p>
  <p><b>作者</b>：Rajarsi Gupta,  Jakub Kaczmarzyk,  Soma Kobayashi,  Tahsin Kurc,  Joel Saltz</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：increasing computing capacity, improved sensors enable, enable quantitative granular, sensors enable quantitative, cell-based analyses</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The combination of data analysis methods, increasing computing capacity, and
improved sensors enable quantitative granular, multi-scale, cell-based
analyses. We describe the rich set of application challenges related to tissue
interpretation and survey AI methods currently used to address these
challenges. We focus on a particular class of targeted human tissue analysis -
histopathology - aimed at quantitative characterization of disease state,
patient outcome prediction and treatment steering.</p>
  </details>
</details>
<details>
  <summary>15. <b>标题：Contrastive Learning as Goal-Conditioned Reinforcement Learning</b></summary>
  <p><b>编号</b>：[59]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07568</p>
  <p><b>作者</b>：Benjamin Eysenbach,  Tianjun Zhang,  Ruslan Salakhutdinov,  Sergey Levine</p>
  <p><b>备注</b>：Code is available on the website: this https URL</p>
  <p><b>关键词</b>：representation learning, easier to solve, learning, representation learning parts, good representations</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In reinforcement learning (RL), it is easier to solve a task if given a good
representation. While deep RL should automatically acquire such good
representations, prior work often finds that learning representations in an
end-to-end fashion is unstable and instead equip RL algorithms with additional
representation learning parts (e.g., auxiliary losses, data augmentation). How
can we design RL algorithms that directly acquire good representations? In this
paper, instead of adding representation learning parts to an existing RL
algorithm, we show (contrastive) representation learning methods can be cast as
RL algorithms in their own right. To do this, we build upon prior work and
apply contrastive representation learning to action-labeled trajectories, in
such a way that the (inner product of) learned representations exactly
corresponds to a goal-conditioned value function. We use this idea to
reinterpret a prior RL method as performing contrastive learning, and then use
the idea to propose a much simpler method that achieves similar performance.
Across a range of goal-conditioned RL tasks, we demonstrate that contrastive RL
methods achieve higher success rates than prior non-contrastive methods,
including in the offline RL setting. We also show that contrastive RL
outperforms prior methods on image-based tasks, without using data augmentation
or auxiliary objectives.</p>
  </details>
</details>
<details>
  <summary>16. <b>标题：Contextualization and Generalization in Entity and Relation Extraction</b></summary>
  <p><b>编号</b>：[63]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07558</p>
  <p><b>作者</b>：Bruno Taillé</p>
  <p><b>备注</b>：PhD Thesis, 122 pages</p>
  <p><b>关键词</b>：prominent in Natural, past decade, neural networks, Natural, Models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>During the past decade, neural networks have become prominent in Natural
Language Processing (NLP), notably for their capacity to learn relevant word
representations from large unlabeled corpora. These word embeddings can then be
transferred and finetuned for diverse end applications during a supervised
training phase. More recently, in 2018, the transfer of entire pretrained
Language Models and the preservation of their contextualization capacities
enabled to reach unprecedented performance on virtually every NLP benchmark,
sometimes even outperforming human baselines. However, as models reach such
impressive scores, their comprehension abilities still appear as shallow, which
reveal limitations of benchmarks to provide useful insights on their factors of
performance and to accurately measure understanding capabilities.
In this thesis, we study the behaviour of state-of-the-art models regarding
generalization to facts unseen during training in two important Information
Extraction tasks: Named Entity Recognition (NER) and Relation Extraction (RE).
Indeed, traditional benchmarks present important lexical overlap between
mentions and relations used for training and evaluating models, whereas the
main interest of Information Extraction is to extract previously unknown
information. We propose empirical studies to separate performance based on
mention and relation overlap with the training set and find that pretrained
Language Models are mainly beneficial to detect unseen mentions, in particular
out-of-domain. While this makes them suited for real use cases, there is still
a gap in performance between seen and unseen mentions that hurts generalization
to new facts. In particular, even state-of-the-art ERE models rely on a shallow
retention heuristic, basing their prediction more on arguments surface forms
than context.</p>
  </details>
</details>
<details>
  <summary>17. <b>标题：How to Reduce Change Detection to Semantic Segmentation</b></summary>
  <p><b>编号</b>：[64]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07557</p>
  <p><b>作者</b>：Guo-Hua Wang,  Bin-Bin Gao,  Chengjie Wang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：aims to identify, image pair, segmentation, general segmentation problems, semantic segmentation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Change detection (CD) aims to identify changes that occur in an image pair
taken different times. Prior methods devise specific networks from scratch to
predict change masks in pixel-level, and struggle with general segmentation
problems. In this paper, we propose a new paradigm that reduces CD to semantic
segmentation which means tailoring an existing and powerful semantic
segmentation network to solve CD. This new paradigm conveniently enjoys the
mainstream semantic segmentation techniques to deal with general segmentation
problems in CD. Hence we can concentrate on studying how to detect changes. We
propose a novel and importance insight that different change types exist in CD
and they should be learned separately. Based on it, we devise a module named
MTF to extract the change information and fuse temporal features. MTF enjoys
high interpretability and reveals the essential characteristic of CD. And most
segmentation networks can be adapted to solve the CD problems with our MTF
module. Finally, we propose C-3PO, a network to detect changes at pixel-level.
C-3PO achieves state-of-the-art performance without bells and whistles. It is
simple but effective and can be considered as a new baseline in this field. Our
code will be available.</p>
  </details>
</details>
<details>
  <summary>18. <b>标题：Unknown-Aware Domain Adversarial Learning for Open-Set Domain Adaptation</b></summary>
  <p><b>编号</b>：[69]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07551</p>
  <p><b>作者</b>：JoonHo Jang,  Byeonghu Na,  DongHyeok Shin,  Mingi Ji,  Kyungwoo Song,  Il-Chul Moon</p>
  <p><b>备注</b>：9 pages, preprint</p>
  <p><b>关键词</b>：Open-Set Domain Adaptation, textit, Domain Adaptation, domain adversarial learning, domain adversarial</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Open-Set Domain Adaptation (OSDA) assumes that a target domain contains
unknown classes, which are not discovered in a source domain. Existing domain
adversarial learning methods are not suitable for OSDA because distribution
matching with \textit{unknown} classes leads to the negative transfer. Previous
OSDA methods have focused on matching the source and the target distribution by
only utilizing \textit{known} classes. However, this \textit{known}-only
matching may fail to learn the target-\textit{unknown} feature space.
Therefore, we propose Unknown-Aware Domain Adversarial Learning (UADAL), which
\textit{aligns} the source and the targe-\textit{known} distribution while
simultaneously \textit{segregating} the target-\textit{unknown} distribution in
the feature alignment procedure. We provide theoretical analyses on the
optimized state of the proposed \textit{unknown-aware} feature alignment, so we
can guarantee both \textit{alignment} and \textit{segregation} theoretically.
Empirically, we evaluate UADAL on the benchmark datasets, which shows that
UADAL outperforms other methods with better feature alignments by reporting the
state-of-the-art performances.</p>
  </details>
</details>
<details>
  <summary>19. <b>标题：MPI: Evaluating and Inducing Personality in Pre-trained Language Models</b></summary>
  <p><b>编号</b>：[70]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07550</p>
  <p><b>作者</b>：Guangyuan Jiang,  Manjie Xu,  Song-Chun Zhu,  Wenjuan Han,  Chi Zhang,  Yixin Zhu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：personality, philosophical quest, terms of thinking, discerns how individuals, individuals differ</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Originated as a philosophical quest, personality discerns how individuals
differ from each other in terms of thinking, feeling, and behaving. Towards
building social machines that work with humans on a daily basis, we are
motivated to ask: (1) Do existing pre-trained language models possess
personality, akin to their human counterpart? If so, (2) how can we evaluate
them? Further, given this evaluation framework, (3) how can we induce a certain
personality in a fully controllable fashion? To tackle these three questions,
we propose the Machine Personality Inventory (MPI) dataset for evaluating the
machine personality; MPI follows standardized personality tests, built upon the
Big Five Personality Factors (Big Five) theory and personality assessment
inventories. By evaluating models with MPI, we provide the first piece of
evidence showing the existence of personality in pre-trained language models.
We further devise a Chain Prompting method to induce the language model with a
specific personality in a controllable manner, capable of producing diversified
behaviors. We hope to shed light on future studies by adopting personality as
the essential psychological guidance for various downstream tasks, building
more human-like and in situ dialogue agents.</p>
  </details>
</details>
<details>
  <summary>20. <b>标题：Autonomous Platoon Control with Integrated Deep Reinforcement Learning  and Dynamic Programming</b></summary>
  <p><b>编号</b>：[73]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07536</p>
  <p><b>作者</b>：Tong Liu,  Lei Lei,  Kan Zheng,  Kuan Zhang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Deep Reinforcement Learning, Reinforcement Learning, Deep Reinforcement, Deep Deterministic Policy, potential method</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep Reinforcement Learning (DRL) is regarded as a potential method for
car-following control and has been mostly studied to support a single following
vehicle. However, it is more challenging to learn a stable and efficient
car-following policy when there are multiple following vehicles in a platoon,
especially with unpredictable leading vehicle behavior. In this context, we
adopt an integrated DRL and Dynamic Programming (DP) approach to learn
autonomous platoon control policies, which embeds the Deep Deterministic Policy
Gradient (DDPG) algorithm into a finite-horizon value iteration framework.
Although the DP framework can improve the stability and performance of DDPG, it
has the limitations of lower sampling and training efficiency. In this paper,
we propose an algorithm, namely Finite-Horizon-DDPG with Sweeping through
reduced state space using Stationary approximation (FH-DDPG-SS), which uses
three key ideas to overcome the above limitations, i.e., transferring network
weights backward in time, stationary policy approximation for earlier time
steps, and sweeping through reduced state space. In order to verify the
effectiveness of FH-DDPG-SS, simulation using real driving data is performed,
where the performance of FH-DDPG-SS is compared with those of the benchmark
algorithms. Finally, platoon safety and string stability for FH-DDPG-SS are
demonstrated.</p>
  </details>
</details>
<details>
  <summary>21. <b>标题：Revisiting Some Common Practices in Cooperative Multi-Agent  Reinforcement Learning</b></summary>
  <p><b>编号</b>：[84]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07505</p>
  <p><b>作者</b>：Wei Fu,  Chao Yu,  Zelai Xu,  Jiaqi Yang,  Yi Wu</p>
  <p><b>备注</b>：15 pages, published as a conference paper in ICML 2022</p>
  <p><b>关键词</b>：common design principles, cooperative multi-agent reinforcement, advances in cooperative, common design, multi-agent reinforcement learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Many advances in cooperative multi-agent reinforcement learning (MARL) are
based on two common design principles: value decomposition and parameter
sharing. A typical MARL algorithm of this fashion decomposes a centralized
Q-function into local Q-networks with parameters shared across agents. Such an
algorithmic paradigm enables centralized training and decentralized execution
(CTDE) and leads to efficient learning in practice. Despite all the advantages,
we revisit these two principles and show that in certain scenarios, e.g.,
environments with a highly multi-modal reward landscape, value decomposition,
and parameter sharing can be problematic and lead to undesired outcomes. In
contrast, policy gradient (PG) methods with individual policies provably
converge to an optimal solution in these cases, which partially supports some
recent empirical observations that PG can be effective in many MARL testbeds.
Inspired by our theoretical analysis, we present practical suggestions on
implementing multi-agent PG algorithms for either high rewards or diverse
emergent behaviors and empirically validate our findings on a variety of
domains, ranging from the simplified matrix and grid-world games to complex
benchmarks such as StarCraft Multi-Agent Challenge and Google Research
Football. We hope our insights could benefit the community towards developing
more general and more powerful MARL algorithms. Check our project website at
this https URL.</p>
  </details>
</details>
<details>
  <summary>22. <b>标题：On the complexity of finding set repairs for data-graphs</b></summary>
  <p><b>编号</b>：[85]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07504</p>
  <p><b>作者</b>：Sergio Abriola,  Santiago Cifuentes,  María Vanina Martínez,  Nina Pardal,  Edwin Pin</p>
  <p><b>备注</b>：35 pages , including Appendix</p>
  <p><b>关键词</b>：information link domains, deeply interconnected world, pieces of information, deeply interconnected, information link</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In the deeply interconnected world we live in, pieces of information link
domains all around us. As graph databases embrace effectively relationships
among data and allow processing and querying these connections efficiently,
they are rapidly becoming a popular platform for storage that supports a wide
range of domains and applications. As in the relational case, it is expected
that data preserves a set of integrity constraints that define the semantic
structure of the world it represents. When a database does not satisfy its
integrity constraints, a possible approach is to search for a 'similar'
database that does satisfy the constraints, also known as a repair. In this
work, we study the problem of computing subset and superset repairs for graph
databases with data values using a notion of consistency based on a set of
Reg-GXPath expressions as integrity constraints. We show that for positive
fragments of Reg-GXPath these problems admit a polynomial-time algorithm, while
the full expressive power of the language renders them intractable.</p>
  </details>
</details>
<details>
  <summary>23. <b>标题：Towards ML Methods for Biodiversity: A Novel Wild Bee Dataset and  Evaluations of XAI Methods for ML-Assisted Rare Species Annotations</b></summary>
  <p><b>编号</b>：[89]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07497</p>
  <p><b>作者</b>：Teodor Chiaburu,  Felix Biessmann,  Frank Hausser</p>
  <p><b>备注</b>：6 pages, 7 figures, 1 table submitted to CVPR 2022 All the code and the link to the dataset can be found at this https URL</p>
  <p><b>关键词</b>：crucial part, XAI, annotation tasks, ecosystem, annotation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Insects are a crucial part of our ecosystem. Sadly, in the past few decades,
their numbers have worryingly decreased. In an attempt to gain a better
understanding of this process and monitor the insects populations, Deep
Learning may offer viable solutions. However, given the breadth of their
taxonomy and the typical hurdles of fine grained analysis, such as high
intraclass variability compared to low interclass variability, insect
classification remains a challenging task. There are few benchmark datasets,
which impedes rapid development of better AI models. The annotation of rare
species training data, however, requires expert knowledge. Explainable
Artificial Intelligence (XAI) could assist biologists in these annotation
tasks, but choosing the optimal XAI method is difficult. Our contribution to
these research challenges is threefold: 1) a dataset of thoroughly annotated
images of wild bees sampled from the iNaturalist database, 2) a ResNet model
trained on the wild bee dataset achieving classification scores comparable to
similar state-of-the-art models trained on other fine-grained datasets and 3)
an investigation of XAI methods to support biologists in annotation tasks.</p>
  </details>
</details>
<details>
  <summary>24. <b>标题：Collaborative Knowledge Graph Fusion by Exploiting the Open Corpus</b></summary>
  <p><b>编号</b>：[95]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07472</p>
  <p><b>作者</b>：Yue Wang,  Yao Wan,  Lu Bai,  Lixin Cui,  Zhuo Xu,  Ming Li,  Philip S. Yu,  Edwin R Hancock</p>
  <p><b>备注</b>：Under review by IEEE Transactions on Knowledge and Data Engineering (TKDE)</p>
  <p><b>关键词</b>：knowledge graph fusion, building Knowledge Graphs, Collaborative Knowledge Graph, knowledge graph, alleviate the challenges</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>To alleviate the challenges of building Knowledge Graphs (KG) from scratch, a
more general task is to enrich a KG using triples from an open corpus, where
the obtained triples contain noisy entities and relations. It is challenging to
enrich a KG with newly harvested triples while maintaining the quality of the
knowledge representation. This paper proposes a system to refine a KG using
information harvested from an additional corpus. To this end, we formulate our
task as two coupled sub-tasks, namely join event extraction (JEE) and knowledge
graph fusion (KGF). We then propose a Collaborative Knowledge Graph Fusion
Framework to allow our sub-tasks to mutually assist one another in an
alternating manner. More concretely, the explorer carries out the JEE
supervised by both the ground-truth annotation and an existing KG provided by
the supervisor. The supervisor then evaluates the triples extracted by the
explorer and enriches the KG with those that are highly ranked. To implement
this evaluation, we further propose a Translated Relation Alignment Scoring
Mechanism to align and translate the extracted triples to the prior KG.
Experiments verify that this collaboration can both improve the performance of
the JEE and the KGF.</p>
  </details>
</details>
<details>
  <summary>25. <b>标题：Conformance Checking with Uncertainty via SMT (Extended Version)</b></summary>
  <p><b>编号</b>：[97]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07461</p>
  <p><b>作者</b>：Paolo Felli,  Alessandro Gianola,  Marco Montali,  Andrey Rivkin,  Sarah Winkler</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：feature uncertainty pertaining, recorded timestamps, pertaining the recorded, real-life processes, feature uncertainty</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Logs of real-life processes often feature uncertainty pertaining the recorded
timestamps, data values, and/or events. We consider the problem of checking
conformance of uncertain logs against data-aware reference processes.
Specifically, we show how to solve it via SMT encodings, lifting previous work
on data-aware SMT-based conformance checking to this more sophisticated
setting. Our approach is modular, in that it homogeneously accommodates for
different types of uncertainty. Moreover, using appropriate cost functions,
different conformance checking tasks can be addressed. We show the correctness
of our approach and witness feasibility through a proof-of-concept
implementation.</p>
  </details>
</details>
<details>
  <summary>26. <b>标题：Physically-admissible polarimetric data augmentation for road-scene  analysis</b></summary>
  <p><b>编号</b>：[108]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07431</p>
  <p><b>作者</b>：Cyprien Ruffino,  Rachel Blin,  Samia Ainouz,  Gilles Gasso,  Romain Hérault,  Fabrice Meriaudeau,  Stéphane Canu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：including scene analysis, shown improved performances, shown improved, tasks including scene, deep learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Polarimetric imaging, along with deep learning, has shown improved
performances on different tasks including scene analysis. However, its
robustness may be questioned because of the small size of the training
datasets. Though the issue could be solved by data augmentation, polarization
modalities are subject to physical feasibility constraints unaddressed by
classical data augmentation techniques. To address this issue, we propose to
use CycleGAN, an image translation technique based on deep generative models
that solely relies on unpaired data, to transfer large labeled road scene
datasets to the polarimetric domain. We design several auxiliary loss terms
that, alongside the CycleGAN losses, deal with the physical constraints of
polarimetric images. The efficiency of this solution is demonstrated on road
scene object detection tasks where generated realistic polarimetric images
allow to improve performances on cars and pedestrian detection up to 9%. The
resulting constrained CycleGAN is publicly released, allowing anyone to
generate their own polarimetric images.</p>
  </details>
</details>
<details>
  <summary>27. <b>标题：Zero-shot object goal visual navigation</b></summary>
  <p><b>编号</b>：[113]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07423</p>
  <p><b>作者</b>：Qianfan Zhao,  Lu Zhang,  Bin He,  Hong Qiao,  Zhiyong Liu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：training stage, Object goal visual, goal visual navigation, target object, classes</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Object goal visual navigation is a challenging task that aims to guide a
robot to find the target object only based on its visual observation, and the
target is limited to the classes specified in the training stage. However, in
real households, there may exist numerous object classes that the robot needs
to deal with, and it is hard for all of these classes to be contained in the
training stage. To address this challenge, we propose a zero-shot object
navigation task by combining zero-shot learning with object goal visual
navigation, which aims at guiding robots to find objects belonging to novel
classes without any training samples. This task gives rise to the need to
generalize the learned policy to novel classes, which is a less addressed issue
of object navigation using deep reinforcement learning. To address this issue,
we utilize "class-unrelated" data as input to alleviate the overfitting of the
classes specified in the training stage. The class-unrelated input consists of
detection results and cosine similarity of word embeddings, and does not
contain any class-related visual features or knowledge graphs. Extensive
experiments on the AI2-THOR platform show that our model outperforms the
baseline models in both seen and unseen classes, which proves that our model is
less class-sensitive and generalizes better. Our code is available at
this https URL</p>
  </details>
</details>
<details>
  <summary>28. <b>标题："Why Here and Not There?" -- Diverse Contrasting Explanations of  Dimensionality Reduction</b></summary>
  <p><b>编号</b>：[123]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07391</p>
  <p><b>作者</b>：André Artelt,  Alexander Schulz,  Barbara Hammer</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：popular preprocessing, Dimensionality reduction, data mining tools, data mining, Dimensionality</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Dimensionality reduction is a popular preprocessing and a widely used tool in
data mining. Transparency, which is usually achieved by means of explanations,
is nowadays a widely accepted and crucial requirement of machine learning based
systems like classifiers and recommender systems. However, transparency of
dimensionality reduction and other data mining tools have not been considered
much yet, still it is crucial to understand their behavior -- in particular
practitioners might want to understand why a specific sample got mapped to a
specific location. In order to (locally) understand the behavior of a given
dimensionality reduction method, we introduce the abstract concept of
contrasting explanations for dimensionality reduction, and apply a realization
of this concept to the specific application of explaining two dimensional data
visualization.</p>
  </details>
</details>
<details>
  <summary>29. <b>标题：Mean-Semivariance Policy Optimization via Risk-Averse Reinforcement  Learning</b></summary>
  <p><b>编号</b>：[129]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07376</p>
  <p><b>作者</b>：Xiaoteng Ma,  Shuai Ma,  Li Xia,  Qianchuan Zhao</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：real-world decision-making situations, maximizing expected reward, autonomous driving, decision-making situations, crucial than maximizing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Keeping risk under control is often more crucial than maximizing expected
reward in real-world decision-making situations, such as finance, robotics,
autonomous driving, etc. The most natural choice of risk measures is variance,
while it penalizes the upside volatility as much as the downside part. Instead,
the (downside) semivariance, which captures negative deviation of a random
variable under its mean, is more suitable for risk-averse proposes. This paper
aims at optimizing the mean-semivariance (MSV) criterion in reinforcement
learning w.r.t. steady rewards. Since semivariance is time-inconsistent and
does not satisfy the standard Bellman equation, the traditional dynamic
programming methods are inapplicable to MSV problems directly. To tackle this
challenge, we resort to the Perturbation Analysis (PA) theory and establish the
performance difference formula for MSV. We reveal that the MSV problem can be
solved by iteratively solving a sequence of RL problems with a policy-dependent
reward function. Further, we propose two on-policy algorithms based on the
policy gradient theory and the trust region method. Finally, we conduct diverse
experiments from simple bandit problems to continuous control tasks in MuJoCo,
which demonstrate the effectiveness of our proposed methods.</p>
  </details>
</details>
<details>
  <summary>30. <b>标题：DiffWire: Inductive Graph Rewiring via the Lovász Bound</b></summary>
  <p><b>编号</b>：[134]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07369</p>
  <p><b>作者</b>：Adrián Arnaiz-Rodríguez,  Ahmed Begga,  Francisco Escolano,  Nuria Oliver</p>
  <p><b>备注</b>：22 pages, 6 figures and 5 tables. Preprint under review</p>
  <p><b>关键词</b>：Graph Neural Networks, achieve competitive results, Graph Neural, tackle graph-related tasks, Neural Networks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Graph Neural Networks (GNNs) have been shown to achieve competitive results
to tackle graph-related tasks, such as node and graph classification, link
prediction and node and graph clustering in a variety of domains. Most GNNs use
a message passing framework and hence are called MPNNs. Despite their promising
results, MPNNs have been reported to suffer from over-smoothing, over-squashing
and under-reaching. Graph rewiring and graph pooling have been proposed in the
literature as solutions to address these limitations. However, most
state-of-the-art graph rewiring methods fail to preserve the global topology of
the graph, are not differentiable (inductive) and require the tuning of
hyper-parameters. In this paper, we propose DiffWire, a novel framework for
graph rewiring in MPNNs that is principled, fully differentiable and
parameter-free by leveraging the Lovász bound. Our approach provides a
unified theory for graph rewiring by proposing two new, complementary layers in
MPNNs: first, CTLayer, a layer that learns the commute times and uses them as a
relevance function for edge re-weighting; second, GAPLayer, a layer to optimize
the spectral gap, depending on the nature of the network and the task at hand.
We empirically validate the value of our proposed approach and each of these
layers separately with benchmark datasets for graph classification. DiffWire
brings together the learnability of commute times to related definitions of
curvature, opening the door to the development of more expressive MPNNs.</p>
  </details>
</details>
<details>
  <summary>31. <b>标题：Modern Machine-Learning Predictive Models for Diagnosing Infectious  Diseases</b></summary>
  <p><b>编号</b>：[136]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07365</p>
  <p><b>作者</b>：Eman Yahia Alqaissi,  Fahd Saleh Alotaibi,  Muhammad Sher Ramzan</p>
  <p><b>备注</b>：13 pages, 4 figures, 6 tables</p>
  <p><b>关键词</b>：major health priority, Controlling infectious diseases, infect humans, epidemics or pandemics, infectious diseases</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Controlling infectious diseases is a major health priority because they can
spread and infect humans, thus evolving into epidemics or pandemics. Therefore,
early detection of infectious diseases is a significant need, and many
researchers have developed models to diagnose them in the early stages. This
paper reviewed research articles for recent machine-learning (ML) algorithms
applied to infectious disease diagnosis. We searched the Web of Science,
ScienceDirect, PubMed, Springer, and IEEE databases from 2015 to 2022,
identified the pros and cons of the reviewed ML models, and discussed the
possible recommendations to advance the studies in this field. We found that
most of the articles used small datasets, and few of them used real-time data.
Our results demonstrated that a suitable ML technique depends on the nature of
the dataset and the desired goal.</p>
  </details>
</details>
<details>
  <summary>32. <b>标题：The Emotion is Not One-hot Encoding: Learning with Grayscale Label for  Emotion Recognition in Conversation</b></summary>
  <p><b>编号</b>：[138]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07359</p>
  <p><b>作者</b>：Joosung Lee</p>
  <p><b>备注</b>：Accepted by INTERSPEECH 2022</p>
  <p><b>关键词</b>：natural language processing, language processing tasks, current utterance, utterance is predicted, natural language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In emotion recognition in conversation (ERC), the emotion of the current
utterance is predicted by considering the previous context, which can be
utilized in many natural language processing tasks. Although multiple emotions
can coexist in a given sentence, most previous approaches take the perspective
of a classification task to predict only a given label. However, it is
expensive and difficult to label the emotion of a sentence with confidence or
multi-label. In this paper, we automatically construct a grayscale label
considering the correlation between emotions and use it for learning. That is,
instead of using a given label as a one-hot encoding, we construct a grayscale
label by measuring scores for different emotions. We introduce several methods
for constructing grayscale labels and confirm that each method improves the
emotion recognition performance. Our method is simple, effective, and
universally applicable to previous systems. The experiments show a significant
improvement in the performance of baselines.</p>
  </details>
</details>
<details>
  <summary>33. <b>标题：Robust SAR ATR on MSTAR with Deep Learning Models trained on Full  Synthetic MOCEM data</b></summary>
  <p><b>编号</b>：[141]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07352</p>
  <p><b>作者</b>：Benjamin Camus,  Corentin Le Barbu,  Eric Monteux</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Automatic Target Recognition, Synthetic Aperture Radar, Target Recognition, Aperture Radar, Deep Learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The promising potential of Deep Learning for Automatic Target Recognition
(ATR) on Synthetic Aperture Radar (SAR) images vanishes when considering the
complexity of collecting training datasets measurements. Simulation can
overcome this issue by producing synthetic training datasets. However, because
of the limited representativeness of simulation, models trained in a classical
way with synthetic images have limited generalization abilities when dealing
with real measurement at test time. Previous works identified a set of equally
promising deep-learning algorithms to tackle this issue. However, these
approaches have been evaluated in a very favorable scenario with a synthetic
training dataset that overfits the ground truth of the measured test data. In
this work, we study the ATR problem outside of this ideal condition, which is
unlikely to occur in real operational contexts. Our contribution is threefold.
(1) Using the MOCEM simulator (developed by SCALIAN DS for the French MoD/DGA),
we produce a synthetic MSTAR training dataset that differs significantly from
the real measurements. (2) We experimentally demonstrate the limits of the
state-of-the-art. (3) We show that domain randomization techniques and
adversarial training can be combined to overcome this issue. We demonstrate
that this approach is more robust than the state-of-the-art, with an accuracy
of 75 %, while having a limited impact on computing performance during
training.</p>
  </details>
</details>
<details>
  <summary>34. <b>标题：Unsupervised Capsule Networks of High-Dimension Point Clouds  classification</b></summary>
  <p><b>编号</b>：[145]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07348</p>
  <p><b>作者</b>：Quanfeng Xu,  Yi Tang,  Yan Yang,  Yumei She,  Zuo Jiang</p>
  <p><b>备注</b>：24 pages</p>
  <p><b>关键词</b>：point clouds, high-dimensional point clouds, clouds, point, point clouds classification</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Three-dimensional point clouds learning is widely applied, but the point
clouds are still unable to deal with classification and recognition tasks
satisfactorily in the cases of irregular geometric structures and
high-dimensional space. In 3D space, point clouds tend to have regular
Euclidean structure because of their density. On the contrary, due to the high
dimensionality, the spatial structure of high-dimensional space is more
complex, and point clouds are mostly presented in non-European structure.
Furthermore, among current 3D point clouds classification algorithms, Canonical
Capsules algorithm based on Euclidean distance is difficult to decompose and
identify non-Euclidean structures effectively. Thus, aiming at the point clouds
classification task of non-Euclidean structure in 3D and high-dimensional
space, this paper refers to the LLE algorithm based on geodesic distance for
optimizing and proposes the unsupervised algorithm of high-dimensional point
clouds capsule. In this paper, the geometric features of point clouds are
considered in the extraction process, so as to transform the high-dimensional
non-Euclidean structure into a lower-dimensional Euclidean structure with
retaining spatial geometric features. To verify the feasibility of the
unsupervised algorithm of high-dimensional point clouds capsule, experiments
are conducted in Swiss Roll dataset, point clouds MNIST dataset and point
clouds LFW dataset. The results show that (1) non-Euclidean structures can be
can effectively identified by this model in Swiss Roll dataset; (2) a
significant unsupervised learning effect is realized in point clouds MNIST
dataset. In conclusion, the high-dimensional point clouds capsule unsupervised
algorithm proposed in this paper is conducive to expand the application
scenarios of current point clouds classification and recognition tasks.</p>
  </details>
</details>
<details>
  <summary>35. <b>标题：Automatic Detection of Rice Disease in Images of Various Leaf Sizes</b></summary>
  <p><b>编号</b>：[147]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07344</p>
  <p><b>作者</b>：Kantip Kiratiratanapruk,  Pitchayagan Temniranrat,  Wasin Sinthupinyo,  Sanparith Marukatat,  Sujin Patarapuwadol</p>
  <p><b>备注</b>：28 pages, 13 figures</p>
  <p><b>关键词</b>：expertise shortages problems, farmers tackling equipment, rice, accurate and affordable, method is required</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Fast, accurate and affordable rice disease detection method is required to
assist rice farmers tackling equipment and expertise shortages problems. In
this paper, we focused on the solution using computer vision technique to
detect rice diseases from rice field photograph images. Dealing with images
took in real-usage situation by general farmers is quite challenging due to
various environmental factors, and rice leaf object size variation is one major
factor caused performance gradation. To solve this problem, we presented a
technique combining a CNN object detection with image tiling technique, based
on automatically estimated width size of rice leaves in the images as a size
reference for dividing the original input image. A model to estimate leaf width
was created by small size CNN such as 18 layer ResNet architecture model. A new
divided tiled sub-image set with uniformly sized object was generated and used
as input for training a rice disease prediction model. Our technique was
evaluated on 4,960 images of eight different types of rice leaf diseases,
including blast, blight, brown spot, narrow brown spot, orange, red stripe,
rice grassy stunt virus, and streak disease. The mean absolute percentage error
(MAPE) for leaf width prediction task evaluated on all eight classes was 11.18%
in the experiment, indicating that the leaf width prediction model performed
well. The mean average precision (mAP) of the prediction performance on YOLOv4
architecture was enhanced from 87.56% to 91.14% when trained and tested with
the tiled dataset. According to our study, the proposed image tiling technique
improved rice disease detection efficiency.</p>
  </details>
</details>
<details>
  <summary>36. <b>标题：Cautious Learning of Multiattribute Preferences</b></summary>
  <p><b>编号</b>：[148]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07341</p>
  <p><b>作者</b>：Hugo Gilbert (LAMSADE),  Mohamed Ouaguenouni,  Meltem Ozturk,  Olivier Spanjaard</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：cautious learning methodology, binary attributes, paper is dedicated, learning methodology, methodology for predicting</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper is dedicated to a cautious learning methodology for predicting
preferences between alternatives characterized by binary attributes (formally,
each alternative is seen as a subset of attributes). By "cautious", we mean
that the model learned to represent the multi-attribute preferences is general
enough to be compatible with any strict weak order on the alternatives, and
that we allow ourselves not to predict some preferences if the data collected
are not compatible with a reliable prediction. A predicted preference will be
considered reliable if all the simplest models (following Occam's razor
principle) explaining the training data agree on it. Predictions are based on
an ordinal dominance relation between alternatives [Fishburn and LaValle,
1996]. The dominance relation relies on an uncertainty set encompassing the
possible values of the parameters of the multi-attribute utility function.
Numerical tests are provided to evaluate the richness and the reliability of
the predictions made.</p>
  </details>
</details>
<details>
  <summary>37. <b>标题：Knowledge Management System with NLP-Assisted Annotations: A Brief  Survey and Outlook</b></summary>
  <p><b>编号</b>：[167]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07304</p>
  <p><b>作者</b>：Baihan Lin</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：industrial researchers, high demand, demand for industrial, evidence-based decision making, decision making</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Knowledge management systems are in high demand for industrial researchers,
chemical or research enterprises, or evidence-based decision making. However,
existing systems have limitations in categorizing and organizing paper insights
or relationships. Traditional databases are usually disjoint with logging
systems, which limit its utility in generating concise, collated overviews. In
this work, we briefly survey existing approaches of this problem space and
propose a unified framework that utilizes relational databases to log
hierarchical information to facilitate the research and writing process, or
generate useful knowledge from references or insights from connected concepts.
This framework of knowledge management system enables novel functionalities
encompassing improved hierarchical notetaking, AI-assisted brainstorming, and
multi-directional relationships. Potential applications include managing
inventories and changes for manufacture or research enterprises, or generating
analytic reports with evidence-based decision making.</p>
  </details>
</details>
<details>
  <summary>38. <b>标题：From Outcome-Based to Language-Based Preferences</b></summary>
  <p><b>编号</b>：[169]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07300</p>
  <p><b>作者</b>：Valerio Capraro,  Joseph Y. Halpern,  Matjaz Perc</p>
  <p><b>备注</b>：Forthcoming in the Journal of Economic Literature</p>
  <p><b>关键词</b>：explain human behavior, monetary payoffs, review the literature, explain human, human behavior</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We review the literature on models that try to explain human behavior in
social interactions described by normal-form games with monetary payoffs. We
start by covering social and moral preferences. We then focus on the growing
body of research showing that people react to the language in which actions are
described, especially when it activates moral concerns. We conclude by arguing
that behavioral economics is in the midst of a paradigm shift towards
language-based preferences, which will require an exploration of new models and
experimental setups.</p>
  </details>
</details>
<details>
  <summary>39. <b>标题：S\textsuperscript{2}-FPN: Scale-ware Strip Attention Guided Feature  Pyramid Network for Real-time Semantic Segmentation</b></summary>
  <p><b>编号</b>：[170]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07298</p>
  <p><b>作者</b>：Mohammed A. M. Elhassan,  Chenhui Yang,  Chenxi Huang,  Tewodros Legesse Munea,  Xin Hong</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Modern high-performance semantic, Modern high-performance, APF, heavy backbone, backbone and dilated</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Modern high-performance semantic segmentation methods employ a heavy backbone
and dilated convolution to extract the relevant feature. Although extracting
features with both contextual and semantic information is critical for the
segmentation tasks, it brings a memory footprint and high computation cost for
real-time applications. This paper presents a new model to achieve a trade-off
between accuracy/speed for real-time road scene semantic segmentation.
Specifically, we proposed a lightweight model named Scale-aware Strip Attention
Guided Feature Pyramid Network (S\textsuperscript{2}-FPN). Our network consists
of three main modules: Attention Pyramid Fusion (APF) module, Scale-aware Strip
Attention Module (SSAM), and Global Feature Upsample (GFU) module. APF adopts
an attention mechanisms to learn discriminative multi-scale features and help
close the semantic gap between different levels. APF uses the scale-aware
attention to encode global context with vertical stripping operation and models
the long-range dependencies, which helps relate pixels with similar semantic
label. In addition, APF employs channel-wise reweighting block (CRB) to
emphasize the channel features. Finally, the decoder of
S\textsuperscript{2}-FPN then adopts GFU, which is used to fuse features from
APF and the encoder. Extensive experiments have been conducted on two
challenging semantic segmentation benchmarks, which demonstrate that our
approach achieves better accuracy/speed trade-off with different model
settings. The proposed models have achieved a results of 76.2\%mIoU/87.3FPS,
77.4\%mIoU/67FPS, and 77.8\%mIoU/30.5FPS on Cityscapes dataset, and
69.6\%mIoU,71.0\% mIoU, and 74.2\% mIoU on Camvid dataset. The code for this
work will be made available at \url{this https URL</p>
  </details>
</details>
<details>
  <summary>40. <b>标题：Text-Aware End-to-end Mispronunciation Detection and Diagnosis</b></summary>
  <p><b>编号</b>：[175]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07289</p>
  <p><b>作者</b>：Linkai Peng,  Yingming Gao,  Binghuai Lin,  Dengfeng Ke,  Yanlu Xie,  Jinsong Zhang</p>
  <p><b>备注</b>：Rejected by Interspeech2022</p>
  <p><b>关键词</b>：computer-assisted pronunciation training, Mispronunciation detection, detection and diagnosis, pronunciation training system, key component</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Mispronunciation detection and diagnosis (MDD) technology is a key component
of computer-assisted pronunciation training system (CAPT). In the field of
assessing the pronunciation quality of constrained speech, the given
transcriptions can play the role of a teacher. Conventional methods have fully
utilized the prior texts for the model construction or improving the system
performance, e.g. forced-alignment and extended recognition networks. Recently,
some end-to-end based methods attempt to incorporate the prior texts into model
training and preliminarily show the effectiveness. However, previous studies
mostly consider applying raw attention mechanism to fuse audio representations
with text representations, without taking possible text-pronunciation mismatch
into account. In this paper, we present a gating strategy that assigns more
importance to the relevant audio features while suppressing irrelevant text
information. Moreover, given the transcriptions, we design an extra contrastive
loss to reduce the gap between the learning objective of phoneme recognition
and MDD. We conducted experiments using two publicly available datasets (TIMIT
and L2-Arctic) and our best model improved the F1 score from $57.51\%$ to
$61.75\%$ compared to the baselines. Besides, we provide a detailed analysis to
shed light on the effectiveness of gating mechanism and contrastive learning on
MDD.</p>
  </details>
</details>
<details>
  <summary>41. <b>标题：ALASCA: Rethinking Label Smoothing for Deep Learning Under Label Noise</b></summary>
  <p><b>编号</b>：[182]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07277</p>
  <p><b>作者</b>：Jongwoo Ko,  Bongsoo Yi,  Se-Young Yun</p>
  <p><b>备注</b>：ICML Workshop on Principles of Distribution Shift 2022</p>
  <p><b>关键词</b>：severely degrades deep, modern deep learning, popular distribution shifts, networks' generalization performance, degrades deep neural</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As label noise, one of the most popular distribution shifts, severely
degrades deep neural networks' generalization performance, robust training with
noisy labels is becoming an important task in modern deep learning. In this
paper, we propose our framework, coined as Adaptive LAbel smoothing on
Sub-ClAssifier (ALASCA), that provides a robust feature extractor with
theoretical guarantee and negligible additional computation. First, we derive
that the label smoothing (LS) incurs implicit Lipschitz regularization (LR).
Furthermore, based on these derivations, we apply the adaptive LS (ALS) on
sub-classifiers architectures for the practical application of adaptive LR on
intermediate layers. We conduct extensive experiments for ALASCA and combine it
with previous noise-robust methods on several datasets and show our framework
consistently outperforms corresponding baselines.</p>
  </details>
</details>
<details>
  <summary>42. <b>标题：Machine vision for vial positioning detection toward the safe automation  of material synthesis</b></summary>
  <p><b>编号</b>：[184]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07272</p>
  <p><b>作者</b>：Leslie Ching Ow Tiong,  Hyuk Jun Yoo,  Na Yeon Kim,  Kwan-Young Lee,  Sang Soo Han,  Donghun Kim</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：machine control errors, dangerous accidents primarily, accidents primarily due, material development process, development process</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Although robot-based automation in chemistry laboratories can accelerate the
material development process, surveillance-free environments may lead to
dangerous accidents primarily due to machine control errors. Object detection
techniques can play vital roles in addressing these safety issues; however,
state-of-the-art detectors, including single-shot detector (SSD) models, suffer
from insufficient accuracy in environments involving complex and noisy scenes.
With the aim of improving safety in a surveillance-free laboratory, we report a
novel deep learning (DL)-based object detector, namely, DenseSSD. For the
foremost and frequent problem of detecting vial positions, DenseSSD achieved a
mean average precision (mAP) over 95% based on a complex dataset involving both
empty and solution-filled vials, greatly exceeding those of conventional
detectors; such high precision is critical to minimizing failure-induced
accidents. Additionally, DenseSSD was observed to be highly insensitive to the
environmental changes, maintaining its high precision under the variations of
solution colors or testing view angles. The robustness of DenseSSD would allow
the utilized equipment settings to be more flexible. This work demonstrates
that DenseSSD is useful for enhancing safety in an automated material synthesis
environment, and it can be extended to various applications where high
detection accuracy and speed are both needed.</p>
  </details>
</details>
<details>
  <summary>43. <b>标题：Human Heuristics for AI-Generated Language Are Flawed</b></summary>
  <p><b>编号</b>：[185]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07271</p>
  <p><b>作者</b>：Maurice Jakesch,  Jeffrey Hancock,  Mor Naaman</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：language, communication is increasingly, increasingly intermixed, Human, generated</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Human communication is increasingly intermixed with language generated by AI.
Across chat, email, and social media, AI systems produce smart replies,
autocompletes, and translations. AI-generated language is often not identified
as such but poses as human language, raising concerns about novel forms of
deception and manipulation. Here, we study how humans discern whether one of
the most personal and consequential forms of language - a self-presentation -
was generated by AI. Across six experiments, participants (N = 4,650) tried to
identify self-presentations generated by state-of-the-art language models.
Across professional, hospitality, and romantic settings, we find that humans
are unable to identify AI-generated self-presentations. Combining qualitative
analyses with language feature engineering, we find that human judgments of
AI-generated language are handicapped by intuitive but flawed heuristics such
as associating first-person pronouns, authentic words, or family topics with
humanity. We show that these heuristics make human judgment of generated
language predictable and manipulable, allowing AI systems to produce language
perceived as more human than human. We conclude by discussing solutions - such
as AI accents or fair use policies - to reduce the deceptive potential of
generated language, limiting the subversion of human intuition.</p>
  </details>
</details>
<details>
  <summary>44. <b>标题：Fair Ranking as Fair Division: Impact-Based Individual Fairness in  Ranking</b></summary>
  <p><b>编号</b>：[197]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07247</p>
  <p><b>作者</b>：Yuta Saito,  Thorsten Joachims</p>
  <p><b>备注</b>：accepted at KDD2022</p>
  <p><b>关键词</b>：two-sided online markets, online markets, primary interface, interface in two-sided, two-sided online</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Rankings have become the primary interface in two-sided online markets. Many
have noted that the rankings not only affect the satisfaction of the users
(e.g., customers, listeners, employers, travelers), but that the position in
the ranking allocates exposure -- and thus economic opportunity -- to the
ranked items (e.g., articles, products, songs, job seekers, restaurants,
hotels). This has raised questions of fairness to the items, and most existing
works have addressed fairness by explicitly linking item exposure to item
relevance. However, we argue that any particular choice of such a link function
may be difficult to defend, and we show that the resulting rankings can still
be unfair. To avoid these shortcomings, we develop a new axiomatic approach
that is rooted in principles of fair division. This not only avoids the need to
choose a link function, but also more meaningfully quantifies the impact on the
items beyond exposure. Our axioms of envy-freeness and dominance over uniform
ranking postulate that for a fair ranking policy every item should prefer their
own rank allocation over that of any other item, and that no item should be
actively disadvantaged by the rankings. To compute ranking policies that are
fair according to these axioms, we propose a new ranking objective related to
the Nash Social Welfare. We show that the solution has guarantees regarding its
envy-freeness, its dominance over uniform rankings for every item, and its
Pareto optimality. In contrast, we show that conventional exposure-based
fairness can produce large amounts of envy and have a highly disparate impact
on the items. Beyond these theoretical results, we illustrate empirically how
our framework controls the trade-off between impact-based individual item
fairness and user utility.</p>
  </details>
</details>
<details>
  <summary>45. <b>标题：An Extractive-and-Abstractive Framework for Source Code Summarization</b></summary>
  <p><b>编号</b>：[198]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07245</p>
  <p><b>作者</b>：Weisong Sun,  Chunrong Fang,  Yuchen Chen,  Quanjun Zhang,  Guanhong Tao,  Tingxu Han,  Yifei Ge,  Yudu You,  Bin Luo</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Code, code snippet, Code summarization, maintain source code, Code summarization aims</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>(Source) Code summarization aims to automatically generate summaries/comments
for a given code snippet in the form of natural language. Such summaries play a
key role in helping developers understand and maintain source code. Existing
code summarization techniques can be categorized into extractive methods and
abstractive methods. The extractive methods extract a subset of important
statements and keywords from the code snippet using retrieval techniques, and
generate a summary that preserves factual details in important statements and
keywords. However, such a subset may miss identifier or entity naming, and
consequently, the naturalness of generated summary is usually poor. The
abstractive methods can generate human-written-like summaries leveraging
encoder-decoder models from the neural machine translation domain. The
generated summaries however often miss important factual details.
To generate human-written-like summaries with preserved factual details, we
propose a novel extractive-and-abstractive framework. The extractive module in
the framework performs a task of extractive code summarization, which takes in
the code snippet and predicts important statements containing key factual
details. The abstractive module in the framework performs a task of abstractive
code summarization, which takes in the entire code snippet and important
statements in parallel and generates a succinct and human-written-like natural
language summary. We evaluate the effectiveness of our technique, called EACS,
by conducting extensive experiments on three datasets involving six programming
languages. Experimental results show that EACS significantly outperforms
state-of-the-art techniques in terms of all three widely used metrics,
including BLEU, METEOR, and ROUGH-L.</p>
  </details>
</details>
<details>
  <summary>46. <b>标题：Test-Time Adaptation for Visual Document Understanding</b></summary>
  <p><b>编号</b>：[202]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07240</p>
  <p><b>作者</b>：Sayna Ebrahimi,  Sercan O. Arik,  Tomas Pfister</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：produce transferable representations, produce transferable, visual document understanding, transferable representations, document understanding</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Self-supervised pretraining has been able to produce transferable
representations for various visual document understanding (VDU) tasks. However,
the ability of such representations to adapt to new distribution shifts at
test-time has not been studied yet. We propose DocTTA, a novel test-time
adaptation approach for documents that leverages cross-modality self-supervised
learning via masked visual language modeling as well as pseudo labeling to
adapt models learned on a \textit{source} domain to an unlabeled
\textit{target} domain at test time. We also introduce new benchmarks using
existing public datasets for various VDU tasks including entity recognition,
key-value extraction, and document visual question answering tasks where DocTTA
improves the source model performance up to 1.79\% in (F1 score), 3.43\% (F1
score), and 17.68\% (ANLS score), respectively while drastically reducing
calibration error on target data.</p>
  </details>
</details>
<details>
  <summary>47. <b>标题：Training Discrete Deep Generative Models via Gapped Straight-Through  Estimator</b></summary>
  <p><b>编号</b>：[204]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07235</p>
  <p><b>作者</b>：Ting-Han Fan,  Ta-Chung Chi,  Alexander I. Rudnicky,  Peter J. Ramadge</p>
  <p><b>备注</b>：Accepted at the International Conference on Machine Learning (ICML) 2022. The first two authors contributed equally</p>
  <p><b>关键词</b>：natural language processing, gradient estimation process, random variables remains, variables remains challenging, remains challenging due</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>While deep generative models have succeeded in image processing, natural
language processing, and reinforcement learning, training that involves
discrete random variables remains challenging due to the high variance of its
gradient estimation process. Monte Carlo is a common solution used in most
variance reduction approaches. However, this involves time-consuming resampling
and multiple function evaluations. We propose a Gapped Straight-Through (GST)
estimator to reduce the variance without incurring resampling overhead. This
estimator is inspired by the essential properties of Straight-Through
Gumbel-Softmax. We determine these properties and show via an ablation study
that they are essential. Experiments demonstrate that the proposed GST
estimator enjoys better performance compared to strong baselines on two
discrete deep generative modeling tasks, MNIST-VAE and ListOps.</p>
  </details>
</details>
<details>
  <summary>48. <b>标题：Codec at SemEval-2022 Task 5: Multi-Modal Multi-Transformer Misogynous  Meme Classification Framework</b></summary>
  <p><b>编号</b>：[224]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07190</p>
  <p><b>作者</b>：Ahmed Mahran,  Carlo Alessandro Borella,  Konstantinos Perifanos</p>
  <p><b>备注</b>：Accepted for publication at the 16th International Workshop on Semantic Evaluation, Task 5: MAMI - Multimedia Automatic Misogyny Identification co-located with NAACL 2022</p>
  <p><b>关键词</b>：Multimedia Automatic Misogyny, Automatic Misogyny Identification, Multimedia Automatic, Misogyny Identification, Automatic Misogyny</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper we describe our work towards building a generic framework for
both multi-modal embedding and multi-label binary classification tasks, while
participating in task 5 (Multimedia Automatic Misogyny Identification) of
SemEval 2022 competition.
Since pretraining deep models from scratch is a resource and data hungry
task, our approach is based on three main strategies. We combine different
state-of-the-art architectures to capture a wide spectrum of semantic signals
from the multi-modal input. We employ a multi-task learning scheme to be able
to use multiple datasets from the same knowledge domain to help increase the
model's performance. We also use multiple objectives to regularize and fine
tune different system components.</p>
  </details>
</details>
<details>
  <summary>49. <b>标题：Automated image analysis in large-scale cellular electron microscopy: A  literature survey</b></summary>
  <p><b>编号</b>：[234]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07171</p>
  <p><b>作者</b>：Anusha Aswatha,  Ahmad Alsahaf,  Ben N. G. Giepmans,  George Azzopardi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Large-scale electron microscopy, Large-scale electron, electron microscopy, analysis, automated microscopes</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large-scale electron microscopy (EM) datasets generated using (semi-)
automated microscopes are becoming the standard in EM. Given the vast amounts
of data, manual analysis of all data is not feasible, thus automated analysis
is crucial. The main challenges in automated analysis include the annotation
that is needed to analyse and interpret biomedical images, coupled with
achieving high-throughput. Here, we review the current state-of-the-art of
automated computer techniques and major challenges for the analysis of
structures in cellular EM. The advanced computer vision, deep learning and
software tools that have been developed in the last five years for automatic
biomedical image analysis are discussed with respect to annotation,
segmentation and scalability for EM data. Integration of automatic image
acquisition and analysis will allow for high-throughput analysis of
millimeter-range datasets with nanometer resolution.</p>
  </details>
</details>
<details>
  <summary>50. <b>标题：Understanding Narratives through Dimensions of Analogy</b></summary>
  <p><b>编号</b>：[236]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07167</p>
  <p><b>作者</b>：Thiloshon Nagarajah,  Filip Ilievski,  Jay Pujara</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：powerful qualitative reasoning, qualitative reasoning tool, Cognitive Science research, Analogical reasoning, Cognitive Science</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Analogical reasoning is a powerful qualitative reasoning tool that enables
humans to connect two situations, and to generalize their knowledge from
familiar to novel situations. Cognitive Science research provides valuable
insights into the richness and complexity of analogical reasoning, together
with implementations of expressive analogical reasoners with limited
scalability. Modern scalable AI techniques with the potential to reason by
analogy have been only applied to the special case of proportional analogy, and
not to understanding higher-order analogies. In this paper, we aim to bridge
the gap by: 1) formalizing six dimensions of analogy based on mature insights
from Cognitive Science research, 2) annotating a corpus of fables with each of
these dimensions, and 3) defining four tasks with increasing complexity that
enable scalable evaluation of AI techniques. Experiments with language models
and neuro-symbolic AI reasoners on these tasks reveal that state-of-the-art
methods can be applied to reason by analogy with a limited success, motivating
the need for further research towards comprehensive and scalable analogical
reasoning by AI. We make all our code and data available.</p>
  </details>
</details>
<details>
  <summary>51. <b>标题：Regularizing a Model-based Policy Stationary Distribution to Stabilize  Offline Reinforcement Learning</b></summary>
  <p><b>编号</b>：[237]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07166</p>
  <p><b>作者</b>：Shentao Yang,  Yihao Feng,  Shujian Zhang,  Mingyuan Zhou</p>
  <p><b>备注</b>：International Conference on Machine Learning (ICML) 2022</p>
  <p><b>关键词</b>：Offline reinforcement learning, reinforcement learning, purely learning, extends the paradigm, undiscounted stationary distribution</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Offline reinforcement learning (RL) extends the paradigm of classical RL
algorithms to purely learning from static datasets, without interacting with
the underlying environment during the learning process. A key challenge of
offline RL is the instability of policy training, caused by the mismatch
between the distribution of the offline data and the undiscounted stationary
state-action distribution of the learned policy. To avoid the detrimental
impact of distribution mismatch, we regularize the undiscounted stationary
distribution of the current policy towards the offline data during the policy
optimization process. Further, we train a dynamics model to both implement this
regularization and better estimate the stationary distribution of the current
policy, reducing the error induced by distribution mismatch. On a wide range of
continuous-control offline RL datasets, our method indicates competitive
performance, which validates our algorithm. The code is publicly available.</p>
  </details>
</details>
<details>
  <summary>52. <b>标题：Edge Security: Challenges and Issues</b></summary>
  <p><b>编号</b>：[238]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07164</p>
  <p><b>作者</b>：Xin Jin,  Charalampos Katsis,  Fan Sang,  Jiahao Sun,  Ashish Kundu,  Ramana Kompella</p>
  <p><b>备注</b>：21 pages. Survey paper</p>
  <p><b>关键词</b>：shifts data processing, data processing services, shifts data, paradigm that shifts, data processing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Edge computing is a paradigm that shifts data processing services to the
network edge, where data are generated. While such an architecture provides
faster processing and response, among other benefits, it also raises critical
security issues and challenges that must be addressed. This paper discusses the
security threats and vulnerabilities emerging from the edge network
architecture spanning from the hardware layer to the system layer. We further
discuss privacy and regulatory compliance challenges in such networks. Finally,
we argue the need for a holistic approach to analyze edge network security
posture, which must consider knowledge from each layer.</p>
  </details>
</details>
<details>
  <summary>53. <b>标题：Category-Agnostic 6D Pose Estimation with Conditional Neural Processes</b></summary>
  <p><b>编号</b>：[240]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07162</p>
  <p><b>作者</b>：Yumeng Li,  Ning Gao,  Hanna Ziesche,  Gerhard Neumann</p>
  <p><b>备注</b>：Accepted at CVPR2022 workshop: Women in Computer Vision (WiCV)</p>
  <p><b>关键词</b>：pose estimation methods, pose estimation, meta-learning approach, pose, unknown objects</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present a novel meta-learning approach for 6D pose estimation on unknown
objects. In contrast to "instance-level" pose estimation methods, our algorithm
learns object representation in a category-agnostic way, which endows it with
strong generalization capabilities within and across object categories.
Specifically, we employ a conditional neural process-based meta-learning
approach to train an encoder to capture texture and geometry of an object in a
latent representation, based on very few RGB-D images and ground-truth
keypoints. The latent representation is then used by a simultaneously
meta-trained decoder to predict the 6D pose of the object in new images. To
evaluate our algorithm, experiments are conducted on our new fully-annotated
synthetic datasets generated from Multiple Categories in Multiple Scenes
(MCMS). Experimental results demonstrate that our model performs well on unseen
objects with various shapes and appearances.</p>
  </details>
</details>
<details>
  <summary>54. <b>标题：GraphFM: Improving Large-Scale GNN Training via Feature Momentum</b></summary>
  <p><b>编号</b>：[241]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07161</p>
  <p><b>作者</b>：Haiyang Yu,  Limei Wang,  Bokun Wang,  Meng Liu,  Tianbao Yang,  Shuiwang Ji</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：graph neural networks, neural networks, classification is challenging, node classification, large-scale node classification</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Training of graph neural networks (GNNs) for large-scale node classification
is challenging. A key difficulty lies in obtaining accurate hidden node
representations while avoiding the neighborhood explosion problem. Here, we
propose a new technique, named as feature momentum (FM), that uses a momentum
step to incorporate historical embeddings when updating feature
representations. We develop two specific algorithms, known as GraphFM-IB and
GraphFM-OB, that consider in-batch and out-of-batch data, respectively.
GraphFM-IB applies FM to in-batch sampled data, while GraphFM-OB applies FM to
out-of-batch data that are 1-hop neighborhood of in-batch data. We provide a
rigorous convergence analysis for GraphFM-IB and theoretical insight of
GraphFM-OB for the estimation error of feature embeddings. Empirically, we
observe that GraphFM-IB can effectively alleviate the neighborhood explosion
problem of existing methods. In addition, GraphFM-OB achieves promising
performance on multiple large-scale graph datasets.</p>
  </details>
</details>
<details>
  <summary>55. <b>标题：An Intelligent Assistant for Converting City Requirements to Formal  Specification</b></summary>
  <p><b>编号</b>：[244]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07152</p>
  <p><b>作者</b>：Zirong Chen,  Isaac Li,  Haoxiang Zhang,  Sarah Preum,  John Stankovic,  Meiyi Ma</p>
  <p><b>备注</b>：This demo paper is accepted by SMARTCOMP 2022</p>
  <p><b>关键词</b>：higher demand, demand for converting, converting new human-specified, smart cities, formal specifications automatically</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As more and more monitoring systems have been deployed to smart cities, there
comes a higher demand for converting new human-specified requirements to
machine-understandable formal specifications automatically. However, these
human-specific requirements are often written in English and bring missing,
inaccurate, or ambiguous information. In this paper, we present CitySpec, an
intelligent assistant system for requirement specification in smart cities.
CitySpec not only helps overcome the language differences brought by English
requirements and formal specifications, but also offers solutions to those
missing, inaccurate, or ambiguous information. The goal of this paper is to
demonstrate how CitySpec works. Specifically, we present three demos: (1)
interactive completion of requirements in CitySpec; (2) human-in-the-loop
correction while CitySepc encounters exceptions; (3) online learning in
CitySpec.</p>
  </details>
</details>
<details>
  <summary>56. <b>标题：MBGDT:Robust Mini-Batch Gradient Descent</b></summary>
  <p><b>编号</b>：[249]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07139</p>
  <p><b>作者</b>：Hanming Wang,  Haozheng Luo,  Yue Wang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：mini-batch gradient descent, gradient descent, machine learning method, learning method perform, method perform fragile</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In high dimensions, most machine learning method perform fragile even there
are a little outliers. To address this, we hope to introduce a new method with
the base learner, such as Bayesian regression or stochastic gradient descent to
solve the problem of the vulnerability in the model. Because the mini-batch
gradient descent allows for a more robust convergence than the batch gradient
descent, we work a method with the mini-batch gradient descent, called
Mini-Batch Gradient Descent with Trimming (MBGDT). Our method show state-of-art
performance and have greater robustness than several baselines when we apply
our method in designed dataset.</p>
  </details>
</details>
<details>
  <summary>57. <b>标题：Plurality Veto: A Simple Voting Rule Achieving Optimal Metric Distortion</b></summary>
  <p><b>编号</b>：[262]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07098</p>
  <p><b>作者</b>：Fatih Erdem Kizilkaya,  David Kempe</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：metric distortion framework, distortion framework posits, metric space, Plurality Veto, voting rule</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The metric distortion framework posits that n voters and m candidates are
jointly embedded in a metric space such that voters rank candidates that are
closer to them higher. A voting rule's purpose is to pick a candidate with
minimum total distance to the voters, given only the rankings, but not the
actual distances. As a result, in the worst case, each deterministic rule picks
a candidate whose total distance is at least three times larger than that of an
optimal one, i.e., has distortion at least 3. A recent breakthrough result
showed that achieving this bound of 3 is possible; however, the proof is
non-constructive, and the voting rule itself is a complicated exhaustive
search.
Our main result is an extremely simple voting rule, called Plurality Veto,
which achieves the same optimal distortion of 3. Each candidate starts with a
score equal to his number of first-place votes. These scores are then gradually
decreased via an n-round veto process in which a candidate drops out when his
score reaches zero. One after the other, voters decrement the score of their
bottom choice among the standing candidates, and the last standing candidate
wins. We give a one-paragraph proof that this voting rule achieves distortion
3. This rule is also immensely practical, and it only makes two queries to each
voter, so it has low communication overhead.
We also generalize Plurality Veto into a class of randomized voting rules in
the following way: Plurality veto is run only for k < n rounds; then, a
candidate is chosen with probability proportional to his residual score. This
general rule interpolates between Random Dictatorship (for k=0) and Plurality
Veto (for k=n-1), and k controls the variance of the output. We show that for
all k, this rule has distortion at most 3.</p>
  </details>
</details>
<details>
  <summary>58. <b>标题：Understanding the Generalization Benefit of Normalization Layers:  Sharpness Reduction</b></summary>
  <p><b>编号</b>：[273]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07085</p>
  <p><b>作者</b>：Kaifeng Lyu,  Zhiyuan Li,  Sanjeev Arora</p>
  <p><b>备注</b>：68 pages, many figures</p>
  <p><b>关键词</b>：Batch Normalization, optimization difficulties, Normalization layers, Layer Normalization, Normalization</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Normalization layers (e.g., Batch Normalization, Layer Normalization) were
introduced to help with optimization difficulties in very deep nets, but they
clearly also help generalization, even in not-so-deep nets. Motivated by the
long-held belief that flatter minima lead to better generalization, this paper
gives mathematical analysis and supporting experiments suggesting that
normalization (together with accompanying weight-decay) encourages GD to reduce
the sharpness of loss surface. Here "sharpness" is carefully defined given that
the loss is scale-invariant, a known consequence of normalization.
Specifically, for a fairly broad class of neural nets with normalization, our
theory explains how GD with a finite learning rate enters the so-called Edge of
Stability (EoS) regime, and characterizes the trajectory of GD in this regime
via a continuous sharpness-reduction flow.</p>
  </details>
</details>
<details>
  <summary>59. <b>标题：An Efficient HTN to STRIPS Encoding for Concurrent Plans</b></summary>
  <p><b>编号</b>：[274]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07084</p>
  <p><b>作者</b>：N. Cavrel,  D. Pellier,  H. Fiorino</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Hierarchical Task Network, Task Network, hierarchical planning problems, planning problems, STRIPS planning problems</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The Hierarchical Task Network (HTN) formalism is used to express a wide
variety of planning problems in terms of decompositions of tasks into subtaks.
Many techniques have been proposed to solve such hierarchical planning
problems. A particular technique is to encode hierarchical planning problems as
classical STRIPS planning problems. One advantage of this technique is to
benefit directly from the constant improvements made by STRIPS planners.
However, there are still few effective and expressive encodings. In this paper,
we present a new HTN to STRIPS encoding allowing to generate concurrent plans.
We show experimentally that this encoding outperforms previous approaches on
hierarchical IPC benchmarks.</p>
  </details>
</details>
<details>
  <summary>60. <b>标题：Stability and Generalization of Stochastic Optimization with Nonconvex  and Nonsmooth Problems</b></summary>
  <p><b>编号</b>：[275]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07082</p>
  <p><b>作者</b>：Yunwen Lei</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：found wide applications, minimizing objective functions, Stochastic optimization, machine learning, practical success</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Stochastic optimization has found wide applications in minimizing objective
functions in machine learning, which motivates a lot of theoretical studies to
understand its practical success. Most of existing studies focus on the
convergence of optimization errors, while the generalization analysis of
stochastic optimization is much lagging behind. This is especially the case for
nonconvex and nonsmooth problems often encountered in practice. In this paper,
we initialize a systematic stability and generalization analysis of stochastic
optimization on nonconvex and nonsmooth problems. We introduce novel
algorithmic stability measures and establish their quantitative connection on
the gap between population gradients and empirical gradients, which is then
further extended to study the gap between the Moreau envelope of the empirical
risk and that of the population risk. To our knowledge, these quantitative
connection between stability and generalization in terms of either gradients or
Moreau envelopes have not been studied in the literature. We introduce a class
of sampling-determined algorithms, for which we develop bounds for three
stability measures. Finally, we apply these discussions to derive error bounds
for stochastic gradient descent and its adaptive variant, where we show how to
achieve an implicit regularization by tuning the step sizes and the number of
iterations.</p>
  </details>
</details>
<details>
  <summary>61. <b>标题：Measuring Inconsistency in Declarative Process Specifications</b></summary>
  <p><b>编号</b>：[277]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07080</p>
  <p><b>作者</b>：Carl Corea,  John Grant,  Matthias Thimm</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：linear temporal logic, fixed traces, address the problem, problem of measuring, emphasis on linear</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We address the problem of measuring inconsistency in declarative process
specifications, with an emphasis on linear temporal logic on fixed traces
(LTLff). As we will show, existing inconsistency measures for classical logic
cannot provide a meaningful assessment of inconsistency in LTL in general, as
they cannot adequately handle the temporal operators. We therefore propose a
novel paraconsistent semantics as a framework for inconsistency measurement. We
then present two new inconsistency measures based on these semantics and show
that they satisfy important desirable properties. We show how these measures
can be applied to declarative process models and investigate the computational
complexity of the introduced approach.</p>
  </details>
</details>
<details>
  <summary>62. <b>标题：Analysis of Augmentations for Contrastive ECG Representation Learning</b></summary>
  <p><b>编号</b>：[285]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07656</p>
  <p><b>作者</b>：Sahar Soltanieh,  Ali Etemad,  Javad Hashemi</p>
  <p><b>备注</b>：This paper has been accepted to IJCNN 2022 conference</p>
  <p><b>关键词</b>：paper systematically investigates, paper systematically, systematically investigates, investigates the effectiveness, self-supervised contrastive learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper systematically investigates the effectiveness of various
augmentations for contrastive self-supervised learning of electrocardiogram
(ECG) signals and identifies the best parameters. The baseline of our proposed
self-supervised framework consists of two main parts: the contrastive learning
and the downstream task. In the first stage, we train an encoder using a number
of augmentations to extract generalizable ECG signal representations. We then
freeze the encoder and finetune a few linear layers with different amounts of
labelled data for downstream arrhythmia detection. We then experiment with
various augmentations techniques and explore a range of parameters. Our
experiments are done on PTB-XL, a large and publicly available 12-lead ECG
dataset. The results show that applying augmentations in a specific range of
complexities works better for self-supervised contrastive learning. For
instance, when adding Gaussian noise, a sigma in the range of 0.1 to 0.2
achieves better results, while poor training occurs when the added noise is too
small or too large (outside of the specified range). A similar trend is
observed with other augmentations, demonstrating the importance of selecting
the optimum level of difficulty for the added augmentations, as augmentations
that are too simple will not result in effective training, while augmentations
that are too difficult will also prevent the model from effective learning of
generalized representations. Our work can influence future research on
self-supervised contrastive learning on bio-signals and aid in selecting
optimum parameters for different augmentations.</p>
  </details>
</details>
<details>
  <summary>63. <b>标题：Classification of EEG Motor Imagery Using Deep Learning for  Brain-Computer Interface Systems</b></summary>
  <p><b>编号</b>：[286]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07655</p>
  <p><b>作者</b>：Alessandro Gallo,  Manh Duong Phung</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Convolutional Neural Network, class Convolutional Neural, Neural Network, fed pre-processed electroencephalography, Convolutional Neural</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A trained T1 class Convolutional Neural Network (CNN) model will be used to
examine its ability to successfully identify motor imagery when fed
pre-processed electroencephalography (EEG) data. In theory, and if the model
has been trained accurately, it should be able to identify a class and label it
accordingly. The CNN model will then be restored and used to try and identify
the same class of motor imagery data using much smaller sampled data in an
attempt to simulate live data.</p>
  </details>
</details>
<details>
  <summary>64. <b>标题：A Deep Learning Network for the Classification of Intracardiac  Electrograms in Atrial Tachycardia</b></summary>
  <p><b>编号</b>：[308]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07515</p>
  <p><b>作者</b>：Zerui Chen,  Sonia Xhyn Teo,  Andrie Ochtman,  Shier Nee Saw,  Nicholas Cheng,  Eric Tien Siang Lim,  Murphy Lyu,  Hwee Kuan Lee</p>
  <p><b>备注</b>：34 pages, 10 figures</p>
  <p><b>关键词</b>：acquired intracardiac electrogram, key technology enabling, catheter ablation treatment, local activation time, EGM signals</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A key technology enabling the success of catheter ablation treatment for
atrial tachycardia is activation mapping, which relies on manual local
activation time (LAT) annotation of all acquired intracardiac electrogram (EGM)
signals. This is a time-consuming and error-prone procedure, due to the
difficulty in identifying the signal activation peaks for fractionated signals.
This work presents a Deep Learning approach for the automated classification of
EGM signals into three different types: normal, abnormal, and unclassified,
which forms part of the LAT annotation pipeline, and contributes towards
bypassing the need for manual annotations of the LAT. The Deep Learning
network, the CNN-LSTM model, is a hybrid network architecture which combines
convolutional neural network (CNN) layers with long short-term memory (LSTM)
layers. 1452 EGM signals from a total of 9 patients undergoing
clinically-indicated 3D cardiac mapping were used for the training, validation
and testing of our models. From our findings, the CNN-LSTM model achieved an
accuracy of 81% for the balanced dataset. For comparison, we separately
developed a rule-based Decision Trees model which attained an accuracy of 67%
for the same balanced dataset. Our work elucidates that analysing the EGM
signals using a set of explicitly specified rules as proposed by the Decision
Trees model is not suitable as EGM signals are complex. The CNN-LSTM model, on
the other hand, has the ability to learn the complex, intrinsic features within
the signals and identify useful features to differentiate the EGM signals.</p>
  </details>
</details>
<details>
  <summary>65. <b>标题：Intelligent analysis of EEG signals to assess consumer decisions: A  Study on Neuromarketing</b></summary>
  <p><b>编号</b>：[312]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07484</p>
  <p><b>作者</b>：Nikunj Phutela,  Abhilash P,  Kaushik Sreevathsan,  B N Krupa</p>
  <p><b>备注</b>：7 pages, 6 figures</p>
  <p><b>关键词</b>：influence consumer decisions, emerging field, field that combines, combines neuroscience, neuroscience and marketing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Neuromarketing is an emerging field that combines neuroscience and marketing
to understand the factors that influence consumer decisions better. The study
proposes a method to understand consumers' positive and negative reactions to
advertisements (ads) and products by analysing electroencephalogram (EEG)
signals. These signals are recorded using a low-cost single electrode headset
from volunteers belonging to the ages 18-22. A detailed subject dependent (SD)
and subject independent (SI) analysis was performed employing machine learning
methods like Naive Bayes (NB), Support Vector Machine (SVM), k-nearest
neighbour and Decision Tree and the proposed deep learning (DL) model. SVM and
NB yielded an accuracy (Acc.) of 0.63 for the SD analysis. In SI analysis, SVM
performed better for the advertisement, product and gender-based analysis.
Furthermore, the performance of the DL model was on par with that of SVM,
especially, in product and ads-based analysis.</p>
  </details>
</details>
<details>
  <summary>66. <b>标题：Lattice Convolutional Networks for Learning Ground States of Quantum  Many-Body Systems</b></summary>
  <p><b>编号</b>：[324]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07370</p>
  <p><b>作者</b>：Cong Fu,  Xuan Zhang,  Huixin Zhang,  Hongyi Ling,  Shenglong Xu,  Shuiwang Ji</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：quantum many-body systems, representing ground-state wave, ground-state wave functions, Deep learning methods, Deep learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep learning methods have been shown to be effective in representing
ground-state wave functions of quantum many-body systems. Existing methods use
convolutional neural networks (CNNs) for square lattices due to their
image-like structures. For non-square lattices, existing method uses graph
neural network (GNN) in which structure information is not precisely captured,
thereby requiring additional hand-crafted sublattice encoding. In this work, we
propose lattice convolutions in which a set of proposed operations are used to
convert non-square lattices into grid-like augmented lattices on which regular
convolution can be applied. Based on the proposed lattice convolutions, we
design lattice convolutional networks (LCN) that use self-gating and attention
mechanisms. Experimental results show that our method achieves performance on
par or better than existing methods on spin 1/2 $J_1$-$J_2$ Heisenberg model
over the square, honeycomb, triangular, and kagome lattices while without using
hand-crafted encoding.</p>
  </details>
</details>
<details>
  <summary>67. <b>标题：Exploiting Cross-domain And Cross-Lingual Ultrasound Tongue Imaging  Features For Elderly And Dysarthric Speech Recognition</b></summary>
  <p><b>编号</b>：[327]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07327</p>
  <p><b>作者</b>：Shujie Hu,  Xurong Xie,  Mengzhe Geng,  Mingyu Cui,  Jiajun Deng,  Tianzi Wang,  Xunying Liu,  Helen Meng</p>
  <p><b>备注</b>：arXiv admin note: text overlap with arXiv:2203.10274</p>
  <p><b>关键词</b>：automatic speech recognition, acoustic signal distortion, inherently invariant, signal distortion, successfully incorporated</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Articulatory features are inherently invariant to acoustic signal distortion
and have been successfully incorporated into automatic speech recognition (ASR)
systems designed for normal speech. Their practical application to atypical
task domains such as elderly and disordered speech across languages is often
limited by the difficulty in collecting such specialist data from target
speakers. This paper presents a cross-domain and cross-lingual A2A inversion
approach that utilizes the parallel audio, visual and ultrasound tongue imaging
(UTI) data of the 24-hour TaL corpus in A2A model pre-training before being
cross-domain and cross-lingual adapted to three datasets across two languages:
the English DementiaBank Pitt and Cantonese JCCOCC MoCA elderly speech corpora;
and the English TORGO dysarthric speech data, to produce UTI based articulatory
features. Experiments conducted on three tasks suggested incorporating the
generated articulatory features consistently outperformed the baseline hybrid
TDNN and Conformer based end-to-end systems constructed using acoustic features
only by statistically significant word error rate or character error rate
reductions up to 2.64%, 1.92% and 1.21% absolute (8.17%, 7.89% and 13.28%
relative) after data augmentation and speaker adaptation were applied.</p>
  </details>
</details>
<details>
  <summary>68. <b>标题：Latency Control for Keyword Spotting</b></summary>
  <p><b>编号</b>：[332]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07261</p>
  <p><b>作者</b>：Christin Jose,  Joseph Wang,  Grant P. Strimel,  Mohammad Omar Khursheed,  Yuriy Mishchenko,  Brian Kulis</p>
  <p><b>备注</b>：Proceedings of INTERSPEECH</p>
  <p><b>关键词</b>：Conversational agents commonly, agents commonly utilize, initiate voice interaction, utilize keyword spotting, commonly utilize keyword</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Conversational agents commonly utilize keyword spotting (KWS) to initiate
voice interaction with the user. For user experience and privacy
considerations, existing approaches to KWS largely focus on accuracy, which can
often come at the expense of introduced latency. To address this tradeoff, we
propose a novel approach to control KWS model latency and which generalizes to
any loss function without explicit knowledge of the keyword endpoint. Through a
single, tunable hyperparameter, our approach enables one to balance detection
latency and accuracy for the targeted application. Empirically, we show that
our approach gives superior performance under latency constraints when compared
to existing methods. Namely, we make a substantial 25\% relative false accepts
improvement for a fixed latency target when compared to the baseline
state-of-the-art. We also show that when our approach is used in conjunction
with a max-pooling loss, we are able to improve relative false accepts by 25 %
at a fixed latency when compared to cross entropy loss.</p>
  </details>
</details>
<details>
  <summary>69. <b>标题：Quantum computing overview: discrete vs. continuous variable models</b></summary>
  <p><b>编号</b>：[334]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07246</p>
  <p><b>作者</b>：Sophie Choe</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：discrete variable model, Intermediate-Scale Quantum era, quantum processing units, superconducting quantum processing, discrete variable</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this Near Intermediate-Scale Quantum era, there are two types of near-term
quantum devices available on cloud: superconducting quantum processing units
(QPUs) based on the discrete variable model and linear optics (photonics) QPUs
based on the continuous variable (CV) model. Quantum computation in the
discrete variable model is performed in a finite dimensional quantum state
space and the CV model in an infinite dimensional space. In implementing
quantum algorithms, the CV model offers more quantum gates that are not
available in the discrete variable model. CV-based photonic quantum computers
provide additional flexibility of controlling the length of the output vectors
of quantum circuits, using different methods of measurement and the notion of
cutoff dimension.</p>
  </details>
</details>
<details>
  <summary>70. <b>标题：A Projection-Based K-space Transformer Network for Undersampled Radial  MRI Reconstruction with Limited Training Subjects</b></summary>
  <p><b>编号</b>：[337]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07219</p>
  <p><b>作者</b>：Chang Gao,  Shu-Fu Shih,  J. Paul Finn,  Xiaodong Zhong</p>
  <p><b>备注</b>：Accepted at MICCAI 2022</p>
  <p><b>关键词</b>：compressed sensing enables, enables fast reconstruction, sensing enables fast, Cartesian k-space trajectories, deep learning combined</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The recent development of deep learning combined with compressed sensing
enables fast reconstruction of undersampled MR images and has achieved
state-of-the-art performance for Cartesian k-space trajectories. However,
non-Cartesian trajectories such as the radial trajectory need to be transformed
onto a Cartesian grid in each iteration of the network training, slowing down
the training process and posing inconvenience and delay during training.
Multiple iterations of nonuniform Fourier transform in the networks offset the
deep learning advantage of fast inference. Current approaches typically either
work on image-to-image networks or grid the non-Cartesian trajectories before
the network training to avoid the repeated gridding process. However, the
image-to-image networks cannot ensure the k-space data consistency in the
reconstructed images and the pre-processing of non-Cartesian k-space leads to
gridding errors which cannot be compensated by the network training. Inspired
by the Transformer network to handle long-range dependencies in sequence
transduction tasks, we propose to rearrange the radial spokes to sequential
data based on the chronological order of acquisition and use the Transformer to
predict unacquired radial spokes from acquired ones. We propose novel data
augmentation methods to generate a large amount of training data from a limited
number of subjects. The network can be generated to different anatomical
structures. Experimental results show superior performance of the proposed
framework compared to state-of-the-art deep neural networks.</p>
  </details>
</details>
<details>
  <summary>71. <b>标题：Minorities in networks and algorithms</b></summary>
  <p><b>编号</b>：[343]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2206.07113</p>
  <p><b>作者</b>：Fariba Karimi,  Marcos Oliveira,  Markus Strohmaier</p>
  <p><b>备注</b>：11 pages, 1 figure, book chapter</p>
  <p><b>关键词</b>：theory-informed complex models, understanding societal inequalities, provide an overview, overview of recent, recent advances</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this chapter, we provide an overview of recent advances in data-driven and
theory-informed complex models of social networks and their potential in
understanding societal inequalities and marginalization. We focus on
inequalities arising from networks and network-based algorithms and how they
affect minorities. In particular, we examine how homophily and mixing biases
shape large and small social networks, influence perception of minorities, and
affect collaboration patterns. We also discuss dynamical processes on and of
networks and the formation of norms and health inequalities. Additionally, we
argue that network modeling is paramount for unveiling the effect of ranking
and social recommendation algorithms on the visibility of minorities. Finally,
we highlight the key challenges and future opportunities in this emerging
research topic.</p>
  </details>
</details>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">徐耀彬</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://louishsu.xyz/2022/06/16/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html">http://louishsu.xyz/2022/06/16/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://louishsu.xyz" target="_blank">LOUIS' BLOG</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"></div><div class="post_share"><div class="social-share" data-image="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="next-post pull-full"><a href="/2021/10/22/%E4%B8%AD%E5%9B%BD%E6%B3%95%E5%BE%8B%E6%99%BA%E8%83%BD%E6%8A%80%E6%9C%AF%E8%AF%84%E6%B5%8B(CAIL2021)%EF%BC%9A%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96(Rank2).html"><img class="next-cover" src="http://cail.cipsc.org.cn/img/index_mainpic.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">中国法律智能技术评测(CAIL2021)：信息抽取(Rank2)</div></div></a></div></nav><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="twikoo-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="card-info-avatar is-center"><img class="avatar-img" src="/img/touxiang.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/><div class="author-info__name">徐耀彬</div><div class="author-info__description">做知识的原创者！</div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">11</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">标签</div><div class="length-num">3</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">分类</div><div class="length-num">7</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/isLouisHsu"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/isLouisHsu" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:is.louishsu@foxmail.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>公告</span></div><div class="announcement_content">记录和分享一些学习和开源内容，若有问题可通过邮箱is.louishsu@foxmail.com联系，欢迎交流！！</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">1.</span> <span class="toc-text">统计</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">2.</span> <span class="toc-text">计算机视觉</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">3.</span> <span class="toc-text">自然语言处理</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">4.</span> <span class="toc-text">机器学习</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">5.</span> <span class="toc-text">人工智能</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2022/06/16/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html" title="Arxiv每日速递(2022-06-16)"><img src="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Arxiv每日速递(2022-06-16)"/></a><div class="content"><a class="title" href="/2022/06/16/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html" title="Arxiv每日速递(2022-06-16)">Arxiv每日速递(2022-06-16)</a><time datetime="2022-06-16T00:43:54.705Z" title="发表于 2022-06-16 08:43:54">2022-06-16</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/10/22/%E4%B8%AD%E5%9B%BD%E6%B3%95%E5%BE%8B%E6%99%BA%E8%83%BD%E6%8A%80%E6%9C%AF%E8%AF%84%E6%B5%8B(CAIL2021)%EF%BC%9A%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96(Rank2).html" title="中国法律智能技术评测(CAIL2021)：信息抽取(Rank2)"><img src="http://cail.cipsc.org.cn/img/index_mainpic.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="中国法律智能技术评测(CAIL2021)：信息抽取(Rank2)"/></a><div class="content"><a class="title" href="/2021/10/22/%E4%B8%AD%E5%9B%BD%E6%B3%95%E5%BE%8B%E6%99%BA%E8%83%BD%E6%8A%80%E6%9C%AF%E8%AF%84%E6%B5%8B(CAIL2021)%EF%BC%9A%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96(Rank2).html" title="中国法律智能技术评测(CAIL2021)：信息抽取(Rank2)">中国法律智能技术评测(CAIL2021)：信息抽取(Rank2)</a><time datetime="2021-10-22T14:29:06.000Z" title="发表于 2021-10-22 22:29:06">2021-10-22</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/05/19/%E5%85%A8%E7%90%83%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%8A%80%E6%9C%AF%E5%88%9B%E6%96%B0%E5%A4%A7%E8%B5%9B%E3%80%90%E8%B5%9B%E9%81%93%E4%B8%80%E3%80%91%EF%BC%9A%E5%8C%BB%E5%AD%A6%E5%BD%B1%E5%83%8F%E6%8A%A5%E5%91%8A%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B.html" title="全球人工智能技术创新大赛【赛道一】：医学影像报告异常检测"><img src="https://tianchi-public.oss-cn-hangzhou.aliyuncs.com/public/files/forum/161037709574435991610377095138.jpeg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="全球人工智能技术创新大赛【赛道一】：医学影像报告异常检测"/></a><div class="content"><a class="title" href="/2021/05/19/%E5%85%A8%E7%90%83%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%8A%80%E6%9C%AF%E5%88%9B%E6%96%B0%E5%A4%A7%E8%B5%9B%E3%80%90%E8%B5%9B%E9%81%93%E4%B8%80%E3%80%91%EF%BC%9A%E5%8C%BB%E5%AD%A6%E5%BD%B1%E5%83%8F%E6%8A%A5%E5%91%8A%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B.html" title="全球人工智能技术创新大赛【赛道一】：医学影像报告异常检测">全球人工智能技术创新大赛【赛道一】：医学影像报告异常检测</a><time datetime="2021-05-19T09:57:06.000Z" title="发表于 2021-05-19 17:57:06">2021-05-19</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2020/09/16/%E8%AF%A6%E8%A7%A3%E5%91%BD%E5%90%8D%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB%E6%A8%A1%E5%9E%8B%EF%BC%9ALSTM-CRF.html" title="详解命名实体识别模型：LSTM-CRF"><img src="https://gimg2.baidu.com/image_search/src=http%3A%2F%2Fpic1.zhimg.com%2Fv2-1ed6a10dbb239a148e42df088c5870a6_1440w.jpg%3Fsource%3D172ae18b&amp;refer=http%3A%2F%2Fpic1.zhimg.com&amp;app=2002&amp;size=f9999,10000&amp;q=a80&amp;n=0&amp;g=0n&amp;fmt=jpeg?sec=1638183974&amp;t=4632f13fd487ed1cfcb12d67a6b71e52" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="详解命名实体识别模型：LSTM-CRF"/></a><div class="content"><a class="title" href="/2020/09/16/%E8%AF%A6%E8%A7%A3%E5%91%BD%E5%90%8D%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB%E6%A8%A1%E5%9E%8B%EF%BC%9ALSTM-CRF.html" title="详解命名实体识别模型：LSTM-CRF">详解命名实体识别模型：LSTM-CRF</a><time datetime="2020-09-16T09:26:44.000Z" title="发表于 2020-09-16 17:26:44">2020-09-16</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2020/06/14/%E8%AE%B0%E4%B8%80%E6%AC%A1MySQL%E8%A7%A3%E5%86%B3%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E6%97%B6%E7%9A%84%E5%88%86%E8%A1%A8%E9%97%AE%E9%A2%98.html" title="记一次MySQL解决大数据存储时的分表问题"><img src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="记一次MySQL解决大数据存储时的分表问题"/></a><div class="content"><a class="title" href="/2020/06/14/%E8%AE%B0%E4%B8%80%E6%AC%A1MySQL%E8%A7%A3%E5%86%B3%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E6%97%B6%E7%9A%84%E5%88%86%E8%A1%A8%E9%97%AE%E9%A2%98.html" title="记一次MySQL解决大数据存储时的分表问题">记一次MySQL解决大数据存储时的分表问题</a><time datetime="2020-06-14T15:24:27.000Z" title="发表于 2020-06-14 23:24:27">2020-06-14</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2022 By 徐耀彬</div><div class="footer_custom_text"><p><a style="margin-inline:5px"target="_blank"href="https://hexo.io/"><img src="https://img.shields.io/badge/Frame-Hexo-blue?style=flat&logo=hexo"title="博客框架为Hexo"alt="img"></a><a style="margin-inline:5px"target="_blank"href="https://butterfly.js.org/"><img src="https://img.shields.io/badge/Theme-Butterfly-6513df?style=flat&logo=bitdefender"title="主题采用butterfly"alt="img"></a><a style="margin-inline:5px"target="_blank"href="https://www.jsdelivr.com/"><img src="https://img.shields.io/badge/CDN-jsDelivr-orange?style=flat&logo=jsDelivr"title="本站使用JsDelivr为静态资源提供CDN加速"alt="img"></a><a style="margin-inline:5px"target="_blank"href="https://github.com/"><img src="https://img.shields.io/badge/Source-Github-d021d6?style=flat&logo=GitHub"title="本站项目由Gtihub托管"alt="img"></a><a style="margin-inline:5px"target="_blank"href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img src="https://img.shields.io/badge/Copyright-BY--NC--SA%204.0-d42328?style=flat&logo=Claris"alt="img"title="本站采用知识共享署名-非商业性使用-相同方式共享4.0国际许可协议进行许可"></a></br></p></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="font-plus" type="button" title="放大字体"><i class="fas fa-plus"></i></button><button id="font-minus" type="button" title="缩小字体"><i class="fas fa-minus"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div></div><hr/><div id="local-search-results"></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.css"><script>(() => {
  document.querySelectorAll('#article-container span.katex-display').forEach(item => {
    btf.wrap(item, 'div', '', 'katex-wrap')
  })
})()</script><script>(()=>{
  const $countDom = document.getElementById('twikoo-count')
  const init = () => {
    let initData = {
      el: '#twikoo-wrap',
      envId: 'blog-',
      region: ''
    }

    if (false) {
      const otherData = false
      initData = Object.assign(initData, otherData)
    }
    
    twikoo.init(initData)
  }

  const getCount = () => {
    twikoo.getCommentsCount({
      envId: 'blog-',
      region: '',
      urls: [window.location.pathname],
      includeReply: false
    }).then(function (res) {
      $countDom.innerText = res[0].count
    }).catch(function (err) {
      console.error(err);
    });
  }

  const loadTwikoo = (bool = false) => {
    if (typeof twikoo === 'object') {
      init()
      bool && $countDom && setTimeout(getCount,0)
    } else {
      getScript('https://cdn.jsdelivr.net/npm/twikoo/dist/twikoo.all.min.js').then(()=> {
        init()
        bool && $countDom && setTimeout(getCount,0)
      })
    }
  }

  if ('Twikoo' === 'Twikoo' || !false) {
    if (false) btf.loadComment(document.getElementById('twikoo-wrap'), loadTwikoo)
    else loadTwikoo(true)
  } else {
    window.loadOtherComment = () => {
      loadTwikoo()
    }
  }
})()</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><!-- hexo injector body_end start --> <script data-pjax>if(document.getElementById('recent-posts') && (location.pathname ==='/'|| '/' ==='all')){
    var parent = document.getElementById('recent-posts');
    var child = '<div class="recent-post-item" style="width:100%;height: auto"><div id="catalog_magnet"><div class="magnet_item"><a class="magnet_link" href="http://louishsu.xyz/categories/机器学习/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🐱 机器学习 (1)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://louishsu.xyz/categories/自然语言处理/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">📚 自然语言处理 (1)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://louishsu.xyz/categories/竞赛相关/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🎮 竞赛相关 (2)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://louishsu.xyz/categories/阅读笔记/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🎮 阅读笔记 (1)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><a class="magnet_link_more"  href="http://louishsu.xyz/categories" style="flex:1;text-align: center;margin-bottom: 10px;">查看更多...</a></div></div>';
    console.log('已挂载magnet')
    parent.insertAdjacentHTML("afterbegin",child)}
     </script><style>#catalog_magnet{flex-wrap: wrap;display: flex;width:100%;justify-content:space-between;padding: 10px 10px 0 10px;align-content: flex-start;}.magnet_item{flex-basis: calc(50% - 5px);background: #f2f2f2;margin-bottom: 10px;border-radius: 8px;transition: all 0.2s ease-in-out;}.magnet_item:hover{background: #b30070}.magnet_link_more{color:#555}.magnet_link{color:black}.magnet_link:hover{color:white}@media screen and (max-width: 600px) {.magnet_item {flex-basis: 100%;}}.magnet_link_context{display:flex;padding: 10px;font-size:16px;transition: all 0.2s ease-in-out;}.magnet_link_context:hover{padding: 10px 20px;}</style>
    <style></style>
  <script data-pjax src="https://cdn.jsdelivr.net/gh/Zfour/hexo-github-calendar@1.21/hexo_githubcalendar.js"></script>
  <script data-pjax>
        function GithubCalendarConfig(){
            var git_githubapiurl ="https://python-github-calendar-api.vercel.app/api?isLouisHsu";
            var git_color =['#ebedf0', '#fdcdec', '#fc9bd9', '#fa6ac5', '#f838b2', '#f5089f', '#c4067e', '#92055e', '#540336', '#48022f', '#30021f'];
            var git_user ="isLouisHsu";
            var parent_div_git = document.getElementById('recent-posts');
            var git_div_html = '<div class="recent-post-item" style="width:100%;height:auto;padding:10px;"><div id="github_loading" style="width:10%;height:100%;margin:0 auto;display: block"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"  viewBox="0 0 50 50" style="enable-background:new 0 0 50 50" xml:space="preserve"><path fill="#d0d0d0" d="M25.251,6.461c-10.318,0-18.683,8.365-18.683,18.683h4.068c0-8.071,6.543-14.615,14.615-14.615V6.461z" transform="rotate(275.098 25 25)"><animateTransform attributeType="xml" attributeName="transform" type="rotate" from="0 25 25" to="360 25 25" dur="0.6s" repeatCount="indefinite"></animateTransform></path></svg></div><div id="github_container"></div></div>';
            if(parent_div_git && location.pathname =='/'){
                console.log('已挂载github calendar')
                // parent_div_git.innerHTML=git_div_html+parent_div_git.innerHTML // 无报错，但不影响使用(支持pjax跳转)
                parent_div_git.insertAdjacentHTML("afterbegin",git_div_html) // 有报错，但不影响使用(支持pjax跳转)
            };
            GithubCalendar(git_githubapiurl,git_color,git_user)
        }
        if(document.getElementById('recent-posts')){
            GithubCalendarConfig()
        }
    </script>
    <style>#github_container{min-height:280px}@media screen and (max-width:650px) {#github_container{background-image:;min-height:0px}}</style>
    <style></style><script data-pjax>function electric_clock_injector_config(){
                var parent_div_git = document.getElementsByClassName('sticky_layout')[0];
                var item_html = '<div class="card-widget card-clock"><div class="card-glass"><div class="card-background"><div class="card-content"><div id="hexo_electric_clock"><img id="card-clock-loading" src="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-clock/clock/images/weather/loading.gif" style="height: 120px; width: 100%;" data-ll-status="loading" class="entered loading"></div></div></div></div></div>';
                console.log('已挂载electric_clock')
                // parent_div_git.innerHTML=item_html+parent_div_git.innerHTML // 无报错，但不影响使用(支持pjax跳转)
                parent_div_git.insertAdjacentHTML("afterbegin",item_html) // 有报错，但不影响使用(支持pjax跳转)
            }if( document.getElementsByClassName('sticky_layout')[0] && (location.pathname ==='all'|| 'all' ==='all')){

            electric_clock_injector_config()
        } </script><script src="https://pv.sohu.com/cityjson?ie=utf-8"></script><script data-pjax  src="https://cdn.jsdelivr.net/gh/Zfour/hexo-electric-clock@1.0.6/clock.js"></script><!-- hexo injector body_end end --><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"model":{"jsonPath":"/live2dw/assets/hijiki.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":false},"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body></html>