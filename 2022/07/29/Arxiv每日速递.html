<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Arxiv每日速递(2022-07-29) | LOUIS' BLOG</title><meta name="author" content="徐耀彬"><meta name="copyright" content="徐耀彬"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="本篇博文主要展示每日从Arxiv论文网站获取的最新论文列表，以计算机视觉、自然语言处理、机器学习、人工智能等大方向进行划分。 统计 今日共更新218篇论文，其中：  51篇计算机视觉（cs.CV） 16篇自然语言处理（cs.CL） 62篇机器学习（cs.LG） 31篇人工智能（cs.AI）  计算机视觉    1. 标题：Initialization and Alignment for Adver">
<meta property="og:type" content="article">
<meta property="og:title" content="Arxiv每日速递(2022-07-29)">
<meta property="og:url" content="http://louishsu.xyz/2022/07/29/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html">
<meta property="og:site_name" content="LOUIS&#39; BLOG">
<meta property="og:description" content="本篇博文主要展示每日从Arxiv论文网站获取的最新论文列表，以计算机视觉、自然语言处理、机器学习、人工智能等大方向进行划分。 统计 今日共更新218篇论文，其中：  51篇计算机视觉（cs.CV） 16篇自然语言处理（cs.CL） 62篇机器学习（cs.LG） 31篇人工智能（cs.AI）  计算机视觉    1. 标题：Initialization and Alignment for Adver">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png">
<meta property="article:published_time" content="2022-07-29T00:45:02.445Z">
<meta property="article:modified_time" content="2022-07-29T00:46:45.977Z">
<meta property="article:author" content="徐耀彬">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://louishsu.xyz/2022/07/29/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2022-07-29 08:46:45'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const fontSizeVal = saveToLocal.get('global-font-size')
    if (fontSizeVal !== undefined) {
      document.documentElement.style.setProperty('--global-font-size', fontSizeVal + 'px')
    }
    })(window)</script><link rel="stylesheet" href="/css/background.css"><script src="https://cdn.jsdelivr.net/npm/echarts@4.7.0/dist/echarts.min.js"></script><!-- hexo injector head_end start --><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Zfour/hexo-electric-clock@1.0.6/clock.css"><!-- hexo injector head_end end --><meta name="generator" content="Hexo 5.4.2"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="author-avatar"><img class="avatar-img" src="/img/touxiang.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">11</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">标签</div><div class="length-num">3</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">分类</div><div class="length-num">7</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/message/"><i class="fa-fw far fa-comment-dots"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa-fw fa fa-book"></i><span> 找文章</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></li><li><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></li><li><a class="site-page" href="/charts/"><i class="fa-fw fa fa-archive"></i><span> 统计</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-tools"></i><span> 工具</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/md_editor/"><i class="fa-fw fas fa-pen"></i><span> 在线markdown</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/isLouisHsu/blog/tree/master/source/_posts"><i class="fa-fw fa fa-star"></i><span> 在线push</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">LOUIS' BLOG</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/message/"><i class="fa-fw far fa-comment-dots"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa-fw fa fa-book"></i><span> 找文章</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></li><li><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></li><li><a class="site-page" href="/charts/"><i class="fa-fw fa fa-archive"></i><span> 统计</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-tools"></i><span> 工具</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/md_editor/"><i class="fa-fw fas fa-pen"></i><span> 在线markdown</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/isLouisHsu/blog/tree/master/source/_posts"><i class="fa-fw fa fa-star"></i><span> 在线push</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Arxiv每日速递(2022-07-29)<a class="post-edit-link" href="https://github.com/isLouisHsu/blog/tree/master/source_posts/Arxiv每日速递.md" title="编辑" target="_blank"><i class="fas fa-pencil-square"></i></a></h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-07-29T00:45:02.445Z" title="发表于 2022-07-29 08:45:02">2022-07-29</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2022-07-29T00:46:45.977Z" title="更新于 2022-07-29 08:46:45">2022-07-29</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">阅读笔记</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">40.7k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>243分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span><span class="post-meta-separator">|</span><span class="post-meta-commentcount"><i class="far fa-comments fa-fw post-meta-icon"></i><span class="post-meta-label">评论数:</span><a href="/2022/07/29/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html#post-comment"><span id="twikoo-count"></span></a></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><p>本篇博文主要展示每日从Arxiv论文网站获取的最新论文列表，以计算机视觉、自然语言处理、机器学习、人工智能等大方向进行划分。</p>
<h1>统计</h1>
<p>今日共更新218篇论文，其中：</p>
<ul>
<li>51篇计算机视觉（<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>）</li>
<li>16篇自然语言处理（<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>）</li>
<li>62篇机器学习（cs.LG）</li>
<li>31篇人工智能（<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>）</li>
</ul>
<h1>计算机视觉</h1>
<details>
  <summary>1. <b>标题：Initialization and Alignment for Adversarial Texture Optimization</b></summary>
  <p><b>编号</b>：[1]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.14289</p>
  <p><b>作者</b>：Xiaoming Zhao,  Zhizhen Zhao,  Alexander G. Schwing</p>
  <p><b>备注</b>：ECCV 2022; Project Page: this https URL</p>
  <p><b>关键词</b>：computer vision, received a lot, lot of attention, attention in computer, adversarial texture optimization</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>While recovery of geometry from image and video data has received a lot of
attention in computer vision, methods to capture the texture for a given
geometry are less mature. Specifically, classical methods for texture
generation often assume clean geometry and reasonably well-aligned image data.
While very recent methods, e.g., adversarial texture optimization, better
handle lower-quality data obtained from hand-held devices, we find them to
still struggle frequently. To improve robustness, particularly of recent
adversarial texture optimization, we develop an explicit initialization and an
alignment procedure. It deals with complex geometry due to a robust mapping of
the geometry to the texture map and a hard-assignment-based initialization. It
deals with misalignment of geometry and images by integrating fast
image-alignment into the texture refinement optimization. We demonstrate
efficacy of our texture generation on a dataset of 11 scenes with a total of
2807 frames, observing 7.8% and 11.1% relative improvements regarding
perceptual and sharpness measurements.</p>
  </details>
</details>
<details>
  <summary>2. <b>标题：Rewriting Geometric Rules of a GAN</b></summary>
  <p><b>编号</b>：[2]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.14288</p>
  <p><b>作者</b>：Sheng-Yu Wang,  David Bau,  Jun-Yan Zhu</p>
  <p><b>备注</b>：SIGGRAPH 2022 website: this https URL code: this https URL</p>
  <p><b>关键词</b>：make visual content, realistic content based, visual content creation, models make visual, realistic content</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep generative models make visual content creation more accessible to novice
users by automating the synthesis of diverse, realistic content based on a
collected dataset. However, the current machine learning approaches miss a key
element of the creative process -- the ability to synthesize things that go far
beyond the data distribution and everyday experience. To begin to address this
issue, we enable a user to "warp" a given model by editing just a handful of
original model outputs with desired geometric changes. Our method applies a
low-rank update to a single model layer to reconstruct edited examples.
Furthermore, to combat overfitting, we propose a latent space augmentation
method based on style-mixing. Our method allows a user to create a model that
synthesizes endless objects with defined geometric changes, enabling the
creation of a new generative model without the burden of curating a large-scale
dataset. We also demonstrate that edited models can be composed to achieve
aggregated effects, and we present an interactive interface to enable users to
create new models through composition. Empirical measurements on multiple test
cases suggest the advantage of our method against recent GAN fine-tuning
methods. Finally, we showcase several applications using the edited models,
including latent space interpolation and image editing.</p>
  </details>
</details>
<details>
  <summary>3. <b>标题：Depth Field Networks for Generalizable Multi-view Scene Representation</b></summary>
  <p><b>编号</b>：[3]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.14287</p>
  <p><b>作者</b>：Vitor Guizilini,  Igor Vasiljevic,  Jiading Fang,  Rares Ambrus,  Greg Shakhnarovich,  Matthew Walter,  Adrien Gaidon</p>
  <p><b>备注</b>：Accepted to ECCV 2022. Project page: this https URL</p>
  <p><b>关键词</b>：computer vision leverages, vision leverages learning, mapping image data, boost geometric reasoning, computer vision</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Modern 3D computer vision leverages learning to boost geometric reasoning,
mapping image data to classical structures such as cost volumes or epipolar
constraints to improve matching. These architectures are specialized according
to the particular problem, and thus require significant task-specific tuning,
often leading to poor domain generalization performance. Recently, generalist
Transformer architectures have achieved impressive results in tasks such as
optical flow and depth estimation by encoding geometric priors as inputs rather
than as enforced constraints. In this paper, we extend this idea and propose to
learn an implicit, multi-view consistent scene representation, introducing a
series of 3D data augmentation techniques as a geometric inductive prior to
increase view diversity. We also show that introducing view synthesis as an
auxiliary task further improves depth estimation. Our Depth Field Networks
(DeFiNe) achieve state-of-the-art results in stereo and video depth estimation
without explicit geometric constraints, and improve on zero-shot domain
generalization by a wide margin.</p>
  </details>
</details>
<details>
  <summary>4. <b>标题：HorNet: Efficient High-Order Spatial Interactions with Recursive Gated  Convolutions</b></summary>
  <p><b>编号</b>：[4]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.14284</p>
  <p><b>作者</b>：Yongming Rao,  Wenliang Zhao,  Yansong Tang,  Jie Zhou,  Ser-Nam Lim,  Jiwen Lu</p>
  <p><b>备注</b>：project page: this https URL</p>
  <p><b>关键词</b>：exhibits great success, Transformers exhibits great, textit, vision Transformers exhibits, high-order spatial interactions</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent progress in vision Transformers exhibits great success in various
tasks driven by the new spatial modeling mechanism based on dot-product
self-attention. In this paper, we show that the key ingredients behind the
vision Transformers, namely input-adaptive, long-range and high-order spatial
interactions, can also be efficiently implemented with a convolution-based
framework. We present the Recursive Gated Convolution
($\textit{g}^\textit{n}$Conv) that performs high-order spatial interactions
with gated convolutions and recursive designs. The new operation is highly
flexible and customizable, which is compatible with various variants of
convolution and extends the two-order interactions in self-attention to
arbitrary orders without introducing significant extra computation.
$\textit{g}^\textit{n}$Conv can serve as a plug-and-play module to improve
various vision Transformers and convolution-based models. Based on the
operation, we construct a new family of generic vision backbones named HorNet.
Extensive experiments on ImageNet classification, COCO object detection and
ADE20K semantic segmentation show HorNet outperform Swin Transformers and
ConvNeXt by a significant margin with similar overall architecture and training
configurations. HorNet also shows favorable scalability to more training data
and a larger model size. Apart from the effectiveness in visual encoders, we
also show $\textit{g}^\textit{n}$Conv can be applied to task-specific decoders
and consistently improve dense prediction performance with less computation.
Our results demonstrate that $\textit{g}^\textit{n}$Conv can be a new basic
module for visual modeling that effectively combines the merits of both vision
Transformers and CNNs. Code is available at
this https URL</p>
  </details>
</details>
<details>
  <summary>5. <b>标题：The One Where They Reconstructed 3D Humans and Environments in TV Shows</b></summary>
  <p><b>编号</b>：[5]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.14279</p>
  <p><b>作者</b>：Georgios Pavlakos,  Ethan Weber,  Matthew Tancik,  Angjoo Kanazawa</p>
  <p><b>备注</b>：ECCV 2022. Project page: this http URL</p>
  <p><b>关键词</b>：depict a wide, wide variety, studied extensively, source of data, shows depict</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>TV shows depict a wide variety of human behaviors and have been studied
extensively for their potential to be a rich source of data for many
applications. However, the majority of the existing work focuses on 2D
recognition tasks. In this paper, we make the observation that there is a
certain persistence in TV shows, i.e., repetition of the environments and the
humans, which makes possible the 3D reconstruction of this content. Building on
this insight, we propose an automatic approach that operates on an entire
season of a TV show and aggregates information in 3D; we build a 3D model of
the environment, compute camera information, static 3D scene structure and body
scale information. Then, we demonstrate how this information acts as rich 3D
context that can guide and improve the recovery of 3D human pose and position
in these environments. Moreover, we show that reasoning about humans and their
environment in 3D enables a broad range of downstream applications:
re-identification, gaze estimation, cinematography and image editing. We apply
our approach on environments from seven iconic TV shows and perform an
extensive evaluation of the proposed system.</p>
  </details>
</details>
<details>
  <summary>6. <b>标题：CuDi: Curve Distillation for Efficient and Controllable Exposure  Adjustment</b></summary>
  <p><b>编号</b>：[6]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.14273</p>
  <p><b>作者</b>：Chongyi Li,  Chunle Guo,  Ruicheng Feng,  Shangchen Zhou,  Chen Change Loy</p>
  <p><b>备注</b>：this https URL</p>
  <p><b>关键词</b>：controllable exposure adjustment, present Curve Distillation, controllable exposure, exposure adjustment, Curve Distillation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present Curve Distillation, CuDi, for efficient and controllable exposure
adjustment without the requirement of paired or unpaired data during training.
Our method inherits the zero-reference learning and curve-based framework from
an effective low-light image enhancement method, Zero-DCE, with further speed
up in its inference speed, reduction in its model size, and extension to
controllable exposure adjustment. The improved inference speed and lightweight
model are achieved through novel curve distillation that approximates the
time-consuming iterative operation in the conventional curve-based framework by
high-order curve's tangent line. The controllable exposure adjustment is made
possible with a new self-supervised spatial exposure control loss that
constrains the exposure levels of different spatial regions of the output to be
close to the brightness distribution of an exposure map serving as an input
condition. Different from most existing methods that can only correct either
underexposed or overexposed photos, our approach corrects both underexposed and
overexposed photos with a single model. Notably, our approach can additionally
adjust the exposure levels of a photo globally or locally with the guidance of
an input condition exposure map, which can be pre-defined or manually set in
the inference stage. Through extensive experiments, we show that our method is
appealing for its fast, robust, and flexible performance, outperforming
state-of-the-art methods in real scenes. Project page:
this https URL.</p>
  </details>
</details>
<details>
  <summary>7. <b>标题：MonteBoxFinder: Detecting and Filtering Primitives to Fit a Noisy Point  Cloud</b></summary>
  <p><b>编号</b>：[8]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.14268</p>
  <p><b>作者</b>：Michaël Ramamonjisoa,  Sinisa Stekovic,  Vincent Lepetit</p>
  <p><b>备注</b>：Accepted at ECCV 2022. Project page: this https URL, Code: this https URL</p>
  <p><b>关键词</b>：input point cloud, noisy input point, present MonteBoxFinder, point cloud, input point</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present MonteBoxFinder, a method that, given a noisy input point cloud,
fits cuboids to the input scene. Our primary contribution is a discrete
optimization algorithm that, from a dense set of initially detected cuboids, is
able to efficiently filter good boxes from the noisy ones. Inspired by recent
applications of MCTS to scene understanding problems, we develop a stochastic
algorithm that is, by design, more efficient for our task. Indeed, the quality
of a fit for a cuboid arrangement is invariant to the order in which the
cuboids are added into the scene. We develop several search baselines for our
problem and demonstrate, on the ScanNet dataset, that our approach is more
efficient and precise. Finally, we strongly believe that our core algorithm is
very general and that it could be extended to many other problems in 3D scene
understanding.</p>
  </details>
</details>
<details>
  <summary>8. <b>标题：Combining human parsing with analytical feature extraction and ranking  schemes for high-generalization person reidentification</b></summary>
  <p><b>编号</b>：[15]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.14243</p>
  <p><b>作者</b>：Nikita Gabdullin</p>
  <p><b>备注</b>：20 pages, 7 figures, 6 tables, 15 equations</p>
  <p><b>关键词</b>：receiving increasing attention, recent years due, Person reidentification, science and society, receiving increasing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Person reidentification (re-ID) has been receiving increasing attention in
recent years due to its importance for both science and society. Machine
learning and particularly Deep Learning (DL) has become the main re-id tool
that allowed researches to achieve unprecedented accuracy levels on benchmark
datasets. However, there is a known problem of poor generalization of DL
models. That is, models trained to achieve high accuracy on one dataset perform
poorly on other ones and require re-training. To address this issue, we present
a model without trainable parameters which shows great potential for high
generalization. It combines a fully analytical feature extraction and
similarity ranking scheme with DL-based human parsing used to obtain the
initial subregion classification. We show that such combination to a high
extent eliminates the drawbacks of existing analytical methods. We use
interpretable color and texture features which have human-readable similarity
measures associated with them. To verify the proposed method we conduct
experiments on Market1501 and CUHK03 datasets achieving competitive rank-1
accuracy comparable with that of DL-models. Most importantly we show that our
method achieves 63.9% and 93.5% rank-1 cross-domain accuracy when applied to
transfer learning tasks. It is significantly higher than previously reported
30-50% transfer accuracy. We discuss the potential ways of adding new features
to further improve the model. We also show the advantage of interpretable
features for constructing human-generated queries from verbal description to
conduct search without a query image.</p>
  </details>
</details>
<details>
  <summary>9. <b>标题：Visual Recognition by Request</b></summary>
  <p><b>编号</b>：[17]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.14227</p>
  <p><b>作者</b>：Chufeng Tang,  Lingxi Xie,  Xiaopeng Zhang,  Xiaolin Hu,  Qi Tian</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：algorithm recognizes targets, visual recognition, annotation, recognition, query-based visual recognition</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we present a novel protocol of annotation and evaluation for
visual recognition. Different from traditional settings, the protocol does not
require the labeler/algorithm to annotate/recognize all targets (objects,
parts, etc.) at once, but instead raises a number of recognition instructions
and the algorithm recognizes targets by request. This mechanism brings two
beneficial properties to reduce the burden of annotation, namely, (i) variable
granularity: different scenarios can have different levels of annotation, in
particular, object parts can be labeled only in large and clear instances, (ii)
being open-domain: new concepts can be added to the database in minimal costs.
To deal with the proposed setting, we maintain a knowledge base and design a
query-based visual recognition framework that constructs queries on-the-fly
based on the requests. We evaluate the recognition system on two
mixed-annotated datasets, CPP and ADE20K, and demonstrate its promising ability
of learning from partially labeled data as well as adapting to new concepts
with only text labels.</p>
  </details>
</details>
<details>
  <summary>10. <b>标题：Electricity Price Forecasting Model based on Gated Recurrent Units</b></summary>
  <p><b>编号</b>：[18]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.14225</p>
  <p><b>作者</b>：Nafise Rezaei,  Roozbeh Rajabi,  Abouzar Estebsari</p>
  <p><b>备注</b>：5 pages, EEEIC 2022 conference</p>
  <p><b>关键词</b>：demand response programs, electricity price, smart grids, power systems, participation of consumers</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The participation of consumers and producers in demand response programs has
increased in smart grids, which reduces investment and operation costs of power
systems. Also, with the advent of renewable energy sources, the electricity
market is becoming more complex and unpredictable. To effectively implement
demand response programs, forecasting the future price of electricity is very
crucial for producers in the electricity market. Electricity prices are very
volatile and change under the influence of various factors such as temperature,
wind speed, rainfall, intensity of commercial and daily activities, etc.
Therefore, considering the influencing factors as dependent variables can
increase the accuracy of the forecast. In this paper, a model for electricity
price forecasting is presented based on Gated Recurrent Units. The electrical
load consumption is considered as an input variable in this model. Noise in
electricity price seriously reduces the efficiency and effectiveness of
analysis. Therefore, an adaptive noise reducer is integrated into the model for
noise reduction. The SAEs are then used to extract features from the de-noised
electricity price. Finally, the de-noised features are fed into the GRU to
train predictor. Results on real dataset shows that the proposed methodology
can perform effectively in prediction of electricity price.</p>
  </details>
</details>
<details>
  <summary>11. <b>标题：Humans disagree with the IoU for measuring object detector localization  error</b></summary>
  <p><b>编号</b>：[20]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.14221</p>
  <p><b>作者</b>：Ombretta Strafforello,  Vanathi Rajasekart,  Osman S. Kayhan,  Oana Inel,  Jan van Gemert</p>
  <p><b>备注</b>：Published at ICIP 2022. Ombretta Strafforello, Vanathi Rajasekart, Osman S. Kayhan and Oana Inel contributed equally to this work</p>
  <p><b>关键词</b>：Intersection over Union, automatic object detectors, Union, automatic object, object detectors</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The localization quality of automatic object detectors is typically evaluated
by the Intersection over Union (IoU) score. In this work, we show that humans
have a different view on localization quality. To evaluate this, we conduct a
survey with more than 70 participants. Results show that for localization
errors with the exact same IoU score, humans might not consider that these
errors are equal, and express a preference. Our work is the first to evaluate
IoU with humans and makes it clear that relying on IoU scores alone to evaluate
localization errors might not be sufficient.</p>
  </details>
</details>
<details>
  <summary>12. <b>标题：Progressive Voronoi Diagram Subdivision: Towards A Holistic Geometric  Framework for Exemplar-free Class-Incremental Learning</b></summary>
  <p><b>编号</b>：[26]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.14202</p>
  <p><b>作者</b>：Chunwei Ma,  Zhanghexuan Ji,  Ziyun Huang,  Yan Shen,  Mingchen Gao,  Jinhui Xu</p>
  <p><b>备注</b>：Preprint. Under review. Up to 37.09% improvement for Class-Incremental Continual Learning. Code freely available!</p>
  <p><b>关键词</b>：Exemplar-free Class-incremental Learning, Deep Neural Networks, Class-incremental Learning, Neural Networks, causing catastrophic forgetting</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Exemplar-free Class-incremental Learning (CIL) is a challenging problem
because rehearsing data from previous phases is strictly prohibited, causing
catastrophic forgetting of Deep Neural Networks (DNNs). In this paper, we
present iVoro, a holistic framework for CIL, derived from computational
geometry. We found Voronoi Diagram (VD), a classical model for space
subdivision, is especially powerful for solving the CIL problem, because VD
itself can be constructed favorably in an incremental manner -- the newly added
sites (classes) will only affect the proximate classes, making the
non-contiguous classes hardly forgettable. Further, in order to find a better
set of centers for VD construction, we colligate DNN with VD using Power
Diagram and show that the VD structure can be optimized by integrating local
DNN models using a divide-and-conquer algorithm. Moreover, our VD construction
is not restricted to the deep feature space, but is also applicable to multiple
intermediate feature spaces, promoting VD to be multi-centered VD (CIVD) that
efficiently captures multi-grained features from DNN. Importantly, iVoro is
also capable of handling uncertainty-aware test-time Voronoi cell assignment
and has exhibited high correlations between geometric uncertainty and
predictive accuracy (up to ~0.9). Putting everything together, iVoro achieves
up to 25.26%, 37.09%, and 33.21% improvements on CIFAR-100, TinyImageNet, and
ImageNet-Subset, respectively, compared to the state-of-the-art non-exemplar
CIL approaches. In conclusion, iVoro enables highly accurate,
privacy-preserving, and geometrically interpretable CIL that is particularly
useful when cross-phase data sharing is forbidden, e.g. in medical
applications. Our code is available at this https URL.</p>
  </details>
</details>
<details>
  <summary>13. <b>标题：Mining Cross-Person Cues for Body-Part Interactiveness Learning in HOI  Detection</b></summary>
  <p><b>编号</b>：[28]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.14192</p>
  <p><b>作者</b>：Xiaoqian Wu,  Yong-Lu Li,  Xinpeng Liu,  Junyi Zhang,  Yuzhe Wu,  Cewu Lu</p>
  <p><b>备注</b>：To appear in ECCV 2022</p>
  <p><b>关键词</b>：Human-Object Interaction, activity understanding, plays a crucial, crucial role, role in activity</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Human-Object Interaction (HOI) detection plays a crucial role in activity
understanding. Though significant progress has been made, interactiveness
learning remains a challenging problem in HOI detection: existing methods
usually generate redundant negative H-O pair proposals and fail to effectively
extract interactive pairs. Though interactiveness has been studied in both
whole body- and part- level and facilitates the H-O pairing, previous works
only focus on the target person once (i.e., in a local perspective) and
overlook the information of the other persons. In this paper, we argue that
comparing body-parts of multi-person simultaneously can afford us more useful
and supplementary interactiveness cues. That said, to learn body-part
interactiveness from a global perspective: when classifying a target person's
body-part interactiveness, visual cues are explored not only from
herself/himself but also from other persons in the image. We construct
body-part saliency maps based on self-attention to mine cross-person
informative cues and learn the holistic relationships between all the
body-parts. We evaluate the proposed method on widely-used benchmarks HICO-DET
and V-COCO. With our new perspective, the holistic global-local body-part
interactiveness learning achieves significant improvements over
state-of-the-art. Our code is available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>14. <b>标题：Learning with Limited Annotations: A Survey on Deep Semi-Supervised  Learning for Medical Image Segmentation</b></summary>
  <p><b>编号</b>：[29]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.14191</p>
  <p><b>作者</b>：Rushi Jiao,  Yichi Zhang,  Le Ding,  Rong Cai,  Jicong Zhang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Medical image segmentation, image-guided clinical approaches, Medical image, image segmentation, fundamental and critical</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Medical image segmentation is a fundamental and critical step in many
image-guided clinical approaches. Recent success of deep learning-based
segmentation methods usually relies on a large amount of labeled data, which is
particularly difficult and costly to obtain especially in the medical imaging
domain where only experts can provide reliable and accurate annotations.
Semi-supervised learning has emerged as an appealing strategy and been widely
applied to medical image segmentation tasks to train deep models with limited
annotations. In this paper, we present a comprehensive review of recently
proposed semi-supervised learning methods for medical image segmentation and
summarized both the technical novelties and empirical results. Furthermore, we
analyze and discuss the limitations and several unsolved problems of existing
approaches. We hope this review could inspire the research community to explore
solutions for this challenge and further promote the developments in medical
image segmentation field.</p>
  </details>
</details>
<details>
  <summary>15. <b>标题：Semantic-Aligned Matching for Enhanced DETR Convergence and Multi-Scale  Feature Fusion</b></summary>
  <p><b>编号</b>：[30]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.14172</p>
  <p><b>作者</b>：Gongjie Zhang,  Zhipeng Luo,  Yingchen Yu,  Jiaxing Huang,  Kaiwen Cui,  Shijian Lu,  Eric P. Xing</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：DETR, established a fully, DETR convergence, SAM-DETR, object</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The recently proposed DEtection TRansformer (DETR) has established a fully
end-to-end paradigm for object detection. However, DETR suffers from slow
training convergence, which hinders its applicability to various detection
tasks. We observe that DETR's slow convergence is largely attributed to the
difficulty in matching object queries to relevant regions due to the unaligned
semantics between object queries and encoded image features. With this
observation, we design Semantic-Aligned-Matching DETR++ (SAM-DETR++) to
accelerate DETR's convergence and improve detection performance. The core of
SAM-DETR++ is a plug-and-play module that projects object queries and encoded
image features into the same feature embedding space, where each object query
can be easily matched to relevant regions with similar semantics. Besides,
SAM-DETR++ searches for multiple representative keypoints and exploits their
features for semantic-aligned matching with enhanced representation capacity.
Furthermore, SAM-DETR++ can effectively fuse multi-scale features in a
coarse-to-fine manner on the basis of the designed semantic-aligned matching.
Extensive experiments show that the proposed SAM-DETR++ achieves superior
convergence speed and competitive detection accuracy. Additionally, as a
plug-and-play method, SAM-DETR++ can complement existing DETR convergence
solutions with even better performance, achieving 44.8% AP with merely 12
training epochs and 49.1% AP with 50 training epochs on COCO val2017 with
ResNet-50. Codes are available at this https URL .</p>
  </details>
</details>
<details>
  <summary>16. <b>标题：Content-oriented learned image compression</b></summary>
  <p><b>编号</b>：[31]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.14168</p>
  <p><b>作者</b>：Meng Li,  Shangyin Gao,  Yihui Feng,  Yibo Shi,  Jing Wang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：deep neural networks, made significant progress, optimized image compression, image compression, recent years</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In recent years, with the development of deep neural networks, end-to-end
optimized image compression has made significant progress and exceeded the
classic methods in terms of rate-distortion performance. However, most
learning-based image compression methods are unlabeled and do not consider
image semantics or content when optimizing the model. In fact, human eyes have
different sensitivities to different content, so the image content also needs
to be considered. In this paper, we propose a content-oriented image
compression method, which handles different kinds of image contents with
different strategies. Extensive experiments show that the proposed method
achieves competitive subjective results compared with state-of-the-art
end-to-end learned image compression methods or classic methods.</p>
  </details>
</details>
<details>
  <summary>17. <b>标题：RHA-Net: An Encoder-Decoder Network with Residual Blocks and Hybrid  Attention Mechanisms for Pavement Crack Segmentation</b></summary>
  <p><b>编号</b>：[32]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.14166</p>
  <p><b>作者</b>：Guijie Zhu,  Zhun Fan,  Jiacheng Liu,  Duan Yuan,  Peili Ma,  Meihua Wang,  Weihua Sheng,  Kelvin C. P. Wang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：pavement condition evaluation, surface data play, pavement crack segmentation, condition evaluation, pavement crack</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The acquisition and evaluation of pavement surface data play an essential
role in pavement condition evaluation. In this paper, an efficient and
effective end-to-end network for automatic pavement crack segmentation, called
RHA-Net, is proposed to improve the pavement crack segmentation accuracy. The
RHA-Net is built by integrating residual blocks (ResBlocks) and hybrid
attention blocks into the encoder-decoder architecture. The ResBlocks are used
to improve the ability of RHA-Net to extract high-level abstract features. The
hybrid attention blocks are designed to fuse both low-level features and
high-level features to help the model focus on correct channels and areas of
cracks, thereby improving the feature presentation ability of RHA-Net. An image
data set containing 789 pavement crack images collected by a self-designed
mobile robot is constructed and used for training and evaluating the proposed
model. Compared with other state-of-the-art networks, the proposed model
achieves better performance and the functionalities of adding residual blocks
and hybrid attention mechanisms are validated in a comprehensive ablation
study. Additionally, a light-weighted version of the model generated by
introducing depthwise separable convolution achieves better a performance and a
much faster processing speed with 1/30 of the number of U-Net parameters. The
developed system can segment pavement crack in real-time on an embedded device
Jetson TX2 (25 FPS). The video taken in real-time experiments is released at
this https URL.</p>
  </details>
</details>
<details>
  <summary>18. <b>标题：Towards Large-Scale Small Object Detection: Survey and Benchmarks</b></summary>
  <p><b>编号</b>：[52]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.14096</p>
  <p><b>作者</b>：Gong Cheng,  Xiang Yuan,  Xiwen Yao,  Kebing Yan,  Qinghua Zeng,  Junwei Han</p>
  <p><b>备注</b>：12 pages, 12 figures</p>
  <p><b>关键词</b>：Small Object Detection, object detection, convolutional neural networks, deep convolutional neural, achieved prominent advances</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>With the rise of deep convolutional neural networks, object detection has
achieved prominent advances in past years. However, such prosperity could not
camouflage the unsatisfactory situation of Small Object Detection (SOD), one of
the notoriously challenging tasks in computer vision, owing to the poor visual
appearance and noisy representation caused by the intrinsic structure of small
targets. In addition, large-scale dataset for benchmarking small object
detection methods remains a bottleneck. In this paper, we first conduct a
thorough review of small object detection. Then, to catalyze the development of
SOD, we construct two large-scale Small Object Detection dAtasets (SODA),
SODA-D and SODA-A, which focus on the Driving and Aerial scenarios
respectively. SODA-D includes 24704 high-quality traffic images and 277596
instances of 9 categories. For SODA-A, we harvest 2510 high-resolution aerial
images and annotate 800203 instances over 9 classes. The proposed datasets, as
we know, are the first-ever attempt to large-scale benchmarks with a vast
collection of exhaustively annotated instances tailored for multi-category SOD.
Finally, we evaluate the performance of mainstream methods on SODA. We expect
the released benchmarks could facilitate the development of SOD and spawn more
breakthroughs in this field. Datasets and codes will be available soon at:
\url{this https URL}.</p>
  </details>
</details>
<details>
  <summary>19. <b>标题：CubeMLP: A MLP-based Model for Multimodal Sentiment Analysis and  Depression Estimation</b></summary>
  <p><b>编号</b>：[54]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.14087</p>
  <p><b>作者</b>：Hao Sun,  Hongyi Wang,  Jiaqing Liu,  Yen-Wei Chen,  Lanfen Lin</p>
  <p><b>备注</b>：Accepted by ACM MM 2022</p>
  <p><b>关键词</b>：predict human mental, human mental states, important research topics, topics that aim, aim to predict</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Multimodal sentiment analysis and depression estimation are two important
research topics that aim to predict human mental states using multimodal data.
Previous research has focused on developing effective fusion strategies for
exchanging and integrating mind-related information from different modalities.
Some MLP-based techniques have recently achieved considerable success in a
variety of computer vision tasks. Inspired by this, we explore multimodal
approaches with a feature-mixing perspective in this study. To this end, we
introduce CubeMLP, a multimodal feature processing framework based entirely on
MLP. CubeMLP consists of three independent MLP units, each of which has two
affine transformations. CubeMLP accepts all relevant modality features as input
and mixes them across three axes. After extracting the characteristics using
CubeMLP, the mixed multimodal features are flattened for task predictions. Our
experiments are conducted on sentiment analysis datasets: CMU-MOSI and
CMU-MOSEI, and depression estimation dataset: AVEC2019. The results show that
CubeMLP can achieve state-of-the-art performance with a much lower computing
cost.</p>
  </details>
</details>
<details>
  <summary>20. <b>标题：Weakly-Supervised Camouflaged Object Detection with Scribble Annotations</b></summary>
  <p><b>编号</b>：[56]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.14083</p>
  <p><b>作者</b>：Ruozhen He,  Qihua Dong,  Jiaying Lin,  Rynson W.H. Lau</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：methods rely heavily, camouflaged object detection, Existing camouflaged object, rely heavily, heavily on large-scale</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Existing camouflaged object detection (COD) methods rely heavily on
large-scale datasets with pixel-wise annotations. However, due to the ambiguous
boundary, it is very time-consuming and labor-intensive to annotate camouflage
objects pixel-wisely (which takes ~ 60 minutes per image). In this paper, we
propose the first weakly-supervised camouflaged object detection (COD) method,
using scribble annotations as supervision. To achieve this, we first construct
a scribble-based camouflaged object dataset with 4,040 images and corresponding
scribble annotations. It is worth noting that annotating the scribbles used in
our dataset takes only ~ 10 seconds per image, which is 360 times faster than
per-pixel annotations. However, the network directly using scribble annotations
for supervision will fail to localize the boundary of camouflaged objects and
tend to have inconsistent predictions since scribble annotations only describe
the primary structure of objects without details. To tackle this problem, we
propose a novel consistency loss composed of two parts: a reliable cross-view
loss to attain reliable consistency over different images, and a soft
inside-view loss to maintain consistency inside a single prediction map.
Besides, we observe that humans use semantic information to segment regions
near boundaries of camouflaged objects. Therefore, we design a feature-guided
loss, which includes visual features directly extracted from images and
semantically significant features captured by models. Moreover, we propose a
novel network that detects camouflaged objects by scribble learning on
structural information and semantic relations. Experimental results show that
our model outperforms relevant state-of-the-art methods on three COD benchmarks
with an average improvement of 11.0% on MAE, 3.2% on S-measure, 2.5% on
E-measure and 4.4% on weighted F-measure.</p>
  </details>
</details>
<details>
  <summary>21. <b>标题：PEA: Improving the Performance of ReLU Networks for Free by Using  Progressive Ensemble Activations</b></summary>
  <p><b>编号</b>：[57]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.14074</p>
  <p><b>作者</b>：Ákos Utasi</p>
  <p><b>备注</b>：Published in Efficient Deep Learning for Computer Vision (ECV) CVPR Workshop 2022</p>
  <p><b>关键词</b>：superior performance compared, show superior performance, recent years, activations, ReLU</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In recent years novel activation functions have been proposed to improve the
performance of neural networks, and they show superior performance compared to
the ReLU counterpart. However, there are environments, where the availability
of complex activations is limited, and usually only the ReLU is supported. In
this paper we propose methods that can be used to improve the performance of
ReLU networks by using these efficient novel activations during model training.
More specifically, we propose ensemble activations that are composed of the
ReLU and one of these novel activations. Furthermore, the coefficients of the
ensemble are neither fixed nor learned, but are progressively updated during
the training process in a way that by the end of the training only the ReLU
activations remain active in the network and the other activations can be
removed. This means that in inference time the network contains ReLU
activations only. We perform extensive evaluations on the ImageNet
classification task using various compact network architectures and various
novel activation functions. Results show 0.2-0.8% top-1 accuracy gain, which
confirms the applicability of the proposed methods. Furthermore, we demonstrate
the proposed methods on semantic segmentation and we boost the performance of a
compact segmentation network by 0.34% mIOU on the Cityscapes dataset.</p>
  </details>
</details>
<details>
  <summary>22. <b>标题：Neural Strands: Learning Hair Geometry and Appearance from Multi-View  Images</b></summary>
  <p><b>编号</b>：[60]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.14067</p>
  <p><b>作者</b>：Radu Alexandru Rosu,  Shunsuke Saito,  Ziyan Wang,  Chenglei Wu,  Sven Behnke,  Giljoo Nam</p>
  <p><b>备注</b>：ECCV 2022. Project page: this https URL</p>
  <p><b>关键词</b>：multi-view image inputs, modeling accurate hair, image inputs, modeling accurate, present Neural Strands</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present Neural Strands, a novel learning framework for modeling accurate
hair geometry and appearance from multi-view image inputs. The learned hair
model can be rendered in real-time from any viewpoint with high-fidelity
view-dependent effects. Our model achieves intuitive shape and style control
unlike volumetric counterparts. To enable these properties, we propose a novel
hair representation based on a neural scalp texture that encodes the geometry
and appearance of individual strands at each texel location. Furthermore, we
introduce a novel neural rendering framework based on rasterization of the
learned hair strands. Our neural rendering is strand-accurate and anti-aliased,
making the rendering view-consistent and photorealistic. Combining appearance
with a multi-view geometric prior, we enable, for the first time, the joint
learning of appearance and explicit hair geometry from a multi-view setup. We
demonstrate the efficacy of our approach in terms of fidelity and efficiency
for various hairstyles.</p>
  </details>
</details>
<details>
  <summary>23. <b>标题：Robust Self-Tuning Data Association for Geo-Referencing Using Lane  Markings</b></summary>
  <p><b>编号</b>：[63]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.14042</p>
  <p><b>作者</b>：Miguel Ángel Muñoz-Bañón,  Jan-Hendrik Pauls,  Haohao Hu,  Christoph Stiller,  Francisco A. Candelas,  Fernando Torres</p>
  <p><b>备注</b>：The paper is being considered for publication in "IEEE Robotics and Automation Letters" (RA-L)</p>
  <p><b>关键词</b>：imagery-based maps offers, aerial imagery-based maps, publicly accessible data, geo-referenced maps, imagery-based maps</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Localization in aerial imagery-based maps offers many advantages, such as
global consistency, geo-referenced maps, and the availability of publicly
accessible data. However, the landmarks that can be observed from both aerial
imagery and on-board sensors is limited. This leads to ambiguities or aliasing
during the data association.
Building upon a highly informative representation (that allows efficient data
association), this paper presents a complete pipeline for resolving these
ambiguities. Its core is a robust self-tuning data association that adapts the
search area depending on the entropy of the measurements. Additionally, to
smooth the final result, we adjust the information matrix for the associated
data as a function of the relative transform produced by the data association
process.
We evaluate our method on real data from urban and rural scenarios around the
city of Karlsruhe in Germany. We compare state-of-the-art outlier mitigation
methods with our self-tuning approach, demonstrating a considerable
improvement, especially for outer-urban scenarios.</p>
  </details>
</details>
<details>
  <summary>24. <b>标题：Separable Quaternion Matrix Factorization for Polarization Images</b></summary>
  <p><b>编号</b>：[64]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.14039</p>
  <p><b>作者</b>：Junjun Pan,  Michael K. Ng</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Stokes parameters, represented by Stokes, unique characteristic, characteristic of transverse, transverse wave</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Polarization is a unique characteristic of transverse wave and is represented
by Stokes parameters. Analysis of polarization states can reveal valuable
information about the sources. In this paper, we propose a separable low-rank
quaternion linear mixing model to polarized signals: we assume each column of
the source factor matrix equals a column of polarized data matrix and refer to
the corresponding problem as separable quaternion matrix factorization (SQMF).
We discuss some properties of the matrix that can be decomposed by SQMF. To
determine the source factor matrix in quaternion space, we propose a heuristic
algorithm called quaternion successive projection algorithm (QSPA) inspired by
the successive projection algorithm. To guarantee the effectiveness of QSPA, a
new normalization operator is proposed for the quaternion matrix. We use a
block coordinate descent algorithm to compute nonnegative factor activation
matrix in real number space. We test our method on the applications of
polarization image representation and spectro-polarimetric imaging unmixing to
verify its effectiveness.</p>
  </details>
</details>
<details>
  <summary>25. <b>标题：Safety-Enhanced Autonomous Driving Using Interpretable Sensor Fusion  Transformer</b></summary>
  <p><b>编号</b>：[69]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.14024</p>
  <p><b>作者</b>：Hao Shao,  LeTian Wang,  RuoBing Chen,  Hongsheng Li,  Yu Liu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：continually delayed due, Large-scale deployment, continually delayed, delayed due, comprehensive scene understanding</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large-scale deployment of autonomous vehicles has been continually delayed
due to safety concerns. On the one hand, comprehensive scene understanding is
indispensable, a lack of which would result in vulnerability to rare but
complex traffic situations, such as the sudden emergence of unknown objects.
However, reasoning from a global context requires access to sensors of multiple
types and adequate fusion of multi-modal sensor signals, which is difficult to
achieve. On the other hand, the lack of interpretability in learning models
also hampers the safety with unverifiable failure causes. In this paper, we
propose a safety-enhanced autonomous driving framework, named Interpretable
Sensor Fusion Transformer(InterFuser), to fully process and fuse information
from multi-modal multi-view sensors for achieving comprehensive scene
understanding and adversarial event detection. Besides, intermediate
interpretable features are generated from our framework, which provide more
semantics and are exploited to better constrain actions to be within the safe
sets. We conducted extensive experiments on CARLA benchmarks, where our model
outperforms prior methods, ranking the first on the public CARLA Leaderboard.</p>
  </details>
</details>
<details>
  <summary>26. <b>标题：Video Mask Transfiner for High-Quality Video Instance Segmentation</b></summary>
  <p><b>编号</b>：[72]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.14012</p>
  <p><b>作者</b>：Lei Ke,  Henghui Ding,  Martin Danelljan,  Yu-Wing Tai,  Chi-Keung Tang,  Fisher Yu</p>
  <p><b>备注</b>：ECCV 2022; Project page: this https URL; Dataset page: this https URL</p>
  <p><b>关键词</b>：Video Instance Segmentation, current approaches struggle, Instance Segmentation, Video Instance, rapid progress</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>While Video Instance Segmentation (VIS) has seen rapid progress, current
approaches struggle to predict high-quality masks with accurate boundary
details. Moreover, the predicted segmentations often fluctuate over time,
suggesting that temporal consistency cues are neglected or not fully utilized.
In this paper, we set out to tackle these issues, with the aim of achieving
highly detailed and more temporally stable mask predictions for VIS. We first
propose the Video Mask Transfiner (VMT) method, capable of leveraging
fine-grained high-resolution features thanks to a highly efficient video
transformer structure. Our VMT detects and groups sparse error-prone
spatio-temporal regions of each tracklet in the video segment, which are then
refined using both local and instance-level cues. Second, we identify that the
coarse boundary annotations of the popular YouTube-VIS dataset constitute a
major limiting factor. Based on our VMT architecture, we therefore design an
automated annotation refinement approach by iterative training and
self-correction. To benchmark high-quality mask predictions for VIS, we
introduce the HQ-YTVIS dataset, consisting of a manually re-annotated test set
and our automatically refined training data. We compare VMT with the most
recent state-of-the-art methods on the HQ-YTVIS, as well as the Youtube-VIS,
OVIS and BDD100K MOTS benchmarks. Experimental results clearly demonstrate the
efficacy and effectiveness of our method on segmenting complex and dynamic
objects, by capturing precise details.</p>
  </details>
</details>
<details>
  <summary>27. <b>标题：On the Effects of Different Types of Label Noise in Multi-Label Remote  Sensing Image Classification</b></summary>
  <p><b>编号</b>：[87]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.13975</p>
  <p><b>作者</b>：Tom Burgert,  Mahdyar Ravanbakhsh,  Begüm Demir</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：important research topics, MLC, label, label noise, noise</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The development of accurate methods for multi-label classification (MLC) of
remote sensing (RS) images is one of the most important research topics in RS.
To address MLC problems, the use of deep neural networks that require a high
number of reliable training images annotated by multiple land-cover class
labels (multi-labels) have been found popular in RS. However, collecting such
annotations is time-consuming and costly. A common procedure to obtain
annotations at zero labeling cost is to rely on thematic products or
crowdsourced labels. As a drawback, these procedures come with the risk of
label noise that can distort the learning process of the MLC algorithms. In the
literature, most label noise robust methods are designed for single label
classification (SLC) problems in computer vision (CV), where each image is
annotated by a single label. Unlike SLC, label noise in MLC can be associated
with: 1) subtractive label-noise (a land cover class label is not assigned to
an image while that class is present in the image); 2) additive label-noise (a
land cover class label is assigned to an image although that class is not
present in the given image); and 3) mixed label-noise (a combination of both).
In this paper, we investigate three different noise robust CV SLC methods and
adapt them to be robust for multi-label noise scenarios in RS. During
experiments we study the effects of different types of multi-label noise and
evaluate the adapted methods rigorously. To this end, we also introduce a
synthetic multi-label noise injection strategy that is more adequate to
simulate operational scenarios compared to the uniform label noise injection
strategy, in which the labels of absent and present classes are flipped at
uniform probability. Further, we study the relevance of different evaluation
metrics in MLC problems under noisy multi-labels.</p>
  </details>
</details>
<details>
  <summary>28. <b>标题：Meta-Learning based Degradation Representation for Blind  Super-Resolution</b></summary>
  <p><b>编号</b>：[91]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.13963</p>
  <p><b>作者</b>：Bin Xia,  Yapeng Tian,  Yulun Zhang,  Yucheng Hang,  Wenming Yang,  Qingmin Liao</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：CNN based super-resolution, degradation, CNN based, Network, CNN</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The most of CNN based super-resolution (SR) methods assume that the
degradation is known (\eg, bicubic). These methods will suffer a severe
performance drop when the degradation is different from their assumption.
Therefore, some approaches attempt to train SR networks with the complex
combination of multiple degradations to cover the real degradation space. To
adapt to multiple unknown degradations, introducing an explicit degradation
estimator can actually facilitate SR performance. However, previous explicit
degradation estimation methods usually predict Gaussian blur with the
supervision of groundtruth blur kernels, and estimation errors may lead to SR
failure. Thus, it is necessary to design a method that can extract implicit
discriminative degradation representation. To this end, we propose a
Meta-Learning based Region Degradation Aware SR Network (MRDA), including
Meta-Learning Network (MLN), Degradation Extraction Network (DEN), and Region
Degradation Aware SR Network (RDAN). To handle the lack of groundtruth
degradation, we use the MLN to rapidly adapt to the specific complex
degradation after several iterations and extract implicit degradation
information. Subsequently, a teacher network MRDA$_{T}$ is designed to further
utilize the degradation information extracted by MLN for SR. However, MLN
requires iterating on paired low-resolution (LR) and corresponding
high-resolution (HR) images, which is unavailable in the inference phase.
Therefore, we adopt knowledge distillation (KD) to make the student network
learn to directly extract the same implicit degradation representation (IDR) as
the teacher from LR images.</p>
  </details>
</details>
<details>
  <summary>29. <b>标题：A Novel Data Augmentation Technique for Out-of-Distribution Sample  Detection using Compounded Corruptions</b></summary>
  <p><b>编号</b>：[105]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.13916</p>
  <p><b>作者</b>：Ramya S. Hebbalaguppe,  Soumya Suvra Goshal,  Jatin Prakash,  Harshad Khadilkar,  Chetan Arora</p>
  <p><b>备注</b>：16 pages main text, 23 pages supplemental material. Accepted in Research Track ECML'22. Project webpage: this https URL</p>
  <p><b>关键词</b>：Modern deep neural, deep neural network, neural network models, OOD, Modern deep</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Modern deep neural network models are known to erroneously classify
out-of-distribution (OOD) test data into one of the in-distribution (ID)
training classes with high confidence. This can have disastrous consequences
for safety-critical applications. A popular mitigation strategy is to train a
separate classifier that can detect such OOD samples at the test time. In most
practical settings OOD examples are not known at the train time, and hence a
key question is: how to augment the ID data with synthetic OOD samples for
training such an OOD detector? In this paper, we propose a novel Compounded
Corruption technique for the OOD data augmentation termed CnC. One of the major
advantages of CnC is that it does not require any hold-out data apart from the
training set. Further, unlike current state-of-the-art (SOTA) techniques, CnC
does not require backpropagation or ensembling at the test time, making our
method much faster at inference. Our extensive comparison with 20 methods from
the major conferences in last 4 years show that a model trained using CnC based
data augmentation, significantly outperforms SOTA, both in terms of OOD
detection accuracy as well as inference time. We include a detailed post-hoc
analysis to investigate the reasons for the success of our method and identify
higher relative entropy and diversity of CnC samples as probable causes. We
also provide theoretical insights via a piece-wise decomposition analysis on a
two-dimensional dataset to reveal (visually and quantitatively) that our
approach leads to a tighter boundary around ID classes, leading to better
detection of OOD samples. Source code link: this https URL</p>
  </details>
</details>
<details>
  <summary>30. <b>标题：Why Accuracy Is Not Enough: The Need for Consistency in Object Detection</b></summary>
  <p><b>编号</b>：[115]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.13890</p>
  <p><b>作者</b>：Caleb Tung,  Abhinav Goel,  Fischer Bordwell,  Nick Eliopoulos,  Xiao Hu,  George K. Thiruvathukal,  Yung-Hsiang Lu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：computer vision applications, vision applications, modern computer vision, computer vision, Object detectors</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Object detectors are vital to many modern computer vision applications.
However, even state-of-the-art object detectors are not perfect. On two images
that look similar to human eyes, the same detector can make different
predictions because of small image distortions like camera sensor noise and
lighting changes. This problem is called inconsistency. Existing accuracy
metrics do not properly account for inconsistency, and similar work in this
area only targets improvements on artificial image distortions. Therefore, we
propose a method to use non-artificial video frames to measure object detection
consistency over time, across frames. Using this method, we show that the
consistency of modern object detectors ranges from 83.2% to 97.1% on different
video datasets from the Multiple Object Tracking Challenge. We conclude by
showing that applying image distortion corrections like .WEBP Image Compression
and Unsharp Masking can improve consistency by as much as 5.1%, with no loss in
accuracy.</p>
  </details>
</details>
<details>
  <summary>31. <b>标题：A Repulsive Force Unit for Garment Collision Handling in Neural Networks</b></summary>
  <p><b>编号</b>：[122]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.13871</p>
  <p><b>作者</b>：Qingyang Tan,  Yi Zhou,  Tuanfeng Wang,  Duygu Ceylan,  Xin Sun,  Dinesh Manocha</p>
  <p><b>备注</b>：ECCV 2022</p>
  <p><b>关键词</b>：Repulsive Force Unit, body motion suffer, deep learning-based methods, called Repulsive Force, recent success</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Despite recent success, deep learning-based methods for predicting 3D garment
deformation under body motion suffer from interpenetration problems between the
garment and the body. To address this problem, we propose a novel collision
handling neural network layer called Repulsive Force Unit (ReFU). Based on the
signed distance function (SDF) of the underlying body and the current garment
vertex positions, ReFU predicts the per-vertex offsets that push any
interpenetrating vertex to a collision-free configuration while preserving the
fine geometric details. We show that ReFU is differentiable with trainable
parameters and can be integrated into different network backbones that predict
3D garment deformations. Our experiments show that ReFU significantly reduces
the number of collisions between the body and the garment and better preserves
geometric details compared to prior methods based on collision loss or
post-processing optimization.</p>
  </details>
</details>
<details>
  <summary>32. <b>标题：Generative Steganography Network</b></summary>
  <p><b>编号</b>：[124]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.13867</p>
  <p><b>作者</b>：Ping Wei,  Sheng Li,  Xinpeng Zhang,  Ge Luo,  Zhenxing Qian,  Qing Zhou</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：stego images, modifies cover media, secret data, images, stego</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Steganography usually modifies cover media to embed secret data. A new
steganographic approach called generative steganography (GS) has emerged
recently, in which stego images (images containing secret data) are generated
from secret data directly without cover media. However, existing GS schemes are
often criticized for their poor performances. In this paper, we propose an
advanced generative steganography network (GSN) that can generate realistic
stego images without using cover images, in which mutual information is firstly
introduced in stego image generation. Our model contains four sub-networks,
i.e., an image generator ($G$), a discriminator ($D$), a steganalyzer ($S$),
and a data extractor ($E$). $D$ and $S$ act as two adversarial discriminators
to ensure the visual and statistical imperceptibility of generated stego
images. $E$ is to extract the hidden secret from generated stego images. The
generator $G$ is flexibly constructed to synthesize either cover or stego
images with different inputs. It facilitates covert communication by hiding the
function of generating stego images in a normal image generator. A module named
secret block is designed delicately to conceal secret data in the feature maps
during image generation, with which high hiding capacity and image fidelity are
achieved. In addition, a novel hierarchical gradient decay skill is developed
to resist steganalysis detection. Experiments demonstrate the superiority of
our work over existing methods.</p>
  </details>
</details>
<details>
  <summary>33. <b>标题：MKANet: A Lightweight Network with Sobel Boundary Loss for Efficient  Land-cover Classification of Satellite Remote Sensing Imagery</b></summary>
  <p><b>编号</b>：[125]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.13866</p>
  <p><b>作者</b>：Zhiqi Zhang,  Wen Lu,  Jinshan Cao,  Guangqi Xie</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：multi-class segmentation task, Land cover classification, natural vegetation, Land cover, earth surface</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Land cover classification is a multi-class segmentation task to classify each
pixel into a certain natural or man-made category of the earth surface, such as
water, soil, natural vegetation, crops, and human infrastructure. Limited by
hardware computational resources and memory capacity, most existing studies
preprocessed original remote sensing images by down sampling or cropping them
into small patches less than 512*512 pixels before sending them to a deep
neural network. However, down sampling images incurs spatial detail loss,
renders small segments hard to discriminate, and reverses the spatial
resolution progress obtained by decades of years of efforts. Cropping images
into small patches causes a loss of long-range context information, and
restoring the predicted results to their original size brings extra latency. In
response to the above weaknesses, we present an efficient lightweight semantic
segmentation network termed MKANet. Aimed at the characteristics of top view
high-resolution remote sensing imagery, MKANet utilizes sharing kernels to
simultaneously and equally handle ground segments of inconsistent scales, and
also employs parallel and shallow architecture to boost inference speed and
friendly support image patches more than 10X larger. To enhance boundary and
small segments discrimination, we also propose a method that captures category
impurity areas, exploits boundary information and exerts an extra penalty on
boundaries and small segment misjudgment. Both visual interpretations and
quantitative metrics of extensive experiments demonstrate that MKANet acquires
state-of-the-art accuracy on two land-cover classification datasets and infers
2X faster than other competitive lightweight networks. All these merits
highlight the potential of MKANet in practical applications.</p>
  </details>
</details>
<details>
  <summary>34. <b>标题：DnSwin: Toward Real-World Denoising via Continuous Wavelet  Sliding-Transformer</b></summary>
  <p><b>编号</b>：[129]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.13861</p>
  <p><b>作者</b>：Hao Li,  Zhijing Yang,  Xiaobin Hong,  Ziying Zhao,  Junyang Chen,  Yukai Shi,  Jinshan Pan</p>
  <p><b>备注</b>：DnSwin, a continuous Wavelet Sliding-Transformer, builds frequency correspondence under real-world scenes for image denoising</p>
  <p><b>关键词</b>：practical image restoration, image restoration problem, obtain clean images, restoration problem, problem that aims</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Real-world image denoising is a practical image restoration problem that aims
to obtain clean images from in-the-wild noisy input. Recently, Vision
Transformer (ViT) exhibits a strong ability to capture long-range dependencies
and many researchers attempt to apply ViT to image denoising tasks. However,
real-world image is an isolated frame that makes the ViT build the long-range
dependencies on the internal patches, which divides images into patches and
disarranges the noise pattern and gradient continuity. In this article, we
propose to resolve this issue by using a continuous Wavelet Sliding-Transformer
that builds frequency correspondence under real-world scenes, called DnSwin.
Specifically, we first extract the bottom features from noisy input images by
using a CNN encoder. The key to DnSwin is to separate high-frequency and
low-frequency information from the features and build frequency dependencies.
To this end, we propose Wavelet Sliding-Window Transformer that utilizes
discrete wavelet transform, self-attention and inverse discrete wavelet
transform to extract deep features. Finally, we reconstruct the deep features
into denoised images using a CNN decoder. Both quantitative and qualitative
evaluations on real-world denoising benchmarks demonstrate that the proposed
DnSwin performs favorably against the state-of-the-art methods.</p>
  </details>
</details>
<details>
  <summary>35. <b>标题：EEG2Mel: Reconstructing Sound from Brain Responses to Music</b></summary>
  <p><b>编号</b>：[135]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.13845</p>
  <p><b>作者</b>：Adolfo G. Ramirez-Aristizabal,  Chris Kello</p>
  <p><b>备注</b>：5 figures, 2 tables, listening examples and code provided</p>
  <p><b>关键词</b>：recording EEG signals, image classes presented, Information retrieval, EEG signals, brain responses</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Information retrieval from brain responses to auditory and visual stimuli has
shown success through classification of song names and image classes presented
to participants while recording EEG signals. Information retrieval in the form
of reconstructing auditory stimuli has also shown some success, but here we
improve on previous methods by reconstructing music stimuli well enough to be
perceived and identified independently. Furthermore, deep learning models were
trained on time-aligned music stimuli spectrum for each corresponding
one-second window of EEG recording, which greatly reduces feature extraction
steps needed when compared to prior studies. The NMED-Tempo and NMED-Hindi
datasets of participants passively listening to full length songs were used to
train and validate Convolutional Neural Network (CNN) regressors. The efficacy
of raw voltage versus power spectrum inputs and linear versus mel spectrogram
outputs were tested, and all inputs and outputs were converted into 2D images.
The quality of reconstructed spectrograms was assessed by training classifiers
which showed 81% accuracy for mel-spectrograms and 72% for linear spectrograms
(10% chance accuracy). Lastly, reconstructions of auditory music stimuli were
discriminated by listeners at an 85% success rate (50% chance) in a
two-alternative match-to-sample task.</p>
  </details>
</details>
<details>
  <summary>36. <b>标题：Cross-Attention of Disentangled Modalities for 3D Human Mesh Recovery  with Transformers</b></summary>
  <p><b>编号</b>：[147]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.13820</p>
  <p><b>作者</b>：Junhyeong Cho,  Kim Youwang,  Tae-Hyun Oh</p>
  <p><b>备注</b>：Accepted to ECCV 2022, Code: this https URL</p>
  <p><b>关键词</b>：results on monocular, recently achieved, expensive computations, human mesh reconstruction, require a substantial</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Transformer encoder architectures have recently achieved state-of-the-art
results on monocular 3D human mesh reconstruction, but they require a
substantial number of parameters and expensive computations. Due to the large
memory overhead and slow inference speed, it is difficult to deploy such models
for practical use. In this paper, we propose a novel transformer
encoder-decoder architecture for 3D human mesh reconstruction from a single
image, called FastMETRO. We identify the performance bottleneck in the
encoder-based transformers is caused by the token design which introduces high
complexity interactions among input tokens. We disentangle the interactions via
an encoder-decoder architecture, which allows our model to demand much fewer
parameters and shorter inference time. In addition, we impose the prior
knowledge of human body's morphological relationship via attention masking and
mesh upsampling operations, which leads to faster convergence with higher
accuracy. Our FastMETRO improves the Pareto-front of accuracy and efficiency,
and clearly outperforms image-based methods on Human3.6M and 3DPW. Furthermore,
we validate its generalizability on FreiHAND.</p>
  </details>
</details>
<details>
  <summary>37. <b>标题：Pose-NDF: Modeling Human Pose Manifolds with Neural Distance Fields</b></summary>
  <p><b>编号</b>：[151]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.13807</p>
  <p><b>作者</b>：Garvita Tiwari,  Dimitrije Antic,  Jan Eric Lenssen,  Nikolaos Sarafianos,  Tony Tung,  Gerard Pons-Moll</p>
  <p><b>备注</b>：Project page: this https URL</p>
  <p><b>关键词</b>：neural distance fields, human poses based, poses, Pose, present Pose-NDF</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present Pose-NDF, a continuous model for plausible human poses based on
neural distance fields (NDFs). Pose or motion priors are important for
generating realistic new poses and for reconstructing accurate poses from noisy
or partial observations. Pose-NDF learns a manifold of plausible poses as the
zero level set of a neural implicit function, extending the idea of modeling
implicit surfaces in 3D to the high-dimensional domain SO(3)^K, where a human
pose is defined by a single data point, represented by K quaternions. The
resulting high-dimensional implicit function can be differentiated with respect
to the input poses and thus can be used to project arbitrary poses onto the
manifold by using gradient descent on the set of 3-dimensional hyperspheres. In
contrast to previous VAE-based human pose priors, which transform the pose
space into a Gaussian distribution, we model the actual pose manifold,
preserving the distances between poses. We demonstrate that PoseNDF outperforms
existing state-of-the-art methods as a prior in various downstream tasks,
ranging from denoising real-world human mocap data, pose recovery from occluded
data to 3D pose reconstruction from images. Furthermore, we show that it can be
used to generate more diverse poses by random sampling and projection than
VAE-based methods.</p>
  </details>
</details>
<details>
  <summary>38. <b>标题：Look at Adjacent Frames: Video Anomaly Detection without Offline  Training</b></summary>
  <p><b>编号</b>：[156]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.13798</p>
  <p><b>作者</b>：Yuqi Ouyang,  Guodong Shen,  Victor Sanchez</p>
  <p><b>备注</b>：Accepted in ECCV 2022 RWS</p>
  <p><b>关键词</b>：detect anomalous events, train a model, detect anomalous, anomalous events, multilayer perceptron</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose a solution to detect anomalous events in videos without the need
to train a model offline. Specifically, our solution is based on a
randomly-initialized multilayer perceptron that is optimized online to
reconstruct video frames, pixel-by-pixel, from their frequency information.
Based on the information shifts between adjacent frames, an incremental learner
is used to update parameters of the multilayer perceptron after observing each
frame, thus allowing to detect anomalous events along the video stream.
Traditional solutions that require no offline training are limited to operating
on videos with only a few abnormal frames. Our solution breaks this limit and
achieves strong performance on benchmark datasets.</p>
  </details>
</details>
<details>
  <summary>39. <b>标题：Learning to Assess Danger from Movies for Cooperative Escape Planning in  Hazardous Environments</b></summary>
  <p><b>编号</b>：[159]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.13791</p>
  <p><b>作者</b>：Vikram Shree,  Sarah Allen,  Beatriz Asfora,  Jacopo Banfi,  Mark Campbell</p>
  <p><b>备注</b>：8 pages, 8 figures Accepted for publication at 2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</p>
  <p><b>关键词</b>：nascent stage, plethora of work, work towards improving, hazardous environments, improving robot perception</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>There has been a plethora of work towards improving robot perception and
navigation, yet their application in hazardous environments, like during a fire
or an earthquake, is still at a nascent stage. We hypothesize two key
challenges here: first, it is difficult to replicate such scenarios in the real
world, which is necessary for training and testing purposes. Second, current
systems are not fully able to take advantage of the rich multi-modal data
available in such hazardous environments. To address the first challenge, we
propose to harness the enormous amount of visual content available in the form
of movies and TV shows, and develop a dataset that can represent hazardous
environments encountered in the real world. The data is annotated with
high-level danger ratings for realistic disaster images, and corresponding
keywords are provided that summarize the content of the scene. In response to
the second challenge, we propose a multi-modal danger estimation pipeline for
collaborative human-robot escape scenarios. Our Bayesian framework improves
danger estimation by fusing information from robot's camera sensor and language
inputs from the human. Furthermore, we augment the estimation module with a
risk-aware planner that helps in identifying safer paths out of the dangerous
environment. Through extensive simulations, we exhibit the advantages of our
multi-modal perception framework that gets translated into tangible benefits
such as higher success rate in a collaborative human-robot mission.</p>
  </details>
</details>
<details>
  <summary>40. <b>标题：AvatarPoser: Articulated Full-Body Pose Tracking from Sparse Motion  Sensing</b></summary>
  <p><b>编号</b>：[163]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.13784</p>
  <p><b>作者</b>：Jiaxi Jiang,  Paul Streli,  Huajian Qiu,  Andreas Fender,  Larissa Laich,  Patrick Snape,  Christian Holz</p>
  <p><b>备注</b>：Accepted by ECCV 2022, Code: this https URL</p>
  <p><b>关键词</b>：Today Mixed Reality, Mixed Reality head-mounted, Reality head-mounted displays, head-mounted displays track, Mixed Reality</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Today's Mixed Reality head-mounted displays track the user's head pose in
world space as well as the user's hands for interaction in both Augmented
Reality and Virtual Reality scenarios. While this is adequate to support user
input, it unfortunately limits users' virtual representations to just their
upper bodies. Current systems thus resort to floating avatars, whose limitation
is particularly evident in collaborative settings. To estimate full-body poses
from the sparse input sources, prior work has incorporated additional trackers
and sensors at the pelvis or lower body, which increases setup complexity and
limits practical application in mobile settings. In this paper, we present
AvatarPoser, the first learning-based method that predicts full-body poses in
world coordinates using only motion input from the user's head and hands. Our
method builds on a Transformer encoder to extract deep features from the input
signals and decouples global motion from the learned local joint orientations
to guide pose estimation. To obtain accurate full-body motions that resemble
motion capture animations, we refine the arm joints' positions using an
optimization routine with inverse kinematics to match the original tracking
input. In our evaluation, AvatarPoser achieved new state-of-the-art results in
evaluations on large motion capture datasets (AMASS). At the same time, our
method's inference speed supports real-time operation, providing a practical
interface to support holistic avatar control and representation for Metaverse
applications.</p>
  </details>
</details>
<details>
  <summary>41. <b>标题：GAUDI: A Neural Architect for Immersive 3D Scene Generation</b></summary>
  <p><b>编号</b>：[171]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.13751</p>
  <p><b>作者</b>：Miguel Angel Bautista,  Pengsheng Guo,  Samira Abnar,  Walter Talbott,  Alexander Toshev,  Zhuoyuan Chen,  Laurent Dinh,  Shuangfei Zhai,  Hanlin Goh,  Daniel Ulbricht,  Afshin Dehghan,  Josh Susskind</p>
  <p><b>备注</b>：Project webpage: this https URL</p>
  <p><b>关键词</b>：complex and realistic, generative model capable, capable of capturing, rendered immersively, introduce GAUDI</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We introduce GAUDI, a generative model capable of capturing the distribution
of complex and realistic 3D scenes that can be rendered immersively from a
moving camera. We tackle this challenging problem with a scalable yet powerful
approach, where we first optimize a latent representation that disentangles
radiance fields and camera poses. This latent representation is then used to
learn a generative model that enables both unconditional and conditional
generation of 3D scenes. Our model generalizes previous works that focus on
single objects by removing the assumption that the camera pose distribution can
be shared across samples. We show that GAUDI obtains state-of-the-art
performance in the unconditional generative setting across multiple datasets
and allows for conditional generation of 3D scenes given conditioning variables
like sparse image observations or text that describes the scene.</p>
  </details>
</details>
<details>
  <summary>42. <b>标题：Lighting (In)consistency of Paint by Text</b></summary>
  <p><b>编号</b>：[173]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.13744</p>
  <p><b>作者</b>：Hany Farid</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：synthesizing highly realistic, generative adversarial networks, seemingly endless categories, synthesize realistic images, highly realistic images</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Whereas generative adversarial networks are capable of synthesizing highly
realistic images of faces, cats, landscapes, or almost any other single
category, paint-by-text synthesis engines can -- from a single text prompt --
synthesize realistic images of seemingly endless categories with arbitrary
configurations and combinations. This powerful technology poses new challenges
to the photo-forensic community. Motivated by the fact that paint by text is
not based on explicit geometric or physical models, and the human visual
system's general insensitivity to lighting inconsistencies, we provide an
initial exploration of the lighting consistency of DALL-E-2 synthesized images
to determine if physics-based forensic analyses will prove fruitful in
detecting this new breed of synthetic media.</p>
  </details>
</details>
<details>
  <summary>43. <b>标题：Break and Make: Interactive Structural Understanding Using LEGO Bricks</b></summary>
  <p><b>编号</b>：[174]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.13738</p>
  <p><b>作者</b>：Aaron Walsman,  Muru Zhang,  Klemen Kotar,  Karthik Desingh,  Ali Farhadi,  Dieter Fox</p>
  <p><b>备注</b>：ECCV 2022. LTRON simulator and environment page: this https URL Training examples: this https URL</p>
  <p><b>关键词</b>：complex spatial relationships, human intelligence, spatial relationships, fundamental component, component of human</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Visual understanding of geometric structures with complex spatial
relationships is a fundamental component of human intelligence. As children, we
learn how to reason about structure not only from observation, but also by
interacting with the world around us -- by taking things apart and putting them
back together again. The ability to reason about structure and compositionality
allows us to not only build things, but also understand and reverse-engineer
complex systems. In order to advance research in interactive reasoning for
part-based geometric understanding, we propose a challenging new assembly
problem using LEGO bricks that we call Break and Make. In this problem an agent
is given a LEGO model and attempts to understand its structure by interactively
inspecting and disassembling it. After this inspection period, the agent must
then prove its understanding by rebuilding the model from scratch using
low-level action primitives. In order to facilitate research on this problem we
have built LTRON, a fully interactive 3D simulator that allows learning agents
to assemble, disassemble and manipulate LEGO models. We pair this simulator
with a new dataset of fan-made LEGO creations that have been uploaded to the
internet in order to provide complex scenes containing over a thousand unique
brick shapes. We take a first step towards solving this problem using
sequence-to-sequence models that provide guidance for how to make progress on
this challenging problem. Our simulator and data are available at
this http URL. Additional training code and PyTorch examples
are available at this http URL.</p>
  </details>
</details>
<details>
  <summary>44. <b>标题：Re-thinking and Re-labeling LIDC-IDRI for Robust Pulmonary Cancer  Prediction</b></summary>
  <p><b>编号</b>：[189]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.14238</p>
  <p><b>作者</b>：Hanxiao Zhang,  Xiao Gu,  Minghui Zhang,  Weihao Yu,  Liang Chen,  Zhexin Wang,  Feng Yao,  Yun Gu,  Guang-Zhong Yang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：LIDC, cancer prediction, lung cancer prediction, popular benchmark, cancer</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The LIDC-IDRI database is the most popular benchmark for lung cancer
prediction. However, with subjective assessment from radiologists, nodules in
LIDC may have entirely different malignancy annotations from the pathological
ground truth, introducing label assignment errors and subsequent supervision
bias during training. The LIDC database thus requires more objective labels for
learning-based cancer prediction. Based on an extra small dataset containing
180 nodules diagnosed by pathological examination, we propose to re-label LIDC
data to mitigate the effect of original annotation bias verified on this robust
benchmark. We demonstrate in this paper that providing new labels by similar
nodule retrieval based on metric learning would be an effective re-labeling
strategy. Training on these re-labeled LIDC nodules leads to improved model
performance, which is enhanced when new labels of uncertain nodules are added.
We further infer that re-labeling LIDC is current an expedient way for robust
lung cancer prediction while building a large pathological-proven nodule
database provides the long-term solution.</p>
  </details>
</details>
<details>
  <summary>45. <b>标题：Topological Analysis of Ensembles of Hydrodynamic Turbulent Flows -- An  Experimental Study</b></summary>
  <p><b>编号</b>：[200]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.14080</p>
  <p><b>作者</b>：Florent Nauleau,  Fabien Vivodtzev,  Thibault Bridel-Bertomeu,  Heloise Beaugendre,  Julien Tierny</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Topological Data Analysis, application paper presents, Data Analysis, comprehensive experimental evaluation, application paper</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This application paper presents a comprehensive experimental evaluation of
the suitability of Topological Data Analysis (TDA) for the quantitative
comparison of turbulent flows. Specifically, our study documents the usage of
the persistence diagram of the maxima of flow enstrophy (an established
vorticity indicator), for the topological representation of 180 ensemble
members, generated by a coarse sampling of the parameter space of five
numerical solvers. We document five main hypotheses reported by domain experts,
describing their expectations regarding the variability of the flows generated
by the distinct solver configurations. We contribute three evaluation protocols
to assess the validation of the above hypotheses by two comparison measures:
(i) a standard distance used in scientific imaging (the L2 norm) and (ii) an
established topological distance between persistence diagrams (the
L2-Wasserstein metric). Extensive experiments on the input ensemble demonstrate
the superiority of the topological distance (ii) to report as close to each
other flows which are expected to be similar by domain experts, due to the
configuration of their vortices. Overall, the insights reported by our study
bring an experimental evidence of the suitability of TDA for representing and
comparing turbulent flows, thereby providing to the fluid dynamics community
confidence for its usage in future work. Also, our flow data and evaluation
protocols provide to the TDA community an application-approved benchmark for
the evaluation and design of further topological distances.</p>
  </details>
</details>
<details>
  <summary>46. <b>标题：SuperVessel: Segmenting High-resolution Vessel from Low-resolution  Retinal Image</b></summary>
  <p><b>编号</b>：[208]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.13882</p>
  <p><b>作者</b>：Yan Hu,  Zhongxi Qiu,  Dan Zeng,  Li Jiang,  Chen Lin,  Jiang Liu</p>
  <p><b>备注</b>：Accepted by PRCV2022</p>
  <p><b>关键词</b>：Vascular segmentation extracts, extracts blood vessels, segmentation extracts blood, ophthalmic diseases, extracts blood</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Vascular segmentation extracts blood vessels from images and serves as the
basis for diagnosing various diseases, like ophthalmic diseases.
Ophthalmologists often require high-resolution segmentation results for
analysis, which leads to super-computational load by most existing methods. If
based on low-resolution input, they easily ignore tiny vessels or cause
discontinuity of segmented vessels. To solve these problems, the paper proposes
an algorithm named SuperVessel, which gives out high-resolution and accurate
vessel segmentation using low-resolution images as input. We first take
super-resolution as our auxiliary branch to provide potential high-resolution
detail features, which can be deleted in the test phase. Secondly, we propose
two modules to enhance the features of the interested segmentation region,
including an upsampling with feature decomposition (UFD) module and a feature
interaction module (FIM) with a constraining loss to focus on the interested
features. Extensive experiments on three publicly available datasets
demonstrate that our proposed SuperVessel can segment more tiny vessels with
higher segmentation accuracy IoU over 6%, compared with other state-of-the-art
algorithms. Besides, the stability of SuperVessel is also stronger than other
algorithms. We will release the code after the paper is published.</p>
  </details>
</details>
<details>
  <summary>47. <b>标题：Real Image Restoration via Structure-preserving Complementarity  Attention</b></summary>
  <p><b>编号</b>：[209]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.13879</p>
  <p><b>作者</b>：Yuanfan Zhang,  Gen Li,  Lei Sun</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：convolutional neural networks, neural networks perform, large-scale data, convolutional neural, learning generalizable image</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Since convolutional neural networks perform well in learning generalizable
image priors from large-scale data, these models have been widely used in image
denoising tasks. However, the computational complexity increases dramatically
as well on complex model. In this paper, We propose a novel lightweight
Complementary Attention Module, which includes a density module and a sparse
module, which can cooperatively mine dense and sparse features for feature
complementary learning to build an efficient lightweight architecture.
Moreover, to reduce the loss of details caused by denoising, this paper
constructs a gradient-based structure-preserving branch. We utilize
gradient-based branches to obtain additional structural priors for denoising,
and make the model pay more attention to image geometric details through
gradient loss optimization.Based on the above, we propose an efficiently Unet
structured network with dual branch, the visual results show that can
effectively preserve the structural details of the original image, we evaluate
benchmarks including SIDD and DND, where SCANet achieves state-of-the-art
performance in PSNR and SSIM while significantly reducing computational cost.</p>
  </details>
</details>
<details>
  <summary>48. <b>标题：Extraction of Vascular Wall in Carotid Ultrasound via a Novel  Boundary-Delineation Network</b></summary>
  <p><b>编号</b>：[211]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.13868</p>
  <p><b>作者</b>：Qinghua Huang,  Lizhi Jia,  Guanqing Ren,  Xiaoyi Wang,  Chunying Liu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Ultrasound imaging plays, vascular wall, Ultrasound imaging, imaging plays, vascular</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Ultrasound imaging plays an important role in the diagnosis of vascular
lesions. Accurate segmentation of the vascular wall is important for the
prevention, diagnosis and treatment of vascular diseases. However, existing
methods have inaccurate localization of the vascular wall boundary.
Segmentation errors occur in discontinuous vascular wall boundaries and dark
boundaries. To overcome these problems, we propose a new boundary-delineation
network (BDNet). We use the boundary refinement module to re-delineate the
boundary of the vascular wall to obtain the correct boundary location. We
designed the feature extraction module to extract and fuse multi-scale features
and different receptive field features to solve the problem of dark boundaries
and discontinuous boundaries. We use a new loss function to optimize the model.
The interference of class imbalance on model optimization is prevented to
obtain finer and smoother boundaries. Finally, to facilitate clinical
applications, we design the model to be lightweight. Experimental results show
that our model achieves the best segmentation results and significantly reduces
memory consumption compared to existing models for the dataset.</p>
  </details>
</details>
<details>
  <summary>49. <b>标题：Extraction of Coronary Vessels in Fluoroscopic X-Ray Sequences Using  Vessel Correspondence Optimization</b></summary>
  <p><b>编号</b>：[213]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.13837</p>
  <p><b>作者</b>：Seung Yeon Shin,  Soochahn Lee,  Kyoung Jin Noh,  Il Dong Yun,  Kyoung Mu Lee</p>
  <p><b>备注</b>：MICCAI 2016</p>
  <p><b>关键词</b>：fluoroscopic x-ray sequences, extract coronary vessels, fluoroscopic x-ray, coronary vessels, extract coronary</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present a method to extract coronary vessels from fluoroscopic x-ray
sequences. Given the vessel structure for the source frame, vessel
correspondence candidates in the subsequent frame are generated by a novel
hierarchical search scheme to overcome the aperture problem. Optimal
correspondences are determined within a Markov random field optimization
framework. Post-processing is performed to extract vessel branches newly
visible due to the inflow of contrast agent. Quantitative and qualitative
evaluation conducted on a dataset of 18 sequences demonstrates the
effectiveness of the proposed method.</p>
  </details>
</details>
<details>
  <summary>50. <b>标题：3D-Morphomics, Morphological Features on CT scans for lung nodule  malignancy diagnosis</b></summary>
  <p><b>编号</b>：[214]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.13830</p>
  <p><b>作者</b>：Elias Munoz,  Pierre Baudot,  Van-Khoa Le,  Charles Voyton,  Benjamin Renoust,  Danny Francis,  Vladimir Groza,  Jean-Christophe Brisset,  Ezequiel Geremia,  Antoine Iannessi,  Yan Liu,  Benoit Huet</p>
  <p><b>备注</b>：10 pages, 7 figures</p>
  <p><b>关键词</b>：Pathologies systematically induce, insufficiently quantified source, systematically induce morphological, AUC, Pathologies systematically</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Pathologies systematically induce morphological changes, thus providing a
major but yet insufficiently quantified source of observables for diagnosis.
The study develops a predictive model of the pathological states based on
morphological features (3D-morphomics) on Computed Tomography (CT) volumes. A
complete workflow for mesh extraction and simplification of an organ's surface
is developed, and coupled with an automatic extraction of morphological
features given by the distribution of mean curvature and mesh energy. An
XGBoost supervised classifier is then trained and tested on the 3D-morphomics
to predict the pathological states. This framework is applied to the prediction
of the malignancy of lung's nodules. On a subset of NLST database with
malignancy confirmed biopsy, using 3D-morphomics only, the classification model
of lung nodules into malignant vs. benign achieves 0.964 of AUC. Three other
sets of classical features are trained and tested, (1) clinical relevant
features gives an AUC of 0.58, (2) 111 radiomics gives an AUC of 0.976, (3)
radiologist ground truth (GT) containing the nodule size, attenuation and
spiculation qualitative annotations gives an AUC of 0.979. We also test the
Brock model and obtain an AUC of 0.826. Combining 3D-morphomics and radiomics
features achieves state-of-the-art results with an AUC of 0.978 where the
3D-morphomics have some of the highest predictive powers. As a validation on a
public independent cohort, models are applied to the LIDC dataset, the
3D-morphomics achieves an AUC of 0.906 and the 3D-morphomics+radiomics achieves
an AUC of 0.958, which ranks second in the challenge among deep models. It
establishes the curvature distributions as efficient features for predicting
lung nodule malignancy and a new method that can be applied directly to
arbitrary computer aided diagnosis task.</p>
  </details>
</details>
<details>
  <summary>51. <b>标题：Deep Learning for Classification of Thyroid Nodules on Ultrasound:  Validation on an Independent Dataset</b></summary>
  <p><b>编号</b>：[216]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.13765</p>
  <p><b>作者</b>：Jingxi Weng,  Benjamin Wildman-Tobriner,  Mateusz Buda,  Jichen Yang,  Lisa M. Ho,  Brian C. Allen,  Wendy L. Ehieli,  Chad M. Miller,  Jikai Zhang,  Maciej A. Mazurowski</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：deep learning algorithm, previously validated deep, deep learning, validated deep learning, learning algorithm</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Objectives: The purpose is to apply a previously validated deep learning
algorithm to a new thyroid nodule ultrasound image dataset and compare its
performances with radiologists. Methods: Prior study presented an algorithm
which is able to detect thyroid nodules and then make malignancy
classifications with two ultrasound images. A multi-task deep convolutional
neural network was trained from 1278 nodules and originally tested with 99
separate nodules. The results were comparable with that of radiologists. The
algorithm was further tested with 378 nodules imaged with ultrasound machines
from different manufacturers and product types than the training cases. Four
experienced radiologists were requested to evaluate the nodules for comparison
with deep learning. Results: The Area Under Curve (AUC) of the deep learning
algorithm and four radiologists were calculated with parametric, binormal
estimation. For the deep learning algorithm, the AUC was 0.70 (95% CI: 0.64 -
0.75). The AUC of radiologists were 0.66 (95% CI: 0.61 - 0.71), 0.67 (95%
CI:0.62 - 0.73), 0.68 (95% CI: 0.63 - 0.73), and 0.66 (95%CI: 0.61 - 0.71).
Conclusion: In the new testing dataset, the deep learning algorithm achieved
similar performances with all four radiologists.</p>
  </details>
</details>
<h1>自然语言处理</h1>
<details>
  <summary>1. <b>标题：Efficient Training of Language Models to Fill in the Middle</b></summary>
  <p><b>编号</b>：[11]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.14255</p>
  <p><b>作者</b>：Mohammad Bavarian,  Heewoo Jun,  Nikolas Tezak,  John Schulman,  Christine McLeavey,  Jerry Tworek,  Mark Chen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：autoregressive language models, apply a straightforward, simply moves, autoregressive language, language models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We show that autoregressive language models can learn to infill text after we
apply a straightforward transformation to the dataset, which simply moves a
span of text from the middle of a document to its end. While this data
augmentation has garnered much interest in recent years, we provide extensive
evidence that training models with a large fraction of data transformed in this
way does not harm the original left-to-right generative capability, as measured
by perplexity and sampling evaluations across a wide range of scales. Given the
usefulness, simplicity, and efficiency of training models to fill-in-the-middle
(FIM), we suggest that future autoregressive language models be trained with
FIM by default. To this end, we run a series of ablations on key
hyperparameters, such as the data transformation frequency, the structure of
the transformation, and the method of selecting the infill span. We use these
ablations to prescribe strong default settings and best practices to train FIM
models. We have released our best infilling model trained with best practices
in our API, and release our infilling benchmarks to aid future research.</p>
  </details>
</details>
<details>
  <summary>2. <b>标题：Measuring Causal Effects of Data Statistics on Language Model's  `Factual' Predictions</b></summary>
  <p><b>编号</b>：[13]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.14251</p>
  <p><b>作者</b>：Yanai Elazar,  Nora Kassner,  Shauli Ravfogel,  Amir Feder,  Abhilasha Ravichander,  Marius Mosbach,  Yonatan Belinkov,  Hinrich Schütze,  Yoav Goldberg</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Large amounts, major reasons, high performance, training data, NLP models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large amounts of training data are one of the major reasons for the high
performance of state-of-the-art NLP models. But what exactly in the training
data causes a model to make a certain prediction? We seek to answer this
question by providing a language for describing how training data influences
predictions, through a causal framework. Importantly, our framework bypasses
the need to retrain expensive models and allows us to estimate causal effects
based on observational data alone. Addressing the problem of extracting factual
knowledge from pretrained language models (PLMs), we focus on simple data
statistics such as co-occurrence counts and show that these statistics do
influence the predictions of PLMs, suggesting that such models rely on shallow
heuristics. Our causal framework and our results demonstrate the importance of
studying datasets and the benefits of causality for understanding NLP models.</p>
  </details>
</details>
<details>
  <summary>3. <b>标题：Claim-Dissector: An Interpretable Fact-Checking System with Joint  Re-ranking and Veracity Prediction</b></summary>
  <p><b>编号</b>：[49]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.14116</p>
  <p><b>作者</b>：Martin Fajcik,  Petr Motlicek,  Pavel Smrz</p>
  <p><b>备注</b>：First release</p>
  <p><b>关键词</b>：final veracity probability, latent variable model, final veracity, learning jointly, latent variable</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present Claim-Dissector: a novel latent variable model for fact-checking
and fact-analysis, which given a claim and a set of retrieved provenances
allows learning jointly: (i) what are the relevant provenances to this claim
(ii) what is the veracity of this claim. We propose to disentangle the
per-provenance relevance probability and its contribution to the final veracity
probability in an interpretable way - the final veracity probability is
proportional to a linear ensemble of per-provenance relevance probabilities.
This way, it can be clearly identified the relevance of which sources
contributes to what extent towards the final probability. We show that our
system achieves state-of-the-art results on FEVER dataset comparable to
two-stage systems typically used in traditional fact-checking pipelines, while
it often uses significantly less parameters and computation.
Our analysis shows that proposed approach further allows to learn not just
which provenances are relevant, but also which provenances lead to supporting
and which toward denying the claim, without direct supervision. This not only
adds interpretability, but also allows to detect claims with conflicting
evidence automatically. Furthermore, we study whether our model can learn
fine-grained relevance cues while using coarse-grained supervision. We show
that our model can achieve competitive sentence-recall while using only
paragraph-level relevance supervision. Finally, traversing towards the finest
granularity of relevance, we show that our framework is capable of identifying
relevance at the token-level. To do this, we present a new benchmark focusing
on token-level interpretability - humans annotate tokens in relevant
provenances they considered essential when making their judgement. Then we
measure how similar are these annotations to tokens our model is focusing on.
Our code, and dataset will be released online.</p>
  </details>
</details>
<details>
  <summary>4. <b>标题：Entity Type Prediction Leveraging Graph Walks and Entity Descriptions</b></summary>
  <p><b>编号</b>：[53]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.14094</p>
  <p><b>作者</b>：Russa Biswas,  Jan Portisch,  Heiko Paulheim,  Harald Sack,  Mehwish Alam</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：information in Knowledge, Knowledge Graphs, entity type information, Entity typing, entity</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The entity type information in Knowledge Graphs (KGs) such as DBpedia,
Freebase, etc. is often incomplete due to automated generation or human
curation. Entity typing is the task of assigning or inferring the semantic type
of an entity in a KG. This paper presents \textit{GRAND}, a novel approach for
entity typing leveraging different graph walk strategies in RDF2vec together
with textual entity descriptions. RDF2vec first generates graph walks and then
uses a language model to obtain embeddings for each node in the graph. This
study shows that the walk generation strategy and the embedding model have a
significant effect on the performance of the entity typing task. The proposed
approach outperforms the baseline approaches on the benchmark datasets DBpedia
and FIGER for entity typing in KGs for both fine-grained and coarse-grained
classes. The results show that the combination of order-aware RDF2vec variants
together with the contextual embeddings of the textual entity descriptions
achieve the best results.</p>
  </details>
</details>
<details>
  <summary>5. <b>标题：CubeMLP: A MLP-based Model for Multimodal Sentiment Analysis and  Depression Estimation</b></summary>
  <p><b>编号</b>：[54]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.14087</p>
  <p><b>作者</b>：Hao Sun,  Hongyi Wang,  Jiaqing Liu,  Yen-Wei Chen,  Lanfen Lin</p>
  <p><b>备注</b>：Accepted by ACM MM 2022</p>
  <p><b>关键词</b>：predict human mental, human mental states, important research topics, topics that aim, aim to predict</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Multimodal sentiment analysis and depression estimation are two important
research topics that aim to predict human mental states using multimodal data.
Previous research has focused on developing effective fusion strategies for
exchanging and integrating mind-related information from different modalities.
Some MLP-based techniques have recently achieved considerable success in a
variety of computer vision tasks. Inspired by this, we explore multimodal
approaches with a feature-mixing perspective in this study. To this end, we
introduce CubeMLP, a multimodal feature processing framework based entirely on
MLP. CubeMLP consists of three independent MLP units, each of which has two
affine transformations. CubeMLP accepts all relevant modality features as input
and mixes them across three axes. After extracting the characteristics using
CubeMLP, the mixed multimodal features are flattened for task predictions. Our
experiments are conducted on sentiment analysis datasets: CMU-MOSI and
CMU-MOSEI, and depression estimation dataset: AVEC2019. The results show that
CubeMLP can achieve state-of-the-art performance with a much lower computing
cost.</p>
  </details>
</details>
<details>
  <summary>6. <b>标题：Raising Student Completion Rates with Adaptive Curriculum and Contextual  Bandits</b></summary>
  <p><b>编号</b>：[76]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.14003</p>
  <p><b>作者</b>：Robert Belfer,  Ekaterina Kochmar,  Iulian Vlad Serban</p>
  <p><b>备注</b>：6 pages, 1 figure, To appear in the Proceedings of the 23rd International Conference on Artificial Intelligence in Education (AIED 2022)</p>
  <p><b>关键词</b>：Intelligent Tutoring System, learning Intelligent Tutoring, Tutoring System, Intelligent Tutoring, adaptive learning Intelligent</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present an adaptive learning Intelligent Tutoring System, which uses
model-based reinforcement learning in the form of contextual bandits to assign
learning activities to students. The model is trained on the trajectories of
thousands of students in order to maximize their exercise completion rates and
continues to learn online, automatically adjusting itself to new activities. A
randomized controlled trial with students shows that our model leads to
superior completion rates and significantly improved student engagement when
compared to other approaches. Our approach is fully-automated unlocking new
opportunities for learning experience personalization.</p>
  </details>
</details>
<details>
  <summary>7. <b>标题：Multi-Step Deductive Reasoning Over Natural Language: An Empirical Study  on Out-of-Distribution Generalisation</b></summary>
  <p><b>编号</b>：[77]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.14000</p>
  <p><b>作者</b>：Qiming Bao,  Alex Yuxuan Peng,  Tim Hartill,  Neset Tan,  Zhenyun Deng,  Michael Witbrock,  Jiamou Liu</p>
  <p><b>备注</b>：10 pages, 3 figures, The 2nd International Joint Conference on Learning & Reasoning and 16th International Workshop on Neural-Symbolic Learning and Reasoning (IJCLR-NeSy 2022)</p>
  <p><b>关键词</b>：Combining deep learning, drawing increasing attention, Combining deep, deep learning, learning with symbolic</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Combining deep learning with symbolic logic reasoning aims to capitalize on
the success of both fields and is drawing increasing attention. Inspired by
DeepLogic, an end-to-end model trained to perform inference on logic programs,
we introduce IMA-GloVe-GA, an iterative neural inference network for multi-step
reasoning expressed in natural language. In our model, reasoning is performed
using an iterative memory neural network based on RNN with a gate attention
mechanism. We evaluate IMA-GloVe-GA on three datasets: PARARULES, CONCEPTRULES
V1 and CONCEPTRULES V2. Experimental results show DeepLogic with gate attention
can achieve higher test accuracy than DeepLogic and other RNN baseline models.
Our model achieves better out-of-distribution generalisation than RoBERTa-Large
when the rules have been shuffled. Furthermore, to address the issue of
unbalanced distribution of reasoning depths in the current multi-step reasoning
datasets, we develop PARARULE-Plus, a large dataset with more examples that
require deeper reasoning steps. Experimental results show that the addition of
PARARULE-Plus can increase the model's performance on examples requiring deeper
reasoning depths. The source code and data are available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>8. <b>标题：Sequence to sequence pretraining for a less-resourced Slovenian language</b></summary>
  <p><b>编号</b>：[81]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.13988</p>
  <p><b>作者</b>：Matej Ulčar,  Marko Robnik-Šikonja</p>
  <p><b>备注</b>：12 pages</p>
  <p><b>关键词</b>：natural language processing, Large pretrained language, Large pretrained, recently conquered, conquered the area</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large pretrained language models have recently conquered the area of natural
language processing. As an alternative to predominant masked language modelling
introduced in BERT, the T5 model has introduced a more general training
objective, namely sequence to sequence transformation, which includes masked
language model but more naturally fits text generation tasks such as machine
translation, summarization, open-domain question answering, text
simplification, dialogue systems, etc. The monolingual variants of T5 models
have been limited to well-resourced languages, while the massively multilingual
T5 model supports 101 languages. In contrast, we trained two different sized
T5-type sequence to sequence models for morphologically rich Slovene language
with much less resources and analyzed their behavior. Concerning classification
tasks, the SloT5 models mostly lag behind the monolingual Slovene SloBERTa
model but are to be considered for the generative tasks.</p>
  </details>
</details>
<details>
  <summary>9. <b>标题：Knowing Where and What: Unified Word Block Pretraining for Document  Understanding</b></summary>
  <p><b>编号</b>：[85]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.13979</p>
  <p><b>作者</b>：Song Tao,  Zijian Wang,  Tiantian Fan,  Canjie Luo,  Can Huang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：challenging to extract, Surrounding Word Prediction, documents, word, complex layouts</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Due to the complex layouts of documents, it is challenging to extract
information for documents. Most previous studies develop multimodal pre-trained
models in a self-supervised way. In this paper, we focus on the embedding
learning of word blocks containing text and layout information, and propose
UTel, a language model with Unified TExt and Layout pre-training. Specifically,
we propose two pre-training tasks: Surrounding Word Prediction (SWP) for the
layout learning, and Contrastive learning of Word Embeddings (CWE) for
identifying different word blocks. Moreover, we replace the commonly used 1D
position embedding with a 1D clipped relative position embedding. In this way,
the joint training of Masked Layout-Language Modeling (MLLM) and two newly
proposed tasks enables the interaction between semantic and spatial features in
a unified way. Additionally, the proposed UTel can process arbitrary-length
sequences by removing the 1D position embedding, while maintaining competitive
performance. Extensive experimental results show UTel learns better joint
representations and achieves superior performance than previous methods on
various downstream tasks, though requiring no image modality. Code is available
at \url{this https URL}.</p>
  </details>
</details>
<details>
  <summary>10. <b>标题：PHEMEPlus: Enriching Social Media Rumour Verification with External  Evidence</b></summary>
  <p><b>编号</b>：[89]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.13970</p>
  <p><b>作者</b>：John Dougrez-Lewis,  Elena Kochkina,  M. Arana-Catania,  Maria Liakata,  Yulan He</p>
  <p><b>备注</b>：10 pages, 1 figure, 5 tables, presented in the Fifth Fact Extraction and VERification Workshop (FEVER). 2022</p>
  <p><b>关键词</b>：verification utilises signals, social media, signals from posts, users involved, utilises signals</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Work on social media rumour verification utilises signals from posts, their
propagation and users involved. Other lines of work target identifying and
fact-checking claims based on information from Wikipedia, or trustworthy news
articles without considering social media context. However works combining the
information from social media with external evidence from the wider web are
lacking. To facilitate research in this direction, we release a novel dataset,
PHEMEPlus, an extension of the PHEME benchmark, which contains social media
conversations as well as relevant external evidence for each rumour. We
demonstrate the effectiveness of incorporating such evidence in improving
rumour verification models. Additionally, as part of the evidence collection,
we evaluate various ways of query formulation to identify the most effective
method.</p>
  </details>
</details>
<details>
  <summary>11. <b>标题：Neural Architecture Search on Efficient Transformers and Beyond</b></summary>
  <p><b>编号</b>：[94]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.13955</p>
  <p><b>作者</b>：Zexiang Liu,  Dong Li,  Kaiyue Lu,  Zhen Qin,  Weixuan Sun,  Jiacheng Xu,  Yiran Zhong</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：numerous efficient Transformers, efficient Transformers, standard Transformers caused, Softmax attention, Transformer</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recently, numerous efficient Transformers have been proposed to reduce the
quadratic computational complexity of standard Transformers caused by the
Softmax attention. However, most of them simply swap Softmax with an efficient
attention mechanism without considering the customized architectures specially
for the efficient attention. In this paper, we argue that the handcrafted
vanilla Transformer architectures for Softmax attention may not be suitable for
efficient Transformers. To address this issue, we propose a new framework to
find optimal architectures for efficient Transformers with the neural
architecture search (NAS) technique. The proposed method is validated on
popular machine translation and image classification tasks. We observe that the
optimal architecture of the efficient Transformer has the reduced computation
compared with that of the standard Transformer, but the general accuracy is
less comparable. It indicates that the Softmax attention and efficient
attention have their own distinctions but neither of them can simultaneously
balance the accuracy and efficiency well. This motivates us to mix the two
types of attention to reduce the performance imbalance. Besides the search
spaces that commonly used in existing NAS Transformer approaches, we propose a
new search space that allows the NAS algorithm to automatically search the
attention variants along with architectures. Extensive experiments on WMT' 14
En-De and CIFAR-10 demonstrate that our searched architecture maintains
comparable accuracy to the standard Transformer with notably improved
computational efficiency.</p>
  </details>
</details>
<details>
  <summary>12. <b>标题：An Interpretability Evaluation Benchmark for Pre-trained Language Models</b></summary>
  <p><b>编号</b>：[96]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.13948</p>
  <p><b>作者</b>：Yaozong Shen,  Lijie Wang,  Ying Chen,  Xinyan Xiao,  Jing Liu,  Hua Wu</p>
  <p><b>备注</b>：10 pages, 2 figures</p>
  <p><b>关键词</b>：brought great improvements, NLP tasks, pre-trained language models, language models, brought great</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>While pre-trained language models (LMs) have brought great improvements in
many NLP tasks, there is increasing attention to explore capabilities of LMs
and interpret their predictions. However, existing works usually focus only on
a certain capability with some downstream tasks. There is a lack of datasets
for directly evaluating the masked word prediction performance and the
interpretability of pre-trained LMs. To fill in the gap, we propose a novel
evaluation benchmark providing with both English and Chinese annotated data. It
tests LMs abilities in multiple dimensions, i.e., grammar, semantics,
knowledge, reasoning and computation. In addition, it provides carefully
annotated token-level rationales that satisfy sufficiency and compactness. It
contains perturbed instances for each original instance, so as to use the
rationale consistency under perturbations as the metric for faithfulness, a
perspective of interpretability. We conduct experiments on several widely-used
pre-trained LMs. The results show that they perform very poorly on the
dimensions of knowledge and computation. And their plausibility in all
dimensions is far from satisfactory, especially when the rationale is short. In
addition, the pre-trained LMs we evaluated are not robust on syntax-aware data.
We will release this evaluation benchmark at \url{http://xyz}, and hope it can
facilitate the research progress of pre-trained LMs.</p>
  </details>
</details>
<details>
  <summary>13. <b>标题：MLRIP: Pre-training a military language representation model with  informative factual knowledge and professional knowledge base</b></summary>
  <p><b>编号</b>：[102]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.13929</p>
  <p><b>作者</b>：Hui Li,  Xuekang Yang,  Xin Zhao,  Lin Yu,  Jiping Zheng,  Wei Sun</p>
  <p><b>备注</b>：11 pages, 6 figures</p>
  <p><b>关键词</b>：pre-trained language models, Incorporating prior knowledge, knowledge-driven NLP tasks, Incorporating prior, relation extraction</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Incorporating prior knowledge into pre-trained language models has proven to
be effective for knowledge-driven NLP tasks, such as entity typing and relation
extraction. Current pre-training procedures usually inject external knowledge
into models by using knowledge masking, knowledge fusion and knowledge
replacement. However, factual information contained in the input sentences have
not been fully mined, and the external knowledge for injecting have not been
strictly checked. As a result, the context information cannot be fully
exploited and extra noise will be introduced or the amount of knowledge
injected is limited. To address these issues, we propose MLRIP, which modifies
the knowledge masking strategies proposed by ERNIE-Baidu, and introduce a
two-stage entity replacement strategy. Extensive experiments with comprehensive
analyses illustrate the superiority of MLRIP over BERT-based models in military
knowledge-driven NLP tasks.</p>
  </details>
</details>
<details>
  <summary>14. <b>标题：Persona-Knowledge Dialogue Multi-Context Retrieval and Enhanced Decoding  Methods</b></summary>
  <p><b>编号</b>：[104]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.13919</p>
  <p><b>作者</b>：Min Sik Oh,  Min Sang Kim</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Knowledge dual context, task introduced recently, dual context open-domain, context open-domain chat, Persona and Knowledge</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Persona and Knowledge dual context open-domain chat is a novel dialogue
generation task introduced recently. While Persona and Knowledge is each
interesting context of open-domain dialogue, the combination of both has not
been well studied. We tackle Persona-Knowledge identification and response
generation tasks in this paper. We design an informed data augmentation
strategy that is compatible with neural Q&A retrieval models. With the
augmented data, we perform permutative Persona-Knowledge evaluation and
successive Persona search fine-tuning. Furthermore, we perform dialogue
generation with various decoding techniques and illustrate crucial elements. We
achieve SOTA across official metrics with 93.99% Grounding accuracy average and
23.62 SacreBLEU score.</p>
  </details>
</details>
<details>
  <summary>15. <b>标题：CompText: Visualizing, Comparing & Understanding Text Corpus</b></summary>
  <p><b>编号</b>：[166]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.13771</p>
  <p><b>作者</b>：Suvi Varshney,  Divjeet Singh Jas</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Natural Language Processing, Language Processing, Natural Language, practice in Natural, topics</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A common practice in Natural Language Processing (NLP) is to visualize the
text corpus without reading through the entire literature, still grasping the
central idea and key points described. For a long time, researchers focused on
extracting topics from the text and visualizing them based on their relative
significance in the corpus. However, recently, researchers started coming up
with more complex systems that not only expose the topics of the corpus but
also word closely related to the topic to give users a holistic view. These
detailed visualizations spawned research on comparing text corpora based on
their visualization. Topics are often compared to idealize the difference
between corpora. However, to capture greater semantics from different corpora,
researchers have started to compare texts based on the sentiment of the topics
related to the text. Comparing the words carrying the most weightage, we can
get an idea about the important topics for corpus. There are multiple existing
texts comparing methods present that compare topics rather than sentiments but
we feel that focusing on sentiment-carrying words would better compare the two
corpora. Since only sentiments can explain the real feeling of the text and not
just the topic, topics without sentiments are just nouns. We aim to
differentiate the corpus with a focus on sentiment, as opposed to comparing all
the words appearing in the two corpora. The rationale behind this is, that the
two corpora do not many have identical words for side-by-side comparison, so
comparing the sentiment words gives us an idea of how the corpora are appealing
to the emotions of the reader. We can argue that the entropy or the
unexpectedness and divergence of topics should also be of importance and help
us to identify key pivot points and the importance of certain topics in the
corpus alongside relative sentiment.</p>
  </details>
</details>
<details>
  <summary>16. <b>标题：The Leaf Clinical Trials Corpus: a new resource for query generation  from clinical trial eligibility criteria</b></summary>
  <p><b>编号</b>：[170]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.13757</p>
  <p><b>作者</b>：Nicholas J Dobbins,  Tony Mullen,  Ozlem Uzuner,  Meliha Yetisgen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Identifying cohorts, medical conditions, cohorts of patients, patients based, critical to recruitment</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Identifying cohorts of patients based on eligibility criteria such as medical
conditions, procedures, and medication use is critical to recruitment for
clinical trials. Such criteria are often most naturally described in free-text,
using language familiar to clinicians and researchers. In order to identify
potential participants at scale, these criteria must first be translated into
queries on clinical databases, which can be labor-intensive and error-prone.
Natural language processing (NLP) methods offer a potential means of such
conversion into database queries automatically. However they must first be
trained and evaluated using corpora which capture clinical trials criteria in
sufficient detail. In this paper, we introduce the Leaf Clinical Trials (LCT)
corpus, a human-annotated corpus of over 1,000 clinical trial eligibility
criteria descriptions using highly granular structured labels capturing a range
of biomedical phenomena. We provide details of our schema, annotation process,
corpus quality, and statistics. Additionally, we present baseline information
extraction results on this corpus as benchmarks for future work.</p>
  </details>
</details>
<h1>机器学习</h1>
<details>
  <summary>1. <b>标题：Depth Field Networks for Generalizable Multi-view Scene Representation</b></summary>
  <p><b>编号</b>：[3]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.14287</p>
  <p><b>作者</b>：Vitor Guizilini,  Igor Vasiljevic,  Jiading Fang,  Rares Ambrus,  Greg Shakhnarovich,  Matthew Walter,  Adrien Gaidon</p>
  <p><b>备注</b>：Accepted to ECCV 2022. Project page: this https URL</p>
  <p><b>关键词</b>：computer vision leverages, vision leverages learning, mapping image data, boost geometric reasoning, computer vision</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Modern 3D computer vision leverages learning to boost geometric reasoning,
mapping image data to classical structures such as cost volumes or epipolar
constraints to improve matching. These architectures are specialized according
to the particular problem, and thus require significant task-specific tuning,
often leading to poor domain generalization performance. Recently, generalist
Transformer architectures have achieved impressive results in tasks such as
optical flow and depth estimation by encoding geometric priors as inputs rather
than as enforced constraints. In this paper, we extend this idea and propose to
learn an implicit, multi-view consistent scene representation, introducing a
series of 3D data augmentation techniques as a geometric inductive prior to
increase view diversity. We also show that introducing view synthesis as an
auxiliary task further improves depth estimation. Our Depth Field Networks
(DeFiNe) achieve state-of-the-art results in stereo and video depth estimation
without explicit geometric constraints, and improve on zero-shot domain
generalization by a wide margin.</p>
  </details>
</details>
<details>
  <summary>2. <b>标题：Cryptographic Hardness of Learning Halfspaces with Massart Noise</b></summary>
  <p><b>编号</b>：[9]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.14266</p>
  <p><b>作者</b>：Ilias Diakonikolas,  Daniel M. Kane,  Pasin Manurangsi,  Lisheng Ren</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Massart noise, study the complexity, mathbf, Massart halfspace learner, Massart</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We study the complexity of PAC learning halfspaces in the presence of Massart
noise. In this problem, we are given i.i.d. labeled examples $(\mathbf{x}, y)
\in \mathbb{R}^N \times \{ \pm 1\}$, where the distribution of $\mathbf{x}$ is
arbitrary and the label $y$ is a Massart corruption of $f(\mathbf{x})$, for an
unknown halfspace $f: \mathbb{R}^N \to \{ \pm 1\}$, with flipping probability
$\eta(\mathbf{x}) \leq \eta < 1/2$. The goal of the learner is to compute a
hypothesis with small 0-1 error. Our main result is the first computational
hardness result for this learning problem. Specifically, assuming the (widely
believed) subexponential-time hardness of the Learning with Errors (LWE)
problem, we show that no polynomial-time Massart halfspace learner can achieve
error better than $\Omega(\eta)$, even if the optimal 0-1 error is small,
namely $\mathrm{OPT} = 2^{-\log^{c} (N)}$ for any universal constant $c \in (0,
1)$. Prior work had provided qualitatively similar evidence of hardness in the
Statistical Query model. Our computational hardness result essentially resolves
the polynomial PAC learnability of Massart halfspaces, by showing that known
efficient learning algorithms for the problem are nearly best possible.</p>
  </details>
</details>
<details>
  <summary>3. <b>标题：Exploiting and Defending Against the Approximate Linearity of Apple's  NeuralHash</b></summary>
  <p><b>编号</b>：[10]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.14258</p>
  <p><b>作者</b>：Jagdeep Singh Bhatia,  Kevin Meng</p>
  <p><b>备注</b>：Accepted to the ML4Cyber Workshop at ICML 2022</p>
  <p><b>关键词</b>：Perceptual hashes map, identical semantic content, hashes map images, mapping semantically-different images, Perceptual hashes</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Perceptual hashes map images with identical semantic content to the same
$n$-bit hash value, while mapping semantically-different images to different
hashes. These algorithms carry important applications in cybersecurity such as
copyright infringement detection, content fingerprinting, and surveillance.
Apple's NeuralHash is one such system that aims to detect the presence of
illegal content on users' devices without compromising consumer privacy. We
make the surprising discovery that NeuralHash is approximately linear, which
inspires the development of novel black-box attacks that can (i) evade
detection of "illegal" images, (ii) generate near-collisions, and (iii) leak
information about hashed images, all without access to model parameters. These
vulnerabilities pose serious threats to NeuralHash's security goals; to address
them, we propose a simple fix using classical cryptographic standards.</p>
  </details>
</details>
<details>
  <summary>4. <b>标题：Improving the Performance of Robust Control through Event-Triggered  Learning</b></summary>
  <p><b>编号</b>：[12]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.14252</p>
  <p><b>作者</b>：Alexander von Rohr,  Friedrich Solowjow,  Sebastian Trimpe</p>
  <p><b>备注</b>：To appear in the proceedings of the 61st IEEE Conference on Decision and Control</p>
  <p><b>关键词</b>：feedback loops designed, controllers ensure stability, Robust controllers ensure, ensure stability, stability in feedback</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Robust controllers ensure stability in feedback loops designed under
uncertainty but at the cost of performance. Model uncertainty in time-invariant
systems can be reduced by recently proposed learning-based methods, thus
improving the performance of robust controllers using data. However, in
practice, many systems also exhibit uncertainty in the form of changes over
time, e.g., due to weight shifts or wear and tear, leading to decreased
performance or instability of the learning-based controller. We propose an
event-triggered learning algorithm that decides when to learn in the face of
uncertainty in the LQR problem with rare or slow changes. Our key idea is to
switch between robust and learned controllers. For learning, we first
approximate the optimal length of the learning phase via Monte-Carlo
estimations using a probabilistic model. We then design a statistical test for
uncertain systems based on the moment-generating function of the LQR cost. The
test detects changes in the system under control and triggers re-learning when
control performance deteriorates due to system changes. We demonstrate improved
performance over a robust controller baseline in a numerical example.</p>
  </details>
</details>
<details>
  <summary>5. <b>标题：Electricity Price Forecasting Model based on Gated Recurrent Units</b></summary>
  <p><b>编号</b>：[18]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.14225</p>
  <p><b>作者</b>：Nafise Rezaei,  Roozbeh Rajabi,  Abouzar Estebsari</p>
  <p><b>备注</b>：5 pages, EEEIC 2022 conference</p>
  <p><b>关键词</b>：demand response programs, electricity price, smart grids, power systems, participation of consumers</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The participation of consumers and producers in demand response programs has
increased in smart grids, which reduces investment and operation costs of power
systems. Also, with the advent of renewable energy sources, the electricity
market is becoming more complex and unpredictable. To effectively implement
demand response programs, forecasting the future price of electricity is very
crucial for producers in the electricity market. Electricity prices are very
volatile and change under the influence of various factors such as temperature,
wind speed, rainfall, intensity of commercial and daily activities, etc.
Therefore, considering the influencing factors as dependent variables can
increase the accuracy of the forecast. In this paper, a model for electricity
price forecasting is presented based on Gated Recurrent Units. The electrical
load consumption is considered as an input variable in this model. Noise in
electricity price seriously reduces the efficiency and effectiveness of
analysis. Therefore, an adaptive noise reducer is integrated into the model for
noise reduction. The SAEs are then used to extract features from the de-noised
electricity price. Finally, the de-noised features are fed into the GRU to
train predictor. Results on real dataset shows that the proposed methodology
can perform effectively in prediction of electricity price.</p>
  </details>
</details>
<details>
  <summary>6. <b>标题：Gender In Gender Out: A Closer Look at User Attributes in Context-Aware  Recommendation</b></summary>
  <p><b>编号</b>：[21]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.14218</p>
  <p><b>作者</b>：Manel Slokom,  Özlem Özgöbek,  Martha Larson</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：recommender system community, paper studies user, studies user attributes, user attributes, paper studies</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper studies user attributes in light of current concerns in the
recommender system community: diversity, coverage, calibration, and data
minimization. In experiments with a conventional context-aware recommender
system that leverages side information, we show that user attributes do not
always improve recommendation. Then, we demonstrate that user attributes can
negatively impact diversity and coverage. Finally, we investigate the amount of
information about users that ``survives'' from the training data into the
recommendation lists produced by the recommender. This information is a weak
signal that could in the future be exploited for calibration or studied further
as a privacy leak.</p>
  </details>
</details>
<details>
  <summary>7. <b>标题：Regret Minimization and Convergence to Equilibria in General-sum Markov  Games</b></summary>
  <p><b>编号</b>：[22]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.14211</p>
  <p><b>作者</b>：Liad Erez,  Tal Lancewicki,  Uri Sherman,  Tomer Koren,  Yishay Mansour</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：recent impossibility results, impossibility results establish, Markov games, regret minimization, abundance of recent</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>An abundance of recent impossibility results establish that regret
minimization in Markov games with adversarial opponents is both statistically
and computationally intractable. Nevertheless, none of these results preclude
the possibility of regret minimization under the assumption that all parties
adopt the same learning procedure. In this work, we present the first (to our
knowledge) algorithm for learning in general-sum Markov games that provides
sublinear regret guarantees when executed by all agents. The bounds we obtain
are for swap regret, and thus, along the way, imply convergence to a correlated
equilibrium. Our algorithm is decentralized, computationally efficient, and
does not require any communication between agents. Our key observation is that
online learning via policy optimization in Markov games essentially reduces to
a form of weighted regret minimization, with unknown weights determined by the
path length of the agents' policy sequence. Consequently, controlling the path
length leads to weighted regret objectives for which sufficiently adaptive
algorithms provide sublinear regret guarantees.</p>
  </details>
</details>
<details>
  <summary>8. <b>标题：Progressive Voronoi Diagram Subdivision: Towards A Holistic Geometric  Framework for Exemplar-free Class-Incremental Learning</b></summary>
  <p><b>编号</b>：[26]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.14202</p>
  <p><b>作者</b>：Chunwei Ma,  Zhanghexuan Ji,  Ziyun Huang,  Yan Shen,  Mingchen Gao,  Jinhui Xu</p>
  <p><b>备注</b>：Preprint. Under review. Up to 37.09% improvement for Class-Incremental Continual Learning. Code freely available!</p>
  <p><b>关键词</b>：Exemplar-free Class-incremental Learning, Deep Neural Networks, Class-incremental Learning, Neural Networks, causing catastrophic forgetting</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Exemplar-free Class-incremental Learning (CIL) is a challenging problem
because rehearsing data from previous phases is strictly prohibited, causing
catastrophic forgetting of Deep Neural Networks (DNNs). In this paper, we
present iVoro, a holistic framework for CIL, derived from computational
geometry. We found Voronoi Diagram (VD), a classical model for space
subdivision, is especially powerful for solving the CIL problem, because VD
itself can be constructed favorably in an incremental manner -- the newly added
sites (classes) will only affect the proximate classes, making the
non-contiguous classes hardly forgettable. Further, in order to find a better
set of centers for VD construction, we colligate DNN with VD using Power
Diagram and show that the VD structure can be optimized by integrating local
DNN models using a divide-and-conquer algorithm. Moreover, our VD construction
is not restricted to the deep feature space, but is also applicable to multiple
intermediate feature spaces, promoting VD to be multi-centered VD (CIVD) that
efficiently captures multi-grained features from DNN. Importantly, iVoro is
also capable of handling uncertainty-aware test-time Voronoi cell assignment
and has exhibited high correlations between geometric uncertainty and
predictive accuracy (up to ~0.9). Putting everything together, iVoro achieves
up to 25.26%, 37.09%, and 33.21% improvements on CIFAR-100, TinyImageNet, and
ImageNet-Subset, respectively, compared to the state-of-the-art non-exemplar
CIL approaches. In conclusion, iVoro enables highly accurate,
privacy-preserving, and geometrically interpretable CIL that is particularly
useful when cross-phase data sharing is forbidden, e.g. in medical
applications. Our code is available at this https URL.</p>
  </details>
</details>
<details>
  <summary>9. <b>标题：CrAM: A Compression-Aware Minimizer</b></summary>
  <p><b>编号</b>：[27]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.14200</p>
  <p><b>作者</b>：Alexandra Peste,  Adrian Vladu,  Dan Alistarh,  Christoph H. Lampert</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：deep neural networks, neural networks, highly-accurate and easily-compressible, examine the question, SGD-based optimization</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We examine the question of whether SGD-based optimization of deep neural
networks (DNNs) can be adapted to produce models which are both highly-accurate
and easily-compressible. We propose a new compression-aware minimizer dubbed
CrAM, which modifies the SGD training iteration in a principled way, in order
to produce models whose local loss behavior is stable under compression
operations such as weight pruning or quantization. Experimental results on
standard image classification tasks show that CrAM produces dense models that
can be more accurate than standard SGD-type baselines, but which are
surprisingly stable under weight pruning: for instance, for ResNet50 on
ImageNet, CrAM-trained models can lose up to 70% of their weights in one shot
with only minor accuracy loss.</p>
  </details>
</details>
<details>
  <summary>10. <b>标题：RHA-Net: An Encoder-Decoder Network with Residual Blocks and Hybrid  Attention Mechanisms for Pavement Crack Segmentation</b></summary>
  <p><b>编号</b>：[32]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.14166</p>
  <p><b>作者</b>：Guijie Zhu,  Zhun Fan,  Jiacheng Liu,  Duan Yuan,  Peili Ma,  Meihua Wang,  Weihua Sheng,  Kelvin C. P. Wang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：pavement condition evaluation, surface data play, pavement crack segmentation, condition evaluation, pavement crack</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The acquisition and evaluation of pavement surface data play an essential
role in pavement condition evaluation. In this paper, an efficient and
effective end-to-end network for automatic pavement crack segmentation, called
RHA-Net, is proposed to improve the pavement crack segmentation accuracy. The
RHA-Net is built by integrating residual blocks (ResBlocks) and hybrid
attention blocks into the encoder-decoder architecture. The ResBlocks are used
to improve the ability of RHA-Net to extract high-level abstract features. The
hybrid attention blocks are designed to fuse both low-level features and
high-level features to help the model focus on correct channels and areas of
cracks, thereby improving the feature presentation ability of RHA-Net. An image
data set containing 789 pavement crack images collected by a self-designed
mobile robot is constructed and used for training and evaluating the proposed
model. Compared with other state-of-the-art networks, the proposed model
achieves better performance and the functionalities of adding residual blocks
and hybrid attention mechanisms are validated in a comprehensive ablation
study. Additionally, a light-weighted version of the model generated by
introducing depthwise separable convolution achieves better a performance and a
much faster processing speed with 1/30 of the number of U-Net parameters. The
developed system can segment pavement crack in real-time on an embedded device
Jetson TX2 (25 FPS). The video taken in real-time experiments is released at
this https URL.</p>
  </details>
</details>
<details>
  <summary>11. <b>标题：A Probabilistic Framework for Estimating the Risk of Pedestrian-Vehicle  Conflicts at Intersections</b></summary>
  <p><b>编号</b>：[39]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.14145</p>
  <p><b>作者</b>：Pei Li,  Huizhong Guo,  Shan Bao,  Arpan Kusari</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：important research topic, Pedestrian safety, pedestrian safety proactively, important research, research topic</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Pedestrian safety has become an important research topic among various
studies due to the increased number of pedestrian-involved crashes. To evaluate
pedestrian safety proactively, surrogate safety measures (SSMs) have been
widely used in traffic conflict-based studies as they do not require historical
crashes as inputs. However, most existing SSMs were developed based on the
assumption that road users would maintain constant velocity and direction. Risk
estimations based on this assumption are less unstable, more likely to be
exaggerated, and unable to capture the evasive maneuvers of drivers.
Considering the limitations among existing SSMs, this study proposes a
probabilistic framework for estimating the risk of pedestrian-vehicle conflicts
at intersections. The proposed framework loosen restrictions of constant speed
by predicting trajectories using a Gaussian Process Regression and accounts for
the different possible driver maneuvers with a Random Forest model. Real-world
LiDAR data collected at an intersection was used to evaluate the performance of
the proposed framework. The newly developed framework is able to identify all
pedestrian-vehicle conflicts. Compared to the Time-to-Collision, the proposed
framework provides a more stable risk estimation and captures the evasive
maneuvers of vehicles. Moreover, the proposed framework does not require
expensive computation resources, which makes it an ideal choice for real-time
proactive pedestrian safety solutions at intersections.</p>
  </details>
</details>
<details>
  <summary>12. <b>标题：Playing a 2D Game Indefinitely using NEAT and Reinforcement Learning</b></summary>
  <p><b>编号</b>：[40]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.14140</p>
  <p><b>作者</b>：Jerin Paul Selvan,  Pravin S. Game</p>
  <p><b>备注</b>：5 pages, 7 figures, 3 tables</p>
  <p><b>关键词</b>：test them.The creation, obstacles.The environment chosen, random heights.The bird, test them.The performance, pipes themselves.The actions</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>For over a decade now, robotics and the use of artificial agents have become
a common thing.Testing the performance of new path finding or search space
optimization algorithms has also become a challenge as they require simulation
or an environment to test them.The creation of artificial environments with
artificial agents is one of the methods employed to test such algorithms.Games
have also become an environment to test them.The performance of the algorithms
can be compared by using artificial agents that will behave according to the
algorithm in the environment they are put in.The performance parameters can be,
how quickly the agent is able to differentiate between rewarding actions and
hostile actions.This can be tested by placing the agent in an environment with
different types of hurdles and the goal of the agent is to reach the farthest
by taking decisions on actions that will lead to avoiding all the obstacles.The
environment chosen is a game called "Flappy Bird".The goal of the game is to
make the bird fly through a set of pipes of random heights.The bird must go in
between these pipes and must not hit the top, the bottom, or the pipes
themselves.The actions that the bird can take are either to flap its wings or
drop down with gravity.The algorithms that are enforced on the artificial
agents are NeuroEvolution of Augmenting Topologies (NEAT) and Reinforcement
Learning.The NEAT algorithm takes an "N" initial population of artificial
agents.They follow genetic algorithms by considering an objective function,
crossover, mutation, and augmenting topologies.Reinforcement learning, on the
other hand, remembers the state, the action taken at that state, and the reward
received for the action taken using a single agent and a Deep Q-learning
Network.The performance of the NEAT algorithm improves as the initial
population of the artificial agents is increased.</p>
  </details>
</details>
<details>
  <summary>13. <b>标题：Towards Robust Ad Hoc Teamwork Agents By Creating Diverse Training  Teammates</b></summary>
  <p><b>编号</b>：[42]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.14138</p>
  <p><b>作者</b>：Arrasy Rahman,  Elliot Fosong,  Ignacio Carlucho,  Stefano V. Albrecht</p>
  <p><b>备注</b>：Workshop on Ad Hoc Teamwork (WAHT) at IJCAI 2022</p>
  <p><b>关键词</b>：hoc teamwork, prior coordination, problem of creating, collaborate with previously, previously unseen teammates</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Ad hoc teamwork (AHT) is the problem of creating an agent that must
collaborate with previously unseen teammates without prior coordination. Many
existing AHT methods can be categorised as type-based methods, which require a
set of predefined teammates for training. Designing teammate types for training
is a challenging issue that determines the generalisation performance of agents
when dealing with teammate types unseen during training. In this work, we
propose a method to discover diverse teammate types based on maximising best
response diversity metrics. We show that our proposed approach yields teammate
types that require a wider range of best responses from the learner during
collaboration, which potentially improves the robustness of a learner's
performance in AHT compared to alternative methods.</p>
  </details>
</details>
<details>
  <summary>14. <b>标题：Learning unseen coexisting attractors</b></summary>
  <p><b>编号</b>：[43]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.14133</p>
  <p><b>作者</b>：Daniel J. Gauthier,  Ingo Fischer,  André Röhm</p>
  <p><b>备注</b>：8 pages, 7 figures</p>
  <p><b>关键词</b>：traditional reservoir computer, next-generation reservoir computing, Reservoir computing, generate a surrogate, surrogate model</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Reservoir computing is a machine learning approach that can generate a
surrogate model of a dynamical system. It can learn the underlying dynamical
system using fewer trainable parameters and hence smaller training data sets
than competing approaches. Recently, a simpler formulation, known as
next-generation reservoir computing, removes many algorithm metaparameters and
identifies a well-performing traditional reservoir computer, thus simplifying
training even further. Here, we study a particularly challenging problem of
learning a dynamical system that has both disparate time scales and multiple
co-existing dynamical states (attractors). We compare the next-generation and
traditional reservoir computer using metrics quantifying the geometry of the
ground-truth and forecasted attractors. For the studied four-dimensional
system, the next-generation reservoir computing approach uses $\sim 1.7 \times$
less training data, requires $10^3 \times$ shorter `warm up' time, has fewer
metaparameters, and has an $\sim 100\times$ higher accuracy in predicting the
co-existing attractor characteristics in comparison to a traditional reservoir
computer. Furthermore, we demonstrate that it predicts the basin of attraction
with high accuracy. This work lends further support to the superior learning
ability of this new machine learning algorithm for dynamical systems.</p>
  </details>
</details>
<details>
  <summary>15. <b>标题：FedVARP: Tackling the Variance Due to Partial Client Participation in  Federated Learning</b></summary>
  <p><b>编号</b>：[45]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.14130</p>
  <p><b>作者</b>：Divyansh Jhunjhunwala,  Pranay Sharma,  Aushim Nagarkatti,  Gauri Joshi</p>
  <p><b>备注</b>：Accepted to UAI 2022</p>
  <p><b>关键词</b>：Data-heterogeneous federated learning, performing multiple local, drift error caused, participation error caused, error caused</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Data-heterogeneous federated learning (FL) systems suffer from two
significant sources of convergence error: 1) client drift error caused by
performing multiple local optimization steps at clients, and 2) partial client
participation error caused by the fact that only a small subset of the edge
clients participate in every training round. We find that among these, only the
former has received significant attention in the literature. To remedy this, we
propose FedVARP, a novel variance reduction algorithm applied at the server
that eliminates error due to partial client participation. To do so, the server
simply maintains in memory the most recent update for each client and uses
these as surrogate updates for the non-participating clients in every round.
Further, to alleviate the memory requirement at the server, we propose a novel
clustering-based variance reduction algorithm ClusterFedVARP. Unlike previously
proposed methods, both FedVARP and ClusterFedVARP do not require additional
computation at clients or communication of additional optimization parameters.
Through extensive experiments, we show that FedVARP outperforms
state-of-the-art methods, and ClusterFedVARP achieves performance comparable to
FedVARP with much less memory requirements.</p>
  </details>
</details>
<details>
  <summary>16. <b>标题：Graph Neural Networks to Predict Sports Outcomes</b></summary>
  <p><b>编号</b>：[47]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.14124</p>
  <p><b>作者</b>：Peter Xenopoulos,  Claudio Silva</p>
  <p><b>备注</b>：Accepted as a short paper (6 pages) to 2021 IEEE International Conference on Big Data</p>
  <p><b>关键词</b>：important for teams, player tracking data, tracking data, Predicting outcomes, player tracking</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Predicting outcomes in sports is important for teams, leagues, bettors,
media, and fans. Given the growing amount of player tracking data, sports
analytics models are increasingly utilizing spatially-derived features built
upon player tracking data. However, player-specific information, such as
location, cannot readily be included as features themselves, since common
modeling techniques rely on vector input. Accordingly, spatially-derived
features are commonly constructed in relation to anchor objects, such as the
distance to a ball or goal, through global feature aggregations, or via
role-assignment schemes, where players are designated a distinct role in the
game. In doing so, we sacrifice inter-player and local relationships in favor
of global ones. To address this issue, we introduce a sport-agnostic
graph-based representation of game states. We then use our proposed graph
representation as input to graph neural networks to predict sports outcomes.
Our approach preserves permutation invariance and allows for flexible player
interaction weights. We demonstrate how our method provides statistically
significant improvements over the state of the art for prediction tasks in both
American football and esports, reducing test set loss by 9% and 20%,
respectively. Additionally, we show how our model can be used to answer "what
if" questions in sports and to visualize relationships between players.</p>
  </details>
</details>
<details>
  <summary>17. <b>标题：PEA: Improving the Performance of ReLU Networks for Free by Using  Progressive Ensemble Activations</b></summary>
  <p><b>编号</b>：[57]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.14074</p>
  <p><b>作者</b>：Ákos Utasi</p>
  <p><b>备注</b>：Published in Efficient Deep Learning for Computer Vision (ECV) CVPR Workshop 2022</p>
  <p><b>关键词</b>：superior performance compared, show superior performance, recent years, activations, ReLU</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In recent years novel activation functions have been proposed to improve the
performance of neural networks, and they show superior performance compared to
the ReLU counterpart. However, there are environments, where the availability
of complex activations is limited, and usually only the ReLU is supported. In
this paper we propose methods that can be used to improve the performance of
ReLU networks by using these efficient novel activations during model training.
More specifically, we propose ensemble activations that are composed of the
ReLU and one of these novel activations. Furthermore, the coefficients of the
ensemble are neither fixed nor learned, but are progressively updated during
the training process in a way that by the end of the training only the ReLU
activations remain active in the network and the other activations can be
removed. This means that in inference time the network contains ReLU
activations only. We perform extensive evaluations on the ImageNet
classification task using various compact network architectures and various
novel activation functions. Results show 0.2-0.8% top-1 accuracy gain, which
confirms the applicability of the proposed methods. Furthermore, we demonstrate
the proposed methods on semantic segmentation and we boost the performance of a
compact segmentation network by 0.34% mIOU on the Cityscapes dataset.</p>
  </details>
</details>
<details>
  <summary>18. <b>标题：Hardness of Agnostically Learning Halfspaces from Worst-Case Lattice  Problems</b></summary>
  <p><b>编号</b>：[68]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.14030</p>
  <p><b>作者</b>：Stefan Tiegel</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：approximating shortest vectors, agnostic model based, approximating shortest, agnostic model, shortest vectors</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We show hardness of improperly learning halfspaces in the agnostic model
based on worst-case lattice problems, e.g., approximating shortest vectors
within polynomial factors. In particular, we show that under this assumption
there is no efficient algorithm that outputs any binary hypothesis, not
necessarily a halfspace, achieving misclassfication error better than $\frac 1
2 - \epsilon$ even if the optimal misclassification error is as small is as
small as $\delta$. Here, $\epsilon$ can be smaller than the inverse of any
polynomial in the dimension and $\delta$ as small as
$\mathrm{exp}\left(-\Omega\left(\log^{1-c}(d)\right)\right)$, where $0 < c < 1$
is an arbitrary constant and $d$ is the dimension.
Previous hardness results [Daniely16] of this problem were based on
average-case complexity assumptions, specifically, variants of Feige's random
3SAT hypothesis. Our work gives the first hardness for this problem based on a
worst-case complexity assumption. It is inspired by a sequence of recent works
showing hardness of learning well-separated Gaussian mixtures based on
worst-case lattice problems.</p>
  </details>
</details>
<details>
  <summary>19. <b>标题：Safety-Enhanced Autonomous Driving Using Interpretable Sensor Fusion  Transformer</b></summary>
  <p><b>编号</b>：[69]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.14024</p>
  <p><b>作者</b>：Hao Shao,  LeTian Wang,  RuoBing Chen,  Hongsheng Li,  Yu Liu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：continually delayed due, Large-scale deployment, continually delayed, delayed due, comprehensive scene understanding</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large-scale deployment of autonomous vehicles has been continually delayed
due to safety concerns. On the one hand, comprehensive scene understanding is
indispensable, a lack of which would result in vulnerability to rare but
complex traffic situations, such as the sudden emergence of unknown objects.
However, reasoning from a global context requires access to sensors of multiple
types and adequate fusion of multi-modal sensor signals, which is difficult to
achieve. On the other hand, the lack of interpretability in learning models
also hampers the safety with unverifiable failure causes. In this paper, we
propose a safety-enhanced autonomous driving framework, named Interpretable
Sensor Fusion Transformer(InterFuser), to fully process and fuse information
from multi-modal multi-view sensors for achieving comprehensive scene
understanding and adversarial event detection. Besides, intermediate
interpretable features are generated from our framework, which provide more
semantics and are exploited to better constrain actions to be within the safe
sets. We conducted extensive experiments on CARLA benchmarks, where our model
outperforms prior methods, ranking the first on the public CARLA Leaderboard.</p>
  </details>
</details>
<details>
  <summary>20. <b>标题：Unsupervised Frequent Pattern Mining for CEP</b></summary>
  <p><b>编号</b>：[70]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.14017</p>
  <p><b>作者</b>：Guy Shapira,  Assaf Schuster</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Complex Event Processing, Event Processing, massive data streams, Complex Event, CEP</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Complex Event Processing (CEP) is a set of methods that allow efficient
knowledge extraction from massive data streams using complex and highly
descriptive patterns. Numerous applications, such as online finance, healthcare
monitoring and fraud detection use CEP technologies to capture critical alerts,
potential threats, or vital notifications in real time. As of today, in many
fields, patterns are manually defined by human experts. However, desired
patterns often contain convoluted relations that are difficult for humans to
detect, and human expertise is scarce in many domains.
We present REDEEMER (REinforcement baseD cEp pattErn MinER), a novel
reinforcement and active learning approach aimed at mining CEP patterns that
allow expansion of the knowledge extracted while reducing the human effort
required. This approach includes a novel policy gradient method for vast
multivariate spaces and a new way to combine reinforcement and active learning
for CEP rule learning while minimizing the number of labels needed for
training.
REDEEMER aims to enable CEP integration in domains that could not utilize it
before. To the best of our knowledge, REDEEMER is the first system that
suggests new CEP rules that were not observed beforehand, and is the first
method aimed for increasing pattern knowledge in fields where experts do not
possess sufficient information required for CEP tools.
Our experiments on diverse data-sets demonstrate that REDEEMER is able to
extend pattern knowledge while outperforming several state-of-the-art
reinforcement learning methods for pattern mining.</p>
  </details>
</details>
<details>
  <summary>21. <b>标题：Raising Student Completion Rates with Adaptive Curriculum and Contextual  Bandits</b></summary>
  <p><b>编号</b>：[76]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.14003</p>
  <p><b>作者</b>：Robert Belfer,  Ekaterina Kochmar,  Iulian Vlad Serban</p>
  <p><b>备注</b>：6 pages, 1 figure, To appear in the Proceedings of the 23rd International Conference on Artificial Intelligence in Education (AIED 2022)</p>
  <p><b>关键词</b>：Intelligent Tutoring System, learning Intelligent Tutoring, Tutoring System, Intelligent Tutoring, adaptive learning Intelligent</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present an adaptive learning Intelligent Tutoring System, which uses
model-based reinforcement learning in the form of contextual bandits to assign
learning activities to students. The model is trained on the trajectories of
thousands of students in order to maximize their exercise completion rates and
continues to learn online, automatically adjusting itself to new activities. A
randomized controlled trial with students shows that our model leads to
superior completion rates and significantly improved student engagement when
compared to other approaches. Our approach is fully-automated unlocking new
opportunities for learning experience personalization.</p>
  </details>
</details>
<details>
  <summary>22. <b>标题：Multi-Step Deductive Reasoning Over Natural Language: An Empirical Study  on Out-of-Distribution Generalisation</b></summary>
  <p><b>编号</b>：[77]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.14000</p>
  <p><b>作者</b>：Qiming Bao,  Alex Yuxuan Peng,  Tim Hartill,  Neset Tan,  Zhenyun Deng,  Michael Witbrock,  Jiamou Liu</p>
  <p><b>备注</b>：10 pages, 3 figures, The 2nd International Joint Conference on Learning & Reasoning and 16th International Workshop on Neural-Symbolic Learning and Reasoning (IJCLR-NeSy 2022)</p>
  <p><b>关键词</b>：Combining deep learning, drawing increasing attention, Combining deep, deep learning, learning with symbolic</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Combining deep learning with symbolic logic reasoning aims to capitalize on
the success of both fields and is drawing increasing attention. Inspired by
DeepLogic, an end-to-end model trained to perform inference on logic programs,
we introduce IMA-GloVe-GA, an iterative neural inference network for multi-step
reasoning expressed in natural language. In our model, reasoning is performed
using an iterative memory neural network based on RNN with a gate attention
mechanism. We evaluate IMA-GloVe-GA on three datasets: PARARULES, CONCEPTRULES
V1 and CONCEPTRULES V2. Experimental results show DeepLogic with gate attention
can achieve higher test accuracy than DeepLogic and other RNN baseline models.
Our model achieves better out-of-distribution generalisation than RoBERTa-Large
when the rules have been shuffled. Furthermore, to address the issue of
unbalanced distribution of reasoning depths in the current multi-step reasoning
datasets, we develop PARARULE-Plus, a large dataset with more examples that
require deeper reasoning steps. Experimental results show that the addition of
PARARULE-Plus can increase the model's performance on examples requiring deeper
reasoning depths. The source code and data are available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>23. <b>标题：ClaSP -- Parameter-free Time Series Segmentation</b></summary>
  <p><b>编号</b>：[82]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.13987</p>
  <p><b>作者</b>：Arik Ermshaus,  Patrick Schäfer,  Ulf Leser</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：aka time series, observed processes result, study of natural, natural and human-made, long sequences</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The study of natural and human-made processes often results in long sequences
of temporally-ordered values, aka time series (TS). Such processes often
consist of multiple states, e.g. operating modes of a machine, such that state
changes in the observed processes result in changes in the distribution of
shape of the measured values. Time series segmentation (TSS) tries to find such
changes in TS post-hoc to deduce changes in the data-generating process. TSS is
typically approached as an unsupervised learning problem aiming at the
identification of segments distinguishable by some statistical property.
Current algorithms for TSS require domain-dependent hyper-parameters to be set
by the user, make assumptions about the TS value distribution or the types of
detectable changes which limits their applicability. Common hyperparameters are
the measure of segment homogeneity and the number of change points, which are
particularly hard to tune for each data set. We present ClaSP, a novel, highly
accurate, hyper-parameter-free and domain-agnostic method for TSS. ClaSP
hierarchically splits a TS into two parts. A change point is determined by
training a binary TS classifier for each possible split point and selecting the
one split that is best at identifying subsequences to be from either of the
partitions. ClaSP learns its main two model-parameters from the data using two
novel bespoke algorithms. In our experimental evaluation using a benchmark of
115 data sets, we show that ClaSP outperforms the state of the art in terms of
accuracy and is fast and scalable. Furthermore, we highlight properties of
ClaSP using several real-world case studies.</p>
  </details>
</details>
<details>
  <summary>24. <b>标题：Federated Learning for IoUT: Concepts, Applications, Challenges and  Opportunities</b></summary>
  <p><b>编号</b>：[86]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.13976</p>
  <p><b>作者</b>：Nancy Victor,  Rajeswari. C,  Mamoun Alazab,  Sweta Bhattacharya,  Sindri Magnusson,  Praveen Kumar Reddy Maddikunta,  Kadiyala Ramana,  Thippa Reddy Gadekallu</p>
  <p><b>备注</b>：The paper is accepted for publication in IEEE IoT Magazine</p>
  <p><b>关键词</b>：Underwater Things, gained rapid momentum, Internet of Underwater, monitoring and exploration, gained rapid</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Internet of Underwater Things (IoUT) have gained rapid momentum over the past
decade with applications spanning from environmental monitoring and
exploration, defence applications, etc. The traditional IoUT systems use
machine learning (ML) approaches which cater the needs of reliability,
efficiency and timeliness. However, an extensive review of the various studies
conducted highlight the significance of data privacy and security in IoUT
frameworks as a predominant factor in achieving desired outcomes in mission
critical applications. Federated learning (FL) is a secured, decentralized
framework which is a recent development in machine learning, that will help in
fulfilling the challenges faced by conventional ML approaches in IoUT. This
paper presents an overview of the various applications of FL in IoUT, its
challenges, open issues and indicates direction of future research prospects.</p>
  </details>
</details>
<details>
  <summary>25. <b>标题：PHEMEPlus: Enriching Social Media Rumour Verification with External  Evidence</b></summary>
  <p><b>编号</b>：[89]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.13970</p>
  <p><b>作者</b>：John Dougrez-Lewis,  Elena Kochkina,  M. Arana-Catania,  Maria Liakata,  Yulan He</p>
  <p><b>备注</b>：10 pages, 1 figure, 5 tables, presented in the Fifth Fact Extraction and VERification Workshop (FEVER). 2022</p>
  <p><b>关键词</b>：verification utilises signals, social media, signals from posts, users involved, utilises signals</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Work on social media rumour verification utilises signals from posts, their
propagation and users involved. Other lines of work target identifying and
fact-checking claims based on information from Wikipedia, or trustworthy news
articles without considering social media context. However works combining the
information from social media with external evidence from the wider web are
lacking. To facilitate research in this direction, we release a novel dataset,
PHEMEPlus, an extension of the PHEME benchmark, which contains social media
conversations as well as relevant external evidence for each rumour. We
demonstrate the effectiveness of incorporating such evidence in improving
rumour verification models. Additionally, as part of the evidence collection,
we evaluate various ways of query formulation to identify the most effective
method.</p>
  </details>
</details>
<details>
  <summary>26. <b>标题：A Novel Data Augmentation Technique for Out-of-Distribution Sample  Detection using Compounded Corruptions</b></summary>
  <p><b>编号</b>：[105]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.13916</p>
  <p><b>作者</b>：Ramya S. Hebbalaguppe,  Soumya Suvra Goshal,  Jatin Prakash,  Harshad Khadilkar,  Chetan Arora</p>
  <p><b>备注</b>：16 pages main text, 23 pages supplemental material. Accepted in Research Track ECML'22. Project webpage: this https URL</p>
  <p><b>关键词</b>：Modern deep neural, deep neural network, neural network models, OOD, Modern deep</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Modern deep neural network models are known to erroneously classify
out-of-distribution (OOD) test data into one of the in-distribution (ID)
training classes with high confidence. This can have disastrous consequences
for safety-critical applications. A popular mitigation strategy is to train a
separate classifier that can detect such OOD samples at the test time. In most
practical settings OOD examples are not known at the train time, and hence a
key question is: how to augment the ID data with synthetic OOD samples for
training such an OOD detector? In this paper, we propose a novel Compounded
Corruption technique for the OOD data augmentation termed CnC. One of the major
advantages of CnC is that it does not require any hold-out data apart from the
training set. Further, unlike current state-of-the-art (SOTA) techniques, CnC
does not require backpropagation or ensembling at the test time, making our
method much faster at inference. Our extensive comparison with 20 methods from
the major conferences in last 4 years show that a model trained using CnC based
data augmentation, significantly outperforms SOTA, both in terms of OOD
detection accuracy as well as inference time. We include a detailed post-hoc
analysis to investigate the reasons for the success of our method and identify
higher relative entropy and diversity of CnC samples as probable causes. We
also provide theoretical insights via a piece-wise decomposition analysis on a
two-dimensional dataset to reveal (visually and quantitatively) that our
approach leads to a tighter boundary around ID classes, leading to better
detection of OOD samples. Source code link: this https URL</p>
  </details>
</details>
<details>
  <summary>27. <b>标题：Exploiting Negative Preference in Content-based Music Recommendation  with Contrastive Learning</b></summary>
  <p><b>编号</b>：[108]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.13909</p>
  <p><b>作者</b>：Minju Park,  Kyogu Lee</p>
  <p><b>备注</b>：Accepted at 16th ACM Conference on Recommender Systems (ACM RecSys 2022)</p>
  <p><b>关键词</b>：music recommendation systems, Advanced music recommendation, music recommendation, music, users' music tastes</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Advanced music recommendation systems are being introduced along with the
development of machine learning. However, it is essential to design a music
recommendation system that can increase user satisfaction by understanding
users' music tastes, not by the complexity of models. Although several studies
related to music recommendation systems exploiting negative preferences have
shown performance improvements, there was a lack of explanation on how they led
to better recommendations. In this work, we analyze the role of negative
preference in users' music tastes by comparing music recommendation models with
contrastive learning exploiting preference (CLEP) but with three different
training strategies - exploiting preferences of both positive and negative
(CLEP-PN), positive only (CLEP-P), and negative only (CLEP-N). We evaluate the
effectiveness of the negative preference by validating each system with a small
amount of personalized data obtained via survey and further illuminate the
possibility of exploiting negative preference in music recommendations. Our
experimental results show that CLEP-N outperforms the other two in accuracy and
false positive rate. Furthermore, the proposed training strategies produced a
consistent tendency regardless of different types of front-end musical feature
extractors, proving the stability of the proposed method.</p>
  </details>
</details>
<details>
  <summary>28. <b>标题：Adaptive Second Order Coresets for Data-efficient Machine Learning</b></summary>
  <p><b>编号</b>：[116]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.13887</p>
  <p><b>作者</b>：Omead Pooladzandi,  David Davini,  Baharan Mirzasoleiman</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：massive datasets incurs, datasets incurs substantial, incurs substantial computational, substantial computational costs, machine learning models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Training machine learning models on massive datasets incurs substantial
computational costs. To alleviate such costs, there has been a sustained effort
to develop data-efficient training methods that can carefully select subsets of
the training examples that generalize on par with the full training data.
However, existing methods are limited in providing theoretical guarantees for
the quality of the models trained on the extracted subsets, and may perform
poorly in practice. We propose AdaCore, a method that leverages the geometry of
the data to extract subsets of the training examples for efficient machine
learning. The key idea behind our method is to dynamically approximate the
curvature of the loss function via an exponentially-averaged estimate of the
Hessian to select weighted subsets (coresets) that provide a close
approximation of the full gradient preconditioned with the Hessian. We prove
rigorous guarantees for the convergence of various first and second-order
methods applied to the subsets chosen by AdaCore. Our extensive experiments
show that AdaCore extracts coresets with higher quality compared to baselines
and speeds up training of convex and non-convex machine learning models, such
as logistic regression and neural networks, by over 2.9x over the full data and
4.5x over random subsets.</p>
  </details>
</details>
<details>
  <summary>29. <b>标题：Diversity Boosted Learning for Domain Generalization with Large Number  of Domains</b></summary>
  <p><b>编号</b>：[126]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.13865</p>
  <p><b>作者</b>：Xi Leng,  Xiaoying Tang,  Yatao Bian</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：average training loss, Machine learning algorithms, learning algorithms minimizing, training data, average training</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Machine learning algorithms minimizing the average training loss usually
suffer from poor generalization performance due to the greedy exploitation of
correlations among the training data, which are not stable under distributional
shifts. It inspires various works for domain generalization (DG), where a
series of methods, such as Causal Matching and FISH, work by pairwise domain
operations. They would need $O(n^2)$ pairwise domain operations with $n$
domains, where each one is often highly expensive. Moreover, while a common
objective in the DG literature is to learn invariant representations against
domain-induced spurious correlations, we highlight the importance of mitigating
spurious correlations caused by objects. Based on the observation that
diversity helps mitigate spurious correlations, we propose a Diversity boosted
twO-level saMplIng framework (DOMI) utilizing Determinantal Point Processes
(DPPs) to efficiently sample the most informative ones among large number of
domains. We show that DOMI helps train robust models against spurious
correlations from both domain-side and object-side, substantially enhancing the
performance of the backbone DG algorithms on rotated MNIST, rotated Fashion
MNIST, and iwildcam datasets.</p>
  </details>
</details>
<details>
  <summary>30. <b>标题：Learning to Adapt Classifier for Imbalanced Semi-supervised Learning</b></summary>
  <p><b>编号</b>：[132]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.13856</p>
  <p><b>作者</b>：Renzhen Wang,  Xixi Jia,  Quanziang Wang,  Deyu Meng</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Existing pseudo-labeling methods, bias, bias attractor, promising semi-supervised learning, SSL</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Pseudo-labeling has proven to be a promising semi-supervised learning (SSL)
paradigm. Existing pseudo-labeling methods commonly assume that the class
distributions of training data are balanced. However, such an assumption is far
from realistic scenarios and existing pseudo-labeling methods suffer from
severe performance degeneration in the context of class-imbalance. In this
work, we investigate pseudo-labeling under imbalanced semi-supervised setups.
The core idea is to automatically assimilate the training bias arising from
class-imbalance, using a bias adaptive classifier that equips the original
linear classifier with a bias attractor. The bias attractor is designed to be a
light-weight residual network for adapting to the training bias. Specifically,
the bias attractor is learned through a bi-level learning framework such that
the bias adaptive classifier is able to fit imbalanced training data, while the
linear classifier can give unbiased label prediction for each class. We conduct
extensive experiments under various imbalanced semi-supervised setups, and the
results demonstrate that our method can be applicable to different
pseudo-labeling models and superior to the prior arts.</p>
  </details>
</details>
<details>
  <summary>31. <b>标题：One-Pass Learning via Bridging Orthogonal Gradient Descent and Recursive  Least-Squares</b></summary>
  <p><b>编号</b>：[133]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.13853</p>
  <p><b>作者</b>：Youngjae Min,  Kwangjun Ahn,  Navid Azizan</p>
  <p><b>备注</b>：IEEE Conference on Decision and Control, 2022</p>
  <p><b>关键词</b>：training typically requires, typically requires iterating, deep neural networks, capable of achieving, neural networks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>While deep neural networks are capable of achieving state-of-the-art
performance in various domains, their training typically requires iterating for
many passes over the dataset. However, due to computational and memory
constraints and potential privacy concerns, storing and accessing all the data
is impractical in many real-world scenarios where the data arrives in a stream.
In this paper, we investigate the problem of one-pass learning, in which a
model is trained on sequentially arriving data without retraining on previous
datapoints. Motivated by the increasing use of overparameterized models, we
develop Orthogonal Recursive Fitting (ORFit), an algorithm for one-pass
learning which seeks to perfectly fit every new datapoint while changing the
parameters in a direction that causes the least change to the predictions on
previous datapoints. By doing so, we bridge two seemingly distinct algorithms
in adaptive filtering and machine learning, namely the recursive least-squares
(RLS) algorithm and orthogonal gradient descent (OGD). Our algorithm uses the
memory efficiently by exploiting the structure of the streaming data via an
incremental principal component analysis (IPCA). Further, we show that, for
overparameterized linear models, the parameter vector obtained by our algorithm
is what stochastic gradient descent (SGD) would converge to in the standard
multi-pass setting. Finally, we generalize the results to the nonlinear setting
for highly overparameterized models, relevant for deep learning. Our
experiments show the effectiveness of the proposed method compared to the
baselines.</p>
  </details>
</details>
<details>
  <summary>32. <b>标题：Predicting the Output Structure of Sparse Matrix Multiplication with  Sampled Compression Ratio</b></summary>
  <p><b>编号</b>：[134]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.13848</p>
  <p><b>作者</b>：Zhaoyang Du,  Yijin Guan,  Tianchan Guan,  Dimin Niu,  Nianxiong Tan,  Xiaopeng Yu,  Hongzhong Zheng,  Jianyi Meng,  Xiaolang Yan,  Yuan Xie</p>
  <p><b>备注</b>：This paper has been submitted to the IEEE International Conference on Parallel and Distributed Systems (ICPADS). 8 pages, 2 fgures, 3 tables</p>
  <p><b>关键词</b>：numerous scientific applications, fundamental building block, general matrix multiplication, existing sampling-based method, output structure</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Sparse general matrix multiplication (SpGEMM) is a fundamental building block
in numerous scientific applications. One critical task of SpGEMM is to compute
or predict the structure of the output matrix (i.e., the number of nonzero
elements per output row) for efficient memory allocation and load balance,
which impact the overall performance of SpGEMM. Existing work either precisely
calculates the output structure or adopts upper-bound or sampling-based methods
to predict the output structure. However, these methods either take much
execution time or are not accurate enough. In this paper, we propose a novel
sampling-based method with better accuracy and low costs compared to the
existing sampling-based method. The proposed method first predicts the
compression ratio of SpGEMM by leveraging the number of intermediate products
(denoted as FLOP) and the number of nonzero elements (denoted as NNZ) of the
same sampled result matrix. And then, the predicted output structure is
obtained by dividing the FLOP per output row by the predicted compression
ratio. We also propose a reference design of the existing sampling-based method
with optimized computing overheads to demonstrate the better accuracy of the
proposed method. We construct 625 test cases with various matrix dimensions and
sparse structures to evaluate the prediction accuracy. Experimental results
show that the absolute relative errors of the proposed method and the reference
design are 1.56\% and 8.12\%, respectively, on average, and 25\% and 156\%,
respectively, in the worst case.</p>
  </details>
</details>
<details>
  <summary>33. <b>标题：Deep Learning-Based Acoustic Mosquito Detection in Noisy Conditions  Using Trainable Kernels and Augmentations</b></summary>
  <p><b>编号</b>：[136]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.13843</p>
  <p><b>作者</b>：Devesh Khandelwal,  Sean Campos,  Shwetha Nagaraj,  Fred Nugen,  Alberto Todeschini</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：deep learning model, machine learning approaches, fusing pre-processing techniques, audio machine learning, learning model</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we demonstrate a unique recipe to enhance the effectiveness of
audio machine learning approaches by fusing pre-processing techniques into a
deep learning model. Our solution accelerates training and inference
performance by optimizing hyper-parameters through training instead of costly
random searches to build a reliable mosquito detector from audio signals. The
experiments and the results presented here are part of the MOS C submission of
the ACM 2022 challenge. Our results outperform the published baseline by 212%
on the unpublished test set. We believe that this is one of the best real-world
examples of building a robust bio-acoustic system that provides reliable
mosquito detection in noisy conditions.</p>
  </details>
</details>
<details>
  <summary>34. <b>标题：Dive into Machine Learning Algorithms for Influenza Virus Host  Prediction with Hemagglutinin Sequences</b></summary>
  <p><b>编号</b>：[137]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.13842</p>
  <p><b>作者</b>：Yanhua Xu,  Dominik Wojtczak</p>
  <p><b>备注</b>：Accepted for publication at BioSystems</p>
  <p><b>关键词</b>：viruses mutate rapidly, Influenza viruses mutate, public health, vulnerable groups, mutate rapidly</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Influenza viruses mutate rapidly and can pose a threat to public health,
especially to those in vulnerable groups. Throughout history, influenza A
viruses have caused pandemics between different species. It is important to
identify the origin of a virus in order to prevent the spread of an outbreak.
Recently, there has been increasing interest in using machine learning
algorithms to provide fast and accurate predictions for viral sequences. In
this study, real testing data sets and a variety of evaluation metrics were
used to evaluate machine learning algorithms at different taxonomic levels. As
hemagglutinin is the major protein in the immune response, only hemagglutinin
sequences were used and represented by position-specific scoring matrix and
word embedding. The results suggest that the 5-grams-transformer neural network
is the most effective algorithm for predicting viral sequence origins, with
approximately 99.54% AUCPR, 98.01% F1 score and 96.60% MCC at a higher
classification level, and approximately 94.74% AUCPR, 87.41% F1 score and
80.79% MCC at a lower classification level.</p>
  </details>
</details>
<details>
  <summary>35. <b>标题：Multi-Objective Provisioning of Network Slices using Deep Reinforcement  Learning</b></summary>
  <p><b>编号</b>：[146]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.13821</p>
  <p><b>作者</b>：Chien-Cheng Wu,  Vasilis Friderikos1,  Cedomir Stefanovic</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：efficiently enabling divergent, Network Slice Provisioning, enabling divergent network, Network Slicing, Slice Provisioning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Network Slicing (NS) is crucial for efficiently enabling divergent network
applications in next generation networks. Nonetheless, the complex Quality of
Service (QoS) requirements and diverse heterogeneity in network services
entails high computational time for Network Slice Provisioning (NSP)
optimization. The legacy optimization methods are challenging to meet the low
latency and high reliability of network applications. To this end, we model the
real-time NSP as an Online Network Slice Provisioning (ONSP) problem.
Specifically, we formulate the ONSP problem as an online Multi-Objective
Integer Programming Optimization (MOIPO) problem. Then, we approximate the
solution of the MOIPO problem by applying the Proximal Policy Optimization
(PPO) method to the traffic demand prediction. Our simulation results show the
effectiveness of the proposed method compared to the state-of-the-art MOIPO
solvers with a lower SLA violation rate and network operation cost.</p>
  </details>
</details>
<details>
  <summary>36. <b>标题：Cross-Attention of Disentangled Modalities for 3D Human Mesh Recovery  with Transformers</b></summary>
  <p><b>编号</b>：[147]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.13820</p>
  <p><b>作者</b>：Junhyeong Cho,  Kim Youwang,  Tae-Hyun Oh</p>
  <p><b>备注</b>：Accepted to ECCV 2022, Code: this https URL</p>
  <p><b>关键词</b>：results on monocular, recently achieved, expensive computations, human mesh reconstruction, require a substantial</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Transformer encoder architectures have recently achieved state-of-the-art
results on monocular 3D human mesh reconstruction, but they require a
substantial number of parameters and expensive computations. Due to the large
memory overhead and slow inference speed, it is difficult to deploy such models
for practical use. In this paper, we propose a novel transformer
encoder-decoder architecture for 3D human mesh reconstruction from a single
image, called FastMETRO. We identify the performance bottleneck in the
encoder-based transformers is caused by the token design which introduces high
complexity interactions among input tokens. We disentangle the interactions via
an encoder-decoder architecture, which allows our model to demand much fewer
parameters and shorter inference time. In addition, we impose the prior
knowledge of human body's morphological relationship via attention masking and
mesh upsampling operations, which leads to faster convergence with higher
accuracy. Our FastMETRO improves the Pareto-front of accuracy and efficiency,
and clearly outperforms image-based methods on Human3.6M and 3DPW. Furthermore,
we validate its generalizability on FreiHAND.</p>
  </details>
</details>
<details>
  <summary>37. <b>标题：Structural Similarity for Improved Transfer in Reinforcement Learning</b></summary>
  <p><b>编号</b>：[150]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.13813</p>
  <p><b>作者</b>：C. Chace Ashcraft,  Benjamin Stoler,  Chigozie Ewulum,  Susama Agarwala</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：increasingly common approach, increasingly common, common approach, approach for developing, developing performant</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Transfer learning is an increasingly common approach for developing
performant RL agents. However, it is not well understood how to define the
relationship between the source and target tasks, and how this relationship
contributes to successful transfer. We present an algorithm called Structural
Similarity for Two MDPS, or SS2, that calculates a state similarity measure for
states in two finite MDPs based on previously developed bisimulation metrics,
and show that the measure satisfies properties of a distance metric. Then,
through empirical results with GridWorld navigation tasks, we provide evidence
that the distance measure can be used to improve transfer performance for
Q-Learning agents over previous implementations.</p>
  </details>
</details>
<details>
  <summary>38. <b>标题：Towards Sleep Scoring Generalization Through Self-Supervised  Meta-Learning</b></summary>
  <p><b>编号</b>：[154]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.13801</p>
  <p><b>作者</b>：Abdelhak Lemkhenter,  Paolo Favaro</p>
  <p><b>备注</b>：EMBC 2022</p>
  <p><b>关键词</b>：sleep scoring based, sleep scoring, work we introduce, scoring based, Model Agnostic</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this work we introduce a novel meta-learning method for sleep scoring
based on self-supervised learning. Our approach aims at building models for
sleep scoring that can generalize across different patients and recording
facilities, but do not require a further adaptation step to the target data.
Towards this goal, we build our method on top of the Model Agnostic
Meta-Learning (MAML) framework by incorporating a self-supervised learning
(SSL) stage, and call it S2MAML. We show that S2MAML can significantly
outperform MAML. The gain in performance comes from the SSL stage, which we
base on a general purpose pseudo-task that limits the overfitting to the
subject-specific patterns present in the training dataset. We show that S2MAML
outperforms standard supervised learning and MAML on the SC, ST, ISRUC, UCD and
CAP datasets.</p>
  </details>
</details>
<details>
  <summary>39. <b>标题：Learning to Assess Danger from Movies for Cooperative Escape Planning in  Hazardous Environments</b></summary>
  <p><b>编号</b>：[159]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.13791</p>
  <p><b>作者</b>：Vikram Shree,  Sarah Allen,  Beatriz Asfora,  Jacopo Banfi,  Mark Campbell</p>
  <p><b>备注</b>：8 pages, 8 figures Accepted for publication at 2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</p>
  <p><b>关键词</b>：nascent stage, plethora of work, work towards improving, hazardous environments, improving robot perception</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>There has been a plethora of work towards improving robot perception and
navigation, yet their application in hazardous environments, like during a fire
or an earthquake, is still at a nascent stage. We hypothesize two key
challenges here: first, it is difficult to replicate such scenarios in the real
world, which is necessary for training and testing purposes. Second, current
systems are not fully able to take advantage of the rich multi-modal data
available in such hazardous environments. To address the first challenge, we
propose to harness the enormous amount of visual content available in the form
of movies and TV shows, and develop a dataset that can represent hazardous
environments encountered in the real world. The data is annotated with
high-level danger ratings for realistic disaster images, and corresponding
keywords are provided that summarize the content of the scene. In response to
the second challenge, we propose a multi-modal danger estimation pipeline for
collaborative human-robot escape scenarios. Our Bayesian framework improves
danger estimation by fusing information from robot's camera sensor and language
inputs from the human. Furthermore, we augment the estimation module with a
risk-aware planner that helps in identifying safer paths out of the dangerous
environment. Through extensive simulations, we exhibit the advantages of our
multi-modal perception framework that gets translated into tangible benefits
such as higher success rate in a collaborative human-robot mission.</p>
  </details>
</details>
<details>
  <summary>40. <b>标题：Physical Pooling Functions in Graph Neural Networks for Molecular  Property Prediction</b></summary>
  <p><b>编号</b>：[164]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.13779</p>
  <p><b>作者</b>：Artur M. Schweidtmann,  Jan G. Rittig,  Jana M. Weber,  Martin Grohe,  Manuel Dahmen,  Kai Leonhard,  Alexander Mitsos</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Graph neural networks, Graph neural, neural networks, learning of physicochemical, pooling</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Graph neural networks (GNNs) are emerging in chemical engineering for the
end-to-end learning of physicochemical properties based on molecular graphs. A
key element of GNNs is the pooling function which combines atom feature vectors
into molecular fingerprints. Most previous works use a standard pooling
function to predict a variety of properties. However, unsuitable pooling
functions can lead to unphysical GNNs that poorly generalize. We compare and
select meaningful GNN pooling methods based on physical knowledge about the
learned properties. The impact of physical pooling functions is demonstrated
with molecular properties calculated from quantum mechanical computations. We
also compare our results to the recent set2set pooling approach. We recommend
using sum pooling for the prediction of properties that depend on molecular
size and compare pooling functions for properties that are molecular
size-independent. Overall, we show that the use of physical pooling functions
significantly enhances generalization.</p>
  </details>
</details>
<details>
  <summary>41. <b>标题：Calibrate: Interactive Analysis of Probabilistic Model Output</b></summary>
  <p><b>编号</b>：[167]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.13770</p>
  <p><b>作者</b>：Peter Xenopoulos,  Joao Rulff,  Luis Gustavo Nonato,  Brian Barr,  Claudio Silva</p>
  <p><b>备注</b>：Accepted to IEEE VIS 2022</p>
  <p><b>关键词</b>：Analyzing classification model, machine learning practitioners, classification model performance, Analyzing classification, crucial task</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Analyzing classification model performance is a crucial task for machine
learning practitioners. While practitioners often use count-based metrics
derived from confusion matrices, like accuracy, many applications, such as
weather prediction, sports betting, or patient risk prediction, rely on a
classifier's predicted probabilities rather than predicted labels. In these
instances, practitioners are concerned with producing a calibrated model, that
is, one which outputs probabilities that reflect those of the true
distribution. Model calibration is often analyzed visually, through static
reliability diagrams, however, the traditional calibration visualization may
suffer from a variety of drawbacks due to the strong aggregations it
necessitates. Furthermore, count-based approaches are unable to sufficiently
analyze model calibration. We present Calibrate, an interactive reliability
diagram that addresses the aforementioned issues. Calibrate constructs a
reliability diagram that is resistant to drawbacks in traditional approaches,
and allows for interactive subgroup analysis and instance-level inspection. We
demonstrate the utility of Calibrate through use cases on both real-world and
synthetic data. We further validate Calibrate by presenting the results of a
think-aloud experiment with data scientists who routinely analyze model
calibration.</p>
  </details>
</details>
<details>
  <summary>42. <b>标题：Label-Only Membership Inference Attack against Node-Level Graph Neural  Networks</b></summary>
  <p><b>编号</b>：[168]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.13766</p>
  <p><b>作者</b>：Mauro Conti,  Jiaxin Li,  Stjepan Picek,  Jing Xu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Convolutional Neural Networks, Graph Neural Networks, Neural Networks, Convolutional Neural, Graph Neural</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Graph Neural Networks (GNNs), inspired by Convolutional Neural Networks
(CNNs), aggregate the message of nodes' neighbors and structure information to
acquire expressive representations of nodes for node classification, graph
classification, and link prediction. Previous studies have indicated that GNNs
are vulnerable to Membership Inference Attacks (MIAs), which infer whether a
node is in the training data of GNNs and leak the node's private information,
like the patient's disease history. The implementation of previous MIAs takes
advantage of the models' probability output, which is infeasible if GNNs only
provide the prediction label (label-only) for the input.
In this paper, we propose a label-only MIA against GNNs for node
classification with the help of GNNs' flexible prediction mechanism, e.g.,
obtaining the prediction label of one node even when neighbors' information is
unavailable. Our attacking method achieves around 60\% accuracy, precision, and
Area Under the Curve (AUC) for most datasets and GNN models, some of which are
competitive or even better than state-of-the-art probability-based MIAs
implemented under our environment and settings. Additionally, we analyze the
influence of the sampling method, model selection approach, and overfitting
level on the attack performance of our label-only MIA. Both of those factors
have an impact on the attack performance. Then, we consider scenarios where
assumptions about the adversary's additional dataset (shadow dataset) and extra
information about the target model are relaxed. Even in those scenarios, our
label-only MIA achieves a better attack performance in most cases. Finally, we
explore the effectiveness of possible defenses, including Dropout,
Regularization, Normalization, and Jumping knowledge. None of those four
defenses prevent our attack completely.</p>
  </details>
</details>
<details>
  <summary>43. <b>标题：GAUDI: A Neural Architect for Immersive 3D Scene Generation</b></summary>
  <p><b>编号</b>：[171]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.13751</p>
  <p><b>作者</b>：Miguel Angel Bautista,  Pengsheng Guo,  Samira Abnar,  Walter Talbott,  Alexander Toshev,  Zhuoyuan Chen,  Laurent Dinh,  Shuangfei Zhai,  Hanlin Goh,  Daniel Ulbricht,  Afshin Dehghan,  Josh Susskind</p>
  <p><b>备注</b>：Project webpage: this https URL</p>
  <p><b>关键词</b>：complex and realistic, generative model capable, capable of capturing, rendered immersively, introduce GAUDI</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We introduce GAUDI, a generative model capable of capturing the distribution
of complex and realistic 3D scenes that can be rendered immersively from a
moving camera. We tackle this challenging problem with a scalable yet powerful
approach, where we first optimize a latent representation that disentangles
radiance fields and camera poses. This latent representation is then used to
learn a generative model that enables both unconditional and conditional
generation of 3D scenes. Our model generalizes previous works that focus on
single objects by removing the assumption that the camera pose distribution can
be shared across samples. We show that GAUDI obtains state-of-the-art
performance in the unconditional generative setting across multiple datasets
and allows for conditional generation of 3D scenes given conditioning variables
like sparse image observations or text that describes the scene.</p>
  </details>
</details>
<details>
  <summary>44. <b>标题：Distributional Actor-Critic Ensemble for Uncertainty-Aware Continuous  Control</b></summary>
  <p><b>编号</b>：[176]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.13730</p>
  <p><b>作者</b>：Takuya Kanazawa,  Haiyan Wang,  Chetan Gupta</p>
  <p><b>备注</b>：10 pages, 6 figures. Accepted to International Joint Conference on Neural Networks (IJCNN 2022), July 18-23, Padua, Italy</p>
  <p><b>关键词</b>：real-world applications, central challenges, challenges for machine, Uncertainty, Deep Deterministic Policy</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Uncertainty quantification is one of the central challenges for machine
learning in real-world applications. In reinforcement learning, an agent
confronts two kinds of uncertainty, called epistemic uncertainty and aleatoric
uncertainty. Disentangling and evaluating these uncertainties simultaneously
stands a chance of improving the agent's final performance, accelerating
training, and facilitating quality assurance after deployment. In this work, we
propose an uncertainty-aware reinforcement learning algorithm for continuous
control tasks that extends the Deep Deterministic Policy Gradient algorithm
(DDPG). It exploits epistemic uncertainty to accelerate exploration and
aleatoric uncertainty to learn a risk-sensitive policy. We conduct numerical
experiments showing that our variant of DDPG outperforms vanilla DDPG without
uncertainty estimation in benchmark tasks on robotic control and power-grid
optimization.</p>
  </details>
</details>
<details>
  <summary>45. <b>标题：SoundChoice: Grapheme-to-Phoneme Models with Semantic Disambiguation</b></summary>
  <p><b>编号</b>：[178]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.13703</p>
  <p><b>作者</b>：Artem Ploujnikov,  Mirco Ravanelli</p>
  <p><b>备注</b>：5 pages, submitted to INTERSPEECH 2022</p>
  <p><b>关键词</b>：models directly convert, synthesis models directly, audio representation, directly convert, convert the input</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>End-to-end speech synthesis models directly convert the input characters into
an audio representation (e.g., spectrograms). Despite their impressive
performance, such models have difficulty disambiguating the pronunciations of
identically spelled words. To mitigate this issue, a separate
Grapheme-to-Phoneme (G2P) model can be employed to convert the characters into
phonemes before synthesizing the audio. This paper proposes SoundChoice, a
novel G2P architecture that processes entire sentences rather than operating at
the word level. The proposed architecture takes advantage of a weighted
homograph loss (that improves disambiguation), exploits curriculum learning
(that gradually switches from word-level to sentence-level G2P), and integrates
word embeddings from BERT (for further performance improvement). Moreover, the
model inherits the best practices in speech recognition, including multi-task
learning with Connectionist Temporal Classification (CTC) and beam search with
an embedded language model. As a result, SoundChoice achieves a Phoneme Error
Rate (PER) of 2.65% on whole-sentence transcription using data from LibriSpeech
and Wikipedia. Index Terms grapheme-to-phoneme, speech synthesis,
text-tospeech, phonetics, pronunciation, disambiguation.</p>
  </details>
</details>
<details>
  <summary>46. <b>标题：Physical Systems Modeled Without Physical Laws</b></summary>
  <p><b>编号</b>：[179]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.13702</p>
  <p><b>作者</b>：David Noever,  Samuel Hyams</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：complex differentiable equations, simulations typically operate, geometric inputs, Physics-based simulations typically, typically operate</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Physics-based simulations typically operate with a combination of complex
differentiable equations and many scientific and geometric inputs. Our work
involves gathering data from those simulations and seeing how well tree-based
machine learning methods can emulate desired outputs without "knowing" the
complex backing involved in the simulations. The selected physics-based
simulations included Navier-Stokes, stress analysis, and electromagnetic field
lines to benchmark performance as numerical and statistical algorithms. We
specifically focus on predicting specific spatial-temporal data between two
simulation outputs and increasing spatial resolution to generalize the physics
predictions to finer test grids without the computational costs of repeating
the numerical calculation.</p>
  </details>
</details>
<details>
  <summary>47. <b>标题：Branch Ranking for Efficient Mixed-Integer Programming via Offline  Ranking-based Policy Learning</b></summary>
  <p><b>编号</b>：[180]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.13701</p>
  <p><b>作者</b>：Zeren Huang,  Wenhao Chen,  Weinan Zhang,  Chuhan Shi,  Furui Liu,  Hui-Ling Zhen,  Mingxuan Yuan,  Jianye Hao,  Yong Yu,  Jun Wang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：modern mixed-integer programming, good variable selection, variable selection strategy, Deriving a good, mixed-integer programming</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deriving a good variable selection strategy in branch-and-bound is essential
for the efficiency of modern mixed-integer programming (MIP) solvers. With MIP
branching data collected during the previous solution process, learning to
branch methods have recently become superior over heuristics. As
branch-and-bound is naturally a sequential decision making task, one should
learn to optimize the utility of the whole MIP solving process instead of being
myopic on each step. In this work, we formulate learning to branch as an
offline reinforcement learning (RL) problem, and propose a long-sighted hybrid
search scheme to construct the offline MIP dataset, which values the long-term
utilities of branching decisions. During the policy training phase, we deploy a
ranking-based reward assignment scheme to distinguish the promising samples
from the long-term or short-term view, and train the branching model named
Branch Ranking via offline policy learning. Experiments on synthetic MIP
benchmarks and real-world tasks demonstrate that Branch Rankink is more
efficient and robust, and can better generalize to large scales of MIP
instances compared to the widely used heuristics and state-of-the-art
learning-based branching models.</p>
  </details>
</details>
<details>
  <summary>48. <b>标题：Remote Medication Status Prediction for Individuals with Parkinson's  Disease using Time-series Data from Smartphones</b></summary>
  <p><b>编号</b>：[181]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.13700</p>
  <p><b>作者</b>：Weijian Li,  Wei Zhu,  Ray Dorsey,  Jiebo Luo</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：remotely at home, Parkinson disease, AUC, Medication, Parkinson disease patients</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Medication for neurological diseases such as the Parkinson's disease usually
happens remotely at home, away from hospitals. Such out-of-lab environments
pose challenges in collecting timely and accurate health status data using the
limited professional care devices for health condition analysis, medication
adherence measurement and future dose or treatment planning. Individual
differences in behavioral signals collected from wearable sensors also lead to
difficulties in adopting current general machine learning analysis pipelines.
To address these challenges, we present a method for predicting medication
status of Parkinson's disease patients using the public mPower dataset, which
contains 62,182 remote multi-modal test records collected on smartphones from
487 patients. The proposed method shows promising results in predicting three
medication status objectively: Before Medication (AUC=0.95), After Medication
(AUC=0.958), and Another Time (AUC=0.976) by examining patient-wise historical
records with the attention weights learned through a Transformer model. We
believe our method provides an innovative way for personalized remote health
sensing in a timely and objective fashion which could benefit a broad range of
similar applications.</p>
  </details>
</details>
<details>
  <summary>49. <b>标题：Modelling non-reinforced preferences using selective attention</b></summary>
  <p><b>编号</b>：[182]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.13699</p>
  <p><b>作者</b>：Noor Sajid,  Panagiotis Tigas,  Zafeirios Fountas,  Qinghai Guo,  Alexey Zakharov,  Lancelot Da Costa</p>
  <p><b>备注</b>：4 pages, 3 figures - Workshop Track: 1st Conference on Lifelong Learning Agents, 2022</p>
  <p><b>关键词</b>：learn non-reinforced preferences, artificial agents learn, agents learn non-reinforced, learn non-reinforced, continuously adapt</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>How can artificial agents learn non-reinforced preferences to continuously
adapt their behaviour to a changing environment? We decompose this question
into two challenges: ($i$) encoding diverse memories and ($ii$) selectively
attending to these for preference formation. Our proposed
\emph{no}n-\emph{re}inforced preference learning mechanism using selective
attention, \textsc{Nore}, addresses both by leveraging the agent's world model
to collect a diverse set of experiences which are interleaved with imagined
roll-outs to encode memories. These memories are selectively attended to, using
attention and gating blocks, to update agent's preferences. We validate
\textsc{Nore} in a modified OpenAI Gym FrozenLake environment (without any
external signal) with and without volatility under a fixed model of the
environment -- and compare its behaviour to \textsc{Pepper}, a Hebbian
preference learning mechanism. We demonstrate that \textsc{Nore} provides a
straightforward framework to induce exploratory preferences in the absence of
external signals.</p>
  </details>
</details>
<details>
  <summary>50. <b>标题：A general framework for multi-step ahead adaptive conformal  heteroscedastic time series forecasting</b></summary>
  <p><b>编号</b>：[191]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.14219</p>
  <p><b>作者</b>：Martim Sousa,  Ana Maria Tomé,  José Moreira</p>
  <p><b>备注</b>：13 pages, 8 figures</p>
  <p><b>关键词</b>：machine learning, exponential growth, growth of machine, prompted a great, great deal</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The exponential growth of machine learning (ML) has prompted a great deal of
interest in quantifying the uncertainty of each prediction for a user-defined
level of confidence. Reliable uncertainty quantification is crucial and is a
step towards increased trust in AI results. It becomes especially important in
high-stakes decision-making, where the true output must be within the
confidence set with high probability. Conformal prediction (CP) is a
distribution-free uncertainty quantification framework that works for any
black-box model and yields prediction intervals (PIs) that are valid under the
mild assumption of exchangeability. CP-type methods are gaining popularity due
to being easy to implement and computationally cheap; however, the
exchangeability assumption immediately excludes time series forecasting.
Although recent papers tackle covariate shift, this is not enough for the
general time series forecasting problem of producing H-step ahead valid PIs. To
attain such a goal, we propose a new method called AEnbMIMOCQR (Adaptive
ensemble batch multiinput multi-output conformalized quantile regression),
which produces asymptotic valid PIs and is appropriate for heteroscedastic time
series. We compare the proposed method against state-of-the-art competitive
methods in the NN5 forecasting competition dataset. All the code and data to
reproduce the experiments are made available</p>
  </details>
</details>
<details>
  <summary>51. <b>标题：Optimization of Artificial Neural Networks models applied to the  identification of images of asteroids' resonant arguments</b></summary>
  <p><b>编号</b>：[193]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.14181</p>
  <p><b>作者</b>：Valerio Carruba,  Safwan Aljbaae,  Gabriel Caritá,  Rita Cassia Domingos,  Bruno Martins</p>
  <p><b>备注</b>：16 pages, 13 figures, 3 tables. Submitted for consideration at Celestial Mechanics and Dynamical Astronomy</p>
  <p><b>关键词</b>：asteroidal main belt, asteroidal main, main belt, belt is crossed, web of mean-motion</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The asteroidal main belt is crossed by a web of mean-motion and secular
resonances, that occur when there is a commensurability between fundamental
frequencies of the asteroids and planets. Traditionally, these objects were
identified by visual inspection of the time evolution of their resonant
argument, which is a combination of orbital elements of the asteroid and the
perturbing planet(s). Since the population of asteroids affected by these
resonances is, in some cases, of the order of several thousand, this has become
a taxing task for a human observer. Recent works used Convolutional Neural
Networks (CNN) models to perform such task automatically. In this work, we
compare the outcome of such models with those of some of the most advanced and
publicly available CNN architectures, like the VGG, Inception and ResNet. The
performance of such models is first tested and optimized for overfitting
issues, using validation sets and a series of regularization techniques like
data augmentation, dropout, and batch normalization. The three best-performing
models were then used to predict the labels of larger testing databases
containing thousands of images. The VGG model, with and without
regularizations, proved to be the most efficient method to predict labels of
large datasets. Since the Vera C. Rubin observatory is likely to discover up to
four million new asteroids in the next few years, the use of these models might
become quite valuable to identify populations of resonant minor bodies.</p>
  </details>
</details>
<details>
  <summary>52. <b>标题：A Transformer-based Generative Adversarial Network for Brain Tumor  Segmentation</b></summary>
  <p><b>编号</b>：[196]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.14134</p>
  <p><b>作者</b>：Liqun Huang (1),  Long Chen (1),  Baihai Zhang (1),  Senchun Chai (1) ((1) School of Automation, Beijing Institute of Technology, China)</p>
  <p><b>备注</b>：11 pages, 2 figures</p>
  <p><b>关键词</b>：remains a challenge, tumor segmentation remains, computer vision tasks, image segmentation tasks, Brain tumor segmentation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Brain tumor segmentation remains a challenge in medical image segmentation
tasks. With the application of transformer in various computer vision tasks,
transformer blocks show the capability of learning long-distance dependency in
global space, which is complementary with CNNs. In this paper, we proposed a
novel transformer-based generative adversarial network to automatically segment
brain tumors with multi-modalities MRI. Our architecture consists of a
generator and a discriminator, which are trained in min-max game progress. The
generator is based on a typical "U-shaped" encoder-decoder architecture, whose
bottom layer is composed of transformer blocks with resnet. Besides, the
generator is trained with deep supervision technology. The discriminator we
designed is a CNN-based network with multi-scale $L_{1}$ loss, which is proved
to be effective for medical semantic image segmentation. To validate the
effectiveness of our method, we conducted experiments on BRATS2015 dataset,
achieving comparable or better performance than previous state-of-the-art
methods.</p>
  </details>
</details>
<details>
  <summary>53. <b>标题：Classification of FIB/SEM-tomography images for highly porous multiphase  materials using random forest classifiers</b></summary>
  <p><b>编号</b>：[197]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.14114</p>
  <p><b>作者</b>：Markus Osenberg,  André Hilger,  Matthias Neumann,  Amalia Wagner,  Nicole Bohn,  Joachim R. Binder,  Volker Schmidt,  John Banhart,  Ingo Manke</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：SEM tomography represents, SEM tomography, represents an indispensable, indispensable tool, SEM</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>FIB/SEM tomography represents an indispensable tool for the characterization
of three-dimensional nanostructures in battery research and many other fields.
However, contrast and 3D classification/reconstruction problems occur in many
cases, which strongly limits the applicability of the technique especially on
porous materials, like those used for electrode materials in batteries or fuel
cells. Distinguishing the different components like active Li storage particles
and carbon/binder materials is difficult and often prevents a reliable
quantitative analysis of image data, or may even lead to wrong conclusions
about structure-property relationships. In this contribution, we present a
novel approach for data classification in three-dimensional image data obtained
by FIB/SEM tomography and its applications to NMC battery electrode materials.
We use two different image signals, namely the signal of the angled SE2 chamber
detector and the Inlens detector signal, combine both signals and train a
random forest, i.e. a particular machine learning algorithm. We demonstrate
that this approach can overcome current limitations of existing techniques
suitable for multi-phase measurements and that it allows for quantitative data
reconstruction even where current state-of the art techniques fail, or demand
for large training sets. This approach may yield as guideline for future
research using FIB/SEM tomography.</p>
  </details>
</details>
<details>
  <summary>54. <b>标题：MarkerMap: nonlinear marker selection for single-cell studies</b></summary>
  <p><b>编号</b>：[198]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.14106</p>
  <p><b>作者</b>：Nabeel Sarwar,  Wilson Gregory,  George A Kevrekidis,  Soledad Villar,  Bianca Dumitrascu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：biological contexts, cell type differences, cell type, Single-cell RNA-seq data, type differences</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Single-cell RNA-seq data allow the quantification of cell type differences
across a growing set of biological contexts. However, pinpointing a small
subset of genomic features explaining this variability can be ill-defined and
computationally intractable. Here we introduce MarkerMap, a generative model
for selecting minimal gene sets which are maximally informative of cell type
origin and enable whole transcriptome reconstruction. MarkerMap provides a
scalable framework for both supervised marker selection, aimed at identifying
specific cell type populations, and unsupervised marker selection, aimed at
gene expression imputation and reconstruction. We benchmark MarkerMap's
competitive performance against previously published approaches on real single
cell gene expression data sets. MarkerMap is available as a pip installable
package, as a community resource aimed at developing explainable machine
learning techniques for enhancing interpretability in single-cell studies.</p>
  </details>
</details>
<details>
  <summary>55. <b>标题：Topological Analysis of Ensembles of Hydrodynamic Turbulent Flows -- An  Experimental Study</b></summary>
  <p><b>编号</b>：[200]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.14080</p>
  <p><b>作者</b>：Florent Nauleau,  Fabien Vivodtzev,  Thibault Bridel-Bertomeu,  Heloise Beaugendre,  Julien Tierny</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Topological Data Analysis, application paper presents, Data Analysis, comprehensive experimental evaluation, application paper</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This application paper presents a comprehensive experimental evaluation of
the suitability of Topological Data Analysis (TDA) for the quantitative
comparison of turbulent flows. Specifically, our study documents the usage of
the persistence diagram of the maxima of flow enstrophy (an established
vorticity indicator), for the topological representation of 180 ensemble
members, generated by a coarse sampling of the parameter space of five
numerical solvers. We document five main hypotheses reported by domain experts,
describing their expectations regarding the variability of the flows generated
by the distinct solver configurations. We contribute three evaluation protocols
to assess the validation of the above hypotheses by two comparison measures:
(i) a standard distance used in scientific imaging (the L2 norm) and (ii) an
established topological distance between persistence diagrams (the
L2-Wasserstein metric). Extensive experiments on the input ensemble demonstrate
the superiority of the topological distance (ii) to report as close to each
other flows which are expected to be similar by domain experts, due to the
configuration of their vortices. Overall, the insights reported by our study
bring an experimental evidence of the suitability of TDA for representing and
comparing turbulent flows, thereby providing to the fluid dynamics community
confidence for its usage in future work. Also, our flow data and evaluation
protocols provide to the TDA community an application-approved benchmark for
the evaluation and design of further topological distances.</p>
  </details>
</details>
<details>
  <summary>56. <b>标题：Automated Classification of Nanoparticles with Various Ultrastructures  and Sizes</b></summary>
  <p><b>编号</b>：[202]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.14023</p>
  <p><b>作者</b>：Claudius Zelenka,  Marius Kamp,  Kolja Strohm,  Akram Kadoura,  Jacob Johny,  Reinhard Koch,  Lorenz Kienle</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Accurately measuring, strongly dependent, classification, neural networks, nanoparticles</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Accurately measuring the size, morphology, and structure of nanoparticles is
very important, because they are strongly dependent on their properties for
many applications. In this paper, we present a deep-learning based method for
nanoparticle measurement and classification trained from a small data set of
scanning transmission electron microscopy images. Our approach is comprised of
two stages: localization, i.e., detection of nanoparticles, and classification,
i.e., categorization of their ultrastructure. For each stage, we optimize the
segmentation and classification by analysis of the different state-of-the-art
neural networks. We show how the generation of synthetic images, either using
image processing or using various image generation neural networks, can be used
to improve the results in both stages. Finally, the application of the
algorithm to bimetallic nanoparticles demonstrates the automated data
collection of size distributions including classification of complex
ultrastructures. The developed method can be easily transferred to other
material systems and nanoparticle structures.</p>
  </details>
</details>
<details>
  <summary>57. <b>标题：HelixFold-Single: MSA-free Protein Structure Prediction by Using Protein  Language Model as an Alternative</b></summary>
  <p><b>编号</b>：[205]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.13921</p>
  <p><b>作者</b>：Xiaomin Fang,  Fan Wang,  Lihang Liu,  Jingzhou He,  Dayong Lin,  Yingfei Xiang,  Xiaonan Zhang,  Hua Wu,  Hui Li,  Le Song</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：achieved near-experimental accuracy, protein structure prediction, AI-based protein structure, achieved near-experimental, protein structure</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>AI-based protein structure prediction pipelines, such as AlphaFold2, have
achieved near-experimental accuracy. These advanced pipelines mainly rely on
Multiple Sequence Alignments (MSAs) and templates as inputs to learn the
co-evolution information from the homologous sequences. Nonetheless, searching
MSAs and templates from protein databases is time-consuming, usually taking
dozens of minutes. Consequently, we attempt to explore the limits of fast
protein structure prediction by using only primary sequences of proteins.
HelixFold-Single is proposed to combine a large-scale protein language model
with the superior geometric learning capability of AlphaFold2. Our proposed
method, HelixFold-Single, first pre-trains a large-scale protein language model
(PLM) with thousands of millions of primary sequences utilizing the
self-supervised learning paradigm, which will be used as an alternative to MSAs
and templates for learning the co-evolution information. Then, by combining the
pre-trained PLM and the essential components of AlphaFold2, we obtain an
end-to-end differentiable model to predict the 3D coordinates of atoms from
only the primary sequence. HelixFold-Single is validated in datasets CASP14 and
CAMEO, achieving competitive accuracy with the MSA-based methods on the targets
with large homologous families. Furthermore, HelixFold-Single consumes much
less time than the mainstream pipelines for protein structure prediction,
demonstrating its potential in tasks requiring many predictions. The code of
HelixFold-Single is available at
this https URL,
and we also provide stable web services on
this https URL.</p>
  </details>
</details>
<details>
  <summary>58. <b>标题：Real Image Restoration via Structure-preserving Complementarity  Attention</b></summary>
  <p><b>编号</b>：[209]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.13879</p>
  <p><b>作者</b>：Yuanfan Zhang,  Gen Li,  Lei Sun</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：convolutional neural networks, neural networks perform, large-scale data, convolutional neural, learning generalizable image</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Since convolutional neural networks perform well in learning generalizable
image priors from large-scale data, these models have been widely used in image
denoising tasks. However, the computational complexity increases dramatically
as well on complex model. In this paper, We propose a novel lightweight
Complementary Attention Module, which includes a density module and a sparse
module, which can cooperatively mine dense and sparse features for feature
complementary learning to build an efficient lightweight architecture.
Moreover, to reduce the loss of details caused by denoising, this paper
constructs a gradient-based structure-preserving branch. We utilize
gradient-based branches to obtain additional structural priors for denoising,
and make the model pay more attention to image geometric details through
gradient loss optimization.Based on the above, we propose an efficiently Unet
structured network with dual branch, the visual results show that can
effectively preserve the structural details of the original image, we evaluate
benchmarks including SIDD and DND, where SCANet achieves state-of-the-art
performance in PSNR and SSIM while significantly reducing computational cost.</p>
  </details>
</details>
<details>
  <summary>59. <b>标题：p-Adic Statistical Field Theory and Deep Belief Networks</b></summary>
  <p><b>编号</b>：[210]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.13877</p>
  <p><b>作者</b>：W. A. Zúñiga-Galindo</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：statistical field theories, adic statistical field, field theories, initiate the study, adic</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this work we initiate the study of the correspondence between $p$-adic
statistical field theories (SFTs) and neural networks (NNs). In general quantum
field theories over a $p$-adic spacetime can be formulated in a rigorous way.
Nowadays these theories are considered just mathematical toy models for
understanding the problems of the true theories. In this work we show these
theories are deeply connected with the deep belief networks (DBNs). Hinton et
al. constructed DBNs by stacking several restricted Boltzmann machines (RBMs).
The purpose of this construction is to obtain a network with a hierarchical
structure (a deep learning architecture). An RBM corresponds a certain spin
glass, thus a DBN should correspond to an ultrametric (hierarchical) spin
glass. A model of such system can be easily constructed by using $p$-adic
numbers. In our approach, a $p$-adic SFT corresponds to a $p$-adic continuous
DBN, and a discretization of this theory corresponds to a $p$-adic discrete
DBN. We show that these last machines are universal approximators. In the
$p$-adic framework, the correspondence between SFTs and NNs is not fully
developed. We point out several open problems.</p>
  </details>
</details>
<details>
  <summary>60. <b>标题：Extraction of Vascular Wall in Carotid Ultrasound via a Novel  Boundary-Delineation Network</b></summary>
  <p><b>编号</b>：[211]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.13868</p>
  <p><b>作者</b>：Qinghua Huang,  Lizhi Jia,  Guanqing Ren,  Xiaoyi Wang,  Chunying Liu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Ultrasound imaging plays, vascular wall, Ultrasound imaging, imaging plays, vascular</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Ultrasound imaging plays an important role in the diagnosis of vascular
lesions. Accurate segmentation of the vascular wall is important for the
prevention, diagnosis and treatment of vascular diseases. However, existing
methods have inaccurate localization of the vascular wall boundary.
Segmentation errors occur in discontinuous vascular wall boundaries and dark
boundaries. To overcome these problems, we propose a new boundary-delineation
network (BDNet). We use the boundary refinement module to re-delineate the
boundary of the vascular wall to obtain the correct boundary location. We
designed the feature extraction module to extract and fuse multi-scale features
and different receptive field features to solve the problem of dark boundaries
and discontinuous boundaries. We use a new loss function to optimize the model.
The interference of class imbalance on model optimization is prevented to
obtain finer and smoother boundaries. Finally, to facilitate clinical
applications, we design the model to be lightweight. Experimental results show
that our model achieves the best segmentation results and significantly reduces
memory consumption compared to existing models for the dataset.</p>
  </details>
</details>
<details>
  <summary>61. <b>标题：Deep Learning for Classification of Thyroid Nodules on Ultrasound:  Validation on an Independent Dataset</b></summary>
  <p><b>编号</b>：[216]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.13765</p>
  <p><b>作者</b>：Jingxi Weng,  Benjamin Wildman-Tobriner,  Mateusz Buda,  Jichen Yang,  Lisa M. Ho,  Brian C. Allen,  Wendy L. Ehieli,  Chad M. Miller,  Jikai Zhang,  Maciej A. Mazurowski</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：deep learning algorithm, previously validated deep, deep learning, validated deep learning, learning algorithm</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Objectives: The purpose is to apply a previously validated deep learning
algorithm to a new thyroid nodule ultrasound image dataset and compare its
performances with radiologists. Methods: Prior study presented an algorithm
which is able to detect thyroid nodules and then make malignancy
classifications with two ultrasound images. A multi-task deep convolutional
neural network was trained from 1278 nodules and originally tested with 99
separate nodules. The results were comparable with that of radiologists. The
algorithm was further tested with 378 nodules imaged with ultrasound machines
from different manufacturers and product types than the training cases. Four
experienced radiologists were requested to evaluate the nodules for comparison
with deep learning. Results: The Area Under Curve (AUC) of the deep learning
algorithm and four radiologists were calculated with parametric, binormal
estimation. For the deep learning algorithm, the AUC was 0.70 (95% CI: 0.64 -
0.75). The AUC of radiologists were 0.66 (95% CI: 0.61 - 0.71), 0.67 (95%
CI:0.62 - 0.73), 0.68 (95% CI: 0.63 - 0.73), and 0.66 (95%CI: 0.61 - 0.71).
Conclusion: In the new testing dataset, the deep learning algorithm achieved
similar performances with all four radiologists.</p>
  </details>
</details>
<details>
  <summary>62. <b>标题：Differentially Private Learning of Hawkes Processes</b></summary>
  <p><b>编号</b>：[218]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.13741</p>
  <p><b>作者</b>：Mohsen Ghassemi,  Eleonora Kreačić,  Niccolò Dalmasso,  Vamsi K. Potluru,  Tucker Balch,  Manuela Veloso</p>
  <p><b>备注</b>：30 pages, 4 figures</p>
  <p><b>关键词</b>：event sequence data, recently gained increasing, gained increasing attention, modeling event sequence, machine learning community</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Hawkes processes have recently gained increasing attention from the machine
learning community for their versatility in modeling event sequence data. While
they have a rich history going back decades, some of their properties, such as
sample complexity for learning the parameters and releasing differentially
private versions, are yet to be thoroughly analyzed. In this work, we study
standard Hawkes processes with background intensity $\mu$ and excitation
function $\alpha e^{-\beta t}$. We provide both non-private and differentially
private estimators of $\mu$ and $\alpha$, and obtain sample complexity results
in both settings to quantify the cost of privacy. Our analysis exploits the
strong mixing property of Hawkes processes and classical central limit theorem
results for weakly dependent random variables. We validate our theoretical
findings on both synthetic and real datasets.</p>
  </details>
</details>
<h1>人工智能</h1>
<details>
  <summary>1. <b>标题：Initialization and Alignment for Adversarial Texture Optimization</b></summary>
  <p><b>编号</b>：[1]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.14289</p>
  <p><b>作者</b>：Xiaoming Zhao,  Zhizhen Zhao,  Alexander G. Schwing</p>
  <p><b>备注</b>：ECCV 2022; Project Page: this https URL</p>
  <p><b>关键词</b>：computer vision, received a lot, lot of attention, attention in computer, adversarial texture optimization</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>While recovery of geometry from image and video data has received a lot of
attention in computer vision, methods to capture the texture for a given
geometry are less mature. Specifically, classical methods for texture
generation often assume clean geometry and reasonably well-aligned image data.
While very recent methods, e.g., adversarial texture optimization, better
handle lower-quality data obtained from hand-held devices, we find them to
still struggle frequently. To improve robustness, particularly of recent
adversarial texture optimization, we develop an explicit initialization and an
alignment procedure. It deals with complex geometry due to a robust mapping of
the geometry to the texture map and a hard-assignment-based initialization. It
deals with misalignment of geometry and images by integrating fast
image-alignment into the texture refinement optimization. We demonstrate
efficacy of our texture generation on a dataset of 11 scenes with a total of
2807 frames, observing 7.8% and 11.1% relative improvements regarding
perceptual and sharpness measurements.</p>
  </details>
</details>
<details>
  <summary>2. <b>标题：Regret Minimization and Convergence to Equilibria in General-sum Markov  Games</b></summary>
  <p><b>编号</b>：[22]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.14211</p>
  <p><b>作者</b>：Liad Erez,  Tal Lancewicki,  Uri Sherman,  Tomer Koren,  Yishay Mansour</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：recent impossibility results, impossibility results establish, Markov games, regret minimization, abundance of recent</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>An abundance of recent impossibility results establish that regret
minimization in Markov games with adversarial opponents is both statistically
and computationally intractable. Nevertheless, none of these results preclude
the possibility of regret minimization under the assumption that all parties
adopt the same learning procedure. In this work, we present the first (to our
knowledge) algorithm for learning in general-sum Markov games that provides
sublinear regret guarantees when executed by all agents. The bounds we obtain
are for swap regret, and thus, along the way, imply convergence to a correlated
equilibrium. Our algorithm is decentralized, computationally efficient, and
does not require any communication between agents. Our key observation is that
online learning via policy optimization in Markov games essentially reduces to
a form of weighted regret minimization, with unknown weights determined by the
path length of the agents' policy sequence. Consequently, controlling the path
length leads to weighted regret objectives for which sufficiently adaptive
algorithms provide sublinear regret guarantees.</p>
  </details>
</details>
<details>
  <summary>3. <b>标题：DoRO: Disambiguation of referred object for embodied agents</b></summary>
  <p><b>编号</b>：[24]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.14205</p>
  <p><b>作者</b>：Pradip Pramanick,  Chayan Sarkar,  Sayan Paul,  Ruddra dev Roychoudhury,  Brojeshwar Bhowmick</p>
  <p><b>备注</b>：Accepted in IEEE Robotics & Automation Letters (RA-L)</p>
  <p><b>关键词</b>：Robotic task instructions, referred object, instructions often involve, object, Robotic task</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Robotic task instructions often involve a referred object that the robot must
locate (ground) within the environment. While task intent understanding is an
essential part of natural language understanding, less effort is made to
resolve ambiguity that may arise while grounding the task. Existing works use
vision-based task grounding and ambiguity detection, suitable for a fixed view
and a static robot. However, the problem magnifies for a mobile robot, where
the ideal view is not known beforehand. Moreover, a single view may not be
sufficient to locate all the object instances in the given area, which leads to
inaccurate ambiguity detection. Human intervention is helpful only if the robot
can convey the kind of ambiguity it is facing. In this article, we present DoRO
(Disambiguation of Referred Object), a system that can help an embodied agent
to disambiguate the referred object by raising a suitable query whenever
required. Given an area where the intended object is, DoRO finds all the
instances of the object by aggregating observations from multiple views while
exploring & scanning the area. It then raises a suitable query using the
information from the grounded object instances. Experiments conducted with the
AI2Thor simulator show that DoRO not only detects the ambiguity more accurately
but also raises verbose queries with more accurate information from the
visual-language grounding.</p>
  </details>
</details>
<details>
  <summary>4. <b>标题：Do We Need Another Explainable AI Method? Toward Unifying Post-hoc XAI  Evaluation Methods into an Interactive and Multi-dimensional Benchmark</b></summary>
  <p><b>编号</b>：[34]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.14160</p>
  <p><b>作者</b>：Mohamed Karim Belaid,  Eyke Hüllermeier,  Maximilian Rabus,  Ralf Krestel</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：countries turned explanations, xAI, xAI algorithms, recent years, attracted a lot</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In recent years, Explainable AI (xAI) attracted a lot of attention as various
countries turned explanations into a legal right. xAI allows for improving
models beyond the accuracy metric by, e.g., debugging the learned pattern and
demystifying the AI's behavior. The widespread use of xAI brought new
challenges. On the one hand, the number of published xAI algorithms underwent a
boom, and it became difficult for practitioners to select the right tool. On
the other hand, some experiments did highlight how easy data scientists could
misuse xAI algorithms and misinterpret their results. To tackle the issue of
comparing and correctly using feature importance xAI algorithms, we propose
Compare-xAI, a benchmark that unifies all exclusive and unitary evaluation
methods applied to xAI algorithms. We propose a selection protocol to shortlist
non-redundant unit tests from the literature, i.e., each targeting a specific
problem in explaining a model. The benchmark encapsulates the complexity of
evaluating xAI methods into a hierarchical scoring of three levels, namely,
targeting three end-user groups: researchers, practitioners, and laymen in xAI.
The most detailed level provides one score per unit test. The second level
regroups tests into five categories (fidelity, fragility, stability,
simplicity, and stress tests). The last level is the aggregated
comprehensibility score, which encapsulates the ease of correctly interpreting
the algorithm's output in one easy to compare value. Compare-xAI's interactive
user interface helps mitigate errors in interpreting xAI results by quickly
listing the recommended xAI solutions for each ML task and their current
limitations. The benchmark is made available at
this https URL</p>
  </details>
</details>
<details>
  <summary>5. <b>标题：A Hazard Analysis Framework for Code Synthesis Large Language Models</b></summary>
  <p><b>编号</b>：[35]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.14157</p>
  <p><b>作者</b>：Heidy Khlaaf,  Pamela Mishkin,  Joshua Achiam,  Gretchen Krueger,  Miles Brundage</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：large language model, variety of codebases, exceeds the previous, large language, previous state</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Codex, a large language model (LLM) trained on a variety of codebases,
exceeds the previous state of the art in its capacity to synthesize and
generate code. Although Codex provides a plethora of benefits, models that may
generate code on such scale have significant limitations, alignment problems,
the potential to be misused, and the possibility to increase the rate of
progress in technical fields that may themselves have destabilizing impacts or
have misuse potential. Yet such safety impacts are not yet known or remain to
be explored. In this paper, we outline a hazard analysis framework constructed
at OpenAI to uncover hazards or safety risks that the deployment of models like
Codex may impose technically, socially, politically, and economically. The
analysis is informed by a novel evaluation framework that determines the
capacity of advanced code generation techniques against the complexity and
expressivity of specification prompts, and their capability to understand and
execute them relative to human ability.</p>
  </details>
</details>
<details>
  <summary>6. <b>标题：Playing a 2D Game Indefinitely using NEAT and Reinforcement Learning</b></summary>
  <p><b>编号</b>：[40]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.14140</p>
  <p><b>作者</b>：Jerin Paul Selvan,  Pravin S. Game</p>
  <p><b>备注</b>：5 pages, 7 figures, 3 tables</p>
  <p><b>关键词</b>：test them.The creation, obstacles.The environment chosen, random heights.The bird, test them.The performance, pipes themselves.The actions</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>For over a decade now, robotics and the use of artificial agents have become
a common thing.Testing the performance of new path finding or search space
optimization algorithms has also become a challenge as they require simulation
or an environment to test them.The creation of artificial environments with
artificial agents is one of the methods employed to test such algorithms.Games
have also become an environment to test them.The performance of the algorithms
can be compared by using artificial agents that will behave according to the
algorithm in the environment they are put in.The performance parameters can be,
how quickly the agent is able to differentiate between rewarding actions and
hostile actions.This can be tested by placing the agent in an environment with
different types of hurdles and the goal of the agent is to reach the farthest
by taking decisions on actions that will lead to avoiding all the obstacles.The
environment chosen is a game called "Flappy Bird".The goal of the game is to
make the bird fly through a set of pipes of random heights.The bird must go in
between these pipes and must not hit the top, the bottom, or the pipes
themselves.The actions that the bird can take are either to flap its wings or
drop down with gravity.The algorithms that are enforced on the artificial
agents are NeuroEvolution of Augmenting Topologies (NEAT) and Reinforcement
Learning.The NEAT algorithm takes an "N" initial population of artificial
agents.They follow genetic algorithms by considering an objective function,
crossover, mutation, and augmenting topologies.Reinforcement learning, on the
other hand, remembers the state, the action taken at that state, and the reward
received for the action taken using a single agent and a Deep Q-learning
Network.The performance of the NEAT algorithm improves as the initial
population of the artificial agents is increased.</p>
  </details>
</details>
<details>
  <summary>7. <b>标题：Towards Robust Ad Hoc Teamwork Agents By Creating Diverse Training  Teammates</b></summary>
  <p><b>编号</b>：[42]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.14138</p>
  <p><b>作者</b>：Arrasy Rahman,  Elliot Fosong,  Ignacio Carlucho,  Stefano V. Albrecht</p>
  <p><b>备注</b>：Workshop on Ad Hoc Teamwork (WAHT) at IJCAI 2022</p>
  <p><b>关键词</b>：hoc teamwork, prior coordination, problem of creating, collaborate with previously, previously unseen teammates</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Ad hoc teamwork (AHT) is the problem of creating an agent that must
collaborate with previously unseen teammates without prior coordination. Many
existing AHT methods can be categorised as type-based methods, which require a
set of predefined teammates for training. Designing teammate types for training
is a challenging issue that determines the generalisation performance of agents
when dealing with teammate types unseen during training. In this work, we
propose a method to discover diverse teammate types based on maximising best
response diversity metrics. We show that our proposed approach yields teammate
types that require a wider range of best responses from the learner during
collaboration, which potentially improves the robustness of a learner's
performance in AHT compared to alternative methods.</p>
  </details>
</details>
<details>
  <summary>8. <b>标题：A Survey of Syntactic Modelling Structures in Biomedical Ontologies</b></summary>
  <p><b>编号</b>：[48]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.14119</p>
  <p><b>作者</b>：Christian Kindermann,  Martin G. Skjæveland</p>
  <p><b>备注</b>：Accepted at The 21st International Semantic Web Conference</p>
  <p><b>关键词</b>：large-scale uptake, uptake of semantic, semantic technologies, ontologies, axioms</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Despite the large-scale uptake of semantic technologies in the biomedical
domain, little is known about common modelling practices in published
ontologies. OWL ontologies are often published only in the crude form of sets
of axioms leaving the underlying design opaque. However, a principled and
systematic ontology development life cycle is likely to be reflected in
regularities of the ontology's emergent syntactic structure. To develop an
understanding of this emergent structure, we propose to reverse-engineer
ontologies taking a syntax-directed approach for identifying and analysing
regularities for axioms and sets of axioms. We survey BioPortal in terms of
syntactic modelling trends and common practices for OWL axioms and class
frames. Our findings suggest that biomedical ontologies only share simple
syntactic structures in which OWL constructors are not deeply nested or
combined in a complex manner. While such simple structures often account for
large proportions of axioms in a given ontology, many ontologies also contain
non-trivial amounts of more complex syntactic structures that are not common
across ontologies.</p>
  </details>
</details>
<details>
  <summary>9. <b>标题：Claim-Dissector: An Interpretable Fact-Checking System with Joint  Re-ranking and Veracity Prediction</b></summary>
  <p><b>编号</b>：[49]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.14116</p>
  <p><b>作者</b>：Martin Fajcik,  Petr Motlicek,  Pavel Smrz</p>
  <p><b>备注</b>：First release</p>
  <p><b>关键词</b>：final veracity probability, latent variable model, final veracity, learning jointly, latent variable</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present Claim-Dissector: a novel latent variable model for fact-checking
and fact-analysis, which given a claim and a set of retrieved provenances
allows learning jointly: (i) what are the relevant provenances to this claim
(ii) what is the veracity of this claim. We propose to disentangle the
per-provenance relevance probability and its contribution to the final veracity
probability in an interpretable way - the final veracity probability is
proportional to a linear ensemble of per-provenance relevance probabilities.
This way, it can be clearly identified the relevance of which sources
contributes to what extent towards the final probability. We show that our
system achieves state-of-the-art results on FEVER dataset comparable to
two-stage systems typically used in traditional fact-checking pipelines, while
it often uses significantly less parameters and computation.
Our analysis shows that proposed approach further allows to learn not just
which provenances are relevant, but also which provenances lead to supporting
and which toward denying the claim, without direct supervision. This not only
adds interpretability, but also allows to detect claims with conflicting
evidence automatically. Furthermore, we study whether our model can learn
fine-grained relevance cues while using coarse-grained supervision. We show
that our model can achieve competitive sentence-recall while using only
paragraph-level relevance supervision. Finally, traversing towards the finest
granularity of relevance, we show that our framework is capable of identifying
relevance at the token-level. To do this, we present a new benchmark focusing
on token-level interpretability - humans annotate tokens in relevant
provenances they considered essential when making their judgement. Then we
measure how similar are these annotations to tokens our model is focusing on.
Our code, and dataset will be released online.</p>
  </details>
</details>
<details>
  <summary>10. <b>标题：Entity Type Prediction Leveraging Graph Walks and Entity Descriptions</b></summary>
  <p><b>编号</b>：[53]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.14094</p>
  <p><b>作者</b>：Russa Biswas,  Jan Portisch,  Heiko Paulheim,  Harald Sack,  Mehwish Alam</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：information in Knowledge, Knowledge Graphs, entity type information, Entity typing, entity</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The entity type information in Knowledge Graphs (KGs) such as DBpedia,
Freebase, etc. is often incomplete due to automated generation or human
curation. Entity typing is the task of assigning or inferring the semantic type
of an entity in a KG. This paper presents \textit{GRAND}, a novel approach for
entity typing leveraging different graph walk strategies in RDF2vec together
with textual entity descriptions. RDF2vec first generates graph walks and then
uses a language model to obtain embeddings for each node in the graph. This
study shows that the walk generation strategy and the embedding model have a
significant effect on the performance of the entity typing task. The proposed
approach outperforms the baseline approaches on the benchmark datasets DBpedia
and FIGER for entity typing in KGs for both fine-grained and coarse-grained
classes. The results show that the combination of order-aware RDF2vec variants
together with the contextual embeddings of the textual entity descriptions
achieve the best results.</p>
  </details>
</details>
<details>
  <summary>11. <b>标题：Safety-Enhanced Autonomous Driving Using Interpretable Sensor Fusion  Transformer</b></summary>
  <p><b>编号</b>：[69]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.14024</p>
  <p><b>作者</b>：Hao Shao,  LeTian Wang,  RuoBing Chen,  Hongsheng Li,  Yu Liu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：continually delayed due, Large-scale deployment, continually delayed, delayed due, comprehensive scene understanding</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large-scale deployment of autonomous vehicles has been continually delayed
due to safety concerns. On the one hand, comprehensive scene understanding is
indispensable, a lack of which would result in vulnerability to rare but
complex traffic situations, such as the sudden emergence of unknown objects.
However, reasoning from a global context requires access to sensors of multiple
types and adequate fusion of multi-modal sensor signals, which is difficult to
achieve. On the other hand, the lack of interpretability in learning models
also hampers the safety with unverifiable failure causes. In this paper, we
propose a safety-enhanced autonomous driving framework, named Interpretable
Sensor Fusion Transformer(InterFuser), to fully process and fuse information
from multi-modal multi-view sensors for achieving comprehensive scene
understanding and adversarial event detection. Besides, intermediate
interpretable features are generated from our framework, which provide more
semantics and are exploited to better constrain actions to be within the safe
sets. We conducted extensive experiments on CARLA benchmarks, where our model
outperforms prior methods, ranking the first on the public CARLA Leaderboard.</p>
  </details>
</details>
<details>
  <summary>12. <b>标题：Raising Student Completion Rates with Adaptive Curriculum and Contextual  Bandits</b></summary>
  <p><b>编号</b>：[76]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.14003</p>
  <p><b>作者</b>：Robert Belfer,  Ekaterina Kochmar,  Iulian Vlad Serban</p>
  <p><b>备注</b>：6 pages, 1 figure, To appear in the Proceedings of the 23rd International Conference on Artificial Intelligence in Education (AIED 2022)</p>
  <p><b>关键词</b>：Intelligent Tutoring System, learning Intelligent Tutoring, Tutoring System, Intelligent Tutoring, adaptive learning Intelligent</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present an adaptive learning Intelligent Tutoring System, which uses
model-based reinforcement learning in the form of contextual bandits to assign
learning activities to students. The model is trained on the trajectories of
thousands of students in order to maximize their exercise completion rates and
continues to learn online, automatically adjusting itself to new activities. A
randomized controlled trial with students shows that our model leads to
superior completion rates and significantly improved student engagement when
compared to other approaches. Our approach is fully-automated unlocking new
opportunities for learning experience personalization.</p>
  </details>
</details>
<details>
  <summary>13. <b>标题：Multi-Step Deductive Reasoning Over Natural Language: An Empirical Study  on Out-of-Distribution Generalisation</b></summary>
  <p><b>编号</b>：[77]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.14000</p>
  <p><b>作者</b>：Qiming Bao,  Alex Yuxuan Peng,  Tim Hartill,  Neset Tan,  Zhenyun Deng,  Michael Witbrock,  Jiamou Liu</p>
  <p><b>备注</b>：10 pages, 3 figures, The 2nd International Joint Conference on Learning & Reasoning and 16th International Workshop on Neural-Symbolic Learning and Reasoning (IJCLR-NeSy 2022)</p>
  <p><b>关键词</b>：Combining deep learning, drawing increasing attention, Combining deep, deep learning, learning with symbolic</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Combining deep learning with symbolic logic reasoning aims to capitalize on
the success of both fields and is drawing increasing attention. Inspired by
DeepLogic, an end-to-end model trained to perform inference on logic programs,
we introduce IMA-GloVe-GA, an iterative neural inference network for multi-step
reasoning expressed in natural language. In our model, reasoning is performed
using an iterative memory neural network based on RNN with a gate attention
mechanism. We evaluate IMA-GloVe-GA on three datasets: PARARULES, CONCEPTRULES
V1 and CONCEPTRULES V2. Experimental results show DeepLogic with gate attention
can achieve higher test accuracy than DeepLogic and other RNN baseline models.
Our model achieves better out-of-distribution generalisation than RoBERTa-Large
when the rules have been shuffled. Furthermore, to address the issue of
unbalanced distribution of reasoning depths in the current multi-step reasoning
datasets, we develop PARARULE-Plus, a large dataset with more examples that
require deeper reasoning steps. Experimental results show that the addition of
PARARULE-Plus can increase the model's performance on examples requiring deeper
reasoning depths. The source code and data are available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>14. <b>标题：ClaSP -- Parameter-free Time Series Segmentation</b></summary>
  <p><b>编号</b>：[82]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.13987</p>
  <p><b>作者</b>：Arik Ermshaus,  Patrick Schäfer,  Ulf Leser</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：aka time series, observed processes result, study of natural, natural and human-made, long sequences</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The study of natural and human-made processes often results in long sequences
of temporally-ordered values, aka time series (TS). Such processes often
consist of multiple states, e.g. operating modes of a machine, such that state
changes in the observed processes result in changes in the distribution of
shape of the measured values. Time series segmentation (TSS) tries to find such
changes in TS post-hoc to deduce changes in the data-generating process. TSS is
typically approached as an unsupervised learning problem aiming at the
identification of segments distinguishable by some statistical property.
Current algorithms for TSS require domain-dependent hyper-parameters to be set
by the user, make assumptions about the TS value distribution or the types of
detectable changes which limits their applicability. Common hyperparameters are
the measure of segment homogeneity and the number of change points, which are
particularly hard to tune for each data set. We present ClaSP, a novel, highly
accurate, hyper-parameter-free and domain-agnostic method for TSS. ClaSP
hierarchically splits a TS into two parts. A change point is determined by
training a binary TS classifier for each possible split point and selecting the
one split that is best at identifying subsequences to be from either of the
partitions. ClaSP learns its main two model-parameters from the data using two
novel bespoke algorithms. In our experimental evaluation using a benchmark of
115 data sets, we show that ClaSP outperforms the state of the art in terms of
accuracy and is fast and scalable. Furthermore, we highlight properties of
ClaSP using several real-world case studies.</p>
  </details>
</details>
<details>
  <summary>15. <b>标题：Knowing Where and What: Unified Word Block Pretraining for Document  Understanding</b></summary>
  <p><b>编号</b>：[85]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.13979</p>
  <p><b>作者</b>：Song Tao,  Zijian Wang,  Tiantian Fan,  Canjie Luo,  Can Huang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：challenging to extract, Surrounding Word Prediction, documents, word, complex layouts</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Due to the complex layouts of documents, it is challenging to extract
information for documents. Most previous studies develop multimodal pre-trained
models in a self-supervised way. In this paper, we focus on the embedding
learning of word blocks containing text and layout information, and propose
UTel, a language model with Unified TExt and Layout pre-training. Specifically,
we propose two pre-training tasks: Surrounding Word Prediction (SWP) for the
layout learning, and Contrastive learning of Word Embeddings (CWE) for
identifying different word blocks. Moreover, we replace the commonly used 1D
position embedding with a 1D clipped relative position embedding. In this way,
the joint training of Masked Layout-Language Modeling (MLLM) and two newly
proposed tasks enables the interaction between semantic and spatial features in
a unified way. Additionally, the proposed UTel can process arbitrary-length
sequences by removing the 1D position embedding, while maintaining competitive
performance. Extensive experimental results show UTel learns better joint
representations and achieves superior performance than previous methods on
various downstream tasks, though requiring no image modality. Code is available
at \url{this https URL}.</p>
  </details>
</details>
<details>
  <summary>16. <b>标题：PHEMEPlus: Enriching Social Media Rumour Verification with External  Evidence</b></summary>
  <p><b>编号</b>：[89]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.13970</p>
  <p><b>作者</b>：John Dougrez-Lewis,  Elena Kochkina,  M. Arana-Catania,  Maria Liakata,  Yulan He</p>
  <p><b>备注</b>：10 pages, 1 figure, 5 tables, presented in the Fifth Fact Extraction and VERification Workshop (FEVER). 2022</p>
  <p><b>关键词</b>：verification utilises signals, social media, signals from posts, users involved, utilises signals</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Work on social media rumour verification utilises signals from posts, their
propagation and users involved. Other lines of work target identifying and
fact-checking claims based on information from Wikipedia, or trustworthy news
articles without considering social media context. However works combining the
information from social media with external evidence from the wider web are
lacking. To facilitate research in this direction, we release a novel dataset,
PHEMEPlus, an extension of the PHEME benchmark, which contains social media
conversations as well as relevant external evidence for each rumour. We
demonstrate the effectiveness of incorporating such evidence in improving
rumour verification models. Additionally, as part of the evidence collection,
we evaluate various ways of query formulation to identify the most effective
method.</p>
  </details>
</details>
<details>
  <summary>17. <b>标题：A Novel Data Augmentation Technique for Out-of-Distribution Sample  Detection using Compounded Corruptions</b></summary>
  <p><b>编号</b>：[105]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.13916</p>
  <p><b>作者</b>：Ramya S. Hebbalaguppe,  Soumya Suvra Goshal,  Jatin Prakash,  Harshad Khadilkar,  Chetan Arora</p>
  <p><b>备注</b>：16 pages main text, 23 pages supplemental material. Accepted in Research Track ECML'22. Project webpage: this https URL</p>
  <p><b>关键词</b>：Modern deep neural, deep neural network, neural network models, OOD, Modern deep</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Modern deep neural network models are known to erroneously classify
out-of-distribution (OOD) test data into one of the in-distribution (ID)
training classes with high confidence. This can have disastrous consequences
for safety-critical applications. A popular mitigation strategy is to train a
separate classifier that can detect such OOD samples at the test time. In most
practical settings OOD examples are not known at the train time, and hence a
key question is: how to augment the ID data with synthetic OOD samples for
training such an OOD detector? In this paper, we propose a novel Compounded
Corruption technique for the OOD data augmentation termed CnC. One of the major
advantages of CnC is that it does not require any hold-out data apart from the
training set. Further, unlike current state-of-the-art (SOTA) techniques, CnC
does not require backpropagation or ensembling at the test time, making our
method much faster at inference. Our extensive comparison with 20 methods from
the major conferences in last 4 years show that a model trained using CnC based
data augmentation, significantly outperforms SOTA, both in terms of OOD
detection accuracy as well as inference time. We include a detailed post-hoc
analysis to investigate the reasons for the success of our method and identify
higher relative entropy and diversity of CnC samples as probable causes. We
also provide theoretical insights via a piece-wise decomposition analysis on a
two-dimensional dataset to reveal (visually and quantitatively) that our
approach leads to a tighter boundary around ID classes, leading to better
detection of OOD samples. Source code link: this https URL</p>
  </details>
</details>
<details>
  <summary>18. <b>标题：A health telemonitoring platform based on data integration from  different sources</b></summary>
  <p><b>编号</b>：[106]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.13913</p>
  <p><b>作者</b>：Gianluigi Ciocca,  Paolo Napoletano,  Matteo Romanato,  Raimondo Schettini</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：national health systems, management of people, people with long-term, long-term or chronic, chronic illness</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The management of people with long-term or chronic illness is one of the
biggest challenges for national health systems. In fact, these diseases are
among the leading causes of hospitalization, especially for the elderly, and
huge amount of resources required to monitor them leads to problems with
sustainability of the healthcare systems. The increasing diffusion of portable
devices and new connectivity technologies allows the implementation of
telemonitoring system capable of providing support to health care providers and
lighten the burden on hospitals and clinics. In this paper, we present the
implementation of a telemonitoring platform for healthcare, designed to capture
several types of physiological health parameters from different consumer mobile
and custom devices. Consumer medical devices can be integrated into the
platform via the Google Fit ecosystem that supports hundreds of devices, while
custom devices can directly interact with the platform with standard
communication protocols. The platform is designed to process the acquired data
using machine learning algorithms, and to provide patients and physicians the
physiological health parameters with a user-friendly, comprehensive, and easy
to understand dashboard which monitors the parameters through time. Preliminary
usability tests show a good user satisfaction in terms of functionality and
usefulness.</p>
  </details>
</details>
<details>
  <summary>19. <b>标题：Measuring Difficulty of Novelty Reaction</b></summary>
  <p><b>编号</b>：[131]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.13857</p>
  <p><b>作者</b>：Ekaterina Nikonova,  Cheng Xue,  Vimukthini Pinto,  Chathura Gamage,  Peng Zhang,  Jochen Renz</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：solve close-world problems, solve close-world, novelty, close-world problems, systems</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Current AI systems are designed to solve close-world problems with the
assumption that the underlying world is remaining more or less the same.
However, when dealing with real-world problems such assumptions can be invalid
as sudden and unexpected changes can occur. To effectively deploy AI-powered
systems in the real world, AI systems should be able to deal with open-world
novelty quickly. Inevitably, dealing with open-world novelty raises an
important question of novelty difficulty. Knowing whether one novelty is harder
to deal with than another, can help researchers to train their systems
systematically. In addition, it can also serve as a measurement of the
performance of novelty robust AI systems. In this paper, we propose to define
the novelty reaction difficulty as a relative difficulty of performing the
known task after the introduction of the novelty. We propose a universal method
that can be applied to approximate the difficulty. We present the
approximations of the difficulty using our method and show how it aligns with
the results of the evaluation of AI agents designed to deal with novelty.</p>
  </details>
</details>
<details>
  <summary>20. <b>标题：Toward Supporting Perceptual Complementarity in Human-AI Collaboration  via Reflection on Unobservables</b></summary>
  <p><b>编号</b>：[140]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.13834</p>
  <p><b>作者</b>：Kenneth Holstein,  Maria De-Arteaga,  Lakshmi Tumati,  Yanghuidi Cheng</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：successful human-AI collaboration, real world contexts, human-AI collaboration requires, collaboration requires humans, productively integrate complementary</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In many real world contexts, successful human-AI collaboration requires
humans to productively integrate complementary sources of information into
AI-informed decisions. However, in practice human decision-makers often lack
understanding of what information an AI model has access to in relation to
themselves. There are few available guidelines regarding how to effectively
communicate about unobservables: features that may influence the outcome, but
which are unavailable to the model. In this work, we conducted an online
experiment to understand whether and how explicitly communicating potentially
relevant unobservables influences how people integrate model outputs and
unobservables when making predictions. Our findings indicate that presenting
prompts about unobservables can change how humans integrate model outputs and
unobservables, but do not necessarily lead to improved performance.
Furthermore, the impacts of these prompts can vary depending on
decision-makers' prior domain expertise. We conclude by discussing implications
for future research and design of AI-based decision support tools.</p>
  </details>
</details>
<details>
  <summary>21. <b>标题：Will AI Make Cyber Swords or Shields: A few mathematical models of  technological progress</b></summary>
  <p><b>编号</b>：[145]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.13825</p>
  <p><b>作者</b>：Andrew J Lohn,  Krystal Alex Jackson</p>
  <p><b>备注</b>：Technical companion paper to CSET report entitled "Will AI Make Cyber Swords or Shields: Using models to project the impact of technology development</p>
  <p><b>关键词</b>：patching and exploitation, mathematical models, aim to demonstrate, policy debates, debates about technological</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We aim to demonstrate the value of mathematical models for policy debates
about technological progress in cybersecurity by considering phishing,
vulnerability discovery, and the dynamics between patching and exploitation. We
then adjust the inputs to those mathematical models to match some possible
advances in their underlying technology. We find that AI's impact on phishing
may be overestimated but could lead to more attacks going undetected. Advances
in vulnerability discovery have the potential to help attackers more than
defenders. And automation that writes exploits is more useful to attackers than
automation that writes patches, although advances that help deploy patches
faster have the potential to be more impactful than either.</p>
  </details>
</details>
<details>
  <summary>22. <b>标题：Cross-Attention of Disentangled Modalities for 3D Human Mesh Recovery  with Transformers</b></summary>
  <p><b>编号</b>：[147]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.13820</p>
  <p><b>作者</b>：Junhyeong Cho,  Kim Youwang,  Tae-Hyun Oh</p>
  <p><b>备注</b>：Accepted to ECCV 2022, Code: this https URL</p>
  <p><b>关键词</b>：results on monocular, recently achieved, expensive computations, human mesh reconstruction, require a substantial</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Transformer encoder architectures have recently achieved state-of-the-art
results on monocular 3D human mesh reconstruction, but they require a
substantial number of parameters and expensive computations. Due to the large
memory overhead and slow inference speed, it is difficult to deploy such models
for practical use. In this paper, we propose a novel transformer
encoder-decoder architecture for 3D human mesh reconstruction from a single
image, called FastMETRO. We identify the performance bottleneck in the
encoder-based transformers is caused by the token design which introduces high
complexity interactions among input tokens. We disentangle the interactions via
an encoder-decoder architecture, which allows our model to demand much fewer
parameters and shorter inference time. In addition, we impose the prior
knowledge of human body's morphological relationship via attention masking and
mesh upsampling operations, which leads to faster convergence with higher
accuracy. Our FastMETRO improves the Pareto-front of accuracy and efficiency,
and clearly outperforms image-based methods on Human3.6M and 3DPW. Furthermore,
we validate its generalizability on FreiHAND.</p>
  </details>
</details>
<details>
  <summary>23. <b>标题：AvatarPoser: Articulated Full-Body Pose Tracking from Sparse Motion  Sensing</b></summary>
  <p><b>编号</b>：[163]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.13784</p>
  <p><b>作者</b>：Jiaxi Jiang,  Paul Streli,  Huajian Qiu,  Andreas Fender,  Larissa Laich,  Patrick Snape,  Christian Holz</p>
  <p><b>备注</b>：Accepted by ECCV 2022, Code: this https URL</p>
  <p><b>关键词</b>：Today Mixed Reality, Mixed Reality head-mounted, Reality head-mounted displays, head-mounted displays track, Mixed Reality</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Today's Mixed Reality head-mounted displays track the user's head pose in
world space as well as the user's hands for interaction in both Augmented
Reality and Virtual Reality scenarios. While this is adequate to support user
input, it unfortunately limits users' virtual representations to just their
upper bodies. Current systems thus resort to floating avatars, whose limitation
is particularly evident in collaborative settings. To estimate full-body poses
from the sparse input sources, prior work has incorporated additional trackers
and sensors at the pelvis or lower body, which increases setup complexity and
limits practical application in mobile settings. In this paper, we present
AvatarPoser, the first learning-based method that predicts full-body poses in
world coordinates using only motion input from the user's head and hands. Our
method builds on a Transformer encoder to extract deep features from the input
signals and decouples global motion from the learned local joint orientations
to guide pose estimation. To obtain accurate full-body motions that resemble
motion capture animations, we refine the arm joints' positions using an
optimization routine with inverse kinematics to match the original tracking
input. In our evaluation, AvatarPoser achieved new state-of-the-art results in
evaluations on large motion capture datasets (AMASS). At the same time, our
method's inference speed supports real-time operation, providing a practical
interface to support holistic avatar control and representation for Metaverse
applications.</p>
  </details>
</details>
<details>
  <summary>24. <b>标题：Lighting (In)consistency of Paint by Text</b></summary>
  <p><b>编号</b>：[173]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.13744</p>
  <p><b>作者</b>：Hany Farid</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：synthesizing highly realistic, generative adversarial networks, seemingly endless categories, synthesize realistic images, highly realistic images</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Whereas generative adversarial networks are capable of synthesizing highly
realistic images of faces, cats, landscapes, or almost any other single
category, paint-by-text synthesis engines can -- from a single text prompt --
synthesize realistic images of seemingly endless categories with arbitrary
configurations and combinations. This powerful technology poses new challenges
to the photo-forensic community. Motivated by the fact that paint by text is
not based on explicit geometric or physical models, and the human visual
system's general insensitivity to lighting inconsistencies, we provide an
initial exploration of the lighting consistency of DALL-E-2 synthesized images
to determine if physics-based forensic analyses will prove fruitful in
detecting this new breed of synthetic media.</p>
  </details>
</details>
<details>
  <summary>25. <b>标题：Break and Make: Interactive Structural Understanding Using LEGO Bricks</b></summary>
  <p><b>编号</b>：[174]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.13738</p>
  <p><b>作者</b>：Aaron Walsman,  Muru Zhang,  Klemen Kotar,  Karthik Desingh,  Ali Farhadi,  Dieter Fox</p>
  <p><b>备注</b>：ECCV 2022. LTRON simulator and environment page: this https URL Training examples: this https URL</p>
  <p><b>关键词</b>：complex spatial relationships, human intelligence, spatial relationships, fundamental component, component of human</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Visual understanding of geometric structures with complex spatial
relationships is a fundamental component of human intelligence. As children, we
learn how to reason about structure not only from observation, but also by
interacting with the world around us -- by taking things apart and putting them
back together again. The ability to reason about structure and compositionality
allows us to not only build things, but also understand and reverse-engineer
complex systems. In order to advance research in interactive reasoning for
part-based geometric understanding, we propose a challenging new assembly
problem using LEGO bricks that we call Break and Make. In this problem an agent
is given a LEGO model and attempts to understand its structure by interactively
inspecting and disassembling it. After this inspection period, the agent must
then prove its understanding by rebuilding the model from scratch using
low-level action primitives. In order to facilitate research on this problem we
have built LTRON, a fully interactive 3D simulator that allows learning agents
to assemble, disassemble and manipulate LEGO models. We pair this simulator
with a new dataset of fan-made LEGO creations that have been uploaded to the
internet in order to provide complex scenes containing over a thousand unique
brick shapes. We take a first step towards solving this problem using
sequence-to-sequence models that provide guidance for how to make progress on
this challenging problem. Our simulator and data are available at
this http URL. Additional training code and PyTorch examples
are available at this http URL.</p>
  </details>
</details>
<details>
  <summary>26. <b>标题：Branch Ranking for Efficient Mixed-Integer Programming via Offline  Ranking-based Policy Learning</b></summary>
  <p><b>编号</b>：[180]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.13701</p>
  <p><b>作者</b>：Zeren Huang,  Wenhao Chen,  Weinan Zhang,  Chuhan Shi,  Furui Liu,  Hui-Ling Zhen,  Mingxuan Yuan,  Jianye Hao,  Yong Yu,  Jun Wang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：modern mixed-integer programming, good variable selection, variable selection strategy, Deriving a good, mixed-integer programming</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deriving a good variable selection strategy in branch-and-bound is essential
for the efficiency of modern mixed-integer programming (MIP) solvers. With MIP
branching data collected during the previous solution process, learning to
branch methods have recently become superior over heuristics. As
branch-and-bound is naturally a sequential decision making task, one should
learn to optimize the utility of the whole MIP solving process instead of being
myopic on each step. In this work, we formulate learning to branch as an
offline reinforcement learning (RL) problem, and propose a long-sighted hybrid
search scheme to construct the offline MIP dataset, which values the long-term
utilities of branching decisions. During the policy training phase, we deploy a
ranking-based reward assignment scheme to distinguish the promising samples
from the long-term or short-term view, and train the branching model named
Branch Ranking via offline policy learning. Experiments on synthetic MIP
benchmarks and real-world tasks demonstrate that Branch Rankink is more
efficient and robust, and can better generalize to large scales of MIP
instances compared to the widely used heuristics and state-of-the-art
learning-based branching models.</p>
  </details>
</details>
<details>
  <summary>27. <b>标题：Remote Medication Status Prediction for Individuals with Parkinson's  Disease using Time-series Data from Smartphones</b></summary>
  <p><b>编号</b>：[181]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.13700</p>
  <p><b>作者</b>：Weijian Li,  Wei Zhu,  Ray Dorsey,  Jiebo Luo</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：remotely at home, Parkinson disease, AUC, Medication, Parkinson disease patients</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Medication for neurological diseases such as the Parkinson's disease usually
happens remotely at home, away from hospitals. Such out-of-lab environments
pose challenges in collecting timely and accurate health status data using the
limited professional care devices for health condition analysis, medication
adherence measurement and future dose or treatment planning. Individual
differences in behavioral signals collected from wearable sensors also lead to
difficulties in adopting current general machine learning analysis pipelines.
To address these challenges, we present a method for predicting medication
status of Parkinson's disease patients using the public mPower dataset, which
contains 62,182 remote multi-modal test records collected on smartphones from
487 patients. The proposed method shows promising results in predicting three
medication status objectively: Before Medication (AUC=0.95), After Medication
(AUC=0.958), and Another Time (AUC=0.976) by examining patient-wise historical
records with the attention weights learned through a Transformer model. We
believe our method provides an innovative way for personalized remote health
sensing in a timely and objective fashion which could benefit a broad range of
similar applications.</p>
  </details>
</details>
<details>
  <summary>28. <b>标题：Modelling non-reinforced preferences using selective attention</b></summary>
  <p><b>编号</b>：[182]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.13699</p>
  <p><b>作者</b>：Noor Sajid,  Panagiotis Tigas,  Zafeirios Fountas,  Qinghai Guo,  Alexey Zakharov,  Lancelot Da Costa</p>
  <p><b>备注</b>：4 pages, 3 figures - Workshop Track: 1st Conference on Lifelong Learning Agents, 2022</p>
  <p><b>关键词</b>：learn non-reinforced preferences, artificial agents learn, agents learn non-reinforced, learn non-reinforced, continuously adapt</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>How can artificial agents learn non-reinforced preferences to continuously
adapt their behaviour to a changing environment? We decompose this question
into two challenges: ($i$) encoding diverse memories and ($ii$) selectively
attending to these for preference formation. Our proposed
\emph{no}n-\emph{re}inforced preference learning mechanism using selective
attention, \textsc{Nore}, addresses both by leveraging the agent's world model
to collect a diverse set of experiences which are interleaved with imagined
roll-outs to encode memories. These memories are selectively attended to, using
attention and gating blocks, to update agent's preferences. We validate
\textsc{Nore} in a modified OpenAI Gym FrozenLake environment (without any
external signal) with and without volatility under a fixed model of the
environment -- and compare its behaviour to \textsc{Pepper}, a Hebbian
preference learning mechanism. We demonstrate that \textsc{Nore} provides a
straightforward framework to induce exploratory preferences in the absence of
external signals.</p>
  </details>
</details>
<details>
  <summary>29. <b>标题：Physics-informed neural networks for diffraction tomography</b></summary>
  <p><b>编号</b>：[190]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.14230</p>
  <p><b>作者</b>：Amirhossein Saba,  Carlo Gigli,  Ahmed B. Ayoub,  Demetri Psaltis</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：model for tomographic, tomographic reconstructions, reconstructions of biological, biological samples, physics-informed neural</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose a physics-informed neural network as the forward model for
tomographic reconstructions of biological samples. We demonstrate that by
training this network with the Helmholtz equation as a physical loss, we can
predict the scattered field accurately. It will be shown that a pretrained
network can be fine-tuned for different samples and used for solving the
scattering problem much faster than other numerical solutions. We evaluate our
methodology with numerical and experimental results. Our physics-informed
neural networks can be generalized for any forward and inverse scattering
problem.</p>
  </details>
</details>
<details>
  <summary>30. <b>标题：Bayesian Optimization-Based Beam Alignment for MmWave MIMO Communication  Systems</b></summary>
  <p><b>编号</b>：[194]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.14174</p>
  <p><b>作者</b>：Songjie Yang,  Baojuan Liu,  Zhiqin Hong,  Zhongpei Zhang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：millimeter wave communication, beam alignment issue, beam alignment, wave communication, millimeter wave</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Due to the very narrow beam used in millimeter wave communication (mmWave),
beam alignment (BA) is a critical issue. In this work, we investigate the issue
of mmWave BA and present a novel beam alignment scheme on the basis of a
machine learning strategy, Bayesian optimization (BO). In this context, we
consider the beam alignment issue to be a black box function and then use BO to
find the possible optimal beam pair. During the BA procedure, this strategy
exploits information from the measured beam pairs to predict the best beam
pair. In addition, we suggest a novel BO algorithm based on the gradient
boosting regression tree model. The simulation results demonstrate the spectral
efficiency performance of our proposed schemes for BA using three different
surrogate models. They also demonstrate that the proposed schemes can achieve
spectral efficiency with a small overhead when compared to the orthogonal match
pursuit (OMP) algorithm and the Thompson sampling-based multi-armed bandit
(TS-MAB) method.</p>
  </details>
</details>
<details>
  <summary>31. <b>标题：HelixFold-Single: MSA-free Protein Structure Prediction by Using Protein  Language Model as an Alternative</b></summary>
  <p><b>编号</b>：[205]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2207.13921</p>
  <p><b>作者</b>：Xiaomin Fang,  Fan Wang,  Lihang Liu,  Jingzhou He,  Dayong Lin,  Yingfei Xiang,  Xiaonan Zhang,  Hua Wu,  Hui Li,  Le Song</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：achieved near-experimental accuracy, protein structure prediction, AI-based protein structure, achieved near-experimental, protein structure</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>AI-based protein structure prediction pipelines, such as AlphaFold2, have
achieved near-experimental accuracy. These advanced pipelines mainly rely on
Multiple Sequence Alignments (MSAs) and templates as inputs to learn the
co-evolution information from the homologous sequences. Nonetheless, searching
MSAs and templates from protein databases is time-consuming, usually taking
dozens of minutes. Consequently, we attempt to explore the limits of fast
protein structure prediction by using only primary sequences of proteins.
HelixFold-Single is proposed to combine a large-scale protein language model
with the superior geometric learning capability of AlphaFold2. Our proposed
method, HelixFold-Single, first pre-trains a large-scale protein language model
(PLM) with thousands of millions of primary sequences utilizing the
self-supervised learning paradigm, which will be used as an alternative to MSAs
and templates for learning the co-evolution information. Then, by combining the
pre-trained PLM and the essential components of AlphaFold2, we obtain an
end-to-end differentiable model to predict the 3D coordinates of atoms from
only the primary sequence. HelixFold-Single is validated in datasets CASP14 and
CAMEO, achieving competitive accuracy with the MSA-based methods on the targets
with large homologous families. Furthermore, HelixFold-Single consumes much
less time than the mainstream pipelines for protein structure prediction,
demonstrating its potential in tasks requiring many predictions. The code of
HelixFold-Single is available at
this https URL,
and we also provide stable web services on
this https URL.</p>
  </details>
</details>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">徐耀彬</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://louishsu.xyz/2022/07/29/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html">http://louishsu.xyz/2022/07/29/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://louishsu.xyz" target="_blank">LOUIS' BLOG</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"></div><div class="post_share"><div class="social-share" data-image="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="next-post pull-full"><a href="/2021/10/22/%E4%B8%AD%E5%9B%BD%E6%B3%95%E5%BE%8B%E6%99%BA%E8%83%BD%E6%8A%80%E6%9C%AF%E8%AF%84%E6%B5%8B(CAIL2021)%EF%BC%9A%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96(Rank2).html"><img class="next-cover" src="http://cail.cipsc.org.cn/img/index_mainpic.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">中国法律智能技术评测(CAIL2021)：信息抽取(Rank2)</div></div></a></div></nav><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="twikoo-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="card-info-avatar is-center"><img class="avatar-img" src="/img/touxiang.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/><div class="author-info__name">徐耀彬</div><div class="author-info__description">做知识的原创者！</div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">11</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">标签</div><div class="length-num">3</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">分类</div><div class="length-num">7</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/isLouisHsu"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/isLouisHsu" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:is.louishsu@foxmail.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>公告</span></div><div class="announcement_content">记录和分享一些学习和开源内容，若有问题可通过邮箱is.louishsu@foxmail.com联系，欢迎交流！！</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">1.</span> <span class="toc-text">统计</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">2.</span> <span class="toc-text">计算机视觉</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">3.</span> <span class="toc-text">自然语言处理</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">4.</span> <span class="toc-text">机器学习</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">5.</span> <span class="toc-text">人工智能</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2022/07/29/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html" title="Arxiv每日速递(2022-07-29)"><img src="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Arxiv每日速递(2022-07-29)"/></a><div class="content"><a class="title" href="/2022/07/29/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html" title="Arxiv每日速递(2022-07-29)">Arxiv每日速递(2022-07-29)</a><time datetime="2022-07-29T00:45:02.445Z" title="发表于 2022-07-29 08:45:02">2022-07-29</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/10/22/%E4%B8%AD%E5%9B%BD%E6%B3%95%E5%BE%8B%E6%99%BA%E8%83%BD%E6%8A%80%E6%9C%AF%E8%AF%84%E6%B5%8B(CAIL2021)%EF%BC%9A%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96(Rank2).html" title="中国法律智能技术评测(CAIL2021)：信息抽取(Rank2)"><img src="http://cail.cipsc.org.cn/img/index_mainpic.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="中国法律智能技术评测(CAIL2021)：信息抽取(Rank2)"/></a><div class="content"><a class="title" href="/2021/10/22/%E4%B8%AD%E5%9B%BD%E6%B3%95%E5%BE%8B%E6%99%BA%E8%83%BD%E6%8A%80%E6%9C%AF%E8%AF%84%E6%B5%8B(CAIL2021)%EF%BC%9A%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96(Rank2).html" title="中国法律智能技术评测(CAIL2021)：信息抽取(Rank2)">中国法律智能技术评测(CAIL2021)：信息抽取(Rank2)</a><time datetime="2021-10-22T14:29:06.000Z" title="发表于 2021-10-22 22:29:06">2021-10-22</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/05/19/%E5%85%A8%E7%90%83%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%8A%80%E6%9C%AF%E5%88%9B%E6%96%B0%E5%A4%A7%E8%B5%9B%E3%80%90%E8%B5%9B%E9%81%93%E4%B8%80%E3%80%91%EF%BC%9A%E5%8C%BB%E5%AD%A6%E5%BD%B1%E5%83%8F%E6%8A%A5%E5%91%8A%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B.html" title="全球人工智能技术创新大赛【赛道一】：医学影像报告异常检测"><img src="https://tianchi-public.oss-cn-hangzhou.aliyuncs.com/public/files/forum/161037709574435991610377095138.jpeg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="全球人工智能技术创新大赛【赛道一】：医学影像报告异常检测"/></a><div class="content"><a class="title" href="/2021/05/19/%E5%85%A8%E7%90%83%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%8A%80%E6%9C%AF%E5%88%9B%E6%96%B0%E5%A4%A7%E8%B5%9B%E3%80%90%E8%B5%9B%E9%81%93%E4%B8%80%E3%80%91%EF%BC%9A%E5%8C%BB%E5%AD%A6%E5%BD%B1%E5%83%8F%E6%8A%A5%E5%91%8A%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B.html" title="全球人工智能技术创新大赛【赛道一】：医学影像报告异常检测">全球人工智能技术创新大赛【赛道一】：医学影像报告异常检测</a><time datetime="2021-05-19T09:57:06.000Z" title="发表于 2021-05-19 17:57:06">2021-05-19</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2020/09/16/%E8%AF%A6%E8%A7%A3%E5%91%BD%E5%90%8D%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB%E6%A8%A1%E5%9E%8B%EF%BC%9ALSTM-CRF.html" title="详解命名实体识别模型：LSTM-CRF"><img src="https://gimg2.baidu.com/image_search/src=http%3A%2F%2Fpic1.zhimg.com%2Fv2-1ed6a10dbb239a148e42df088c5870a6_1440w.jpg%3Fsource%3D172ae18b&amp;refer=http%3A%2F%2Fpic1.zhimg.com&amp;app=2002&amp;size=f9999,10000&amp;q=a80&amp;n=0&amp;g=0n&amp;fmt=jpeg?sec=1638183974&amp;t=4632f13fd487ed1cfcb12d67a6b71e52" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="详解命名实体识别模型：LSTM-CRF"/></a><div class="content"><a class="title" href="/2020/09/16/%E8%AF%A6%E8%A7%A3%E5%91%BD%E5%90%8D%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB%E6%A8%A1%E5%9E%8B%EF%BC%9ALSTM-CRF.html" title="详解命名实体识别模型：LSTM-CRF">详解命名实体识别模型：LSTM-CRF</a><time datetime="2020-09-16T09:26:44.000Z" title="发表于 2020-09-16 17:26:44">2020-09-16</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2020/06/14/%E8%AE%B0%E4%B8%80%E6%AC%A1MySQL%E8%A7%A3%E5%86%B3%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E6%97%B6%E7%9A%84%E5%88%86%E8%A1%A8%E9%97%AE%E9%A2%98.html" title="记一次MySQL解决大数据存储时的分表问题"><img src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="记一次MySQL解决大数据存储时的分表问题"/></a><div class="content"><a class="title" href="/2020/06/14/%E8%AE%B0%E4%B8%80%E6%AC%A1MySQL%E8%A7%A3%E5%86%B3%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E6%97%B6%E7%9A%84%E5%88%86%E8%A1%A8%E9%97%AE%E9%A2%98.html" title="记一次MySQL解决大数据存储时的分表问题">记一次MySQL解决大数据存储时的分表问题</a><time datetime="2020-06-14T15:24:27.000Z" title="发表于 2020-06-14 23:24:27">2020-06-14</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2022 By 徐耀彬</div><div class="footer_custom_text"><p><a style="margin-inline:5px"target="_blank"href="https://hexo.io/"><img src="https://img.shields.io/badge/Frame-Hexo-blue?style=flat&logo=hexo"title="博客框架为Hexo"alt="img"></a><a style="margin-inline:5px"target="_blank"href="https://butterfly.js.org/"><img src="https://img.shields.io/badge/Theme-Butterfly-6513df?style=flat&logo=bitdefender"title="主题采用butterfly"alt="img"></a><a style="margin-inline:5px"target="_blank"href="https://www.jsdelivr.com/"><img src="https://img.shields.io/badge/CDN-jsDelivr-orange?style=flat&logo=jsDelivr"title="本站使用JsDelivr为静态资源提供CDN加速"alt="img"></a><a style="margin-inline:5px"target="_blank"href="https://github.com/"><img src="https://img.shields.io/badge/Source-Github-d021d6?style=flat&logo=GitHub"title="本站项目由Gtihub托管"alt="img"></a><a style="margin-inline:5px"target="_blank"href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img src="https://img.shields.io/badge/Copyright-BY--NC--SA%204.0-d42328?style=flat&logo=Claris"alt="img"title="本站采用知识共享署名-非商业性使用-相同方式共享4.0国际许可协议进行许可"></a></br></p></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="font-plus" type="button" title="放大字体"><i class="fas fa-plus"></i></button><button id="font-minus" type="button" title="缩小字体"><i class="fas fa-minus"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div></div><hr/><div id="local-search-results"></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.css"><script>(() => {
  document.querySelectorAll('#article-container span.katex-display').forEach(item => {
    btf.wrap(item, 'div', '', 'katex-wrap')
  })
})()</script><script>(()=>{
  const $countDom = document.getElementById('twikoo-count')
  const init = () => {
    let initData = {
      el: '#twikoo-wrap',
      envId: 'blog-',
      region: ''
    }

    if (false) {
      const otherData = false
      initData = Object.assign(initData, otherData)
    }
    
    twikoo.init(initData)
  }

  const getCount = () => {
    twikoo.getCommentsCount({
      envId: 'blog-',
      region: '',
      urls: [window.location.pathname],
      includeReply: false
    }).then(function (res) {
      $countDom.innerText = res[0].count
    }).catch(function (err) {
      console.error(err);
    });
  }

  const loadTwikoo = (bool = false) => {
    if (typeof twikoo === 'object') {
      init()
      bool && $countDom && setTimeout(getCount,0)
    } else {
      getScript('https://cdn.jsdelivr.net/npm/twikoo/dist/twikoo.all.min.js').then(()=> {
        init()
        bool && $countDom && setTimeout(getCount,0)
      })
    }
  }

  if ('Twikoo' === 'Twikoo' || !false) {
    if (false) btf.loadComment(document.getElementById('twikoo-wrap'), loadTwikoo)
    else loadTwikoo(true)
  } else {
    window.loadOtherComment = () => {
      loadTwikoo()
    }
  }
})()</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><!-- hexo injector body_end start --> <script data-pjax>if(document.getElementById('recent-posts') && (location.pathname ==='/'|| '/' ==='all')){
    var parent = document.getElementById('recent-posts');
    var child = '<div class="recent-post-item" style="width:100%;height: auto"><div id="catalog_magnet"><div class="magnet_item"><a class="magnet_link" href="http://louishsu.xyz/categories/机器学习/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🐱 机器学习 (1)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://louishsu.xyz/categories/自然语言处理/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">📚 自然语言处理 (1)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://louishsu.xyz/categories/竞赛相关/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🎮 竞赛相关 (2)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://louishsu.xyz/categories/阅读笔记/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🎮 阅读笔记 (1)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><a class="magnet_link_more"  href="http://louishsu.xyz/categories" style="flex:1;text-align: center;margin-bottom: 10px;">查看更多...</a></div></div>';
    console.log('已挂载magnet')
    parent.insertAdjacentHTML("afterbegin",child)}
     </script><style>#catalog_magnet{flex-wrap: wrap;display: flex;width:100%;justify-content:space-between;padding: 10px 10px 0 10px;align-content: flex-start;}.magnet_item{flex-basis: calc(50% - 5px);background: #f2f2f2;margin-bottom: 10px;border-radius: 8px;transition: all 0.2s ease-in-out;}.magnet_item:hover{background: #b30070}.magnet_link_more{color:#555}.magnet_link{color:black}.magnet_link:hover{color:white}@media screen and (max-width: 600px) {.magnet_item {flex-basis: 100%;}}.magnet_link_context{display:flex;padding: 10px;font-size:16px;transition: all 0.2s ease-in-out;}.magnet_link_context:hover{padding: 10px 20px;}</style>
    <style></style>
  <script data-pjax src="https://cdn.jsdelivr.net/gh/Zfour/hexo-github-calendar@1.21/hexo_githubcalendar.js"></script>
  <script data-pjax>
        function GithubCalendarConfig(){
            var git_githubapiurl ="https://python-github-calendar-api.vercel.app/api?isLouisHsu";
            var git_color =['#ebedf0', '#fdcdec', '#fc9bd9', '#fa6ac5', '#f838b2', '#f5089f', '#c4067e', '#92055e', '#540336', '#48022f', '#30021f'];
            var git_user ="isLouisHsu";
            var parent_div_git = document.getElementById('recent-posts');
            var git_div_html = '<div class="recent-post-item" style="width:100%;height:auto;padding:10px;"><div id="github_loading" style="width:10%;height:100%;margin:0 auto;display: block"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"  viewBox="0 0 50 50" style="enable-background:new 0 0 50 50" xml:space="preserve"><path fill="#d0d0d0" d="M25.251,6.461c-10.318,0-18.683,8.365-18.683,18.683h4.068c0-8.071,6.543-14.615,14.615-14.615V6.461z" transform="rotate(275.098 25 25)"><animateTransform attributeType="xml" attributeName="transform" type="rotate" from="0 25 25" to="360 25 25" dur="0.6s" repeatCount="indefinite"></animateTransform></path></svg></div><div id="github_container"></div></div>';
            if(parent_div_git && location.pathname =='/'){
                console.log('已挂载github calendar')
                // parent_div_git.innerHTML=git_div_html+parent_div_git.innerHTML // 无报错，但不影响使用(支持pjax跳转)
                parent_div_git.insertAdjacentHTML("afterbegin",git_div_html) // 有报错，但不影响使用(支持pjax跳转)
            };
            GithubCalendar(git_githubapiurl,git_color,git_user)
        }
        if(document.getElementById('recent-posts')){
            GithubCalendarConfig()
        }
    </script>
    <style>#github_container{min-height:280px}@media screen and (max-width:650px) {#github_container{background-image:;min-height:0px}}</style>
    <style></style><script data-pjax>function electric_clock_injector_config(){
                var parent_div_git = document.getElementsByClassName('sticky_layout')[0];
                var item_html = '<div class="card-widget card-clock"><div class="card-glass"><div class="card-background"><div class="card-content"><div id="hexo_electric_clock"><img id="card-clock-loading" src="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-clock/clock/images/weather/loading.gif" style="height: 120px; width: 100%;" data-ll-status="loading" class="entered loading"></div></div></div></div></div>';
                console.log('已挂载electric_clock')
                // parent_div_git.innerHTML=item_html+parent_div_git.innerHTML // 无报错，但不影响使用(支持pjax跳转)
                parent_div_git.insertAdjacentHTML("afterbegin",item_html) // 有报错，但不影响使用(支持pjax跳转)
            }if( document.getElementsByClassName('sticky_layout')[0] && (location.pathname ==='all'|| 'all' ==='all')){

            electric_clock_injector_config()
        } </script><script src="https://pv.sohu.com/cityjson?ie=utf-8"></script><script data-pjax  src="https://cdn.jsdelivr.net/gh/Zfour/hexo-electric-clock@1.0.6/clock.js"></script><!-- hexo injector body_end end --><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"model":{"jsonPath":"/live2dw/assets/hijiki.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":false},"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body></html>