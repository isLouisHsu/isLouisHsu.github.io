<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Arxiv每日速递(2022-08-23) | LOUIS' BLOG</title><meta name="author" content="徐耀彬"><meta name="copyright" content="徐耀彬"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="本篇博文主要展示每日从Arxiv论文网站获取的最新论文列表，以计算机视觉、自然语言处理、机器学习、人工智能等大方向进行划分。 统计 今日共更新458篇论文，其中：  98篇计算机视觉（cs.CV） 50篇自然语言处理（cs.CL） 145篇机器学习（cs.LG） 80篇人工智能（cs.AI）  计算机视觉    1. 标题：BARReL: Bottleneck Attention for Adve">
<meta property="og:type" content="article">
<meta property="og:title" content="Arxiv每日速递(2022-08-23)">
<meta property="og:url" content="http://louishsu.xyz/2022/08/23/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html">
<meta property="og:site_name" content="LOUIS&#39; BLOG">
<meta property="og:description" content="本篇博文主要展示每日从Arxiv论文网站获取的最新论文列表，以计算机视觉、自然语言处理、机器学习、人工智能等大方向进行划分。 统计 今日共更新458篇论文，其中：  98篇计算机视觉（cs.CV） 50篇自然语言处理（cs.CL） 145篇机器学习（cs.LG） 80篇人工智能（cs.AI）  计算机视觉    1. 标题：BARReL: Bottleneck Attention for Adve">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png">
<meta property="article:published_time" content="2022-08-23T00:56:42.253Z">
<meta property="article:modified_time" content="2022-08-23T00:58:14.285Z">
<meta property="article:author" content="徐耀彬">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://louishsu.xyz/2022/08/23/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2022-08-23 08:58:14'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const fontSizeVal = saveToLocal.get('global-font-size')
    if (fontSizeVal !== undefined) {
      document.documentElement.style.setProperty('--global-font-size', fontSizeVal + 'px')
    }
    })(window)</script><link rel="stylesheet" href="/css/background.css"><script src="https://cdn.jsdelivr.net/npm/echarts@4.7.0/dist/echarts.min.js"></script><!-- hexo injector head_end start --><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Zfour/hexo-electric-clock@1.0.6/clock.css"><!-- hexo injector head_end end --><meta name="generator" content="Hexo 5.4.2"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="author-avatar"><img class="avatar-img" src="/img/touxiang.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">11</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">标签</div><div class="length-num">3</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">分类</div><div class="length-num">7</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/message/"><i class="fa-fw far fa-comment-dots"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa-fw fa fa-book"></i><span> 找文章</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></li><li><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></li><li><a class="site-page" href="/charts/"><i class="fa-fw fa fa-archive"></i><span> 统计</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-tools"></i><span> 工具</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/md_editor/"><i class="fa-fw fas fa-pen"></i><span> 在线markdown</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/isLouisHsu/blog/tree/master/source/_posts"><i class="fa-fw fa fa-star"></i><span> 在线push</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">LOUIS' BLOG</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/message/"><i class="fa-fw far fa-comment-dots"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa-fw fa fa-book"></i><span> 找文章</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></li><li><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></li><li><a class="site-page" href="/charts/"><i class="fa-fw fa fa-archive"></i><span> 统计</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-tools"></i><span> 工具</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/md_editor/"><i class="fa-fw fas fa-pen"></i><span> 在线markdown</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/isLouisHsu/blog/tree/master/source/_posts"><i class="fa-fw fa fa-star"></i><span> 在线push</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Arxiv每日速递(2022-08-23)<a class="post-edit-link" href="https://github.com/isLouisHsu/blog/tree/master/source_posts/Arxiv每日速递.md" title="编辑" target="_blank"><i class="fas fa-pencil-square"></i></a></h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-08-23T00:56:42.253Z" title="发表于 2022-08-23 08:56:42">2022-08-23</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2022-08-23T00:58:14.285Z" title="更新于 2022-08-23 08:58:14">2022-08-23</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">阅读笔记</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">1.3k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>7分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span><span class="post-meta-separator">|</span><span class="post-meta-commentcount"><i class="far fa-comments fa-fw post-meta-icon"></i><span class="post-meta-label">评论数:</span><a href="/2022/08/23/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html#post-comment"><span id="twikoo-count"></span></a></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><p>本篇博文主要展示每日从Arxiv论文网站获取的最新论文列表，以计算机视觉、自然语言处理、机器学习、人工智能等大方向进行划分。</p>
<h1>统计</h1>
<p>今日共更新458篇论文，其中：</p>
<ul>
<li>98篇计算机视觉（<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>）</li>
<li>50篇自然语言处理（<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>）</li>
<li>145篇机器学习（cs.LG）</li>
<li>80篇人工智能（<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>）</li>
</ul>
<h1>计算机视觉</h1>
<details>
  <summary>1. <b>标题：BARReL: Bottleneck Attention for Adversarial Robustness in Vision-Based  Reinforcement Learning</b></summary>
  <p><b>编号</b>：[2]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10481</p>
  <p><b>作者</b>：Eugene Bykovets,  Yannick Metz,  Mennatallah El-Assady,  Daniel A. Keim,  Joachim M. Buhmann</p>
  <p><b>备注</b>：5 pages, 2 figures, 3 tables</p>
  <p><b>关键词</b>：computer vision, areas of computer, vision-based reinforcement learning, vision-based reinforcement, reinforcement learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Robustness to adversarial perturbations has been explored in many areas of
computer vision. This robustness is particularly relevant in vision-based
reinforcement learning, as the actions of autonomous agents might be
safety-critic or impactful in the real world. We investigate the susceptibility
of vision-based reinforcement learning agents to gradient-based adversarial
attacks and evaluate a potential defense. We observe that Bottleneck Attention
Modules (BAM) included in CNN architectures can act as potential tools to
increase robustness against adversarial attacks. We show how learned attention
maps can be used to recover activations of a convolutional layer by restricting
the spatial activations to salient regions. Across a number of RL environments,
BAM-enhanced architectures show increased robustness during inference. Finally,
we discuss potential future research directions.</p>
  </details>
</details>
<details>
  <summary>2. <b>标题：SCONE: Surface Coverage Optimization in Unknown Environments by  Volumetric Integration</b></summary>
  <p><b>编号</b>：[15]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10449</p>
  <p><b>作者</b>：Antoine Guédon,  Pascal Monasse,  Vincent Lepetit</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：informative sensor position, View computation, problem in robotics, efficiently and accurately, long-standing problem</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Next Best View computation (NBV) is a long-standing problem in robotics, and
consists in identifying the next most informative sensor position(s) for
reconstructing a 3D object or scene efficiently and accurately. Like most
current methods, we consider NBV prediction from a depth sensor. Learning-based
methods relying on a volumetric representation of the scene are suitable for
path planning, but do not scale well with the size of the scene and have lower
accuracy than methods using a surface-based representation. However, the latter
constrain the camera to a small number of poses. To obtain the advantages of
both representations, we show that we can maximize surface metrics by Monte
Carlo integration over a volumetric representation. Our method scales to large
scenes and handles free camera motion: It takes as input an arbitrarily large
point cloud gathered by a depth sensor like Lidar systems as well as camera
poses to predict NBV. We demonstrate our approach on a novel dataset made of
large and complex 3D scenes.</p>
  </details>
</details>
<details>
  <summary>3. <b>标题：Image as a Foreign Language: BEiT Pretraining for All Vision and  Vision-Language Tasks</b></summary>
  <p><b>编号</b>：[19]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10442</p>
  <p><b>作者</b>：Wenhui Wang,  Hangbo Bao,  Li Dong,  Johan Bjorck,  Zhiliang Peng,  Qiang Liu,  Kriti Aggarwal,  Owais Khan Mohammed,  Saksham Singhal,  Subhojit Som,  Furu Wei</p>
  <p><b>备注</b>：18 pages</p>
  <p><b>关键词</b>：COCO, big convergence, introduce Multiway Transformers, multimodal foundation model, general-purpose multimodal foundation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A big convergence of language, vision, and multimodal pretraining is
emerging. In this work, we introduce a general-purpose multimodal foundation
model BEiT-3, which achieves state-of-the-art transfer performance on both
vision and vision-language tasks. Specifically, we advance the big convergence
from three aspects: backbone architecture, pretraining task, and model scaling
up. We introduce Multiway Transformers for general-purpose modeling, where the
modular architecture enables both deep fusion and modality-specific encoding.
Based on the shared backbone, we perform masked "language" modeling on images
(Imglish), texts (English), and image-text pairs ("parallel sentences") in a
unified manner. Experimental results show that BEiT-3 obtains state-of-the-art
performance on object detection (COCO), semantic segmentation (ADE20K), image
classification (ImageNet), visual reasoning (NLVR2), visual question answering
(VQAv2), image captioning (COCO), and cross-modal retrieval (Flickr30K, COCO).</p>
  </details>
</details>
<details>
  <summary>4. <b>标题：ProtoPFormer: Concentrating on Prototypical Parts in Vision Transformers  for Interpretable Image Recognition</b></summary>
  <p><b>编号</b>：[22]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10431</p>
  <p><b>作者</b>：Mengqi Xue,  Qihan Huang,  Haofei Zhang,  Lechao Cheng,  Jie Song,  Minghui Wu,  Mingli Song</p>
  <p><b>备注</b>：Arxiv preprint; 9 pages, 6 figures, 2 tables</p>
  <p><b>关键词</b>：explainable artificial intelligence, follow-up studies due, drawn wide attention, Prototypical part network, artificial intelligence</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Prototypical part network (ProtoPNet) has drawn wide attention and boosted
many follow-up studies due to its self-explanatory property for explainable
artificial intelligence (XAI). However, when directly applying ProtoPNet on
vision transformer (ViT) backbones, learned prototypes have a ''distraction''
problem: they have a relatively high probability of being activated by the
background and pay less attention to the foreground. The powerful capability of
modeling long-term dependency makes the transformer-based ProtoPNet hard to
focus on prototypical parts, thus severely impairing its inherent
interpretability. This paper proposes prototypical part transformer
(ProtoPFormer) for appropriately and effectively applying the prototype-based
method with ViTs for interpretable image recognition. The proposed method
introduces global and local prototypes for capturing and highlighting the
representative holistic and partial features of targets according to the
architectural characteristics of ViTs. The global prototypes are adopted to
provide the global view of objects to guide local prototypes to concentrate on
the foreground while eliminating the influence of the background. Afterwards,
local prototypes are explicitly supervised to concentrate on their respective
prototypical visual parts, increasing the overall interpretability. Extensive
experiments demonstrate that our proposed global and local prototypes can
mutually correct each other and jointly make final decisions, which faithfully
and transparently reason the decision-making processes associatively from the
whole and local perspectives, respectively. Moreover, ProtoPFormer consistently
achieves superior performance and visualization results over the
state-of-the-art (SOTA) prototype-based baselines. Our code has been released
at this https URL.</p>
  </details>
</details>
<details>
  <summary>5. <b>标题：Patient-level Microsatellite Stability Assessment from Whole Slide  Images By Combining Momentum Contrast Learning and Group Patch Embeddings</b></summary>
  <p><b>编号</b>：[23]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10429</p>
  <p><b>作者</b>：Daniel Shats,  Hadar Hezi,  Guy Shani,  Yosef E. Maruvka,  Moti Freiman</p>
  <p><b>备注</b>：To appear in the proceedings of the ECCV workshop on Medical Computer Vision (ECCV-MCV 2022). Link: this https URL</p>
  <p><b>关键词</b>：personalizing treatment regime, WSI high resolution, patient colorectal cancer, treatment regime, WSI</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Assessing microsatellite stability status of a patient's colorectal cancer is
crucial in personalizing treatment regime. Recently,
convolutional-neural-networks (CNN) combined with transfer-learning approaches
were proposed to circumvent traditional laboratory testing for determining
microsatellite status from hematoxylin and eosin stained biopsy whole slide
images (WSI). However, the high resolution of WSI practically prevent direct
classification of the entire WSI. Current approaches bypass the WSI high
resolution by first classifying small patches extracted from the WSI, and then
aggregating patch-level classification logits to deduce the patient-level
status. Such approaches limit the capacity to capture important information
which resides at the high resolution WSI data. We introduce an effective
approach to leverage WSI high resolution information by momentum contrastive
learning of patch embeddings along with training a patient-level classifier on
groups of those embeddings. Our approach achieves up to 7.4\% better accuracy
compared to the straightforward patch-level classification and patient level
aggregation approach with a higher stability (AUC, $0.91 \pm 0.01$ vs. $0.85
\pm 0.04$, p-value$<0.01$). our code can be found at this https url.< p>
  </0.01$).></p></details>
</details>
<details>
  <summary>6. <b>标题：FurryGAN: High Quality Foreground-aware Image Synthesis</b></summary>
  <p><b>编号</b>：[26]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10422</p>
  <p><b>作者</b>：Jeongmin Bae,  Mingi Kwon,  Youngjung Uh</p>
  <p><b>备注</b>：Accepted to ECCV 2022. Project page: this https URL</p>
  <p><b>关键词</b>：Foreground-aware image synthesis, image synthesis aims, synthesis aims, aims to generate, image</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Foreground-aware image synthesis aims to generate images as well as their
foreground masks. A common approach is to formulate an image as an masked
blending of a foreground image and a background image. It is a challenging
problem because it is prone to reach the trivial solution where either image
overwhelms the other, i.e., the masks become completely full or empty, and the
foreground and background are not meaningfully separated. We present FurryGAN
with three key components: 1) imposing both the foreground image and the
composite image to be realistic, 2) designing a mask as a combination of coarse
and fine masks, and 3) guiding the generator by an auxiliary mask predictor in
the discriminator. Our method produces realistic images with remarkably
detailed alpha masks which cover hair, fur, and whiskers in a fully
unsupervised manner.</p>
  </details>
</details>
<details>
  <summary>7. <b>标题：MetaFi: Device-Free Pose Estimation via Commodity WiFi for Metaverse  Avatar Simulation</b></summary>
  <p><b>编号</b>：[28]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10414</p>
  <p><b>作者</b>：Jianfei Yang,  Yunjiao Zhou,  He Huang,  Han Zou,  Lihua Xie</p>
  <p><b>备注</b>：6 pages, 3 figures, 3 tables</p>
  <p><b>关键词</b>：physical user, activities and interact, human pose estimation, human pose, Avatar refers</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Avatar refers to a representative of a physical user in the virtual world
that can engage in different activities and interact with other objects in
metaverse. Simulating the avatar requires accurate human pose estimation.
Though camera-based solutions yield remarkable performance, they encounter the
privacy issue and degraded performance caused by varying illumination,
especially in smart home. In this paper, we propose a WiFi-based IoT-enabled
human pose estimation scheme for metaverse avatar simulation, namely MetaFi.
Specifically, a deep neural network is designed with customized convolutional
layers and residual blocks to map the channel state information to human pose
landmarks. It is enforced to learn the annotations from the accurate computer
vision model, thus achieving cross-modal supervision. WiFi is ubiquitous and
robust to illumination, making it a feasible solution for avatar applications
in smart home. The experiments are conducted in the real world, and the results
show that the MetaFi achieves very high performance with a PCK@50 of 95.23%.</p>
  </details>
</details>
<details>
  <summary>8. <b>标题：Minimizing the Effect of Noise and Limited Dataset Size in Image  Classification Using Depth Estimation as an Auxiliary Task with Deep  Multitask Learning</b></summary>
  <p><b>编号</b>：[35]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10390</p>
  <p><b>作者</b>：Khashayar Namdar,  Partoo Vafaeikia,  Farzad Khalvati</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Machine Learning, goal of Machine, major concerns, ultimate goal, limited dataset size</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Generalizability is the ultimate goal of Machine Learning (ML) image
classifiers, for which noise and limited dataset size are among the major
concerns. We tackle these challenges through utilizing the framework of deep
Multitask Learning (dMTL) and incorporating image depth estimation as an
auxiliary task. On a customized and depth-augmented derivation of the MNIST
dataset, we show a) multitask loss functions are the most effective approach of
implementing dMTL, b) limited dataset size primarily contributes to
classification inaccuracy, and c) depth estimation is mostly impacted by noise.
In order to further validate the results, we manually labeled the NYU Depth V2
dataset for scene classification tasks. As a contribution to the field, we have
made the data in python native format publicly available as an open-source
dataset and provided the scene labels. Our experiments on MNIST and
NYU-Depth-V2 show dMTL improves generalizability of the classifiers when the
dataset is noisy and the number of examples is limited.</p>
  </details>
</details>
<details>
  <summary>9. <b>标题：Fight Fire With Fire: Reversing Skin Adversarial Examples by Multiscale  Diffusive and Denoising Aggregation Mechanism</b></summary>
  <p><b>编号</b>：[44]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10373</p>
  <p><b>作者</b>：Yongwei Wang,  Yuan Li,  Zhiqi Shen</p>
  <p><b>备注</b>：11 pages</p>
  <p><b>关键词</b>：cancer diagnosis models, skin cancer diagnosis, skin cancer, Reliable skin cancer, cancer diagnosis</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Reliable skin cancer diagnosis models play an essential role in early
screening and medical intervention. Prevailing computer-aided skin cancer
classification systems employ deep learning approaches. However, recent studies
reveal their extreme vulnerability to adversarial attacks -- often
imperceptible perturbations to significantly reduce performances of skin cancer
diagnosis models. To mitigate these threats, this work presents a simple,
effective and resource-efficient defense framework by reverse engineering
adversarial perturbations in skin cancer images. Specifically, a multiscale
image pyramid is first established to better preserve discriminative structures
in medical imaging domain. To neutralize adversarial effects, skin images at
different scales are then progressively diffused by injecting isotropic
Gaussian noises to move the adversarial examples to the clean image manifold.
Crucially, to further reverse adversarial noises and suppress redundant
injected noises, a novel multiscale denoising mechanism is carefully designed
that aggregates image information from neighboring scales. We evaluated the
defensive effectiveness of our method on ISIC 2019, a largest skin cancer
multiclass classification dataset. Experimental results demonstrate that the
proposed method can successfully reverse adversarial perturbations from
different attacks and significantly outperform some state-of-the-art methods in
defending skin cancer diagnosis models.</p>
  </details>
</details>
<details>
  <summary>10. <b>标题：Collaborative Perception for Autonomous Driving: Current Status and  Future Trend</b></summary>
  <p><b>编号</b>：[45]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10371</p>
  <p><b>作者</b>：Shunli Ren,  Siheng Chen,  Wenjun Zhang</p>
  <p><b>备注</b>：Published in Proceedings of CCSICC 2021</p>
  <p><b>关键词</b>：autonomous driving system, great progress recently, made great progress, driving system, progress recently</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Perception is one of the crucial module of the autonomous driving system,
which has made great progress recently. However, limited ability of individual
vehicles results in the bottleneck of improvement of the perception
performance. To break through the limits of individual perception,
collaborative perception has been proposed which enables vehicles to share
information to perceive the environments beyond line-of-sight and
field-of-view. In this paper, we provide a review of the related work about the
promising collaborative perception technology, including introducing the
fundamental concepts, generalizing the collaboration modes and summarizing the
key ingredients and applications of collaborative perception. Finally, we
discuss the open challenges and issues of this research area and give some
potential further directions.</p>
  </details>
</details>
<details>
  <summary>11. <b>标题：A Medical Semantic-Assisted Transformer for Radiographic Report  Generation</b></summary>
  <p><b>编号</b>：[50]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10358</p>
  <p><b>作者</b>：Zhanyu Wang,  Mingkang Tang,  Lei Wang,  Xiu Li,  Luping Zhou</p>
  <p><b>备注</b>：MICCAI 2022</p>
  <p><b>关键词</b>：automatically generate accurate, challenging cross-domain task, challenging cross-domain, aims to automatically, automatically generate</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Automated radiographic report generation is a challenging cross-domain task
that aims to automatically generate accurate and semantic-coherence reports to
describe medical images. Despite the recent progress in this field, there are
still many challenges at least in the following aspects. First, radiographic
images are very similar to each other, and thus it is difficult to capture the
fine-grained visual differences using CNN as the visual feature extractor like
many existing methods. Further, semantic information has been widely applied to
boost the performance of generation tasks (e.g. image captioning), but existing
methods often fail to provide effective medical semantic features. Toward
solving those problems, in this paper, we propose a memory-augmented sparse
attention block utilizing bilinear pooling to capture the higher-order
interactions between the input fine-grained image features while producing
sparse attention. Moreover, we introduce a novel Medical Concepts Generation
Network (MCGN) to predict fine-grained semantic concepts and incorporate them
into the report generation process as guidance. Our proposed method shows
promising performance on the recently released largest benchmark MIMIC-CXR. It
outperforms multiple state-of-the-art methods in image captioning and medical
report generation.</p>
  </details>
</details>
<details>
  <summary>12. <b>标题：Neuro-Symbolic Visual Dialog</b></summary>
  <p><b>编号</b>：[52]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10353</p>
  <p><b>作者</b>：Adnen Abdessaied,  Mihai Bâce,  Andreas Bulling</p>
  <p><b>备注</b>：To appear at COLING 2022</p>
  <p><b>关键词</b>：multi-round visually-grounded reasoning, combine deep learning, symbolic program execution, propose Neuro-Symbolic Visual, visually-grounded reasoning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose Neuro-Symbolic Visual Dialog (NSVD) -the first method to combine
deep learning and symbolic program execution for multi-round visually-grounded
reasoning. NSVD significantly outperforms existing purely-connectionist methods
on two key challenges inherent to visual dialog: long-distance co-reference
resolution as well as vanishing question-answering performance. We demonstrate
the latter by proposing a more realistic and stricter evaluation scheme in
which we use predicted answers for the full dialog history when calculating
accuracy. We describe two variants of our model and show that using this new
scheme, our best model achieves an accuracy of 99.72% on CLEVR-Dialog -a
relative improvement of more than 10% over the state of the art while only
requiring a fraction of training data. Moreover, we demonstrate that our
neuro-symbolic models have a higher mean first failure round, are more robust
against incomplete dialog histories, and generalise better not only to dialogs
that are up to three times longer than those seen during training but also to
unseen question types and scenes.</p>
  </details>
</details>
<details>
  <summary>13. <b>标题：Intensity-Aware Loss for Dynamic Facial Expression Recognition in the  Wild</b></summary>
  <p><b>编号</b>：[55]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10335</p>
  <p><b>作者</b>：Hanting Li,  Hongjing Niu,  Zhaoqing Zhu,  Feng Zhao</p>
  <p><b>备注</b>：8 pages</p>
  <p><b>关键词</b>：facial expression recognition, expression recognition scene, natural expression recognition, expression recognition, image-based static facial</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Compared with the image-based static facial expression recognition (SFER)
task, the dynamic facial expression recognition (DFER) task based on video
sequences is closer to the natural expression recognition scene. However, DFER
is often more challenging. One of the main reasons is that video sequences
often contain frames with different expression intensities, especially for the
facial expressions in the real-world scenarios, while the images in SFER
frequently present uniform and high expression intensities. However, if the
expressions with different intensities are treated equally, the features
learned by the networks will have large intra-class and small inter-class
differences, which is harmful to DFER. To tackle this problem, we propose the
global convolution-attention block (GCA) to rescale the channels of the feature
maps. In addition, we introduce the intensity-aware loss (IAL) in the training
process to help the network distinguish the samples with relatively low
expression intensities. Experiments on two in-the-wild dynamic facial
expression datasets (i.e., DFEW and FERV39k) indicate that our method
outperforms the state-of-the-art DFER approaches. The source code will be made
publicly available.</p>
  </details>
</details>
<details>
  <summary>14. <b>标题：To show or not to show: Redacting sensitive text from videos of  electronic displays</b></summary>
  <p><b>编号</b>：[84]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10270</p>
  <p><b>作者</b>：Abhishek Mukhopadhyay,  Shubham Agarwal,  Patrick Dylan Zwick,  Pradipta Biswas</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：increasing prevalence, maintain the privacy, Google Cloud Vision, video recordings, OCR</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>With the increasing prevalence of video recordings there is a growing need
for tools that can maintain the privacy of those recorded. In this paper, we
define an approach for redacting personally identifiable text from videos using
a combination of optical character recognition (OCR) and natural language
processing (NLP) techniques. We examine the relative performance of this
approach when used with different OCR models, specifically Tesseract and the
OCR system from Google Cloud Vision (GCV). For the proposed approach the
performance of GCV, in both accuracy and speed, is significantly higher than
Tesseract. Finally, we explore the advantages and disadvantages of both models
in real-world applications.</p>
  </details>
</details>
<details>
  <summary>15. <b>标题：Learning Branched Fusion and Orthogonal Projection for Face-Voice  Association</b></summary>
  <p><b>编号</b>：[104]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10238</p>
  <p><b>作者</b>：Muhammad Saad Saeed,  Shah Nawaz,  Muhammad Haris Khan,  Sajid Javed,  Muhammad Haroon Yousaf,  Alessio Del Bue</p>
  <p><b>备注</b>：Submitted: IEEE Transactions on Multimedia. arXiv admin note: substantial text overlap with arXiv:2112.10483</p>
  <p><b>关键词</b>：celebrities leveraging audio-visual, leveraging audio-visual information, Recent years, information from YouTube, increased interest</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent years have seen an increased interest in establishing association
between faces and voices of celebrities leveraging audio-visual information
from YouTube. Prior works adopt metric learning methods to learn an embedding
space that is amenable for associated matching and verification tasks. Albeit
showing some progress, such formulations are, however, restrictive due to
dependency on distance-dependent margin parameter, poor run-time training
complexity, and reliance on carefully crafted negative mining procedures. In
this work, we hypothesize that an enriched representation coupled with an
effective yet efficient supervision is important towards realizing a
discriminative joint embedding space for face-voice association tasks. To this
end, we propose a light-weight, plug-and-play mechanism that exploits the
complementary cues in both modalities to form enriched fused embeddings and
clusters them based on their identity labels via orthogonality constraints. We
coin our proposed mechanism as fusion and orthogonal projection (FOP) and
instantiate in a two-stream network. The overall resulting framework is
evaluated on VoxCeleb1 and MAV-Celeb datasets with a multitude of tasks,
including cross-modal verification and matching. Results reveal that our method
performs favourably against the current state-of-the-art methods and our
proposed formulation of supervision is more effective and efficient than the
ones employed by the contemporary methods. In addition, we leverage cross-modal
verification and matching tasks to analyze the impact of multiple languages on
face-voice association. Code is available:
\url{this https URL}</p>
  </details>
</details>
<details>
  <summary>16. <b>标题：An anomaly detection approach for backdoored neural networks: face  recognition as a case study</b></summary>
  <p><b>编号</b>：[107]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10231</p>
  <p><b>作者</b>：Alexander Unnervik,  Sébastien Marcel</p>
  <p><b>备注</b>：Accepted at Biosig 2022, 8 pages, 4 figures</p>
  <p><b>关键词</b>：jeopardizing proper behavior, embed functionality jeopardizing, functionality jeopardizing proper, machine learning, jeopardizing proper</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Backdoor attacks allow an attacker to embed functionality jeopardizing proper
behavior of any algorithm, machine learning or not. This hidden functionality
can remain inactive for normal use of the algorithm until activated by the
attacker. Given how stealthy backdoor attacks are, consequences of these
backdoors could be disastrous if such networks were to be deployed for
applications as critical as border or access control. In this paper, we propose
a novel backdoored network detection method based on the principle of anomaly
detection, involving access to the clean part of the training data and the
trained network. We highlight its promising potential when considering various
triggers, locations and identity pairs, without the need to make any
assumptions on the nature of the backdoor and its setup. We test our method on
a novel dataset of backdoored networks and report detectability results with
perfect scores.</p>
  </details>
</details>
<details>
  <summary>17. <b>标题：Dynamic Adaptive Threshold based Learning for Noisy Annotations Robust  Facial Expression Recognition</b></summary>
  <p><b>编号</b>：[112]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10221</p>
  <p><b>作者</b>：Darshan Gera,  Naveen Siva Kumar Badveeti,  Bobbili Veerendra Raj Kumar,  S Balasubramanian</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：facial expression recognition, real-world facial expression, noisy annotations due, expression recognition, facial expression</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The real-world facial expression recognition (FER) datasets suffer from noisy
annotations due to crowd-sourcing, ambiguity in expressions, the subjectivity
of annotators and inter-class similarity. However, the recent deep networks
have strong capacity to memorize the noisy annotations leading to corrupted
feature embedding and poor generalization. To handle noisy annotations, we
propose a dynamic FER learning framework (DNFER) in which clean samples are
selected based on dynamic class specific threshold during training.
Specifically, DNFER is based on supervised training using selected clean
samples and unsupervised consistent training using all the samples. During
training, the mean posterior class probabilities of each mini-batch is used as
dynamic class-specific threshold to select the clean samples for supervised
training. This threshold is independent of noise rate and does not need any
clean data unlike other methods. In addition, to learn from all samples, the
posterior distributions between weakly-augmented image and strongly-augmented
image are aligned using an unsupervised consistency loss. We demonstrate the
robustness of DNFER on both synthetic as well as on real noisy annotated FER
datasets like RAFDB, FERPlus, SFEW and AffectNet.</p>
  </details>
</details>
<details>
  <summary>18. <b>标题：PoseBERT: A Generic Transformer Module for Temporal 3D Human Modeling</b></summary>
  <p><b>编号</b>：[115]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10211</p>
  <p><b>作者</b>：Fabien Baradel,  Romain Brégier,  Thibault Groueix,  Philippe Weinzaepfel,  Yannis Kalantidis,  Grégory Rogez</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：videos requires datasets, expensive to obtain, videos requires, requires datasets, datasets with annotations</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Training state-of-the-art models for human pose estimation in videos requires
datasets with annotations that are really hard and expensive to obtain.
Although transformers have been recently utilized for body pose sequence
modeling, related methods rely on pseudo-ground truth to augment the currently
limited training data available for learning such models. In this paper, we
introduce PoseBERT, a transformer module that is fully trained on 3D Motion
Capture (MoCap) data via masked modeling. It is simple, generic and versatile,
as it can be plugged on top of any image-based model to transform it in a
video-based model leveraging temporal information. We showcase variants of
PoseBERT with different inputs varying from 3D skeleton keypoints to rotations
of a 3D parametric model for either the full body (SMPL) or just the hands
(MANO). Since PoseBERT training is task agnostic, the model can be applied to
several tasks such as pose refinement, future pose prediction or motion
completion without finetuning. Our experimental results validate that adding
PoseBERT on top of various state-of-the-art pose estimation methods
consistently improves their performances, while its low computational cost
allows us to use it in a real-time demo for smoothly animating a robotic hand
via a webcam. Test code and models are available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>19. <b>标题：Learning Low Bending and Low Distortion Manifold Embeddings: Theory and  Applications</b></summary>
  <p><b>编号</b>：[119]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10193</p>
  <p><b>作者</b>：Juliane Braunsmann,  Marko Rajković,  Martin Rumpf,  Benedikt Wirth</p>
  <p><b>备注</b>：27 pages, 10 figures. This publication is an extended version of the previous conference proceeding presented at DiffCVML 2021</p>
  <p><b>关键词</b>：data, dimension reduction, reduction of high-dimensional, manifold, input data manifold</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Autoencoders, which consist of an encoder and a decoder, are widely used in
machine learning for dimension reduction of high-dimensional data. The encoder
embeds the input data manifold into a lower-dimensional latent space, while the
decoder represents the inverse map, providing a parametrization of the data
manifold by the manifold in latent space. A good regularity and structure of
the embedded manifold may substantially simplify further data processing tasks
such as cluster analysis or data interpolation. We propose and analyze a novel
regularization for learning the encoder component of an autoencoder: a loss
functional that prefers isometric, extrinsically flat embeddings and allows to
train the encoder on its own. To perform the training it is assumed that for
pairs of nearby points on the input manifold their local Riemannian distance
and their local Riemannian average can be evaluated. The loss functional is
computed via Monte Carlo integration with different sampling strategies for
pairs of points on the input manifold. Our main theorem identifies a geometric
loss functional of the embedding map as the $\Gamma$-limit of the
sampling-dependent loss functionals. Numerical tests, using image data that
encodes different explicitly given data manifolds, show that smooth manifold
embeddings into latent space are obtained. Due to the promotion of extrinsic
flatness, these embeddings are regular enough such that interpolation between
not too distant points on the manifold is well approximated by linear
interpolation in latent space as one possible postprocessing.</p>
  </details>
</details>
<details>
  <summary>20. <b>标题：Aesthetics Driven Autonomous Time-Lapse Photography Generation by  Virtual and Real Robots</b></summary>
  <p><b>编号</b>：[122]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10181</p>
  <p><b>作者</b>：Xiaobo Gao,  Qi Kuang,  Xin Jin,  Bin Zhou,  Boyan Dong,  Xunyu Wang</p>
  <p><b>备注</b>：5 pages, 3 figures, on going research</p>
  <p><b>关键词</b>：Time-lapse photography, Time-lapse, visual attraction, time-lapse videos, employed in movies</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Time-lapse photography is employed in movies and promotional films because it
can reflect the passage of time in a short time and strengthen the visual
attraction. However, since it takes a long time and requires the stable
shooting, it is a great challenge for the photographer.
In this article, we propose a time-lapse photography system with virtual and
real robots. To help users shoot time-lapse videos efficiently, we first
parameterize the time-lapse photography and propose a parameter optimization
method. For different parameters, different aesthetic models, including image
and video aesthetic quality assessment networks, are used to generate optimal
parameters. Then we propose a time-lapse photography interface to facilitate
users to view and adjust parameters and use virtual robots to conduct virtual
photography in a three-dimensional scene. The system can also export the
parameters and provide them to real robots so that the time-lapse videos can be
filmed in the real world.
In addition, we propose a time-lapse photography aesthetic assessment method
that can automatically evaluate the aesthetic quality of time-lapse video.
The experimental results show that our method can efficiently obtain the
time-lapse videos. We also conduct a user study. The results show that our
system has the similar effect as professional photographers and is more
efficient.</p>
  </details>
</details>
<details>
  <summary>21. <b>标题：TaCo: Textual Attribute Recognition via Contrastive Learning</b></summary>
  <p><b>编号</b>：[123]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10180</p>
  <p><b>作者</b>：Chang Nie,  Yiqing Hu,  Yanqiu Qu,  Hao Liu,  Deqiang Jiang,  Bo Ren</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：comprehensive practical applications, favor comprehensive practical, recognition favor comprehensive, core design elements, page style</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As textual attributes like font are core design elements of document format
and page style, automatic attributes recognition favor comprehensive practical
applications. Existing approaches already yield satisfactory performance in
differentiating disparate attributes, but they still suffer in distinguishing
similar attributes with only subtle difference. Moreover, their performance
drop severely in real-world scenarios where unexpected and obvious imaging
distortions appear. In this paper, we aim to tackle these problems by proposing
TaCo, a contrastive framework for textual attribute recognition tailored toward
the most common document scenes. Specifically, TaCo leverages contrastive
learning to dispel the ambiguity trap arising from vague and open-ended
attributes. To realize this goal, we design the learning paradigm from three
perspectives: 1) generating attribute views, 2) extracting subtle but crucial
details, and 3) exploiting valued view pairs for learning, to fully unlock the
pre-training potential. Extensive experiments show that TaCo surpasses the
supervised counterparts and advances the state-of-the-art remarkably on
multiple attribute recognition tasks. Online services of TaCo will be made
available.</p>
  </details>
</details>
<details>
  <summary>22. <b>标题：Multi-Granularity Distillation Scheme Towards Lightweight  Semi-Supervised Semantic Segmentation</b></summary>
  <p><b>编号</b>：[127]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10169</p>
  <p><b>作者</b>：Jie Qin,  Jie Wu,  Ming Li,  Xuefeng Xiao,  Min Zheng,  Xingang Wang</p>
  <p><b>备注</b>：Accepted by ECCV2022</p>
  <p><b>关键词</b>：Albeit with varying, varying degrees, degrees of progress, data, data cooperative distillation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Albeit with varying degrees of progress in the field of Semi-Supervised
Semantic Segmentation, most of its recent successes are involved in unwieldy
models and the lightweight solution is still not yet explored. We find that
existing knowledge distillation techniques pay more attention to pixel-level
concepts from labeled data, which fails to take more informative cues within
unlabeled data into account. Consequently, we offer the first attempt to
provide lightweight SSSS models via a novel multi-granularity distillation
(MGD) scheme, where multi-granularity is captured from three aspects: i)
complementary teacher structure; ii) labeled-unlabeled data cooperative
distillation; iii) hierarchical and multi-levels loss setting. Specifically,
MGD is formulated as a labeled-unlabeled data cooperative distillation scheme,
which helps to take full advantage of diverse data characteristics that are
essential in the semi-supervised setting. Image-level semantic-sensitive loss,
region-level content-aware loss, and pixel-level consistency loss are set up to
enrich hierarchical distillation abstraction via structurally complementary
teachers. Experimental results on PASCAL VOC2012 and Cityscapes reveal that MGD
can outperform the competitive approaches by a large margin under diverse
partition protocols. For example, the performance of ResNet-18 and MobileNet-v2
backbone is boosted by 11.5% and 4.6% respectively under 1/16 partition
protocol on Cityscapes. Although the FLOPs of the model backbone is compressed
by 3.4-5.3x (ResNet-18) and 38.7-59.6x (MobileNetv2), the model manages to
achieve satisfactory segmentation results.</p>
  </details>
</details>
<details>
  <summary>23. <b>标题：Prompt-Matched Semantic Segmentation</b></summary>
  <p><b>编号</b>：[134]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10159</p>
  <p><b>作者</b>：Lingbo Liu,  Bruce X.B. Yu,  Jianlong Chang,  Qi Tian,  Chang-Wen Chen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：efficiently adapt pre-trained, efficiently adapt, image semantic segmentation, adapt pre-trained foundation, semantic segmentation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The objective of this work is to explore how to effectively and efficiently
adapt pre-trained foundation models to various downstream tasks of image
semantic segmentation. Conventional methods usually fine-tuned the whole
networks for each specific dataset and it was burdensome to store the massive
parameters of these networks. A few recent works attempted to insert some
trainable parameters into the frozen network to learn visual prompts for
efficient tuning. However, these works significantly modified the original
structure of standard modules, making them inoperable on many existing
high-speed inference devices, where standard modules and their parameters have
been embedded. To facilitate prompt-based semantic segmentation, we propose a
novel Inter-Stage Prompt-Matched Framework, which maintains the original
structure of the foundation model while generating visual prompts adaptively
for task-oriented tuning. Specifically, the pre-trained model is first divided
into multiple stages, and their parameters are frozen and shared for all
semantic segmentation tasks. A lightweight module termed Semantic-aware Prompt
Matcher is then introduced to hierarchically interpolate between two stages to
learn reasonable prompts for each specific task under the guidance of interim
semantic maps. In this way, we can better stimulate the pre-trained knowledge
of the frozen model to learn semantic concepts effectively on downstream
datasets. Extensive experiments conducted on five benchmarks show that the
proposed method can achieve a promising trade-off between parameter efficiency
and performance effectiveness.</p>
  </details>
</details>
<details>
  <summary>24. <b>标题：Meta-Causal Feature Learning for Out-of-Distribution Generalization</b></summary>
  <p><b>编号</b>：[135]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10156</p>
  <p><b>作者</b>：Yuqing Wang,  Xiangxian Li,  Zhuang Qi,  Jingyu Li,  Xuelong Li,  Xiangxu Meng,  Lei Meng</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：generalization problem, invariant feature learning, powerful tool, tool to handle, aims to extract</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Causal inference has become a powerful tool to handle the out-of-distribution
(OOD) generalization problem, which aims to extract the invariant features.
However, conventional methods apply causal learners from multiple data splits,
which may incur biased representation learning from imbalanced data
distributions and difficulty in invariant feature learning from heterogeneous
sources. To address these issues, this paper presents a balanced meta-causal
learner (BMCL), which includes a balanced task generation module (BTG) and a
meta-causal feature learning module (MCFL). Specifically, the BTG module learns
to generate balanced subsets by a self-learned partitioning algorithm with
constraints on the proportions of sample classes and contexts. The MCFL module
trains a meta-learner adapted to different distributions. Experiments conducted
on NICO++ dataset verified that BMCL effectively identifies the class-invariant
visual regions for classification and may serve as a general framework to
improve the performance of the state-of-the-art methods.</p>
  </details>
</details>
<details>
  <summary>25. <b>标题：STS: Surround-view Temporal Stereo for Multi-view 3D Detection</b></summary>
  <p><b>编号</b>：[136]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10145</p>
  <p><b>作者</b>：Zengran Wang,  Chen Min,  Zheng Ge,  Yinhao Li,  Zeming Li,  Hongyu Yang,  Di Huang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：essential to multi-view, Surround-view Temporal Stereo, depth, monocular depth, Temporal Stereo</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Learning accurate depth is essential to multi-view 3D object detection.
Recent approaches mainly learn depth from monocular images, which confront
inherent difficulties due to the ill-posed nature of monocular depth learning.
Instead of using a sole monocular depth method, in this work, we propose a
novel Surround-view Temporal Stereo (STS) technique that leverages the geometry
correspondence between frames across time to facilitate accurate depth
learning. Specifically, we regard the field of views from all cameras around
the ego vehicle as a unified view, namely surroundview, and conduct temporal
stereo matching on it. The resulting geometrical correspondence between
different frames from STS is utilized and combined with the monocular depth to
yield final depth prediction. Comprehensive experiments on nuScenes show that
STS greatly boosts 3D detection ability, notably for medium and long distance
objects. On BEVDepth with ResNet-50 backbone, STS improves mAP and NDS by 2.6%
and 1.4%, respectively. Consistent improvements are observed when using a
larger backbone and a larger image resolution, demonstrating its effectiveness</p>
  </details>
</details>
<details>
  <summary>26. <b>标题：Rethinking Knowledge Distillation via Cross-Entropy</b></summary>
  <p><b>编号</b>：[139]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10139</p>
  <p><b>作者</b>：Zhendong Yang,  Zhe Li,  Yuan Gong,  Tianke Zhang,  Shanshan Lao,  Chun Yuan,  Yu Li</p>
  <p><b>备注</b>：2 figures, 8 tables</p>
  <p><b>关键词</b>：Knowledge Distillation, loss, boosted various tasks, developed extensively, extensively and boosted</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Knowledge Distillation (KD) has developed extensively and boosted various
tasks. The classical KD method adds the KD loss to the original cross-entropy
(CE) loss. We try to decompose the KD loss to explore its relation with the CE
loss. Surprisingly, we find it can be regarded as a combination of the CE loss
and an extra loss which has the identical form as the CE loss. However, we
notice the extra loss forces the student's relative probability to learn the
teacher's absolute probability. Moreover, the sum of the two probabilities is
different, making it hard to optimize. To address this issue, we revise the
formulation and propose a distributed loss. In addition, we utilize teachers'
target output as the soft target, proposing the soft loss. Combining the soft
loss and the distributed loss, we propose a new KD loss (NKD). Furthermore, we
smooth students' target output to treat it as the soft target for training
without teachers and propose a teacher-free new KD loss (tf-NKD). Our method
achieves state-of-the-art performance on CIFAR-100 and ImageNet. For example,
with ResNet-34 as the teacher, we boost the ImageNet Top-1 accuracy of ResNet18
from 69.90% to 71.96%. In training without teachers, MobileNet, ResNet-18 and
SwinTransformer-Tiny achieve 70.04%, 70.76%, and 81.48%, which are 0.83%,
0.86%, and 0.30% higher than the baseline, respectively. The code is available
at this https URL.</p>
  </details>
</details>
<details>
  <summary>27. <b>标题：SWEM: Towards Real-Time Video Object Segmentation with Sequential  Weighted Expectation-Maximization</b></summary>
  <p><b>编号</b>：[144]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10128</p>
  <p><b>作者</b>：Zhihui Lin,  Tianyu Yang,  Maomao Li,  Ziyu Wang,  Chun Yuan,  Wenhao Jiang,  Wei Liu</p>
  <p><b>备注</b>：15 pages with Supplementary Material</p>
  <p><b>关键词</b>：video object segmentation, semi-supervised video object, object segmentation, based on space-time, significantly ahead</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Matching-based methods, especially those based on space-time memory, are
significantly ahead of other solutions in semi-supervised video object
segmentation (VOS). However, continuously growing and redundant template
features lead to an inefficient inference. To alleviate this, we propose a
novel Sequential Weighted Expectation-Maximization (SWEM) network to greatly
reduce the redundancy of memory features. Different from the previous methods
which only detect feature redundancy between frames, SWEM merges both
intra-frame and inter-frame similar features by leveraging the sequential
weighted EM algorithm. Further, adaptive weights for frame features endow SWEM
with the flexibility to represent hard samples, improving the discrimination of
templates. Besides, the proposed method maintains a fixed number of template
features in memory, which ensures the stable inference complexity of the VOS
system. Extensive experiments on commonly used DAVIS and YouTube-VOS datasets
verify the high efficiency (36 FPS) and high performance (84.3\%
$\mathcal{J}\&\mathcal{F}$ on DAVIS 2017 validation dataset) of SWEM. Code is
available at: this https URL.</p>
  </details>
</details>
<details>
  <summary>28. <b>标题：Revising Image-Text Retrieval via Multi-Modal Entailment</b></summary>
  <p><b>编号</b>：[146]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10126</p>
  <p><b>作者</b>：Xu Yan,  Chunhui Ai,  Ziqiang Cao,  Min Cao,  Sujian Li,  Wenjie Chen,  Guohong Fu</p>
  <p><b>备注</b>：10 pages</p>
  <p><b>关键词</b>：high-quality labeled data, image-text retrieval, outstanding image-text retrieval, image-text retrieval datasets, retrieval model depends</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>An outstanding image-text retrieval model depends on high-quality labeled
data. While the builders of existing image-text retrieval datasets strive to
ensure that the caption matches the linked image, they cannot prevent a caption
from fitting other images. We observe that such a many-to-many matching
phenomenon is quite common in the widely-used retrieval datasets, where one
caption can describe up to 178 images. These large matching-lost data not only
confuse the model in training but also weaken the evaluation accuracy. Inspired
by visual and textual entailment tasks, we propose a multi-modal entailment
classifier to determine whether a sentence is entailed by an image plus its
linked captions. Subsequently, we revise the image-text retrieval datasets by
adding these entailed captions as additional weak labels of an image and
develop a universal variable learning rate strategy to teach a retrieval model
to distinguish the entailed captions from other negative samples. In
experiments, we manually annotate an entailment-corrected image-text retrieval
dataset for evaluation. The results demonstrate that the proposed entailment
classifier achieves about 78% accuracy and consistently improves the
performance of image-text retrieval baselines.</p>
  </details>
</details>
<details>
  <summary>29. <b>标题：Lirot.ai: A Novel Platform for Crowd-Sourcing Retinal Image  Segmentations</b></summary>
  <p><b>编号</b>：[151]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10100</p>
  <p><b>作者</b>：Jonathan Fhima,  Jan Van Eijgen,  Moti Freiman,  Ingeborg Stalmans,  Joachim A. Behar</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：http URL, http, supervised deep learning, supervised deep, http URL-app</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Introduction: For supervised deep learning (DL) tasks, researchers need a
large annotated dataset. In medical data science, one of the major limitations
to develop DL models is the lack of annotated examples in large quantity. This
is most often due to the time and expertise required to annotate. We introduce
this http URL, a novel platform for facilitating and crowd-sourcing image
segmentations. Methods: this http URL is composed of three components; an iPadOS
client application named this http URL-app, a backend server named this http URL-server
and a python API name this http URL-API. this http URL-app was developed in Swift 5.6 and
this http URL-server is a firebase backend. this http URL-API allows the management of
the database. this http URL-app can be installed on as many iPadOS devices as needed
so that annotators may be able to perform their segmentation simultaneously and
remotely. We incorporate Apple Pencil compatibility, making the segmentation
faster, more accurate, and more intuitive for the expert than any other
computer-based alternative. Results: We demonstrate the usage of this http URL for
the creation of a retinal fundus dataset with reference vasculature
segmentations. Discussion and future work: We will use active learning
strategies to continue enlarging our retinal fundus dataset by including a more
efficient process to select the images to be annotated and distribute them to
annotators.</p>
  </details>
</details>
<details>
  <summary>30. <b>标题：Identifying Auxiliary or Adversarial Tasks Using Necessary Condition  Analysis for Adversarial Multi-task Video Understanding</b></summary>
  <p><b>编号</b>：[159]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10077</p>
  <p><b>作者</b>：Stephen Su,  Samuel Kwong,  Qingyu Zhao,  De-An Huang,  Juan Carlos Niebles,  Ehsan Adeli</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：recent years, multi-task learning, increasing interest, Multi-Task Neural Networks, Adversarial Multi-Task Neural</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>There has been an increasing interest in multi-task learning for video
understanding in recent years. In this work, we propose a generalized notion of
multi-task learning by incorporating both auxiliary tasks that the model should
perform well on and adversarial tasks that the model should not perform well
on. We employ Necessary Condition Analysis (NCA) as a data-driven approach for
deciding what category these tasks should fall in. Our novel proposed
framework, Adversarial Multi-Task Neural Networks (AMT), penalizes adversarial
tasks, determined by NCA to be scene recognition in the Holistic Video
Understanding (HVU) dataset, to improve action recognition. This upends the
common assumption that the model should always be encouraged to do well on all
tasks in multi-task learning. Simultaneously, AMT still retains all the
benefits of multi-task learning as a generalization of existing methods and
uses object recognition as an auxiliary task to aid action recognition. We
introduce two challenging Scene-Invariant test splits of HVU, where the model
is evaluated on action-scene co-occurrences not encountered in training. We
show that our approach improves accuracy by ~3% and encourages the model to
attend to action features instead of correlation-biasing scene features.</p>
  </details>
</details>
<details>
  <summary>31. <b>标题：Minkowski Tracker: A Sparse Spatio-Temporal R-CNN for Joint Object  Detection and Tracking</b></summary>
  <p><b>编号</b>：[166]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10056</p>
  <p><b>作者</b>：JunYoung Gwak,  Silvio Savarese,  Jeannette Bohg</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：solving related problems, Minkowski Tracker, single neural network, Recent research, reveals the benefit</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent research in multi-task learning reveals the benefit of solving related
problems in a single neural network. 3D object detection and multi-object
tracking (MOT) are two heavily intertwined problems predicting and associating
an object instance location across time. However, most previous works in 3D MOT
treat the detector as a preceding separated pipeline, disjointly taking the
output of the detector as an input to the tracker. In this work, we present
Minkowski Tracker, a sparse spatio-temporal R-CNN that jointly solves object
detection and tracking. Inspired by region-based CNN (R-CNN), we propose to
solve tracking as a second stage of the object detector R-CNN that predicts
assignment probability to tracks. First, Minkowski Tracker takes 4D point
clouds as input to generate a spatio-temporal Bird's-eye-view (BEV) feature map
through a 4D sparse convolutional encoder network. Then, our proposed
TrackAlign aggregates the track region-of-interest (ROI) features from the BEV
features. Finally, Minkowski Tracker updates the track and its confidence score
based on the detection-to-track match probability predicted from the ROI
features. We show in large-scale experiments that the overall performance gain
of our method is due to four factors: 1. The temporal reasoning of the 4D
encoder improves the detection performance 2. The multi-task learning of object
detection and MOT jointly enhances each other 3. The detection-to-track match
score learns implicit motion model to enhance track assignment 4. The
detection-to-track match score improves the quality of the track confidence
score. As a result, Minkowski Tracker achieved the state-of-the-art performance
on Nuscenes dataset tracking task without hand-designed motion models.</p>
  </details>
</details>
<details>
  <summary>32. <b>标题：Reference-Limited Compositional Zero-Shot Learning</b></summary>
  <p><b>编号</b>：[170]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10046</p>
  <p><b>作者</b>：Siteng Huang,  Qiyao Wei,  Donglin Wang</p>
  <p><b>备注</b>：Under Review</p>
  <p><b>关键词</b>：artificial intelligence systems, understand the world, unseen compositions, essential ability, ability for artificial</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Compositional zero-shot learning (CZSL) refers to recognizing unseen
compositions of known visual primitives, which is an essential ability for
artificial intelligence systems to learn and understand the world. While
considerable progress has been made on existing benchmarks, we suspect whether
popular CZSL methods can address the challenges of few-shot and few referential
compositions, which is common when learning in real-world unseen environments.
To this end, we study the challenging reference-limited compositional zero-shot
learning (RL-CZSL) problem in this paper, i.e. , given limited seen
compositions that contain only a few samples as reference, unseen compositions
of observed primitives should be identified. We propose a novel Meta
Compositional Graph Learner (MetaCGL) that can efficiently learn the
compositionality from insufficient referential information and generalize to
unseen compositions. Besides, we build a benchmark with two new large-scale
datasets that consist of natural images with diverse compositional labels,
providing more realistic environments for RL-CZSL. Extensive experiments in the
benchmarks show that our method achieves state-of-the-art performance in
recognizing unseen compositions when reference is limited for compositional
learning.</p>
  </details>
</details>
<details>
  <summary>33. <b>标题：Multilayer deep feature extraction for visual texture recognition</b></summary>
  <p><b>编号</b>：[171]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10044</p>
  <p><b>作者</b>：Lucas O. Lyra,  Antonio Elias Fabris,  Joao B. Florindo</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：shown successful results, achieving real-time results, real-time results superior, classification achieving real-time, successful results</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Convolutional neural networks have shown successful results in image
classification achieving real-time results superior to the human level.
However, texture images still pose some challenge to these models due, for
example, to the limited availability of data for training in several problems
where these images appear, high inter-class similarity, the absence of a global
viewpoint of the object represented, and others. In this context, the present
paper is focused on improving the accuracy of convolutional neural networks in
texture classification. This is done by extracting features from multiple
convolutional layers of a pretrained neural network and aggregating such
features using Fisher vector. The reason for using features from earlier
convolutional layers is obtaining information that is less domain specific. We
verify the effectiveness of our method on texture classification of benchmark
datasets, as well as on a practical task of Brazilian plant species
identification. In both scenarios, Fisher vectors calculated on multiple layers
outperform state-of-art methods, confirming that early convolutional layers
provide important information about the texture image for classification.</p>
  </details>
</details>
<details>
  <summary>34. <b>标题：Towards Calibrated Hyper-Sphere Representation via Distribution Overlap  Coefficient for Long-tailed Learning</b></summary>
  <p><b>编号</b>：[172]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10043</p>
  <p><b>作者</b>：Hualiang Wang,  Siming Fu,  Xiaoxuan He,  Hangxiang Fang,  Zuozhu Liu,  Haoji Hu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：severe class imbalance, head classes dominate, Long-tailed learning aims, distribution overlap coefficient, head classes</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Long-tailed learning aims to tackle the crucial challenge that head classes
dominate the training procedure under severe class imbalance in real-world
scenarios. However, little attention has been given to how to quantify the
dominance severity of head classes in the representation space. Motivated by
this, we generalize the cosine-based classifiers to a von Mises-Fisher (vMF)
mixture model, denoted as vMF classifier, which enables to quantitatively
measure representation quality upon the hyper-sphere space via calculating
distribution overlap coefficient. To our knowledge, this is the first work to
measure representation quality of classifiers and features from the perspective
of distribution overlap coefficient. On top of it, we formulate the inter-class
discrepancy and class-feature consistency loss terms to alleviate the
interference among the classifier weights and align features with classifier
weights. Furthermore, a novel post-training calibration algorithm is devised to
zero-costly boost the performance via inter-class overlap coefficients. Our
method outperforms previous work with a large margin and achieves
state-of-the-art performance on long-tailed image classification, semantic
segmentation, and instance segmentation tasks (e.g., we achieve 55.0\% overall
accuracy with ResNetXt-50 in ImageNet-LT). Our code is available at
this https URL\_OP.</p>
  </details>
</details>
<details>
  <summary>35. <b>标题：A Simple Baseline for Multi-Camera 3D Object Detection</b></summary>
  <p><b>编号</b>：[175]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10035</p>
  <p><b>作者</b>：Yunpeng Zhang,  Wenzhao Zheng,  Zheng Zhu,  Guan Huang,  Jie Zhou,  Jiwen Lu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：object detection, autonomous driving, surrounding cameras, promising direction, direction for autonomous</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>3D object detection with surrounding cameras has been a promising direction
for autonomous driving. In this paper, we present SimMOD, a Simple baseline for
Multi-camera Object Detection, to solve the problem. To incorporate multi-view
information as well as build upon previous efforts on monocular 3D object
detection, the framework is built on sample-wise object proposals and designed
to work in a two-stage manner. First, we extract multi-scale features and
generate the perspective object proposals on each monocular image. Second, the
multi-view proposals are aggregated and then iteratively refined with
multi-view and multi-scale visual features in the DETR3D-style. The refined
proposals are end-to-end decoded into the detection results. To further boost
the performance, we incorporate the auxiliary branches alongside the proposal
generation to enhance the feature learning. Also, we design the methods of
target filtering and teacher forcing to promote the consistency of two-stage
training. We conduct extensive experiments on the 3D object detection benchmark
of nuScenes to demonstrate the effectiveness of SimMOD and achieve new
state-of-the-art performance. Code will be available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>36. <b>标题：GCISG: Guided Causal Invariant Learning for Improved Syn-to-real  Generalization</b></summary>
  <p><b>编号</b>：[178]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10024</p>
  <p><b>作者</b>：Gilhyun Nam,  Gyeongjae Choi,  Kyungmin Lee</p>
  <p><b>备注</b>：Accepted to ECCV 2022</p>
  <p><b>关键词</b>：artificially generated data, large domain gap, artificially generated, training data, generalization</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Training a deep learning model with artificially generated data can be an
alternative when training data are scarce, yet it suffers from poor
generalization performance due to a large domain gap. In this paper, we
characterize the domain gap by using a causal framework for data generation. We
assume that the real and synthetic data have common content variables but
different style variables. Thus, a model trained on synthetic dataset might
have poor generalization as the model learns the nuisance style variables. To
that end, we propose causal invariance learning which encourages the model to
learn a style-invariant representation that enhances the syn-to-real
generalization. Furthermore, we propose a simple yet effective feature
distillation method that prevents catastrophic forgetting of semantic knowledge
of the real domain. In sum, we refer to our method as Guided Causal Invariant
Syn-to-real Generalization that effectively improves the performance of
syn-to-real generalization. We empirically verify the validity of proposed
methods, and especially, our method achieves state-of-the-art on visual
syn-to-real domain generalization tasks such as image classification and
semantic segmentation.</p>
  </details>
</details>
<details>
  <summary>37. <b>标题：FairDisCo: Fairer AI in Dermatology via Disentanglement Contrastive  Learning</b></summary>
  <p><b>编号</b>：[180]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10013</p>
  <p><b>作者</b>：Siyi Du,  Ben Hers,  Nourhan Bayasi,  Ghassan Hamarneh,  Rafeef Garbi</p>
  <p><b>备注</b>：14 pages, 3 figures, accepted by European Conference on Computer Vision (ECCV) ISIC Workshops, 2022</p>
  <p><b>关键词</b>：achieved great success, models have achieved, achieved great, great success, success in automating</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep learning models have achieved great success in automating skin lesion
diagnosis. However, the ethnic disparity in these models' predictions, where
lesions on darker skin types are usually underrepresented and have lower
diagnosis accuracy, receives little attention. In this paper, we propose
FairDisCo, a disentanglement deep learning framework with contrastive learning
that utilizes an additional network branch to remove sensitive attributes, i.e.
skin-type information from representations for fairness and another contrastive
branch to enhance feature extraction. We compare FairDisCo to three fairness
methods, namely, resampling, reweighting, and attribute-aware, on two newly
released skin lesion datasets with different skin types: Fitzpatrick17k and
Diverse Dermatology Images (DDI). We adapt two fairness-based metrics DPM and
EOM for our multiple classes and sensitive attributes task, highlighting the
skin-type bias in skin lesion classification. Extensive experimental evaluation
demonstrates the effectiveness of FairDisCo, with fairer and superior
performance on skin lesion classification tasks.</p>
  </details>
</details>
<details>
  <summary>38. <b>标题：A diverse large-scale building dataset and a novel plug-and-play domain  generalization method for building extraction</b></summary>
  <p><b>编号</b>：[183]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10004</p>
  <p><b>作者</b>：Muying Luo,  Shunping Ji,  Shiqing Wei</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：building extraction model, WHU-Mix building dataset, high-resolution remote sensing, building extraction, building dataset</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we introduce a new building dataset and propose a novel domain
generalization method to facilitate the development of building extraction from
high-resolution remote sensing images. The problem with the current building
datasets involves that they lack diversity, the quality of the labels is
unsatisfactory, and they are hardly used to train a building extraction model
with good generalization ability, so as to properly evaluate the real
performance of a model in practical scenes. To address these issues, we built a
diverse, large-scale, and high-quality building dataset named the WHU-Mix
building dataset, which is more practice-oriented. The WHU-Mix building dataset
consists of a training/validation set containing 43,727 diverse images
collected from all over the world, and a test set containing 8402 images from
five other cities on five continents. In addition, to further improve the
generalization ability of a building extraction model, we propose a domain
generalization method named batch style mixing (BSM), which can be embedded as
an efficient plug-and-play module in the frond-end of a building extraction
model, providing the model with a progressively larger data distribution to
learn data-invariant knowledge. The experiments conducted in this study
confirmed the potential of the WHU-Mix building dataset to improve the
performance of a building extraction model, resulting in a 6-36% improvement in
mIoU, compared to the other existing datasets. The adverse impact of the
inaccurate labels in the other datasets can cause about 20% IoU decrease. The
experiments also confirmed the high performance of the proposed BSM module in
enhancing the generalization ability and robustness of a model, exceeding the
baseline model without domain generalization by 13% and the recent domain
generalization methods by 4-15% in mIoU.</p>
  </details>
</details>
<details>
  <summary>39. <b>标题：TransNet: Category-Level Transparent Object Pose Estimation</b></summary>
  <p><b>编号</b>：[185]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10002</p>
  <p><b>作者</b>：Huijie Zhang,  Anthony Opipari,  Xiaotong Chen,  Jiyue Zhu,  Zeren Yu,  Odest Chadwicke Jenkins</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：multiple distinct challenges, present multiple distinct, Transparent, visual perception systems, Transparent objects</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Transparent objects present multiple distinct challenges to visual perception
systems. First, their lack of distinguishing visual features makes transparent
objects harder to detect and localize than opaque objects. Even humans find
certain transparent surfaces with little specular reflection or refraction,
e.g. glass doors, difficult to perceive. A second challenge is that common
depth sensors typically used for opaque object perception cannot obtain
accurate depth measurements on transparent objects due to their unique
reflective properties. Stemming from these challenges, we observe that
transparent object instances within the same category (e.g. cups) look more
similar to each other than to ordinary opaque objects of that same category.
Given this observation, the present paper sets out to explore the possibility
of category-level transparent object pose estimation rather than instance-level
pose estimation. We propose TransNet, a two-stage pipeline that learns to
estimate category-level transparent object pose using localized depth
completion and surface normal estimation. TransNet is evaluated in terms of
pose estimation accuracy on a recent, large-scale transparent object dataset
and compared to a state-of-the-art category-level pose estimation approach.
Results from this comparison demonstrate that TransNet achieves improved pose
estimation accuracy on transparent objects and key findings from the included
ablation studies suggest future directions for performance improvements.</p>
  </details>
</details>
<details>
  <summary>40. <b>标题：PLMCL: Partial-Label Momentum Curriculum Learning for Multi-Label Image  Classification</b></summary>
  <p><b>编号</b>：[186]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09999</p>
  <p><b>作者</b>：Rabab Abdelfattah,  Xin Zhang,  Zhenyao Wu,  Xinyi Wu,  Xiaofeng Wang,  Song Wang</p>
  <p><b>备注</b>：Accepted in ECCVw</p>
  <p><b>关键词</b>：training image, training, labels, aims to predict, image</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Multi-label image classification aims to predict all possible labels in an
image. It is usually formulated as a partial-label learning problem, given the
fact that it could be expensive in practice to annotate all labels in every
training image. Existing works on partial-label learning focus on the case
where each training image is annotated with only a subset of its labels. A
special case is to annotate only one positive label in each training image. To
further relieve the annotation burden and enhance the performance of the
classifier, this paper proposes a new partial-label setting in which only a
subset of the training images are labeled, each with only one positive label,
while the rest of the training images remain unlabeled. To handle this new
setting, we propose an end-to-end deep network, PLMCL (Partial Label Momentum
Curriculum Learning), that can learn to produce confident pseudo labels for
both partially-labeled and unlabeled training images. The novel momentum-based
law updates soft pseudo labels on each training image with the consideration of
the updating velocity of pseudo labels, which help avoid trapping to
low-confidence local minimum, especially at the early stage of training in lack
of both observed labels and confidence on pseudo labels. In addition, we
present a confidence-aware scheduler to adaptively perform easy-to-hard
learning for different labels. Extensive experiments demonstrate that our
proposed PLMCL outperforms many state-of-the-art multi-label classification
methods under various partial-label settings on three different datasets.</p>
  </details>
</details>
<details>
  <summary>41. <b>标题：Equalization and Brightness Mapping Modes of Color-to-Gray Projection  Operators</b></summary>
  <p><b>编号</b>：[201]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09950</p>
  <p><b>作者</b>：Diego Frias</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：color RGB images, RGB images, color RGB, images to grayscale, grayscale is covered</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this article, the conversion of color RGB images to grayscale is covered
by characterizing the mathematical operators used to project 3 color channels
to a single one. Based on the fact that most operators assign each of the
$256^3$ colors a single gray level, ranging from 0 to 255, they are clustering
algorithms that distribute the color population into 256 clusters of increasing
brightness. To visualize the way operators work the sizes of the clusters and
the average brightness of each cluster are plotted. The equalization mode (EQ)
introduced in this work focuses on cluster sizes, while the brightness mapping
(BM) mode describes the CIE L* luminance distribution per cluster. Three
classes of EQ modes and two classes of BM modes were found in linear operators,
defining a 6-class taxonomy. The theoretical/methodological framework
introduced was applied in a case study considering the equal-weights uniform
operator, the NTSC standard operator, and an operator chosen as ideal to
lighten the faces of black people to improve facial recognition in current
biased classifiers. It was found that most current metrics used to assess the
quality of color-to-gray conversions better assess one of the two BM mode
classes, but the ideal operator chosen by a human team belongs to the other
class. Therefore, this cautions against using these general metrics for
specific purpose color-to-gray conversions. It should be noted that eventual
applications of this framework to non-linear operators can give rise to new
classes of EQ and BM modes. The main contribution of this article is to provide
a tool to better understand color to gray converters in general, even those
based on machine learning, within the current trend of better explainability of
models.</p>
  </details>
</details>
<details>
  <summary>42. <b>标题：Improving GANs for Long-Tailed Data through Group Spectral  Regularization</b></summary>
  <p><b>编号</b>：[209]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09932</p>
  <p><b>作者</b>：Harsh Rangwani,  Naman Jaswani,  Tejan Karmali,  Varun Jampani,  R. Venkatesh Babu</p>
  <p><b>备注</b>：ECCV 2022. Project Page: this https URL</p>
  <p><b>关键词</b>：real-world imbalanced distributions, Deep long-tailed learning, Generative Adversarial Networks, real-world imbalanced, long-tailed learning aims</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep long-tailed learning aims to train useful deep networks on practical,
real-world imbalanced distributions, wherein most labels of the tail classes
are associated with a few samples. There has been a large body of work to train
discriminative models for visual recognition on long-tailed distribution. In
contrast, we aim to train conditional Generative Adversarial Networks, a class
of image generation models on long-tailed distributions. We find that similar
to recognition, state-of-the-art methods for image generation also suffer from
performance degradation on tail classes. The performance degradation is mainly
due to class-specific mode collapse for tail classes, which we observe to be
correlated with the spectral explosion of the conditioning parameter matrix. We
propose a novel group Spectral Regularizer (gSR) that prevents the spectral
explosion alleviating mode collapse, which results in diverse and plausible
image generation even for tail classes. We find that gSR effectively combines
with existing augmentation and regularization techniques, leading to
state-of-the-art image generation performance on long-tailed data. Extensive
experiments demonstrate the efficacy of our regularizer on long-tailed datasets
with different degrees of imbalance.</p>
  </details>
</details>
<details>
  <summary>43. <b>标题：A semi-supervised Teacher-Student framework for surgical tool detection  and localization</b></summary>
  <p><b>编号</b>：[213]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09926</p>
  <p><b>作者</b>：Mansoor Ali,  Gilberto Ochoa-Ruiz,  Sharib Ali</p>
  <p><b>备注</b>：Paper accepted at Augmented Reality, Augmented Environments for Computer Assisted Interventions (AE-CAI), Computer Assisted and Robotic Endoscopy (CARE) and Context-Aware Operating Theaters (OR 2.0) at MICCAI 2022</p>
  <p><b>关键词</b>：minimally invasive surgery, computer-assisted interventions, minimally invasive, invasive surgery, essential part</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Surgical tool detection in minimally invasive surgery is an essential part of
computer-assisted interventions. Current approaches are mostly based on
supervised methods which require large fully labeled data to train supervised
models and suffer from pseudo label bias because of class imbalance issues.
However large image datasets with bounding box annotations are often scarcely
available. Semi-supervised learning (SSL) has recently emerged as a means for
training large models using only a modest amount of annotated data; apart from
reducing the annotation cost. SSL has also shown promise to produce models that
are more robust and generalizable. Therefore, in this paper we introduce a
semi-supervised learning (SSL) framework in surgical tool detection paradigm
which aims to mitigate the scarcity of training data and the data imbalance
through a knowledge distillation approach. In the proposed work, we train a
model with labeled data which initialises the Teacher-Student joint learning,
where the Student is trained on Teacher-generated pseudo labels from unlabeled
data. We propose a multi-class distance with a margin based classification loss
function in the region-of-interest head of the detector to effectively
segregate foreground classes from background region. Our results on
m2cai16-tool-locations dataset indicate the superiority of our approach on
different supervised data settings (1%, 2%, 5%, 10% of annotated data) where
our model achieves overall improvements of 8%, 12% and 27% in mAP (on 1%
labeled data) over the state-of-the-art SSL methods and a fully supervised
baseline, respectively. The code is available at
this https URL</p>
  </details>
</details>
<details>
  <summary>44. <b>标题：A Web Application for Experimenting and Validating Remote Measurement of  Vital Signs</b></summary>
  <p><b>编号</b>：[215]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09916</p>
  <p><b>作者</b>：Amtul Haq Ayesha,  Donghao Qiao,  Farhana Zulkernine</p>
  <p><b>备注</b>：12 pages, 2 figures</p>
  <p><b>关键词</b>：medical advising remote, advising remote monitoring, online medical advising, Blood Volume Pulse, advising remote</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>With a surge in online medical advising remote monitoring of patient vitals
is required. This can be facilitated with the Remote Photoplethysmography
(rPPG) techniques that compute vital signs from facial videos. It involves
processing video frames to obtain skin pixels, extracting the cardiac data from
it and applying signal processing filters to extract the Blood Volume Pulse
(BVP) signal. Different algorithms are applied to the BVP signal to estimate
the various vital signs. We implemented a web application framework to measure
a person's Heart Rate (HR), Heart Rate Variability (HRV), Oxygen Saturation
(SpO2), Respiration Rate (RR), Blood Pressure (BP), and stress from the face
video. The rPPG technique is highly sensitive to illumination and motion
variation. The web application guides the users to reduce the noise due to
these variations and thereby yield a cleaner BVP signal. The accuracy and
robustness of the framework was validated with the help of volunteers.</p>
  </details>
</details>
<details>
  <summary>45. <b>标题：A Unified Analysis of Mixed Sample Data Augmentation: A Loss Function  Perspective</b></summary>
  <p><b>编号</b>：[217]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09913</p>
  <p><b>作者</b>：Chanwoo Park,  Sangdoo Yun,  Sanghyuk Chun</p>
  <p><b>备注</b>：First two authors contributed equally; 29 pages</p>
  <p><b>关键词</b>：sample data augmentation, mixed sample data, unified theoretical analysis, Mixup, theoretical results</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose the first unified theoretical analysis of mixed sample data
augmentation (MSDA), such as Mixup and CutMix. Our theoretical results show
that regardless of the choice of the mixing strategy, MSDA behaves as a
pixel-level regularization of the underlying training loss and a regularization
of the first layer parameters. Similarly, our theoretical results support that
the MSDA training strategy can improve adversarial robustness and
generalization compared to the vanilla training strategy. Using the theoretical
results, we provide a high-level understanding of how different design choices
of MSDA work differently. For example, we show that the most popular MSDA
methods, Mixup and CutMix, behave differently, e.g., CutMix regularizes the
input gradients by pixel distances, while Mixup regularizes the input gradients
regardless of pixel distances. Our theoretical results also show that the
optimal MSDA strategy depends on tasks, datasets, or model parameters. From
these observations, we propose generalized MSDAs, a Hybrid version of Mixup and
CutMix (HMix) and Gaussian Mixup (GMix), simple extensions of Mixup and CutMix.
Our implementation can leverage the advantages of Mixup and CutMix, while our
implementation is very efficient, and the computation cost is almost
neglectable as Mixup and CutMix. Our empirical study shows that our HMix and
GMix outperform the previous state-of-the-art MSDA methods in CIFAR-100 and
ImageNet classification tasks. Source code is available at
this https URL</p>
  </details>
</details>
<details>
  <summary>46. <b>标题：Revisiting Weak-to-Strong Consistency in Semi-Supervised Semantic  Segmentation</b></summary>
  <p><b>编号</b>：[219]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09910</p>
  <p><b>作者</b>：Lihe Yang,  Lei Qi,  Litong Feng,  Wayne Zhang,  Yinghuan Shi</p>
  <p><b>备注</b>：18 pages, 18 tables</p>
  <p><b>关键词</b>：strongly perturbed version, perturbed image serves, weakly perturbed image, consistency framework, perturbed version</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this work, we revisit the weak-to-strong consistency framework,
popularized by FixMatch from semi-supervised classification, where the
prediction of a weakly perturbed image serves as supervision for its strongly
perturbed version. Intriguingly, we observe that such a simple pipeline already
achieves competitive results against recent advanced works, when transferred to
our segmentation scenario. Its success heavily relies on the manual design of
strong data augmentations, however, which may be limited and inadequate to
explore a broader perturbation space. Motivated by this, we propose an
auxiliary feature perturbation stream as a supplement, leading to an expanded
perturbation space. On the other, to sufficiently probe original image-level
augmentations, we present a dual-stream perturbation technique, enabling two
strong views to be simultaneously guided by a common weak view. Consequently,
our overall Unified Dual-Stream Perturbations approach (UniMatch) surpasses all
existing methods significantly across all evaluation protocols on the Pascal,
Cityscapes, and COCO benchmarks. We also demonstrate the superiority of our
method in remote sensing interpretation and medical image analysis. Code is
available at this https URL.</p>
  </details>
</details>
<details>
  <summary>47. <b>标题：SIM2E: Benchmarking the Group Equivariant Capability of Correspondence  Matching Algorithms</b></summary>
  <p><b>编号</b>：[224]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09896</p>
  <p><b>作者</b>：Shuai Su,  Zhongkai Zhao,  Yixin Fei,  Shuda Li,  Qijun Chen,  Rui Fan</p>
  <p><b>备注</b>：ECCV2022 Workshop Paper</p>
  <p><b>关键词</b>：Correspondence matching, matching, Correspondence, computer vision, vision and robotics</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Correspondence matching is a fundamental problem in computer vision and
robotics applications. Solving correspondence matching problems using neural
networks has been on the rise recently. Rotation-equivariance and
scale-equivariance are both critical in correspondence matching applications.
Classical correspondence matching approaches are designed to withstand scaling
and rotation transformations. However, the features extracted using
convolutional neural networks (CNNs) are only translation-equivariant to a
certain extent. Recently, researchers have strived to improve the
rotation-equivariance of CNNs based on group theories. Sim(2) is the group of
similarity transformations in the 2D plane. This paper presents a specialized
dataset dedicated to evaluating sim(2)-equivariant correspondence matching
algorithms. We compare the performance of 16 state-of-the-art (SoTA)
correspondence matching approaches. The experimental results demonstrate the
importance of group equivariant algorithms for correspondence matching on
various sim(2) transformation conditions. Since the subpixel accuracy achieved
by CNN-based correspondence matching approaches is unsatisfactory, this
specific area requires more attention in future works. Our dataset is publicly
available at: mias.group/SIM2E.</p>
  </details>
</details>
<details>
  <summary>48. <b>标题：HST: Hierarchical Swin Transformer for Compressed Image Super-resolution</b></summary>
  <p><b>编号</b>：[226]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09885</p>
  <p><b>作者</b>：Bingchen Li,  Xin Li,  Yiting Lu,  Sen Liu,  Ruoyu Feng,  Zhibo Chen</p>
  <p><b>备注</b>：Accepted by ECCV2022 Workshop (AIM2022)</p>
  <p><b>关键词</b>：achieved great attention, Compressed Image Super-resolution, Compressed Image, Image Super-resolution, compression artifacts</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Compressed Image Super-resolution has achieved great attention in recent
years, where images are degraded with compression artifacts and low-resolution
artifacts. Since the complex hybrid distortions, it is hard to restore the
distorted image with the simple cooperation of super-resolution and compression
artifacts removing. In this paper, we take a step forward to propose the
Hierarchical Swin Transformer (HST) network to restore the low-resolution
compressed image, which jointly captures the hierarchical feature
representations and enhances each-scale representation with Swin transformer,
respectively. Moreover, we find that the pretraining with Super-resolution (SR)
task is vital in compressed image super-resolution. To explore the effects of
different SR pretraining, we take the commonly-used SR tasks (e.g., bicubic and
different real super-resolution simulations) as our pretraining tasks, and
reveal that SR plays an irreplaceable role in the compressed image
super-resolution. With the cooperation of HST and pre-training, our HST
achieves the fifth place in AIM 2022 challenge on the low-quality compressed
image super-resolution track, with the PSNR of 23.51dB. Extensive experiments
and ablation studies have validated the effectiveness of our proposed methods.</p>
  </details>
</details>
<details>
  <summary>49. <b>标题：DiscrimLoss: A Universal Loss for Hard Samples and Incorrect Samples  Discrimination</b></summary>
  <p><b>编号</b>：[227]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09884</p>
  <p><b>作者</b>：Tingting Wu,  Xiao Ding,  Hao Zhang,  Jinglong Gao,  Li Du,  Bing Qin,  Ting Liu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：deep neural networks, samples, impair model performance, incorrect samples, deep neural</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Given data with label noise (i.e., incorrect data), deep neural networks
would gradually memorize the label noise and impair model performance. To
relieve this issue, curriculum learning is proposed to improve model
performance and generalization by ordering training samples in a meaningful
(e.g., easy to hard) sequence. Previous work takes incorrect samples as generic
hard ones without discriminating between hard samples (i.e., hard samples in
correct data) and incorrect samples. Indeed, a model should learn from hard
samples to promote generalization rather than overfit to incorrect ones. In
this paper, we address this problem by appending a novel loss function
DiscrimLoss, on top of the existing task loss. Its main effect is to
automatically and stably estimate the importance of easy samples and difficult
samples (including hard and incorrect samples) at the early stages of training
to improve the model performance. Then, during the following stages,
DiscrimLoss is dedicated to discriminating between hard and incorrect samples
to improve the model generalization. Such a training strategy can be formulated
dynamically in a self-supervised manner, effectively mimicking the main
principle of curriculum learning. Experiments on image classification, image
regression, text sequence regression, and event relation reasoning demonstrate
the versatility and effectiveness of our method, particularly in the presence
of diversified noise levels.</p>
  </details>
</details>
<details>
  <summary>50. <b>标题：Masked Video Modeling with Correlation-aware Contrastive Learning for  Breast Cancer Diagnosis in Ultrasound</b></summary>
  <p><b>编号</b>：[229]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09881</p>
  <p><b>作者</b>：Zehui Lin,  Ruobing Huang,  Dong Ni,  Jiayi Wu,  Baoming Luo</p>
  <p><b>备注</b>：Accepted by MICCAI-REMIA 2022</p>
  <p><b>关键词</b>：deaths in women, Breast, cancer deaths, cancer, Breast cancer</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Breast cancer is one of the leading causes of cancer deaths in women. As the
primary output of breast screening, breast ultrasound (US) video contains
exclusive dynamic information for cancer diagnosis. However, training models
for video analysis is non-trivial as it requires a voluminous dataset which is
also expensive to annotate. Furthermore, the diagnosis of breast lesion faces
unique challenges such as inter-class similarity and intra-class variation. In
this paper, we propose a pioneering approach that directly utilizes US videos
in computer-aided breast cancer diagnosis. It leverages masked video modeling
as pretraning to reduce reliance on dataset size and detailed annotations.
Moreover, a correlation-aware contrastive loss is developed to facilitate the
identifying of the internal and external relationship between benign and
malignant lesions. Experimental results show that our proposed approach
achieved promising classification performance and can outperform other
state-of-the-art methods.</p>
  </details>
</details>
<details>
  <summary>51. <b>标题：DPTNet: A Dual-Path Transformer Architecture for Scene Text Detection</b></summary>
  <p><b>编号</b>：[231]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09878</p>
  <p><b>作者</b>：Jingyu Lin,  Jie Jiang,  Yan Yan,  Chunchao Guo,  Hongfa Wang,  Wei Liu,  Hanzi Wang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：deep learning contributes, scene text detection, prosperity of deep, deep learning, learning contributes</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The prosperity of deep learning contributes to the rapid progress in scene
text detection. Among all the methods with convolutional networks,
segmentation-based ones have drawn extensive attention due to their superiority
in detecting text instances of arbitrary shapes and extreme aspect ratios.
However, the bottom-up methods are limited to the performance of their
segmentation models. In this paper, we propose DPTNet (Dual-Path Transformer
Network), a simple yet effective architecture to model the global and local
information for the scene text detection task. We further propose a parallel
design that integrates the convolutional network with a powerful self-attention
mechanism to provide complementary clues between the attention path and
convolutional path. Moreover, a bi-directional interaction module across the
two paths is developed to provide complementary clues in the channel and
spatial dimensions. We also upgrade the concentration operation by adding an
extra multi-head attention layer to it. Our DPTNet achieves state-of-the-art
results on the MSRA-TD500 dataset, and provides competitive results on other
standard benchmarks in terms of both detection accuracy and speed.</p>
  </details>
</details>
<details>
  <summary>52. <b>标题：Objects Can Move: 3D Change Detection by Geometric Transformation  Constistency</b></summary>
  <p><b>编号</b>：[234]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09870</p>
  <p><b>作者</b>：Aikaterini Adam,  Torsten Sattler,  Konstantinos Karantzalos,  Tomas Pajdla</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：applications and robots, scene, method, changed, scene has changed</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>AR/VR applications and robots need to know when the scene has changed. An
example is when objects are moved, added, or removed from the scene. We propose
a 3D object discovery method that is based only on scene changes. Our method
does not need to encode any assumptions about what is an object, but rather
discovers objects by exploiting their coherent move. Changes are initially
detected as differences in the depth maps and segmented as objects if they
undergo rigid motions. A graph cut optimization propagates the changing labels
to geometrically consistent regions. Experiments show that our method achieves
state-of-the-art performance on the 3RScan dataset against competitive
baselines. The source code of our method can be found at
this https URL.</p>
  </details>
</details>
<details>
  <summary>53. <b>标题：Semantic-enhanced Image Clustering</b></summary>
  <p><b>编号</b>：[243]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09849</p>
  <p><b>作者</b>：Shaotian Cai,  Liping Qiu,  Xiaojun Chen,  Qin Zhang,  Longteng Chen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Image clustering, open challenge task, clustering, Image, Semantic-enhanced Image Clustering</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Image clustering is an important, and open challenge task in computer vision.
Although many methods have been proposed to solve the image clustering task,
they only explore images and uncover clusters according to the image features,
thus are unable to distinguish visually similar but semantically different
images. In this paper, we propose to investigate the task of image clustering
with the help of visual-language pre-training model. Different from the
zero-shot setting in which the class names are known, we only know the number
of clusters in this setting. Therefore, how to map images to a proper semantic
space and how to cluster images from both image and semantic spaces are two key
problems. To solve the above problems, we propose a novel image clustering
method guided by the visual-language pre-training model CLIP, named as
\textbf{Semantic-enhanced Image Clustering (SIC)}. In this new method, we
propose a method to map the given images to a proper semantic space first and
efficient methods to generate pseudo-labels according to the relationships
between images and semantics. Finally, we propose to perform clustering with
the consistency learning in both image space and semantic space, in a
self-supervised learning fashion. Theoretical result on convergence analysis
shows that our proposed method can converge in sublinear speed. Theoretical
analysis on expectation risk also shows that we can reduce the expectation risk
by improving the neighborhood consistency or prediction confidence or reducing
neighborhood imbalance. Experimental results on five benchmark datasets clearly
show the superiority of our new method.</p>
  </details>
</details>
<details>
  <summary>54. <b>标题：Multi-task Learning for Monocular Depth and Defocus Estimations with  Real Images</b></summary>
  <p><b>编号</b>：[244]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09848</p>
  <p><b>作者</b>：Renzhi He,  Hualin Hong,  Boya Fu,  Fei Liu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：defocus estimation, Monocular depth estimation, depth estimation, depth, defocus</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Monocular depth estimation and defocus estimation are two fundamental tasks
in computer vision. Most existing methods treat depth estimation and defocus
estimation as two separate tasks, ignoring the strong connection between them.
In this work, we propose a multi-task learning network consisting of an encoder
with two decoders to estimate the depth and defocus map from a single focused
image. Through the multi-task network, the depth estimation facilitates the
defocus estimation to get better results in the weak texture region and the
defocus estimation facilitates the depth estimation by the strong physical
connection between the two maps. We set up a dataset (named ALL-in-3D dataset)
which is the first all-real image dataset consisting of 100K sets of
all-in-focus images, focused images with focus depth, depth maps, and defocus
maps. It enables the network to learn features and solid physical connections
between the depth and real defocus images. Experiments demonstrate that the
network learns more solid features from the real focused images than the
synthetic focused images. Benefiting from this multi-task structure where
different tasks facilitate each other, our depth and defocus estimations
achieve significantly better performance than other state-of-art algorithms.
The code and dataset will be publicly available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>55. <b>标题：CycleTrans: Learning Neutral yet Discriminative Features for  Visible-Infrared Person Re-Identification</b></summary>
  <p><b>编号</b>：[247]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09844</p>
  <p><b>作者</b>：Qiong Wu,  Jiaer Xia,  Pingyang Dai,  Yiyi Zhou,  Yongjian Wu,  Rongrong Ji</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Visible-infrared person re-identification, Visible-infrared person, person re-identification, task of matching, Knowledge Capturing Module</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Visible-infrared person re-identification (VI-ReID) is a task of matching the
same individuals across the visible and infrared modalities. Its main challenge
lies in the modality gap caused by cameras operating on different spectra.
Existing VI-ReID methods mainly focus on learning general features across
modalities, often at the expense of feature discriminability. To address this
issue, we present a novel cycle-construction-based network for neutral yet
discriminative feature learning, termed CycleTrans. Specifically, CycleTrans
uses a lightweight Knowledge Capturing Module (KCM) to capture rich semantics
from the modality-relevant feature maps according to pseudo queries.
Afterwards, a Discrepancy Modeling Module (DMM) is deployed to transform these
features into neutral ones according to the modality-irrelevant prototypes. To
ensure feature discriminability, another two KCMs are further deployed for
feature cycle constructions. With cycle construction, our method can learn
effective neutral features for visible and infrared images while preserving
their salient semantics. Extensive experiments on SYSU-MM01 and RegDB datasets
validate the merits of CycleTrans against a flurry of state-of-the-art methods,
+4.57% on rank-1 in SYSU-MM01 and +2.2% on rank-1 in RegDB.</p>
  </details>
</details>
<details>
  <summary>56. <b>标题：CODER: Coupled Diversity-Sensitive Momentum Contrastive Learning for  Image-Text Retrieval</b></summary>
  <p><b>编号</b>：[248]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09843</p>
  <p><b>作者</b>：Haoran Wang,  Dongliang He,  Wenhao Wu,  Boyang Xia,  Min Yang,  Fu Li,  Yunlong Yu,  Zhong Ji,  Errui Ding,  Jingdong Wang</p>
  <p><b>备注</b>：Accepted by ECCV 2022</p>
  <p><b>关键词</b>：Image-Text Retrieval, ITR, challenging in bridging, bridging visual, visual and lingual</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Image-Text Retrieval (ITR) is challenging in bridging visual and lingual
modalities. Contrastive learning has been adopted by most prior arts. Except
for limited amount of negative image-text pairs, the capability of constrastive
learning is restricted by manually weighting negative pairs as well as
unawareness of external knowledge. In this paper, we propose our novel Coupled
Diversity-Sensitive Momentum Constrastive Learning (CODER) for improving
cross-modal representation. Firstly, a novel diversity-sensitive contrastive
learning (DCL) architecture is invented. We introduce dynamic dictionaries for
both modalities to enlarge the scale of image-text pairs, and
diversity-sensitiveness is achieved by adaptive negative pair weighting.
Furthermore, two branches are designed in CODER. One learns instance-level
embeddings from image/text, and it also generates pseudo online clustering
labels for its input image/text based on their embeddings. Meanwhile, the other
branch learns to query from commonsense knowledge graph to form concept-level
descriptors for both modalities. Afterwards, both branches leverage DCL to
align the cross-modal embedding spaces while an extra pseudo clustering label
prediction loss is utilized to promote concept-level representation learning
for the second branch. Extensive experiments conducted on two popular
benchmarks, i.e. MSCOCO and Flicker30K, validate CODER remarkably outperforms
the state-of-the-art approaches.</p>
  </details>
</details>
<details>
  <summary>57. <b>标题：qDWI-Morph: Motion-compensated quantitative Diffusion-Weighted MRI  analysis for fetal lung maturity assessment</b></summary>
  <p><b>编号</b>：[252]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09836</p>
  <p><b>作者</b>：Yael Zaffrani-Reznikov,  Onur Afacan,  Sila Kurugol,  Simon Warfield,  Moti Freiman</p>
  <p><b>备注</b>：Accepted to ECCV-MCV: this https URL</p>
  <p><b>关键词</b>：lung Diffusion-Weighted MRI, Diffusion-Weighted MRI, providing quantitative imaging, quantitative imaging biomarkers, indirectly reflect fetal</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Quantitative analysis of fetal lung Diffusion-Weighted MRI (DWI) data shows
potential in providing quantitative imaging biomarkers that indirectly reflect
fetal lung maturation. However, fetal motion during the acquisition hampered
quantitative analysis of the acquired DWI data and, consequently, reliable
clinical utilization. We introduce qDWI-morph, an unsupervised
deep-neural-network architecture for motion compensated quantitative DWI (qDWI)
analysis. Our approach couples a registration sub-network with a quantitative
DWI model fitting sub-network. We simultaneously estimate the qDWI parameters
and the motion model by minimizing a bio-physically-informed loss function
integrating a registration loss and a model fitting quality loss. We
demonstrated the added-value of qDWI-morph over: 1) a baseline qDWI analysis
without motion compensation and 2) a baseline deep-learning model incorporating
registration loss solely. The qDWI-morph achieved a substantially improved
correlation with the gestational age through in-vivo qDWI analysis of fetal
lung DWI data (R-squared=0.32 vs. 0.13, 0.28). Our qDWI-morph has the potential
to enable motion-compensated quantitative analysis of DWI data and to provide
clinically feasible bio-markers for non-invasive fetal lung maturity
assessment. Our code is available at:
this https URL.</p>
  </details>
</details>
<details>
  <summary>58. <b>标题：CenDerNet: Center and Curvature Representations for Render-and-Compare  6D Pose Estimation</b></summary>
  <p><b>编号</b>：[255]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09829</p>
  <p><b>作者</b>：Peter De Roovere,  Rembert Daems,  Jonathan Croenen,  Taoufik Bourgana,  Joris de Hoog,  Francis wyffels</p>
  <p><b>备注</b>：19 pages, 14 figures</p>
  <p><b>关键词</b>：multi-view images based, estimation from multi-view, multi-view images, images based, curvature representations</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We introduce CenDerNet, a framework for 6D pose estimation from multi-view
images based on center and curvature representations. Finding precise poses for
reflective, textureless objects is a key challenge for industrial robotics. Our
approach consists of three stages: First, a fully convolutional neural network
predicts center and curvature heatmaps for each view; Second, center heatmaps
are used to detect object instances and find their 3D centers; Third, 6D object
poses are estimated using 3D centers and curvature heatmaps. By jointly
optimizing poses across views using a render-and-compare approach, our method
naturally handles occlusions and object symmetries. We show that CenDerNet
outperforms previous methods on two industry-relevant datasets: DIMO and
T-LESS.</p>
  </details>
</details>
<details>
  <summary>59. <b>标题：Depth-Assisted ResiDualGAN for Cross-Domain Aerial Images Semantic  Segmentation</b></summary>
  <p><b>编号</b>：[259]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09823</p>
  <p><b>作者</b>：Yang Zhao,  Peng Guo,  Han Gao,  Xiuwan Chen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Unsupervised domain adaptation, minimizing domain gap, UDA, domain gap, approach to minimizing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Unsupervised domain adaptation (UDA) is an approach to minimizing domain gap.
Generative methods are common approaches to minimizing the domain gap of aerial
images which improves the performance of the downstream tasks, e.g.,
cross-domain semantic segmentation. For aerial images, the digital surface
model (DSM) is usually available in both the source domain and the target
domain. Depth information in DSM brings external information to generative
models. However, little research utilizes it. In this paper, depth-assisted
ResiDualGAN (DRDG) is proposed where depth supervised loss (DSL), and depth
cycle consistency loss (DCCL) are used to bring depth information into the
generative model. Experimental results show that DRDG reaches state-of-the-art
accuracy between generative methods in cross-domain semantic segmentation
tasks.</p>
  </details>
</details>
<details>
  <summary>60. <b>标题：LWA-HAND: Lightweight Attention Hand for Interacting Hand Reconstruction</b></summary>
  <p><b>编号</b>：[263]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09815</p>
  <p><b>作者</b>：Xinhan Di,  Pengqian Yu</p>
  <p><b>备注</b>：Accepted by ECCV 2022 Computer Vision for Metaverse Workshop (17 pages, 6 figures, 1 table). arXiv admin note: substantial text overlap with arXiv:2203.09364 by other authors</p>
  <p><b>关键词</b>：achieved great success, visual reality, augmented reality, two-hand reconstruction, left unexplored</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Hand reconstruction has achieved great success in real-time applications such
as visual reality and augmented reality while interacting with two-hand
reconstruction through efficient transformers is left unexplored. In this
paper, we propose a method called lightweight attention hand (LWA-HAND) to
reconstruct hands in low flops from a single RGB image. To solve the occlusion
and interaction challenges in efficient attention architectures, we introduce
three mobile attention modules. The first module is a lightweight feature
attention module that extracts both local occlusion representation and global
image patch representation in a coarse-to-fine manner. The second module is a
cross image and graph bridge module which fuses image context and hand vertex.
The third module is a lightweight cross-attention mechanism that uses
element-wise operation for cross attention of two hands in linear complexity.
The resulting model achieves comparable performance on the InterHand2.6M
benchmark in comparison with the state-of-the-art models. Simultaneously, it
reduces the flops to $0.47GFlops$ while the state-of-the-art models have heavy
computations between $10GFlops$ and $20GFlops$.</p>
  </details>
</details>
<details>
  <summary>61. <b>标题：PointDP: Diffusion-driven Purification against Adversarial Attacks on 3D  Point Cloud Recognition</b></summary>
  <p><b>编号</b>：[267]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09801</p>
  <p><b>作者</b>：Jiachen Sun,  Weili Nie,  Zhiding Yu,  Z. Morley Mao,  Chaowei Xiao</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：critical data representation, Point cloud, Point, autonomous driving, medical imaging</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>3D Point cloud is becoming a critical data representation in many real-world
applications like autonomous driving, robotics, and medical imaging. Although
the success of deep learning further accelerates the adoption of 3D point
clouds in the physical world, deep learning is notorious for its vulnerability
to adversarial attacks. In this work, we first identify that the
state-of-the-art empirical defense, adversarial training, has a major
limitation in applying to 3D point cloud models due to gradient obfuscation. We
further propose PointDP, a purification strategy that leverages diffusion
models to defend against 3D adversarial attacks. We extensively evaluate
PointDP on six representative 3D point cloud architectures, and leverage 10+
strong and adaptive attacks to demonstrate its lower-bound robustness. Our
evaluation shows that PointDP achieves significantly better robustness than
state-of-the-art purification methods under strong attacks. Results of
certified defenses on randomized smoothing combined with PointDP will be
included in the near future.</p>
  </details>
</details>
<details>
  <summary>62. <b>标题：Towards MOOCs for Lip Reading: Using Synthetic Talking Heads to Train  Humans in Lipreading at Scale</b></summary>
  <p><b>编号</b>：[270]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09796</p>
  <p><b>作者</b>：Aditya Agarwal,  Bipasha Sen,  Rudrabha Mukhopadhyay,  Vinay Namboodiri,  C.V Jawahar</p>
  <p><b>备注</b>：Accepted at WACV 2023</p>
  <p><b>关键词</b>：primary mode, lipreading, Coursera and Udemy, communication, resources</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Many people with some form of hearing loss consider lipreading as their
primary mode of day-to-day communication. However, finding resources to learn
or improve one's lipreading skills can be challenging. This is further
exacerbated in COVID$19$ pandemic due to restrictions on direct interactions
with peers and speech therapists. Today, online MOOCs platforms like Coursera
and Udemy have become the most effective form of training for many kinds of
skill development. However, online lipreading resources are scarce as creating
such resources is an extensive process needing months of manual effort to
record hired actors. Because of the manual pipeline, such platforms are also
limited in the vocabulary, supported languages, accents, and speakers, and have
a high usage cost. In this work, we investigate the possibility of replacing
real human talking videos with synthetically generated videos. Synthetic data
can be used to easily incorporate larger vocabularies, variations in accent,
and even local languages, and many speakers. We propose an end-to-end automated
pipeline to develop such a platform using state-of-the-art talking heading
video generator networks, text-to-speech models, and computer vision
techniques. We then perform an extensive human evaluation using carefully
thought out lipreading exercises to validate the quality of our designed
platform against the existing lipreading platforms. Our studies concretely
point towards the potential of our approach for the development of a
large-scale lipreading MOOCs platform that can impact millions of people with
hearing loss.</p>
  </details>
</details>
<details>
  <summary>63. <b>标题：FaceOff: A Video-to-Video Face Swapping System</b></summary>
  <p><b>编号</b>：[273]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09788</p>
  <p><b>作者</b>：Aditya Agarwal,  Bipasha Sen,  Rudrabha Mukhopadhyay,  Vinay Namboodiri,  C.V. Jawahar</p>
  <p><b>备注</b>：Accepted at WACV 2023</p>
  <p><b>关键词</b>：movie industry, indispensable role, actor plays multiple, face video, face</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Doubles play an indispensable role in the movie industry. They take the place
of the actors in dangerous stunt scenes or in scenes where the same actor plays
multiple characters. The double's face is later replaced with the actor's face
and expressions manually using expensive CGI technology, costing millions of
dollars and taking months to complete. An automated, inexpensive, and fast way
can be to use face-swapping techniques that aim to swap an identity from a
source face video (or an image) to a target face video. However, such methods
can not preserve the source expressions of the actor important for the scene's
context. % essential for the scene. % that are essential in cinemas. To tackle
this challenge, we introduce video-to-video (V2V) face-swapping, a novel task
of face-swapping that can preserve (1) the identity and expressions of the
source (actor) face video and (2) the background and pose of the target
(double) video. We propose FaceOff, a V2V face-swapping system that operates by
learning a robust blending operation to merge two face videos following the
constraints above. It first reduces the videos to a quantized latent space and
then blends them in the reduced space. FaceOff is trained in a self-supervised
manner and robustly tackles the non-trivial challenges of V2V face-swapping. As
shown in the experimental section, FaceOff significantly outperforms alternate
approaches qualitatively and quantitatively.</p>
  </details>
</details>
<details>
  <summary>64. <b>标题：RGBD1K: A Large-scale Dataset and Benchmark for RGB-D Object Tracking</b></summary>
  <p><b>编号</b>：[274]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09787</p>
  <p><b>作者</b>：Xue-Feng Zhu,  Tianyang Xu,  Zhangyong Tang,  Zucheng Wu,  Haodong Liu,  Xiao Yang,  Xiao-Jun Wu,  Josef Kittler</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：considerable attention recently, attracted considerable attention, achieving promising performance, attention recently, achieving promising</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>RGB-D object tracking has attracted considerable attention recently,
achieving promising performance thanks to the symbiosis between visual and
depth channels. However, given a limited amount of annotated RGB-D tracking
data, most state-of-the-art RGB-D trackers are simple extensions of
high-performance RGB-only trackers, without fully exploiting the underlying
potential of the depth channel in the offline training stage. To address the
dataset deficiency issue, a new RGB-D dataset named RGBD1K is released in this
paper. The RGBD1K contains 1,050 sequences with about 2.5M frames in total. To
demonstrate the benefits of training on a larger RGB-D data set in general, and
RGBD1K in particular, we develop a transformer-based RGB-D tracker, named SPT,
as a baseline for future visual object tracking studies using the new dataset.
The results, of extensive experiments using the SPT tracker emonstrate the
potential of the RGBD1K dataset to improve the performance of RGB-D tracking,
inspiring future developments of effective tracker designs. The dataset and
codes will be available on the project homepage:
https://will.be.available.at.this.website.</p>
  </details>
</details>
<details>
  <summary>65. <b>标题：JVLDLoc: a Joint Optimization of Visual-LiDAR Constraints and Direction  Priors for Localization in Driving Scenario</b></summary>
  <p><b>编号</b>：[279]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09777</p>
  <p><b>作者</b>：Longrui Dong,  Gang Zeng</p>
  <p><b>备注</b>：28 pages (including supplementary material)</p>
  <p><b>关键词</b>：emerging applications, autonomous driving, agent to localize, basic demand, demand for emerging</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The ability for a moving agent to localize itself in environment is the basic
demand for emerging applications, such as autonomous driving, etc. Many
existing methods based on multiple sensors still suffer from drift. We propose
a scheme that fuses map prior and vanishing points from images, which can
establish an energy term that is only constrained on rotation, called the
direction projection error. Then we embed these direction priors into a
visual-LiDAR SLAM system that integrates camera and LiDAR measurements in a
tightly-coupled way at backend. Specifically, our method generates visual
reprojection error and point to Implicit Moving Least Square(IMLS) surface of
scan constraints, and solves them jointly along with direction projection error
at global optimization. Experiments on KITTI, KITTI-360 and Oxford Radar
Robotcar show that we achieve lower localization error or Absolute Pose Error
(APE) than prior map, which validates our method is effective.</p>
  </details>
</details>
<details>
  <summary>66. <b>标题：Artifact-Based Domain Generalization of Skin Lesion Models</b></summary>
  <p><b>编号</b>：[284]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09756</p>
  <p><b>作者</b>：Alceu Bissoto,  Catarina Barata,  Eduardo Valle,  Sandra Avila</p>
  <p><b>备注</b>：Accepted to the ISIC Skin Image Analysis Workshop @ ECCV 2022</p>
  <p><b>关键词</b>：Deep Learning failure, Learning failure cases, Deep Learning, Learning failure, medical area</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep Learning failure cases are abundant, particularly in the medical area.
Recent studies in out-of-distribution generalization have advanced considerably
on well-controlled synthetic datasets, but they do not represent medical
imaging contexts. We propose a pipeline that relies on artifacts annotation to
enable generalization evaluation and debiasing for the challenging skin lesion
analysis context. First, we partition the data into levels of increasingly
higher biased training and test sets for better generalization assessment.
Then, we create environments based on skin lesion artifacts to enable domain
generalization methods. Finally, after robust training, we perform a test-time
debiasing procedure, reducing spurious features in inference images. Our
experiments show our pipeline improves performance metrics in biased cases, and
avoids artifacts when using explanation methods. Still, when evaluating such
models in out-of-distribution data, they did not prefer clinically-meaningful
features. Instead, performance only improved in test sets that present similar
artifacts from training, suggesting models learned to ignore the known set of
artifacts. Our results raise a concern that debiasing models towards a single
aspect may not be enough for fair skin lesion analysis.</p>
  </details>
</details>
<details>
  <summary>67. <b>标题：A Multi-Head Model for Continual Learning via Out-of-Distribution Replay</b></summary>
  <p><b>编号</b>：[295]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09734</p>
  <p><b>作者</b>：Gyuhak Kim,  Zixuan Ke,  Bing Liu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：previous tasks, studies class incremental, task, tasks, CIL</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper studies class incremental learning (CIL) of continual learning
(CL). Many approaches have been proposed to deal with catastrophic forgetting
(CF) in CIL. Most methods incrementally construct a single classifier for all
classes of all tasks in a single head network. To prevent CF, a popular
approach is to memorize a small number of samples from previous tasks and
replay them during training of the new task. However, this approach still
suffers from serious CF as the parameters learned for previous tasks are
updated or adjusted with only the limited number of saved samples in the
memory. This paper proposes an entirely different approach that builds a
separate classifier (head) for each task (called a multi-head model) using a
transformer network, called MORE. Instead of using the saved samples in memory
to update the network for previous tasks/classes in the existing approach, MORE
leverages the saved samples to build a task specific classifier (adding a new
classification head) without updating the network learned for previous
tasks/classes. The model for the new task in MORE is trained to learn the
classes of the task and also to detect samples that are not from the same data
distribution (i.e., out-of-distribution (OOD)) of the task. This enables the
classifier for the task to which the test instance belongs to produce a high
score for the correct class and the classifiers of other tasks to produce low
scores because the test instance is not from the data distributions of these
classifiers. Experimental results show that MORE outperforms state-of-the-art
baselines and is also naturally capable of performing OOD detection in the
continual learning setting.</p>
  </details>
</details>
<details>
  <summary>68. <b>标题：Learning Primitive-aware Discriminative Representations for FSL</b></summary>
  <p><b>编号</b>：[300]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09717</p>
  <p><b>作者</b>：Jianpeng Yang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：achieved promising performance, ignore abundant local, unseen classes.Some study, cognitive science argue, episodic training mechanism,We</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Few-shot learning (FSL) aims to learn a classifier that can be easily adapted
to recognize novel classes,given only a few labeled examples per class.Limited
data keep this task challenging for deep learning.Recent metric-based methods
has achieved promising performance based on image-level features.However,these
global features ignore abundant local and structural information that is
transferable and consistent between seen and unseen classes.Some study in
cognitive science argue that humans can recognize novel classes with the
learned primitives.We expect to mine both transferable and discriminative
representation from base classes and adopt them to recognize novel
classes.Building on the episodic training mechanism,We propose a Primitive
Mining and Reasoning Network(PMRN) to learn primitive-aware representation in
an end-to-end manner for metric-based FSL model.We first add self-supervision
auxiliary task,forcing feature extractor to learn tvisual pattern corresponding
to this http URL further mine and produce transferable primitive-aware
representations,we design an Adaptive Channel Grouping(ACG)module to synthesize
a set of visual primitives from object embedding by enhancing informative
channel maps while suppressing useless ones. Based on the learned primitive
feature,a Semantic Correlation Reasoning (SCR) module is proposed to capture
internal relations among them.Finally,we learn the task-specific importance of
primitives and conduct primitive-level metric based on the task-specific
attention feature.Extensive experiments show that our method achieves
state-of-the-art results on six standard benchmarks.</p>
  </details>
</details>
<details>
  <summary>69. <b>标题：DenseShift: Towards Accurate and Transferable Low-Bit Shift Network</b></summary>
  <p><b>编号</b>：[305]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09708</p>
  <p><b>作者</b>：Xinlin Li,  Bang Liu,  Rui Heng Yang,  Vanessa Courville,  Chao Xing,  Vahid Partovi Nia</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：ever-increasing resource requirements, low-resource edge devices, Deploying deep neural, deep neural networks, low-bit shift networks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deploying deep neural networks on low-resource edge devices is challenging
due to their ever-increasing resource requirements. Recent investigations
propose multiplication-free neural networks to reduce computation and memory
consumption. Shift neural network is one of the most effective tools towards
these reductions. However, existing low-bit shift networks are not as accurate
as their full precision counterparts and cannot efficiently transfer to a wide
range of tasks due to their inherent design flaws. We propose DenseShift
network that exploits the following novel designs. First, we demonstrate that
the zero-weight values in low-bit shift networks are neither useful to the
model capacity nor simplify the model inference. Therefore, we propose to use a
zero-free shifting mechanism to simplify inference while increasing the model
capacity. Second, we design a new metric to measure the weight freezing issue
in training low-bit shift networks, and propose a sign-scale decomposition to
improve the training efficiency. Third, we propose the low-variance random
initialization strategy to improve the model's performance in transfer learning
scenarios. We run extensive experiments on various computer vision and speech
tasks. The experimental results show that DenseShift network significantly
outperforms existing low-bit multiplication-free networks and can achieve
competitive performance to the full-precision counterpart. It also exhibits
strong transfer learning performance with no drop in accuracy.</p>
  </details>
</details>
<details>
  <summary>70. <b>标题：SnowFormer: Scale-aware Transformer via Context Interaction for Single  Image Desnowing</b></summary>
  <p><b>编号</b>：[308]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09703</p>
  <p><b>作者</b>：Sixiang Chen,  Tian Ye,  Yun Liu,  Erkang Chen,  Jun Shi,  Jingchun Zhou</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：context interaction, common yet challenging, Scale-aware Feature Aggregation, Context Interaction Transformer, interaction</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Single image desnowing is a common yet challenging task. The complex snow
degradations and diverse degradation scales demand strong representation
ability. In order for the desnowing network to see various snow degradations
and model the context interaction of local details and global information, we
propose a powerful architecture dubbed as SnowFormer. First, it performs
Scale-aware Feature Aggregation in the encoder to capture rich snow information
of various degradations. Second, in order to tackle with large-scale
degradation, it uses a novel Context Interaction Transformer Block in the
decoder, which conducts context interaction of local details and global
information from previous scale-aware feature aggregation in global context
interaction. And the introduction of local context interaction improves
recovery of scene details. Third, we devise a Heterogeneous Feature Projection
Head which progressively fuse features from both the encoder and decoder and
project the refined feature into the clean image. Extensive experiments
demonstrate that the proposed SnowFormer achieves significant improvements over
other SOTA methods. Compared with SOTA single image desnowing method HDCW-Net,
it boosts the PSNR metric by 9.2dB on the CSD testset. Moreover, it also
achieves a 5.13dB increase in PSNR compared with general image restoration
architecture NAFNet, which verifies the strong representation ability of our
SnowFormer for snow removal task. The code is released in
\url{this https URL}.</p>
  </details>
</details>
<details>
  <summary>71. <b>标题：Fuse and Attend: Generalized Embedding Learning for Art and Sketches</b></summary>
  <p><b>编号</b>：[312]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09698</p>
  <p><b>作者</b>：Ujjal Kr Dutta</p>
  <p><b>备注</b>：Accepted in European Conference on Computer Vision (ECCV) 2022 Workshops: DIRA</p>
  <p><b>关键词</b>：witnessed widespread success, deep Embedding Learning, Embedding Learning approaches, representing natural images, Embedding Learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>While deep Embedding Learning approaches have witnessed widespread success in
multiple computer vision tasks, the state-of-the-art methods for representing
natural images need not necessarily perform well on images from other domains,
such as paintings, cartoons, and sketch. This is because of the huge shift in
the distribution of data from across these domains, as compared to natural
images. Domains like sketch often contain sparse informative pixels. However,
recognizing objects in such domains is crucial, given multiple relevant
applications leveraging such data, for instance, sketch to image retrieval.
Thus, achieving an Embedding Learning model that could perform well across
multiple domains is not only challenging, but plays a pivotal role in computer
vision. To this end, in this paper, we propose a novel Embedding Learning
approach with the goal of generalizing across different domains. During
training, given a query image from a domain, we employ gated fusion and
attention to generate a positive example, which carries a broad notion of the
semantics of the query object category (from across multiple domains). By
virtue of Contrastive Learning, we pull the embeddings of the query and
positive, in order to learn a representation which is robust across domains. At
the same time, to teach the model to be discriminative against examples from
different semantic categories (across domains), we also maintain a pool of
negative embeddings (from different categories). We show the prowess of our
method using the DomainBed framework, on the popular PACS (Photo, Art painting,
Cartoon, and Sketch) dataset.</p>
  </details>
</details>
<details>
  <summary>72. <b>标题：Effectiveness of Function Matching in Driving Scene Recognition</b></summary>
  <p><b>编号</b>：[314]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09694</p>
  <p><b>作者</b>：Shingo Yashima</p>
  <p><b>备注</b>：Autonomous Vehicle Vision (AVVision) Workshop at ECCV2022</p>
  <p><b>关键词</b>：training compact recognizers, compact recognizers required, effective approach, approach for training, recognizers required</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Knowledge distillation is an effective approach for training compact
recognizers required in autonomous driving. Recent studies on image
classification have shown that matching student and teacher on a wide range of
data points is critical for improving performance in distillation. This concept
(called function matching) is suitable for driving scene recognition, where
generally an almost infinite amount of unlabeled data are available. In this
study, we experimentally investigate the impact of using such a large amount of
unlabeled data for distillation on the performance of student models in
structured prediction tasks for autonomous driving. Through extensive
experiments, we demonstrate that the performance of the compact student model
can be improved dramatically and even match the performance of the large-scale
teacher by knowledge distillation with massive unlabeled data.</p>
  </details>
</details>
<details>
  <summary>73. <b>标题：Learning Sub-Pixel Disparity Distribution for Light Field Depth  Estimation</b></summary>
  <p><b>编号</b>：[317]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09688</p>
  <p><b>作者</b>：Wentao Chao,  Xuechun Wang,  Yingqian Wang,  Liang Chang,  Fuqing Duan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Existing light field, estimation methods generally, regressed disparity map, depth estimation methods, depth estimation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Existing light field (LF) depth estimation methods generally consider depth
estimation as a regression problem, supervised by a pixel-wise L1 loss between
the regressed disparity map and the groundtruth one. However, the disparity map
is only a sub-space projection (i.e., an expectation) of the disparity
distribution, while the latter one is more essential for models to learn. In
this paper, we propose a simple yet effective method to learn the sub-pixel
disparity distribution by fully utilizing the power of deep networks. In our
method, we construct the cost volume at sub-pixel level to produce a finer
depth distribution and design an uncertainty-aware focal loss to supervise the
disparity distribution to be close to the groundtruth one. Extensive
experimental results demonstrate the effectiveness of our method. Our method,
called SubFocal, ranks the first place among 99 submitted algorithms on the HCI
4D LF Benchmark in terms of all the five accuracy metrics (i.e., BadPix0.01,
BadPix0.03, BadPix0.07, MSE and Q25), and significantly outperforms recent
state-of-the-art LF depth methods such as OACC-Net and AttMLFNet. Code and
model are available at this https URL.</p>
  </details>
</details>
<details>
  <summary>74. <b>标题：YOLOV: Making Still Image Object Detectors Great at Video Object  Detection</b></summary>
  <p><b>编号</b>：[318]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09686</p>
  <p><b>作者</b>：Yuheng Shi,  Naiyan Wang,  Xiaojie Guo</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Video object detection, object appearance, Video object, high variation, diverse deterioration</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Video object detection (VID) is challenging because of the high variation of
object appearance as well as the diverse deterioration in some frames. On the
positive side, the detection in a certain frame of a video, compared with in a
still image, can draw support from other frames. Hence, how to aggregate
features across different frames is pivotal to the VID problem. Most of
existing aggregation algorithms are customized for two-stage detectors. But,
the detectors in this category are usually computationally expensive due to the
two-stage nature. This work proposes a simple yet effective strategy to address
the above concerns, which spends marginal overheads with significant gains in
accuracy. Concretely, different from the traditional two-stage pipeline, we
advocate putting the region-level selection after the one-stage detection to
avoid processing massive low-quality candidates. Besides, a novel module is
constructed to evaluate the relationship between a target frame and its
reference ones, and guide the aggregation. Extensive experiments and ablation
studies are conducted to verify the efficacy of our design, and reveal its
superiority over other state-of-the-art VID approaches in both effectiveness
and efficiency. Our YOLOX-based model can achieve promising performance (e.g.,
87.5\% AP50 at over 30 FPS on the ImageNet VID dataset on a single 2080Ti GPU),
making it attractive for large-scale or real-time applications. The
implementation is simple, the demo code and models have been made available at
this https URL .</p>
  </details>
</details>
<details>
  <summary>75. <b>标题：Finding Emotions in Faces: A Meta-Classifier</b></summary>
  <p><b>编号</b>：[320]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09678</p>
  <p><b>作者</b>：Siddartha Dalal,  Sierra Vo,  Michael Lesk,  Wesley Yuan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：anger and contempt, emotions in faces, emotional states, recognize emotions, Machine learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Machine learning has been used to recognize emotions in faces, typically by
looking for 8 different emotional states (neutral, happy, sad, surprise, fear,
disgust, anger and contempt). We consider two approaches: feature recognition
based on facial landmarks and deep learning on all pixels; each produced 58%
overall accuracy. However, they produced different results on different images
and thus we propose a new meta-classifier combining these approaches. It
produces far better results with 77% accuracy</p>
  </details>
</details>
<details>
  <summary>76. <b>标题：Net2Brain: A Toolbox to compare artificial vision models with human  brain responses</b></summary>
  <p><b>编号</b>：[321]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09677</p>
  <p><b>作者</b>：Domenic Bersch,  Kshitij Dwivedi,  Martina Vilas,  Radoslaw M. Cichy,  Gemma Roig</p>
  <p><b>备注</b>：4 Pages, 3 figures, submitted and accepted to CCNeuro 2022. For associated repository, see this https URL</p>
  <p><b>关键词</b>：deep neural networks, command-line user interface, artificial deep neural, user interface toolbox, human brain recordings</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We introduce Net2Brain, a graphical and command-line user interface toolbox
for comparing the representational spaces of artificial deep neural networks
(DNNs) and human brain recordings. While different toolboxes facilitate only
single functionalities or only focus on a small subset of supervised image
classification models, Net2Brain allows the extraction of activations of more
than 600 DNNs trained to perform a diverse range of vision-related tasks (e.g
semantic segmentation, depth estimation, action recognition, etc.), over both
image and video datasets. The toolbox computes the representational
dissimilarity matrices (RDMs) over those activations and compares them to brain
recordings using representational similarity analysis (RSA), weighted RSA, both
in specific ROIs and with searchlight search. In addition, it is possible to
add a new data set of stimuli and brain recordings to the toolbox for
evaluation. We demonstrate the functionality and advantages of Net2Brain with
an example showcasing how it can be used to test hypotheses of cognitive
computational neuroscience.</p>
  </details>
</details>
<details>
  <summary>77. <b>标题：Generalised Co-Salient Object Detection</b></summary>
  <p><b>编号</b>：[327]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09668</p>
  <p><b>作者</b>：Jiawei Liu,  Jing Zhang,  Kaihao Zhang,  Nick Barnes</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：co-salient object detection, salient object exists, common salient object, Generalised CoSOD Training, co-salient object</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Conventional co-salient object detection (CoSOD) has a strong assumption that
\enquote{a common salient object exists in every image of the same group}.
However, the biased assumption contradicts real scenarios where co-salient
objects could be partially or completely absent in a group of images. We
propose a random sampling based Generalised CoSOD Training (GCT) strategy to
distill the awareness of inter-image absence of co-salient object(s) into CoSOD
models. In addition, the random sampling process inherent in GCT enables the
generation of a high-quality uncertainty map, with which we can further
remediate less confident model predictions that are prone to localising
non-common salient objects. To evaluate the generalisation ability of CoSOD
models, we propose two new testing datasets, namely CoCA-Common and CoCA-Zero,
where a common salient object is partially present in the former and completely
absent in the latter. Extensive experiments demonstrate that our proposed
method significantly improves the generalisation ability of CoSOD models on the
two new datasets, while not negatively impacting its performance under the
conventional CoSOD setting. Codes are available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>78. <b>标题：Modeling, Quantifying, and Predicting Subjectivity of Image Aesthetics</b></summary>
  <p><b>编号</b>：[328]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09666</p>
  <p><b>作者</b>：Hyeongnam Jang,  Yeejin Lee,  Jong-Seok Lee</p>
  <p><b>备注</b>：8 pages, 6 figures</p>
  <p><b>关键词</b>：computer vision task, challenging computer vision, vision task, challenging computer, computer vision</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Assessing image aesthetics is a challenging computer vision task. One reason
is that aesthetic preference is highly subjective and may vary significantly
among people for certain images. Thus, it is important to properly model and
quantify such \textit{subjectivity}, but there has not been much effort to
resolve this issue. In this paper, we propose a novel unified probabilistic
framework that can model and quantify subjective aesthetic preference based on
the subjective logic. In this framework, the rating distribution is modeled as
a beta distribution, from which the probabilities of being definitely pleasing,
being definitely unpleasing, and being uncertain can be obtained. We use the
probability of being uncertain to define an intuitive metric of subjectivity.
Furthermore, we present a method to learn deep neural networks for prediction
of image aesthetics, which is shown to be effective in improving the
performance of subjectivity prediction via experiments. We also present an
application scenario where the framework is beneficial for aesthetics-based
image recommendation.</p>
  </details>
</details>
<details>
  <summary>79. <b>标题：Offline Handwritten Mathematical Recognition using Adversarial Learning  and Transformers</b></summary>
  <p><b>编号</b>：[330]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09662</p>
  <p><b>作者</b>：Ujjwal Thakur,  Anuj Sharma</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Mathematical Expression Recognition, Expression Recognition, Handwritten Mathematical Expression, Offline Handwritten Mathematical, Recognition</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Offline Handwritten Mathematical Expression Recognition (HMER) is a major
area in the field of mathematical expression recognition. Offline HMER is often
viewed as a much harder problem as compared to online HMER due to a lack of
temporal information and variability in writing style. In this paper, we
purpose a encoder-decoder model that uses paired adversarial learning.
Semantic-invariant features are extracted from handwritten mathematical
expression images and their printed mathematical expression counterpart in the
encoder. Learning of semantic-invariant features combined with the DenseNet
encoder and transformer decoder, helped us to improve the expression rate from
previous studies. Evaluated on the CROHME dataset, we have been able to improve
latest CROHME 2019 test set results by 4% approx.</p>
  </details>
</details>
<details>
  <summary>80. <b>标题：A Visual Analytics Framework for Composing a Hierarchical Classification  for Medieval Illuminations</b></summary>
  <p><b>编号</b>：[334]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09657</p>
  <p><b>作者</b>：Christofer Meinecke,  Estelle Guéville,  David Joseph Wrisley,  Stefan Jänicke</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：applying supervised machine, supervised machine learning, requirement for applying, supervised machine, machine learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Annotated data is a requirement for applying supervised machine learning
methods, and the quality of annotations is crucial for the result. Especially
when working with cultural heritage collections that inhere a manifold of
uncertainties, annotating data remains a manual, arduous task to be carried out
by domain experts. Our project started with two already annotated sets of
medieval manuscript images which however were incomplete and comprised
conflicting metadata based on scholarly and linguistic differences. Our aims
were to create (1) a uniform set of descriptive labels for the combined data
set, and (2) a hierarchical classification of a high quality that can be used
as a valuable input for supervised machine learning. To reach these goals, we
developed a visual analytics system to enable medievalists to combine,
regularize and extend the vocabulary used to describe these data sets. Visual
interfaces for word and image embeddings as well as co-occurrences of the
annotations across the data sets enable annotating multiple images at the same
time, recommend annotation label candidates and support composing a
hierarchical classification of labels. Our system itself implements a
semi-supervised method as it updates visual representations based on the
medievalists' feedback, and a series of usage scenarios document its value for
the target community.</p>
  </details>
</details>
<details>
  <summary>81. <b>标题：Persuasion Strategies in Advertisements: Dataset, Modeling, and  Baselines</b></summary>
  <p><b>编号</b>：[346]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09626</p>
  <p><b>作者</b>：Yaman Kumar Singla,  Rajat Jha,  Arunim Gupta,  Milan Aggarwal,  Aditya Garg,  Ayush Bhardwaj,  Tushar,  Balaji Krishnamurthy,  Rajiv Ratn Shah,  Changyou Chen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：advertisement persuasive, eliciting the desired, response from consumer, makes an advertisement, desired response</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Modeling what makes an advertisement persuasive, i.e., eliciting the desired
response from consumer, is critical to the study of propaganda, social
psychology, and marketing. Despite its importance, computational modeling of
persuasion in computer vision is still in its infancy, primarily due to the
lack of benchmark datasets that can provide persuasion-strategy labels
associated with ads. Motivated by persuasion literature in social psychology
and marketing, we introduce an extensive vocabulary of persuasion strategies
and build the first ad image corpus annotated with persuasion strategies. We
then formulate the task of persuasion strategy prediction with multi-modal
learning, where we design a multi-task attention fusion model that can leverage
other ad-understanding tasks to predict persuasion strategies. Further, we
conduct a real-world case study on 1600 advertising campaigns of 30 Fortune-500
companies where we use our model's predictions to analyze which strategies work
with different demographics (age and gender). The dataset also provides image
segmentation masks, which labels persuasion strategies in the corresponding ad
images on the test split. We publicly release our code and dataset
this https URL.</p>
  </details>
</details>
<details>
  <summary>82. <b>标题：MemoNav: Selecting Informative Memories for Visual Navigation</b></summary>
  <p><b>编号</b>：[358]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09610</p>
  <p><b>作者</b>：Hongxin Li,  Xu Yang,  Yuran Yang,  Shuqi Mei,  Zhaoxiang Zhang</p>
  <p><b>备注</b>：Submitted to ICLR2023</p>
  <p><b>关键词</b>：previously unseen scene, short-term memory, memory, navigation, unseen scene</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Image-goal navigation is a challenging task, as it requires the agent to
navigate to a target indicated by an image in a previously unseen scene.
Current methods introduce diverse memory mechanisms which save navigation
history to solve this task. However, these methods use all observations in the
memory for generating navigation actions without considering which fraction of
this memory is informative. To address this limitation, we present the MemoNav,
a novel memory mechanism for image-goal navigation, which retains the agent's
informative short-term memory and long-term memory to improve the navigation
performance on a multi-goal task. The node features on the agent's topological
map are stored in the short-term memory, as these features are dynamically
updated. To aid the short-term memory, we also generate long-term memory by
continuously aggregating the short-term memory via a graph attention module.
The MemoNav retains the informative fraction of the short-term memory via a
forgetting module based on a Transformer decoder and then incorporates this
retained short-term memory and the long-term memory into working memory.
Lastly, the agent uses the working memory for action generation. We evaluate
our model on a new multi-goal navigation dataset. The experimental results show
that the MemoNav outperforms the SoTA methods by a large margin with a smaller
fraction of navigation history. The results also empirically show that our
model is less likely to be trapped in a deadlock, which further validates that
the MemoNav improves the agent's navigation efficiency by reducing redundant
steps.</p>
  </details>
</details>
<details>
  <summary>83. <b>标题：Analyzing Adversarial Robustness of Vision Transformers against Spatial  and Spectral Attacks</b></summary>
  <p><b>编号</b>：[360]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09602</p>
  <p><b>作者</b>：Gihyun Kim,  Jong-Seok Lee</p>
  <p><b>备注</b>：11 pages, 13 figures</p>
  <p><b>关键词</b>：convolutional neural networks, outperform convolutional neural, image classification tasks, Transformers, neural networks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Vision Transformers have emerged as a powerful architecture that can
outperform convolutional neural networks (CNNs) in image classification tasks.
Several attempts have been made to understand robustness of Transformers
against adversarial attacks, but existing studies draw inconsistent results,
i.e., some conclude that Transformers are more robust than CNNs, while some
others find that they have similar degrees of robustness. In this paper, we
address two issues unexplored in the existing studies examining adversarial
robustness of Transformers. First, we argue that the image quality should be
simultaneously considered in evaluating adversarial robustness. We find that
the superiority of one architecture to another in terms of robustness can
change depending on the attack strength expressed by the quality of the
attacked images. Second, by noting that Transformers and CNNs rely on different
types of information in images, we formulate an attack framework, called
Fourier attack, as a tool for implementing flexible attacks, where an image can
be attacked in the spectral domain as well as in the spatial domain. This
attack perturbs the magnitude and phase information of particular frequency
components selectively. Through extensive experiments, we find that
Transformers tend to rely more on phase information and low frequency
information than CNNs, and thus sometimes they are even more vulnerable under
frequency-selective attacks. It is our hope that this work provides new
perspectives in understanding the properties and adversarial robustness of
Transformers.</p>
  </details>
</details>
<details>
  <summary>84. <b>标题：Vision-Language Matching for Text-to-Image Synthesis via Generative  Adversarial Networks</b></summary>
  <p><b>编号</b>：[363]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09596</p>
  <p><b>作者</b>：Qingrong Cheng,  Keyu Wen,  Xiaodong Gu</p>
  <p><b>备注</b>：14 pages</p>
  <p><b>关键词</b>：Vision-Language Matching, image, text description, dual vision-language matching, specific text description</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Text-to-image synthesis aims to generate a photo-realistic and semantic
consistent image from a specific text description. The images synthesized by
off-the-shelf models usually contain limited components compared with the
corresponding image and text description, which decreases the image quality and
the textual-visual consistency. To address this issue, we propose a novel
Vision-Language Matching strategy for text-to-image synthesis, named VLMGAN*,
which introduces a dual vision-language matching mechanism to strengthen the
image quality and semantic consistency. The dual vision-language matching
mechanism considers textual-visual matching between the generated image and the
corresponding text description, and visual-visual consistent constraints
between the synthesized image and the real image. Given a specific text
description, VLMGAN* firstly encodes it into textual features and then feeds
them to a dual vision-language matching-based generative model to synthesize a
photo-realistic and textual semantic consistent image. Besides, the popular
evaluation metrics for text-to-image synthesis are borrowed from simple image
generation, which mainly evaluates the reality and diversity of the synthesized
images. Therefore, we introduce a metric named Vision-Language Matching Score
(VLMS) to evaluate the performance of text-to-image synthesis which can
consider both the image quality and the semantic consistency between
synthesized image and the description. The proposed dual multi-level
vision-language matching strategy can be applied to other text-to-image
synthesis methods. We implement this strategy on two popular baselines, which
are marked with ${\text{VLMGAN}_{+\text{AttnGAN}}}$ and
${\text{VLMGAN}_{+\text{DFGAN}}}$. The experimental results on two widely-used
datasets show that the model achieves significant improvements over other
state-of-the-art methods.</p>
  </details>
</details>
<details>
  <summary>85. <b>标题：Transforming the Interactive Segmentation for Medical Imaging</b></summary>
  <p><b>编号</b>：[365]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09592</p>
  <p><b>作者</b>：Wentao Liu,  Chaofan Ma,  Yuhuan Yang,  Weidi Xie,  Ya Zhang</p>
  <p><b>备注</b>：Accepted to MICCAI 2022</p>
  <p><b>关键词</b>：small organs, interactively refine, refine the automatic, structures that fall, fall behind human</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The goal of this paper is to interactively refine the automatic segmentation
on challenging structures that fall behind human performance, either due to the
scarcity of available annotations or the difficulty nature of the problem
itself, for example, on segmenting cancer or small organs. Specifically, we
propose a novel Transformer-based architecture for Interactive Segmentation
(TIS), that treats the refinement task as a procedure for grouping pixels with
similar features to those clicks given by the end users. Our proposed
architecture is composed of Transformer Decoder variants, which naturally
fulfills feature comparison with the attention mechanisms. In contrast to
existing approaches, our proposed TIS is not limited to binary segmentations,
and allows the user to edit masks for arbitrary number of categories. To
validate the proposed approach, we conduct extensive experiments on three
challenging datasets and demonstrate superior performance over the existing
state-of-the-art methods. The project page is: this https URL.</p>
  </details>
</details>
<details>
  <summary>86. <b>标题：Review on Action Recognition for Accident Detection in Smart City  Transportation Systems</b></summary>
  <p><b>编号</b>：[368]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09588</p>
  <p><b>作者</b>：Victor Adewopo,  Nelly Elsayed,  Zag ElSayed,  Murat Ozer,  Ahmed Abdelgawad,  Magdy Bayoumi</p>
  <p><b>备注</b>：16 pages</p>
  <p><b>关键词</b>：crucial aspects, safe community, accident detection, public traffic safety, traffic</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Action detection and public traffic safety are crucial aspects of a safe
community and a better society. Monitoring traffic flows in a smart city using
different surveillance cameras can play a significant role in recognizing
accidents and alerting first responders. The utilization of action recognition
(AR) in computer vision tasks has contributed towards high-precision
applications in video surveillance, medical imaging, and digital signal
processing. This paper presents an intensive review focusing on action
recognition in accident detection and autonomous transportation systems for a
smart city. In this paper, we focused on AR systems that used diverse sources
of traffic video capturing, such as static surveillance cameras on traffic
intersections, highway monitoring cameras, drone cameras, and dash-cams.
Through this review, we identified the primary techniques, taxonomies, and
algorithms used in AR for autonomous transportation and accident detection. We
also examined data sets utilized in the AR tasks, identifying the main sources
of datasets and features of the datasets. This paper provides potential
research direction to develop and integrate accident detection systems for
autonomous cars and public traffic safety systems by alerting emergency
personnel and law enforcement in the event of road accidents to minimize human
error in accident reporting and provide a spontaneous response to victims</p>
  </details>
</details>
<details>
  <summary>87. <b>标题：Learning in Audio-visual Context: A Review, Analysis, and New  Perspective</b></summary>
  <p><b>编号</b>：[372]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09579</p>
  <p><b>作者</b>：Yake Wei,  Di Hu,  Yapeng Tian,  Xuelong Li</p>
  <p><b>备注</b>：this https URL</p>
  <p><b>关键词</b>：audio-visual, audio-visual learning, Sight and hearing, senses that play, play a vital</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Sight and hearing are two senses that play a vital role in human
communication and scene understanding. To mimic human perception ability,
audio-visual learning, aimed at developing computational approaches to learn
from both audio and visual modalities, has been a flourishing field in recent
years. A comprehensive survey that can systematically organize and analyze
studies of the audio-visual field is expected. Starting from the analysis of
audio-visual cognition foundations, we introduce several key findings that have
inspired our computational studies. Then, we systematically review the recent
audio-visual learning studies and divide them into three categories:
audio-visual boosting, cross-modal perception and audio-visual collaboration.
Through our analysis, we discover that, the consistency of audio-visual data
across semantic, spatial and temporal support the above studies. To revisit the
current development of the audio-visual learning field from a more macro view,
we further propose a new perspective on audio-visual scene understanding, then
discuss and analyze the feasible future direction of the audio-visual learning
area. Overall, this survey reviews and outlooks the current audio-visual
learning field from different aspects. We hope it can provide researchers with
a better understanding of this area. A website including constantly-updated
survey is released: \url{this https URL}.</p>
  </details>
</details>
<details>
  <summary>88. <b>标题：Contrastive Domain Adaptation for Early Misinformation Detection: A Case  Study on COVID-19</b></summary>
  <p><b>编号</b>：[373]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09578</p>
  <p><b>作者</b>：Zhenrui Yue,  Huimin Zeng,  Ziyi Kou,  Lanyu Shang,  Dong Wang</p>
  <p><b>备注</b>：Accepted to CIKM 2022</p>
  <p><b>关键词</b>：early misinformation detection, early misinformation, misinformation detection, elusive challenge, misinformation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Despite recent progress in improving the performance of misinformation
detection systems, classifying misinformation in an unseen domain remains an
elusive challenge. To address this issue, a common approach is to introduce a
domain critic and encourage domain-invariant input features. However, early
misinformation often demonstrates both conditional and label shifts against
existing misinformation data (e.g., class imbalance in COVID-19 datasets),
rendering such methods less effective for detecting early misinformation. In
this paper, we propose contrastive adaptation network for early misinformation
detection (CANMD). Specifically, we leverage pseudo labeling to generate
high-confidence target examples for joint training with source data. We
additionally design a label correction component to estimate and correct the
label shifts (i.e., class priors) between the source and target domains.
Moreover, a contrastive adaptation loss is integrated in the objective function
to reduce the intra-class discrepancy and enlarge the inter-class discrepancy.
As such, the adapted model learns corrected class priors and an invariant
conditional distribution across both domains for improved estimation of the
target data distribution. To demonstrate the effectiveness of the proposed
CANMD, we study the case of COVID-19 early misinformation detection and perform
extensive experiments using multiple real-world datasets. The results suggest
that CANMD can effectively adapt misinformation detection systems to the unseen
COVID-19 target domain with significant improvements compared to the
state-of-the-art baselines.</p>
  </details>
</details>
<details>
  <summary>89. <b>标题：Multiple Instance Neuroimage Transformer</b></summary>
  <p><b>编号</b>：[379]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09567</p>
  <p><b>作者</b>：Ayush Singla,  Qingyu Zhao,  Daniel K. Do,  Yuyin Zhou,  Kilian M. Pohl,  Ehsan Adeli</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：called Multiple Instance, multiple instance learning, Multiple Instance Neuroimage, learning based convolution-free, based convolution-free transformer</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>For the first time, we propose using a multiple instance learning based
convolution-free transformer model, called Multiple Instance Neuroimage
Transformer (MINiT), for the classification of T1weighted (T1w) MRIs. We first
present several variants of transformer models adopted for neuroimages. These
models extract non-overlapping 3D blocks from the input volume and perform
multi-headed self-attention on a sequence of their linear projections. MINiT,
on the other hand, treats each of the non-overlapping 3D blocks of the input
MRI as its own instance, splitting it further into non-overlapping 3D patches,
on which multi-headed self-attention is computed. As a proof-of-concept, we
evaluate the efficacy of our model by training it to identify sex from T1w-MRIs
of two public datasets: Adolescent Brain Cognitive Development (ABCD) and the
National Consortium on Alcohol and Neurodevelopment in Adolescence (NCANDA).
The learned attention maps highlight voxels contributing to identifying sex
differences in brain morphometry. The code is available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>90. <b>标题：A Dual Modality Approach For (Zero-Shot) Multi-Label Classification</b></summary>
  <p><b>编号</b>：[380]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09562</p>
  <p><b>作者</b>：Shichao Xu,  Yikang Li,  Jenhao Hsiao,  Chiuman Ho,  Zhu Qi</p>
  <p><b>备注</b>：preprint</p>
  <p><b>关键词</b>：multi-label classification, Aligned Dual moDality, including zero-shot multi-label, zero-shot multi-label classification, real-world applications</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In computer vision, multi-label classification, including zero-shot
multi-label classification are important tasks with many real-world
applications. In this paper, we propose a novel algorithm, Aligned Dual
moDality ClaSsifier (ADDS), which includes a Dual-Modal decoder (DM-decoder)
with alignment between visual and textual features, for multi-label
classification tasks. Moreover, we design a simple and yet effective method
called Pyramid-Forwarding to enhance the performance for inputs with high
resolutions. Extensive experiments conducted on standard multi-label benchmark
datasets, MS-COCO and NUS-WIDE, demonstrate that our approach significantly
outperforms previous methods and provides state-of-the-art performance for
conventional multi-label classification, zero-shot multi-label classification,
and an extreme case called single-to-multi label classification where models
trained on single-label datasets (ImageNet-1k, ImageNet-21k) are tested on
multi-label ones (MS-COCO and NUS-WIDE). We also analyze how visual-textual
alignment contributes to the proposed approach, validate the significance of
the DM-decoder, and demonstrate the effectiveness of Pyramid-Forwarding on
vision transformer.</p>
  </details>
</details>
<details>
  <summary>91. <b>标题：Accelerating Vision Transformer Training via a Patch Sampling Schedule</b></summary>
  <p><b>编号</b>：[393]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09520</p>
  <p><b>作者</b>：Bradley McDanel,  Chi Phuong Huynh</p>
  <p><b>备注</b>：7 pages, 3 page appendix, 13 figures</p>
  <p><b>关键词</b>：Patch Sampling Schedule, Vision Transformer, Sampling Schedule, Patch Sampling, introduce the notion</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We introduce the notion of a Patch Sampling Schedule (PSS), that varies the
number of Vision Transformer (ViT) patches used per batch during training.
Since all patches are not equally important for most vision objectives (e.g.,
classification), we argue that less important patches can be used in fewer
training iterations, leading to shorter training time with minimal impact on
performance. Additionally, we observe that training with a PSS makes a ViT more
robust to a wider patch sampling range during inference. This allows for a
fine-grained, dynamic trade-off between throughput and accuracy during
inference. We evaluate using PSSs on ViTs for ImageNet both trained from
scratch and pre-trained using a reconstruction loss function. For the
pre-trained model, we achieve a 0.26% reduction in classification accuracy for
a 31% reduction in training time (from 25 to 17 hours) compared to using all
patches each iteration. Code, model checkpoints and logs are available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>92. <b>标题：Explainable Biometrics in the Age of Deep Learning</b></summary>
  <p><b>编号</b>：[400]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09500</p>
  <p><b>作者</b>：Pedro C. Neto,  Tiago Gonçalves,  João Ribeiro Pinto,  Wilson Silva,  Ana F. Sequeira,  Arun Ross,  Jaime S. Cardoso</p>
  <p><b>备注</b>：Submitted for review</p>
  <p><b>关键词</b>：quantifying human physical, behavioral traits, application variability, capable of analyzing, analyzing and quantifying</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Systems capable of analyzing and quantifying human physical or behavioral
traits, known as biometrics systems, are growing in use and application
variability. Since its evolution from handcrafted features and traditional
machine learning to deep learning and automatic feature extraction, the
performance of biometric systems increased to outstanding values. Nonetheless,
the cost of this fast progression is still not understood. Due to its opacity,
deep neural networks are difficult to understand and analyze, hence, hidden
capacities or decisions motivated by the wrong motives are a potential risk.
Researchers have started to pivot their focus towards the understanding of deep
neural networks and the explanation of their predictions. In this paper, we
provide a review of the current state of explainable biometrics based on the
study of 47 papers and discuss comprehensively the direction in which this
field should be developed.</p>
  </details>
</details>
<details>
  <summary>93. <b>标题：Optimising Chest X-Rays for Image Analysis by Identifying and Removing  Confounding Factors</b></summary>
  <p><b>编号</b>：[412]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10320</p>
  <p><b>作者</b>：Shahab Aslani,  Watjana Lilaonitkul,  Vaishnavi Gnanananthan,  Divya Raj,  Bojidar Rangelov,  Alexandra L Young,  Yipeng Hu,  Paul Taylor,  Daniel C Alexander,  Joseph Jacob</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：clinical CXR acquisitions, CXR, CXR acquisitions, sheer volume, emergency setting</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>During the COVID-19 pandemic, the sheer volume of imaging performed in an
emergency setting for COVID-19 diagnosis has resulted in a wide variability of
clinical CXR acquisitions. This variation is seen in the CXR projections used,
image annotations added and in the inspiratory effort and degree of rotation of
clinical images. The image analysis community has attempted to ease the burden
on overstretched radiology departments during the pandemic by developing
automated COVID-19 diagnostic algorithms, the input for which has been CXR
imaging. Large publicly available CXR datasets have been leveraged to improve
deep learning algorithms for COVID-19 diagnosis. Yet the variable quality of
clinically-acquired CXRs within publicly available datasets could have a
profound effect on algorithm performance. COVID-19 diagnosis may be inferred by
an algorithm from non-anatomical features on an image such as image labels.
These imaging shortcuts may be dataset-specific and limit the generalisability
of AI systems. Understanding and correcting key potential biases in CXR images
is therefore an essential first step prior to CXR image analysis. In this
study, we propose a simple and effective step-wise approach to pre-processing a
COVID-19 chest X-ray dataset to remove undesired biases. We perform ablation
studies to show the impact of each individual step. The results suggest that
using our proposed pipeline could increase accuracy of the baseline COVID-19
detection algorithm by up to 13%.</p>
  </details>
</details>
<details>
  <summary>94. <b>标题：Noise-Adaptive Intelligent Programmable Meta-Imager</b></summary>
  <p><b>编号</b>：[417]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10171</p>
  <p><b>作者</b>：Chenqi Qian,  Philipp del Hougne</p>
  <p><b>备注</b>：22 pages, 5 figures</p>
  <p><b>关键词</b>：specific information-extraction task, learned illumination patterns, coherent scene illuminations, object recognition, information-extraction task</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present an intelligent programmable computational meta-imager that tailors
its sequence of coherent scene illuminations not only to a specific
information-extraction task (e.g., object recognition) but also adapts to
different types and levels of noise. We systematically study how the learned
illumination patterns depend on the noise, and we discover that trends in
intensity and overlap of the learned illumination patterns can be understood
intuitively. We conduct our analysis based on an analytical coupled-dipole
forward model of a microwave dynamic metasurface antenna (DMA); we formulate a
differentiable end-to-end information-flow pipeline comprising the programmable
physical measurement process including noise as well as the subsequent digital
processing layers. This pipeline allows us to jointly inverse-design the
programmable physical weights (DMA configurations that determine the coherent
scene illuminations) and the trainable digital weights. Our noise-adaptive
intelligent meta-imager outperforms the conventional use of pseudo-random
illumination patterns most clearly under conditions that make the extraction of
sufficient task-relevant information challenging: latency constraints (limiting
the number of allowed measurements) and strong noise. Programmable microwave
meta-imagers in indoor surveillance and earth observation will be confronted
with these conditions.</p>
  </details>
</details>
<details>
  <summary>95. <b>标题：Forensic Dental Age Estimation Using Modified Deep Learning Neural  Network</b></summary>
  <p><b>编号</b>：[436]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09799</p>
  <p><b>作者</b>：Isa Atas,  Cuneyt Ozdemir,  Musa Atas,  Yahya Dogan</p>
  <p><b>备注</b>：18 pages, 10 figures, 3 tables</p>
  <p><b>关键词</b>：reliable methods, age, Dental age, individual age, DPR images</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Dental age is one of the most reliable methods to identify an individual's
age. By using dental panoramic radiography (DPR) images, physicians and
pathologists in forensic sciences try to establish the chronological age of
individuals with no valid legal records or registered patients. The current
methods in practice demand intensive labor, time, and qualified experts. The
development of deep learning algorithms in the field of medical image
processing has improved the sensitivity of predicting truth values while
reducing the processing speed of imaging time. This study proposed an automated
approach to estimate the forensic ages of individuals ranging in age from 8 to
68 using 1,332 DPR images. Initially, experimental analyses were performed with
the transfer learning-based models, including InceptionV3, DenseNet201,
EfficientNetB4, MobileNetV2, VGG16, and ResNet50V2; and accordingly, the
best-performing model, InceptionV3, was modified, and a new neural network
model was developed. Reducing the number of the parameters already available in
the developed model architecture resulted in a faster and more accurate dental
age estimation. The performance metrics of the results attained were as
follows: mean absolute error (MAE) was 3.13, root mean square error (RMSE) was
4.77, and correlation coefficient R$^2$ was 87%. It is conceivable to propose
the new model as potentially dependable and practical ancillary equipment in
forensic sciences and dental medicine.</p>
  </details>
</details>
<details>
  <summary>96. <b>标题：PARSE challenge 2022: Pulmonary Arteries Segmentation using Swin U-Net  Transformer(Swin UNETR) and U-Net</b></summary>
  <p><b>编号</b>：[447]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09636</p>
  <p><b>作者</b>：Akansh Maurya,  Kunal Dashrath Patil,  Rohan Padhy,  Kalluri Ramakrishna,  Ganapathy Krishnamurthi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：deep neural network, neural network architecture, Swin UNETR, deep neural, network architecture</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this work, we present our proposed method to segment the pulmonary
arteries from the CT scans using Swin UNETR and U-Net-based deep neural network
architecture. Six models, three models based on Swin UNETR, and three models
based on 3D U-net with residual units were ensemble using a weighted average to
make the final segmentation masks. Our team achieved a multi-level dice score
of 84.36 percent through this method. The code of our work is available on the
following link: this https URL. This work is part of the
MICCAI PARSE 2022 challenge.</p>
  </details>
</details>
<details>
  <summary>97. <b>标题：Exploring the Limits of Synthetic Creation of Solar EUV Images via  Image-to-Image Translation</b></summary>
  <p><b>编号</b>：[454]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09512</p>
  <p><b>作者</b>：Valentina Salvatelli,  Luiz F. G. dos Santos,  Souvik Bose,  Brad Neuberg,  Mark C. M. Cheung,  Miho Janvier,  Meng Jin,  Yarin Gal,  Atilim Gunes Baydin</p>
  <p><b>备注</b>：16 pages, 8 figures. To be published on ApJ (submitted on Feb 21st, accepted on July 28th)</p>
  <p><b>关键词</b>：Solar Dynamics Observatory, NASA multi-spectral decade-long, daily producing terabytes, Dynamics Observatory, multi-spectral decade-long mission</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The Solar Dynamics Observatory (SDO), a NASA multi-spectral decade-long
mission that has been daily producing terabytes of observational data from the
Sun, has been recently used as a use-case to demonstrate the potential of
machine learning methodologies and to pave the way for future deep-space
mission planning. In particular, the idea of using image-to-image translation
to virtually produce extreme ultra-violet channels has been proposed in several
recent studies, as a way to both enhance missions with less available channels
and to alleviate the challenges due to the low downlink rate in deep space.
This paper investigates the potential and the limitations of such a deep
learning approach by focusing on the permutation of four channels and an
encoder--decoder based architecture, with particular attention to how
morphological traits and brightness of the solar surface affect the neural
network predictions. In this work we want to answer the question: can synthetic
images of the solar corona produced via image-to-image translation be used for
scientific studies of the Sun? The analysis highlights that the neural network
produces high-quality images over three orders of magnitude in count rate
(pixel intensity) and can generally reproduce the covariance across channels
within a 1% error. However the model performance drastically diminishes in
correspondence of extremely high energetic events like flares, and we argue
that the reason is related to the rareness of such events posing a challenge to
model training.</p>
  </details>
</details>
<details>
  <summary>98. <b>标题：Blind Image Deblurring with Unknown Kernel Size and Substantial Noise</b></summary>
  <p><b>编号</b>：[456]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09483</p>
  <p><b>作者</b>：Zhong Zhuang,  Taihui Li,  Hengkang Wang,  Ju Sun</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Blind image deblurring, Blind image, image deblurring, adjacent fields, extensively studied</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Blind image deblurring (BID) has been extensively studied in computer vision
and adjacent fields. Modern methods for BID can be grouped into two categories:
single-instance methods that deal with individual instances using statistical
inference and numerical optimization, and data-driven methods that train
deep-learning models to deblur future instances directly. Data-driven methods
can be free from the difficulty in deriving accurate blur models, but are
fundamentally limited by the diversity and quality of the training data --
collecting sufficiently expressive and realistic training data is a standing
challenge. In this paper, we focus on single-instance methods that remain
competitive and indispensable. However, most such methods do not prescribe how
to deal with unknown kernel size and substantial noise, precluding practical
deployment. Indeed, we show that several state-of-the-art (SOTA)
single-instance methods are unstable when the kernel size is overspecified,
and/or the noise level is high. On the positive side, we propose a practical
BID method that is stable against both, the first of its kind. Our method
builds on the recent ideas of solving inverse problems by integrating the
physical models and structured deep neural networks, without extra training
data. We introduce several crucial modifications to achieve the desired
stability. Extensive empirical tests on standard synthetic datasets, as well as
real-world NTIRE2020 and RealBlur datasets, show the superior effectiveness and
practicality of our BID method compared to SOTA single-instance as well as
data-driven methods. The code of our method is available at:
\url{this https URL}.</p>
  </details>
</details>
<h1>自然语言处理</h1>
<details>
  <summary>1. <b>标题：Dialogue Term Extraction using Transfer Learning and Topological Data  Analysis</b></summary>
  <p><b>编号</b>：[16]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10448</p>
  <p><b>作者</b>：Renato Vukovic,  Michael Heck,  Benjamin Matthias Ruppik,  Carel van Niekerk,  Marcus Zibrowius,  Milica Gašić</p>
  <p><b>备注</b>：Accepted as a long paper to SIGDIAL 2022 (Edinburgh)</p>
  <p><b>关键词</b>：Goal oriented dialogue, Goal oriented, oriented dialogue systems, originally designed, entities that users</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Goal oriented dialogue systems were originally designed as a natural language
interface to a fixed data-set of entities that users might inquire about,
further described by domain, slots, and values. As we move towards adaptable
dialogue systems where knowledge about domains, slots, and values may change,
there is an increasing need to automatically extract these terms from raw
dialogues or related non-dialogue data on a large scale. In this paper, we take
an important step in this direction by exploring different features that can
enable systems to discover realizations of domains, slots, and values in
dialogues in a purely data-driven fashion. The features that we examine stem
from word embeddings, language modelling features, as well as topological
features of the word embedding space. To examine the utility of each feature
set, we train a seed model based on the widely used MultiWOZ data-set. Then, we
apply this model to a different corpus, the Schema-Guided Dialogue data-set.
Our method outperforms the previously proposed approach that relies solely on
word embeddings. We also demonstrate that each of the features is responsible
for discovering different kinds of content. We believe our results warrant
further research towards ontology induction, and continued harnessing of
topological data analysis for dialogue and natural language processing
research.</p>
  </details>
</details>
<details>
  <summary>2. <b>标题：Image as a Foreign Language: BEiT Pretraining for All Vision and  Vision-Language Tasks</b></summary>
  <p><b>编号</b>：[19]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10442</p>
  <p><b>作者</b>：Wenhui Wang,  Hangbo Bao,  Li Dong,  Johan Bjorck,  Zhiliang Peng,  Qiang Liu,  Kriti Aggarwal,  Owais Khan Mohammed,  Saksham Singhal,  Subhojit Som,  Furu Wei</p>
  <p><b>备注</b>：18 pages</p>
  <p><b>关键词</b>：COCO, big convergence, introduce Multiway Transformers, multimodal foundation model, general-purpose multimodal foundation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A big convergence of language, vision, and multimodal pretraining is
emerging. In this work, we introduce a general-purpose multimodal foundation
model BEiT-3, which achieves state-of-the-art transfer performance on both
vision and vision-language tasks. Specifically, we advance the big convergence
from three aspects: backbone architecture, pretraining task, and model scaling
up. We introduce Multiway Transformers for general-purpose modeling, where the
modular architecture enables both deep fusion and modality-specific encoding.
Based on the shared backbone, we perform masked "language" modeling on images
(Imglish), texts (English), and image-text pairs ("parallel sentences") in a
unified manner. Experimental results show that BEiT-3 obtains state-of-the-art
performance on object detection (COCO), semantic segmentation (ADE20K), image
classification (ImageNet), visual reasoning (NLVR2), visual question answering
(VQAv2), image captioning (COCO), and cross-modal retrieval (Flickr30K, COCO).</p>
  </details>
</details>
<details>
  <summary>3. <b>标题：DP-Rewrite: Towards Reproducibility and Transparency in Differentially  Private Text Rewriting</b></summary>
  <p><b>编号</b>：[33]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10400</p>
  <p><b>作者</b>：Timour Igamberdiev,  Thomas Arnold,  Ivan Habernal</p>
  <p><b>备注</b>：Accepted at COLING 2022</p>
  <p><b>关键词</b>：concrete theoretical guarantees, Text rewriting, textual documents, private text rewriting, text rewriting research</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Text rewriting with differential privacy (DP) provides concrete theoretical
guarantees for protecting the privacy of individuals in textual documents. In
practice, existing systems may lack the means to validate their
privacy-preserving claims, leading to problems of transparency and
reproducibility. We introduce DP-Rewrite, an open-source framework for
differentially private text rewriting which aims to solve these problems by
being modular, extensible, and highly customizable. Our system incorporates a
variety of downstream datasets, models, pre-training procedures, and evaluation
metrics to provide a flexible way to lead and validate private text rewriting
research. To demonstrate our software in practice, we provide a set of
experiments as a case study on the ADePT DP text rewriting system, detecting a
privacy leak in its pre-training approach. Our system is publicly available,
and we hope that it will help the community to make DP text rewriting research
more accessible and transparent.</p>
  </details>
</details>
<details>
  <summary>4. <b>标题：The optimality of word lengths. Theoretical foundations and an empirical  study</b></summary>
  <p><b>编号</b>：[39]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10384</p>
  <p><b>作者</b>：Sonia Petrini,  Antoni Casas-i-Muñoz,  Jordi Cluet-i-Martinell,  Mengxue Wang,  Christian Bentz,  Ramon Ferrer-i-Cancho</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：robust patterns found, word lengths, robust patterns, patterns found, languages</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>One of the most robust patterns found in human languages is Zipf's law of
abbreviation, that is, the tendency of more frequent words to be shorter. Since
Zipf's pioneering research, this law has been viewed as a manifestation of
compression, i.e. the minimization of the length of forms - a universal
principle of natural communication. Although the claim that languages are
optimized has become trendy, attempts to measure the degree of optimization of
languages have been rather scarce. Here we demonstrate that compression
manifests itself in a wide sample of languages without exceptions, and
independently of the unit of measurement. It is detectable for both word
lengths in characters of written language as well as durations in time in
spoken language. Moreover, to measure the degree of optimization, we derive a
simple formula for a random baseline and present two scores that are dualy
normalized, namely, they are normalized with respect to both the minimum and
the random baseline. We analyze the theoretical and statistical advantages and
disadvantages of these and other scores. Harnessing the best score, we quantify
for the first time the degree of optimality of word lengths in languages. This
indicates that languages are optimized to 62 or 67 percent on average
(depending on the source) when word lengths are measured in characters, and to
65 percent on average when word lengths are measured in time. In general,
spoken word durations are more optimized than written word lengths in
characters. Beyond the analyses reported here, our work paves the way to
measure the degree of optimality of the vocalizations or gestures of other
species, and to compare them against written, spoken, or signed human
languages.</p>
  </details>
</details>
<details>
  <summary>5. <b>标题：Inductive Knowledge Graph Reasoning for Multi-batch Emerging Entities</b></summary>
  <p><b>编号</b>：[42]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10378</p>
  <p><b>作者</b>：Yuanning Cui,  Yuxin Wang,  Zequn Sun,  Wenqiang Liu,  Yiqiao Jiang,  Kexin Han,  Wei Hu</p>
  <p><b>备注</b>：Accepted in the 31st ACM International Conference on Information and Knowledge Management (CIKM 2022)</p>
  <p><b>关键词</b>：aims to infer, infer new conclusions, focused on static, static KGs, KGs</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Over the years, reasoning over knowledge graphs (KGs), which aims to infer
new conclusions from known facts, has mostly focused on static KGs. The
unceasing growth of knowledge in real life raises the necessity to enable the
inductive reasoning ability on expanding KGs. Existing inductive work assumes
that new entities all emerge once in a batch, which oversimplifies the real
scenario that new entities continually appear. This study dives into a more
realistic and challenging setting where new entities emerge in multiple
batches. We propose a walk-based inductive reasoning model to tackle the new
setting. Specifically, a graph convolutional network with adaptive relation
aggregation is designed to encode and update entities using their neighboring
relations. To capture the varying neighbor importance, we employ a query-aware
feedback attention mechanism during the aggregation. Furthermore, to alleviate
the sparse link problem of new entities, we propose a link augmentation
strategy to add trustworthy facts into KGs. We construct three new datasets for
simulating this multi-batch emergence scenario. The experimental results show
that our proposed model outperforms state-of-the-art embedding-based,
walk-based and rule-based models on inductive KG reasoning.</p>
  </details>
</details>
<details>
  <summary>6. <b>标题：Repurposing Knowledge Graph Embeddings for Triple Representation via  Weak Supervision</b></summary>
  <p><b>编号</b>：[57]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10328</p>
  <p><b>作者</b>：Alexander Kalinowski,  Yuan An</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：techniques treat entities, separate embedding matrices, embedding techniques treat, techniques treat, treat entities</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The majority of knowledge graph embedding techniques treat entities and
predicates as separate embedding matrices, using aggregation functions to build
a representation of the input triple. However, these aggregations are lossy,
i.e. they do not capture the semantics of the original triples, such as
information contained in the predicates. To combat these shortcomings, current
methods learn triple embeddings from scratch without utilizing entity and
predicate embeddings from pre-trained models. In this paper, we design a novel
fine-tuning approach for learning triple embeddings by creating weak
supervision signals from pre-trained knowledge graph embeddings. We develop a
method for automatically sampling triples from a knowledge graph and estimating
their pairwise similarities from pre-trained embedding models. These pairwise
similarity scores are then fed to a Siamese-like neural architecture to
fine-tune triple representations. We evaluate the proposed method on two widely
studied knowledge graphs and show consistent improvement over other
state-of-the-art triple embedding methods on triple classification and triple
clustering tasks.</p>
  </details>
</details>
<details>
  <summary>7. <b>标题：A Novel Multi-Task Learning Approach for Context-Sensitive Compound Type  Identification in Sanskrit</b></summary>
  <p><b>编号</b>：[63]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10310</p>
  <p><b>作者</b>：Jivnesh Sandhan,  Ashish Gupta,  Hrishikesh Terdalkar,  Tushar Sandhan,  Suvendu Samanta,  Laxmidhar Behera,  Pawan Goyal</p>
  <p><b>备注</b>：The work is accepted at COLING22, Gyeongju, Republic of Korea</p>
  <p><b>关键词</b>：phenomenon of compounding, compounding is ubiquitous, Sanskrit Compound Type, Compound Type Identification, Sanskrit Compound</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The phenomenon of compounding is ubiquitous in Sanskrit. It serves for
achieving brevity in expressing thoughts, while simultaneously enriching the
lexical and structural formation of the language. In this work, we focus on the
Sanskrit Compound Type Identification (SaCTI) task, where we consider the
problem of identifying semantic relations between the components of a compound
word. Earlier approaches solely rely on the lexical information obtained from
the components and ignore the most crucial contextual and syntactic information
useful for SaCTI. However, the SaCTI task is challenging primarily due to the
implicitly encoded context-sensitive semantic relation between the compound
components.
Thus, we propose a novel multi-task learning architecture which incorporates
the contextual information and enriches the complementary syntactic information
using morphological tagging and dependency parsing as two auxiliary tasks.
Experiments on the benchmark datasets for SaCTI show 6.1 points (Accuracy) and
7.7 points (F1-score) absolute gain compared to the state-of-the-art system.
Further, our multi-lingual experiments demonstrate the efficacy of the proposed
architecture in English and Marathi languages.The code and datasets are
publicly available at this https URL</p>
  </details>
</details>
<details>
  <summary>8. <b>标题：Locate Then Ask: Interpretable Stepwise Reasoning for Multi-hop Question  Answering</b></summary>
  <p><b>编号</b>：[70]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10297</p>
  <p><b>作者</b>：Siyuan Wang,  Zhongyu Wei,  Zhihao Fan,  Qi Zhang,  Xuanjing Huang</p>
  <p><b>备注</b>：11 pages, 6 figures, 6 tables, accepted as a long paper to COLING 2022</p>
  <p><b>关键词</b>：requires aggregating multiple, aggregating multiple documents, reasoning requires aggregating, Multi-hop reasoning requires, requires aggregating</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Multi-hop reasoning requires aggregating multiple documents to answer a
complex question. Existing methods usually decompose the multi-hop question
into simpler single-hop questions to solve the problem for illustrating the
explainable reasoning process. However, they ignore grounding on the supporting
facts of each reasoning step, which tends to generate inaccurate
decompositions. In this paper, we propose an interpretable stepwise reasoning
framework to incorporate both single-hop supporting sentence identification and
single-hop question generation at each intermediate step, and utilize the
inference of the current hop for the next until reasoning out the final result.
We employ a unified reader model for both intermediate hop reasoning and final
hop inference and adopt joint optimization for more accurate and robust
multi-hop reasoning. We conduct experiments on two benchmark datasets HotpotQA
and 2WikiMultiHopQA. The results show that our method can effectively boost
performance and also yields a better interpretable reasoning process without
decomposition supervision.</p>
  </details>
</details>
<details>
  <summary>9. <b>标题：Language-independence of DisCoCirc's Text Circuits: English and Urdu</b></summary>
  <p><b>编号</b>：[77]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10281</p>
  <p><b>作者</b>：Muhammad Hamza Waseem,  Jonathon Liu,  Vincent Wang-Maścianica,  Bob Coecke</p>
  <p><b>备注</b>：In Proceedings E2ECOMPVEC, arXiv:2208.05313</p>
  <p><b>关键词</b>：Categorical Distributional Compositional, newly proposed framework, Distributional Compositional, newly proposed, semantics of texts</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>DisCoCirc is a newly proposed framework for representing the grammar and
semantics of texts using compositional, generative circuits. While it
constitutes a development of the Categorical Distributional Compositional
(DisCoCat) framework, it exposes radically new features. In particular, [14]
suggested that DisCoCirc goes some way toward eliminating grammatical
differences between languages. In this paper we provide a sketch that this is
indeed the case for restricted fragments of English and Urdu. We first develop
DisCoCirc for a fragment of Urdu, as it was done for English in [14]. There is
a simple translation from English grammar to Urdu grammar, and vice versa. We
then show that differences in grammatical structure between English and Urdu -
primarily relating to the ordering of words and phrases - vanish when passing
to DisCoCirc circuits.</p>
  </details>
</details>
<details>
  <summary>10. <b>标题：A Twitter-Driven Deep Learning Mechanism for the Determination of  Vehicle Hijacking Spots in Cities</b></summary>
  <p><b>编号</b>：[78]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10280</p>
  <p><b>作者</b>：Taahir Aiyoob Patel,  Clement N. Nyirenda</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：leading crimes, South Africa, Vehicle hijacking, Feed-forward Neural Network, Bidirectional Encoder Representations</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Vehicle hijacking is one of the leading crimes in many cities. For instance,
in South Africa, drivers must constantly remain vigilant on the road in order
to ensure that they do not become hijacking victims. This work is aimed at
developing a map depicting hijacking spots in a city by using Twitter data.
Tweets, which include the keyword "hijacking", are obtained in a designated
city of Cape Town, in this work. In order to extract relevant tweets, these
tweets are analyzed by using the following machine learning techniques: 1) a
Multi-layer Feed-forward Neural Network (MLFNN); 2) Convolutional Neural
Network; and Bidirectional Encoder Representations from Transformers (BERT).
Through training and testing, CNN achieved an accuracy of 99.66%, while MLFNN
and BERT achieve accuracies of 98.99% and 73.99% respectively. In terms of
Recall, Precision and F1-score, CNN also achieved the best results. Therefore,
CNN was used for the identification of relevant tweets. The relevant reports
that it generates are visually presented on a points map of the City of Cape
Town. This work used a small dataset of 426 tweets. In future, the use of
evolutionary computation will be explored for purposes of optimizing the deep
learning models. A mobile application is under development to make this
information usable by the general public.</p>
  </details>
</details>
<details>
  <summary>11. <b>标题：Using Large Language Models to Simulate Multiple Humans</b></summary>
  <p><b>编号</b>：[88]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10264</p>
  <p><b>作者</b>：Gati Aher,  Rosa I. Arriaga,  Adam Tauman Kalai</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：language, language model, large language model, large language, model</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose a method for using a large language model, such as GPT-3, to
simulate responses of different humans in a given context. We test our method
by attempting to reproduce well-established economic, psycholinguistic, and
social experiments. The method requires prompt templates for each experiment.
Simulations are run by varying the (hypothetical) subject details such as name
and analyzing the text generated by the language model. We validate our
methodology by using GPT-3, to show that it is possible to simulate responses
of different people and that their responses are consistent with prior human
studies from the literature. We find that the distributions generated by larger
language models better align with prior experimental results, suggesting a
trend that future language models may be used for even more faithful
simulations of human responses. Our use of a language model for simulation is
contrasted with anthropomorphic views of a language model as having its own
behavior.</p>
  </details>
</details>
<details>
  <summary>12. <b>标题：An Exploratory Study of Tweets about the SARS-CoV-2 Omicron Variant:  Insights from Sentiment Analysis, Language Interpretation, Source Tracking,  Type Classification, and Embedded URL Detection</b></summary>
  <p><b>编号</b>：[93]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10252</p>
  <p><b>作者</b>：Nirmalya Thakur,  Chia Y. Han</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：generating Big Data, continuously generating Big, Big Data, globally dominant variant, Omicron variant</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper presents the findings of an exploratory study on the continuously
generating Big Data on Twitter related to the sharing of information, news,
views, opinions, ideas, feedback, and experiences about the COVID-19 pandemic,
with a specific focus on the Omicron variant, which is the globally dominant
variant of SARS-CoV-2 at this time. A total of 12028 tweets about the Omicron
variant were studied, and the specific characteristics of tweets that were
analyzed include - sentiment, language, source, type, and embedded URLs. The
findings of this study are manifold. First, from sentiment analysis, it was
observed that 50.5% of tweets had a neutral emotion. The other emotions - bad,
good, terrible, and great were found in 15.6%, 14.0%, 12.5%, and 7.5% of the
tweets, respectively. Second, the findings of language interpretation showed
that 65.9% of the tweets were posted in English. It was followed by Spanish,
French, Italian, and other languages. Third, the findings from source tracking
showed that Twitter for Android was associated with 35.2% of tweets. It was
followed by Twitter Web App, Twitter for iPhone, Twitter for iPad, and other
sources. Fourth, studying the type of tweets revealed that retweets accounted
for 60.8% of the tweets, it was followed by original tweets and replies that
accounted for 19.8% and 19.4% of the tweets, respectively. Fifth, in terms of
embedded URL analysis, the most common domain embedded in the tweets was found
to be this http URL, which was followed by this http URL, this http URL, and other
domains. Finally, to support similar research in this field, we have developed
a Twitter dataset that comprises more than 500,000 tweets about the SARS-CoV-2
omicron variant since the first detected case of this variant on November 24,
2021.</p>
  </details>
</details>
<details>
  <summary>13. <b>标题：Rethinking Textual Adversarial Defense for Pre-trained Language Models</b></summary>
  <p><b>编号</b>：[94]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10251</p>
  <p><b>作者</b>：Jiayi Wang,  Rongzhou Bao,  Zhuosheng Zhang,  Hai Zhao</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：recent studies demonstrate, pre-trained language models, adversarial, achieved significant success, language models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Although pre-trained language models (PrLMs) have achieved significant
success, recent studies demonstrate that PrLMs are vulnerable to adversarial
attacks. By generating adversarial examples with slight perturbations on
different levels (sentence / word / character), adversarial attacks can fool
PrLMs to generate incorrect predictions, which questions the robustness of
PrLMs. However, we find that most existing textual adversarial examples are
unnatural, which can be easily distinguished by both human and machine. Based
on a general anomaly detector, we propose a novel metric (Degree of Anomaly) as
a constraint to enable current adversarial attack approaches to generate more
natural and imperceptible adversarial examples. Under this new constraint, the
success rate of existing attacks drastically decreases, which reveals that the
robustness of PrLMs is not as fragile as they claimed. In addition, we find
that four types of randomization can invalidate a large portion of textual
adversarial examples. Based on anomaly detector and randomization, we design a
universal defense framework, which is among the first to perform textual
adversarial defense without knowing the specific attack. Empirical results show
that our universal defense framework achieves comparable or even higher
after-attack accuracy with other specific defenses, while preserving higher
original accuracy at the same time. Our work discloses the essence of textual
adversarial attacks, and indicates that (1) further works of adversarial
attacks should focus more on how to overcome the detection and resist the
randomization, otherwise their adversarial examples would be easily detected
and invalidated; and (2) compared with the unnatural and perceptible
adversarial examples, it is those undetectable adversarial examples that pose
real risks for PrLMs and require more attention for future robustness-enhancing
strategies.</p>
  </details>
</details>
<details>
  <summary>14. <b>标题：Multi-Task Learning for Depression Detection in Dialogs</b></summary>
  <p><b>编号</b>：[95]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10250</p>
  <p><b>作者</b>：Chuyuan Li (SEMAGRAMME, LORIA),  Chloé Braud (IRIT),  Maxime Amblard (SEMAGRAMME, LORIA)</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：people communicate, mental illness, illness that impacts, Depression, allegedly</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Depression is a serious mental illness that impacts the way people
communicate, especially through their emotions, and, allegedly, the way they
interact with others. This work examines depression signals in dialogs, a less
studied setting that suffers from data sparsity. We hypothesize that depression
and emotion can inform each other, and we propose to explore the influence of
dialog structure through topic and dialog act prediction. We investigate a
Multi-Task Learning (MTL) approach, where all tasks mentioned above are learned
jointly with dialog-tailored hierarchical modeling. We experiment on the DAIC
and DailyDialog corpora-both contain dialogs in English-and show important
improvements over state-ofthe-art on depression detection (at best 70.6% F 1),
which demonstrates the correlation of depression with emotion and dialog
organization and the power of MTL to leverage information from different
sources.</p>
  </details>
</details>
<details>
  <summary>15. <b>标题：Prediction of User Request and Complaint in Spoken Customer-Agent  Conversations</b></summary>
  <p><b>编号</b>：[96]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10249</p>
  <p><b>作者</b>：Nikola Lackovic,  Claude Montacié,  Gauthier Lalande,  Marie-José Caraty</p>
  <p><b>备注</b>：5 pages, 1 figure, 4 tables</p>
  <p><b>关键词</b>：feature sets, General Data Protection, Malakoff Humanis, features, sets</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present the corpus called HealthCall. This was recorded in real-life
conditions in the call center of Malakoff Humanis. It includes two separate
audio channels, the first one for the customer and the second one for the
agent. Each conversation was anonymized respecting the General Data Protection
Regulation. This corpus includes a transcription of the spoken conversations
and was divided into two sets: Train and Devel sets. Two important customer
relationship management tasks were assessed on the HealthCall corpus: Automatic
prediction of type of user requests and complaints detection. For this purpose,
we have investigated 14 feature sets: 6 linguistic feature sets, 6 audio
feature sets and 2 vocal interaction feature sets. We have used Bidirectional
Encoder Representation from Transformers models for the linguistic features,
openSMILE and Wav2Vec 2.0 for the audio features. The vocal interaction feature
sets were designed and developed from Turn Takings. The results show that the
linguistic features always give the best results (91.2% for the Request task
and 70.3% for the Complaint task). The Wav2Vec 2.0 features seem more suitable
for these two tasks than the ComPaRe16 features. Vocal interaction features
outperformed ComPaRe16 features on Complaint task with a 57% rate achieved with
only six features.</p>
  </details>
</details>
<details>
  <summary>16. <b>标题：Composing RNNs and FSTs for Small Data: Recovering Missing Characters in  Old Hawaiian Text</b></summary>
  <p><b>编号</b>：[97]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10248</p>
  <p><b>作者</b>：Oiwi Parker Jones,  Brendan Shillingford</p>
  <p><b>备注</b>：This paper originally appeared in a NeurIPS Workshop in 2018: IRASL - Interpretability and Robustness in Audio, Speech, and Language. It builds on a shorter paper that appeared in the Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing (EMNLP). See acknowledgements for details</p>
  <p><b>关键词</b>：modern Hawaiian orthography, Hawaiian orthography employs, orthography employs characters, older writing system, modern Hawaiian</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In contrast to the older writing system of the 19th century, modern Hawaiian
orthography employs characters for long vowels and glottal stops. These extra
characters account for about one-third of the phonemes in Hawaiian, so
including them makes a big difference to reading comprehension and
pronunciation. However, transliterating between older and newer texts is a
laborious task when performed manually. We introduce two related methods to
help solve this transliteration problem automatically, given that there were
not enough data to train an end-to-end deep learning model. One method is
implemented, end-to-end, using finite state transducers (FSTs). The other is a
hybrid deep learning approach which approximately composes an FST with a
recurrent neural network (RNN). We find that the hybrid approach outperforms
the end-to-end FST by partitioning the original problem into one part that can
be modelled by hand, using an FST, and into another part, which is easily
solved by an RNN trained on the available data.</p>
  </details>
</details>
<details>
  <summary>17. <b>标题：Generalized Attention Mechanism and Relative Position for Transformer</b></summary>
  <p><b>编号</b>：[98]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10247</p>
  <p><b>作者</b>：R. V. R. Pandya</p>
  <p><b>备注</b>：6 pages</p>
  <p><b>关键词</b>：generalized attention mechanism, propose generalized attention, GAM, Vaswani, generalized attention</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we propose generalized attention mechanism (GAM) by first
suggesting a new interpretation for self-attention mechanism of Vaswani et al.
. Following the interpretation, we provide description for different variants
of attention mechanism which together form GAM. Further, we propose a new
relative position representation within the framework of GAM. This
representation can be easily utilized for cases in which elements next to each
other in input sequence can be at random locations in actual dataset/corpus.</p>
  </details>
</details>
<details>
  <summary>18. <b>标题：SDBERT: SparseDistilBERT, a faster and smaller BERT model</b></summary>
  <p><b>编号</b>：[99]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10246</p>
  <p><b>作者</b>：Devaraju Vinoda,  Pawan Kumar Yadav</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：transformer architecture called, architecture called, work we introduce, transformer architecture, sparse attention</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this work we introduce a new transformer architecture called
SparseDistilBERT (SDBERT), which is a combination of sparse attention and
knowledge distillantion (KD). We implemented sparse attention mechanism to
reduce quadratic dependency on input length to linear. In addition to reducing
computational complexity of the model, we used knowledge distillation (KD). We
were able to reduce the size of BERT model by 60% while retaining 97%
performance and it only took 40% of time to train.</p>
  </details>
</details>
<details>
  <summary>19. <b>标题：When BERT Fails -- The Limits of EHR Classification</b></summary>
  <p><b>编号</b>：[100]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10245</p>
  <p><b>作者</b>：Augusto Garcia-Agundez,  Carsten Eickhoff</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：text representation learners, decision support tasks, powerful text representation, clinical decision support, Transformers are powerful</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Transformers are powerful text representation learners, useful for all kinds
of clinical decision support tasks. Although they outperform baselines on
readmission prediction, they are not infallible. Here, we look into one such
failure case, and report patterns that lead to inferior predictive performance.</p>
  </details>
</details>
<details>
  <summary>20. <b>标题：Unit Testing for Concepts in Neural Networks</b></summary>
  <p><b>编号</b>：[101]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10244</p>
  <p><b>作者</b>：Charles Lovering,  Ellie Pavlick</p>
  <p><b>备注</b>：TACL, In Press. 12 Pages</p>
  <p><b>关键词</b>：complex problems, problems are naturally, naturally understood, understood in terms, concepts</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Many complex problems are naturally understood in terms of symbolic concepts.
For example, our concept of "cat" is related to our concepts of "ears" and
"whiskers" in a non-arbitrary way. Fodor (1998) proposes one theory of
concepts, which emphasizes symbolic representations related via constituency
structures. Whether neural networks are consistent with such a theory is open
for debate. We propose unit tests for evaluating whether a system's behavior is
consistent with several key aspects of Fodor's criteria. Using a simple visual
concept learning task, we evaluate several modern neural architectures against
this specification. We find that models succeed on tests of groundedness,
modularlity, and reusability of concepts, but that important questions about
causality remain open. Resolving these will require new methods for analyzing
models' internal states.</p>
  </details>
</details>
<details>
  <summary>21. <b>标题：SciAnnotate: A Tool for Integrating Weak Labeling Sources for Sequence  Labeling</b></summary>
  <p><b>编号</b>：[102]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10241</p>
  <p><b>作者</b>：Mengyang Liu,  Haozheng Luo,  Leonard Thong,  Yinghao Li,  Chao Zhang,  Le Song</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Named Entity, strategy for Named, popular weak supervision, weak supervision strategy, annotation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Weak labeling is a popular weak supervision strategy for Named Entity
Recognition (NER) tasks, with the goal of reducing the necessity for
hand-crafted annotations. Although there are numerous remarkable annotation
tools for NER labeling, the subject of integrating weak labeling sources is
still unexplored. We introduce a web-based tool for text annotation called
SciAnnotate, which stands for scientific annotation tool. Compared to
frequently used text annotation tools, our annotation tool allows for the
development of weak labels in addition to providing a manual annotation
experience. Our tool provides users with multiple user-friendly interfaces for
creating weak labels. SciAnnotate additionally allows users to incorporate
their own language models and visualize the output of their model for
evaluation. In this study, we take multi-source weak label denoising as an
example, we utilized a Bertifying Conditional Hidden Markov Model to denoise
the weak label generated by our tool. We also evaluate our annotation tool
against the dataset provided by Mysore which contains 230 annotated materials
synthesis procedures. The results shows that a 53.7% reduction in annotation
time obtained AND a 1.6\% increase in recall using weak label denoising. Online
demo is available at this https URL account can be
found in README), but we don't host a model server with it, please check the
README in supplementary material for model server usage.</p>
  </details>
</details>
<details>
  <summary>22. <b>标题：A Multimodal Transformer: Fusing Clinical Notes with Structured EHR Data  for Interpretable In-Hospital Mortality Prediction</b></summary>
  <p><b>编号</b>：[103]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10240</p>
  <p><b>作者</b>：Weimin Lyu,  Xinyu Dong,  Rachel Wong,  Songzhu Zheng,  Kayley Abell-Hart,  Fusheng Wang,  Chao Chen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：electronic health records, active research area, clinical decision support, structured electronic health, health records</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep-learning-based clinical decision support using structured electronic
health records (EHR) has been an active research area for predicting risks of
mortality and diseases. Meanwhile, large amounts of narrative clinical notes
provide complementary information, but are often not integrated into predictive
models. In this paper, we provide a novel multimodal transformer to fuse
clinical notes and structured EHR data for better prediction of in-hospital
mortality. To improve interpretability, we propose an integrated gradients (IG)
method to select important words in clinical notes and discover the critical
structured EHR features with Shapley values. These important words and clinical
features are visualized to assist with interpretation of the prediction
outcomes. We also investigate the significance of domain adaptive pretraining
and task adaptive fine-tuning on the Clinical BERT, which is used to learn the
representations of clinical notes. Experiments demonstrated that our model
outperforms other methods (AUCPR: 0.538, AUCROC: 0.877, F1:0.490).</p>
  </details>
</details>
<details>
  <summary>23. <b>标题：Survey of NLP in Pharmacology: Methodology, Tasks, Resources, Knowledge,  and Tools</b></summary>
  <p><b>编号</b>：[108]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10228</p>
  <p><b>作者</b>：Dimitar Trajanov,  Vangel Trajkovski,  Makedonka Dimitrieva,  Jovana Dobreva,  Milos Jovanovik,  Matej Klemen,  Aleš Žagar,  Marko Robnik-Šikonja</p>
  <p><b>备注</b>：35 pages, 2 figures, 7 tables</p>
  <p><b>关键词</b>：Natural language processing, applies information technologies, Natural language, human language, artificial intelligence</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Natural language processing (NLP) is an area of artificial intelligence that
applies information technologies to process the human language, understand it
to a certain degree, and use it in various applications. This area has rapidly
developed in the last few years and now employs modern variants of deep neural
networks to extract relevant patterns from large text corpora. The main
objective of this work is to survey the recent use of NLP in the field of
pharmacology. As our work shows, NLP is a highly relevant information
extraction and processing approach for pharmacology. It has been used
extensively, from intelligent searches through thousands of medical documents
to finding traces of adversarial drug interactions in social media. We split
our coverage into five categories to survey modern NLP methodology, commonly
addressed tasks, relevant textual data, knowledge bases, and useful programming
libraries. We split each of the five categories into appropriate subcategories,
describe their main properties and ideas, and summarize them in a tabular form.
The resulting survey presents a comprehensive overview of the area, useful to
practitioners and interested observers.</p>
  </details>
</details>
<details>
  <summary>24. <b>标题：PANDA: Prompt Transfer Meets Knowledge Distillation for Efficient Model  Adaptation</b></summary>
  <p><b>编号</b>：[133]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10160</p>
  <p><b>作者</b>：Qihuang Zhong,  Liang Ding,  Juhua Liu,  Bo Du,  Dacheng Tao</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：freezes pretrained language, additional soft prompt, pretrained language models, prompt, case of smaller</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Prompt-tuning, which freezes pretrained language models (PLMs) and only
fine-tunes few parameters of additional soft prompt, shows competitive
performance against full-parameter fine-tuning (i.e.model-tuning) when the PLM
has billions of parameters, but still performs poorly in the case of smaller
PLMs. Hence, prompt transfer (PoT), which initializes the target prompt with
the trained prompt of similar source tasks, is recently proposed to improve
over prompt-tuning. However, such a vanilla PoT approach usually achieves
sub-optimal performance, as (i) the PoT is sensitive to the similarity of
source-target pair and (ii) directly fine-tuning the prompt initialized with
source prompt on target task might lead to catastrophic forgetting of source
knowledge. In response to these problems, we propose a new metric to accurately
predict the prompt transferability (regarding (i)), and a novel PoT approach
(namely PANDA) that leverages the knowledge distillation technique to transfer
the "knowledge" from the source prompt to the target prompt in a subtle manner
and alleviate the catastrophic forgetting effectively (regarding (ii)).
Furthermore, to achieve adaptive prompt transfer for each source-target pair,
we use our metric to control the knowledge transfer in our PANDA approach.
Extensive and systematic experiments on 189 combinations of 21 source and 9
target datasets across 5 scales of PLMs demonstrate that: 1) our proposed
metric works well to predict the prompt transferability; 2) our PANDA
consistently outperforms the vanilla PoT approach by 2.3% average score (up to
24.1%) among all tasks and model sizes; 3) with our PANDA approach,
prompt-tuning can achieve competitive and even better performance than
model-tuning in various PLM scales scenarios. Code and models will be released
upon acceptance.</p>
  </details>
</details>
<details>
  <summary>25. <b>标题：Revising Image-Text Retrieval via Multi-Modal Entailment</b></summary>
  <p><b>编号</b>：[146]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10126</p>
  <p><b>作者</b>：Xu Yan,  Chunhui Ai,  Ziqiang Cao,  Min Cao,  Sujian Li,  Wenjie Chen,  Guohong Fu</p>
  <p><b>备注</b>：10 pages</p>
  <p><b>关键词</b>：high-quality labeled data, image-text retrieval, outstanding image-text retrieval, image-text retrieval datasets, retrieval model depends</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>An outstanding image-text retrieval model depends on high-quality labeled
data. While the builders of existing image-text retrieval datasets strive to
ensure that the caption matches the linked image, they cannot prevent a caption
from fitting other images. We observe that such a many-to-many matching
phenomenon is quite common in the widely-used retrieval datasets, where one
caption can describe up to 178 images. These large matching-lost data not only
confuse the model in training but also weaken the evaluation accuracy. Inspired
by visual and textual entailment tasks, we propose a multi-modal entailment
classifier to determine whether a sentence is entailed by an image plus its
linked captions. Subsequently, we revise the image-text retrieval datasets by
adding these entailed captions as additional weak labels of an image and
develop a universal variable learning rate strategy to teach a retrieval model
to distinguish the entailed captions from other negative samples. In
experiments, we manually annotate an entailment-corrected image-text retrieval
dataset for evaluation. The results demonstrate that the proposed entailment
classifier achieves about 78% accuracy and consistently improves the
performance of image-text retrieval baselines.</p>
  </details>
</details>
<details>
  <summary>26. <b>标题：Recent Advances in Text-to-SQL: A Survey of What We Have and What We  Expect</b></summary>
  <p><b>编号</b>：[152]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10099</p>
  <p><b>作者</b>：Naihao Deng,  Yulong Chen,  Yue Zhang</p>
  <p><b>备注</b>：COLING 2022 oral. Github page: this https URL</p>
  <p><b>关键词</b>：natural language processing, natural language interfaces, building natural language, natural language, SQL queries</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Text-to-SQL has attracted attention from both the natural language processing
and database communities because of its ability to convert the semantics in
natural language into SQL queries and its practical application in building
natural language interfaces to database systems. The major challenges in
text-to-SQL lie in encoding the meaning of natural utterances, decoding to SQL
queries, and translating the semantics between these two forms. These
challenges have been addressed to different extents by the recent advances.
However, there is still a lack of comprehensive surveys for this task. To this
end, we review recent progress on text-to-SQL for datasets, methods, and
evaluation and provide this systematic survey, addressing the aforementioned
challenges and discussing potential future directions. We hope that this survey
can serve as quick access to existing work and motivate future research.</p>
  </details>
</details>
<details>
  <summary>27. <b>标题：Type-enriched Hierarchical Contrastive Strategy for Fine-Grained Entity  Typing</b></summary>
  <p><b>编号</b>：[157]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10081</p>
  <p><b>作者</b>：Xinyu Zuo,  Haijin Liang,  Ning Jing,  Shuang Zeng,  Zhou Fang,  Yu Luo</p>
  <p><b>备注</b>：Accepted by COLING2022, Long paper, 13 pages, 6 figures</p>
  <p><b>关键词</b>：deduce specific semantic, Fine-grained entity typing, specific semantic types, aims to deduce, mentions in text</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Fine-grained entity typing (FET) aims to deduce specific semantic types of
the entity mentions in text. Modern methods for FET mainly focus on learning
what a certain type looks like. And few works directly model the type
differences, that is, let models know the extent that one type is different
from others. To alleviate this problem, we propose a type-enriched hierarchical
contrastive strategy for FET. Our method can directly model the differences
between hierarchical types and improve the ability to distinguish multi-grained
similar types. On the one hand, we embed type into entity contexts to make type
information directly perceptible. On the other hand, we design a constrained
contrastive strategy on the hierarchical structure to directly model the type
differences, which can simultaneously perceive the distinguishability between
types at different granularity. Experimental results on three benchmarks, BBN,
OntoNotes, and FIGER show that our method achieves significant performance on
FET by effectively modeling type differences.</p>
  </details>
</details>
<details>
  <summary>28. <b>标题：Selection Collider Bias in Large Language Models</b></summary>
  <p><b>编号</b>：[163]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10063</p>
  <p><b>作者</b>：Emily McMilin</p>
  <p><b>备注</b>：10 pages, 16 figures, UAI 2022 Causal Representation Learning Workshop</p>
  <p><b>关键词</b>：Large Language, selection collider bias, sample selection induced, induced collider bias, collider bias</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper we motivate the causal mechanisms behind sample selection
induced collider bias (selection collider bias) that can cause Large Language
Models (LLMs) to learn unconditional dependence between entities that are
unconditionally independent in the real world. We show that selection collider
bias can be amplified in underspecified learning tasks, and that the magnitude
of the resulting spurious correlations appear scale agnostic. While selection
collider bias can be difficult to overcome, we describe a method to exploit the
resulting spurious correlations for determination of when a model may be
uncertain about its prediction, and demonstrate that it matches human
uncertainty in tasks with gender pronoun underspecification on an extended
version of the Winogender Schemas evaluation set.</p>
  </details>
</details>
<details>
  <summary>29. <b>标题：GRETEL: Graph Contrastive Topic Enhanced Language Model for Long  Document Extractive Summarization</b></summary>
  <p><b>编号</b>：[190]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09982</p>
  <p><b>作者</b>：Qianqian Xie,  Jimin Huang,  Tulika Saha,  Sophia Ananiadou</p>
  <p><b>备注</b>：Accepted by COLING2022</p>
  <p><b>关键词</b>：global semantic information, graph contrastive topic, semantic information, global semantic, contrastive topic model</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recently, neural topic models (NTMs) have been incorporated into pre-trained
language models (PLMs), to capture the global semantic information for text
summarization. However, in these methods, there remain limitations in the way
they capture and integrate the global semantic information. In this paper, we
propose a novel model, the graph contrastive topic enhanced language model
(GRETEL), that incorporates the graph contrastive topic model with the
pre-trained language model, to fully leverage both the global and local
contextual semantics for long document extractive summarization. To better
capture and incorporate the global semantic information into PLMs, the graph
contrastive topic model integrates the hierarchical transformer encoder and the
graph contrastive learning to fuse the semantic information from the global
document context and the gold summary. To this end, GRETEL encourages the model
to efficiently extract salient sentences that are topically related to the gold
summary, rather than redundant sentences that cover sub-optimal topics.
Experimental results on both general domain and biomedical datasets demonstrate
that our proposed method outperforms SOTA methods.</p>
  </details>
</details>
<details>
  <summary>30. <b>标题：MockingBERT: A Method for Retroactively Adding Resilience to NLP Models</b></summary>
  <p><b>编号</b>：[216]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09915</p>
  <p><b>作者</b>：Jan Jezabek,  Akash Singh</p>
  <p><b>备注</b>：8 pages (excl. bibiography and appendix), 2 figures The code necessary for reproduction is available at this https URL To be published in Proceedings of the 29th International Conference on Computational Linguistics (COLING 2022)</p>
  <p><b>关键词</b>：Protecting NLP models, past few years, Protecting NLP, object of research, research interest</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Protecting NLP models against misspellings whether accidental or adversarial
has been the object of research interest for the past few years. Existing
remediations have typically either compromised accuracy or required full model
re-training with each new class of attacks. We propose a novel method of
retroactively adding resilience to misspellings to transformer-based NLP
models. This robustness can be achieved without the need for re-training of the
original NLP model and with only a minimal loss of language understanding
performance on inputs without misspellings. Additionally we propose a new
efficient approximate method of generating adversarial misspellings, which
significantly reduces the cost needed to evaluate a model's resilience to
adversarial attacks.</p>
  </details>
</details>
<details>
  <summary>31. <b>标题：A Syntax Aware BERT for Identifying Well-Formed Queries in a Curriculum  Framework</b></summary>
  <p><b>编号</b>：[218]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09912</p>
  <p><b>作者</b>：Avinash Madasu,  Anvesh Rao Vijjini</p>
  <p><b>备注</b>：ICPR 2022</p>
  <p><b>关键词</b>：spelling and grammar, correct interrogatives, formed query, query is defined, query</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A well formed query is defined as a query which is formulated in the manner
of an inquiry, and with correct interrogatives, spelling and grammar. While
identifying well formed queries is an important task, few works have attempted
to address it. In this paper we propose transformer based language model -
Bidirectional Encoder Representations from Transformers (BERT) to this task. We
further imbibe BERT with parts-of-speech information inspired from earlier
works. Furthermore, we also train the model in multiple curriculum settings for
improvement in performance. Curriculum Learning over the task is experimented
with Baby Steps and One Pass techniques. Proposed architecture performs
exceedingly well on the task. The best approach achieves accuracy of 83.93%,
outperforming previous state-of-the-art at 75.0% and reaching close to the
approximate human upper bound of 88.4%.</p>
  </details>
</details>
<details>
  <summary>32. <b>标题：Automatic tagging of knowledge points for K12 math problems</b></summary>
  <p><b>编号</b>：[235]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09867</p>
  <p><b>作者</b>：Xiaolu Wang,  Ziqi Ding,  Liangyu Chen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：managing question bases, Automatic tagging, knowledge points, math problems, automatic tagging technology</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Automatic tagging of knowledge points for practice problems is the basis for
managing question bases and improving the automation and intelligence of
education. Therefore, it is of great practical significance to study the
automatic tagging technology for practice problems. However, there are few
studies on the automatic tagging of knowledge points for math problems. Math
texts have more complex structures and semantics compared with general texts
because they contain unique elements such as symbols and formulas. Therefore,
it is difficult to meet the accuracy requirement of knowledge point prediction
by directly applying the text classification techniques in general domains. In
this paper, K12 math problems taken as the research object, the LABS model
based on label-semantic attention and multi-label smoothing combining textual
features is proposed to improve the automatic tagging of knowledge points for
math problems. The model combines the text classification techniques in general
domains and the unique features of math texts. The results show that the models
using label-semantic attention or multi-label smoothing perform better on
precision, recall, and F1-score metrics than the traditional BiLSTM model,
while the LABS model using both performs best. It can be seen that label
information can guide the neural networks to extract meaningful information
from the problem text, which improves the text classification performance of
the model. Moreover, multi-label smoothing combining textual features can fully
explore the relationship between text and labels, improve the model's
prediction ability for new data and improve the model's classification
accuracy.</p>
  </details>
</details>
<details>
  <summary>33. <b>标题：I Know What You Do Not Know: Knowledge Graph Embedding via  Co-distillation Learning</b></summary>
  <p><b>编号</b>：[256]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09828</p>
  <p><b>作者</b>：Yang Liu,  Zequn Sun Guangyao Li,  Wei Hu</p>
  <p><b>备注</b>：Accepted in the 31st ACM International Conference on Information and Knowledge Management (CIKM 2022)</p>
  <p><b>关键词</b>：graph structures, graph, Co-distillation Learning, embedding, learn vector representations</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Knowledge graph (KG) embedding seeks to learn vector representations for
entities and relations. Conventional models reason over graph structures, but
they suffer from the issues of graph incompleteness and long-tail entities.
Recent studies have used pre-trained language models to learn embeddings based
on the textual information of entities and relations, but they cannot take
advantage of graph structures. In the paper, we show empirically that these two
kinds of features are complementary for KG embedding. To this end, we propose
CoLE, a Co-distillation Learning method for KG Embedding that exploits the
complementarity of graph structures and text information. Its graph embedding
model employs Transformer to reconstruct the representation of an entity from
its neighborhood subgraph. Its text embedding model uses a pre-trained language
model to generate entity representations from the soft prompts of their names,
descriptions, and relational neighbors. To let the two model promote each
other, we propose co-distillation learning that allows them to distill
selective knowledge from each other's prediction logits. In our co-distillation
learning, each model serves as both a teacher and a student. Experiments on
benchmark datasets demonstrate that the two models outperform their related
baselines, and the ensemble method CoLE with co-distillation learning advances
the state-of-the-art of KG embedding.</p>
  </details>
</details>
<details>
  <summary>34. <b>标题：The Development of a Labelled te reo Māori-English Bilingual Database  for Language Technology</b></summary>
  <p><b>编号</b>：[278]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09778</p>
  <p><b>作者</b>：Jesin James,  Isabella Shields,  Vithya Yogarajan,  Peter J. Keegan,  Catherine Watson,  Peter-Lucas Jones,  Keoni Mahelona</p>
  <p><b>备注</b>：Submitted to Springer Language Resources and Evaluation Journal 2022</p>
  <p><b>关键词</b>：Māori, language, reo Māori, Māori language, English</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Te reo Māori (referred to as Māori), New Zealand's indigenous language,
is under-resourced in language technology. Māori speakers are bilingual,
where Māori is code-switched with English. Unfortunately, there are minimal
resources available for Māori language technology, language detection and
code-switch detection between Māori-English pair. Both English and Māori
use Roman-derived orthography making rule-based systems for detecting language
and code-switching restrictive. Most Māori language detection is done
manually by language experts. This research builds a Māori-English bilingual
database of 66,016,807 words with word-level language annotation. The New
Zealand Parliament Hansard debates reports were used to build the database. The
language labels are assigned using language-specific rules and expert manual
annotations. Words with the same spelling, but different meanings, exist for
Māori and English. These words could not be categorised as Māori or English
based on word-level language rules. Hence, manual annotations were necessary.
An analysis reporting the various aspects of the database such as metadata,
year-wise analysis, frequently occurring words, sentence length and N-grams is
also reported. The database developed here is a valuable tool for future
language and speech technology development for Aotearoa New Zealand. The
methodology followed to label the database can also be followed by other
low-resourced language pairs.</p>
  </details>
</details>
<details>
  <summary>35. <b>标题：Z-Code++: A Pre-trained Language Model Optimized for Abstractive  Summarization</b></summary>
  <p><b>编号</b>：[281]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09770</p>
  <p><b>作者</b>：Pengcheng He,  Baolin Peng,  Liyang Lu,  Song Wang,  Jie Mei,  Yang Liu,  Ruochen Xu,  Hany Hassan Awadalla,  Yu Shi,  Chenguang Zhu,  Wayne Xiong,  Michael Zeng,  Jianfeng Gao,  Xuedong Huang</p>
  <p><b>备注</b>：16 pages, 3 figures</p>
  <p><b>关键词</b>：paper presents Z-Code, paper presents, optimized for abstractive, abstractive text summarization, model</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper presents Z-Code++, a new pre-trained language model optimized for
abstractive text summarization. The model extends the state of the art
encoder-decoder model using three techniques. First, we use a two-phase
pre-training process to improve model's performance on low-resource
summarization tasks. The model is first pre-trained using text corpora for
language understanding, and then is continually pre-trained on summarization
corpora for grounded text generation. Second, we replace self-attention layers
in the encoder with disentangled attention layers, where each word is
represented using two vectors that encode its content and position,
respectively. Third, we use fusion-in-encoder, a simple yet effective method of
encoding long sequences in a hierarchical manner. Z-Code++ creates new state of
the art on 9 out of 13 text summarization tasks across 5 languages. Our model
is parameter-efficient in that it outperforms the 600x larger PaLM-540B on
XSum, and the finetuned 200x larger GPT3-175B on SAMSum. In zero-shot and
few-shot settings, our model substantially outperforms the competing models.</p>
  </details>
</details>
<details>
  <summary>36. <b>标题：Cognitive Modeling of Semantic Fluency Using Transformers</b></summary>
  <p><b>编号</b>：[299]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09719</p>
  <p><b>作者</b>：Animesh Nighojkar,  Anna Khlyzova,  John Licato</p>
  <p><b>备注</b>：Cognitive Aspects of Knowledge Representation workshop at IJCAI-ECAI 2022</p>
  <p><b>关键词</b>：deep language models, human cognition, deep language, explanatory models, models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Can deep language models be explanatory models of human cognition? If so,
what are their limits? In order to explore this question, we propose an
approach called hyperparameter hypothesization that uses predictive
hyperparameter tuning in order to find individuating descriptors of
cognitive-behavioral profiles. We take the first step in this approach by
predicting human performance in the semantic fluency task (SFT), a well-studied
task in cognitive science that has never before been modeled using
transformer-based language models (TLMs). In our task setup, we compare several
approaches to predicting which word an individual performing SFT will utter
next. We report preliminary evidence suggesting that, despite obvious
implementational differences in how people and TLMs learn and use language,
TLMs can be used to identify individual differences in human fluency task
behaviors better than existing computational models, and may offer insights
into human memory retrieval strategies -- cognitive process not typically
considered to be the kinds of things TLMs can model. Finally, we discuss the
implications of this work for cognitive modeling of knowledge representations.</p>
  </details>
</details>
<details>
  <summary>37. <b>标题：SemEval-2022 Task 8: Multi-lingual News Article Similarity</b></summary>
  <p><b>编号</b>：[302]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09715</p>
  <p><b>作者</b>：Nikhil Goel,  Ranjith Reddy</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：feed-forward neural network, similarity, feed-forward neural, articles, neural network</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This work is about finding the similarity between a pair of news articles.
There are seven different objective similarity metrics provided in the dataset
for each pair and the news articles are in multiple different languages. On top
of the pre-trained embedding model, we calculated cosine similarity for
baseline results and feed-forward neural network was then trained on top of it
to improve the results. We also built separate pipelines for each similarity
metric for feature extraction. We could see significant improvement from
baseline results using feature extraction and feed-forward neural network.</p>
  </details>
</details>
<details>
  <summary>38. <b>标题：BSpell: A CNN-blended BERT Based Bengali Spell Checker</b></summary>
  <p><b>编号</b>：[304]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09709</p>
  <p><b>作者</b>：Chowdhury Rafeed Rahman,  MD. Hasibur Rahman,  Samiha Zakir,  Mohammad Rafsan,  Mohammed Eunus Ali</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：similarly pronounced letters, performed using English, English keyboard, highly erroneous due, pronounced letters</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Bengali typing is mostly performed using English keyboard and can be highly
erroneous due to the presence of compound and similarly pronounced letters.
Spelling correction of a misspelled word requires understanding of word typing
pattern as well as the context of the word usage. We propose a specialized BERT
model, BSpell targeted towards word for word correction in sentence level.
BSpell contains an end-to-end trainable CNN sub-model named SemanticNet along
with specialized auxiliary loss. This allows BSpell to specialize in highly
inflected Bengali vocabulary in the presence of spelling errors. We further
propose hybrid pretraining scheme for BSpell combining word level and character
level masking. Utilizing this pretraining scheme, BSpell achieves 91.5%
accuracy on real life Bengali spelling correction validation set. Detailed
comparison on two Bengali and one Hindi spelling correction dataset shows the
superiority of proposed BSpell over existing spell checkers.</p>
  </details>
</details>
<details>
  <summary>39. <b>标题：gBuilder: A Scalable Knowledge Graph Construction System for  Unstructured Corpus</b></summary>
  <p><b>编号</b>：[307]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09705</p>
  <p><b>作者</b>：Yanzeng Li,  Lei Zou</p>
  <p><b>备注</b>：This is a preview version</p>
  <p><b>关键词</b>：unstructured corpus, extracting structured knowledge, user-friendly and scalable, extracting structured, existing KGC systems</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We design a user-friendly and scalable knowledge graph construction (KGC)
system for extracting structured knowledge from the unstructured corpus.
Different from existing KGC systems, gBuilder provides a flexible and
user-defined pipeline to embracing the rapid development of IE models. More
built-in template-based or heuristic operators and programmable operators are
available for adapting to data from different domains. Furthermore, we also
design a cloud-based self-adaptive task scheduling for gBuilder to ensure its
scalability on large-scale knowledge graph construction. Experimental
evaluation not only demonstrates the ability of gBuilder to organize multiple
information extraction models for knowledge graph construction in a uniform
platform, and also confirms its high scalability on large-scale KGC task.</p>
  </details>
</details>
<details>
  <summary>40. <b>标题：Judge a Sentence by Its Content to Generate Grammatical Errors</b></summary>
  <p><b>编号</b>：[315]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09693</p>
  <p><b>作者</b>：Chowdhury Rafeed Rahman</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：grammatical error correction, well-known problem, GEC, error correction, Data</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Data sparsity is a well-known problem for grammatical error correction (GEC).
Generating synthetic training data is one widely proposed solution to this
problem, and has allowed models to achieve state-of-the-art (SOTA) performance
in recent years. However, these methods often generate unrealistic errors, or
aim to generate sentences with only one error. We propose a learning based two
stage method for synthetic data generation for GEC that relaxes this constraint
on sentences containing only one error. Errors are generated in accordance with
sentence merit. We show that a GEC model trained on our synthetically generated
corpus outperforms models trained on synthetic data from prior work.</p>
  </details>
</details>
<details>
  <summary>41. <b>标题：Combining Compressions for Multiplicative Size Scaling on Natural  Language Tasks</b></summary>
  <p><b>编号</b>：[319]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09684</p>
  <p><b>作者</b>：Rajiv Movva,  Jinhao Lei,  Shayne Longpre,  Ajay Gupta,  Chris DuBois</p>
  <p><b>备注</b>：Accepted as short paper at COLING 2022. 5 pages main text, 5 pages appendix</p>
  <p><b>关键词</b>：model size, neural network compression, neural network, reduce model size, model size tradeoffs</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Quantization, knowledge distillation, and magnitude pruning are among the
most popular methods for neural network compression in NLP. Independently,
these methods reduce model size and can accelerate inference, but their
relative benefit and combinatorial interactions have not been rigorously
studied. For each of the eight possible subsets of these techniques, we compare
accuracy vs. model size tradeoffs across six BERT architecture sizes and eight
GLUE tasks. We find that quantization and distillation consistently provide
greater benefit than pruning. Surprisingly, except for the pair of pruning and
quantization, using multiple methods together rarely yields diminishing
returns. Instead, we observe complementary and super-multiplicative reductions
to model size. Our work quantitatively demonstrates that combining compression
methods can synergistically reduce model size, and that practitioners should
prioritize (1) quantization, (2) knowledge distillation, and (3) pruning to
maximize accuracy vs. model size tradeoffs.</p>
  </details>
</details>
<details>
  <summary>42. <b>标题：Lost in Context? On the Sense-wise Variance of Contextualized Word  Embeddings</b></summary>
  <p><b>编号</b>：[326]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09669</p>
  <p><b>作者</b>：Yile Wang,  Yue Zhang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：word, language models, NLP, Contextualized, embeddings</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Contextualized word embeddings in language models have given much advance to
NLP. Intuitively, sentential information is integrated into the representation
of words, which can help model polysemy. However, context sensitivity also
leads to the variance of representations, which may break the semantic
consistency for synonyms. We quantify how much the contextualized embeddings of
each word sense vary across contexts in typical pre-trained models. Results
show that contextualized embeddings can be highly consistent across contexts.
In addition, part-of-speech, number of word senses, and sentence length have an
influence on the variance of sense representations. Interestingly, we find that
word representations are position-biased, where the first words in different
contexts tend to be more similar. We analyze such a phenomenon and also propose
a simple way to alleviate such bias in distance-based word sense disambiguation
settings.</p>
  </details>
</details>
<details>
  <summary>43. <b>标题：Trigger-free Event Detection via Derangement Reading Comprehension</b></summary>
  <p><b>编号</b>：[332]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09659</p>
  <p><b>作者</b>：Jiachen Zhao,  Haiqin Yang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：understanding actual happenings, aiming to detect, real life, vital to understanding, understanding actual</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Event detection (ED), aiming to detect events from texts and categorize them,
is vital to understanding actual happenings in real life. However, mainstream
event detection models require high-quality expert human annotations of
triggers, which are often costly and thus deter the application of ED to new
domains. Therefore, in this paper, we focus on low-resource ED without triggers
and aim to tackle the following formidable challenges: multi-label
classification, insufficient clues, and imbalanced events distribution. We
propose a novel trigger-free ED method via Derangement mechanism on a machine
Reading Comprehension (DRC) framework. More specifically, we treat the input
text as Context and concatenate it with all event type tokens that are deemed
as Answers with an omitted default question. So we can leverage the
self-attention in pre-trained language models to absorb semantic relations
between input text and the event types. Moreover, we design a simple yet
effective event derangement module (EDM) to prevent major events from being
excessively learned so as to yield a more balanced training process. The
experiment results show that our proposed trigger-free ED model is remarkably
competitive to mainstream trigger-based models, showing its strong performance
on low-source event detection.</p>
  </details>
</details>
<details>
  <summary>44. <b>标题：Persuasion Strategies in Advertisements: Dataset, Modeling, and  Baselines</b></summary>
  <p><b>编号</b>：[346]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09626</p>
  <p><b>作者</b>：Yaman Kumar Singla,  Rajat Jha,  Arunim Gupta,  Milan Aggarwal,  Aditya Garg,  Ayush Bhardwaj,  Tushar,  Balaji Krishnamurthy,  Rajiv Ratn Shah,  Changyou Chen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：advertisement persuasive, eliciting the desired, response from consumer, makes an advertisement, desired response</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Modeling what makes an advertisement persuasive, i.e., eliciting the desired
response from consumer, is critical to the study of propaganda, social
psychology, and marketing. Despite its importance, computational modeling of
persuasion in computer vision is still in its infancy, primarily due to the
lack of benchmark datasets that can provide persuasion-strategy labels
associated with ads. Motivated by persuasion literature in social psychology
and marketing, we introduce an extensive vocabulary of persuasion strategies
and build the first ad image corpus annotated with persuasion strategies. We
then formulate the task of persuasion strategy prediction with multi-modal
learning, where we design a multi-task attention fusion model that can leverage
other ad-understanding tasks to predict persuasion strategies. Further, we
conduct a real-world case study on 1600 advertising campaigns of 30 Fortune-500
companies where we use our model's predictions to analyze which strategies work
with different demographics (age and gender). The dataset also provides image
segmentation masks, which labels persuasion strategies in the corresponding ad
images on the test split. We publicly release our code and dataset
this https URL.</p>
  </details>
</details>
<details>
  <summary>45. <b>标题：Representing Knowledge by Spans: A Knowledge-Enhanced Model for  Information Extraction</b></summary>
  <p><b>编号</b>：[347]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09625</p>
  <p><b>作者</b>：Jiacheng Li,  Yannis Katsis,  Tyler Baldwin,  Ho-Cheol Kim,  Andrew Bartko,  Julian McAuley,  Chun-Nan Hsu</p>
  <p><b>备注</b>：CIKM 2022</p>
  <p><b>关键词</b>：knowledge base construction, base construction tasks, entities, base construction, BERT</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Knowledge-enhanced pre-trained models for language representation have been
shown to be more effective in knowledge base construction tasks (i.e.,~relation
extraction) than language models such as BERT. These knowledge-enhanced
language models incorporate knowledge into pre-training to generate
representations of entities or relationships. However, existing methods
typically represent each entity with a separate embedding. As a result, these
methods struggle to represent out-of-vocabulary entities and a large amount of
parameters, on top of their underlying token models (i.e.,~the transformer),
must be used and the number of entities that can be handled is limited in
practice due to memory constraints. Moreover, existing models still struggle to
represent entities and relationships simultaneously. To address these problems,
we propose a new pre-trained model that learns representations of both entities
and relationships from token spans and span pairs in the text respectively. By
encoding spans efficiently with span modules, our model can represent both
entities and their relationships but requires fewer parameters than existing
models. We pre-trained our model with the knowledge graph extracted from
Wikipedia and test it on a broad range of supervised and unsupervised
information extraction tasks. Results show that our model learns better
representations for both entities and relationships than baselines, while in
supervised settings, fine-tuning our model outperforms RoBERTa consistently and
achieves competitive results on information extraction tasks.</p>
  </details>
</details>
<details>
  <summary>46. <b>标题：Pretrained Language Encoders are Natural Tagging Frameworks for Aspect  Sentiment Triplet Extraction</b></summary>
  <p><b>编号</b>：[351]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09617</p>
  <p><b>作者</b>：Yanjie Gou,  Yinjie Lei,  Lingqiao Liu,  Yong Dai,  Chunxu Shen,  Yongqi Tong</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Sentiment Triplet Extraction, Aspect Sentiment Triplet, Triplet Extraction, Sentiment Triplet, Aspect Sentiment</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Aspect Sentiment Triplet Extraction (ASTE) aims to extract the spans of
aspect, opinion, and their sentiment relations as sentiment triplets. Existing
works usually formulate the span detection as a 1D token tagging problem, and
model the sentiment recognition with a 2D tagging matrix of token pairs.
Moreover, by leveraging the token representation of Pretrained Language
Encoders (PLEs) like BERT, they can achieve better performance. However, they
simply leverage PLEs as feature extractors to build their modules but never
have a deep look at what specific knowledge does PLEs contain. In this paper,
we argue that instead of further designing modules to capture the inductive
bias of ASTE, PLEs themselves contain "enough" features for 1D and 2D tagging:
(1) The token representation contains the contextualized meaning of token
itself, so this level feature carries necessary information for 1D tagging. (2)
The attention matrix of different PLE layers can further capture multi-level
linguistic knowledge existing in token pairs, which benefits 2D tagging. (3)
Furthermore, with simple transformations, these two features can also be easily
converted to the 2D tagging matrix and 1D tagging sequence, respectively. That
will further boost the tagging results. By doing so, PLEs can be natural
tagging frameworks and achieve a new state of the art, which is verified by
extensive experiments and deep analyses.</p>
  </details>
</details>
<details>
  <summary>47. <b>标题：General-to-Specific Transfer Labeling for Domain Adaptable Keyphrase  Generation</b></summary>
  <p><b>编号</b>：[359]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09606</p>
  <p><b>作者</b>：Rui Meng,  Tong Wang,  Xingdi Yuan,  Yingbo Zhou,  Daqing He</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Training keyphrase generation, prohibitively expensive, KPG, large amount, models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Training keyphrase generation (KPG) models requires a large amount of
annotated data, which can be prohibitively expensive and often limited to
specific domains. In this study, we first demonstrate that large distribution
shifts among different domains severely hinder the transferability of KPG
models. We then propose a three-stage pipeline, which gradually guides KPG
models' learning focus from general syntactical features to domain-related
semantics, in a data-efficient manner. With Domain-general Phrase pre-training,
we pre-train Sequence-to-Sequence models with generic phrase annotations that
are widely available on the web, which enables the models to generate phrases
in a wide range of domains. The resulting model is then applied in the Transfer
Labeling stage to produce domain-specific pseudo keyphrases, which help adapt
models to a new domain. Finally, we fine-tune the model with limited data with
true labels to fully adapt it to the target domain. Our experiment results show
that the proposed process can produce good quality keyphrases in new domains
and achieve consistent improvements after adaptation with limited in-domain
annotated data.</p>
  </details>
</details>
<details>
  <summary>48. <b>标题：Using Multi-Encoder Fusion Strategies to Improve Personalized Response  Selection</b></summary>
  <p><b>编号</b>：[361]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09601</p>
  <p><b>作者</b>：Souvik Das,  Sougata Saha,  Rohini K. Srihari</p>
  <p><b>备注</b>：COLING 2022. arXiv admin note: text overlap with arXiv:2105.09050 by other authors</p>
  <p><b>关键词</b>：Personalized response selection, generally grounded, Personalized response, response selection systems, response selection</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Personalized response selection systems are generally grounded on persona.
However, there exists a co-relation between persona and empathy, which is not
explored well in these systems. Also, faithfulness to the conversation context
plunges when a contradictory or an off-topic response is selected. This paper
attempts to address these issues by proposing a suite of fusion strategies that
capture the interaction between persona, emotion, and entailment information of
the utterances. Ablation studies on the Persona-Chat dataset show that
incorporating emotion and entailment improves the accuracy of response
selection. We combine our fusion strategies and concept-flow encoding to train
a BERT-based model which outperforms the previous methods by margins larger
than 2.3 % on original personas and 1.9 % on revised personas in terms of
hits@1 (top-1 accuracy), achieving a new state-of-the-art performance on the
Persona-Chat dataset.</p>
  </details>
</details>
<details>
  <summary>49. <b>标题：Contrastive Domain Adaptation for Early Misinformation Detection: A Case  Study on COVID-19</b></summary>
  <p><b>编号</b>：[373]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09578</p>
  <p><b>作者</b>：Zhenrui Yue,  Huimin Zeng,  Ziyi Kou,  Lanyu Shang,  Dong Wang</p>
  <p><b>备注</b>：Accepted to CIKM 2022</p>
  <p><b>关键词</b>：early misinformation detection, early misinformation, misinformation detection, elusive challenge, misinformation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Despite recent progress in improving the performance of misinformation
detection systems, classifying misinformation in an unseen domain remains an
elusive challenge. To address this issue, a common approach is to introduce a
domain critic and encourage domain-invariant input features. However, early
misinformation often demonstrates both conditional and label shifts against
existing misinformation data (e.g., class imbalance in COVID-19 datasets),
rendering such methods less effective for detecting early misinformation. In
this paper, we propose contrastive adaptation network for early misinformation
detection (CANMD). Specifically, we leverage pseudo labeling to generate
high-confidence target examples for joint training with source data. We
additionally design a label correction component to estimate and correct the
label shifts (i.e., class priors) between the source and target domains.
Moreover, a contrastive adaptation loss is integrated in the objective function
to reduce the intra-class discrepancy and enlarge the inter-class discrepancy.
As such, the adapted model learns corrected class priors and an invariant
conditional distribution across both domains for improved estimation of the
target data distribution. To demonstrate the effectiveness of the proposed
CANMD, we study the case of COVID-19 early misinformation detection and perform
extensive experiments using multiple real-world datasets. The results suggest
that CANMD can effectively adapt misinformation detection systems to the unseen
COVID-19 target domain with significant improvements compared to the
state-of-the-art baselines.</p>
  </details>
</details>
<details>
  <summary>50. <b>标题：Characterizing narrative time in books through fluctuations in power and  danger arcs</b></summary>
  <p><b>编号</b>：[401]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09496</p>
  <p><b>作者</b>：Mikaela Irene Fudolig,  Thayer Alshaabi,  Kathryn Cramer,  Christopher M. Danforth,  Peter Sheridan Dodds</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：quantifying word usage, narrative emotional arcs, word usage, recent studies, studies have focused</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>While recent studies have focused on quantifying word usage to find the
overall shapes of narrative emotional arcs, certain features of narratives
within narratives remain to be explored. Here, we characterize the narrative
time scale of sub-narratives by finding the length of text at which
fluctuations in word usage begin to be relevant. We represent more than 30,000
Project Gutenberg books as time series using ousiometrics, a power-danger
framework for essential meaning, itself a reinterpretation of the
valence-arousal-dominance framework derived from semantic differentials. We
decompose each book's power and danger time series using empirical mode
decomposition into a sum of constituent oscillatory modes and a non-oscillatory
trend. By comparing the decomposition of the original power and danger time
series with those derived from shuffled text, we find that shorter books
exhibit only a general trend, while longer books have fluctuations in addition
to the general trend, similar to how subplots have arcs within an overall
narrative arc. These fluctuations typically have a period of a few thousand
words regardless of the book length or library classification code, but vary
depending on the content and structure of the book. Our method provides a
data-driven denoising approach that works for text of various lengths, in
contrast to the more traditional approach of using large window sizes that may
inadvertently smooth out relevant information, especially for shorter texts.</p>
  </details>
</details>
<h1>机器学习</h1>
<details>
  <summary>1. <b>标题：Prioritizing Samples in Reinforcement Learning with Reducible Loss</b></summary>
  <p><b>编号</b>：[1]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10483</p>
  <p><b>作者</b>：Shivakanth Sujit,  Somjit Nath,  Pedro H. M. Braga,  Samira Ebrahimi Kahou</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：reinforcement learning algorithms, reinforcement learning, buffer to repeatedly, repeatedly train, agent has observed</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Most reinforcement learning algorithms take advantage of an experience replay
buffer to repeatedly train on samples the agent has observed in the past. This
prevents catastrophic forgetting, however simply assigning equal importance to
each of the samples is a naive strategy. In this paper, we propose a method to
prioritize samples based on how much we can learn from a sample. We define the
learn-ability of a sample as the steady decrease of the training loss
associated with this sample over time. We develop an algorithm to prioritize
samples with high learn-ability, while assigning lower priority to those that
are hard-to-learn, typically caused by noise or stochasticity. We empirically
show that our method is more robust than random sampling and also better than
just prioritizing with respect to the training loss, i.e. the temporal
difference loss, which is used in vanilla prioritized experience replay.</p>
  </details>
</details>
<details>
  <summary>2. <b>标题：BARReL: Bottleneck Attention for Adversarial Robustness in Vision-Based  Reinforcement Learning</b></summary>
  <p><b>编号</b>：[2]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10481</p>
  <p><b>作者</b>：Eugene Bykovets,  Yannick Metz,  Mennatallah El-Assady,  Daniel A. Keim,  Joachim M. Buhmann</p>
  <p><b>备注</b>：5 pages, 2 figures, 3 tables</p>
  <p><b>关键词</b>：computer vision, areas of computer, vision-based reinforcement learning, vision-based reinforcement, reinforcement learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Robustness to adversarial perturbations has been explored in many areas of
computer vision. This robustness is particularly relevant in vision-based
reinforcement learning, as the actions of autonomous agents might be
safety-critic or impactful in the real world. We investigate the susceptibility
of vision-based reinforcement learning agents to gradient-based adversarial
attacks and evaluate a potential defense. We observe that Bottleneck Attention
Modules (BAM) included in CNN architectures can act as potential tools to
increase robustness against adversarial attacks. We show how learned attention
maps can be used to recover activations of a convolutional layer by restricting
the spatial activations to salient regions. Across a number of RL environments,
BAM-enhanced architectures show increased robustness during inference. Finally,
we discuss potential future research directions.</p>
  </details>
</details>
<details>
  <summary>3. <b>标题：Survey of Machine Learning Techniques To Predict Heartbeat Arrhythmias</b></summary>
  <p><b>编号</b>：[8]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10463</p>
  <p><b>作者</b>：Samuel Armstrong</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：give accurate results, biomedical computer science, computer science research, accurate results, machine learning techniques</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Many works in biomedical computer science research use machine learning
techniques to give accurate results. However, these techniques may not be
feasible for real-time analysis of data pulled from live hospital feeds. In
this project, different machine learning techniques are compared from various
sources to find one that provides not only high accuracy but also low latency
and memory overhead to be used in real-world health care systems.</p>
  </details>
</details>
<details>
  <summary>4. <b>标题：Shapelet-Based Counterfactual Explanations for Multivariate Time Series</b></summary>
  <p><b>编号</b>：[9]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10462</p>
  <p><b>作者</b>：Omar Bahri,  Soukaina Filali Boubrahimi,  Shah Muhammad Hamdi</p>
  <p><b>备注</b>：Appeared in ACM SIGKDD Workshop on Mining and Learning from Time Series (KDD-MiLeTS 2022)</p>
  <p><b>关键词</b>：deep learning models, machine learning, deep learning, multitude of domains, highly prevalent</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As machine learning and deep learning models have become highly prevalent in
a multitude of domains, the main reservation in their adoption for
decision-making processes is their black-box nature. The Explainable Artificial
Intelligence (XAI) paradigm has gained a lot of momentum lately due to its
ability to reduce models opacity. XAI methods have not only increased
stakeholders' trust in the decision process but also helped developers ensure
its fairness. Recent efforts have been invested in creating transparent models
and post-hoc explanations. However, fewer methods have been developed for time
series data, and even less when it comes to multivariate datasets. In this
work, we take advantage of the inherent interpretability of shapelets to
develop a model agnostic multivariate time series (MTS) counterfactual
explanation algorithm. Counterfactuals can have a tremendous impact on making
black-box models explainable by indicating what changes have to be performed on
the input to change the final decision. We test our approach on a real-life
solar flare prediction dataset and prove that our approach produces
high-quality counterfactuals. Moreover, a comparison to the only MTS
counterfactual generation algorithm shows that, in addition to being visually
interpretable, our explanations are superior in terms of proximity, sparsity,
and plausibility.</p>
  </details>
</details>
<details>
  <summary>5. <b>标题：Minimax-Optimal Multi-Agent RL in Zero-Sum Markov Games With a  Generative Model</b></summary>
  <p><b>编号</b>：[11]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10458</p>
  <p><b>作者</b>：Gen Li,  Yuejie Chi,  Yuting Wei,  Yuxin Chen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：two-player zero-sum Markov, multi-agent reinforcement learning, zero-sum Markov games, paper is concerned, concerned with two-player</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper is concerned with two-player zero-sum Markov games -- arguably the
most basic setting in multi-agent reinforcement learning -- with the goal of
learning a Nash equilibrium (NE) sample-optimally. All prior results suffer
from at least one of the two obstacles: the curse of multiple agents and the
barrier of long horizon, regardless of the sampling protocol in use. We take a
step towards settling this problem, assuming access to a flexible sampling
mechanism: the generative model. Focusing on non-stationary finite-horizon
Markov games, we develop a learning algorithm
$\mathsf{Nash}\text{-}\mathsf{Q}\text{-}\mathsf{FTRL}$ and an adaptive sampling
scheme that leverage the optimism principle in adversarial learning
(particularly the Follow-the-Regularized-Leader (FTRL) method), with a delicate
design of bonus terms that ensure certain decomposability under the FTRL
dynamics. Our algorithm learns an $\varepsilon$-approximate Markov NE policy
using
$$ \widetilde{O}\bigg( \frac{H^4 S(A+B)}{\varepsilon^2} \bigg) $$ samples,
where $S$ is the number of states, $H$ is the horizon, and $A$ (resp.~$B$)
denotes the number of actions for the max-player (resp.~min-player). This is
nearly un-improvable in a minimax sense. Along the way, we derive a refined
regret bound for FTRL that makes explicit the role of variance-type quantities,
which might be of independent interest.</p>
  </details>
</details>
<details>
  <summary>6. <b>标题：Minimax AUC Fairness: Efficient Algorithm with Provable Convergence</b></summary>
  <p><b>编号</b>：[14]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10451</p>
  <p><b>作者</b>：Zhenhuan Yang,  Yan Lok Ko,  Kush R. Varshney,  Yiming Ying</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：exacerbates societal inequity, consequential decision making, yielding disparate impact, marginalized groups defined, machine learning models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The use of machine learning models in consequential decision making often
exacerbates societal inequity, in particular yielding disparate impact on
members of marginalized groups defined by race and gender. The area under the
ROC curve (AUC) is widely used to evaluate the performance of a scoring
function in machine learning, but is studied in algorithmic fairness less than
other performance metrics. Due to the pairwise nature of the AUC, defining an
AUC-based group fairness metric is pairwise-dependent and may involve both
\emph{intra-group} and \emph{inter-group} AUCs. Importantly, considering only
one category of AUCs is not sufficient to mitigate unfairness in AUC
optimization. In this paper, we propose a minimax learning and bias mitigation
framework that incorporates both intra-group and inter-group AUCs while
maintaining utility. Based on this Rawlsian framework, we design an efficient
stochastic optimization algorithm and prove its convergence to the minimum
group-level AUC. We conduct numerical experiments on both synthetic and
real-world datasets to validate the effectiveness of the minimax framework and
the proposed optimization algorithm.</p>
  </details>
</details>
<details>
  <summary>7. <b>标题：Membership-Doctor: Comprehensive Assessment of Membership Inference  Against Machine Learning Models</b></summary>
  <p><b>编号</b>：[17]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10445</p>
  <p><b>作者</b>：Xinlei He,  Zheng Li,  Weilin Xu,  Cory Cornelius,  Yang Zhang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：membership inference attacks, membership inference, attacks, inference attacks, Machine learning models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Machine learning models are prone to memorizing sensitive data, making them
vulnerable to membership inference attacks in which an adversary aims to infer
whether an input sample was used to train the model. Over the past few years,
researchers have produced many membership inference attacks and defenses.
However, these attacks and defenses employ a variety of strategies and are
conducted in different models and datasets. The lack of comprehensive
benchmark, however, means we do not understand the strengths and weaknesses of
existing attacks and defenses.
We fill this gap by presenting a large-scale measurement of different
membership inference attacks and defenses. We systematize membership inference
through the study of nine attacks and six defenses and measure the performance
of different attacks and defenses in the holistic evaluation. We then quantify
the impact of the threat model on the results of these attacks. We find that
some assumptions of the threat model, such as same-architecture and
same-distribution between shadow and target models, are unnecessary. We are
also the first to execute attacks on the real-world data collected from the
Internet, instead of laboratory datasets. We further investigate what
determines the performance of membership inference attacks and reveal that the
commonly believed overfitting level is not sufficient for the success of the
attacks. Instead, the Jensen-Shannon distance of entropy/cross-entropy between
member and non-member samples correlates with attack performance much better.
This gives us a new way to accurately predict membership inference risks
without running the attack. Finally, we find that data augmentation degrades
the performance of existing attacks to a larger extent, and we propose an
adaptive attack using augmentation to train shadow and attack models that
improve attack performance.</p>
  </details>
</details>
<details>
  <summary>8. <b>标题：The GENEA Challenge 2022: A large evaluation of data-driven co-speech  gesture generation</b></summary>
  <p><b>编号</b>：[20]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10441</p>
  <p><b>作者</b>：Youngwoo Yoon,  Pieter Wolfert,  Taras Kucherenko,  Carla Viegas,  Teodor Nikolov,  Mihail Tsakov,  Gustav Eje Henter</p>
  <p><b>备注</b>：12 pages, 5 figures; final version for ACM ICMI 2022</p>
  <p><b>关键词</b>：benchmark data-driven automatic, data-driven automatic co-speech, co-speech gesture generation, automatic co-speech gesture, GENEA Challenge</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper reports on the second GENEA Challenge to benchmark data-driven
automatic co-speech gesture generation. Participating teams used the same
speech and motion dataset to build gesture-generation systems. Motion generated
by all these systems was rendered to video using a standardised visualisation
pipeline and evaluated in several large, crowdsourced user studies. Unlike when
comparing different research papers, differences in results are here only due
to differences between methods, enabling direct comparison between systems.
This year's dataset was based on 18 hours of full-body motion capture,
including fingers, of different persons engaging in dyadic conversation. Ten
teams participated in the challenge across two tiers: full-body and upper-body
gesticulation. For each tier we evaluated both the human-likeness of the
gesture motion and its appropriateness for the specific speech signal. Our
evaluations decouple human-likeness from gesture appropriateness, which
previously was a major challenge in the field.
The evaluation results are a revolution, and a revelation. Some synthetic
conditions are rated as significantly more human-like than human motion
capture. To the best of our knowledge, this has never been shown before on a
high-fidelity avatar. On the other hand, all synthetic motion is found to be
vastly less appropriate for the speech than the original motion-capture
recordings. Additional material is available via the project website at
this https URL</p>
  </details>
</details>
<details>
  <summary>9. <b>标题：Patient-level Microsatellite Stability Assessment from Whole Slide  Images By Combining Momentum Contrast Learning and Group Patch Embeddings</b></summary>
  <p><b>编号</b>：[23]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10429</p>
  <p><b>作者</b>：Daniel Shats,  Hadar Hezi,  Guy Shani,  Yosef E. Maruvka,  Moti Freiman</p>
  <p><b>备注</b>：To appear in the proceedings of the ECCV workshop on Medical Computer Vision (ECCV-MCV 2022). Link: this https URL</p>
  <p><b>关键词</b>：personalizing treatment regime, WSI high resolution, patient colorectal cancer, treatment regime, WSI</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Assessing microsatellite stability status of a patient's colorectal cancer is
crucial in personalizing treatment regime. Recently,
convolutional-neural-networks (CNN) combined with transfer-learning approaches
were proposed to circumvent traditional laboratory testing for determining
microsatellite status from hematoxylin and eosin stained biopsy whole slide
images (WSI). However, the high resolution of WSI practically prevent direct
classification of the entire WSI. Current approaches bypass the WSI high
resolution by first classifying small patches extracted from the WSI, and then
aggregating patch-level classification logits to deduce the patient-level
status. Such approaches limit the capacity to capture important information
which resides at the high resolution WSI data. We introduce an effective
approach to leverage WSI high resolution information by momentum contrastive
learning of patch embeddings along with training a patient-level classifier on
groups of those embeddings. Our approach achieves up to 7.4\% better accuracy
compared to the straightforward patch-level classification and patient level
aggregation approach with a higher stability (AUC, $0.91 \pm 0.01$ vs. $0.85
\pm 0.04$, p-value$<0.01$). our code can be found at this https url.< p>
  </0.01$).></p></details>
</details>
<details>
  <summary>10. <b>标题：Equivariant Hypergraph Neural Networks</b></summary>
  <p><b>编号</b>：[24]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10428</p>
  <p><b>作者</b>：Jinwoo Kim,  Saeyoon Oh,  Sungjun Cho,  Seunghoon Hong</p>
  <p><b>备注</b>：29 pages, 2 figures</p>
  <p><b>关键词</b>：represent higher-order relations, higher-order relations, computer vision, vision and machine, represent higher-order</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Many problems in computer vision and machine learning can be cast as learning
on hypergraphs that represent higher-order relations. Recent approaches for
hypergraph learning extend graph neural networks based on message passing,
which is simple yet fundamentally limited in modeling long-range dependencies
and expressive power. On the other hand, tensor-based equivariant neural
networks enjoy maximal expressiveness, but their application has been limited
in hypergraphs due to heavy computation and strict assumptions on fixed-order
hyperedges. We resolve these problems and present Equivariant Hypergraph Neural
Network (EHNN), the first attempt to realize maximally expressive equivariant
layers for general hypergraph learning. We also present two practical
realizations of our framework based on hypernetworks (EHNN-MLP) and
self-attention (EHNN-Transformer), which are easy to implement and
theoretically more expressive than most message passing approaches. We
demonstrate their capability in a range of hypergraph learning problems,
including synthetic k-edge identification, semi-supervised classification, and
visual keypoint matching, and report improved performances over strong message
passing baselines. Our implementation is available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>11. <b>标题：SVD-NAS: Coupling Low-Rank Approximation and Neural Architecture Search</b></summary>
  <p><b>编号</b>：[32]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10404</p>
  <p><b>作者</b>：Zhewen Yu,  Christos-Savvas Bouganis</p>
  <p><b>备注</b>：Accepted at WACV 2023</p>
  <p><b>关键词</b>：Deep Neural Networks, compressing pre-trained Deep, pre-trained Deep Neural, data access requirements, attracted wide interest</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The task of compressing pre-trained Deep Neural Networks has attracted wide
interest of the research community due to its great benefits in freeing
practitioners from data access requirements. In this domain, low-rank
approximation is a promising method, but existing solutions considered a
restricted number of design choices and failed to efficiently explore the
design space, which lead to severe accuracy degradation and limited compression
ratio achieved. To address the above limitations, this work proposes the
SVD-NAS framework that couples the domains of low-rank approximation and neural
architecture search. SVD-NAS generalises and expands the design choices of
previous works by introducing the Low-Rank architecture space, LR-space, which
is a more fine-grained design space of low-rank approximation. Afterwards, this
work proposes a gradient-descent-based search for efficiently traversing the
LR-space. This finer and more thorough exploration of the possible design
choices results in improved accuracy as well as reduction in parameters, FLOPS,
and latency of a CNN model. Results demonstrate that the SVD-NAS achieves
2.06-12.85pp higher accuracy on ImageNet than state-of-the-art methods under
the data-limited problem setting. SVD-NAS is open-sourced at
this https URL.</p>
  </details>
</details>
<details>
  <summary>12. <b>标题：Constants of motion network</b></summary>
  <p><b>编号</b>：[37]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10387</p>
  <p><b>作者</b>：Muhammad Firmansyah Kasim,  Yi Heng Lim</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：constants of motion, beauty of physics, conserved quantity, motion, always-changing system</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The beauty of physics is that there is usually a conserved quantity in an
always-changing system, known as the constant of motion. Finding the constant
of motion is important in understanding the dynamics of the system, but
typically requires mathematical proficiency and manual analytical work. In this
paper, we present a neural network that can simultaneously learn the dynamics
of the system and the constants of motion from data. By exploiting the
discovered constants of motion, it can produce better predictions on dynamics
and can work on a wider range of systems than Hamiltonian-based neural
networks. In addition, the training progresses of our method can be used as an
indication of the number of constants of motion in a system which could be
useful in studying a novel physical system.</p>
  </details>
</details>
<details>
  <summary>13. <b>标题：Simulation-Informed Revenue Extrapolation with Confidence Estimate for  Scaleup Companies Using Scarce Time-Series Data</b></summary>
  <p><b>编号</b>：[43]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10375</p>
  <p><b>作者</b>：Lele Cao,  Sonja Horn,  Vilhelm von Ehrenheim,  Richard Anselmo Stahl,  Henrik Landgren</p>
  <p><b>备注</b>：Accepted by CIKM 2022 as full applied research paper (12 pages and 6 figures). For source code and datasets, see this https URL</p>
  <p><b>关键词</b>：extrapolating company revenue, Investment professionals rely, private companies, high-growth stage, rely on extrapolating</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Investment professionals rely on extrapolating company revenue into the
future (i.e. revenue forecast) to approximate the valuation of scaleups
(private companies in a high-growth stage) and inform their investment
decision. This task is manual and empirical, leaving the forecast quality
heavily dependent on the investment professionals' experiences and insights.
Furthermore, financial data on scaleups is typically proprietary, costly and
scarce, ruling out the wide adoption of data-driven approaches. To this end, we
propose a simulation-informed revenue extrapolation (SiRE) algorithm that
generates fine-grained long-term revenue predictions on small datasets and
short time-series. SiRE models the revenue dynamics as a linear dynamical
system (LDS), which is solved using the EM algorithm. The main innovation lies
in how the noisy revenue measurements are obtained during training and
inferencing. SiRE works for scaleups that operate in various sectors and
provides confidence estimates. The quantitative experiments on two practical
tasks show that SiRE significantly surpasses the baseline methods by a large
margin. We also observe high performance when SiRE extrapolates from short
time-series and predicts for long-term. The performance-efficiency balance and
result explainability of SiRE are also validated empirically. Evaluated from
the perspective of investment professionals, SiRE can precisely locate the
scaleups that have a great potential return in 2 to 5 years. Furthermore, our
qualitative inspection illustrates some advantageous attributes of the SiRE
revenue forecasts.</p>
  </details>
</details>
<details>
  <summary>14. <b>标题：Multi-View Attention Transfer for Efficient Speech Enhancement</b></summary>
  <p><b>编号</b>：[46]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10367</p>
  <p><b>作者</b>：Wooseok Shin,  Hyun Joon Park,  Jin Sob Kim,  Byung Hoon Lee,  Sung Won Han</p>
  <p><b>备注</b>：Accepted by Interspeech 2022</p>
  <p><b>关键词</b>：Recent deep learning, speech enhancement, significant performance degradation, fast and low-complexity, speech enhancement task</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent deep learning models have achieved high performance in speech
enhancement; however, it is still challenging to obtain a fast and
low-complexity model without significant performance degradation. Previous
knowledge distillation studies on speech enhancement could not solve this
problem because their output distillation methods do not fit the speech
enhancement task in some aspects. In this study, we propose multi-view
attention transfer (MV-AT), a feature-based distillation, to obtain efficient
speech enhancement models in the time domain. Based on the multi-view features
extraction model, MV-AT transfers multi-view knowledge of the teacher network
to the student network without additional parameters. The experimental results
show that the proposed method consistently improved the performance of student
models of various sizes on the Valentini and deep noise suppression (DNS)
datasets. MANNER-S-8.1GF with our proposed method, a lightweight model for
efficient deployment, achieved 15.4x and 4.71x fewer parameters and
floating-point operations (FLOPs), respectively, compared to the baseline model
with similar performance.</p>
  </details>
</details>
<details>
  <summary>15. <b>标题：High-quality Task Division for Large-scale Entity Alignment</b></summary>
  <p><b>编号</b>：[47]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10366</p>
  <p><b>作者</b>：Bing Liu,  Wen Hua,  Guido Zuccon,  Genghong Zhao,  Xia Zhang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Entity Alignment, step for Knowledge, Knowledge Graph, real-world objects, key step</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Entity Alignment (EA) aims to match equivalent entities that refer to the
same real-world objects and is a key step for Knowledge Graph (KG) fusion. Most
neural EA models cannot be applied to large-scale real-life KGs due to their
excessive consumption of GPU memory and time. One promising solution is to
divide a large EA task into several subtasks such that each subtask only needs
to match two small subgraphs of the original KGs. However, it is challenging to
divide the EA task without losing effectiveness. Existing methods display low
coverage of potential mappings, insufficient evidence in context graphs, and
largely differing subtask sizes.
In this work, we design the DivEA framework for large-scale EA with
high-quality task division. To include in the EA subtasks a high proportion of
the potential mappings originally present in the large EA task, we devise a
counterpart discovery method that exploits the locality principle of the EA
task and the power of trained EA models. Unique to our counterpart discovery
method is the explicit modelling of the chance of a potential mapping. We also
introduce an evidence passing mechanism to quantify the informativeness of
context entities and find the most informative context graphs with flexible
control of the subtask size. Extensive experiments show that DivEA achieves
higher EA performance than alternative state-of-the-art solutions.</p>
  </details>
</details>
<details>
  <summary>16. <b>标题：Scaling Up Dynamic Graph Representation Learning via Spiking Neural  Networks</b></summary>
  <p><b>编号</b>：[48]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10364</p>
  <p><b>作者</b>：Jintang Li,  Zhouxin Yu,  Zulun Zhu,  Liang Chen,  Qi Yu,  Zibin Zheng,  Sheng Tian,  Ruofan Wu,  Changhua Meng</p>
  <p><b>备注</b>：Preprint; Code available at this https URL</p>
  <p><b>关键词</b>：temporal graphs, temporal, graph representation learning, dynamic graph representation, Recent years</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent years have seen a surge in research on dynamic graph representation
learning, which aims to model temporal graphs that are dynamic and evolving
constantly over time. However, current work typically models graph dynamics
with recurrent neural networks (RNNs), making them suffer seriously from
computation and memory overheads on large temporal graphs. So far, scalability
of dynamic graph representation learning on large temporal graphs remains one
of the major challenges. In this paper, we present a scalable framework, namely
SpikeNet, to efficiently capture the temporal and structural patterns of
temporal graphs. We explore a new direction in that we can capture the evolving
dynamics of temporal graphs with spiking neural networks (SNNs) instead of
RNNs. As a low-power alternative to RNNs, SNNs explicitly model graph dynamics
as spike trains of neuron populations and enable spike-based propagation in an
efficient way. Experiments on three large real-world temporal graph datasets
demonstrate that SpikeNet outperforms strong baselines on the temporal node
classification task with lower computational costs. Particularly, SpikeNet
generalizes to a large temporal graph (2M nodes and 13M edges) with
significantly fewer parameters and computation overheads. Our code is publicly
available at this https URL</p>
  </details>
</details>
<details>
  <summary>17. <b>标题：Real-world-robustness of tree-based classifiers</b></summary>
  <p><b>编号</b>：[51]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10354</p>
  <p><b>作者</b>：Christoph Schweimer,  Sebastian Scher</p>
  <p><b>备注</b>：6 pages, 3 figures</p>
  <p><b>关键词</b>：gained widespread attention, gained widespread, widespread attention, tree-based classifiers, classifiers</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The concept of trustworthy AI has gained widespread attention lately. One of
the aspects relevant to trustworthy AI is robustness of ML models. In this
study, we show how to compute the recently introduced measure of
real-world-robustness - a measure for robustness against naturally occurring
distortions of input data - for tree-based classifiers. The original method for
computing real-world-robustness works for all black box classifiers, but is
only an approximation. Here we show how real-world-robustness, under the
assumption that the natural distortions are given by multivariate normal
distributions, can be exactly computed for tree-based classifiers.</p>
  </details>
</details>
<details>
  <summary>18. <b>标题：FORBID: Fast Overlap Removal By stochastic gradIent Descent for Graph  Drawing</b></summary>
  <p><b>编号</b>：[56]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10334</p>
  <p><b>作者</b>：Loann Giovannangeli,  Frederic Lalanne,  Romain Giot,  Romain Bourqui</p>
  <p><b>备注</b>：Appears in the Proceedings of the 30th International Symposium on Graph Drawing and Network Visualization (GD 2022)</p>
  <p><b>关键词</b>：tools often represent, graph visualization tools, graph drawing algorithms, visualization tools, graph drawing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>While many graph drawing algorithms consider nodes as points, graph
visualization tools often represent them as shapes. These shapes support the
display of information such as labels or encode various data with size or
color. However, they can create overlaps between nodes which hinder the
exploration process by hiding parts of the information. It is therefore of
utmost importance to remove these overlaps to improve graph visualization
readability. If not handled by the layout process, Overlap Removal (OR)
algorithms have been proposed as layout post-processing. As graph layouts
usually convey information about their topology, it is important that OR
algorithms preserve them as much as possible. We propose a novel algorithm that
models OR as a joint stress and scaling optimization problem, and leverages
efficient stochastic gradient descent. This approach is compared with
state-of-the-art algorithms, and several quality metrics demonstrate its
efficiency to quickly remove overlaps while retaining the initial layout
structures.</p>
  </details>
</details>
<details>
  <summary>19. <b>标题：Mix-Pooling Strategy for Attention Mechanism</b></summary>
  <p><b>编号</b>：[59]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10322</p>
  <p><b>作者</b>：Shanshan Zhong,  Wushao Wen,  Jinghui Qin</p>
  <p><b>备注</b>：Work in progress</p>
  <p><b>关键词</b>：convolutional neural networks, global average pooling, effective self-attention modules, Recently many effective, computer vision</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recently many effective self-attention modules are proposed to boot the model
performance by exploiting the internal information of convolutional neural
networks in computer vision. In general, many previous works ignore considering
the design of the pooling strategy of the self-attention mechanism since they
adopt the global average pooling for granted, which hinders the further
improvement of the performance of the self-attention mechanism. However, we
empirically find and verify a phenomenon that the simple linear combination of
global max-pooling and global min-pooling can produce pooling strategies that
match or exceed the performance of global average pooling. Based on this
empirical observation, we propose a simple-yet-effective self-attention module
SPENet, which adopts a self-adaptive pooling strategy based on global
max-pooling and global min-pooling and a lightweight module for producing the
attention map. The effectiveness of SPENet is demonstrated by extensive
experiments on widely used benchmark datasets and popular self-attention
networks.</p>
  </details>
</details>
<details>
  <summary>20. <b>标题：Latent Neural Stochastic Differential Equations for Change Point  Detection</b></summary>
  <p><b>编号</b>：[60]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10317</p>
  <p><b>作者</b>：Artem Ryzhikov,  Mikhail Hushchyn,  Denis Derkach</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：change point detection, change point, point detection problem, point detection algorithms, locate an abrupt</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The purpose of change point detection algorithms is to locate an abrupt
change in the time evolution of a process. In this paper, we introduce an
application of latent neural stochastic differential equations for change point
detection problem. We demonstrate the detection capabilities and performance of
our model on a range of synthetic and real-world datasets and benchmarks. Most
of the studied scenarios show that the proposed algorithm outperforms the
state-of-the-art algorithms. We also discuss the strengths and limitations of
this approach and indicate directions for further improvements.</p>
  </details>
</details>
<details>
  <summary>21. <b>标题：Semi-supervised classification using a supervised autoencoder for  biomedical applications</b></summary>
  <p><b>编号</b>：[61]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10315</p>
  <p><b>作者</b>：Cyprien Gille,  Frederic Guyard,  Michel Barlaud</p>
  <p><b>备注</b>：9 pages</p>
  <p><b>关键词</b>：Fully Connected Neural, Connected Neural Network, biomedical applications, involving a supervised, paper we present</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper we present a new approach to solve semi-supervised
classification tasks for biomedical applications, involving a supervised
autoencoder network. We create a network architecture that encodes labels into
the latent space of an autoencoder, and define a global criterion combining
classification and reconstruction losses. We train the Semi-Supervised
AutoEncoder (SSAE) on labelled data using a double descent algorithm. Then, we
classify unlabelled samples using the learned network thanks to a softmax
classifier applied to the latent space which provides a classification
confidence score for each class.
We implemented our SSAE method using the PyTorch framework for the model,
optimizer, schedulers, and loss functions. We compare our semi-supervised
autoencoder method (SSAE) with classical semi-supervised methods such as Label
Propagation and Label Spreading, and with a Fully Connected Neural Network
(FCNN). Experiments show that the SSAE outperforms Label Propagation and
Spreading and the Fully Connected Neural Network both on a synthetic dataset
and on two real-world biological datasets.</p>
  </details>
</details>
<details>
  <summary>22. <b>标题：BigBraveBN: algorithm of structural learning for bayesian networks with  a large number of nodes</b></summary>
  <p><b>编号</b>：[62]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10312</p>
  <p><b>作者</b>：Yury Kaminsky,  Irina Deeva</p>
  <p><b>备注</b>：The article contains 10 pages and 10 figures</p>
  <p><b>关键词</b>：Bayesian networks, learning Bayesian networks, number of nodes, large Bayesian Networks, Bayesian</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Learning a Bayesian network is an NP-hard problem and with an increase in the
number of nodes, classical algorithms for learning the structure of Bayesian
networks become inefficient. In recent years, some methods and algorithms for
learning Bayesian networks with a high number of nodes (more than 50) were
developed. But these solutions have their disadvantages, for instance, they
only operate one type of data (discrete or continuous) or their algorithm has
been created to meet a specific nature of data (medical, social, etc.). The
article presents a BigBraveBN algorithm for learning large Bayesian Networks
with a high number of nodes (over 100). The algorithm utilizes the Brave
coefficient that measures the mutual occurrence of instances in several groups.
To form these groups, we use the method of nearest neighbours based on the
Mutual information (MI) measure. In the experimental part of the article, we
compare the performance of BigBraveBN to other existing solutions on multiple
data sets both discrete and continuous. The experimental part also represents
tests on real data. The aforementioned experimental results demonstrate the
efficiency of the BigBraveBN algorithm in structure learning of Bayesian
Networks.</p>
  </details>
</details>
<details>
  <summary>23. <b>标题：Efficient Utility Function Learning for Multi-Objective Parameter  Optimization with Prior Knowledge</b></summary>
  <p><b>编号</b>：[67]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10300</p>
  <p><b>作者</b>：Farha A. Khan,  Jörg P. Dietrich,  Christian Wirth</p>
  <p><b>备注</b>：16 pages</p>
  <p><b>关键词</b>：complete Pareto front, utility function, Pareto front, complete Pareto, utility function interactively</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The current state-of-the-art in multi-objective optimization assumes either a
given utility function, learns a utility function interactively or tries to
determine the complete Pareto front, requiring a post elicitation of the
preferred result. However, result elicitation in real world problems is often
based on implicit and explicit expert knowledge, making it difficult to define
a utility function, whereas interactive learning or post elicitation requires
repeated and expensive expert involvement. To mitigate this, we learn a utility
function offline, using expert knowledge by means of preference learning. In
contrast to other works, we do not only use (pairwise) result preferences, but
also coarse information about the utility function space. This enables us to
improve the utility function estimate, especially when using very few results.
Additionally, we model the occurring uncertainties in the utility function
learning task and propagate them through the whole optimization chain. Our
method to learn a utility function eliminates the need of repeated expert
involvement while still leading to high-quality results. We show the sample
efficiency and quality gains of the proposed method in 4 domains, especially in
cases where the surrogate utility function is not able to exactly capture the
true expert utility function. We also show that to obtain good results, it is
important to consider the induced uncertainties and analyze the effect of
biased samples, which is a common problem in real world domains.</p>
  </details>
</details>
<details>
  <summary>24. <b>标题：Efficient Planning in a Compact Latent Action Space</b></summary>
  <p><b>编号</b>：[73]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10291</p>
  <p><b>作者</b>：Zhengyao Jiang,  Tianjun Zhang,  Michael Janner,  Yueying Li,  Tim Rocktäschel,  Edward Grefenstette,  Yuandong Tian</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：shown great potential, open challenge due, planning-based sequence modelling, shown great, great potential</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>While planning-based sequence modelling methods have shown great potential in
continuous control, scaling them to high-dimensional state-action sequences
remains an open challenge due to the high computational complexity and innate
difficulty of planning in high-dimensional spaces. We propose the Trajectory
Autoencoding Planner (TAP), a planning-based sequence modelling RL method that
scales to high state-action dimensionalities. Using a state-conditional
Vector-Quantized Variational Autoencoder (VQ-VAE), TAP models the conditional
distribution of the trajectories given the current state. When deployed as an
RL agent, TAP avoids planning step-by-step in a high-dimensional continuous
action space but instead looks for the optimal latent code sequences by beam
search. Unlike $O(D^3)$ complexity of Trajectory Transformer, TAP enjoys
constant $O(C)$ planning computational complexity regarding state-action
dimensionality $D$. Our empirical evaluation also shows the increasingly strong
performance of TAP with the growing dimensionality. For Adroit robotic hand
manipulation tasks with high state and action dimensionality, TAP surpasses
existing model-based methods, including TT, with a large margin and also beats
strong model-free actor-critic baselines.</p>
  </details>
</details>
<details>
  <summary>25. <b>标题：Deterministic Graph-Walking Program Mining</b></summary>
  <p><b>编号</b>：[74]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10290</p>
  <p><b>作者</b>：Peter Belcak,  Roger Wattenhofer</p>
  <p><b>备注</b>：Paper accepted for an oral presentation at Advanced Data Mining and Applications (ADMA) 2022. 15 pages, 3 figures</p>
  <p><b>关键词</b>：structures admit representations, separate entities comprising, graph structures admit, comprising the data, structures admit</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Owing to their versatility, graph structures admit representations of
intricate relationships between the separate entities comprising the data. We
formalise the notion of connection between two vertex sets in terms of edge and
vertex features by introducing graph-walking programs. We give two algorithms
for mining of deterministic graph-walking programs that yield programs in the
order of increasing length. These programs characterise linear long-distance
relationships between the given two vertex sets in the context of the whole
graph.</p>
  </details>
</details>
<details>
  <summary>26. <b>标题：A Twitter-Driven Deep Learning Mechanism for the Determination of  Vehicle Hijacking Spots in Cities</b></summary>
  <p><b>编号</b>：[78]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10280</p>
  <p><b>作者</b>：Taahir Aiyoob Patel,  Clement N. Nyirenda</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：leading crimes, South Africa, Vehicle hijacking, Feed-forward Neural Network, Bidirectional Encoder Representations</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Vehicle hijacking is one of the leading crimes in many cities. For instance,
in South Africa, drivers must constantly remain vigilant on the road in order
to ensure that they do not become hijacking victims. This work is aimed at
developing a map depicting hijacking spots in a city by using Twitter data.
Tweets, which include the keyword "hijacking", are obtained in a designated
city of Cape Town, in this work. In order to extract relevant tweets, these
tweets are analyzed by using the following machine learning techniques: 1) a
Multi-layer Feed-forward Neural Network (MLFNN); 2) Convolutional Neural
Network; and Bidirectional Encoder Representations from Transformers (BERT).
Through training and testing, CNN achieved an accuracy of 99.66%, while MLFNN
and BERT achieve accuracies of 98.99% and 73.99% respectively. In terms of
Recall, Precision and F1-score, CNN also achieved the best results. Therefore,
CNN was used for the identification of relevant tweets. The relevant reports
that it generates are visually presented on a points map of the City of Cape
Town. This work used a small dataset of 426 tweets. In future, the use of
evolutionary computation will be explored for purposes of optimizing the deep
learning models. A mobile application is under development to make this
information usable by the general public.</p>
  </details>
</details>
<details>
  <summary>27. <b>标题：Defensive Distillation based Adversarial Attacks Mitigation Method for  Channel Estimation using Deep Learning Models in Next-Generation Wireless  Networks</b></summary>
  <p><b>编号</b>：[79]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10279</p>
  <p><b>作者</b>：Ferhat Ozgur Catak,  Murat Kuzlu,  Evren Catak,  Umit Cali,  Ozgur Guler</p>
  <p><b>备注</b>：13 Pages</p>
  <p><b>关键词</b>：forthcoming cellular systems, Future wireless networks, Future wireless, connecting billions, NextG networks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Future wireless networks (5G and beyond) are the vision of forthcoming
cellular systems, connecting billions of devices and people together. In the
last decades, cellular networks have been dramatically growth with advanced
telecommunication technologies for high-speed data transmission, high cell
capacity, and low latency. The main goal of those technologies is to support a
wide range of new applications, such as virtual reality, metaverse, telehealth,
online education, autonomous and flying vehicles, smart cities, smart grids,
advanced manufacturing, and many more. The key motivation of NextG networks is
to meet the high demand for those applications by improving and optimizing
network functions. Artificial Intelligence (AI) has a high potential to achieve
these requirements by being integrated in applications throughout all layers of
the network. However, the security concerns on network functions of NextG using
AI-based models, i.e., model poising, have not been investigated deeply.
Therefore, it needs to design efficient mitigation techniques and secure
solutions for NextG networks using AI-based methods. This paper proposes a
comprehensive vulnerability analysis of deep learning (DL)-based channel
estimation models trained with the dataset obtained from MATLAB's 5G toolbox
for adversarial attacks and defensive distillation-based mitigation methods.
The adversarial attacks produce faulty results by manipulating trained DL-based
models for channel estimation in NextG networks, while making models more
robust against any attacks through mitigation methods. This paper also presents
the performance of the proposed defensive distillation mitigation method for
each adversarial attack against the channel estimation model. The results
indicated that the proposed mitigation method can defend the DL-based channel
estimation models against adversarial attacks in NextG networks.</p>
  </details>
</details>
<details>
  <summary>28. <b>标题：Practical Vertical Federated Learning with Unsupervised Representation  Learning</b></summary>
  <p><b>编号</b>：[80]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10278</p>
  <p><b>作者</b>：Zhaomin Wu,  Qinbin Li,  Bingsheng He</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：witnessed data silos, privacy recently increase, Federated learning, recently increase, Vertical federated learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As societal concerns on data privacy recently increase, we have witnessed
data silos among multiple parties in various applications. Federated learning
emerges as a new learning paradigm that enables multiple parties to
collaboratively train a machine learning model without sharing their raw data.
Vertical federated learning, where each party owns different features of the
same set of samples and only a single party has the label, is an important and
challenging topic in federated learning. Communication costs among different
parties have been a major hurdle for practical vertical learning systems. In
this paper, we propose a novel communication-efficient vertical federated
learning algorithm named FedOnce, which requires only one-shot communication
among parties. To improve model accuracy and provide privacy guarantee, FedOnce
features unsupervised learning representations in the federated setting and
privacy-preserving techniques based on moments accountant. The comprehensive
experiments on 10 datasets demonstrate that FedOnce achieves close performance
compared to state-of-the-art vertical federated learning algorithms with much
lower communication costs. Meanwhile, our privacy-preserving technique
significantly outperforms the state-of-the-art approaches under the same
privacy budget.</p>
  </details>
</details>
<details>
  <summary>29. <b>标题：Long-Short History of Gradients is All You Need: Detecting Malicious and  Unreliable Clients in Federated Learning</b></summary>
  <p><b>编号</b>：[82]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10273</p>
  <p><b>作者</b>：Ashish Gupta,  Tie Luo,  Mao V. Ngo,  Sajal K. Das</p>
  <p><b>备注</b>：European Symposium on Research in Computer Security (ESORICS) 2022</p>
  <p><b>关键词</b>：machine learning model, offers a framework, distributed fashion, fashion while preserving, preserving privacy</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Federated learning offers a framework of training a machine learning model in
a distributed fashion while preserving privacy of the participants. As the
server cannot govern the clients' actions, nefarious clients may attack the
global model by sending malicious local gradients. In the meantime, there could
also be unreliable clients who are benign but each has a portion of low-quality
training data (e.g., blur or low-resolution images), thus may appearing similar
as malicious clients. Therefore, a defense mechanism will need to perform a
three-fold differentiation which is much more challenging than the conventional
(two-fold) case. This paper introduces MUD-HoG, a novel defense algorithm that
addresses this challenge in federated learning using long-short history of
gradients, and treats the detected malicious and unreliable clients
differently. Not only this, but we can also distinguish between targeted and
untargeted attacks among malicious clients, unlike most prior works which only
consider one type of the attacks. Specifically, we take into account
sign-flipping, additive-noise, label-flipping, and multi-label-flipping
attacks, under a non-IID setting. We evaluate MUD-HoG with six state-of-the-art
methods on two datasets. The results show that MUD-HoG outperforms all of them
in terms of accuracy as well as precision and recall, in the presence of a
mixture of multiple (four) types of attackers as well as unreliable clients.
Moreover, unlike most prior works which can only tolerate a low population of
harmful users, MUD-HoG can work with and successfully detect a wide range of
malicious and unreliable clients - up to 47.5% and 10%, respectively, of the
total population. Our code is open-sourced at
this https URL.</p>
  </details>
</details>
<details>
  <summary>30. <b>标题：To show or not to show: Redacting sensitive text from videos of  electronic displays</b></summary>
  <p><b>编号</b>：[84]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10270</p>
  <p><b>作者</b>：Abhishek Mukhopadhyay,  Shubham Agarwal,  Patrick Dylan Zwick,  Pradipta Biswas</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：increasing prevalence, maintain the privacy, Google Cloud Vision, video recordings, OCR</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>With the increasing prevalence of video recordings there is a growing need
for tools that can maintain the privacy of those recorded. In this paper, we
define an approach for redacting personally identifiable text from videos using
a combination of optical character recognition (OCR) and natural language
processing (NLP) techniques. We examine the relative performance of this
approach when used with different OCR models, specifically Tesseract and the
OCR system from Google Cloud Vision (GCV). For the proposed approach the
performance of GCV, in both accuracy and speed, is significantly higher than
Tesseract. Finally, we explore the advantages and disadvantages of both models
in real-world applications.</p>
  </details>
</details>
<details>
  <summary>31. <b>标题：A semantic web approach to uplift decentralized household energy data</b></summary>
  <p><b>编号</b>：[87]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10265</p>
  <p><b>作者</b>：Jiantao Wu,  Fabrizio Orlandi,  Tarek AlSkaif,  Declan O'Sullivan,  Soumyabrata Dev</p>
  <p><b>备注</b>：Published in Sustainable Energy, Grids and Networks (SEGAN)</p>
  <p><b>关键词</b>：electric energy consumption, electric vehicles, achieve energy sustainability, energy system comprised, home appliances</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In a decentralized household energy system comprised of various devices such
as home appliances, electric vehicles, and solar panels, end-users are able to
dig deeper into the system's details and further achieve energy sustainability
if they are presented with data on the electric energy consumption and
production at the granularity of the device. However, many databases in this
field are siloed from other domains, including solely information pertaining to
energy. This may result in the loss of information (\textit{e.g.} weather) on
each device's energy use. Meanwhile, a large number of these datasets have been
extensively used in computational modeling techniques such as machine learning
models. While such computational approaches achieve great accuracy and
performance by concentrating only on a local view of datasets, model
reliability cannot be guaranteed since such models are very vulnerable to data
input fluctuations when information omission is taken into account. This
article tackles the data isolation issue in the field of smart energy systems
by examining Semantic Web methods on top of a household energy system. We offer
an ontology-based approach for managing decentralized data at the device-level
resolution in a system. As a consequence, the scope of the data associated with
each device may easily be expanded in an interoperable manner throughout the
Web, and additional information, such as weather, can be obtained from the Web,
provided that the data is organized according to W3C standards.</p>
  </details>
</details>
<details>
  <summary>32. <b>标题：Using Large Language Models to Simulate Multiple Humans</b></summary>
  <p><b>编号</b>：[88]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10264</p>
  <p><b>作者</b>：Gati Aher,  Rosa I. Arriaga,  Adam Tauman Kalai</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：language, language model, large language model, large language, model</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose a method for using a large language model, such as GPT-3, to
simulate responses of different humans in a given context. We test our method
by attempting to reproduce well-established economic, psycholinguistic, and
social experiments. The method requires prompt templates for each experiment.
Simulations are run by varying the (hypothetical) subject details such as name
and analyzing the text generated by the language model. We validate our
methodology by using GPT-3, to show that it is possible to simulate responses
of different people and that their responses are consistent with prior human
studies from the literature. We find that the distributions generated by larger
language models better align with prior experimental results, suggesting a
trend that future language models may be used for even more faithful
simulations of human responses. Our use of a language model for simulation is
contrasted with anthropomorphic views of a language model as having its own
behavior.</p>
  </details>
</details>
<details>
  <summary>33. <b>标题：Meta-Learning Online Control for Linear Dynamical Systems</b></summary>
  <p><b>编号</b>：[89]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10259</p>
  <p><b>作者</b>：Deepan Muthirayan,  Dileep Kalathil,  Pramod P. Khargonekar</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：meta-learning online control, online control algorithm, online control, tasks, meta-learning online</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we consider the problem of finding a meta-learning online
control algorithm that can learn across the tasks when faced with a sequence of
$N$ (similar) control tasks. Each task involves controlling a linear dynamical
system for a finite horizon of $T$ time steps. The cost function and system
noise at each time step are adversarial and unknown to the controller before
taking the control action. Meta-learning is a broad approach where the goal is
to prescribe an online policy for any new unseen task exploiting the
information from other tasks and the similarity between the tasks. We propose a
meta-learning online control algorithm for the control setting and characterize
its performance by \textit{meta-regret}, the average cumulative regret across
the tasks. We show that when the number of tasks are sufficiently large, our
proposed approach achieves a meta-regret that is smaller by a factor $D/D^{*}$
compared to an independent-learning online control algorithm which does not
perform learning across the tasks, where $D$ is a problem constant and $D^{*}$
is a scalar that decreases with increase in the similarity between tasks. Thus,
when the sequence of tasks are similar the regret of the proposed meta-learning
online control is significantly lower than that of the naive approaches without
meta-learning. We also present experiment results to demonstrate the superior
performance achieved by our meta-learning algorithm.</p>
  </details>
</details>
<details>
  <summary>34. <b>标题：On the non-efficient PAC learnability of acyclic conjunctive queries</b></summary>
  <p><b>编号</b>：[91]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10255</p>
  <p><b>作者</b>：Balder ten Cate,  Maurice Funk,  Jean Christoph Jung,  Carsten Lutz</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：serves three purposes, efficiently PAC learnable, note serves, provide a self-contained, self-contained exposition</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This note serves three purposes: (i) we provide a self-contained exposition
of the fact that conjunctive queries are not efficiently learnable in the
Probably-Approximately-Correct (PAC) model, paying clear attention to the
complicating fact that this concept class lacks the polynomial-size fitting
property, a property that is tacitly assumed in much of the computational
learning theory literature; (ii) we establish a strong negative PAC
learnability result that applies to many restricted classes of conjunctive
queries (CQs), including acyclic CQs for a wide range of notions of
"acyclicity"; (iii) we show that CQs are efficiently PAC learnable with
membership queries.</p>
  </details>
</details>
<details>
  <summary>35. <b>标题：An Exploratory Study of Tweets about the SARS-CoV-2 Omicron Variant:  Insights from Sentiment Analysis, Language Interpretation, Source Tracking,  Type Classification, and Embedded URL Detection</b></summary>
  <p><b>编号</b>：[93]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10252</p>
  <p><b>作者</b>：Nirmalya Thakur,  Chia Y. Han</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：generating Big Data, continuously generating Big, Big Data, globally dominant variant, Omicron variant</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper presents the findings of an exploratory study on the continuously
generating Big Data on Twitter related to the sharing of information, news,
views, opinions, ideas, feedback, and experiences about the COVID-19 pandemic,
with a specific focus on the Omicron variant, which is the globally dominant
variant of SARS-CoV-2 at this time. A total of 12028 tweets about the Omicron
variant were studied, and the specific characteristics of tweets that were
analyzed include - sentiment, language, source, type, and embedded URLs. The
findings of this study are manifold. First, from sentiment analysis, it was
observed that 50.5% of tweets had a neutral emotion. The other emotions - bad,
good, terrible, and great were found in 15.6%, 14.0%, 12.5%, and 7.5% of the
tweets, respectively. Second, the findings of language interpretation showed
that 65.9% of the tweets were posted in English. It was followed by Spanish,
French, Italian, and other languages. Third, the findings from source tracking
showed that Twitter for Android was associated with 35.2% of tweets. It was
followed by Twitter Web App, Twitter for iPhone, Twitter for iPad, and other
sources. Fourth, studying the type of tweets revealed that retweets accounted
for 60.8% of the tweets, it was followed by original tweets and replies that
accounted for 19.8% and 19.4% of the tweets, respectively. Fifth, in terms of
embedded URL analysis, the most common domain embedded in the tweets was found
to be this http URL, which was followed by this http URL, this http URL, and other
domains. Finally, to support similar research in this field, we have developed
a Twitter dataset that comprises more than 500,000 tweets about the SARS-CoV-2
omicron variant since the first detected case of this variant on November 24,
2021.</p>
  </details>
</details>
<details>
  <summary>36. <b>标题：Multi-Task Learning for Depression Detection in Dialogs</b></summary>
  <p><b>编号</b>：[95]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10250</p>
  <p><b>作者</b>：Chuyuan Li (SEMAGRAMME, LORIA),  Chloé Braud (IRIT),  Maxime Amblard (SEMAGRAMME, LORIA)</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：people communicate, mental illness, illness that impacts, Depression, allegedly</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Depression is a serious mental illness that impacts the way people
communicate, especially through their emotions, and, allegedly, the way they
interact with others. This work examines depression signals in dialogs, a less
studied setting that suffers from data sparsity. We hypothesize that depression
and emotion can inform each other, and we propose to explore the influence of
dialog structure through topic and dialog act prediction. We investigate a
Multi-Task Learning (MTL) approach, where all tasks mentioned above are learned
jointly with dialog-tailored hierarchical modeling. We experiment on the DAIC
and DailyDialog corpora-both contain dialogs in English-and show important
improvements over state-ofthe-art on depression detection (at best 70.6% F 1),
which demonstrates the correlation of depression with emotion and dialog
organization and the power of MTL to leverage information from different
sources.</p>
  </details>
</details>
<details>
  <summary>37. <b>标题：Composing RNNs and FSTs for Small Data: Recovering Missing Characters in  Old Hawaiian Text</b></summary>
  <p><b>编号</b>：[97]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10248</p>
  <p><b>作者</b>：Oiwi Parker Jones,  Brendan Shillingford</p>
  <p><b>备注</b>：This paper originally appeared in a NeurIPS Workshop in 2018: IRASL - Interpretability and Robustness in Audio, Speech, and Language. It builds on a shorter paper that appeared in the Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing (EMNLP). See acknowledgements for details</p>
  <p><b>关键词</b>：modern Hawaiian orthography, Hawaiian orthography employs, orthography employs characters, older writing system, modern Hawaiian</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In contrast to the older writing system of the 19th century, modern Hawaiian
orthography employs characters for long vowels and glottal stops. These extra
characters account for about one-third of the phonemes in Hawaiian, so
including them makes a big difference to reading comprehension and
pronunciation. However, transliterating between older and newer texts is a
laborious task when performed manually. We introduce two related methods to
help solve this transliteration problem automatically, given that there were
not enough data to train an end-to-end deep learning model. One method is
implemented, end-to-end, using finite state transducers (FSTs). The other is a
hybrid deep learning approach which approximately composes an FST with a
recurrent neural network (RNN). We find that the hybrid approach outperforms
the end-to-end FST by partitioning the original problem into one part that can
be modelled by hand, using an FST, and into another part, which is easily
solved by an RNN trained on the available data.</p>
  </details>
</details>
<details>
  <summary>38. <b>标题：Generalized Attention Mechanism and Relative Position for Transformer</b></summary>
  <p><b>编号</b>：[98]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10247</p>
  <p><b>作者</b>：R. V. R. Pandya</p>
  <p><b>备注</b>：6 pages</p>
  <p><b>关键词</b>：generalized attention mechanism, propose generalized attention, GAM, Vaswani, generalized attention</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we propose generalized attention mechanism (GAM) by first
suggesting a new interpretation for self-attention mechanism of Vaswani et al.
. Following the interpretation, we provide description for different variants
of attention mechanism which together form GAM. Further, we propose a new
relative position representation within the framework of GAM. This
representation can be easily utilized for cases in which elements next to each
other in input sequence can be at random locations in actual dataset/corpus.</p>
  </details>
</details>
<details>
  <summary>39. <b>标题：SDBERT: SparseDistilBERT, a faster and smaller BERT model</b></summary>
  <p><b>编号</b>：[99]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10246</p>
  <p><b>作者</b>：Devaraju Vinoda,  Pawan Kumar Yadav</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：transformer architecture called, architecture called, work we introduce, transformer architecture, sparse attention</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this work we introduce a new transformer architecture called
SparseDistilBERT (SDBERT), which is a combination of sparse attention and
knowledge distillantion (KD). We implemented sparse attention mechanism to
reduce quadratic dependency on input length to linear. In addition to reducing
computational complexity of the model, we used knowledge distillation (KD). We
were able to reduce the size of BERT model by 60% while retaining 97%
performance and it only took 40% of time to train.</p>
  </details>
</details>
<details>
  <summary>40. <b>标题：When BERT Fails -- The Limits of EHR Classification</b></summary>
  <p><b>编号</b>：[100]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10245</p>
  <p><b>作者</b>：Augusto Garcia-Agundez,  Carsten Eickhoff</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：text representation learners, decision support tasks, powerful text representation, clinical decision support, Transformers are powerful</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Transformers are powerful text representation learners, useful for all kinds
of clinical decision support tasks. Although they outperform baselines on
readmission prediction, they are not infallible. Here, we look into one such
failure case, and report patterns that lead to inferior predictive performance.</p>
  </details>
</details>
<details>
  <summary>41. <b>标题：An anomaly detection approach for backdoored neural networks: face  recognition as a case study</b></summary>
  <p><b>编号</b>：[107]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10231</p>
  <p><b>作者</b>：Alexander Unnervik,  Sébastien Marcel</p>
  <p><b>备注</b>：Accepted at Biosig 2022, 8 pages, 4 figures</p>
  <p><b>关键词</b>：jeopardizing proper behavior, embed functionality jeopardizing, functionality jeopardizing proper, machine learning, jeopardizing proper</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Backdoor attacks allow an attacker to embed functionality jeopardizing proper
behavior of any algorithm, machine learning or not. This hidden functionality
can remain inactive for normal use of the algorithm until activated by the
attacker. Given how stealthy backdoor attacks are, consequences of these
backdoors could be disastrous if such networks were to be deployed for
applications as critical as border or access control. In this paper, we propose
a novel backdoored network detection method based on the principle of anomaly
detection, involving access to the clean part of the training data and the
trained network. We highlight its promising potential when considering various
triggers, locations and identity pairs, without the need to make any
assumptions on the nature of the backdoor and its setup. We test our method on
a novel dataset of backdoored networks and report detectability results with
perfect scores.</p>
  </details>
</details>
<details>
  <summary>42. <b>标题：Survey of NLP in Pharmacology: Methodology, Tasks, Resources, Knowledge,  and Tools</b></summary>
  <p><b>编号</b>：[108]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10228</p>
  <p><b>作者</b>：Dimitar Trajanov,  Vangel Trajkovski,  Makedonka Dimitrieva,  Jovana Dobreva,  Milos Jovanovik,  Matej Klemen,  Aleš Žagar,  Marko Robnik-Šikonja</p>
  <p><b>备注</b>：35 pages, 2 figures, 7 tables</p>
  <p><b>关键词</b>：Natural language processing, applies information technologies, Natural language, human language, artificial intelligence</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Natural language processing (NLP) is an area of artificial intelligence that
applies information technologies to process the human language, understand it
to a certain degree, and use it in various applications. This area has rapidly
developed in the last few years and now employs modern variants of deep neural
networks to extract relevant patterns from large text corpora. The main
objective of this work is to survey the recent use of NLP in the field of
pharmacology. As our work shows, NLP is a highly relevant information
extraction and processing approach for pharmacology. It has been used
extensively, from intelligent searches through thousands of medical documents
to finding traces of adversarial drug interactions in social media. We split
our coverage into five categories to survey modern NLP methodology, commonly
addressed tasks, relevant textual data, knowledge bases, and useful programming
libraries. We split each of the five categories into appropriate subcategories,
describe their main properties and ideas, and summarize them in a tabular form.
The resulting survey presents a comprehensive overview of the area, useful to
practitioners and interested observers.</p>
  </details>
</details>
<details>
  <summary>43. <b>标题：One Model, Any CSP: Graph Neural Networks as Fast Global Search  Heuristics for Constraint Satisfaction</b></summary>
  <p><b>编号</b>：[109]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10227</p>
  <p><b>作者</b>：Jan Tönshoff,  Berke Kisin,  Jakob Lindner,  Martin Grohe</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Constraint Satisfaction Problem, Neural Network architecture, Graph Neural Network, Satisfaction Problem, Constraint Satisfaction</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose a universal Graph Neural Network architecture which can be trained
as an end-2-end search heuristic for any Constraint Satisfaction Problem (CSP).
Our architecture can be trained unsupervised with policy gradient descent to
generate problem specific heuristics for any CSP in a purely data driven
manner. The approach is based on a novel graph representation for CSPs that is
both generic and compact and enables us to process every possible CSP instance
with one GNN, regardless of constraint arity, relations or domain size. Unlike
previous RL-based methods, we operate on a global search action space and allow
our GNN to modify any number of variables in every step of the stochastic
search. This enables our method to properly leverage the inherent parallelism
of GNNs. We perform a thorough empirical evaluation where we learn heuristics
for well known and important CSPs from random data, including graph coloring,
MaxCut, 3-SAT and MAX-k-SAT. Our approach outperforms prior approaches for
neural combinatorial optimization by a substantial margin. It can compete with,
and even improve upon, conventional search heuristics on test instances that
are several orders of magnitude larger and structurally more complex than those
seen during training.</p>
  </details>
</details>
<details>
  <summary>44. <b>标题：Friendly Noise against Adversarial Noise: A Powerful Defense against  Data Poisoning Attacks</b></summary>
  <p><b>编号</b>：[111]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10224</p>
  <p><b>作者</b>：Tian Yu Liu,  Yu Yang,  Baharan Mirzasoleiman</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：data poisoning attacks, test-time data, poisoning attacks modify, poisoning attacks, modify a subset</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A powerful category of data poisoning attacks modify a subset of training
examples by small adversarial perturbations to change the prediction of certain
test-time data. Existing defense mechanisms are not desirable to deploy in
practice, as they often drastically harm the generalization performance, or are
attack-specific and prohibitively slow to apply. Here, we propose a simple but
highly effective approach that unlike existing methods breaks various types of
poisoning attacks with the slightest drop in the generalization performance. We
make the key observation that attacks exploit sharp loss regions to craft
adversarial perturbations which can substantially alter examples' gradient or
representations under small perturbations. To break poisoning attacks, our
approach comprises two components: an optimized friendly noise that is
generated to maximally perturb examples without degrading the performance, and
a random varying noise component. The first component takes examples farther
away from the sharp loss regions, and the second component smooths out the loss
landscape. The combination of both components builds a very light-weight but
extremely effective defense against the most powerful triggerless targeted and
hidden-trigger backdoor poisoning attacks, including Gradient Matching,
Bulls-eye Polytope, and Sleeper Agent. We show that our friendly noise is
transferable to other architectures, and adaptive attacks cannot break our
defense due to its random noise component.</p>
  </details>
</details>
<details>
  <summary>45. <b>标题：LTE4G: Long-Tail Experts for Graph Neural Networks</b></summary>
  <p><b>编号</b>：[116]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10205</p>
  <p><b>作者</b>：Sukwon Yun,  Kibum Kim,  Kanghoon Yoon,  Chanyoung Park</p>
  <p><b>备注</b>：Accepted by CIKM 2022</p>
  <p><b>关键词</b>：Graph Neural Networks, Neural Networks, Existing Graph Neural, Graph Neural, node degree distribution</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Existing Graph Neural Networks (GNNs) usually assume a balanced situation
where both the class distribution and the node degree distribution are
balanced. However, in real-world situations, we often encounter cases where a
few classes (i.e., head class) dominate other classes (i.e., tail class) as
well as in the node degree perspective, and thus naively applying existing GNNs
eventually fall short of generalizing to the tail cases. Although recent
studies proposed methods to handle long-tail situations on graphs, they only
focus on either the class long-tailedness or the degree long-tailedness. In
this paper, we propose a novel framework for training GNNs, called Long-Tail
Experts for Graphs (LTE4G), which jointly considers the class long-tailedness,
and the degree long-tailedness for node classification. The core idea is to
assign an expert GNN model to each subset of nodes that are split in a balanced
manner considering both the class and degree long-tailedness. After having
trained an expert for each balanced subset, we adopt knowledge distillation to
obtain two class-wise students, i.e., Head class student and Tail class
student, each of which is responsible for classifying nodes in the head classes
and tail classes, respectively. We demonstrate that LTE4G outperforms a wide
range of state-of-the-art methods in node classification evaluated on both
manual and natural imbalanced graphs. The source code of LTE4G can be found at
this https URL.</p>
  </details>
</details>
<details>
  <summary>46. <b>标题：Learning Low Bending and Low Distortion Manifold Embeddings: Theory and  Applications</b></summary>
  <p><b>编号</b>：[119]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10193</p>
  <p><b>作者</b>：Juliane Braunsmann,  Marko Rajković,  Martin Rumpf,  Benedikt Wirth</p>
  <p><b>备注</b>：27 pages, 10 figures. This publication is an extended version of the previous conference proceeding presented at DiffCVML 2021</p>
  <p><b>关键词</b>：data, dimension reduction, reduction of high-dimensional, manifold, input data manifold</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Autoencoders, which consist of an encoder and a decoder, are widely used in
machine learning for dimension reduction of high-dimensional data. The encoder
embeds the input data manifold into a lower-dimensional latent space, while the
decoder represents the inverse map, providing a parametrization of the data
manifold by the manifold in latent space. A good regularity and structure of
the embedded manifold may substantially simplify further data processing tasks
such as cluster analysis or data interpolation. We propose and analyze a novel
regularization for learning the encoder component of an autoencoder: a loss
functional that prefers isometric, extrinsically flat embeddings and allows to
train the encoder on its own. To perform the training it is assumed that for
pairs of nearby points on the input manifold their local Riemannian distance
and their local Riemannian average can be evaluated. The loss functional is
computed via Monte Carlo integration with different sampling strategies for
pairs of points on the input manifold. Our main theorem identifies a geometric
loss functional of the embedding map as the $\Gamma$-limit of the
sampling-dependent loss functionals. Numerical tests, using image data that
encodes different explicitly given data manifolds, show that smooth manifold
embeddings into latent space are obtained. Due to the promotion of extrinsic
flatness, these embeddings are regular enough such that interpolation between
not too distant points on the manifold is well approximated by linear
interpolation in latent space as one possible postprocessing.</p>
  </details>
</details>
<details>
  <summary>47. <b>标题：BRIEF but Powerful: Byzantine-Robust and Privacy-Preserving Federated  Learning via Model Segmentation and Secure clustering</b></summary>
  <p><b>编号</b>：[132]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10161</p>
  <p><b>作者</b>：Rui Wang,  Xingkai Wang,  Huanhuan Chen,  Stjepan Picek,  Zhen Liu,  Kaitai Liang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Byzantine-robust Federated Learning, Federated Learning, accurate global model, extremely low attack, Byzantine-robust Federated</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Byzantine-robust Federated Learning (FL) aims to counter malicious clients
and to train an accurate global model while maintaining an extremely low attack
success rate. Most of the existing systems, however, are only robust in
honest/semi-honest majority settings. FLTrust (NDSS '21) extends the context to
the malicious majority for clients but with a strong restriction that the
server should be provided with an auxiliary dataset before training in order to
filter malicious inputs. Private FLAME/FLGUARD (USENIX '22) gives a solution to
guarantee both robustness and updates confidentiality in the semi-honest
majority context. It is so far impossible to balance the trade-off among
malicious context, robustness, and updates confidentiality. To tackle this
problem, we propose a novel Byzantine-robust and privacy-preserving FL system,
called BRIEF, to capture malicious minority and majority for server and client
sides. Specifically, based on the DBSCAN algorithm, we design a new method for
clustering via pairwise adjusted cosine similarity to boost the accuracy of the
clustering results. To thwart attacks of malicious majority, we develop an
algorithm called Model Segmentation, where local updates in the same cluster
are aggregated together, and the aggregations are sent back to corresponding
clients correctly. We also leverage multiple cryptographic tools to conduct
clustering tasks without sacrificing training correctness and updates
confidentiality. We present detailed security proof and empirical evaluation
along with convergence analysis for BRIEF. The experimental results demonstrate
that the testing accuracy of BRIEF is practically close to the FL baseline
(0.8% gap on average). At the same time, the attack success rate is around
0%-5%. We further optimize our design so that the communication overhead and
runtime can be decreased by {67%-89.17% and 66.05%-68.75%}, respectively.</p>
  </details>
</details>
<details>
  <summary>48. <b>标题：SoK: Machine Learning with Confidential Computing</b></summary>
  <p><b>编号</b>：[143]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10134</p>
  <p><b>作者</b>：Fan Mo,  Zahra Tarkhani,  Hamed Haddadi</p>
  <p><b>备注</b>：Survey paper</p>
  <p><b>关键词</b>：large attack surfaces, Machine Learning, topic to address, attack surfaces, critical topic</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Privacy and security challenges in Machine Learning (ML) have become a
critical topic to address, along with ML's pervasive development and the recent
demonstration of large attack surfaces. As a mature system-oriented approach,
confidential computing has been increasingly utilized in both academia and
industry to improve privacy and security in various ML scenarios. In this
paper, we systematize the findings on confidential computing-assisted ML
security and privacy techniques for providing i) confidentiality guarantees and
ii) integrity assurances. We further identify key challenges and provide
dedicated analyses of the limitations in existing Trusted Execution Environment
(TEE) systems for ML use cases. We discuss prospective works, including
grounded privacy definitions, partitioned ML executions, dedicated TEE designs
for ML, TEE-aware ML, and ML full pipeline guarantee. These potential solutions
can help achieve a much strong TEE-enabled ML for privacy guarantees without
introducing computation and system costs.</p>
  </details>
</details>
<details>
  <summary>49. <b>标题：Socially Fair Center-based and Linear Subspace Clustering</b></summary>
  <p><b>编号</b>：[153]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10095</p>
  <p><b>作者</b>：Sruthi Gorantla,  Kishen N. Gowda,  Amit Deshpande,  Anand Louis</p>
  <p><b>备注</b>：17 pages</p>
  <p><b>关键词</b>：partition real-world data, smaller clusters, popular techniques, techniques to partition, partition real-world</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Center-based clustering (e.g., $k$-means, $k$-medians) and clustering using
linear subspaces are two most popular techniques to partition real-world data
into smaller clusters. However, when the data consists of sensitive demographic
groups, significantly different clustering cost per point for different
sensitive groups can lead to fairness-related harms (e.g., different
quality-of-service). The goal of socially fair clustering is to minimize the
maximum cost of clustering per point over all groups. In this work, we propose
a unified framework to solve socially fair center-based clustering and linear
subspace clustering, and give practical, efficient approximation algorithms for
these problems. We do extensive experiments to show that on multiple benchmark
datasets our algorithms either closely match or outperform state-of-the-art
baselines.</p>
  </details>
</details>
<details>
  <summary>50. <b>标题：MetaRF: Differentiable Random Forest for Reaction Yield Prediction with  a Few Trails</b></summary>
  <p><b>编号</b>：[156]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10083</p>
  <p><b>作者</b>：Kexin Chen,  Guangyong Chen,  Junyou Li,  Yuansheng Huang,  Pheng-Ann Heng</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：impressive applications, applications requires, Artificial intelligence, high-quality annotations, intelligence has deeply</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Artificial intelligence has deeply revolutionized the field of medicinal
chemistry with many impressive applications, but the success of these
applications requires a massive amount of training samples with high-quality
annotations, which seriously limits the wide usage of data-driven methods. In
this paper, we focus on the reaction yield prediction problem, which assists
chemists in selecting high-yield reactions in a new chemical space only with a
few experimental trials. To attack this challenge, we first put forth MetaRF,
an attention-based differentiable random forest model specially designed for
the few-shot yield prediction, where the attention weight of a random forest is
automatically optimized by the meta-learning framework and can be quickly
adapted to predict the performance of new reagents while given a few additional
samples. To improve the few-shot learning performance, we further introduce a
dimension-reduction based sampling method to determine valuable samples to be
experimentally tested and then learned. Our methodology is evaluated on three
different datasets and acquires satisfactory performance on few-shot
prediction. In high-throughput experimentation (HTE) datasets, the average
yield of our methodology's top 10 high-yield reactions is relatively close to
the results of ideal yield selection.</p>
  </details>
</details>
<details>
  <summary>51. <b>标题：Robust Bayesian Nonnegative Matrix Factorization with Implicit  Regularizers</b></summary>
  <p><b>编号</b>：[167]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10053</p>
  <p><b>作者</b>：Jun Lu,  Christine P. Chai</p>
  <p><b>备注</b>：arXiv admin note: text overlap with arXiv:2205.11025</p>
  <p><b>关键词</b>：implicit norm regularization, finding hidden patterns, nonnegative matrix factorization, learning nonnegative matrix, matrix factorization</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We introduce a probabilistic model with implicit norm regularization for
learning nonnegative matrix factorization (NMF) that is commonly used for
predicting missing values and finding hidden patterns in the data, in which the
matrix factors are latent variables associated with each data dimension. The
nonnegativity constraint for the latent factors is handled by choosing priors
with support on the nonnegative subspace, e.g., exponential density or
distribution based on exponential function. Bayesian inference procedure based
on Gibbs sampling is employed. We evaluate the model on several real-world
datasets including Genomics of Drug Sensitivity in Cancer (GDSC $IC_{50}$) and
Gene body methylation with different sizes and dimensions, and show that the
proposed Bayesian NMF GL$_2^2$ and GL$_\infty$ models lead to robust
predictions for different data values and avoid overfitting compared with
competitive Bayesian NMF approaches.</p>
  </details>
</details>
<details>
  <summary>52. <b>标题：Evaluating and Crafting Datasets Effective for Deep Learning With Data  Maps</b></summary>
  <p><b>编号</b>：[176]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10033</p>
  <p><b>作者</b>：Jay Bishnu,  Andrew Gondoputro</p>
  <p><b>备注</b>：5 pages, 1 figure</p>
  <p><b>关键词</b>：Rapid development, development in deep, construction has prompted, prompted an increased, large datasets</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Rapid development in deep learning model construction has prompted an
increased need for appropriate training data. The popularity of large datasets
- sometimes known as "big data" - has diverted attention from assessing their
quality. Training on large datasets often requires excessive system resources
and an infeasible amount of time. Furthermore, the supervised machine learning
process has yet to be fully automated: for supervised learning, large datasets
require more time for manually labeling samples. We propose a method of
curating smaller datasets with comparable out-of-distribution model accuracy
after an initial training session using an appropriate distribution of samples
classified by how difficult it is for a model to learn from them.</p>
  </details>
</details>
<details>
  <summary>53. <b>标题：Simple and Optimal Stochastic Gradient Methods for Nonsmooth Nonconvex  Optimization</b></summary>
  <p><b>编号</b>：[177]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10025</p>
  <p><b>作者</b>：Zhize Li,  Jian Li</p>
  <p><b>备注</b>：60 pages. To appear in JMLR. arXiv admin note: text overlap with arXiv:1904.09265</p>
  <p><b>关键词</b>：possibly with nonsmooth, nonsmooth regularizer, ProxSVRG, stochastic gradient, gradient</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose and analyze several stochastic gradient algorithms for finding
stationary points or local minimum in nonconvex, possibly with nonsmooth
regularizer, finite-sum and online optimization problems. First, we propose a
simple proximal stochastic gradient algorithm based on variance reduction
called ProxSVRG+. We provide a clean and tight analysis of ProxSVRG+, which
shows that it outperforms the deterministic proximal gradient descent (ProxGD)
for a wide range of minibatch sizes, hence solves an open problem proposed in
Reddi et al. (2016b). Also, ProxSVRG+ uses much less proximal oracle calls than
ProxSVRG (Reddi et al., 2016b) and extends to the online setting by avoiding
full gradient computations. Then, we further propose an optimal algorithm,
called SSRGD, based on SARAH (Nguyen et al., 2017) and show that SSRGD further
improves the gradient complexity of ProxSVRG+ and achieves the optimal upper
bound, matching the known lower bound of (Fang et al., 2018; Li et al., 2021).
Moreover, we show that both ProxSVRG+ and SSRGD enjoy automatic adaptation with
local structure of the objective function such as the Polyak-Łojasiewicz
(PL) condition for nonconvex functions in the finite-sum case, i.e., we prove
that both of them can automatically switch to faster global linear convergence
without any restart performed in prior work ProxSVRG (Reddi et al., 2016b).
Finally, we focus on the more challenging problem of finding an $(\epsilon,
\delta)$-local minimum instead of just finding an $\epsilon$-approximate
(first-order) stationary point (which may be some bad unstable saddle points).
We show that SSRGD can find an $(\epsilon, \delta)$-local minimum by simply
adding some random perturbations. Our algorithm is almost as simple as its
counterpart for finding stationary points, and achieves similar optimal rates.</p>
  </details>
</details>
<details>
  <summary>54. <b>标题：NOSMOG: Learning Noise-robust and Structure-aware MLPs on Graphs</b></summary>
  <p><b>编号</b>：[182]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10010</p>
  <p><b>作者</b>：Yijun Tian,  Chuxu Zhang,  Zhichun Guo,  Xiangliang Zhang,  Nitesh V. Chawla</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Graph Neural Networks, Neural Networks, multi-hop data dependency, real applications due, scalability constraint imposed</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>While Graph Neural Networks (GNNs) have demonstrated their efficacy in
dealing with non-Euclidean structural data, they are difficult to be deployed
in real applications due to the scalability constraint imposed by multi-hop
data dependency. Existing methods attempt to address this scalability issue by
training multi-layer perceptrons (MLPs) exclusively on node content features
using labels derived from trained GNNs. Even though the performance of MLPs can
be significantly improved, two issues prevent MLPs from outperforming GNNs and
being used in practice: the ignorance of graph structural information and the
sensitivity to node feature noises. In this paper, we propose to learn
NOise-robust Structure-aware MLPs On Graphs (NOSMOG) to overcome the
challenges. Specifically, we first complement node content with position
features to help MLPs capture graph structural information. We then design a
novel representational similarity distillation strategy to inject structural
node similarities into MLPs. Finally, we introduce the adversarial feature
augmentation to ensure stable learning against feature noises and further
improve performance. Extensive experiments demonstrate that NOSMOG outperforms
GNNs and the state-of-the-art method in both transductive and inductive
settings across seven datasets, while maintaining a competitive inference
efficiency.</p>
  </details>
</details>
<details>
  <summary>55. <b>标题：Collaboration between parallel connected neural networks -- A possible  criterion for distinguishing artificial neural networks from natural organs</b></summary>
  <p><b>编号</b>：[189]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09983</p>
  <p><b>作者</b>：Guang Ping He</p>
  <p><b>备注</b>：9 pages, 8 figures, 3 tables</p>
  <p><b>关键词</b>：find experimentally, connected in parallel, parallel and trained, neural networks, PNN</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We find experimentally that when artificial neural networks are connected in
parallel and trained together, they display the following properties. (i) When
the parallel-connected neural network (PNN) is optimized, each sub-network in
the connection is not optimized. (ii) The contribution of an inferior
sub-network to the whole PNN can be on par with that of the superior
sub-network. (iii) The PNN can output the correct result even when all
sub-networks give incorrect results. These properties are unlikely for natural
biological sense organs. Therefore, they could serve as a simple yet effective
criterion for measuring the bionic level of neural networks. With this
criterion, we further show that when serving as the activation function, the
ReLU function can make an artificial neural network more bionic than the
sigmoid and Tanh functions do.</p>
  </details>
</details>
<details>
  <summary>56. <b>标题：Inferring Sensitive Attributes from Model Explanations</b></summary>
  <p><b>编号</b>：[195]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09967</p>
  <p><b>作者</b>：Vasisht Duddu,  Antoine Boutet</p>
  <p><b>备注</b>：ACM CIKM 2022</p>
  <p><b>关键词</b>：trained machine learning, Model, explanations, attack, machine learning model</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Model explanations provide transparency into a trained machine learning
model's blackbox behavior to a model builder. They indicate the influence of
different input attributes to its corresponding model prediction. The
dependency of explanations on input raises privacy concerns for sensitive user
data. However, current literature has limited discussion on privacy risks of
model explanations.
We focus on the specific privacy risk of attribute inference attack wherein
an adversary infers sensitive attributes of an input (e.g., race and sex) given
its model explanations. We design the first attribute inference attack against
model explanations in two threat models where model builder either (a) includes
the sensitive attributes in training data and input or (b) censors the
sensitive attributes by not including them in the training data and input.
We evaluate our proposed attack on four benchmark datasets and four
state-of-the-art algorithms. We show that an adversary can successfully infer
the value of sensitive attributes from explanations in both the threat models
accurately. Moreover, the attack is successful even by exploiting only the
explanations corresponding to sensitive attributes. These suggest that our
attack is effective against explanations and poses a practical threat to data
privacy.
On combining the model predictions (an attack surface exploited by prior
attacks) with explanations, we note that the attack success does not improve.
Additionally, the attack success on exploiting model explanations is better
compared to exploiting only model predictions. These suggest that model
explanations are a strong attack surface to exploit for an adversary.</p>
  </details>
</details>
<details>
  <summary>57. <b>标题：Performance, Opaqueness, Consequences, and Assumptions: Simple questions  for responsible planning of machine learning solutions</b></summary>
  <p><b>编号</b>：[196]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09966</p>
  <p><b>作者</b>：Przemyslaw Biecek</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：revolution has generated, generated a huge, huge demand, data revolution, data-driven solutions</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The data revolution has generated a huge demand for data-driven solutions.
This demand propels a growing number of easy-to-use tools and training for
aspiring data scientists that enable the rapid building of predictive models.
Today, weapons of math destruction can be easily built and deployed without
detailed planning and validation. This rapidly extends the list of AI failures,
i.e. deployments that lead to financial losses or even violate democratic
values such as equality, freedom and justice. The lack of planning, rules and
standards around the model development leads to the ,,anarchisation of AI".
This problem is reported under different names such as validation debt,
reproducibility crisis, and lack of explainability. Post-mortem analysis of AI
failures often reveals mistakes made in the early phase of model development or
data acquisition. Thus, instead of curing the consequences of deploying harmful
models, we shall prevent them as early as possible by putting more attention to
the initial planning stage.
In this paper, we propose a quick and simple framework to support planning of
AI solutions. The POCA framework is based on four pillars: Performance,
Opaqueness, Consequences, and Assumptions. It helps to set the expectations and
plan the constraints for the AI solution before any model is built and any data
is collected. With the help of the POCA method, preliminary requirements can be
defined for the model-building process, so that costly model misspecification
errors can be identified as soon as possible or even avoided. AI researchers,
product owners and business analysts can use this framework in the initial
stages of building AI solutions.</p>
  </details>
</details>
<details>
  <summary>58. <b>标题：Heterogeneous Graph Masked Autoencoders</b></summary>
  <p><b>编号</b>：[198]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09957</p>
  <p><b>作者</b>：Yijun Tian,  Kaiwen Dong,  Chunhui Zhang,  Chuxu Zhang,  Nitesh V. Chawla</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：shown great potential, handling graph data, exciting learning paradigms, shown great, great potential</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Generative self-supervised learning (SSL), especially masked autoencoders,
has become one of the most exciting learning paradigms and has shown great
potential in handling graph data. However, real-world graphs are always
heterogeneous, which poses three critical challenges that existing methods
ignore: 1) how to capture complex graph structure? 2) how to incorporate
various node attributes? and 3) how to encode different node positions? In
light of this, we study the problem of generative SSL on heterogeneous graphs
and propose HGMAE, a novel heterogeneous graph masked autoencoder model to
address these challenges. HGMAE captures comprehensive graph information via
two innovative masking techniques and three unique training strategies. In
particular, we first develop metapath masking and adaptive attribute masking
with dynamic mask rate to enable effective and stable learning on heterogeneous
graphs. We then design several training strategies including metapath-based
edge reconstruction to adopt complex structural information, target attribute
restoration to incorporate various node attributes, and positional feature
prediction to encode node positional information. Extensive experiments
demonstrate that HGMAE outperforms both contrastive and generative
state-of-the-art baselines on several tasks across multiple datasets.</p>
  </details>
</details>
<details>
  <summary>59. <b>标题：Energy-aware Scheduling of Virtualized Base Stations in O-RAN with  Online Learning</b></summary>
  <p><b>编号</b>：[199]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09956</p>
  <p><b>作者</b>：Michail Kalntis,  George Iosifidis</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Open Radio Access, virtualized Base Stations, Radio Access Network, Base Stations, Open Radio</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The design of Open Radio Access Network (O-RAN) compliant systems for
configuring the virtualized Base Stations (vBSs) is of paramount importance for
network operators. This task is challenging since optimizing the vBS scheduling
procedure requires knowledge of parameters, which are erratic and demanding to
obtain in advance. In this paper, we propose an online learning algorithm for
balancing the performance and energy consumption of a vBS. This algorithm
provides performance guarantees under unforeseeable conditions, such as
non-stationary traffic and network state, and is oblivious to the vBS operation
profile. We study the problem in its most general form and we prove that the
proposed technique achieves sub-linear regret (i.e., zero average optimality
gap) even in a fast-changing environment. By using real-world data and various
trace-driven evaluations, our findings indicate savings of up to 74.3% in the
power consumption of a vBS in comparison with state-of-the-art benchmarks.</p>
  </details>
</details>
<details>
  <summary>60. <b>标题：MolGraph: a Python package for the implementation of small molecular  graphs and graph neural networks with TensorFlow and Keras</b></summary>
  <p><b>编号</b>：[203]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09944</p>
  <p><b>作者</b>：Alexander Kensert,  Gert Desmet,  Deirdre Cabooter</p>
  <p><b>备注</b>：16 pages, 4 figures, 5 tables</p>
  <p><b>关键词</b>：blood brain-barrier permeability, Molecular machine learning, machine learning, including the prediction, brain-barrier permeability</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Molecular machine learning (ML) has proven important for tackling various
molecular problems, including the prediction of protein-drug interactions and
blood brain-barrier permeability. Since relatively recently, so-called graph
neural networks (GNNs) have been implemented for molecular ML, showing
comparable or superior performance to descriptor-based approaches. Although
various tools and packages exist to apply GNNs for molecular ML, a new GNN
package, named MolGraph (this https URL), was developed
in this work with the motivation to create GNNs highly compatible with the
TensorFlow and Keras application programming interface (API). As MolGraph
focuses specifically and exclusively on molecular ML, a chemistry module was
implemented to accommodate the generation of molecular graphs $\unicode{x2014}$
which could then be inputted to the GNNs for molecular ML. To validate the
GNNs, they were benchmarked against the datasets of MoleculeNet, as well as
three chromatographic retention time datasets. The results on these benchmarks
show that the GNNs performed as expected. Additionally, the GNNs proved useful
for molecular identification and improved interpretability of chromatographic
retention data.</p>
  </details>
</details>
<details>
  <summary>61. <b>标题：Instability and Local Minima in GAN Training with Kernel Discriminators</b></summary>
  <p><b>编号</b>：[207]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09938</p>
  <p><b>作者</b>：Evan Becker,  Parthe Pandit,  Sundeep Rangan,  Alyson K. Fletcher</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Generative Adversarial Networks, Adversarial Networks, Generative Adversarial, generative modeling, complex data</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Generative Adversarial Networks (GANs) are a widely-used tool for generative
modeling of complex data. Despite their empirical success, the training of GANs
is not fully understood due to the min-max optimization of the generator and
discriminator. This paper analyzes these joint dynamics when the true samples,
as well as the generated samples, are discrete, finite sets, and the
discriminator is kernel-based. A simple yet expressive framework for analyzing
training called the $\textit{Isolated Points Model}$ is introduced. In the
proposed model, the distance between true samples greatly exceeds the kernel
width, so each generated point is influenced by at most one true point. Our
model enables precise characterization of the conditions for convergence, both
to good and bad minima. In particular, the analysis explains two common failure
modes: (i) an approximate mode collapse and (ii) divergence. Numerical
simulations are provided that predictably replicate these behaviors.</p>
  </details>
</details>
<details>
  <summary>62. <b>标题：Improving GANs for Long-Tailed Data through Group Spectral  Regularization</b></summary>
  <p><b>编号</b>：[209]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09932</p>
  <p><b>作者</b>：Harsh Rangwani,  Naman Jaswani,  Tejan Karmali,  Varun Jampani,  R. Venkatesh Babu</p>
  <p><b>备注</b>：ECCV 2022. Project Page: this https URL</p>
  <p><b>关键词</b>：real-world imbalanced distributions, Deep long-tailed learning, Generative Adversarial Networks, real-world imbalanced, long-tailed learning aims</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep long-tailed learning aims to train useful deep networks on practical,
real-world imbalanced distributions, wherein most labels of the tail classes
are associated with a few samples. There has been a large body of work to train
discriminative models for visual recognition on long-tailed distribution. In
contrast, we aim to train conditional Generative Adversarial Networks, a class
of image generation models on long-tailed distributions. We find that similar
to recognition, state-of-the-art methods for image generation also suffer from
performance degradation on tail classes. The performance degradation is mainly
due to class-specific mode collapse for tail classes, which we observe to be
correlated with the spectral explosion of the conditioning parameter matrix. We
propose a novel group Spectral Regularizer (gSR) that prevents the spectral
explosion alleviating mode collapse, which results in diverse and plausible
image generation even for tail classes. We find that gSR effectively combines
with existing augmentation and regularization techniques, leading to
state-of-the-art image generation performance on long-tailed data. Extensive
experiments demonstrate the efficacy of our regularizer on long-tailed datasets
with different degrees of imbalance.</p>
  </details>
</details>
<details>
  <summary>63. <b>标题：ProPaLL: Probabilistic Partial Label Learning</b></summary>
  <p><b>编号</b>：[210]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09931</p>
  <p><b>作者</b>：Łukasz Struski,  Jacek Tabor,  Bartosz Zieliński</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Partial label learning, weakly supervised learning, training instance corresponds, Partial label, type of weakly</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Partial label learning is a type of weakly supervised learning, where each
training instance corresponds to a set of candidate labels, among which only
one is true. In this paper, we introduce ProPaLL, a novel probabilistic
approach to this problem, which has at least three advantages compared to the
existing approaches: it simplifies the training process, improves performance,
and can be applied to any deep architecture. Experiments conducted on
artificial and real-world datasets indicate that ProPaLL outperforms the
existing approaches.</p>
  </details>
</details>
<details>
  <summary>64. <b>标题：A semi-supervised Teacher-Student framework for surgical tool detection  and localization</b></summary>
  <p><b>编号</b>：[213]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09926</p>
  <p><b>作者</b>：Mansoor Ali,  Gilberto Ochoa-Ruiz,  Sharib Ali</p>
  <p><b>备注</b>：Paper accepted at Augmented Reality, Augmented Environments for Computer Assisted Interventions (AE-CAI), Computer Assisted and Robotic Endoscopy (CARE) and Context-Aware Operating Theaters (OR 2.0) at MICCAI 2022</p>
  <p><b>关键词</b>：minimally invasive surgery, computer-assisted interventions, minimally invasive, invasive surgery, essential part</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Surgical tool detection in minimally invasive surgery is an essential part of
computer-assisted interventions. Current approaches are mostly based on
supervised methods which require large fully labeled data to train supervised
models and suffer from pseudo label bias because of class imbalance issues.
However large image datasets with bounding box annotations are often scarcely
available. Semi-supervised learning (SSL) has recently emerged as a means for
training large models using only a modest amount of annotated data; apart from
reducing the annotation cost. SSL has also shown promise to produce models that
are more robust and generalizable. Therefore, in this paper we introduce a
semi-supervised learning (SSL) framework in surgical tool detection paradigm
which aims to mitigate the scarcity of training data and the data imbalance
through a knowledge distillation approach. In the proposed work, we train a
model with labeled data which initialises the Teacher-Student joint learning,
where the Student is trained on Teacher-generated pseudo labels from unlabeled
data. We propose a multi-class distance with a margin based classification loss
function in the region-of-interest head of the detector to effectively
segregate foreground classes from background region. Our results on
m2cai16-tool-locations dataset indicate the superiority of our approach on
different supervised data settings (1%, 2%, 5%, 10% of annotated data) where
our model achieves overall improvements of 8%, 12% and 27% in mAP (on 1%
labeled data) over the state-of-the-art SSL methods and a fully supervised
baseline, respectively. The code is available at
this https URL</p>
  </details>
</details>
<details>
  <summary>65. <b>标题：Alexa, Predict My Flight Delay</b></summary>
  <p><b>编号</b>：[214]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09921</p>
  <p><b>作者</b>：Sia Gholami,  Saba Khashe</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Airlines are critical, critical today, today for carrying, carrying people, people and commodities</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Airlines are critical today for carrying people and commodities on time. Any
delay in the schedule of these planes can potentially disrupt the business and
trade of thousands of employees at any given time. Therefore, precise flight
delay prediction is beneficial for the aviation industry and passenger travel.
Recent research has focused on using artificial intelligence algorithms to
predict the possibility of flight delays. Earlier prediction algorithms were
designed for a specific air route or airfield. Many present flight delay
prediction algorithms rely on tiny samples and are challenging to understand,
allowing almost no room for machine learning implementation. This research
study develops a flight delay prediction system by analyzing data from domestic
flights inside the United States of America. The proposed models learn about
the factors that cause flight delays and cancellations and the link between
departure and arrival delays.</p>
  </details>
</details>
<details>
  <summary>66. <b>标题：A Unified Analysis of Mixed Sample Data Augmentation: A Loss Function  Perspective</b></summary>
  <p><b>编号</b>：[217]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09913</p>
  <p><b>作者</b>：Chanwoo Park,  Sangdoo Yun,  Sanghyuk Chun</p>
  <p><b>备注</b>：First two authors contributed equally; 29 pages</p>
  <p><b>关键词</b>：sample data augmentation, mixed sample data, unified theoretical analysis, Mixup, theoretical results</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose the first unified theoretical analysis of mixed sample data
augmentation (MSDA), such as Mixup and CutMix. Our theoretical results show
that regardless of the choice of the mixing strategy, MSDA behaves as a
pixel-level regularization of the underlying training loss and a regularization
of the first layer parameters. Similarly, our theoretical results support that
the MSDA training strategy can improve adversarial robustness and
generalization compared to the vanilla training strategy. Using the theoretical
results, we provide a high-level understanding of how different design choices
of MSDA work differently. For example, we show that the most popular MSDA
methods, Mixup and CutMix, behave differently, e.g., CutMix regularizes the
input gradients by pixel distances, while Mixup regularizes the input gradients
regardless of pixel distances. Our theoretical results also show that the
optimal MSDA strategy depends on tasks, datasets, or model parameters. From
these observations, we propose generalized MSDAs, a Hybrid version of Mixup and
CutMix (HMix) and Gaussian Mixup (GMix), simple extensions of Mixup and CutMix.
Our implementation can leverage the advantages of Mixup and CutMix, while our
implementation is very efficient, and the computation cost is almost
neglectable as Mixup and CutMix. Our empirical study shows that our HMix and
GMix outperform the previous state-of-the-art MSDA methods in CIFAR-100 and
ImageNet classification tasks. Source code is available at
this https URL</p>
  </details>
</details>
<details>
  <summary>67. <b>标题：MentorGNN: Deriving Curriculum for Pre-Training GNNs</b></summary>
  <p><b>编号</b>：[220]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09905</p>
  <p><b>作者</b>：Dawei Zhou,  Lecheng Zheng,  Dongqi Fu,  Jiawei Han,  Jingrui He</p>
  <p><b>备注</b>：Accepted by CIKM 2022</p>
  <p><b>关键词</b>：graph mining community, graph neural networks, parameterizing graph neural, graph signals, mining community</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Graph pre-training strategies have been attracting a surge of attention in
the graph mining community, due to their flexibility in parameterizing graph
neural networks (GNNs) without any label information. The key idea lies in
encoding valuable information into the backbone GNNs, by predicting the masked
graph signals extracted from the input graphs. In order to balance the
importance of diverse graph signals (e.g., nodes, edges, subgraphs), the
existing approaches are mostly hand-engineered by introducing hyperparameters
to re-weight the importance of graph signals. However, human interventions with
sub-optimal hyperparameters often inject additional bias and deteriorate the
generalization performance in the downstream applications. This paper addresses
these limitations from a new perspective, i.e., deriving curriculum for
pre-training GNNs. We propose an end-to-end model named MentorGNN that aims to
supervise the pre-training process of GNNs across graphs with diverse
structures and disparate feature spaces. To comprehend heterogeneous graph
signals at different granularities, we propose a curriculum learning paradigm
that automatically re-weighs graph signals in order to ensure a good
generalization in the target domain. Moreover, we shed new light on the problem
of domain adaption on relational data (i.e., graphs) by deriving a natural and
interpretable upper bound on the generalization error of the pre-trained GNNs.
Extensive experiments on a wealth of real graphs validate and verify the
performance of MentorGNN.</p>
  </details>
</details>
<details>
  <summary>68. <b>标题：Provable Adaptivity in Adam</b></summary>
  <p><b>编号</b>：[222]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09900</p>
  <p><b>作者</b>：Bohan Wang,  Yushun Zhang,  Huishuai Zhang,  Qi Meng,  Zhi-Ming Ma,  Tie-Yan Liu,  Wei Chen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Adaptive Moment Estimation, Moment Estimation, fast convergence properties, Adam, deep learning tasks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Adaptive Moment Estimation (Adam) optimizer is widely used in deep learning
tasks because of its fast convergence properties. However, the convergence of
Adam is still not well understood. In particular, the existing analysis of Adam
cannot clearly demonstrate the advantage of Adam over SGD. We attribute this
theoretical embarrassment to $L$-smooth condition (i.e., assuming the gradient
is globally Lipschitz continuous with constant $L$) adopted by literature,
which has been pointed out to often fail in practical neural networks. To
tackle this embarrassment, we analyze the convergence of Adam under a relaxed
condition called $(L_0,L_1)$ smoothness condition, which allows the gradient
Lipschitz constant to change with the local gradient norm. $(L_0,L_1)$ is
strictly weaker than $L$-smooth condition and it has been empirically verified
to hold for practical deep neural networks. Under the $(L_0,L_1)$ smoothness
condition, we establish the convergence for Adam with practical
hyperparameters. Specifically, we argue that Adam can adapt to the local
smoothness condition, justifying the \emph{adaptivity} of Adam. In contrast,
SGD can be arbitrarily slow under this condition. Our result might shed light
on the benefit of adaptive gradient methods over non-adaptive ones.</p>
  </details>
</details>
<details>
  <summary>69. <b>标题：Byzantines can also Learn from History: Fall of Centered Clipping in  Federated Learning</b></summary>
  <p><b>编号</b>：[225]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09894</p>
  <p><b>作者</b>：Kerem Ozfatura,  Emre Ozfatura,  Alptekin Kupcu,  Deniz Gunduz</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：collaborative learning tasks, learning framework due, learned model due, federated learning framework, malicious clients participating</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The increasing popularity of the federated learning framework due to its
success in a wide range of collaborative learning tasks also induces certain
security concerns regarding the learned model due to the possibility of
malicious clients participating in the learning process. Hence, the objective
is to neutralize the impact of the malicious participants and to ensure the
final model is trustable. One common observation regarding the Byzantine
attacks is that the higher the variance among the clients' models/updates, the
more space for attacks to be hidden. To this end, it has been recently shown
that by utilizing momentum, thus reducing the variance, it is possible to
weaken the strength of the known Byzantine attacks. The Centered Clipping
framework (ICML 2021) has further shown that, besides reducing the variance,
the momentum term from the previous iteration can be used as a reference point
to neutralize the Byzantine attacks and show impressive performance against
well-known attacks. However, in the scope of this work, we show that the
centered clipping framework has certain vulnerabilities, and existing attacks
can be revised based on these vulnerabilities to circumvent the centered
clipping defense. Hence, we introduce a strategy to design an attack to
circumvent the centered clipping framework and numerically illustrate its
effectiveness against centered clipping as well as other known defense
strategies by reducing test accuracy to 5-40 on best-case scenarios.</p>
  </details>
</details>
<details>
  <summary>70. <b>标题：DiscrimLoss: A Universal Loss for Hard Samples and Incorrect Samples  Discrimination</b></summary>
  <p><b>编号</b>：[227]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09884</p>
  <p><b>作者</b>：Tingting Wu,  Xiao Ding,  Hao Zhang,  Jinglong Gao,  Li Du,  Bing Qin,  Ting Liu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：deep neural networks, samples, impair model performance, incorrect samples, deep neural</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Given data with label noise (i.e., incorrect data), deep neural networks
would gradually memorize the label noise and impair model performance. To
relieve this issue, curriculum learning is proposed to improve model
performance and generalization by ordering training samples in a meaningful
(e.g., easy to hard) sequence. Previous work takes incorrect samples as generic
hard ones without discriminating between hard samples (i.e., hard samples in
correct data) and incorrect samples. Indeed, a model should learn from hard
samples to promote generalization rather than overfit to incorrect ones. In
this paper, we address this problem by appending a novel loss function
DiscrimLoss, on top of the existing task loss. Its main effect is to
automatically and stably estimate the importance of easy samples and difficult
samples (including hard and incorrect samples) at the early stages of training
to improve the model performance. Then, during the following stages,
DiscrimLoss is dedicated to discriminating between hard and incorrect samples
to improve the model generalization. Such a training strategy can be formulated
dynamically in a self-supervised manner, effectively mimicking the main
principle of curriculum learning. Experiments on image classification, image
regression, text sequence regression, and event relation reasoning demonstrate
the versatility and effectiveness of our method, particularly in the presence
of diversified noise levels.</p>
  </details>
</details>
<details>
  <summary>71. <b>标题：Provably Tightest Linear Approximation for Robustness Verification of  Sigmoid-like Neural Networks</b></summary>
  <p><b>编号</b>：[233]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09872</p>
  <p><b>作者</b>：Zhaodi Zhang,  Yiting Wu,  Si Liu,  Jing Liu,  Min Zhang</p>
  <p><b>备注</b>：Accepted at ASE 2022</p>
  <p><b>关键词</b>：modern AI-enabled systems, formally verified, deep neural networks, crucial to modern, modern AI-enabled</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The robustness of deep neural networks is crucial to modern AI-enabled
systems and should be formally verified. Sigmoid-like neural networks have been
adopted in a wide range of applications. Due to their non-linearity,
Sigmoid-like activation functions are usually over-approximated for efficient
verification, which inevitably introduces imprecision. Considerable efforts
have been devoted to finding the so-called tighter approximations to obtain
more precise verification results. However, existing tightness definitions are
heuristic and lack theoretical foundations. We conduct a thorough empirical
analysis of existing neuron-wise characterizations of tightness and reveal that
they are superior only on specific neural networks. We then introduce the
notion of network-wise tightness as a unified tightness definition and show
that computing network-wise tightness is a complex non-convex optimization
problem. We bypass the complexity from different perspectives via two
efficient, provably tightest approximations. The results demonstrate the
promising performance achievement of our approaches over state of the art: (i)
achieving up to 251.28% improvement to certified lower robustness bounds; and
(ii) exhibiting notably more precise verification results on convolutional
networks.</p>
  </details>
</details>
<details>
  <summary>72. <b>标题：Twin Papers: A Simple Framework of Causal Inference for Citations via  Coupling</b></summary>
  <p><b>编号</b>：[238]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09862</p>
  <p><b>作者</b>：Ryoma Sato,  Makoto Yamada,  Hisashi Kashima</p>
  <p><b>备注</b>：CIKM 2022 short paper</p>
  <p><b>关键词</b>：research process includes, process includes, investigating the effects, decisions, research process</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The research process includes many decisions, e.g., how to entitle and where
to publish the paper. In this paper, we introduce a general framework for
investigating the effects of such decisions. The main difficulty in
investigating the effects is that we need to know counterfactual results, which
are not available in reality. The key insight of our framework is inspired by
the existing counterfactual analysis using twins, where the researchers regard
twins as counterfactual units. The proposed framework regards a pair of papers
that cite each other as twins. Such papers tend to be parallel works, on
similar topics, and in similar communities. We investigate twin papers that
adopted different decisions, observe the progress of the research impact
brought by these studies, and estimate the effect of decisions by the
difference in the impacts of these studies. We release our code and data, which
we believe are highly beneficial owing to the scarcity of the dataset on
counterfactual studies.</p>
  </details>
</details>
<details>
  <summary>73. <b>标题：Emergence of hierarchical modes from deep learning</b></summary>
  <p><b>编号</b>：[240]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09859</p>
  <p><b>作者</b>：Chan Li,  Haiping Huang</p>
  <p><b>备注</b>：5 pages, 4 figures, and SM is available upon request</p>
  <p><b>关键词</b>：less-interpretable weight matrices, weight matrices constructing, neural networks consume, networks consume expensive, consume expensive training</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large-scale deep neural networks consume expensive training costs, but the
training results in less-interpretable weight matrices constructing the
networks. Here, we propose a mode decomposition learning that can interpret the
weight matrices as a hierarchy of latent modes. These modes are akin to
patterns in physics studies of memory networks. The mode decomposition learning
not only saves a significant large amount of training costs, but also explains
the network performance with the leading modes. The mode learning scheme shows
a progressively compact latent space across the network hierarchy, and the
least number of modes increases only logarithmically with the network width.
Our mode decomposition learning is also studied in an analytic on-line learning
setting, which reveals multi-stage of learning dynamics. Therefore, the
proposed mode decomposition learning points to a cheap and interpretable route
towards the magical deep learning.</p>
  </details>
</details>
<details>
  <summary>74. <b>标题：Last-Iterate Convergence with Full- and Noisy-Information Feedback in  Two-Player Zero-Sum Games</b></summary>
  <p><b>编号</b>：[241]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09855</p>
  <p><b>作者</b>：Kenshi Abe,  Kaito Ariu,  Mitsuki Sakamoto,  Kentaro Toyoshima,  Atsushi Iwasaki</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：multi-agent reinforcement learning, Generative Adversarial Networks, Multiplicative Weights Update, Adversarial Networks, rising applications</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The theory of learning in games is prominent in the AI community, motivated
by several rising applications such as multi-agent reinforcement learning and
Generative Adversarial Networks. We propose Mutation-driven Multiplicative
Weights Update (M2WU) for learning an equilibrium in two-player zero-sum
normal-form games and prove that it exhibits the last-iterate convergence
property in both full- and noisy-information feedback settings. In the
full-information feedback setting, the players observe their exact gradient
vectors of the utility functions. On the other hand, in the noisy-information
feedback setting, they can only observe the noisy gradient vectors. Existing
algorithms, including the well-known Multiplicative Weights Update (MWU) and
Optimistic MWU (OMWU) algorithms, fail to converge to a Nash equilibrium with
noisy-information feedback. In contrast, M2WU exhibits the last-iterate
convergence to a stationary point near a Nash equilibrium in both of the
feedback settings. We then prove that it converges to an exact Nash equilibrium
by adapting the mutation term iteratively. We empirically confirm that M2WU
outperforms MWU and OMWU in exploitability and convergence rates.</p>
  </details>
</details>
<details>
  <summary>75. <b>标题：Semantic-enhanced Image Clustering</b></summary>
  <p><b>编号</b>：[243]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09849</p>
  <p><b>作者</b>：Shaotian Cai,  Liping Qiu,  Xiaojun Chen,  Qin Zhang,  Longteng Chen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Image clustering, open challenge task, clustering, Image, Semantic-enhanced Image Clustering</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Image clustering is an important, and open challenge task in computer vision.
Although many methods have been proposed to solve the image clustering task,
they only explore images and uncover clusters according to the image features,
thus are unable to distinguish visually similar but semantically different
images. In this paper, we propose to investigate the task of image clustering
with the help of visual-language pre-training model. Different from the
zero-shot setting in which the class names are known, we only know the number
of clusters in this setting. Therefore, how to map images to a proper semantic
space and how to cluster images from both image and semantic spaces are two key
problems. To solve the above problems, we propose a novel image clustering
method guided by the visual-language pre-training model CLIP, named as
\textbf{Semantic-enhanced Image Clustering (SIC)}. In this new method, we
propose a method to map the given images to a proper semantic space first and
efficient methods to generate pseudo-labels according to the relationships
between images and semantics. Finally, we propose to perform clustering with
the consistency learning in both image space and semantic space, in a
self-supervised learning fashion. Theoretical result on convergence analysis
shows that our proposed method can converge in sublinear speed. Theoretical
analysis on expectation risk also shows that we can reduce the expectation risk
by improving the neighborhood consistency or prediction confidence or reducing
neighborhood imbalance. Experimental results on five benchmark datasets clearly
show the superiority of our new method.</p>
  </details>
</details>
<details>
  <summary>76. <b>标题：Comparison-based Conversational Recommender System with Relative Bandit  Feedback</b></summary>
  <p><b>编号</b>：[251]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09837</p>
  <p><b>作者</b>：Zhihui Xie,  Tong Yu,  Canzhe Zhao,  Shuai Li</p>
  <p><b>备注</b>：10 pages, 5 figures, accepted by SIGIR 2021</p>
  <p><b>关键词</b>：dynamically elicit user, conversational recommender systems, elicit user preference, recent advances, actively and dynamically</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>With the recent advances of conversational recommendations, the recommender
system is able to actively and dynamically elicit user preference via
conversational interactions. To achieve this, the system periodically queries
users' preference on attributes and collects their feedback. However, most
existing conversational recommender systems only enable the user to provide
absolute feedback to the attributes. In practice, the absolute feedback is
usually limited, as the users tend to provide biased feedback when expressing
the preference. Instead, the user is often more inclined to express comparative
preferences, since user preferences are inherently relative. To enable users to
provide comparative preferences during conversational interactions, we propose
a novel comparison-based conversational recommender system. The relative
feedback, though more practical, is not easy to be incorporated since its
feedback scale is always mismatched with users' absolute preferences. With
effectively collecting and understanding the relative feedback from an
interactive manner, we further propose a new bandit algorithm, which we call
RelativeConUCB. The experiments on both synthetic and real-world datasets
validate the advantage of our proposed method, compared to the existing bandit
algorithms in the conversational recommender systems.</p>
  </details>
</details>
<details>
  <summary>77. <b>标题：Combating Noisy-Labeled and Imbalanced Data by Two Stage Bi-Dimensional  Sample Selection</b></summary>
  <p><b>编号</b>：[253]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09833</p>
  <p><b>作者</b>：Yiliang Zhang,  Yang Lu,  Bo Han,  Yiu-ming Cheung,  Hanzi Wang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：noise directly leads, deep learning models, label noise directly, real applications, important task</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Robust learning on noisy-labeled data has been an important task in real
applications, because label noise directly leads to the poor generalization of
deep learning models. Existing label-noise learning methods usually assume that
the ground-truth classes of the training data are balanced. However, the
real-world data is often imbalanced, leading to the inconsistency between
observed and intrinsic class distribution due to label noises. Distribution
inconsistency makes the problem of label-noise learning more challenging
because it is hard to distinguish clean samples from noisy samples on the
intrinsic tail classes. In this paper, we propose a learning framework for
label-noise learning with intrinsically long-tailed data. Specifically, we
propose a robust sample selection method called two-stage bi-dimensional sample
selection (TBSS) to better separate clean samples from noisy samples,
especially for the tail classes. TBSS consists of two new separation metrics to
jointly separate samples in each class. Extensive experiments on multiple
noisy-labeled datasets with intrinsically long-tailed class distribution
demonstrate the effectiveness of our method.</p>
  </details>
</details>
<details>
  <summary>78. <b>标题：Representation Learning with Graph Neural Networks for Speech Emotion  Recognition</b></summary>
  <p><b>编号</b>：[254]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09830</p>
  <p><b>作者</b>：Junghun Kim,  Jihie Kim</p>
  <p><b>备注</b>：AAAI 2022 Workshop on Graphs and More Complex Structures for Learning and Reasoning (GCLR)</p>
  <p><b>关键词</b>：crucial in deep, expressive representation, Graph Neural Network, SER, representation learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Learning expressive representation is crucial in deep learning. In speech
emotion recognition (SER), vacuum regions or noises in the speech interfere
with expressive representation learning. However, traditional RNN-based models
are susceptible to such noise. Recently, Graph Neural Network (GNN) has
demonstrated its effectiveness for representation learning, and we adopt this
framework for SER. In particular, we propose a cosine similarity-based graph as
an ideal graph structure for representation learning in SER. We present a
Cosine similarity-based Graph Convolutional Network (CoGCN) that is robust to
perturbation and noise. Experimental results show that our method outperforms
state-of-the-art methods or provides competitive results with a significant
model size reduction with only 1/30 parameters.</p>
  </details>
</details>
<details>
  <summary>79. <b>标题：Critical Bach Size Minimizes Stochastic First-Order Oracle Complexity of  Deep Learning Optimizer using Hyperparameters Close to One</b></summary>
  <p><b>编号</b>：[264]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09814</p>
  <p><b>作者</b>：Hideaki Iiduka</p>
  <p><b>备注</b>：arXiv admin note: text overlap with arXiv:2112.07163</p>
  <p><b>关键词</b>：small constant learning, constant learning rate, deep neural networks, critical batch size, deep learning optimizers</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Practical results have shown that deep learning optimizers using small
constant learning rates, hyperparameters close to one, and large batch sizes
can find the model parameters of deep neural networks that minimize the loss
functions. We first show theoretical evidence that the momentum method
(Momentum) and adaptive moment estimation (Adam) perform well in the sense that
the upper bound of the theoretical performance measure is small with a small
constant learning rate, hyperparameters close to one, and a large batch size.
Next, we show that there exists a batch size called the critical batch size
minimizing the stochastic first-order oracle (SFO) complexity, which is the
stochastic gradient computation cost, and that SFO complexity increases once
the batch size exceeds the critical batch size. Finally, we provide numerical
results that support our theoretical results. That is, the numerical results
indicate that Adam using a small constant learning rate, hyperparameters close
to one, and the critical batch size minimizing SFO complexity has faster
convergence than Momentum and stochastic gradient descent (SGD).</p>
  </details>
</details>
<details>
  <summary>80. <b>标题：PointDP: Diffusion-driven Purification against Adversarial Attacks on 3D  Point Cloud Recognition</b></summary>
  <p><b>编号</b>：[267]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09801</p>
  <p><b>作者</b>：Jiachen Sun,  Weili Nie,  Zhiding Yu,  Z. Morley Mao,  Chaowei Xiao</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：critical data representation, Point cloud, Point, autonomous driving, medical imaging</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>3D Point cloud is becoming a critical data representation in many real-world
applications like autonomous driving, robotics, and medical imaging. Although
the success of deep learning further accelerates the adoption of 3D point
clouds in the physical world, deep learning is notorious for its vulnerability
to adversarial attacks. In this work, we first identify that the
state-of-the-art empirical defense, adversarial training, has a major
limitation in applying to 3D point cloud models due to gradient obfuscation. We
further propose PointDP, a purification strategy that leverages diffusion
models to defend against 3D adversarial attacks. We extensively evaluate
PointDP on six representative 3D point cloud architectures, and leverage 10+
strong and adaptive attacks to demonstrate its lower-bound robustness. Our
evaluation shows that PointDP achieves significantly better robustness than
state-of-the-art purification methods under strong attacks. Results of
certified defenses on randomized smoothing combined with PointDP will be
included in the near future.</p>
  </details>
</details>
<details>
  <summary>81. <b>标题：Stop&Hop: Early Classification of Irregular Time Series</b></summary>
  <p><b>编号</b>：[271]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09795</p>
  <p><b>作者</b>：Thomas Hartvigsen,  Walter Gerych,  Jidapa Thadajarassiri,  Xiangnan Kong,  Elke Rundensteiner</p>
  <p><b>备注</b>：This paper was accepted to CIKM'22. Code at this https URL</p>
  <p><b>关键词</b>：users react faster, irregular time series, time series, time, Early classification</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Early classification algorithms help users react faster to their machine
learning model's predictions. Early warning systems in hospitals, for example,
let clinicians improve their patients' outcomes by accurately predicting
infections. While early classification systems are advancing rapidly, a major
gap remains: existing systems do not consider irregular time series, which have
uneven and often-long gaps between their observations. Such series are
notoriously pervasive in impactful domains like healthcare. We bridge this gap
and study early classification of irregular time series, a new setting for
early classifiers that opens doors to more real-world problems. Our solution,
Stop&Hop, uses a continuous-time recurrent network to model ongoing irregular
time series in real time, while an irregularity-aware halting policy, trained
with reinforcement learning, predicts when to stop and classify the streaming
series. By taking real-valued step sizes, the halting policy flexibly decides
exactly when to stop ongoing series in real time. This way, Stop&Hop seamlessly
integrates information contained in the timing of observations, a new and vital
source for early classification in this setting, with the time series values to
provide early classifications for irregular time series. Using four synthetic
and three real-world datasets, we demonstrate that Stop&Hop consistently makes
earlier and more-accurate predictions than state-of-the-art alternatives
adapted to this new problem. Our code is publicly available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>82. <b>标题：Robust Node Classification on Graphs: Jointly from Bayesian Label  Transition and Topology-based Label Propagation</b></summary>
  <p><b>编号</b>：[277]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09779</p>
  <p><b>作者</b>：Jun Zhuang,  Mohammad Al Hasan</p>
  <p><b>备注</b>：The paper is accepted for CIKM 2022</p>
  <p><b>关键词</b>：Graph Neural Networks, Neural Networks, GNN-based node classification, Graph Neural, Node classification</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Node classification using Graph Neural Networks (GNNs) has been widely
applied in various real-world scenarios. However, in recent years, compelling
evidence emerges that the performance of GNN-based node classification may
deteriorate substantially by topological perturbation, such as random
connections or adversarial attacks. Various solutions, such as topological
denoising methods and mechanism design methods, have been proposed to develop
robust GNN-based node classifiers but none of these works can fully address the
problems related to topological perturbations. Recently, the Bayesian label
transition model is proposed to tackle this issue but its slow convergence may
lead to inferior performance. In this work, we propose a new label inference
model, namely LInDT, which integrates both Bayesian label transition and
topology-based label propagation for improving the robustness of GNNs against
topological perturbations. LInDT is superior to existing label transition
methods as it improves the label prediction of uncertain nodes by utilizing
neighborhood-based label propagation leading to better convergence of label
inference. Besides, LIndT adopts asymmetric Dirichlet distribution as a prior,
which also helps it to improve label inference. Extensive experiments on five
graph datasets demonstrate the superiority of LInDT for GNN-based node
classification under three scenarios of topological perturbations.</p>
  </details>
</details>
<details>
  <summary>83. <b>标题：FLIS: Clustered Federated Learning via Inference Similarity for Non-IID  Data Distribution</b></summary>
  <p><b>编号</b>：[285]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09754</p>
  <p><b>作者</b>：Mahdi Morafah,  Saeed Vahidian,  Weijia Wang,  Bill Lin</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：approaches yield significant, learning approaches yield, yield significant performance, significant performance degradation, Non-IID data distributions</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Classical federated learning approaches yield significant performance
degradation in the presence of Non-IID data distributions of participants. When
the distribution of each local dataset is highly different from the global one,
the local objective of each client will be inconsistent with the global optima
which incur a drift in the local updates. This phenomenon highly impacts the
performance of clients. This is while the primary incentive for clients to
participate in federated learning is to obtain better personalized models. To
address the above-mentioned issue, we present a new algorithm, FLIS, which
groups the clients population in clusters with jointly trainable data
distributions by leveraging the inference similarity of clients' models. This
framework captures settings where different groups of users have their own
objectives (learning tasks) but by aggregating their data with others in the
same cluster (same learning task) to perform more efficient and personalized
federated learning. We present experimental results to demonstrate the benefits
of FLIS over the state-of-the-art benchmarks on CIFAR-100/10, SVHN, and FMNIST
datasets. Our code is available at this https URL.</p>
  </details>
</details>
<details>
  <summary>84. <b>标题：MLExchange -- A web-based platform enabling exchangeable machine  learning workflows</b></summary>
  <p><b>编号</b>：[287]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09751</p>
  <p><b>作者</b>：Zhuowen Zhao,  Tanny Chavez,  Elizabeth Holman,  Guanhua Hao,  Adam Green,  Harinarayan Krishnan,  Dylan McReynolds,  Ronald Pandolfi,  Eric J. Roberts,  Petrus H. Zwart,  Howard Yanxon,  Nicholas Schwarz,  Subramanian Sankaranarayanan,  Sergei V. Kalinin,  Apurva Mehta,  Stuart Campbel,  Alexander Hexemer</p>
  <p><b>备注</b>：Submitting to The Int'l Conference for High Performance Computing, Networking, Storage, and Analysis</p>
  <p><b>关键词</b>：diverse data problems, Machine learning, showing a growing, growing trend, trend in helping</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Machine learning (ML) algorithms are showing a growing trend in helping the
scientific communities across different disciplines and institutions to address
large and diverse data problems. However, many available ML tools are
programmatically demanding and computationally costly. The MLExchange project
aims to build a collaborative platform equipped with enabling tools that allow
scientists and facility users who do not have a profound ML background to use
ML and computational resources in scientific discovery. At the high level, we
are targeting a full user experience where managing and exchanging ML
algorithms, workflows, and data are readily available through web applications.
So far, we have built four major components, i.e, the central job manager, the
centralized content registry, user portal, and search engine, and successfully
deployed these components on a testing server.
Since each component is an independent container, the whole platform or its
individual service(s) can be easily deployed at servers of different scales,
ranging from a laptop (usually a single user) to high performance clusters
(HPC) accessed (simultaneously) by many users. Thus, MLExchange renders
flexible using scenarios -- users could either access the services and
resources from a remote server or run the whole platform or its individual
service(s) within their local network.</p>
  </details>
</details>
<details>
  <summary>85. <b>标题：Near-Optimal $Φ$-Regret Learning in Extensive-Form Games</b></summary>
  <p><b>编号</b>：[289]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09747</p>
  <p><b>作者</b>：Ioannis Anagnostides,  Gabriele Farina,  Tuomas Sandholm</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：multiplayer perfect-recall imperfect-information, imperfect-information extensive-form games, perfect-recall imperfect-information extensive-form, emph, repetitions of play</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we establish efficient and uncoupled learning dynamics so
that, when employed by all players in multiplayer perfect-recall
imperfect-information extensive-form games, the \emph{trigger regret} of each
player grows as $O(\log T)$ after $T$ repetitions of play. This improves
exponentially over the prior best known trigger-regret bound of $O(T^{1/4})$,
and settles a recent open question by Bai et al. (2022). As an immediate
consequence, we guarantee convergence to the set of \emph{extensive-form
correlated equilibria} and \emph{coarse correlated equilibria} at a
near-optimal rate of $\frac{\log T}{T}$.
Building on prior work, at the heart of our construction lies a more general
result regarding fixed points deriving from rational functions with
\emph{polynomial degree}, a property that we establish for the fixed points of
\emph{(coarse) trigger deviation functions}. Moreover, our construction
leverages a refined \textit{regret circuit} for the convex hull, which --
unlike prior guarantees -- preserves the \emph{RVU property} introduced by
Syrgkanis et al. (NIPS, 2015); this observation has an independent interest in
establishing near-optimal regret under learning dynamics based on a CFR-type
decomposition of the regret.</p>
  </details>
</details>
<details>
  <summary>86. <b>标题：C$^{2}$IMUFS: Complementary and Consensus Learning-based Incomplete  Multi-view Unsupervised Feature Selection</b></summary>
  <p><b>编号</b>：[294]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09736</p>
  <p><b>作者</b>：Yanyong Huang,  Zongxin Shen,  Yuxin Cai,  Xiuwen Yi,  Dongjie Wang,  Fengmao Lv,  Tianrui Li</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：effective technique, technique to reduce, reduce the dimensionality, multi-view unlabeled data, Multi-view unsupervised feature</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Multi-view unsupervised feature selection (MUFS) has been demonstrated as an
effective technique to reduce the dimensionality of multi-view unlabeled data.
The existing methods assume that all of views are complete. However, multi-view
data are usually incomplete, i.e., a part of instances are presented on some
views but not all views. Besides, learning the complete similarity graph, as an
important promising technology in existing MUFS methods, cannot achieve due to
the missing views. In this paper, we propose a complementary and consensus
learning-based incomplete multi-view unsupervised feature selection method
(C$^{2}$IMUFS) to address the aforementioned issues. Concretely, C$^{2}$IMUFS
integrates feature selection into an extended weighted non-negative matrix
factorization model equipped with adaptive learning of view-weights and a
sparse $\ell_{2,p}$-norm, which can offer better adaptability and flexibility.
By the sparse linear combinations of multiple similarity matrices derived from
different views, a complementary learning-guided similarity matrix
reconstruction model is presented to obtain the complete similarity graph in
each view. Furthermore, C$^{2}$IMUFS learns a consensus clustering indicator
matrix across different views and embeds it into a spectral graph term to
preserve the local geometric structure. Comprehensive experimental results on
real-world datasets demonstrate the effectiveness of C$^{2}$IMUFS compared with
state-of-the-art methods.</p>
  </details>
</details>
<details>
  <summary>87. <b>标题：A Multi-Head Model for Continual Learning via Out-of-Distribution Replay</b></summary>
  <p><b>编号</b>：[295]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09734</p>
  <p><b>作者</b>：Gyuhak Kim,  Zixuan Ke,  Bing Liu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：previous tasks, studies class incremental, task, tasks, CIL</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper studies class incremental learning (CIL) of continual learning
(CL). Many approaches have been proposed to deal with catastrophic forgetting
(CF) in CIL. Most methods incrementally construct a single classifier for all
classes of all tasks in a single head network. To prevent CF, a popular
approach is to memorize a small number of samples from previous tasks and
replay them during training of the new task. However, this approach still
suffers from serious CF as the parameters learned for previous tasks are
updated or adjusted with only the limited number of saved samples in the
memory. This paper proposes an entirely different approach that builds a
separate classifier (head) for each task (called a multi-head model) using a
transformer network, called MORE. Instead of using the saved samples in memory
to update the network for previous tasks/classes in the existing approach, MORE
leverages the saved samples to build a task specific classifier (adding a new
classification head) without updating the network learned for previous
tasks/classes. The model for the new task in MORE is trained to learn the
classes of the task and also to detect samples that are not from the same data
distribution (i.e., out-of-distribution (OOD)) of the task. This enables the
classifier for the task to which the test instance belongs to produce a high
score for the correct class and the classifiers of other tasks to produce low
scores because the test instance is not from the data distributions of these
classifiers. Experimental results show that MORE outperforms state-of-the-art
baselines and is also naturally capable of performing OOD detection in the
continual learning setting.</p>
  </details>
</details>
<details>
  <summary>88. <b>标题：Matrix Completion with Cross-Concentrated Sampling: Bridging Uniform  Sampling and CUR Sampling</b></summary>
  <p><b>编号</b>：[298]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09723</p>
  <p><b>作者</b>：HanQin Cai,  Longxiu Huang,  Pengyu Li,  Deanna Needell</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：CUR sampling approximates, sampling, column samples, widely studied, approximates a low-rank</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>While uniform sampling has been widely studied in the matrix completion
literature, CUR sampling approximates a low-rank matrix via row and column
samples. Unfortunately, both sampling models lack flexibility for various
circumstances in real-world applications. In this work, we propose a novel and
easy-to-implement sampling strategy, coined Cross-Concentrated Sampling (CCS).
By bridging uniform sampling and CUR sampling, CCS provides extra flexibility
that can potentially save sampling costs in applications. In addition, we also
provide a sufficient condition for CCS-based matrix completion. Moreover, we
propose a highly efficient non-convex algorithm, termed Iterative CUR
Completion (ICURC), for the proposed CCS model. Numerical experiments verify
the empirical advantages of CCS and ICURC against uniform sampling and its
baseline algorithms, on both synthetic and real-world datasets.</p>
  </details>
</details>
<details>
  <summary>89. <b>标题：Improving Multilayer-Perceptron(MLP)-based Network Anomaly Detection  with Birch Clustering on CICIDS-2017 Dataset</b></summary>
  <p><b>编号</b>：[303]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09711</p>
  <p><b>作者</b>：Yuhua Yin,  Julian Jang-Jaccard,  Fariza Sabrina,  Jin Kwak</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：including Multi-layer Perceptron, Multi-layer Perceptron, including Multi-layer, Machine learning algorithms, Machine learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Machine learning algorithms have been widely used in intrusion detection
systems, including Multi-layer Perceptron (MLP). In this study, we proposed a
two-stage model that combines the Birch clustering algorithm and MLP classifier
to improve the performance of network anomaly multi-classification. In our
proposed method, we first apply Birch or Kmeans as an unsupervised clustering
algorithm to the CICIDS-2017 dataset to pre-group the data. The generated
pseudo-label is then added as an additional feature to the training of the
MLP-based classifier. The experimental results show that using Birch and
K-Means clustering for data pre-grouping can improve intrusion detection system
performance. Our method can achieve 99.73% accuracy in multi-classification
using Birch clustering, which is better than similar researches using a
stand-alone MLP model.</p>
  </details>
</details>
<details>
  <summary>90. <b>标题：DenseShift: Towards Accurate and Transferable Low-Bit Shift Network</b></summary>
  <p><b>编号</b>：[305]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09708</p>
  <p><b>作者</b>：Xinlin Li,  Bang Liu,  Rui Heng Yang,  Vanessa Courville,  Chao Xing,  Vahid Partovi Nia</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：ever-increasing resource requirements, low-resource edge devices, Deploying deep neural, deep neural networks, low-bit shift networks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deploying deep neural networks on low-resource edge devices is challenging
due to their ever-increasing resource requirements. Recent investigations
propose multiplication-free neural networks to reduce computation and memory
consumption. Shift neural network is one of the most effective tools towards
these reductions. However, existing low-bit shift networks are not as accurate
as their full precision counterparts and cannot efficiently transfer to a wide
range of tasks due to their inherent design flaws. We propose DenseShift
network that exploits the following novel designs. First, we demonstrate that
the zero-weight values in low-bit shift networks are neither useful to the
model capacity nor simplify the model inference. Therefore, we propose to use a
zero-free shifting mechanism to simplify inference while increasing the model
capacity. Second, we design a new metric to measure the weight freezing issue
in training low-bit shift networks, and propose a sign-scale decomposition to
improve the training efficiency. Third, we propose the low-variance random
initialization strategy to improve the model's performance in transfer learning
scenarios. We run extensive experiments on various computer vision and speech
tasks. The experimental results show that DenseShift network significantly
outperforms existing low-bit multiplication-free networks and can achieve
competitive performance to the full-precision counterpart. It also exhibits
strong transfer learning performance with no drop in accuracy.</p>
  </details>
</details>
<details>
  <summary>91. <b>标题：Fuse and Attend: Generalized Embedding Learning for Art and Sketches</b></summary>
  <p><b>编号</b>：[312]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09698</p>
  <p><b>作者</b>：Ujjal Kr Dutta</p>
  <p><b>备注</b>：Accepted in European Conference on Computer Vision (ECCV) 2022 Workshops: DIRA</p>
  <p><b>关键词</b>：witnessed widespread success, deep Embedding Learning, Embedding Learning approaches, representing natural images, Embedding Learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>While deep Embedding Learning approaches have witnessed widespread success in
multiple computer vision tasks, the state-of-the-art methods for representing
natural images need not necessarily perform well on images from other domains,
such as paintings, cartoons, and sketch. This is because of the huge shift in
the distribution of data from across these domains, as compared to natural
images. Domains like sketch often contain sparse informative pixels. However,
recognizing objects in such domains is crucial, given multiple relevant
applications leveraging such data, for instance, sketch to image retrieval.
Thus, achieving an Embedding Learning model that could perform well across
multiple domains is not only challenging, but plays a pivotal role in computer
vision. To this end, in this paper, we propose a novel Embedding Learning
approach with the goal of generalizing across different domains. During
training, given a query image from a domain, we employ gated fusion and
attention to generate a positive example, which carries a broad notion of the
semantics of the query object category (from across multiple domains). By
virtue of Contrastive Learning, we pull the embeddings of the query and
positive, in order to learn a representation which is robust across domains. At
the same time, to teach the model to be discriminative against examples from
different semantic categories (across domains), we also maintain a pool of
negative embeddings (from different categories). We show the prowess of our
method using the DomainBed framework, on the popular PACS (Photo, Art painting,
Cartoon, and Sketch) dataset.</p>
  </details>
</details>
<details>
  <summary>92. <b>标题：Effectiveness of Function Matching in Driving Scene Recognition</b></summary>
  <p><b>编号</b>：[314]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09694</p>
  <p><b>作者</b>：Shingo Yashima</p>
  <p><b>备注</b>：Autonomous Vehicle Vision (AVVision) Workshop at ECCV2022</p>
  <p><b>关键词</b>：training compact recognizers, compact recognizers required, effective approach, approach for training, recognizers required</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Knowledge distillation is an effective approach for training compact
recognizers required in autonomous driving. Recent studies on image
classification have shown that matching student and teacher on a wide range of
data points is critical for improving performance in distillation. This concept
(called function matching) is suitable for driving scene recognition, where
generally an almost infinite amount of unlabeled data are available. In this
study, we experimentally investigate the impact of using such a large amount of
unlabeled data for distillation on the performance of student models in
structured prediction tasks for autonomous driving. Through extensive
experiments, we demonstrate that the performance of the compact student model
can be improved dramatically and even match the performance of the large-scale
teacher by knowledge distillation with massive unlabeled data.</p>
  </details>
</details>
<details>
  <summary>93. <b>标题：Visual Analysis of Neural Architecture Spaces for Summarizing Design  Principles</b></summary>
  <p><b>编号</b>：[329]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09665</p>
  <p><b>作者</b>：Jun Yuan,  Mengchen Liu,  Fengyuan Tian,  Shixia Liu</p>
  <p><b>备注</b>：11 pages, 11 figures; accepted for IEEE VIS 2022</p>
  <p><b>关键词</b>：artificial intelligence largely, intelligence largely benefit, Recent advances, advances in artificial, artificial intelligence</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent advances in artificial intelligence largely benefit from better neural
network architectures. These architectures are a product of a costly process of
trial-and-error. To ease this process, we develop ArchExplorer, a visual
analysis method for understanding a neural architecture space and summarizing
design principles. The key idea behind our method is to make the architecture
space explainable by exploiting structural distances between architectures. We
formulate the pairwise distance calculation as solving an all-pairs shortest
path problem. To improve efficiency, we decompose this problem into a set of
single-source shortest path problems. The time complexity is reduced from
O(kn^2N) to O(knN). Architectures are hierarchically clustered according to the
distances between them. A circle-packing-based architecture visualization has
been developed to convey both the global relationships between clusters and
local neighborhoods of the architectures in each cluster. Two case studies and
a post-analysis are presented to demonstrate the effectiveness of ArchExplorer
in summarizing design principles and selecting better-performing architectures.</p>
  </details>
</details>
<details>
  <summary>94. <b>标题：From Time Series to Networks in R with the ts2net Package</b></summary>
  <p><b>编号</b>：[331]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09660</p>
  <p><b>作者</b>：Leonardo N. Ferreira</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：time series, series, time, complex systems, single time series</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Network science established itself as a prominent tool for modeling time
series and complex systems. This modeling process consists of transforming a
set or a single time series into a network. Nodes may represent complete time
series, segments, or single values, while links define associations or
similarities between the represented parts. R is one of the main programming
languages used in data science, statistics, and machine learning, with many
packages available. However, no single package provides the necessary methods
to transform time series into networks. This paper presents ts2net, an R
package for modeling one or multiple time series into networks. The package
provides the time series distance functions that can be easily computed in
parallel and in supercomputers to process larger data sets and methods to
transform distance matrices into networks. Ts2net also provides methods to
transform a single time series into a network, such as recurrence networks,
visibility graphs, and transition networks. Together with other packages,
ts2net permits using network science and graph mining tools to extract
information from time series.</p>
  </details>
</details>
<details>
  <summary>95. <b>标题：Trigger-free Event Detection via Derangement Reading Comprehension</b></summary>
  <p><b>编号</b>：[332]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09659</p>
  <p><b>作者</b>：Jiachen Zhao,  Haiqin Yang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：understanding actual happenings, aiming to detect, real life, vital to understanding, understanding actual</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Event detection (ED), aiming to detect events from texts and categorize them,
is vital to understanding actual happenings in real life. However, mainstream
event detection models require high-quality expert human annotations of
triggers, which are often costly and thus deter the application of ED to new
domains. Therefore, in this paper, we focus on low-resource ED without triggers
and aim to tackle the following formidable challenges: multi-label
classification, insufficient clues, and imbalanced events distribution. We
propose a novel trigger-free ED method via Derangement mechanism on a machine
Reading Comprehension (DRC) framework. More specifically, we treat the input
text as Context and concatenate it with all event type tokens that are deemed
as Answers with an omitted default question. So we can leverage the
self-attention in pre-trained language models to absorb semantic relations
between input text and the event types. Moreover, we design a simple yet
effective event derangement module (EDM) to prevent major events from being
excessively learned so as to yield a more balanced training process. The
experiment results show that our proposed trigger-free ED model is remarkably
competitive to mainstream trigger-based models, showing its strong performance
on low-source event detection.</p>
  </details>
</details>
<details>
  <summary>96. <b>标题：A biologically-inspired evaluation of molecular generative machine  learning</b></summary>
  <p><b>编号</b>：[333]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09658</p>
  <p><b>作者</b>：Elizaveta Vinogradova,  Abay Artykbayev,  Alisher Amanatay,  Mukhamejan Karatayev,  Maxim Mametkulov,  Albina Li,  Anuar Suleimenov,  Abylay Salimzhanov,  Karina Pats,  Rustam Zhumagambetov,  Ferdinand Molnár,  Vsevolod Peshkov,  Siamac Fazli</p>
  <p><b>备注</b>：59 pages, 26 figures Project GitHub repository, this https URL</p>
  <p><b>关键词</b>：scientific areas, generative models, recently become ubiquitous, molecular generative models, generative</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>While generative models have recently become ubiquitous in many scientific
areas, less attention has been paid to their evaluation. For molecular
generative models, the state-of-the-art examines their output in isolation or
in relation to its input. However, their biological and functional properties,
such as ligand-target interaction is not being addressed. In this study, a
novel biologically-inspired benchmark for the evaluation of molecular
generative models is proposed. Specifically, three diverse reference datasets
are designed and a set of metrics are introduced which are directly relevant to
the drug discovery process. In particular we propose a recreation metric, apply
drug-target affinity prediction and molecular docking as complementary
techniques for the evaluation of generative outputs. While all three metrics
show consistent results across the tested generative models, a more detailed
comparison of drug-target affinity binding and molecular docking scores
revealed that unimodal predictiors can lead to erroneous conclusions about
target binding on a molecular level and a multi-modal approach is thus
preferrable. The key advantage of this framework is that it incorporates prior
physico-chemical domain knowledge into the benchmarking process by focusing
explicitly on ligand-target interactions and thus creating a highly efficient
tool not only for evaluating molecular generative outputs in particular, but
also for enriching the drug discovery process in general.</p>
  </details>
</details>
<details>
  <summary>97. <b>标题：A Domain Generalization Approach for Out-Of-Distribution 12-lead ECG  Classification with Convolutional Neural Networks</b></summary>
  <p><b>编号</b>：[335]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09656</p>
  <p><b>作者</b>：Aristotelis Ballas,  Christos Diou</p>
  <p><b>备注</b>：This paper has been accepted at: IEEE BigDataService2022 (this http URL)</p>
  <p><b>关键词</b>：Deep Learning systems, achieved great success, Learning systems, surpassing human intelligence, Deep Learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep Learning systems have achieved great success in the past few years, even
surpassing human intelligence in several cases. As of late, they have also
established themselves in the biomedical and healthcare domains, where they
have shown a lot of promise, but have not yet achieved widespread adoption.
This is in part due to the fact that most methods fail to maintain their
performance when they are called to make decisions on data that originate from
a different distribution than the one they were trained on, namely
Out-Of-Distribution (OOD) data. For example, in the case of biosignal
classification, models often fail to generalize well on datasets from different
hospitals, due to the distribution discrepancy amongst different sources of
data. Our goal is to demonstrate the Domain Generalization problem present
between distinct hospital databases and propose a method that classifies
abnormalities on 12-lead Electrocardiograms (ECGs), by leveraging information
extracted across the architecture of a Deep Neural Network, and capturing the
underlying structure of the signal. To this end, we adopt a ResNet-18 as the
backbone model and extract features from several intermediate convolutional
layers of the network. To evaluate our method, we adopt publicly available ECG
datasets from four sources and handle them as separate domains. To simulate the
distributional shift present in real-world settings, we train our model on a
subset of the domains and leave-out the remaining ones. We then evaluate our
model both on the data present at training time (intra-distribution) and the
held-out data (out-of-distribution), achieving promising results and surpassing
the baseline of a vanilla Residual Network in most of the cases.</p>
  </details>
</details>
<details>
  <summary>98. <b>标题：Few-Shot Learning of Accurate Folding Landscape for Protein Structure  Prediction</b></summary>
  <p><b>编号</b>：[336]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09652</p>
  <p><b>作者</b>：Jun Zhang,  Sirui Liu,  Mengyun Chen,  Haotian Chu,  Min Wang,  Zidong Wang,  Jialiang Yu,  Ningxi Ni,  Fan Yu,  Diqing Chen,  Yi Isaac Yang,  Boxin Xue,  Lijiang Yang,  Yuan Liu,  Yi Qin Gao</p>
  <p><b>备注</b>：version 1.0; 18 pages, 6 figures</p>
  <p><b>关键词</b>：Data-driven predictive methods, biologically active structures, Data-driven predictive, therapeutical development, biologically active</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Data-driven predictive methods which can efficiently and accurately transform
protein sequences into biologically active structures are highly valuable for
scientific research and therapeutical development. Determining accurate folding
landscape using co-evolutionary information is fundamental to the success of
modern protein structure prediction methods. As the state of the art,
AlphaFold2 has dramatically raised the accuracy without performing explicit
co-evolutionary analysis. Nevertheless, its performance still shows strong
dependence on available sequence homologs. We investigated the cause of such
dependence and presented EvoGen, a meta generative model, to remedy the
underperformance of AlphaFold2 for poor MSA targets. EvoGen allows us to
manipulate the folding landscape either by denoising the searched MSA or by
generating virtual MSA, and helps AlphaFold2 fold accurately in low-data regime
or even achieve encouraging performance with single-sequence predictions. Being
able to make accurate predictions with few-shot MSA not only generalizes
AlphaFold2 better for orphan sequences, but also democratizes its use for
high-throughput applications. Besides, EvoGen combined with AlphaFold2 yields a
probabilistic structure generation method which could explore alternative
conformations of protein sequences, and the task-aware differentiable algorithm
for sequence generation will benefit other related tasks including protein
design.</p>
  </details>
</details>
<details>
  <summary>99. <b>标题：The computational complexity of some explainable clustering problems</b></summary>
  <p><b>编号</b>：[339]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09643</p>
  <p><b>作者</b>：Eduardo Sany Laber</p>
  <p><b>备注</b>：14 pages and 1 figure</p>
  <p><b>关键词</b>：axis-aligned decision trees, explainable clustering problems, decision trees, study the computational, computational complexity</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We study the computational complexity of some explainable clustering problems
in the framework proposed by [Dasgupta et al., ICML 2020], where explainability
is achieved via axis-aligned decision trees. We consider the $k$-means,
$k$-medians, $k$-centers and the spacing cost functions. We prove that the
first three are hard to optimize while the latter can be optimized in
polynomial time.</p>
  </details>
</details>
<details>
  <summary>100. <b>标题：Adam Can Converge Without Any Modification on Update Rules</b></summary>
  <p><b>编号</b>：[343]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09632</p>
  <p><b>作者</b>：Yushun Zhang,  Congliang Chen,  Naichen Shi,  Ruoyu Sun,  Zhi-Quan Luo</p>
  <p><b>备注</b>：66 pages</p>
  <p><b>关键词</b>：beta, Adam, Adam converges, convergence, result</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Ever since Reddi et al. 2018 pointed out the divergence issue of Adam, many
new variants have been designed to obtain convergence. However, vanilla Adam
remains exceptionally popular and it works well in practice. Why is there a gap
between theory and practice? We point out there is a mismatch between the
settings of theory and practice: Reddi et al. 2018 pick the problem after
picking the hyperparameters of Adam, i.e., $(\beta_1, \beta_2)$; while
practical applications often fix the problem first and then tune $(\beta_1,
\beta_2)$. Due to this observation, we conjecture that the empirical
convergence can be theoretically justified, only if we change the order of
picking the problem and hyperparameter. In this work, we confirm this
conjecture. We prove that, when $\beta_2$ is large and $\beta_1 <
\sqrt{\beta_2}<1$, adam converges to the neighborhood of critical points. size is propositional variance stochastic gradients. under an extra condition (strong growth condition), as $\beta_2$ increases, our convergence result can cover any $\beta_1 \in [0,1)$ including which default setting in deep learning libraries. shows that converge a wide range hyperparameters without modification on its update rules. knowledge, we are first prove this strong assumptions such bounded when small, further point out large region $(\beta_1,\beta_2)$ where diverge infinity. divergence considers same result, indicating phase transition from increasing $\beta_2$. these positive and negative results provide suggestions how tune hyperparameters.< p>
  </1$,></p></details>
</details>
<details>
  <summary>101. <b>标题：Are You Comfortable Now: Deep Learning the Temporal Variation in Thermal  Comfort in Winters</b></summary>
  <p><b>编号</b>：[344]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09628</p>
  <p><b>作者</b>：Betty Lala,  Srikant Manas Kala,  Anmol Rastogi,  Kunal Dahiya,  Aya Hagishima</p>
  <p><b>备注</b>：Accepted for publication in IEEE SMC 2022</p>
  <p><b>关键词</b>：thermal comfort, Indoor thermal comfort, thermal, Indoor thermal, comfort</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Indoor thermal comfort in smart buildings has a significant impact on the
health and performance of occupants. Consequently, machine learning (ML) is
increasingly used to solve challenges related to indoor thermal comfort.
Temporal variability of thermal comfort perception is an important problem that
regulates occupant well-being and energy consumption. However, in most ML-based
thermal comfort studies, temporal aspects such as the time of day, circadian
rhythm, and outdoor temperature are not considered. This work addresses these
problems. It investigates the impact of circadian rhythm and outdoor
temperature on the prediction accuracy and classification performance of ML
models. The data is gathered through month-long field experiments carried out
in 14 classrooms of 5 schools, involving 512 primary school students. Four
thermal comfort metrics are considered as the outputs of Deep Neural Networks
and Support Vector Machine models for the dataset. The effect of temporal
variability on school children's comfort is shown through a "time of day"
analysis. Temporal variability in prediction accuracy is demonstrated (up to
80%). Furthermore, we show that outdoor temperature (varying over time)
positively impacts the prediction performance of thermal comfort models by up
to 30%. The importance of spatio-temporal context is demonstrated by
contrasting micro-level (location specific) and macro-level (6 locations across
a city) performance. The most important finding of this work is that a
definitive improvement in prediction accuracy is shown with an increase in the
time of day and sky illuminance, for multiple thermal comfort metrics.</p>
  </details>
</details>
<details>
  <summary>102. <b>标题：Learning to predict test effectiveness</b></summary>
  <p><b>编号</b>：[348]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09623</p>
  <p><b>作者</b>：Morteza Zakeri-Nasrabadi,  Saeed Parsa</p>
  <p><b>备注</b>：19 pages, 11 figures</p>
  <p><b>关键词</b>：source code metrics, source code, dramatically reduced, high cost, code metrics</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The high cost of the test can be dramatically reduced, provided that the
coverability as an inherent feature of the code under test is predictable. This
article offers a machine learning model to predict the extent to which the test
could cover a class in terms of a new metric called Coverageability. The
prediction model consists of an ensemble of four regression models. The
learning samples consist of feature vectors, where features are source code
metrics computed for a class. The samples are labeled by the Coverageability
values computed for their corresponding classes. We offer a mathematical model
to evaluate test effectiveness in terms of size and coverage of the test suite
generated automatically for each class. We extend the size of the feature space
by introducing a new approach to defining sub-metrics in terms of existing
source code metrics. Using feature importance analysis on the learned
prediction models, we sort source code metrics in the order of their impact on
the test effectiveness. As a result of which, we found the class strict
cyclomatic complexity as the most influential source code metric. Our
experiments with the prediction models on a large corpus of Java projects
containing about 23,000 classes demonstrate the Mean Absolute Error (MAE) of
0.032, Mean Squared Error (MSE) of 0.004, and an R2-score of 0.855. Compared
with the state-of-the-art coverage prediction models, our models improve MAE,
MSE, and an R2-score by 5.78%, 2.84%, and 20.71%, respectively.</p>
  </details>
</details>
<details>
  <summary>103. <b>标题：A Novel Hybrid Sampling Framework for Imbalanced Learning</b></summary>
  <p><b>编号</b>：[349]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09619</p>
  <p><b>作者</b>：Asif Newaz,  Farhan Shahriyar Haq</p>
  <p><b>备注</b>：Submitted to "Expert Systems with Applications"</p>
  <p><b>关键词</b>：frequently occurring scenario, sampling techniques, frequently occurring, occurring scenario, sampling</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Class imbalance is a frequently occurring scenario in classification tasks.
Learning from imbalanced data poses a major challenge, which has instigated a
lot of research in this area. Data preprocessing using sampling techniques is a
standard approach to deal with the imbalance present in the data. Since
standard classification algorithms do not perform well on imbalanced data, the
dataset needs to be adequately balanced before training. This can be
accomplished by oversampling the minority class or undersampling the majority
class. In this study, a novel hybrid sampling algorithm has been proposed. To
overcome the limitations of the sampling techniques while ensuring the quality
of the retained sampled dataset, a sophisticated framework has been developed
to properly combine three different sampling techniques. Neighborhood Cleaning
rule is first applied to reduce the imbalance. Random undersampling is then
strategically coupled with the SMOTE algorithm to obtain an optimal balance in
the dataset. This proposed hybrid methodology, termed "SMOTE-RUS-NC", has been
compared with other state-of-the-art sampling techniques. The strategy is
further incorporated into the ensemble learning framework to obtain a more
robust classification algorithm, termed "SRN-BRF". Rigorous experimentation has
been conducted on 26 imbalanced datasets with varying degrees of imbalance. In
virtually all datasets, the proposed two algorithms outperformed existing
sampling strategies, in many cases by a substantial margin. Especially in
highly imbalanced datasets where popular sampling techniques failed utterly,
they achieved unparalleled performance. The superior results obtained
demonstrate the efficacy of the proposed models and their potential to be
powerful sampling algorithms in imbalanced domain.</p>
  </details>
</details>
<details>
  <summary>104. <b>标题：An ensemble meta-estimator to predict source code testability</b></summary>
  <p><b>编号</b>：[354]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09614</p>
  <p><b>作者</b>：Morteza Zakeri-Nasrabadi,  Saeed Parsa</p>
  <p><b>备注</b>：33 pages, 10 figures</p>
  <p><b>关键词</b>：testability, test, testability prediction model, model, metrics</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Software testing could be a lengthy and costly process, especially if the
software under test is not testable. Refactoring techniques may enhance
testability by improving the software metrics affecting testability. The
metrics are determined while building regression models learning how to relate
metrics computed for a source code to its testability. We identified 15
software metrics highly affecting testability while interpreting our
testability prediction model. Our experiments with 42 java classes reveal that
refactorings that improve these 15 metrics could enhance testability by an
average of 15.57%, besides improving some other quality attributes. Our
testability prediction model is trained to map source code metrics to test
effectiveness and efficiency as two significant ingredients of testable
software. Test effectiveness improves as the coverage gained by the test suite
increases. On the other hand, the test efficiency reduces as the size of the
test suite increases. This article offers a mathematical model to compute class
testability in terms of the size and coverage of the test suite. We use this
mathematical model to compute testability as the target of our testability
prediction model. The mathematical model requires the execution of the class
under test to compute test coverage, while our regression model measures
testability statically. Prediction of test results in terms of testability
should precede the test to avoid unnecessary costs. Our testability prediction
model has been trained and tested on 23,886 Java classes and 262 software
metrics. The learned model predicts testability with an R2 of 0.68 and a mean
squared error of 0.03.</p>
  </details>
</details>
<details>
  <summary>105. <b>标题：Weighted Maximum Entropy Inverse Reinforcement Learning</b></summary>
  <p><b>编号</b>：[357]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09611</p>
  <p><b>作者</b>：The Viet Bui,  Tien Mai,  Patrick Jaillet</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：study inverse reinforcement, expert demonstrated trajectories, inverse reinforcement learning, Markov Decision Processes, demonstrated trajectories</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We study inverse reinforcement learning (IRL) and imitation learning (IM),
the problems of recovering a reward or policy function from expert's
demonstrated trajectories. We propose a new way to improve the learning process
by adding a weight function to the maximum entropy framework, with the
motivation of having the ability to learn and recover the stochasticity (or the
bounded rationality) of the expert policy. Our framework and algorithms allow
to learn both a reward (or policy) function and the structure of the entropy
terms added to the Markov Decision Processes, thus enhancing the learning
procedure. Our numerical experiments using human and simulated demonstrations
and with discrete and continuous IRL/IM tasks show that our approach
outperforms prior algorithms.</p>
  </details>
</details>
<details>
  <summary>106. <b>标题：Looking For A Match: Self-supervised Clustering For Automatic Doubt  Matching In e-learning Platforms</b></summary>
  <p><b>编号</b>：[362]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09600</p>
  <p><b>作者</b>：Vedant Sandeep Joshi,  Sivanagaraja Tatinati,  Yubo Wang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：smart phones, resolved in minutes, e-learning platforms, doubt resolution time, resolution time</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recently, e-learning platforms have grown as a place where students can post
doubts (as a snap taken with smart phones) and get them resolved in minutes.
However, the significant increase in the number of student-posted doubts with
high variance in quality on these platforms not only presents challenges for
teachers' navigation to address them but also increases the resolution time per
doubt. Both are not acceptable, as high doubt resolution time hinders the
students learning progress. This necessitates ways to automatically identify if
there exists a similar doubt in repository and then serve it to the teacher as
the plausible solution to validate and communicate with the student. Supervised
learning techniques (like Siamese architecture) require labels to identify the
matches, which is not feasible as labels are scarce and expensive. In this
work, we, thus, developed a label-agnostic doubt matching paradigm based on the
representations learnt via self-supervised technique. Building on prior
theoretical insights of BYOL (bootstrap your own latent space), we propose
custom BYOL which combines domain-specific augmentation with contrastive
objective over a varied set of appropriately constructed data views. Results
highlighted that, custom BYOL improves the top-1 matching accuracy by
approximately 6\% and 5\% as compared to both BYOL and supervised learning
instances, respectively. We further show that both BYOL-based learning
instances performs either on par or better than human labeling.</p>
  </details>
</details>
<details>
  <summary>107. <b>标题：The Saddle-Point Accountant for Differential Privacy</b></summary>
  <p><b>编号</b>：[364]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09595</p>
  <p><b>作者</b>：Wael Alghamdi,  Shahab Asoodeh,  Flavio P. Calmon,  Juan Felipe Gomez,  Oliver Kosut,  Lalitha Sankar,  Fei Wei</p>
  <p><b>备注</b>：31 pages, 4 figures</p>
  <p><b>关键词</b>：accountant called, SPA, saddle-point accountant, called the saddle-point, accountant</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We introduce a new differential privacy (DP) accountant called the
saddle-point accountant (SPA). SPA approximates privacy guarantees for the
composition of DP mechanisms in an accurate and fast manner. Our approach is
inspired by the saddle-point method -- a ubiquitous numerical technique in
statistics. We prove rigorous performance guarantees by deriving upper and
lower bounds for the approximation error offered by SPA. The crux of SPA is a
combination of large-deviation methods with central limit theorems, which we
derive via exponentially tilting the privacy loss random variables
corresponding to the DP mechanisms. One key advantage of SPA is that it runs in
constant time for the $n$-fold composition of a privacy mechanism. Numerical
experiments demonstrate that SPA achieves comparable accuracy to
state-of-the-art accounting methods with a faster runtime.</p>
  </details>
</details>
<details>
  <summary>108. <b>标题：TopoDiff: A Performance and Constraint-Guided Diffusion Model for  Topology Optimization</b></summary>
  <p><b>编号</b>：[366]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09591</p>
  <p><b>作者</b>：François Mazé,  Faez Ahmed</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Structural topology optimization, topology optimization, aims to find, maximizes mechanical performance, Structural topology</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Structural topology optimization, which aims to find the optimal physical
structure that maximizes mechanical performance, is vital in engineering design
applications in aerospace, mechanical, and civil engineering. Generative
adversarial networks (GANs) have recently emerged as a popular alternative to
traditional iterative topology optimization methods. However, these models are
often difficult to train, have limited generalizability, and due to their goal
of mimicking optimal topologies, neglect manufacturability and performance
objectives like mechanical compliance. We propose TopoDiff, a conditional
diffusion-model-based architecture to perform performance-aware and
manufacturability-aware topology optimization that overcomes these issues. Our
model introduces a surrogate model-based guidance strategy that actively favors
structures with low compliance and good manufacturability. Our method
significantly outperforms a state-of-art conditional GAN by reducing the
average error on physical performance by a factor of eight and by producing 11
times fewer infeasible samples. By introducing diffusion models to topology
optimization, we show that conditional diffusion models have the ability to
outperform GANs in engineering design synthesis applications too. Our work also
suggests a general framework for engineering optimization problems using
diffusion models and external performance and constraint-aware guidance.</p>
  </details>
</details>
<details>
  <summary>109. <b>标题：Data-Driven Causal Effect Estimation Based on Graphical Causal  Modelling: A Survey</b></summary>
  <p><b>编号</b>：[367]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09590</p>
  <p><b>作者</b>：Debo Cheng,  Jiuyong Li,  Lin Liu,  Jixue Liu,  Thuc Duy Le</p>
  <p><b>备注</b>：25 pages, 7 figures and 1 table</p>
  <p><b>关键词</b>：causal effect estimation, responses or interventions, causal, fields of scientific, crucial for understanding</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In many fields of scientific research and real-world applications, unbiased
estimation of causal effects from non-experimental data is crucial for
understanding the mechanism underlying the data and for decision-making on
effective responses or interventions. A great deal of research has been
conducted on this challenging problem from different angles. For causal effect
estimation in data, assumptions such as Markov property, faithfulness and
causal sufficiency are always made. Under the assumptions, full knowledge such
as, a set of covariates or an underlying causal graph, is still required. A
practical challenge is that in many applications, no such full knowledge or
only some partial knowledge is available. In recent years, research has emerged
to use a search strategy based on graphical causal modelling to discover useful
knowledge from data for causal effect estimation, with some mild assumptions,
and has shown promose in tackling the practical challenge. In this survey, we
review the methods and focus on the challenges the data-driven methods face. We
discuss the assumptions, strengths and limitations of the data-driven methods.
We hope this review will motivate more researchers to design better data-driven
methods based on graphical causal modelling for the challenging problem of
causal effect estimation.</p>
  </details>
</details>
<details>
  <summary>110. <b>标题：Study of Novel Sparse Array Design Based on the Maximum Inter-Element  Spacing Criterion</b></summary>
  <p><b>编号</b>：[375]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09574</p>
  <p><b>作者</b>：W. Shi,  Y. Li,  R. C. de Lamare</p>
  <p><b>备注</b>：9 pages, 3 figures</p>
  <p><b>关键词</b>：IMISC arrays, maximum inter-element spacing, proposed IMISC arrays, traditional MISC array, IMISC</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A novel sparse array (SA) structure is proposed based on the maximum
inter-element spacing (IES) constraint (MISC) criterion. Compared with the
traditional MISC array, the proposed SA configurations, termed as improved MISC
(IMISC) has significantly increased uniform degrees of freedom (uDOF) and
reduced mutual coupling. In particular, the IMISC arrays are composed of six
uniform linear arrays (ULAs), which can be determined by an IES set. The IES
set is constrained by two parameters, namely the maximum IES and the number of
sensors. The uDOF of the IMISC arrays is derived and the weight function of the
IMISC arrays is analyzed as well. The proposed IMISC arrays have a great
advantage in terms of uDOF against the existing SAs, while their mutual
coupling remains at a low level. Simulations are carried out to demonstrate the
advantages of the IMISC arrays.</p>
  </details>
</details>
<details>
  <summary>111. <b>标题：Calculus on MDPs: Potential Shaping as a Gradient</b></summary>
  <p><b>编号</b>：[376]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09570</p>
  <p><b>作者</b>：Erik Jenner,  Herke van Hoof,  Adam Gleave</p>
  <p><b>备注</b>：17 pages, 6 figures</p>
  <p><b>关键词</b>：reinforcement learning, potential shaping, equivalent in terms, shaping, potential</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In reinforcement learning, different reward functions can be equivalent in
terms of the optimal policies they induce. A particularly well-known and
important example is potential shaping, a class of functions that can be added
to any reward function without changing the optimal policy set under arbitrary
transition dynamics. Potential shaping is conceptually similar to potentials,
conservative vector fields and gauge transformations in math and physics, but
this connection has not previously been formally explored. We develop a
formalism for discrete calculus on graphs that abstract a Markov Decision
Process, and show how potential shaping can be formally interpreted as a
gradient within this framework. This allows us to strengthen results from Ng et
al. (1999) describing conditions under which potential shaping is the only
additive reward transformation to always preserve optimal policies. As an
additional application of our formalism, we define a rule for picking a single
unique reward function from each potential shaping equivalence class.</p>
  </details>
</details>
<details>
  <summary>112. <b>标题：Multiple Instance Neuroimage Transformer</b></summary>
  <p><b>编号</b>：[379]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09567</p>
  <p><b>作者</b>：Ayush Singla,  Qingyu Zhao,  Daniel K. Do,  Yuyin Zhou,  Kilian M. Pohl,  Ehsan Adeli</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：called Multiple Instance, multiple instance learning, Multiple Instance Neuroimage, learning based convolution-free, based convolution-free transformer</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>For the first time, we propose using a multiple instance learning based
convolution-free transformer model, called Multiple Instance Neuroimage
Transformer (MINiT), for the classification of T1weighted (T1w) MRIs. We first
present several variants of transformer models adopted for neuroimages. These
models extract non-overlapping 3D blocks from the input volume and perform
multi-headed self-attention on a sequence of their linear projections. MINiT,
on the other hand, treats each of the non-overlapping 3D blocks of the input
MRI as its own instance, splitting it further into non-overlapping 3D patches,
on which multi-headed self-attention is computed. As a proof-of-concept, we
evaluate the efficacy of our model by training it to identify sex from T1w-MRIs
of two public datasets: Adolescent Brain Cognitive Development (ABCD) and the
National Consortium on Alcohol and Neurodevelopment in Adolescence (NCANDA).
The learned attention maps highlight voxels contributing to identifying sex
differences in brain morphometry. The code is available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>113. <b>标题：A Dual Modality Approach For (Zero-Shot) Multi-Label Classification</b></summary>
  <p><b>编号</b>：[380]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09562</p>
  <p><b>作者</b>：Shichao Xu,  Yikang Li,  Jenhao Hsiao,  Chiuman Ho,  Zhu Qi</p>
  <p><b>备注</b>：preprint</p>
  <p><b>关键词</b>：multi-label classification, Aligned Dual moDality, including zero-shot multi-label, zero-shot multi-label classification, real-world applications</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In computer vision, multi-label classification, including zero-shot
multi-label classification are important tasks with many real-world
applications. In this paper, we propose a novel algorithm, Aligned Dual
moDality ClaSsifier (ADDS), which includes a Dual-Modal decoder (DM-decoder)
with alignment between visual and textual features, for multi-label
classification tasks. Moreover, we design a simple and yet effective method
called Pyramid-Forwarding to enhance the performance for inputs with high
resolutions. Extensive experiments conducted on standard multi-label benchmark
datasets, MS-COCO and NUS-WIDE, demonstrate that our approach significantly
outperforms previous methods and provides state-of-the-art performance for
conventional multi-label classification, zero-shot multi-label classification,
and an extreme case called single-to-multi label classification where models
trained on single-label datasets (ImageNet-1k, ImageNet-21k) are tested on
multi-label ones (MS-COCO and NUS-WIDE). We also analyze how visual-textual
alignment contributes to the proposed approach, validate the significance of
the DM-decoder, and demonstrate the effectiveness of Pyramid-Forwarding on
vision transformer.</p>
  </details>
</details>
<details>
  <summary>114. <b>标题：Game-Theoretic Algorithms for Conditional Moment Matching</b></summary>
  <p><b>编号</b>：[384]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09551</p>
  <p><b>作者</b>：Gokul Swamy,  Sanjiban Choudhury,  J. Andrew Bagnell,  Zhiwei Steven Wu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Bellman residual minimization, including instrumental variable, conditional moment restrictions, instrumental variable regression, regression and Bellman</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A variety of problems in econometrics and machine learning, including
instrumental variable regression and Bellman residual minimization, can be
formulated as satisfying a set of conditional moment restrictions (CMR). We
derive a general, game-theoretic strategy for satisfying CMR that scales to
nonlinear problems, is amenable to gradient-based optimization, and is able to
account for finite sample uncertainty. We recover the approaches of Dikkala et
al. and Dai et al. as special cases of our general framework before detailing
various extensions and how to efficiently solve the game defined by CMR.</p>
  </details>
</details>
<details>
  <summary>115. <b>标题：Meta Learning for High-dimensional Ising Model Selection Using  $\ell_1$-regularized Logistic Regression</b></summary>
  <p><b>编号</b>：[387]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09539</p>
  <p><b>作者</b>：Huiming Xie,  Jean Honorio</p>
  <p><b>备注</b>：arXiv admin note: text overlap with arXiv:1010.0311, arXiv:0804.4202 by other authors</p>
  <p><b>关键词</b>：regularized logistic regression, meta learning problem, high-dimensional Ising models, sufficient sample complexity, regularized logistic</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we consider the meta learning problem for estimating the
graphs associated with high-dimensional Ising models, using the method of
$\ell_1$-regularized logistic regression for neighborhood selection of each
node. Our goal is to use the information learned from the auxiliary tasks in
the learning of the novel task to reduce its sufficient sample complexity. To
this end, we propose a novel generative model as well as an improper estimation
method. In our setting, all the tasks are \emph{similar} in their \emph{random}
model parameters and supports. By pooling all the samples from the auxiliary
tasks to \emph{improperly} estimate a single parameter vector, we can recover
the true support union, assumed small in size, with a high probability with a
sufficient sample complexity of $\Omega(1) $ per task, for $K = \Omega(d^3 \log
p ) $ tasks of Ising models with $p$ nodes and a maximum neighborhood size $d$.
Then, with the support for the novel task restricted to the estimated support
union, we prove that consistent neighborhood selection for the novel task can
be obtained with a reduced sufficient sample complexity of $\Omega(d^3 \log
d)$.</p>
  </details>
</details>
<details>
  <summary>116. <b>标题：Intersection of Parallels as an Early Stopping Criterion</b></summary>
  <p><b>编号</b>：[390]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09529</p>
  <p><b>作者</b>：Ali Vardasbi,  Maarten de Rijke,  Mostafa Dehghani</p>
  <p><b>备注</b>：CIKM 2022</p>
  <p><b>关键词</b>：validation set, training, iterative evaluation, find a sweet, set</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A common way to avoid overfitting in supervised learning is early stopping,
where a held-out set is used for iterative evaluation during training to find a
sweet spot in the number of training steps that gives maximum generalization.
However, such a method requires a disjoint validation set, thus part of the
labeled data from the training set is usually left out for this purpose, which
is not ideal when training data is scarce. Furthermore, when the training
labels are noisy, the performance of the model over a validation set may not be
an accurate proxy for generalization. In this paper, we propose a method to
spot an early stopping point in the training iterations without the need for a
validation set. We first show that in the overparameterized regime the randomly
initialized weights of a linear model converge to the same direction during
training. Using this result, we propose to train two parallel instances of a
linear model, initialized with different random seeds, and use their
intersection as a signal to detect overfitting. In order to detect
intersection, we use the cosine distance between the weights of the parallel
models during training iterations. Noticing that the final layer of a NN is a
linear map of pre-last layer activations to output logits, we build on our
criterion for linear models and propose an extension to multi-layer networks,
using the new notion of counterfactual weights. We conduct experiments on two
areas that early stopping has noticeable impact on preventing overfitting of a
NN: (i) learning from noisy labels; and (ii) learning to rank in IR. Our
experiments on four widely used datasets confirm the effectiveness of our
method for generalization. For a wide range of learning rates, our method,
called Cosine-Distance Criterion (CDC), leads to better generalization on
average than all the methods that we compare against in almost all of the
tested cases.</p>
  </details>
</details>
<details>
  <summary>117. <b>标题：Recurrent Neural Network-based Anti-jamming Framework for Defense  Against Multiple Jamming Policies</b></summary>
  <p><b>编号</b>：[395]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09518</p>
  <p><b>作者</b>：Ali Pourranjbar,  Georges Kaddoum,  Walid Saad</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：multiple jammers, anti-jamming methods, Conventional anti-jamming methods, proposed anti-jamming methods, preventing single jammer</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Conventional anti-jamming methods mainly focus on preventing single jammer
attacks with an invariant jamming policy or jamming attacks from multiple
jammers with similar jamming policies. These anti-jamming methods are
ineffective against a single jammer following several different jamming
policies or multiple jammers with distinct policies. Therefore, this paper
proposes an anti-jamming method that can adapt its policy to the current
jamming attack. Moreover, for the multiple jammers scenario, an anti-jamming
method that estimates the future occupied channels using the jammers' occupied
channels in previous time slots is proposed. In both single and multiple
jammers scenarios, the interaction between the users and jammers is modeled
using recurrent neural networks (RNN)s. The performance of the proposed
anti-jamming methods is evaluated by calculating the users' successful
transmission rate (STR) and ergodic rate (ER), and compared to a baseline based
on Q-learning (DQL). Simulation results show that for the single jammer
scenario, all the considered jamming policies are perfectly detected and high
STR and ER are maintained. Moreover, when 70 % of the spectrum is under jamming
attacks from multiple jammers, the proposed method achieves an STR and ER
greater than 75 % and 80 %, respectively. These values rise to 90 % when 30 %
of the spectrum is under jamming attacks. In addition, the proposed
anti-jamming methods significantly outperform the DQL method for all the
considered cases and jamming scenarios.</p>
  </details>
</details>
<details>
  <summary>118. <b>标题：Exploring Popularity Bias in Music Recommendation Models and Commercial  Steaming Services</b></summary>
  <p><b>编号</b>：[396]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09517</p>
  <p><b>作者</b>：Douglas R. Turnbull,  Sean McQuillan,  Vera Crabtree,  John Hunter,  Sunny Zhang</p>
  <p><b>备注</b>：Music Recommendation, Popularity bias, Recommender Systems, 6 pages</p>
  <p><b>关键词</b>：unduly favor popular, favor popular artists, Popularity bias, unduly favor, favor popular</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Popularity bias is the idea that a recommender system will unduly favor
popular artists when recommending artists to users. As such, they may
contribute to a winner-take-all marketplace in which a small number of artists
receive nearly all of the attention, while similarly meritorious artists are
unlikely to be discovered. In this paper, we attempt to measure popularity bias
in three state-of-art recommender system models (e.g., SLIM, Multi-VAE, WRMF)
and on three commercial music streaming services (Spotify, Amazon Music,
YouTube). We find that the most accurate model (SLIM) also has the most
popularity bias while less accurate models have less popularity bias. We also
find no evidence of popularity bias in the commercial recommendations based on
a simulated user experiment.</p>
  </details>
</details>
<details>
  <summary>119. <b>标题：Spectral Decomposition Representation for Reinforcement Learning</b></summary>
  <p><b>编号</b>：[397]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09515</p>
  <p><b>作者</b>：Tongzheng Ren,  Tianjun Zhang,  Lisa Lee,  Joseph E. Gonzalez,  Dale Schuurmans,  Bo Dai</p>
  <p><b>备注</b>：The first two authors contribute equally</p>
  <p><b>关键词</b>：Spectral Decomposition Representation, curse of dimensionality, plays a critical, critical role, role in reinforcement</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Representation learning often plays a critical role in reinforcement learning
by managing the curse of dimensionality. A representative class of algorithms
exploits a spectral decomposition of the stochastic transition dynamics to
construct representations that enjoy strong theoretical properties in an
idealized setting. However, current spectral methods suffer from limited
applicability because they are constructed for state-only aggregation and
derived from a policy-dependent transition kernel, without considering the
issue of exploration. To address these issues, we propose an alternative
spectral method, Spectral Decomposition Representation (SPEDER), that extracts
a state-action abstraction from the dynamics without inducing spurious
dependence on the data collection policy, while also balancing the
exploration-versus-exploitation trade-off during learning. A theoretical
analysis establishes the sample efficiency of the proposed algorithm in both
the online and offline settings. In addition, an experimental investigation
demonstrates superior performance over current state-of-the-art algorithms
across several benchmarks.</p>
  </details>
</details>
<details>
  <summary>120. <b>标题：Scale invariant process regression</b></summary>
  <p><b>编号</b>：[406]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10461</p>
  <p><b>作者</b>：Matthias Wieler</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：medium datasets, small to medium, non-parametric regression, process, Gaussian processes</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Gaussian processes are the leading method for non-parametric regression on
small to medium datasets. One main challenge is the choice of kernel and
optimization of hyperparameters. We propose a novel regression method that does
not require specification of a kernel, length scale, variance, nor prior mean.
Its only hyperparameter is the assumed regularity (degree of differentiability)
of the true function.
We achieve this with a novel non-Gaussian stochastic process that we
construct from minimal assumptions of translation and scale invariance. The
process can be thought of as a hierarchical Gaussian process model, where the
hyperparameters have been incorporated into the process itself. To perform
inference with this process we develop the required mathematical tools.
It turns out that for interpolation, the posterior is a t-process with a
polyharmonic spline as mean. For regression, we state the exact posterior and
find its mean (again a polyharmonic spline) and approximate variance with a
sampling method. Experiments show a performance equal to that of Gaussian
processes with optimized hyperparameters.
The most important insight is that it is possible to derive a working machine
learning method by assuming nothing but regularity and scale- and translation
invariance, without any other model assumptions.</p>
  </details>
</details>
<details>
  <summary>121. <b>标题：A simple learning agent interacting with an agent-based market model</b></summary>
  <p><b>编号</b>：[407]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10434</p>
  <p><b>作者</b>：Matthew Dicks,  Tim Gebbie</p>
  <p><b>备注</b>：67 pages, 45 figures</p>
  <p><b>关键词</b>：single reinforcement learning, driven agent-based financial, event driven agent-based, optimal execution agent, reinforcement learning optimal</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We consider the learning dynamics of a single reinforcement learning optimal
execution trading agent when it interacts with an event driven agent-based
financial market model. Trading takes place asynchronously through a matching
engine in event time. The optimal execution agent is considered at different
levels of initial order-sizes and differently sized state spaces. The resulting
impact on the agent-based model and market are considered using a calibration
approach that explores changes in the empirical stylised facts and price impact
curves. Convergence, volume trajectory and action trace plots are used to
visualise the learning dynamics. This demonstrates how an optimal execution
agent learns optimal trading decisions inside a simulated reactive market
framework and how this in turn generates a back-reaction that changes the
simulated market through the introduction of strategic order-splitting.</p>
  </details>
</details>
<details>
  <summary>122. <b>标题：Exploiting Temporal Structures of Cyclostationary Signals for  Data-Driven Single-Channel Source Separation</b></summary>
  <p><b>编号</b>：[410]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10325</p>
  <p><b>作者</b>：Gary C.F. Lee,  Amir Weiss,  Alejandro Lancho,  Jennifer Tang,  Yuheng Bu,  Yury Polyanskiy,  Gregory W. Wornell</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：application domains, Unlike classical SCSS, classical SCSS approaches, study the problem, problem of single-channel</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We study the problem of single-channel source separation (SCSS), and focus on
cyclostationary signals, which are particularly suitable in a variety of
application domains. Unlike classical SCSS approaches, we consider a setting
where only examples of the sources are available rather than their models,
inspiring a data-driven approach. For source models with underlying
cyclostationary Gaussian constituents, we establish a lower bound on the
attainable mean squared error (MSE) for any separation method, model-based or
data-driven. Our analysis further reveals the operation for optimal separation
and the associated implementation challenges. As a computationally attractive
alternative, we propose a deep learning approach using a U-Net architecture,
which is competitive with the minimum MSE estimator. We demonstrate in
simulation that, with suitable domain-informed architectural choices, our U-Net
method can approach the optimal performance with substantially reduced
computational burden.</p>
  </details>
</details>
<details>
  <summary>123. <b>标题：Optimising Chest X-Rays for Image Analysis by Identifying and Removing  Confounding Factors</b></summary>
  <p><b>编号</b>：[412]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10320</p>
  <p><b>作者</b>：Shahab Aslani,  Watjana Lilaonitkul,  Vaishnavi Gnanananthan,  Divya Raj,  Bojidar Rangelov,  Alexandra L Young,  Yipeng Hu,  Paul Taylor,  Daniel C Alexander,  Joseph Jacob</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：clinical CXR acquisitions, CXR, CXR acquisitions, sheer volume, emergency setting</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>During the COVID-19 pandemic, the sheer volume of imaging performed in an
emergency setting for COVID-19 diagnosis has resulted in a wide variability of
clinical CXR acquisitions. This variation is seen in the CXR projections used,
image annotations added and in the inspiratory effort and degree of rotation of
clinical images. The image analysis community has attempted to ease the burden
on overstretched radiology departments during the pandemic by developing
automated COVID-19 diagnostic algorithms, the input for which has been CXR
imaging. Large publicly available CXR datasets have been leveraged to improve
deep learning algorithms for COVID-19 diagnosis. Yet the variable quality of
clinically-acquired CXRs within publicly available datasets could have a
profound effect on algorithm performance. COVID-19 diagnosis may be inferred by
an algorithm from non-anatomical features on an image such as image labels.
These imaging shortcuts may be dataset-specific and limit the generalisability
of AI systems. Understanding and correcting key potential biases in CXR images
is therefore an essential first step prior to CXR image analysis. In this
study, we propose a simple and effective step-wise approach to pre-processing a
COVID-19 chest X-ray dataset to remove undesired biases. We perform ablation
studies to show the impact of each individual step. The results suggest that
using our proposed pipeline could increase accuracy of the baseline COVID-19
detection algorithm by up to 13%.</p>
  </details>
</details>
<details>
  <summary>124. <b>标题：Predicting the protein-ligand affinity from molecular dynamics  trajectories</b></summary>
  <p><b>编号</b>：[414]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10230</p>
  <p><b>作者</b>：Yaosen Min,  Ye Wei,  Peizhuo Wang,  Nian Wu,  Stefan Bauer,  Shuxin Zheng,  Yu Shi,  Yingheng Wang,  Dan Zhao,  Ji Wu,  Jianyang Zeng</p>
  <p><b>备注</b>：initial version</p>
  <p><b>关键词</b>：molecular recognition problems, accurate protein-ligand binding, binding affinity prediction, protein-ligand binding affinity, recognition problems</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The accurate protein-ligand binding affinity prediction is essential in drug
design and many other molecular recognition problems. Despite many advances in
affinity prediction based on machine learning techniques, they are still
limited since the protein-ligand binding is determined by the dynamics of atoms
and molecules. To this end, we curated an MD dataset containing 3,218 dynamic
protein-ligand complexes and further developed Dynaformer, a graph-based deep
learning framework. Dynaformer can fully capture the dynamic binding rules by
considering various geometric characteristics of the interaction. Our method
shows superior performance over the methods hitherto reported. Moreover, we
performed virtual screening on heat shock protein 90 (HSP90) by integrating our
model with structure-based docking. We benchmarked our performance against
other baselines, demonstrating that our method can identify the molecule with
the highest experimental potency. We anticipate that large-scale MD dataset and
machine learning models will form a new synergy, providing a new route towards
accelerated drug discovery and optimization.</p>
  </details>
</details>
<details>
  <summary>125. <b>标题：Hierarchical Capsule Prediction Network for Marketing Campaigns Effect</b></summary>
  <p><b>编号</b>：[418]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10113</p>
  <p><b>作者</b>：Zhixuan Chu,  Hui Ding,  Guang Zeng,  Yuchen Huang,  Tan Yan,  Yulin Kang,  Sheng Li</p>
  <p><b>备注</b>：Proceedings of the 31st ACM International Conference on Information and Knowledge Management (CIKM '22)</p>
  <p><b>关键词</b>：Marketing campaigns, business goal, set of strategic, strategic activities, promote a business</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Marketing campaigns are a set of strategic activities that can promote a
business's goal. The effect prediction for marketing campaigns in a real
industrial scenario is very complex and challenging due to the fact that prior
knowledge is often learned from observation data, without any intervention for
the marketing campaign. Furthermore, each subject is always under the
interference of several marketing campaigns simultaneously. Therefore, we
cannot easily parse and evaluate the effect of a single marketing campaign. To
the best of our knowledge, there are currently no effective methodologies to
solve such a problem, i.e., modeling an individual-level prediction task based
on a hierarchical structure with multiple intertwined events. In this paper, we
provide an in-depth analysis of the underlying parse tree-like structure
involved in the effect prediction task and we further establish a Hierarchical
Capsule Prediction Network (HapNet) for predicting the effects of marketing
campaigns. Extensive results based on both the synthetic data and real data
demonstrate the superiority of our model over the state-of-the-art methods and
show remarkable practicability in real industrial applications.</p>
  </details>
</details>
<details>
  <summary>126. <b>标题：Learning Invariant Representations under General Interventions on the  Response</b></summary>
  <p><b>编号</b>：[422]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10027</p>
  <p><b>作者</b>：Kang Du,  Yu Xiang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：increasingly common nowadays, increasingly common, common nowadays, nowadays to collect, collect observations</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>It has become increasingly common nowadays to collect observations of feature
and response pairs from different environments. As a consequence, one has to
apply learned predictors to data with a different distribution due to
distribution shifts. One principled approach is to adopt the structural causal
models to describe training and test models, following the invariance principle
which says that the conditional distribution of the response given its
predictors remains the same across environments. However, this principle might
be violated in practical settings when the response is intervened. A natural
question is whether it is still possible to identify other forms of invariance
to facilitate prediction in unseen environments. To shed light on this
challenging scenario, we introduce invariant matching property (IMP) which is
an explicit relation to capture interventions through an additional feature.
This leads to an alternative form of invariance that enables a unified
treatment of general interventions on the response. We analyze the asymptotic
generalization errors of our method under both the discrete and continuous
environment settings, where the continuous case is handled by relating it to
the semiparametric varying coefficient models. We present algorithms that show
competitive performance compared to existing methods over various experimental
settings.</p>
  </details>
</details>
<details>
  <summary>127. <b>标题：Bayesian Complementary Kernelized Learning for Multidimensional  Spatiotemporal Data</b></summary>
  <p><b>编号</b>：[426]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09978</p>
  <p><b>作者</b>：Mengying Lei,  Aurelie Labbe,  Lijun Sun</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：real-world applications, multidimensional spatiotemporal data, spatiotemporal data, real-world spatiotemporal, spatiotemporal</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Probabilistic modeling of multidimensional spatiotemporal data is critical to
many real-world applications. However, real-world spatiotemporal data often
exhibits complex dependencies that are nonstationary, i.e., correlation
structure varies with location/time, and nonseparable, i.e., dependencies exist
between space and time. Developing effective and computationally efficient
statistical models to accommodate nonstationary/nonseparable processes
containing both long-range and short-scale variations becomes a challenging
task, especially for large-scale datasets with various corruption/missing
structures. In this paper, we propose a new statistical framework -- Bayesian
Complementary Kernelized Learning (BCKL) -- to achieve scalable probabilistic
modeling for multidimensional spatiotemporal data. To effectively describe
complex dependencies, BCKL integrates kernelized low-rank factorization with
short-range spatiotemporal Gaussian processes (GP), in which the two components
complement each other. Specifically, we use a multi-linear low-rank
factorization component to capture the global/long-range correlations in the
data and introduce an additive short-scale GP based on compactly supported
kernel functions to characterize the remaining local variabilities. We develop
an efficient Markov chain Monte Carlo (MCMC) algorithm for model inference and
evaluate the proposed BCKL framework on both synthetic and real-world
spatiotemporal datasets. Our results confirm the superior performance of BCKL
in providing accurate posterior mean and high-quality uncertainty estimates.</p>
  </details>
</details>
<details>
  <summary>128. <b>标题：Transfer Ranking in Finance: Applications to Cross-Sectional Momentum  with Data Scarcity</b></summary>
  <p><b>编号</b>：[427]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09968</p>
  <p><b>作者</b>：Daniel Poh,  Stephen Roberts,  Stefan Zohren</p>
  <p><b>备注</b>：15 pages, 9 figures</p>
  <p><b>关键词</b>：sophisticated neural architectures, performing variants incorporating, variants incorporating sophisticated, incorporating sophisticated neural, Fused Encoder Networks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Cross-sectional strategies are a classical and popular trading style, with
recent high performing variants incorporating sophisticated neural
architectures. While these strategies have been applied successfully to
data-rich settings involving mature assets with long histories, deploying them
on instruments with limited samples generally produces over-fitted models with
degraded performance. In this paper, we introduce Fused Encoder Networks -- a
hybrid parameter-sharing transfer ranking model. The model fuses information
extracted using an encoder-attention module operated on a source dataset with a
similar but separate module focused on a smaller target dataset of interest. In
addition to mitigating the issue of target data scarcity, the model's
self-attention mechanism enables interactions among instruments to be accounted
for, not just at the loss level during model training, but also at inference
time. Focusing on momentum applied to the top ten cryptocurrencies by market
capitalisation as a demonstrative use-case, the Fused Encoder Networks
outperforms the reference benchmarks on most performance measures, delivering a
three-fold boost in the Sharpe ratio over classical momentum as well as an
improvement of approximately 50% against the best benchmark model without
transaction costs. It continues outperforming baselines even after accounting
for the high transaction costs associated with trading cryptocurrencies.</p>
  </details>
</details>
<details>
  <summary>129. <b>标题：Do-AIQ: A Design-of-Experiment Approach to Quality Evaluation of AI  Mislabel Detection Algorithm</b></summary>
  <p><b>编号</b>：[428]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09953</p>
  <p><b>作者</b>：J. Lian,  K. Choi,  B. Veeramani,  A. Hu,  L. Freeman,  E. Bowen,  X. Deng</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Artificial Intelligence, confidently adopting algorithms, quality of Artificial, quality, autonomous driving</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The quality of Artificial Intelligence (AI) algorithms is of significant
importance for confidently adopting algorithms in various applications such as
cybersecurity, healthcare, and autonomous driving. This work presents a
principled framework of using a design-of-experimental approach to
systematically evaluate the quality of AI algorithms, named as Do-AIQ.
Specifically, we focus on investigating the quality of the AI mislabel data
algorithm against data poisoning. The performance of AI algorithms is affected
by hyperparameters in the algorithm and data quality, particularly, data
mislabeling, class imbalance, and data types. To evaluate the quality of the AI
algorithms and obtain a trustworthy assessment on the quality of the
algorithms, we establish a design-of-experiment framework to construct an
efficient space-filling design in a high-dimensional constraint space and
develop an effective surrogate model using additive Gaussian process to enable
the emulation of the quality of AI algorithms. Both theoretical and numerical
studies are conducted to justify the merits of the proposed framework. The
proposed framework can set an exemplar for AI algorithm to enhance the AI
assurance of robustness, reproducibility, and transparency.</p>
  </details>
</details>
<details>
  <summary>130. <b>标题：AA-Forecast: Anomaly-Aware Forecast for Extreme Events</b></summary>
  <p><b>编号</b>：[429]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09933</p>
  <p><b>作者</b>：Ashkan Farhangi,  Jiang Bian,  Arthur Huang,  Haoyi Xiong,  Jun Wang,  Zhishan Guo</p>
  <p><b>备注</b>：Data Mining and Knowledge Discovery</p>
  <p><b>关键词</b>：Time series models, extreme events, Time series, prevalent in real-world, events</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Time series models often deal with extreme events and anomalies, both
prevalent in real-world datasets. Such models often need to provide careful
probabilistic forecasting, which is vital in risk management for extreme events
such as hurricanes and pandemics. However, it is challenging to automatically
detect and learn to use extreme events and anomalies for large-scale datasets,
which often require manual effort. Hence, we propose an anomaly-aware forecast
framework that leverages the previously seen effects of anomalies to improve
its prediction accuracy during and after the presence of extreme events.
Specifically, the framework automatically extracts anomalies and incorporates
them through an attention mechanism to increase its accuracy for future extreme
events. Moreover, the framework employs a dynamic uncertainty optimization
algorithm that reduces the uncertainty of forecasts in an online manner. The
proposed framework demonstrated consistent superior accuracy with less
uncertainty on three datasets with different varieties of anomalies over the
current prediction models.</p>
  </details>
</details>
<details>
  <summary>131. <b>标题：Multiple Descent in the Multiple Random Feature Model</b></summary>
  <p><b>编号</b>：[431]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09897</p>
  <p><b>作者</b>：Xuran Meng,  Jianfeng Yao,  Yuan Cao</p>
  <p><b>备注</b>：81 pages, 9 figures</p>
  <p><b>关键词</b>：random feature model, random feature, double random feature, model parameters increases, highly over-parameterized</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent works have demonstrated a double descent phenomenon in
over-parameterized learning: as the number of model parameters increases, the
excess risk has a $\mathsf{U}$-shape at beginning, then decreases again when
the model is highly over-parameterized. Although this phenomenon has been
investigated by recent works under different settings such as linear models,
random feature models and kernel methods, it has not been fully understood in
theory. In this paper, we consider a double random feature model (DRFM)
consisting of two types of random features, and study the excess risk achieved
by the DRFM in ridge regression. We calculate the precise limit of the excess
risk under the high dimensional framework where the training sample size, the
dimension of data, and the dimension of random features tend to infinity
proportionally. Based on the calculation, we demonstrate that the risk curves
of DRFMs can exhibit triple descent. We then provide an explanation of the
triple descent phenomenon, and discuss how the ratio between random feature
dimensions, the regularization parameter and the signal-to-noise ratio control
the shape of the risk curves of DRFMs. At last, we extend our study to the
multiple random feature model (MRFM), and show that MRFMs with $K$ types of
random features may exhibit $(K+1)$-fold descent. Our analysis points out that
risk curves with a specific number of descent generally exist in random feature
based regression. Another interesting finding is that our result can recover
the risk peak locations reported in the literature when learning neural
networks are in the "neural tangent kernel" regime.</p>
  </details>
</details>
<details>
  <summary>132. <b>标题：G2Φnet: Relating Genotype and Biomechanical Phenotype of Tissues  with Deep Learning</b></summary>
  <p><b>编号</b>：[432]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09889</p>
  <p><b>作者</b>：Enrui Zhang,  Bart Spronck,  Jay D. Humphrey,  George Em Karniadakis</p>
  <p><b>备注</b>：41 pages, 9 figures</p>
  <p><b>关键词</b>：mutations adversely affect, genetic mutations adversely, disability or death, mutations adversely, adversely affect</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Many genetic mutations adversely affect the structure and function of
load-bearing soft tissues, with clinical sequelae often responsible for
disability or death. Parallel advances in genetics and histomechanical
characterization provide significant insight into these conditions, but there
remains a pressing need to integrate such information. We present a novel
genotype-to-biomechanical-phenotype neural network (G2{\Phi}net) for
characterizing and classifying biomechanical properties of soft tissues, which
serve as important functional readouts of tissue health or disease. We
illustrate the utility of our approach by inferring the nonlinear,
genotype-dependent constitutive behavior of the aorta for four mouse models
involving defects or deficiencies in extracellular constituents. We show that
G2{\Phi}net can infer the biomechanical response while simultaneously ascribing
the associated genotype correctly by utilizing limited, noisy, and unstructured
experimental data. More broadly, G2{\Phi}net provides a powerful method and a
paradigm shift for correlating genotype and biomechanical phenotype
quantitatively, promising a better understanding of their interplay in
biological tissues.</p>
  </details>
</details>
<details>
  <summary>133. <b>标题：Robust Tests in Online Decision-Making</b></summary>
  <p><b>编号</b>：[434]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09819</p>
  <p><b>作者</b>：Gi-Soo Kim,  Hyun-Joon Yang,  Jane P. Kim</p>
  <p><b>备注</b>：17 pages, 1 figure, supplementary material for "Robust Tests in Online Decision-Making" published in Proceedings of the AAAI Conference on Artificial Intelligence (2022)</p>
  <p><b>关键词</b>：sequential decision problems, sequential decision, decision problems, problems to maximize, maximize the cumulative</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Bandit algorithms are widely used in sequential decision problems to maximize
the cumulative reward. One potential application is mobile health, where the
goal is to promote the user's health through personalized interventions based
on user specific information acquired through wearable devices. Important
considerations include the type of, and frequency with which data is collected
(e.g. GPS, or continuous monitoring), as such factors can severely impact app
performance and users' adherence. In order to balance the need to collect data
that is useful with the constraint of impacting app performance, one needs to
be able to assess the usefulness of variables. Bandit feedback data are
sequentially correlated, so traditional testing procedures developed for
independent data cannot apply. Recently, a statistical testing procedure was
developed for the actor-critic bandit algorithm. An actor-critic algorithm
maintains two separate models, one for the actor, the action selection policy,
and the other for the critic, the reward model. The performance of the
algorithm as well as the validity of the test are guaranteed only when the
critic model is correctly specified. However, misspecification is frequent in
practice due to incorrect functional form or missing covariates. In this work,
we propose a modified actor-critic algorithm which is robust to critic
misspecification and derive a novel testing procedure for the actor parameters
in this case.</p>
  </details>
</details>
<details>
  <summary>134. <b>标题：On Robustness in Nonconvex Optimization with Application to Defense  Planning</b></summary>
  <p><b>编号</b>：[442]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09725</p>
  <p><b>作者</b>：Johannes O. Royset</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：structured nonconvex optimization, nonconvex robust optimization, nominal problem, local Lipschitz moduli, context of structured</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In the context of structured nonconvex optimization, we estimate the increase
in minimum value for a decision that is robust to parameter perturbations as
compared to the value of a nominal problem. The estimates rely on detailed
expressions for subgradients and local Lipschitz moduli of min-value functions
in nonconvex robust optimization and require only the solution of the nominal
problem. The theoretical results are illustrated by examples from military
operations research involving mixed-integer optimization models. Across 54
cases examined, the median error in estimating the increase in minimum value is
12%. Therefore, the derived expressions for subgradients and local Lipschitz
moduli may accurately inform analysts about the possibility of obtaining
cost-effective, parameter-robust decisions in nonconvex optimization.</p>
  </details>
</details>
<details>
  <summary>135. <b>标题：Adversarial contamination of networks in the setting of vertex  nomination: a new trimming method</b></summary>
  <p><b>编号</b>：[444]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09710</p>
  <p><b>作者</b>：Sheyda Peyman,  Minh Tang,  Vince Lyzinski</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：complex data domains, robust inferential graph, inferential graph algorithms, domains is crucial, robust inferential</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As graph data becomes more ubiquitous, the need for robust inferential graph
algorithms to operate in these complex data domains is crucial. In many cases
of interest, inference is further complicated by the presence of adversarial
data contamination. The effect of the adversary is frequently to change the
data distribution in ways that negatively affect statistical and algorithmic
performance. We study this phenomenon in the context of vertex nomination, a
semi-supervised information retrieval task for network data. Here, a common
suite of methods relies on spectral graph embeddings, which have been shown to
provide both good algorithmic performance and flexible settings in which
regularization techniques can be implemented to help mitigate the effect of an
adversary. Many current regularization methods rely on direct network trimming
to effectively excise the adversarial contamination, although this direct
trimming often gives rise to complicated dependency structures in the resulting
graph. We propose a new trimming method that operates in model space which can
address both block structure contamination and white noise contamination
(contamination whose distribution is unknown). This model trimming is more
amenable to theoretical analysis while also demonstrating superior performance
in a number of simulations, compared to direct trimming.</p>
  </details>
</details>
<details>
  <summary>136. <b>标题：Machine learning based surrogate models for microchannel heat sink  optimization</b></summary>
  <p><b>编号</b>：[445]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09683</p>
  <p><b>作者</b>：Ante Sikirica,  Luka Grbčić,  Lado Kranjčević</p>
  <p><b>备注</b>：30 pages, brief appendix</p>
  <p><b>关键词</b>：computational fluid dynamics, propose optimal solutions, optimal solutions based, secondary channels, computational fluid</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, microchannel designs with secondary channels and with ribs are
investigated using computational fluid dynamics and are coupled with a
multi-objective optimization algorithm to determine and propose optimal
solutions based on observed thermal resistance and pumping power. A workflow
that combines Latin hypercube sampling, machine learning-based surrogate
modeling and multi-objective optimization is proposed. Random forests, gradient
boosting algorithms and neural networks were considered during the search for
the best surrogate. We demonstrated that tuned neural networks can make
accurate predictions and be used to create an acceptable surrogate model.
Optimized solutions show a negligible difference in overall performance when
compared to the conventional optimization approach. Additionally, solutions are
calculated in one-fifth of the original time. Generated designs attain
temperatures that are lower by more than 10% under the same pressure limits as
a convectional microchannel design. When limited by temperature, pressure drops
are reduced by more than 25%. Finally, the influence of each design variable on
the thermal resistance and pumping power was investigated by employing the
SHapley Additive exPlanations technique. Overall, we have demonstrated that the
proposed framework has merit and can be used as a viable methodology in
microchannel heat sink design optimization.</p>
  </details>
</details>
<details>
  <summary>137. <b>标题：Transferable Cross-Tokamak Disruption Prediction with Deep Hybrid Neural  Network Feature Extractor</b></summary>
  <p><b>编号</b>：[448]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09594</p>
  <p><b>作者</b>：Wei Zheng,  Fengming Xue,  Ming Zhang,  Zhongyong Chen,  Chengshuo Shen,  Xinkun Ai,  Nengchao Wang,  Dalong Chen,  Bihao Guo,  Yonghua Ding,  Zhipeng Chen,  Zhoujun Yang,  Biao Shen,  Bingjia Xiao,  Yuan Pan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：obstacle to overcome, disruption, great obstacle, disruption prediction model, feature extractor</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Predicting disruptions across different tokamaks is a great obstacle to
overcome. Future tokamaks can hardly tolerate disruptions at high performance
discharge. Few disruption discharges at high performance can hardly compose an
abundant training set, which makes it difficult for current data-driven methods
to obtain an acceptable result. A machine learning method capable of
transferring a disruption prediction model trained on one tokamak to another is
required to solve the problem. The key is a disruption prediction model
containing a feature extractor that is able to extract common disruption
precursor traces in tokamak diagnostic data, and a transferable disruption
classifier. Based on the concerns above, the paper first presents a deep fusion
feature extractor designed specifically for extracting disruption precursor
features from common diagnostics on tokamaks according to currently known
precursors of disruption, providing a promising foundation for transferable
models. The fusion feature extractor is proved by comparing with manual feature
extraction on J-TEXT. Based on the feature extractor trained on J-TEXT, the
disruption prediction model was transferred to EAST data with mere 20
discharges from EAST experiment. The performance is comparable with a model
trained with 1896 discharges from EAST. From the comparison among other model
training scenarios, transfer learning showed its potential in predicting
disruptions across different tokamaks.</p>
  </details>
</details>
<details>
  <summary>138. <b>标题：Neural network facilitated ab initio derivation of linear formula: A  case study on formulating the relationship between DNA motifs and gene  expression</b></summary>
  <p><b>编号</b>：[451]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09559</p>
  <p><b>作者</b>：Chengyu Liu,  Wei Wang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：high interpretability, quantify relationships, relationships between biological, biological data, Developing models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Developing models with high interpretability and even deriving formulas to
quantify relationships between biological data is an emerging need. We propose
here a framework for ab initio derivation of sequence motifs and linear formula
using a new approach based on the interpretable neural network model called
contextual regression model. We showed that this linear model could predict
gene expression levels using promoter sequences with a performance comparable
to deep neural network models. We uncovered a list of 300 motifs with important
regulatory roles on gene expression and showed that they also had significant
contributions to cell-type specific gene expression in 154 diverse cell types.
This work illustrates the possibility of deriving formulas to represent biology
laws that may not be easily elucidated.
(this https URL)</p>
  </details>
</details>
<details>
  <summary>139. <b>标题：Sudakov-Fernique post-AMP, and a new proof of the local convexity of the  TAP free energy</b></summary>
  <p><b>编号</b>：[452]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09550</p>
  <p><b>作者</b>：Michael Celentano</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：non-convex risk function, risk function eventually, function eventually enters, non-convex risk, risk function</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In many problems in modern statistics and machine learning, it is often of
interest to establish that a first order method on a non-convex risk function
eventually enters a region of parameter space in which the risk is locally
convex. We derive an asymptotic comparison inequality, which we call the
Sudakov-Fernique post-AMP inequality, which, in a certain class of problems
involving a GOE matrix, is able to probe properties of an optimization
landscape locally around the iterates of an approximate message passing (AMP)
algorithm. As an example of its use, we provide a new, and arguably simpler,
proof of some of the results of Celentano et al. (2021), which establishes that
the so-called TAP free energy in the $\mathbb{Z}_2$-synchronization problem is
locally convex in the region to which AMP converges. We further prove a
conjecture of El Alaoui et al. (2022) involving the local convexity of a
related but distinct TAP free energy, which, as a consequence, confirms that
their algorithm efficiently samples from the Sherrington-Kirkpatrick Gibbs
measure throughout the "easy" regime.</p>
  </details>
</details>
<details>
  <summary>140. <b>标题：Predicting Exotic Hadron Masses with Data Augmentation Using Multilayer  Perceptron</b></summary>
  <p><b>编号</b>：[453]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09538</p>
  <p><b>作者</b>：Huseyin Bahtiyar</p>
  <p><b>备注</b>：8 pages, 4 figures</p>
  <p><b>关键词</b>：physics literature, neural networks, significant developments, neural, Constituent Quark Model</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recently, there have been significant developments in neural networks; thus,
neural networks have been frequently used in the physics literature. This work
estimates the masses of exotic hadrons, doubly charmed and bottomed baryons
from the meson and baryon masses using neural networks. Subsequently, the
number of data has been increased using the artificial data augmentation
technique proposed recently. We have observed that the neural network's
predictive ability increases using augmented data. This study has shown that
data augmentation techniques play an essential role in improving neural network
predictions; moreover, neural networks can make reasonable predictions for
exotic hadrons, doubly charmed, and doubly bottomed baryons. The results are
also comparable to Gaussian Process and Constituent Quark Model.</p>
  </details>
</details>
<details>
  <summary>141. <b>标题：Exploring the Limits of Synthetic Creation of Solar EUV Images via  Image-to-Image Translation</b></summary>
  <p><b>编号</b>：[454]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09512</p>
  <p><b>作者</b>：Valentina Salvatelli,  Luiz F. G. dos Santos,  Souvik Bose,  Brad Neuberg,  Mark C. M. Cheung,  Miho Janvier,  Meng Jin,  Yarin Gal,  Atilim Gunes Baydin</p>
  <p><b>备注</b>：16 pages, 8 figures. To be published on ApJ (submitted on Feb 21st, accepted on July 28th)</p>
  <p><b>关键词</b>：Solar Dynamics Observatory, NASA multi-spectral decade-long, daily producing terabytes, Dynamics Observatory, multi-spectral decade-long mission</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The Solar Dynamics Observatory (SDO), a NASA multi-spectral decade-long
mission that has been daily producing terabytes of observational data from the
Sun, has been recently used as a use-case to demonstrate the potential of
machine learning methodologies and to pave the way for future deep-space
mission planning. In particular, the idea of using image-to-image translation
to virtually produce extreme ultra-violet channels has been proposed in several
recent studies, as a way to both enhance missions with less available channels
and to alleviate the challenges due to the low downlink rate in deep space.
This paper investigates the potential and the limitations of such a deep
learning approach by focusing on the permutation of four channels and an
encoder--decoder based architecture, with particular attention to how
morphological traits and brightness of the solar surface affect the neural
network predictions. In this work we want to answer the question: can synthetic
images of the solar corona produced via image-to-image translation be used for
scientific studies of the Sun? The analysis highlights that the neural network
produces high-quality images over three orders of magnitude in count rate
(pixel intensity) and can generally reproduce the covariance across channels
within a 1% error. However the model performance drastically diminishes in
correspondence of extremely high energetic events like flares, and we argue
that the reason is related to the rareness of such events posing a challenge to
model training.</p>
  </details>
</details>
<details>
  <summary>142. <b>标题：In Silico Prediction of Blood-Brain Barrier Permeability of Chemical  Compounds through Molecular Feature Modeling</b></summary>
  <p><b>编号</b>：[455]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09484</p>
  <p><b>作者</b>：Tanish Jain,  Praveen Kumar Pandian Shanmuganathan</p>
  <p><b>备注</b>：Editor Praveen Kumar Pandian Shanmuganathan, 17 pages, 5 figures</p>
  <p><b>关键词</b>：analytical study, analyze chemical data, chemical data, blood-brain barrier, biological systems</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The introduction of computational techniques to analyze chemical data has
given rise to the analytical study of biological systems, known as
"bioinformatics". One facet of bioinformatics is using machine learning (ML)
technology to detect multivariable trends in various cases. Amongst the most
pressing cases is predicting blood-brain barrier (BBB) permeability. The
development of new drugs to treat central nervous system disorders presents
unique challenges due to poor penetration efficacy across the blood-brain
barrier. In this research, we aim to mitigate this problem through an ML model
that analyzes chemical features. To do so: (i) An overview into the relevant
biological systems and processes as well as the use case is given. (ii) Second,
an in-depth literature review of existing computational techniques for
detecting BBB permeability is undertaken. From there, an aspect unexplored
across current techniques is identified and a solution is proposed. (iii)
Lastly, a two-part in silico model to quantify likelihood of permeability of
drugs with defined features across the BBB through passive diffusion is
developed, tested, and reflected on. Testing and validation with the dataset
determined the predictive logBB model's mean squared error to be around 0.112
units and the neuroinflammation model's mean squared error to be approximately
0.3 units, outperforming all relevant studies found.</p>
  </details>
</details>
<details>
  <summary>143. <b>标题：Blind Image Deblurring with Unknown Kernel Size and Substantial Noise</b></summary>
  <p><b>编号</b>：[456]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09483</p>
  <p><b>作者</b>：Zhong Zhuang,  Taihui Li,  Hengkang Wang,  Ju Sun</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Blind image deblurring, Blind image, image deblurring, adjacent fields, extensively studied</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Blind image deblurring (BID) has been extensively studied in computer vision
and adjacent fields. Modern methods for BID can be grouped into two categories:
single-instance methods that deal with individual instances using statistical
inference and numerical optimization, and data-driven methods that train
deep-learning models to deblur future instances directly. Data-driven methods
can be free from the difficulty in deriving accurate blur models, but are
fundamentally limited by the diversity and quality of the training data --
collecting sufficiently expressive and realistic training data is a standing
challenge. In this paper, we focus on single-instance methods that remain
competitive and indispensable. However, most such methods do not prescribe how
to deal with unknown kernel size and substantial noise, precluding practical
deployment. Indeed, we show that several state-of-the-art (SOTA)
single-instance methods are unstable when the kernel size is overspecified,
and/or the noise level is high. On the positive side, we propose a practical
BID method that is stable against both, the first of its kind. Our method
builds on the recent ideas of solving inverse problems by integrating the
physical models and structured deep neural networks, without extra training
data. We introduce several crucial modifications to achieve the desired
stability. Extensive empirical tests on standard synthetic datasets, as well as
real-world NTIRE2020 and RealBlur datasets, show the superior effectiveness and
practicality of our BID method compared to SOTA single-instance as well as
data-driven methods. The code of our method is available at:
\url{this https URL}.</p>
  </details>
</details>
<details>
  <summary>144. <b>标题：Graph neural networks for materials science and chemistry</b></summary>
  <p><b>编号</b>：[457]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09481</p>
  <p><b>作者</b>：Patrick Reiser,  Marlen Neubert,  André Eberhard,  Luca Torresi,  Chen Zhou,  Chen Shao,  Houssam Metni,  Clint van Hoesel,  Henrik Schopmans,  Timo Sommer,  Pascal Friederich</p>
  <p><b>备注</b>：37 pages, 2 figures</p>
  <p><b>关键词</b>：predict synthesis routes, predict materials properties, increasingly important role, Machine learning plays, predict synthesis</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Machine learning plays an increasingly important role in many areas of
chemistry and materials science, e.g. to predict materials properties, to
accelerate simulations, to design new materials, and to predict synthesis
routes of new materials. Graph neural networks (GNNs) are one of the fastest
growing classes of machine learning models. They are of particular relevance
for chemistry and materials science, as they directly work on a graph or
structural representation of molecules and materials and therefore have full
access to all relevant information required to characterize materials. In this
review article, we provide an overview of the basic principles of GNNs, widely
used datasets, and state-of-the-art architectures, followed by a discussion of
a wide range of recent applications of GNNs in chemistry and materials science,
and concluding with a road-map for the further development and application of
GNNs.</p>
  </details>
</details>
<details>
  <summary>145. <b>标题：Stock Performance Evaluation for Portfolio Design from Different Sectors  of the Indian Stock Market</b></summary>
  <p><b>编号</b>：[458]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.07166</p>
  <p><b>作者</b>：Jaydip Sen,  Arpit Awad,  Aaditya Raj,  Gourav Ray,  Pusparna Chakraborty,  Sanket Das,  Subhasmita Mishra</p>
  <p><b>备注</b>：The report is 113 pages long. The report is based on the capstone project done in the post graduate course of data science in Praxis Business School, Kolkata, India - Group 5 of the Autumn Batch, 2021. arXiv admin note: text overlap with arXiv:2201.05570; text overlap with arXiv:2005.11417 by other authors</p>
  <p><b>关键词</b>：publicly listed companies, stock market offers, stock price prediction, listed companies, Portfolio</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The stock market offers a platform where people buy and sell shares of
publicly listed companies. Generally, stock prices are quite volatile; hence
predicting them is a daunting task. There is still much research going to
develop more accuracy in stock price prediction. Portfolio construction refers
to the allocation of different sector stocks optimally to achieve a maximum
return by taking a minimum risk. A good portfolio can help investors earn
maximum profit by taking a minimum risk. Beginning with Dow Jones Theory a lot
of advancement has happened in the area of building efficient portfolios. In
this project, we have tried to predict the future value of a few stocks from
six important sectors of the Indian economy and also built a portfolio. As part
of the project, our team has conducted a study of the performance of various
Time series, machine learning, and deep learning models in stock price
prediction on selected stocks from the chosen six important sectors of the
economy. As part of building an efficient portfolio, we have studied multiple
portfolio optimization theories beginning with the Modern Portfolio theory. We
have built a minimum variance portfolio and optimal risk portfolio for all the
six chosen sectors by using the daily stock prices over the past five years as
training data and have also conducted back testing to check the performance of
the portfolio. We look forward to continuing our study in the area of stock
price prediction and asset allocation and consider this project as the first
stepping stone.</p>
  </details>
</details>
<h1>人工智能</h1>
<details>
  <summary>1. <b>标题：Prioritizing Samples in Reinforcement Learning with Reducible Loss</b></summary>
  <p><b>编号</b>：[1]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10483</p>
  <p><b>作者</b>：Shivakanth Sujit,  Somjit Nath,  Pedro H. M. Braga,  Samira Ebrahimi Kahou</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：reinforcement learning algorithms, reinforcement learning, buffer to repeatedly, repeatedly train, agent has observed</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Most reinforcement learning algorithms take advantage of an experience replay
buffer to repeatedly train on samples the agent has observed in the past. This
prevents catastrophic forgetting, however simply assigning equal importance to
each of the samples is a naive strategy. In this paper, we propose a method to
prioritize samples based on how much we can learn from a sample. We define the
learn-ability of a sample as the steady decrease of the training loss
associated with this sample over time. We develop an algorithm to prioritize
samples with high learn-ability, while assigning lower priority to those that
are hard-to-learn, typically caused by noise or stochasticity. We empirically
show that our method is more robust than random sampling and also better than
just prioritizing with respect to the training loss, i.e. the temporal
difference loss, which is used in vanilla prioritized experience replay.</p>
  </details>
</details>
<details>
  <summary>2. <b>标题：BARReL: Bottleneck Attention for Adversarial Robustness in Vision-Based  Reinforcement Learning</b></summary>
  <p><b>编号</b>：[2]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10481</p>
  <p><b>作者</b>：Eugene Bykovets,  Yannick Metz,  Mennatallah El-Assady,  Daniel A. Keim,  Joachim M. Buhmann</p>
  <p><b>备注</b>：5 pages, 2 figures, 3 tables</p>
  <p><b>关键词</b>：computer vision, areas of computer, vision-based reinforcement learning, vision-based reinforcement, reinforcement learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Robustness to adversarial perturbations has been explored in many areas of
computer vision. This robustness is particularly relevant in vision-based
reinforcement learning, as the actions of autonomous agents might be
safety-critic or impactful in the real world. We investigate the susceptibility
of vision-based reinforcement learning agents to gradient-based adversarial
attacks and evaluate a potential defense. We observe that Bottleneck Attention
Modules (BAM) included in CNN architectures can act as potential tools to
increase robustness against adversarial attacks. We show how learned attention
maps can be used to recover activations of a convolutional layer by restricting
the spatial activations to salient regions. Across a number of RL environments,
BAM-enhanced architectures show increased robustness during inference. Finally,
we discuss potential future research directions.</p>
  </details>
</details>
<details>
  <summary>3. <b>标题：Automated Pruning of Polyculture Plants</b></summary>
  <p><b>编号</b>：[6]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10472</p>
  <p><b>作者</b>：Mark Presten,  Rishi Parikh,  Shrey Aeron,  Sandeep Mukherjee,  Simeon Adebola,  Satvik Sharma,  Mark Theis,  Walter Teitelbaum,  Ken Goldberg</p>
  <p><b>备注</b>：CASE 2022, 8 pages. arXiv admin note: substantial text overlap with arXiv:2111.06014</p>
  <p><b>关键词</b>：Polyculture farming, monoculture farming, environmental advantages, advantages but requires, requires substantially</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Polyculture farming has environmental advantages but requires substantially
more pruning than monoculture farming. We present novel hardware and algorithms
for automated pruning. Using an overhead camera to collect data from a physical
scale garden testbed, the autonomous system utilizes a learned Plant
Phenotyping convolutional neural network and a Bounding Disk Tracking algorithm
to evaluate the individual plant distribution and estimate the state of the
garden each day. From this garden state, AlphaGardenSim selects plants to
autonomously prune. A trained neural network detects and targets specific prune
points on the plant. Two custom-designed pruning tools, compatible with a
FarmBot gantry system, are experimentally evaluated and execute autonomous cuts
through controlled algorithms. We present results for four 60-day garden
cycles. Results suggest the system can autonomously achieve 0.94 normalized
plant diversity with pruning shears while maintaining an average canopy
coverage of 0.84 by the end of the cycles. For code, videos, and datasets, see
this https URL.</p>
  </details>
</details>
<details>
  <summary>4. <b>标题：Get It in Writing: Formal Contracts Mitigate Social Dilemmas in  Multi-Agent RL</b></summary>
  <p><b>编号</b>：[7]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10469</p>
  <p><b>作者</b>：Phillip J.K. Christoffersen,  Andreas A. Haupt,  Dylan Hadfield-Menell</p>
  <p><b>备注</b>：12 pages, 7 figures</p>
  <p><b>关键词</b>：Multi-agent reinforcement learning, training automated systems, automated systems acting, systems acting independently, Multi-agent reinforcement</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Multi-agent reinforcement learning (MARL) is a powerful tool for training
automated systems acting independently in a common environment. However, it can
lead to sub-optimal behavior when individual incentives and group incentives
diverge. Humans are remarkably capable at solving these social dilemmas. It is
an open problem in MARL to replicate such cooperative behaviors in selfish
agents. In this work, we draw upon the idea of formal contracting from
economics to overcome diverging incentives between agents in MARL. We propose
an augmentation to a Markov game where agents voluntarily agree to binding
state-dependent transfers of reward, under pre-specified conditions. Our
contributions are theoretical and empirical. First, we show that this
augmentation makes all subgame-perfect equilibria of all fully observed Markov
games exhibit socially optimal behavior, given a sufficiently rich space of
contracts. Next, we complement our game-theoretic analysis by showing that
state-of-the-art RL algorithms learn socially optimal policies given our
augmentation. Our experiments include classic static dilemmas like Stag Hunt,
Prisoner's Dilemma and a public goods game, as well as dynamic interactions
that simulate traffic, pollution management and common pool resource
management.</p>
  </details>
</details>
<details>
  <summary>5. <b>标题：ProtoPFormer: Concentrating on Prototypical Parts in Vision Transformers  for Interpretable Image Recognition</b></summary>
  <p><b>编号</b>：[22]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10431</p>
  <p><b>作者</b>：Mengqi Xue,  Qihan Huang,  Haofei Zhang,  Lechao Cheng,  Jie Song,  Minghui Wu,  Mingli Song</p>
  <p><b>备注</b>：Arxiv preprint; 9 pages, 6 figures, 2 tables</p>
  <p><b>关键词</b>：explainable artificial intelligence, follow-up studies due, drawn wide attention, Prototypical part network, artificial intelligence</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Prototypical part network (ProtoPNet) has drawn wide attention and boosted
many follow-up studies due to its self-explanatory property for explainable
artificial intelligence (XAI). However, when directly applying ProtoPNet on
vision transformer (ViT) backbones, learned prototypes have a ''distraction''
problem: they have a relatively high probability of being activated by the
background and pay less attention to the foreground. The powerful capability of
modeling long-term dependency makes the transformer-based ProtoPNet hard to
focus on prototypical parts, thus severely impairing its inherent
interpretability. This paper proposes prototypical part transformer
(ProtoPFormer) for appropriately and effectively applying the prototype-based
method with ViTs for interpretable image recognition. The proposed method
introduces global and local prototypes for capturing and highlighting the
representative holistic and partial features of targets according to the
architectural characteristics of ViTs. The global prototypes are adopted to
provide the global view of objects to guide local prototypes to concentrate on
the foreground while eliminating the influence of the background. Afterwards,
local prototypes are explicitly supervised to concentrate on their respective
prototypical visual parts, increasing the overall interpretability. Extensive
experiments demonstrate that our proposed global and local prototypes can
mutually correct each other and jointly make final decisions, which faithfully
and transparently reason the decision-making processes associatively from the
whole and local perspectives, respectively. Moreover, ProtoPFormer consistently
achieves superior performance and visualization results over the
state-of-the-art (SOTA) prototype-based baselines. Our code has been released
at this https URL.</p>
  </details>
</details>
<details>
  <summary>6. <b>标题：Patient-level Microsatellite Stability Assessment from Whole Slide  Images By Combining Momentum Contrast Learning and Group Patch Embeddings</b></summary>
  <p><b>编号</b>：[23]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10429</p>
  <p><b>作者</b>：Daniel Shats,  Hadar Hezi,  Guy Shani,  Yosef E. Maruvka,  Moti Freiman</p>
  <p><b>备注</b>：To appear in the proceedings of the ECCV workshop on Medical Computer Vision (ECCV-MCV 2022). Link: this https URL</p>
  <p><b>关键词</b>：personalizing treatment regime, WSI high resolution, patient colorectal cancer, treatment regime, WSI</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Assessing microsatellite stability status of a patient's colorectal cancer is
crucial in personalizing treatment regime. Recently,
convolutional-neural-networks (CNN) combined with transfer-learning approaches
were proposed to circumvent traditional laboratory testing for determining
microsatellite status from hematoxylin and eosin stained biopsy whole slide
images (WSI). However, the high resolution of WSI practically prevent direct
classification of the entire WSI. Current approaches bypass the WSI high
resolution by first classifying small patches extracted from the WSI, and then
aggregating patch-level classification logits to deduce the patient-level
status. Such approaches limit the capacity to capture important information
which resides at the high resolution WSI data. We introduce an effective
approach to leverage WSI high resolution information by momentum contrastive
learning of patch embeddings along with training a patient-level classifier on
groups of those embeddings. Our approach achieves up to 7.4\% better accuracy
compared to the straightforward patch-level classification and patient level
aggregation approach with a higher stability (AUC, $0.91 \pm 0.01$ vs. $0.85
\pm 0.04$, p-value$<0.01$). our code can be found at this https url.< p>
  </0.01$).></p></details>
</details>
<details>
  <summary>7. <b>标题：MetaFi: Device-Free Pose Estimation via Commodity WiFi for Metaverse  Avatar Simulation</b></summary>
  <p><b>编号</b>：[28]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10414</p>
  <p><b>作者</b>：Jianfei Yang,  Yunjiao Zhou,  He Huang,  Han Zou,  Lihua Xie</p>
  <p><b>备注</b>：6 pages, 3 figures, 3 tables</p>
  <p><b>关键词</b>：physical user, activities and interact, human pose estimation, human pose, Avatar refers</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Avatar refers to a representative of a physical user in the virtual world
that can engage in different activities and interact with other objects in
metaverse. Simulating the avatar requires accurate human pose estimation.
Though camera-based solutions yield remarkable performance, they encounter the
privacy issue and degraded performance caused by varying illumination,
especially in smart home. In this paper, we propose a WiFi-based IoT-enabled
human pose estimation scheme for metaverse avatar simulation, namely MetaFi.
Specifically, a deep neural network is designed with customized convolutional
layers and residual blocks to map the channel state information to human pose
landmarks. It is enforced to learn the annotations from the accurate computer
vision model, thus achieving cross-modal supervision. WiFi is ubiquitous and
robust to illumination, making it a feasible solution for avatar applications
in smart home. The experiments are conducted in the real world, and the results
show that the MetaFi achieves very high performance with a PCK@50 of 95.23%.</p>
  </details>
</details>
<details>
  <summary>8. <b>标题：On Deep Learning in Password Guessing, a Survey</b></summary>
  <p><b>编号</b>：[29]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10413</p>
  <p><b>作者</b>：Fangyi Yu</p>
  <p><b>备注</b>：8 pages, 4 figures, 3 tables. arXiv admin note: substantial text overlap with arXiv:2208.06943</p>
  <p><b>关键词</b>：Recurrent Neural Networks, password, dictionary attacks, security, password security</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The security of passwords is dependent on a thorough understanding of the
strategies used by attackers. Unfortunately, real-world adversaries use
pragmatic guessing tactics like dictionary attacks, which are difficult to
simulate in password security research. Dictionary attacks must be carefully
configured and modified to be representative of the actual threat. This
approach, however, needs domain-specific knowledge and expertise that are
difficult to duplicate. This paper compares various deep learning-based
password guessing approaches that do not require domain knowledge or
assumptions about users' password structures and combinations. The involved
model categories are Recurrent Neural Networks, Generative Adversarial
Networks, Autoencoder, and Attention mechanisms. Additionally, we proposed a
promising research experimental design on using variations of IWGAN on password
guessing under non-targeted offline attacks. Using these advanced strategies,
we can enhance password security and create more accurate and efficient
Password Strength Meters.</p>
  </details>
</details>
<details>
  <summary>9. <b>标题：Constants of motion network</b></summary>
  <p><b>编号</b>：[37]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10387</p>
  <p><b>作者</b>：Muhammad Firmansyah Kasim,  Yi Heng Lim</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：constants of motion, beauty of physics, conserved quantity, motion, always-changing system</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The beauty of physics is that there is usually a conserved quantity in an
always-changing system, known as the constant of motion. Finding the constant
of motion is important in understanding the dynamics of the system, but
typically requires mathematical proficiency and manual analytical work. In this
paper, we present a neural network that can simultaneously learn the dynamics
of the system and the constants of motion from data. By exploiting the
discovered constants of motion, it can produce better predictions on dynamics
and can work on a wider range of systems than Hamiltonian-based neural
networks. In addition, the training progresses of our method can be used as an
indication of the number of constants of motion in a system which could be
useful in studying a novel physical system.</p>
  </details>
</details>
<details>
  <summary>10. <b>标题：Inductive Knowledge Graph Reasoning for Multi-batch Emerging Entities</b></summary>
  <p><b>编号</b>：[42]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10378</p>
  <p><b>作者</b>：Yuanning Cui,  Yuxin Wang,  Zequn Sun,  Wenqiang Liu,  Yiqiao Jiang,  Kexin Han,  Wei Hu</p>
  <p><b>备注</b>：Accepted in the 31st ACM International Conference on Information and Knowledge Management (CIKM 2022)</p>
  <p><b>关键词</b>：aims to infer, infer new conclusions, focused on static, static KGs, KGs</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Over the years, reasoning over knowledge graphs (KGs), which aims to infer
new conclusions from known facts, has mostly focused on static KGs. The
unceasing growth of knowledge in real life raises the necessity to enable the
inductive reasoning ability on expanding KGs. Existing inductive work assumes
that new entities all emerge once in a batch, which oversimplifies the real
scenario that new entities continually appear. This study dives into a more
realistic and challenging setting where new entities emerge in multiple
batches. We propose a walk-based inductive reasoning model to tackle the new
setting. Specifically, a graph convolutional network with adaptive relation
aggregation is designed to encode and update entities using their neighboring
relations. To capture the varying neighbor importance, we employ a query-aware
feedback attention mechanism during the aggregation. Furthermore, to alleviate
the sparse link problem of new entities, we propose a link augmentation
strategy to add trustworthy facts into KGs. We construct three new datasets for
simulating this multi-batch emergence scenario. The experimental results show
that our proposed model outperforms state-of-the-art embedding-based,
walk-based and rule-based models on inductive KG reasoning.</p>
  </details>
</details>
<details>
  <summary>11. <b>标题：High-quality Task Division for Large-scale Entity Alignment</b></summary>
  <p><b>编号</b>：[47]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10366</p>
  <p><b>作者</b>：Bing Liu,  Wen Hua,  Guido Zuccon,  Genghong Zhao,  Xia Zhang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Entity Alignment, step for Knowledge, Knowledge Graph, real-world objects, key step</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Entity Alignment (EA) aims to match equivalent entities that refer to the
same real-world objects and is a key step for Knowledge Graph (KG) fusion. Most
neural EA models cannot be applied to large-scale real-life KGs due to their
excessive consumption of GPU memory and time. One promising solution is to
divide a large EA task into several subtasks such that each subtask only needs
to match two small subgraphs of the original KGs. However, it is challenging to
divide the EA task without losing effectiveness. Existing methods display low
coverage of potential mappings, insufficient evidence in context graphs, and
largely differing subtask sizes.
In this work, we design the DivEA framework for large-scale EA with
high-quality task division. To include in the EA subtasks a high proportion of
the potential mappings originally present in the large EA task, we devise a
counterpart discovery method that exploits the locality principle of the EA
task and the power of trained EA models. Unique to our counterpart discovery
method is the explicit modelling of the chance of a potential mapping. We also
introduce an evidence passing mechanism to quantify the informativeness of
context entities and find the most informative context graphs with flexible
control of the subtask size. Extensive experiments show that DivEA achieves
higher EA performance than alternative state-of-the-art solutions.</p>
  </details>
</details>
<details>
  <summary>12. <b>标题：Scaling Up Dynamic Graph Representation Learning via Spiking Neural  Networks</b></summary>
  <p><b>编号</b>：[48]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10364</p>
  <p><b>作者</b>：Jintang Li,  Zhouxin Yu,  Zulun Zhu,  Liang Chen,  Qi Yu,  Zibin Zheng,  Sheng Tian,  Ruofan Wu,  Changhua Meng</p>
  <p><b>备注</b>：Preprint; Code available at this https URL</p>
  <p><b>关键词</b>：temporal graphs, temporal, graph representation learning, dynamic graph representation, Recent years</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent years have seen a surge in research on dynamic graph representation
learning, which aims to model temporal graphs that are dynamic and evolving
constantly over time. However, current work typically models graph dynamics
with recurrent neural networks (RNNs), making them suffer seriously from
computation and memory overheads on large temporal graphs. So far, scalability
of dynamic graph representation learning on large temporal graphs remains one
of the major challenges. In this paper, we present a scalable framework, namely
SpikeNet, to efficiently capture the temporal and structural patterns of
temporal graphs. We explore a new direction in that we can capture the evolving
dynamics of temporal graphs with spiking neural networks (SNNs) instead of
RNNs. As a low-power alternative to RNNs, SNNs explicitly model graph dynamics
as spike trains of neuron populations and enable spike-based propagation in an
efficient way. Experiments on three large real-world temporal graph datasets
demonstrate that SpikeNet outperforms strong baselines on the temporal node
classification task with lower computational costs. Particularly, SpikeNet
generalizes to a large temporal graph (2M nodes and 13M edges) with
significantly fewer parameters and computation overheads. Our code is publicly
available at this https URL</p>
  </details>
</details>
<details>
  <summary>13. <b>标题：Repurposing Knowledge Graph Embeddings for Triple Representation via  Weak Supervision</b></summary>
  <p><b>编号</b>：[57]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10328</p>
  <p><b>作者</b>：Alexander Kalinowski,  Yuan An</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：techniques treat entities, separate embedding matrices, embedding techniques treat, techniques treat, treat entities</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The majority of knowledge graph embedding techniques treat entities and
predicates as separate embedding matrices, using aggregation functions to build
a representation of the input triple. However, these aggregations are lossy,
i.e. they do not capture the semantics of the original triples, such as
information contained in the predicates. To combat these shortcomings, current
methods learn triple embeddings from scratch without utilizing entity and
predicate embeddings from pre-trained models. In this paper, we design a novel
fine-tuning approach for learning triple embeddings by creating weak
supervision signals from pre-trained knowledge graph embeddings. We develop a
method for automatically sampling triples from a knowledge graph and estimating
their pairwise similarities from pre-trained embedding models. These pairwise
similarity scores are then fed to a Siamese-like neural architecture to
fine-tune triple representations. We evaluate the proposed method on two widely
studied knowledge graphs and show consistent improvement over other
state-of-the-art triple embedding methods on triple classification and triple
clustering tasks.</p>
  </details>
</details>
<details>
  <summary>14. <b>标题：Incorporating Rivalry in Reinforcement Learning for a Competitive Game</b></summary>
  <p><b>编号</b>：[58]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10327</p>
  <p><b>作者</b>：Pablo Barros,  Ozge Nilay Yalcın,  Ana Tanevska,  Alessandra Sciutti</p>
  <p><b>备注</b>：Accepted at the Neural Computing and Applications Journal</p>
  <p><b>关键词</b>：specific interaction tasks, achieve human-level performance, Recent advances, interaction tasks, achieve human-level</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent advances in reinforcement learning with social agents have allowed
such models to achieve human-level performance on specific interaction tasks.
However, most interactive scenarios do not have a version alone as an end goal;
instead, the social impact of these agents when interacting with humans is as
important and largely unexplored. In this regard, this work proposes a novel
reinforcement learning mechanism based on the social impact of rivalry
behavior. Our proposed model aggregates objective and social perception
mechanisms to derive a rivalry score that is used to modulate the learning of
artificial agents. To investigate our proposed model, we design an interactive
game scenario, using the Chef's Hat Card Game, and examine how the rivalry
modulation changes the agent's playing style, and how this impacts the
experience of human players in the game. Our results show that humans can
detect specific social characteristics when playing against rival agents when
compared to common agents, which directly affects the performance of the human
players in subsequent games. We conclude our work by discussing how the
different social and objective features that compose the artificial rivalry
score contribute to our results.</p>
  </details>
</details>
<details>
  <summary>15. <b>标题：Semi-supervised classification using a supervised autoencoder for  biomedical applications</b></summary>
  <p><b>编号</b>：[61]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10315</p>
  <p><b>作者</b>：Cyprien Gille,  Frederic Guyard,  Michel Barlaud</p>
  <p><b>备注</b>：9 pages</p>
  <p><b>关键词</b>：Fully Connected Neural, Connected Neural Network, biomedical applications, involving a supervised, paper we present</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper we present a new approach to solve semi-supervised
classification tasks for biomedical applications, involving a supervised
autoencoder network. We create a network architecture that encodes labels into
the latent space of an autoencoder, and define a global criterion combining
classification and reconstruction losses. We train the Semi-Supervised
AutoEncoder (SSAE) on labelled data using a double descent algorithm. Then, we
classify unlabelled samples using the learned network thanks to a softmax
classifier applied to the latent space which provides a classification
confidence score for each class.
We implemented our SSAE method using the PyTorch framework for the model,
optimizer, schedulers, and loss functions. We compare our semi-supervised
autoencoder method (SSAE) with classical semi-supervised methods such as Label
Propagation and Label Spreading, and with a Fully Connected Neural Network
(FCNN). Experiments show that the SSAE outperforms Label Propagation and
Spreading and the Fully Connected Neural Network both on a synthetic dataset
and on two real-world biological datasets.</p>
  </details>
</details>
<details>
  <summary>16. <b>标题：BigBraveBN: algorithm of structural learning for bayesian networks with  a large number of nodes</b></summary>
  <p><b>编号</b>：[62]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10312</p>
  <p><b>作者</b>：Yury Kaminsky,  Irina Deeva</p>
  <p><b>备注</b>：The article contains 10 pages and 10 figures</p>
  <p><b>关键词</b>：Bayesian networks, learning Bayesian networks, number of nodes, large Bayesian Networks, Bayesian</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Learning a Bayesian network is an NP-hard problem and with an increase in the
number of nodes, classical algorithms for learning the structure of Bayesian
networks become inefficient. In recent years, some methods and algorithms for
learning Bayesian networks with a high number of nodes (more than 50) were
developed. But these solutions have their disadvantages, for instance, they
only operate one type of data (discrete or continuous) or their algorithm has
been created to meet a specific nature of data (medical, social, etc.). The
article presents a BigBraveBN algorithm for learning large Bayesian Networks
with a high number of nodes (over 100). The algorithm utilizes the Brave
coefficient that measures the mutual occurrence of instances in several groups.
To form these groups, we use the method of nearest neighbours based on the
Mutual information (MI) measure. In the experimental part of the article, we
compare the performance of BigBraveBN to other existing solutions on multiple
data sets both discrete and continuous. The experimental part also represents
tests on real data. The aforementioned experimental results demonstrate the
efficiency of the BigBraveBN algorithm in structure learning of Bayesian
Networks.</p>
  </details>
</details>
<details>
  <summary>17. <b>标题：Efficient Utility Function Learning for Multi-Objective Parameter  Optimization with Prior Knowledge</b></summary>
  <p><b>编号</b>：[67]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10300</p>
  <p><b>作者</b>：Farha A. Khan,  Jörg P. Dietrich,  Christian Wirth</p>
  <p><b>备注</b>：16 pages</p>
  <p><b>关键词</b>：complete Pareto front, utility function, Pareto front, complete Pareto, utility function interactively</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The current state-of-the-art in multi-objective optimization assumes either a
given utility function, learns a utility function interactively or tries to
determine the complete Pareto front, requiring a post elicitation of the
preferred result. However, result elicitation in real world problems is often
based on implicit and explicit expert knowledge, making it difficult to define
a utility function, whereas interactive learning or post elicitation requires
repeated and expensive expert involvement. To mitigate this, we learn a utility
function offline, using expert knowledge by means of preference learning. In
contrast to other works, we do not only use (pairwise) result preferences, but
also coarse information about the utility function space. This enables us to
improve the utility function estimate, especially when using very few results.
Additionally, we model the occurring uncertainties in the utility function
learning task and propagate them through the whole optimization chain. Our
method to learn a utility function eliminates the need of repeated expert
involvement while still leading to high-quality results. We show the sample
efficiency and quality gains of the proposed method in 4 domains, especially in
cases where the surrogate utility function is not able to exactly capture the
true expert utility function. We also show that to obtain good results, it is
important to consider the induced uncertainties and analyze the effect of
biased samples, which is a common problem in real world domains.</p>
  </details>
</details>
<details>
  <summary>18. <b>标题：To show or not to show: Redacting sensitive text from videos of  electronic displays</b></summary>
  <p><b>编号</b>：[84]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10270</p>
  <p><b>作者</b>：Abhishek Mukhopadhyay,  Shubham Agarwal,  Patrick Dylan Zwick,  Pradipta Biswas</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：increasing prevalence, maintain the privacy, Google Cloud Vision, video recordings, OCR</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>With the increasing prevalence of video recordings there is a growing need
for tools that can maintain the privacy of those recorded. In this paper, we
define an approach for redacting personally identifiable text from videos using
a combination of optical character recognition (OCR) and natural language
processing (NLP) techniques. We examine the relative performance of this
approach when used with different OCR models, specifically Tesseract and the
OCR system from Google Cloud Vision (GCV). For the proposed approach the
performance of GCV, in both accuracy and speed, is significantly higher than
Tesseract. Finally, we explore the advantages and disadvantages of both models
in real-world applications.</p>
  </details>
</details>
<details>
  <summary>19. <b>标题：A semantic web approach to uplift decentralized household energy data</b></summary>
  <p><b>编号</b>：[87]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10265</p>
  <p><b>作者</b>：Jiantao Wu,  Fabrizio Orlandi,  Tarek AlSkaif,  Declan O'Sullivan,  Soumyabrata Dev</p>
  <p><b>备注</b>：Published in Sustainable Energy, Grids and Networks (SEGAN)</p>
  <p><b>关键词</b>：electric energy consumption, electric vehicles, achieve energy sustainability, energy system comprised, home appliances</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In a decentralized household energy system comprised of various devices such
as home appliances, electric vehicles, and solar panels, end-users are able to
dig deeper into the system's details and further achieve energy sustainability
if they are presented with data on the electric energy consumption and
production at the granularity of the device. However, many databases in this
field are siloed from other domains, including solely information pertaining to
energy. This may result in the loss of information (\textit{e.g.} weather) on
each device's energy use. Meanwhile, a large number of these datasets have been
extensively used in computational modeling techniques such as machine learning
models. While such computational approaches achieve great accuracy and
performance by concentrating only on a local view of datasets, model
reliability cannot be guaranteed since such models are very vulnerable to data
input fluctuations when information omission is taken into account. This
article tackles the data isolation issue in the field of smart energy systems
by examining Semantic Web methods on top of a household energy system. We offer
an ontology-based approach for managing decentralized data at the device-level
resolution in a system. As a consequence, the scope of the data associated with
each device may easily be expanded in an interoperable manner throughout the
Web, and additional information, such as weather, can be obtained from the Web,
provided that the data is organized according to W3C standards.</p>
  </details>
</details>
<details>
  <summary>20. <b>标题：Using Large Language Models to Simulate Multiple Humans</b></summary>
  <p><b>编号</b>：[88]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10264</p>
  <p><b>作者</b>：Gati Aher,  Rosa I. Arriaga,  Adam Tauman Kalai</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：language, language model, large language model, large language, model</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose a method for using a large language model, such as GPT-3, to
simulate responses of different humans in a given context. We test our method
by attempting to reproduce well-established economic, psycholinguistic, and
social experiments. The method requires prompt templates for each experiment.
Simulations are run by varying the (hypothetical) subject details such as name
and analyzing the text generated by the language model. We validate our
methodology by using GPT-3, to show that it is possible to simulate responses
of different people and that their responses are consistent with prior human
studies from the literature. We find that the distributions generated by larger
language models better align with prior experimental results, suggesting a
trend that future language models may be used for even more faithful
simulations of human responses. Our use of a language model for simulation is
contrasted with anthropomorphic views of a language model as having its own
behavior.</p>
  </details>
</details>
<details>
  <summary>21. <b>标题：Information-Theoretic Equivalence of Entropic Multi-Marginal Optimal  Transport: a Theory for Multi-Agent Communication</b></summary>
  <p><b>编号</b>：[90]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10256</p>
  <p><b>作者</b>：Shuchan Wang</p>
  <p><b>备注</b>：This work is the unfinished doctoral thesis of Mr. Shuchan Wang at Sorbonne University and EURECOM. Mr. Wang has to leave EURECOM and is therefore unable to continue his study</p>
  <p><b>关键词</b>：multi-marginal optimal transport, optimal transport, MOT, entropic optimal transport, propose our information-theoretic</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we propose our information-theoretic equivalence of entropic
multi-marginal optimal transport (MOT). This equivalence can be easily reduced
to the case of entropic optimal transport (OT). Because OT is widely used to
compare differences between knowledge or beliefs, we apply this result to the
communication between agents with different beliefs. Our results formally prove
the statement that entropic OT is information-theoretically optimal given by
Wang et al. [2020] and generalize it to the multi-agent case. We believe that
our work can shed light on OT theory in future multi-agent teaming systems.</p>
  </details>
</details>
<details>
  <summary>22. <b>标题：On the non-efficient PAC learnability of acyclic conjunctive queries</b></summary>
  <p><b>编号</b>：[91]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10255</p>
  <p><b>作者</b>：Balder ten Cate,  Maurice Funk,  Jean Christoph Jung,  Carsten Lutz</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：serves three purposes, efficiently PAC learnable, note serves, provide a self-contained, self-contained exposition</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This note serves three purposes: (i) we provide a self-contained exposition
of the fact that conjunctive queries are not efficiently learnable in the
Probably-Approximately-Correct (PAC) model, paying clear attention to the
complicating fact that this concept class lacks the polynomial-size fitting
property, a property that is tacitly assumed in much of the computational
learning theory literature; (ii) we establish a strong negative PAC
learnability result that applies to many restricted classes of conjunctive
queries (CQs), including acyclic CQs for a wide range of notions of
"acyclicity"; (iii) we show that CQs are efficiently PAC learnable with
membership queries.</p>
  </details>
</details>
<details>
  <summary>23. <b>标题：Rethinking Textual Adversarial Defense for Pre-trained Language Models</b></summary>
  <p><b>编号</b>：[94]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10251</p>
  <p><b>作者</b>：Jiayi Wang,  Rongzhou Bao,  Zhuosheng Zhang,  Hai Zhao</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：recent studies demonstrate, pre-trained language models, adversarial, achieved significant success, language models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Although pre-trained language models (PrLMs) have achieved significant
success, recent studies demonstrate that PrLMs are vulnerable to adversarial
attacks. By generating adversarial examples with slight perturbations on
different levels (sentence / word / character), adversarial attacks can fool
PrLMs to generate incorrect predictions, which questions the robustness of
PrLMs. However, we find that most existing textual adversarial examples are
unnatural, which can be easily distinguished by both human and machine. Based
on a general anomaly detector, we propose a novel metric (Degree of Anomaly) as
a constraint to enable current adversarial attack approaches to generate more
natural and imperceptible adversarial examples. Under this new constraint, the
success rate of existing attacks drastically decreases, which reveals that the
robustness of PrLMs is not as fragile as they claimed. In addition, we find
that four types of randomization can invalidate a large portion of textual
adversarial examples. Based on anomaly detector and randomization, we design a
universal defense framework, which is among the first to perform textual
adversarial defense without knowing the specific attack. Empirical results show
that our universal defense framework achieves comparable or even higher
after-attack accuracy with other specific defenses, while preserving higher
original accuracy at the same time. Our work discloses the essence of textual
adversarial attacks, and indicates that (1) further works of adversarial
attacks should focus more on how to overcome the detection and resist the
randomization, otherwise their adversarial examples would be easily detected
and invalidated; and (2) compared with the unnatural and perceptible
adversarial examples, it is those undetectable adversarial examples that pose
real risks for PrLMs and require more attention for future robustness-enhancing
strategies.</p>
  </details>
</details>
<details>
  <summary>24. <b>标题：Multi-Task Learning for Depression Detection in Dialogs</b></summary>
  <p><b>编号</b>：[95]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10250</p>
  <p><b>作者</b>：Chuyuan Li (SEMAGRAMME, LORIA),  Chloé Braud (IRIT),  Maxime Amblard (SEMAGRAMME, LORIA)</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：people communicate, mental illness, illness that impacts, Depression, allegedly</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Depression is a serious mental illness that impacts the way people
communicate, especially through their emotions, and, allegedly, the way they
interact with others. This work examines depression signals in dialogs, a less
studied setting that suffers from data sparsity. We hypothesize that depression
and emotion can inform each other, and we propose to explore the influence of
dialog structure through topic and dialog act prediction. We investigate a
Multi-Task Learning (MTL) approach, where all tasks mentioned above are learned
jointly with dialog-tailored hierarchical modeling. We experiment on the DAIC
and DailyDialog corpora-both contain dialogs in English-and show important
improvements over state-ofthe-art on depression detection (at best 70.6% F 1),
which demonstrates the correlation of depression with emotion and dialog
organization and the power of MTL to leverage information from different
sources.</p>
  </details>
</details>
<details>
  <summary>25. <b>标题：Prediction of User Request and Complaint in Spoken Customer-Agent  Conversations</b></summary>
  <p><b>编号</b>：[96]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10249</p>
  <p><b>作者</b>：Nikola Lackovic,  Claude Montacié,  Gauthier Lalande,  Marie-José Caraty</p>
  <p><b>备注</b>：5 pages, 1 figure, 4 tables</p>
  <p><b>关键词</b>：feature sets, General Data Protection, Malakoff Humanis, features, sets</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present the corpus called HealthCall. This was recorded in real-life
conditions in the call center of Malakoff Humanis. It includes two separate
audio channels, the first one for the customer and the second one for the
agent. Each conversation was anonymized respecting the General Data Protection
Regulation. This corpus includes a transcription of the spoken conversations
and was divided into two sets: Train and Devel sets. Two important customer
relationship management tasks were assessed on the HealthCall corpus: Automatic
prediction of type of user requests and complaints detection. For this purpose,
we have investigated 14 feature sets: 6 linguistic feature sets, 6 audio
feature sets and 2 vocal interaction feature sets. We have used Bidirectional
Encoder Representation from Transformers models for the linguistic features,
openSMILE and Wav2Vec 2.0 for the audio features. The vocal interaction feature
sets were designed and developed from Turn Takings. The results show that the
linguistic features always give the best results (91.2% for the Request task
and 70.3% for the Complaint task). The Wav2Vec 2.0 features seem more suitable
for these two tasks than the ComPaRe16 features. Vocal interaction features
outperformed ComPaRe16 features on Complaint task with a 57% rate achieved with
only six features.</p>
  </details>
</details>
<details>
  <summary>26. <b>标题：Unit Testing for Concepts in Neural Networks</b></summary>
  <p><b>编号</b>：[101]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10244</p>
  <p><b>作者</b>：Charles Lovering,  Ellie Pavlick</p>
  <p><b>备注</b>：TACL, In Press. 12 Pages</p>
  <p><b>关键词</b>：complex problems, problems are naturally, naturally understood, understood in terms, concepts</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Many complex problems are naturally understood in terms of symbolic concepts.
For example, our concept of "cat" is related to our concepts of "ears" and
"whiskers" in a non-arbitrary way. Fodor (1998) proposes one theory of
concepts, which emphasizes symbolic representations related via constituency
structures. Whether neural networks are consistent with such a theory is open
for debate. We propose unit tests for evaluating whether a system's behavior is
consistent with several key aspects of Fodor's criteria. Using a simple visual
concept learning task, we evaluate several modern neural architectures against
this specification. We find that models succeed on tests of groundedness,
modularlity, and reusability of concepts, but that important questions about
causality remain open. Resolving these will require new methods for analyzing
models' internal states.</p>
  </details>
</details>
<details>
  <summary>27. <b>标题：One Model, Any CSP: Graph Neural Networks as Fast Global Search  Heuristics for Constraint Satisfaction</b></summary>
  <p><b>编号</b>：[109]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10227</p>
  <p><b>作者</b>：Jan Tönshoff,  Berke Kisin,  Jakob Lindner,  Martin Grohe</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Constraint Satisfaction Problem, Neural Network architecture, Graph Neural Network, Satisfaction Problem, Constraint Satisfaction</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose a universal Graph Neural Network architecture which can be trained
as an end-2-end search heuristic for any Constraint Satisfaction Problem (CSP).
Our architecture can be trained unsupervised with policy gradient descent to
generate problem specific heuristics for any CSP in a purely data driven
manner. The approach is based on a novel graph representation for CSPs that is
both generic and compact and enables us to process every possible CSP instance
with one GNN, regardless of constraint arity, relations or domain size. Unlike
previous RL-based methods, we operate on a global search action space and allow
our GNN to modify any number of variables in every step of the stochastic
search. This enables our method to properly leverage the inherent parallelism
of GNNs. We perform a thorough empirical evaluation where we learn heuristics
for well known and important CSPs from random data, including graph coloring,
MaxCut, 3-SAT and MAX-k-SAT. Our approach outperforms prior approaches for
neural combinatorial optimization by a substantial margin. It can compete with,
and even improve upon, conventional search heuristics on test instances that
are several orders of magnitude larger and structurally more complex than those
seen during training.</p>
  </details>
</details>
<details>
  <summary>28. <b>标题：From Easy to Hard: A Dual Curriculum Learning Framework for  Context-Aware Document Ranking</b></summary>
  <p><b>编号</b>：[110]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10226</p>
  <p><b>作者</b>：Yutao Zhu,  Jian-Yun Nie,  Yixuan Su,  Haonan Chen,  Xinyu Zhang,  Zhicheng Dou</p>
  <p><b>备注</b>：CIKM 2022 Camera Ready</p>
  <p><b>关键词</b>：capturing users' search, Contextual information, important for capturing, capturing users', users' search intents</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Contextual information in search sessions is important for capturing users'
search intents. Various approaches have been proposed to model user behavior
sequences to improve document ranking in a session. Typically, training samples
of (search context, document) pairs are sampled randomly in each training
epoch. In reality, the difficulty to understand user's search intent and to
judge document's relevance varies greatly from one search context to another.
Mixing up training samples of different difficulties may confuse the model's
optimization process. In this work, we propose a curriculum learning framework
for context-aware document ranking, in which the ranking model learns matching
signals between the search context and the candidate document in an
easy-to-hard manner. In so doing, we aim to guide the model gradually toward a
global optimum. To leverage both positive and negative examples, two curricula
are designed. Experiments on two real query log datasets show that our proposed
framework can improve the performance of several existing methods
significantly, demonstrating the effectiveness of curriculum learning for
context-aware document ranking.</p>
  </details>
</details>
<details>
  <summary>29. <b>标题：Dynamic Adaptive Threshold based Learning for Noisy Annotations Robust  Facial Expression Recognition</b></summary>
  <p><b>编号</b>：[112]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10221</p>
  <p><b>作者</b>：Darshan Gera,  Naveen Siva Kumar Badveeti,  Bobbili Veerendra Raj Kumar,  S Balasubramanian</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：facial expression recognition, real-world facial expression, noisy annotations due, expression recognition, facial expression</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The real-world facial expression recognition (FER) datasets suffer from noisy
annotations due to crowd-sourcing, ambiguity in expressions, the subjectivity
of annotators and inter-class similarity. However, the recent deep networks
have strong capacity to memorize the noisy annotations leading to corrupted
feature embedding and poor generalization. To handle noisy annotations, we
propose a dynamic FER learning framework (DNFER) in which clean samples are
selected based on dynamic class specific threshold during training.
Specifically, DNFER is based on supervised training using selected clean
samples and unsupervised consistent training using all the samples. During
training, the mean posterior class probabilities of each mini-batch is used as
dynamic class-specific threshold to select the clean samples for supervised
training. This threshold is independent of noise rate and does not need any
clean data unlike other methods. In addition, to learn from all samples, the
posterior distributions between weakly-augmented image and strongly-augmented
image are aligned using an unsupervised consistency loss. We demonstrate the
robustness of DNFER on both synthetic as well as on real noisy annotated FER
datasets like RAFDB, FERPlus, SFEW and AffectNet.</p>
  </details>
</details>
<details>
  <summary>30. <b>标题：KEEP: An Industrial Pre-Training Framework for Online Recommendation via  Knowledge Extraction and Plugging</b></summary>
  <p><b>编号</b>：[125]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10174</p>
  <p><b>作者</b>：Yujing Zhang,  Zhangming Chan,  Shuhao Xu,  Weijie Bian,  Shuguang Han,  Hongbo Deng,  Bo Zheng</p>
  <p><b>备注</b>：Accepted at CIKM 2022, 10 pages. Yujing Zhang and Zhangming Chan contributed equally to this work</p>
  <p><b>关键词</b>：recommender system generally, system generally presents, generally presents, presents a hybrid, hybrid list</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>An industrial recommender system generally presents a hybrid list that
contains results from multiple subsystems. In practice, each subsystem is
optimized with its own feedback data to avoid the disturbance among different
subsystems. However, we argue that such data usage may lead to sub-optimal
online performance because of the \textit{data sparsity}. To alleviate this
issue, we propose to extract knowledge from the \textit{super-domain} that
contains web-scale and long-time impression data, and further assist the online
recommendation task (downstream task). To this end, we propose a novel
industrial \textbf{K}nowl\textbf{E}dge \textbf{E}xtraction and
\textbf{P}lugging (\textbf{KEEP}) framework, which is a two-stage framework
that consists of 1) a supervised pre-training knowledge extraction module on
super-domain, and 2) a plug-in network that incorporates the extracted
knowledge into the downstream model. This makes it friendly for incremental
training of online recommendation. Moreover, we design an efficient empirical
approach for KEEP and introduce our hands-on experience during the
implementation of KEEP in a large-scale industrial system. Experiments
conducted on two real-world datasets demonstrate that KEEP can achieve
promising results. It is notable that KEEP has also been deployed on the
display advertising system in Alibaba, bringing a lift of $+5.4\%$ CTR and
$+4.7\%$ RPM.</p>
  </details>
</details>
<details>
  <summary>31. <b>标题：BRIEF but Powerful: Byzantine-Robust and Privacy-Preserving Federated  Learning via Model Segmentation and Secure clustering</b></summary>
  <p><b>编号</b>：[132]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10161</p>
  <p><b>作者</b>：Rui Wang,  Xingkai Wang,  Huanhuan Chen,  Stjepan Picek,  Zhen Liu,  Kaitai Liang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Byzantine-robust Federated Learning, Federated Learning, accurate global model, extremely low attack, Byzantine-robust Federated</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Byzantine-robust Federated Learning (FL) aims to counter malicious clients
and to train an accurate global model while maintaining an extremely low attack
success rate. Most of the existing systems, however, are only robust in
honest/semi-honest majority settings. FLTrust (NDSS '21) extends the context to
the malicious majority for clients but with a strong restriction that the
server should be provided with an auxiliary dataset before training in order to
filter malicious inputs. Private FLAME/FLGUARD (USENIX '22) gives a solution to
guarantee both robustness and updates confidentiality in the semi-honest
majority context. It is so far impossible to balance the trade-off among
malicious context, robustness, and updates confidentiality. To tackle this
problem, we propose a novel Byzantine-robust and privacy-preserving FL system,
called BRIEF, to capture malicious minority and majority for server and client
sides. Specifically, based on the DBSCAN algorithm, we design a new method for
clustering via pairwise adjusted cosine similarity to boost the accuracy of the
clustering results. To thwart attacks of malicious majority, we develop an
algorithm called Model Segmentation, where local updates in the same cluster
are aggregated together, and the aggregations are sent back to corresponding
clients correctly. We also leverage multiple cryptographic tools to conduct
clustering tasks without sacrificing training correctness and updates
confidentiality. We present detailed security proof and empirical evaluation
along with convergence analysis for BRIEF. The experimental results demonstrate
that the testing accuracy of BRIEF is practically close to the FL baseline
(0.8% gap on average). At the same time, the attack success rate is around
0%-5%. We further optimize our design so that the communication overhead and
runtime can be decreased by {67%-89.17% and 66.05%-68.75%}, respectively.</p>
  </details>
</details>
<details>
  <summary>32. <b>标题：Revising Image-Text Retrieval via Multi-Modal Entailment</b></summary>
  <p><b>编号</b>：[146]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10126</p>
  <p><b>作者</b>：Xu Yan,  Chunhui Ai,  Ziqiang Cao,  Min Cao,  Sujian Li,  Wenjie Chen,  Guohong Fu</p>
  <p><b>备注</b>：10 pages</p>
  <p><b>关键词</b>：high-quality labeled data, image-text retrieval, outstanding image-text retrieval, image-text retrieval datasets, retrieval model depends</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>An outstanding image-text retrieval model depends on high-quality labeled
data. While the builders of existing image-text retrieval datasets strive to
ensure that the caption matches the linked image, they cannot prevent a caption
from fitting other images. We observe that such a many-to-many matching
phenomenon is quite common in the widely-used retrieval datasets, where one
caption can describe up to 178 images. These large matching-lost data not only
confuse the model in training but also weaken the evaluation accuracy. Inspired
by visual and textual entailment tasks, we propose a multi-modal entailment
classifier to determine whether a sentence is entailed by an image plus its
linked captions. Subsequently, we revise the image-text retrieval datasets by
adding these entailed captions as additional weak labels of an image and
develop a universal variable learning rate strategy to teach a retrieval model
to distinguish the entailed captions from other negative samples. In
experiments, we manually annotate an entailment-corrected image-text retrieval
dataset for evaluation. The results demonstrate that the proposed entailment
classifier achieves about 78% accuracy and consistently improves the
performance of image-text retrieval baselines.</p>
  </details>
</details>
<details>
  <summary>33. <b>标题：Incorporating Domain Knowledge through Task Augmentation for Front-End  JavaScript Code Generation</b></summary>
  <p><b>编号</b>：[154]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10091</p>
  <p><b>作者</b>：Sijie Shen,  Xiang Zhu,  Yihong Dong,  Qizhi Guo,  Yankun Zhen,  Ge Li</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Code generation, code snippet automatically, natural language descriptions, Code generation aims, Code</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Code generation aims to generate a code snippet automatically from natural
language descriptions. Generally, the mainstream code generation methods rely
on a large amount of paired training data, including both the natural language
description and the code. However, in some domain-specific scenarios, building
such a large paired corpus for code generation is difficult because there is no
directly available pairing data, and a lot of effort is required to manually
write the code descriptions to construct a high-quality training dataset. Due
to the limited training data, the generation model cannot be well trained and
is likely to be overfitting, making the model's performance unsatisfactory for
real-world use. To this end, in this paper, we propose a task augmentation
method that incorporates domain knowledge into code generation models through
auxiliary tasks and a Subtoken-TranX model by extending the original TranX
model to support subtoken-level code generation. To verify our proposed
approach, we collect a real-world code generation dataset and conduct
experiments on it. Our experimental results demonstrate that the subtoken-level
TranX model outperforms the original TranX model and the Transformer model on
our dataset, and the exact match accuracy of Subtoken-TranX improves
significantly by 12.75\% with the help of our task augmentation method. The
model performance on several code categories has satisfied the requirements for
application in industrial systems. Our proposed approach has been adopted by
Alibaba's \emph{BizCook} platform. To the best of our knowledge, this is the
first domain code generation system adopted in industrial development
environments.</p>
  </details>
</details>
<details>
  <summary>34. <b>标题：Identifying Auxiliary or Adversarial Tasks Using Necessary Condition  Analysis for Adversarial Multi-task Video Understanding</b></summary>
  <p><b>编号</b>：[159]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10077</p>
  <p><b>作者</b>：Stephen Su,  Samuel Kwong,  Qingyu Zhao,  De-An Huang,  Juan Carlos Niebles,  Ehsan Adeli</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：recent years, multi-task learning, increasing interest, Multi-Task Neural Networks, Adversarial Multi-Task Neural</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>There has been an increasing interest in multi-task learning for video
understanding in recent years. In this work, we propose a generalized notion of
multi-task learning by incorporating both auxiliary tasks that the model should
perform well on and adversarial tasks that the model should not perform well
on. We employ Necessary Condition Analysis (NCA) as a data-driven approach for
deciding what category these tasks should fall in. Our novel proposed
framework, Adversarial Multi-Task Neural Networks (AMT), penalizes adversarial
tasks, determined by NCA to be scene recognition in the Holistic Video
Understanding (HVU) dataset, to improve action recognition. This upends the
common assumption that the model should always be encouraged to do well on all
tasks in multi-task learning. Simultaneously, AMT still retains all the
benefits of multi-task learning as a generalization of existing methods and
uses object recognition as an auxiliary task to aid action recognition. We
introduce two challenging Scene-Invariant test splits of HVU, where the model
is evaluated on action-scene co-occurrences not encountered in training. We
show that our approach improves accuracy by ~3% and encourages the model to
attend to action features instead of correlation-biasing scene features.</p>
  </details>
</details>
<details>
  <summary>35. <b>标题：Selection Collider Bias in Large Language Models</b></summary>
  <p><b>编号</b>：[163]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10063</p>
  <p><b>作者</b>：Emily McMilin</p>
  <p><b>备注</b>：10 pages, 16 figures, UAI 2022 Causal Representation Learning Workshop</p>
  <p><b>关键词</b>：Large Language, selection collider bias, sample selection induced, induced collider bias, collider bias</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper we motivate the causal mechanisms behind sample selection
induced collider bias (selection collider bias) that can cause Large Language
Models (LLMs) to learn unconditional dependence between entities that are
unconditionally independent in the real world. We show that selection collider
bias can be amplified in underspecified learning tasks, and that the magnitude
of the resulting spurious correlations appear scale agnostic. While selection
collider bias can be difficult to overcome, we describe a method to exploit the
resulting spurious correlations for determination of when a model may be
uncertain about its prediction, and demonstrate that it matches human
uncertainty in tasks with gender pronoun underspecification on an extended
version of the Winogender Schemas evaluation set.</p>
  </details>
</details>
<details>
  <summary>36. <b>标题：Antecedent Predictions Are Dominant for Tree-Based Code Generation</b></summary>
  <p><b>编号</b>：[187]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09998</p>
  <p><b>作者</b>：Yihong Dong,  Ge Li,  Zhi Jin</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：antecedent predictions, Code generation focuses, predictions, antecedent, Antecedent Prioritized TRANX</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Code generation focuses on the automatic conversion of natural language (NL)
utterances into code snippets. The sequence-to-tree (Seq2Tree) methods, e.g.,
TRANX, are proposed for code generation, with the guarantee of the
compilability of the generated code, which generate the subsequent Abstract
Syntax Tree (AST) node relying on antecedent predictions of AST nodes. Existing
Seq2Tree methods tend to treat both antecedent predictions and subsequent
predictions equally. However, under the AST constraints, it is difficult for
Seq2Tree models to produce the correct subsequent prediction based on incorrect
antecedent predictions. Thus, antecedent predictions ought to receive more
attention than subsequent predictions. To this end, in this paper, we propose
an effective method, named APTRANX (Antecedent Prioritized TRANX), on the basis
of TRANX. APTRANX contains an Antecedent Prioritized (AP) Loss, which helps the
model attach importance to antecedent predictions by exploiting the position
information of the generated AST nodes. With better antecedent predictions and
accompanying subsequent predictions, APTRANX significantly improves the
performance. We conduct extensive experiments on several benchmark datasets,
and the experimental results demonstrate the superiority and generality of our
proposed method compared with the state-of-the-art methods.</p>
  </details>
</details>
<details>
  <summary>37. <b>标题：Development of a CAV-based Intersection Control System and Corridor  Level Impact Assessment</b></summary>
  <p><b>编号</b>：[193]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09973</p>
  <p><b>作者</b>：Ardeshir Mirbakhsh,  Joyoung Lee,  Dejan Besenski</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Deep Reinforcement Learning, Reinforcement Learning, Deep Reinforcement, pixel reservation algorithm, corridor-level impact assessment</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper presents a signal-free intersection control system for CAVs by
combination of a pixel reservation algorithm and a Deep Reinforcement Learning
(DRL) decision-making logic, followed by a corridor-level impact assessment of
the proposed model. The pixel reservation algorithm detects potential colliding
maneuvers and the DRL logic optimizes vehicles' movements to avoid collision
and minimize the overall delay at the intersection. The proposed control system
is called Decentralized Sparse Coordination System (DSCLS) since each vehicle
has its own control logic and interacts with other vehicles in coordinated
states only. Due to the chain impact of taking random actions in the DRL's
training course, the trained model can deal with unprecedented volume
conditions, which poses the main challenge in intersection management. The
performance of the developed model is compared with conventional and CAV-based
control systems, including fixed traffic lights, actuated traffic lights, and
the Longest Queue First (LQF) control system under three volume regimes in a
corridor of four intersections in VISSIM software. The simulation result
revealed that the proposed model reduces delay by 50%, 29%, and 23% in
moderate, high, and extreme volume regimes compared to the other CAV-based
control system. Improvements in travel time, fuel consumption, emission, and
Surrogate Safety Measures (SSM) are also noticeable.</p>
  </details>
</details>
<details>
  <summary>38. <b>标题：Performance, Opaqueness, Consequences, and Assumptions: Simple questions  for responsible planning of machine learning solutions</b></summary>
  <p><b>编号</b>：[196]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09966</p>
  <p><b>作者</b>：Przemyslaw Biecek</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：revolution has generated, generated a huge, huge demand, data revolution, data-driven solutions</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The data revolution has generated a huge demand for data-driven solutions.
This demand propels a growing number of easy-to-use tools and training for
aspiring data scientists that enable the rapid building of predictive models.
Today, weapons of math destruction can be easily built and deployed without
detailed planning and validation. This rapidly extends the list of AI failures,
i.e. deployments that lead to financial losses or even violate democratic
values such as equality, freedom and justice. The lack of planning, rules and
standards around the model development leads to the ,,anarchisation of AI".
This problem is reported under different names such as validation debt,
reproducibility crisis, and lack of explainability. Post-mortem analysis of AI
failures often reveals mistakes made in the early phase of model development or
data acquisition. Thus, instead of curing the consequences of deploying harmful
models, we shall prevent them as early as possible by putting more attention to
the initial planning stage.
In this paper, we propose a quick and simple framework to support planning of
AI solutions. The POCA framework is based on four pillars: Performance,
Opaqueness, Consequences, and Assumptions. It helps to set the expectations and
plan the constraints for the AI solution before any model is built and any data
is collected. With the help of the POCA method, preliminary requirements can be
defined for the model-building process, so that costly model misspecification
errors can be identified as soon as possible or even avoided. AI researchers,
product owners and business analysts can use this framework in the initial
stages of building AI solutions.</p>
  </details>
</details>
<details>
  <summary>39. <b>标题：Bipartite Matchings with Group Fairness and Individual Fairness  Constraints</b></summary>
  <p><b>编号</b>：[200]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09951</p>
  <p><b>作者</b>：Atasi Panda,  Anand Louis,  Prajakta Nibhorkar</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：fairness, group, context of assigning, individual fairness, fairness constraints</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We address group as well as individual fairness constraints in matchings in
the context of assigning items to platforms. Each item belongs to certain
groups and has a preference ordering over platforms. Each platform enforces
group fairness by specifying an upper and a lower bound on the number of items
that can be matched to it from each group. There could be multiple optimal
solutions that satisfy the group fairness constraints. To achieve individual
fairness, we introduce `probabilistic individual fairness', where the goal is
to compute a distribution over `group fair' matchings such that every item has
a reasonable probability of being matched to a platform among its top choices.
In the case where each item belongs to exactly one group, we provide a
polynomial-time algorithm that computes a probabilistic individually fair
distribution over group fair matchings. When an item can belong to multiple
groups, and the group fairness constraints are specified as only upper bounds,
we rehash the same algorithm to achieve three different polynomial-time
approximation algorithms.</p>
  </details>
</details>
<details>
  <summary>40. <b>标题：ProPaLL: Probabilistic Partial Label Learning</b></summary>
  <p><b>编号</b>：[210]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09931</p>
  <p><b>作者</b>：Łukasz Struski,  Jacek Tabor,  Bartosz Zieliński</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Partial label learning, weakly supervised learning, training instance corresponds, Partial label, type of weakly</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Partial label learning is a type of weakly supervised learning, where each
training instance corresponds to a set of candidate labels, among which only
one is true. In this paper, we introduce ProPaLL, a novel probabilistic
approach to this problem, which has at least three advantages compared to the
existing approaches: it simplifies the training process, improves performance,
and can be applied to any deep architecture. Experiments conducted on
artificial and real-world datasets indicate that ProPaLL outperforms the
existing approaches.</p>
  </details>
</details>
<details>
  <summary>41. <b>标题：A Web Application for Experimenting and Validating Remote Measurement of  Vital Signs</b></summary>
  <p><b>编号</b>：[215]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09916</p>
  <p><b>作者</b>：Amtul Haq Ayesha,  Donghao Qiao,  Farhana Zulkernine</p>
  <p><b>备注</b>：12 pages, 2 figures</p>
  <p><b>关键词</b>：medical advising remote, advising remote monitoring, online medical advising, Blood Volume Pulse, advising remote</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>With a surge in online medical advising remote monitoring of patient vitals
is required. This can be facilitated with the Remote Photoplethysmography
(rPPG) techniques that compute vital signs from facial videos. It involves
processing video frames to obtain skin pixels, extracting the cardiac data from
it and applying signal processing filters to extract the Blood Volume Pulse
(BVP) signal. Different algorithms are applied to the BVP signal to estimate
the various vital signs. We implemented a web application framework to measure
a person's Heart Rate (HR), Heart Rate Variability (HRV), Oxygen Saturation
(SpO2), Respiration Rate (RR), Blood Pressure (BP), and stress from the face
video. The rPPG technique is highly sensitive to illumination and motion
variation. The web application guides the users to reduce the noise due to
these variations and thereby yield a cleaner BVP signal. The accuracy and
robustness of the framework was validated with the help of volunteers.</p>
  </details>
</details>
<details>
  <summary>42. <b>标题：SIM2E: Benchmarking the Group Equivariant Capability of Correspondence  Matching Algorithms</b></summary>
  <p><b>编号</b>：[224]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09896</p>
  <p><b>作者</b>：Shuai Su,  Zhongkai Zhao,  Yixin Fei,  Shuda Li,  Qijun Chen,  Rui Fan</p>
  <p><b>备注</b>：ECCV2022 Workshop Paper</p>
  <p><b>关键词</b>：Correspondence matching, matching, Correspondence, computer vision, vision and robotics</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Correspondence matching is a fundamental problem in computer vision and
robotics applications. Solving correspondence matching problems using neural
networks has been on the rise recently. Rotation-equivariance and
scale-equivariance are both critical in correspondence matching applications.
Classical correspondence matching approaches are designed to withstand scaling
and rotation transformations. However, the features extracted using
convolutional neural networks (CNNs) are only translation-equivariant to a
certain extent. Recently, researchers have strived to improve the
rotation-equivariance of CNNs based on group theories. Sim(2) is the group of
similarity transformations in the 2D plane. This paper presents a specialized
dataset dedicated to evaluating sim(2)-equivariant correspondence matching
algorithms. We compare the performance of 16 state-of-the-art (SoTA)
correspondence matching approaches. The experimental results demonstrate the
importance of group equivariant algorithms for correspondence matching on
various sim(2) transformation conditions. Since the subpixel accuracy achieved
by CNN-based correspondence matching approaches is unsatisfactory, this
specific area requires more attention in future works. Our dataset is publicly
available at: mias.group/SIM2E.</p>
  </details>
</details>
<details>
  <summary>43. <b>标题：Byzantines can also Learn from History: Fall of Centered Clipping in  Federated Learning</b></summary>
  <p><b>编号</b>：[225]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09894</p>
  <p><b>作者</b>：Kerem Ozfatura,  Emre Ozfatura,  Alptekin Kupcu,  Deniz Gunduz</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：collaborative learning tasks, learning framework due, learned model due, federated learning framework, malicious clients participating</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The increasing popularity of the federated learning framework due to its
success in a wide range of collaborative learning tasks also induces certain
security concerns regarding the learned model due to the possibility of
malicious clients participating in the learning process. Hence, the objective
is to neutralize the impact of the malicious participants and to ensure the
final model is trustable. One common observation regarding the Byzantine
attacks is that the higher the variance among the clients' models/updates, the
more space for attacks to be hidden. To this end, it has been recently shown
that by utilizing momentum, thus reducing the variance, it is possible to
weaken the strength of the known Byzantine attacks. The Centered Clipping
framework (ICML 2021) has further shown that, besides reducing the variance,
the momentum term from the previous iteration can be used as a reference point
to neutralize the Byzantine attacks and show impressive performance against
well-known attacks. However, in the scope of this work, we show that the
centered clipping framework has certain vulnerabilities, and existing attacks
can be revised based on these vulnerabilities to circumvent the centered
clipping defense. Hence, we introduce a strategy to design an attack to
circumvent the centered clipping framework and numerically illustrate its
effectiveness against centered clipping as well as other known defense
strategies by reducing test accuracy to 5-40 on best-case scenarios.</p>
  </details>
</details>
<details>
  <summary>44. <b>标题：DiscrimLoss: A Universal Loss for Hard Samples and Incorrect Samples  Discrimination</b></summary>
  <p><b>编号</b>：[227]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09884</p>
  <p><b>作者</b>：Tingting Wu,  Xiao Ding,  Hao Zhang,  Jinglong Gao,  Li Du,  Bing Qin,  Ting Liu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：deep neural networks, samples, impair model performance, incorrect samples, deep neural</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Given data with label noise (i.e., incorrect data), deep neural networks
would gradually memorize the label noise and impair model performance. To
relieve this issue, curriculum learning is proposed to improve model
performance and generalization by ordering training samples in a meaningful
(e.g., easy to hard) sequence. Previous work takes incorrect samples as generic
hard ones without discriminating between hard samples (i.e., hard samples in
correct data) and incorrect samples. Indeed, a model should learn from hard
samples to promote generalization rather than overfit to incorrect ones. In
this paper, we address this problem by appending a novel loss function
DiscrimLoss, on top of the existing task loss. Its main effect is to
automatically and stably estimate the importance of easy samples and difficult
samples (including hard and incorrect samples) at the early stages of training
to improve the model performance. Then, during the following stages,
DiscrimLoss is dedicated to discriminating between hard and incorrect samples
to improve the model generalization. Such a training strategy can be formulated
dynamically in a self-supervised manner, effectively mimicking the main
principle of curriculum learning. Experiments on image classification, image
regression, text sequence regression, and event relation reasoning demonstrate
the versatility and effectiveness of our method, particularly in the presence
of diversified noise levels.</p>
  </details>
</details>
<details>
  <summary>45. <b>标题：Tyche: A library for probabilistic reasoning and belief modelling in  Python</b></summary>
  <p><b>编号</b>：[250]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09838</p>
  <p><b>作者</b>：Padraig X. Lamont</p>
  <p><b>备注</b>：21 pages, submitted to AJCAI2022</p>
  <p><b>关键词</b>：Python library, paper presents Tyche, paper presents, reasoning in uncertain, uncertain worlds</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper presents Tyche, a Python library to facilitate probabilistic
reasoning in uncertain worlds through the construction, querying, and learning
of belief models. Tyche uses aleatoric description logic (ADL), which provides
computational advantages in its evaluation over other description logics. Tyche
belief models can be succinctly created by defining classes of individuals, the
probabilistic beliefs about them (concepts), and the probabilistic
relationships between them (roles). We also introduce a method of observation
propagation to facilitate learning from complex ADL observations. A
demonstration of Tyche to predict the author of anonymised messages, and to
extract author writing tendencies from anonymised messages, is provided. Tyche
has the potential to assist in the development of expert systems, knowledge
extraction systems, and agents to play games with incomplete and probabilistic
information.</p>
  </details>
</details>
<details>
  <summary>46. <b>标题：I Know What You Do Not Know: Knowledge Graph Embedding via  Co-distillation Learning</b></summary>
  <p><b>编号</b>：[256]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09828</p>
  <p><b>作者</b>：Yang Liu,  Zequn Sun Guangyao Li,  Wei Hu</p>
  <p><b>备注</b>：Accepted in the 31st ACM International Conference on Information and Knowledge Management (CIKM 2022)</p>
  <p><b>关键词</b>：graph structures, graph, Co-distillation Learning, embedding, learn vector representations</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Knowledge graph (KG) embedding seeks to learn vector representations for
entities and relations. Conventional models reason over graph structures, but
they suffer from the issues of graph incompleteness and long-tail entities.
Recent studies have used pre-trained language models to learn embeddings based
on the textual information of entities and relations, but they cannot take
advantage of graph structures. In the paper, we show empirically that these two
kinds of features are complementary for KG embedding. To this end, we propose
CoLE, a Co-distillation Learning method for KG Embedding that exploits the
complementarity of graph structures and text information. Its graph embedding
model employs Transformer to reconstruct the representation of an entity from
its neighborhood subgraph. Its text embedding model uses a pre-trained language
model to generate entity representations from the soft prompts of their names,
descriptions, and relational neighbors. To let the two model promote each
other, we propose co-distillation learning that allows them to distill
selective knowledge from each other's prediction logits. In our co-distillation
learning, each model serves as both a teacher and a student. Experiments on
benchmark datasets demonstrate that the two models outperform their related
baselines, and the ensemble method CoLE with co-distillation learning advances
the state-of-the-art of KG embedding.</p>
  </details>
</details>
<details>
  <summary>47. <b>标题：Z-Code++: A Pre-trained Language Model Optimized for Abstractive  Summarization</b></summary>
  <p><b>编号</b>：[281]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09770</p>
  <p><b>作者</b>：Pengcheng He,  Baolin Peng,  Liyang Lu,  Song Wang,  Jie Mei,  Yang Liu,  Ruochen Xu,  Hany Hassan Awadalla,  Yu Shi,  Chenguang Zhu,  Wayne Xiong,  Michael Zeng,  Jianfeng Gao,  Xuedong Huang</p>
  <p><b>备注</b>：16 pages, 3 figures</p>
  <p><b>关键词</b>：paper presents Z-Code, paper presents, optimized for abstractive, abstractive text summarization, model</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper presents Z-Code++, a new pre-trained language model optimized for
abstractive text summarization. The model extends the state of the art
encoder-decoder model using three techniques. First, we use a two-phase
pre-training process to improve model's performance on low-resource
summarization tasks. The model is first pre-trained using text corpora for
language understanding, and then is continually pre-trained on summarization
corpora for grounded text generation. Second, we replace self-attention layers
in the encoder with disentangled attention layers, where each word is
represented using two vectors that encode its content and position,
respectively. Third, we use fusion-in-encoder, a simple yet effective method of
encoding long sequences in a hierarchical manner. Z-Code++ creates new state of
the art on 9 out of 13 text summarization tasks across 5 languages. Our model
is parameter-efficient in that it outperforms the 600x larger PaLM-540B on
XSum, and the finetuned 200x larger GPT3-175B on SAMSum. In zero-shot and
few-shot settings, our model substantially outperforms the competing models.</p>
  </details>
</details>
<details>
  <summary>48. <b>标题：Artifact-Based Domain Generalization of Skin Lesion Models</b></summary>
  <p><b>编号</b>：[284]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09756</p>
  <p><b>作者</b>：Alceu Bissoto,  Catarina Barata,  Eduardo Valle,  Sandra Avila</p>
  <p><b>备注</b>：Accepted to the ISIC Skin Image Analysis Workshop @ ECCV 2022</p>
  <p><b>关键词</b>：Deep Learning failure, Learning failure cases, Deep Learning, Learning failure, medical area</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep Learning failure cases are abundant, particularly in the medical area.
Recent studies in out-of-distribution generalization have advanced considerably
on well-controlled synthetic datasets, but they do not represent medical
imaging contexts. We propose a pipeline that relies on artifacts annotation to
enable generalization evaluation and debiasing for the challenging skin lesion
analysis context. First, we partition the data into levels of increasingly
higher biased training and test sets for better generalization assessment.
Then, we create environments based on skin lesion artifacts to enable domain
generalization methods. Finally, after robust training, we perform a test-time
debiasing procedure, reducing spurious features in inference images. Our
experiments show our pipeline improves performance metrics in biased cases, and
avoids artifacts when using explanation methods. Still, when evaluating such
models in out-of-distribution data, they did not prefer clinically-meaningful
features. Instead, performance only improved in test sets that present similar
artifacts from training, suggesting models learned to ignore the known set of
artifacts. Our results raise a concern that debiasing models towards a single
aspect may not be enough for fair skin lesion analysis.</p>
  </details>
</details>
<details>
  <summary>49. <b>标题：MLExchange -- A web-based platform enabling exchangeable machine  learning workflows</b></summary>
  <p><b>编号</b>：[287]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09751</p>
  <p><b>作者</b>：Zhuowen Zhao,  Tanny Chavez,  Elizabeth Holman,  Guanhua Hao,  Adam Green,  Harinarayan Krishnan,  Dylan McReynolds,  Ronald Pandolfi,  Eric J. Roberts,  Petrus H. Zwart,  Howard Yanxon,  Nicholas Schwarz,  Subramanian Sankaranarayanan,  Sergei V. Kalinin,  Apurva Mehta,  Stuart Campbel,  Alexander Hexemer</p>
  <p><b>备注</b>：Submitting to The Int'l Conference for High Performance Computing, Networking, Storage, and Analysis</p>
  <p><b>关键词</b>：diverse data problems, Machine learning, showing a growing, growing trend, trend in helping</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Machine learning (ML) algorithms are showing a growing trend in helping the
scientific communities across different disciplines and institutions to address
large and diverse data problems. However, many available ML tools are
programmatically demanding and computationally costly. The MLExchange project
aims to build a collaborative platform equipped with enabling tools that allow
scientists and facility users who do not have a profound ML background to use
ML and computational resources in scientific discovery. At the high level, we
are targeting a full user experience where managing and exchanging ML
algorithms, workflows, and data are readily available through web applications.
So far, we have built four major components, i.e, the central job manager, the
centralized content registry, user portal, and search engine, and successfully
deployed these components on a testing server.
Since each component is an independent container, the whole platform or its
individual service(s) can be easily deployed at servers of different scales,
ranging from a laptop (usually a single user) to high performance clusters
(HPC) accessed (simultaneously) by many users. Thus, MLExchange renders
flexible using scenarios -- users could either access the services and
resources from a remote server or run the whole platform or its individual
service(s) within their local network.</p>
  </details>
</details>
<details>
  <summary>50. <b>标题：Cognitive Modeling of Semantic Fluency Using Transformers</b></summary>
  <p><b>编号</b>：[299]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09719</p>
  <p><b>作者</b>：Animesh Nighojkar,  Anna Khlyzova,  John Licato</p>
  <p><b>备注</b>：Cognitive Aspects of Knowledge Representation workshop at IJCAI-ECAI 2022</p>
  <p><b>关键词</b>：deep language models, human cognition, deep language, explanatory models, models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Can deep language models be explanatory models of human cognition? If so,
what are their limits? In order to explore this question, we propose an
approach called hyperparameter hypothesization that uses predictive
hyperparameter tuning in order to find individuating descriptors of
cognitive-behavioral profiles. We take the first step in this approach by
predicting human performance in the semantic fluency task (SFT), a well-studied
task in cognitive science that has never before been modeled using
transformer-based language models (TLMs). In our task setup, we compare several
approaches to predicting which word an individual performing SFT will utter
next. We report preliminary evidence suggesting that, despite obvious
implementational differences in how people and TLMs learn and use language,
TLMs can be used to identify individual differences in human fluency task
behaviors better than existing computational models, and may offer insights
into human memory retrieval strategies -- cognitive process not typically
considered to be the kinds of things TLMs can model. Finally, we discuss the
implications of this work for cognitive modeling of knowledge representations.</p>
  </details>
</details>
<details>
  <summary>51. <b>标题：SemEval-2022 Task 8: Multi-lingual News Article Similarity</b></summary>
  <p><b>编号</b>：[302]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09715</p>
  <p><b>作者</b>：Nikhil Goel,  Ranjith Reddy</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：feed-forward neural network, similarity, feed-forward neural, articles, neural network</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This work is about finding the similarity between a pair of news articles.
There are seven different objective similarity metrics provided in the dataset
for each pair and the news articles are in multiple different languages. On top
of the pre-trained embedding model, we calculated cosine similarity for
baseline results and feed-forward neural network was then trained on top of it
to improve the results. We also built separate pipelines for each similarity
metric for feature extraction. We could see significant improvement from
baseline results using feature extraction and feed-forward neural network.</p>
  </details>
</details>
<details>
  <summary>52. <b>标题：DenseShift: Towards Accurate and Transferable Low-Bit Shift Network</b></summary>
  <p><b>编号</b>：[305]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09708</p>
  <p><b>作者</b>：Xinlin Li,  Bang Liu,  Rui Heng Yang,  Vanessa Courville,  Chao Xing,  Vahid Partovi Nia</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：ever-increasing resource requirements, low-resource edge devices, Deploying deep neural, deep neural networks, low-bit shift networks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deploying deep neural networks on low-resource edge devices is challenging
due to their ever-increasing resource requirements. Recent investigations
propose multiplication-free neural networks to reduce computation and memory
consumption. Shift neural network is one of the most effective tools towards
these reductions. However, existing low-bit shift networks are not as accurate
as their full precision counterparts and cannot efficiently transfer to a wide
range of tasks due to their inherent design flaws. We propose DenseShift
network that exploits the following novel designs. First, we demonstrate that
the zero-weight values in low-bit shift networks are neither useful to the
model capacity nor simplify the model inference. Therefore, we propose to use a
zero-free shifting mechanism to simplify inference while increasing the model
capacity. Second, we design a new metric to measure the weight freezing issue
in training low-bit shift networks, and propose a sign-scale decomposition to
improve the training efficiency. Third, we propose the low-variance random
initialization strategy to improve the model's performance in transfer learning
scenarios. We run extensive experiments on various computer vision and speech
tasks. The experimental results show that DenseShift network significantly
outperforms existing low-bit multiplication-free networks and can achieve
competitive performance to the full-precision counterpart. It also exhibits
strong transfer learning performance with no drop in accuracy.</p>
  </details>
</details>
<details>
  <summary>53. <b>标题：Fuse and Attend: Generalized Embedding Learning for Art and Sketches</b></summary>
  <p><b>编号</b>：[312]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09698</p>
  <p><b>作者</b>：Ujjal Kr Dutta</p>
  <p><b>备注</b>：Accepted in European Conference on Computer Vision (ECCV) 2022 Workshops: DIRA</p>
  <p><b>关键词</b>：witnessed widespread success, deep Embedding Learning, Embedding Learning approaches, representing natural images, Embedding Learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>While deep Embedding Learning approaches have witnessed widespread success in
multiple computer vision tasks, the state-of-the-art methods for representing
natural images need not necessarily perform well on images from other domains,
such as paintings, cartoons, and sketch. This is because of the huge shift in
the distribution of data from across these domains, as compared to natural
images. Domains like sketch often contain sparse informative pixels. However,
recognizing objects in such domains is crucial, given multiple relevant
applications leveraging such data, for instance, sketch to image retrieval.
Thus, achieving an Embedding Learning model that could perform well across
multiple domains is not only challenging, but plays a pivotal role in computer
vision. To this end, in this paper, we propose a novel Embedding Learning
approach with the goal of generalizing across different domains. During
training, given a query image from a domain, we employ gated fusion and
attention to generate a positive example, which carries a broad notion of the
semantics of the query object category (from across multiple domains). By
virtue of Contrastive Learning, we pull the embeddings of the query and
positive, in order to learn a representation which is robust across domains. At
the same time, to teach the model to be discriminative against examples from
different semantic categories (across domains), we also maintain a pool of
negative embeddings (from different categories). We show the prowess of our
method using the DomainBed framework, on the popular PACS (Photo, Art painting,
Cartoon, and Sketch) dataset.</p>
  </details>
</details>
<details>
  <summary>54. <b>标题：Net2Brain: A Toolbox to compare artificial vision models with human  brain responses</b></summary>
  <p><b>编号</b>：[321]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09677</p>
  <p><b>作者</b>：Domenic Bersch,  Kshitij Dwivedi,  Martina Vilas,  Radoslaw M. Cichy,  Gemma Roig</p>
  <p><b>备注</b>：4 Pages, 3 figures, submitted and accepted to CCNeuro 2022. For associated repository, see this https URL</p>
  <p><b>关键词</b>：deep neural networks, command-line user interface, artificial deep neural, user interface toolbox, human brain recordings</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We introduce Net2Brain, a graphical and command-line user interface toolbox
for comparing the representational spaces of artificial deep neural networks
(DNNs) and human brain recordings. While different toolboxes facilitate only
single functionalities or only focus on a small subset of supervised image
classification models, Net2Brain allows the extraction of activations of more
than 600 DNNs trained to perform a diverse range of vision-related tasks (e.g
semantic segmentation, depth estimation, action recognition, etc.), over both
image and video datasets. The toolbox computes the representational
dissimilarity matrices (RDMs) over those activations and compares them to brain
recordings using representational similarity analysis (RSA), weighted RSA, both
in specific ROIs and with searchlight search. In addition, it is possible to
add a new data set of stimuli and brain recordings to the toolbox for
evaluation. We demonstrate the functionality and advantages of Net2Brain with
an example showcasing how it can be used to test hypotheses of cognitive
computational neuroscience.</p>
  </details>
</details>
<details>
  <summary>55. <b>标题：Trigger-free Event Detection via Derangement Reading Comprehension</b></summary>
  <p><b>编号</b>：[332]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09659</p>
  <p><b>作者</b>：Jiachen Zhao,  Haiqin Yang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：understanding actual happenings, aiming to detect, real life, vital to understanding, understanding actual</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Event detection (ED), aiming to detect events from texts and categorize them,
is vital to understanding actual happenings in real life. However, mainstream
event detection models require high-quality expert human annotations of
triggers, which are often costly and thus deter the application of ED to new
domains. Therefore, in this paper, we focus on low-resource ED without triggers
and aim to tackle the following formidable challenges: multi-label
classification, insufficient clues, and imbalanced events distribution. We
propose a novel trigger-free ED method via Derangement mechanism on a machine
Reading Comprehension (DRC) framework. More specifically, we treat the input
text as Context and concatenate it with all event type tokens that are deemed
as Answers with an omitted default question. So we can leverage the
self-attention in pre-trained language models to absorb semantic relations
between input text and the event types. Moreover, we design a simple yet
effective event derangement module (EDM) to prevent major events from being
excessively learned so as to yield a more balanced training process. The
experiment results show that our proposed trigger-free ED model is remarkably
competitive to mainstream trigger-based models, showing its strong performance
on low-source event detection.</p>
  </details>
</details>
<details>
  <summary>56. <b>标题：A biologically-inspired evaluation of molecular generative machine  learning</b></summary>
  <p><b>编号</b>：[333]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09658</p>
  <p><b>作者</b>：Elizaveta Vinogradova,  Abay Artykbayev,  Alisher Amanatay,  Mukhamejan Karatayev,  Maxim Mametkulov,  Albina Li,  Anuar Suleimenov,  Abylay Salimzhanov,  Karina Pats,  Rustam Zhumagambetov,  Ferdinand Molnár,  Vsevolod Peshkov,  Siamac Fazli</p>
  <p><b>备注</b>：59 pages, 26 figures Project GitHub repository, this https URL</p>
  <p><b>关键词</b>：scientific areas, generative models, recently become ubiquitous, molecular generative models, generative</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>While generative models have recently become ubiquitous in many scientific
areas, less attention has been paid to their evaluation. For molecular
generative models, the state-of-the-art examines their output in isolation or
in relation to its input. However, their biological and functional properties,
such as ligand-target interaction is not being addressed. In this study, a
novel biologically-inspired benchmark for the evaluation of molecular
generative models is proposed. Specifically, three diverse reference datasets
are designed and a set of metrics are introduced which are directly relevant to
the drug discovery process. In particular we propose a recreation metric, apply
drug-target affinity prediction and molecular docking as complementary
techniques for the evaluation of generative outputs. While all three metrics
show consistent results across the tested generative models, a more detailed
comparison of drug-target affinity binding and molecular docking scores
revealed that unimodal predictiors can lead to erroneous conclusions about
target binding on a molecular level and a multi-modal approach is thus
preferrable. The key advantage of this framework is that it incorporates prior
physico-chemical domain knowledge into the benchmarking process by focusing
explicitly on ligand-target interactions and thus creating a highly efficient
tool not only for evaluating molecular generative outputs in particular, but
also for enriching the drug discovery process in general.</p>
  </details>
</details>
<details>
  <summary>57. <b>标题：A Domain Generalization Approach for Out-Of-Distribution 12-lead ECG  Classification with Convolutional Neural Networks</b></summary>
  <p><b>编号</b>：[335]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09656</p>
  <p><b>作者</b>：Aristotelis Ballas,  Christos Diou</p>
  <p><b>备注</b>：This paper has been accepted at: IEEE BigDataService2022 (this http URL)</p>
  <p><b>关键词</b>：Deep Learning systems, achieved great success, Learning systems, surpassing human intelligence, Deep Learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep Learning systems have achieved great success in the past few years, even
surpassing human intelligence in several cases. As of late, they have also
established themselves in the biomedical and healthcare domains, where they
have shown a lot of promise, but have not yet achieved widespread adoption.
This is in part due to the fact that most methods fail to maintain their
performance when they are called to make decisions on data that originate from
a different distribution than the one they were trained on, namely
Out-Of-Distribution (OOD) data. For example, in the case of biosignal
classification, models often fail to generalize well on datasets from different
hospitals, due to the distribution discrepancy amongst different sources of
data. Our goal is to demonstrate the Domain Generalization problem present
between distinct hospital databases and propose a method that classifies
abnormalities on 12-lead Electrocardiograms (ECGs), by leveraging information
extracted across the architecture of a Deep Neural Network, and capturing the
underlying structure of the signal. To this end, we adopt a ResNet-18 as the
backbone model and extract features from several intermediate convolutional
layers of the network. To evaluate our method, we adopt publicly available ECG
datasets from four sources and handle them as separate domains. To simulate the
distributional shift present in real-world settings, we train our model on a
subset of the domains and leave-out the remaining ones. We then evaluate our
model both on the data present at training time (intra-distribution) and the
held-out data (out-of-distribution), achieving promising results and surpassing
the baseline of a vanilla Residual Network in most of the cases.</p>
  </details>
</details>
<details>
  <summary>58. <b>标题：Few-Shot Learning of Accurate Folding Landscape for Protein Structure  Prediction</b></summary>
  <p><b>编号</b>：[336]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09652</p>
  <p><b>作者</b>：Jun Zhang,  Sirui Liu,  Mengyun Chen,  Haotian Chu,  Min Wang,  Zidong Wang,  Jialiang Yu,  Ningxi Ni,  Fan Yu,  Diqing Chen,  Yi Isaac Yang,  Boxin Xue,  Lijiang Yang,  Yuan Liu,  Yi Qin Gao</p>
  <p><b>备注</b>：version 1.0; 18 pages, 6 figures</p>
  <p><b>关键词</b>：Data-driven predictive methods, biologically active structures, Data-driven predictive, therapeutical development, biologically active</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Data-driven predictive methods which can efficiently and accurately transform
protein sequences into biologically active structures are highly valuable for
scientific research and therapeutical development. Determining accurate folding
landscape using co-evolutionary information is fundamental to the success of
modern protein structure prediction methods. As the state of the art,
AlphaFold2 has dramatically raised the accuracy without performing explicit
co-evolutionary analysis. Nevertheless, its performance still shows strong
dependence on available sequence homologs. We investigated the cause of such
dependence and presented EvoGen, a meta generative model, to remedy the
underperformance of AlphaFold2 for poor MSA targets. EvoGen allows us to
manipulate the folding landscape either by denoising the searched MSA or by
generating virtual MSA, and helps AlphaFold2 fold accurately in low-data regime
or even achieve encouraging performance with single-sequence predictions. Being
able to make accurate predictions with few-shot MSA not only generalizes
AlphaFold2 better for orphan sequences, but also democratizes its use for
high-throughput applications. Besides, EvoGen combined with AlphaFold2 yields a
probabilistic structure generation method which could explore alternative
conformations of protein sequences, and the task-aware differentiable algorithm
for sequence generation will benefit other related tasks including protein
design.</p>
  </details>
</details>
<details>
  <summary>59. <b>标题：An Initial Investigation for Detecting Vocoder Fingerprints of Fake  Audio</b></summary>
  <p><b>编号</b>：[338]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09646</p>
  <p><b>作者</b>：Xinrui Yan,  Jiangyan Yi,  Jianhua Tao,  Chenglong Wang,  Haoxin Ma,  Tao Wang,  Shiming Wang,  Ruibo Fu</p>
  <p><b>备注</b>：Accepted by ACM Multimedia 2022 Workshop: First International Workshop on Deepfake Detection for Audio Multimedia</p>
  <p><b>关键词</b>：effective attempts, fake audio, fake, audio, fake audio detection</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Many effective attempts have been made for fake audio detection. However,
they can only provide detection results but no countermeasures to curb this
harm. For many related practical applications, what model or algorithm
generated the fake audio also is needed. Therefore, We propose a new problem
for detecting vocoder fingerprints of fake audio. Experiments are conducted on
the datasets synthesized by eight state-of-the-art vocoders. We have
preliminarily explored the features and model architectures. The t-SNE
visualization shows that different vocoders generate distinct vocoder
fingerprints.</p>
  </details>
</details>
<details>
  <summary>60. <b>标题：Are You Comfortable Now: Deep Learning the Temporal Variation in Thermal  Comfort in Winters</b></summary>
  <p><b>编号</b>：[344]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09628</p>
  <p><b>作者</b>：Betty Lala,  Srikant Manas Kala,  Anmol Rastogi,  Kunal Dahiya,  Aya Hagishima</p>
  <p><b>备注</b>：Accepted for publication in IEEE SMC 2022</p>
  <p><b>关键词</b>：thermal comfort, Indoor thermal comfort, thermal, Indoor thermal, comfort</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Indoor thermal comfort in smart buildings has a significant impact on the
health and performance of occupants. Consequently, machine learning (ML) is
increasingly used to solve challenges related to indoor thermal comfort.
Temporal variability of thermal comfort perception is an important problem that
regulates occupant well-being and energy consumption. However, in most ML-based
thermal comfort studies, temporal aspects such as the time of day, circadian
rhythm, and outdoor temperature are not considered. This work addresses these
problems. It investigates the impact of circadian rhythm and outdoor
temperature on the prediction accuracy and classification performance of ML
models. The data is gathered through month-long field experiments carried out
in 14 classrooms of 5 schools, involving 512 primary school students. Four
thermal comfort metrics are considered as the outputs of Deep Neural Networks
and Support Vector Machine models for the dataset. The effect of temporal
variability on school children's comfort is shown through a "time of day"
analysis. Temporal variability in prediction accuracy is demonstrated (up to
80%). Furthermore, we show that outdoor temperature (varying over time)
positively impacts the prediction performance of thermal comfort models by up
to 30%. The importance of spatio-temporal context is demonstrated by
contrasting micro-level (location specific) and macro-level (6 locations across
a city) performance. The most important finding of this work is that a
definitive improvement in prediction accuracy is shown with an increase in the
time of day and sky illuminance, for multiple thermal comfort metrics.</p>
  </details>
</details>
<details>
  <summary>61. <b>标题：Representing Knowledge by Spans: A Knowledge-Enhanced Model for  Information Extraction</b></summary>
  <p><b>编号</b>：[347]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09625</p>
  <p><b>作者</b>：Jiacheng Li,  Yannis Katsis,  Tyler Baldwin,  Ho-Cheol Kim,  Andrew Bartko,  Julian McAuley,  Chun-Nan Hsu</p>
  <p><b>备注</b>：CIKM 2022</p>
  <p><b>关键词</b>：knowledge base construction, base construction tasks, entities, base construction, BERT</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Knowledge-enhanced pre-trained models for language representation have been
shown to be more effective in knowledge base construction tasks (i.e.,~relation
extraction) than language models such as BERT. These knowledge-enhanced
language models incorporate knowledge into pre-training to generate
representations of entities or relationships. However, existing methods
typically represent each entity with a separate embedding. As a result, these
methods struggle to represent out-of-vocabulary entities and a large amount of
parameters, on top of their underlying token models (i.e.,~the transformer),
must be used and the number of entities that can be handled is limited in
practice due to memory constraints. Moreover, existing models still struggle to
represent entities and relationships simultaneously. To address these problems,
we propose a new pre-trained model that learns representations of both entities
and relationships from token spans and span pairs in the text respectively. By
encoding spans efficiently with span modules, our model can represent both
entities and their relationships but requires fewer parameters than existing
models. We pre-trained our model with the knowledge graph extracted from
Wikipedia and test it on a broad range of supervised and unsupervised
information extraction tasks. Results show that our model learns better
representations for both entities and relationships than baselines, while in
supervised settings, fine-tuning our model outperforms RoBERTa consistently and
achieves competitive results on information extraction tasks.</p>
  </details>
</details>
<details>
  <summary>62. <b>标题：A Novel Hybrid Sampling Framework for Imbalanced Learning</b></summary>
  <p><b>编号</b>：[349]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09619</p>
  <p><b>作者</b>：Asif Newaz,  Farhan Shahriyar Haq</p>
  <p><b>备注</b>：Submitted to "Expert Systems with Applications"</p>
  <p><b>关键词</b>：frequently occurring scenario, sampling techniques, frequently occurring, occurring scenario, sampling</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Class imbalance is a frequently occurring scenario in classification tasks.
Learning from imbalanced data poses a major challenge, which has instigated a
lot of research in this area. Data preprocessing using sampling techniques is a
standard approach to deal with the imbalance present in the data. Since
standard classification algorithms do not perform well on imbalanced data, the
dataset needs to be adequately balanced before training. This can be
accomplished by oversampling the minority class or undersampling the majority
class. In this study, a novel hybrid sampling algorithm has been proposed. To
overcome the limitations of the sampling techniques while ensuring the quality
of the retained sampled dataset, a sophisticated framework has been developed
to properly combine three different sampling techniques. Neighborhood Cleaning
rule is first applied to reduce the imbalance. Random undersampling is then
strategically coupled with the SMOTE algorithm to obtain an optimal balance in
the dataset. This proposed hybrid methodology, termed "SMOTE-RUS-NC", has been
compared with other state-of-the-art sampling techniques. The strategy is
further incorporated into the ensemble learning framework to obtain a more
robust classification algorithm, termed "SRN-BRF". Rigorous experimentation has
been conducted on 26 imbalanced datasets with varying degrees of imbalance. In
virtually all datasets, the proposed two algorithms outperformed existing
sampling strategies, in many cases by a substantial margin. Especially in
highly imbalanced datasets where popular sampling techniques failed utterly,
they achieved unparalleled performance. The superior results obtained
demonstrate the efficacy of the proposed models and their potential to be
powerful sampling algorithms in imbalanced domain.</p>
  </details>
</details>
<details>
  <summary>63. <b>标题：Fully Automated End-to-End Fake Audio Detection</b></summary>
  <p><b>编号</b>：[350]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09618</p>
  <p><b>作者</b>：Chenglong Wang,  Jiangyan Yi,  Jianhua Tao,  Haiyang Sun,  Xun Chen,  Zhengkun Tian,  Haoxin Ma,  Cunhang Fan,  Ruibo Fu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：existing fake audio, design the acoustic, design the hyperparameters, fake audio detection, rely on expert</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The existing fake audio detection systems often rely on expert experience to
design the acoustic features or manually design the hyperparameters of the
network structure. However, artificial adjustment of the parameters can have a
relatively obvious influence on the results. It is almost impossible to
manually set the best set of parameters. Therefore this paper proposes a fully
automated end-toend fake audio detection method. We first use wav2vec
pre-trained model to obtain a high-level representation of the speech.
Furthermore, for the network structure, we use a modified version of the
differentiable architecture search (DARTS) named light-DARTS. It learns deep
speech representations while automatically learning and optimizing complex
neural structures consisting of convolutional operations and residual blocks.
The experimental results on the ASVspoof 2019 LA dataset show that our proposed
system achieves an equal error rate (EER) of 1.08%, which outperforms the
state-of-the-art single system.</p>
  </details>
</details>
<details>
  <summary>64. <b>标题：MemoNav: Selecting Informative Memories for Visual Navigation</b></summary>
  <p><b>编号</b>：[358]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09610</p>
  <p><b>作者</b>：Hongxin Li,  Xu Yang,  Yuran Yang,  Shuqi Mei,  Zhaoxiang Zhang</p>
  <p><b>备注</b>：Submitted to ICLR2023</p>
  <p><b>关键词</b>：previously unseen scene, short-term memory, memory, navigation, unseen scene</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Image-goal navigation is a challenging task, as it requires the agent to
navigate to a target indicated by an image in a previously unseen scene.
Current methods introduce diverse memory mechanisms which save navigation
history to solve this task. However, these methods use all observations in the
memory for generating navigation actions without considering which fraction of
this memory is informative. To address this limitation, we present the MemoNav,
a novel memory mechanism for image-goal navigation, which retains the agent's
informative short-term memory and long-term memory to improve the navigation
performance on a multi-goal task. The node features on the agent's topological
map are stored in the short-term memory, as these features are dynamically
updated. To aid the short-term memory, we also generate long-term memory by
continuously aggregating the short-term memory via a graph attention module.
The MemoNav retains the informative fraction of the short-term memory via a
forgetting module based on a Transformer decoder and then incorporates this
retained short-term memory and the long-term memory into working memory.
Lastly, the agent uses the working memory for action generation. We evaluate
our model on a new multi-goal navigation dataset. The experimental results show
that the MemoNav outperforms the SoTA methods by a large margin with a smaller
fraction of navigation history. The results also empirically show that our
model is less likely to be trapped in a deadlock, which further validates that
the MemoNav improves the agent's navigation efficiency by reducing redundant
steps.</p>
  </details>
</details>
<details>
  <summary>65. <b>标题：Using Multi-Encoder Fusion Strategies to Improve Personalized Response  Selection</b></summary>
  <p><b>编号</b>：[361]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09601</p>
  <p><b>作者</b>：Souvik Das,  Sougata Saha,  Rohini K. Srihari</p>
  <p><b>备注</b>：COLING 2022. arXiv admin note: text overlap with arXiv:2105.09050 by other authors</p>
  <p><b>关键词</b>：Personalized response selection, generally grounded, Personalized response, response selection systems, response selection</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Personalized response selection systems are generally grounded on persona.
However, there exists a co-relation between persona and empathy, which is not
explored well in these systems. Also, faithfulness to the conversation context
plunges when a contradictory or an off-topic response is selected. This paper
attempts to address these issues by proposing a suite of fusion strategies that
capture the interaction between persona, emotion, and entailment information of
the utterances. Ablation studies on the Persona-Chat dataset show that
incorporating emotion and entailment improves the accuracy of response
selection. We combine our fusion strategies and concept-flow encoding to train
a BERT-based model which outperforms the previous methods by margins larger
than 2.3 % on original personas and 1.9 % on revised personas in terms of
hits@1 (top-1 accuracy), achieving a new state-of-the-art performance on the
Persona-Chat dataset.</p>
  </details>
</details>
<details>
  <summary>66. <b>标题：Data-Driven Causal Effect Estimation Based on Graphical Causal  Modelling: A Survey</b></summary>
  <p><b>编号</b>：[367]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09590</p>
  <p><b>作者</b>：Debo Cheng,  Jiuyong Li,  Lin Liu,  Jixue Liu,  Thuc Duy Le</p>
  <p><b>备注</b>：25 pages, 7 figures and 1 table</p>
  <p><b>关键词</b>：causal effect estimation, responses or interventions, causal, fields of scientific, crucial for understanding</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In many fields of scientific research and real-world applications, unbiased
estimation of causal effects from non-experimental data is crucial for
understanding the mechanism underlying the data and for decision-making on
effective responses or interventions. A great deal of research has been
conducted on this challenging problem from different angles. For causal effect
estimation in data, assumptions such as Markov property, faithfulness and
causal sufficiency are always made. Under the assumptions, full knowledge such
as, a set of covariates or an underlying causal graph, is still required. A
practical challenge is that in many applications, no such full knowledge or
only some partial knowledge is available. In recent years, research has emerged
to use a search strategy based on graphical causal modelling to discover useful
knowledge from data for causal effect estimation, with some mild assumptions,
and has shown promose in tackling the practical challenge. In this survey, we
review the methods and focus on the challenges the data-driven methods face. We
discuss the assumptions, strengths and limitations of the data-driven methods.
We hope this review will motivate more researchers to design better data-driven
methods based on graphical causal modelling for the challenging problem of
causal effect estimation.</p>
  </details>
</details>
<details>
  <summary>67. <b>标题：Review on Action Recognition for Accident Detection in Smart City  Transportation Systems</b></summary>
  <p><b>编号</b>：[368]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09588</p>
  <p><b>作者</b>：Victor Adewopo,  Nelly Elsayed,  Zag ElSayed,  Murat Ozer,  Ahmed Abdelgawad,  Magdy Bayoumi</p>
  <p><b>备注</b>：16 pages</p>
  <p><b>关键词</b>：crucial aspects, safe community, accident detection, public traffic safety, traffic</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Action detection and public traffic safety are crucial aspects of a safe
community and a better society. Monitoring traffic flows in a smart city using
different surveillance cameras can play a significant role in recognizing
accidents and alerting first responders. The utilization of action recognition
(AR) in computer vision tasks has contributed towards high-precision
applications in video surveillance, medical imaging, and digital signal
processing. This paper presents an intensive review focusing on action
recognition in accident detection and autonomous transportation systems for a
smart city. In this paper, we focused on AR systems that used diverse sources
of traffic video capturing, such as static surveillance cameras on traffic
intersections, highway monitoring cameras, drone cameras, and dash-cams.
Through this review, we identified the primary techniques, taxonomies, and
algorithms used in AR for autonomous transportation and accident detection. We
also examined data sets utilized in the AR tasks, identifying the main sources
of datasets and features of the datasets. This paper provides potential
research direction to develop and integrate accident detection systems for
autonomous cars and public traffic safety systems by alerting emergency
personnel and law enforcement in the event of road accidents to minimize human
error in accident reporting and provide a spontaneous response to victims</p>
  </details>
</details>
<details>
  <summary>68. <b>标题：Learning in Audio-visual Context: A Review, Analysis, and New  Perspective</b></summary>
  <p><b>编号</b>：[372]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09579</p>
  <p><b>作者</b>：Yake Wei,  Di Hu,  Yapeng Tian,  Xuelong Li</p>
  <p><b>备注</b>：this https URL</p>
  <p><b>关键词</b>：audio-visual, audio-visual learning, Sight and hearing, senses that play, play a vital</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Sight and hearing are two senses that play a vital role in human
communication and scene understanding. To mimic human perception ability,
audio-visual learning, aimed at developing computational approaches to learn
from both audio and visual modalities, has been a flourishing field in recent
years. A comprehensive survey that can systematically organize and analyze
studies of the audio-visual field is expected. Starting from the analysis of
audio-visual cognition foundations, we introduce several key findings that have
inspired our computational studies. Then, we systematically review the recent
audio-visual learning studies and divide them into three categories:
audio-visual boosting, cross-modal perception and audio-visual collaboration.
Through our analysis, we discover that, the consistency of audio-visual data
across semantic, spatial and temporal support the above studies. To revisit the
current development of the audio-visual learning field from a more macro view,
we further propose a new perspective on audio-visual scene understanding, then
discuss and analyze the feasible future direction of the audio-visual learning
area. Overall, this survey reviews and outlooks the current audio-visual
learning field from different aspects. We hope it can provide researchers with
a better understanding of this area. A website including constantly-updated
survey is released: \url{this https URL}.</p>
  </details>
</details>
<details>
  <summary>69. <b>标题：Contrastive Domain Adaptation for Early Misinformation Detection: A Case  Study on COVID-19</b></summary>
  <p><b>编号</b>：[373]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09578</p>
  <p><b>作者</b>：Zhenrui Yue,  Huimin Zeng,  Ziyi Kou,  Lanyu Shang,  Dong Wang</p>
  <p><b>备注</b>：Accepted to CIKM 2022</p>
  <p><b>关键词</b>：early misinformation detection, early misinformation, misinformation detection, elusive challenge, misinformation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Despite recent progress in improving the performance of misinformation
detection systems, classifying misinformation in an unseen domain remains an
elusive challenge. To address this issue, a common approach is to introduce a
domain critic and encourage domain-invariant input features. However, early
misinformation often demonstrates both conditional and label shifts against
existing misinformation data (e.g., class imbalance in COVID-19 datasets),
rendering such methods less effective for detecting early misinformation. In
this paper, we propose contrastive adaptation network for early misinformation
detection (CANMD). Specifically, we leverage pseudo labeling to generate
high-confidence target examples for joint training with source data. We
additionally design a label correction component to estimate and correct the
label shifts (i.e., class priors) between the source and target domains.
Moreover, a contrastive adaptation loss is integrated in the objective function
to reduce the intra-class discrepancy and enlarge the inter-class discrepancy.
As such, the adapted model learns corrected class priors and an invariant
conditional distribution across both domains for improved estimation of the
target data distribution. To demonstrate the effectiveness of the proposed
CANMD, we study the case of COVID-19 early misinformation detection and perform
extensive experiments using multiple real-world datasets. The results suggest
that CANMD can effectively adapt misinformation detection systems to the unseen
COVID-19 target domain with significant improvements compared to the
state-of-the-art baselines.</p>
  </details>
</details>
<details>
  <summary>70. <b>标题：Unit Selection with Nonbinary Treatment and Effect</b></summary>
  <p><b>编号</b>：[377]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09569</p>
  <p><b>作者</b>：Ang Li,  Judea Pearl</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：unit selection problem, selection problem aims, mode of behavior, unit selection, selection problem</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The unit selection problem aims to identify a set of individuals who are most
likely to exhibit a desired mode of behavior, for example, selecting
individuals who would respond one way if encouraged and a different way if not
encouraged. Using a combination of experimental and observational data, Li and
Pearl derived tight bounds on the "benefit function", which is the payoff/cost
associated with selecting an individual with given characteristics. This paper
extends the benefit function to the general form such that the treatment and
effect are not restricted to binary. We propose an algorithm to test the
identifiability of the nonbinary benefit function and an algorithm to compute
the bounds of the nonbinary benefit function using experimental and
observational data.</p>
  </details>
</details>
<details>
  <summary>71. <b>标题：Probabilities of Causation with Nonbinary Treatment and Effect</b></summary>
  <p><b>编号</b>：[378]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09568</p>
  <p><b>作者</b>：Ang Li,  Judea Pearl</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：problem of estimating, probability of necessity, Pearl derived sharp, probabilities of causation, paper deals</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper deals with the problem of estimating the probabilities of
causation when treatment and effect are not binary. Tian and Pearl derived
sharp bounds for the probability of necessity and sufficiency (PNS), the
probability of sufficiency (PS), and the probability of necessity (PN) using
experimental and observational data. In this paper, we provide theoretical
bounds for all types of probabilities of causation to multivalued treatments
and effects. We further discuss examples where our bounds guide practical
decisions and use simulation studies to evaluate how informative the bounds are
for various combinations of data.</p>
  </details>
</details>
<details>
  <summary>72. <b>标题：A Dual Modality Approach For (Zero-Shot) Multi-Label Classification</b></summary>
  <p><b>编号</b>：[380]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09562</p>
  <p><b>作者</b>：Shichao Xu,  Yikang Li,  Jenhao Hsiao,  Chiuman Ho,  Zhu Qi</p>
  <p><b>备注</b>：preprint</p>
  <p><b>关键词</b>：multi-label classification, Aligned Dual moDality, including zero-shot multi-label, zero-shot multi-label classification, real-world applications</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In computer vision, multi-label classification, including zero-shot
multi-label classification are important tasks with many real-world
applications. In this paper, we propose a novel algorithm, Aligned Dual
moDality ClaSsifier (ADDS), which includes a Dual-Modal decoder (DM-decoder)
with alignment between visual and textual features, for multi-label
classification tasks. Moreover, we design a simple and yet effective method
called Pyramid-Forwarding to enhance the performance for inputs with high
resolutions. Extensive experiments conducted on standard multi-label benchmark
datasets, MS-COCO and NUS-WIDE, demonstrate that our approach significantly
outperforms previous methods and provides state-of-the-art performance for
conventional multi-label classification, zero-shot multi-label classification,
and an extreme case called single-to-multi label classification where models
trained on single-label datasets (ImageNet-1k, ImageNet-21k) are tested on
multi-label ones (MS-COCO and NUS-WIDE). We also analyze how visual-textual
alignment contributes to the proposed approach, validate the significance of
the DM-decoder, and demonstrate the effectiveness of Pyramid-Forwarding on
vision transformer.</p>
  </details>
</details>
<details>
  <summary>73. <b>标题：Personalized Decision Making -- A Conceptual Introduction</b></summary>
  <p><b>编号</b>：[381]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09558</p>
  <p><b>作者</b>：Scott Mueller,  Judea Pearl</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Personalized decision making, decision making targets, population-based decision making, decision making concerns, making targets</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Personalized decision making targets the behavior of a specific individual,
while population-based decision making concerns a sub-population resembling
that individual. This paper clarifies the distinction between the two and
explains why the former leads to more informed decisions. We further show that
by combining experimental and observational studies we can obtain valuable
information about individual behavior and, consequently, improve decisions over
those obtained from experimental studies alone.</p>
  </details>
</details>
<details>
  <summary>74. <b>标题：Evaluating Diverse Knowledge Sources for Online One-shot Learning of  Novel Tasks</b></summary>
  <p><b>编号</b>：[383]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09554</p>
  <p><b>作者</b>：James R. Kirk,  Robert E. Wray,  Peter Lindes,  John E. Laird</p>
  <p><b>备注</b>：7 pages, 4 figures</p>
  <p><b>关键词</b>：current approaches invariably, approaches invariably focus, Online autonomous agents, Online autonomous, wide variety</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Online autonomous agents are able to draw on a wide variety of potential
sources of task knowledge; however current approaches invariably focus on only
one or two. Here we investigate the challenges and impact of exploiting diverse
knowledge sources to learn, in one-shot, new tasks for a simulated household
mobile robot. The resulting agent, developed in the Soar cognitive
architecture, uses the following sources of domain and task knowledge:
interaction with the environment, task execution and planning knowledge, human
natural language instruction, and responses retrieved from a large language
model (GPT-3). We explore the distinct contributions of these knowledge sources
and evaluate the performance of different combinations in terms of learning
correct task knowledge, human workload, and computational costs. The results
from combining all sources demonstrate that integration improves one-shot task
learning overall in terms of computational costs and human workload.</p>
  </details>
</details>
<details>
  <summary>75. <b>标题：[Re] Differentiable Spatial Planning using Transformers</b></summary>
  <p><b>编号</b>：[388]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09536</p>
  <p><b>作者</b>：Rohit Ranjan,  Himadri Bhakta,  Animesh Jha,  Parv Maheshwari,  Debashish Chakravarty</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：report covers, covers our reproduction, Transformers' by Chaplot, Spatial Planning Transformers, Spatial Planning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This report covers our reproduction effort of the paper 'Differentiable
Spatial Planning using Transformers' by Chaplot et al. . In this paper, the
problem of spatial path planning in a differentiable way is considered. They
show that their proposed method of using Spatial Planning Transformers
outperforms prior data-driven models and leverages differentiable structures to
learn mapping without a ground truth map simultaneously. We verify these claims
by reproducing their experiments and testing their method on new data. We also
investigate the stability of planning accuracy with maps with increased
obstacle complexity. Efforts to investigate and verify the learnings of the
Mapper module were met with failure stemming from a paucity of computational
resources and unreachable authors.</p>
  </details>
</details>
<details>
  <summary>76. <b>标题：Globus Automation Services: Research process automation across the  space-time continuum</b></summary>
  <p><b>编号</b>：[398]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09513</p>
  <p><b>作者</b>：Ryan Chard,  Jim Pruyne,  Kurt McKee,  Josh Bryan,  Brigitte Raumann,  Rachana Ananthakrishnan,  Kyle Chard,  Ian Foster</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Globus automation services, Research process automation, Globus research data, modern science, essential element</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Research process automation--the reliable, efficient, and reproducible
execution of linked sets of actions on scientific instruments, computers, data
stores, and other resources--has emerged as an essential element of modern
science. We report here on new services within the Globus research data
management platform that enable the specification of diverse research processes
as reusable sets of actions, flows, and the execution of such flows in
heterogeneous research environments. To support flows with broad spatial extent
(e.g., from scientific instrument to remote data center) and temporal extent
(from seconds to weeks), these Globus automation services feature: 1) cloud
hosting for reliable execution of even long-lived flows despite sporadic
failures; 2) a declarative notation, and extensible asynchronous action
provider API, for defining and executing a wide variety of actions and flow
specifications involving arbitrary resources; 3) authorization delegation
mechanisms for secure invocation of actions. These services permit researchers
to outsource and automate the management of a broad range of research tasks to
a reliable, scalable, and secure cloud platform. We present use cases for
Globus automation services, describe the design and implementation of the
services, present microbenchmark studies, and review experiences applying the
services in a range of applications</p>
  </details>
</details>
<details>
  <summary>77. <b>标题：Topical: Learning Repository Embeddings from Source Code using Attention</b></summary>
  <p><b>编号</b>：[402]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09495</p>
  <p><b>作者</b>：Agathe Lherondelle,  Yash Satsangi,  Fran Silavong,  Shaltiel Eloul,  Sean Moran</p>
  <p><b>备注</b>：Pre-print, under review</p>
  <p><b>关键词</b>：Machine learning, promises to transform, code, repository, repository level</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Machine learning on source code (MLOnCode) promises to transform how software
is delivered. By mining the context and relationship between software
artefacts, MLOnCode augments the software developers capabilities with code
auto-generation, code recommendation, code auto-tagging and other data-driven
enhancements. For many of these tasks a script level representation of code is
sufficient, however, in many cases a repository level representation that takes
into account various dependencies and repository structure is imperative, for
example, auto-tagging repositories with topics or auto-documentation of
repository code etc. Existing methods for computing repository level
representations suffer from (a) reliance on natural language documentation of
code (for example, README files) (b) naive aggregation of method/script-level
representation, for example, by concatenation or averaging. This paper
introduces Topical a deep neural network to generate repository level
embeddings of publicly available GitHub code repositories directly from source
code. Topical incorporates an attention mechanism that projects the source
code, the full dependency graph and the script level textual information into a
dense repository-level representation. To compute the repository-level
representations, Topical is trained to predict the topics associated with a
repository, on a dataset of publicly available GitHub repositories that were
crawled along with their ground truth topic tags. Our experiments show that the
embeddings computed by Topical are able to outperform multiple baselines,
including baselines that naively combine the method-level representations
through averaging or concatenation at the task of repository auto-tagging.</p>
  </details>
</details>
<details>
  <summary>78. <b>标题：Exploiting Temporal Structures of Cyclostationary Signals for  Data-Driven Single-Channel Source Separation</b></summary>
  <p><b>编号</b>：[410]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10325</p>
  <p><b>作者</b>：Gary C.F. Lee,  Amir Weiss,  Alejandro Lancho,  Jennifer Tang,  Yuheng Bu,  Yury Polyanskiy,  Gregory W. Wornell</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：application domains, Unlike classical SCSS, classical SCSS approaches, study the problem, problem of single-channel</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We study the problem of single-channel source separation (SCSS), and focus on
cyclostationary signals, which are particularly suitable in a variety of
application domains. Unlike classical SCSS approaches, we consider a setting
where only examples of the sources are available rather than their models,
inspiring a data-driven approach. For source models with underlying
cyclostationary Gaussian constituents, we establish a lower bound on the
attainable mean squared error (MSE) for any separation method, model-based or
data-driven. Our analysis further reveals the operation for optimal separation
and the associated implementation challenges. As a computationally attractive
alternative, we propose a deep learning approach using a U-Net architecture,
which is competitive with the minimum MSE estimator. We demonstrate in
simulation that, with suitable domain-informed architectural choices, our U-Net
method can approach the optimal performance with substantially reduced
computational burden.</p>
  </details>
</details>
<details>
  <summary>79. <b>标题：An Entropy-based Measure of Intelligence Degree of System Structures</b></summary>
  <p><b>编号</b>：[413]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.10266</p>
  <p><b>作者</b>：Wei Su</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：intelligence degree, systems under specific, intelligence, structures, specific environments</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we investigate how to measure the intelligence of systems
under specific structures. Two indicators are adopted to characterize the
intelligence of a given structure, namely the function diversity of the
structure, and the ability to generate order under specific environments. A
measure of intelligence degree is proposed, with which the intelligence degree
of several basic structures is calculated. It is shown that some structures are
indeed "smarter" than the others under the proposed measure. The results add a
possible way of revealing the evolution mechanism of natural life and
constructing life-like structures with high intelligence degree.</p>
  </details>
</details>
<details>
  <summary>80. <b>标题：FastCPH: Efficient Survival Analysis for Neural Networks</b></summary>
  <p><b>编号</b>：[437]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2208.09793</p>
  <p><b>作者</b>：Xuelin Yang,  Louis Abraham,  Sejin Kim,  Petr Smirnov,  Feng Ruan,  Benjamin Haibe-Kains,  Robert Tibshirani</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Cox proportional hazards, proportional hazards model, Cox proportional, original form, proportional hazards</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The Cox proportional hazards model is a canonical method in survival analysis
for prediction of the life expectancy of a patient given clinical or genetic
covariates -- it is a linear model in its original form. In recent years,
several methods have been proposed to generalize the Cox model to neural
networks, but none of these are both numerically correct and computationally
efficient. We propose FastCPH, a new method that runs in linear time and
supports both the standard Breslow and Efron methods for tied events. We also
demonstrate the performance of FastCPH combined with LassoNet, a neural network
that provides interpretability through feature sparsity, on survival datasets.
The final procedure is efficient, selects useful covariates and outperforms
existing CoxPH approaches.</p>
  </details>
</details>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">徐耀彬</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://louishsu.xyz/2022/08/23/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html">http://louishsu.xyz/2022/08/23/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://louishsu.xyz" target="_blank">LOUIS' BLOG</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"></div><div class="post_share"><div class="social-share" data-image="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="next-post pull-full"><a href="/2021/10/22/%E4%B8%AD%E5%9B%BD%E6%B3%95%E5%BE%8B%E6%99%BA%E8%83%BD%E6%8A%80%E6%9C%AF%E8%AF%84%E6%B5%8B(CAIL2021)%EF%BC%9A%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96(Rank2).html"><img class="next-cover" src="http://cail.cipsc.org.cn/img/index_mainpic.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">中国法律智能技术评测(CAIL2021)：信息抽取(Rank2)</div></div></a></div></nav><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="twikoo-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="card-info-avatar is-center"><img class="avatar-img" src="/img/touxiang.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/><div class="author-info__name">徐耀彬</div><div class="author-info__description">做知识的原创者！</div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">11</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">标签</div><div class="length-num">3</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">分类</div><div class="length-num">7</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/isLouisHsu"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/isLouisHsu" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:is.louishsu@foxmail.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>公告</span></div><div class="announcement_content">记录和分享一些学习和开源内容，若有问题可通过邮箱is.louishsu@foxmail.com联系，欢迎交流！！</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">1.</span> <span class="toc-text">统计</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">2.</span> <span class="toc-text">计算机视觉</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">3.</span> <span class="toc-text">自然语言处理</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">4.</span> <span class="toc-text">机器学习</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">5.</span> <span class="toc-text">人工智能</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2022/08/23/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html" title="Arxiv每日速递(2022-08-23)"><img src="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Arxiv每日速递(2022-08-23)"/></a><div class="content"><a class="title" href="/2022/08/23/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html" title="Arxiv每日速递(2022-08-23)">Arxiv每日速递(2022-08-23)</a><time datetime="2022-08-23T00:56:42.253Z" title="发表于 2022-08-23 08:56:42">2022-08-23</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/10/22/%E4%B8%AD%E5%9B%BD%E6%B3%95%E5%BE%8B%E6%99%BA%E8%83%BD%E6%8A%80%E6%9C%AF%E8%AF%84%E6%B5%8B(CAIL2021)%EF%BC%9A%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96(Rank2).html" title="中国法律智能技术评测(CAIL2021)：信息抽取(Rank2)"><img src="http://cail.cipsc.org.cn/img/index_mainpic.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="中国法律智能技术评测(CAIL2021)：信息抽取(Rank2)"/></a><div class="content"><a class="title" href="/2021/10/22/%E4%B8%AD%E5%9B%BD%E6%B3%95%E5%BE%8B%E6%99%BA%E8%83%BD%E6%8A%80%E6%9C%AF%E8%AF%84%E6%B5%8B(CAIL2021)%EF%BC%9A%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96(Rank2).html" title="中国法律智能技术评测(CAIL2021)：信息抽取(Rank2)">中国法律智能技术评测(CAIL2021)：信息抽取(Rank2)</a><time datetime="2021-10-22T14:29:06.000Z" title="发表于 2021-10-22 22:29:06">2021-10-22</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/05/19/%E5%85%A8%E7%90%83%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%8A%80%E6%9C%AF%E5%88%9B%E6%96%B0%E5%A4%A7%E8%B5%9B%E3%80%90%E8%B5%9B%E9%81%93%E4%B8%80%E3%80%91%EF%BC%9A%E5%8C%BB%E5%AD%A6%E5%BD%B1%E5%83%8F%E6%8A%A5%E5%91%8A%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B.html" title="全球人工智能技术创新大赛【赛道一】：医学影像报告异常检测"><img src="https://tianchi-public.oss-cn-hangzhou.aliyuncs.com/public/files/forum/161037709574435991610377095138.jpeg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="全球人工智能技术创新大赛【赛道一】：医学影像报告异常检测"/></a><div class="content"><a class="title" href="/2021/05/19/%E5%85%A8%E7%90%83%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%8A%80%E6%9C%AF%E5%88%9B%E6%96%B0%E5%A4%A7%E8%B5%9B%E3%80%90%E8%B5%9B%E9%81%93%E4%B8%80%E3%80%91%EF%BC%9A%E5%8C%BB%E5%AD%A6%E5%BD%B1%E5%83%8F%E6%8A%A5%E5%91%8A%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B.html" title="全球人工智能技术创新大赛【赛道一】：医学影像报告异常检测">全球人工智能技术创新大赛【赛道一】：医学影像报告异常检测</a><time datetime="2021-05-19T09:57:06.000Z" title="发表于 2021-05-19 17:57:06">2021-05-19</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2020/09/16/%E8%AF%A6%E8%A7%A3%E5%91%BD%E5%90%8D%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB%E6%A8%A1%E5%9E%8B%EF%BC%9ALSTM-CRF.html" title="详解命名实体识别模型：LSTM-CRF"><img src="https://gimg2.baidu.com/image_search/src=http%3A%2F%2Fpic1.zhimg.com%2Fv2-1ed6a10dbb239a148e42df088c5870a6_1440w.jpg%3Fsource%3D172ae18b&amp;refer=http%3A%2F%2Fpic1.zhimg.com&amp;app=2002&amp;size=f9999,10000&amp;q=a80&amp;n=0&amp;g=0n&amp;fmt=jpeg?sec=1638183974&amp;t=4632f13fd487ed1cfcb12d67a6b71e52" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="详解命名实体识别模型：LSTM-CRF"/></a><div class="content"><a class="title" href="/2020/09/16/%E8%AF%A6%E8%A7%A3%E5%91%BD%E5%90%8D%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB%E6%A8%A1%E5%9E%8B%EF%BC%9ALSTM-CRF.html" title="详解命名实体识别模型：LSTM-CRF">详解命名实体识别模型：LSTM-CRF</a><time datetime="2020-09-16T09:26:44.000Z" title="发表于 2020-09-16 17:26:44">2020-09-16</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2020/06/14/%E8%AE%B0%E4%B8%80%E6%AC%A1MySQL%E8%A7%A3%E5%86%B3%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E6%97%B6%E7%9A%84%E5%88%86%E8%A1%A8%E9%97%AE%E9%A2%98.html" title="记一次MySQL解决大数据存储时的分表问题"><img src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="记一次MySQL解决大数据存储时的分表问题"/></a><div class="content"><a class="title" href="/2020/06/14/%E8%AE%B0%E4%B8%80%E6%AC%A1MySQL%E8%A7%A3%E5%86%B3%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E6%97%B6%E7%9A%84%E5%88%86%E8%A1%A8%E9%97%AE%E9%A2%98.html" title="记一次MySQL解决大数据存储时的分表问题">记一次MySQL解决大数据存储时的分表问题</a><time datetime="2020-06-14T15:24:27.000Z" title="发表于 2020-06-14 23:24:27">2020-06-14</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2022 By 徐耀彬</div><div class="footer_custom_text"><p><a style="margin-inline:5px"target="_blank"href="https://hexo.io/"><img src="https://img.shields.io/badge/Frame-Hexo-blue?style=flat&logo=hexo"title="博客框架为Hexo"alt="img"></a><a style="margin-inline:5px"target="_blank"href="https://butterfly.js.org/"><img src="https://img.shields.io/badge/Theme-Butterfly-6513df?style=flat&logo=bitdefender"title="主题采用butterfly"alt="img"></a><a style="margin-inline:5px"target="_blank"href="https://www.jsdelivr.com/"><img src="https://img.shields.io/badge/CDN-jsDelivr-orange?style=flat&logo=jsDelivr"title="本站使用JsDelivr为静态资源提供CDN加速"alt="img"></a><a style="margin-inline:5px"target="_blank"href="https://github.com/"><img src="https://img.shields.io/badge/Source-Github-d021d6?style=flat&logo=GitHub"title="本站项目由Gtihub托管"alt="img"></a><a style="margin-inline:5px"target="_blank"href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img src="https://img.shields.io/badge/Copyright-BY--NC--SA%204.0-d42328?style=flat&logo=Claris"alt="img"title="本站采用知识共享署名-非商业性使用-相同方式共享4.0国际许可协议进行许可"></a></br></p></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="font-plus" type="button" title="放大字体"><i class="fas fa-plus"></i></button><button id="font-minus" type="button" title="缩小字体"><i class="fas fa-minus"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div></div><hr/><div id="local-search-results"></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.css"><script>(() => {
  document.querySelectorAll('#article-container span.katex-display').forEach(item => {
    btf.wrap(item, 'div', '', 'katex-wrap')
  })
})()</script><script>(()=>{
  const $countDom = document.getElementById('twikoo-count')
  const init = () => {
    let initData = {
      el: '#twikoo-wrap',
      envId: 'blog-',
      region: ''
    }

    if (false) {
      const otherData = false
      initData = Object.assign(initData, otherData)
    }
    
    twikoo.init(initData)
  }

  const getCount = () => {
    twikoo.getCommentsCount({
      envId: 'blog-',
      region: '',
      urls: [window.location.pathname],
      includeReply: false
    }).then(function (res) {
      $countDom.innerText = res[0].count
    }).catch(function (err) {
      console.error(err);
    });
  }

  const loadTwikoo = (bool = false) => {
    if (typeof twikoo === 'object') {
      init()
      bool && $countDom && setTimeout(getCount,0)
    } else {
      getScript('https://cdn.jsdelivr.net/npm/twikoo/dist/twikoo.all.min.js').then(()=> {
        init()
        bool && $countDom && setTimeout(getCount,0)
      })
    }
  }

  if ('Twikoo' === 'Twikoo' || !false) {
    if (false) btf.loadComment(document.getElementById('twikoo-wrap'), loadTwikoo)
    else loadTwikoo(true)
  } else {
    window.loadOtherComment = () => {
      loadTwikoo()
    }
  }
})()</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><!-- hexo injector body_end start --> <script data-pjax>if(document.getElementById('recent-posts') && (location.pathname ==='/'|| '/' ==='all')){
    var parent = document.getElementById('recent-posts');
    var child = '<div class="recent-post-item" style="width:100%;height: auto"><div id="catalog_magnet"><div class="magnet_item"><a class="magnet_link" href="http://louishsu.xyz/categories/机器学习/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🐱 机器学习 (1)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://louishsu.xyz/categories/自然语言处理/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">📚 自然语言处理 (1)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://louishsu.xyz/categories/竞赛相关/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🎮 竞赛相关 (2)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://louishsu.xyz/categories/阅读笔记/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🎮 阅读笔记 (1)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><a class="magnet_link_more"  href="http://louishsu.xyz/categories" style="flex:1;text-align: center;margin-bottom: 10px;">查看更多...</a></div></div>';
    console.log('已挂载magnet')
    parent.insertAdjacentHTML("afterbegin",child)}
     </script><style>#catalog_magnet{flex-wrap: wrap;display: flex;width:100%;justify-content:space-between;padding: 10px 10px 0 10px;align-content: flex-start;}.magnet_item{flex-basis: calc(50% - 5px);background: #f2f2f2;margin-bottom: 10px;border-radius: 8px;transition: all 0.2s ease-in-out;}.magnet_item:hover{background: #b30070}.magnet_link_more{color:#555}.magnet_link{color:black}.magnet_link:hover{color:white}@media screen and (max-width: 600px) {.magnet_item {flex-basis: 100%;}}.magnet_link_context{display:flex;padding: 10px;font-size:16px;transition: all 0.2s ease-in-out;}.magnet_link_context:hover{padding: 10px 20px;}</style>
    <style></style>
  <script data-pjax src="https://cdn.jsdelivr.net/gh/Zfour/hexo-github-calendar@1.21/hexo_githubcalendar.js"></script>
  <script data-pjax>
        function GithubCalendarConfig(){
            var git_githubapiurl ="https://python-github-calendar-api.vercel.app/api?isLouisHsu";
            var git_color =['#ebedf0', '#fdcdec', '#fc9bd9', '#fa6ac5', '#f838b2', '#f5089f', '#c4067e', '#92055e', '#540336', '#48022f', '#30021f'];
            var git_user ="isLouisHsu";
            var parent_div_git = document.getElementById('recent-posts');
            var git_div_html = '<div class="recent-post-item" style="width:100%;height:auto;padding:10px;"><div id="github_loading" style="width:10%;height:100%;margin:0 auto;display: block"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"  viewBox="0 0 50 50" style="enable-background:new 0 0 50 50" xml:space="preserve"><path fill="#d0d0d0" d="M25.251,6.461c-10.318,0-18.683,8.365-18.683,18.683h4.068c0-8.071,6.543-14.615,14.615-14.615V6.461z" transform="rotate(275.098 25 25)"><animateTransform attributeType="xml" attributeName="transform" type="rotate" from="0 25 25" to="360 25 25" dur="0.6s" repeatCount="indefinite"></animateTransform></path></svg></div><div id="github_container"></div></div>';
            if(parent_div_git && location.pathname =='/'){
                console.log('已挂载github calendar')
                // parent_div_git.innerHTML=git_div_html+parent_div_git.innerHTML // 无报错，但不影响使用(支持pjax跳转)
                parent_div_git.insertAdjacentHTML("afterbegin",git_div_html) // 有报错，但不影响使用(支持pjax跳转)
            };
            GithubCalendar(git_githubapiurl,git_color,git_user)
        }
        if(document.getElementById('recent-posts')){
            GithubCalendarConfig()
        }
    </script>
    <style>#github_container{min-height:280px}@media screen and (max-width:650px) {#github_container{background-image:;min-height:0px}}</style>
    <style></style><script data-pjax>function electric_clock_injector_config(){
                var parent_div_git = document.getElementsByClassName('sticky_layout')[0];
                var item_html = '<div class="card-widget card-clock"><div class="card-glass"><div class="card-background"><div class="card-content"><div id="hexo_electric_clock"><img id="card-clock-loading" src="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-clock/clock/images/weather/loading.gif" style="height: 120px; width: 100%;" data-ll-status="loading" class="entered loading"></div></div></div></div></div>';
                console.log('已挂载electric_clock')
                // parent_div_git.innerHTML=item_html+parent_div_git.innerHTML // 无报错，但不影响使用(支持pjax跳转)
                parent_div_git.insertAdjacentHTML("afterbegin",item_html) // 有报错，但不影响使用(支持pjax跳转)
            }if( document.getElementsByClassName('sticky_layout')[0] && (location.pathname ==='all'|| 'all' ==='all')){

            electric_clock_injector_config()
        } </script><script src="https://pv.sohu.com/cityjson?ie=utf-8"></script><script data-pjax  src="https://cdn.jsdelivr.net/gh/Zfour/hexo-electric-clock@1.0.6/clock.js"></script><!-- hexo injector body_end end --><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"model":{"jsonPath":"/live2dw/assets/hijiki.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":false},"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body></html>