<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Arxiv每日速递(2022-09-23) | LOUIS' BLOG</title><meta name="author" content="徐耀彬"><meta name="copyright" content="徐耀彬"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="本篇博文主要展示每日从Arxiv论文网站获取的最新论文列表，以计算机视觉、自然语言处理、机器学习、人工智能等大方向进行划分。 统计 今日共更新276篇论文，其中：  57篇计算机视觉（cs.CV） 23篇自然语言处理（cs.CL） 94篇机器学习（cs.LG） 45篇人工智能（cs.AI）  计算机视觉    1. 标题：NamedMask: Distilling Segmenters from">
<meta property="og:type" content="article">
<meta property="og:title" content="Arxiv每日速递(2022-09-23)">
<meta property="og:url" content="http://louishsu.xyz/2022/09/23/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html">
<meta property="og:site_name" content="LOUIS&#39; BLOG">
<meta property="og:description" content="本篇博文主要展示每日从Arxiv论文网站获取的最新论文列表，以计算机视觉、自然语言处理、机器学习、人工智能等大方向进行划分。 统计 今日共更新276篇论文，其中：  57篇计算机视觉（cs.CV） 23篇自然语言处理（cs.CL） 94篇机器学习（cs.LG） 45篇人工智能（cs.AI）  计算机视觉    1. 标题：NamedMask: Distilling Segmenters from">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png">
<meta property="article:published_time" content="2022-09-23T00:57:07.696Z">
<meta property="article:modified_time" content="2022-09-23T00:58:37.741Z">
<meta property="article:author" content="徐耀彬">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://louishsu.xyz/2022/09/23/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2022-09-23 08:58:37'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const fontSizeVal = saveToLocal.get('global-font-size')
    if (fontSizeVal !== undefined) {
      document.documentElement.style.setProperty('--global-font-size', fontSizeVal + 'px')
    }
    })(window)</script><link rel="stylesheet" href="/css/background.css"><script src="https://cdn.jsdelivr.net/npm/echarts@4.7.0/dist/echarts.min.js"></script><!-- hexo injector head_end start --><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Zfour/hexo-electric-clock@1.0.6/clock.css"><!-- hexo injector head_end end --><meta name="generator" content="Hexo 5.4.2"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="author-avatar"><img class="avatar-img" src="/img/touxiang.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">11</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">标签</div><div class="length-num">3</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">分类</div><div class="length-num">7</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/message/"><i class="fa-fw far fa-comment-dots"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa-fw fa fa-book"></i><span> 找文章</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></li><li><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></li><li><a class="site-page" href="/charts/"><i class="fa-fw fa fa-archive"></i><span> 统计</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-tools"></i><span> 工具</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/md_editor/"><i class="fa-fw fas fa-pen"></i><span> 在线markdown</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/isLouisHsu/blog/tree/master/source/_posts"><i class="fa-fw fa fa-star"></i><span> 在线push</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">LOUIS' BLOG</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/message/"><i class="fa-fw far fa-comment-dots"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa-fw fa fa-book"></i><span> 找文章</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></li><li><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></li><li><a class="site-page" href="/charts/"><i class="fa-fw fa fa-archive"></i><span> 统计</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-tools"></i><span> 工具</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/md_editor/"><i class="fa-fw fas fa-pen"></i><span> 在线markdown</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/isLouisHsu/blog/tree/master/source/_posts"><i class="fa-fw fa fa-star"></i><span> 在线push</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Arxiv每日速递(2022-09-23)<a class="post-edit-link" href="https://github.com/isLouisHsu/blog/tree/master/source_posts/Arxiv每日速递.md" title="编辑" target="_blank"><i class="fas fa-pencil-square"></i></a></h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-09-23T00:57:07.696Z" title="发表于 2022-09-23 08:57:07">2022-09-23</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2022-09-23T00:58:37.741Z" title="更新于 2022-09-23 08:58:37">2022-09-23</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">阅读笔记</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">3.6k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>21分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span><span class="post-meta-separator">|</span><span class="post-meta-commentcount"><i class="far fa-comments fa-fw post-meta-icon"></i><span class="post-meta-label">评论数:</span><a href="/2022/09/23/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html#post-comment"><span id="twikoo-count"></span></a></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><p>本篇博文主要展示每日从Arxiv论文网站获取的最新论文列表，以计算机视觉、自然语言处理、机器学习、人工智能等大方向进行划分。</p>
<h1>统计</h1>
<p>今日共更新276篇论文，其中：</p>
<ul>
<li>57篇计算机视觉（<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>）</li>
<li>23篇自然语言处理（<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>）</li>
<li>94篇机器学习（cs.LG）</li>
<li>45篇人工智能（<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>）</li>
</ul>
<h1>计算机视觉</h1>
<details>
  <summary>1. <b>标题：NamedMask: Distilling Segmenters from Complementary Foundation Models</b></summary>
  <p><b>编号</b>：[1]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.11228</p>
  <p><b>作者</b>：Gyungin Shin,  Weidi Xie,  Samuel Albanie</p>
  <p><b>备注</b>：Tech report. Code: this https URL</p>
  <p><b>关键词</b>：access to pixel-level, pixel-level labels, CLIP, images, object</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The goal of this work is to segment and name regions of images without access
to pixel-level labels during training. To tackle this task, we construct
segmenters by distilling the complementary strengths of two foundation models.
The first, CLIP (Radford et al. 2021), exhibits the ability to assign names to
image content but lacks an accessible representation of object structure. The
second, DINO (Caron et al. 2021), captures the spatial extent of objects but
has no knowledge of object names. Our method, termed NamedMask, begins by using
CLIP to construct category-specific archives of images. These images are
pseudo-labelled with a category-agnostic salient object detector bootstrapped
from DINO, then refined by category-specific segmenters using the CLIP archive
labels. Thanks to the high quality of the refined masks, we show that a
standard segmentation architecture trained on these archives with appropriate
data augmentation achieves impressive semantic segmentation abilities for both
single-object and multi-object images. As a result, our proposed NamedMask
performs favourably against a range of prior work on five benchmarks including
the VOC2012, COCO and large-scale ImageNet-S datasets.</p>
  </details>
</details>
<details>
  <summary>2. <b>标题：VToonify: Controllable High-Resolution Portrait Video Style Transfer</b></summary>
  <p><b>编号</b>：[2]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.11224</p>
  <p><b>作者</b>：Shuai Yang,  Liming Jiang,  Ziwei Liu,  Chen Change Loy</p>
  <p><b>备注</b>：ACM Transactions on Graphics (SIGGRAPH Asia 2022). Code: this https URL Project page: this https URL</p>
  <p><b>关键词</b>：artistic portrait videos, graphics and vision, portrait video style, important and desirable, desirable task</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Generating high-quality artistic portrait videos is an important and
desirable task in computer graphics and vision. Although a series of successful
portrait image toonification models built upon the powerful StyleGAN have been
proposed, these image-oriented methods have obvious limitations when applied to
videos, such as the fixed frame size, the requirement of face alignment,
missing non-facial details and temporal inconsistency. In this work, we
investigate the challenging controllable high-resolution portrait video style
transfer by introducing a novel VToonify framework. Specifically, VToonify
leverages the mid- and high-resolution layers of StyleGAN to render
high-quality artistic portraits based on the multi-scale content features
extracted by an encoder to better preserve the frame details. The resulting
fully convolutional architecture accepts non-aligned faces in videos of
variable size as input, contributing to complete face regions with natural
motions in the output. Our framework is compatible with existing StyleGAN-based
image toonification models to extend them to video toonification, and inherits
appealing features of these models for flexible style control on color and
intensity. This work presents two instantiations of VToonify built upon Toonify
and DualStyleGAN for collection-based and exemplar-based portrait video style
transfer, respectively. Extensive experimental results demonstrate the
effectiveness of our proposed VToonify framework over existing methods in
generating high-quality and temporally-coherent artistic portrait videos with
flexible style controls.</p>
  </details>
</details>
<details>
  <summary>3. <b>标题：UniColor: A Unified Framework for Multi-Modal Colorization with  Transformer</b></summary>
  <p><b>编号</b>：[3]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.11223</p>
  <p><b>作者</b>：Zhitong Huang,  Nanxuan Zhao,  Jing Liao</p>
  <p><b>备注</b>：Accepted by SIGGRAPH Asia 2022. Project page: this https URL</p>
  <p><b>关键词</b>：multiple modalities, UniColor to support, unconditional and conditional, unified framework UniColor, hint points</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose the first unified framework UniColor to support colorization in
multiple modalities, including both unconditional and conditional ones, such as
stroke, exemplar, text, and even a mix of them. Rather than learning a separate
model for each type of condition, we introduce a two-stage colorization
framework for incorporating various conditions into a single model. In the
first stage, multi-modal conditions are converted into a common representation
of hint points. Particularly, we propose a novel CLIP-based method to convert
the text to hint points. In the second stage, we propose a Transformer-based
network composed of Chroma-VQGAN and Hybrid-Transformer to generate diverse and
high-quality colorization results conditioned on hint points. Both qualitative
and quantitative comparisons demonstrate that our method outperforms
state-of-the-art methods in every control modality and further enables
multi-modal colorization that was not feasible before. Moreover, we design an
interactive interface showing the effectiveness of our unified framework in
practical usage, including automatic colorization, hybrid-control colorization,
local recolorization, and iterative color editing. Our code and models are
available at this https URL.</p>
  </details>
</details>
<details>
  <summary>4. <b>标题：Siamese Network-based Lightweight Framework for Tomato Leaf Disease  Recognition</b></summary>
  <p><b>编号</b>：[7]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.11214</p>
  <p><b>作者</b>：Selvarajah Thuseethan,  Palanisamy Vigneshwaran,  Joseph Charles,  Chathrie Wimalasooriya</p>
  <p><b>备注</b>：10 pages</p>
  <p><b>关键词</b>：avoid crop losses, applying control measures, tomato disease recognition, disease recognition, measures on time</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Automatic tomato disease recognition from leaf images is vital to avoid crop
losses by applying control measures on time. Even though recent deep
learning-based tomato disease recognition methods with classical training
procedures showed promising recognition results, they demand large labelled
data and involve expensive training. The traditional deep learning models
proposed for tomato disease recognition also consume high memory and storage
because of a high number of parameters. While lightweight networks overcome
some of these issues to a certain extent, they continue to show low performance
and struggle to handle imbalanced data. In this paper, a novel Siamese
network-based lightweight framework is proposed for automatic tomato leaf
disease recognition. This framework achieves the highest accuracy of 96.97% on
the tomato subset obtained from the PlantVillage dataset and 95.48% on the
Taiwan tomato leaf disease dataset. Experimental results further confirm that
the proposed framework is effective with imbalanced and small data. The
backbone deep network integrated with this framework is lightweight with
approximately 2.9629 million trainable parameters, which is way lower than
existing lightweight deep networks.</p>
  </details>
</details>
<details>
  <summary>5. <b>标题：Layer Freezing & Data Sieving: Missing Pieces of a Generic Framework for  Sparse Training</b></summary>
  <p><b>编号</b>：[11]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.11204</p>
  <p><b>作者</b>：Geng Yuan,  Yanyu Li,  Sheng Li,  Zhenglun Kong,  Sergey Tulyakov,  Xulong Tang,  Yanzhi Wang,  Jian Ren</p>
  <p><b>备注</b>：Published in 36th Conference on Neural Information Processing Systems (NeurIPS 2022)</p>
  <p><b>关键词</b>：efficient deep learning, training, sparse training, training costs, layer freezing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recently, sparse training has emerged as a promising paradigm for efficient
deep learning on edge devices. The current research mainly devotes efforts to
reducing training costs by further increasing model sparsity. However,
increasing sparsity is not always ideal since it will inevitably introduce
severe accuracy degradation at an extremely high sparsity level. This paper
intends to explore other possible directions to effectively and efficiently
reduce sparse training costs while preserving accuracy. To this end, we
investigate two techniques, namely, layer freezing and data sieving. First, the
layer freezing approach has shown its success in dense model training and
fine-tuning, yet it has never been adopted in the sparse training domain.
Nevertheless, the unique characteristics of sparse training may hinder the
incorporation of layer freezing techniques. Therefore, we analyze the
feasibility and potentiality of using the layer freezing technique in sparse
training and find it has the potential to save considerable training costs.
Second, we propose a data sieving method for dataset-efficient training, which
further reduces training costs by ensuring only a partial dataset is used
throughout the entire training process. We show that both techniques can be
well incorporated into the sparse training algorithm to form a generic
framework, which we dub SpFDE. Our extensive experiments demonstrate that SpFDE
can significantly reduce training costs while preserving accuracy from three
dimensions: weight sparsity, layer freezing, and dataset sieving.</p>
  </details>
</details>
<details>
  <summary>6. <b>标题：Attention is All They Need: Exploring the Media Archaeology of the  Computer Vision Research Paper</b></summary>
  <p><b>编号</b>：[13]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.11200</p>
  <p><b>作者</b>：Samuel Goree,  Gabriel Appleby,  David Crandall,  Norman Su</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：including computer vision, computer vision, success of deep, deep learning, learning has led</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The success of deep learning has led to the rapid transformation and growth
of many areas of computer science, including computer vision. In this work, we
examine the effects of this growth through the computer vision research paper
itself by analyzing the figures and tables in research papers from a media
archaeology perspective. We ground our investigation both through interviews
with veteran researchers spanning computer vision, graphics and visualization,
and computational analysis of a decade of vision conference papers. Our
analysis focuses on elements with roles in advertising, measuring and
disseminating an increasingly commodified "contribution." We argue that each of
these elements has shaped and been shaped by the climate of computer vision,
ultimately contributing to that commodification. Through this work, we seek to
motivate future discussion surrounding the design of the research paper and the
broader socio-technical publishing system.</p>
  </details>
</details>
<details>
  <summary>7. <b>标题：Learning Visual Explanations for DCNN-Based Image Classifiers Using an  Attention Mechanism</b></summary>
  <p><b>编号</b>：[18]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.11189</p>
  <p><b>作者</b>：Ioanna Gkartzonika,  Nikolaos Gkalelis,  Vasileios Mezaris</p>
  <p><b>备注</b>：Accepted for publication; to be included in Proc. ECCV Workshops 2022. The version posted here is the "submitted manuscript" version</p>
  <p><b>关键词</b>：convolutional neural network, deep convolutional neural, neural network, learning-based eXplainable, deep convolutional</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper two new learning-based eXplainable AI (XAI) methods for deep
convolutional neural network (DCNN) image classifiers, called L-CAM-Fm and
L-CAM-Img, are proposed. Both methods use an attention mechanism that is
inserted in the original (frozen) DCNN and is trained to derive class
activation maps (CAMs) from the last convolutional layer's feature maps. During
training, CAMs are applied to the feature maps (L-CAM-Fm) or the input image
(L-CAM-Img) forcing the attention mechanism to learn the image regions
explaining the DCNN's outcome. Experimental evaluation on ImageNet shows that
the proposed methods achieve competitive results while requiring a single
forward pass at the inference stage. Moreover, based on the derived
explanations a comprehensive qualitative analysis is performed providing
valuable insight for understanding the reasons behind classification errors,
including possible dataset biases affecting the trained classifier.</p>
  </details>
</details>
<details>
  <summary>8. <b>标题：Traffic Accident Risk Forecasting using Contextual Vision Transformers</b></summary>
  <p><b>编号</b>：[21]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.11180</p>
  <p><b>作者</b>：Khaled Saleh,  Artur Grigorev,  Adriana-Simona Mihaita</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：traffic accident risk, accident risk forecasting, intelligent transportation systems, transportation systems community, systems community due</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recently, the problem of traffic accident risk forecasting has been getting
the attention of the intelligent transportation systems community due to its
significant impact on traffic clearance. This problem is commonly tackled in
the literature by using data-driven approaches that model the spatial and
temporal incident impact, since they were shown to be crucial for the traffic
accident risk forecasting problem. To achieve this, most approaches build
different architectures to capture the spatio-temporal correlations features,
making them inefficient for large traffic accident datasets. Thus, in this
work, we are proposing a novel unified framework, namely a contextual vision
transformer, that can be trained in an end-to-end approach which can
effectively reason about the spatial and temporal aspects of the problem while
providing accurate traffic accident risk predictions. We evaluate and compare
the performance of our proposed methodology against baseline approaches from
the literature across two large-scale traffic accident datasets from two
different geographical locations. The results have shown a significant
improvement with roughly 2\% in RMSE score in comparison to previous
state-of-art works (SoTA) in the literature. Moreover, our proposed approach
has outperformed the SoTA technique over the two datasets while only requiring
23x fewer computational requirements.</p>
  </details>
</details>
<details>
  <summary>9. <b>标题：Poisson Flow Generative Models</b></summary>
  <p><b>编号</b>：[22]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.11178</p>
  <p><b>作者</b>：Yilun Xu,  Ziming Liu,  Max Tegmark,  Tommi Jaakkola</p>
  <p><b>备注</b>：Accepted by NeurIPS 2022</p>
  <p><b>关键词</b>：high-dimensional electric field, Poisson flow, Poisson equation, electric field, data distribution</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose a new "Poisson flow" generative model (PFGM) that maps a uniform
distribution on a high-dimensional hemisphere into any data distribution. We
interpret the data points as electrical charges on the $z=0$ hyperplane in a
space augmented with an additional dimension $z$, generating a high-dimensional
electric field (the gradient of the solution to Poisson equation). We prove
that if these charges flow upward along electric field lines, their initial
distribution in the $z=0$ plane transforms into a distribution on the
hemisphere of radius $r$ that becomes uniform in the $r \to\infty$ limit. To
learn the bijective transformation, we estimate the normalized field in the
augmented space. For sampling, we devise a backward ODE that is anchored by the
physically meaningful additional dimension: the samples hit the unaugmented
data manifold when the $z$ reaches zero. Experimentally, PFGM achieves current
state-of-the-art performance among the normalizing flow models on CIFAR-10,
with an Inception score of $9.68$ and a FID score of $2.48$. It also performs
on par with the state-of-the-art SDE approaches while offering $10\times $ to
$20 \times$ acceleration on image generation tasks. Additionally, PFGM appears
more tolerant of estimation errors on a weaker network architecture and robust
to the step size in the Euler method. The code is available at
this https URL .</p>
  </details>
</details>
<details>
  <summary>10. <b>标题：GET3D: A Generative Model of High Quality 3D Textured Shapes Learned  from Images</b></summary>
  <p><b>编号</b>：[25]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.11163</p>
  <p><b>作者</b>：Jun Gao,  Tianchang Shen,  Zian Wang,  Wenzheng Chen,  Kangxue Yin,  Daiqing Li,  Or Litany,  Zan Gojcic,  Sanja Fidler</p>
  <p><b>备注</b>：NeurIPS 2022, Project Page: this https URL</p>
  <p><b>关键词</b>：content creation tools, virtual worlds, content creation, industries are moving, creation tools</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As several industries are moving towards modeling massive 3D virtual worlds,
the need for content creation tools that can scale in terms of the quantity,
quality, and diversity of 3D content is becoming evident. In our work, we aim
to train performant 3D generative models that synthesize textured meshes which
can be directly consumed by 3D rendering engines, thus immediately usable in
downstream applications. Prior works on 3D generative modeling either lack
geometric details, are limited in the mesh topology they can produce, typically
do not support textures, or utilize neural renderers in the synthesis process,
which makes their use in common 3D software non-trivial. In this work, we
introduce GET3D, a Generative model that directly generates Explicit Textured
3D meshes with complex topology, rich geometric details, and high-fidelity
textures. We bridge recent success in the differentiable surface modeling,
differentiable rendering as well as 2D Generative Adversarial Networks to train
our model from 2D image collections. GET3D is able to generate high-quality 3D
textured meshes, ranging from cars, chairs, animals, motorbikes and human
characters to buildings, achieving significant improvements over previous
methods.</p>
  </details>
</details>
<details>
  <summary>11. <b>标题：Model-Assisted Labeling via Explainability for Visual Inspection of  Civil Infrastructures</b></summary>
  <p><b>编号</b>：[26]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.11159</p>
  <p><b>作者</b>：Klara Janouskova,  Mattia Rigotti,  Ioana Giurgiu,  Cristiano Malossi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：specialized expert annotators, time-consuming task, application domains, provided by specialized, expert annotators</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Labeling images for visual segmentation is a time-consuming task which can be
costly, particularly in application domains where labels have to be provided by
specialized expert annotators, such as civil engineering. In this paper, we
propose to use attribution methods to harness the valuable interactions between
expert annotators and the data to be annotated in the case of defect
segmentation for visual inspection of civil infrastructures. Concretely, a
classifier is trained to detect defects and coupled with an attribution-based
method and adversarial climbing to generate and refine segmentation masks
corresponding to the classification outputs. These are used within an assisted
labeling framework where the annotators can interact with them as proposal
segmentation masks by deciding to accept, reject or modify them, and
interactions are logged as weak labels to further refine the classifier.
Applied on a real-world dataset resulting from the automated visual inspection
of bridges, our proposed method is able to save more than 50\% of annotators'
time when compared to manual annotation of defects.</p>
  </details>
</details>
<details>
  <summary>12. <b>标题：PACT: Perception-Action Causal Transformer for Autoregressive Robotics  Pre-Training</b></summary>
  <p><b>编号</b>：[33]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.11133</p>
  <p><b>作者</b>：Rogerio Bonatti,  Sai Vemprala,  Shuang Ma,  Felipe Frujeri,  Shuhang Chen,  Ashish Kapoor</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：require significant human, significant human expertise, Robotics has long, modules and connections, traditional or learning-based</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Robotics has long been a field riddled with complex systems architectures
whose modules and connections, whether traditional or learning-based, require
significant human expertise and prior knowledge. Inspired by large pre-trained
language models, this work introduces a paradigm for pre-training a general
purpose representation that can serve as a starting point for multiple tasks on
a given robot. We present the Perception-Action Causal Transformer (PACT), a
generative transformer-based architecture that aims to build representations
directly from robot data in a self-supervised fashion. Through autoregressive
prediction of states and actions over time, our model implicitly encodes
dynamics and behaviors for a particular robot. Our experimental evaluation
focuses on the domain of mobile agents, where we show that this robot-specific
representation can function as a single starting point to achieve distinct
tasks such as safe navigation, localization and mapping. We evaluate two form
factors: a wheeled robot that uses a LiDAR sensor as perception input (MuSHR),
and a simulated agent that uses first-person RGB images (Habitat). We show that
finetuning small task-specific networks on top of the larger pretrained model
results in significantly better performance compared to training a single model
from scratch for all tasks simultaneously, and comparable performance to
training a separate large model for each task independently. By sharing a
common good-quality representation across tasks we can lower overall model
capacity and speed up the real-time deployment of such systems.</p>
  </details>
</details>
<details>
  <summary>13. <b>标题：Uncertainty-aware Perception Models for Off-road Autonomous Unmanned  Ground Vehicles</b></summary>
  <p><b>编号</b>：[38]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.11115</p>
  <p><b>作者</b>：Zhaoyuan Yang,  Yewteck Tan,  Shiraj Sen,  Johan Reimann,  John Karigiannis,  Mohammed Yousefhussien,  Nurali Virani</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：unmanned ground vehicles, deliver crucial supplies, autonomous unmanned ground, Off-road autonomous unmanned, ground vehicles</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Off-road autonomous unmanned ground vehicles (UGVs) are being developed for
military and commercial use to deliver crucial supplies in remote locations,
help with mapping and surveillance, and to assist war-fighters in contested
environments. Due to complexity of the off-road environments and variability in
terrain, lighting conditions, diurnal and seasonal changes, the models used to
perceive the environment must handle a lot of input variability. Current
datasets used to train perception models for off-road autonomous navigation
lack of diversity in seasons, locations, semantic classes, as well as time of
day. We test the hypothesis that model trained on a single dataset may not
generalize to other off-road navigation datasets and new locations due to the
input distribution drift. Additionally, we investigate how to combine multiple
datasets to train a semantic segmentation-based environment perception model
and we show that training the model to capture uncertainty could improve the
model performance by a significant margin. We extend the Masksembles approach
for uncertainty quantification to the semantic segmentation task and compare it
with Monte Carlo Dropout and standard baselines. Finally, we test the approach
against data collected from a UGV platform in a new testing environment. We
show that the developed perception model with uncertainty quantification can be
feasibly deployed on an UGV to support online perception and navigation tasks.</p>
  </details>
</details>
<details>
  <summary>14. <b>标题：Deep Learning on Home Drone: Searching for the Optimal Architecture</b></summary>
  <p><b>编号</b>：[59]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.11064</p>
  <p><b>作者</b>：Alaa Maalouf,  Yotam Gurfinkel,  Barak Diker,  Oren Gal,  Daniela Rus,  Dan Feldman</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：DJI Tello toy-drone, runs real-time semantic, real-time semantic segmentation, commercial DJI Tello, semantic segmentation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We suggest the first system that runs real-time semantic segmentation via
deep learning on a weak micro-computer such as the Raspberry Pi Zero v2 (whose
price was \$15) attached to a toy-drone. In particular, since the Raspberry Pi
weighs less than $16$ grams, and its size is half of a credit card, we could
easily attach it to the common commercial DJI Tello toy-drone (<\$100, 41 98 <90 grams, $\times$ 92.5 mm). the result is an autonomous drone (no laptop nor human in loop) that can detect and classify objects real-time from a video stream of on-board monocular rgb camera gps or lidar sensors). companion videos demonstrate how this tello scans lab for people (e.g. use firefighters security forces) empty parking slot outside lab. existing deep learning solutions are either much too slow computation on such iot devices, provide results impractical quality. our main challenge was to design system takes best all worlds among numerous combinations networks, platforms frameworks, compression techniques, ratios. end, we efficient searching algorithm aims find optimal combination which tradeoff between network running time its accuracy performance.< p>
  </\$100,></p></details>
</details>
<details>
  <summary>15. <b>标题：MIDMs: Matching Interleaved Diffusion Models for Exemplar-based Image  Translation</b></summary>
  <p><b>编号</b>：[63]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.11047</p>
  <p><b>作者</b>：Junyoung Seo,  Gyuseong Lee,  Seokju Cho,  Jiyoung Lee,  Seungryong Kim</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：called matching interleaved, interleaved diffusion models, matching interleaved diffusion, exemplar-based image translation, diffusion models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present a novel method for exemplar-based image translation, called
matching interleaved diffusion models (MIDMs). Most existing methods for this
task were formulated as GAN-based matching-then-generation framework. However,
in this framework, matching errors induced by the difficulty of semantic
matching across cross-domain, e.g., sketch and photo, can be easily propagated
to the generation step, which in turn leads to degenerated results. Motivated
by the recent success of diffusion models overcoming the shortcomings of GANs,
we incorporate the diffusion models to overcome these limitations.
Specifically, we formulate a diffusion-based matching-and-generation framework
that interleaves cross-domain matching and diffusion steps in the latent space
by iteratively feeding the intermediate warp into the noising process and
denoising it to generate a translated image. In addition, to improve the
reliability of the diffusion process, we design a confidence-aware process
using cycle-consistency to consider only confident regions during translation.
Experimental results show that our MIDMs generate more plausible images than
state-of-the-art methods.</p>
  </details>
</details>
<details>
  <summary>16. <b>标题：Google Coral-based edge computing person reidentification using human  parsing combined with analytical method</b></summary>
  <p><b>编号</b>：[72]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.11024</p>
  <p><b>作者</b>：Nikita Gabdullin,  Anton Raskovalov</p>
  <p><b>备注</b>：11 pages, 3 figures, 3 tables</p>
  <p><b>关键词</b>：computer vision due, significant application areas, edge computing, edge computing re-ID, Person reidentification</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Person reidentification (re-ID) is becoming one of the most significant
application areas of computer vision due to its importance for science and
social security. Due to enormous size and scale of camera systems it is
beneficial to develop edge computing re-ID applications where at least part of
the analysis could be performed by the cameras. However, conventional re-ID
relies heavily on deep learning (DL) computationally demanding models which are
not readily applicable for edge computing. In this paper we adapt a recently
proposed re-ID method that combines DL human parsing with analytical feature
extraction and ranking schemes to be more suitable for edge computing re-ID.
First, we compare parsers that use ResNet101, ResNet18, MobileNetV2, and OSNet
backbones and show that parsing can be performed using compact backbones with
sufficient accuracy. Second, we transfer parsers to tensor processing unit
(TPU) of Google Coral Dev Board and show that it can act as a portable edge
computing re-ID station. We also implement the analytical part of re-ID method
on Coral CPU to ensure that it can perform a complete re-ID cycle. For
quantitative analysis we compare inference speed, parsing masks, and re-ID
accuracy on GPU and Coral TPU depending on parser backbone. We also discuss
possible application scenarios of edge computing in re-ID taking into account
known limitations mainly related to memory and storage space of portable
devices.</p>
  </details>
</details>
<details>
  <summary>17. <b>标题：Privacy Attacks Against Biometric Models with Fewer Samples:  Incorporating the Output of Multiple Models</b></summary>
  <p><b>编号</b>：[74]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.11020</p>
  <p><b>作者</b>：Sohaib Ahmad,  Benjamin Fuller,  Kaleel Mahmood</p>
  <p><b>备注</b>：This is a major revision of a paper titled "Inverting Biometric Models with Fewer Samples: Incorporating the Output of Multiple Models" by the same authors that appears at IJCB 2022</p>
  <p><b>关键词</b>：machine learning model, model inversion attacks, model inversion, approximate the inverse, target machine learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Authentication systems are vulnerable to model inversion attacks where an
adversary is able to approximate the inverse of a target machine learning
model. Biometric models are a prime candidate for this type of attack. This is
because inverting a biometric model allows the attacker to produce a realistic
biometric input to spoof biometric authentication systems.
One of the main constraints in conducting a successful model inversion attack
is the amount of training data required. In this work, we focus on iris and
facial biometric systems and propose a new technique that drastically reduces
the amount of training data necessary. By leveraging the output of multiple
models, we are able to conduct model inversion attacks with 1/10th the training
set size of Ahmad and Fuller (IJCB 2020) for iris data and 1/1000th the
training set size of Mai et al. (Pattern Analysis and Machine Intelligence
2019) for facial data. We denote our new attack technique as structured random
with alignment loss. Our attacks are black-box, requiring no knowledge of the
weights of the target neural network, only the dimension, and values of the
output vector.
To show the versatility of the alignment loss, we apply our attack framework
to the task of membership inference (Shokri et al., IEEE S&P 2017) on biometric
data. For the iris, membership inference attack against classification networks
improves from 52% to 62% accuracy.</p>
  </details>
</details>
<details>
  <summary>18. <b>标题：Challenges in Visual Anomaly Detection for Mobile Robots</b></summary>
  <p><b>编号</b>：[81]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10995</p>
  <p><b>作者</b>：Dario Mantegazza,  Alessandro Giusti,  Luca M. Gambardella,  Andrea Rizzoli,  Jérôme Guzzi</p>
  <p><b>备注</b>：Workshop paper presented at the ICRA 2022 Workshop on Safe and Reliable Robot Autonomy under Uncertainty this https URL</p>
  <p><b>关键词</b>：autonomous mobile robots, mobile robots based, based on vision, autonomous mobile, mobile robots</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We consider the task of detecting anomalies for autonomous mobile robots
based on vision. We categorize relevant types of visual anomalies and discuss
how they can be detected by unsupervised deep learning methods. We propose a
novel dataset built specifically for this task, on which we test a
state-of-the-art approach; we finally discuss deployment in a real scenario.</p>
  </details>
</details>
<details>
  <summary>19. <b>标题：Learning to Simulate Realistic LiDARs</b></summary>
  <p><b>编号</b>：[82]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10986</p>
  <p><b>作者</b>：Benoit Guillard,  Sai Vemprala,  Jayesh K. Gupta,  Ondrej Miksik,  Vibhav Vineet,  Pascal Fua,  Ashish Kapoor</p>
  <p><b>备注</b>：IROS2022 paper</p>
  <p><b>关键词</b>：involving carefully handcrafted, handcrafted sensor design, carefully handcrafted sensor, autonomous systems, physics modeling</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Simulating realistic sensors is a challenging part in data generation for
autonomous systems, often involving carefully handcrafted sensor design, scene
properties, and physics modeling. To alleviate this, we introduce a pipeline
for data-driven simulation of a realistic LiDAR sensor. We propose a model that
learns a mapping between RGB images and corresponding LiDAR features such as
raydrop or per-point intensities directly from real datasets. We show that our
model can learn to encode realistic effects such as dropped points on
transparent surfaces or high intensity returns on reflective materials. When
applied to naively raycasted point clouds provided by off-the-shelf simulator
software, our model enhances the data by predicting intensities and removing
points based on the scene's appearance to match a real LiDAR sensor. We use our
technique to learn models of two distinct LiDAR sensors and use them to improve
simulated LiDAR data accordingly. Through a sample task of vehicle
segmentation, we show that enhancing simulated point clouds with our technique
improves downstream task performance.</p>
  </details>
</details>
<details>
  <summary>20. <b>标题：Implementing and Experimenting with Diffusion Models for Text-to-Image  Generation</b></summary>
  <p><b>编号</b>：[95]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10948</p>
  <p><b>作者</b>：Robin Zbinden</p>
  <p><b>备注</b>：Master's Thesis</p>
  <p><b>关键词</b>：general public attention, models, Taking advantage, deep learning, public attention</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Taking advantage of the many recent advances in deep learning, text-to-image
generative models currently have the merit of attracting the general public
attention. Two of these models, DALL-E 2 and Imagen, have demonstrated that
highly photorealistic images could be generated from a simple textual
description of an image. Based on a novel approach for image generation called
diffusion models, text-to-image models enable the production of many different
types of high resolution images, where human imagination is the only limit.
However, these models require exceptionally large amounts of computational
resources to train, as well as handling huge datasets collected from the
internet. In addition, neither the codebase nor the models have been released.
It consequently prevents the AI community from experimenting with these
cutting-edge models, making the reproduction of their results complicated, if
not impossible.
In this thesis, we aim to contribute by firstly reviewing the different
approaches and techniques used by these models, and then by proposing our own
implementation of a text-to-image model. Highly based on DALL-E 2, we introduce
several slight modifications to tackle the high computational cost induced. We
thus have the opportunity to experiment in order to understand what these
models are capable of, especially in a low resource regime. In particular, we
provide additional and analyses deeper than the ones performed by the authors
of DALL-E 2, including ablation studies.
Besides, diffusion models use so-called guidance methods to help the
generating process. We introduce a new guidance method which can be used in
conjunction with other guidance methods to improve image quality. Finally, the
images generated by our model are of reasonably good quality, without having to
sustain the significant training costs of state-of-the-art text-to-image
models.</p>
  </details>
</details>
<details>
  <summary>21. <b>标题：Learning Invariant Representations for Equivariant Neural Networks Using  Orthogonal Moments</b></summary>
  <p><b>编号</b>：[97]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10944</p>
  <p><b>作者</b>：Jaspreet Singh,  Chandan Singh</p>
  <p><b>备注</b>：International Joint Conference on Neural Networks (IJCNN), 2022</p>
  <p><b>关键词</b>：standard convolutional neural, standard convolutional, convolutional neural networks, convolutional layers, layers</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The convolutional layers of standard convolutional neural networks (CNNs) are
equivariant to translation. However, the convolution and fully-connected layers
are not equivariant or invariant to other affine geometric transformations.
Recently, a new class of CNNs is proposed in which the conventional layers of
CNNs are replaced with equivariant convolution, pooling, and
batch-normalization layers. The final classification layer in equivariant
neural networks is invariant to different affine geometric transformations such
as rotation, reflection and translation, and the scalar value is obtained by
either eliminating the spatial dimensions of filter responses using convolution
and down-sampling throughout the network or average is taken over the filter
responses. In this work, we propose to integrate the orthogonal moments which
gives the high-order statistics of the function as an effective means for
encoding global invariance with respect to rotation, reflection and translation
in fully-connected layers. As a result, the intermediate layers of the network
become equivariant while the classification layer becomes invariant. The most
widely used Zernike, pseudo-Zernike and orthogonal Fourier-Mellin moments are
considered for this purpose. The effectiveness of the proposed work is
evaluated by integrating the invariant transition and fully-connected layer in
the architecture of group-equivariant CNNs (G-CNNs) on rotated MNIST and
CIFAR10 datasets.</p>
  </details>
</details>
<details>
  <summary>22. <b>标题：MGTR: End-to-End Mutual Gaze Detection with Transformer</b></summary>
  <p><b>编号</b>：[103]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10930</p>
  <p><b>作者</b>：Hang Guo,  Zhengxi Hu,  Jingtai Liu</p>
  <p><b>备注</b>：16 pages</p>
  <p><b>关键词</b>：mutual gaze, mutual gaze detection, detecting mutual gaze, gaze, gaze detection</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>People's looking at each other or mutual gaze is ubiquitous in our daily
interactions, and detecting mutual gaze is of great significance for
understanding human social scenes. Current mutual gaze detection methods focus
on two-stage methods, whose inference speed is limited by the two-stage
pipeline and the performance in the second stage is affected by the first one.
In this paper, we propose a novel one-stage mutual gaze detection framework
called Mutual Gaze TRansformer or MGTR to perform mutual gaze detection in an
end-to-end manner. By designing mutual gaze instance triples, MGTR can detect
each human head bounding box and simultaneously infer mutual gaze relationship
based on global image information, which streamlines the whole process with
simplicity. Experimental results on two mutual gaze datasets show that our
method is able to accelerate mutual gaze detection process without losing
performance. Ablation study shows that different components of MGTR can capture
different levels of semantic information in images. Code is available at
this https URL</p>
  </details>
</details>
<details>
  <summary>23. <b>标题：CONE: An Efficient COarse-to-fiNE Alignment Framework for Long Video  Temporal Grounding</b></summary>
  <p><b>编号</b>：[108]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10918</p>
  <p><b>作者</b>：Zhijian Hou,  Wanjun Zhong,  Lei Ji,  Difei Gao,  Kun Yan,  Wing-Kwong Chan,  Chong-Wah Ngo,  Zheng Shou,  Nan Duan</p>
  <p><b>备注</b>：Preprint. 9 pages, 5 figures, 3 tables</p>
  <p><b>关键词</b>：localize temporal moments, temporal grounding, Video temporal grounding, targets to localize, natural language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Video temporal grounding (VTG) targets to localize temporal moments in an
untrimmed video according to a natural language (NL) description. Since
real-world applications provide a never-ending video stream, it raises demands
for temporal grounding for long-form videos, which leads to two major
challenges: (1) the long video length makes it difficult to process the entire
video without decreasing sample rate and leads to high computational burden;
(2) the accurate multi-modal alignment is more challenging as the number of
moment candidates increases. To address these challenges, we propose CONE, an
efficient window-centric COarse-to-fiNE alignment framework, which flexibly
handles long-form video inputs with higher inference speed, and enhances the
temporal grounding via our novel coarse-to-fine multi-modal alignment
framework. Specifically, we dynamically slice the long video into candidate
windows via a sliding window approach. Centering at windows, CONE (1) learns
the inter-window (coarse-grained) semantic variance through contrastive
learning and speeds up inference by pre-filtering the candidate windows
relevant to the NL query, and (2) conducts intra-window (fine-grained)
candidate moments ranking utilizing the powerful multi-modal alignment ability
of a contrastive vision-text pre-trained model. Extensive experiments on two
large-scale VTG benchmarks for long videos consistently show a substantial
performance gain (from 3.13% to 6.87% on MAD and from 10.46% to 13.46% on
Ego4d-NLQ) and CONE achieves the SOTA results on both datasets. Analysis
reveals the effectiveness of components and higher efficiency in long video
grounding as our system improves the inference speed by 2x on Ego4d-NLQ and 15x
on MAD while keeping the SOTA performance of CONE.</p>
  </details>
</details>
<details>
  <summary>24. <b>标题：DRKF: Distilled Rotated Kernel Fusion for Efficiently Boosting Rotation  Invariance in Image Matching</b></summary>
  <p><b>编号</b>：[114]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10907</p>
  <p><b>作者</b>：Chao Li,  Jiancheng Cai,  Ranran Huang,  Xinmin Liu</p>
  <p><b>备注</b>：7 pages, 5 figures</p>
  <p><b>关键词</b>：existing learning-based image, learning-based image matching, image matching pipelines, repeated textures, existing learning-based</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Most existing learning-based image matching pipelines are designed for better
feature detectors and descriptors which are robust to repeated textures,
viewpoint changes, etc., while little attention has been paid to rotation
invariance. As a consequence, these approaches usually demonstrate inferior
performance compared to the handcrafted algorithms in circumstances where a
significant level of rotation exists in data, due to the lack of keypoint
orientation prediction. To address the issue efficiently, an approach based on
knowledge distillation is proposed for improving rotation robustness without
extra computational costs. Specifically, based on the base model, we propose
Multi-Oriented Feature Aggregation (MOFA), which is subsequently adopted as the
teacher in the distillation pipeline. Moreover, Rotated Kernel Fusion (RKF) is
applied to each convolution kernel of the student model to facilitate learning
rotation-invariant features. Eventually, experiments show that our proposals
can generalize successfully under various rotations without additional costs in
the inference stage.</p>
  </details>
</details>
<details>
  <summary>25. <b>标题：AcroFOD: An Adaptive Method for Cross-domain Few-shot Object Detection</b></summary>
  <p><b>编号</b>：[115]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10904</p>
  <p><b>作者</b>：Yipeng Gao,  Lingxiao Yang,  Yunmu Huang,  Song Xie,  Shiyong Li,  Wei-shi Zheng</p>
  <p><b>备注</b>：Accepted in ECCV 2022</p>
  <p><b>关键词</b>：cross-domain few-shot object, few-shot object detection, object detection aims, adapt object detectors, few-shot object</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Under the domain shift, cross-domain few-shot object detection aims to adapt
object detectors in the target domain with a few annotated target data. There
exists two significant challenges: (1) Highly insufficient target domain data;
(2) Potential over-adaptation and misleading caused by inappropriately
amplified target samples without any restriction. To address these challenges,
we propose an adaptive method consisting of two parts. First, we propose an
adaptive optimization strategy to select augmented data similar to target
samples rather than blindly increasing the amount. Specifically, we filter the
augmented candidates which significantly deviate from the target feature
distribution in the very beginning. Second, to further relieve the data
limitation, we propose the multi-level domain-aware data augmentation to
increase the diversity and rationality of augmented data, which exploits the
cross-image foreground-background mixture. Experiments show that the proposed
method achieves state-of-the-art performance on multiple benchmarks.</p>
  </details>
</details>
<details>
  <summary>26. <b>标题：Efficient CNN with uncorrelated Bag of Features pooling</b></summary>
  <p><b>编号</b>：[132]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10865</p>
  <p><b>作者</b>：Firas Laakom,  Jenni Raitoharju,  Alexandros Iosifidis,  Moncef Gabbouj</p>
  <p><b>备注</b>：6 pages, 2 Figures</p>
  <p><b>关键词</b>：low computational power, computational power devices, typically computationally expensive, computationally expensive, low computational</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Despite the superior performance of CNN, deploying them on low computational
power devices is still limited as they are typically computationally expensive.
One key cause of the high complexity is the connection between the convolution
layers and the fully connected layers, which typically requires a high number
of parameters. To alleviate this issue, Bag of Features (BoF) pooling has been
recently proposed. BoF learns a dictionary, that is used to compile a histogram
representation of the input. In this paper, we propose an approach that builds
on top of BoF pooling to boost its efficiency by ensuring that the items of the
learned dictionary are non-redundant. We propose an additional loss term, based
on the pair-wise correlation of the items of the dictionary, which complements
the standard loss to explicitly regularize the model to learn a more diverse
and rich dictionary. The proposed strategy yields an efficient variant of BoF
and further boosts its performance, without any additional parameters.</p>
  </details>
</details>
<details>
  <summary>27. <b>标题：DIG: Draping Implicit Garment over the Human Body</b></summary>
  <p><b>编号</b>：[138]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10845</p>
  <p><b>作者</b>：Ren Li,  Benoît Guillard,  Edoardo Remelli,  Pascal Fua</p>
  <p><b>备注</b>：16 pages, 9 figures, 5 tables, ACCV 2022</p>
  <p><b>关键词</b>：posed human bodies, Existing data-driven methods, Existing data-driven, human bodies, posed human</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Existing data-driven methods for draping garments over posed human bodies,
despite being effective, cannot handle garments of arbitrary topology and are
typically not end-to-end differentiable. To address these limitations, we
propose an end-to-end differentiable pipeline that represents garments using
implicit surfaces and learns a skinning field conditioned on shape and pose
parameters of an articulated body model. To limit body-garment
interpenetrations and artifacts, we propose an interpretation-aware
pre-processing strategy of training data and a novel training loss that
penalizes self-intersections while draping garments. We demonstrate that our
method yields more accurate results for garment reconstruction and deformation
with respect to state-of-the-art methods. Furthermore, we show that our method,
thanks to its end-to-end differentiability, allows to recover body and garments
parameters jointly from image observations, something that previous work could
not do.</p>
  </details>
</details>
<details>
  <summary>28. <b>标题：Identity-Aware Hand Mesh Estimation and Personalization from RGB Images</b></summary>
  <p><b>编号</b>：[140]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10840</p>
  <p><b>作者</b>：Deying Kong,  Linguang Zhang,  Liangjian Chen,  Haoyu Ma,  Xiangyi Yan,  Shanlin Sun,  Xingwei Liu,  Kun Han,  Xiaohui Xie</p>
  <p><b>备注</b>：ECCV 2022. Github this https URL</p>
  <p><b>关键词</b>：attracted increasing amount, enormous potential applications, monocular RGB images, meshes from monocular, attracted increasing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Reconstructing 3D hand meshes from monocular RGB images has attracted
increasing amount of attention due to its enormous potential applications in
the field of AR/VR. Most state-of-the-art methods attempt to tackle this task
in an anonymous manner. Specifically, the identity of the subject is ignored
even though it is practically available in real applications where the user is
unchanged in a continuous recording session. In this paper, we propose an
identity-aware hand mesh estimation model, which can incorporate the identity
information represented by the intrinsic shape parameters of the subject. We
demonstrate the importance of the identity information by comparing the
proposed identity-aware model to a baseline which treats subject anonymously.
Furthermore, to handle the use case where the test subject is unseen, we
propose a novel personalization pipeline to calibrate the intrinsic shape
parameters using only a few unlabeled RGB images of the subject. Experiments on
two large scale public datasets validate the state-of-the-art performance of
our proposed method.</p>
  </details>
</details>
<details>
  <summary>29. <b>标题：Detecting Rotated Objects as Gaussian Distributions and Its 3-D  Generalization</b></summary>
  <p><b>编号</b>：[141]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10839</p>
  <p><b>作者</b>：Xue Yang,  Gefan Zhang,  Xiaojiang Yang,  Yue Zhou,  Wentao Wang,  Jin Tang,  Tao He,  Junchi Yan</p>
  <p><b>备注</b>：19 pages, 11 figures, 16 tables, accepted by TPAMI 2022. Journal extension for GWD (ICML'21) and KLD (NeurIPS'21). arXiv admin note: text overlap with arXiv:2101.11952</p>
  <p><b>关键词</b>：parameterized bounding box, additional rotation angle, bounding box, rotation angle parameter, parameterized bounding</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Existing detection methods commonly use a parameterized bounding box (BBox)
to model and detect (horizontal) objects and an additional rotation angle
parameter is used for rotated objects. We argue that such a mechanism has
fundamental limitations in building an effective regression loss for rotation
detection, especially for high-precision detection with high IoU (e.g. 0.75).
Instead, we propose to model the rotated objects as Gaussian distributions. A
direct advantage is that our new regression loss regarding the distance between
two Gaussians e.g. Kullback-Leibler Divergence (KLD), can well align the actual
detection performance metric, which is not well addressed in existing methods.
Moreover, the two bottlenecks i.e. boundary discontinuity and square-like
problem also disappear. We also propose an efficient Gaussian metric-based
label assignment strategy to further boost the performance. Interestingly, by
analyzing the BBox parameters' gradients under our Gaussian-based KLD loss, we
show that these parameters are dynamically updated with interpretable physical
meaning, which help explain the effectiveness of our approach, especially for
high-precision detection. We extend our approach from 2-D to 3-D with a
tailored algorithm design to handle the heading estimation, and experimental
results on twelve public datasets (2-D/3-D, aerial/text/face images) with
various base detectors show its superiority.</p>
  </details>
</details>
<details>
  <summary>30. <b>标题：High-order Multi-view Clustering for Generic Data</b></summary>
  <p><b>编号</b>：[142]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10838</p>
  <p><b>作者</b>：Erlin Pan,  Zhao Kang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Graph-based multi-view clustering, graph, Graph-based multi-view, data, multi-view clustering</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Graph-based multi-view clustering has achieved better performance than most
non-graph approaches. However, in many real-world scenarios, the graph
structure of data is not given or the quality of initial graph is poor.
Additionally, existing methods largely neglect the high-order neighborhood
information that characterizes complex intrinsic interactions. To tackle these
problems, we introduce an approach called high-order multi-view clustering
(HMvC) to explore the topology structure information of generic data. Firstly,
graph filtering is applied to encode structure information, which unifies the
processing of attributed graph data and non-graph data in a single framework.
Secondly, up to infinity-order intrinsic relationships are exploited to enrich
the learned graph. Thirdly, to explore the consistent and complementary
information of various views, an adaptive graph fusion mechanism is proposed to
achieve a consensus graph. Comprehensive experimental results on both non-graph
and attributed graph data show the superior performance of our method with
respect to various state-of-the-art techniques, including some deep learning
methods.</p>
  </details>
</details>
<details>
  <summary>31. <b>标题：A Spatial-channel-temporal-fused Attention for Spiking Neural Networks</b></summary>
  <p><b>编号</b>：[143]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10837</p>
  <p><b>作者</b>：Wuque Cai,  Hongze Sun,  Rui Liu,  Yan Cui,  Jun Wang,  Yang Xia,  Dezhong Yao,  Daqing Guo</p>
  <p><b>备注</b>：12 pages, 8 figures, 5 tabes; This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible</p>
  <p><b>关键词</b>：Spiking neural networks, exhibit substantial capabilities, spatiotemporal information processing, mimic brain computational, brain computational strategies</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Spiking neural networks (SNNs) mimic brain computational strategies, and
exhibit substantial capabilities in spatiotemporal information processing. As
an essential factor for human perception, visual attention refers to the
dynamic selection process of salient regions in biological vision systems.
Although mechanisms of visual attention have achieved great success in computer
vision, they are rarely introduced into SNNs. Inspired by experimental
observations on predictive attentional remapping, we here propose a new
spatial-channel-temporal-fused attention (SCTFA) module that can guide SNNs to
efficiently capture underlying target regions by utilizing historically
accumulated spatial-channel information. Through a systematic evaluation on
three event stream datasets (DVS Gesture, SL-Animals-DVS and MNIST-DVS), we
demonstrate that the SNN with the SCTFA module (SCTFA-SNN) not only
significantly outperforms the baseline SNN (BL-SNN) and other two SNN models
with degenerated attention modules, but also achieves competitive accuracy with
existing state-of-the-art methods. Additionally, our detailed analysis shows
that the proposed SCTFA-SNN model has strong robustness to noise and
outstanding stability to incomplete data, while maintaining acceptable
complexity and efficiency. Overall, these findings indicate that appropriately
incorporating cognitive mechanisms of the brain may provide a promising
approach to elevate the capability of SNNs.</p>
  </details>
</details>
<details>
  <summary>32. <b>标题：Physical Interaction: Reconstructing Hand-object Interactions with  Physics</b></summary>
  <p><b>编号</b>：[144]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10833</p>
  <p><b>作者</b>：Haoyu Hu,  Xinyu Yi,  Hao Zhang,  Jun-Hai Yong,  Feng Xu</p>
  <p><b>备注</b>：SIGGRAPH Asia 2022 Conference Track</p>
  <p><b>关键词</b>：severe observation missing, observation missing caused, Single view-based reconstruction, caused by occlusions, challenging due</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Single view-based reconstruction of hand-object interaction is challenging
due to the severe observation missing caused by occlusions. This paper proposes
a physics-based method to better solve the ambiguities in the reconstruction.
It first proposes a force-based dynamic model of the in-hand object, which not
only recovers the unobserved contacts but also solves for plausible contact
forces. Next, a confidence-based slide prevention scheme is proposed, which
combines both the kinematic confidences and the contact forces to jointly model
static and sliding contact motion. Qualitative and quantitative experiments
show that the proposed technique reconstructs both physically plausible and
more accurate hand-object interaction and estimates plausible contact forces in
real-time with a single RGBD sensor.</p>
  </details>
</details>
<details>
  <summary>33. <b>标题：Color Recommendation for Vector Graphic Documents based on Multi-Palette  Representation</b></summary>
  <p><b>编号</b>：[147]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10820</p>
  <p><b>作者</b>：Qianru Qiu,  Xueting Wang,  Mayu Otani,  Yuki Iwazaki</p>
  <p><b>备注</b>：Accepted to WACV 2023</p>
  <p><b>关键词</b>：multiple visual elements, present multiple visual, documents present multiple, graphic documents present, Vector graphic documents</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Vector graphic documents present multiple visual elements, such as images,
shapes, and texts. Choosing appropriate colors for multiple visual elements is
a difficult but crucial task for both amateurs and professional designers.
Instead of creating a single color palette for all elements, we extract
multiple color palettes from each visual element in a graphic document, and
then combine them into a color sequence. We propose a masked color model for
color sequence completion and recommend the specified colors based on color
context in multi-palette with high probability. We train the model and build a
color recommendation system on a large-scale dataset of vector graphic
documents. The proposed color recommendation method outperformed other
state-of-the-art methods by both quantitative and qualitative evaluations on
color prediction and our color recommendation system received positive feedback
from professional designers in an interview study.</p>
  </details>
</details>
<details>
  <summary>34. <b>标题：IntereStyle: Encoding an Interest Region for Robust StyleGAN Inversion</b></summary>
  <p><b>编号</b>：[151]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10811</p>
  <p><b>作者</b>：Seungjun Moon,  GyeongMoon Park</p>
  <p><b>备注</b>：ECCV2022</p>
  <p><b>关键词</b>：Generative Adversarial Networks, Adversarial Networks, Generative Adversarial, uninterest region, interest region</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recently, manipulation of real-world images has been highly elaborated along
with the development of Generative Adversarial Networks (GANs) and
corresponding encoders, which embed real-world images into the latent space.
However, designing encoders of GAN still remains a challenging task due to the
trade-off between distortion and perception. In this paper, we point out that
the existing encoders try to lower the distortion not only on the interest
region, e.g., human facial region but also on the uninterest region, e.g.,
background patterns and obstacles. However, most uninterest regions in
real-world images are located at out-of-distribution (OOD), which are
infeasible to be ideally reconstructed by generative models. Moreover, we
empirically find that the uninterest region overlapped with the interest region
can mangle the original feature of the interest region, e.g., a microphone
overlapped with a facial region is inverted into the white beard. As a result,
lowering the distortion of the whole image while maintaining the perceptual
quality is very challenging. To overcome this trade-off, we propose a simple
yet effective encoder training scheme, coined IntereStyle, which facilitates
encoding by focusing on the interest region. IntereStyle steers the encoder to
disentangle the encodings of the interest and uninterest regions. To this end,
we filter the information of the uninterest region iteratively to regulate the
negative impact of the uninterest region. We demonstrate that IntereStyle
achieves both lower distortion and higher perceptual quality compared to the
existing state-of-the-art encoders. Especially, our model robustly conserves
features of the original images, which shows the robust image editing and style
mixing results. We will release our code with the pre-trained model after the
review.</p>
  </details>
</details>
<details>
  <summary>35. <b>标题：Deep Lake: a Lakehouse for Deep Learning</b></summary>
  <p><b>编号</b>：[166]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10785</p>
  <p><b>作者</b>：Sasun Hambardzumyan,  Abhinav Tuli,  Levon Ghukasyan,  Fariz Rahman,  Hrant Topchyan,  David Isayan,  Mikayel Harutyunyan,  Tatevik Hakobyan,  Ivo Stranic,  Davit Buniatyan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：running SQL queries, enabling time travel, running SQL, SQL queries, lakes provide critical</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Traditional data lakes provide critical data infrastructure for analytical
workloads by enabling time travel, running SQL queries, ingesting data with
ACID transactions, and visualizing petabyte-scale datasets on cloud storage.
They allow organizations to break down data silos, unlock data-driven
decision-making, improve operational efficiency, and reduce costs. However, as
deep learning takes over common analytical workflows, traditional data lakes
become less useful for applications such as natural language processing (NLP),
audio processing, computer vision, and applications involving non-tabular
datasets. This paper presents Deep Lake, an open-source lakehouse for deep
learning applications developed at Activeloop. Deep Lake maintains the benefits
of a vanilla data lake with one key difference: it stores complex data, such as
images, videos, annotations, as well as tabular data, in the form of tensors
and rapidly streams the data over the network to (a) Tensor Query Language, (b)
in-browser visualization engine, or (c) deep learning frameworks without
sacrificing GPU utilization. Datasets stored in Deep Lake can be accessed from
PyTorch, TensorFlow, JAX, and integrate with numerous MLOps tools.</p>
  </details>
</details>
<details>
  <summary>36. <b>标题：Multi-level Adversarial Spatio-temporal Learning for Footstep Pressure  based FoG Detection</b></summary>
  <p><b>编号</b>：[170]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10770</p>
  <p><b>作者</b>：Kun Hu,  Shaohui Mei,  Wei Wang,  Kaylena A. Ehgoetz Martens,  Liang Wang,  Simon J.G. Lewis,  David D. Feng,  Zhiyong Wang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：central nervous system, nervous system impacting, system impacting millions, Parkinson disease, symptoms of Parkinson</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Freezing of gait (FoG) is one of the most common symptoms of Parkinson's
disease, which is a neurodegenerative disorder of the central nervous system
impacting millions of people around the world. To address the pressing need to
improve the quality of treatment for FoG, devising a computer-aided detection
and quantification tool for FoG has been increasingly important. As a
non-invasive technique for collecting motion patterns, the footstep pressure
sequences obtained from pressure sensitive gait mats provide a great
opportunity for evaluating FoG in the clinic and potentially in the home
environment. In this study, FoG detection is formulated as a sequential
modelling task and a novel deep learning architecture, namely Adversarial
Spatio-temporal Network (ASTN), is proposed to learn FoG patterns across
multiple levels. A novel adversarial training scheme is introduced with a
multi-level subject discriminator to obtain subject-independent FoG
representations, which helps to reduce the over-fitting risk due to the high
inter-subject variance. As a result, robust FoG detection can be achieved for
unseen subjects. The proposed scheme also sheds light on improving
subject-level clinical studies from other scenarios as it can be integrated
with many existing deep architectures. To the best of our knowledge, this is
one of the first studies of footstep pressure-based FoG detection and the
approach of utilizing ASTN is the first deep neural network architecture in
pursuit of subject-independent representations. Experimental results on 393
trials collected from 21 subjects demonstrate encouraging performance of the
proposed ASTN for FoG detection with an AUC 0.85.</p>
  </details>
</details>
<details>
  <summary>37. <b>标题：DRAMA: Joint Risk Localization and Captioning in Driving</b></summary>
  <p><b>编号</b>：[171]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10767</p>
  <p><b>作者</b>：Srikanth Malla,  Chiho Choi,  Isht Dwivedi,  Joon Hee Choi,  Jiachen Li</p>
  <p><b>备注</b>：WACV 2023 (Winter Conference on Applications of Computer Vision)</p>
  <p><b>关键词</b>：safety-critical automation systems, driving, driving scenes, Driving Risk Assessment, Risk Assessment Mechanism</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Considering the functionality of situational awareness in safety-critical
automation systems, the perception of risk in driving scenes and its
explainability is of particular importance for autonomous and cooperative
driving. Toward this goal, this paper proposes a new research direction of
joint risk localization in driving scenes and its risk explanation as a natural
language description. Due to the lack of standard benchmarks, we collected a
large-scale dataset, DRAMA (Driving Risk Assessment Mechanism with A captioning
module), which consists of 17,785 interactive driving scenarios collected in
Tokyo, Japan. Our DRAMA dataset accommodates video- and object-level questions
on driving risks with associated important objects to achieve the goal of
visual captioning as a free-form language description utilizing closed and
open-ended responses for multi-level questions, which can be used to evaluate a
range of visual captioning capabilities in driving scenarios. We make this data
available to the community for further research. Using DRAMA, we explore
multiple facets of joint risk localization and captioning in interactive
driving scenarios. In particular, we benchmark various multi-task prediction
architectures and provide a detailed analysis of joint risk localization and
risk captioning. The data set is available at this https URL</p>
  </details>
</details>
<details>
  <summary>38. <b>标题：CCR: Facial Image Editing with Continuity, Consistency and Reversibility</b></summary>
  <p><b>编号</b>：[181]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10734</p>
  <p><b>作者</b>：Nan Yang,  Xin Luan,  Huidi Jia,  Zhi Han,  Yandong Tang</p>
  <p><b>备注</b>：10 pages, 11 figures</p>
  <p><b>关键词</b>：editing, sequential facial image, facial image editing, incontinuous editing, facial image</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Three problems exist in sequential facial image editing: incontinuous
editing, inconsistent editing, and irreversible editing. Incontinuous editing
is that the current editing can not retain the previously edited attributes.
Inconsistent editing is that swapping the attribute editing orders can not
yield the same results. Irreversible editing means that operating on a facial
image is irreversible, especially in sequential facial image editing. In this
work, we put forward three concepts and corresponding definitions: editing
continuity, consistency, and reversibility. Then, we propose a novel model to
achieve the goal of editing continuity, consistency, and reversibility. A
sufficient criterion is defined to determine whether a model is continuous,
consistent, and reversible. Extensive qualitative and quantitative experimental
results validate our proposed model and show that a continuous, consistent and
reversible editing model has a more flexible editing function while preserving
facial identity. Furthermore, we think that our proposed definitions and model
will have wide and promising applications in multimedia processing. Code and
data are available at this https URL.</p>
  </details>
</details>
<details>
  <summary>39. <b>标题：FusionRCNN: LiDAR-Camera Fusion for Two-stage 3D Object Detection</b></summary>
  <p><b>编号</b>：[182]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10733</p>
  <p><b>作者</b>：Xinli Xu,  Shaocong Dong,  Lihe Ding,  Jie Wang,  Tingfa Xu,  Jianan Li</p>
  <p><b>备注</b>：7 pages, 3 figures</p>
  <p><b>关键词</b>：reliable perception system, object detection, driving and robotics, detection with multi-sensors, multi-sensors is essential</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>3D object detection with multi-sensors is essential for an accurate and
reliable perception system of autonomous driving and robotics. Existing 3D
detectors significantly improve the accuracy by adopting a two-stage paradigm
which merely relies on LiDAR point clouds for 3D proposal refinement. Though
impressive, the sparsity of point clouds, especially for the points far away,
making it difficult for the LiDAR-only refinement module to accurately
recognize and locate this http URL address this problem, we propose a novel
multi-modality two-stage approach named FusionRCNN, which effectively and
efficiently fuses point clouds and camera images in the Regions of
Interest(RoI). FusionRCNN adaptively integrates both sparse geometry
information from LiDAR and dense texture information from camera in a unified
attention mechanism. Specifically, it first utilizes RoIPooling to obtain an
image set with a unified size and gets the point set by sampling raw points
within proposals in the RoI extraction step; then leverages an intra-modality
self-attention to enhance the domain-specific features, following by a
well-designed cross-attention to fuse the information from two
modalities.FusionRCNN is fundamentally plug-and-play and supports different
one-stage methods with almost no architectural changes. Extensive experiments
on KITTI and Waymo benchmarks demonstrate that our method significantly boosts
the performances of popular detectors.Remarkably, FusionRCNN significantly
improves the strong SECOND baseline by 6.14% mAP on Waymo, and outperforms
competing two-stage approaches. Code will be released soon at
this https URL.</p>
  </details>
</details>
<details>
  <summary>40. <b>标题：Fair Robust Active Learning by Joint Inconsistency</b></summary>
  <p><b>编号</b>：[184]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10729</p>
  <p><b>作者</b>：Tsung-Han Wu,  Shang-Tse Chen,  Winston H. Hsu</p>
  <p><b>备注</b>：11 pages, 3 figures</p>
  <p><b>关键词</b>：Active Learning, utilized active learning, active learning techniques, Fair Active Learning, Fair Robust Active</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Fair Active Learning (FAL) utilized active learning techniques to achieve
high model performance with limited data and to reach fairness between
sensitive groups (e.g., genders). However, the impact of the adversarial
attack, which is vital for various safety-critical machine learning
applications, is not yet addressed in FAL. Observing this, we introduce a novel
task, Fair Robust Active Learning (FRAL), integrating conventional FAL and
adversarial robustness. FRAL requires ML models to leverage active learning
techniques to jointly achieve equalized performance on benign data and
equalized robustness against adversarial attacks between groups. In this new
task, previous FAL methods generally face the problem of unbearable
computational burden and ineffectiveness. Therefore, we develop a simple yet
effective FRAL strategy by Joint INconsistency (JIN). To efficiently find
samples that can boost the performance and robustness of disadvantaged groups
for labeling, our method exploits the prediction inconsistency between benign
and adversarial samples as well as between standard and robust models.
Extensive experiments under diverse datasets and sensitive groups demonstrate
that our method not only achieves fairer performance on benign samples but also
obtains fairer robustness under white-box PGD attacks compared with existing
active learning and FAL baselines. We are optimistic that FRAL would pave a new
path for developing safe and robust ML research and applications such as facial
attribute recognition in biometrics systems.</p>
  </details>
</details>
<details>
  <summary>41. <b>标题：Self-adversarial Multi-scale Contrastive Learning for Semantic  Segmentation of Thermal Facial Images</b></summary>
  <p><b>编号</b>：[191]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10700</p>
  <p><b>作者</b>：Jitesh Joshi,  Nadia Bianchi-Berthouze,  Youngjun Cho</p>
  <p><b>备注</b>：Submitted to the British Machine Vision Conference (BMVC), 2022</p>
  <p><b>关键词</b>：features lack salience, facial features lack, train segmentation networks, lack salience, facial features</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Reliable segmentation of thermal facial images in unconstrained settings such
as thermal ambience and occlusions is challenging as facial features lack
salience. Limited availability of datasets from such settings further makes it
difficult to train segmentation networks. To address the challenge, we propose
Self-Adversarial Multi-scale Contrastive Learning (SAM-CL) as a generic
learning framework to train segmentation networks. SAM-CL framework constitutes
SAM-CL loss function and a thermal image augmentation (TiAug) as a
domain-specific augmentation technique to simulate unconstrained settings based
upon existing datasets collected from controlled settings. We use the
Thermal-Face-Database to demonstrate effectiveness of our approach. Experiments
conducted on the existing segmentation networks- UNET, Attention-UNET,
DeepLabV3 and HRNetv2 evidence the consistent performance gain from the SAM-CL
framework. Further, we present a qualitative analysis with UBComfort and
DeepBreath datasets to discuss how our proposed methods perform in handling
unconstrained situations.</p>
  </details>
</details>
<details>
  <summary>42. <b>标题：Stochastic Future Prediction in Real World Driving Scenarios</b></summary>
  <p><b>编号</b>：[192]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10693</p>
  <p><b>作者</b>：Adil Kaan Akan</p>
  <p><b>备注</b>：MS thesis, overlap with arXiv:2203.13641, arXiv:2203.10528, arXiv:2108.02760</p>
  <p><b>关键词</b>：plays a key, key role, future prediction, future, Uncertainty plays</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Uncertainty plays a key role in future prediction. The future is uncertain.
That means there might be many possible futures. A future prediction method
should cover the whole possibilities to be robust. In autonomous driving,
covering multiple modes in the prediction part is crucially important to make
safety-critical decisions. Although computer vision systems have advanced
tremendously in recent years, future prediction remains difficult today.
Several examples are uncertainty of the future, the requirement of full scene
understanding, and the noisy outputs space. In this thesis, we propose
solutions to these challenges by modeling the motion explicitly in a stochastic
way and learning the temporal dynamics in a latent space.</p>
  </details>
</details>
<details>
  <summary>43. <b>标题：PREF: Predictability Regularized Neural Motion Fields</b></summary>
  <p><b>编号</b>：[193]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10691</p>
  <p><b>作者</b>：Liangchen Song,  Xuan Gong,  Benjamin Planche,  Meng Zheng,  David Doermann,  Junsong Yuan,  Terrence Chen,  Ziyan Wu</p>
  <p><b>备注</b>：Accepted at ECCV 2022 (oral). Paper + supplementary material</p>
  <p><b>关键词</b>：vision applications, motion, dynamic scene, estimated motion, scene</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Knowing the 3D motions in a dynamic scene is essential to many vision
applications. Recent progress is mainly focused on estimating the activity of
some specific elements like humans. In this paper, we leverage a neural motion
field for estimating the motion of all points in a multiview setting. Modeling
the motion from a dynamic scene with multiview data is challenging due to the
ambiguities in points of similar color and points with time-varying color. We
propose to regularize the estimated motion to be predictable. If the motion
from previous frames is known, then the motion in the near future should be
predictable. Therefore, we introduce a predictability regularization by first
conditioning the estimated motion on latent embeddings, then by adopting a
predictor network to enforce predictability on the embeddings. The proposed
framework PREF (Predictability REgularized Fields) achieves on par or better
results than state-of-the-art neural motion field-based dynamic scene
representation methods, while requiring no prior knowledge of the scene.</p>
  </details>
</details>
<details>
  <summary>44. <b>标题：Attention Beats Concatenation for Conditioning Neural Fields</b></summary>
  <p><b>编号</b>：[196]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10684</p>
  <p><b>作者</b>：Daniel Rebain,  Mark J. Matthews,  Kwang Moo Yi,  Gopal Sharma,  Dmitry Lagun,  Andrea Tagliasacchi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：mapping coordinate inputs, Neural fields model, fields model signals, mapping coordinate, coordinate inputs</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Neural fields model signals by mapping coordinate inputs to sampled values.
They are becoming an increasingly important backbone architecture across many
fields from vision and graphics to biology and astronomy. In this paper, we
explore the differences between common conditioning mechanisms within these
networks, an essential ingredient in shifting neural fields from memorization
of signals to generalization, where the set of signals lying on a manifold is
modelled jointly. In particular, we are interested in the scaling behaviour of
these mechanisms to increasingly high-dimensional conditioning variables. As we
show in our experiments, high-dimensional conditioning is key to modelling
complex data distributions, thus it is important to determine what architecture
choices best enable this when working on such problems. To this end, we run
experiments modelling 2D, 3D, and 4D signals with neural fields, employing
concatenation, hyper-network, and attention-based conditioning strategies -- a
necessary but laborious effort that has not been performed in the literature.
We find that attention-based conditioning outperforms other approaches in a
variety of settings.</p>
  </details>
</details>
<details>
  <summary>45. <b>标题：NashAE: Disentangling Representations through Adversarial Covariance  Minimization</b></summary>
  <p><b>编号</b>：[199]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10677</p>
  <p><b>作者</b>：Eric Yeats,  Frank Liu,  David Womble,  Hai Li</p>
  <p><b>备注</b>：Published as a conference paper in the European Conference on Computer Vision (ECCV) 2022</p>
  <p><b>关键词</b>：underlying variation profile, individual latent variables, variation profile, underlying variation, present a self-supervised</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present a self-supervised method to disentangle factors of variation in
high-dimensional data that does not rely on prior knowledge of the underlying
variation profile (e.g., no assumptions on the number or distribution of the
individual latent variables to be extracted). In this method which we call
NashAE, high-dimensional feature disentanglement is accomplished in the
low-dimensional latent space of a standard autoencoder (AE) by promoting the
discrepancy between each encoding element and information of the element
recovered from all other encoding elements. Disentanglement is promoted
efficiently by framing this as a minmax game between the AE and an ensemble of
regression networks which each provide an estimate of an element conditioned on
an observation of all other elements. We quantitatively compare our approach
with leading disentanglement methods using existing disentanglement metrics.
Furthermore, we show that NashAE has increased reliability and increased
capacity to capture salient data characteristics in the learned latent
representation.</p>
  </details>
</details>
<details>
  <summary>46. <b>标题：Convolutional Bayesian Kernel Inference for 3D Semantic Mapping</b></summary>
  <p><b>编号</b>：[205]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10663</p>
  <p><b>作者</b>：Joey Wilson,  Yuewei Fu,  Arthur Zhang,  Jingyu Song,  Andrew Capodieci,  Paramsothy Jayakumar,  Kira Barton,  Maani Ghaffari</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：efficient latent space, Convolutional Bayesian Kernel, Bayesian Kernel Inference, Robotic perception, latent space</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Robotic perception is currently at a cross-roads between modern methods which
operate in an efficient latent space, and classical methods which are
mathematically founded and provide interpretable, trustworthy results. In this
paper, we introduce a Convolutional Bayesian Kernel Inference (ConvBKI) layer
which explicitly performs Bayesian inference within a depthwise separable
convolution layer to simultaneously maximize efficiency while maintaining
reliability. We apply our layer to the task of 3D semantic mapping, where we
learn semantic-geometric probability distributions for LiDAR sensor information
in real time. We evaluate our network against state-of-the-art semantic mapping
algorithms on the KITTI data set, and demonstrate improved latency with
comparable semantic results.</p>
  </details>
</details>
<details>
  <summary>47. <b>标题：GNPM: Geometric-Aware Neural Parametric Models</b></summary>
  <p><b>编号</b>：[219]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10621</p>
  <p><b>作者</b>：Mirgahney Mohamed,  Lourdes Agapito</p>
  <p><b>备注</b>：10 pages, 8 figures</p>
  <p><b>关键词</b>：Geometric Neural Parametric, Neural Parametric Models, propose Geometric Neural, learned parametric model, Geometric Neural</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose Geometric Neural Parametric Models (GNPM), a learned parametric
model that takes into account the local structure of data to learn disentangled
shape and pose latent spaces of 4D dynamics, using a geometric-aware
architecture on point clouds. Temporally consistent 3D deformations are
estimated without the need for dense correspondences at training time, by
exploiting cycle consistency. Besides its ability to learn dense
correspondences, GNPMs also enable latent-space manipulations such as
interpolation and shape/pose transfer. We evaluate GNPMs on various datasets of
clothed humans, and show that it achieves comparable performance to
state-of-the-art methods that require dense correspondences during training.</p>
  </details>
</details>
<details>
  <summary>48. <b>标题：OLIVES Dataset: Ophthalmic Labels for Investigating Visual Eye Semantics</b></summary>
  <p><b>编号</b>：[238]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.11195</p>
  <p><b>作者</b>：Mohit Prabhushankar,  Kiran Kokilepersaud,  Yash-yee Logan,  Stephanie Trejo Corona,  Ghassan AlRegib,  Charles Wykoff</p>
  <p><b>备注</b>：Accepted at 36th Conference on Neural Information Processing Systems (NeurIPS 2022) Track on Datasets and Benchmarks</p>
  <p><b>关键词</b>：Optical Coherence Tomography, three-dimensional Optical Coherence, Coherence Tomography, Optical Coherence, Diabetic Macular Edema</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Clinical diagnosis of the eye is performed over multifarious data modalities
including scalar clinical labels, vectorized biomarkers, two-dimensional fundus
images, and three-dimensional Optical Coherence Tomography (OCT) scans.
Clinical practitioners use all available data modalities for diagnosing and
treating eye diseases like Diabetic Retinopathy (DR) or Diabetic Macular Edema
(DME). Enabling usage of machine learning algorithms within the ophthalmic
medical domain requires research into the relationships and interactions
between all relevant data over a treatment period. Existing datasets are
limited in that they neither provide data nor consider the explicit
relationship modeling between the data modalities. In this paper, we introduce
the Ophthalmic Labels for Investigating Visual Eye Semantics (OLIVES) dataset
that addresses the above limitation. This is the first OCT and near-IR fundus
dataset that includes clinical labels, biomarker labels, disease labels, and
time-series patient treatment information from associated clinical trials. The
dataset consists of 1268 near-IR fundus images each with at least 49 OCT scans,
and 16 biomarkers, along with 4 clinical labels and a disease diagnosis of DR
or DME. In total, there are 96 eyes' data averaged over a period of at least
two years with each eye treated for an average of 66 weeks and 7 injections. We
benchmark the utility of OLIVES dataset for ophthalmic data as well as provide
benchmarks and concrete research directions for core and emerging machine
learning paradigms within medical image analysis.</p>
  </details>
</details>
<details>
  <summary>49. <b>标题：Structure Guided Manifolds for Discovery of Disease Characteristics</b></summary>
  <p><b>编号</b>：[249]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.11015</p>
  <p><b>作者</b>：Siyu Liu,  Linfeng Liu,  Fatima Nasrallah,  Craig Engstrom,  Stuart Crozier,  Shekhar Chandra</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：challenging to discern, Alzheimer Disease, Disease, mild Alzheimer Disease, medical image analysis</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In medical image analysis, the subtle visual characteristics of many diseases
are challenging to discern, particularly due to the lack of paired data. For
example, in mild Alzheimer's Disease (AD), brain tissue atrophy can be
difficult to observe from pure imaging data, especially without paired AD and
Cognitively Normal ( CN ) data for comparison. This work presents Disease
Discovery GAN ( DiDiGAN), a weakly-supervised style-based framework for
discovering and visualising subtle disease features. DiDiGAN learns a disease
manifold of AD and CN visual characteristics, and the style codes sampled from
this manifold are imposed onto an anatomical structural "blueprint" to
synthesise paired AD and CN magnetic resonance images (MRIs). To suppress
non-disease-related variations between the generated AD and CN pairs, DiDiGAN
leverages a structural constraint with cycle consistency and anti-aliasing to
enforce anatomical correspondence. When tested on the Alzheimer's Disease
Neuroimaging Initiative ( ADNI) dataset, DiDiGAN showed key AD characteristics
(reduced hippocampal volume, ventricular enlargement, and atrophy of cortical
structures) through synthesising paired AD and CN scans. The qualitative
results were backed up by automated brain volume analysis, where systematic
pair-wise reductions in brain tissue structures were also measured</p>
  </details>
</details>
<details>
  <summary>50. <b>标题：Entropic Descent Archetypal Analysis for Blind Hyperspectral Unmixing</b></summary>
  <p><b>编号</b>：[252]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.11002</p>
  <p><b>作者</b>：Alexandre Zouaoui (1),  Gedeon Muhawenayo (1),  Behnood Rasti (2),  Jocelyn Chanussot (1),  Julien Mairal (1) ((1) Thoth, Inria, UGA, CNRS, Grenoble INP, LJK, (2) HZDR)</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：assuming linear mixing, assuming linear, archetypal analysis, linear mixing, blind hyperspectral unmixing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we introduce a new algorithm based on archetypal analysis for
blind hyperspectral unmixing, assuming linear mixing of endmembers. Archetypal
analysis is a natural formulation for this task. This method does not require
the presence of pure pixels (i.e., pixels containing a single material) but
instead represents endmembers as convex combinations of a few pixels present in
the original hyperspectral image. Our approach leverages an entropic gradient
descent strategy, which (i) provides better solutions for hyperspectral
unmixing than traditional archetypal analysis algorithms, and (ii) leads to
efficient GPU implementations. Since running a single instance of our algorithm
is fast, we also propose an ensembling mechanism along with an appropriate
model selection procedure that make our method robust to hyper-parameter
choices while keeping the computational complexity reasonable. By using six
standard real datasets, we show that our approach outperforms state-of-the-art
matrix factorization and recent deep learning methods. We also provide an
open-source PyTorch implementation: this https URL.</p>
  </details>
</details>
<details>
  <summary>51. <b>标题：DLUNet: Semi-supervised Learning based Dual-Light UNet for Multi-organ  Segmentation</b></summary>
  <p><b>编号</b>：[254]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10984</p>
  <p><b>作者</b>：Haoran Lai,  Tao Wang,  Shuoling Zhou</p>
  <p><b>备注</b>：13 page, 3 figures</p>
  <p><b>关键词</b>：manual ground truth, multi-organ is labor-intensive, manual ground, ground truth, truth of abdominal</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The manual ground truth of abdominal multi-organ is labor-intensive. In order
to make full use of CT data, we developed a semi-supervised learning based
dual-light UNet. In the training phase, it consists of two light UNets, which
make full use of label and unlabeled data simultaneously by using
consistent-based learning. Moreover, separable convolution and residual
concatenation was introduced light UNet to reduce the computational cost.
Further, a robust segmentation loss was applied to improve the performance. In
the inference phase, only a light UNet is used, which required low time cost
and less GPU memory utilization. The average DSC of this method in the
validation set is 0.8718. The code is available in
this https URL.</p>
  </details>
</details>
<details>
  <summary>52. <b>标题：COVID-19 Detection and Analysis From Lung CT Images using Novel Channel  Boosted CNNs</b></summary>
  <p><b>编号</b>：[256]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10963</p>
  <p><b>作者</b>：Saddam Hussain Khan</p>
  <p><b>备注</b>：13 Figures, 6 Tables, 28 Pages</p>
  <p><b>关键词</b>：affected human life, diagnostic system, proposed diagnostic system, affected human, worldwide economy</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In December 2019, the global pandemic COVID-19 in Wuhan, China, affected
human life and the worldwide economy. Therefore, an efficient diagnostic system
is required to control its spread. However, the automatic diagnostic system
poses challenges with a limited amount of labeled data, minor contrast
variation, and high structural similarity between infection and background. In
this regard, a new two-phase deep convolutional neural network (CNN) based
diagnostic system is proposed to detect minute irregularities and analyze
COVID-19 infection. In the first phase, a novel SB-STM-BRNet CNN is proposed,
incorporating a new channel Squeezed and Boosted (SB) and dilated
convolutional-based Split-Transform-Merge (STM) block to detect COVID-19
infected CT lungs images. The new STM blocks performed multi-path
region-smoothing and boundary operations, which helped to learn minor contrast
variation and global COVID-19 specific patterns. Furthermore, the diverse
boosted channels are achieved using the SB and Transfer Learning concepts in
STM blocks to learn texture variation between COVID-19-specific and healthy
images. In the second phase, COVID-19 infected images are provided to the novel
COVID-CB-RESeg segmentation CNN to identify and analyze COVID-19 infectious
regions. The proposed COVID-CB-RESeg methodically employed region-homogeneity,
heterogeneity operations, and channel boosting using auxiliary channels in each
encoder and decoder block to simultaneously learn the low illumination and
boundaries of the COVID-19 infected region. The proposed diagnostic system
yields good performance in terms of accuracy: 98.21 %, F-score: 98.24%, Dice
Similarity: 96.40 %, and IOU: 98.85 % for the COVID-19 infected region. The
proposed diagnostic system would reduce the burden and strengthen the
radiologist's decision for a fast and accurate COVID-19 diagnosis.</p>
  </details>
</details>
<details>
  <summary>53. <b>标题：Beyond Voxel Prediction Uncertainty: Identifying brain lesions you can  trust</b></summary>
  <p><b>编号</b>：[259]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10877</p>
  <p><b>作者</b>：Benjamin Lambert,  Florence Forbes,  Senan Doyle,  Alan Tucholka,  Michel Dojat</p>
  <p><b>备注</b>：Accepted for presentation at the Workshop on Interpretability of Machine Intelligence in Medical Image Computing (iMIMIC) at MICCAI 2022</p>
  <p><b>关键词</b>：Monte Carlo dropout, Deep neural networks, Monte Carlo, popular Monte Carlo, Graph Neural Network</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep neural networks have become the gold-standard approach for the automated
segmentation of 3D medical images. Their full acceptance by clinicians remains
however hampered by the lack of intelligible uncertainty assessment of the
provided results. Most approaches to quantify their uncertainty, such as the
popular Monte Carlo dropout, restrict to some measure of uncertainty in
prediction at the voxel level. In addition not to be clearly related to genuine
medical uncertainty, this is not clinically satisfying as most objects of
interest (e.g. brain lesions) are made of groups of voxels whose overall
relevance may not simply reduce to the sum or mean of their individual
uncertainties. In this work, we propose to go beyond voxel-wise assessment
using an innovative Graph Neural Network approach, trained from the outputs of
a Monte Carlo dropout model. This network allows the fusion of three estimators
of voxel uncertainty: entropy, variance, and model's confidence; and can be
applied to any lesion, regardless of its shape or size. We demonstrate the
superiority of our approach for uncertainty estimate on a task of Multiple
Sclerosis lesions segmentation.</p>
  </details>
</details>
<details>
  <summary>54. <b>标题：Automated head and neck tumor segmentation from 3D PET/CT</b></summary>
  <p><b>编号</b>：[261]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10809</p>
  <p><b>作者</b>：Andriy Myronenko,  Md Mahfuzur Rahman Siddiquee,  Dong Yang,  Yufan He,  Daguang Xu</p>
  <p><b>备注</b>：HECKTOR22 segmentation challenge. MICCAI 2022. arXiv admin note: text overlap with arXiv:2209.09546</p>
  <p><b>关键词</b>：offers a platform, PET images, platform for researchers, researchers to compare, lymph nodes</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Head and neck tumor segmentation challenge (HECKTOR) 2022 offers a platform
for researchers to compare their solutions to segmentation of tumors and lymph
nodes from 3D CT and PET images. In this work, we describe our solution to
HECKTOR 2022 segmentation task. We re-sample all images to a common resolution,
crop around head and neck region, and train SegResNet semantic segmentation
network from MONAI. We use 5-fold cross validation to select best model
checkpoints. The final submission is an ensemble of 15 models from 3 runs. Our
solution (team name NVAUTO) achieves the 1st place on the HECKTOR22 challenge
leaderboard with an aggregated dice score of 0.78802.</p>
  </details>
</details>
<details>
  <summary>55. <b>标题：A CT-Based Airway Segmentation Using U$^2$-net Trained by the Dice Loss  Function</b></summary>
  <p><b>编号</b>：[262]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10796</p>
  <p><b>作者</b>：Kunpeng Wang,  Yuexi Dong,  Yunpu Zeng,  Zhichun Ye,  Yangzhe Wang</p>
  <p><b>备注</b>：8 pages, 5 figures</p>
  <p><b>关键词</b>：pulmonary disease diagnosis, chest computed tomography, computed tomography scans, airway segmentation based, computer-assisted airway segmentation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Airway segmentation from chest computed tomography scans has played an
essential role in the pulmonary disease diagnosis. The computer-assisted airway
segmentation based on the U-net architecture is more efficient and accurate
compared to the manual segmentation. In this paper we employ the U$^2$-net
trained by the Dice loss function to model the airway tree from the multi-site
CT scans based on 299 training CT scans provided by the ATM'22. The derived
saliency probability map from the training is applied to the validation data to
extract the corresponding airway trees. The observation shows that the majority
of the segmented airway trees behave well from the perspective of accuracy and
connectivity. Refinements such as non-airway regions labeling and removing are
applied to certain obtained airway tree models to display the largest component
of the binary results.</p>
  </details>
</details>
<details>
  <summary>56. <b>标题：Automated segmentation of intracranial hemorrhages from 3D CT</b></summary>
  <p><b>编号</b>：[269]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10648</p>
  <p><b>作者</b>：Md Mahfuzur Rahman Siddiquee,  Dong Yang,  Yufan He,  Daguang Xu,  Andriy Myronenko</p>
  <p><b>备注</b>：INSTANCE22 challenge report, MICCAI2022. arXiv admin note: substantial text overlap with arXiv:2209.09546</p>
  <p><b>关键词</b>：hemorrhage stroke regions, hemorrhage segmentation challenge, Intracranial hemorrhage segmentation, offers a platform, Intracranial hemorrhage</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Intracranial hemorrhage segmentation challenge (INSTANCE 2022) offers a
platform for researchers to compare their solutions to segmentation of
hemorrhage stroke regions from 3D CTs. In this work, we describe our solution
to INSTANCE 2022. We use a 2D segmentation network, SegResNet from MONAI,
operating slice-wise without resampling. The final submission is an ensemble of
18 models. Our solution (team name NVAUTO) achieves the top place in terms of
Dice metric (0.721), and overall rank 2. It is implemented with Auto3DSeg.</p>
  </details>
</details>
<details>
  <summary>57. <b>标题：An Image Processing approach to identify solar plages observed at 393.37  nm by Kodaikanal Solar Observatory</b></summary>
  <p><b>编号</b>：[272]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10631</p>
  <p><b>作者</b>：Sarvesh Gharat,  Bhaskar Bose</p>
  <p><b>备注</b>：Output data will be made available on request after 2 years of publication</p>
  <p><b>关键词</b>：bright chromospheric features, chromospheric features observed, bright chromospheric, sun, chromospheric features</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Solar Plages are bright chromospheric features observed in Ca II K
photographic observations of the sun. These are regions of high magnetic field
concentration thus tracer of magnetic activity of the Sun and are one of the
most important features to study long-term variability of the Sun as Ca II K
spectroheliograms are recorded for more than a century. . However, detection of
the plages from century-long databases is a non-trivial task and need
significant human resources for doing it manually. Hence, in this study, we
propose an image processing algorithm that can identify solar plages from Ca II
K photographic observations. The proposed study has been implemented on
archival data from Kodaikanal Solar Observatory. To ensure that the algorithm
works, irrespective of noise level, brightness, and other image properties, we
randomly draw a sample of images from the data archive to test our algorithm.</p>
  </details>
</details>
<h1>自然语言处理</h1>
<details>
  <summary>1. <b>标题：Learning Interpretable Latent Dialogue Actions With Less Supervision</b></summary>
  <p><b>编号</b>：[34]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.11128</p>
  <p><b>作者</b>：Vojtěch Hudeček,  Ondřej Dušek</p>
  <p><b>备注</b>：9 pages, accepted to AACL-IJCNLP 2022</p>
  <p><b>关键词</b>：architecture for explainable, discrete latent variables, latent variables, represent dialogue actions, discrete latent</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present a novel architecture for explainable modeling of task-oriented
dialogues with discrete latent variables to represent dialogue actions. Our
model is based on variational recurrent neural networks (VRNN) and requires no
explicit annotation of semantic information. Unlike previous works, our
approach models the system and user turns separately and performs database
query modeling, which makes the model applicable to task-oriented dialogues
while producing easily interpretable action latent variables. We show that our
model outperforms previous approaches with less supervision in terms of
perplexity and BLEU on three datasets, and we propose a way to measure dialogue
success without the need for expert annotation. Finally, we propose a novel way
to explain semantics of the latent variables with respect to system actions.</p>
  </details>
</details>
<details>
  <summary>2. <b>标题：Scope of Pre-trained Language Models for Detecting Conflicting Health  Information</b></summary>
  <p><b>编号</b>：[45]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.11102</p>
  <p><b>作者</b>：Joseph Gatto,  Madhusudan Basak,  Sarah M. Preum</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Health advice, health, HCD, increasing number, rely on online</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>An increasing number of people now rely on online platforms to meet their
health information needs. Thus identifying inconsistent or conflicting textual
health information has become a safety-critical task. Health advice data poses
a unique challenge where information that is accurate in the context of one
diagnosis can be conflicting in the context of another. For example, people
suffering from diabetes and hypertension often receive conflicting health
advice on diet. This motivates the need for technologies which can provide
contextualized, user-specific health advice. A crucial step towards
contextualized advice is the ability to compare health advice statements and
detect if and how they are conflicting. This is the task of health conflict
detection (HCD). Given two pieces of health advice, the goal of HCD is to
detect and categorize the type of conflict. It is a challenging task, as (i)
automatically identifying and categorizing conflicts requires a deeper
understanding of the semantics of the text, and (ii) the amount of available
data is quite limited.
In this study, we are the first to explore HCD in the context of pre-trained
language models. We find that DeBERTa-v3 performs best with a mean F1 score of
0.68 across all experiments. We additionally investigate the challenges posed
by different conflict types and how synthetic data improves a model's
understanding of conflict-specific semantics. Finally, we highlight the
difficulty in collecting real health conflicts and propose a human-in-the-loop
synthetic data augmentation approach to expand existing HCD datasets. Our HCD
training dataset is over 2x bigger than the existing HCD dataset and is made
publicly available on Github.</p>
  </details>
</details>
<details>
  <summary>3. <b>标题：Prompting for a conversation: How to control a dialog model?</b></summary>
  <p><b>编号</b>：[56]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.11068</p>
  <p><b>作者</b>：Josef Valvoda,  Yimai Fang,  David Vandyke</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Dialog modelling faces, modelling faces, faces a difficult, Dialog modelling, pre-trained dialog models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Dialog modelling faces a difficult trade-off. Models are trained on a large
amount of text, yet their responses need to be limited to a desired scope and
style of a dialog agent. Because the datasets used to achieve the former
contain language that is not compatible with the latter, pre-trained dialog
models are fine-tuned on smaller curated datasets. However, the fine-tuning
process robs them of the ability to produce diverse responses, eventually
reducing them to dull conversation partners. In this paper we investigate if
prompting can mitigate the above trade-off. Specifically, we experiment with
conditioning the prompt on the query, rather than training a single prompt for
all queries. By following the intuition that freezing the pre-trained language
model will conserve its expressivity, we find that compared to fine-tuning,
prompting can achieve a higher BLEU score and substantially improve the
diversity and novelty of the responses.</p>
  </details>
</details>
<details>
  <summary>4. <b>标题：Efficient Few-Shot Learning Without Prompts</b></summary>
  <p><b>编号</b>：[61]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.11055</p>
  <p><b>作者</b>：Lewis Tunstall,  Nils Reimers,  Unso Eun Seo Jo,  Luke Bates,  Daniel Korat,  Moshe Wasserblat,  Oren Pereg</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：pattern exploiting training, Recent few-shot methods, achieved impressive results, exploiting training, pattern exploiting</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent few-shot methods, such as parameter-efficient fine-tuning (PEFT) and
pattern exploiting training (PET), have achieved impressive results in
label-scarce settings. However, they are difficult to employ since they are
subject to high variability from manually crafted prompts, and typically
require billion-parameter language models to achieve high accuracy. To address
these shortcomings, we propose SetFit (Sentence Transformer Fine-tuning), an
efficient and prompt-free framework for few-shot fine-tuning of Sentence
Transformers (ST). SetFit works by first fine-tuning a pretrained ST on a small
number of text pairs, in a contrastive Siamese manner. The resulting model is
then used to generate rich text embeddings, which are used to train a
classification head. This simple framework requires no prompts or verbalizers,
and achieves high accuracy with orders of magnitude less parameters than
existing techniques. Our experiments show that SetFit obtains comparable
results with PEFT and PET techniques, while being an order of magnitude faster
to train. We also show that SetFit can be applied in multilingual settings by
simply switching the ST body. Our code is available at
this https URL and our datasets at
this https URL .</p>
  </details>
</details>
<details>
  <summary>5. <b>标题：MonoByte: A Pool of Monolingual Byte-level Language Models</b></summary>
  <p><b>编号</b>：[66]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.11035</p>
  <p><b>作者</b>：Hugo Abonizio,  Leandro Rodrigues de Souza,  Roberto Lotufo,  Rodrigo Nogueira</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：intriguing empirical result, empirical result, zero-shot cross-lingual ability, spurred many hypotheses, hypotheses to explain</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The zero-shot cross-lingual ability of models pretrained on multilingual and
even monolingual corpora has spurred many hypotheses to explain this intriguing
empirical result. However, due to the costs of pretraining, most research uses
public models whose pretraining methodology, such as the choice of
tokenization, corpus size, and computational budget, might differ drastically.
When researchers pretrain their own models, they often do so under a
constrained budget, and the resulting models might underperform significantly
compared to SOTA models. These experimental differences led to various
inconsistent conclusions about the nature of the cross-lingual ability of these
models. To help further research on the topic, we released 10 monolingual
byte-level models rigorously pretrained under the same configuration with a
large compute budget (equivalent to 420 days on a V100) and corpora that are 4
times larger than the original BERT's. Because they are tokenizer-free, the
problem of unseen token embeddings is eliminated, thus allowing researchers to
try a wider range of cross-lingual experiments in languages with different
scripts. Additionally, we release two models pretrained on non-natural language
texts that can be used in sanity-check experiments. Experiments on QA and NLI
tasks show that our monolingual models achieve competitive performance to the
multilingual one, and hence can be served to strengthen our understanding of
cross-lingual transferability in language models.</p>
  </details>
</details>
<details>
  <summary>6. <b>标题：Approaching English-Polish Machine Translation Quality Assessment with  Neural-based Methods</b></summary>
  <p><b>编号</b>：[75]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.11016</p>
  <p><b>作者</b>：Artur Nowakowski</p>
  <p><b>备注</b>：PolEval 2021</p>
  <p><b>关键词</b>：quality assessment metrics, translation quality assessment, translation quality, quality assessment, paper presents</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper presents our contribution to the PolEval 2021 Task 2: Evaluation
of translation quality assessment metrics. We describe experiments with
pre-trained language models and state-of-the-art frameworks for translation
quality assessment in both nonblind and blind versions of the task. Our
solutions ranked second in the nonblind version and third in the blind version.</p>
  </details>
</details>
<details>
  <summary>7. <b>标题：Predicting pairwise preferences between TTS audio stimuli using parallel  ratings data and anti-symmetric twin neural networks</b></summary>
  <p><b>编号</b>：[78]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.11003</p>
  <p><b>作者</b>：Cassia Valentini-Botinhao,  Manuel Sam Ribeiro,  Oliver Watts,  Korin Richmond,  Gustav Eje Henter</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：subjective listening tests, Automatically predicting, subjective listening, challenging task, listening tests</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Automatically predicting the outcome of subjective listening tests is a
challenging task. Ratings may vary from person to person even if preferences
are consistent across listeners. While previous work has focused on predicting
listeners' ratings (mean opinion scores) of individual stimuli, we focus on the
simpler task of predicting subjective preference given two speech stimuli for
the same text. We propose a model based on anti-symmetric twin neural networks,
trained on pairs of waveforms and their corresponding preference scores. We
explore both attention and recurrent neural nets to account for the fact that
stimuli in a pair are not time aligned. To obtain a large training set we
convert listeners' ratings from MUSHRA tests to values that reflect how often
one stimulus in the pair was rated higher than the other. Specifically, we
evaluate performance on data obtained from twelve MUSHRA evaluations conducted
over five years, containing different TTS systems, built from data of different
speakers. Our results compare favourably to a state-of-the-art model trained to
predict MOS scores.</p>
  </details>
</details>
<details>
  <summary>8. <b>标题：Selecting Better Samples from Pre-trained LLMs: A Case Study on Question  Generation</b></summary>
  <p><b>编号</b>：[79]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.11000</p>
  <p><b>作者</b>：Xingdi Yuan,  Tong Wang,  Yen-Hsiang Wang,  Emery Fine,  Rania Abdelghani,  Pauline Lucas,  Hélène Sauzéon,  Pierre-Yves Oudeyer</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Large Language Models, recent years demonstrated, years demonstrated impressive, demonstrated impressive prowess, natural language generation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large Language Models (LLMs) have in recent years demonstrated impressive
prowess in natural language generation. A common practice to improve generation
diversity is to sample multiple outputs from the model. However, there lacks a
simple and robust way of selecting the best output from these stochastic
samples. As a case study framed in the context of question generation, we
propose two prompt-based approaches to selecting high-quality questions from a
set of LLM-generated candidates. Our method works under the constraints of 1) a
black-box (non-modifiable) question generation model and 2) lack of access to
human-annotated references -- both of which are realistic limitations for
real-world deployment of LLMs. With automatic as well as human evaluations, we
empirically demonstrate that our approach can effectively select questions of
higher qualities than greedy generation.</p>
  </details>
</details>
<details>
  <summary>9. <b>标题：Adaptation of domain-specific transformer models with text oversampling  for sentiment analysis of social media posts on Covid-19 vaccines</b></summary>
  <p><b>编号</b>：[90]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10966</p>
  <p><b>作者</b>：Anmol Bansal,  Arjun Choudhry,  Anubhav Sharma,  Seba Susan</p>
  <p><b>备注</b>：The paper has been accepted for publication in Computer Science journal: this http URL</p>
  <p><b>关键词</b>：pre-trained transformer models, transformer models, domain-specific transformer models, pre-trained transformer, counter its surge</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Covid-19 has spread across the world and several vaccines have been developed
to counter its surge. To identify the correct sentiments associated with the
vaccines from social media posts, we fine-tune various state-of-the-art
pre-trained transformer models on tweets associated with Covid-19 vaccines.
Specifically, we use the recently introduced state-of-the-art pre-trained
transformer models RoBERTa, XLNet and BERT, and the domain-specific transformer
models CT-BERT and BERTweet that are pre-trained on Covid-19 tweets. We further
explore the option of text augmentation by oversampling using Language Model
based Oversampling Technique (LMOTE) to improve the accuracies of these models,
specifically, for small sample datasets where there is an imbalanced class
distribution among the positive, negative and neutral sentiment classes. Our
results summarize our findings on the suitability of text oversampling for
imbalanced small sample datasets that are used to fine-tune state-of-the-art
pre-trained transformer models, and the utility of domain-specific transformer
models for the classification task.</p>
  </details>
</details>
<details>
  <summary>10. <b>标题：An Information Minimization Based Contrastive Learning Model for  Unsupervised Sentence Embeddings Learning</b></summary>
  <p><b>编号</b>：[94]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10951</p>
  <p><b>作者</b>：Shaobin Chen,  Jie Zhou,  Yuling Sun,  Liang He</p>
  <p><b>备注</b>：11 pages, 3 figures, published to COLING 2022</p>
  <p><b>关键词</b>：push negative pairs, positive pairs similar, contrastive learning methods, positive instances, information</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Unsupervised sentence embeddings learning has been recently dominated by
contrastive learning methods (e.g., SimCSE), which keep positive pairs similar
and push negative pairs apart. The contrast operation aims to keep as much
information as possible by maximizing the mutual information between positive
instances, which leads to redundant information in sentence embedding. To
address this problem, we present an information minimization based contrastive
learning (InforMin-CL) model to retain the useful information and discard the
redundant information by maximizing the mutual information and minimizing the
information entropy between positive instances meanwhile for unsupervised
sentence representation learning. Specifically, we find that information
minimization can be achieved by simple contrast and reconstruction objectives.
The reconstruction operation reconstitutes the positive instance via the other
positive instance to minimize the information entropy between positive
instances. We evaluate our model on fourteen downstream tasks, including both
supervised and unsupervised (semantic textual similarity) tasks. Extensive
experimental results show that our InforMin-CL obtains a state-of-the-art
performance.</p>
  </details>
</details>
<details>
  <summary>11. <b>标题：Equivariant Transduction through Invariant Alignment</b></summary>
  <p><b>编号</b>：[105]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10926</p>
  <p><b>作者</b>：Jennifer C. White,  Ryan Cotterell</p>
  <p><b>备注</b>：Accepted at COLING 2022</p>
  <p><b>关键词</b>：potentially infinite number, number of words, infinite number, number of sentences, finite number</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The ability to generalize compositionally is key to understanding the
potentially infinite number of sentences that can be constructed in a human
language from only a finite number of words. Investigating whether NLP models
possess this ability has been a topic of interest: SCAN (Lake and Baroni, 2018)
is one task specifically proposed to test for this property. Previous work has
achieved impressive empirical results using a group-equivariant neural network
that naturally encodes a useful inductive bias for SCAN (Gordon et al., 2020).
Inspired by this, we introduce a novel group-equivariant architecture that
incorporates a group-invariant hard alignment mechanism. We find that our
network's structure allows it to develop stronger equivariance properties than
existing group-equivariant approaches. We additionally find that it outperforms
previous group-equivariant networks empirically on the SCAN task. Our results
suggest that integrating group-equivariance into a variety of neural
architectures is a potentially fruitful avenue of research, and demonstrate the
value of careful analysis of the theoretical properties of such architectures.</p>
  </details>
</details>
<details>
  <summary>12. <b>标题：Learning to Write with Coherence From Negative Examples</b></summary>
  <p><b>编号</b>：[106]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10922</p>
  <p><b>作者</b>：Seonil Son,  Jaeseo Lim,  Youwon Jang,  Jaeyoung Lee,  Byoung-Tak Zhang</p>
  <p><b>备注</b>：4+1 pages, 4 figures, 2 tables. ICASSP 2022 rejected</p>
  <p><b>关键词</b>：critical factors, factors that determine, determine the quality, propose writing relevance, natural language generation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Coherence is one of the critical factors that determine the quality of
writing. We propose writing relevance (WR) training method for neural
encoder-decoder natural language generation (NLG) models which improves
coherence of the continuation by leveraging negative examples. WR loss
regresses the vector representation of the context and generated sentence
toward positive continuation by contrasting it with the negatives. We compare
our approach with Unlikelihood (UL) training in a text continuation task on
commonsense natural language inference (NLI) corpora to show which method
better models the coherence by avoiding unlikely continuations. The preference
of our approach in human evaluation shows the efficacy of our method in
improving coherence.</p>
  </details>
</details>
<details>
  <summary>13. <b>标题：A Multi-Stage Multi-Codebook VQ-VAE Approach to High-Performance Neural  TTS</b></summary>
  <p><b>编号</b>：[122]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10887</p>
  <p><b>作者</b>：Haohan Guo,  Fenglong Xie,  Frank K. Soong,  Xixin Wu,  Helen Meng</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：high-performance neural TTS, MSMC, TTS, encode Mel spectrograms, proposed TTS</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose a Multi-Stage, Multi-Codebook (MSMC) approach to high-performance
neural TTS synthesis. A vector-quantized, variational autoencoder (VQ-VAE)
based feature analyzer is used to encode Mel spectrograms of speech training
data by down-sampling progressively in multiple stages into MSMC
Representations (MSMCRs) with different time resolutions, and quantizing them
with multiple VQ codebooks, respectively. Multi-stage predictors are trained to
map the input text sequence to MSMCRs progressively by minimizing a combined
loss of the reconstruction Mean Square Error (MSE) and "triplet loss". In
synthesis, the neural vocoder converts the predicted MSMCRs into final speech
waveforms. The proposed approach is trained and tested with an English TTS
database of 16 hours by a female speaker. The proposed TTS achieves an MOS
score of 4.41, which outperforms the baseline with an MOS of 3.62. Compact
versions of the proposed TTS with much less parameters can still preserve high
MOS scores. Ablation studies show that both multiple stages and multiple
codebooks are effective for achieving high TTS performance.</p>
  </details>
</details>
<details>
  <summary>14. <b>标题：Improving Attention-Based Interpretability of Text Classification  Transformers</b></summary>
  <p><b>编号</b>：[125]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10876</p>
  <p><b>作者</b>：Nikolaos Mylonas,  Ioannis Mollas,  Grigorios Tsoumakas</p>
  <p><b>备注</b>：13 pages, 6 figures, 6 tables, to be submitted to conference</p>
  <p><b>关键词</b>：consistently achieve, NLP, Transformers, performance, rich linguistic relations</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Transformers are widely used in NLP, where they consistently achieve
state-of-the-art performance. This is due to their attention-based
architecture, which allows them to model rich linguistic relations between
words. However, transformers are difficult to interpret. Being able to provide
reasoning for its decisions is an important property for a model in domains
where human lives are affected, such as hate speech detection and biomedicine.
With transformers finding wide use in these fields, the need for
interpretability techniques tailored to them arises. The effectiveness of
attention-based interpretability techniques for transformers in text
classification is studied in this work. Despite concerns about attention-based
interpretations in the literature, we show that, with proper setup, attention
may be used in such tasks with results comparable to state-of-the-art
techniques, while also being faster and friendlier to the environment. We
validate our claims with a series of experiments that employ a new feature
importance metric.</p>
  </details>
</details>
<details>
  <summary>15. <b>标题：Semantically Consistent Data Augmentation for Neural Machine Translation  via Conditional Masked Language Model</b></summary>
  <p><b>编号</b>：[126]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10875</p>
  <p><b>作者</b>：Qiao Cheng,  Jin Huang,  Yitao Duan</p>
  <p><b>备注</b>：Accepted to COLING 2022 Main Conference (Long paper). this https URL</p>
  <p><b>关键词</b>：Masked Language Model, Conditional Masked Language, enforce stronger semantic, neural machine translation, paper introduces</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper introduces a new data augmentation method for neural machine
translation that can enforce stronger semantic consistency both within and
across languages. Our method is based on Conditional Masked Language Model
(CMLM) which is bi-directional and can be conditional on both left and right
context, as well as the label. We demonstrate that CMLM is a good technique for
generating context-dependent word distributions. In particular, we show that
CMLM is capable of enforcing semantic consistency by conditioning on both
source and target during substitution. In addition, to enhance diversity, we
incorporate the idea of soft word substitution for data augmentation which
replaces a word with a probabilistic distribution over the vocabulary.
Experiments on four translation datasets of different scales show that the
overall solution results in more realistic data augmentation and better
translation quality. Our approach consistently achieves the best performance in
comparison with strong and recent works and yields improvements of up to 1.90
BLEU points over the baseline.</p>
  </details>
</details>
<details>
  <summary>16. <b>标题：Controllable Accented Text-to-Speech Synthesis</b></summary>
  <p><b>编号</b>：[155]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10804</p>
  <p><b>作者</b>：Rui Liu,  Berrak Sisman,  Guanglai Gao,  Haizhou Li</p>
  <p><b>备注</b>：To be submitted for possible journal publication</p>
  <p><b>关键词</b>：Accented TTS synthesis, Accented TTS, TTS synthesis, accent, standard version</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Accented text-to-speech (TTS) synthesis seeks to generate speech with an
accent (L2) as a variant of the standard version (L1). Accented TTS synthesis
is challenging as L2 is different from L1 in both in terms of phonetic
rendering and prosody pattern. Furthermore, there is no easy solution to the
control of the accent intensity in an utterance. In this work, we propose a
neural TTS architecture, that allows us to control the accent and its intensity
during inference. This is achieved through three novel mechanisms, 1) an accent
variance adaptor to model the complex accent variance with three prosody
controlling factors, namely pitch, energy and duration; 2) an accent intensity
modeling strategy to quantify the accent intensity; 3) a consistency constraint
module to encourage the TTS system to render the expected accent intensity at a
fine level. Experiments show that the proposed system attains superior
performance to the baseline models in terms of accent rendering and intensity
control. To our best knowledge, this is the first study of accented TTS
synthesis with explicit intensity control.</p>
  </details>
</details>
<details>
  <summary>17. <b>标题：Deep Learning Based Page Creation for Improving E-Commerce Organic  Search Traffic</b></summary>
  <p><b>编号</b>：[160]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10792</p>
  <p><b>作者</b>：Cheng Jie,  Da Xu,  Zigeng Wang,  Wei Shen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Organic search comprises, e-commerce companies, comprises a large, large portion, total traffic</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Organic search comprises a large portion of the total traffic for e-commerce
companies. One approach to expand company's exposure on organic search channel
lies on creating landing pages having broader coverage on customer intentions.
In this paper, we present a transformer language model based organic channel
page management system aiming at increasing prominence of the company's overall
clicks on the channel. Our system successfully handles the creation and
deployment process of millions of new landing pages. We show and discuss the
real-world performances of state-of-the-art language representation learning
method, and reveal how we find them as the production-optimal solutions.</p>
  </details>
</details>
<details>
  <summary>18. <b>标题：Homophone Reveals the Truth: A Reality Check for Speech2Vec</b></summary>
  <p><b>编号</b>：[161]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10791</p>
  <p><b>作者</b>：Guangyu Chen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Generating spoken word, possess semantic information, Generating spoken, fascinating topic, possess semantic</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Generating spoken word embeddings that possess semantic information is a
fascinating topic. Compared with text-based embeddings, they cover both
phonetic and semantic characteristics, which can provide richer information and
are potentially helpful for improving ASR and speech translation systems. In
this paper, we review and examine the authenticity of a seminal work in this
field: Speech2Vec. First, a homophone-based inspection method is proposed to
check the speech embeddings released by the author of Speech2Vec. There is no
indication that these embeddings are generated by the Speech2Vec model.
Moreover, through further analysis of the vocabulary composition, we suspect
that a text-based model fabricates these embeddings. Finally, we reproduce the
Speech2Vec model, referring to the official code and optimal settings in the
original paper. Experiments showed that this model failed to learn effective
semantic embeddings. In word similarity benchmarks, it gets a correlation score
of 0.08 in MEN and 0.15 in WS-353-SIM tests, which is over 0.5 lower than those
described in the original paper. Our data and code are available.</p>
  </details>
</details>
<details>
  <summary>19. <b>标题：AIR-JPMC@SMM4H'22: Classifying Self-Reported Intimate Partner Violence  in Tweets with Multiple BERT-based Models</b></summary>
  <p><b>编号</b>：[173]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10763</p>
  <p><b>作者</b>：Alec Candidato,  Akshat Gupta,  Xiaomo Liu,  Sameena Shah</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：intimate partner violence, self-reported intimate partner, intimate partner, partner violence, paper presents</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper presents our submission for the SMM4H 2022-Shared Task on the
classification of self-reported intimate partner violence on Twitter (in
English). The goal of this task was to accurately determine if the contents of
a given tweet demonstrated someone reporting their own experience with intimate
partner violence. The submitted system is an ensemble of five RoBERTa models
each weighted by their respective F1-scores on the validation data-set. This
system performed 13% better than the baseline and was the best performing
system overall for this shared task.</p>
  </details>
</details>
<details>
  <summary>20. <b>标题：INFINITY: A Simple Yet Effective Unsupervised Framework for Graph-Text  Mutual Conversion</b></summary>
  <p><b>编号</b>：[175]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10754</p>
  <p><b>作者</b>：Yi Xu,  Luoyi Fu,  Zhouhan Lin,  Jiexing Qi,  Xinbing Wang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：triple extraction, applying knowledge graphs, constructing and applying, applying knowledge, unsupervised</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Graph-to-text (G2T) generation and text-to-graph (T2G) triple extraction are
two essential tasks for constructing and applying knowledge graphs. Existing
unsupervised approaches turn out to be suitable candidates for jointly learning
the two tasks due to their avoidance of using graph-text parallel data.
However, they are composed of multiple modules and still require both entity
information and relation type in the training process. To this end, we propose
INFINITY, a simple yet effective unsupervised approach that does not require
external annotation tools or additional parallel information. It achieves fully
unsupervised graph-text mutual conversion for the first time. Specifically,
INFINITY treats both G2T and T2G as a bidirectional sequence generation task by
fine-tuning only one pretrained seq2seq model. A novel back-translation-based
framework is then designed to automatically generate continuous synthetic
parallel data. To obtain reasonable graph sequences with structural information
from source texts, INFINITY employs reward-based training loss by leveraging
the advantage of reward augmented maximum likelihood. As a fully unsupervised
framework, INFINITY is empirically verified to outperform state-of-the-art
baselines for G2T and T2G tasks.</p>
  </details>
</details>
<details>
  <summary>21. <b>标题：Dodging the Data Bottleneck: Automatic Subtitling with Automatically  Segmented ST Corpora</b></summary>
  <p><b>编号</b>：[223]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10608</p>
  <p><b>作者</b>：Sara Papi,  Alina Karakanta,  Matteo Negri,  Marco Turchi</p>
  <p><b>备注</b>：Accepted to AACL 2022</p>
  <p><b>关键词</b>：specific displaying guidelines, translating speech data, displaying guidelines, compliant to specific, specific displaying</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Speech translation for subtitling (SubST) is the task of automatically
translating speech data into well-formed subtitles by inserting subtitle breaks
compliant to specific displaying guidelines. Similar to speech translation
(ST), model training requires parallel data comprising audio inputs paired with
their textual translations. In SubST, however, the text has to be also
annotated with subtitle breaks. So far, this requirement has represented a
bottleneck for system development, as confirmed by the dearth of publicly
available SubST corpora. To fill this gap, we propose a method to convert
existing ST corpora into SubST resources without human intervention. We build a
segmenter model that automatically segments texts into proper subtitles by
exploiting audio and text in a multimodal fashion, achieving high segmentation
quality in zero-shot conditions. Comparative experiments with SubST systems
respectively trained on manual and automatic segmentations result in similar
performance, showing the effectiveness of our approach.</p>
  </details>
</details>
<details>
  <summary>22. <b>标题：Representing Affect Information in Word Embeddings</b></summary>
  <p><b>编号</b>：[231]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10583</p>
  <p><b>作者</b>：Yuhan Zhang,  Wenqi Chen,  Ruihan Zhang,  Xiajie Zhang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：natural language processing, natural language understanding, investigating human-like knowledge, human-like knowledge learned, natural language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A growing body of research in natural language processing (NLP) and natural
language understanding (NLU) is investigating human-like knowledge learned or
encoded in the word embeddings from large language models. This is a step
towards understanding what knowledge language models capture that resembles
human understanding of language and communication. Here, we investigated
whether and how the affect meaning of a word (i.e., valence, arousal,
dominance) is encoded in word embeddings pre-trained in large neural networks.
We used the human-labeled dataset as the ground truth and performed various
correlational and classification tests on four types of word embeddings. The
embeddings varied in being static or contextualized, and how much affect
specific information was prioritized during the pre-training and fine-tuning
phase. Our analyses show that word embedding from the vanilla BERT model did
not saliently encode the affect information of English words. Only when the
BERT model was fine-tuned on emotion-related tasks or contained extra
contextualized information from emotion-rich contexts could the corresponding
embedding encode more relevant affect information.</p>
  </details>
</details>
<details>
  <summary>23. <b>标题：Assessing ASR Model Quality on Disordered Speech using BERTScore</b></summary>
  <p><b>编号</b>：[273]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10591</p>
  <p><b>作者</b>：Jimmy Tobin,  Qisheng Li,  Subhashini Venugopalan,  Katie Seaver,  Richard Cave,  Katrin Tomanek</p>
  <p><b>备注</b>：Accepted to Interspeech 2022 Workshop on Speech for Social Good</p>
  <p><b>关键词</b>：Word Error Rate, automatic speech recognition, assess automatic speech, ASR, ASR model</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Word Error Rate (WER) is the primary metric used to assess automatic speech
recognition (ASR) model quality. It has been shown that ASR models tend to have
much higher WER on speakers with speech impairments than typical English
speakers. It is hard to determine if models can be be useful at such high error
rates. This study investigates the use of BERTScore, an evaluation metric for
text generation, to provide a more informative measure of ASR model quality and
usefulness. Both BERTScore and WER were compared to prediction errors manually
annotated by Speech Language Pathologists for error type and assessment.
BERTScore was found to be more correlated with human assessment of error type
and assessment. BERTScore was specifically more robust to orthographic changes
(contraction and normalization errors) where meaning was preserved.
Furthermore, BERTScore was a better fit of error assessment than WER, as
measured using an ordinal logistic regression and the Akaike's Information
Criterion (AIC). Overall, our findings suggest that BERTScore can complement
WER when assessing ASR model performance from a practical perspective,
especially for accessibility applications where models are useful even at lower
accuracy than for typical speech.</p>
  </details>
</details>
<h1>机器学习</h1>
<details>
  <summary>1. <b>标题：NamedMask: Distilling Segmenters from Complementary Foundation Models</b></summary>
  <p><b>编号</b>：[1]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.11228</p>
  <p><b>作者</b>：Gyungin Shin,  Weidi Xie,  Samuel Albanie</p>
  <p><b>备注</b>：Tech report. Code: this https URL</p>
  <p><b>关键词</b>：access to pixel-level, pixel-level labels, CLIP, images, object</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The goal of this work is to segment and name regions of images without access
to pixel-level labels during training. To tackle this task, we construct
segmenters by distilling the complementary strengths of two foundation models.
The first, CLIP (Radford et al. 2021), exhibits the ability to assign names to
image content but lacks an accessible representation of object structure. The
second, DINO (Caron et al. 2021), captures the spatial extent of objects but
has no knowledge of object names. Our method, termed NamedMask, begins by using
CLIP to construct category-specific archives of images. These images are
pseudo-labelled with a category-agnostic salient object detector bootstrapped
from DINO, then refined by category-specific segmenters using the CLIP archive
labels. Thanks to the high quality of the refined masks, we show that a
standard segmentation architecture trained on these archives with appropriate
data augmentation achieves impressive semantic segmentation abilities for both
single-object and multi-object images. As a result, our proposed NamedMask
performs favourably against a range of prior work on five benchmarks including
the VOC2012, COCO and large-scale ImageNet-S datasets.</p>
  </details>
</details>
<details>
  <summary>2. <b>标题：VToonify: Controllable High-Resolution Portrait Video Style Transfer</b></summary>
  <p><b>编号</b>：[2]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.11224</p>
  <p><b>作者</b>：Shuai Yang,  Liming Jiang,  Ziwei Liu,  Chen Change Loy</p>
  <p><b>备注</b>：ACM Transactions on Graphics (SIGGRAPH Asia 2022). Code: this https URL Project page: this https URL</p>
  <p><b>关键词</b>：artistic portrait videos, graphics and vision, portrait video style, important and desirable, desirable task</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Generating high-quality artistic portrait videos is an important and
desirable task in computer graphics and vision. Although a series of successful
portrait image toonification models built upon the powerful StyleGAN have been
proposed, these image-oriented methods have obvious limitations when applied to
videos, such as the fixed frame size, the requirement of face alignment,
missing non-facial details and temporal inconsistency. In this work, we
investigate the challenging controllable high-resolution portrait video style
transfer by introducing a novel VToonify framework. Specifically, VToonify
leverages the mid- and high-resolution layers of StyleGAN to render
high-quality artistic portraits based on the multi-scale content features
extracted by an encoder to better preserve the frame details. The resulting
fully convolutional architecture accepts non-aligned faces in videos of
variable size as input, contributing to complete face regions with natural
motions in the output. Our framework is compatible with existing StyleGAN-based
image toonification models to extend them to video toonification, and inherits
appealing features of these models for flexible style control on color and
intensity. This work presents two instantiations of VToonify built upon Toonify
and DualStyleGAN for collection-based and exemplar-based portrait video style
transfer, respectively. Extensive experimental results demonstrate the
effectiveness of our proposed VToonify framework over existing methods in
generating high-quality and temporally-coherent artistic portrait videos with
flexible style controls.</p>
  </details>
</details>
<details>
  <summary>3. <b>标题：Concept Activation Regions: A Generalized Framework For Concept-Based  Explanations</b></summary>
  <p><b>编号</b>：[4]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.11222</p>
  <p><b>作者</b>：Jonathan Crabbé,  Mihaela van der Schaar</p>
  <p><b>备注</b>：Presented at NeurIPS 2022</p>
  <p><b>关键词</b>：DNN latent space, deep neural network, DNN latent, latent space, DNN</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Concept-based explanations permit to understand the predictions of a deep
neural network (DNN) through the lens of concepts specified by users. Existing
methods assume that the examples illustrating a concept are mapped in a fixed
direction of the DNN's latent space. When this holds true, the concept can be
represented by a concept activation vector (CAV) pointing in that direction. In
this work, we propose to relax this assumption by allowing concept examples to
be scattered across different clusters in the DNN's latent space. Each concept
is then represented by a region of the DNN's latent space that includes these
clusters and that we call concept activation region (CAR). To formalize this
idea, we introduce an extension of the CAV formalism that is based on the
kernel trick and support vector classifiers. This CAR formalism yields global
concept-based explanations and local concept-based feature importance. We prove
that CAR explanations built with radial kernels are invariant under latent
space isometries. In this way, CAR assigns the same explanations to latent
spaces that have the same geometry. We further demonstrate empirically that
CARs offer (1) more accurate descriptions of how concepts are scattered in the
DNN's latent space; (2) global explanations that are closer to human concept
annotations and (3) concept-based feature importance that meaningfully relate
concepts with each other. Finally, we use CARs to show that DNNs can
autonomously rediscover known scientific concepts, such as the prostate cancer
grading system.</p>
  </details>
</details>
<details>
  <summary>4. <b>标题：Sampling is as easy as learning the score: theory for diffusion models  with minimal data assumptions</b></summary>
  <p><b>编号</b>：[6]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.11215</p>
  <p><b>作者</b>：Sitan Chen,  Sinho Chewi,  Jerry Li,  Yuanzhi Li,  Adil Salim,  Anru R. Zhang</p>
  <p><b>备注</b>：30 pages</p>
  <p><b>关键词</b>：score-based generative models, real-world generative models, large-scale real-world generative, generative models, diffusion probabilistic models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We provide theoretical convergence guarantees for score-based generative
models (SGMs) such as denoising diffusion probabilistic models (DDPMs), which
constitute the backbone of large-scale real-world generative models such as
DALL$\cdot$E 2. Our main result is that, assuming accurate score estimates,
such SGMs can efficiently sample from essentially any realistic data
distribution. In contrast to prior works, our results (1) hold for an
$L^2$-accurate score estimate (rather than $L^\infty$-accurate); (2) do not
require restrictive functional inequality conditions that preclude substantial
non-log-concavity; (3) scale polynomially in all relevant problem parameters;
and (4) match state-of-the-art complexity guarantees for discretization of the
Langevin diffusion, provided that the score error is sufficiently small. We
view this as strong theoretical justification for the empirical success of
SGMs. We also examine SGMs based on the critically damped Langevin diffusion
(CLD). Contrary to conventional wisdom, we provide evidence that the use of the
CLD does not reduce the complexity of SGMs.</p>
  </details>
</details>
<details>
  <summary>5. <b>标题：A Closer Look at Learned Optimization: Stability, Robustness, and  Inductive Biases</b></summary>
  <p><b>编号</b>：[10]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.11208</p>
  <p><b>作者</b>：James Harrison,  Luke Metz,  Jascha Sohl-Dickstein</p>
  <p><b>备注</b>：NeurIPS 2022</p>
  <p><b>关键词</b>：machine learning models, dramatically accelerate training, trained to act, potential to dramatically, dramatically accelerate</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Learned optimizers -- neural networks that are trained to act as optimizers
-- have the potential to dramatically accelerate training of machine learning
models. However, even when meta-trained across thousands of tasks at huge
computational expense, blackbox learned optimizers often struggle with
stability and generalization when applied to tasks unlike those in their
meta-training set. In this paper, we use tools from dynamical systems to
investigate the inductive biases and stability properties of optimization
algorithms, and apply the resulting insights to designing inductive biases for
blackbox optimizers. Our investigation begins with a noisy quadratic model,
where we characterize conditions in which optimization is stable, in terms of
eigenvalues of the training dynamics. We then introduce simple modifications to
a learned optimizer's architecture and meta-training procedure which lead to
improved stability, and improve the optimizer's inductive bias. We apply the
resulting learned optimizer to a variety of neural network training tasks,
where it outperforms the current state of the art learned optimizer -- at
matched optimizer computational overhead -- with regard to optimization
performance and meta-training speed, and is capable of generalization to tasks
far different from those it was meta-trained on.</p>
  </details>
</details>
<details>
  <summary>6. <b>标题：Layer Freezing & Data Sieving: Missing Pieces of a Generic Framework for  Sparse Training</b></summary>
  <p><b>编号</b>：[11]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.11204</p>
  <p><b>作者</b>：Geng Yuan,  Yanyu Li,  Sheng Li,  Zhenglun Kong,  Sergey Tulyakov,  Xulong Tang,  Yanzhi Wang,  Jian Ren</p>
  <p><b>备注</b>：Published in 36th Conference on Neural Information Processing Systems (NeurIPS 2022)</p>
  <p><b>关键词</b>：efficient deep learning, training, sparse training, training costs, layer freezing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recently, sparse training has emerged as a promising paradigm for efficient
deep learning on edge devices. The current research mainly devotes efforts to
reducing training costs by further increasing model sparsity. However,
increasing sparsity is not always ideal since it will inevitably introduce
severe accuracy degradation at an extremely high sparsity level. This paper
intends to explore other possible directions to effectively and efficiently
reduce sparse training costs while preserving accuracy. To this end, we
investigate two techniques, namely, layer freezing and data sieving. First, the
layer freezing approach has shown its success in dense model training and
fine-tuning, yet it has never been adopted in the sparse training domain.
Nevertheless, the unique characteristics of sparse training may hinder the
incorporation of layer freezing techniques. Therefore, we analyze the
feasibility and potentiality of using the layer freezing technique in sparse
training and find it has the potential to save considerable training costs.
Second, we propose a data sieving method for dataset-efficient training, which
further reduces training costs by ensuring only a partial dataset is used
throughout the entire training process. We show that both techniques can be
well incorporated into the sparse training algorithm to form a generic
framework, which we dub SpFDE. Our extensive experiments demonstrate that SpFDE
can significantly reduce training costs while preserving accuracy from three
dimensions: weight sparsity, layer freezing, and dataset sieving.</p>
  </details>
</details>
<details>
  <summary>7. <b>标题：Poisson Flow Generative Models</b></summary>
  <p><b>编号</b>：[22]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.11178</p>
  <p><b>作者</b>：Yilun Xu,  Ziming Liu,  Max Tegmark,  Tommi Jaakkola</p>
  <p><b>备注</b>：Accepted by NeurIPS 2022</p>
  <p><b>关键词</b>：high-dimensional electric field, Poisson flow, Poisson equation, electric field, data distribution</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose a new "Poisson flow" generative model (PFGM) that maps a uniform
distribution on a high-dimensional hemisphere into any data distribution. We
interpret the data points as electrical charges on the $z=0$ hyperplane in a
space augmented with an additional dimension $z$, generating a high-dimensional
electric field (the gradient of the solution to Poisson equation). We prove
that if these charges flow upward along electric field lines, their initial
distribution in the $z=0$ plane transforms into a distribution on the
hemisphere of radius $r$ that becomes uniform in the $r \to\infty$ limit. To
learn the bijective transformation, we estimate the normalized field in the
augmented space. For sampling, we devise a backward ODE that is anchored by the
physically meaningful additional dimension: the samples hit the unaugmented
data manifold when the $z$ reaches zero. Experimentally, PFGM achieves current
state-of-the-art performance among the normalizing flow models on CIFAR-10,
with an Inception score of $9.68$ and a FID score of $2.48$. It also performs
on par with the state-of-the-art SDE approaches while offering $10\times $ to
$20 \times$ acceleration on image generation tasks. Additionally, PFGM appears
more tolerant of estimation errors on a weaker network architecture and robust
to the step size in the Euler method. The code is available at
this https URL .</p>
  </details>
</details>
<details>
  <summary>8. <b>标题：A Generalist Neural Algorithmic Learner</b></summary>
  <p><b>编号</b>：[29]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.11142</p>
  <p><b>作者</b>：Borja Ibarz,  Vitaly Kurin,  George Papamakarios,  Kyriacos Nikiforou,  Mehdi Bennani,  Róbert Csordás,  Andrew Dudzik,  Matko Bošnjak,  Alex Vitvitskyi,  Yulia Rubanova,  Andreea Deac,  Beatrice Bevilacqua,  Yaroslav Ganin,  Charles Blundell,  Petar Veličković</p>
  <p><b>备注</b>：20 pages, 10 figures</p>
  <p><b>关键词</b>：solve algorithmic tasks, neural algorithmic reasoning, ability to solve, specialist models, algorithmic tasks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The cornerstone of neural algorithmic reasoning is the ability to solve
algorithmic tasks, especially in a way that generalises out of distribution.
While recent years have seen a surge in methodological improvements in this
area, they mostly focused on building specialist models. Specialist models are
capable of learning to neurally execute either only one algorithm or a
collection of algorithms with identical control-flow backbone. Here, instead,
we focus on constructing a generalist neural algorithmic learner -- a single
graph neural network processor capable of learning to execute a wide range of
algorithms, such as sorting, searching, dynamic programming, path-finding and
geometry. We leverage the CLRS benchmark to empirically show that, much like
recent successes in the domain of perception, generalist algorithmic learners
can be built by "incorporating" knowledge. That is, it is possible to
effectively learn algorithms in a multi-task manner, so long as we can learn to
execute them well in a single-task regime. Motivated by this, we present a
series of improvements to the input representation, training regime and
processor architecture over CLRS, improving average single-task performance by
over 20% from prior art. We then conduct a thorough ablation of multi-task
learners leveraging these improvements. Our results demonstrate a generalist
learner that effectively incorporates knowledge captured by specialist models.</p>
  </details>
</details>
<details>
  <summary>9. <b>标题：PACT: Perception-Action Causal Transformer for Autoregressive Robotics  Pre-Training</b></summary>
  <p><b>编号</b>：[33]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.11133</p>
  <p><b>作者</b>：Rogerio Bonatti,  Sai Vemprala,  Shuang Ma,  Felipe Frujeri,  Shuhang Chen,  Ashish Kapoor</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：require significant human, significant human expertise, Robotics has long, modules and connections, traditional or learning-based</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Robotics has long been a field riddled with complex systems architectures
whose modules and connections, whether traditional or learning-based, require
significant human expertise and prior knowledge. Inspired by large pre-trained
language models, this work introduces a paradigm for pre-training a general
purpose representation that can serve as a starting point for multiple tasks on
a given robot. We present the Perception-Action Causal Transformer (PACT), a
generative transformer-based architecture that aims to build representations
directly from robot data in a self-supervised fashion. Through autoregressive
prediction of states and actions over time, our model implicitly encodes
dynamics and behaviors for a particular robot. Our experimental evaluation
focuses on the domain of mobile agents, where we show that this robot-specific
representation can function as a single starting point to achieve distinct
tasks such as safe navigation, localization and mapping. We evaluate two form
factors: a wheeled robot that uses a LiDAR sensor as perception input (MuSHR),
and a simulated agent that uses first-person RGB images (Habitat). We show that
finetuning small task-specific networks on top of the larger pretrained model
results in significantly better performance compared to training a single model
from scratch for all tasks simultaneously, and comparable performance to
training a separate large model for each task independently. By sharing a
common good-quality representation across tasks we can lower overall model
capacity and speed up the real-time deployment of such systems.</p>
  </details>
</details>
<details>
  <summary>10. <b>标题：A Bibliographic View on Constrained Clustering</b></summary>
  <p><b>编号</b>：[35]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.11125</p>
  <p><b>作者</b>：Ludmila Kuncheva,  Francis Williams,  Samuel Hennessey</p>
  <p><b>备注</b>：18 pages, 11 figures, 177 references</p>
  <p><b>关键词</b>：keyword search, search on constrained, constrained clustering, documents, ran automatic analyses</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A keyword search on constrained clustering on Web-of-Science returned just
under 3,000 documents. We ran automatic analyses of those, and compiled our own
bibliography of 183 papers which we analysed in more detail based on their
topic and experimental study, if any. This paper presents general trends of the
area and its sub-topics by Pareto analysis, using citation count and year of
publication. We list available software and analyse the experimental sections
of our reference collection. We found a notable lack of large comparison
experiments. Among the topics we reviewed, applications studies were most
abundant recently, alongside deep learning, active learning and ensemble
learning.</p>
  </details>
</details>
<details>
  <summary>11. <b>标题：Modern Machine Learning Tools for Monitoring and Control of Industrial  Processes: A Survey</b></summary>
  <p><b>编号</b>：[36]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.11123</p>
  <p><b>作者</b>：R. Bhushan Gopaluni,  Aditya Tulsyan,  Benoit Chachuat,  Biao Huang,  Jong Min Lee,  Faraz Amjad,  Seshu Kumar Damarla,  Jong Woo Kim,  Nathan P. Lawrence</p>
  <p><b>备注</b>：IFAC World Congress 2020</p>
  <p><b>关键词</b>：major theoretical advances, ten years, industrial data, tremendous improvement, computational power</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Over the last ten years, we have seen a significant increase in industrial
data, tremendous improvement in computational power, and major theoretical
advances in machine learning. This opens up an opportunity to use modern
machine learning tools on large-scale nonlinear monitoring and control
problems. This article provides a survey of recent results with applications in
the process industry.</p>
  </details>
</details>
<details>
  <summary>12. <b>标题：Uncertainty-aware Perception Models for Off-road Autonomous Unmanned  Ground Vehicles</b></summary>
  <p><b>编号</b>：[38]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.11115</p>
  <p><b>作者</b>：Zhaoyuan Yang,  Yewteck Tan,  Shiraj Sen,  Johan Reimann,  John Karigiannis,  Mohammed Yousefhussien,  Nurali Virani</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：unmanned ground vehicles, deliver crucial supplies, autonomous unmanned ground, Off-road autonomous unmanned, ground vehicles</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Off-road autonomous unmanned ground vehicles (UGVs) are being developed for
military and commercial use to deliver crucial supplies in remote locations,
help with mapping and surveillance, and to assist war-fighters in contested
environments. Due to complexity of the off-road environments and variability in
terrain, lighting conditions, diurnal and seasonal changes, the models used to
perceive the environment must handle a lot of input variability. Current
datasets used to train perception models for off-road autonomous navigation
lack of diversity in seasons, locations, semantic classes, as well as time of
day. We test the hypothesis that model trained on a single dataset may not
generalize to other off-road navigation datasets and new locations due to the
input distribution drift. Additionally, we investigate how to combine multiple
datasets to train a semantic segmentation-based environment perception model
and we show that training the model to capture uncertainty could improve the
model performance by a significant margin. We extend the Masksembles approach
for uncertainty quantification to the semantic segmentation task and compare it
with Monte Carlo Dropout and standard baselines. Finally, we test the approach
against data collected from a UGV platform in a new testing environment. We
show that the developed perception model with uncertainty quantification can be
feasibly deployed on an UGV to support online perception and navigation tasks.</p>
  </details>
</details>
<details>
  <summary>13. <b>标题：CMGAN: Conformer-Based Metric-GAN for Monaural Speech Enhancement</b></summary>
  <p><b>编号</b>：[40]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.11112</p>
  <p><b>作者</b>：Sherif Abdulatif,  Ruizhe Cao,  Bin Yang</p>
  <p><b>备注</b>：16 pages, 10 figures and 5 tables. arXiv admin note: text overlap with arXiv:2203.15149</p>
  <p><b>关键词</b>：automatic speech recognition, Convolution-augmented transformers, speech-domain applications, recently proposed, capture both local</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Convolution-augmented transformers (Conformers) are recently proposed in
various speech-domain applications, such as automatic speech recognition (ASR)
and speech separation, as they can capture both local and global dependencies.
In this paper, we propose a conformer-based metric generative adversarial
network (CMGAN) for speech enhancement (SE) in the time-frequency (TF) domain.
The generator encodes the magnitude and complex spectrogram information using
two-stage conformer blocks to model both time and frequency dependencies. The
decoder then decouples the estimation into a magnitude mask decoder branch to
filter out unwanted distortions and a complex refinement branch to further
improve the magnitude estimation and implicitly enhance the phase information.
Additionally, we include a metric discriminator to alleviate metric mismatch by
optimizing the generator with respect to a corresponding evaluation score.
Objective and subjective evaluations illustrate that CMGAN is able to show
superior performance compared to state-of-the-art methods in three speech
enhancement tasks (denoising, dereverberation and super-resolution). For
instance, quantitative denoising analysis on Voice Bank+DEMAND dataset
indicates that CMGAN outperforms various previous models with a margin, i.e.,
PESQ of 3.41 and SSNR of 11.10 dB.</p>
  </details>
</details>
<details>
  <summary>14. <b>标题：Deep Learning on Home Drone: Searching for the Optimal Architecture</b></summary>
  <p><b>编号</b>：[59]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.11064</p>
  <p><b>作者</b>：Alaa Maalouf,  Yotam Gurfinkel,  Barak Diker,  Oren Gal,  Daniela Rus,  Dan Feldman</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：DJI Tello toy-drone, runs real-time semantic, real-time semantic segmentation, commercial DJI Tello, semantic segmentation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We suggest the first system that runs real-time semantic segmentation via
deep learning on a weak micro-computer such as the Raspberry Pi Zero v2 (whose
price was \$15) attached to a toy-drone. In particular, since the Raspberry Pi
weighs less than $16$ grams, and its size is half of a credit card, we could
easily attach it to the common commercial DJI Tello toy-drone (<\$100, 41 98 <90 grams, $\times$ 92.5 mm). the result is an autonomous drone (no laptop nor human in loop) that can detect and classify objects real-time from a video stream of on-board monocular rgb camera gps or lidar sensors). companion videos demonstrate how this tello scans lab for people (e.g. use firefighters security forces) empty parking slot outside lab. existing deep learning solutions are either much too slow computation on such iot devices, provide results impractical quality. our main challenge was to design system takes best all worlds among numerous combinations networks, platforms frameworks, compression techniques, ratios. end, we efficient searching algorithm aims find optimal combination which tradeoff between network running time its accuracy performance.< p>
  </\$100,></p></details>
</details>
<details>
  <summary>15. <b>标题：Inverted Landing in a Small Aerial Robot via Deep Reinforcement Learning  for Triggering and Control of Rotational Maneuvers</b></summary>
  <p><b>编号</b>：[65]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.11043</p>
  <p><b>作者</b>：Bryan Habas,  Jack W. Langelaan,  Bo Cheng</p>
  <p><b>备注</b>：8 pages, 6 Figures, Submitted for ICRA 2023 Conference (Pending Review)</p>
  <p><b>关键词</b>：sensing and computation, aerial robots, landing, Inverted landing, utilized Deep Reinforcement</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Inverted landing in a rapid and robust manner is a challenging feat for
aerial robots, especially while depending entirely on onboard sensing and
computation. In spite of this, this feat is routinely performed by biological
fliers such as bats, flies, and bees. Our previous work has identified a direct
causal connection between a series of onboard visual cues and kinematic actions
that allow for reliable execution of this challenging aerobatic maneuver in
small aerial robots. In this work, we first utilized Deep Reinforcement
Learning and a physics-based simulation to obtain a general, optimal control
policy for robust inverted landing starting from any arbitrary approach
condition. This optimized control policy provides a computationally-efficient
mapping from the system's observational space to its motor command action
space, including both triggering and control of rotational maneuvers. This was
done by training the system over a large range of approach flight velocities
that varied with magnitude and direction.
Next, we performed a sim-to-real transfer and experimental validation of the
learned policy via domain randomization, by varying the robot's inertial
parameters in the simulation. Through experimental trials, we identified
several dominant factors which greatly improved landing robustness and the
primary mechanisms that determined inverted landing success. We expect the
learning framework developed in this study can be generalized to solve more
challenging tasks, such as utilizing noisy onboard sensory data, landing on
surfaces of various orientations, or landing on dynamically-moving surfaces.</p>
  </details>
</details>
<details>
  <summary>16. <b>标题：Counterfactual Explanations Using Optimization With Constraint Learning</b></summary>
  <p><b>编号</b>：[80]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10997</p>
  <p><b>作者</b>：Donato Maragno,  Tabea E. Röber,  Ilker Birbil</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：receive increasing attention, machine learning community, Counterfactual explanations, interpretability techniques, techniques that receive</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Counterfactual explanations embody one of the many interpretability
techniques that receive increasing attention from the machine learning
community. Their potential to make model predictions more sensible to the user
is considered to be invaluable. To increase their adoption in practice, several
criteria that counterfactual explanations should adhere to have been put
forward in the literature. We propose counterfactual explanations using
optimization with constraint learning (CE-OCL), a generic and flexible approach
that addresses all these criteria and allows room for further extensions.
Specifically, we discuss how we can leverage an optimization with constraint
learning framework for the generation of counterfactual explanations, and how
components of this framework readily map to the criteria. We also propose two
novel modeling approaches to address data manifold closeness and diversity,
which are two key criteria for practical counterfactual explanations. We test
CE-OCL on several datasets and present our results in a case study. Compared
against the current state-of-the-art methods, CE-OCL allows for more
flexibility and has an overall superior performance in terms of several
evaluation metrics proposed in related work.</p>
  </details>
</details>
<details>
  <summary>17. <b>标题：Identifiability and generalizability from multiple experts in Inverse  Reinforcement Learning</b></summary>
  <p><b>编号</b>：[85]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10974</p>
  <p><b>作者</b>：Paul Rolland,  Luca Viano,  Norman Schuerhoff,  Boris Nikolov,  Volkan Cevher</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Inverse Reinforcement Learning, Reinforcement Learning, Inverse Reinforcement, Learning, reward function</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>While Reinforcement Learning (RL) aims to train an agent from a reward
function in a given environment, Inverse Reinforcement Learning (IRL) seeks to
recover the reward function from observing an expert's behavior. It is well
known that, in general, various reward functions can lead to the same optimal
policy, and hence, IRL is ill-defined. However, (Cao et al., 2021) showed that,
if we observe two or more experts with different discount factors or acting in
different environments, the reward function can under certain conditions be
identified up to a constant. This work starts by showing an equivalent
identifiability statement from multiple experts in tabular MDPs based on a rank
condition, which is easily verifiable and is shown to be also necessary. We
then extend our result to various different scenarios, i.e., we characterize
reward identifiability in the case where the reward function can be represented
as a linear combination of given features, making it more interpretable, or
when we have access to approximate transition matrices. Even when the reward is
not identifiable, we provide conditions characterizing when data on multiple
experts in a given environment allows to generalize and train an optimal agent
in a new environment. Our theoretical results on reward identifiability and
generalizability are validated in various numerical experiments.</p>
  </details>
</details>
<details>
  <summary>18. <b>标题：Proximal Point Imitation Learning</b></summary>
  <p><b>编号</b>：[88]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10968</p>
  <p><b>作者</b>：Luca Viano,  Angeliki Kamoutsi,  Gergely Neu,  Igor Krawczuk,  Volkan Cevher</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：horizon imitation learning, restrictive coherence assumptions, infinite horizon imitation, rigorous efficiency guarantees, imitation learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This work develops new algorithms with rigorous efficiency guarantees for
infinite horizon imitation learning (IL) with linear function approximation
without restrictive coherence assumptions. We begin with the minimax
formulation of the problem and then outline how to leverage classical tools
from optimization, in particular, the proximal-point method (PPM) and dual
smoothing, for online and offline IL, respectively. Thanks to PPM, we avoid
nested policy evaluation and cost updates for online IL appearing in the prior
literature. In particular, we do away with the conventional alternating updates
by the optimization of a single convex and smooth objective over both cost and
Q-functions. When solved inexactly, we relate the optimization errors to the
suboptimality of the recovered policy. As an added bonus, by re-interpreting
PPM as dual smoothing with the expert policy as a center point, we also obtain
an offline IL algorithm enjoying theoretical guarantees in terms of required
expert trajectories. Finally, we achieve convincing empirical performance for
both linear and neural network function approximation.</p>
  </details>
</details>
<details>
  <summary>19. <b>标题：XClusters: Explainability-first Clustering</b></summary>
  <p><b>编号</b>：[92]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10956</p>
  <p><b>作者</b>：Hyunseung Hwang,  Steven Euijong Whang</p>
  <p><b>备注</b>：11 pages</p>
  <p><b>关键词</b>：first-class citizen, decision tree, clustering, decision, explainability-first clustering</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We study the problem of explainability-first clustering where explainability
becomes a first-class citizen for clustering. Previous clustering approaches
use decision trees for explanation, but only after the clustering is completed.
In contrast, our approach is to perform clustering and decision tree training
holistically where the decision tree's performance and size also influence the
clustering results. We assume the attributes for clustering and explaining are
distinct, although this is not necessary. We observe that our problem is a
monotonic optimization where the objective function is a difference of
monotonic functions. We then propose an efficient branch-and-bound algorithm
for finding the best parameters that lead to a balance of cluster distortion
and decision tree explainability. Our experiments show that our method can
improve the explainability of any clustering that fits in our framework.</p>
  </details>
</details>
<details>
  <summary>20. <b>标题：Implementing and Experimenting with Diffusion Models for Text-to-Image  Generation</b></summary>
  <p><b>编号</b>：[95]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10948</p>
  <p><b>作者</b>：Robin Zbinden</p>
  <p><b>备注</b>：Master's Thesis</p>
  <p><b>关键词</b>：general public attention, models, Taking advantage, deep learning, public attention</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Taking advantage of the many recent advances in deep learning, text-to-image
generative models currently have the merit of attracting the general public
attention. Two of these models, DALL-E 2 and Imagen, have demonstrated that
highly photorealistic images could be generated from a simple textual
description of an image. Based on a novel approach for image generation called
diffusion models, text-to-image models enable the production of many different
types of high resolution images, where human imagination is the only limit.
However, these models require exceptionally large amounts of computational
resources to train, as well as handling huge datasets collected from the
internet. In addition, neither the codebase nor the models have been released.
It consequently prevents the AI community from experimenting with these
cutting-edge models, making the reproduction of their results complicated, if
not impossible.
In this thesis, we aim to contribute by firstly reviewing the different
approaches and techniques used by these models, and then by proposing our own
implementation of a text-to-image model. Highly based on DALL-E 2, we introduce
several slight modifications to tackle the high computational cost induced. We
thus have the opportunity to experiment in order to understand what these
models are capable of, especially in a low resource regime. In particular, we
provide additional and analyses deeper than the ones performed by the authors
of DALL-E 2, including ablation studies.
Besides, diffusion models use so-called guidance methods to help the
generating process. We introduce a new guidance method which can be used in
conjunction with other guidance methods to improve image quality. Finally, the
images generated by our model are of reasonably good quality, without having to
sustain the significant training costs of state-of-the-art text-to-image
models.</p>
  </details>
</details>
<details>
  <summary>21. <b>标题：Making Byzantine Decentralized Learning Efficient</b></summary>
  <p><b>编号</b>：[102]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10931</p>
  <p><b>作者</b>：Sadegh Farhadkhani,  Rachid Guerraoui,  Nirupam Gupta,  Lê Nguyên Hoang,  Rafael Pinot,  John Stephan</p>
  <p><b>备注</b>：63 pages,5 figures</p>
  <p><b>关键词</b>：distributes heavy learning, Byzantine resilience, Byzantine, heavy learning tasks, distributes heavy</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Decentralized-SGD (D-SGD) distributes heavy learning tasks across multiple
machines (a.k.a., {\em nodes}), effectively dividing the workload per node by
the size of the system. However, a handful of \emph{Byzantine} (i.e.,
misbehaving) nodes can jeopardize the entire learning procedure. This
vulnerability is further amplified when the system is \emph{asynchronous}.
Although approaches that confer Byzantine resilience to D-SGD have been
proposed, these significantly impact the efficiency of the process to the point
of even negating the benefit of decentralization. This naturally raises the
question: \emph{can decentralized learning simultaneously enjoy Byzantine
resilience and reduced workload per node?}
We answer positively by proposing \newalgorithm{} that ensures Byzantine
resilience without losing the computational efficiency of D-SGD. Essentially,
\newalgorithm{} weakens the impact of Byzantine nodes by reducing the variance
in local updates using \emph{Polyak's momentum}. Then, by establishing
coordination between nodes via {\em signed echo broadcast} and a {\em
nearest-neighbor averaging} scheme, we effectively tolerate Byzantine nodes
whilst distributing the overhead amongst the non-Byzantine nodes. To
demonstrate the correctness of our algorithm, we introduce and analyze a novel
{\em Lyapunov function} that accounts for the {\em non-Markovian model drift}
arising from the use of momentum. We also demonstrate the efficiency of
\newalgorithm{} through experiments on several image classification tasks.</p>
  </details>
</details>
<details>
  <summary>22. <b>标题：Equivariant Transduction through Invariant Alignment</b></summary>
  <p><b>编号</b>：[105]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10926</p>
  <p><b>作者</b>：Jennifer C. White,  Ryan Cotterell</p>
  <p><b>备注</b>：Accepted at COLING 2022</p>
  <p><b>关键词</b>：potentially infinite number, number of words, infinite number, number of sentences, finite number</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The ability to generalize compositionally is key to understanding the
potentially infinite number of sentences that can be constructed in a human
language from only a finite number of words. Investigating whether NLP models
possess this ability has been a topic of interest: SCAN (Lake and Baroni, 2018)
is one task specifically proposed to test for this property. Previous work has
achieved impressive empirical results using a group-equivariant neural network
that naturally encodes a useful inductive bias for SCAN (Gordon et al., 2020).
Inspired by this, we introduce a novel group-equivariant architecture that
incorporates a group-invariant hard alignment mechanism. We find that our
network's structure allows it to develop stronger equivariance properties than
existing group-equivariant approaches. We additionally find that it outperforms
previous group-equivariant networks empirically on the SCAN task. Our results
suggest that integrating group-equivariance into a variety of neural
architectures is a potentially fruitful avenue of research, and demonstrate the
value of careful analysis of the theoretical properties of such architectures.</p>
  </details>
</details>
<details>
  <summary>23. <b>标题：CAMRI Loss: Improving Recall of a Specific Class without Sacrificing  Accuracy</b></summary>
  <p><b>编号</b>：[107]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10920</p>
  <p><b>作者</b>：Daiki Nishiyama,  Kazuto Fukuchi,  Youhei Akimoto,  Jun Sakuma</p>
  <p><b>备注</b>：2022 International Joint Conference on Neural Networks (IJCNN 2022)</p>
  <p><b>关键词</b>：important class, multi-class classification models, important, loss, class</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In real-world applications of multi-class classification models,
misclassification in an important class (e.g., stop sign) can be significantly
more harmful than in other classes (e.g., speed limit). In this paper, we
propose a loss function that can improve the recall of an important class while
maintaining the same level of accuracy as the case using cross-entropy loss.
For our purpose, we need to make the separation of the important class better
than the other classes. However, existing methods that give a class-sensitive
penalty for cross-entropy loss do not improve the separation. On the other
hand, the method that gives a margin to the angle between the feature vectors
and the weight vectors of the last fully connected layer corresponding to each
feature can improve the separation. Therefore, we propose a loss function that
can improve the separation of the important class by setting the margin only
for the important class, called Class-sensitive Additive Angular Margin Loss
(CAMRI Loss). CAMRI loss is expected to reduce the variance of angles between
features and weights of the important class relative to other classes due to
the margin around the important class in the feature space by adding a penalty
to the angle. In addition, concentrating the penalty only on the important
classes hardly sacrifices the separation of the other classes. Experiments on
CIFAR-10, GTSRB, and AwA2 showed that the proposed method could improve up to
9% recall improvement on cross-entropy loss without sacrificing accuracy.</p>
  </details>
</details>
<details>
  <summary>24. <b>标题：Vanilla feedforward neural networks as a discretization of dynamic  systems</b></summary>
  <p><b>编号</b>：[112]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10909</p>
  <p><b>作者</b>：Yifei Duan,  Li'ang Li,  Guanghua Ji,  Yongqiang Cai</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：made significant applications, dynamic systems, data science, natural science, learning has made</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep learning has made significant applications in the field of data science
and natural science. Some studies have linked deep neural networks to dynamic
systems, but the network structure is restricted to the residual network. It is
known that residual networks can be regarded as a numerical discretization of
dynamic systems. In this paper, we back to the classical network structure and
prove that the vanilla feedforward networks could also be a numerical
discretization of dynamic systems, where the width of the network is equal to
the dimension of the input and output. Our proof is based on the properties of
the leaky-ReLU function and the numerical technique of splitting method to
solve differential equations. Our results could provide a new perspective for
understanding the approximation properties of feedforward neural networks.</p>
  </details>
</details>
<details>
  <summary>25. <b>标题：Pretraining the Vision Transformer using self-supervised methods for  vision based Deep Reinforcement Learning</b></summary>
  <p><b>编号</b>：[116]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10901</p>
  <p><b>作者</b>：Manuel Goulão,  Arlindo L. Oliveira</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：dethroned convolution-based networks, Convolutional Neural Networks, Vision Transformer architecture, Vision Transformer, convolution-based networks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The Vision Transformer architecture has shown to be competitive in the
computer vision (CV) space where it has dethroned convolution-based networks in
several benchmarks. Nevertheless, Convolutional Neural Networks (CNN) remain
the preferential architecture for the representation module in Reinforcement
Learning. In this work, we study pretraining a Vision Transformer using several
state-of-the-art self-supervised methods and assess data-efficiency gains from
this training framework. We propose a new self-supervised learning method
called TOV-VICReg that extends VICReg to better capture temporal relations
between observations by adding a temporal order verification task. Furthermore,
we evaluate the resultant encoders with Atari games in a sample-efficiency
regime. Our results show that the vision transformer, when pretrained with
TOV-VICReg, outperforms the other self-supervised methods but still struggles
to overcome a CNN. Nevertheless, we were able to outperform a CNN in two of the
ten games where we perform a 100k steps evaluation. Ultimately, we believe that
such approaches in Deep Reinforcement Learning (DRL) might be the key to
achieving new levels of performance as seen in natural language processing and
computer vision. Source code will be available at:
this https URL</p>
  </details>
</details>
<details>
  <summary>26. <b>标题：mini-ELSA: using Machine Learning to improve space efficiency in Edge  Lightweight Searchable Attribute-based encryption for Industry 4.0</b></summary>
  <p><b>编号</b>：[119]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10896</p>
  <p><b>作者</b>：Jawhara Aljabri,  Anna Lito Michala,  Jeremy Singer,  Ioannis Vourganas</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Lightweight Searchable Attribute-based, Searchable Attribute-based encryption, Edge Lightweight Searchable, Lightweight Searchable, Searchable Attribute-based</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In previous work a novel Edge Lightweight Searchable Attribute-based
encryption (ELSA) method was proposed to support Industry 4.0 and specifically
Industrial Internet of Things applications. In this paper, we aim to improve
ELSA by minimising the lookup table size and summarising the data records by
integrating Machine Learning (ML) methods suitable for execution at the edge.
This integration will eliminate records of unnecessary data by evaluating added
value to further processing. Thus, resulting in the minimization of both the
lookup table size, the cloud storage and the network traffic taking full
advantage of the edge architecture benefits. We demonstrate our mini-ELSA
expanded method on a well-known power plant dataset. Our results demonstrate a
reduction of storage requirements by 21% while improving execution time by
1.27x.</p>
  </details>
</details>
<details>
  <summary>27. <b>标题：Amortized Variational Inference: Towards the Mathematical Foundation and  Review</b></summary>
  <p><b>编号</b>：[121]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10888</p>
  <p><b>作者</b>：Ankush Ganguly,  Sanjana Jain,  Ukrit Watchareeruetai</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：statistical inference problem, Variational Inference, tractable optimization problem, inference problem, principle of Variational</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The core principle of Variational Inference (VI) is to convert the
statistical inference problem of computing complex posterior probability
densities into a tractable optimization problem. This property enables VI to be
faster than several sampling-based techniques. However, the traditional VI
algorithm is not scalable to large data sets and is unable to readily infer
out-of-bounds data points without re-running the optimization process. Recent
developments in the field, like stochastic-, black box- and amortized-VI, have
helped address these issues. Generative modeling tasks nowadays widely make use
of amortized VI for its efficiency and scalability, as it utilizes a
parameterized function to learn the approximate posterior density parameters.
With this paper, we review the mathematical foundations of various VI
techniques to form the basis for understanding amortized VI. Additionally, we
provide an overview of the recent trends that address several issues of
amortized VI, such as the amortization gap, generalization issues, inconsistent
representation learning, and posterior collapse. Finally, we analyze alternate
divergence measures that improve VI optimization.</p>
  </details>
</details>
<details>
  <summary>28. <b>标题：Non-Negative Matrix Factorization with Scale Data Structure Preservation</b></summary>
  <p><b>编号</b>：[124]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10881</p>
  <p><b>作者</b>：Rachid Hedjam,  Abdelhamid Abdesselam,  Abderrahmane Rahiche,  Mohamed Cheriet</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：factorization methods designed, non-negative matrix factorization, matrix factorization methods, dimension reduction, matrix factorization</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The model described in this paper belongs to the family of non-negative
matrix factorization methods designed for data representation and dimension
reduction. In addition to preserving the data positivity property, it aims also
to preserve the structure of data during matrix factorization. The idea is to
add, to the NMF cost function, a penalty term to impose a scale relationship
between the pairwise similarity matrices of the original and transformed data
points. The solution of the new model involves deriving a new parametrized
update scheme for the coefficient matrix, which makes it possible to improve
the quality of reduced data when used for clustering and classification. The
proposed clustering algorithm is compared to some existing NMF-based algorithms
and to some manifold learning-based algorithms when applied to some real-life
datasets. The obtained results show the effectiveness of the proposed
algorithm.</p>
  </details>
</details>
<details>
  <summary>29. <b>标题：Improving Attention-Based Interpretability of Text Classification  Transformers</b></summary>
  <p><b>编号</b>：[125]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10876</p>
  <p><b>作者</b>：Nikolaos Mylonas,  Ioannis Mollas,  Grigorios Tsoumakas</p>
  <p><b>备注</b>：13 pages, 6 figures, 6 tables, to be submitted to conference</p>
  <p><b>关键词</b>：consistently achieve, NLP, Transformers, performance, rich linguistic relations</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Transformers are widely used in NLP, where they consistently achieve
state-of-the-art performance. This is due to their attention-based
architecture, which allows them to model rich linguistic relations between
words. However, transformers are difficult to interpret. Being able to provide
reasoning for its decisions is an important property for a model in domains
where human lives are affected, such as hate speech detection and biomedicine.
With transformers finding wide use in these fields, the need for
interpretability techniques tailored to them arises. The effectiveness of
attention-based interpretability techniques for transformers in text
classification is studied in this work. Despite concerns about attention-based
interpretations in the literature, we show that, with proper setup, attention
may be used in such tasks with results comparable to state-of-the-art
techniques, while also being faster and friendlier to the environment. We
validate our claims with a series of experiments that employ a new feature
importance metric.</p>
  </details>
</details>
<details>
  <summary>30. <b>标题：Turning Normalizing Flows into Monge Maps with Geodesic Gaussian  Preserving Flows</b></summary>
  <p><b>编号</b>：[128]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10873</p>
  <p><b>作者</b>：Guillaume Morel (IMT Atlantique - ITI),  Lucas Drumetz (Lab-STICC\_OSE, IMT Atlantique - MEE),  Nicolas Courty (IRISA, UBS),  François Rousseau (IMT Atlantique - ITI, LaTIM)</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：powerful likelihood-based generative, model complex densities, likelihood-based generative models, complex densities, powerful likelihood-based</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Normalizing Flows (NF) are powerful likelihood-based generative models that
are able to trade off between expressivity and tractability to model complex
densities. A now well established research avenue leverages optimal transport
(OT) and looks for Monge maps, i.e. models with minimal effort between the
source and target distributions. This paper introduces a method based on
Brenier's polar factorization theorem to transform any trained NF into a more
OT-efficient version without changing the final density. We do so by learning a
rearrangement of the source (Gaussian) distribution that minimizes the OT cost
between the source and the final density. We further constrain the path leading
to the estimated Monge map to lie on a geodesic in the space of
volume-preserving diffeomorphisms thanks to Euler's equations. The proposed
method leads to smooth flows with reduced OT cost for several existing models
without affecting the model performance.</p>
  </details>
</details>
<details>
  <summary>31. <b>标题：One-Shot Federated Learning for Model Clustering and Learning in  Heterogeneous Environments</b></summary>
  <p><b>编号</b>：[131]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10866</p>
  <p><b>作者</b>：Aleksandar Armacki,  Dragana Bajovic,  Dusan Jakovetic,  Soummya Kar</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：communication efficient approach, heterogeneous environments, communication efficient, efficient approach, federated learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose a communication efficient approach for federated learning in
heterogeneous environments. The system heterogeneity is reflected in the
presence of $K$ different data distributions, with each user sampling data from
only one of $K$ distributions. The proposed approach requires only one
communication round between the users and server, thus significantly reducing
the communication cost. Moreover, the proposed method provides strong learning
guarantees in heterogeneous environments, by achieving the optimal mean-squared
error (MSE) rates in terms of the sample size, i.e., matching the MSE
guarantees achieved by learning on all data points belonging to users with the
same data distribution, provided that the number of data points per user is
above a threshold that we explicitly characterize in terms of system
parameters. Remarkably, this is achieved without requiring any knowledge of the
underlying distributions, or even the true number of distributions $K$.
Numerical experiments illustrate our findings and underline the performance of
the proposed method.</p>
  </details>
</details>
<details>
  <summary>32. <b>标题：A novel corrective-source term approach to modeling unknown physics in  aluminum extraction process</b></summary>
  <p><b>编号</b>：[133]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10861</p>
  <p><b>作者</b>：Haakon Robinson,  Erlend Lundby,  Adil Rasheed,  Jan Tommy Gravdahl</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：applying modern machine, modern machine learning, machine learning methods, availability of data, ever-increasing availability</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>With the ever-increasing availability of data, there has been an explosion of
interest in applying modern machine learning methods to fields such as modeling
and control. However, despite the flexibility and surprising accuracy of such
black-box models, it remains difficult to trust them. Recent efforts to combine
the two approaches aim to develop flexible models that nonetheless generalize
well; a paradigm we call Hybrid Analysis and modeling (HAM). In this work we
investigate the Corrective Source Term Approach (CoSTA), which uses a
data-driven model to correct a misspecified physics-based model. This enables
us to develop models that make accurate predictions even when the underlying
physics of the problem is not well understood. We apply CoSTA to model the
Hall-Héroult process in an aluminum electrolysis cell. We demonstrate that
the method improves both accuracy and predictive stability, yielding an overall
more trustworthy model.</p>
  </details>
</details>
<details>
  <summary>33. <b>标题：SCALES: From Fairness Principles to Constrained Decision-Making</b></summary>
  <p><b>编号</b>：[134]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10860</p>
  <p><b>作者</b>：Sreejith Balakrishnan,  Jianxin Bi,  Harold Soh</p>
  <p><b>备注</b>：Accepted to the 2022 AAAI/ACM Conference on AI, Ethics, and Society (AIES '22), Updated version with additional citations, 14 pages</p>
  <p><b>关键词</b>：common representation based, paper proposes SCALES, translates well-established fairness, Markov Decision Process, paper proposes</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper proposes SCALES, a general framework that translates
well-established fairness principles into a common representation based on the
Constraint Markov Decision Process (CMDP). With the help of causal language,
our framework can place constraints on both the procedure of decision making
(procedural fairness) as well as the outcomes resulting from decisions (outcome
fairness). Specifically, we show that well-known fairness principles can be
encoded either as a utility component, a non-causal component, or a causal
component in a SCALES-CMDP. We illustrate SCALES using a set of case studies
involving a simulated healthcare scenario and the real-world COMPAS dataset.
Experiments demonstrate that our framework produces fair policies that embody
alternative fairness principles in single-step and sequential decision-making
scenarios.</p>
  </details>
</details>
<details>
  <summary>34. <b>标题：DIG: Draping Implicit Garment over the Human Body</b></summary>
  <p><b>编号</b>：[138]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10845</p>
  <p><b>作者</b>：Ren Li,  Benoît Guillard,  Edoardo Remelli,  Pascal Fua</p>
  <p><b>备注</b>：16 pages, 9 figures, 5 tables, ACCV 2022</p>
  <p><b>关键词</b>：posed human bodies, Existing data-driven methods, Existing data-driven, human bodies, posed human</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Existing data-driven methods for draping garments over posed human bodies,
despite being effective, cannot handle garments of arbitrary topology and are
typically not end-to-end differentiable. To address these limitations, we
propose an end-to-end differentiable pipeline that represents garments using
implicit surfaces and learns a skinning field conditioned on shape and pose
parameters of an articulated body model. To limit body-garment
interpenetrations and artifacts, we propose an interpretation-aware
pre-processing strategy of training data and a novel training loss that
penalizes self-intersections while draping garments. We demonstrate that our
method yields more accurate results for garment reconstruction and deformation
with respect to state-of-the-art methods. Furthermore, we show that our method,
thanks to its end-to-end differentiability, allows to recover body and garments
parameters jointly from image observations, something that previous work could
not do.</p>
  </details>
</details>
<details>
  <summary>35. <b>标题：Detecting Rotated Objects as Gaussian Distributions and Its 3-D  Generalization</b></summary>
  <p><b>编号</b>：[141]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10839</p>
  <p><b>作者</b>：Xue Yang,  Gefan Zhang,  Xiaojiang Yang,  Yue Zhou,  Wentao Wang,  Jin Tang,  Tao He,  Junchi Yan</p>
  <p><b>备注</b>：19 pages, 11 figures, 16 tables, accepted by TPAMI 2022. Journal extension for GWD (ICML'21) and KLD (NeurIPS'21). arXiv admin note: text overlap with arXiv:2101.11952</p>
  <p><b>关键词</b>：parameterized bounding box, additional rotation angle, bounding box, rotation angle parameter, parameterized bounding</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Existing detection methods commonly use a parameterized bounding box (BBox)
to model and detect (horizontal) objects and an additional rotation angle
parameter is used for rotated objects. We argue that such a mechanism has
fundamental limitations in building an effective regression loss for rotation
detection, especially for high-precision detection with high IoU (e.g. 0.75).
Instead, we propose to model the rotated objects as Gaussian distributions. A
direct advantage is that our new regression loss regarding the distance between
two Gaussians e.g. Kullback-Leibler Divergence (KLD), can well align the actual
detection performance metric, which is not well addressed in existing methods.
Moreover, the two bottlenecks i.e. boundary discontinuity and square-like
problem also disappear. We also propose an efficient Gaussian metric-based
label assignment strategy to further boost the performance. Interestingly, by
analyzing the BBox parameters' gradients under our Gaussian-based KLD loss, we
show that these parameters are dynamically updated with interpretable physical
meaning, which help explain the effectiveness of our approach, especially for
high-precision detection. We extend our approach from 2-D to 3-D with a
tailored algorithm design to handle the heading estimation, and experimental
results on twelve public datasets (2-D/3-D, aerial/text/face images) with
various base detectors show its superiority.</p>
  </details>
</details>
<details>
  <summary>36. <b>标题：High-order Multi-view Clustering for Generic Data</b></summary>
  <p><b>编号</b>：[142]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10838</p>
  <p><b>作者</b>：Erlin Pan,  Zhao Kang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Graph-based multi-view clustering, graph, Graph-based multi-view, data, multi-view clustering</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Graph-based multi-view clustering has achieved better performance than most
non-graph approaches. However, in many real-world scenarios, the graph
structure of data is not given or the quality of initial graph is poor.
Additionally, existing methods largely neglect the high-order neighborhood
information that characterizes complex intrinsic interactions. To tackle these
problems, we introduce an approach called high-order multi-view clustering
(HMvC) to explore the topology structure information of generic data. Firstly,
graph filtering is applied to encode structure information, which unifies the
processing of attributed graph data and non-graph data in a single framework.
Secondly, up to infinity-order intrinsic relationships are exploited to enrich
the learned graph. Thirdly, to explore the consistent and complementary
information of various views, an adaptive graph fusion mechanism is proposed to
achieve a consensus graph. Comprehensive experimental results on both non-graph
and attributed graph data show the superior performance of our method with
respect to various state-of-the-art techniques, including some deep learning
methods.</p>
  </details>
</details>
<details>
  <summary>37. <b>标题：Boosting as Frank-Wolfe</b></summary>
  <p><b>编号</b>：[145]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10831</p>
  <p><b>作者</b>：Ryotaro Mitsuboshi,  Kohei Hatano,  Eiji Takimoto</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：norm regularization, aim to solve, approximate solution, algorithm, epsilon</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Some boosting algorithms, such as LPBoost, ERLPBoost, and C-ERLPBoost, aim to
solve the soft margin optimization problem with the $\ell_1$-norm
regularization. LPBoost rapidly converges to an $\epsilon$-approximate solution
in practice, but it is known to take $\Omega(m)$ iterations in the worst case,
where $m$ is the sample size. On the other hand, ERLPBoost and C-ERLPBoost are
guaranteed to converge to an $\epsilon$-approximate solution in
$O(\frac{1}{\epsilon^2} \ln \frac{m}{\nu})$ iterations. However, the
computation per iteration is very high compared to LPBoost.
To address this issue, we propose a generic boosting scheme that combines the
Frank-Wolfe algorithm and any secondary algorithm and switches one to the other
iteratively. We show that the scheme retains the same convergence guarantee as
ERLPBoost and C-ERLPBoost. One can incorporate any secondary algorithm to
improve in practice. This scheme comes from a unified view of boosting
algorithms for soft margin optimization. More specifically, we show that
LPBoost, ERLPBoost, and C-ERLPBoost are instances of the Frank-Wolfe algorithm.
In experiments on real datasets, one of the instances of our scheme exploits
the better updates of the secondary algorithm and performs comparably with
LPBoost.</p>
  </details>
</details>
<details>
  <summary>38. <b>标题：Memory-Augmented Graph Neural Networks: A Neuroscience Perspective</b></summary>
  <p><b>编号</b>：[148]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10818</p>
  <p><b>作者</b>：Guixiang Ma,  Vy Vo,  Theodore Willke,  Nesreen K. Ahmed</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：including social networks, Graph neural networks, neural networks, social networks, including social</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Graph neural networks (GNNs) have been extensively used for many domains
where data are represented as graphs, including social networks, recommender
systems, biology, chemistry, etc. Recently, the expressive power of GNNs has
drawn much interest. It has been shown that, despite the promising empirical
results achieved by GNNs for many applications, there are some limitations in
GNNs that hinder their performance for some tasks. For example, since GNNs
update node features mainly based on local information, they have limited
expressive power in capturing long-range dependencies among nodes in graphs. To
address some of the limitations of GNNs, several recent works started to
explore augmenting GNNs with memory for improving their expressive power in the
relevant tasks. In this paper, we provide a comprehensive review of the
existing literature of memory-augmented GNNs. We review these works through the
lens of psychology and neuroscience, which has established multiple memory
systems and mechanisms in biological brains. We propose a taxonomy of the
memory GNN works, as well as a set of criteria for comparing the memory
mechanisms. We also provide critical discussions on the limitations of these
works. Finally, we discuss the challenges and future directions for this area.</p>
  </details>
</details>
<details>
  <summary>39. <b>标题：IntereStyle: Encoding an Interest Region for Robust StyleGAN Inversion</b></summary>
  <p><b>编号</b>：[151]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10811</p>
  <p><b>作者</b>：Seungjun Moon,  GyeongMoon Park</p>
  <p><b>备注</b>：ECCV2022</p>
  <p><b>关键词</b>：Generative Adversarial Networks, Adversarial Networks, Generative Adversarial, uninterest region, interest region</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recently, manipulation of real-world images has been highly elaborated along
with the development of Generative Adversarial Networks (GANs) and
corresponding encoders, which embed real-world images into the latent space.
However, designing encoders of GAN still remains a challenging task due to the
trade-off between distortion and perception. In this paper, we point out that
the existing encoders try to lower the distortion not only on the interest
region, e.g., human facial region but also on the uninterest region, e.g.,
background patterns and obstacles. However, most uninterest regions in
real-world images are located at out-of-distribution (OOD), which are
infeasible to be ideally reconstructed by generative models. Moreover, we
empirically find that the uninterest region overlapped with the interest region
can mangle the original feature of the interest region, e.g., a microphone
overlapped with a facial region is inverted into the white beard. As a result,
lowering the distortion of the whole image while maintaining the perceptual
quality is very challenging. To overcome this trade-off, we propose a simple
yet effective encoder training scheme, coined IntereStyle, which facilitates
encoding by focusing on the interest region. IntereStyle steers the encoder to
disentangle the encodings of the interest and uninterest regions. To this end,
we filter the information of the uninterest region iteratively to regulate the
negative impact of the uninterest region. We demonstrate that IntereStyle
achieves both lower distortion and higher perceptual quality compared to the
existing state-of-the-art encoders. Especially, our model robustly conserves
features of the original images, which shows the robust image editing and style
mixing results. We will release our code with the pre-trained model after the
review.</p>
  </details>
</details>
<details>
  <summary>40. <b>标题：Robust Forecasting for Robotic Control: A Game-Theoretic Approach</b></summary>
  <p><b>编号</b>：[156]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10802</p>
  <p><b>作者</b>：Shubhankar Agarwal,  David Fridovich-Keil,  Sandeep P. Chinchali</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：make optimal decisions, Modern robots require, require accurate forecasts, real world, robots require accurate</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Modern robots require accurate forecasts to make optimal decisions in the
real world. For example, self-driving cars need an accurate forecast of other
agents' future actions to plan safe trajectories. Current methods rely heavily
on historical time series to accurately predict the future. However, relying
entirely on the observed history is problematic since it could be corrupted by
noise, have outliers, or not completely represent all possible outcomes. To
solve this problem, we propose a novel framework for generating robust
forecasts for robotic control. In order to model real-world factors affecting
future forecasts, we introduce the notion of an adversary, which perturbs
observed historical time series to increase a robot's ultimate control cost.
Specifically, we model this interaction as a zero-sum two-player game between a
robot's forecaster and this hypothetical adversary. We show that our proposed
game may be solved to a local Nash equilibrium using gradient-based
optimization techniques. Furthermore, we show that a forecaster trained with
our method performs 30.14% better on out-of-distribution real-world lane change
data than baselines.</p>
  </details>
</details>
<details>
  <summary>41. <b>标题：STING: Self-attention based Time-series Imputation Networks using GAN</b></summary>
  <p><b>编号</b>：[157]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10801</p>
  <p><b>作者</b>：Eunkyu Oh,  Taehun Kim,  Yunhu Ji,  Sushil Khyalia</p>
  <p><b>备注</b>：10 pages. This paper is an accepted version by ICDM'21. The published version is this https URL</p>
  <p><b>关键词</b>：Time series data, Time series, multivariate time series, series data, series</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Time series data are ubiquitous in real-world applications. However, one of
the most common problems is that the time series data could have missing values
by the inherent nature of the data collection process. So imputing missing
values from multivariate (correlated) time series data is imperative to improve
a prediction performance while making an accurate data-driven decision.
Conventional works for imputation simply delete missing values or fill them
based on mean/zero. Although recent works based on deep neural networks have
shown remarkable results, they still have a limitation to capture the complex
generation process of the multivariate time series. In this paper, we propose a
novel imputation method for multivariate time series data, called STING
(Self-attention based Time-series Imputation Networks using GAN). We take
advantage of generative adversarial networks and bidirectional recurrent neural
networks to learn latent representations of the time series. In addition, we
introduce a novel attention mechanism to capture the weighted correlations of
the whole sequence and avoid potential bias brought by unrelated ones.
Experimental results on three real-world datasets demonstrate that STING
outperforms the existing state-of-the-art methods in terms of imputation
accuracy as well as downstream tasks with the imputed values therein.</p>
  </details>
</details>
<details>
  <summary>42. <b>标题：How Does It Feel? Self-Supervised Costmap Learning for Off-Road Vehicle  Traversability</b></summary>
  <p><b>编号</b>：[163]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10788</p>
  <p><b>作者</b>：Mateo Guaman Castro,  Samuel Triest,  Wenshan Wang,  Jason M. Gregory,  Felix Sanchez,  John G. Rogers III,  Sebastian Scherer</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：environments requires reasoning, complex interaction dynamics, off-road environments requires, environments requires, requires reasoning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Estimating terrain traversability in off-road environments requires reasoning
about complex interaction dynamics between the robot and these terrains.
However, it is challenging to build an accurate physics model, or create
informative labels to learn a model in a supervised manner, for these
interactions. We propose a method that learns to predict traversability
costmaps by combining exteroceptive environmental information with
proprioceptive terrain interaction feedback in a self-supervised manner.
Additionally, we propose a novel way of incorporating robot velocity in the
costmap prediction pipeline. We validate our method in multiple short and
large-scale navigation tasks on a large, autonomous all-terrain vehicle (ATV)
on challenging off-road terrains, and demonstrate ease of integration on a
separate large ground robot. Our short-scale navigation results show that using
our learned costmaps leads to overall smoother navigation, and provides the
robot with a more fine-grained understanding of the interactions between the
robot and different terrain types, such as grass and gravel. Our large-scale
navigation trials show that we can reduce the number of interventions by up to
57% compared to an occupancy-based navigation baseline in challenging off-road
courses ranging from 400 m to 3150 m.</p>
  </details>
</details>
<details>
  <summary>43. <b>标题：Learning Model Predictive Controllers with Real-Time Attention for  Real-World Navigation</b></summary>
  <p><b>编号</b>：[167]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10780</p>
  <p><b>作者</b>：Xuesu Xiao,  Tingnan Zhang,  Krzysztof Choromanski,  Edward Lee,  Anthony Francis,  Jake Varley,  Stephen Tu,  Sumeet Singh,  Peng Xu,  Fei Xia,  Sven Mikael Persson,  Dmitry Kalashnikov,  Leila Takayama,  Roy Frostig,  Jie Tan,  Carolina Parada,  Vikas Sindhwani</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：human-occupied public spaces, face real-world challenges, existing navigation systems, decades of research, public spaces</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Despite decades of research, existing navigation systems still face
real-world challenges when deployed in the wild, e.g., in cluttered home
environments or in human-occupied public spaces. To address this, we present a
new class of implicit control policies combining the benefits of imitation
learning with the robust handling of system constraints from Model Predictive
Control (MPC). Our approach, called Performer-MPC, uses a learned cost function
parameterized by vision context embeddings provided by Performers -- a low-rank
implicit-attention Transformer. We jointly train the cost function and
construct the controller relying on it, effectively solving end-to-end the
corresponding bi-level optimization problem. We show that the resulting policy
improves standard MPC performance by leveraging a few expert demonstrations of
the desired navigation behavior in different challenging real-world scenarios.
Compared with a standard MPC policy, Performer-MPC achieves >40% better goal
reached in cluttered environments and >65% better on social metrics when
navigating around humans.</p>
  </details>
</details>
<details>
  <summary>44. <b>标题：Nesting Forward Automatic Differentiation for Memory-Efficient Deep  Neural Network Training</b></summary>
  <p><b>编号</b>：[168]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10778</p>
  <p><b>作者</b>：Cong Guo,  Yuxian Qiu,  Jingwen Leng,  Chen Zhang,  Ying Cao,  Quanlu Zhang,  Yunxin Liu,  Fan Yang,  Minyi Guo</p>
  <p><b>备注</b>：8 pages, ICCD 2022</p>
  <p><b>关键词</b>：deep neural networks, element-wise mathematical function, neural networks, element-wise activation function, plays a crucial</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>An activation function is an element-wise mathematical function and plays a
crucial role in deep neural networks (DNN). Many novel and sophisticated
activation functions have been proposed to improve the DNN accuracy but also
consume massive memory in the training process with back-propagation. In this
study, we propose the nested forward automatic differentiation (Forward-AD),
specifically for the element-wise activation function for memory-efficient DNN
training. We deploy nested Forward-AD in two widely-used deep learning
frameworks, TensorFlow and PyTorch, which support the static and dynamic
computation graph, respectively. Our evaluation shows that nested Forward-AD
reduces the memory footprint by up to 1.97x than the baseline model and
outperforms the recomputation by 20% under the same memory reduction ratio.</p>
  </details>
</details>
<details>
  <summary>45. <b>标题：DRAMA: Joint Risk Localization and Captioning in Driving</b></summary>
  <p><b>编号</b>：[171]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10767</p>
  <p><b>作者</b>：Srikanth Malla,  Chiho Choi,  Isht Dwivedi,  Joon Hee Choi,  Jiachen Li</p>
  <p><b>备注</b>：WACV 2023 (Winter Conference on Applications of Computer Vision)</p>
  <p><b>关键词</b>：safety-critical automation systems, driving, driving scenes, Driving Risk Assessment, Risk Assessment Mechanism</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Considering the functionality of situational awareness in safety-critical
automation systems, the perception of risk in driving scenes and its
explainability is of particular importance for autonomous and cooperative
driving. Toward this goal, this paper proposes a new research direction of
joint risk localization in driving scenes and its risk explanation as a natural
language description. Due to the lack of standard benchmarks, we collected a
large-scale dataset, DRAMA (Driving Risk Assessment Mechanism with A captioning
module), which consists of 17,785 interactive driving scenarios collected in
Tokyo, Japan. Our DRAMA dataset accommodates video- and object-level questions
on driving risks with associated important objects to achieve the goal of
visual captioning as a free-form language description utilizing closed and
open-ended responses for multi-level questions, which can be used to evaluate a
range of visual captioning capabilities in driving scenarios. We make this data
available to the community for further research. Using DRAMA, we explore
multiple facets of joint risk localization and captioning in interactive
driving scenarios. In particular, we benchmark various multi-task prediction
architectures and provide a detailed analysis of joint risk localization and
risk captioning. The data set is available at this https URL</p>
  </details>
</details>
<details>
  <summary>46. <b>标题：Common human diseases prediction using machine learning based on survey  data</b></summary>
  <p><b>编号</b>：[177]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10750</p>
  <p><b>作者</b>：Jabir Al Nahian,  Abu Kaisar Mohammad Masum,  Sheikh Abujar,  Md. Jueal Mia</p>
  <p><b>备注</b>：11 pages, 6 figures, accepted in Bulletin of Electrical Engineering and Informatics Journal</p>
  <p><b>关键词</b>：medical treatment, moment has arrived, arrived to move, primary emphasis, emphasis of medical</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this era, the moment has arrived to move away from disease as the primary
emphasis of medical treatment. Although impressive, the multiple techniques
that have been developed to detect the diseases. In this time, there are some
types of diseases COVID-19, normal flue, migraine, lung disease, heart disease,
kidney disease, diabetics, stomach disease, gastric, bone disease, autism are
the very common diseases. In this analysis, we analyze disease symptoms and
have done disease predictions based on their symptoms. We studied a range of
symptoms and took a survey from people in order to complete the task. Several
classification algorithms have been employed to train the model. Furthermore,
performance evaluation matrices are used to measure the model's performance.
Finally, we discovered that the part classifier surpasses the others.</p>
  </details>
</details>
<details>
  <summary>47. <b>标题：Enhancing the Inductive Biases of Graph Neural ODE for Modeling  Dynamical Systems</b></summary>
  <p><b>编号</b>：[179]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10740</p>
  <p><b>作者</b>：Suresh Bishnoi,  Ravinder Bhattoo,  Sayan Ranu,  N. M. Anoop Krishnan</p>
  <p><b>备注</b>：22 pages</p>
  <p><b>关键词</b>：inductive biases, Neural networks, Neural, biases, inductive</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Neural networks with physics based inductive biases such as Lagrangian neural
networks (LNN), and Hamiltonian neural networks (HNN) learn the dynamics of
physical systems by encoding strong inductive biases. Alternatively, Neural
ODEs with appropriate inductive biases have also been shown to give similar
performances. However, these models, when applied to particle based systems,
are transductive in nature and hence, do not generalize to large system sizes.
In this paper, we present a graph based neural ODE, GNODE, to learn the time
evolution of dynamical systems. Further, we carefully analyse the role of
different inductive biases on the performance of GNODE. We show that, similar
to LNN and HNN, encoding the constraints explicitly can significantly improve
the training efficiency and performance of GNODE significantly. Our experiments
also assess the value of additional inductive biases, such as Newtons third
law, on the final performance of the model. We demonstrate that inducing these
biases can enhance the performance of model by orders of magnitude in terms of
both energy violation and rollout error. Interestingly, we observe that the
GNODE trained with the most effective inductive biases, namely MCGNODE,
outperforms the graph versions of LNN and HNN, namely, Lagrangian graph
networks (LGN) and Hamiltonian graph networks (HGN) in terms of energy
violation error by approx 4 orders of magnitude for a pendulum system, and
approx 2 orders of magnitude for spring systems. These results suggest that
competitive performances with energy conserving neural networks can be obtained
for NODE based systems by inducing appropriate inductive biases.</p>
  </details>
</details>
<details>
  <summary>48. <b>标题：In Differential Privacy, There is Truth: On Vote Leakage in Ensemble  Private Learning</b></summary>
  <p><b>编号</b>：[183]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10732</p>
  <p><b>作者</b>：Jiaqi Wang,  Roei Schuster,  Ilia Shumailov,  David Lie,  Nicolas Papernot</p>
  <p><b>备注</b>：To appear at NeurIPS 2022</p>
  <p><b>关键词</b>：address privacy concerns, training algorithms address, algorithms address privacy, canonical Private Aggregation, algorithms address</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>When learning from sensitive data, care must be taken to ensure that training
algorithms address privacy concerns. The canonical Private Aggregation of
Teacher Ensembles, or PATE, computes output labels by aggregating the
predictions of a (possibly distributed) collection of teacher models via a
voting mechanism. The mechanism adds noise to attain a differential privacy
guarantee with respect to the teachers' training data. In this work, we observe
that this use of noise, which makes PATE predictions stochastic, enables new
forms of leakage of sensitive information. For a given input, our adversary
exploits this stochasticity to extract high-fidelity histograms of the votes
submitted by the underlying teachers. From these histograms, the adversary can
learn sensitive attributes of the input such as race, gender, or age. Although
this attack does not directly violate the differential privacy guarantee, it
clearly violates privacy norms and expectations, and would not be possible at
all without the noise inserted to obtain differential privacy. In fact,
counter-intuitively, the attack becomes easier as we add more noise to provide
stronger differential privacy. We hope this encourages future work to consider
privacy holistically rather than treat differential privacy as a panacea.</p>
  </details>
</details>
<details>
  <summary>49. <b>标题：Fair Robust Active Learning by Joint Inconsistency</b></summary>
  <p><b>编号</b>：[184]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10729</p>
  <p><b>作者</b>：Tsung-Han Wu,  Shang-Tse Chen,  Winston H. Hsu</p>
  <p><b>备注</b>：11 pages, 3 figures</p>
  <p><b>关键词</b>：Active Learning, utilized active learning, active learning techniques, Fair Active Learning, Fair Robust Active</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Fair Active Learning (FAL) utilized active learning techniques to achieve
high model performance with limited data and to reach fairness between
sensitive groups (e.g., genders). However, the impact of the adversarial
attack, which is vital for various safety-critical machine learning
applications, is not yet addressed in FAL. Observing this, we introduce a novel
task, Fair Robust Active Learning (FRAL), integrating conventional FAL and
adversarial robustness. FRAL requires ML models to leverage active learning
techniques to jointly achieve equalized performance on benign data and
equalized robustness against adversarial attacks between groups. In this new
task, previous FAL methods generally face the problem of unbearable
computational burden and ineffectiveness. Therefore, we develop a simple yet
effective FRAL strategy by Joint INconsistency (JIN). To efficiently find
samples that can boost the performance and robustness of disadvantaged groups
for labeling, our method exploits the prediction inconsistency between benign
and adversarial samples as well as between standard and robust models.
Extensive experiments under diverse datasets and sensitive groups demonstrate
that our method not only achieves fairer performance on benign samples but also
obtains fairer robustness under white-box PGD attacks compared with existing
active learning and FAL baselines. We are optimistic that FRAL would pave a new
path for developing safe and robust ML research and applications such as facial
attribute recognition in biometrics systems.</p>
  </details>
</details>
<details>
  <summary>50. <b>标题：Enhanced Decentralized Federated Learning based on Consensus in  Connected Vehicles</b></summary>
  <p><b>编号</b>：[186]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10722</p>
  <p><b>作者</b>：Xiaoyan Liu,  Zehui Dong,  Zhiwei Xu,  Siyuan Liu,  Jie Tian</p>
  <p><b>备注</b>：9 pages, 10 figures, Journal</p>
  <p><b>关键词</b>：distributed decision making, Machine Learning, train machine learning, Federated learning, Advanced researches</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Advanced researches on connected vehicles have recently targeted to the
integration of vehicle-to-everything (V2X) networks with Machine Learning (ML)
tools and distributed decision making. Federated learning (FL) is emerging as a
new paradigm to train machine learning (ML) models in distributed systems,
including vehicles in V2X networks. Rather than sharing and uploading the
training data to the server, the updating of model parameters (e.g., neural
networks' weights and biases) is applied by large populations of interconnected
vehicles, acting as local learners. Despite these benefits, the limitation of
existing approaches is the centralized optimization which relies on a server
for aggregation and fusion of local parameters, leading to the drawback of a
single point of failure and scaling issues for increasing V2X network size.
Meanwhile, in intelligent transport scenarios, data collected from onboard
sensors are redundant, which degrades the performance of aggregation. To tackle
these problems, we explore a novel idea of decentralized data processing and
introduce a federated learning framework for in-network vehicles,
C-DFL(Consensus based Decentralized Federated Learning), to tackle federated
learning on connected vehicles and improve learning quality. Extensive
simulations have been implemented to evaluate the performance of C-DFL, that
demonstrates C-DFL outperforms the performance of conventional methods in all
cases.</p>
  </details>
</details>
<details>
  <summary>51. <b>标题：Batch Bayesian optimisation via density-ratio estimation with guarantees</b></summary>
  <p><b>编号</b>：[188]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10715</p>
  <p><b>作者</b>：Rafael Oliveira,  Louis Tiao,  Fabio Ramos</p>
  <p><b>备注</b>：Paper accepted at NeurIPS 2022</p>
  <p><b>关键词</b>：shown remarkable success, applications involving expensive, involving expensive black-box, expensive black-box functions, shown remarkable</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Bayesian optimisation (BO) algorithms have shown remarkable success in
applications involving expensive black-box functions. Traditionally BO has been
set as a sequential decision-making process which estimates the utility of
query points via an acquisition function and a prior over functions, such as a
Gaussian process. Recently, however, a reformulation of BO via density-ratio
estimation (BORE) allowed reinterpreting the acquisition function as a
probabilistic binary classifier, removing the need for an explicit prior over
functions and increasing scalability. In this paper, we present a theoretical
analysis of BORE's regret and an extension of the algorithm with improved
uncertainty estimates. We also show that BORE can be naturally extended to a
batch optimisation setting by recasting the problem as approximate Bayesian
inference. The resulting algorithm comes equipped with theoretical performance
guarantees and is assessed against other batch BO baselines in a series of
experiments.</p>
  </details>
</details>
<details>
  <summary>52. <b>标题：Stochastic Future Prediction in Real World Driving Scenarios</b></summary>
  <p><b>编号</b>：[192]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10693</p>
  <p><b>作者</b>：Adil Kaan Akan</p>
  <p><b>备注</b>：MS thesis, overlap with arXiv:2203.13641, arXiv:2203.10528, arXiv:2108.02760</p>
  <p><b>关键词</b>：plays a key, key role, future prediction, future, Uncertainty plays</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Uncertainty plays a key role in future prediction. The future is uncertain.
That means there might be many possible futures. A future prediction method
should cover the whole possibilities to be robust. In autonomous driving,
covering multiple modes in the prediction part is crucially important to make
safety-critical decisions. Although computer vision systems have advanced
tremendously in recent years, future prediction remains difficult today.
Several examples are uncertainty of the future, the requirement of full scene
understanding, and the noisy outputs space. In this thesis, we propose
solutions to these challenges by modeling the motion explicitly in a stochastic
way and learning the temporal dynamics in a latent space.</p>
  </details>
</details>
<details>
  <summary>53. <b>标题：PREF: Predictability Regularized Neural Motion Fields</b></summary>
  <p><b>编号</b>：[193]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10691</p>
  <p><b>作者</b>：Liangchen Song,  Xuan Gong,  Benjamin Planche,  Meng Zheng,  David Doermann,  Junsong Yuan,  Terrence Chen,  Ziyan Wu</p>
  <p><b>备注</b>：Accepted at ECCV 2022 (oral). Paper + supplementary material</p>
  <p><b>关键词</b>：vision applications, motion, dynamic scene, estimated motion, scene</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Knowing the 3D motions in a dynamic scene is essential to many vision
applications. Recent progress is mainly focused on estimating the activity of
some specific elements like humans. In this paper, we leverage a neural motion
field for estimating the motion of all points in a multiview setting. Modeling
the motion from a dynamic scene with multiview data is challenging due to the
ambiguities in points of similar color and points with time-varying color. We
propose to regularize the estimated motion to be predictable. If the motion
from previous frames is known, then the motion in the near future should be
predictable. Therefore, we introduce a predictability regularization by first
conditioning the estimated motion on latent embeddings, then by adopting a
predictor network to enforce predictability on the embeddings. The proposed
framework PREF (Predictability REgularized Fields) achieves on par or better
results than state-of-the-art neural motion field-based dynamic scene
representation methods, while requiring no prior knowledge of the scene.</p>
  </details>
</details>
<details>
  <summary>54. <b>标题：NashAE: Disentangling Representations through Adversarial Covariance  Minimization</b></summary>
  <p><b>编号</b>：[199]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10677</p>
  <p><b>作者</b>：Eric Yeats,  Frank Liu,  David Womble,  Hai Li</p>
  <p><b>备注</b>：Published as a conference paper in the European Conference on Computer Vision (ECCV) 2022</p>
  <p><b>关键词</b>：underlying variation profile, individual latent variables, variation profile, underlying variation, present a self-supervised</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present a self-supervised method to disentangle factors of variation in
high-dimensional data that does not rely on prior knowledge of the underlying
variation profile (e.g., no assumptions on the number or distribution of the
individual latent variables to be extracted). In this method which we call
NashAE, high-dimensional feature disentanglement is accomplished in the
low-dimensional latent space of a standard autoencoder (AE) by promoting the
discrepancy between each encoding element and information of the element
recovered from all other encoding elements. Disentanglement is promoted
efficiently by framing this as a minmax game between the AE and an ensemble of
regression networks which each provide an estimate of an element conditioned on
an observation of all other elements. We quantitatively compare our approach
with leading disentanglement methods using existing disentanglement metrics.
Furthermore, we show that NashAE has increased reliability and increased
capacity to capture salient data characteristics in the learned latent
representation.</p>
  </details>
</details>
<details>
  <summary>55. <b>标题：Modeling Perceptual Loudness of Piano Tone: Theory and Applications</b></summary>
  <p><b>编号</b>：[200]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10674</p>
  <p><b>作者</b>：Yang Qu,  Yutian Qin,  Lecheng Chao,  Hangkai Qian,  Ziyu Wang,  Gus Xia</p>
  <p><b>备注</b>：Accepted to ISMIR 2022</p>
  <p><b>关键词</b>：music and psychoacoustics, physical attributes, computer music, important subject, loudness</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The relationship between perceptual loudness and physical attributes of sound
is an important subject in both computer music and psychoacoustics. Early
studies of "equal-loudness contour" can trace back to the 1920s and the
measured loudness with respect to intensity and frequency has been revised many
times since then. However, most studies merely focus on synthesized sound, and
the induced theories on natural tones with complex timbre have rarely been
justified. To this end, we investigate both theory and applications of
natural-tone loudness perception in this paper via modeling piano tone. The
theory part contains: 1) an accurate measurement of piano-tone equal-loudness
contour of pitches, and 2) a machine-learning model capable of inferring
loudness purely based on spectral features trained on human subject
measurements. As for the application, we apply our theory to piano control
transfer, in which we adjust the MIDI velocities on two different player pianos
(in different acoustic environments) to achieve the same perceptual effect.
Experiments show that both our theoretical loudness modeling and the
corresponding performance control transfer algorithm significantly outperform
their baselines.</p>
  </details>
</details>
<details>
  <summary>56. <b>标题：Adaptive Bias Correction for Improved Subseasonal Forecasting</b></summary>
  <p><b>编号</b>：[203]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10666</p>
  <p><b>作者</b>：Soukayna Mouatadid,  Paulo Orenstein,  Genevieve Flaspohler,  Judah Cohen,  Miruna Oprescu,  Ernest Fraenkel,  Lester Mackey</p>
  <p><b>备注</b>：16 pages of main paper and 2 pages of appendix text</p>
  <p><b>关键词</b>：effective water allocation, wildfire management, ahead is critical, water allocation, flood mitigation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Subseasonal forecasting $\unicode{x2013}$ predicting temperature and
precipitation 2 to 6 weeks $\unicode{x2013}$ ahead is critical for effective
water allocation, wildfire management, and drought and flood mitigation. Recent
international research efforts have advanced the subseasonal capabilities of
operational dynamical models, yet temperature and precipitation prediction
skills remains poor, partly due to stubborn errors in representing atmospheric
dynamics and physics inside dynamical models. To counter these errors, we
introduce an adaptive bias correction (ABC) method that combines
state-of-the-art dynamical forecasts with observations using machine learning.
When applied to the leading subseasonal model from the European Centre for
Medium-Range Weather Forecasts (ECMWF), ABC improves temperature forecasting
skill by 60-90% and precipitation forecasting skill by 40-69% in the contiguous
U.S. We couple these performance improvements with a practical workflow, based
on Cohort Shapley, for explaining ABC skill gains and identifying higher-skill
windows of opportunity based on specific climate conditions.</p>
  </details>
</details>
<details>
  <summary>57. <b>标题：Contrastive Learning for Time Series on Dynamic Graphs</b></summary>
  <p><b>编号</b>：[206]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10662</p>
  <p><b>作者</b>：Yitian Zhang,  Florence Regol,  Antonios Valkanas,  Mark Coates</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：recent efforts, efforts towards developing, developing representations, multivariate time-series, unsupervised learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>There have been several recent efforts towards developing representations for
multivariate time-series in an unsupervised learning framework. Such
representations can prove beneficial in tasks such as activity recognition,
health monitoring, and anomaly detection. In this paper, we consider a setting
where we observe time-series at each node in a dynamic graph. We propose a
framework called GraphTNC for unsupervised learning of joint representations of
the graph and the time-series. Our approach employs a contrastive learning
strategy. Based on an assumption that the time-series and graph evolution
dynamics are piecewise smooth, we identify local windows of time where the
signals exhibit approximate stationarity. We then train an encoding that allows
the distribution of signals within a neighborhood to be distinguished from the
distribution of non-neighboring signals. We first demonstrate the performance
of our proposed framework using synthetic data, and subsequently we show that
it can prove beneficial for the classification task with real-world datasets.</p>
  </details>
</details>
<details>
  <summary>58. <b>标题：Explaining Anomalies using Denoising Autoencoders for Financial Tabular  Data</b></summary>
  <p><b>编号</b>：[207]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10658</p>
  <p><b>作者</b>：Timur Sattarov,  Dayananda Herurkar,  Jörn Hees</p>
  <p><b>备注</b>：10 pages, 4 figures, 3 tables, preprint version, currently under review</p>
  <p><b>关键词</b>：advances in Explainable, Recent advances, increased the demand, industry sectors, demand for deployment</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent advances in Explainable AI (XAI) increased the demand for deployment
of safe and interpretable AI models in various industry sectors. Despite the
latest success of deep neural networks in a variety of domains, understanding
the decision-making process of such complex models still remains a challenging
task for domain experts. Especially in the financial domain, merely pointing to
an anomaly composed of often hundreds of mixed type columns, has limited value
for experts.
Hence, in this paper, we propose a framework for explaining anomalies using
denoising autoencoders designed for mixed type tabular data. We specifically
focus our technique on anomalies that are erroneous observations. This is
achieved by localizing individual sample columns (cells) with potential errors
and assigning corresponding confidence scores. In addition, the model provides
the expected cell value estimates to fix the errors.
We evaluate our approach based on three standard public tabular datasets
(Credit Default, Adult, IEEE Fraud) and one proprietary dataset (Holdings). We
find that denoising autoencoders applied to this task already outperform other
approaches in the cell error detection rates as well as in the expected value
rates. Additionally, we analyze how a specialized loss designed for cell error
detection can further improve these metrics. Our framework is designed for a
domain expert to understand abnormal characteristics of an anomaly, as well as
to improve in-house data quality management processes.</p>
  </details>
</details>
<details>
  <summary>59. <b>标题：Mega: Moving Average Equipped Gated Attention</b></summary>
  <p><b>编号</b>：[209]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10655</p>
  <p><b>作者</b>：Xuezhe Ma,  Chunting Zhou,  Xiang Kong,  Junxian He,  Liangke Gui,  Graham Neubig,  Jonathan May,  Luke Zettlemoyer</p>
  <p><b>备注</b>：13 pages, 4 figures and 7 tables</p>
  <p><b>关键词</b>：weak inductive bias, quadratic computational complexity, attention mechanism, Transformer attention mechanism, including weak inductive</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The design choices in the Transformer attention mechanism, including weak
inductive bias and quadratic computational complexity, have limited its
application for modeling long sequences. In this paper, we introduce Mega, a
simple, theoretically grounded, single-head gated attention mechanism equipped
with (exponential) moving average to incorporate inductive bias of
position-aware local dependencies into the position-agnostic attention
mechanism. We further propose a variant of Mega that offers linear time and
space complexity yet yields only minimal quality loss, by efficiently splitting
the whole sequence into multiple chunks with fixed length. Extensive
experiments on a wide range of sequence modeling benchmarks, including the Long
Range Arena, neural machine translation, auto-regressive language modeling, and
image and speech classification, show that Mega achieves significant
improvements over other sequence models, including variants of Transformers and
recent state space models.</p>
  </details>
</details>
<details>
  <summary>60. <b>标题：Toy Models of Superposition</b></summary>
  <p><b>编号</b>：[210]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10652</p>
  <p><b>作者</b>：Nelson Elhage,  Tristan Hume,  Catherine Olsson,  Nicholas Schiefer,  Tom Henighan,  Shauna Kravec,  Zac Hatfield-Dodds,  Robert Lasenby,  Dawn Drain,  Carol Chen,  Roger Grosse,  Sam McCandlish,  Jared Kaplan,  Dario Amodei,  Martin Wattenberg,  Christopher Olah</p>
  <p><b>备注</b>：Also available at this https URL</p>
  <p><b>关键词</b>：Neural networks, single neuron, networks often pack, pack many unrelated, unrelated concepts</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Neural networks often pack many unrelated concepts into a single neuron - a
puzzling phenomenon known as 'polysemanticity' which makes interpretability
much more challenging. This paper provides a toy model where polysemanticity
can be fully understood, arising as a result of models storing additional
sparse features in "superposition." We demonstrate the existence of a phase
change, a surprising connection to the geometry of uniform polytopes, and
evidence of a link to adversarial examples. We also discuss potential
implications for mechanistic interpretability.</p>
  </details>
</details>
<details>
  <summary>61. <b>标题：Benchmarking Apache Spark and Hadoop MapReduce on Big Data  Classification</b></summary>
  <p><b>编号</b>：[213]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10637</p>
  <p><b>作者</b>：Taha Tekdogan,  Ali Cakmak</p>
  <p><b>备注</b>：2021 5th International Conference on Cloud and Big Data Computing (ICCBDC 2021)</p>
  <p><b>关键词</b>：popular Big Data, Big Data, Big Data analytics, Big Data Mining, extract valuable information</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Most of the popular Big Data analytics tools evolved to adapt their working
environment to extract valuable information from a vast amount of unstructured
data. The ability of data mining techniques to filter this helpful information
from Big Data led to the term Big Data Mining. Shifting the scope of data from
small-size, structured, and stable data to huge volume, unstructured, and
quickly changing data brings many data management challenges. Different tools
cope with these challenges in their own way due to their architectural
limitations. There are numerous parameters to take into consideration when
choosing the right data management framework based on the task at hand. In this
paper, we present a comprehensive benchmark for two widely used Big Data
analytics tools, namely Apache Spark and Hadoop MapReduce, on a common data
mining task, i.e., classification. We employ several evaluation metrics to
compare the performance of the benchmarked frameworks, such as execution time,
accuracy, and scalability. These metrics are specialized to measure the
performance for classification task. To the best of our knowledge, there is no
previous study in the literature that employs all these metrics while taking
into consideration task-specific concerns. We show that Spark is 5 times faster
than MapReduce on training the model. Nevertheless, the performance of Spark
degrades when the input workload gets larger. Scaling the environment by
additional clusters significantly improves the performance of Spark. However,
similar enhancement is not observed in Hadoop. Machine learning utility of
MapReduce tend to have better accuracy scores than that of Spark, like around
3%, even in small size data sets.</p>
  </details>
</details>
<details>
  <summary>62. <b>标题：Neural Generalized Ordinary Differential Equations with Layer-varying  Parameters</b></summary>
  <p><b>编号</b>：[214]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10633</p>
  <p><b>作者</b>：Duo Yu,  Hongyu Miao,  Hulin Wu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Deep residual networks, Deep residual, residual networks, real-world applications, ordinary differential equation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep residual networks (ResNets) have shown state-of-the-art performance in
various real-world applications. Recently, the ResNets model was
reparameterized and interpreted as solutions to a continuous ordinary
differential equation or Neural-ODE model. In this study, we propose a neural
generalized ordinary differential equation (Neural-GODE) model with
layer-varying parameters to further extend the Neural-ODE to approximate the
discrete ResNets. Specifically, we use nonparametric B-spline functions to
parameterize the Neural-GODE so that the trade-off between the model complexity
and computational efficiency can be easily balanced. It is demonstrated that
ResNets and Neural-ODE models are special cases of the proposed Neural-GODE
model. Based on two benchmark datasets, MNIST and CIFAR-10, we show that the
layer-varying Neural-GODE is more flexible and general than the standard
Neural-ODE. Furthermore, the Neural-GODE enjoys the computational and memory
benefits while performing comparably to ResNets in prediction accuracy.</p>
  </details>
</details>
<details>
  <summary>63. <b>标题：Seen to Unseen: When Fuzzy Inference System Predicts IoT Device  Positioning Labels That Had Not Appeared in Training Phase</b></summary>
  <p><b>编号</b>：[216]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10627</p>
  <p><b>作者</b>：Han Xu,  Zheming Zuo,  Jie Li,  Victor Chang</p>
  <p><b>备注</b>：Accepted by International Conference on Internet of Things, Big Data and Security (IoTBDS) 2022</p>
  <p><b>关键词</b>：Machine Learning, Deep Learning, Artificial Intelligence, embraced great success, core of Artificial</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Situating at the core of Artificial Intelligence (AI), Machine Learning (ML),
and more specifically, Deep Learning (DL) have embraced great success in the
past two decades. However, unseen class label prediction is far less explored
due to missing classes being invisible in training ML or DL models. In this
work, we propose a fuzzy inference system to cope with such a challenge by
adopting TSK+ fuzzy inference engine in conjunction with the Curvature-based
Feature Selection (CFS) method. The practical feasibility of our system has
been evaluated by predicting the positioning labels of networking devices
within the realm of the Internet of Things (IoT). Competitive prediction
performance confirms the efficiency and efficacy of our system, especially when
a large number of continuous class labels are unseen during the model training
stage.</p>
  </details>
</details>
<details>
  <summary>64. <b>标题：SW-VAE: Weakly Supervised Learn Disentangled Representation Via Latent  Factor Swapping</b></summary>
  <p><b>编号</b>：[217]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10623</p>
  <p><b>作者</b>：Jiageng Zhu,  Hanchen Xie,  Wael Abd-Almageed</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：benefits various downstream, Representation disentanglement, Representation, important goal, disentanglement</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Representation disentanglement is an important goal of representation
learning that benefits various downstream tasks. To achieve this goal, many
unsupervised learning representation disentanglement approaches have been
developed. However, the training process without utilizing any supervision
signal have been proved to be inadequate for disentanglement representation
learning. Therefore, we propose a novel weakly-supervised training approach,
named as SW-VAE, which incorporates pairs of input observations as supervision
signals by using the generative factors of datasets. Furthermore, we introduce
strategies to gradually increase the learning difficulty during training to
smooth the training process. As shown on several datasets, our model shows
significant improvement over state-of-the-art (SOTA) methods on representation
disentanglement tasks.</p>
  </details>
</details>
<details>
  <summary>65. <b>标题：DeepGraphONet: A Deep Graph Operator Network to Learn and Zero-shot  Transfer the Dynamic Response of Networked Systems</b></summary>
  <p><b>编号</b>：[218]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10622</p>
  <p><b>作者</b>：Yixuan Sun,  Christian Moya,  Guang Lin,  Meng Yue</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Deep Graph Operator, Graph Operator Network, Graph Neural Networks, underlying sub-graph structure, framework that learns</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper develops a Deep Graph Operator Network (DeepGraphONet) framework
that learns to approximate the dynamics of a complex system (e.g. the power
grid or traffic) with an underlying sub-graph structure. We build our
DeepGraphONet by fusing the ability of (i) Graph Neural Networks (GNN) to
exploit spatially correlated graph information and (ii) Deep Operator
Networks~(DeepONet) to approximate the solution operator of dynamical systems.
The resulting DeepGraphONet can then predict the dynamics within a given
short/medium-term time horizon by observing a finite history of the graph state
information. Furthermore, we design our DeepGraphONet to be
resolution-independent. That is, we do not require the finite history to be
collected at the exact/same resolution. In addition, to disseminate the results
from a trained DeepGraphONet, we design a zero-shot learning strategy that
enables using it on a different sub-graph. Finally, empirical results on the
(i) transient stability prediction problem of power grids and (ii) traffic flow
forecasting problem of a vehicular system illustrate the effectiveness of the
proposed DeepGraphONet.</p>
  </details>
</details>
<details>
  <summary>66. <b>标题：Learning-Augmented Algorithms for Online Linear and Semidefinite  Programming</b></summary>
  <p><b>编号</b>：[221]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10614</p>
  <p><b>作者</b>：Elena Grigorescu,  Young-San Lin,  Sandeep Silwal,  Maoyuan Song,  Samson Zhou</p>
  <p><b>备注</b>：42 pages, 3 figures. To appear in NeurIPS 2022</p>
  <p><b>关键词</b>：quadratically-constrained quadratic programming, yielding efficient solvers, quadratic programming, efficient solvers, covering SDP</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Semidefinite programming (SDP) is a unifying framework that generalizes both
linear programming and quadratically-constrained quadratic programming, while
also yielding efficient solvers, both in theory and in practice. However, there
exist known impossibility results for approximating the optimal solution when
constraints for covering SDPs arrive in an online fashion. In this paper, we
study online covering linear and semidefinite programs in which the algorithm
is augmented with advice from a possibly erroneous predictor. We show that if
the predictor is accurate, we can efficiently bypass these impossibility
results and achieve a constant-factor approximation to the optimal solution,
i.e., consistency. On the other hand, if the predictor is inaccurate, under
some technical conditions, we achieve results that match both the classical
optimal upper bounds and the tight lower bounds up to constant factors, i.e.,
robustness.
More broadly, we introduce a framework that extends both (1) the online set
cover problem augmented with machine-learning predictors, studied by Bamas,
Maggiori, and Svensson (NeurIPS 2020), and (2) the online covering SDP problem,
initiated by Elad, Kale, and Naor (ICALP 2016). Specifically, we obtain general
online learning-augmented algorithms for covering linear programs with
fractional advice and constraints, and initiate the study of learning-augmented
algorithms for covering SDP problems.
Our techniques are based on the primal-dual framework of Buchbinder and Naor
(Mathematics of Operations Research, 34, 2009) and can be further adjusted to
handle constraints where the variables lie in a bounded region, i.e., box
constraints.</p>
  </details>
</details>
<details>
  <summary>67. <b>标题：Grape Cold Hardiness Prediction via Multi-Task Learning</b></summary>
  <p><b>编号</b>：[229]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10585</p>
  <p><b>作者</b>：Aseem Saxena,  Paola Pesantez-Cabrera,  Rohan Ballapragada,  Kin-Ho Lam,  Alan Fern,  Markus Keller</p>
  <p><b>备注</b>：6 pages, 2 figures, submitted to IAAI-23</p>
  <p><b>关键词</b>：decrease harvest yields, significantly decrease harvest, harvest yields, temperatures during fall, fall and spring</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Cold temperatures during fall and spring have the potential to cause frost
damage to grapevines and other fruit plants, which can significantly decrease
harvest yields. To help prevent these losses, farmers deploy expensive frost
mitigation measures, such as, sprinklers, heaters, and wind machines, when they
judge that damage may occur. This judgment, however, is challenging because the
cold hardiness of plants changes throughout the dormancy period and it is
difficult to directly measure. This has led scientists to develop cold
hardiness prediction models that can be tuned to different grape cultivars
based on laborious field measurement data. In this paper, we study whether
deep-learning models can improve cold hardiness prediction for grapes based on
data that has been collected over a 30-year time period. A key challenge is
that the amount of data per cultivar is highly variable, with some cultivars
having only a small amount. For this purpose, we investigate the use of
multi-task learning to leverage data across cultivars in order to improve
prediction performance for individual cultivars. We evaluate a number of
multi-task learning approaches and show that the highest performing approach is
able to significantly improve over learning for single cultivars and
outperforms the current state-of-the-art scientific model for most cultivars.</p>
  </details>
</details>
<details>
  <summary>68. <b>标题：Continuous Mixtures of Tractable Probabilistic Models</b></summary>
  <p><b>编号</b>：[230]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10584</p>
  <p><b>作者</b>：Alvaro H.C. Correia,  Gennaro Gala,  Erik Quaeghebeur,  Cassio de Campos,  Robert Peharz</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：components depend continuously, variational autoencoders, components depend, depend continuously, continuous latent spaces</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Probabilistic models based on continuous latent spaces, such as variational
autoencoders, can be understood as uncountable mixture models where components
depend continuously on the latent code. They have proven expressive tools for
generative and probabilistic modelling, but are at odds with tractable
probabilistic inference, that is, computing marginals and conditionals of the
represented probability distribution. Meanwhile, tractable probabilistic models
such as probabilistic circuits (PCs) can be understood as hierarchical discrete
mixture models, which allows them to perform exact inference, but often they
show subpar performance in comparison to continuous latent-space models. In
this paper, we investigate a hybrid approach, namely continuous mixtures of
tractable models with a small latent dimension. While these models are
analytically intractable, they are well amenable to numerical integration
schemes based on a finite set of integration points. With a large enough number
of integration points the approximation becomes de-facto exact. Moreover, using
a finite set of integration points, the approximation method can be compiled
into a PC performing `exact inference in an approximate model'. In experiments,
we show that this simple scheme proves remarkably effective, as PCs learned
this way set new state-of-the-art for tractable models on many standard density
estimation benchmarks.</p>
  </details>
</details>
<details>
  <summary>69. <b>标题：First-order Policy Optimization for Robust Markov Decision Process</b></summary>
  <p><b>编号</b>：[232]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10579</p>
  <p><b>作者</b>：Yan Li,  Tuo Zhao,  Guanghui Lan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Markov decision process, solving robust Markov, robust Markov decision, uncertain transition kernels, finite action space</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We consider the problem of solving robust Markov decision process (MDP),
which involves a set of discounted, finite state, finite action space MDPs with
uncertain transition kernels. The goal of planning is to find a robust policy
that optimizes the worst-case values against the transition uncertainties, and
thus encompasses the standard MDP planning as a special case. For
$(\mathbf{s},\mathbf{a})$-rectangular uncertainty sets, we develop a
policy-based first-order method, namely the robust policy mirror descent
(RPMD), and establish an $\mathcal{O}(\log(1/\epsilon))$ and
$\mathcal{O}(1/\epsilon)$ iteration complexity for finding an
$\epsilon$-optimal policy, with two increasing-stepsize schemes. The prior
convergence of RPMD is applicable to any Bregman divergence, provided the
policy space has bounded radius measured by the divergence when centering at
the initial policy. Moreover, when the Bregman divergence corresponds to the
squared euclidean distance, we establish an $\mathcal{O}(\max \{1/\epsilon,
1/(\eta \epsilon^2)\})$ complexity of RPMD with any constant stepsize $\eta$.
For a general class of Bregman divergences, a similar complexity is also
established for RPMD with constant stepsizes, provided the uncertainty set
satisfies the relative strong convexity. We further develop a stochastic
variant, named SRPMD, when the first-order information is only available
through online interactions with the nominal environment. For general Bregman
divergences, we establish an $\mathcal{O}(1/\epsilon^2)$ and
$\mathcal{O}(1/\epsilon^3)$ sample complexity with two increasing-stepsize
schemes. For the euclidean Bregman divergence, we establish an
$\mathcal{O}(1/\epsilon^3)$ sample complexity with constant stepsizes. To the
best of our knowledge, all the aforementioned results appear to be new for
policy-based first-order methods applied to the robust MDP problem.</p>
  </details>
</details>
<details>
  <summary>70. <b>标题：Algorithm-Agnostic Interpretations for Clustering</b></summary>
  <p><b>编号</b>：[233]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10578</p>
  <p><b>作者</b>：Christian A. Scholbeck,  Henri Funk,  Giuseppe Casalicchio</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：involving dimension reduction, subsequent visualization, typically interpreted, reduction and subsequent, high-dimensional data</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A clustering outcome for high-dimensional data is typically interpreted via
post-processing, involving dimension reduction and subsequent visualization.
This destroys the meaning of the data and obfuscates interpretations. We
propose algorithm-agnostic interpretation methods to explain clustering
outcomes in reduced dimensions while preserving the integrity of the data. The
permutation feature importance for clustering represents a general framework
based on shuffling feature values and measuring changes in cluster assignments
through custom score functions. The individual conditional expectation for
clustering indicates observation-wise changes in the cluster assignment due to
changes in the data. The partial dependence for clustering evaluates average
changes in cluster assignments for the entire feature space. All methods can be
used with any clustering algorithm able to reassign instances through soft or
hard labels. In contrast to common post-processing methods such as principal
component analysis, the introduced methods maintain the original structure of
the features.</p>
  </details>
</details>
<details>
  <summary>71. <b>标题：A Tent Lévy Flying Sparrow Search Algorithm for Feature Selection: A  COVID-19 Case Study</b></summary>
  <p><b>编号</b>：[234]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10542</p>
  <p><b>作者</b>：Qinwen Yang,  Yuelin Gao,  Yanjie Song</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Curse of Dimensionality, sparrow search algorithm, information science, rapid development, development of information</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The "Curse of Dimensionality" induced by the rapid development of information
science, might have a negative impact when dealing with big datasets. In this
paper, we propose a variant of the sparrow search algorithm (SSA), called Tent
Lévy flying sparrow search algorithm (TFSSA), and use it to select the best
subset of features in the packing pattern for classification purposes. SSA is a
recently proposed algorithm that has not been systematically applied to feature
selection problems. After verification by the CEC2020 benchmark function, TFSSA
is used to select the best feature combination to maximize classification
accuracy and minimize the number of selected features. The proposed TFSSA is
compared with nine algorithms in the literature. Nine evaluation metrics are
used to properly evaluate and compare the performance of these algorithms on
twenty-one datasets from the UCI repository. Furthermore, the approach is
applied to the coronavirus disease (COVID-19) dataset, yielding the best
average classification accuracy and the average number of feature selections,
respectively, of 93.47% and 2.1. Experimental results confirm the advantages of
the proposed algorithm in improving classification accuracy and reducing the
number of selected features compared to other wrapper-based algorithms.</p>
  </details>
</details>
<details>
  <summary>72. <b>标题：Beyond Heisenberg Limit Quantum Metrology through Quantum Signal  Processing</b></summary>
  <p><b>编号</b>：[237]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.11207</p>
  <p><b>作者</b>：Yulong Dong,  Jonathan Gross,  Murphy Yuezhen Niu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Leveraging quantum effects, enhanced sensitivity, entanglement and coherence, Leveraging quantum, quantum effects</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Leveraging quantum effects in metrology such as entanglement and coherence
allows one to measure parameters with enhanced sensitivity. However,
time-dependent noise can disrupt such Heisenberg-limited amplification. We
propose a quantum-metrology method based on the quantum-signal-processing
framework to overcome these realistic noise-induced limitations in practical
quantum metrology. Our algorithm separates the gate parameter
$\varphi$~(single-qubit Z phase) that is susceptible to time-dependent error
from the target gate parameter $\theta$~(swap-angle between |10> and |01>
states) that is largely free of time-dependent error. Our method achieves an
accuracy of $10^{-4}$ radians in standard deviation for learning $\theta$ in
superconducting-qubit experiments, outperforming existing alternative schemes
by two orders of magnitude. We also demonstrate the increased robustness in
learning time-dependent gate parameters through fast Fourier transformation and
sequential phase difference. We show both theoretically and numerically that
there is an interesting transition of the optimal metrology variance scaling as
a function of circuit depth $d$ from the pre-asymptotic regime $d \ll 1/\theta$
to Heisenberg limit $d \to \infty$. Remarkably, in the pre-asymptotic regime
our method's estimation variance on time-sensitive parameter $\varphi$ scales
faster than the asymptotic Heisenberg limit as a function of depth,
$\text{Var}(\hat{\varphi})\approx 1/d^4$. Our work is the first
quantum-signal-processing algorithm that demonstrates practical application in
laboratory quantum computers.</p>
  </details>
</details>
<details>
  <summary>73. <b>标题：OLIVES Dataset: Ophthalmic Labels for Investigating Visual Eye Semantics</b></summary>
  <p><b>编号</b>：[238]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.11195</p>
  <p><b>作者</b>：Mohit Prabhushankar,  Kiran Kokilepersaud,  Yash-yee Logan,  Stephanie Trejo Corona,  Ghassan AlRegib,  Charles Wykoff</p>
  <p><b>备注</b>：Accepted at 36th Conference on Neural Information Processing Systems (NeurIPS 2022) Track on Datasets and Benchmarks</p>
  <p><b>关键词</b>：Optical Coherence Tomography, three-dimensional Optical Coherence, Coherence Tomography, Optical Coherence, Diabetic Macular Edema</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Clinical diagnosis of the eye is performed over multifarious data modalities
including scalar clinical labels, vectorized biomarkers, two-dimensional fundus
images, and three-dimensional Optical Coherence Tomography (OCT) scans.
Clinical practitioners use all available data modalities for diagnosing and
treating eye diseases like Diabetic Retinopathy (DR) or Diabetic Macular Edema
(DME). Enabling usage of machine learning algorithms within the ophthalmic
medical domain requires research into the relationships and interactions
between all relevant data over a treatment period. Existing datasets are
limited in that they neither provide data nor consider the explicit
relationship modeling between the data modalities. In this paper, we introduce
the Ophthalmic Labels for Investigating Visual Eye Semantics (OLIVES) dataset
that addresses the above limitation. This is the first OCT and near-IR fundus
dataset that includes clinical labels, biomarker labels, disease labels, and
time-series patient treatment information from associated clinical trials. The
dataset consists of 1268 near-IR fundus images each with at least 49 OCT scans,
and 16 biomarkers, along with 4 clinical labels and a disease diagnosis of DR
or DME. In total, there are 96 eyes' data averaged over a period of at least
two years with each eye treated for an average of 66 weeks and 7 injections. We
benchmark the utility of OLIVES dataset for ophthalmic data as well as provide
benchmarks and concrete research directions for core and emerging machine
learning paradigms within medical image analysis.</p>
  </details>
</details>
<details>
  <summary>74. <b>标题：SERF: Interpretable Sleep Staging using Embeddings, Rules, and Features</b></summary>
  <p><b>编号</b>：[239]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.11174</p>
  <p><b>作者</b>：Irfan Al-Hussaini (1),  Cassie S. Mitchell (1) ((1) Georgia Institute of Technology)</p>
  <p><b>备注</b>：Accepted by CIKM 2022</p>
  <p><b>关键词</b>：decision support systems, recent deep learning, deep learning based, systems is promising, learning based clinical</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The accuracy of recent deep learning based clinical decision support systems
is promising. However, lack of model interpretability remains an obstacle to
widespread adoption of artificial intelligence in healthcare. Using sleep as a
case study, we propose a generalizable method to combine clinical
interpretability with high accuracy derived from black-box deep learning.
Clinician-determined sleep stages from polysomnogram (PSG) remain the gold
standard for evaluating sleep quality. However, PSG manual annotation by
experts is expensive and time-prohibitive. We propose SERF, interpretable Sleep
staging using Embeddings, Rules, and Features to read PSG. SERF provides
interpretation of classified sleep stages through meaningful features derived
from the AASM Manual for the Scoring of Sleep and Associated Events. In SERF,
the embeddings obtained from a hybrid of convolutional and recurrent neural
networks are transposed to the interpretable feature space. These
representative interpretable features are used to train simple models like a
shallow decision tree for classification. Model results are validated on two
publicly available datasets. SERF surpasses the current state-of-the-art for
interpretable sleep staging by 2%. Using Gradient Boosted Trees as the
classifier, SERF obtains 0.766 $\kappa$ and 0.870 AUC-ROC, within 2% of the
current state-of-the-art black-box models.</p>
  </details>
</details>
<details>
  <summary>75. <b>标题：U-Sleep: resilient to AASM guidelines</b></summary>
  <p><b>编号</b>：[240]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.11173</p>
  <p><b>作者</b>：Luigi Fiorillo,  Giuliana Monachino,  Julia van der Meer,  Marco Pesce,  Jan Warncke,  Markus H. Schmidt,  Claudio L.A. Bassetti,  Athina Tzovara,  Paolo Favaro,  Francesca D. Faraci</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：sleep scoring, sleep scoring procedure, sleep scoring algorithm, sleep scoring rules, commonly used methodology</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>AASM guidelines are the results of decades of efforts to try to standardize
the sleep scoring procedure as to have a commonly used methodology. The
guidelines cover several aspects from the technical/digital specifications,
e.g., recommended EEG derivations, to the sleep scoring rules, e.g., different
rules for adults, children and infants. In the context of sleep scoring
automation, in the last decades, deep learning has demonstrated better
performance compared to many other approaches. In most of the cases, clinical
knowledge and guidelines have been exploited to support the automated sleep
scoring algorithms in solving the task. In this paper we show that, actually, a
deep learning based sleep scoring algorithm may not need to fully exploit the
clinical knowledge or to strictly follow the AASM guidelines. Specifically, we
demonstrate that U-Sleep, a state-of-the-art sleep scoring algorithm, can be
strong enough to solve the scoring task even using clinically non-recommended
or non-conventional derivations, and with no need to exploit information about
the chronological age of the subjects. We finally strengthen a well-known
finding that using data from multiple data centers always results in a better
performing model compared with training on a single cohort. Indeed, we show
that this latter statement is still valid even by increasing the size and the
heterogeneity of the single data cohort. In all our experiments we used 28528
polysomnography studies from 13 different clinical studies.</p>
  </details>
</details>
<details>
  <summary>76. <b>标题：EEG-Based Epileptic Seizure Prediction Using Temporal Multi-Channel  Transformers</b></summary>
  <p><b>编号</b>：[241]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.11172</p>
  <p><b>作者</b>：Ricardo V. Godoy,  Tharik J. S. Reis,  Paulo H. Polegato,  Gustavo J. G. Lahr,  Ricardo L. Saute,  Frederico N. Nakano,  Helio R. Machado,  Americo C. Sakamoto,  Marcelo Becker,  Glauco A. P. Caurin</p>
  <p><b>备注</b>：15 pages, 10 figures</p>
  <p><b>关键词</b>：common neurological diseases, unprovoked events called, events called epileptic, neurological diseases, characterized by transient</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Epilepsy is one of the most common neurological diseases, characterized by
transient and unprovoked events called epileptic seizures. Electroencephalogram
(EEG) is an auxiliary method used to perform both the diagnosis and the
monitoring of epilepsy. Given the unexpected nature of an epileptic seizure,
its prediction would improve patient care, optimizing the quality of life and
the treatment of epilepsy. Predicting an epileptic seizure implies the
identification of two distinct states of EEG in a patient with epilepsy: the
preictal and the interictal. In this paper, we developed two deep learning
models called Temporal Multi-Channel Transformer (TMC-T) and Vision Transformer
(TMC-ViT), adaptations of Transformer-based architectures for multi-channel
temporal signals. Moreover, we accessed the impact of choosing different
preictal duration, since its length is not a consensus among experts, and also
evaluated how the sample size benefits each model. Our models are compared with
fully connected, convolutional, and recurrent networks. The algorithms were
patient-specific trained and evaluated on raw EEG signals from the CHB-MIT
database. Experimental results and statistical validation demonstrated that our
TMC-ViT model surpassed the CNN architecture, state-of-the-art in seizure
prediction.</p>
  </details>
</details>
<details>
  <summary>77. <b>标题：MLGWSC-1: The first Machine Learning Gravitational-Wave Search Mock Data  Challenge</b></summary>
  <p><b>编号</b>：[243]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.11146</p>
  <p><b>作者</b>：Marlin B. Schäfer,  Ondřej Zelenka,  Alexander H. Nitz,  He Wang,  Shichao Wu,  Zong-Kuan Guo,  Zhoujian Cao,  Zhixiang Ren,  Paraskevi Nousi,  Nikolaos Stergioulas,  Panagiotis Iosif,  Alexandra E. Koloniari,  Anastasios Tefas,  Nikolaos Passalis,  Francesco Salemi,  Gabriele Vedovato,  Sergey Klimenko,  Tanmaya Mishra,  Bernd Brügmann,  Elena Cuoco,  E. A. Huerta,  Chris Messenger,  Frank Ohme</p>
  <p><b>备注</b>：25 pages, 6 figures, 4 tables, additional material available at this https URL</p>
  <p><b>关键词</b>：Machine Learning, Mock Data Challenge, machine learning algorithms, machine learning search, Learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present the results of the first Machine Learning Gravitational-Wave
Search Mock Data Challenge (MLGWSC-1). For this challenge, participating groups
had to identify gravitational-wave signals from binary black hole mergers of
increasing complexity and duration embedded in progressively more realistic
noise. The final of the 4 provided datasets contained real noise from the O3a
observing run and signals up to a duration of 20 seconds with the inclusion of
precession effects and higher order modes. We present the average sensitivity
distance and runtime for the 6 entered algorithms derived from 1 month of test
data unknown to the participants prior to submission. Of these, 4 are machine
learning algorithms. We find that the best machine learning based algorithms
are able to achieve up to 95% of the sensitive distance of matched-filtering
based production analyses for simulated Gaussian noise at a false-alarm rate
(FAR) of one per month. In contrast, for real noise, the leading machine
learning search achieved 70%. For higher FARs the differences in sensitive
distance shrink to the point where select machine learning submissions
outperform traditional search algorithms at FARs $\geq 200$ per month on some
datasets. Our results show that current machine learning search algorithms may
already be sensitive enough in limited parameter regions to be useful for some
production settings. To improve the state-of-the-art, machine learning
algorithms need to reduce the false-alarm rates at which they are capable of
detecting signals and extend their validity to regions of parameter space where
modeled searches are computationally expensive to run. Based on our findings we
compile a list of research areas that we believe are the most important to
elevate machine learning searches to an invaluable tool in gravitational-wave
signal detection.</p>
  </details>
</details>
<details>
  <summary>78. <b>标题：Structure Learning of Quantum Embeddings</b></summary>
  <p><b>编号</b>：[244]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.11144</p>
  <p><b>作者</b>：Massimiliano Incudini,  Francesco Martini,  Alessandra Di Pierro</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：machine learning methods, paramount importance, importance for machine, machine learning, learning methods</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The representation of data is of paramount importance for machine learning
methods. Kernel methods are used to enrich the feature representation, allowing
better generalization. Quantum kernels implement efficiently complex
transformation encoding classical data in the Hilbert space of a quantum
system, resulting in even exponential speedup. However, we need prior knowledge
of the data to choose an appropriate parametric quantum circuit that can be
used as quantum embedding. We propose an algorithm that automatically selects
the best quantum embedding through a combinatorial optimization procedure that
modifies the structure of the circuit, changing the generators of the gates,
their angles (which depend on the data points), and the qubits on which the
various gates act. Since combinatorial optimization is computationally
expensive, we have introduced a criterion based on the exponential
concentration of kernel matrix coefficients around the mean to immediately
discard an arbitrarily large portion of solutions that are believed to perform
poorly. Contrary to the gradient-based optimization (e.g. trainable quantum
kernels), our approach is not affected by the barren plateau by construction.
We have used both artificial and real-world datasets to demonstrate the
increased performance of our approach with respect to randomly generated PQC.
We have also compared the effect of different optimization algorithms,
including greedy local search, simulated annealing, and genetic algorithms,
showing that the algorithm choice largely affects the result.</p>
  </details>
</details>
<details>
  <summary>79. <b>标题：Training neural network ensembles via trajectory sampling</b></summary>
  <p><b>编号</b>：[245]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.11116</p>
  <p><b>作者</b>：Jamie F. Mair,  Dominic C. Rose,  Juan P. Garrahan</p>
  <p><b>备注</b>：12 pages, 5 figures, 1 appendix</p>
  <p><b>关键词</b>：neural network ensembles, single larger model, network ensembles, renewed interest, interest in neural</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In machine learning, there is renewed interest in neural network ensembles
(NNEs), whereby predictions are obtained as an aggregate from a diverse set of
smaller models, rather than from a single larger model. Here, we show how to
define and train a NNE using techniques from the study of rare trajectories in
stochastic systems. We define an NNE in terms of the trajectory of the model
parameters under a simple, and discrete in time, diffusive dynamics, and train
the NNE by biasing these trajectories towards a small time-integrated loss, as
controlled by appropriate counting fields which act as hyperparameters. We
demonstrate the viability of this technique on a range of simple supervised
learning tasks. We discuss potential advantages of our trajectory sampling
approach compared with more conventional gradient based methods.</p>
  </details>
</details>
<details>
  <summary>80. <b>标题：Cross-domain Voice Activity Detection with Self-Supervised  Representations</b></summary>
  <p><b>编号</b>：[246]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.11061</p>
  <p><b>作者</b>：Sina Alisamir,  Fabien Ringeval,  Francois Portet</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Voice Activity Detection, Activity Detection, detecting speech segments, Voice Activity, aims at detecting</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Voice Activity Detection (VAD) aims at detecting speech segments on an audio
signal, which is a necessary first step for many today's speech based
applications. Current state-of-the-art methods focus on training a neural
network exploiting features directly contained in the acoustics, such as Mel
Filter Banks (MFBs). Such methods therefore require an extra normalisation step
to adapt to a new domain where the acoustics is impacted, which can be simply
due to a change of speaker, microphone, or environment. In addition, this
normalisation step is usually a rather rudimentary method that has certain
limitations, such as being highly susceptible to the amount of data available
for the new domain. Here, we exploited the crowd-sourced Common Voice (CV)
corpus to show that representations based on Self-Supervised Learning (SSL) can
adapt well to different domains, because they are computed with contextualised
representations of speech across multiple domains. SSL representations also
achieve better results than systems based on hand-crafted representations
(MFBs), and off-the-shelf VADs, with significant improvement in cross-domain
settings.</p>
  </details>
</details>
<details>
  <summary>81. <b>标题：Fault Detection in Ball Bearings</b></summary>
  <p><b>编号</b>：[247]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.11041</p>
  <p><b>作者</b>：Joshua Pickard,  Sarah Moll</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：bearing joint IFD, rotating machinery, industry and research, critical component, detecting and locating</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Ball bearing joints are a critical component in all rotating machinery, and
detecting and locating faults in these joints is a significant problem in
industry and research. Intelligent fault detection (IFD) is the process of
applying machine learning and other statistical methods to monitor the health
states of machines. This paper explores the construction of vibration images, a
preprocessing technique that has been previously used to train convolutional
neural networks for ball bearing joint IFD. The main results demonstrate the
robustness of this technique by applying it to a larger dataset than previously
used and exploring the hyperparameters used in constructing the vibration
images.</p>
  </details>
</details>
<details>
  <summary>82. <b>标题：EventNet: Detecting Events in EEG</b></summary>
  <p><b>编号</b>：[250]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.11007</p>
  <p><b>作者</b>：Nick Seeuws,  Maarten De Vos,  Alexander Bertrand</p>
  <p><b>备注</b>：This work has been submitted to the IEEE for possible publication</p>
  <p><b>关键词</b>：analyzing EEG, EEG, events, event, event detection</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Neurologists are often looking for various "events of interest" when
analyzing EEG. To support them in this task various machine-learning-based
algorithms have been developed. Most of these algorithms treat the problem as
classification, thereby independently processing signal segments and ignoring
temporal dependencies inherent to events of varying duration. At inference
time, the predicted labels for each segment then have to be post processed to
detect the actual events. We propose an end-to-end event detection approach
(EventNet), based on deep learning, that directly works with events as learning
targets, stepping away from ad-hoc postprocessing schemes to turn model outputs
into events. We compare EventNet with a state-of-the-art approach for artefact
and and epileptic seizure detection, two event types with highly variable
durations. EventNet shows improved performance in detecting both event types.
These results show the power of treating events as direct learning targets,
instead of using ad-hoc postprocessing to obtain them. Our event detection
framework can easily be extended to other event detection problems in signal
processing, since the deep learning backbone does not depend on any
task-specific features.</p>
  </details>
</details>
<details>
  <summary>83. <b>标题：Entropic Descent Archetypal Analysis for Blind Hyperspectral Unmixing</b></summary>
  <p><b>编号</b>：[252]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.11002</p>
  <p><b>作者</b>：Alexandre Zouaoui (1),  Gedeon Muhawenayo (1),  Behnood Rasti (2),  Jocelyn Chanussot (1),  Julien Mairal (1) ((1) Thoth, Inria, UGA, CNRS, Grenoble INP, LJK, (2) HZDR)</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：assuming linear mixing, assuming linear, archetypal analysis, linear mixing, blind hyperspectral unmixing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we introduce a new algorithm based on archetypal analysis for
blind hyperspectral unmixing, assuming linear mixing of endmembers. Archetypal
analysis is a natural formulation for this task. This method does not require
the presence of pure pixels (i.e., pixels containing a single material) but
instead represents endmembers as convex combinations of a few pixels present in
the original hyperspectral image. Our approach leverages an entropic gradient
descent strategy, which (i) provides better solutions for hyperspectral
unmixing than traditional archetypal analysis algorithms, and (ii) leads to
efficient GPU implementations. Since running a single instance of our algorithm
is fast, we also propose an ensembling mechanism along with an appropriate
model selection procedure that make our method robust to hyper-parameter
choices while keeping the computational complexity reasonable. By using six
standard real datasets, we show that our approach outperforms state-of-the-art
matrix factorization and recent deep learning methods. We also provide an
open-source PyTorch implementation: this https URL.</p>
  </details>
</details>
<details>
  <summary>84. <b>标题：Modeling cognitive load as a self-supervised brain rate with  electroencephalography and deep learning</b></summary>
  <p><b>编号</b>：[253]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10992</p>
  <p><b>作者</b>：Luca Longo</p>
  <p><b>备注</b>：18 pages, 12 figures, 1 table</p>
  <p><b>关键词</b>：predict human performance, measuring mental workload, mental workload, mental workload modelling, EEG data</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The principal reason for measuring mental workload is to quantify the
cognitive cost of performing tasks to predict human performance. Unfortunately,
a method for assessing mental workload that has general applicability does not
exist yet. This research presents a novel self-supervised method for mental
workload modelling from EEG data employing Deep Learning and a continuous brain
rate, an index of cognitive activation, without requiring human declarative
knowledge. This method is a convolutional recurrent neural network trainable
with spatially preserving spectral topographic head-maps from EEG data to fit
the brain rate variable. Findings demonstrate the capacity of the convolutional
layers to learn meaningful high-level representations from EEG data since
within-subject models had a test Mean Absolute Percentage Error average of 11%.
The addition of a Long-Short Term Memory layer for handling sequences of
high-level representations was not significant, although it did improve their
accuracy. Findings point to the existence of quasi-stable blocks of learnt
high-level representations of cognitive activation because they can be induced
through convolution and seem not to be dependent on each other over time,
intuitively matching the non-stationary nature of brain responses.
Across-subject models, induced with data from an increasing number of
participants, thus containing more variability, obtained a similar accuracy to
the within-subject models. This highlights the potential generalisability of
the induced high-level representations across people, suggesting the existence
of subject-independent cognitive activation patterns. This research contributes
to the body of knowledge by providing scholars with a novel computational
method for mental workload modelling that aims to be generally applicable, does
not rely on ad-hoc human-crafted models supporting replicability and
falsifiability.</p>
  </details>
</details>
<details>
  <summary>85. <b>标题：EPIC TTS Models: Empirical Pruning Investigations Characterizing  Text-To-Speech Models</b></summary>
  <p><b>编号</b>：[258]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10890</p>
  <p><b>作者</b>：Perry Lam,  Huayun Zhang,  Nancy F. Chen,  Berrak Sisman</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：outperform dense models, outperform dense, TTS, Neural models, recent work</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Neural models are known to be over-parameterized, and recent work has shown
that sparse text-to-speech (TTS) models can outperform dense models. Although a
plethora of sparse methods has been proposed for other domains, such methods
have rarely been applied in TTS. In this work, we seek to answer the question:
what are the characteristics of selected sparse techniques on the performance
and model complexity? We compare a Tacotron2 baseline and the results of
applying five techniques. We then evaluate the performance via the factors of
naturalness, intelligibility and prosody, while reporting model size and
training time. Complementary to prior research, we find that pruning before or
during training can achieve similar performance to pruning after training and
can be trained much faster, while removing entire neurons degrades performance
much more than removing parameters. To our best knowledge, this is the first
work that compares sparsity paradigms in text-to-speech synthesis.</p>
  </details>
</details>
<details>
  <summary>86. <b>标题：Beyond Voxel Prediction Uncertainty: Identifying brain lesions you can  trust</b></summary>
  <p><b>编号</b>：[259]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10877</p>
  <p><b>作者</b>：Benjamin Lambert,  Florence Forbes,  Senan Doyle,  Alan Tucholka,  Michel Dojat</p>
  <p><b>备注</b>：Accepted for presentation at the Workshop on Interpretability of Machine Intelligence in Medical Image Computing (iMIMIC) at MICCAI 2022</p>
  <p><b>关键词</b>：Monte Carlo dropout, Deep neural networks, Monte Carlo, popular Monte Carlo, Graph Neural Network</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep neural networks have become the gold-standard approach for the automated
segmentation of 3D medical images. Their full acceptance by clinicians remains
however hampered by the lack of intelligible uncertainty assessment of the
provided results. Most approaches to quantify their uncertainty, such as the
popular Monte Carlo dropout, restrict to some measure of uncertainty in
prediction at the voxel level. In addition not to be clearly related to genuine
medical uncertainty, this is not clinically satisfying as most objects of
interest (e.g. brain lesions) are made of groups of voxels whose overall
relevance may not simply reduce to the sum or mean of their individual
uncertainties. In this work, we propose to go beyond voxel-wise assessment
using an innovative Graph Neural Network approach, trained from the outputs of
a Monte Carlo dropout model. This network allows the fusion of three estimators
of voxel uncertainty: entropy, variance, and model's confidence; and can be
applied to any lesion, regardless of its shape or size. We demonstrate the
superiority of our approach for uncertainty estimate on a task of Multiple
Sclerosis lesions segmentation.</p>
  </details>
</details>
<details>
  <summary>87. <b>标题：Nonsmooth Composite Nonconvex-Concave Minimax Optimization</b></summary>
  <p><b>编号</b>：[260]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10825</p>
  <p><b>作者</b>：Jiajin Li,  Linglingzhi Zhu,  Anthony Man-Cho So</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：including learning, adversarial learning, machine learning, received intense interest, learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Nonconvex-concave minimax optimization has received intense interest in
machine learning, including learning with robustness to data distribution,
learning with non-decomposable loss, adversarial learning, to name a few.
Nevertheless, most existing works focus on the gradient-descent-ascent (GDA)
variants that can only be applied in smooth settings. In this paper, we
consider a family of minimax problems whose objective function enjoys the
nonsmooth composite structure in the variable of minimization and is concave in
the variables of maximization. By fully exploiting the composite structure, we
propose a smoothed proximal linear descent ascent (\textit{smoothed} PLDA)
algorithm and further establish its $\mathcal{O}(\epsilon^{-4})$ iteration
complexity, which matches that of smoothed GDA~\cite{zhang2020single} under
smooth settings. Moreover, under the mild assumption that the objective
function satisfies the one-sided Kurdyka-Łojasiewicz condition with exponent
$\theta \in (0,1)$, we can further improve the iteration complexity to
$\mathcal{O}(\epsilon^{-2\max\{2\theta,1\}})$. To the best of our knowledge,
this is the first provably efficient algorithm for nonsmooth nonconvex-concave
problems that can achieve the optimal iteration complexity
$\mathcal{O}(\epsilon^{-2})$ if $\theta \in (0,1/2]$. As a byproduct, we
discuss different stationarity concepts and clarify their relationships
quantitatively, which could be of independent interest. Empirically, we
illustrate the effectiveness of the proposed smoothed PLDA in variation
regularized Wasserstein distributionally robust optimization problems.</p>
  </details>
</details>
<details>
  <summary>88. <b>标题：Review of Time Series Forecasting Methods and Their Applications to  Particle Accelerators</b></summary>
  <p><b>编号</b>：[264]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10705</p>
  <p><b>作者</b>：Sichen Li,  Andreas Adelmann</p>
  <p><b>备注</b>：13 pages, 11 figures</p>
  <p><b>关键词</b>：produce large amounts, clear optimization goals, defined control requirements, precisely defined control, time series forecasting</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Particle accelerators are complex facilities that produce large amounts of
structured data and have clear optimization goals as well as precisely defined
control requirements. As such they are naturally amenable to data-driven
research methodologies. The data from sensors and monitors inside the
accelerator form multivariate time series. With fast pre-emptive approaches
being highly preferred in accelerator control and diagnostics, the application
of data-driven time series forecasting methods is particularly promising.
This review formulates the time series forecasting problem and summarizes
existing models with applications in various scientific areas. Several current
and future attempts in the field of particle accelerators are introduced. The
application of time series forecasting to particle accelerators has shown
encouraging results and the promise for broader use, and existing problems such
as data consistency and compatibility have started to be addressed.</p>
  </details>
</details>
<details>
  <summary>89. <b>标题：SPICE, A Dataset of Drug-like Molecules and Peptides for Training  Machine Learning Potentials</b></summary>
  <p><b>编号</b>：[265]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10702</p>
  <p><b>作者</b>：Peter Eastman,  Pavan Kumar Behara,  David L. Dotson,  Raimondas Galvelis,  John E. Herr,  Josh T. Horton,  Yuezhi Mao,  John D. Chodera,  Benjamin P. Pritchard,  Yuanqing Wang,  Gianni De Fabritiis,  Thomas E. Markland</p>
  <p><b>备注</b>：19 pages, 6 figures</p>
  <p><b>关键词</b>：high quality datasets, important tool, development is held, held back, shortage of high</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Machine learning potentials are an important tool for molecular simulation,
but their development is held back by a shortage of high quality datasets to
train them on. We describe the SPICE dataset, a new quantum chemistry dataset
for training potentials relevant to simulating drug-like small molecules
interacting with proteins. It contains over 1.1 million conformations for a
diverse set of small molecules, dimers, dipeptides, and solvated amino acids.
It includes 15 elements, charged and uncharged molecules, and a wide range of
covalent and non-covalent interactions. It provides both forces and energies
calculated at the {\omega}B97M-D3(BJ)/def2-TZVPPD level of theory, along with
other useful quantities such as multipole moments and bond orders. We train a
set of machine learning potentials on it and demonstrate that they can achieve
chemical accuracy across a broad region of chemical space. It can serve as a
valuable resource for the creation of transferable, ready to use potential
functions for use in molecular simulations.</p>
  </details>
</details>
<details>
  <summary>90. <b>标题：A Validation Approach to Over-parameterized Matrix and Image Recovery</b></summary>
  <p><b>编号</b>：[267]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10675</p>
  <p><b>作者</b>：Lijun Ding,  Zhen Qin,  Liwei Jiang,  Jinxin Zhou,  Zhihui Zhu</p>
  <p><b>备注</b>：29 pages and 9 figures</p>
  <p><b>关键词</b>：noisy random linear, ground-truth matrix, random linear measurements, recovering a low-rank, number of noisy</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we study the problem of recovering a low-rank matrix from a
number of noisy random linear measurements. We consider the setting where the
rank of the ground-truth matrix is unknown a prior and use an overspecified
factored representation of the matrix variable, where the global optimal
solutions overfit and do not correspond to the underlying ground-truth. We then
solve the associated nonconvex problem using gradient descent with small random
initialization. We show that as long as the measurement operators satisfy the
restricted isometry property (RIP) with its rank parameter scaling with the
rank of ground-truth matrix rather than scaling with the overspecified matrix
variable, gradient descent iterations are on a particular trajectory towards
the ground-truth matrix and achieve nearly information-theoretically optimal
recovery when stop appropriately. We then propose an efficient early stopping
strategy based on the common hold-out method and show that it detects nearly
optimal estimator provably. Moreover, experiments show that the proposed
validation approach can also be efficiently used for image restoration with
deep image prior which over-parameterizes an image with a deep network.</p>
  </details>
</details>
<details>
  <summary>91. <b>标题：Modelling the Frequency of Home Deliveries: An Induced Travel Demand  Contribution of Aggrandized E-shopping in Toronto during COVID-19 Pandemics</b></summary>
  <p><b>编号</b>：[268]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10664</p>
  <p><b>作者</b>：Yicong Liu,  Kaili Wang,  Patrick Loa,  Khandker Nurul Habib</p>
  <p><b>备注</b>：The paper was presented at 2022 Annual Meeting of Transportation Research Board</p>
  <p><b>关键词</b>：pandemic dramatically catalyzed, pandemic dramatically, dramatically catalyzed, catalyzed the proliferation, machine learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The COVID-19 pandemic dramatically catalyzed the proliferation of e-shopping.
The dramatic growth of e-shopping will undoubtedly cause significant impacts on
travel demand. As a result, transportation modeller's ability to model
e-shopping demand is becoming increasingly important. This study developed
models to predict household' weekly home delivery frequencies. We used both
classical econometric and machine learning techniques to obtain the best model.
It is found that socioeconomic factors such as having an online grocery
membership, household members' average age, the percentage of male household
members, the number of workers in the household and various land use factors
influence home delivery demand. This study also compared the interpretations
and performances of the machine learning models and the classical econometric
model. Agreement is found in the variable's effects identified through the
machine learning and econometric models. However, with similar recall accuracy,
the ordered probit model, a classical econometric model, can accurately predict
the aggregate distribution of household delivery demand. In contrast, both
machine learning models failed to match the observed distribution.</p>
  </details>
</details>
<details>
  <summary>92. <b>标题：Interneurons accelerate learning dynamics in recurrent neural networks  for statistical adaptation</b></summary>
  <p><b>编号</b>：[271]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10634</p>
  <p><b>作者</b>：David Lipshutz,  Cengiz Pehlevan,  Dmitri B. Chklovskii</p>
  <p><b>备注</b>：16 pages, 5 figures</p>
  <p><b>关键词</b>：direct recurrent connections, Early sensory systems, brain rapidly adapt, direct recurrent, requires recurrent communication</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Early sensory systems in the brain rapidly adapt to fluctuating input
statistics, which requires recurrent communication between neurons.
Mechanistically, such recurrent communication is often indirect and mediated by
local interneurons. In this work, we explore the computational benefits of
mediating recurrent communication via interneurons compared with direct
recurrent connections. To this end, we consider two mathematically tractable
recurrent neural networks that statistically whiten their inputs -- one with
direct recurrent connections and the other with interneurons that mediate
recurrent communication. By analyzing the corresponding continuous synaptic
dynamics and numerically simulating the networks, we show that the network with
interneurons is more robust to initialization than the network with direct
recurrent connections in the sense that the convergence time for the synaptic
dynamics in the network with interneurons (resp. direct recurrent connections)
scales logarithmically (resp. linearly) with the spectrum of their
initialization. Our results suggest that interneurons are computationally
useful for rapid adaptation to changing input statistics. Interestingly, the
network with interneurons is an overparameterized solution of the whitening
objective for the network with direct recurrent connections, so our results can
be viewed as a recurrent neural network analogue of the implicit acceleration
phenomenon observed in overparameterized feedforward linear networks.</p>
  </details>
</details>
<details>
  <summary>93. <b>标题：Assessing ASR Model Quality on Disordered Speech using BERTScore</b></summary>
  <p><b>编号</b>：[273]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10591</p>
  <p><b>作者</b>：Jimmy Tobin,  Qisheng Li,  Subhashini Venugopalan,  Katie Seaver,  Richard Cave,  Katrin Tomanek</p>
  <p><b>备注</b>：Accepted to Interspeech 2022 Workshop on Speech for Social Good</p>
  <p><b>关键词</b>：Word Error Rate, automatic speech recognition, assess automatic speech, ASR, ASR model</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Word Error Rate (WER) is the primary metric used to assess automatic speech
recognition (ASR) model quality. It has been shown that ASR models tend to have
much higher WER on speakers with speech impairments than typical English
speakers. It is hard to determine if models can be be useful at such high error
rates. This study investigates the use of BERTScore, an evaluation metric for
text generation, to provide a more informative measure of ASR model quality and
usefulness. Both BERTScore and WER were compared to prediction errors manually
annotated by Speech Language Pathologists for error type and assessment.
BERTScore was found to be more correlated with human assessment of error type
and assessment. BERTScore was specifically more robust to orthographic changes
(contraction and normalization errors) where meaning was preserved.
Furthermore, BERTScore was a better fit of error assessment than WER, as
measured using an ordinal logistic regression and the Akaike's Information
Criterion (AIC). Overall, our findings suggest that BERTScore can complement
WER when assessing ASR model performance from a practical perspective,
especially for accessibility applications where models are useful even at lower
accuracy than for typical speech.</p>
  </details>
</details>
<details>
  <summary>94. <b>标题：SGC: A semi-supervised pipeline for gene clustering using self-training  approach in gene co-expression networks</b></summary>
  <p><b>编号</b>：[276]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10545</p>
  <p><b>作者</b>：Niloofar Aghaieabiane,  Ioannis Koutis</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：discover network structure, Gene Ontology, gene co-expression network, gene, gene expression</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A widely used approach for extracting information from gene expression data
employ the construction of a gene co-expression network and the subsequent
application of algorithms that discover network structure. In particular, a
common goal is the computational discovery of gene clusters, commonly called
modules. When applied on a novel gene expression dataset, the quality of the
computed modules can be evaluated automatically, using Gene Ontology
enrichment, a method that measures the frequencies of Gene Ontology terms in
the computed modules and evaluates their statistical likelihood. In this work
we propose SGC a novel pipeline for gene clustering based on relatively recent
seminal work in the mathematics of spectral network theory. SGC consists of
multiple novel steps that enable the computation of highly enriched modules in
an unsupervised manner. But unlike all existing frameworks, it further
incorporates a novel step that leverages Gene Ontology information in a
semi-supervised clustering method that further improves the quality of the
computed modules. Comparing with already well-known existing frameworks, we
show that SGC results in higher enrichment in real data. In particular, in 12
real gene expression datasets, SGC outperforms in all except one.</p>
  </details>
</details>
<h1>人工智能</h1>
<details>
  <summary>1. <b>标题：NamedMask: Distilling Segmenters from Complementary Foundation Models</b></summary>
  <p><b>编号</b>：[1]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.11228</p>
  <p><b>作者</b>：Gyungin Shin,  Weidi Xie,  Samuel Albanie</p>
  <p><b>备注</b>：Tech report. Code: this https URL</p>
  <p><b>关键词</b>：access to pixel-level, pixel-level labels, CLIP, images, object</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The goal of this work is to segment and name regions of images without access
to pixel-level labels during training. To tackle this task, we construct
segmenters by distilling the complementary strengths of two foundation models.
The first, CLIP (Radford et al. 2021), exhibits the ability to assign names to
image content but lacks an accessible representation of object structure. The
second, DINO (Caron et al. 2021), captures the spatial extent of objects but
has no knowledge of object names. Our method, termed NamedMask, begins by using
CLIP to construct category-specific archives of images. These images are
pseudo-labelled with a category-agnostic salient object detector bootstrapped
from DINO, then refined by category-specific segmenters using the CLIP archive
labels. Thanks to the high quality of the refined masks, we show that a
standard segmentation architecture trained on these archives with appropriate
data augmentation achieves impressive semantic segmentation abilities for both
single-object and multi-object images. As a result, our proposed NamedMask
performs favourably against a range of prior work on five benchmarks including
the VOC2012, COCO and large-scale ImageNet-S datasets.</p>
  </details>
</details>
<details>
  <summary>2. <b>标题：Concept Activation Regions: A Generalized Framework For Concept-Based  Explanations</b></summary>
  <p><b>编号</b>：[4]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.11222</p>
  <p><b>作者</b>：Jonathan Crabbé,  Mihaela van der Schaar</p>
  <p><b>备注</b>：Presented at NeurIPS 2022</p>
  <p><b>关键词</b>：DNN latent space, deep neural network, DNN latent, latent space, DNN</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Concept-based explanations permit to understand the predictions of a deep
neural network (DNN) through the lens of concepts specified by users. Existing
methods assume that the examples illustrating a concept are mapped in a fixed
direction of the DNN's latent space. When this holds true, the concept can be
represented by a concept activation vector (CAV) pointing in that direction. In
this work, we propose to relax this assumption by allowing concept examples to
be scattered across different clusters in the DNN's latent space. Each concept
is then represented by a region of the DNN's latent space that includes these
clusters and that we call concept activation region (CAR). To formalize this
idea, we introduce an extension of the CAV formalism that is based on the
kernel trick and support vector classifiers. This CAR formalism yields global
concept-based explanations and local concept-based feature importance. We prove
that CAR explanations built with radial kernels are invariant under latent
space isometries. In this way, CAR assigns the same explanations to latent
spaces that have the same geometry. We further demonstrate empirically that
CARs offer (1) more accurate descriptions of how concepts are scattered in the
DNN's latent space; (2) global explanations that are closer to human concept
annotations and (3) concept-based feature importance that meaningfully relate
concepts with each other. Finally, we use CARs to show that DNNs can
autonomously rediscover known scientific concepts, such as the prostate cancer
grading system.</p>
  </details>
</details>
<details>
  <summary>3. <b>标题：Learning Dexterous Manipulation from Exemplar Object Trajectories and  Pre-Grasps</b></summary>
  <p><b>编号</b>：[5]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.11221</p>
  <p><b>作者</b>：Sudeep Dasari,  Abhinav Gupta,  Vikash Kumar</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：open grand challenge, grand challenge, dexterous manipulation, dexterous manipulation behaviors, assorted objects remains</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Learning diverse dexterous manipulation behaviors with assorted objects
remains an open grand challenge. While policy learning methods offer a powerful
avenue to attack this problem, they require extensive per-task engineering and
algorithmic tuning. This paper seeks to escape these constraints, by developing
a Pre-Grasp informed Dexterous Manipulation (PGDM) framework that generates
diverse dexterous manipulation behaviors, without any task-specific reasoning
or hyper-parameter tuning. At the core of PGDM is a well known robotics
construct, pre-grasps (i.e. the hand-pose preparing for object interaction).
This simple primitive is enough to induce efficient exploration strategies for
acquiring complex dexterous manipulation behaviors. To exhaustively verify
these claims, we introduce TCDM, a benchmark of 50 diverse manipulation tasks
defined over multiple objects and dexterous manipulators. Tasks for TCDM are
defined automatically using exemplar object trajectories from various sources
(animators, human behaviors, etc.), without any per-task engineering and/or
supervision. Our experiments validate that PGDM's exploration strategy, induced
by a surprisingly simple ingredient (single pre-grasp pose), matches the
performance of prior methods, which require expensive per-task feature/reward
engineering, expert supervision, and hyper-parameter tuning. For animated
visualizations, trained policies, and project code, please refer to:
this https URL</p>
  </details>
</details>
<details>
  <summary>4. <b>标题：Layer Freezing & Data Sieving: Missing Pieces of a Generic Framework for  Sparse Training</b></summary>
  <p><b>编号</b>：[11]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.11204</p>
  <p><b>作者</b>：Geng Yuan,  Yanyu Li,  Sheng Li,  Zhenglun Kong,  Sergey Tulyakov,  Xulong Tang,  Yanzhi Wang,  Jian Ren</p>
  <p><b>备注</b>：Published in 36th Conference on Neural Information Processing Systems (NeurIPS 2022)</p>
  <p><b>关键词</b>：efficient deep learning, training, sparse training, training costs, layer freezing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recently, sparse training has emerged as a promising paradigm for efficient
deep learning on edge devices. The current research mainly devotes efforts to
reducing training costs by further increasing model sparsity. However,
increasing sparsity is not always ideal since it will inevitably introduce
severe accuracy degradation at an extremely high sparsity level. This paper
intends to explore other possible directions to effectively and efficiently
reduce sparse training costs while preserving accuracy. To this end, we
investigate two techniques, namely, layer freezing and data sieving. First, the
layer freezing approach has shown its success in dense model training and
fine-tuning, yet it has never been adopted in the sparse training domain.
Nevertheless, the unique characteristics of sparse training may hinder the
incorporation of layer freezing techniques. Therefore, we analyze the
feasibility and potentiality of using the layer freezing technique in sparse
training and find it has the potential to save considerable training costs.
Second, we propose a data sieving method for dataset-efficient training, which
further reduces training costs by ensuring only a partial dataset is used
throughout the entire training process. We show that both techniques can be
well incorporated into the sparse training algorithm to form a generic
framework, which we dub SpFDE. Our extensive experiments demonstrate that SpFDE
can significantly reduce training costs while preserving accuracy from three
dimensions: weight sparsity, layer freezing, and dataset sieving.</p>
  </details>
</details>
<details>
  <summary>5. <b>标题：Traffic Accident Risk Forecasting using Contextual Vision Transformers</b></summary>
  <p><b>编号</b>：[21]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.11180</p>
  <p><b>作者</b>：Khaled Saleh,  Artur Grigorev,  Adriana-Simona Mihaita</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：traffic accident risk, accident risk forecasting, intelligent transportation systems, transportation systems community, systems community due</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recently, the problem of traffic accident risk forecasting has been getting
the attention of the intelligent transportation systems community due to its
significant impact on traffic clearance. This problem is commonly tackled in
the literature by using data-driven approaches that model the spatial and
temporal incident impact, since they were shown to be crucial for the traffic
accident risk forecasting problem. To achieve this, most approaches build
different architectures to capture the spatio-temporal correlations features,
making them inefficient for large traffic accident datasets. Thus, in this
work, we are proposing a novel unified framework, namely a contextual vision
transformer, that can be trained in an end-to-end approach which can
effectively reason about the spatial and temporal aspects of the problem while
providing accurate traffic accident risk predictions. We evaluate and compare
the performance of our proposed methodology against baseline approaches from
the literature across two large-scale traffic accident datasets from two
different geographical locations. The results have shown a significant
improvement with roughly 2\% in RMSE score in comparison to previous
state-of-art works (SoTA) in the literature. Moreover, our proposed approach
has outperformed the SoTA technique over the two datasets while only requiring
23x fewer computational requirements.</p>
  </details>
</details>
<details>
  <summary>6. <b>标题：A Generalist Neural Algorithmic Learner</b></summary>
  <p><b>编号</b>：[29]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.11142</p>
  <p><b>作者</b>：Borja Ibarz,  Vitaly Kurin,  George Papamakarios,  Kyriacos Nikiforou,  Mehdi Bennani,  Róbert Csordás,  Andrew Dudzik,  Matko Bošnjak,  Alex Vitvitskyi,  Yulia Rubanova,  Andreea Deac,  Beatrice Bevilacqua,  Yaroslav Ganin,  Charles Blundell,  Petar Veličković</p>
  <p><b>备注</b>：20 pages, 10 figures</p>
  <p><b>关键词</b>：solve algorithmic tasks, neural algorithmic reasoning, ability to solve, specialist models, algorithmic tasks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The cornerstone of neural algorithmic reasoning is the ability to solve
algorithmic tasks, especially in a way that generalises out of distribution.
While recent years have seen a surge in methodological improvements in this
area, they mostly focused on building specialist models. Specialist models are
capable of learning to neurally execute either only one algorithm or a
collection of algorithms with identical control-flow backbone. Here, instead,
we focus on constructing a generalist neural algorithmic learner -- a single
graph neural network processor capable of learning to execute a wide range of
algorithms, such as sorting, searching, dynamic programming, path-finding and
geometry. We leverage the CLRS benchmark to empirically show that, much like
recent successes in the domain of perception, generalist algorithmic learners
can be built by "incorporating" knowledge. That is, it is possible to
effectively learn algorithms in a multi-task manner, so long as we can learn to
execute them well in a single-task regime. Motivated by this, we present a
series of improvements to the input representation, training regime and
processor architecture over CLRS, improving average single-task performance by
over 20% from prior art. We then conduct a thorough ablation of multi-task
learners leveraging these improvements. Our results demonstrate a generalist
learner that effectively incorporates knowledge captured by specialist models.</p>
  </details>
</details>
<details>
  <summary>7. <b>标题：Power Method, Inverse Power Method and Shifted Inverse Power Method  Neural Networks for Solving Eigenvalue Problems of Linear Operators</b></summary>
  <p><b>编号</b>：[32]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.11134</p>
  <p><b>作者</b>：Qihong Yang,  Yangtao Deng,  Yu Yang,  Qiaolin He,  Shiquan Zhang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Inverse Power Method, Shifted Inverse Power, Power Method Neural, Power Method, Inverse Power</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this article, we propose three methods Power Method Neural Network (PMNN),
Inverse Power Method Neural Networ (IPMNN) and Shifted Inverse Power Method
Neural Network (SIPMNN) combined with power method, inverse power method and
shifted inverse power method to solve eigenvalue problems with the dominant
eigenvalue, the smallest eigenvalue and the smallest zero eigenvalue,
respectively. The methods share similar spirits with traditional methods, but
the differences are the differential operator realized by Automatic
Differentiation (AD), the eigenfunction learned by the neural network and the
iterations implemented by optimizing the specially defined loss function. We
examine the applicability and accuracy of our methods in several numerical
examples in high dimensions. Numerical results obtained by our methods for
multidimensional problems show that our methods can provide accurate eigenvalue
and eigenfunction approximations.</p>
  </details>
</details>
<details>
  <summary>8. <b>标题：PACT: Perception-Action Causal Transformer for Autoregressive Robotics  Pre-Training</b></summary>
  <p><b>编号</b>：[33]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.11133</p>
  <p><b>作者</b>：Rogerio Bonatti,  Sai Vemprala,  Shuang Ma,  Felipe Frujeri,  Shuhang Chen,  Ashish Kapoor</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：require significant human, significant human expertise, Robotics has long, modules and connections, traditional or learning-based</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Robotics has long been a field riddled with complex systems architectures
whose modules and connections, whether traditional or learning-based, require
significant human expertise and prior knowledge. Inspired by large pre-trained
language models, this work introduces a paradigm for pre-training a general
purpose representation that can serve as a starting point for multiple tasks on
a given robot. We present the Perception-Action Causal Transformer (PACT), a
generative transformer-based architecture that aims to build representations
directly from robot data in a self-supervised fashion. Through autoregressive
prediction of states and actions over time, our model implicitly encodes
dynamics and behaviors for a particular robot. Our experimental evaluation
focuses on the domain of mobile agents, where we show that this robot-specific
representation can function as a single starting point to achieve distinct
tasks such as safe navigation, localization and mapping. We evaluate two form
factors: a wheeled robot that uses a LiDAR sensor as perception input (MuSHR),
and a simulated agent that uses first-person RGB images (Habitat). We show that
finetuning small task-specific networks on top of the larger pretrained model
results in significantly better performance compared to training a single model
from scratch for all tasks simultaneously, and comparable performance to
training a separate large model for each task independently. By sharing a
common good-quality representation across tasks we can lower overall model
capacity and speed up the real-time deployment of such systems.</p>
  </details>
</details>
<details>
  <summary>9. <b>标题：CMGAN: Conformer-Based Metric-GAN for Monaural Speech Enhancement</b></summary>
  <p><b>编号</b>：[40]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.11112</p>
  <p><b>作者</b>：Sherif Abdulatif,  Ruizhe Cao,  Bin Yang</p>
  <p><b>备注</b>：16 pages, 10 figures and 5 tables. arXiv admin note: text overlap with arXiv:2203.15149</p>
  <p><b>关键词</b>：automatic speech recognition, Convolution-augmented transformers, speech-domain applications, recently proposed, capture both local</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Convolution-augmented transformers (Conformers) are recently proposed in
various speech-domain applications, such as automatic speech recognition (ASR)
and speech separation, as they can capture both local and global dependencies.
In this paper, we propose a conformer-based metric generative adversarial
network (CMGAN) for speech enhancement (SE) in the time-frequency (TF) domain.
The generator encodes the magnitude and complex spectrogram information using
two-stage conformer blocks to model both time and frequency dependencies. The
decoder then decouples the estimation into a magnitude mask decoder branch to
filter out unwanted distortions and a complex refinement branch to further
improve the magnitude estimation and implicitly enhance the phase information.
Additionally, we include a metric discriminator to alleviate metric mismatch by
optimizing the generator with respect to a corresponding evaluation score.
Objective and subjective evaluations illustrate that CMGAN is able to show
superior performance compared to state-of-the-art methods in three speech
enhancement tasks (denoising, dereverberation and super-resolution). For
instance, quantitative denoising analysis on Voice Bank+DEMAND dataset
indicates that CMGAN outperforms various previous models with a margin, i.e.,
PESQ of 3.41 and SSNR of 11.10 dB.</p>
  </details>
</details>
<details>
  <summary>10. <b>标题：Parallel Reinforcement Learning Simulation for Visual Quadrotor  Navigation</b></summary>
  <p><b>编号</b>：[48]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.11094</p>
  <p><b>作者</b>：Jack Saunders,  Sajad Saeedi,  Wenbin Li</p>
  <p><b>备注</b>：This work has been submitted to the IEEE International Conference on Robotics and Automation (ICRA) for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible</p>
  <p><b>关键词</b>：Reinforcement learning, agent-based approach, approach for teaching, teaching robots, robots to navigate</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Reinforcement learning (RL) is an agent-based approach for teaching robots to
navigate within the physical world. Gathering data for RL is known to be a
laborious task, and real-world experiments can be risky. Simulators facilitate
the collection of training data in a quicker and more cost-effective manner.
However, RL frequently requires a significant number of simulation steps for an
agent to become skilful at simple tasks. This is a prevalent issue within the
field of RL-based visual quadrotor navigation where state dimensions are
typically very large and dynamic models are complex. Furthermore, rendering
images and obtaining physical properties of the agent can be computationally
expensive. To solve this, we present a simulation framework, built on AirSim,
which provides efficient parallel training. Building on this framework, Ape-X
is modified to incorporate decentralised training of AirSim environments to
make use of numerous networked computers. Through experiments we were able to
achieve a reduction in training time from 3.9 hours to 11 minutes using the
aforementioned framework and a total of 74 agents and two networked computers.
Further details including a github repo and videos about our project,
PRL4AirSim, can be found at this https URL</p>
  </details>
</details>
<details>
  <summary>11. <b>标题：Query-based Industrial Analytics over Knowledge Graphs with Ontology  Reshaping</b></summary>
  <p><b>编号</b>：[50]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.11089</p>
  <p><b>作者</b>：Zhuoxun Zheng,  Baifan Zhou,  Dongzhuoran Zhou,  Gong Cheng,  Ernesto Jiménez-Ruiz,  Ahmet Soylu,  Evgeny Kharlamo</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：anomaly detection heavily, detection heavily relies, heterogeneous production data, equipment diagnosis, diagnosis and anomaly</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Industrial analytics that includes among others equipment diagnosis and
anomaly detection heavily relies on integration of heterogeneous production
data. Knowledge Graphs (KGs) as the data format and ontologies as the unified
data schemata are a prominent solution that offers high quality data
integration and a convenient and standardised way to exchange data and to layer
analytical applications over it. However, poor design of ontologies of high
degree of mismatch between them and industrial data naturally lead to KGs of
low quality that impede the adoption and scalability of industrial analytics.
Indeed, such KGs substantially increase the training time of writing queries
for users, consume high volume of storage for redundant information, and are
hard to maintain and update. To address this problem we propose an ontology
reshaping approach to transform ontologies into KG schemata that better reflect
the underlying data and thus help to construct better KGs. In this poster we
present a preliminary discussion of our on-going research, evaluate our
approach with a rich set of SPARQL queries on real-world industry data at Bosch
and discuss our findings.</p>
  </details>
</details>
<details>
  <summary>12. <b>标题：Towards Ontology Reshaping for KG Generation with User-in-the-Loop:  Applied to Bosch Welding</b></summary>
  <p><b>编号</b>：[57]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.11067</p>
  <p><b>作者</b>：Dongzhuoran Zhou,  Baifan Zhou,  Jieying Chen,  Gong Cheng,  Egor V. Kostylev,  Evgeny Kharlamov</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：range of applications, ontology, wide range, domain ontology, data</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Knowledge graphs (KG) are used in a wide range of applications. The
automation of KG generation is very desired due to the data volume and variety
in industries. One important approach of KG generation is to map the raw data
to a given KG schema, namely a domain ontology, and construct the entities and
properties according to the ontology. However, the automatic generation of such
ontology is demanding and existing solutions are often not satisfactory. An
important challenge is a trade-off between two principles of ontology
engineering: knowledge-orientation and data-orientation. The former one
prescribes that an ontology should model the general knowledge of a domain,
while the latter one emphasises on reflecting the data specificities to ensure
good usability. We address this challenge by our method of ontology reshaping,
which automates the process of converting a given domain ontology to a smaller
ontology that serves as the KG schema. The domain ontology can be designed to
be knowledge-oriented and the KG schema covers the data specificities. In
addition, our approach allows the option of including user preferences in the
loop. We demonstrate our on-going research on ontology reshaping and present an
evaluation using real industrial data, with promising results.</p>
  </details>
</details>
<details>
  <summary>13. <b>标题：Developing, Evaluating and Scaling Learning Agents in Multi-Agent  Environments</b></summary>
  <p><b>编号</b>：[91]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10958</p>
  <p><b>作者</b>：Ian Gemp,  Thomas Anthony,  Yoram Bachrach,  Avishkar Bhoopchand,  Kalesha Bullard,  Jerome Connor,  Vibhavari Dasagi,  Bart De Vylder,  Edgar Duenez-Guzman,  Romuald Elie,  Richard Everett,  Daniel Hennes,  Edward Hughes,  Mina Khan,  Marc Lanctot,  Kate Larson,  Guy Lever,  Siqi Liu,  Luke Marris,  Kevin R. McKee,  Paul Muller,  Julien Perolat,  Florian Strub,  Andrea Tacchetti,  Eugene Tarassov,  Zhe Wang,  Karl Tuyls</p>
  <p><b>备注</b>：Published in AI Communications 2022</p>
  <p><b>关键词</b>：Game Theory, simulating social dilemmas, rich spatial environments, team coordination tasks, difficult team coordination</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The Game Theory & Multi-Agent team at DeepMind studies several aspects of
multi-agent learning ranging from computing approximations to fundamental
concepts in game theory to simulating social dilemmas in rich spatial
environments and training 3-d humanoids in difficult team coordination tasks. A
signature aim of our group is to use the resources and expertise made available
to us at DeepMind in deep reinforcement learning to explore multi-agent systems
in complex environments and use these benchmarks to advance our understanding.
Here, we summarise the recent work of our team and present a taxonomy that we
feel highlights many important open challenges in multi-agent research.</p>
  </details>
</details>
<details>
  <summary>14. <b>标题：An Information Minimization Based Contrastive Learning Model for  Unsupervised Sentence Embeddings Learning</b></summary>
  <p><b>编号</b>：[94]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10951</p>
  <p><b>作者</b>：Shaobin Chen,  Jie Zhou,  Yuling Sun,  Liang He</p>
  <p><b>备注</b>：11 pages, 3 figures, published to COLING 2022</p>
  <p><b>关键词</b>：push negative pairs, positive pairs similar, contrastive learning methods, positive instances, information</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Unsupervised sentence embeddings learning has been recently dominated by
contrastive learning methods (e.g., SimCSE), which keep positive pairs similar
and push negative pairs apart. The contrast operation aims to keep as much
information as possible by maximizing the mutual information between positive
instances, which leads to redundant information in sentence embedding. To
address this problem, we present an information minimization based contrastive
learning (InforMin-CL) model to retain the useful information and discard the
redundant information by maximizing the mutual information and minimizing the
information entropy between positive instances meanwhile for unsupervised
sentence representation learning. Specifically, we find that information
minimization can be achieved by simple contrast and reconstruction objectives.
The reconstruction operation reconstitutes the positive instance via the other
positive instance to minimize the information entropy between positive
instances. We evaluate our model on fourteen downstream tasks, including both
supervised and unsupervised (semantic textual similarity) tasks. Extensive
experimental results show that our InforMin-CL obtains a state-of-the-art
performance.</p>
  </details>
</details>
<details>
  <summary>15. <b>标题：A Capability and Skill Model for Heterogeneous Autonomous Robots</b></summary>
  <p><b>编号</b>：[117]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10900</p>
  <p><b>作者</b>：Luis Miguel Vieira da Silva,  Aljosha Köcher,  Alexander Fay</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：increasingly important due, complex tasks, increasingly important, important due, heterogeneous autonomous robots</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Teams of heterogeneous autonomous robots become increasingly important due to
their facilitation of various complex tasks. For such heterogeneous robots,
there is currently no consistent way of describing the functions that each
robot provides. In the field of manufacturing, capability modeling is
considered a promising approach to semantically model functions provided by
different machines. This contribution investigates how to apply and extend
capability models from manufacturing to the field of autonomous robots and
presents an approach for such a capability model.</p>
  </details>
</details>
<details>
  <summary>16. <b>标题：Process Modeling and Conformance Checking in Healthcare: A COVID-19 Case  Study</b></summary>
  <p><b>编号</b>：[118]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10897</p>
  <p><b>作者</b>：Elisabetta Benevento,  Marco Pegoraro,  Mattia Antoniazzi,  Harry H. Beyel,  Viki Peeva,  Paul Balfanz,  Wil M.P. van der Aalst,  Lukas Martin,  Gernot Marx</p>
  <p><b>备注</b>：12 pages, 2 figures, 3 tables, 15 references</p>
  <p><b>关键词</b>：solid track record, Intensive Care Unit, healthcare domain, solid track, track record</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The discipline of process mining has a solid track record of successful
applications to the healthcare domain. Within such research space, we conducted
a case study related to the Intensive Care Unit (ICU) ward of the Uniklinik
Aachen hospital in Germany. The aim of this work is twofold: developing a
normative model representing the clinical guidelines for the treatment of
COVID-19 patients, and analyzing the adherence of the observed behavior
(recorded in the information system of the hospital) to such guidelines. We
show that, through conformance checking techniques, it is possible to analyze
the care process for COVID-19 patients, highlighting the main deviations from
the clinical guidelines. The results provide physicians with useful indications
for improving the process and ensuring service quality and patient
satisfaction. We share the resulting model as an open-source BPMN file.</p>
  </details>
</details>
<details>
  <summary>17. <b>标题：SCALES: From Fairness Principles to Constrained Decision-Making</b></summary>
  <p><b>编号</b>：[134]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10860</p>
  <p><b>作者</b>：Sreejith Balakrishnan,  Jianxin Bi,  Harold Soh</p>
  <p><b>备注</b>：Accepted to the 2022 AAAI/ACM Conference on AI, Ethics, and Society (AIES '22), Updated version with additional citations, 14 pages</p>
  <p><b>关键词</b>：common representation based, paper proposes SCALES, translates well-established fairness, Markov Decision Process, paper proposes</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper proposes SCALES, a general framework that translates
well-established fairness principles into a common representation based on the
Constraint Markov Decision Process (CMDP). With the help of causal language,
our framework can place constraints on both the procedure of decision making
(procedural fairness) as well as the outcomes resulting from decisions (outcome
fairness). Specifically, we show that well-known fairness principles can be
encoded either as a utility component, a non-causal component, or a causal
component in a SCALES-CMDP. We illustrate SCALES using a set of case studies
involving a simulated healthcare scenario and the real-world COMPAS dataset.
Experiments demonstrate that our framework produces fair policies that embody
alternative fairness principles in single-step and sequential decision-making
scenarios.</p>
  </details>
</details>
<details>
  <summary>18. <b>标题：MnTTS: An Open-Source Mongolian Text-to-Speech Synthesis Dataset and  Accompanied Baseline</b></summary>
  <p><b>编号</b>：[136]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10848</p>
  <p><b>作者</b>：Yifan Hu,  Pengkai Yin,  Rui Liu,  Feilong Bao,  Guanglai Gao</p>
  <p><b>备注</b>：Accepted at the 2022 International Conference on Asian Language Processing (IALP2022)</p>
  <p><b>关键词</b>：million people worldwide, low-resource language spoken, high-quality open-source, million people, people worldwide</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper introduces a high-quality open-source text-to-speech (TTS)
synthesis dataset for Mongolian, a low-resource language spoken by over 10
million people worldwide. The dataset, named MnTTS, consists of about 8 hours
of transcribed audio recordings spoken by a 22-year-old professional female
Mongolian announcer. It is the first publicly available dataset developed to
promote Mongolian TTS applications in both academia and industry. In this
paper, we share our experience by describing the dataset development procedures
and faced challenges. To demonstrate the reliability of our dataset, we built a
powerful non-autoregressive baseline system based on FastSpeech2 model and
HiFi-GAN vocoder, and evaluated it using the subjective mean opinion score
(MOS) and real time factor (RTF) metrics. Evaluation results show that the
powerful baseline system trained on our dataset achieves MOS above 4 and RTF
about $3.30\times10^{-1}$, which makes it applicable for practical use. The
dataset, training recipe, and pretrained TTS models are freely available
\footnote{\label{github}\url{this https URL}}.</p>
  </details>
</details>
<details>
  <summary>19. <b>标题：The SpeakIn System Description for CNSRC2022</b></summary>
  <p><b>编号</b>：[137]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10846</p>
  <p><b>作者</b>：Yu Zheng,  Yihao Chen,  Jinghan Peng,  Yajun Zhang,  Min Liu,  Minqiang Xu</p>
  <p><b>备注</b>：4 pages</p>
  <p><b>关键词</b>：Speaker Recognition Challenge, CN-Celeb Speaker Recognition, track, fixed track, task</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This report describes our speaker verification systems for the tasks of the
CN-Celeb Speaker Recognition Challenge 2022 (CNSRC 2022). This challenge
includes two tasks, namely speaker verification(SV) and speaker retrieval(SR).
The SV task involves two tracks: fixed track and open track. In the fixed
track, we only used CN-Celeb.T as the training set. For the open track of the
SV task and SR task, we added our open-source audio data. The ResNet-based,
RepVGG-based, and TDNN-based architectures were developed for this challenge.
Global statistic pooling structure and MQMHA pooling structure were used to
aggregate the frame-level features across time to obtain utterance-level
representation. We adopted AM-Softmax and AAM-Softmax combined with the
Sub-Center method to classify the resulting embeddings. We also used the
Large-Margin Fine-Tuning strategy to further improve the model performance. In
the backend, Sub-Mean and AS-Norm were used. In the SV task fixed track, our
system was a fusion of five models, and two models were fused in the SV task
open track. And we used a single system in the SR task. Our approach leads to
superior performance and comes the 1st place in the open track of the SV task,
the 2nd place in the fixed track of the SV task, and the 3rd place in the SR
task.</p>
  </details>
</details>
<details>
  <summary>20. <b>标题：DIG: Draping Implicit Garment over the Human Body</b></summary>
  <p><b>编号</b>：[138]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10845</p>
  <p><b>作者</b>：Ren Li,  Benoît Guillard,  Edoardo Remelli,  Pascal Fua</p>
  <p><b>备注</b>：16 pages, 9 figures, 5 tables, ACCV 2022</p>
  <p><b>关键词</b>：posed human bodies, Existing data-driven methods, Existing data-driven, human bodies, posed human</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Existing data-driven methods for draping garments over posed human bodies,
despite being effective, cannot handle garments of arbitrary topology and are
typically not end-to-end differentiable. To address these limitations, we
propose an end-to-end differentiable pipeline that represents garments using
implicit surfaces and learns a skinning field conditioned on shape and pose
parameters of an articulated body model. To limit body-garment
interpenetrations and artifacts, we propose an interpretation-aware
pre-processing strategy of training data and a novel training loss that
penalizes self-intersections while draping garments. We demonstrate that our
method yields more accurate results for garment reconstruction and deformation
with respect to state-of-the-art methods. Furthermore, we show that our method,
thanks to its end-to-end differentiability, allows to recover body and garments
parameters jointly from image observations, something that previous work could
not do.</p>
  </details>
</details>
<details>
  <summary>21. <b>标题：Detecting Rotated Objects as Gaussian Distributions and Its 3-D  Generalization</b></summary>
  <p><b>编号</b>：[141]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10839</p>
  <p><b>作者</b>：Xue Yang,  Gefan Zhang,  Xiaojiang Yang,  Yue Zhou,  Wentao Wang,  Jin Tang,  Tao He,  Junchi Yan</p>
  <p><b>备注</b>：19 pages, 11 figures, 16 tables, accepted by TPAMI 2022. Journal extension for GWD (ICML'21) and KLD (NeurIPS'21). arXiv admin note: text overlap with arXiv:2101.11952</p>
  <p><b>关键词</b>：parameterized bounding box, additional rotation angle, bounding box, rotation angle parameter, parameterized bounding</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Existing detection methods commonly use a parameterized bounding box (BBox)
to model and detect (horizontal) objects and an additional rotation angle
parameter is used for rotated objects. We argue that such a mechanism has
fundamental limitations in building an effective regression loss for rotation
detection, especially for high-precision detection with high IoU (e.g. 0.75).
Instead, we propose to model the rotated objects as Gaussian distributions. A
direct advantage is that our new regression loss regarding the distance between
two Gaussians e.g. Kullback-Leibler Divergence (KLD), can well align the actual
detection performance metric, which is not well addressed in existing methods.
Moreover, the two bottlenecks i.e. boundary discontinuity and square-like
problem also disappear. We also propose an efficient Gaussian metric-based
label assignment strategy to further boost the performance. Interestingly, by
analyzing the BBox parameters' gradients under our Gaussian-based KLD loss, we
show that these parameters are dynamically updated with interpretable physical
meaning, which help explain the effectiveness of our approach, especially for
high-precision detection. We extend our approach from 2-D to 3-D with a
tailored algorithm design to handle the heading estimation, and experimental
results on twelve public datasets (2-D/3-D, aerial/text/face images) with
various base detectors show its superiority.</p>
  </details>
</details>
<details>
  <summary>22. <b>标题：High-order Multi-view Clustering for Generic Data</b></summary>
  <p><b>编号</b>：[142]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10838</p>
  <p><b>作者</b>：Erlin Pan,  Zhao Kang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Graph-based multi-view clustering, graph, Graph-based multi-view, data, multi-view clustering</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Graph-based multi-view clustering has achieved better performance than most
non-graph approaches. However, in many real-world scenarios, the graph
structure of data is not given or the quality of initial graph is poor.
Additionally, existing methods largely neglect the high-order neighborhood
information that characterizes complex intrinsic interactions. To tackle these
problems, we introduce an approach called high-order multi-view clustering
(HMvC) to explore the topology structure information of generic data. Firstly,
graph filtering is applied to encode structure information, which unifies the
processing of attributed graph data and non-graph data in a single framework.
Secondly, up to infinity-order intrinsic relationships are exploited to enrich
the learned graph. Thirdly, to explore the consistent and complementary
information of various views, an adaptive graph fusion mechanism is proposed to
achieve a consensus graph. Comprehensive experimental results on both non-graph
and attributed graph data show the superior performance of our method with
respect to various state-of-the-art techniques, including some deep learning
methods.</p>
  </details>
</details>
<details>
  <summary>23. <b>标题：Memory-Augmented Graph Neural Networks: A Neuroscience Perspective</b></summary>
  <p><b>编号</b>：[148]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10818</p>
  <p><b>作者</b>：Guixiang Ma,  Vy Vo,  Theodore Willke,  Nesreen K. Ahmed</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：including social networks, Graph neural networks, neural networks, social networks, including social</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Graph neural networks (GNNs) have been extensively used for many domains
where data are represented as graphs, including social networks, recommender
systems, biology, chemistry, etc. Recently, the expressive power of GNNs has
drawn much interest. It has been shown that, despite the promising empirical
results achieved by GNNs for many applications, there are some limitations in
GNNs that hinder their performance for some tasks. For example, since GNNs
update node features mainly based on local information, they have limited
expressive power in capturing long-range dependencies among nodes in graphs. To
address some of the limitations of GNNs, several recent works started to
explore augmenting GNNs with memory for improving their expressive power in the
relevant tasks. In this paper, we provide a comprehensive review of the
existing literature of memory-augmented GNNs. We review these works through the
lens of psychology and neuroscience, which has established multiple memory
systems and mechanisms in biological brains. We propose a taxonomy of the
memory GNN works, as well as a set of criteria for comparing the memory
mechanisms. We also provide critical discussions on the limitations of these
works. Finally, we discuss the challenges and future directions for this area.</p>
  </details>
</details>
<details>
  <summary>24. <b>标题：SR-GCL: Session-Based Recommendation with Global Context Enhanced  Augmentation in Contrastive Learning</b></summary>
  <p><b>编号</b>：[152]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10807</p>
  <p><b>作者</b>：Eunkyu Oh,  Taehun Kim,  Minsoo Kim,  Yunhu Ji,  Sushil Khyalia</p>
  <p><b>备注</b>：11 pages. This paper is accepted by DLG-AAAI'22</p>
  <p><b>关键词</b>：aim to predict, behavior of users, users based, based on ongoing, Session-based recommendations aim</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Session-based recommendations aim to predict the next behavior of users based
on ongoing sessions. The previous works have been modeling the session as a
variable-length of a sequence of items and learning the representation of both
individual items and the aggregated session. Recent research has applied graph
neural networks with an attention mechanism to capture complicated item
transitions and dependencies by modeling the sessions into graph-structured
data. However, they still face fundamental challenges in terms of data and
learning methodology such as sparse supervision signals and noisy interactions
in sessions, leading to sub-optimal performance. In this paper, we propose
SR-GCL, a novel contrastive learning framework for a session-based
recommendation. As a crucial component of contrastive learning, we propose two
global context enhanced data augmentation methods while maintaining the
semantics of the original session. The extensive experiment results on two
real-world E-commerce datasets demonstrate the superiority of SR-GCL as
compared to other state-of-the-art methods.</p>
  </details>
</details>
<details>
  <summary>25. <b>标题：STING: Self-attention based Time-series Imputation Networks using GAN</b></summary>
  <p><b>编号</b>：[157]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10801</p>
  <p><b>作者</b>：Eunkyu Oh,  Taehun Kim,  Yunhu Ji,  Sushil Khyalia</p>
  <p><b>备注</b>：10 pages. This paper is an accepted version by ICDM'21. The published version is this https URL</p>
  <p><b>关键词</b>：Time series data, Time series, multivariate time series, series data, series</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Time series data are ubiquitous in real-world applications. However, one of
the most common problems is that the time series data could have missing values
by the inherent nature of the data collection process. So imputing missing
values from multivariate (correlated) time series data is imperative to improve
a prediction performance while making an accurate data-driven decision.
Conventional works for imputation simply delete missing values or fill them
based on mean/zero. Although recent works based on deep neural networks have
shown remarkable results, they still have a limitation to capture the complex
generation process of the multivariate time series. In this paper, we propose a
novel imputation method for multivariate time series data, called STING
(Self-attention based Time-series Imputation Networks using GAN). We take
advantage of generative adversarial networks and bidirectional recurrent neural
networks to learn latent representations of the time series. In addition, we
introduce a novel attention mechanism to capture the weighted correlations of
the whole sequence and avoid potential bias brought by unrelated ones.
Experimental results on three real-world datasets demonstrate that STING
outperforms the existing state-of-the-art methods in terms of imputation
accuracy as well as downstream tasks with the imputed values therein.</p>
  </details>
</details>
<details>
  <summary>26. <b>标题：Deep Lake: a Lakehouse for Deep Learning</b></summary>
  <p><b>编号</b>：[166]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10785</p>
  <p><b>作者</b>：Sasun Hambardzumyan,  Abhinav Tuli,  Levon Ghukasyan,  Fariz Rahman,  Hrant Topchyan,  David Isayan,  Mikayel Harutyunyan,  Tatevik Hakobyan,  Ivo Stranic,  Davit Buniatyan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：running SQL queries, enabling time travel, running SQL, SQL queries, lakes provide critical</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Traditional data lakes provide critical data infrastructure for analytical
workloads by enabling time travel, running SQL queries, ingesting data with
ACID transactions, and visualizing petabyte-scale datasets on cloud storage.
They allow organizations to break down data silos, unlock data-driven
decision-making, improve operational efficiency, and reduce costs. However, as
deep learning takes over common analytical workflows, traditional data lakes
become less useful for applications such as natural language processing (NLP),
audio processing, computer vision, and applications involving non-tabular
datasets. This paper presents Deep Lake, an open-source lakehouse for deep
learning applications developed at Activeloop. Deep Lake maintains the benefits
of a vanilla data lake with one key difference: it stores complex data, such as
images, videos, annotations, as well as tabular data, in the form of tensors
and rapidly streams the data over the network to (a) Tensor Query Language, (b)
in-browser visualization engine, or (c) deep learning frameworks without
sacrificing GPU utilization. Datasets stored in Deep Lake can be accessed from
PyTorch, TensorFlow, JAX, and integrate with numerous MLOps tools.</p>
  </details>
</details>
<details>
  <summary>27. <b>标题：Learning Model Predictive Controllers with Real-Time Attention for  Real-World Navigation</b></summary>
  <p><b>编号</b>：[167]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10780</p>
  <p><b>作者</b>：Xuesu Xiao,  Tingnan Zhang,  Krzysztof Choromanski,  Edward Lee,  Anthony Francis,  Jake Varley,  Stephen Tu,  Sumeet Singh,  Peng Xu,  Fei Xia,  Sven Mikael Persson,  Dmitry Kalashnikov,  Leila Takayama,  Roy Frostig,  Jie Tan,  Carolina Parada,  Vikas Sindhwani</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：human-occupied public spaces, face real-world challenges, existing navigation systems, decades of research, public spaces</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Despite decades of research, existing navigation systems still face
real-world challenges when deployed in the wild, e.g., in cluttered home
environments or in human-occupied public spaces. To address this, we present a
new class of implicit control policies combining the benefits of imitation
learning with the robust handling of system constraints from Model Predictive
Control (MPC). Our approach, called Performer-MPC, uses a learned cost function
parameterized by vision context embeddings provided by Performers -- a low-rank
implicit-attention Transformer. We jointly train the cost function and
construct the controller relying on it, effectively solving end-to-end the
corresponding bi-level optimization problem. We show that the resulting policy
improves standard MPC performance by leveraging a few expert demonstrations of
the desired navigation behavior in different challenging real-world scenarios.
Compared with a standard MPC policy, Performer-MPC achieves >40% better goal
reached in cluttered environments and >65% better on social metrics when
navigating around humans.</p>
  </details>
</details>
<details>
  <summary>28. <b>标题：MUI-TARE: Multi-Agent Cooperative Exploration with Unknown Initial  Position</b></summary>
  <p><b>编号</b>：[169]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10775</p>
  <p><b>作者</b>：Jingtian Yan,  Xingqiao Lin,  Zhongqiang Ren,  Shiqi Zhao,  Jieqiong Yu,  Chao Cao,  Peng Yin,  Ji Zhang,  Sebastian Scherer</p>
  <p><b>备注</b>：8 pages, 8 figures, Submitted to IEEE RAL</p>
  <p><b>关键词</b>：unknown initial positions, challenging problem, unknown initial, initial positions, exploration</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Multi-agent exploration of a bounded 3D environment with unknown initial
positions of agents is a challenging problem. It requires quickly exploring the
environments as well as robustly merging the sub-maps built by the agents. We
take the view that the existing approaches are either aggressive or
conservative: Aggressive strategies merge two sub-maps built by different
agents together when overlap is detected, which can lead to incorrect merging
due to the false-positive detection of the overlap and is thus not robust.
Conservative strategies direct one agent to revisit an excessive amount of the
historical trajectory of another agent for verification before merging, which
can lower the exploration efficiency due to the repeated exploration of the
same space. To intelligently balance the robustness of sub-map merging and
exploration efficiency, we develop a new approach for lidar-based multi-agent
exploration, which can direct one agent to repeat another agent's trajectory in
an \emph{adaptive} manner based on the quality indicator of the sub-map merging
process. Additionally, our approach extends the recent single-agent
hierarchical exploration strategy to multiple agents in a \emph{cooperative}
manner by planning for agents with merged sub-maps together to further improve
exploration efficiency. Our experiments show that our approach is up to 50\%
more efficient than the baselines on average while merging sub-maps robustly.</p>
  </details>
</details>
<details>
  <summary>29. <b>标题：Multi-level Adversarial Spatio-temporal Learning for Footstep Pressure  based FoG Detection</b></summary>
  <p><b>编号</b>：[170]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10770</p>
  <p><b>作者</b>：Kun Hu,  Shaohui Mei,  Wei Wang,  Kaylena A. Ehgoetz Martens,  Liang Wang,  Simon J.G. Lewis,  David D. Feng,  Zhiyong Wang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：central nervous system, nervous system impacting, system impacting millions, Parkinson disease, symptoms of Parkinson</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Freezing of gait (FoG) is one of the most common symptoms of Parkinson's
disease, which is a neurodegenerative disorder of the central nervous system
impacting millions of people around the world. To address the pressing need to
improve the quality of treatment for FoG, devising a computer-aided detection
and quantification tool for FoG has been increasingly important. As a
non-invasive technique for collecting motion patterns, the footstep pressure
sequences obtained from pressure sensitive gait mats provide a great
opportunity for evaluating FoG in the clinic and potentially in the home
environment. In this study, FoG detection is formulated as a sequential
modelling task and a novel deep learning architecture, namely Adversarial
Spatio-temporal Network (ASTN), is proposed to learn FoG patterns across
multiple levels. A novel adversarial training scheme is introduced with a
multi-level subject discriminator to obtain subject-independent FoG
representations, which helps to reduce the over-fitting risk due to the high
inter-subject variance. As a result, robust FoG detection can be achieved for
unseen subjects. The proposed scheme also sheds light on improving
subject-level clinical studies from other scenarios as it can be integrated
with many existing deep architectures. To the best of our knowledge, this is
one of the first studies of footstep pressure-based FoG detection and the
approach of utilizing ASTN is the first deep neural network architecture in
pursuit of subject-independent representations. Experimental results on 393
trials collected from 21 subjects demonstrate encouraging performance of the
proposed ASTN for FoG detection with an AUC 0.85.</p>
  </details>
</details>
<details>
  <summary>30. <b>标题：DRAMA: Joint Risk Localization and Captioning in Driving</b></summary>
  <p><b>编号</b>：[171]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10767</p>
  <p><b>作者</b>：Srikanth Malla,  Chiho Choi,  Isht Dwivedi,  Joon Hee Choi,  Jiachen Li</p>
  <p><b>备注</b>：WACV 2023 (Winter Conference on Applications of Computer Vision)</p>
  <p><b>关键词</b>：safety-critical automation systems, driving, driving scenes, Driving Risk Assessment, Risk Assessment Mechanism</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Considering the functionality of situational awareness in safety-critical
automation systems, the perception of risk in driving scenes and its
explainability is of particular importance for autonomous and cooperative
driving. Toward this goal, this paper proposes a new research direction of
joint risk localization in driving scenes and its risk explanation as a natural
language description. Due to the lack of standard benchmarks, we collected a
large-scale dataset, DRAMA (Driving Risk Assessment Mechanism with A captioning
module), which consists of 17,785 interactive driving scenarios collected in
Tokyo, Japan. Our DRAMA dataset accommodates video- and object-level questions
on driving risks with associated important objects to achieve the goal of
visual captioning as a free-form language description utilizing closed and
open-ended responses for multi-level questions, which can be used to evaluate a
range of visual captioning capabilities in driving scenarios. We make this data
available to the community for further research. Using DRAMA, we explore
multiple facets of joint risk localization and captioning in interactive
driving scenarios. In particular, we benchmark various multi-task prediction
architectures and provide a detailed analysis of joint risk localization and
risk captioning. The data set is available at this https URL</p>
  </details>
</details>
<details>
  <summary>31. <b>标题：INFINITY: A Simple Yet Effective Unsupervised Framework for Graph-Text  Mutual Conversion</b></summary>
  <p><b>编号</b>：[175]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10754</p>
  <p><b>作者</b>：Yi Xu,  Luoyi Fu,  Zhouhan Lin,  Jiexing Qi,  Xinbing Wang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：triple extraction, applying knowledge graphs, constructing and applying, applying knowledge, unsupervised</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Graph-to-text (G2T) generation and text-to-graph (T2G) triple extraction are
two essential tasks for constructing and applying knowledge graphs. Existing
unsupervised approaches turn out to be suitable candidates for jointly learning
the two tasks due to their avoidance of using graph-text parallel data.
However, they are composed of multiple modules and still require both entity
information and relation type in the training process. To this end, we propose
INFINITY, a simple yet effective unsupervised approach that does not require
external annotation tools or additional parallel information. It achieves fully
unsupervised graph-text mutual conversion for the first time. Specifically,
INFINITY treats both G2T and T2G as a bidirectional sequence generation task by
fine-tuning only one pretrained seq2seq model. A novel back-translation-based
framework is then designed to automatically generate continuous synthetic
parallel data. To obtain reasonable graph sequences with structural information
from source texts, INFINITY employs reward-based training loss by leveraging
the advantage of reward augmented maximum likelihood. As a fully unsupervised
framework, INFINITY is empirically verified to outperform state-of-the-art
baselines for G2T and T2G tasks.</p>
  </details>
</details>
<details>
  <summary>32. <b>标题：Reinforcement Learning in Computing and Network Convergence  Orchestration</b></summary>
  <p><b>编号</b>：[176]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10753</p>
  <p><b>作者</b>：Aidong Yang,  Mohan Wu,  Boquan Cheng,  Xiaozhou Ye,  Ye Ouyang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：digital economy era, attracted wide attention, Network Convergence, CNC orchestration, CNC</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As computing power is becoming the core productivity of the digital economy
era, the concept of Computing and Network Convergence (CNC), under which
network and computing resources can be dynamically scheduled and allocated
according to users' needs, has been proposed and attracted wide attention.
Based on the tasks' properties, the network orchestration plane needs to
flexibly deploy tasks to appropriate computing nodes and arrange paths to the
computing nodes. This is a orchestration problem that involves resource
scheduling and path arrangement. Since CNC is relatively new, in this paper, we
review some researches and applications on CNC. Then, we design a CNC
orchestration method using reinforcement learning (RL), which is the first
attempt, that can flexibly allocate and schedule computing resources and
network resources. Which aims at high profit and low latency. Meanwhile, we use
multi-factors to determine the optimization objective so that the orchestration
strategy is optimized in terms of total performance from different aspects,
such as cost, profit, latency and system overload in our experiment. The
experiments shows that the proposed RL-based method can achieve higher profit
and lower latency than the greedy method, random selection and
balanced-resource method. We demonstrate RL is suitable for CNC orchestration.
This paper enlightens the RL application on CNC orchestration.</p>
  </details>
</details>
<details>
  <summary>33. <b>标题：CCR: Facial Image Editing with Continuity, Consistency and Reversibility</b></summary>
  <p><b>编号</b>：[181]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10734</p>
  <p><b>作者</b>：Nan Yang,  Xin Luan,  Huidi Jia,  Zhi Han,  Yandong Tang</p>
  <p><b>备注</b>：10 pages, 11 figures</p>
  <p><b>关键词</b>：editing, sequential facial image, facial image editing, incontinuous editing, facial image</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Three problems exist in sequential facial image editing: incontinuous
editing, inconsistent editing, and irreversible editing. Incontinuous editing
is that the current editing can not retain the previously edited attributes.
Inconsistent editing is that swapping the attribute editing orders can not
yield the same results. Irreversible editing means that operating on a facial
image is irreversible, especially in sequential facial image editing. In this
work, we put forward three concepts and corresponding definitions: editing
continuity, consistency, and reversibility. Then, we propose a novel model to
achieve the goal of editing continuity, consistency, and reversibility. A
sufficient criterion is defined to determine whether a model is continuous,
consistent, and reversible. Extensive qualitative and quantitative experimental
results validate our proposed model and show that a continuous, consistent and
reversible editing model has a more flexible editing function while preserving
facial identity. Furthermore, we think that our proposed definitions and model
will have wide and promising applications in multimedia processing. Code and
data are available at this https URL.</p>
  </details>
</details>
<details>
  <summary>34. <b>标题：Enhanced Decentralized Federated Learning based on Consensus in  Connected Vehicles</b></summary>
  <p><b>编号</b>：[186]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10722</p>
  <p><b>作者</b>：Xiaoyan Liu,  Zehui Dong,  Zhiwei Xu,  Siyuan Liu,  Jie Tian</p>
  <p><b>备注</b>：9 pages, 10 figures, Journal</p>
  <p><b>关键词</b>：distributed decision making, Machine Learning, train machine learning, Federated learning, Advanced researches</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Advanced researches on connected vehicles have recently targeted to the
integration of vehicle-to-everything (V2X) networks with Machine Learning (ML)
tools and distributed decision making. Federated learning (FL) is emerging as a
new paradigm to train machine learning (ML) models in distributed systems,
including vehicles in V2X networks. Rather than sharing and uploading the
training data to the server, the updating of model parameters (e.g., neural
networks' weights and biases) is applied by large populations of interconnected
vehicles, acting as local learners. Despite these benefits, the limitation of
existing approaches is the centralized optimization which relies on a server
for aggregation and fusion of local parameters, leading to the drawback of a
single point of failure and scaling issues for increasing V2X network size.
Meanwhile, in intelligent transport scenarios, data collected from onboard
sensors are redundant, which degrades the performance of aggregation. To tackle
these problems, we explore a novel idea of decentralized data processing and
introduce a federated learning framework for in-network vehicles,
C-DFL(Consensus based Decentralized Federated Learning), to tackle federated
learning on connected vehicles and improve learning quality. Extensive
simulations have been implemented to evaluate the performance of C-DFL, that
demonstrates C-DFL outperforms the performance of conventional methods in all
cases.</p>
  </details>
</details>
<details>
  <summary>35. <b>标题：Batch Bayesian optimisation via density-ratio estimation with guarantees</b></summary>
  <p><b>编号</b>：[188]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10715</p>
  <p><b>作者</b>：Rafael Oliveira,  Louis Tiao,  Fabio Ramos</p>
  <p><b>备注</b>：Paper accepted at NeurIPS 2022</p>
  <p><b>关键词</b>：shown remarkable success, applications involving expensive, involving expensive black-box, expensive black-box functions, shown remarkable</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Bayesian optimisation (BO) algorithms have shown remarkable success in
applications involving expensive black-box functions. Traditionally BO has been
set as a sequential decision-making process which estimates the utility of
query points via an acquisition function and a prior over functions, such as a
Gaussian process. Recently, however, a reformulation of BO via density-ratio
estimation (BORE) allowed reinterpreting the acquisition function as a
probabilistic binary classifier, removing the need for an explicit prior over
functions and increasing scalability. In this paper, we present a theoretical
analysis of BORE's regret and an extension of the algorithm with improved
uncertainty estimates. We also show that BORE can be naturally extended to a
batch optimisation setting by recasting the problem as approximate Bayesian
inference. The resulting algorithm comes equipped with theoretical performance
guarantees and is assessed against other batch BO baselines in a series of
experiments.</p>
  </details>
</details>
<details>
  <summary>36. <b>标题：Learning from Symmetry: Meta-Reinforcement Learning with Symmetric Data  and Language Instructions</b></summary>
  <p><b>编号</b>：[208]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10656</p>
  <p><b>作者</b>：Xiangtong Yao,  Zhenshan Bing,  Genghang Zhuang,  Kejia Chen,  Hongkuan Zhou,  Kai Huang,  Alois Knoll</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：promising approach, learning, language instructions, tasks quickly, generalization</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Meta-reinforcement learning (meta-RL) is a promising approach that enables
the agent to learn new tasks quickly. However, most meta-RL algorithms show
poor generalization in multiple-task scenarios due to the insufficient task
information provided only by rewards. Language-conditioned meta-RL improves the
generalization by matching language instructions and the agent's behaviors.
Learning from symmetry is an important form of human learning, therefore,
combining symmetry and language instructions into meta-RL can help improve the
algorithm's generalization and learning efficiency. We thus propose a dual-MDP
meta-reinforcement learning method that enables learning new tasks efficiently
with symmetric data and language instructions. We evaluate our method in
multiple challenging manipulation tasks, and experimental results show our
method can greatly improve the generalization and efficiency of
meta-reinforcement learning.</p>
  </details>
</details>
<details>
  <summary>37. <b>标题：SW-VAE: Weakly Supervised Learn Disentangled Representation Via Latent  Factor Swapping</b></summary>
  <p><b>编号</b>：[217]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10623</p>
  <p><b>作者</b>：Jiageng Zhu,  Hanchen Xie,  Wael Abd-Almageed</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：benefits various downstream, Representation disentanglement, Representation, important goal, disentanglement</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Representation disentanglement is an important goal of representation
learning that benefits various downstream tasks. To achieve this goal, many
unsupervised learning representation disentanglement approaches have been
developed. However, the training process without utilizing any supervision
signal have been proved to be inadequate for disentanglement representation
learning. Therefore, we propose a novel weakly-supervised training approach,
named as SW-VAE, which incorporates pairs of input observations as supervision
signals by using the generative factors of datasets. Furthermore, we introduce
strategies to gradually increase the learning difficulty during training to
smooth the training process. As shown on several datasets, our model shows
significant improvement over state-of-the-art (SOTA) methods on representation
disentanglement tasks.</p>
  </details>
</details>
<details>
  <summary>38. <b>标题：Current and Near-Term AI as a Potential Existential Risk Factor</b></summary>
  <p><b>编号</b>：[224]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10604</p>
  <p><b>作者</b>：Benjamin S. Bucknall,  Shiri Dori-Hacohen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Artificial General Intelligence, artificial intelligence technologies, Artificial intelligence, Artificial General, unaligned Artificial General</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>There is a substantial and ever-growing corpus of evidence and literature
exploring the impacts of Artificial intelligence (AI) technologies on society,
politics, and humanity as a whole. A separate, parallel body of work has
explored existential risks to humanity, including but not limited to that
stemming from unaligned Artificial General Intelligence (AGI). In this paper,
we problematise the notion that current and near-term artificial intelligence
technologies have the potential to contribute to existential risk by acting as
intermediate risk factors, and that this potential is not limited to the
unaligned AGI scenario. We propose the hypothesis that certain
already-documented effects of AI can act as existential risk factors,
magnifying the likelihood of previously identified sources of existential risk.
Moreover, future developments in the coming decade hold the potential to
significantly exacerbate these risk factors, even in the absence of artificial
general intelligence. Our main contribution is a (non-exhaustive) exposition of
potential AI risk factors and the causal relationships between them, focusing
on how AI can affect power dynamics and information security. This exposition
demonstrates that there exist causal pathways from AI systems to existential
risks that do not presuppose hypothetical future AI capabilities.</p>
  </details>
</details>
<details>
  <summary>39. <b>标题：Continuous Mixtures of Tractable Probabilistic Models</b></summary>
  <p><b>编号</b>：[230]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10584</p>
  <p><b>作者</b>：Alvaro H.C. Correia,  Gennaro Gala,  Erik Quaeghebeur,  Cassio de Campos,  Robert Peharz</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：components depend continuously, variational autoencoders, components depend, depend continuously, continuous latent spaces</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Probabilistic models based on continuous latent spaces, such as variational
autoencoders, can be understood as uncountable mixture models where components
depend continuously on the latent code. They have proven expressive tools for
generative and probabilistic modelling, but are at odds with tractable
probabilistic inference, that is, computing marginals and conditionals of the
represented probability distribution. Meanwhile, tractable probabilistic models
such as probabilistic circuits (PCs) can be understood as hierarchical discrete
mixture models, which allows them to perform exact inference, but often they
show subpar performance in comparison to continuous latent-space models. In
this paper, we investigate a hybrid approach, namely continuous mixtures of
tractable models with a small latent dimension. While these models are
analytically intractable, they are well amenable to numerical integration
schemes based on a finite set of integration points. With a large enough number
of integration points the approximation becomes de-facto exact. Moreover, using
a finite set of integration points, the approximation method can be compiled
into a PC performing `exact inference in an approximate model'. In experiments,
we show that this simple scheme proves remarkably effective, as PCs learned
this way set new state-of-the-art for tractable models on many standard density
estimation benchmarks.</p>
  </details>
</details>
<details>
  <summary>40. <b>标题：First-order Policy Optimization for Robust Markov Decision Process</b></summary>
  <p><b>编号</b>：[232]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10579</p>
  <p><b>作者</b>：Yan Li,  Tuo Zhao,  Guanghui Lan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Markov decision process, solving robust Markov, robust Markov decision, uncertain transition kernels, finite action space</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We consider the problem of solving robust Markov decision process (MDP),
which involves a set of discounted, finite state, finite action space MDPs with
uncertain transition kernels. The goal of planning is to find a robust policy
that optimizes the worst-case values against the transition uncertainties, and
thus encompasses the standard MDP planning as a special case. For
$(\mathbf{s},\mathbf{a})$-rectangular uncertainty sets, we develop a
policy-based first-order method, namely the robust policy mirror descent
(RPMD), and establish an $\mathcal{O}(\log(1/\epsilon))$ and
$\mathcal{O}(1/\epsilon)$ iteration complexity for finding an
$\epsilon$-optimal policy, with two increasing-stepsize schemes. The prior
convergence of RPMD is applicable to any Bregman divergence, provided the
policy space has bounded radius measured by the divergence when centering at
the initial policy. Moreover, when the Bregman divergence corresponds to the
squared euclidean distance, we establish an $\mathcal{O}(\max \{1/\epsilon,
1/(\eta \epsilon^2)\})$ complexity of RPMD with any constant stepsize $\eta$.
For a general class of Bregman divergences, a similar complexity is also
established for RPMD with constant stepsizes, provided the uncertainty set
satisfies the relative strong convexity. We further develop a stochastic
variant, named SRPMD, when the first-order information is only available
through online interactions with the nominal environment. For general Bregman
divergences, we establish an $\mathcal{O}(1/\epsilon^2)$ and
$\mathcal{O}(1/\epsilon^3)$ sample complexity with two increasing-stepsize
schemes. For the euclidean Bregman divergence, we establish an
$\mathcal{O}(1/\epsilon^3)$ sample complexity with constant stepsizes. To the
best of our knowledge, all the aforementioned results appear to be new for
policy-based first-order methods applied to the robust MDP problem.</p>
  </details>
</details>
<details>
  <summary>41. <b>标题：SERF: Interpretable Sleep Staging using Embeddings, Rules, and Features</b></summary>
  <p><b>编号</b>：[239]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.11174</p>
  <p><b>作者</b>：Irfan Al-Hussaini (1),  Cassie S. Mitchell (1) ((1) Georgia Institute of Technology)</p>
  <p><b>备注</b>：Accepted by CIKM 2022</p>
  <p><b>关键词</b>：decision support systems, recent deep learning, deep learning based, systems is promising, learning based clinical</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The accuracy of recent deep learning based clinical decision support systems
is promising. However, lack of model interpretability remains an obstacle to
widespread adoption of artificial intelligence in healthcare. Using sleep as a
case study, we propose a generalizable method to combine clinical
interpretability with high accuracy derived from black-box deep learning.
Clinician-determined sleep stages from polysomnogram (PSG) remain the gold
standard for evaluating sleep quality. However, PSG manual annotation by
experts is expensive and time-prohibitive. We propose SERF, interpretable Sleep
staging using Embeddings, Rules, and Features to read PSG. SERF provides
interpretation of classified sleep stages through meaningful features derived
from the AASM Manual for the Scoring of Sleep and Associated Events. In SERF,
the embeddings obtained from a hybrid of convolutional and recurrent neural
networks are transposed to the interpretable feature space. These
representative interpretable features are used to train simple models like a
shallow decision tree for classification. Model results are validated on two
publicly available datasets. SERF surpasses the current state-of-the-art for
interpretable sleep staging by 2%. Using Gradient Boosted Trees as the
classifier, SERF obtains 0.766 $\kappa$ and 0.870 AUC-ROC, within 2% of the
current state-of-the-art black-box models.</p>
  </details>
</details>
<details>
  <summary>42. <b>标题：EEG-Based Epileptic Seizure Prediction Using Temporal Multi-Channel  Transformers</b></summary>
  <p><b>编号</b>：[241]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.11172</p>
  <p><b>作者</b>：Ricardo V. Godoy,  Tharik J. S. Reis,  Paulo H. Polegato,  Gustavo J. G. Lahr,  Ricardo L. Saute,  Frederico N. Nakano,  Helio R. Machado,  Americo C. Sakamoto,  Marcelo Becker,  Glauco A. P. Caurin</p>
  <p><b>备注</b>：15 pages, 10 figures</p>
  <p><b>关键词</b>：common neurological diseases, unprovoked events called, events called epileptic, neurological diseases, characterized by transient</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Epilepsy is one of the most common neurological diseases, characterized by
transient and unprovoked events called epileptic seizures. Electroencephalogram
(EEG) is an auxiliary method used to perform both the diagnosis and the
monitoring of epilepsy. Given the unexpected nature of an epileptic seizure,
its prediction would improve patient care, optimizing the quality of life and
the treatment of epilepsy. Predicting an epileptic seizure implies the
identification of two distinct states of EEG in a patient with epilepsy: the
preictal and the interictal. In this paper, we developed two deep learning
models called Temporal Multi-Channel Transformer (TMC-T) and Vision Transformer
(TMC-ViT), adaptations of Transformer-based architectures for multi-channel
temporal signals. Moreover, we accessed the impact of choosing different
preictal duration, since its length is not a consensus among experts, and also
evaluated how the sample size benefits each model. Our models are compared with
fully connected, convolutional, and recurrent networks. The algorithms were
patient-specific trained and evaluated on raw EEG signals from the CHB-MIT
database. Experimental results and statistical validation demonstrated that our
TMC-ViT model surpassed the CNN architecture, state-of-the-art in seizure
prediction.</p>
  </details>
</details>
<details>
  <summary>43. <b>标题：Over-the-Air Computation over Balanced Numerals</b></summary>
  <p><b>编号</b>：[251]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.11004</p>
  <p><b>作者</b>：Alphan Sahin,  Rui Yang</p>
  <p><b>备注</b>：6 pages, 3 figures, Accepted to GLOBECOM'2022 Workshops: Workshop on Wireless Communications for Distributed Intelligence</p>
  <p><b>关键词</b>：continuous-valued gradient aggregation, achieving continuous-valued gradient, achieving continuous-valued, proposed scheme, proposed scheme encodes</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this study, a digital over-the-air computation (OAC) scheme for achieving
continuous-valued gradient aggregation is proposed. It is shown that the
average of a set of real-valued parameters can be calculated approximately by
using the average of the corresponding numerals, where the numerals are
obtained based on a balanced number system. By using this property, the
proposed scheme encodes the local gradients into a set of numerals. It then
determines the positions of the activated orthogonal frequency division
multiplexing (OFDM) subcarriers by using the values of the numerals. To
eliminate the need for a precise sample-level time synchronization, channel
estimation overhead, and power instabilities due to the channel inversion, the
proposed scheme also uses a non-coherent receiver at the edge server (ES) and
does not utilize a pre-equalization at the edge devices (EDs). Finally, the
theoretical mean squared error (MSE) performance of the proposed scheme is
derived and its performance for federated edge learning (FEEL) is demonstrated.</p>
  </details>
</details>
<details>
  <summary>44. <b>标题：Modeling cognitive load as a self-supervised brain rate with  electroencephalography and deep learning</b></summary>
  <p><b>编号</b>：[253]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10992</p>
  <p><b>作者</b>：Luca Longo</p>
  <p><b>备注</b>：18 pages, 12 figures, 1 table</p>
  <p><b>关键词</b>：predict human performance, measuring mental workload, mental workload, mental workload modelling, EEG data</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The principal reason for measuring mental workload is to quantify the
cognitive cost of performing tasks to predict human performance. Unfortunately,
a method for assessing mental workload that has general applicability does not
exist yet. This research presents a novel self-supervised method for mental
workload modelling from EEG data employing Deep Learning and a continuous brain
rate, an index of cognitive activation, without requiring human declarative
knowledge. This method is a convolutional recurrent neural network trainable
with spatially preserving spectral topographic head-maps from EEG data to fit
the brain rate variable. Findings demonstrate the capacity of the convolutional
layers to learn meaningful high-level representations from EEG data since
within-subject models had a test Mean Absolute Percentage Error average of 11%.
The addition of a Long-Short Term Memory layer for handling sequences of
high-level representations was not significant, although it did improve their
accuracy. Findings point to the existence of quasi-stable blocks of learnt
high-level representations of cognitive activation because they can be induced
through convolution and seem not to be dependent on each other over time,
intuitively matching the non-stationary nature of brain responses.
Across-subject models, induced with data from an increasing number of
participants, thus containing more variability, obtained a similar accuracy to
the within-subject models. This highlights the potential generalisability of
the induced high-level representations across people, suggesting the existence
of subject-independent cognitive activation patterns. This research contributes
to the body of knowledge by providing scholars with a novel computational
method for mental workload modelling that aims to be generally applicable, does
not rely on ad-hoc human-crafted models supporting replicability and
falsifiability.</p>
  </details>
</details>
<details>
  <summary>45. <b>标题：DeepVARwT: Deep Learning for a VAR Model with Trend</b></summary>
  <p><b>编号</b>：[274]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2209.10587</p>
  <p><b>作者</b>：Xixi Li,  Jingsong Yuan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：multiple time series, stationary time series, time series, multiple time, VAR model</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The vector autoregressive (VAR) model has been used to describe the
dependence within and across multiple time series. This is a model for
stationary time series which can be extended to allow the presence of a
deterministic trend in each series. Detrending the data either parametrically
or nonparametrically before fitting the VAR model gives rise to more errors in
the latter part. In this study, we propose a new approach called DeepVARwT that
employs deep learning methodology for maximum likelihood estimation of the
trend and the dependence structure at the same time. A Long Short-Term Memory
(LSTM) network is used for this purpose. To ensure the stability of the model,
we enforce the causality condition on the autoregressive coefficients using the
transformation of Ansley & Kohn (1986). We provide a simulation study and an
application to real data. In the simulation study, we use realistic trend
functions generated from real data and compare the estimates with true
function/parameter values. In the real data application, we compare the
prediction performance of this model with state-of-the-art models in the
literature.</p>
  </details>
</details>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">徐耀彬</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://louishsu.xyz/2022/09/23/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html">http://louishsu.xyz/2022/09/23/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://louishsu.xyz" target="_blank">LOUIS' BLOG</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"></div><div class="post_share"><div class="social-share" data-image="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="next-post pull-full"><a href="/2021/10/22/%E4%B8%AD%E5%9B%BD%E6%B3%95%E5%BE%8B%E6%99%BA%E8%83%BD%E6%8A%80%E6%9C%AF%E8%AF%84%E6%B5%8B(CAIL2021)%EF%BC%9A%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96(Rank2).html"><img class="next-cover" src="http://cail.cipsc.org.cn/img/index_mainpic.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">中国法律智能技术评测(CAIL2021)：信息抽取(Rank2)</div></div></a></div></nav><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="twikoo-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="card-info-avatar is-center"><img class="avatar-img" src="/img/touxiang.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/><div class="author-info__name">徐耀彬</div><div class="author-info__description">做知识的原创者！</div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">11</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">标签</div><div class="length-num">3</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">分类</div><div class="length-num">7</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/isLouisHsu"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/isLouisHsu" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:is.louishsu@foxmail.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>公告</span></div><div class="announcement_content">记录和分享一些学习和开源内容，若有问题可通过邮箱is.louishsu@foxmail.com联系，欢迎交流！！</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">1.</span> <span class="toc-text">统计</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">2.</span> <span class="toc-text">计算机视觉</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">3.</span> <span class="toc-text">自然语言处理</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">4.</span> <span class="toc-text">机器学习</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">5.</span> <span class="toc-text">人工智能</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2022/09/23/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html" title="Arxiv每日速递(2022-09-23)"><img src="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Arxiv每日速递(2022-09-23)"/></a><div class="content"><a class="title" href="/2022/09/23/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html" title="Arxiv每日速递(2022-09-23)">Arxiv每日速递(2022-09-23)</a><time datetime="2022-09-23T00:57:07.696Z" title="发表于 2022-09-23 08:57:07">2022-09-23</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/10/22/%E4%B8%AD%E5%9B%BD%E6%B3%95%E5%BE%8B%E6%99%BA%E8%83%BD%E6%8A%80%E6%9C%AF%E8%AF%84%E6%B5%8B(CAIL2021)%EF%BC%9A%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96(Rank2).html" title="中国法律智能技术评测(CAIL2021)：信息抽取(Rank2)"><img src="http://cail.cipsc.org.cn/img/index_mainpic.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="中国法律智能技术评测(CAIL2021)：信息抽取(Rank2)"/></a><div class="content"><a class="title" href="/2021/10/22/%E4%B8%AD%E5%9B%BD%E6%B3%95%E5%BE%8B%E6%99%BA%E8%83%BD%E6%8A%80%E6%9C%AF%E8%AF%84%E6%B5%8B(CAIL2021)%EF%BC%9A%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96(Rank2).html" title="中国法律智能技术评测(CAIL2021)：信息抽取(Rank2)">中国法律智能技术评测(CAIL2021)：信息抽取(Rank2)</a><time datetime="2021-10-22T14:29:06.000Z" title="发表于 2021-10-22 22:29:06">2021-10-22</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/05/19/%E5%85%A8%E7%90%83%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%8A%80%E6%9C%AF%E5%88%9B%E6%96%B0%E5%A4%A7%E8%B5%9B%E3%80%90%E8%B5%9B%E9%81%93%E4%B8%80%E3%80%91%EF%BC%9A%E5%8C%BB%E5%AD%A6%E5%BD%B1%E5%83%8F%E6%8A%A5%E5%91%8A%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B.html" title="全球人工智能技术创新大赛【赛道一】：医学影像报告异常检测"><img src="https://tianchi-public.oss-cn-hangzhou.aliyuncs.com/public/files/forum/161037709574435991610377095138.jpeg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="全球人工智能技术创新大赛【赛道一】：医学影像报告异常检测"/></a><div class="content"><a class="title" href="/2021/05/19/%E5%85%A8%E7%90%83%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%8A%80%E6%9C%AF%E5%88%9B%E6%96%B0%E5%A4%A7%E8%B5%9B%E3%80%90%E8%B5%9B%E9%81%93%E4%B8%80%E3%80%91%EF%BC%9A%E5%8C%BB%E5%AD%A6%E5%BD%B1%E5%83%8F%E6%8A%A5%E5%91%8A%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B.html" title="全球人工智能技术创新大赛【赛道一】：医学影像报告异常检测">全球人工智能技术创新大赛【赛道一】：医学影像报告异常检测</a><time datetime="2021-05-19T09:57:06.000Z" title="发表于 2021-05-19 17:57:06">2021-05-19</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2020/09/16/%E8%AF%A6%E8%A7%A3%E5%91%BD%E5%90%8D%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB%E6%A8%A1%E5%9E%8B%EF%BC%9ALSTM-CRF.html" title="详解命名实体识别模型：LSTM-CRF"><img src="https://gimg2.baidu.com/image_search/src=http%3A%2F%2Fpic1.zhimg.com%2Fv2-1ed6a10dbb239a148e42df088c5870a6_1440w.jpg%3Fsource%3D172ae18b&amp;refer=http%3A%2F%2Fpic1.zhimg.com&amp;app=2002&amp;size=f9999,10000&amp;q=a80&amp;n=0&amp;g=0n&amp;fmt=jpeg?sec=1638183974&amp;t=4632f13fd487ed1cfcb12d67a6b71e52" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="详解命名实体识别模型：LSTM-CRF"/></a><div class="content"><a class="title" href="/2020/09/16/%E8%AF%A6%E8%A7%A3%E5%91%BD%E5%90%8D%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB%E6%A8%A1%E5%9E%8B%EF%BC%9ALSTM-CRF.html" title="详解命名实体识别模型：LSTM-CRF">详解命名实体识别模型：LSTM-CRF</a><time datetime="2020-09-16T09:26:44.000Z" title="发表于 2020-09-16 17:26:44">2020-09-16</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2020/06/14/%E8%AE%B0%E4%B8%80%E6%AC%A1MySQL%E8%A7%A3%E5%86%B3%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E6%97%B6%E7%9A%84%E5%88%86%E8%A1%A8%E9%97%AE%E9%A2%98.html" title="记一次MySQL解决大数据存储时的分表问题"><img src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="记一次MySQL解决大数据存储时的分表问题"/></a><div class="content"><a class="title" href="/2020/06/14/%E8%AE%B0%E4%B8%80%E6%AC%A1MySQL%E8%A7%A3%E5%86%B3%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E6%97%B6%E7%9A%84%E5%88%86%E8%A1%A8%E9%97%AE%E9%A2%98.html" title="记一次MySQL解决大数据存储时的分表问题">记一次MySQL解决大数据存储时的分表问题</a><time datetime="2020-06-14T15:24:27.000Z" title="发表于 2020-06-14 23:24:27">2020-06-14</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2022 By 徐耀彬</div><div class="footer_custom_text"><p><a style="margin-inline:5px"target="_blank"href="https://hexo.io/"><img src="https://img.shields.io/badge/Frame-Hexo-blue?style=flat&logo=hexo"title="博客框架为Hexo"alt="img"></a><a style="margin-inline:5px"target="_blank"href="https://butterfly.js.org/"><img src="https://img.shields.io/badge/Theme-Butterfly-6513df?style=flat&logo=bitdefender"title="主题采用butterfly"alt="img"></a><a style="margin-inline:5px"target="_blank"href="https://www.jsdelivr.com/"><img src="https://img.shields.io/badge/CDN-jsDelivr-orange?style=flat&logo=jsDelivr"title="本站使用JsDelivr为静态资源提供CDN加速"alt="img"></a><a style="margin-inline:5px"target="_blank"href="https://github.com/"><img src="https://img.shields.io/badge/Source-Github-d021d6?style=flat&logo=GitHub"title="本站项目由Gtihub托管"alt="img"></a><a style="margin-inline:5px"target="_blank"href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img src="https://img.shields.io/badge/Copyright-BY--NC--SA%204.0-d42328?style=flat&logo=Claris"alt="img"title="本站采用知识共享署名-非商业性使用-相同方式共享4.0国际许可协议进行许可"></a></br></p></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="font-plus" type="button" title="放大字体"><i class="fas fa-plus"></i></button><button id="font-minus" type="button" title="缩小字体"><i class="fas fa-minus"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div></div><hr/><div id="local-search-results"></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.css"><script>(() => {
  document.querySelectorAll('#article-container span.katex-display').forEach(item => {
    btf.wrap(item, 'div', '', 'katex-wrap')
  })
})()</script><script>(()=>{
  const $countDom = document.getElementById('twikoo-count')
  const init = () => {
    let initData = {
      el: '#twikoo-wrap',
      envId: 'blog-',
      region: ''
    }

    if (false) {
      const otherData = false
      initData = Object.assign(initData, otherData)
    }
    
    twikoo.init(initData)
  }

  const getCount = () => {
    twikoo.getCommentsCount({
      envId: 'blog-',
      region: '',
      urls: [window.location.pathname],
      includeReply: false
    }).then(function (res) {
      $countDom.innerText = res[0].count
    }).catch(function (err) {
      console.error(err);
    });
  }

  const loadTwikoo = (bool = false) => {
    if (typeof twikoo === 'object') {
      init()
      bool && $countDom && setTimeout(getCount,0)
    } else {
      getScript('https://cdn.jsdelivr.net/npm/twikoo/dist/twikoo.all.min.js').then(()=> {
        init()
        bool && $countDom && setTimeout(getCount,0)
      })
    }
  }

  if ('Twikoo' === 'Twikoo' || !false) {
    if (false) btf.loadComment(document.getElementById('twikoo-wrap'), loadTwikoo)
    else loadTwikoo(true)
  } else {
    window.loadOtherComment = () => {
      loadTwikoo()
    }
  }
})()</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><!-- hexo injector body_end start --> <script data-pjax>if(document.getElementById('recent-posts') && (location.pathname ==='/'|| '/' ==='all')){
    var parent = document.getElementById('recent-posts');
    var child = '<div class="recent-post-item" style="width:100%;height: auto"><div id="catalog_magnet"><div class="magnet_item"><a class="magnet_link" href="http://louishsu.xyz/categories/机器学习/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🐱 机器学习 (1)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://louishsu.xyz/categories/自然语言处理/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">📚 自然语言处理 (1)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://louishsu.xyz/categories/竞赛相关/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🎮 竞赛相关 (2)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://louishsu.xyz/categories/阅读笔记/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🎮 阅读笔记 (1)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><a class="magnet_link_more"  href="http://louishsu.xyz/categories" style="flex:1;text-align: center;margin-bottom: 10px;">查看更多...</a></div></div>';
    console.log('已挂载magnet')
    parent.insertAdjacentHTML("afterbegin",child)}
     </script><style>#catalog_magnet{flex-wrap: wrap;display: flex;width:100%;justify-content:space-between;padding: 10px 10px 0 10px;align-content: flex-start;}.magnet_item{flex-basis: calc(50% - 5px);background: #f2f2f2;margin-bottom: 10px;border-radius: 8px;transition: all 0.2s ease-in-out;}.magnet_item:hover{background: #b30070}.magnet_link_more{color:#555}.magnet_link{color:black}.magnet_link:hover{color:white}@media screen and (max-width: 600px) {.magnet_item {flex-basis: 100%;}}.magnet_link_context{display:flex;padding: 10px;font-size:16px;transition: all 0.2s ease-in-out;}.magnet_link_context:hover{padding: 10px 20px;}</style>
    <style></style>
  <script data-pjax src="https://cdn.jsdelivr.net/gh/Zfour/hexo-github-calendar@1.21/hexo_githubcalendar.js"></script>
  <script data-pjax>
        function GithubCalendarConfig(){
            var git_githubapiurl ="https://python-github-calendar-api.vercel.app/api?isLouisHsu";
            var git_color =['#ebedf0', '#fdcdec', '#fc9bd9', '#fa6ac5', '#f838b2', '#f5089f', '#c4067e', '#92055e', '#540336', '#48022f', '#30021f'];
            var git_user ="isLouisHsu";
            var parent_div_git = document.getElementById('recent-posts');
            var git_div_html = '<div class="recent-post-item" style="width:100%;height:auto;padding:10px;"><div id="github_loading" style="width:10%;height:100%;margin:0 auto;display: block"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"  viewBox="0 0 50 50" style="enable-background:new 0 0 50 50" xml:space="preserve"><path fill="#d0d0d0" d="M25.251,6.461c-10.318,0-18.683,8.365-18.683,18.683h4.068c0-8.071,6.543-14.615,14.615-14.615V6.461z" transform="rotate(275.098 25 25)"><animateTransform attributeType="xml" attributeName="transform" type="rotate" from="0 25 25" to="360 25 25" dur="0.6s" repeatCount="indefinite"></animateTransform></path></svg></div><div id="github_container"></div></div>';
            if(parent_div_git && location.pathname =='/'){
                console.log('已挂载github calendar')
                // parent_div_git.innerHTML=git_div_html+parent_div_git.innerHTML // 无报错，但不影响使用(支持pjax跳转)
                parent_div_git.insertAdjacentHTML("afterbegin",git_div_html) // 有报错，但不影响使用(支持pjax跳转)
            };
            GithubCalendar(git_githubapiurl,git_color,git_user)
        }
        if(document.getElementById('recent-posts')){
            GithubCalendarConfig()
        }
    </script>
    <style>#github_container{min-height:280px}@media screen and (max-width:650px) {#github_container{background-image:;min-height:0px}}</style>
    <style></style><script data-pjax>function electric_clock_injector_config(){
                var parent_div_git = document.getElementsByClassName('sticky_layout')[0];
                var item_html = '<div class="card-widget card-clock"><div class="card-glass"><div class="card-background"><div class="card-content"><div id="hexo_electric_clock"><img id="card-clock-loading" src="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-clock/clock/images/weather/loading.gif" style="height: 120px; width: 100%;" data-ll-status="loading" class="entered loading"></div></div></div></div></div>';
                console.log('已挂载electric_clock')
                // parent_div_git.innerHTML=item_html+parent_div_git.innerHTML // 无报错，但不影响使用(支持pjax跳转)
                parent_div_git.insertAdjacentHTML("afterbegin",item_html) // 有报错，但不影响使用(支持pjax跳转)
            }if( document.getElementsByClassName('sticky_layout')[0] && (location.pathname ==='all'|| 'all' ==='all')){

            electric_clock_injector_config()
        } </script><script src="https://pv.sohu.com/cityjson?ie=utf-8"></script><script data-pjax  src="https://cdn.jsdelivr.net/gh/Zfour/hexo-electric-clock@1.0.6/clock.js"></script><!-- hexo injector body_end end --><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"model":{"jsonPath":"/live2dw/assets/hijiki.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":false},"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body></html>