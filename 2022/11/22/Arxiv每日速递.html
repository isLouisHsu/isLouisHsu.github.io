<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Arxiv每日速递(2022-11-22) | LOUIS' BLOG</title><meta name="author" content="徐耀彬"><meta name="copyright" content="徐耀彬"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="本篇博文主要展示每日从Arxiv论文网站获取的最新论文列表，以计算机视觉、自然语言处理、机器学习、人工智能等大方向进行划分。 统计 今日共更新250篇论文，其中：  56篇计算机视觉（cs.CV） 24篇自然语言处理（cs.CL） 105篇机器学习（cs.LG） 56篇人工智能（cs.AI）  计算机视觉    1. 标题：Magic3D: High-Resolution Text-to-3D C">
<meta property="og:type" content="article">
<meta property="og:title" content="Arxiv每日速递(2022-11-22)">
<meta property="og:url" content="http://louishsu.xyz/2022/11/22/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html">
<meta property="og:site_name" content="LOUIS&#39; BLOG">
<meta property="og:description" content="本篇博文主要展示每日从Arxiv论文网站获取的最新论文列表，以计算机视觉、自然语言处理、机器学习、人工智能等大方向进行划分。 统计 今日共更新250篇论文，其中：  56篇计算机视觉（cs.CV） 24篇自然语言处理（cs.CL） 105篇机器学习（cs.LG） 56篇人工智能（cs.AI）  计算机视觉    1. 标题：Magic3D: High-Resolution Text-to-3D C">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png">
<meta property="article:published_time" content="2022-11-22T00:48:15.880Z">
<meta property="article:modified_time" content="2022-11-22T00:49:47.901Z">
<meta property="article:author" content="徐耀彬">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://louishsu.xyz/2022/11/22/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2022-11-22 08:49:47'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const fontSizeVal = saveToLocal.get('global-font-size')
    if (fontSizeVal !== undefined) {
      document.documentElement.style.setProperty('--global-font-size', fontSizeVal + 'px')
    }
    })(window)</script><link rel="stylesheet" href="/css/background.css"><script src="https://cdn.jsdelivr.net/npm/echarts@4.7.0/dist/echarts.min.js"></script><!-- hexo injector head_end start --><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Zfour/hexo-electric-clock@1.0.6/clock.css"><!-- hexo injector head_end end --><meta name="generator" content="Hexo 5.4.2"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="author-avatar"><img class="avatar-img" src="/img/touxiang.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">12</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">标签</div><div class="length-num">3</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">分类</div><div class="length-num">7</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/message/"><i class="fa-fw far fa-comment-dots"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa-fw fa fa-book"></i><span> 找文章</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></li><li><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></li><li><a class="site-page" href="/charts/"><i class="fa-fw fa fa-archive"></i><span> 统计</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-tools"></i><span> 工具</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/md_editor/"><i class="fa-fw fas fa-pen"></i><span> 在线markdown</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/isLouisHsu/blog/tree/master/source/_posts"><i class="fa-fw fa fa-star"></i><span> 在线push</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">LOUIS' BLOG</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/message/"><i class="fa-fw far fa-comment-dots"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa-fw fa fa-book"></i><span> 找文章</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></li><li><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></li><li><a class="site-page" href="/charts/"><i class="fa-fw fa fa-archive"></i><span> 统计</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-tools"></i><span> 工具</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/md_editor/"><i class="fa-fw fas fa-pen"></i><span> 在线markdown</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/isLouisHsu/blog/tree/master/source/_posts"><i class="fa-fw fa fa-star"></i><span> 在线push</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Arxiv每日速递(2022-11-22)<a class="post-edit-link" href="https://github.com/isLouisHsu/blog/tree/master/source_posts/Arxiv每日速递.md" title="编辑" target="_blank"><i class="fas fa-pencil-square"></i></a></h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-11-22T00:48:15.880Z" title="发表于 2022-11-22 08:48:15">2022-11-22</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2022-11-22T00:49:47.901Z" title="更新于 2022-11-22 08:49:47">2022-11-22</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">阅读笔记</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">60k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>359分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span><span class="post-meta-separator">|</span><span class="post-meta-commentcount"><i class="far fa-comments fa-fw post-meta-icon"></i><span class="post-meta-label">评论数:</span><a href="/2022/11/22/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html#post-comment"><span id="twikoo-count"></span></a></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><p>本篇博文主要展示每日从Arxiv论文网站获取的最新论文列表，以计算机视觉、自然语言处理、机器学习、人工智能等大方向进行划分。</p>
<h1>统计</h1>
<p>今日共更新250篇论文，其中：</p>
<ul>
<li>56篇计算机视觉（<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>）</li>
<li>24篇自然语言处理（<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>）</li>
<li>105篇机器学习（cs.LG）</li>
<li>56篇人工智能（<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>）</li>
</ul>
<h1>计算机视觉</h1>
<details>
  <summary>1. <b>标题：Magic3D: High-Resolution Text-to-3D Content Creation</b></summary>
  <p><b>编号</b>：[1]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10440</p>
  <p><b>作者</b>：Chen-Hsuan Lin,  Jun Gao,  Luming Tang,  Towaki Takikawa,  Xiaohui Zeng,  Xun Huang,  Karsten Kreis,  Sanja Fidler,  Ming-Yu Liu,  Tsung-Yi Lin</p>
  <p><b>备注</b>：Project website: this https URL</p>
  <p><b>关键词</b>：Neural Radiance Fields, optimize Neural Radiance, Radiance Fields, Neural Radiance, optimize Neural</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>DreamFusion has recently demonstrated the utility of a pre-trained
text-to-image diffusion model to optimize Neural Radiance Fields (NeRF),
achieving remarkable text-to-3D synthesis results. However, the method has two
inherent limitations: (a) extremely slow optimization of NeRF and (b)
low-resolution image space supervision on NeRF, leading to low-quality 3D
models with a long processing time. In this paper, we address these limitations
by utilizing a two-stage optimization framework. First, we obtain a coarse
model using a low-resolution diffusion prior and accelerate with a sparse 3D
hash grid structure. Using the coarse representation as the initialization, we
further optimize a textured 3D mesh model with an efficient differentiable
renderer interacting with a high-resolution latent diffusion model. Our method,
dubbed Magic3D, can create high quality 3D mesh models in 40 minutes, which is
2x faster than DreamFusion (reportedly taking 1.5 hours on average), while also
achieving higher resolution. User studies show 61.7% raters to prefer our
approach over DreamFusion. Together with the image-conditioned generation
capabilities, we provide users with new ways to control 3D synthesis, opening
up new avenues to various creative applications.</p>
  </details>
</details>
<details>
  <summary>2. <b>标题：BEVFormer v2: Adapting Modern Image Backbones to Bird's-Eye-View  Recognition via Perspective Supervision</b></summary>
  <p><b>编号</b>：[2]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10439</p>
  <p><b>作者</b>：Chenyu Yang,  Yuntao Chen,  Hao Tian,  Chenxin Tao,  Xizhou Zhu,  Zhaoxiang Zhang,  Gao Huang,  Hongyang Li,  Yu Qiao,  Lewei Lu,  Jie Zhou,  Jifeng Dai</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：modern image backbones, BEV detectors, image backbones, suits modern image, BEV</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present a novel bird's-eye-view (BEV) detector with perspective
supervision, which converges faster and better suits modern image backbones.
Existing state-of-the-art BEV detectors are often tied to certain depth
pre-trained backbones like VoVNet, hindering the synergy between booming image
backbones and BEV detectors. To address this limitation, we prioritize easing
the optimization of BEV detectors by introducing perspective space supervision.
To this end, we propose a two-stage BEV detector, where proposals from the
perspective head are fed into the bird's-eye-view head for final predictions.
To evaluate the effectiveness of our model, we conduct extensive ablation
studies focusing on the form of supervision and the generality of the proposed
detector. The proposed method is verified with a wide spectrum of traditional
and modern image backbones and achieves new SoTA results on the large-scale
nuScenes dataset. The code shall be released soon.</p>
  </details>
</details>
<details>
  <summary>3. <b>标题：A Structure-Guided Diffusion Model for Large-Hole Diverse Image  Completion</b></summary>
  <p><b>编号</b>：[4]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10437</p>
  <p><b>作者</b>：Daichi Horita,  Jiaolong Yang,  Dong Chen,  Yuki Koyama,  Kiyoharu Aizawa</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：filling incomplete regions, made remarkable success, incomplete regions, remarkable success, filling incomplete</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Diverse image completion, a problem of generating various ways of filling
incomplete regions (i.e. holes) of an image, has made remarkable success.
However, managing input images with large holes is still a challenging problem
due to the corruption of semantically important structures. In this paper, we
tackle this problem by incorporating explicit structural guidance. We propose a
structure-guided diffusion model (SGDM) for the large-hole diverse completion
problem. Our proposed SGDM consists of a structure generator and a texture
generator, which are both diffusion probabilistic models (DMs). The structure
generator generates an edge image representing a plausible structure within the
holes, which is later used to guide the texture generation process. To jointly
train these two generators, we design a strategy that combines optimal Bayesian
denoising and a momentum framework. In addition to the quality improvement,
auxiliary edge images generated by the structure generator can be manually
edited to allow user-guided image editing. Our experiments using datasets of
faces (CelebA-HQ) and natural scenes (Places) show that our method achieves a
comparable or superior trade-off between visual quality and diversity compared
to other state-of-the-art methods.</p>
  </details>
</details>
<details>
  <summary>4. <b>标题：CNeRV: Content-adaptive Neural Representation for Visual Data</b></summary>
  <p><b>编号</b>：[6]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10421</p>
  <p><b>作者</b>：Hao Chen,  Matt Gwilliam,  Bo He,  Ser-Nam Lim,  Abhinav Shrivastava</p>
  <p><b>备注</b>：BMVC 2022 at this https URL</p>
  <p><b>关键词</b>：computer vision community, vision community, deep learning, widely studied, computer vision</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Compression and reconstruction of visual data have been widely studied in the
computer vision community, even before the popularization of deep learning.
More recently, some have used deep learning to improve or refine existing
pipelines, while others have proposed end-to-end approaches, including
autoencoders and implicit neural representations, such as SIREN and NeRV. In
this work, we propose Neural Visual Representation with Content-adaptive
Embedding (CNeRV), which combines the generalizability of autoencoders with the
simplicity and compactness of implicit representation. We introduce a novel
content-adaptive embedding that is unified, concise, and internally
(within-video) generalizable, that compliments a powerful decoder with a
single-layer encoder. We match the performance of NeRV, a state-of-the-art
implicit neural representation, on the reconstruction task for frames seen
during training while far surpassing for frames that are skipped during
training (unseen images). To achieve similar reconstruction quality on unseen
images, NeRV needs 120x more time to overfit per-frame due to its lack of
internal generalization. With the same latent code length and similar model
size, CNeRV outperforms autoencoders on reconstruction of both seen and unseen
images. We also show promising results for visual data compression. More
details can be found in the project pagehttps://haochenthis http URL</p>
  </details>
</details>
<details>
  <summary>5. <b>标题：Video Unsupervised Domain Adaptation with Deep Learning: A Comprehensive  Survey</b></summary>
  <p><b>编号</b>：[9]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10412</p>
  <p><b>作者</b>：Yuecong Xu,  Haozhi Cao,  Zhenghua Chen,  Xiaoli Li,  Lihua Xie,  Jianfei Yan</p>
  <p><b>备注</b>：Survey on Video Unsupervised Domain Adaptation (VUDA), 16 pages, 1 figure, 8 tables</p>
  <p><b>关键词</b>：Video analysis tasks, deep learning-based representations, Video, VUDA, received increasing research</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Video analysis tasks such as action recognition have received increasing
research interest with growing applications in fields such as smart healthcare,
thanks to the introduction of large-scale datasets and deep learning-based
representations. However, video models trained on existing datasets suffer from
significant performance degradation when deployed directly to real-world
applications due to domain shifts between the training public video datasets
(source video domains) and real-world videos (target video domains). Further,
with the high cost of video annotation, it is more practical to use unlabeled
videos for training. To tackle performance degradation and address concerns in
high video annotation cost uniformly, the video unsupervised domain adaptation
(VUDA) is introduced to adapt video models from the labeled source domain to
the unlabeled target domain by alleviating video domain shift, improving the
generalizability and portability of video models. This paper surveys recent
progress in VUDA with deep learning. We begin with the motivation of VUDA,
followed by its definition, and recent progress of methods for both closed-set
VUDA and VUDA under different scenarios, and current benchmark datasets for
VUDA research. Eventually, future directions are provided to promote further
VUDA research.</p>
  </details>
</details>
<details>
  <summary>6. <b>标题：Improved Cross-view Completion Pre-training for Stereo Matching</b></summary>
  <p><b>编号</b>：[12]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10408</p>
  <p><b>作者</b>：Philippe Weinzaepfel,  Vaibhav Arora,  Yohann Cabon,  Thomas Lucas,  Romain Brégier,  Vincent Leroy,  Gabriela Csurka,  Leonid Antsfeld,  Boris Chidlovskii,  Jérôme Revaud</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：high-level downstream tasks, self-supervised pre-training methods, masked image modeling, impressive performance, performance for high-level</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Despite impressive performance for high-level downstream tasks,
self-supervised pre-training methods have not yet fully delivered on dense
geometric vision tasks such as stereo matching. The application of
self-supervised learning concepts, such as instance discrimination or masked
image modeling, to geometric tasks is an active area of research. In this work
we build on the recent cross-view completion framework: this variation of
masked image modeling leverages a second view from the same scene, which is
well suited for binocular downstream tasks. However, the applicability of this
concept has so far been limited in at least two ways: (a) by the difficulty of
collecting real-world image pairs - in practice only synthetic data had been
used - and (b) by the lack of generalization of vanilla transformers to dense
downstream tasks for which relative position is more meaningful than absolute
position. We explore three avenues of improvement: first, we introduce a method
to collect suitable real-world image pairs at large scale. Second, we
experiment with relative positional embeddings and demonstrate that they enable
vision transformers to perform substantially better. Third, we scale up vision
transformer based cross-completion architectures, which is made possible by the
use of large amounts of data. With these improvements, we show for the first
time that state-of-the-art results on deep stereo matching can be reached
without using any standard task-specific techniques like correlation volume,
iterative estimation or multi-scale reasoning.</p>
  </details>
</details>
<details>
  <summary>7. <b>标题：Informative Sample-Aware Proxy for Deep Metric Learning</b></summary>
  <p><b>编号</b>：[18]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10382</p>
  <p><b>作者</b>：Aoyu Li,  Ikuro Sato,  Kohta Ishikawa,  Rei Kawakami,  Rio Yokota</p>
  <p><b>备注</b>：Accepted at ACM Multimedia Asia (MMAsia) 2022</p>
  <p><b>关键词</b>：supervised deep metric, deep metric learning, high retrieval accuracies, achieved high retrieval, metric learning methods</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Among various supervised deep metric learning methods proxy-based approaches
have achieved high retrieval accuracies. Proxies, which are
class-representative points in an embedding space, receive updates based on
proxy-sample similarities in a similar manner to sample representations. In
existing methods, a relatively small number of samples can produce large
gradient magnitudes (ie, hard samples), and a relatively large number of
samples can produce small gradient magnitudes (ie, easy samples); these can
play a major part in updates. Assuming that acquiring too much sensitivity to
such extreme sets of samples would deteriorate the generalizability of a
method, we propose a novel proxy-based method called Informative Sample-Aware
Proxy (Proxy-ISA), which directly modifies a gradient weighting factor for each
sample using a scheduled threshold function, so that the model is more
sensitive to the informative samples. Extensive experiments on the
CUB-200-2011, Cars-196, Stanford Online Products and In-shop Clothes Retrieval
datasets demonstrate the superiority of Proxy-ISA compared with the
state-of-the-art methods.</p>
  </details>
</details>
<details>
  <summary>8. <b>标题：Invariant Learning via Diffusion Dreamed Distribution Shifts</b></summary>
  <p><b>编号</b>：[20]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10370</p>
  <p><b>作者</b>：Priyatham Kattakinda,  Alexander Levine,  Soheil Feizi</p>
  <p><b>备注</b>：18 pages, 13 figures, 5 tables</p>
  <p><b>关键词</b>：background, Diffusion Dreamed Distribution, foreground, important signal, incorrect predictions</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Though the background is an important signal for image classification, over
reliance on it can lead to incorrect predictions when spurious correlations
between foreground and background are broken at test time. Training on a
dataset where these correlations are unbiased would lead to more robust models.
In this paper, we propose such a dataset called Diffusion Dreamed Distribution
Shifts (D3S). D3S consists of synthetic images generated through
StableDiffusion using text prompts and image guides obtained by pasting a
sample foreground image onto a background template image. Using this scalable
approach we generate 120K images of objects from all 1000 ImageNet classes in
10 diverse backgrounds. Due to the incredible photorealism of the diffusion
model, our images are much closer to natural images than previous synthetic
datasets. D3S contains a validation set of more than 17K images whose labels
are human-verified in an MTurk study. Using the validation set, we evaluate
several popular DNN image classifiers and find that the classification
performance of models generally suffers on our background diverse images. Next,
we leverage the foreground & background labels in D3S to learn a foreground
(background) representation that is invariant to changes in background
(foreground) by penalizing the mutual information between the foreground
(background) features and the background (foreground) labels. Linear
classifiers trained on these features to predict foreground (background) from
foreground (background) have high accuracies at 82.9% (93.8%), while
classifiers that predict these labels from background and foreground have a
much lower accuracy of 2.4% and 45.6% respectively. This suggests that our
foreground and background features are well disentangled. We further test the
efficacy of these representations by training classifiers on a task with strong
spurious correlations.</p>
  </details>
</details>
<details>
  <summary>9. <b>标题：Deep learning based landslide density estimation on SAR data for rapid  response</b></summary>
  <p><b>编号</b>：[27]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10338</p>
  <p><b>作者</b>：Vanessa Boehm,  Wei Ji Leong,  Ragini Bal Mahesh,  Ioannis Prapas,  Edoardo Nemni,  Freddie Kalaitzis,  Siddha Ganju,  Raul Ramos-Pollan</p>
  <p><b>备注</b>：7 pages, 5 figures</p>
  <p><b>关键词</b>：estimates using Synthetic, States Geological Survey, United States Geological, work aims, Synthetic</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This work aims to produce landslide density estimates using Synthetic
Aperture Radar (SAR) satellite imageries to prioritise emergency resources for
rapid response. We use the United States Geological Survey (USGS) Landslide
Inventory data annotated by experts after Hurricane María in Puerto Rico on
Sept 20, 2017, and their subsequent susceptibility study which uses extensive
additional information such as precipitation, soil moisture, geological terrain
features, closeness to waterways and roads, etc. Since such data might not be
available during other events or regions, we aimed to produce a landslide
density map using only elevation and SAR data to be useful to decision-makers
in rapid response scenarios.
The USGS Landslide Inventory contains the coordinates of 71,431 landslide
heads (not their full extent) and was obtained by manual inspection of aerial
and satellite imagery. It is estimated that around 45\% of the landslides are
smaller than a Sentinel-1 typical pixel which is 10m $\times$ 10m, although
many are long and thin, probably leaving traces across several pixels. Our
method obtains 0.814 AUC in predicting the correct density estimation class at
the chip level (128$\times$128 pixels, at Sentinel-1 resolution) using only
elevation data and up to three SAR acquisitions pre- and post-hurricane, thus
enabling rapid assessment after a disaster. The USGS Susceptibility Study
reports a 0.87 AUC, but it is measured at the landslide level and uses
additional information sources (such as proximity to fluvial channels, roads,
precipitation, etc.) which might not regularly be available in an rapid
response emergency scenario.</p>
  </details>
</details>
<details>
  <summary>10. <b>标题：SeaTurtleID: A novel long-span dataset highlighting the importance of  timestamps in wildlife re-identification</b></summary>
  <p><b>编号</b>：[37]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10307</p>
  <p><b>作者</b>：Kostas Papafitsoros,  Lukáš Adam,  Vojtěch Čermák,  Lukáš Picek</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：paper introduces SeaTurtleID, sea turtle photographs, turtle photographs captured, introduces SeaTurtleID, paper introduces</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper introduces SeaTurtleID, the first public large-scale, long-span
dataset with sea turtle photographs captured in the wild. The dataset is
suitable for benchmarking re-identification methods and evaluating several
other computer vision tasks. The dataset consists of 7774 high-resolution
photographs of 400 unique individuals collected within 12 years in 1081
encounters. Each photograph is accompanied by rich metadata, e.g., identity
label, head segmentation mask, and encounter timestamp. The 12-year span of the
dataset makes it the longest-spanned public wild animal dataset with
timestamps. By exploiting this unique property, we show that timestamps are
necessary for an unbiased evaluation of animal re-identification methods
because they allow time-aware splits of the dataset into reference and query
sets. We show that time-unaware splits can lead to performance overestimation
of more than 100% compared to the time-aware splits for both feature- and
CNN-based re-identification methods. We also argue that time-aware splits
correspond to more realistic re-identification pipelines than the time-unaware
ones. We recommend that animal re-identification methods should only be tested
on datasets with timestamps using time-aware splits, and we encourage dataset
curators to include such information in the associated metadata.</p>
  </details>
</details>
<details>
  <summary>11. <b>标题：Just a Matter of Scale? Reevaluating Scale Equivariance in Convolutional  Neural Networks</b></summary>
  <p><b>编号</b>：[42]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10288</p>
  <p><b>作者</b>：Thomas Altstidl,  An Nguyen,  Leo Schwinn,  Franz Köferl,  Christopher Mutschler,  Björn Eskofier,  Dario Zanca</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：convolutional neural networks, Translated Image Recognition, widespread success, success of convolutional, convolutional neural</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The widespread success of convolutional neural networks may largely be
attributed to their intrinsic property of translation equivariance. However,
convolutions are not equivariant to variations in scale and fail to generalize
to objects of different sizes. Despite recent advances in this field, it
remains unclear how well current methods generalize to unobserved scales on
real-world data and to what extent scale equivariance plays a role. To address
this, we propose the novel Scaled and Translated Image Recognition (STIR)
benchmark based on four different domains. Additionally, we introduce a new
family of models that applies many re-scaled kernels with shared weights in
parallel and then selects the most appropriate one. Our experimental results on
STIR show that both the existing and proposed approaches can improve
generalization across scales compared to standard convolutions. We also
demonstrate that our family of models is able to generalize well towards larger
scales and improve scale equivariance. Moreover, due to their unique design we
can validate that kernel selection is consistent with input scale. Even so,
none of the evaluated models maintain their performance for large differences
in scale, demonstrating that a general understanding of how scale equivariance
can improve generalization and robustness is still lacking.</p>
  </details>
</details>
<details>
  <summary>12. <b>标题：Estimating more camera poses for ego-centric videos is essential for  VQ3D</b></summary>
  <p><b>编号</b>：[44]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10284</p>
  <p><b>作者</b>：Jinjie Mai,  Chen Zhao,  Abdullah Hamdi,  Silvio Giancola,  Bernard Ghanem</p>
  <p><b>备注</b>：Second International Ego4D Workshop at ECCV 2022</p>
  <p><b>关键词</b>：Episodic Memory, Visual queries, Episodic, Memory, egocentric video</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Visual queries 3D localization (VQ3D) is a task in the Ego4D Episodic Memory
Benchmark. Given an egocentric video, the goal is to answer queries of the form
"Where did I last see object X?", where the query object X is specified as a
static image, and the answer should be a 3D displacement vector pointing to
object X. However, current techniques use naive ways to estimate the camera
poses of video frames, resulting in a low query with pose (QwP) ratio, thus a
poor overall success rate. We design a new pipeline for the challenging
egocentric video camera pose estimation problem in our work. Moreover, we
revisit the current VQ3D framework and optimize it in terms of performance and
efficiency. As a result, we get the top-1 overall success rate of 25.8% on VQ3D
leaderboard, which is two times better than the 8.7% reported by the baseline.</p>
  </details>
</details>
<details>
  <summary>13. <b>标题：Unsupervised 3D Pose Transfer with Cross Consistency and Dual  Reconstruction</b></summary>
  <p><b>编号</b>：[47]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10278</p>
  <p><b>作者</b>：Chaoyue Song,  Jiacheng Wei,  Ruibo Li,  Fayao Liu,  Guosheng Lin</p>
  <p><b>备注</b>：arXiv admin note: text overlap with arXiv:2109.15025</p>
  <p><b>关键词</b>：target mesh, pose transfer, source mesh, pose, identity information</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The goal of 3D pose transfer is to transfer the pose from the source mesh to
the target mesh while preserving the identity information (e.g., face, body
shape) of the target mesh. Deep learning-based methods improved the efficiency
and performance of 3D pose transfer. However, most of them are trained under
the supervision of the ground truth, whose availability is limited in
real-world scenarios. In this work, we present X-DualNet, a simple yet
effective approach that enables unsupervised 3D pose transfer. In X-DualNet, we
introduce a generator $G$ which contains correspondence learning and pose
transfer modules to achieve 3D pose transfer. We learn the shape correspondence
by solving an optimal transport problem without any key point annotations and
generate high-quality meshes with our elastic instance normalization (ElaIN) in
the pose transfer module. With $G$ as the basic component, we propose a cross
consistency learning scheme and a dual reconstruction objective to learn the
pose transfer without supervision. Besides that, we also adopt an
as-rigid-as-possible deformer in the training process to fine-tune the body
shape of the generated results. Extensive experiments on human and animal data
demonstrate that our framework can successfully achieve comparable performance
as the state-of-the-art supervised approaches.</p>
  </details>
</details>
<details>
  <summary>14. <b>标题：Task Residual for Tuning Vision-Language Models</b></summary>
  <p><b>编号</b>：[48]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10277</p>
  <p><b>作者</b>：Tao Yu,  Zhihe Lu,  Xin Jin,  Zhibo Chen,  Xinchao Wang</p>
  <p><b>备注</b>：A new paradigm for tuning vision-language models</p>
  <p><b>关键词</b>：broad visual concepts, learned general visual, general visual representations, Large-scale vision-language models, visual concepts</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large-scale vision-language models (VLMs) pre-trained on billion-level data
have learned general visual representations and broad visual concepts. In
principle, the well-learned knowledge structure of the VLMs should be inherited
appropriately when being transferred to downstream tasks with limited data.
However, most existing efficient transfer learning (ETL) approaches for VLMs
either damage or are excessively biased towards the prior knowledge, e.g.,
prompt tuning (PT) discards the pre-trained text-based classifier and builds a
new one while adapter-style tuning (AT) fully relies on the pre-trained
features. To address this, we propose a new efficient tuning approach for VLMs
named Task Residual Tuning (TaskRes), which performs directly on the text-based
classifier and explicitly decouples the prior knowledge of the pre-trained
models and new knowledge regarding a target task. Specifically, TaskRes keeps
the original classifier weights from the VLMs frozen and obtains a new
classifier for the target task by tuning a set of prior-independent parameters
as a residual to the original one, which enables reliable prior knowledge
preservation and flexible task-specific knowledge exploration. The proposed
TaskRes is simple yet effective, which significantly outperforms previous ETL
methods (e.g., PT and AT) on 11 benchmark datasets while requiring minimal
effort for the implementation. Our code will be available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>15. <b>标题：SolderNet: Towards Trustworthy Visual Inspection of Solder Joints in  Electronics Manufacturing Using Explainable Artificial Intelligence</b></summary>
  <p><b>编号</b>：[50]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10274</p>
  <p><b>作者</b>：Hayden Gunraj,  Paul Guerrier,  Sheldon Fernandez,  Alexander Wong</p>
  <p><b>备注</b>：Accepted by IAAI-23, 7 pages</p>
  <p><b>关键词</b>：common problem affecting, circuit board components, solder joint defects, printed circuit board, solder joint</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In electronics manufacturing, solder joint defects are a common problem
affecting a variety of printed circuit board components. To identify and
correct solder joint defects, the solder joints on a circuit board are
typically inspected manually by trained human inspectors, which is a very
time-consuming and error-prone process. To improve both inspection efficiency
and accuracy, in this work we describe an explainable deep learning-based
visual quality inspection system tailored for visual inspection of solder
joints in electronics manufacturing environments. At the core of this system is
an explainable solder joint defect identification system called SolderNet which
we design and implement with trust and transparency in mind. While several
challenges remain before the full system can be developed and deployed, this
study presents important progress towards trustworthy visual inspection of
solder joints in electronics manufacturing.</p>
  </details>
</details>
<details>
  <summary>16. <b>标题：Delving into Transformer for Incremental Semantic Segmentation</b></summary>
  <p><b>编号</b>：[57]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10253</p>
  <p><b>作者</b>：Zekai Xu,  Mingyi Zhang,  Jiayue Hou,  Xing Gong,  Chuan Wen,  Chengjie Wang,  Junge Zhang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Incremental semantic segmentation, adding new classes, Transformer based, ISS, Incremental semantic</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Incremental semantic segmentation(ISS) is an emerging task where old model is
updated by incrementally adding new classes. At present, methods based on
convolutional neural networks are dominant in ISS. However, studies have shown
that such methods have difficulty in learning new tasks while maintaining good
performance on old ones (catastrophic forgetting). In contrast, a Transformer
based method has a natural advantage in curbing catastrophic forgetting due to
its ability to model both long-term and short-term tasks. In this work, we
explore the reasons why Transformer based architecture are more suitable for
ISS, and accordingly propose propose TISS, a Transformer based method for
Incremental Semantic Segmentation. In addition, to better alleviate
catastrophic forgetting while preserving transferability on ISS, we introduce
two patch-wise contrastive losses to imitate similar features and enhance
feature diversity respectively, which can further improve the performance of
TISS. Under extensive experimental settings with Pascal-VOC 2012 and ADE20K
datasets, our method significantly outperforms state-of-the-art incremental
semantic segmentation methods.</p>
  </details>
</details>
<details>
  <summary>17. <b>标题：Knowing What to Label for Few Shot Microscopy Image Cell Segmentation</b></summary>
  <p><b>编号</b>：[61]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10244</p>
  <p><b>作者</b>：Youssef Dawoud,  Arij Bouazizi,  Katharina Ernst,  Gustavo Carneiro,  Vasileios Belagiannis</p>
  <p><b>备注</b>：Accepted to WACV 2023</p>
  <p><b>关键词</b>：deep neural network, target images, training target images, annotated training target, unlabelled target images</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In microscopy image cell segmentation, it is common to train a deep neural
network on source data, containing different types of microscopy images, and
then fine-tune it using a support set comprising a few randomly selected and
annotated training target images. In this paper, we argue that the random
selection of unlabelled training target images to be annotated and included in
the support set may not enable an effective fine-tuning process, so we propose
a new approach to optimise this image selection process. Our approach involves
a new scoring function to find informative unlabelled target images. In
particular, we propose to measure the consistency in the model predictions on
target images against specific data augmentations. However, we observe that the
model trained with source datasets does not reliably evaluate consistency on
target images. To alleviate this problem, we propose novel self-supervised
pretext tasks to compute the scores of unlabelled target images. Finally, the
top few images with the least consistency scores are added to the support set
for oracle (i.e., expert) annotation and later used to fine-tune the model to
the target images. In our evaluations that involve the segmentation of five
different types of cell images, we demonstrate promising results on several
target test sets compared to the random selection approach as well as other
selection approaches, such as Shannon's entropy and Monte-Carlo dropout.</p>
  </details>
</details>
<details>
  <summary>18. <b>标题：Adversarial Detection by Approximation of Ensemble Boundary</b></summary>
  <p><b>编号</b>：[65]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10227</p>
  <p><b>作者</b>：T. Windeatt</p>
  <p><b>备注</b>：8 pages, 8 figures, 8 tables</p>
  <p><b>关键词</b>：Deep Neural Networks, pattern recognition problems, Neural Networks, Deep Neural, solving two-class pattern</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A spectral approximation of a Boolean function is proposed for approximating
the decision boundary of an ensemble of Deep Neural Networks (DNNs) solving
two-class pattern recognition problems. The Walsh combination of relatively
weak DNN classifiers is shown experimentally to be capable of detecting
adversarial attacks. By observing the difference in Walsh coefficient
approximation between clean and adversarial images, it appears that
transferability of attack may be used for detection. Approximating the decision
boundary may also aid in understanding the learning and transferability
properties of DNNs. While the experiments here use images, the proposed
approach of modelling two-class ensemble decision boundaries could in principle
be applied to any application area.</p>
  </details>
</details>
<details>
  <summary>19. <b>标题：Leveraging Multi-stream Information Fusion for Trajectory Prediction in  Low-illumination Scenarios: A Multi-channel Graph Convolutional Approach</b></summary>
  <p><b>编号</b>：[66]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10226</p>
  <p><b>作者</b>：Hailong Gong,  Zirui Li,  Chao Lu,  Guodong Du,  Jianwei Gong</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：fundamental problem, problem and challenge, challenge for autonomous, Long Short-term Memory, Trajectory prediction</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Trajectory prediction is a fundamental problem and challenge for autonomous
vehicles. Early works mainly focused on designing complicated architectures for
deep-learning-based prediction models in normal-illumination environments,
which fail in dealing with low-light conditions. This paper proposes a novel
approach for trajectory prediction in low-illumination scenarios by leveraging
multi-stream information fusion, which flexibly integrates image, optical flow,
and object trajectory information. The image channel employs Convolutional
Neural Network (CNN) and Long Short-term Memory (LSTM) networks to extract
temporal information from the camera. The optical flow channel is applied to
capture the pattern of relative motion between adjacent camera frames and
modelled by Spatial-Temporal Graph Convolutional Network (ST-GCN). The
trajectory channel is used to recognize high-level interactions between
vehicles. Finally, information from all the three channels is effectively fused
in the prediction module to generate future trajectories of surrounding
vehicles in low-illumination conditions. The proposed multi-channel graph
convolutional approach is validated on HEV-I and newly generated Dark-HEV-I,
egocentric vision datasets that primarily focus on urban intersection
scenarios. The results demonstrate that our method outperforms the baselines,
in standard and low-illumination scenarios. Additionally, our approach is
generic and applicable to scenarios with different types of perception data.
The source code of the proposed approach is available at
this https URL}{this https URL.</p>
  </details>
</details>
<details>
  <summary>20. <b>标题：Multi-view Inverse Rendering for Large-scale Real-world Indoor Scenes</b></summary>
  <p><b>编号</b>：[70]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10206</p>
  <p><b>作者</b>：Zhen Li,  Lingli Wang,  Mofang Cheng,  Cihui Pan,  Jiaqi Yang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：large-scale real-world indoor, real-world indoor scenes, multi-view inverse rendering, reconstructs global illumination, present a multi-view</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present a multi-view inverse rendering method for large-scale real-world
indoor scenes that reconstructs global illumination and physically-reasonable
SVBRDFs. Unlike previous representations, where the global illumination of
large scenes is simplified as multiple environment maps, we propose a compact
representation called Texture-based Lighting (TBL). It consists of 3D meshs and
HDR textures, and efficiently models direct and infinite-bounce indirect
lighting of the entire large scene. Based on TBL, we further propose a hybrid
lighting representation with precomputed irradiance, which significantly
improves the efficiency and alleviate the rendering noise in the material
optimization. To physically disentangle the ambiguity between materials, we
propose a three-stage material optimization strategy based on the priors of
semantic segmentation and room segmentation. Extensive experiments show that
the proposed method outperforms the state-of-the-arts quantitatively and
qualitatively, and enables physically-reasonable mixed-reality applications
such as material editing, editable novel view synthesis and relighting. The
project page is at this https URL.</p>
  </details>
</details>
<details>
  <summary>21. <b>标题：LVOS: A Benchmark for Long-term Video Object Segmentation</b></summary>
  <p><b>编号</b>：[76]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10181</p>
  <p><b>作者</b>：Lingyi Hong,  Wenchao Chen,  Zhongying Liu,  Wei Zhang,  Pinxue Guo,  Zhaoyu Chen,  Wenqiang Zhang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：VOS, focus on short-term, long-term VOS, long-term VOS dataset, video object segmentation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Existing video object segmentation (VOS) benchmarks focus on short-term
videos which just last about 3-5 seconds and where objects are visible most of
the time. These videos are poorly representative of practical applications, and
the absence of long-term datasets restricts further investigation of VOS on the
application in realistic scenarios. So, in this paper, we present a new
benchmark dataset and evaluation methodology named LVOS, which consists of 220
videos with a total duration of 421 minutes. To the best of our knowledge, LVOS
is the first densely annotated long-term VOS dataset. The videos in our LVOS
last 1.59 minutes on average, which is 20 times longer than videos in existing
VOS datasets. Each video includes various attributes, especially challenges
deriving from the wild, such as long-term reappearing and cross-temporal
similar objeccts. Moreover, we provide additional language descriptions to
encourage the exploration of integrating linguistic and visual features for
video object segmentation. Based on LVOS, we assess existing video object
segmentation algorithms and propose a Diverse Dynamic Memory network (DDMemory)
that consists of three complementary memory banks to exploit temporal
information adequately. The experiment results demonstrate the strength and
weaknesses of prior methods, pointing promising directions for further study.
Our objective is to provide the community with a large and varied benchmark to
boost the advancement of long-term VOS. Data and code are available at
\url{this https URL}.</p>
  </details>
</details>
<details>
  <summary>22. <b>标题：Improving Pixel-Level Contrastive Learning by Leveraging Exogenous Depth  Information</b></summary>
  <p><b>编号</b>：[77]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10177</p>
  <p><b>作者</b>：Ahmed Ben Saad,  Kristina Prokopetc,  Josselin Kherroubi,  Axel Davy,  Adrien Courtois,  Gabriele Facciolo</p>
  <p><b>备注</b>：Accepted for WACV 2023</p>
  <p><b>关键词</b>：Self-supervised representation learning, representation learning based, Contrastive Learning, recent years, learning based</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Self-supervised representation learning based on Contrastive Learning (CL)
has been the subject of much attention in recent years. This is due to the
excellent results obtained on a variety of subsequent tasks (in particular
classification), without requiring a large amount of labeled samples. However,
most reference CL algorithms (such as SimCLR and MoCo, but also BYOL and Barlow
Twins) are not adapted to pixel-level downstream tasks. One existing solution
known as PixPro proposes a pixel-level approach that is based on filtering of
pairs of positive/negative image crops of the same image using the distance
between the crops in the whole image. We argue that this idea can be further
enhanced by incorporating semantic information provided by exogenous data as an
additional selection filter, which can be used (at training time) to improve
the selection of the pixel-level positive/negative samples. In this paper we
will focus on the depth information, which can be obtained by using a depth
estimation network or measured from available data (stereovision, parallax
motion, LiDAR, etc.). Scene depth can provide meaningful cues to distinguish
pixels belonging to different objects based on their depth. We show that using
this exogenous information in the contrastive loss leads to improved results
and that the learned representations better follow the shapes of objects. In
addition, we introduce a multi-scale loss that alleviates the issue of finding
the training parameters adapted to different object sizes. We demonstrate the
effectiveness of our ideas on the Breakout Segmentation on Borehole Images
where we achieve an improvement of 1.9\% over PixPro and nearly 5\% over the
supervised baseline. We further validate our technique on the indoor scene
segmentation tasks with ScanNet and outdoor scenes with CityScapes ( 1.6\% and
1.1\% improvement over PixPro respectively).</p>
  </details>
</details>
<details>
  <summary>23. <b>标题：UMFuse: Unified Multi View Fusion for Human Editing applications</b></summary>
  <p><b>编号</b>：[83]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10157</p>
  <p><b>作者</b>：Rishabh Jain,  Mayur Hemani,  Duygu Ceylan,  Krishna Kumar Singh,  Jingwan Lu,  Mausooom Sarkar,  Balaji Krishnamurthy</p>
  <p><b>备注</b>：10 pages, 10 figures</p>
  <p><b>关键词</b>：explored numerous pose, numerous pose guided, extensive practical applications, vision community, community has explored</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The vision community has explored numerous pose guided human editing methods
due to their extensive practical applications. Most of these methods still use
an image-to-image formulation in which a single image is given as input to
produce an edited image as output. However, the problem is ill-defined in cases
when the target pose is significantly different from the input pose. Existing
methods then resort to in-painting or style transfer to handle occlusions and
preserve content. In this paper, we explore the utilization of multiple views
to minimize the issue of missing information and generate an accurate
representation of the underlying human model. To fuse the knowledge from
multiple viewpoints, we design a selector network that takes the pose keypoints
and texture from images and generates an interpretable per-pixel selection map.
After that, the encodings from a separate network (trained on a single image
human reposing task) are merged in the latent space. This enables us to
generate accurate, precise, and visually coherent images for different editing
tasks. We show the application of our network on 2 newly proposed tasks -
Multi-view human reposing, and Mix-and-match human image generation.
Additionally, we study the limitations of single-view editing and scenarios in
which multi-view provides a much better alternative.</p>
  </details>
</details>
<details>
  <summary>24. <b>标题：DETRDistill: A Universal Knowledge Distillation Framework for  DETR-families</b></summary>
  <p><b>编号</b>：[84]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10156</p>
  <p><b>作者</b>：Jiahao Chang,  Shuo Wang,  Guangkai Xu,  Zehui Chen,  Chenhongyi Yang,  Feng Zhao</p>
  <p><b>备注</b>：10 pages, 5 figures</p>
  <p><b>关键词</b>：great attention due, attracted great attention, huge model, post-processing operations, real-world applications</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Transformer-based detectors (DETRs) have attracted great attention due to
their sparse training paradigm and the removal of post-processing operations,
but the huge model can be computationally time-consuming and difficult to be
deployed in real-world applications. To tackle this problem, knowledge
distillation (KD) can be employed to compress the huge model by constructing a
universal teacher-student learning framework. Different from the traditional
CNN detectors, where the distillation targets can be naturally aligned through
the feature map, DETR regards object detection as a set prediction problem,
leading to an unclear relationship between teacher and student during
distillation. In this paper, we propose DETRDistill, a novel knowledge
distillation dedicated to DETR-families. We first explore a sparse matching
paradigm with progressive stage-by-stage instance distillation. Considering the
diverse attention mechanisms adopted in different DETRs, we propose
attention-agnostic feature distillation module to overcome the ineffectiveness
of conventional feature imitation. Finally, to fully leverage the intermediate
products from the teacher, we introduce teacher-assisted assignment
distillation, which uses the teacher's object queries and assignment results
for a group with additional guidance. Extensive experiments demonstrate that
our distillation method achieves significant improvement on various competitive
DETR approaches, without introducing extra consumption in the inference phase.
To the best of our knowledge, this is the first systematic study to explore a
general distillation method for DETR-style detectors.</p>
  </details>
</details>
<details>
  <summary>25. <b>标题：Structured Pruning Adapters</b></summary>
  <p><b>编号</b>：[85]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10155</p>
  <p><b>作者</b>：Lukas Hedegaard,  Aman Alok,  Juby Jose,  Alexandros Iosifidis</p>
  <p><b>备注</b>：12 pages, 9 figures, 4 tables</p>
  <p><b>关键词</b>：task-switching network adapters, tiny parameter sets, task-switching network, family of compressing, propose Structured Pruning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose Structured Pruning Adapters (SPAs), a family of compressing,
task-switching network adapters, that accelerate and specialize networks using
tiny parameter sets. Specifically, we propose a channel- and a block-based SPA
and evaluate them with a suite of pruning methods on both computer vision and
natural language processing benchmarks. Compared to regular structured pruning
with fine-tuning, our channel-SPA improves accuracy by 6.9% on average while
using half the parameters at 90% pruned weights. Alternatively, it can learn
adaptations with 17x fewer parameters at 70% pruning with 1.6% lower accuracy.
Similarly, our block-SPA requires far fewer parameters than pruning with
fine-tuning. Our experimental code and Python library of adapters are available
at this http URL.</p>
  </details>
</details>
<details>
  <summary>26. <b>标题：CRAFT: Concept Recursive Activation FacTorization for Explainability</b></summary>
  <p><b>编号</b>：[86]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10154</p>
  <p><b>作者</b>：Thomas Fel,  Agustin Picard,  Louis Bethune,  Thibaut Boissin,  David Vigouroux,  Julien Colin,  Rémi Cadène,  Thomas Serre</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：popular class, heatmaps to depict, important areas, model decision, Concept Attribution Maps</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Attribution methods are a popular class of explainability methods that use
heatmaps to depict the most important areas of an image that drive a model
decision. Nevertheless, recent work has shown that these methods have limited
utility in practice, presumably because they only highlight the most salient
parts of an image (i.e., 'where' the model looked) and do not communicate any
information about 'what' the model saw at those locations. In this work, we try
to fill in this gap with CRAFT -- a novel approach to identify both 'what' and
'where' by generating concept-based explanations. We introduce 3 new
ingredients to the automatic concept extraction literature: (i) a recursive
strategy to detect and decompose concepts across layers, (ii) a novel method
for a more faithful estimation of concept importance using Sobol indices, and
(iii) the use of implicit differentiation to unlock Concept Attribution Maps.
We conduct both human and computer vision experiments to demonstrate the
benefits of the proposed approach. We show that our recursive decomposition
generates meaningful and accurate concepts and that the proposed concept
importance estimation technique is more faithful to the model than previous
methods. When evaluating the usefulness of the method for human experimenters
on a human-defined utility benchmark, we find that our approach significantly
improves on two of the three test scenarios (while none of the current methods
including ours help on the third). Overall, our study suggests that, while much
work remains toward the development of general explainability methods that are
useful in practical scenarios, the identification of meaningful concepts at the
proper level of granularity yields useful and complementary information beyond
that afforded by attribution methods.</p>
  </details>
</details>
<details>
  <summary>27. <b>标题：Spatio-Temporal Feedback Control of Small Target Motion Detection Visual  System</b></summary>
  <p><b>编号</b>：[93]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10128</p>
  <p><b>作者</b>：Hongxin Wang,  Zhiyan Zhong,  Fang Lei,  Xiaohua Jing,  Jigen Peng,  Shigang Yue</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：perception in animals', animals' visual systems, spatio-temporal feedback, visual system, Feedback</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Feedback is crucial to motion perception in animals' visual systems where its
spatial and temporal dynamics are often shaped by movement patterns of
surrounding environments. However, such spatio-temporal feedback has not been
deeply explored in designing neural networks to detect small moving targets
that cover only one or a few pixels in image while presenting extremely limited
visual features. In this paper, we address small target motion detection
problem by developing a visual system with spatio-temporal feedback loop, and
further reveal its important roles in suppressing false positive background
movement while enhancing network responses to small targets. Specifically, the
proposed visual system is composed of two complementary subnetworks. The first
subnetwork is designed to extract spatial and temporal motion patterns of
cluttered backgrounds by neuronal ensemble coding. The second subnetwork is
developed to capture small target motion information and integrate the
spatio-temporal feedback signal from the first subnetwork to inhibit background
false positives. Experimental results demonstrate that the proposed
spatio-temporal feedback visual system is more competitive than existing
methods in discriminating small moving targets from complex dynamic
environment.</p>
  </details>
</details>
<details>
  <summary>28. <b>标题：Mixture Domain Adaptation to Improve Semantic Segmentation in Real-World  Surveillance</b></summary>
  <p><b>编号</b>：[94]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10119</p>
  <p><b>作者</b>：Sébastien Piérard,  Anthony Cioppa,  Anaïs Halin,  Renaud Vandeghen,  Maxime Zanella,  Benoît Macq,  Saïd Mahmoudi,  Marc Van Droogenbroeck</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Bayesian inference, machine learning, addressed by determining, inference or machine, critical decisions</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Various tasks encountered in real-world surveillance can be addressed by
determining posteriors (e.g. by Bayesian inference or machine learning), based
on which critical decisions must be taken. However, the surveillance domain
(acquisition device, operating conditions, etc.) is often unknown, which
prevents any possibility of scene-specific optimization. In this paper, we
define a probabilistic framework and present a formal proof of an algorithm for
the unsupervised many-to-infinity domain adaptation of posteriors. Our proposed
algorithm is applicable when the probability measure associated with the target
domain is a convex combination of the probability measures of the source
domains. It makes use of source models and a domain discriminator model trained
off-line to compute posteriors adapted on the fly to the target domain.
Finally, we show the effectiveness of our algorithm for the task of semantic
segmentation in real-world surveillance. The code is publicly available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>29. <b>标题：$α$ DARTS Once More: Enhancing Differentiable Architecture Search  by Masked Image Modeling</b></summary>
  <p><b>编号</b>：[96]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10105</p>
  <p><b>作者</b>：Bicheng Guo,  Shuxuan Guo,  Miaojing Shi,  Peng Chen,  Shibo He,  Jiming Chen,  Kaicheng Yu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：automatic machine learning, Differentiable architecture search, mainstream direction, direction in automatic, automatic machine</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Differentiable architecture search (DARTS) has been a mainstream direction in
automatic machine learning. Since the discovery that original DARTS will
inevitably converge to poor architectures, recent works alleviate this by
either designing rule-based architecture selection techniques or incorporating
complex regularization techniques, abandoning the simplicity of the original
DARTS that selects architectures based on the largest parametric value, namely
$\alpha$. Moreover, we find that all the previous attempts only rely on
classification labels, hence learning only single modal information and
limiting the representation power of the shared network. To this end, we
propose to additionally inject semantic information by formulating a patch
recovery approach. Specifically, we exploit the recent trending masked image
modeling and do not abandon the guidance from the downstream tasks during the
search phase. Our method surpasses all previous DARTS variants and achieves
state-of-the-art results on CIFAR-10, CIFAR-100, and ImageNet without complex
manual-designed strategies.</p>
  </details>
</details>
<details>
  <summary>30. <b>标题：Stereo Image Rain Removal via Dual-View Mutual Attention</b></summary>
  <p><b>编号</b>：[97]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10104</p>
  <p><b>作者</b>：Yanyan Wei,  Zhao Zhang,  Zhongqiu Zhao,  Yang Zhao,  Richang Hong,  Yi Yang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：low-vision tasks recently, solving low-vision tasks, tasks recently, rain removal methods, utilized in solving</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Stereo images, containing left and right view images with disparity, are
utilized in solving low-vision tasks recently, e.g., rain removal and
super-resolution. Stereo image restoration methods usually obtain better
performance than monocular methods by learning the disparity between dual views
either implicitly or explicitly. However, existing stereo rain removal methods
still cannot make full use of the complementary information between two views,
and we find it is because: 1) the rain streaks have more complex distributions
in directions and densities, which severely damage the complementary
information and pose greater challenges; 2) the disparity estimation is not
accurate enough due to the imperfect fusion mechanism for the features between
two views. To overcome such limitations, we propose a new \underline{Stereo}
\underline{I}mage \underline{R}ain \underline{R}emoval method (StereoIRR) via
sufficient interaction between two views, which incorporates: 1) a new
Dual-view Mutual Attention (DMA) mechanism which generates mutual attention
maps by taking left and right views as key information for each other to
facilitate cross-view feature fusion; 2) a long-range and cross-view
interaction, which is constructed with basic blocks and dual-view mutual
attention, can alleviate the adverse effect of rain on complementary
information to help the features of stereo images to get long-range and
cross-view interaction and fusion. Notably, StereoIRR outperforms other related
monocular and stereo image rain removal methods on several datasets. Our codes
and datasets will be released.</p>
  </details>
</details>
<details>
  <summary>31. <b>标题：Let's Enhance: A Deep Learning Approach to Extreme Deblurring of Text  Images</b></summary>
  <p><b>编号</b>：[98]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10103</p>
  <p><b>作者</b>：Theophil Trippe,  Martin Genzel,  Jan Macdonald,  Maximilian März</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：work presents, synthetic data, leveraging augmentation, Helsinki Deblur Challenge, Challenge</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This work presents a novel deep-learning-based pipeline for the inverse
problem of image deblurring, leveraging augmentation and pre-training with
synthetic data. Our results build on our winning submission to the recent
Helsinki Deblur Challenge 2021, whose goal was to explore the limits of
state-of-the-art deblurring algorithms in a real-world data setting. The task
of the challenge was to deblur out-of-focus images of random text, thereby in a
downstream task, maximizing an optical-character-recognition-based score
function. A key step of our solution is the data-driven estimation of the
physical forward model describing the blur process. This enables a stream of
synthetic data, generating pairs of ground-truth and blurry images on-the-fly,
which is used for an extensive augmentation of the small amount of challenge
data provided. The actual deblurring pipeline consists of an approximate
inversion of the radial lens distortion (determined by the estimated forward
model) and a U-Net architecture, which is trained end-to-end. Our algorithm was
the only one passing the hardest challenge level, achieving over 70% character
recognition accuracy. Our findings are well in line with the paradigm of
data-centric machine learning, and we demonstrate its effectiveness in the
context of inverse problems. Apart from a detailed presentation of our
methodology, we also analyze the importance of several design choices in a
series of ablation studies. The code of our challenge submission is available
under this https URL.</p>
  </details>
</details>
<details>
  <summary>32. <b>标题：UnconFuse: Avatar Reconstruction from Unconstrained Images</b></summary>
  <p><b>编号</b>：[101]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10098</p>
  <p><b>作者</b>：Han Huang,  Liliang Chen,  Xihao Wang</p>
  <p><b>备注</b>：Accepted to ECCV 2022 Workshop</p>
  <p><b>关键词</b>：human body reconstruction, multiple unconstrained frames, human body, frames for ECCV, WCPA Challenge</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The report proposes an effective solution about 3D human body reconstruction
from multiple unconstrained frames for ECCV 2022 WCPA Challenge: From Face,
Body and Fashion to 3D Virtual avatars I (track1: Multi-View Based 3D Human
Body Reconstruction). We reproduce the reconstruction method presented in
MVP-Human as our baseline, and make some improvements for the particularity of
this challenge. We finally achieve the score 0.93 on the official testing set,
getting the 1st place on the leaderboard.</p>
  </details>
</details>
<details>
  <summary>33. <b>标题：Reference-Based Autoencoder for Surface Defect Detection</b></summary>
  <p><b>编号</b>：[115]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10060</p>
  <p><b>作者</b>：Wei Luo,  Haiming Yao,  Wenyong Yu,  Xue Wang</p>
  <p><b>备注</b>：13pages</p>
  <p><b>关键词</b>：product quality inspection, industrial automatic product, automatic product quality, visual anomaly detection, abnormal data</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Due to the extreme imbalance in the number of normal data and abnormal data,
visual anomaly detection is important for the development of industrial
automatic product quality inspection. Unsupervised methods based on
reconstruction and embedding have been widely studied for anomaly detection, of
which reconstruction-based methods are the most popular. However, establishing
a unified model for textured surface defect detection remains a challenge
because these surfaces can vary in homogeneous and non regularly ways.
Furthermore, existing reconstruction-based methods do not have a strong ability
to convert the defect feature to the normal feature. To address these
challenges, we propose a novel unsupervised reference-based autoencoder (RB-AE)
to accurately inspect a variety of textured defects. Unlike most
reconstruction-based methods, artificial defects and a novel pixel-level
discrimination loss function are utilized for training to enable the model to
obtain pixel-level discrimination ability. First, the RB-AE employs an encoding
module to extract multi-scale features of the textured surface. Subsequently, a
novel reference-based attention module (RBAM) is proposed to convert the defect
features to normal features to suppress the reconstruction of defects. In
addition, RBAM can also effectively suppress the defective feature residual
caused by skip-connection. Next, a decoding module utilizes the repaired
features to reconstruct the normal texture background. Finally, a novel
multiscale feature discrimination module (MSFDM) is employed to defect
detection and segmentation.</p>
  </details>
</details>
<details>
  <summary>34. <b>标题：Contrastive Losses Are Natural Criteria for Unsupervised Video  Summarization</b></summary>
  <p><b>编号</b>：[117]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10056</p>
  <p><b>作者</b>：Zongshang Pang,  Yuta Nakashima,  Mayu Otani,  Hajime Nagahara</p>
  <p><b>备注</b>：To appear in WACV2023</p>
  <p><b>关键词</b>：efficient video browsing, Video summarization aims, facilitate efficient video, summarization aims, aims to select</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Video summarization aims to select the most informative subset of frames in a
video to facilitate efficient video browsing. Unsupervised methods usually rely
on heuristic training objectives such as diversity and representativeness.
However, such methods need to bootstrap the online-generated summaries to
compute the objectives for importance score regression. We consider such a
pipeline inefficient and seek to directly quantify the frame-level importance
with the help of contrastive losses in the representation learning literature.
Leveraging the contrastive losses, we propose three metrics featuring a
desirable key frame: local dissimilarity, global consistency, and uniqueness.
With features pre-trained on the image classification task, the metrics can
already yield high-quality importance scores, demonstrating competitive or
better performance than past heavily-trained methods. We show that by refining
the pre-trained features with a lightweight contrastively learned projection
module, the frame-level importance scores can be further improved, and the
model can also leverage a large number of random videos and generalize to test
videos with decent performance. Code available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>35. <b>标题：Pedestrian Spatio-Temporal Information Fusion For Video Anomaly  Detection</b></summary>
  <p><b>编号</b>：[119]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10052</p>
  <p><b>作者</b>：Chao Hu,  Liqiang Zhu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：video anomaly detection, anomaly detection, anomaly detection method, ignore the diversity, integrate the spatiotemporal</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Aiming at the problem that the current video anomaly detection cannot fully
use the temporal information and ignore the diversity of normal behavior, an
anomaly detection method is proposed to integrate the spatiotemporal
information of pedestrians. Based on the convolutional autoencoder, the input
frame is compressed and restored through the encoder and decoder. Anomaly
detection is realized according to the difference between the output frame and
the true value. In order to strengthen the characteristic information
connection between continuous video frames, the residual temporal shift module
and the residual channel attention module are introduced to improve the
modeling ability of the network on temporal information and channel
information, respectively. Due to the excessive generalization of convolutional
neural networks, in the memory enhancement modules, the hopping connections of
each codec layer are added to limit autoencoders' ability to represent abnormal
frames too vigorously and improve the anomaly detection accuracy of the
network. In addition, the objective function is modified by a feature
discretization loss, which effectively distinguishes different normal behavior
patterns. The experimental results on the CUHK Avenue and ShanghaiTech datasets
show that the proposed method is superior to the current mainstream video
anomaly detection methods while meeting the real-time requirements.</p>
  </details>
</details>
<details>
  <summary>36. <b>标题：Vision Transformers in Medical Imaging: A Review</b></summary>
  <p><b>编号</b>：[122]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10043</p>
  <p><b>作者</b>：Emerald U. Henry,  Onyeka Emebob,  Conrad Asotie Omonhinmin</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：natural language processing, comprising attention-based encoder-decoder, model comprising attention-based, attention-based encoder-decoder architecture, computer vision</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Transformer, a model comprising attention-based encoder-decoder architecture,
have gained prevalence in the field of natural language processing (NLP) and
recently influenced the computer vision (CV) space. The similarities between
computer vision and medical imaging, reviewed the question among researchers if
the impact of transformers on computer vision be translated to medical imaging?
In this paper, we attempt to provide a comprehensive and recent review on the
application of transformers in medical imaging by; describing the transformer
model comparing it with a diversity of convolutional neural networks (CNNs),
detailing the transformer based approaches for medical image classification,
segmentation, registration and reconstruction with a focus on the image
modality, comparing the performance of state-of-the-art transformer
architectures to best performing CNNs on standard medical datasets.</p>
  </details>
</details>
<details>
  <summary>37. <b>标题：LiSnowNet: Real-time Snow Removal for LiDAR Point Cloud</b></summary>
  <p><b>编号</b>：[130]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10023</p>
  <p><b>作者</b>：Ming-Yuan Yu,  Ram Vasudevan,  Matthew Johnson-Roberson</p>
  <p><b>备注</b>：The paper has been accepted for the 2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2022)</p>
  <p><b>关键词</b>：modern self-driving vehicles, self-driving vehicles, surrounding objects, widely adopted, scene and surrounding</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>LiDARs have been widely adopted to modern self-driving vehicles, providing 3D
information of the scene and surrounding objects. However, adverser weather
conditions still pose significant challenges to LiDARs since point clouds
captured during snowfall can easily be corrupted. The resulting noisy point
clouds degrade downstream tasks such as mapping. Existing works in de-noising
point clouds corrupted by snow are based on nearest-neighbor search, and thus
do not scale well with modern LiDARs which usually capture $100k$ or more
points at 10Hz. In this paper, we introduce an unsupervised de-noising
algorithm, LiSnowNet, running 52$\times$ faster than the state-of-the-art
methods while achieving superior performance in de-noising. Unlike previous
methods, the proposed algorithm is based on a deep convolutional neural network
and can be easily deployed to hardware accelerators such as GPUs. In addition,
we demonstrate how to use the proposed method for mapping even with corrupted
point clouds.</p>
  </details>
</details>
<details>
  <summary>38. <b>标题：3d human motion generation from the text via gesture action  classification and the autoregressive model</b></summary>
  <p><b>编号</b>：[139]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10003</p>
  <p><b>作者</b>：Gwantae Kim,  Youngsuk Ryu,  Junyeop Lee,  David K. Han,  Jeongmin Bae,  Hanseok Ko</p>
  <p><b>备注</b>：5 pages, 3 figures, ICIP 2022</p>
  <p><b>关键词</b>：deep learning-based model, text classification model, model, gesture action classification, deep learning-based</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, a deep learning-based model for 3D human motion generation
from the text is proposed via gesture action classification and an
autoregressive model. The model focuses on generating special gestures that
express human thinking, such as waving and nodding. To achieve the goal, the
proposed method predicts expression from the sentences using a text
classification model based on a pretrained language model and generates
gestures using the gate recurrent unit-based autoregressive model. Especially,
we proposed the loss for the embedding space for restoring raw motions and
generating intermediate motions well. Moreover, the novel data augmentation
method and stop token are proposed to generate variable length motions. To
evaluate the text classification model and 3D human motion generation model, a
gesture action classification dataset and action-based gesture dataset are
collected. With several experiments, the proposed method successfully generates
perceptually natural and realistic 3D human motion from the text. Moreover, we
verified the effectiveness of the proposed method using a public-available
action recognition dataset to evaluate cross-dataset generalization
performance.</p>
  </details>
</details>
<details>
  <summary>39. <b>标题：Look More but Care Less in Video Recognition</b></summary>
  <p><b>编号</b>：[144]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.09992</p>
  <p><b>作者</b>：Yitian Zhang,  Yue Bai,  Huan Wang,  Yi Xu,  Yun Fu</p>
  <p><b>备注</b>：Accepted by NeurIPS 2022</p>
  <p><b>关键词</b>：Existing action recognition, action recognition methods, recognition methods typically, methods typically sample, recognition performance</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Existing action recognition methods typically sample a few frames to
represent each video to avoid the enormous computation, which often limits the
recognition performance. To tackle this problem, we propose Ample and Focal
Network (AFNet), which is composed of two branches to utilize more frames but
with less computation. Specifically, the Ample Branch takes all input frames to
obtain abundant information with condensed computation and provides the
guidance for Focal Branch by the proposed Navigation Module; the Focal Branch
squeezes the temporal size to only focus on the salient frames at each
convolution block; in the end, the results of two branches are adaptively fused
to prevent the loss of information. With this design, we can introduce more
frames to the network but cost less computation. Besides, we demonstrate AFNet
can utilize fewer frames while achieving higher accuracy as the dynamic
selection in intermediate features enforces implicit temporal modeling.
Further, we show that our method can be extended to reduce spatial redundancy
with even less cost. Extensive experiments on five datasets demonstrate the
effectiveness and efficiency of our method.</p>
  </details>
</details>
<details>
  <summary>40. <b>标题：Contrastive Positive Sample Propagation along the Audio-Visual Event  Line</b></summary>
  <p><b>编号</b>：[149]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.09980</p>
  <p><b>作者</b>：Jinxing Zhou,  Dan Guo,  Meng Wang</p>
  <p><b>备注</b>：Accepted to TPAMI; Dataset and Code are available at this https URL arXiv admin note: substantial text overlap with arXiv:2104.00239</p>
  <p><b>关键词</b>：forming audio-visual events, positive sample propagation, Visual and audio, natural environments, audio signals</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Visual and audio signals often coexist in natural environments, forming
audio-visual events (AVEs). Given a video, we aim to localize video segments
containing an AVE and identify its category. It is pivotal to learn the
discriminative features for each video segment. Unlike existing work focusing
on audio-visual feature fusion, in this paper, we propose a new contrastive
positive sample propagation (CPSP) method for better deep feature
representation learning. The contribution of CPSP is to introduce the available
full or weak label as a prior that constructs the exact positive-negative
samples for contrastive learning. Specifically, the CPSP involves comprehensive
contrastive constraints: pair-level positive sample propagation (PSP),
segment-level and video-level positive sample activation (PSA$_S$ and PSA$_V$).
Three new contrastive objectives are proposed (\emph{i.e.},
$\mathcal{L}_{\text{avpsp}}$, $\mathcal{L}_\text{spsa}$, and
$\mathcal{L}_\text{vpsa}$) and introduced into both the fully and weakly
supervised AVE localization. To draw a complete picture of the contrastive
learning in AVE localization, we also study the self-supervised positive sample
propagation (SSPSP). As a result, CPSP is more helpful to obtain the refined
audio-visual features that are distinguishable from the negatives, thus
benefiting the classifier prediction. Extensive experiments on the AVE and the
newly collected VGGSound-AVEL100k datasets verify the effectiveness and
generalization ability of our method.</p>
  </details>
</details>
<details>
  <summary>41. <b>标题：Comparison between EM and FCM algorithms in skin tone extraction</b></summary>
  <p><b>编号</b>：[150]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.09979</p>
  <p><b>作者</b>：Elham Ravanbakhsh,  Mosab Rezaei,  Ehsan Namjoo,  Padideh Choobdar</p>
  <p><b>备注</b>：2016 1st International Conference on New Research Achievements in Electrical and Computer Engineering (ICNRAECE)</p>
  <p><b>关键词</b>：FCM algorithms, study aims, aims to investigate, investigate implementing, HSV color</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This study aims to investigate implementing EM and FCM algorithms for skin
color extraction. The capabilities of three well-known color spaces, namely,
RGB, HSV, and YCbCr for skin-tone extraction are assessed by using statistical
modeling of skin tones using EM and FCM algorithms. The results show that
utilizing a Gaussian mixture model for parametric modeling of skin tones using
EM algorithm works well in HSV color space when all three components of the
color vector are used. In spite of discarding the luminance components in YCbCr
and HSV color spaces, EM algorithm provides the best results. The results of
the detailed comparisons are explained in the conclusion.</p>
  </details>
</details>
<details>
  <summary>42. <b>标题：The Runner-up Solution for YouTube-VIS Long Video Challenge 2022</b></summary>
  <p><b>编号</b>：[152]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.09973</p>
  <p><b>作者</b>：Junfeng Wu,  Yi Jiang,  Qihao Liu,  Xiang Bai,  Song Bai</p>
  <p><b>备注</b>：The Runner-up Solution for YouTube-VIS Long Video Challenge 2022, ECCV 2022 Workshop. arXiv admin note: text overlap with arXiv:2207.10661</p>
  <p><b>关键词</b>：technical report describes, technical report, report describes, Long Video Challenge, ECCV</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This technical report describes our 2nd-place solution for the ECCV 2022
YouTube-VIS Long Video Challenge. We adopt the previously proposed online video
instance segmentation method IDOL for this challenge. In addition, we use
pseudo labels to further help contrastive learning, so as to obtain more
temporally consistent instance embedding to improve tracking performance
between frames. The proposed method obtains 40.2 AP on the YouTube-VIS 2022
long video dataset and was ranked second place in this challenge. We hope our
simple and effective method could benefit further research.</p>
  </details>
</details>
<details>
  <summary>43. <b>标题：AVATAR submission to the Ego4D AV Transcription Challenge</b></summary>
  <p><b>编号</b>：[155]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.09966</p>
  <p><b>作者</b>：Paul Hongsuck Seo,  Arsha Nagrani,  Cordelia Schmid</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Speech Transcription Challenge, Speech Transcription, Transcription Challenge, AudioVisual, Challenge</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this report, we describe our submission to the Ego4D AudioVisual (AV)
Speech Transcription Challenge 2022. Our pipeline is based on AVATAR, a state
of the art encoder-decoder model for AV-ASR that performs early fusion of
spectrograms and RGB images. We describe the datasets, experimental settings
and ablations. Our final method achieves a WER of 68.40 on the challenge test
set, outperforming the baseline by 43.7%, and winning the challenge.</p>
  </details>
</details>
<details>
  <summary>44. <b>标题：Ask4Help: Learning to Leverage an Expert for Embodied Tasks</b></summary>
  <p><b>编号</b>：[158]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.09960</p>
  <p><b>作者</b>：Kunal Pratap Singh,  Luca Weihs,  Alvaro Herrasti,  Jonghyun Choi,  Aniruddha Kemhavi,  Roozbeh Mottaghi</p>
  <p><b>备注</b>：Accepted at NeurIPS, 2022</p>
  <p><b>关键词</b>：deployed in real, capable every year, performant and reliable, agents continue, agents</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Embodied AI agents continue to become more capable every year with the advent
of new models, environments, and benchmarks, but are still far away from being
performant and reliable enough to be deployed in real, user-facing,
applications. In this paper, we ask: can we bridge this gap by enabling agents
to ask for assistance from an expert such as a human being? To this end, we
propose the Ask4Help policy that augments agents with the ability to request,
and then use expert assistance. Ask4Help policies can be efficiently trained
without modifying the original agent's parameters and learn a desirable
trade-off between task performance and the amount of requested help, thereby
reducing the cost of querying the expert. We evaluate Ask4Help on two different
tasks -- object goal navigation and room rearrangement and see substantial
improvements in performance using minimal help. On object navigation, an agent
that achieves a $52\%$ success rate is raised to $86\%$ with $13\%$ help and
for rearrangement, the state-of-the-art model with a $7\%$ success rate is
dramatically improved to $90.4\%$ using $39\%$ help. Human trials with Ask4Help
demonstrate the efficacy of our approach in practical scenarios. We release the
code for Ask4Help here: this https URL.</p>
  </details>
</details>
<details>
  <summary>45. <b>标题：Potential Auto-driving Threat: Universal Rain-removal Attack</b></summary>
  <p><b>编号</b>：[159]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.09959</p>
  <p><b>作者</b>：Jinchegn Hu,  Jihao Li,  Zhuoran Hou,  Jingjing Jiang,  Cunjia Liu,  Yuanjian Zhang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：adverse weather conditions, computer vision algorithms, robustness in adverse, adverse weather, weather conditions</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The problem of robustness in adverse weather conditions is considered a
significant challenge for computer vision algorithms in the applicants of
autonomous driving. Image rain removal algorithms are a general solution to
this problem. They find a deep connection between raindrops/rain-streaks and
images by mining the hidden features and restoring information about the
rain-free environment based on the powerful representation capabilities of
neural networks. However, previous research has focused on architecture
innovations and has yet to consider the vulnerability issues that already exist
in neural networks. This research gap hints at a potential security threat
geared toward the intelligent perception of autonomous driving in the rain. In
this paper, we propose a universal rain-removal attack (URA) on the
vulnerability of image rain-removal algorithms by generating a non-additive
spatial perturbation that significantly reduces the similarity and image
quality of scene restoration. Notably, this perturbation is difficult to
recognise by humans and is also the same for different target images. Thus, URA
could be considered a critical tool for the vulnerability detection of image
rain-removal algorithms. It also could be developed as a real-world artificial
intelligence attack method. Experimental results show that URA can reduce the
scene repair capability by 39.5% and the image generation quality by 26.4%,
targeting the state-of-the-art (SOTA) single-image rain-removal algorithms
currently available.</p>
  </details>
</details>
<details>
  <summary>46. <b>标题：TempNet: Temporal Attention Towards the Detection of Animal Behaviour in  Videos</b></summary>
  <p><b>编号</b>：[163]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.09950</p>
  <p><b>作者</b>：Declan McIntosh,  Tunai Porto Marques,  Alexandra Branzan Albu,  Rodney Rountree,  Fabio De Leo</p>
  <p><b>备注</b>：6 pages, 5 figures, 2 tables, International Conference on Pattern Recognition, ICPR 2022, ICPR</p>
  <p><b>关键词</b>：cabled ocean observatories, high-level biologically relevant, biologically relevant information, Recent advancements, advancements in cabled</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent advancements in cabled ocean observatories have increased the quality
and prevalence of underwater videos; this data enables the extraction of
high-level biologically relevant information such as species' behaviours.
Despite this increase in capability, most modern methods for the automatic
interpretation of underwater videos focus only on the detection and counting
organisms. We propose an efficient computer vision- and deep learning-based
method for the detection of biological behaviours in videos. TempNet uses an
encoder bridge and residual blocks to maintain model performance with a
two-staged, spatial, then temporal, encoder. TempNet also presents temporal
attention during spatial encoding as well as Wavelet Down-Sampling
pre-processing to improve model accuracy. Although our system is designed for
applications to diverse fish behaviours (i.e, is generic), we demonstrate its
application to the detection of sablefish (Anoplopoma fimbria) startle events.
We compare the proposed approach with a state-of-the-art end-to-end video
detection method (ReMotENet) and a hybrid method previously offered exclusively
for the detection of sablefish's startle events in videos from an existing
dataset. Results show that our novel method comfortably outperforms the
comparison baselines in multiple metrics, reaching a per-clip accuracy and
precision of 80% and 0.81, respectively. This represents a relative improvement
of 31% in accuracy and 27% in precision over the compared methods using this
dataset. Our computational pipeline is also highly efficient, as it can process
each 4-second video clip in only 38ms. Furthermore, since it does not employ
features specific to sablefish startle events, our system can be easily
extended to other behaviours in future works.</p>
  </details>
</details>
<details>
  <summary>47. <b>标题：SparseVLR: A Novel Framework for Verified Locally Robust Sparse Neural  Networks Search</b></summary>
  <p><b>编号</b>：[165]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.09945</p>
  <p><b>作者</b>：Sawinder Kaur,  Asif Salekin</p>
  <p><b>备注</b>：16 pages, 9 tables, 7 figures</p>
  <p><b>关键词</b>：autonomous robots, limits their deployment, cell phones, compute-intensive nature, nature of neural</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The compute-intensive nature of neural networks (NNs) limits their deployment
in resource-constrained environments such as cell phones, drones, autonomous
robots, etc. Hence, developing robust sparse models fit for safety-critical
applications has been an issue of longstanding interest. Though adversarial
training with model sparsification has been combined to attain the goal,
conventional adversarial training approaches provide no formal guarantee that
the models would be robust against any rogue samples in a restricted space
around a benign sample. Recently proposed verified local robustness techniques
provide such a guarantee. This is the first paper that combines the ideas from
verified local robustness and dynamic sparse training to develop `SparseVLR'--
a novel framework to search verified locally robust sparse networks. Obtained
sparse models exhibit accuracy and robustness comparable to their dense
counterparts at sparsity as high as 99%. Furthermore, unlike most conventional
sparsification techniques, SparseVLR does not require a pre-trained dense
model, reducing the training time by 50%. We exhaustively investigated
SparseVLR's efficacy and generalizability by evaluating various benchmark and
application-specific datasets across several models.</p>
  </details>
</details>
<details>
  <summary>48. <b>标题：SAR-based landslide classification pretraining leads to better  segmentation</b></summary>
  <p><b>编号</b>：[176]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.09927</p>
  <p><b>作者</b>：Vanessa Böhm,  Wei Ji Leong,  Ragini Bal Mahesh,  Ioannis Prapas,  Edoardo Nemni,  Freddie Kalaitzis,  Siddha Ganju,  Raul Ramos-Pollan</p>
  <p><b>备注</b>：Accepted to the NeurIPS 2022 workshop Artificial Intelligence for Humanitarian Assistance and Disaster Response. This research was conducted as part of the Frontier Development Lab (FDL) 2022</p>
  <p><b>关键词</b>：prioritizing emergency resources, Rapid assessment, natural disaster, disaster is key, key for prioritizing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Rapid assessment after a natural disaster is key for prioritizing emergency
resources. In the case of landslides, rapid assessment involves determining the
extent of the area affected and measuring the size and location of individual
landslides. Synthetic Aperture Radar (SAR) is an active remote sensing
technique that is unaffected by weather conditions. Deep Learning algorithms
can be applied to SAR data, but training them requires large labeled datasets.
In the case of landslides, these datasets are laborious to produce for
segmentation, and often they are not available for the specific region in which
the event occurred. Here, we study how deep learning algorithms for landslide
segmentation on SAR products can benefit from pretraining on a simpler task and
from data from different regions. The method we explore consists of two
training stages. First, we learn the task of identifying whether a SAR image
contains any landslides or not. Then, we learn to segment in a sparsely labeled
scenario where half of the data do not contain landslides. We test whether the
inclusion of feature embeddings derived from stage-1 helps with landslide
detection in stage-2. We find that it leads to minor improvements in the Area
Under the Precision-Recall Curve, but also to a significantly lower false
positive rate in areas without landslides and an improved estimate of the
average number of landslide pixels in a chip. A more accurate pixel count
allows to identify the most affected areas with higher confidence. This could
be valuable in rapid response scenarios where prioritization of resources at a
global scale is important. We make our code publicly available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>49. <b>标题：Patch-Craft Self-Supervised Training for Correlated Image Denoising</b></summary>
  <p><b>编号</b>：[180]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.09919</p>
  <p><b>作者</b>：Gregory Vaksman,  Michael Elad</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Supervised neural networks, achieve excellent results, Supervised neural, neural networks, achieve excellent</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Supervised neural networks are known to achieve excellent results in various
image restoration tasks. However, such training requires datasets composed of
pairs of corrupted images and their corresponding ground truth targets.
Unfortunately, such data is not available in many applications. For the task of
image denoising in which the noise statistics is unknown, several
self-supervised training methods have been proposed for overcoming this
difficulty. Some of these require knowledge of the noise model, while others
assume that the contaminating noise is uncorrelated, both assumptions are too
limiting for many practical needs. This work proposes a novel self-supervised
training technique suitable for the removal of unknown correlated noise. The
proposed approach neither requires knowledge of the noise model nor access to
ground truth targets. The input to our algorithm consists of easily captured
bursts of noisy shots. Our algorithm constructs artificial patch-craft images
from these bursts by patch matching and stitching, and the obtained crafted
images are used as targets for the training. Our method does not require
registration of the images within the burst. We evaluate the proposed framework
through extensive experiments with synthetic and real image noise.</p>
  </details>
</details>
<details>
  <summary>50. <b>标题：RenderDiffusion: Image Diffusion for 3D Reconstruction, Inpainting and  Generation</b></summary>
  <p><b>编号</b>：[188]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.09869</p>
  <p><b>作者</b>：Titas Anciukevičius,  Zexiang Xu,  Matthew Fisher,  Paul Henderson,  Hakan Bilen,  Niloy J. Mitra,  Paul Guerrero</p>
  <p><b>备注</b>：We will release our datasets, code, and checkpoints at this https URL</p>
  <p><b>关键词</b>：conditional and unconditional, unconditional image generation, Diffusion models, image diffusion models, Diffusion</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Diffusion models currently achieve state-of-the-art performance for both
conditional and unconditional image generation. However, so far, image
diffusion models do not support tasks required for 3D understanding, such as
view-consistent 3D generation or single-view object reconstruction. In this
paper, we present RenderDiffusion as the first diffusion model for 3D
generation and inference that can be trained using only monocular 2D
supervision. At the heart of our method is a novel image denoising architecture
that generates and renders an intermediate three-dimensional representation of
a scene in each denoising step. This enforces a strong inductive structure into
the diffusion process that gives us a 3D consistent representation while only
requiring 2D supervision. The resulting 3D representation can be rendered from
any viewpoint. We evaluate RenderDiffusion on ShapeNet and Clevr datasets and
show competitive performance for generation of 3D scenes and inference of 3D
scenes from 2D images. Additionally, our diffusion-based approach allows us to
use 2D inpainting to edit 3D scenes. We believe that our work promises to
enable full 3D generation at scale when trained on massive image collections,
thus circumventing the need to have large-scale 3D model collections for
supervision.</p>
  </details>
</details>
<details>
  <summary>51. <b>标题：Self-Supervised Visual Representation Learning via Residual Momentum</b></summary>
  <p><b>编号</b>：[191]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.09861</p>
  <p><b>作者</b>：Trung X. Pham,  Axi Niu,  Zhang Kang,  Sultan Rizky Madjid,  Ji Woo Hong,  Daehyeok Kim,  Joshua Tian Jin Tee,  Chang D. Yoo</p>
  <p><b>备注</b>：18 pages, 16 figures</p>
  <p><b>关键词</b>：shown promising capabilities, SSL frameworks, momentum-based SSL frameworks, approaches have shown, unlabeled data</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Self-supervised learning (SSL) approaches have shown promising capabilities
in learning the representation from unlabeled data. Amongst them,
momentum-based frameworks have attracted significant attention. Despite being a
great success, these momentum-based SSL frameworks suffer from a large gap in
representation between the online encoder (student) and the momentum encoder
(teacher), which hinders performance on downstream tasks. This paper is the
first to investigate and identify this invisible gap as a bottleneck that has
been overlooked in the existing SSL frameworks, potentially preventing the
models from learning good representation. To solve this problem, we propose
"residual momentum" to directly reduce this gap to encourage the student to
learn the representation as close to that of the teacher as possible, narrow
the performance gap with the teacher, and significantly improve the existing
SSL. Our method is straightforward, easy to implement, and can be easily
plugged into other SSL frameworks. Extensive experimental results on numerous
benchmark datasets and diverse network architectures have demonstrated the
effectiveness of our method over the state-of-the-art contrastive learning
baselines.</p>
  </details>
</details>
<details>
  <summary>52. <b>标题：Data-Centric Debugging: mitigating model failures via targeted data  collection</b></summary>
  <p><b>编号</b>：[192]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.09859</p>
  <p><b>作者</b>：Sahil Singla,  Atoosa Malemir Chegini,  Mazda Moayeri,  Soheil Feiz</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Deep neural networks, mathcal, Deep neural, neural networks, real world</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep neural networks can be unreliable in the real world when the training
set does not adequately cover all the settings where they are deployed.
Focusing on image classification, we consider the setting where we have an
error distribution $\mathcal{E}$ representing a deployment scenario where the
model fails. We have access to a small set of samples $\mathcal{E}_{sample}$
from $\mathcal{E}$ and it can be expensive to obtain additional samples. In the
traditional model development framework, mitigating failures of the model in
$\mathcal{E}$ can be challenging and is often done in an ad hoc manner. In this
paper, we propose a general methodology for model debugging that can
systemically improve model performance on $\mathcal{E}$ while maintaining its
performance on the original test set. Our key assumption is that we have access
to a large pool of weakly (noisily) labeled data $\mathcal{F}$. However,
naively adding $\mathcal{F}$ to the training would hurt model performance due
to the large extent of label noise. Our Data-Centric Debugging (DCD) framework
carefully creates a debug-train set by selecting images from $\mathcal{F}$ that
are perceptually similar to the images in $\mathcal{E}_{sample}$. To do this,
we use the $\ell_2$ distance in the feature space (penultimate layer
activations) of various models including ResNet, Robust ResNet and DINO where
we observe DINO ViTs are significantly better at discovering similar images
compared to Resnets. Compared to LPIPS, we find that our method reduces compute
and storage requirements by 99.58\%. Compared to the baselines that maintain
model performance on the test set, we achieve significantly (+9.45\%) improved
results on the debug-heldout sets.</p>
  </details>
</details>
<details>
  <summary>53. <b>标题：Arbitrarily Accurate Classification Applied to Specific Emitter  Identification</b></summary>
  <p><b>编号</b>：[213]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10379</p>
  <p><b>作者</b>：Michael C. Kleder</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：obtaining arbitrary accuracy, article introduces, introduces a method, method of evaluating, obtaining arbitrary</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This article introduces a method of evaluating subsamples until any
prescribed level of classification accuracy is attained, thus obtaining
arbitrary accuracy. A logarithmic reduction in error rate is obtained with a
linear increase in sample count. The technique is applied to specific emitter
identification on a published dataset of physically recorded over-the-air
signals from 16 ostensibly identical high-performance radios. The technique
uses a multi-channel deep learning convolutional neural network acting on the
bispectra of I/Q signal subsamples each consisting of 56 parts per million
(ppm) of the original signal duration. High levels of accuracy are obtained
with minimal computation time: in this application, each addition of eight
samples decreases error by one order of magnitude.</p>
  </details>
</details>
<details>
  <summary>54. <b>标题：Joint nnU-Net and Radiomics Approaches for Segmentation and Prognosis of  Head and Neck Cancers with PET/CT images</b></summary>
  <p><b>编号</b>：[228]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10138</p>
  <p><b>作者</b>：Hui Xu,  Yihao Li,  Wei Zhao,  Gwenolé Quellec,  Lijun Lu,  Mathieu Hatt</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：optimization treatment strategy, Automatic segmentation, neck cancer, head and neck, plays a crucial</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Automatic segmentation of head and neck cancer (HNC) tumors and lymph nodes
plays a crucial role in the optimization treatment strategy and prognosis
analysis. This study aims to employ nnU-Net for automatic segmentation and
radiomics for recurrence-free survival (RFS) prediction using pretreatment
PET/CT images in multi-center HNC cohort. A multi-center HNC dataset with 883
patients (524 patients for training, 359 for testing) was provided in HECKTOR
2022. A bounding box of the extended oropharyngeal region was retrieved for
each patient with fixed size of 224 x 224 x 224 $mm^{3}$. Then 3D nnU-Net
architecture was adopted to automatic segmentation of primary tumor and lymph
nodes synchronously.Based on predicted segmentation, ten conventional features
and 346 standardized radiomics features were extracted for each patient. Three
prognostic models were constructed containing conventional and radiomics
features alone, and their combinations by multivariate CoxPH modelling. The
statistical harmonization method, ComBat, was explored towards reducing
multicenter variations. Dice score and C-index were used as evaluation metrics
for segmentation and prognosis task, respectively. For segmentation task, we
achieved mean dice score around 0.701 for primary tumor and lymph nodes by 3D
nnU-Net. For prognostic task, conventional and radiomics models obtained the
C-index of 0.658 and 0.645 in the test set, respectively, while the combined
model did not improve the prognostic performance with the C-index of 0.648.</p>
  </details>
</details>
<details>
  <summary>55. <b>标题：DGD-cGAN: A Dual Generator for Image Dewatering and Restoration</b></summary>
  <p><b>编号</b>：[233]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10026</p>
  <p><b>作者</b>：Salma Gonzalez-Sabbagh,  Antonio Robles-Kelly,  Shang Gao</p>
  <p><b>备注</b>：12 pages and 61 images</p>
  <p><b>关键词</b>：blue-greenish colour cast, making them distorted, blurry or low, low in contrast, Dual Generator Dewatering</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Underwater images are usually covered with a blue-greenish colour cast,
making them distorted, blurry or low in contrast. This phenomenon occurs due to
the light attenuation given by the scattering and absorption in the water
column. In this paper, we present an image enhancement approach for dewatering
which employs a conditional generative adversarial network (cGAN) with two
generators. Our Dual Generator Dewatering cGAN (DGD-cGAN) removes the haze and
colour cast induced by the water column and restores the true colours of
underwater scenes whereby the effects of various attenuation and scattering
phenomena that occur in underwater images are tackled by the two generators.
The first generator takes at input the underwater image and predicts the
dewatered scene, while the second generator learns the underwater image
formation process by implementing a custom loss function based upon the
transmission and the veiling light components of the image formation model. Our
experiments show that DGD-cGAN consistently delivers a margin of improvement as
compared with the state-of-the-art methods on several widely available
datasets.</p>
  </details>
</details>
<details>
  <summary>56. <b>标题：Bayesian Optimization of 2D Echocardiography Segmentation</b></summary>
  <p><b>编号</b>：[245]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.09888</p>
  <p><b>作者</b>：Son-Tung Tran,  Joshua V. Stough,  Xiaoyan Zhang,  Christopher M. Haggerty</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：high-parameter machine learning, machine learning problems, Bayesian Optimization, well-studied hyperparameter tuning, hyperparameter tuning technique</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Bayesian Optimization (BO) is a well-studied hyperparameter tuning technique
that is more efficient than grid search for high-cost, high-parameter machine
learning problems. Echocardiography is a ubiquitous modality for evaluating
heart structure and function in cardiology. In this work, we use BO to optimize
the architectural and training-related hyperparameters of a previously
published deep fully convolutional neural network model for multi-structure
segmentation in echocardiography. In a fair comparison, the resulting model
outperforms this recent state-of-the-art on the annotated CAMUS dataset in both
apical two- and four-chamber echo views. We report mean Dice overlaps of 0.95,
0.96, and 0.93 on left ventricular (LV) endocardium, LV epicardium, and left
atrium respectively. We also observe significant improvement in derived
clinical indices, including smaller median absolute errors for LV end-diastolic
volume (4.9mL vs. 6.7), end-systolic volume (3.1mL vs. 5.2), and ejection
fraction (2.6% vs. 3.7); and much tighter limits of agreement, which were
already within inter-rater variability for non-contrast echo. These results
demonstrate the benefits of BO for echocardiography segmentation over a recent
state-of-the-art framework, although validation using large-scale independent
clinical data is required.</p>
  </details>
</details>
<h1>自然语言处理</h1>
<details>
  <summary>1. <b>标题：SmoothQuant: Accurate and Efficient Post-Training Quantization for Large  Language Models</b></summary>
  <p><b>编号</b>：[3]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10438</p>
  <p><b>作者</b>：Guangxuan Xiao,  Ji Lin,  Mickael Seznec,  Julien Demouth,  Song Han</p>
  <p><b>备注</b>：The first two authors contributed equally to this work</p>
  <p><b>关键词</b>：Large language models, show excellent performance, Large language, language models, show excellent</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large language models (LLMs) show excellent performance but are compute- and
memory-intensive. Quantization can reduce memory and accelerate inference.
However, for LLMs beyond 100 billion parameters, existing methods cannot
maintain accuracy or do not run efficiently on hardware. We propose
SmoothQuant, a training-free, accuracy-preserving, and general-purpose
post-training quantization (PTQ) solution to enable 8-bit weight, 8-bit
activation (W8A8) quantization for LLMs that can be implemented efficiently. We
observe that systematic outliers appear at fixed activation channels. Based on
the fact that weights are easy to quantize while activations are not,
SmoothQuant smooths the activation outliers by migrating the quantization
difficulty from activations to weights with a mathematically equivalent
transformation. SmoothQuant enables an INT8 quantization of both weights and
activations for all the GEMMs in LLMs, including OPT-175B, BLOOM-176B and
GLM-130B. SmoothQuant has better hardware efficiency than existing techniques
using mixed-precision activation quantization or weight-only quantization. We
demonstrate up to 1.56x speedup and 2x memory reduction for LLMs with
negligible loss in accuracy. Thanks to the hardware-friendly design, we
integrate SmoothQuant into FasterTransformer, a state-of-the-art LLM serving
framework, and achieve faster inference speed with half the number of GPUs
compared to FP16. Our work offers a turn-key solution that reduces hardware
costs and democratizes LLMs. Code will be released at:
this https URL.</p>
  </details>
</details>
<details>
  <summary>2. <b>标题：PAL: Program-aided Language Models</b></summary>
  <p><b>编号</b>：[5]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10435</p>
  <p><b>作者</b>：Luyu Gao,  Aman Madaan,  Shuyan Zhou,  Uri Alon,  Pengfei Liu,  Yiming Yang,  Jamie Callan,  Graham Neubig</p>
  <p><b>备注</b>：The first three authors contributed equally. Our code and data are publicly available at this http URL</p>
  <p><b>关键词</b>：reasoning, Large language models, test time, reasoning tasks, recently demonstrated</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large language models (LLMs) have recently demonstrated an impressive ability
to perform arithmetic and symbolic reasoning tasks when provided with a few
examples at test time (few-shot prompting). Much of this success can be
attributed to prompting methods for reasoning, such as chain-of-thought, that
employ LLMs for both understanding the problem description by decomposing it
into steps, as well as solving each step of the problem. While LLMs seem to be
adept at this sort of step-by-step decomposition, LLMs often make logical and
arithmetic mistakes in the solution part, even when the problem is correctly
decomposed. We present Program-Aided Language models (PaL): a new method that
uses the LLM to understand natural language problems and generate programs as
the intermediate reasoning steps, but offloads the solution step to a
programmatic runtime such as a Python interpreter. With PaL, decomposing the
natural language problem into runnable steps remains the only learning task for
the LLM, while solving is delegated to the interpreter. We experiment with 12
reasoning tasks from BIG-Bench Hard and other benchmarks, including
mathematical reasoning, symbolic reasoning, and algorithmic problems. In all
these natural language reasoning tasks, generating code using an LLM and
reasoning using a Python interpreter leads to more accurate results than much
larger models, and we set new state-of-the-art results in all 12 benchmarks.
For example, PaL using Codex achieves state-of-the-art few-shot accuracy on the
GSM benchmark of math word problems when the model is allowed only a single
decoding, surpassing PaLM-540B with chain-of-thought prompting by an absolute
8% .In three reasoning tasks from the BIG-Bench Hard benchmark, PaL outperforms
CoT by 11%. On GSM-hard, a more challenging version of GSM that we create, PaL
outperforms chain-of-thought by an absolute 40%.</p>
  </details>
</details>
<details>
  <summary>3. <b>标题：CITADEL: Conditional Token Interaction via Dynamic Lexical Routing for  Efficient and Effective Multi-Vector Retrieval</b></summary>
  <p><b>编号</b>：[10]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10411</p>
  <p><b>作者</b>：Minghan Li,  Sheng-Chieh Lin,  Barlas Oguz,  Asish Ghoshal,  Jimmy Lin,  Yashar Mehdad,  Wen-tau Yih,  Xilun Chen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：retrieval methods combine, merits of sparse, Multi-vector retrieval, combine the merits, Multi-vector retrieval methods</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Multi-vector retrieval methods combine the merits of sparse (e.g. BM25) and
dense (e.g. DPR) retrievers and have achieved state-of-the-art performance on
various retrieval tasks. These methods, however, are orders of magnitude slower
and need much more space to store their indices compared to their single-vector
counterparts. In this paper, we unify different multi-vector retrieval models
from a token routing viewpoint and propose conditional token interaction via
dynamic lexical routing, namely CITADEL, for efficient and effective
multi-vector retrieval. CITADEL learns to route different token vectors to the
predicted lexical ``keys'' such that a query token vector only interacts with
document token vectors routed to the same key. This design significantly
reduces the computation cost while maintaining high accuracy. Notably, CITADEL
achieves the same or slightly better performance than the previous state of the
art, ColBERT-v2, on both in-domain (MS MARCO) and out-of-domain (BEIR)
evaluations, while being nearly 40 times faster. Code and data are available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>4. <b>标题：GENIUS: Sketch-based Language Model Pre-training via Extreme and  Selective Masking for Text Generation and Augmentation</b></summary>
  <p><b>编号</b>：[30]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10330</p>
  <p><b>作者</b>：Biyang Guo,  Yeyun Gong,  Yelong Shen,  Songqiao Han,  Hailiang Huang,  Nan Duan,  Weizhu Chen</p>
  <p><b>备注</b>：21 pages</p>
  <p><b>关键词</b>：key information consisting, key information, concatenated by mask, mask tokens, missing contexts</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We introduce GENIUS: a conditional text generation model using sketches as
input, which can fill in the missing contexts for a given sketch (key
information consisting of textual spans, phrases, or words, concatenated by
mask tokens). GENIUS is pre-trained on a large-scale textual corpus with a
novel reconstruction from sketch objective using an extreme and selective
masking strategy, enabling it to generate diverse and high-quality texts given
sketches. Comparison with other competitive conditional language models (CLMs)
reveals the superiority of GENIUS's text generation quality. We further show
that GENIUS can be used as a strong and ready-to-use data augmentation tool for
various natural language processing (NLP) tasks. Most existing textual data
augmentation methods are either too conservative, by making small changes to
the original text, or too aggressive, by creating entirely new samples. With
GENIUS, we propose GeniusAug, which first extracts the target-aware sketches
from the original training set and then generates new samples based on the
sketches. Empirical experiments on 6 text classification datasets show that
GeniusAug significantly improves the models' performance in both
in-distribution (ID) and out-of-distribution (OOD) settings. We also
demonstrate the effectiveness of GeniusAug on named entity recognition (NER)
and machine reading comprehension (MRC) tasks. (Code and models are publicly
available at this https URL and
this https URL)</p>
  </details>
</details>
<details>
  <summary>5. <b>标题：A Copy Mechanism for Handling Knowledge Base Elements in SPARQL Neural  Machine Translation</b></summary>
  <p><b>编号</b>：[51]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10271</p>
  <p><b>作者</b>：Rose Hirigoyen,  Amal Zouaq,  Samuel Reyd</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Neural Machine Translation, Machine Translation, SPARQL query generation, neural SPARQL query, SPARQL query</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Neural Machine Translation (NMT) models from English to SPARQL are a
promising development for SPARQL query generation. However, current
architectures are unable to integrate the knowledge base (KB) schema and handle
questions on knowledge resources, classes, and properties unseen during
training, rendering them unusable outside the scope of topics covered in the
training set. Inspired by the performance gains in natural language processing
tasks, we propose to integrate a copy mechanism for neural SPARQL query
generation as a way to tackle this issue. We illustrate our proposal by adding
a copy layer and a dynamic knowledge base vocabulary to two Seq2Seq
architectures (CNNs and Transformers). This layer makes the models copy KB
elements directly from the questions, instead of generating them. We evaluate
our approach on state-of-the-art datasets, including datasets referencing
unknown KB elements and measure the accuracy of the copy-augmented
architectures. Our results show a considerable increase in performance on all
datasets compared to non-copy architectures.</p>
  </details>
</details>
<details>
  <summary>6. <b>标题：Context Variance Evaluation of Pretrained Language Models for  Prompt-based Biomedical Knowledge Probing</b></summary>
  <p><b>编号</b>：[53]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10265</p>
  <p><b>作者</b>：Zonghai Yao,  Yi Cao,  Zhichao Yang,  Hong Yu</p>
  <p><b>备注</b>：submitted to AMIA 2023 Informatics Summit</p>
  <p><b>关键词</b>：Pretrained language models, models learn, language models, Pretrained language, knowledge</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Pretrained language models (PLMs) have motivated research on what kinds of
knowledge these models learn. Fill-in-the-blanks problem (e.g., cloze tests) is
a natural approach for gauging such knowledge. BioLAMA generates prompts for
biomedical factual knowledge triples and uses the Top-k accuracy metric to
evaluate different PLMs' knowledge. However, existing research has shown that
such prompt-based knowledge probing methods can only probe a lower bound of
knowledge. Many factors like prompt-based probing biases make the LAMA
benchmark unreliable and unstable. This problem is more prominent in BioLAMA.
The severe long-tailed distribution in vocabulary and large-N-M relation make
the performance gap between LAMA and BioLAMA remain notable. To address these,
we introduce context variance into the prompt generation and propose a new
rank-change-based evaluation metric. Different from the previous known-unknown
evaluation criteria, we propose the concept of "Misunderstand" in LAMA for the
first time. Through experiments on 12 PLMs, our context variance prompts and
Understand-Confuse-Misunderstand (UCM) metric makes BioLAMA more friendly to
large-N-M relations and rare relations. We also conducted a set of control
experiments to disentangle "understand" from just "read and copy".</p>
  </details>
</details>
<details>
  <summary>7. <b>标题：GoSum: Extractive Summarization of Long Documents by Reinforcement  Learning and Graph Organized discourse state</b></summary>
  <p><b>编号</b>：[60]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10247</p>
  <p><b>作者</b>：Junyi Bian,  Xiaodi Huang,  Hong Zhou,  Shanfeng Zhu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Handling long texts, Handling long, long texts, texts with structural, structural information</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Handling long texts with structural information and excluding redundancy
between summary sentences are essential in extractive document summarization.
In this work, we propose GoSum, a novel reinforcement-learning-based extractive
model for long-paper summarization. GoSum encodes states by building a
heterogeneous graph from different discourse levels for each input document. We
evaluate the model on two datasets of scientific articles summarization: PubMed
and arXiv where it outperforms all extractive summarization models and most of
the strong abstractive baselines.</p>
  </details>
</details>
<details>
  <summary>8. <b>标题：Overview of the HASOC Subtrack at FIRE 2022: Offensive Language  Identification in Marathi</b></summary>
  <p><b>编号</b>：[81]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10163</p>
  <p><b>作者</b>：Tharindu Ranasinghe,  Kai North,  Damith Premasiri,  Marcos Zampieri</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：develop robust systems, robust systems capable, Offensive Content Identification, offensive content online, offensive content</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The widespread of offensive content online has become a reason for great
concern in recent years, motivating researchers to develop robust systems
capable of identifying such content automatically. With the goal of carrying
out a fair evaluation of these systems, several international competitions have
been organized, providing the community with important benchmark data and
evaluation methods for various languages. Organized since 2019, the HASOC (Hate
Speech and Offensive Content Identification) shared task is one of these
initiatives. In its fourth iteration, HASOC 2022 included three subtracks for
English, Hindi, and Marathi. In this paper, we report the results of the HASOC
2022 Marathi subtrack which provided participants with a dataset containing
data from Twitter manually annotated using the popular OLID taxonomy. The
Marathi track featured three additional subtracks, each corresponding to one
level of the taxonomy: Task A - offensive content identification (offensive vs.
non-offensive); Task B - categorization of offensive types (targeted vs.
untargeted), and Task C - offensive target identification (individual vs. group
vs. others). Overall, 59 runs were submitted by 10 teams. The best systems
obtained an F1 of 0.9745 for Subtrack 3A, an F1 of 0.9207 for Subtrack 3B, and
F1 of 0.9607 for Subtrack 3C. The best performing algorithms were a mixture of
traditional and deep learning approaches.</p>
  </details>
</details>
<details>
  <summary>9. <b>标题：FiE: Building a Global Probability Space by Leveraging Early Fusion in  Encoder for Open-Domain Question Answering</b></summary>
  <p><b>编号</b>：[88]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10147</p>
  <p><b>作者</b>：Akhil Kedia,  Mohd Abbas Zaidi,  Haejun Lee</p>
  <p><b>备注</b>：Accepted at EMNLP 2022 Main Conference</p>
  <p><b>关键词</b>：Domain Question Answering, recently started, Open Domain Question, Exact Match, Question Answering</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Generative models have recently started to outperform extractive models in
Open Domain Question Answering, largely by leveraging their decoder to attend
over multiple encoded passages and combining their information. However,
generative models tend to be larger than extractive models due to the need for
a decoder, run slower during inference due to auto-regressive decoder beam
search, and their generated output often suffers from hallucinations. We
propose to extend transformer encoders with the ability to fuse information
from multiple passages, using global representation to provide cross-sample
attention over all tokens across samples. Furthermore, we propose an
alternative answer span probability calculation to better aggregate answer
scores in the global space of all samples. Using our proposed method, we
outperform the current state-of-the-art method by $2.5$ Exact Match score on
the Natural Question dataset while using only $25\%$ of parameters and $35\%$
of the latency during inference, and $4.4$ Exact Match on WebQuestions dataset.
When coupled with synthetic data augmentation, we outperform larger models on
the TriviaQA dataset as well. The latency and parameter savings of our method
make it particularly attractive for open-domain question answering, as these
models are often compute-intensive.</p>
  </details>
</details>
<details>
  <summary>10. <b>标题：Scaling Native Language Identification with Transformer Adapters</b></summary>
  <p><b>编号</b>：[95]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10117</p>
  <p><b>作者</b>：Ahmet Yavuz Uluslu,  Gerold Schneider</p>
  <p><b>备注</b>：Paper accepted to International Conference on Natural Language and Speech Processing 2022 (ICNLSP 2022)</p>
  <p><b>关键词</b>：Native language identification, Native language, language identification, learned language, language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Native language identification (NLI) is the task of automatically identifying
the native language (L1) of an individual based on their language production in
a learned language. It is useful for a variety of purposes including marketing,
security and educational applications. NLI is usually framed as a multi-label
classification task, where numerous designed features are combined to achieve
state-of-the-art results. Recently deep generative approach based on
transformer decoders (GPT-2) outperformed its counterparts and achieved the
best results on the NLI benchmark datasets. We investigate this approach to
determine the practical implications compared to traditional state-of-the-art
NLI systems. We introduce transformer adapters to address memory limitations
and improve training/inference speed to scale NLI applications for production.</p>
  </details>
</details>
<details>
  <summary>11. <b>标题：Metadata Might Make Language Models Better</b></summary>
  <p><b>编号</b>：[104]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10086</p>
  <p><b>作者</b>：Kaspar Beelen,  Daniel van Strien</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：training language models, Masked Language Model, historical collections, paper discusses, discusses the benefits</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper discusses the benefits of including metadata when training
language models on historical collections. Using 19th-century newspapers as a
case study, we extend the time-masking approach proposed by Rosin et al., 2022
and compare different strategies for inserting temporal, political and
geographical information into a Masked Language Model. After fine-tuning
several DistilBERT on enhanced input data, we provide a systematic evaluation
of these models on a set of evaluation tasks: pseudo-perplexity, metadata
mask-filling and supervised classification. We find that showing relevant
metadata to a language model has a beneficial impact and may even produce more
robust and fairer models.</p>
  </details>
</details>
<details>
  <summary>12. <b>标题：Overview of the WANLP 2022 Shared Task on Propaganda Detection in Arabic</b></summary>
  <p><b>编号</b>：[116]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10057</p>
  <p><b>作者</b>：Firoj Alam,  Hamdy Mubarak,  Wajdi Zaghouani,  Giovanni Da San Martino,  Preslav Nakov</p>
  <p><b>备注</b>：Accepted at WANLP-22 (EMNLP-22), propaganda, disinformation, misinformation, fake news, memes, multimodality. arXiv admin note: text overlap with arXiv:2109.08013, arXiv:2105.09284</p>
  <p><b>关键词</b>：group deliberately designed, Propaganda techniques, group deliberately, predetermined ends, psychological devices</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Propaganda is the expression of an opinion or an action by an individual or a
group deliberately designed to influence the opinions or the actions of other
individuals or groups with reference to predetermined ends, which is achieved
by means of well-defined rhetorical and psychological devices. Propaganda
techniques are commonly used in social media to manipulate or to mislead users.
Thus, there has been a lot of recent research on automatic detection of
propaganda techniques in text as well as in memes. However, so far the focus
has been primarily on English. With the aim to bridge this language gap, we ran
a shared task on detecting propaganda techniques in Arabic tweets as part of
the WANLP 2022 workshop, which included two subtasks. Subtask~1 asks to
identify the set of propaganda techniques used in a tweet, which is a
multilabel classification problem, while Subtask~2 asks to detect the
propaganda techniques used in a tweet together with the exact span(s) of text
in which each propaganda technique appears. The task attracted 63 team
registrations, and eventually 14 and 3 teams made submissions for subtask 1 and
2, respectively. Finally, 11 teams submitted system description papers.</p>
  </details>
</details>
<details>
  <summary>13. <b>标题：A Dataset for Hyper-Relational Extraction and a Cube-Filling Approach</b></summary>
  <p><b>编号</b>：[133]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10018</p>
  <p><b>作者</b>：Yew Ken Chia,  Lidong Bing,  Sharifah Mahani Aljunied,  Luo Si,  Soujanya Poria</p>
  <p><b>备注</b>：19 pages, 6 figures, accepted by EMNLP 2022</p>
  <p><b>关键词</b>：knowledge graph construction, quantity or location, knowledge graph structure, knowledge graph, complex knowledge graph</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Relation extraction has the potential for large-scale knowledge graph
construction, but current methods do not consider the qualifier attributes for
each relation triplet, such as time, quantity or location. The qualifiers form
hyper-relational facts which better capture the rich and complex knowledge
graph structure. For example, the relation triplet (Leonard Parker, Educated
At, Harvard University) can be factually enriched by including the qualifier
(End Time, 1967). Hence, we propose the task of hyper-relational extraction to
extract more specific and complete facts from text. To support the task, we
construct HyperRED, a large-scale and general-purpose dataset. Existing models
cannot perform hyper-relational extraction as it requires a model to consider
the interaction between three entities. Hence, we propose CubeRE, a
cube-filling model inspired by table-filling approaches and explicitly
considers the interaction between relation triplets and qualifiers. To improve
model scalability and reduce negative class imbalance, we further propose a
cube-pruning method. Our experiments show that CubeRE outperforms strong
baselines and reveal possible directions for future research. Our code and data
are available at this http URL.</p>
  </details>
</details>
<details>
  <summary>14. <b>标题：Who Says Elephants Can't Run: Bringing Large Scale MoE Models into Cloud  Scale Production</b></summary>
  <p><b>编号</b>：[134]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10017</p>
  <p><b>作者</b>：Young Jin Kim,  Rawn Henry,  Raffy Fahim,  Hany Hassan Awadalla</p>
  <p><b>备注</b>：Accepted to SustaiNLP 2022 (EMNLP 2022)</p>
  <p><b>关键词</b>：sparsely activated layers, enabled training models, number of parameters, conditional execution, execution of sparsely</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Mixture of Experts (MoE) models with conditional execution of sparsely
activated layers have enabled training models with a much larger number of
parameters. As a result, these models have achieved significantly better
quality on various natural language processing tasks including machine
translation. However, it remains challenging to deploy such models in real-life
scenarios due to the large memory requirements and inefficient inference. In
this work, we introduce a highly efficient inference framework with several
optimization approaches to accelerate the computation of sparse models and cut
down the memory consumption significantly. While we achieve up to 26x speed-up
in terms of throughput, we also reduce the model size almost to one eighth of
the original 32-bit float model by quantizing expert weights into 4-bit
integers. As a result, we are able to deploy 136x larger models with 27% less
cost and significantly better quality compared to the existing solutions. This
enables a paradigm shift in deploying large scale multilingual MoE transformers
models replacing the traditional practice of distilling teacher models into
dozens of smaller models per language or task.</p>
  </details>
</details>
<details>
  <summary>15. <b>标题：Towards Explaining Subjective Ground of Individuals on Social Media</b></summary>
  <p><b>编号</b>：[162]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.09953</p>
  <p><b>作者</b>：Younghun Lee,  Dan Goldwasser</p>
  <p><b>备注</b>：Findings of EMNLP 2022</p>
  <p><b>关键词</b>：Large-scale language models, Large-scale language, real world, reducing the gap, gap between machines</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large-scale language models have been reducing the gap between machines and
humans in understanding the real world, yet understanding an individual's
theory of mind and behavior from text is far from being resolved.
This research proposes a neural model -- Subjective Ground Attention -- that
learns subjective grounds of individuals and accounts for their judgments on
situations of others posted on social media. Using simple attention modules as
well as taking one's previous activities into consideration, we empirically
show that our model provides human-readable explanations of an individual's
subjective preference in judging social situations. We further qualitatively
evaluate the explanations generated by the model and claim that our model
learns an individual's subjective orientation towards abstract moral concepts</p>
  </details>
</details>
<details>
  <summary>16. <b>标题：Compressing Transformer-based self-supervised models for speech  processing</b></summary>
  <p><b>编号</b>：[164]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.09949</p>
  <p><b>作者</b>：Tzu-Quan Lin,  Tsung-Huan Yang,  Chun-Yao Chang,  Kuang-Ming Chen,  Tzu-hsun Feng,  Hung-yi Lee,  Hao Tang</p>
  <p><b>备注</b>：Submitted to ICASSP 2023</p>
  <p><b>关键词</b>：spectrum of devices, learning with applications, computational cost, cost of training, training and inference</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Despite the success of Transformers in self-supervised learning with
applications to various downstream tasks, the computational cost of training
and inference remains a major challenge for applying these models to a wide
spectrum of devices. Several isolated attempts have been made to compress
Transformers, prior to applying them to downstream tasks. In this work, we aim
to provide context for the isolated results, studying several commonly used
compression techniques, including weight pruning, head pruning, low-rank
approximation, and knowledge distillation. We report wall-clock time, the
number of parameters, and the number of multiply-accumulate operations for
these techniques, charting the landscape of compressing Transformer-based
self-supervised models.</p>
  </details>
</details>
<details>
  <summary>17. <b>标题：MelHuBERT: A simplified HuBERT on Mel spectrogram</b></summary>
  <p><b>编号</b>：[166]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.09944</p>
  <p><b>作者</b>：Tzu-Quan Lin,  Hung-yi Lee,  Hao Tang</p>
  <p><b>备注</b>：Submitted to ICASSP 2023</p>
  <p><b>关键词</b>：learning speech representations, downstream tasks, great success, success in learning, learning speech</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Self-supervised models have had great success in learning speech
representations that can generalize to various downstream tasks. HuBERT, in
particular, achieves strong performance while being relatively simple in
training compared to others. The original experimental setting is
computationally extensive, hindering the reproducibility of the models. It is
also unclear why certain design decisions are made, such as the ad-hoc loss
function, and whether these decisions have an impact on the learned
representations. We propose MelHuBERT, a simplified version of HuBERT that
takes Mel spectrograms as input, significantly reducing computation and memory
consumption. We study several aspects of training, including the loss function,
multi-stage training, and streaming options. Our result is a efficient yet
performant model that can be trained on a single GPU.</p>
  </details>
</details>
<details>
  <summary>18. <b>标题：Professional Presentation and Projected Power: A Case Study of Implicit  Gender Information in English CVs</b></summary>
  <p><b>编号</b>：[167]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.09942</p>
  <p><b>作者</b>：Jinrui Yang,  Sheilla Njoto,  Marc Cheong,  Leah Ruppanner,  Lea Frermann</p>
  <p><b>备注</b>：Accepted at the NLP+CSS 2022 workshop (co-located with EMNLP)</p>
  <p><b>关键词</b>：bias in NLP, bias in society, persistent bias, exploring bias, discrimination in hiring</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Gender discrimination in hiring is a pertinent and persistent bias in
society, and a common motivating example for exploring bias in NLP. However,
the manifestation of gendered language in application materials has received
limited attention. This paper investigates the framing of skills and background
in CVs of self-identified men and women. We introduce a data set of 1.8K
authentic, English-language, CVs from the US, covering 16 occupations, allowing
us to partially control for the confound occupation-specific gender base rates.
We find that (1) women use more verbs evoking impressions of low power; and (2)
classifiers capture gender signal even after data balancing and removal of
pronouns and named entities, and this holds for both transformer-based and
linear classifiers.</p>
  </details>
</details>
<details>
  <summary>19. <b>标题：Explainability Via Causal Self-Talk</b></summary>
  <p><b>编号</b>：[170]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.09937</p>
  <p><b>作者</b>：Nicholas A. Roy,  Junkyung Kim,  Neil Rabinowitz</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：generally avoided, important problem, deep learning community, wider deep learning, deep learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Explaining the behavior of AI systems is an important problem that, in
practice, is generally avoided. While the XAI community has been developing an
abundance of techniques, most incur a set of costs that the wider deep learning
community has been unwilling to pay in most situations. We take a pragmatic
view of the issue, and define a set of desiderata that capture both the
ambitions of XAI and the practical constraints of deep learning. We describe an
effective way to satisfy all the desiderata: train the AI system to build a
causal model of itself. We develop an instance of this solution for Deep RL
agents: Causal Self-Talk. CST operates by training the agent to communicate
with itself across time. We implement this method in a simulated 3D
environment, and show how it enables agents to generate faithful and
semantically-meaningful explanations of their own behavior. Beyond
explanations, we also demonstrate that these learned models provide new ways of
building semantic control interfaces to AI systems.</p>
  </details>
</details>
<details>
  <summary>20. <b>标题：Planning with Large Language Models via Corrective Re-prompting</b></summary>
  <p><b>编号</b>：[171]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.09935</p>
  <p><b>作者</b>：Shreyas Sundara Raman,  Vanya Cohen,  Eric Rosen,  Ifrah Idrees,  David Paulius,  Stefanie Tellex</p>
  <p><b>备注</b>：21 pages, 7 figures, Accepted to Foundation Models for Decision Making Workshop at Neural Information Processing Systems 2022</p>
  <p><b>关键词</b>：Large Language Models, Language Models, Large Language, common sense knowledge, sense knowledge present</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Extracting the common sense knowledge present in Large Language Models (LLMs)
offers a path to designing intelligent, embodied agents. Related works have
queried LLMs with a wide-range of contextual information, such as goals, sensor
observations and scene descriptions, to generate high-level action plans for
specific tasks; however these approaches often involve human intervention or
additional machinery to enable sensor-motor interactions. In this work, we
propose a prompting-based strategy for extracting executable plans from an LLM,
which leverages a novel and readily-accessible source of information:
precondition errors. Our approach assumes that actions are only afforded
execution in certain contexts, i.e., implicit preconditions must be met for an
action to execute (e.g., a door must be unlocked to open it), and that the
embodied agent has the ability to determine if the action is/is not executable
in the current context (e.g., detect if a precondition error is present). When
an agent is unable to execute an action, our approach re-prompts the LLM with
precondition error information to extract an executable corrective action to
achieve the intended goal in the current context. We evaluate our approach in
the VirtualHome simulation environment on 88 different tasks and 7 scenes. We
evaluate different prompt templates and compare to methods that naively
re-sample actions from the LLM. Our approach, using precondition errors,
improves executability and semantic correctness of plans, while also reducing
the number of re-prompts required when querying actions.</p>
  </details>
</details>
<details>
  <summary>21. <b>标题：Summarizing Community-based Question-Answer Pairs</b></summary>
  <p><b>编号</b>：[186]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.09892</p>
  <p><b>作者</b>：Ting-Yao Hsu,  Yoshi Suhara,  Xiaolan Wang</p>
  <p><b>备注</b>：To appear in EMNLP 2022 main conference</p>
  <p><b>关键词</b>：Community-based Question Answering, Question Answering, Community-based Question, CQA summarization task, CQA pairs</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Community-based Question Answering (CQA), which allows users to acquire their
desired information, has increasingly become an essential component of online
services in various domains such as E-commerce, travel, and dining. However, an
overwhelming number of CQA pairs makes it difficult for users without
particular intent to find useful information spread over CQA pairs. To help
users quickly digest the key information, we propose the novel CQA
summarization task that aims to create a concise summary from CQA pairs. To
this end, we first design a multi-stage data annotation process and create a
benchmark dataset, CoQASUM, based on the Amazon QA corpus. We then compare a
collection of extractive and abstractive summarization methods and establish a
strong baseline approach DedupLED for the CQA summarization task. Our
experiment further confirms two key challenges, sentence-type transfer and
deduplication removal, towards the CQA summarization task. Our data and code
are publicly available.</p>
  </details>
</details>
<details>
  <summary>22. <b>标题：Reducing Hallucinations in Neural Machine Translation with Feature  Attribution</b></summary>
  <p><b>编号</b>：[187]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.09878</p>
  <p><b>作者</b>：Joël Tang,  Marina Fomicheva,  Lucia Specia</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：conditional language generation, Neural Machine Translation, Neural conditional language, generation models achieve, Neural conditional</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Neural conditional language generation models achieve the state-of-the-art in
Neural Machine Translation (NMT) but are highly dependent on the quality of
parallel training dataset. When trained on low-quality datasets, these models
are prone to various error types, including hallucinations, i.e. outputs that
are fluent, but unrelated to the source sentences. These errors are
particularly dangerous, because on the surface the translation can be perceived
as a correct output, especially if the reader does not understand the source
language. We present a case study focusing on model understanding and
regularisation to reduce hallucinations in NMT. We first use feature
attribution methods to study the behaviour of an NMT model that produces
hallucinations. We then leverage these methods to propose a novel loss function
that substantially helps reduce hallucinations and does not require retraining
the model from scratch.</p>
  </details>
</details>
<details>
  <summary>23. <b>标题：ProtSi: Prototypical Siamese Network with Data Augmentation for Few-Shot  Subjective Answer Evaluation</b></summary>
  <p><b>编号</b>：[195]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.09855</p>
  <p><b>作者</b>：Yining Lu,  Jingxi Qiu,  Gaurav Gupta</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：subjective personal characteristics, tedious task, personal characteristics, Subjective answer evaluation, time-consuming and tedious</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Subjective answer evaluation is a time-consuming and tedious task, and the
quality of the evaluation is heavily influenced by a variety of subjective
personal characteristics. Instead, machine evaluation can effectively assist
educators in saving time while also ensuring that evaluations are fair and
realistic. However, most existing methods using regular machine learning and
natural language processing techniques are generally hampered by a lack of
annotated answers and poor model interpretability, making them unsuitable for
real-world use. To solve these challenges, we propose ProtSi Network, a unique
semi-supervised architecture that for the first time uses few-shot learning to
subjective answer evaluation. To evaluate students' answers by similarity
prototypes, ProtSi Network simulates the natural process of evaluator scoring
answers by combining Siamese Network which consists of BERT and encoder layers
with Prototypical Network. We employed an unsupervised diverse paraphrasing
model ProtAugment, in order to prevent overfitting for effective few-shot text
classification. By integrating contrastive learning, the discriminative text
issue can be mitigated. Experiments on the Kaggle Short Scoring Dataset
demonstrate that the ProtSi Network outperforms the most recent baseline models
in terms of accuracy and quadratic weighted kappa.</p>
  </details>
</details>
<details>
  <summary>24. <b>标题：CoLI-Machine Learning Approaches for Code-mixed Language Identification  at the Word Level in Kannada-English Texts</b></summary>
  <p><b>编号</b>：[197]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.09847</p>
  <p><b>作者</b>：H.L. Shashirekha,  F. Balouchzahi,  M.D. Anusha,  G. Sidorov</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：called Language Identification, Language Identification, learning, Identification, task of automatically</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The task of automatically identifying a language used in a given text is
called Language Identification (LI). India is a multilingual country and many
Indians especially youths are comfortable with Hindi and English, in addition
to their local languages. Hence, they often use more than one language to post
their comments on social media. Texts containing more than one language are
called "code-mixed texts" and are a good source of input for LI. Languages in
these texts may be mixed at sentence level, word level or even at sub-word
level. LI at word level is a sequence labeling problem where each and every
word in a sentence is tagged with one of the languages in the predefined set of
languages. In order to address word level LI in code-mixed Kannada-English
(Kn-En) texts, this work presents i) the construction of code-mixed Kn-En
dataset called CoLI-Kenglish dataset, ii) code-mixed Kn-En embedding and iii)
learning models using Machine Learning (ML), Deep Learning (DL) and Transfer
Learning (TL) approaches. Code-mixed Kn-En texts are extracted from Kannada
YouTube video comments to construct CoLI-Kenglish dataset and code-mixed Kn-En
embedding. The words in CoLI-Kenglish dataset are grouped into six major
categories, namely, "Kannada", "English", "Mixed-language", "Name", "Location"
and "Other". The learning models, namely, CoLI-vectors and CoLI-ngrams based on
ML, CoLI-BiLSTM based on DL and CoLI-ULMFiT based on TL approaches are built
and evaluated using CoLI-Kenglish dataset. The performances of the learning
models illustrated, the superiority of CoLI-ngrams model, compared to other
models with a macro average F1-score of 0.64. However, the results of all the
learning models were quite competitive with each other.</p>
  </details>
</details>
<h1>机器学习</h1>
<details>
  <summary>1. <b>标题：Magic3D: High-Resolution Text-to-3D Content Creation</b></summary>
  <p><b>编号</b>：[1]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10440</p>
  <p><b>作者</b>：Chen-Hsuan Lin,  Jun Gao,  Luming Tang,  Towaki Takikawa,  Xiaohui Zeng,  Xun Huang,  Karsten Kreis,  Sanja Fidler,  Ming-Yu Liu,  Tsung-Yi Lin</p>
  <p><b>备注</b>：Project website: this https URL</p>
  <p><b>关键词</b>：Neural Radiance Fields, optimize Neural Radiance, Radiance Fields, Neural Radiance, optimize Neural</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>DreamFusion has recently demonstrated the utility of a pre-trained
text-to-image diffusion model to optimize Neural Radiance Fields (NeRF),
achieving remarkable text-to-3D synthesis results. However, the method has two
inherent limitations: (a) extremely slow optimization of NeRF and (b)
low-resolution image space supervision on NeRF, leading to low-quality 3D
models with a long processing time. In this paper, we address these limitations
by utilizing a two-stage optimization framework. First, we obtain a coarse
model using a low-resolution diffusion prior and accelerate with a sparse 3D
hash grid structure. Using the coarse representation as the initialization, we
further optimize a textured 3D mesh model with an efficient differentiable
renderer interacting with a high-resolution latent diffusion model. Our method,
dubbed Magic3D, can create high quality 3D mesh models in 40 minutes, which is
2x faster than DreamFusion (reportedly taking 1.5 hours on average), while also
achieving higher resolution. User studies show 61.7% raters to prefer our
approach over DreamFusion. Together with the image-conditioned generation
capabilities, we provide users with new ways to control 3D synthesis, opening
up new avenues to various creative applications.</p>
  </details>
</details>
<details>
  <summary>2. <b>标题：SmoothQuant: Accurate and Efficient Post-Training Quantization for Large  Language Models</b></summary>
  <p><b>编号</b>：[3]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10438</p>
  <p><b>作者</b>：Guangxuan Xiao,  Ji Lin,  Mickael Seznec,  Julien Demouth,  Song Han</p>
  <p><b>备注</b>：The first two authors contributed equally to this work</p>
  <p><b>关键词</b>：Large language models, show excellent performance, Large language, language models, show excellent</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large language models (LLMs) show excellent performance but are compute- and
memory-intensive. Quantization can reduce memory and accelerate inference.
However, for LLMs beyond 100 billion parameters, existing methods cannot
maintain accuracy or do not run efficiently on hardware. We propose
SmoothQuant, a training-free, accuracy-preserving, and general-purpose
post-training quantization (PTQ) solution to enable 8-bit weight, 8-bit
activation (W8A8) quantization for LLMs that can be implemented efficiently. We
observe that systematic outliers appear at fixed activation channels. Based on
the fact that weights are easy to quantize while activations are not,
SmoothQuant smooths the activation outliers by migrating the quantization
difficulty from activations to weights with a mathematically equivalent
transformation. SmoothQuant enables an INT8 quantization of both weights and
activations for all the GEMMs in LLMs, including OPT-175B, BLOOM-176B and
GLM-130B. SmoothQuant has better hardware efficiency than existing techniques
using mixed-precision activation quantization or weight-only quantization. We
demonstrate up to 1.56x speedup and 2x memory reduction for LLMs with
negligible loss in accuracy. Thanks to the hardware-friendly design, we
integrate SmoothQuant into FasterTransformer, a state-of-the-art LLM serving
framework, and achieve faster inference speed with half the number of GPUs
compared to FP16. Our work offers a turn-key solution that reduces hardware
costs and democratizes LLMs. Code will be released at:
this https URL.</p>
  </details>
</details>
<details>
  <summary>3. <b>标题：Mirror Sinkhorn: Fast Online Optimization on Transport Polytopes</b></summary>
  <p><b>编号</b>：[7]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10420</p>
  <p><b>作者</b>：Marin Ballu,  Quentin Berthet</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：capture geometric properties, machine learning, allowing to capture, important tool, tool in machine</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Optimal transport has arisen as an important tool in machine learning,
allowing to capture geometric properties of the data. It is formulated as a
linear program on transport polytopes. The problem of convex optimization on
this set includes both OT and multiple related ones, such as point cloud
registration.
We present in this work an optimization algorithm that utilizes Sinkhorn
matrix scaling and mirror descent to minimize convex objectives on this domain.
This algorithm can be run online and is both adaptive and robust to noise. A
mathematical analysis of the convergence rate of the algorithm for minimising
convex functions is provided, as well as experiments that illustrate its
performance on synthetic data and real-world data.</p>
  </details>
</details>
<details>
  <summary>4. <b>标题：Indexing AI Risks with Incidents, Issues, and Variants</b></summary>
  <p><b>编号</b>：[17]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10384</p>
  <p><b>作者</b>：Sean McGregor,  Kevin Paeth,  Khoa Lam</p>
  <p><b>备注</b>：To be published in Human-Centered AI Workshop at NeurIPS 2022</p>
  <p><b>关键词</b>：incident ingestion criteria, review queue, years after publicly, publicly launching, database current criteria</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Two years after publicly launching the AI Incident Database (AIID) as a
collection of harms or near harms produced by AI in the world, a backlog of
"issues" that do not meet its incident ingestion criteria have accumulated in
its review queue. Despite not passing the database's current criteria for
incidents, these issues advance human understanding of where AI presents the
potential for harm. Similar to databases in aviation and computer security, the
AIID proposes to adopt a two-tiered system for indexing AI incidents (i.e., a
harm or near harm event) and issues (i.e., a risk of a harm event). Further, as
some machine learning-based systems will sometimes produce a large number of
incidents, the notion of an incident "variant" is introduced. These proposed
changes mark the transition of the AIID to a new version in response to lessons
learned from editing 2,000+ incident reports and additional reports that fall
under the new category of "issue."</p>
  </details>
</details>
<details>
  <summary>5. <b>标题：Comparing Explanation Methods for Traditional Machine Learning Models  Part 2: Quantifying Model Explainability Faithfulness and Improvements with  Dimensionality Reduction</b></summary>
  <p><b>编号</b>：[19]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10378</p>
  <p><b>作者</b>：Montgomery Flora,  Corey Potvin,  Amy McGovern,  Shawn Handler</p>
  <p><b>备注</b>：18 pages; 12 figures ; part I (arXiv:2211.08943)</p>
  <p><b>关键词</b>：atmospheric science community, methods, Machine learning, feature, range of applications</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Machine learning (ML) models are becoming increasingly common in the
atmospheric science community with a wide range of applications. To enable
users to understand what an ML model has learned, ML explainability has become
a field of active research. In Part I of this two-part study, we described
several explainability methods and demonstrated that feature rankings from
different methods can substantially disagree with each other. It is unclear,
though, whether the disagreement is overinflated due to some methods being less
faithful in assigning importance. Herein, "faithfulness" or "fidelity" refer to
the correspondence between the assigned feature importance and the contribution
of the feature to model performance. In the present study, we evaluate the
faithfulness of feature ranking methods using multiple methods. Given the
sensitivity of explanation methods to feature correlations, we also quantify
how much explainability faithfulness improves after correlated features are
limited. Before dimensionality reduction, the feature relevance methods [e.g.,
SHAP, LIME, ALE variance, and logistic regression (LR) coefficients] were
generally more faithful than the permutation importance methods due to the
negative impact of correlated features. Once correlated features were reduced,
traditional permutation importance became the most faithful method. In
addition, the ranking uncertainty (i.e., the spread in rank assigned to a
feature by the different ranking methods) was reduced by a factor of 2-10, and
excluding less faithful feature ranking methods reduces it further. This study
is one of the first to quantify the improvement in explainability from limiting
correlated features and knowing the relative fidelity of different
explainability methods.</p>
  </details>
</details>
<details>
  <summary>6. <b>标题：Invariant Learning via Diffusion Dreamed Distribution Shifts</b></summary>
  <p><b>编号</b>：[20]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10370</p>
  <p><b>作者</b>：Priyatham Kattakinda,  Alexander Levine,  Soheil Feizi</p>
  <p><b>备注</b>：18 pages, 13 figures, 5 tables</p>
  <p><b>关键词</b>：background, Diffusion Dreamed Distribution, foreground, important signal, incorrect predictions</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Though the background is an important signal for image classification, over
reliance on it can lead to incorrect predictions when spurious correlations
between foreground and background are broken at test time. Training on a
dataset where these correlations are unbiased would lead to more robust models.
In this paper, we propose such a dataset called Diffusion Dreamed Distribution
Shifts (D3S). D3S consists of synthetic images generated through
StableDiffusion using text prompts and image guides obtained by pasting a
sample foreground image onto a background template image. Using this scalable
approach we generate 120K images of objects from all 1000 ImageNet classes in
10 diverse backgrounds. Due to the incredible photorealism of the diffusion
model, our images are much closer to natural images than previous synthetic
datasets. D3S contains a validation set of more than 17K images whose labels
are human-verified in an MTurk study. Using the validation set, we evaluate
several popular DNN image classifiers and find that the classification
performance of models generally suffers on our background diverse images. Next,
we leverage the foreground & background labels in D3S to learn a foreground
(background) representation that is invariant to changes in background
(foreground) by penalizing the mutual information between the foreground
(background) features and the background (foreground) labels. Linear
classifiers trained on these features to predict foreground (background) from
foreground (background) have high accuracies at 82.9% (93.8%), while
classifiers that predict these labels from background and foreground have a
much lower accuracy of 2.4% and 45.6% respectively. This suggests that our
foreground and background features are well disentangled. We further test the
efficacy of these representations by training classifiers on a task with strong
spurious correlations.</p>
  </details>
</details>
<details>
  <summary>7. <b>标题：Data efficient surrogate modeling for engineering design: Ensemble-free  batch mode deep active learning for regression</b></summary>
  <p><b>编号</b>：[23]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10360</p>
  <p><b>作者</b>：Harsh Vardhan,  Umesh Timalsina,  Peter Volgyesi,  Janos Sztipanovits</p>
  <p><b>备注</b>：23 pages, 12 figures</p>
  <p><b>关键词</b>：involves notoriously complex, time-consuming simulator, cheaper cost, involves notoriously, data-driven surrogate</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In a computer-aided engineering design optimization problem that involves
notoriously complex and time-consuming simulator, the prevalent approach is to
replace these simulations with a data-driven surrogate that approximates the
simulator's behavior at a much cheaper cost. The main challenge in creating an
inexpensive data-driven surrogate is the generation of a sheer number of data
using these computationally expensive numerical simulations. In such cases,
Active Learning (AL) methods have been used that attempt to learn an
input--output behavior while labeling the fewest samples possible. The current
trend in AL for a regression problem is dominated by the Bayesian framework
that needs training an ensemble of learning models that makes surrogate
training computationally tedious if the underlying learning model is Deep
Neural Networks (DNNs). However, DNNs have an excellent capability to learn
highly nonlinear and complex relationships even for a very high dimensional
problem. To leverage the excellent learning capability of deep networks along
with avoiding the computational complexity of the Bayesian paradigm, in this
work we propose a simple and scalable approach for active learning that works
in a student-teacher manner to train a surrogate model. By using this proposed
approach, we are able to achieve the same level of surrogate accuracy as the
other baselines like DBAL and Monte Carlo sampling with up to 40 % fewer
samples. We empirically evaluated this method on multiple use cases including
three different engineering design domains:finite element analysis,
computational fluid dynamics, and propeller design.</p>
  </details>
</details>
<details>
  <summary>8. <b>标题：Physics-informed neural networks for operator equations with stochastic  data</b></summary>
  <p><b>编号</b>：[25]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10344</p>
  <p><b>作者</b>：Paul Escapil-Inchauspé,  Gonzalo A. Ruz</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：stochastic data, computation of statistical, statistical moments, tensor operator equations, operator equations</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We consider the computation of statistical moments to operator equations with
stochastic data. We remark that application of PINNs -- referred to as TPINNs
-- allows to solve the induced tensor operator equations under minimal changes
of existing PINNs code. This scheme can overcome the curse of dimensionality
and covers non-linear and time-dependent operators. We propose two types of
architectures, referred to as vanilla and multi-output TPINNs, and investigate
their benefits and limitations. Exhaustive numerical experiments are performed;
demonstrating applicability and performance; raising a variety of new promising
research avenues.</p>
  </details>
</details>
<details>
  <summary>9. <b>标题：Few-shot Learning for Multi-modal Social Media Event Filtering</b></summary>
  <p><b>编号</b>：[26]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10340</p>
  <p><b>作者</b>：José Nascimento,  João Phillipe Cardenuto,  Jing Yang,  Anderson Rocha</p>
  <p><b>备注</b>：Accepted in IEEE International Workshop on Information Forensics and Security - WIFS 2022, Shanghai, China</p>
  <p><b>关键词</b>：important data source, event analysis, event, event filtering, important data</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Social media has become an important data source for event analysis. When
collecting this type of data, most contain no useful information to a target
event. Thus, it is essential to filter out those noisy data at the earliest
opportunity for a human expert to perform further inspection. Most existing
solutions for event filtering rely on fully supervised methods for training.
However, in many real-world scenarios, having access to large number of labeled
samples is not possible. To deal with a few labeled sample training problem for
event filtering, we propose a graph-based few-shot learning pipeline. We also
release the Brazilian Protest Dataset to test our method. To the best of our
knowledge, this dataset is the first of its kind in event filtering that
focuses on protests in multi-modal social media data, with most of the text in
Portuguese. Our experimental results show that our proposed pipeline has
comparable performance with only a few labeled samples (60) compared with a
fully labeled dataset (3100). To facilitate the research community, we make our
dataset and code available at this https URL.</p>
  </details>
</details>
<details>
  <summary>10. <b>标题：Deep learning based landslide density estimation on SAR data for rapid  response</b></summary>
  <p><b>编号</b>：[27]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10338</p>
  <p><b>作者</b>：Vanessa Boehm,  Wei Ji Leong,  Ragini Bal Mahesh,  Ioannis Prapas,  Edoardo Nemni,  Freddie Kalaitzis,  Siddha Ganju,  Raul Ramos-Pollan</p>
  <p><b>备注</b>：7 pages, 5 figures</p>
  <p><b>关键词</b>：estimates using Synthetic, States Geological Survey, United States Geological, work aims, Synthetic</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This work aims to produce landslide density estimates using Synthetic
Aperture Radar (SAR) satellite imageries to prioritise emergency resources for
rapid response. We use the United States Geological Survey (USGS) Landslide
Inventory data annotated by experts after Hurricane María in Puerto Rico on
Sept 20, 2017, and their subsequent susceptibility study which uses extensive
additional information such as precipitation, soil moisture, geological terrain
features, closeness to waterways and roads, etc. Since such data might not be
available during other events or regions, we aimed to produce a landslide
density map using only elevation and SAR data to be useful to decision-makers
in rapid response scenarios.
The USGS Landslide Inventory contains the coordinates of 71,431 landslide
heads (not their full extent) and was obtained by manual inspection of aerial
and satellite imagery. It is estimated that around 45\% of the landslides are
smaller than a Sentinel-1 typical pixel which is 10m $\times$ 10m, although
many are long and thin, probably leaving traces across several pixels. Our
method obtains 0.814 AUC in predicting the correct density estimation class at
the chip level (128$\times$128 pixels, at Sentinel-1 resolution) using only
elevation data and up to three SAR acquisitions pre- and post-hurricane, thus
enabling rapid assessment after a disaster. The USGS Susceptibility Study
reports a 0.87 AUC, but it is measured at the landslide level and uses
additional information sources (such as proximity to fluvial channels, roads,
precipitation, etc.) which might not regularly be available in an rapid
response emergency scenario.</p>
  </details>
</details>
<details>
  <summary>11. <b>标题：Tire-road friction estimation and uncertainty assessment to improve  electric aircraft braking system</b></summary>
  <p><b>编号</b>：[28]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10336</p>
  <p><b>作者</b>：Francesco Crocetti,  G. Costante,  M.L. Fravolini,  P. Valigi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：brake control system, advanced brake control, MLP Neural Net, accurate online estimation, control system</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The accurate online estimation of the road-friction coefficient is an
essential feature for any advanced brake control system. In this study, a
data-driven scheme based on a MLP Neural Net is proposed to estimate the
optimum friction coefficient as a function of windowed slip-friction
measurements. A stochastic NN weights drop-out mechanism is used to online
estimate the confidence interval of the estimated best friction coefficient
thus providing a characterization of the epistemic uncertainty associated to
the NN block. Open loop and closed loop simulations of the landing phase of an
aircraft on an unknown surface are used to show the potentiality and efficacy
of the proposed robust friction estimation approach.</p>
  </details>
</details>
<details>
  <summary>12. <b>标题：Understanding the double descent curve in Machine Learning</b></summary>
  <p><b>编号</b>：[32]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10322</p>
  <p><b>作者</b>：Luis Sa-Couto,  Jose Miguel Ramos,  Miguel Almeida,  Andreas Wichert</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Machine Learning algorithms, applying Machine Learning, Machine Learning, Learning algorithms, applying Machine</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The theory of bias-variance used to serve as a guide for model selection when
applying Machine Learning algorithms. However, modern practice has shown
success with over-parameterized models that were expected to overfit but did
not. This led to the proposal of the double descent curve of performance by
Belkin et al. Although it seems to describe a real, representative phenomenon,
the field is lacking a fundamental theoretical understanding of what is
happening, what are the consequences for model selection and when is double
descent expected to occur. In this paper we develop a principled understanding
of the phenomenon, and sketch answers to these important questions.
Furthermore, we report real experimental results that are correctly predicted
by our proposed hypothesis.</p>
  </details>
</details>
<details>
  <summary>13. <b>标题：Dueling Bandits: From Two-dueling to Multi-dueling</b></summary>
  <p><b>编号</b>：[40]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10293</p>
  <p><b>作者</b>：Yihan Du,  Siwei Wang,  Longbo Huang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：agent compares multiple, compares multiple options, multiple options simultaneously, selecting suboptimal arms, bandit problem</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We study a general multi-dueling bandit problem, where an agent compares
multiple options simultaneously and aims to minimize the regret due to
selecting suboptimal arms. This setting generalizes the traditional two-dueling
bandit problem and finds many real-world applications involving subjective
feedback on multiple options. We start with the two-dueling bandit setting and
propose two efficient algorithms, DoublerBAI and MultiSBM-Feedback. DoublerBAI
provides a generic schema for translating known results on best arm
identification algorithms to the dueling bandit problem, and achieves a regret
bound of $O(\ln T)$. MultiSBM-Feedback not only has an optimal $O(\ln T)$
regret, but also reduces the constant factor by almost a half compared to
benchmark results. Then, we consider the general multi-dueling case and develop
an efficient algorithm MultiRUCB. Using a novel finite-time regret analysis for
the general multi-dueling bandit problem, we show that MultiRUCB also achieves
an $O(\ln T)$ regret bound and the bound tightens as the capacity of the
comparison set increases. Based on both synthetic and real-world datasets, we
empirically demonstrate that our algorithms outperform existing algorithms.</p>
  </details>
</details>
<details>
  <summary>14. <b>标题：Evident: a Development Methodology and a Knowledge Base Topology for  Data Mining, Machine Learning and General Knowledge Management</b></summary>
  <p><b>编号</b>：[41]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10291</p>
  <p><b>作者</b>：Mingwu (Barton)Gao,  Samer Haidar</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：knowledge, years, EKB, prediction, methodologies</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Software has been developed for knowledge discovery, prediction and
management for over 30 years. However, there are still unresolved pain points
when using existing project development and artifact management methodologies.
Historically, there has been a lack of applicable methodologies. Further,
methodologies that have been applied, such as Agile, have several limitations
including scientific unfalsifiability that reduce their applicability. Evident,
a development methodology rooted in the philosophy of logical reasoning and
EKB, a knowledge base topology, are proposed. Many pain points in data mining,
machine learning and general knowledge management are alleviated conceptually.
Evident can be extended potentially to accelerate philosophical exploration,
science discovery, education as well as knowledge sharing & retention across
the globe. EKB offers one solution of storing information as knowledge, a
granular level above data. Related topics in computer history, software
engineering, database, sensor, philosophy, and project & organization &
military managements are also discussed.</p>
  </details>
</details>
<details>
  <summary>15. <b>标题：A Fair Loss Function for Network Pruning</b></summary>
  <p><b>编号</b>：[43]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10285</p>
  <p><b>作者</b>：Robbie Meyer,  Alexander Wong</p>
  <p><b>备注</b>：Trustworthy and Socially Responsible Machine Learning (TSRML 2022) workshop co-located with NeurIPS 2022</p>
  <p><b>关键词</b>：resource constraints, deployment of neural, neural networks, networks in environments, environments with resource</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Model pruning can enable the deployment of neural networks in environments
with resource constraints. While pruning may have a small effect on the overall
performance of the model, it can exacerbate existing biases into the model such
that subsets of samples see significantly degraded performance. In this paper,
we introduce the performance weighted loss function, a simple modified
cross-entropy loss function that can be used to limit the introduction of
biases during pruning. Experiments using biased classifiers for facial
classification and skin-lesion classification tasks demonstrate that the
proposed method is a simple and effective tool that can enable existing pruning
methods to be used in fairness sensitive contexts.</p>
  </details>
</details>
<details>
  <summary>16. <b>标题：Exploring through Random Curiosity with General Value Functions</b></summary>
  <p><b>编号</b>：[45]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10282</p>
  <p><b>作者</b>：Aditya Ramesh,  Louis Kirsch,  Sjoerd van Steenkiste,  Jürgen Schmidhuber</p>
  <p><b>备注</b>：Accepted to NeurIPS 2022</p>
  <p><b>关键词</b>：challenging problem commonly, problem commonly addressed, reinforcement learning, commonly addressed, intrinsic rewards</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Efficient exploration in reinforcement learning is a challenging problem
commonly addressed through intrinsic rewards. Recent prominent approaches are
based on state novelty or variants of artificial curiosity. However, directly
applying them to partially observable environments can be ineffective and lead
to premature dissipation of intrinsic rewards. Here we propose random curiosity
with general value functions (RC-GVF), a novel intrinsic reward function that
draws upon connections between these distinct approaches. Instead of using only
the current observation's novelty or a curiosity bonus for failing to predict
precise environment dynamics, RC-GVF derives intrinsic rewards through
predicting temporally extended general value functions. We demonstrate that
this improves exploration in a hard-exploration diabolical lock problem.
Furthermore, RC-GVF significantly outperforms previous methods in the absence
of ground-truth episodic counts in the partially observable MiniGrid
environments. Panoramic observations on MiniGrid further boost RC-GVF's
performance such that it is competitive to baselines exploiting privileged
information in form of episodic counts.</p>
  </details>
</details>
<details>
  <summary>17. <b>标题：TensAIR: Online Learning from Data Streams via Asynchronous Iterative  Routing</b></summary>
  <p><b>编号</b>：[46]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10280</p>
  <p><b>作者</b>：Mauro Dalle Lucca Tosi,  Vinu E. Venugopal,  Martin Theobald</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：encompasses numerous challenges, Online learning, machine learning, emerging area, area of research</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Online learning (OL) from data streams is an emerging area of research that
encompasses numerous challenges from stream processing, machine learning, and
networking. Recent extensions of stream-processing platforms, such as Apache
Kafka and Flink, already provide basic extensions for the training of neural
networks in a stream-processing pipeline. However, these extensions are not
scalable and flexible enough for many real-world use-cases, since they do not
integrate the neural-network libraries as a first-class citizen into their
architectures. In this paper, we present TensAIR, which provides an end-to-end
dataflow engine for OL from data streams via a protocol to which we refer as
asynchronous iterative routing. TensAIR supports the common dataflow operators,
such as Map, Reduce, Join, and has been augmented by the data-parallel OL
functions train and predict. These belong to the new Model operator, in which
an initial TensorFlow model (either freshly initialized or pre-trained) is
replicated among multiple decentralized worker nodes. Our decentralized
architecture allows TensAIR to efficiently shard incoming data batches across
the distributed model replicas, which in turn trigger the model updates via
asynchronous stochastic gradient descent. We empirically demonstrate that
TensAIR achieves a nearly linear scale-out in terms of (1) the number of worker
nodes deployed in the network, and (2) the throughput at which the data batches
arrive at the dataflow operators. We exemplify the versatility of TensAIR by
investigating both sparse (Word2Vec) and dense (CIFAR-10) use-cases, for which
we are able to demonstrate very significant performance improvements in
comparison to Kafka, Flink, and Horovod. We also demonstrate the magnitude of
these improvements by depicting the possibility of real-time concept drift
adaptation of a sentiment analysis model trained over a Twitter stream.</p>
  </details>
</details>
<details>
  <summary>18. <b>标题：A Copy Mechanism for Handling Knowledge Base Elements in SPARQL Neural  Machine Translation</b></summary>
  <p><b>编号</b>：[51]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10271</p>
  <p><b>作者</b>：Rose Hirigoyen,  Amal Zouaq,  Samuel Reyd</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Neural Machine Translation, Machine Translation, SPARQL query generation, neural SPARQL query, SPARQL query</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Neural Machine Translation (NMT) models from English to SPARQL are a
promising development for SPARQL query generation. However, current
architectures are unable to integrate the knowledge base (KB) schema and handle
questions on knowledge resources, classes, and properties unseen during
training, rendering them unusable outside the scope of topics covered in the
training set. Inspired by the performance gains in natural language processing
tasks, we propose to integrate a copy mechanism for neural SPARQL query
generation as a way to tackle this issue. We illustrate our proposal by adding
a copy layer and a dynamic knowledge base vocabulary to two Seq2Seq
architectures (CNNs and Transformers). This layer makes the models copy KB
elements directly from the questions, instead of generating them. We evaluate
our approach on state-of-the-art datasets, including datasets referencing
unknown KB elements and measure the accuracy of the copy-augmented
architectures. Our results show a considerable increase in performance on all
datasets compared to non-copy architectures.</p>
  </details>
</details>
<details>
  <summary>19. <b>标题：Integrated Space Domain Awareness and Communication System</b></summary>
  <p><b>编号</b>：[54]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10260</p>
  <p><b>作者</b>：Selen Gecgel Cetin,  Gunes Karabulut Kurt</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：malicious intent, major challenge, evolution brings, technological developments, developments and malicious</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Space has been reforming and this evolution brings new threats that, together
with technological developments and malicious intent, can pose a major
challenge. Space domain awareness (SDA), a new conceptual idea, has come to the
forefront. It aims sensing, detection, identification and countermeasures by
providing autonomy, intelligence and flexibility against potential threats in
space. In this study, we first present an insightful and clear view of the new
space. Secondly, we propose an integrated SDA and communication (ISDAC) system
for attacker detection. We assume that the attacker has beam-steering antennas
and is capable to vary attack scenarios, such as random attacks on some
receiver antennas. To track random patterns and meet SDA requirements, a
lightweight convolutional neural network architecture is developed. The
proposed ISDAC system shows superior and robust performance under 12 different
attacker configurations with a detection accuracy of over 97.8%.</p>
  </details>
</details>
<details>
  <summary>20. <b>标题：Model-based Causal Bayesian Optimization</b></summary>
  <p><b>编号</b>：[55]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10257</p>
  <p><b>作者</b>：Scott Sussex,  Anastasiia Makarova,  Andreas Krause</p>
  <p><b>备注</b>：24 pages, 8 figures</p>
  <p><b>关键词</b>：unknown structural causal, Bayesian optimization, unknown structural, maximize a downstream, causal Bayesian optimization</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>How should we intervene on an unknown structural causal model to maximize a
downstream variable of interest? This optimization of the output of a system of
interconnected variables, also known as causal Bayesian optimization (CBO), has
important applications in medicine, ecology, and manufacturing. Standard
Bayesian optimization algorithms fail to effectively leverage the underlying
causal structure. Existing CBO approaches assume noiseless measurements and do
not come with guarantees. We propose model-based causal Bayesian optimization
(MCBO), an algorithm that learns a full system model instead of only modeling
intervention-reward pairs. MCBO propagates epistemic uncertainty about the
causal mechanisms through the graph and trades off exploration and exploitation
via the optimism principle. We bound its cumulative regret, and obtain the
first non-asymptotic bounds for CBO. Unlike in standard Bayesian optimization,
our acquisition function cannot be evaluated in closed form, so we show how the
reparameterization trick can be used to apply gradient-based optimizers.
Empirically we find that MCBO compares favorably with existing state-of-the-art
approaches.</p>
  </details>
</details>
<details>
  <summary>21. <b>标题：HiveNAS: Neural Architecture Search using Artificial Bee Colony  Optimization</b></summary>
  <p><b>编号</b>：[58]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10250</p>
  <p><b>作者</b>：Mohamed Shahawy,  Elhadj Benkhelifa</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Network-development process requires, Neural Network-development process, traditional Neural Network-development, process requires substantial, requires substantial expert</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The traditional Neural Network-development process requires substantial
expert knowledge and relies heavily on intuition and trial-and-error. Neural
Architecture Search (NAS) frameworks were introduced to robustly search for
network topologies, as well as facilitate the automated development of Neural
Networks. While some optimization approaches -- such as Genetic Algorithms --
have been extensively explored in the NAS context, other Metaheuristic
Optimization algorithms have not yet been evaluated. In this paper, we propose
HiveNAS, the first Artificial Bee Colony-based NAS framework.</p>
  </details>
</details>
<details>
  <summary>22. <b>标题：Rationale-aware Autonomous Driving Policy utilizing Safety Force Field  implemented on CARLA Simulator</b></summary>
  <p><b>编号</b>：[63]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10237</p>
  <p><b>作者</b>：Ho Suk,  Taewoo Kim,  Hyungbin Park,  Pamul Yadav,  Junyong Lee,  Shiho Kim</p>
  <p><b>备注</b>：9 pages including appendices, 4 figures, NeurIPS 2022 Workshop: Machine Learning for Autonomous Driving (ML4AD)</p>
  <p><b>关键词</b>：commercialize autonomous passenger, autonomous passenger car, car of SAE, resolve liability issues, autonomous driving technology</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Despite the rapid improvement of autonomous driving technology in recent
years, automotive manufacturers must resolve liability issues to commercialize
autonomous passenger car of SAE J3016 Level 3 or higher. To cope with the
product liability law, manufacturers develop autonomous driving systems in
compliance with international standards for safety such as ISO 26262 and ISO
21448. Concerning the safety of the intended functionality (SOTIF) requirement
in ISO 26262, the driving policy recommends providing an explicit rational
basis for maneuver decisions. In this case, mathematical models such as Safety
Force Field (SFF) and Responsibility-Sensitive Safety (RSS) which have
interpretability on decision, may be suitable. In this work, we implement SFF
from scratch to substitute the undisclosed NVIDIA's source code and integrate
it with CARLA open-source simulator. Using SFF and CARLA, we present a
predictor for claimed sets of vehicles, and based on the predictor, propose an
integrated driving policy that consistently operates regardless of safety
conditions it encounters while passing through dynamic traffic. The policy does
not have a separate plan for each condition, but using safety potential, it
aims human-like driving blended in with traffic flow.</p>
  </details>
</details>
<details>
  <summary>23. <b>标题：GNS: A generalizable Graph Neural Network-based simulator for  particulate and fluid modeling</b></summary>
  <p><b>编号</b>：[64]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10228</p>
  <p><b>作者</b>：Krishna Kumar,  Joseph Vantassel</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Graph Network Simulator, PyTorch-based Graph Network, Network Simulator, Graph Network, GNS</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We develop a PyTorch-based Graph Network Simulator (GNS) that learns physics
and predicts the flow behavior of particulate and fluid systems. GNS
discretizes the domain with nodes representing a collection of material points
and the links connecting the nodes representing the local interaction between
particles or clusters of particles. The GNS learns the interaction laws through
message passing on the graph. GNS has three components: (a) Encoder, which
embeds particle information to a latent graph, the edges are learned functions;
(b) Processor, which allows data propagation and computes the nodal
interactions across steps; and (c) Decoder, which extracts the relevant
dynamics (e.g., particle acceleration) from the graph. We introduce
physics-inspired simple inductive biases, such as an inertial frame that allows
learning algorithms to prioritize one solution (constant gravitational
acceleration) over another, reducing learning time. The GNS implementation uses
semi-implicit Euler integration to update the next state based on the predicted
accelerations. GNS trained on trajectory data is generalizable to predict
particle kinematics in complex boundary conditions not seen during training.
The trained model accurately predicts within a 5\% error of its associated
material point method (MPM) simulation. The predictions are 5,000x faster than
traditional MPM simulations (2.5 hours for MPM simulations versus 20 s for GNS
simulation of granular flow). GNS surrogates are popular for solving
optimization, control, critical-region prediction for in situ viz, and
inverse-type problems. The GNS code is available under the open-source MIT
license at this https URL.</p>
  </details>
</details>
<details>
  <summary>24. <b>标题：Adversarial Detection by Approximation of Ensemble Boundary</b></summary>
  <p><b>编号</b>：[65]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10227</p>
  <p><b>作者</b>：T. Windeatt</p>
  <p><b>备注</b>：8 pages, 8 figures, 8 tables</p>
  <p><b>关键词</b>：Deep Neural Networks, pattern recognition problems, Neural Networks, Deep Neural, solving two-class pattern</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A spectral approximation of a Boolean function is proposed for approximating
the decision boundary of an ensemble of Deep Neural Networks (DNNs) solving
two-class pattern recognition problems. The Walsh combination of relatively
weak DNN classifiers is shown experimentally to be capable of detecting
adversarial attacks. By observing the difference in Walsh coefficient
approximation between clean and adversarial images, it appears that
transferability of attack may be used for detection. Approximating the decision
boundary may also aid in understanding the learning and transferability
properties of DNNs. While the experiments here use images, the proposed
approach of modelling two-class ensemble decision boundaries could in principle
be applied to any application area.</p>
  </details>
</details>
<details>
  <summary>25. <b>标题：Leveraging Algorithmic Fairness to Mitigate Blackbox Attribute Inference  Attacks</b></summary>
  <p><b>编号</b>：[68]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10209</p>
  <p><b>作者</b>：Jan Aalmoes,  Vasisht Duddu,  Antoine Boutet</p>
  <p><b>备注</b>：arXiv admin note: text overlap with arXiv:2202.02242</p>
  <p><b>关键词</b>：attribute inference, attribute inference attacks, inference, inference attacks, attribute</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Machine learning (ML) models have been deployed for high-stakes applications,
e.g., healthcare and criminal justice. Prior work has shown that ML models are
vulnerable to attribute inference attacks where an adversary, with some
background knowledge, trains an ML attack model to infer sensitive attributes
by exploiting distinguishable model predictions. However, some prior attribute
inference attacks have strong assumptions about adversary's background
knowledge (e.g., marginal distribution of sensitive attribute) and pose no more
privacy risk than statistical inference. Moreover, none of the prior attacks
account for class imbalance of sensitive attribute in datasets coming from
real-world applications (e.g., Race and Sex). In this paper, we propose an
practical and effective attribute inference attack that accounts for this
imbalance using an adaptive threshold over the attack model's predictions. We
exhaustively evaluate our proposed attack on multiple datasets and show that
the adaptive threshold over the model's predictions drastically improves the
attack accuracy over prior work. Finally, current literature lacks an effective
defence against attribute inference attacks. We investigate the impact of
fairness constraints (i.e., designed to mitigate unfairness in model
predictions) during model training on our attribute inference attack. We show
that constraint based fairness algorithms which enforces equalized odds acts as
an effective defense against attribute inference attacks without impacting the
model utility. Hence, the objective of algorithmic fairness and sensitive
attribute privacy are aligned.</p>
  </details>
</details>
<details>
  <summary>26. <b>标题：Layer-Stack Temperature Scaling</b></summary>
  <p><b>编号</b>：[73]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10193</p>
  <p><b>作者</b>：Amr Khalifa,  Michael C. Mozer,  Hanie Sedghi,  Behnam Neyshabur,  Ibrahim Alabdulmohsin</p>
  <p><b>备注</b>：10 pages, 7 figures, 3 tables</p>
  <p><b>关键词</b>：Recent works demonstrate, Recent works, information for prediction, works demonstrate, demonstrate that early</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent works demonstrate that early layers in a neural network contain useful
information for prediction. Inspired by this, we show that extending
temperature scaling across all layers improves both calibration and accuracy.
We call this procedure "layer-stack temperature scaling" (LATES). Informally,
LATES grants each layer a weighted vote during inference. We evaluate it on
five popular convolutional neural network architectures both in- and
out-of-distribution and observe a consistent improvement over temperature
scaling in terms of accuracy, calibration, and AUC. All conclusions are
supported by comprehensive statistical analyses. Since LATES neither retrains
the architecture nor introduces many more parameters, its advantages can be
reaped without requiring additional data beyond what is used in temperature
scaling. Finally, we show that combining LATES with Monte Carlo Dropout matches
state-of-the-art results on CIFAR10/100.</p>
  </details>
</details>
<details>
  <summary>27. <b>标题：Deep Gaussian Processes for Air Quality Inference</b></summary>
  <p><b>编号</b>：[78]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10174</p>
  <p><b>作者</b>：Aadesh Desai,  Eshan Gujarathi,  Saagar Parikh,  Sachin Yadav,  Zeel Patel,  Nipun Batra</p>
  <p><b>备注</b>：Accepted for publication at ACM India Joint International Conference on Data Science and Management of Data (CoDS-COMAD 2023)</p>
  <p><b>关键词</b>：million people annually, million people, people annually, Air pollution kills, hazardous air pollution</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Air pollution kills around 7 million people annually, and approximately 2.4
billion people are exposed to hazardous air pollution. Accurate, fine-grained
air quality (AQ) monitoring is essential to control and reduce pollution.
However, AQ station deployment is sparse, and thus air quality inference for
unmonitored locations is crucial. Conventional interpolation methods fail to
learn the complex AQ phenomena. This work demonstrates that Deep Gaussian
Process models (DGPs) are a promising model for the task of AQ inference. We
implement Doubly Stochastic Variational Inference, a DGP algorithm, and show
that it performs comparably to the state-of-the-art models.</p>
  </details>
</details>
<details>
  <summary>28. <b>标题：How Do Input Attributes Impact the Privacy Loss in Differential Privacy?</b></summary>
  <p><b>编号</b>：[79]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10173</p>
  <p><b>作者</b>：Tamara T. Mueller,  Stefan Kolek,  Friederike Jungmann,  Alexander Ziller,  Dmitrii Usynin,  Moritz Knolle,  Daniel Rueckert,  Georgios Kaissis</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：worst-case privacy guarantee, typically formulated, Differential privacy, privacy, worst-case privacy</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Differential privacy (DP) is typically formulated as a worst-case privacy
guarantee over all individuals in a database. More recently, extensions to
individual subjects or their attributes, have been introduced. Under the
individual/per-instance DP interpretation, we study the connection between the
per-subject gradient norm in DP neural networks and individual privacy loss and
introduce a novel metric termed the Privacy Loss-Input Susceptibility (PLIS),
which allows one to apportion the subject's privacy loss to their input
attributes. We experimentally show how this enables the identification of
sensitive attributes and of subjects at high risk of data reconstruction.</p>
  </details>
</details>
<details>
  <summary>29. <b>标题：Language-Conditioned Reinforcement Learning to Solve Misunderstandings  with Action Corrections</b></summary>
  <p><b>编号</b>：[80]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10168</p>
  <p><b>作者</b>：Frank Röder,  Manfred Eppe</p>
  <p><b>备注</b>：Accepted to the 2nd Workshop on Language in Reinforcement Learning, (NeurIPS 2022)</p>
  <p><b>关键词</b>：talking and listening, reinforcement learning, incremental, conversation, listening</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Human-to-human conversation is not just talking and listening. It is an
incremental process where participants continually establish a common
understanding to rule out misunderstandings. Current language understanding
methods for intelligent robots do not consider this. There exist numerous
approaches considering non-understandings, but they ignore the incremental
process of resolving misunderstandings. In this article, we present a first
formalization and experimental validation of incremental action-repair for
robotic instruction-following based on reinforcement learning. To evaluate our
approach, we propose a collection of benchmark environments for action
correction in language-conditioned reinforcement learning, utilizing a
synthetic instructor to generate language goals and their corresponding
corrections. We show that a reinforcement learning agent can successfully learn
to understand incremental corrections of misunderstood instructions.</p>
  </details>
</details>
<details>
  <summary>30. <b>标题：Overview of the HASOC Subtrack at FIRE 2022: Offensive Language  Identification in Marathi</b></summary>
  <p><b>编号</b>：[81]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10163</p>
  <p><b>作者</b>：Tharindu Ranasinghe,  Kai North,  Damith Premasiri,  Marcos Zampieri</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：develop robust systems, robust systems capable, Offensive Content Identification, offensive content online, offensive content</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The widespread of offensive content online has become a reason for great
concern in recent years, motivating researchers to develop robust systems
capable of identifying such content automatically. With the goal of carrying
out a fair evaluation of these systems, several international competitions have
been organized, providing the community with important benchmark data and
evaluation methods for various languages. Organized since 2019, the HASOC (Hate
Speech and Offensive Content Identification) shared task is one of these
initiatives. In its fourth iteration, HASOC 2022 included three subtracks for
English, Hindi, and Marathi. In this paper, we report the results of the HASOC
2022 Marathi subtrack which provided participants with a dataset containing
data from Twitter manually annotated using the popular OLID taxonomy. The
Marathi track featured three additional subtracks, each corresponding to one
level of the taxonomy: Task A - offensive content identification (offensive vs.
non-offensive); Task B - categorization of offensive types (targeted vs.
untargeted), and Task C - offensive target identification (individual vs. group
vs. others). Overall, 59 runs were submitted by 10 teams. The best systems
obtained an F1 of 0.9745 for Subtrack 3A, an F1 of 0.9207 for Subtrack 3B, and
F1 of 0.9607 for Subtrack 3C. The best performing algorithms were a mixture of
traditional and deep learning approaches.</p>
  </details>
</details>
<details>
  <summary>31. <b>标题：Optimal service station design for traffic mitigation via genetic  algorithm and neural network</b></summary>
  <p><b>编号</b>：[82]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10159</p>
  <p><b>作者</b>：Carlo Cenedese,  Michele Cucuzzella,  Adriano Cotta Ramusino,  Davide Spalenza,  John Lygeros,  Antonella Ferrara</p>
  <p><b>备注</b>：Submitted to IFAC Worlds conference 2023</p>
  <p><b>关键词</b>：affects traffic congestion, highways affects traffic, total traffic congestion, traffic congestion, paper analyzes</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper analyzes how the presence of service stations on highways affects
traffic congestion. We focus on the problem of optimally designing a service
station to achieve beneficial effects in terms of total traffic congestion and
peak traffic reduction. Microsimulators cannot be used for this task due to
their computational inefficiency. We propose a genetic algorithm based on the
recently proposed CTMs, that efficiently describes the dynamics of a service
station. Then, we leverage the algorithm to train a neural network capable of
solving the same problem, avoiding implementing the CTMs. Finally, we examine
two case studies to validate the capabilities and performance of our
algorithms. In these simulations, we use real data extracted from Dutch
highways.</p>
  </details>
</details>
<details>
  <summary>32. <b>标题：Rare Yet Popular: Evidence and Implications from Labeled Datasets for  Network Anomaly Detection</b></summary>
  <p><b>编号</b>：[92]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10129</p>
  <p><b>作者</b>：Jose Manuel Navarro,  Alexis Huet,  Dario Rossi</p>
  <p><b>备注</b>：Published in the International Teletraffic Congress (ITC 34), 14-16 September 2022</p>
  <p><b>关键词</b>：research works generally, works generally propose, automatically discover outliers, generally propose algorithms, detection research works</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Anomaly detection research works generally propose algorithms or end-to-end
systems that are designed to automatically discover outliers in a dataset or a
stream. While literature abounds concerning algorithms or the definition of
metrics for better evaluation, the quality of the ground truth against which
they are evaluated is seldom questioned. In this paper, we present a systematic
analysis of available public (and additionally our private) ground truth for
anomaly detection in the context of network environments, where data is
intrinsically temporal, multivariate and, in particular, exhibits spatial
properties, which, to the best of our knowledge, we are the first to explore.
Our analysis reveals that, while anomalies are, by definition, temporally rare
events, their spatial characterization clearly shows some type of anomalies are
significantly more popular than others. We find that simple clustering can
reduce the need for human labeling by a factor of 2x-10x, that we are first to
quantitatively analyze in the wild.</p>
  </details>
</details>
<details>
  <summary>33. <b>标题：Let's Enhance: A Deep Learning Approach to Extreme Deblurring of Text  Images</b></summary>
  <p><b>编号</b>：[98]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10103</p>
  <p><b>作者</b>：Theophil Trippe,  Martin Genzel,  Jan Macdonald,  Maximilian März</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：work presents, synthetic data, leveraging augmentation, Helsinki Deblur Challenge, Challenge</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This work presents a novel deep-learning-based pipeline for the inverse
problem of image deblurring, leveraging augmentation and pre-training with
synthetic data. Our results build on our winning submission to the recent
Helsinki Deblur Challenge 2021, whose goal was to explore the limits of
state-of-the-art deblurring algorithms in a real-world data setting. The task
of the challenge was to deblur out-of-focus images of random text, thereby in a
downstream task, maximizing an optical-character-recognition-based score
function. A key step of our solution is the data-driven estimation of the
physical forward model describing the blur process. This enables a stream of
synthetic data, generating pairs of ground-truth and blurry images on-the-fly,
which is used for an extensive augmentation of the small amount of challenge
data provided. The actual deblurring pipeline consists of an approximate
inversion of the radial lens distortion (determined by the estimated forward
model) and a U-Net architecture, which is trained end-to-end. Our algorithm was
the only one passing the hardest challenge level, achieving over 70% character
recognition accuracy. Our findings are well in line with the paradigm of
data-centric machine learning, and we demonstrate its effectiveness in the
context of inverse problems. Apart from a detailed presentation of our
methodology, we also analyze the importance of several design choices in a
series of ablation studies. The code of our challenge submission is available
under this https URL.</p>
  </details>
</details>
<details>
  <summary>34. <b>标题：Credit-cognisant reinforcement learning for multi-agent cooperation</b></summary>
  <p><b>编号</b>：[99]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10100</p>
  <p><b>作者</b>：F. Bredell,  H. A. Engelbrecht,  J. C. Schoeman</p>
  <p><b>备注</b>：11 pages, 6 figures, 1 appendix, submitted to IEEE Transaction on Games</p>
  <p><b>关键词</b>：partially observable scenarios, develop delicate action, Traditional multi-agent reinforcement, delicate action sequences, Traditional multi-agent</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Traditional multi-agent reinforcement learning (MARL) algorithms, such as
independent Q-learning, struggle when presented with partially observable
scenarios, and where agents are required to develop delicate action sequences.
This is often the result of the reward for a good action only being available
after other agents have taken theirs, and these actions are not credited
accordingly. Recurrent neural networks have proven to be a viable solution
strategy for solving these types of problems, resulting in significant
performance increase when compared to other methods. In this paper, we explore
a different approach and focus on the experiences used to update the
action-value functions of each agent. We introduce the concept of
credit-cognisant rewards (CCRs), which allows an agent to perceive the effect
its actions had on the environment as well as on its co-agents. We show that by
manipulating these experiences and constructing the reward contained within
them to include the rewards received by all the agents within the same action
sequence, we are able to improve significantly on the performance of
independent deep Q-learning as well as deep recurrent Q-learning. We evaluate
and test the performance of CCRs when applied to deep reinforcement learning
techniques at the hands of a simplified version of the popular card game
Hanabi.</p>
  </details>
</details>
<details>
  <summary>35. <b>标题：Hyperbolic Sliced-Wasserstein via Geodesic and Horospherical Projections</b></summary>
  <p><b>编号</b>：[112]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10066</p>
  <p><b>作者</b>：Clément Bonet,  Laetitia Chapel,  Lucas Drumetz,  Nicolas Courty</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：underlying hierarchical structure, shown beneficial, types of data, data which present, hierarchical structure</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>It has been shown beneficial for many types of data which present an
underlying hierarchical structure to be embedded in hyperbolic spaces.
Consequently, many tools of machine learning were extended to such spaces, but
only few discrepancies to compare probability distributions defined over those
spaces exist. Among the possible candidates, optimal transport distances are
well defined on such Riemannian manifolds and enjoy strong theoretical
properties, but suffer from high computational cost. On Euclidean spaces,
sliced-Wasserstein distances, which leverage a closed-form of the Wasserstein
distance in one dimension, are more computationally efficient, but are not
readily available on hyperbolic spaces. In this work, we propose to derive
novel hyperbolic sliced-Wasserstein discrepancies. These constructions use
projections on the underlying geodesics either along horospheres or geodesics.
We study and compare them on different tasks where hyperbolic representations
are relevant, such as sampling or image classification.</p>
  </details>
</details>
<details>
  <summary>36. <b>标题：How to train your draGAN: A task oriented solution to imbalanced  classification</b></summary>
  <p><b>编号</b>：[113]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10065</p>
  <p><b>作者</b>：Leon O. Guertler,  Andri Ashfahani,  Anh Tuan Luu</p>
  <p><b>备注</b>：94 Datasets; under review (Elsevier Neural Networks)</p>
  <p><b>关键词</b>：Minority Over-sampling Technique, Synthetic Minority Over-sampling, Over-sampling Technique, building effective classification, Synthetic Minority</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The long-standing challenge of building effective classification models for
small and imbalanced datasets has seen little improvement since the creation of
the Synthetic Minority Over-sampling Technique (SMOTE) over 20 years ago.
Though GAN based models seem promising, there has been a lack of purpose built
architectures for solving the aforementioned problem, as most previous studies
focus on applying already existing models. This paper proposes a unique,
performance-oriented, data-generating strategy that utilizes a new
architecture, coined draGAN, to generate both minority and majority samples.
The samples are generated with the objective of optimizing the classification
model's performance, rather than similarity to the real data. We benchmark our
approach against state-of-the-art methods from the SMOTE family and competitive
GAN based approaches on 94 tabular datasets with varying degrees of imbalance
and linearity. Empirically we show the superiority of draGAN, but also
highlight some of its shortcomings. All code is available on:
this https URL.</p>
  </details>
</details>
<details>
  <summary>37. <b>标题：Intrusion Detection in Internet of Things using Convolutional Neural  Networks</b></summary>
  <p><b>编号</b>：[114]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10062</p>
  <p><b>作者</b>：Martin Kodys,  Zhi Lu,  Kar Wai Fok,  Vrizlynn L. L. Thing</p>
  <p><b>备注</b>：Keywords: Cybersecurity, Intrusion Detection, IoT, Deep Learning, Convolutional Neural Networks; this https URL</p>
  <p><b>关键词</b>：Internet of Things, asset tracking, resource monitoring, monitoring and automation, popular paradigm</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Internet of Things (IoT) has become a popular paradigm to fulfil needs of the
industry such as asset tracking, resource monitoring and automation. As
security mechanisms are often neglected during the deployment of IoT devices,
they are more easily attacked by complicated and large volume intrusion attacks
using advanced techniques. Artificial Intelligence (AI) has been used by the
cyber security community in the past decade to automatically identify such
attacks. However, deep learning methods have yet to be extensively explored for
Intrusion Detection Systems (IDS) specifically for IoT. Most recent works are
based on time sequential models like LSTM and there is short of research in
CNNs as they are not naturally suited for this problem. In this article, we
propose a novel solution to the intrusion attacks against IoT devices using
CNNs. The data is encoded as the convolutional operations to capture the
patterns from the sensors data along time that are useful for attacks detection
by CNNs. The proposed method is integrated with two classical CNNs: ResNet and
EfficientNet, where the detection performance is evaluated. The experimental
results show significant improvement in both true positive rate and false
positive rate compared to the baseline using LSTM.</p>
  </details>
</details>
<details>
  <summary>38. <b>标题：Overview of the WANLP 2022 Shared Task on Propaganda Detection in Arabic</b></summary>
  <p><b>编号</b>：[116]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10057</p>
  <p><b>作者</b>：Firoj Alam,  Hamdy Mubarak,  Wajdi Zaghouani,  Giovanni Da San Martino,  Preslav Nakov</p>
  <p><b>备注</b>：Accepted at WANLP-22 (EMNLP-22), propaganda, disinformation, misinformation, fake news, memes, multimodality. arXiv admin note: text overlap with arXiv:2109.08013, arXiv:2105.09284</p>
  <p><b>关键词</b>：group deliberately designed, Propaganda techniques, group deliberately, predetermined ends, psychological devices</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Propaganda is the expression of an opinion or an action by an individual or a
group deliberately designed to influence the opinions or the actions of other
individuals or groups with reference to predetermined ends, which is achieved
by means of well-defined rhetorical and psychological devices. Propaganda
techniques are commonly used in social media to manipulate or to mislead users.
Thus, there has been a lot of recent research on automatic detection of
propaganda techniques in text as well as in memes. However, so far the focus
has been primarily on English. With the aim to bridge this language gap, we ran
a shared task on detecting propaganda techniques in Arabic tweets as part of
the WANLP 2022 workshop, which included two subtasks. Subtask~1 asks to
identify the set of propaganda techniques used in a tweet, which is a
multilabel classification problem, while Subtask~2 asks to detect the
propaganda techniques used in a tweet together with the exact span(s) of text
in which each propaganda technique appears. The task attracted 63 team
registrations, and eventually 14 and 3 teams made submissions for subtask 1 and
2, respectively. Finally, 11 teams submitted system description papers.</p>
  </details>
</details>
<details>
  <summary>39. <b>标题：Decorr: Environment Partitioning for Invariant Learning and OOD  Generalization</b></summary>
  <p><b>编号</b>：[118]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10054</p>
  <p><b>作者</b>：Yufan Liao,  Qi Wu,  Xing Yan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：OOD generalization, popular in OOD, OOD, Invariant learning, environments</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Invariant learning methods try to find an invariant predictor across several
environments and have become popular in OOD generalization. However, in
situations where environments do not naturally exist in the data, they have to
be decided by practitioners manually. Environment partitioning, which splits
the whole training dataset into environments by algorithms, will significantly
influence the performance of invariant learning and has been left undiscussed.
A good environment partitioning method can bring invariant learning to
applications with more general settings and improve its performance. We propose
to split the dataset into several environments by finding low-correlated data
subsets. Theoretical interpretations and algorithm details are both introduced
in the paper. Through experiments on both synthetic and real data, we show that
our Decorr method can achieve outstanding performance, while some other
partitioning methods may lead to bad, even below-ERM results using the same
training scheme of IRM.</p>
  </details>
</details>
<details>
  <summary>40. <b>标题：Clustering based opcode graph generation for malware variant detection</b></summary>
  <p><b>编号</b>：[120]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10048</p>
  <p><b>作者</b>：Kar Wai Fok,  Vrizlynn L. L. Thing</p>
  <p><b>备注</b>：Keywords: malware detection and attribution, malware family, clustering, opcode graph, machine learning; this https URL</p>
  <p><b>关键词</b>：key means leveraged, leveraged by threat, threat actors, cyber space, malware</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Malwares are the key means leveraged by threat actors in the cyber space for
their attacks. There is a large array of commercial solutions in the market and
significant scientific research to tackle the challenge of the detection and
defense against malwares. At the same time, attackers also advance their
capabilities in creating polymorphic and metamorphic malwares to make it
increasingly challenging for existing solutions. To tackle this issue, we
propose a methodology to perform malware detection and family attribution. The
proposed methodology first performs the extraction of opcodes from malwares in
each family and constructs their respective opcode graphs. We explore the use
of clustering algorithms on the opcode graphs to detect clusters of malwares
within the same malware family. Such clusters can be seen as belonging to
different sub-family groups. Opcode graph signatures are built from each
detected cluster. Hence, for each malware family, a group of signatures is
generated to represent the family. These signatures are used to classify an
unknown sample as benign or belonging to one the malware families. We evaluate
our methodology by performing experiments on a dataset consisting of both
benign files and malware samples belonging to a number of different malware
families and comparing the results to existing approach.</p>
  </details>
</details>
<details>
  <summary>41. <b>标题：Why pseudo label based algorithm is effective? --from the perspective of  pseudo labeled data</b></summary>
  <p><b>编号</b>：[124]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10039</p>
  <p><b>作者</b>：Zeping Min,  Cheng Tai</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：label based semi-supervised, pseudo label based, based semi-supervised learning, label based, based semi-supervised</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recently, pseudo label based semi-supervised learning has achieved great
success in many fields. The core idea of the pseudo label based semi-supervised
learning algorithm is to use the model trained on the labeled data to generate
pseudo labels on the unlabeled data, and then train a model to fit the
previously generated pseudo labels. We give a theory analysis for why pseudo
label based semi-supervised learning is effective in this paper. We mainly
compare the generalization error of the model trained under two settings: (1)
There are N labeled data. (2) There are N unlabeled data and a suitable initial
model. Our analysis shows that, firstly, when the amount of unlabeled data
tends to infinity, the pseudo label based semi-supervised learning algorithm
can obtain model which have the same generalization error upper bound as model
obtained by normally training in the condition of the amount of labeled data
tends to infinity. More importantly, we prove that when the amount of unlabeled
data is large enough, the generalization error upper bound of the model
obtained by pseudo label based semi-supervised learning algorithm can converge
to the optimal upper bound with linear convergence rate. We also give the lower
bound on sampling complexity to achieve linear convergence rate. Our analysis
contributes to understanding the empirical successes of pseudo label-based
semi-supervised learning.</p>
  </details>
</details>
<details>
  <summary>42. <b>标题：Adversarial Stimuli: Attacking Brain-Computer Interfaces via Perturbed  Sensory Events</b></summary>
  <p><b>编号</b>：[125]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10033</p>
  <p><b>作者</b>：Bibek Upadhayay,  Vahid Behzadan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：causing incorrect predictions, Machine learning models, Brain Computer Interfaces, Machine learning, input domain</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Machine learning models are known to be vulnerable to adversarial
perturbations in the input domain, causing incorrect predictions. Inspired by
this phenomenon, we explore the feasibility of manipulating EEG-based Motor
Imagery (MI) Brain Computer Interfaces (BCIs) via perturbations in sensory
stimuli. Similar to adversarial examples, these \emph{adversarial stimuli} aim
to exploit the limitations of the integrated brain-sensor-processing components
of the BCI system in handling shifts in participants' response to changes in
sensory stimuli. This paper proposes adversarial stimuli as an attack vector
against BCIs, and reports the findings of preliminary experiments on the impact
of visual adversarial stimuli on the integrity of EEG-based MI BCIs. Our
findings suggest that minor adversarial stimuli can significantly deteriorate
the performance of MI BCIs across all participants (p=0.0003). Additionally,
our results indicate that such attacks are more effective in conditions with
induced stress.</p>
  </details>
</details>
<details>
  <summary>43. <b>标题：Contrastive Knowledge Graph Error Detection</b></summary>
  <p><b>编号</b>：[126]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10030</p>
  <p><b>作者</b>：Qinggang Zhang,  Junnan Dong,  Keyu Duan,  Xiao Huang,  Yezi Liu,  Linchuan Xu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：severely affecting KG-related, KG-related downstream tasks, affecting KG-related downstream, introduce non-negligible noise, non-negligible noise</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Knowledge Graph (KG) errors introduce non-negligible noise, severely
affecting KG-related downstream tasks. Detecting errors in KGs is challenging
since the patterns of errors are unknown and diverse, while ground-truth labels
are rare or even unavailable. A traditional solution is to construct logical
rules to verify triples, but it is not generalizable since different KGs have
distinct rules with domain knowledge involved. Recent studies focus on
designing tailored detectors or ranking triples based on KG embedding loss.
However, they all rely on negative samples for training, which are generated by
randomly replacing the head or tail entity of existing triples. Such a negative
sampling strategy is not enough for prototyping practical KG errors, e.g.,
(Bruce_Lee, place_of_birth, China), in which the three elements are often
relevant, although mismatched. We desire a more effective unsupervised learning
mechanism tailored for KG error detection. To this end, we propose a novel
framework - ContrAstive knowledge Graph Error Detection (CAGED). It introduces
contrastive learning into KG learning and provides a novel way of modeling KG.
Instead of following the traditional setting, i.e., considering entities as
nodes and relations as semantic edges, CAGED augments a KG into different
hyper-views, by regarding each relational triple as a node. After joint
training with KG embedding and contrastive learning loss, CAGED assesses the
trustworthiness of each triple based on two learning signals, i.e., the
consistency of triple representations across multi-views and the
self-consistency within the triple. Extensive experiments on three real-world
KGs show that CAGED outperforms state-of-the-art methods in KG error detection.
Our codes and datasets are available at this https URL.</p>
  </details>
</details>
<details>
  <summary>44. <b>标题：Diagnostics for Deep Neural Networks with Automated Copy/Paste Attacks</b></summary>
  <p><b>编号</b>：[129]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10024</p>
  <p><b>作者</b>：Stephen Casper,  Kaivalya Hariharan,  Dylan Hadfield-Menell</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Deep neural networks, pose significant risks, Deep neural, neural networks, significant risks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep neural networks (DNNs) are powerful, but they can make mistakes that
pose significant risks. A model performing well on a test set does not imply
safety in deployment, so it is important to have additional tools to understand
its flaws. Adversarial examples can help reveal weaknesses, but they are often
difficult for a human to interpret or draw generalizable, actionable
conclusions from. Some previous works have addressed this by studying
human-interpretable attacks. We build on these with three contributions. First,
we introduce a method termed Search for Natural Adversarial Features Using
Embeddings (SNAFUE) which offers a fully-automated method for finding
"copy/paste" attacks in which one natural image can be pasted into another in
order to induce an unrelated misclassification. Second, we use this to red team
an ImageNet classifier and identify hundreds of easily-describable sets of
vulnerabilities. Third, we compare this approach with other interpretability
tools by attempting to rediscover trojans. Our results suggest that SNAFUE can
be useful for interpreting DNNs and generating adversarial data for them. Code
is available at this https URL</p>
  </details>
</details>
<details>
  <summary>45. <b>标题：LiSnowNet: Real-time Snow Removal for LiDAR Point Cloud</b></summary>
  <p><b>编号</b>：[130]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10023</p>
  <p><b>作者</b>：Ming-Yuan Yu,  Ram Vasudevan,  Matthew Johnson-Roberson</p>
  <p><b>备注</b>：The paper has been accepted for the 2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2022)</p>
  <p><b>关键词</b>：modern self-driving vehicles, self-driving vehicles, surrounding objects, widely adopted, scene and surrounding</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>LiDARs have been widely adopted to modern self-driving vehicles, providing 3D
information of the scene and surrounding objects. However, adverser weather
conditions still pose significant challenges to LiDARs since point clouds
captured during snowfall can easily be corrupted. The resulting noisy point
clouds degrade downstream tasks such as mapping. Existing works in de-noising
point clouds corrupted by snow are based on nearest-neighbor search, and thus
do not scale well with modern LiDARs which usually capture $100k$ or more
points at 10Hz. In this paper, we introduce an unsupervised de-noising
algorithm, LiSnowNet, running 52$\times$ faster than the state-of-the-art
methods while achieving superior performance in de-noising. Unlike previous
methods, the proposed algorithm is based on a deep convolutional neural network
and can be easily deployed to hardware accelerators such as GPUs. In addition,
we demonstrate how to use the proposed method for mapping even with corrupted
point clouds.</p>
  </details>
</details>
<details>
  <summary>46. <b>标题：Who Says Elephants Can't Run: Bringing Large Scale MoE Models into Cloud  Scale Production</b></summary>
  <p><b>编号</b>：[134]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10017</p>
  <p><b>作者</b>：Young Jin Kim,  Rawn Henry,  Raffy Fahim,  Hany Hassan Awadalla</p>
  <p><b>备注</b>：Accepted to SustaiNLP 2022 (EMNLP 2022)</p>
  <p><b>关键词</b>：sparsely activated layers, enabled training models, number of parameters, conditional execution, execution of sparsely</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Mixture of Experts (MoE) models with conditional execution of sparsely
activated layers have enabled training models with a much larger number of
parameters. As a result, these models have achieved significantly better
quality on various natural language processing tasks including machine
translation. However, it remains challenging to deploy such models in real-life
scenarios due to the large memory requirements and inefficient inference. In
this work, we introduce a highly efficient inference framework with several
optimization approaches to accelerate the computation of sparse models and cut
down the memory consumption significantly. While we achieve up to 26x speed-up
in terms of throughput, we also reduce the model size almost to one eighth of
the original 32-bit float model by quantizing expert weights into 4-bit
integers. As a result, we are able to deploy 136x larger models with 27% less
cost and significantly better quality compared to the existing solutions. This
enables a paradigm shift in deploying large scale multilingual MoE transformers
models replacing the traditional practice of distilling teacher models into
dozens of smaller models per language or task.</p>
  </details>
</details>
<details>
  <summary>47. <b>标题：A Tale of Two Cities: Data and Configuration Variances in Robust Deep  Learning</b></summary>
  <p><b>编号</b>：[136]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10012</p>
  <p><b>作者</b>：Guanqin Zhang,  Jiankun Sun,  Feng Xu,  H.M.N. Dilum Bandara,  Shiping Chen,  Yulei Sui,  Tim Menzies</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Deep neural networks, supply chain, medical diagnosis, neural networks, image recognition</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep neural networks (DNNs), are widely used in many industries such as image
recognition, supply chain, medical diagnosis, and autonomous driving. However,
prior work has shown the high accuracy of a DNN model does not imply high
robustness (i.e., consistent performances on new and future datasets) because
the input data and external environment (e.g., software and model
configurations) for a deployed model are constantly changing. Hence, ensuring
the robustness of deep learning is not an option but a priority to enhance
business and consumer confidence. Previous studies mostly focus on the data
aspect of model variance. In this article, we systematically summarize DNN
robustness issues and formulate them in a holistic view through two important
aspects, i.e., data and software configuration variances in DNNs. We also
provide a predictive framework to generate representative variances
(counterexamples) by considering both data and configurations for robust
learning through the lens of search-based optimization.</p>
  </details>
</details>
<details>
  <summary>48. <b>标题：Influential Recommender System</b></summary>
  <p><b>编号</b>：[140]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10002</p>
  <p><b>作者</b>：Haoren Zhu,  Hao Ge,  Xiaodong Gu,  Pengfei Zhao,  Dik Lun Lee</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Traditional recommender systems, user historical interests, typically passive, Influential Recommender Network, user</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Traditional recommender systems are typically passive in that they try to
adapt their recommendations to the user's historical interests. However, it is
highly desirable for commercial applications, such as e-commerce, advertisement
placement, and news portals, to be able to expand the users' interests so that
they would accept items that they were not originally aware of or interested in
to increase customer interactions. In this paper, we present Influential
Recommender System (IRS), a new recommendation paradigm that aims to
proactively lead a user to like a given objective item by progressively
recommending to the user a sequence of carefully selected items (called an
influence path). We propose the Influential Recommender Network (IRN), which is
a Transformer-based sequential model to encode the items' sequential
dependencies. Since different people react to external influences differently,
we introduce the Personalized Impressionability Mask (PIM) to model how
receptive a user is to external influence to generate the most effective
influence path for the user. To evaluate IRN, we design several performance
metrics to measure whether or not the influence path can smoothly expand the
user interest to include the objective item while maintaining the user's
satisfaction with the recommendation. Experimental results show that IRN
significantly outperforms the baseline recommenders and demonstrates its
capability of influencing users' interests.</p>
  </details>
</details>
<details>
  <summary>49. <b>标题：Protein language model rescue mutations highlight variant effects and  structure in clinically relevant genes</b></summary>
  <p><b>编号</b>：[142]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10000</p>
  <p><b>作者</b>：Onuralp Soylemez,  Pablo Cordero</p>
  <p><b>备注</b>：NeurIPS 2022, Workshop on Learning Meaningful Representations of Life</p>
  <p><b>关键词</b>：shown remarkable performance, fundamental biological tasks, shown remarkable, remarkable performance, performance in fundamental</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Despite being self-supervised, protein language models have shown remarkable
performance in fundamental biological tasks such as predicting impact of
genetic variation on protein structure and function. The effectiveness of these
models on diverse set of tasks suggests that they learn meaningful
representations of fitness landscape that can be useful for downstream clinical
applications. Here, we interrogate the use of these language models in
characterizing known pathogenic mutations in curated, medically actionable
genes through an exhaustive search of putative compensatory mutations on each
variant's genetic background. Systematic analysis of the predicted effects of
these compensatory mutations reveal unappreciated structural features of
proteins that are missed by other structure predictors like AlphaFold. While
deep mutational scan experiments provide an unbiased estimate of the mutational
landscape, we encourage the community to generate and curate rescue mutation
experiments to inform the design of more sophisticated co-masking strategies
and leverage large language models more effectively for downstream clinical
prediction tasks.</p>
  </details>
</details>
<details>
  <summary>50. <b>标题：Look More but Care Less in Video Recognition</b></summary>
  <p><b>编号</b>：[144]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.09992</p>
  <p><b>作者</b>：Yitian Zhang,  Yue Bai,  Huan Wang,  Yi Xu,  Yun Fu</p>
  <p><b>备注</b>：Accepted by NeurIPS 2022</p>
  <p><b>关键词</b>：Existing action recognition, action recognition methods, recognition methods typically, methods typically sample, recognition performance</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Existing action recognition methods typically sample a few frames to
represent each video to avoid the enormous computation, which often limits the
recognition performance. To tackle this problem, we propose Ample and Focal
Network (AFNet), which is composed of two branches to utilize more frames but
with less computation. Specifically, the Ample Branch takes all input frames to
obtain abundant information with condensed computation and provides the
guidance for Focal Branch by the proposed Navigation Module; the Focal Branch
squeezes the temporal size to only focus on the salient frames at each
convolution block; in the end, the results of two branches are adaptively fused
to prevent the loss of information. With this design, we can introduce more
frames to the network but cost less computation. Besides, we demonstrate AFNet
can utilize fewer frames while achieving higher accuracy as the dynamic
selection in intermediate features enforces implicit temporal modeling.
Further, we show that our method can be extended to reduce spatial redundancy
with even less cost. Extensive experiments on five datasets demonstrate the
effectiveness and efficiency of our method.</p>
  </details>
</details>
<details>
  <summary>51. <b>标题：Pandering in a Flexible Representative Democracy</b></summary>
  <p><b>编号</b>：[145]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.09986</p>
  <p><b>作者</b>：Xiaolin Sun,  Jacob Masur,  Ben Abramowitz,  Nicholas Mattei,  Zizhan Zheng</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：regular election cycles, meant to prevent, prevent corruption, accountable in service, Flexible Representative Democracy</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In representative democracies, the election of new representatives in regular
election cycles is meant to prevent corruption and other misbehavior by elected
officials and to keep them accountable in service of the ``will of the people."
This democratic ideal can be undermined when candidates are dishonest when
campaigning for election over these multiple cycles or rounds of voting. Much
of the work on COMSOC to date has investigated strategic actions in only a
single round. We introduce a novel formal model of \emph{pandering}, or
strategic preference reporting by candidates seeking to be elected, and examine
the resilience of two democratic voting systems to pandering within a single
round and across multiple rounds. The two voting systems we compare are
Representative Democracy (RD) and Flexible Representative Democracy (FRD). For
each voting system, our analysis centers on the types of strategies candidates
employ and how voters update their views of candidates based on how the
candidates have pandered in the past. We provide theoretical results on the
complexity of pandering in our setting for a single cycle, formulate our
problem for multiple cycles as a Markov Decision Process, and use reinforcement
learning to study the effects of pandering by both single candidates and groups
of candidates across a number of rounds.</p>
  </details>
</details>
<details>
  <summary>52. <b>标题：Multi-task Learning for Sparse Traffic Forecasting</b></summary>
  <p><b>编号</b>：[146]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.09984</p>
  <p><b>作者</b>：Jiezhang Li,  Junjun Li,  Yue-Jiao Gong</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：intelligent transportation systems, Accurate traffic prediction, traffic prediction tasks, Previous traffic prediction, traffic prediction</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Accurate traffic prediction is crucial to improve the performance of
intelligent transportation systems. Previous traffic prediction tasks mainly
focus on small and non-isolated traffic subsystems, while the Traffic4cast 2022
competition is dedicated to exploring the traffic state dynamics of entire
cities. Given one hour of sparse loop count data only, the task is to predict
the congestion classes for all road segments and the expected times of arrival
along super-segments 15 minutes into the future. The sparsity of loop counter
data and highly uncertain real-time traffic conditions make the competition
challenging. For this reason, we propose a multi-task learning network that can
simultaneously predict the congestion classes and the speed of each road
segment. Specifically, we use clustering and neural network methods to learn
the dynamic features of loop counter data. Then, we construct a graph with road
segments as nodes and capture the spatial dependence between road segments
based on a Graph Neural Network. Finally, we learn three measures, namely the
congestion class, the speed value and the volume class, simultaneously through
a multi-task learning module. For the extended competition, we use the
predicted speeds to calculate the expected times of arrival along
super-segments. Our method achieved excellent results on the dataset provided
by the Traffic4cast Competition 2022, source code is available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>53. <b>标题：Weighted Ensemble Self-Supervised Learning</b></summary>
  <p><b>编号</b>：[148]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.09981</p>
  <p><b>作者</b>：Yangjun Ruan,  Saurabh Singh,  Warren Morningstar,  Alexander A. Alemi,  Sergey Ioffe,  Ian Fischer,  Joshua V. Dillon</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：boosting model performance, uncertainty estimation, supervised learning performance, boosting model, model performance</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Ensembling has proven to be a powerful technique for boosting model
performance, uncertainty estimation, and robustness in supervised learning.
Advances in self-supervised learning (SSL) enable leveraging large unlabeled
corpora for state-of-the-art few-shot and supervised learning performance. In
this paper, we explore how ensemble methods can improve recent SSL techniques
by developing a framework that permits data-dependent weighted cross-entropy
losses. We refrain from ensembling the representation backbone; this choice
yields an efficient ensemble method that incurs a small training cost and
requires no architectural changes or computational overhead to downstream
evaluation. The effectiveness of our method is demonstrated with two
state-of-the-art SSL methods, DINO (Caron et al., 2021) and MSN (Assran et al.,
2022). Our method outperforms both in multiple evaluation metrics on
ImageNet-1K, particularly in the few-shot setting. We explore several weighting
schemes and find that those which increase the diversity of ensemble heads lead
to better downstream evaluation results. Thorough experiments yield improved
prior art baselines which our method still surpasses; e.g., our overall
improvement with MSN ViT-B/16 is 3.9 p.p. for 1-shot learning.</p>
  </details>
</details>
<details>
  <summary>54. <b>标题：Estimating defection in subscription-type markets: empirical analysis  from the scholarly publishing industry</b></summary>
  <p><b>编号</b>：[153]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.09970</p>
  <p><b>作者</b>：Michael Roberts,  J. Ignacio Deza,  Hisham Ihshaish,  Yanhui Zhu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：scholarly publishing industry, empirical study, customer churn prediction, publishing industry, scholarly publishing business</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present the first empirical study on customer churn prediction in the
scholarly publishing industry. The study examines our proposed method for
prediction on a customer subscription data over a period of 6.5 years, which
was provided by a major academic publisher. We explore the subscription-type
market within the context of customer defection and modelling, and provide
analysis of the business model of such markets, and how these characterise the
academic publishing business. The proposed method for prediction attempts to
provide inference of customer's likelihood of defection on the basis of their
re-sampled use of provider resources -in this context, the volume and frequency
of content downloads. We show that this approach can be both accurate as well
as uniquely useful in the business-to-business context, with which the
scholarly publishing business model shares similarities. The main findings of
this work suggest that whilst all predictive models examined, especially
ensemble methods of machine learning, achieve substantially accurate prediction
of churn, nearly a year ahead, this can be furthermore achieved even when the
specific behavioural attributes that can be associated to each customer
probability to churn are overlooked. Allowing as such highly accurate inference
of churn from minimal possible data. We show that modelling churn on the basis
of re-sampling customers' use of resources over subscription time is a better
(simplified) approach than when considering the high granularity that can often
characterise consumption behaviour.</p>
  </details>
</details>
<details>
  <summary>55. <b>标题：Path Independent Equilibrium Models Can Better Exploit Test-Time  Computation</b></summary>
  <p><b>编号</b>：[157]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.09961</p>
  <p><b>作者</b>：Cem Anil,  Ashwini Pokle,  Kaiqu Liang,  Johannes Treutlein,  Yuhuai Wu,  Shaojie Bai,  Zico Kolter,  Roger Grosse</p>
  <p><b>备注</b>：NeurIPS 2022</p>
  <p><b>关键词</b>：increased inference budget, harder problem instances, Designing networks capable, budget is important, path independence</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Designing networks capable of attaining better performance with an increased
inference budget is important to facilitate generalization to harder problem
instances. Recent efforts have shown promising results in this direction by
making use of depth-wise recurrent networks. We show that a broad class of
architectures named equilibrium models display strong upwards generalization,
and find that stronger performance on harder examples (which require more
iterations of inference to get correct) strongly correlates with the path
independence of the system -- its tendency to converge to the same steady-state
behaviour regardless of initialization, given enough computation. Experimental
interventions made to promote path independence result in improved
generalization on harder problem instances, while those that penalize it
degrade this ability. Path independence analyses are also useful on a
per-example basis: for equilibrium models that have good in-distribution
performance, path independence on out-of-distribution samples strongly
correlates with accuracy. Our results help explain why equilibrium models are
capable of strong upwards generalization and motivates future work that
harnesses path independence as a general modelling principle to facilitate
scalable test-time usage.</p>
  </details>
</details>
<details>
  <summary>56. <b>标题：Emergence of a stochastic resonance in machine learning</b></summary>
  <p><b>编号</b>：[160]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.09955</p>
  <p><b>作者</b>：Zheng-Meng Zhai,  Ling-Wei Kong,  Ying-Cheng Lai</p>
  <p><b>备注</b>：7 pages, 4 figures</p>
  <p><b>关键词</b>：beneficial to machine-learning, stochastic resonance, chaotic systems, machine-learning prediction, high-dimensional chaotic systems</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Can noise be beneficial to machine-learning prediction of chaotic systems?
Utilizing reservoir computers as a paradigm, we find that injecting noise to
the training data can induce a stochastic resonance with significant benefits
to both short-term prediction of the state variables and long-term prediction
of the attractor of the system. A key to inducing the stochastic resonance is
to include the amplitude of the noise in the set of hyperparameters for
optimization. By so doing, the prediction accuracy, stability and horizon can
be dramatically improved. The stochastic resonance phenomenon is demonstrated
using two prototypical high-dimensional chaotic systems.</p>
  </details>
</details>
<details>
  <summary>57. <b>标题：Robust DNN Surrogate Models with Uncertainty Quantification via  Adversarial Training</b></summary>
  <p><b>编号</b>：[161]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.09954</p>
  <p><b>作者</b>：Lixiang Zhang,  Jia Li</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：emulate mathematical simulators, surrogate models, Monte Carlo method, computational efficiency, biological processes</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>For computational efficiency, surrogate models have been used to emulate
mathematical simulators for physical or biological processes. High-speed
simulation is crucial for conducting uncertainty quantification (UQ) when the
simulation is repeated over many randomly sampled input points (aka, the Monte
Carlo method). In some cases, UQ is only feasible with a surrogate model.
Recently, Deep Neural Network (DNN) surrogate models have gained popularity for
their hard-to-match emulation accuracy. However, it is well-known that DNN is
prone to errors when input data are perturbed in particular ways, the very
motivation for adversarial training. In the usage scenario of surrogate models,
the concern is less of a deliberate attack but more of the high sensitivity of
the DNN's accuracy to input directions, an issue largely ignored by researchers
using emulation models. In this paper, we show the severity of this issue
through empirical studies and hypothesis testing. Furthermore, we adopt methods
in adversarial training to enhance the robustness of DNN surrogate models.
Experiments demonstrate that our approaches significantly improve the
robustness of the surrogate models without compromising emulation accuracy.</p>
  </details>
</details>
<details>
  <summary>58. <b>标题：Compressing Transformer-based self-supervised models for speech  processing</b></summary>
  <p><b>编号</b>：[164]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.09949</p>
  <p><b>作者</b>：Tzu-Quan Lin,  Tsung-Huan Yang,  Chun-Yao Chang,  Kuang-Ming Chen,  Tzu-hsun Feng,  Hung-yi Lee,  Hao Tang</p>
  <p><b>备注</b>：Submitted to ICASSP 2023</p>
  <p><b>关键词</b>：spectrum of devices, learning with applications, computational cost, cost of training, training and inference</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Despite the success of Transformers in self-supervised learning with
applications to various downstream tasks, the computational cost of training
and inference remains a major challenge for applying these models to a wide
spectrum of devices. Several isolated attempts have been made to compress
Transformers, prior to applying them to downstream tasks. In this work, we aim
to provide context for the isolated results, studying several commonly used
compression techniques, including weight pruning, head pruning, low-rank
approximation, and knowledge distillation. We report wall-clock time, the
number of parameters, and the number of multiply-accumulate operations for
these techniques, charting the landscape of compressing Transformer-based
self-supervised models.</p>
  </details>
</details>
<details>
  <summary>59. <b>标题：MelHuBERT: A simplified HuBERT on Mel spectrogram</b></summary>
  <p><b>编号</b>：[166]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.09944</p>
  <p><b>作者</b>：Tzu-Quan Lin,  Hung-yi Lee,  Hao Tang</p>
  <p><b>备注</b>：Submitted to ICASSP 2023</p>
  <p><b>关键词</b>：learning speech representations, downstream tasks, great success, success in learning, learning speech</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Self-supervised models have had great success in learning speech
representations that can generalize to various downstream tasks. HuBERT, in
particular, achieves strong performance while being relatively simple in
training compared to others. The original experimental setting is
computationally extensive, hindering the reproducibility of the models. It is
also unclear why certain design decisions are made, such as the ad-hoc loss
function, and whether these decisions have an impact on the learned
representations. We propose MelHuBERT, a simplified version of HuBERT that
takes Mel spectrograms as input, significantly reducing computation and memory
consumption. We study several aspects of training, including the loss function,
multi-stage training, and streaming options. Our result is a efficient yet
performant model that can be trained on a single GPU.</p>
  </details>
</details>
<details>
  <summary>60. <b>标题：Expert Selection in Distributed Gaussian Processes: A Multi-label  Classification Approach</b></summary>
  <p><b>编号</b>：[168]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.09940</p>
  <p><b>作者</b>：Hamed Jalali,  Gjergji Kasneci</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：standard Gaussian Process, Gaussian Process, local approximation reduces, training process, standard Gaussian</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>By distributing the training process, local approximation reduces the cost of
the standard Gaussian Process. An ensemble technique combines local predictions
from Gaussian experts trained on different partitions of the data by assuming a
perfect diversity of local predictors. Although it keeps the aggregation
tractable, this assumption is often violated in practice. Taking dependencies
between experts enables ensemble methods to provide consistent results.
However, they have a high computational cost, which is cubic in the number of
experts involved. By implementing an expert selection strategy, the final
aggregation step uses fewer experts and is more efficient. Indeed, a static
selection approach that assigns a fixed set of experts to each new data point
cannot encode the specific properties of each unique data point. This paper
proposes a flexible expert selection approach based on the characteristics of
entry data points. To this end, we investigate the selection task as a
multi-label classification problem where the experts define labels, and each
entry point is assigned to some experts. The proposed solution's prediction
quality, efficiency, and asymptotic properties are discussed in detail. We
demonstrate the efficacy of our method through extensive numerical experiments
using synthetic and real-world data sets.</p>
  </details>
</details>
<details>
  <summary>61. <b>标题：Explainability Via Causal Self-Talk</b></summary>
  <p><b>编号</b>：[170]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.09937</p>
  <p><b>作者</b>：Nicholas A. Roy,  Junkyung Kim,  Neil Rabinowitz</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：generally avoided, important problem, deep learning community, wider deep learning, deep learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Explaining the behavior of AI systems is an important problem that, in
practice, is generally avoided. While the XAI community has been developing an
abundance of techniques, most incur a set of costs that the wider deep learning
community has been unwilling to pay in most situations. We take a pragmatic
view of the issue, and define a set of desiderata that capture both the
ambitions of XAI and the practical constraints of deep learning. We describe an
effective way to satisfy all the desiderata: train the AI system to build a
causal model of itself. We develop an instance of this solution for Deep RL
agents: Causal Self-Talk. CST operates by training the agent to communicate
with itself across time. We implement this method in a simulated 3D
environment, and show how it enables agents to generate faithful and
semantically-meaningful explanations of their own behavior. Beyond
explanations, we also demonstrate that these learned models provide new ways of
building semantic control interfaces to AI systems.</p>
  </details>
</details>
<details>
  <summary>62. <b>标题：Planning with Large Language Models via Corrective Re-prompting</b></summary>
  <p><b>编号</b>：[171]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.09935</p>
  <p><b>作者</b>：Shreyas Sundara Raman,  Vanya Cohen,  Eric Rosen,  Ifrah Idrees,  David Paulius,  Stefanie Tellex</p>
  <p><b>备注</b>：21 pages, 7 figures, Accepted to Foundation Models for Decision Making Workshop at Neural Information Processing Systems 2022</p>
  <p><b>关键词</b>：Large Language Models, Language Models, Large Language, common sense knowledge, sense knowledge present</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Extracting the common sense knowledge present in Large Language Models (LLMs)
offers a path to designing intelligent, embodied agents. Related works have
queried LLMs with a wide-range of contextual information, such as goals, sensor
observations and scene descriptions, to generate high-level action plans for
specific tasks; however these approaches often involve human intervention or
additional machinery to enable sensor-motor interactions. In this work, we
propose a prompting-based strategy for extracting executable plans from an LLM,
which leverages a novel and readily-accessible source of information:
precondition errors. Our approach assumes that actions are only afforded
execution in certain contexts, i.e., implicit preconditions must be met for an
action to execute (e.g., a door must be unlocked to open it), and that the
embodied agent has the ability to determine if the action is/is not executable
in the current context (e.g., detect if a precondition error is present). When
an agent is unable to execute an action, our approach re-prompts the LLM with
precondition error information to extract an executable corrective action to
achieve the intended goal in the current context. We evaluate our approach in
the VirtualHome simulation environment on 88 different tasks and 7 scenes. We
evaluate different prompt templates and compare to methods that naively
re-sample actions from the LLM. Our approach, using precondition errors,
improves executability and semantic correctness of plans, while also reducing
the number of re-prompts required when querying actions.</p>
  </details>
</details>
<details>
  <summary>63. <b>标题：Contrastive Credibility Propagation for Reliable Semi-Supervised  Learning</b></summary>
  <p><b>编号</b>：[174]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.09929</p>
  <p><b>作者</b>：Brody Kutt,  Pamela Toman,  Xavier Mignot,  Sujit Rokka Chhetri,  Shan Huang,  Nandini Ramanan,  Min Du,  William Hewlett</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Inferencing unlabeled data, unlabeled data, labeled data, Inferencing unlabeled, data from labeled</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Inferencing unlabeled data from labeled data is an error-prone process.
Conventional neural network training is highly sensitive to supervision errors.
These two realities make semi-supervised learning (SSL) troublesome. Often, SSL
approaches fail to outperform their fully supervised baseline. Proposed is a
novel framework for deep SSL, specifically pseudo-labeling, called contrastive
credibility propagation (CCP). Through an iterative process of generating and
refining soft pseudo-labels, CCP unifies a novel contrastive approach to
generating pseudo-labels and a powerful technique to overcome instance-based
label noise. The result is a semi-supervised classification framework
explicitly designed to overcome inevitable pseudo-label errors in an attempt to
reliably boost performance over a supervised baseline. Our empirical evaluation
across five benchmark classification datasets suggests one must choose between
reliability or effectiveness with prior approaches while CCP delivers both. We
also demonstrate an unsupervised signal to subsample pseudo-labels to eliminate
errors between iterations of CCP and after its conclusion.</p>
  </details>
</details>
<details>
  <summary>64. <b>标题：SMS: Spiking Marching Scheme for Efficient Long Time Integration of  Differential Equations</b></summary>
  <p><b>编号</b>：[175]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.09928</p>
  <p><b>作者</b>：Qian Zhang,  Adar Kahana,  George Em Karniadakis,  Panos Stinis</p>
  <p><b>备注</b>：14 pages, 7 figures</p>
  <p><b>关键词</b>：Spiking Neural Network, Partial Differential, Spiking Neural, Ordinary and Partial, long time integration</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose a Spiking Neural Network (SNN)-based explicit numerical scheme for
long time integration of time-dependent Ordinary and Partial Differential
Equations (ODEs, PDEs). The core element of the method is a SNN, trained to use
spike-encoded information about the solution at previous timesteps to predict
spike-encoded information at the next timestep. After the network has been
trained, it operates as an explicit numerical scheme that can be used to
compute the solution at future timesteps, given a spike-encoded initial
condition. A decoder is used to transform the evolved spiking-encoded solution
back to function values. We present results from numerical experiments of using
the proposed method for ODEs and PDEs of varying complexity.</p>
  </details>
</details>
<details>
  <summary>65. <b>标题：FairMILE: A Multi-Level Framework for Fair and Scalable Graph  Representation Learning</b></summary>
  <p><b>编号</b>：[177]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.09925</p>
  <p><b>作者</b>：Yuntian He,  Saket Gurukar,  Srinivasan Parthasarathy</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：multiple high-stakes scenarios, high-stakes scenarios, deployed for making, making decisions, decisions in multiple</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Graph representation learning models have been deployed for making decisions
in multiple high-stakes scenarios. It is therefore critical to ensure that
these models are fair. Prior research has shown that graph neural networks can
inherit and reinforce the bias present in graph data. Researchers have begun to
examine ways to mitigate the bias in such models. However, existing efforts are
restricted by their inefficiency, limited applicability, and the constraints
they place on sensitive attributes. To address these issues, we present
FairMILE a general framework for fair and scalable graph representation
learning. FairMILE is a multi-level framework that allows contemporary
unsupervised graph embedding methods to scale to large graphs in an agnostic
manner. FairMILE learns both fair and high-quality node embeddings where the
fairness constraints are incorporated in each phase of the framework. Our
experiments across two distinct tasks demonstrate that FairMILE can learn node
representations that often achieve superior fairness scores and high downstream
performance while significantly outperforming all the baselines in terms of
efficiency.</p>
  </details>
</details>
<details>
  <summary>66. <b>标题：Online Distribution Shift Detection via Recency Prediction</b></summary>
  <p><b>编号</b>：[181]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.09916</p>
  <p><b>作者</b>：Rachel Luo,  Rohan Sinha,  Ali Hindy,  Shengjia Zhao,  Silvio Savarese,  Edward Schmerling,  Marco Pavone</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：deploying modern machine, modern machine learning-enabled, detecting distribution shift, machine learning-enabled robotic, distribution shift</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>When deploying modern machine learning-enabled robotic systems in high-stakes
applications, detecting distribution shift is critical. However, most existing
methods for detecting distribution shift are not well-suited to robotics
settings, where data often arrives in a streaming fashion and may be very
high-dimensional. In this work, we present an online method for detecting
distribution shift with guarantees on the false positive rate - i.e., when
there is no distribution shift, our system is very unlikely (with probability
$< \epsilon$) to falsely issue an alert; any alerts that are issued should
therefore be heeded. Our method is specifically designed for efficient
detection even with high dimensional data, and it empirically achieves up to
11x faster detection on realistic robotics settings compared to prior work
while maintaining a low false negative rate in practice (whenever there is a
distribution shift in our experiments, our method indeed emits an alert).</p>
  </details>
</details>
<details>
  <summary>67. <b>标题：Audio Anti-spoofing Using a Simple Attention Module and Joint  Optimization Based on Additive Angular Margin Loss and Meta-learning</b></summary>
  <p><b>编号</b>：[183]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.09898</p>
  <p><b>作者</b>：Zhenyu Wang,  John H.L. Hansen</p>
  <p><b>备注</b>：Interspeech 2022</p>
  <p><b>关键词</b>：Automatic speaker verification, speaker verification systems, effective spoofing detection, Automatic speaker, access threats</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Automatic speaker verification systems are vulnerable to a variety of access
threats, prompting research into the formulation of effective spoofing
detection systems to act as a gate to filter out such spoofing attacks. This
study introduces a simple attention module to infer 3-dim attention weights for
the feature map in a convolutional layer, which then optimizes an energy
function to determine each neuron's importance. With the advancement of both
voice conversion and speech synthesis technologies, unseen spoofing attacks are
constantly emerging to limit spoofing detection system performance. Here, we
propose a joint optimization approach based on the weighted additive angular
margin loss for binary classification, with a meta-learning training framework
to develop an efficient system that is robust to a wide range of spoofing
attacks for model generalization enhancement. As a result, when compared to
current state-of-the-art systems, our proposed approach delivers a competitive
result with a pooled EER of 0.99% and min t-DCF of 0.0289.</p>
  </details>
</details>
<details>
  <summary>68. <b>标题：Features Compression based on Counterfactual Analysis</b></summary>
  <p><b>编号</b>：[185]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.09894</p>
  <p><b>作者</b>：Veronica Piccialli,  Dolores Romero Morales,  Cecilia Salvatore</p>
  <p><b>备注</b>：29 pages, 12 figures</p>
  <p><b>关键词</b>：interpretable machine learning, post-hoc interpretable machine, counterfactual explanation corresponds, Counterfactual Explanations, leverage Counterfactual Explanations</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Counterfactual Explanations are becoming a de-facto standard in post-hoc
interpretable machine learning. For a given classifier and an instance
classified in an undesired class, its counterfactual explanation corresponds to
small perturbations of that instance that allow changing the classification
outcome. This work aims to leverage Counterfactual Explanations to detect the
important decision boundaries of a pre-trained black-box model. This
information is used to build a supervised discretization of the features in the
dataset with a tunable granularity. A small and interpretable Decision Tree is
trained on the discretized dataset that is stable and robust. Numerical results
on real-world datasets show the effectiveness of the approach.</p>
  </details>
</details>
<details>
  <summary>69. <b>标题：RenderDiffusion: Image Diffusion for 3D Reconstruction, Inpainting and  Generation</b></summary>
  <p><b>编号</b>：[188]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.09869</p>
  <p><b>作者</b>：Titas Anciukevičius,  Zexiang Xu,  Matthew Fisher,  Paul Henderson,  Hakan Bilen,  Niloy J. Mitra,  Paul Guerrero</p>
  <p><b>备注</b>：We will release our datasets, code, and checkpoints at this https URL</p>
  <p><b>关键词</b>：conditional and unconditional, unconditional image generation, Diffusion models, image diffusion models, Diffusion</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Diffusion models currently achieve state-of-the-art performance for both
conditional and unconditional image generation. However, so far, image
diffusion models do not support tasks required for 3D understanding, such as
view-consistent 3D generation or single-view object reconstruction. In this
paper, we present RenderDiffusion as the first diffusion model for 3D
generation and inference that can be trained using only monocular 2D
supervision. At the heart of our method is a novel image denoising architecture
that generates and renders an intermediate three-dimensional representation of
a scene in each denoising step. This enforces a strong inductive structure into
the diffusion process that gives us a 3D consistent representation while only
requiring 2D supervision. The resulting 3D representation can be rendered from
any viewpoint. We evaluate RenderDiffusion on ShapeNet and Clevr datasets and
show competitive performance for generation of 3D scenes and inference of 3D
scenes from 2D images. Additionally, our diffusion-based approach allows us to
use 2D inpainting to edit 3D scenes. We believe that our work promises to
enable full 3D generation at scale when trained on massive image collections,
thus circumventing the need to have large-scale 3D model collections for
supervision.</p>
  </details>
</details>
<details>
  <summary>70. <b>标题：Robust Vocal Quality Feature Embeddings for Dysphonic Voice Detection</b></summary>
  <p><b>编号</b>：[193]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.09858</p>
  <p><b>作者</b>：Jianwei Zhang,  Julie Liss,  Suren Jayasuriya,  Visar Berisha</p>
  <p><b>备注</b>：This manuscript is submitted on July 06, 2022 to IEEE/ACM Transactions on Audio, Speech, and Language Processing for peer-review</p>
  <p><b>关键词</b>：impaired voice production, world population, population has impaired, voice production, voice</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Approximately 1.2% of the world's population has impaired voice production.
As a result, automatic dysphonic voice detection has attracted considerable
academic and clinical interest. However, existing methods for automated voice
assessment often fail to generalize outside the training conditions or to other
related applications. In this paper, we propose a deep learning framework for
generating acoustic feature embeddings sensitive to vocal quality and robust
across different corpora. A contrastive loss is combined with a classification
loss to train our deep learning model jointly. Data warping methods are used on
input voice samples to improve the robustness of our method. Empirical results
demonstrate that our method not only achieves high in-corpus and cross-corpus
classification accuracy but also generates good embeddings sensitive to voice
quality and robust across different corpora. We also compare our results
against three baseline methods on clean and three variations of deteriorated
in-corpus and cross-corpus datasets and demonstrate that the proposed model
consistently outperforms the baseline methods.</p>
  </details>
</details>
<details>
  <summary>71. <b>标题：Machine Learning-Assisted Recurrence Prediction for Early-Stage  Non-Small-Cell Lung Cancer Patients</b></summary>
  <p><b>编号</b>：[194]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.09856</p>
  <p><b>作者</b>：Adrianna Janik,  Maria Torrente,  Luca Costabello,  Virginia Calvo,  Brian Walsh,  Carlos Camps,  Sameh K. Mohamed,  Ana L. Ortega,  Vít Nováček,  Bartomeu Massutí,  Pasquale Minervini,  M.Rosario Garcia Campelo,  Edel del Barco,  Joaquim Bosch-Barrera,  Ernestina Menasalvas,  Mohan Timilsina,  Mariano Provencio</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Stratifying cancer patients, Stratifying cancer, lung cancer, machine learning, cancer</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Background: Stratifying cancer patients according to risk of relapse can
personalize their care. In this work, we provide an answer to the following
research question: How to utilize machine learning to estimate probability of
relapse in early-stage non-small-cell lung cancer patients?
Methods: For predicting relapse in 1,387 early-stage (I-II), non-small-cell
lung cancer (NSCLC) patients from the Spanish Lung Cancer Group data (65.7
average age, 24.8% females, 75.2% males) we train tabular and graph machine
learning models. We generate automatic explanations for the predictions of such
models. For models trained on tabular data, we adopt SHAP local explanations to
gauge how each patient feature contributes to the predicted outcome. We explain
graph machine learning predictions with an example-based method that highlights
influential past patients. Results: Machine learning models trained on tabular
data exhibit a 76% accuracy for the Random Forest model at predicting relapse
evaluated with a 10-fold cross-validation (model was trained 10 times with
different independent sets of patients in test, train and validation sets, the
reported metrics are averaged over these 10 test sets). Graph machine learning
reaches 68% accuracy over a 200-patient, held-out test set, calibrated on a
held-out set of 100 patients. Conclusions: Our results show that machine
learning models trained on tabular and graph data can enable objective,
personalised and reproducible prediction of relapse and therefore, disease
outcome in patients with early-stage NSCLC. With further prospective and
multisite validation, and additional radiological and molecular data, this
prognostic model could potentially serve as a predictive decision support tool
for deciding the use of adjuvant treatments in early-stage lung cancer.
Keywords: Non-Small-Cell Lung Cancer, Tumor Recurrence Prediction, Machine
Learning</p>
  </details>
</details>
<details>
  <summary>72. <b>标题：CoLI-Machine Learning Approaches for Code-mixed Language Identification  at the Word Level in Kannada-English Texts</b></summary>
  <p><b>编号</b>：[197]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.09847</p>
  <p><b>作者</b>：H.L. Shashirekha,  F. Balouchzahi,  M.D. Anusha,  G. Sidorov</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：called Language Identification, Language Identification, learning, Identification, task of automatically</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The task of automatically identifying a language used in a given text is
called Language Identification (LI). India is a multilingual country and many
Indians especially youths are comfortable with Hindi and English, in addition
to their local languages. Hence, they often use more than one language to post
their comments on social media. Texts containing more than one language are
called "code-mixed texts" and are a good source of input for LI. Languages in
these texts may be mixed at sentence level, word level or even at sub-word
level. LI at word level is a sequence labeling problem where each and every
word in a sentence is tagged with one of the languages in the predefined set of
languages. In order to address word level LI in code-mixed Kannada-English
(Kn-En) texts, this work presents i) the construction of code-mixed Kn-En
dataset called CoLI-Kenglish dataset, ii) code-mixed Kn-En embedding and iii)
learning models using Machine Learning (ML), Deep Learning (DL) and Transfer
Learning (TL) approaches. Code-mixed Kn-En texts are extracted from Kannada
YouTube video comments to construct CoLI-Kenglish dataset and code-mixed Kn-En
embedding. The words in CoLI-Kenglish dataset are grouped into six major
categories, namely, "Kannada", "English", "Mixed-language", "Name", "Location"
and "Other". The learning models, namely, CoLI-vectors and CoLI-ngrams based on
ML, CoLI-BiLSTM based on DL and CoLI-ULMFiT based on TL approaches are built
and evaluated using CoLI-Kenglish dataset. The performances of the learning
models illustrated, the superiority of CoLI-ngrams model, compared to other
models with a macro average F1-score of 0.64. However, the results of all the
learning models were quite competitive with each other.</p>
  </details>
</details>
<details>
  <summary>73. <b>标题：Latent User Intent Modeling for Sequential Recommenders</b></summary>
  <p><b>编号</b>：[198]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.09832</p>
  <p><b>作者</b>：Bo Chang,  Alexandros Karatzoglou,  Yuyan Wang,  Can Xu,  Ed H. Chi,  Minmin Chen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：essential components, components of modern, industrial recommender systems, Sequential recommender models, user</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Sequential recommender models are essential components of modern industrial
recommender systems. These models learn to predict the next items a user is
likely to interact with based on his/her interaction history on the platform.
Most sequential recommenders however lack a higher-level understanding of user
intents, which often drive user behaviors online. Intent modeling is thus
critical for understanding users and optimizing long-term user experience. We
propose a probabilistic modeling approach and formulate user intent as latent
variables, which are inferred based on user behavior signals using variational
autoencoders (VAE). The recommendation policy is then adjusted accordingly
given the inferred user intent. We demonstrate the effectiveness of the latent
user intent modeling via offline analyses as well as live experiments on a
large-scale industrial recommendation platform.</p>
  </details>
</details>
<details>
  <summary>74. <b>标题：Deep learning for Lagrangian drift simulation at the sea surface</b></summary>
  <p><b>编号</b>：[199]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.09818</p>
  <p><b>作者</b>：Daria Botvynko (Lab-STICC\_OSE, IMT Atlantique - MEE, ENIB),  Carlos Granero-Belinchon,  Simon Van Gennip,  Abdesslam Benzinou (ENIB),  Ronan Fablet</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：deep learning approaches, model-based and Markovian, Lagrangian drift simulation, address Lagrangian drift, Markovian approaches</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We address Lagrangian drift simulation in geophysical dynamics and explore
deep learning approaches to overcome known limitations of state-of-the-art
model-based and Markovian approaches in terms of computational complexity and
error propagation. We introduce a novel architecture, referred to as DriftNet,
inspired from the Eulerian Fokker-Planck representation of Lagrangian dynamics.
Numerical experiments for Lagrangian drift simulation at the sea surface
demonstrates the relevance of DriftNet w.r.t. state-of-the-art schemes.
Benefiting from the fully-convolutional nature of Drift-Net, we explore through
a neural inversion how to diagnose modelderived velocities w.r.t. real drifter
trajectories.</p>
  </details>
</details>
<details>
  <summary>75. <b>标题：On the Effect of Pre-training for Transformer in Different Modality on  Offline Reinforcement Learning</b></summary>
  <p><b>编号</b>：[200]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.09817</p>
  <p><b>作者</b>：Shiro Takagi</p>
  <p><b>备注</b>：48 pages. Published in NeurIPS 2022</p>
  <p><b>关键词</b>：Transformer-based models, empirically investigate, pre-trained Transformers, pre-trained Transformers reveals, fine-tuning of Transformer-based</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We empirically investigate how pre-training on data of different modalities,
such as language and vision, affects fine-tuning of Transformer-based models to
Mujoco offline reinforcement learning tasks. Analysis of the internal
representation reveals that the pre-trained Transformers acquire largely
different representations before and after pre-training, but acquire less
information of data in fine-tuning than the randomly initialized one. A closer
look at the parameter changes of the pre-trained Transformers reveals that
their parameters do not change that much and that the bad performance of the
model pre-trained with image data could partially come from large gradients and
gradient clipping. To study what information the Transformer pre-trained with
language data utilizes, we fine-tune this model with no context provided,
finding that the model learns efficiently even without context information.
Subsequent follow-up analysis supports the hypothesis that pre-training with
language data is likely to make the Transformer get context-like information
and utilize it to solve the downstream task.</p>
  </details>
</details>
<details>
  <summary>76. <b>标题：Data-driven Real-time Short-term Prediction of Air Quality: Comparison  of ES, ARIMA, and LSTM</b></summary>
  <p><b>编号</b>：[201]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.09814</p>
  <p><b>作者</b>：Iryna Talamanova,  Sabri Pllana</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：urban areas, worldwide issue, issue that affects, affects the lives, Air pollution</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Air pollution is a worldwide issue that affects the lives of many people in
urban areas. It is considered that the air pollution may lead to heart and lung
diseases. A careful and timely forecast of the air quality could help to reduce
the exposure risk for affected people. In this paper, we use a data-driven
approach to predict air quality based on historical data. We compare three
popular methods for time series prediction: Exponential Smoothing (ES),
Auto-Regressive Integrated Moving Average (ARIMA) and Long short-term memory
(LSTM). Considering prediction accuracy and time complexity, our experiments
reveal that for short-term air pollution prediction ES performs better than
ARIMA and LSTM.</p>
  </details>
</details>
<details>
  <summary>77. <b>标题：Hierarchical Estimation for Effective and Efficient Sampling Graph  Neural Network</b></summary>
  <p><b>编号</b>：[202]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.09813</p>
  <p><b>作者</b>：Yang Li,  Bingbing Xu,  Qi Cao,  Yige Yuan,  Huawei Shen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：critical for large, sampling, node embeddings, node, variance</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Improving the scalability of GNNs is critical for large graphs. Existing
methods leverage three sampling paradigms including node-wise, layer-wise and
subgraph sampling, then design unbiased estimator for scalability. However, the
high variance still severely hinders GNNs' performance. On account that
previous studies either lacks variance analysis or only focus on a particular
sampling paradigm, we firstly propose an unified node sampling variance
analysis framework and analyze the core challenge "circular dependency" for
deriving the minimum variance sampler, i. e., sampling probability depends on
node embeddings while node embeddings can not be calculated until sampling is
finished. Existing studies either ignore the node embeddings or introduce
external parameters, resulting in the lack of a both efficient and effective
variance reduction methods. Therefore, we propose the \textbf{H}ierarchical
\textbf{E}stimation based \textbf{S}ampling GNN (HE-SGNN) with first level
estimating the node embeddings in sampling probability to break circular
dependency, and second level employing sampling GNN operator to estimate the
nodes' representations on the entire graph. Considering the technical
difference, we propose different first level estimator, i.e., a time series
simulation for layer-wise sampling and a feature based simulation for subgraph
sampling. The experimental results on seven representative datasets demonstrate
the effectiveness and efficiency of our method.</p>
  </details>
</details>
<details>
  <summary>78. <b>标题：GAMMT: Generative Ambiguity Modeling Using Multiple Transformers</b></summary>
  <p><b>编号</b>：[203]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.09812</p>
  <p><b>作者</b>：Xingcheng Xu</p>
  <p><b>备注</b>：10 pages, 2 figures, 3 algorithms</p>
  <p><b>关键词</b>：model based, Generative Ambiguity Models, sequential data, model, model GAMMT</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We introduce a new model based on sets of probabilities for sequential data.
We name the model GAMMT, which stands for Generative Ambiguity Models using
Multiple Transformers. We suppose that data generating process of a sequence is
ambiguous and determined by a set of probabilities rather than one as in the
conventional model. We use multiple parallel transformers connected by a
selection mechanism to approximate ambiguous probabilities. The GAMMT allows
for ambiguity modeling in a generative way and multiple representations of the
input tokens and the input sequence. This work explores the combination of
attention mechanism and ambiguity by deep neural networks. We expect that this
framework will facilitate new research into machine learning, improving our
understanding of the attention-ambiguity mechanism.</p>
  </details>
</details>
<details>
  <summary>79. <b>标题：Certifying Robustness of Convolutional Neural Networks with Tight Linear  Approximation</b></summary>
  <p><b>编号</b>：[204]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.09810</p>
  <p><b>作者</b>：Yuan Xiao,  Tongtong Bai,  Mingzheng Gu,  Chunrong Fang,  Zhenyu Chen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：neural network classifiers, Convolutional Neural Networks, safety-critical domain, robustness, Neuron-wise Tightest</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The robustness of neural network classifiers is becoming important in the
safety-critical domain and can be quantified by robustness verification.
However, at present, efficient and scalable verification techniques are always
sound but incomplete. Therefore, the improvement of certified robustness bounds
is the key criterion to evaluate the superiority of robustness verification
approaches. In this paper, we present a Tight Linear approximation approach for
robustness verification of Convolutional Neural Networks(Ti-Lin). For general
CNNs, we first provide a new linear constraints for S-shaped activation
functions, which is better than both existing Neuron-wise Tightest and
Network-wise Tightest tools. We then propose Neuron-wise Tightest linear bounds
for Maxpool function. We implement Ti-Lin, the resulting verification method.
We evaluate it with 48 different CNNs trained on MNIST, CIFAR-10, and Tiny
ImageNet datasets. Experimental results show that Ti-Lin significantly
outperforms other five state-of-the-art methods(CNN-Cert, DeepPoly, DeepCert,
VeriNet, Newise). Concretely, Ti-Lin certifies much more precise robustness
bounds on pure CNNs with Sigmoid/Tanh/Arctan functions and CNNs with Maxpooling
function with at most 63.70% and 253.54% improvement, respectively.</p>
  </details>
</details>
<details>
  <summary>80. <b>标题：Improving ECG-based COVID-19 diagnosis and mortality predictions using  pre-pandemic medical records at population-scale</b></summary>
  <p><b>编号</b>：[205]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10431</p>
  <p><b>作者</b>：Weijie Sun,  Sunil Vasu Kalmady,  Nariman Sepehrvan,  Luan Manh Chu,  Zihan Wang,  Amir Salimi,  Abram Hindle,  Russell Greiner,  Padma Kaul</p>
  <p><b>备注</b>：Accepted for NeurIPS 2022 TS4H workshop</p>
  <p><b>关键词</b>：potential devastating consequences, occur unexpectedly, action due, potential devastating, devastating consequences</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Pandemic outbreaks such as COVID-19 occur unexpectedly, and need immediate
action due to their potential devastating consequences on global health.
Point-of-care routine assessments such as electrocardiogram (ECG), can be used
to develop prediction models for identifying individuals at risk. However,
there is often too little clinically-annotated medical data, especially in
early phases of a pandemic, to develop accurate prediction models. In such
situations, historical pre-pandemic health records can be utilized to estimate
a preliminary model, which can then be fine-tuned based on limited available
pandemic data. This study shows this approach -- pre-train deep learning models
with pre-pandemic data -- can work effectively, by demonstrating substantial
performance improvement over three different COVID-19 related diagnostic and
prognostic prediction tasks. Similar transfer learning strategies can be useful
for developing timely artificial intelligence solutions in future pandemic
outbreaks.</p>
  </details>
</details>
<details>
  <summary>81. <b>标题：Forecasting labels under distribution-shift for machine-guided sequence  design</b></summary>
  <p><b>编号</b>：[206]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10422</p>
  <p><b>作者</b>：Lauren Berk Wheelock,  Stephen Malina,  Jeffrey Gerold,  Sam Sinai</p>
  <p><b>备注</b>：15 pages, 3 figures, to appear in MLCB-PMLR proceedings, oral presentation at MLCB 2022 and LMLR 2022</p>
  <p><b>关键词</b>：optimize biological sequences, technology and healthcare, optimize biological, specific functionalities, functionalities would unlock</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The ability to design and optimize biological sequences with specific
functionalities would unlock enormous value in technology and healthcare. In
recent years, machine learning-guided sequence design has progressed this goal
significantly, though validating designed sequences in the lab or clinic takes
many months and substantial labor. It is therefore valuable to assess the
likelihood that a designed set contains sequences of the desired quality (which
often lies outside the label distribution in our training data) before
committing resources to an experiment. Forecasting, a prominent concept in many
domains where feedback can be delayed (e.g. elections), has not been used or
studied in the context of sequence design. Here we propose a method to guide
decision-making that forecasts the performance of high-throughput libraries
(e.g. containing $10^5$ unique variants) based on estimates provided by models,
providing a posterior for the distribution of labels in the library. We show
that our method outperforms baselines that naively use model scores to estimate
library performance, which are the only tool available today for this purpose.</p>
  </details>
</details>
<details>
  <summary>82. <b>标题：A Neural Active Inference Model of Perceptual-Motor Learning</b></summary>
  <p><b>编号</b>：[207]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10419</p>
  <p><b>作者</b>：Zhizhuo Yang,  Gabriel J. Diaz,  Brett R. Fajen,  Reynold Bailey,  Alexander Ororbia</p>
  <p><b>备注</b>：16 pages including references, 6 figures. Submitted to Frontiers in Computational Neuroscience</p>
  <p><b>关键词</b>：active inference framework, computational framework grounded, produce human-like behavior, inference framework, computational framework</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The active inference framework (AIF) is a promising new computational
framework grounded in contemporary neuroscience that can produce human-like
behavior through reward-based learning. In this study, we test the ability for
the AIF to capture the role of anticipation in the visual guidance of action in
humans through the systematic investigation of a visual-motor task that has
been well-explored -- that of intercepting a target moving over a ground plane.
Previous research demonstrated that humans performing this task resorted to
anticipatory changes in speed intended to compensate for semi-predictable
changes in target speed later in the approach. To capture this behavior, our
proposed "neural" AIF agent uses artificial neural networks to select actions
on the basis of a very short term prediction of the information about the task
environment that these actions would reveal along with a long-term estimate of
the resulting cumulative expected free energy. Systematic variation revealed
that anticipatory behavior emerged only when required by limitations on the
agent's movement capabilities, and only when the agent was able to estimate
accumulated free energy over sufficiently long durations into the future. In
addition, we present a novel formulation of the prior function that maps a
multi-dimensional world-state to a uni-dimensional distribution of free-energy.
Together, these results demonstrate the use of AIF as a plausible model of
anticipatory visually guided behavior in humans.</p>
  </details>
</details>
<details>
  <summary>83. <b>标题：Sample-efficient Quantum Born Machine through Coding Rate Reduction</b></summary>
  <p><b>编号</b>：[208]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10418</p>
  <p><b>作者</b>：Pengyuan Zhai</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：circuit Born machine, physics inspired implicit, inspired implicit generative, Born machine, modeling discrete distributions</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The quantum circuit Born machine (QCBM) is a quantum physics inspired
implicit generative model naturally suitable for learning binary images, with a
potential advantage of modeling discrete distributions that are hard to
simulate classically. As data samples are generated quantum-mechanically, QCBMs
encompass a unique optimization landscape. However, pioneering works on QCBMs
do not consider the practical scenario where only small batch sizes are allowed
during training. QCBMs trained with a statistical two-sample test objective in
the image space require large amounts of projective measurements to approximate
the model distribution well, unpractical for large-scale quantum systems due to
the exponential scaling of the probability space. QCBMs trained adversarially
against a deep neural network discriminator are proof-of-concept models that
face mode collapse. In this work we investigate practical learning of QCBMs. We
use the information-theoretic \textit{Maximal Coding Rate Reduction} (MCR$^2$)
metric as a second moment matching tool and study its effect on mode collapse
in QCBMs. We compute the sampling based gradient of MCR$^2$ with respect to
quantum circuit parameters with or without an explicit feature mapping. We
experimentally show that matching up to the second moment alone is not
sufficient for training the quantum generator, but when combined with the class
probability estimation loss, MCR$^2$ is able to resist mode collapse. In
addition, we show that adversarially trained neural network kernel for infinite
moment matching is also effective against mode collapse. On the Bars and
Stripes dataset, our proposed techniques alleviate mode collapse to a larger
degree than previous QCBM training schemes, moving one step closer towards
practicality and scalability.</p>
  </details>
</details>
<details>
  <summary>84. <b>标题：Patch-Based Denoising Diffusion Probabilistic Model for Sparse-View CT  Reconstruction</b></summary>
  <p><b>编号</b>：[211]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10388</p>
  <p><b>作者</b>：Wenjun Xia,  Wenxiang Cong,  Ge Wang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：reduce radiation dose, radiation dose greatly, Sparse-view computed tomography, computed tomography, reduce radiation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Sparse-view computed tomography (CT) can be used to reduce radiation dose
greatly but is suffers from severe image artifacts. Recently, the deep learning
based method for sparse-view CT reconstruction has attracted a major attention.
However, neural networks often have a limited ability to remove the artifacts
when they only work in the image domain. Deep learning-based sinogram
processing can achieve a better anti-artifact performance, but it inevitably
requires feature maps of the whole image in a video memory, which makes
handling large-scale or three-dimensional (3D) images rather challenging. In
this paper, we propose a patch-based denoising diffusion probabilistic model
(DDPM) for sparse-view CT reconstruction. A DDPM network based on patches
extracted from fully sampled projection data is trained and then used to
inpaint down-sampled projection data. The network does not require paired
full-sampled and down-sampled data, enabling unsupervised learning. Since the
data processing is patch-based, the deep learning workflow can be distributed
in parallel, overcoming the memory problem of large-scale data. Our experiments
show that the proposed method can effectively suppress few-view artifacts while
faithfully preserving textural details.</p>
  </details>
</details>
<details>
  <summary>85. <b>标题：Active Learning with Convolutional Gaussian Neural Processes for  Environmental Sensor Placement</b></summary>
  <p><b>编号</b>：[212]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10381</p>
  <p><b>作者</b>：Tom R. Andersson,  Wessel P. Bruinsma,  Stratis Markou,  Daniel C. Jones,  J. Scott Hosking,  James Requeima,  Alejandro Coca-Castro,  Anna Vaughan,  Anna-Louise Ellis,  Matthew Lazzara,  Richard E. Turner</p>
  <p><b>备注</b>：Accepted to the NeurIPS 2022 Workshop on Gaussian Processes, Spatiotemporal Modeling, and Decision-making Systems</p>
  <p><b>关键词</b>：time consuming procedure, Deploying environmental measurement, environmental measurement stations, consuming procedure, costly and time</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deploying environmental measurement stations can be a costly and time
consuming procedure, especially in regions which are remote or otherwise
difficult to access, such as Antarctica. Therefore, it is crucial that sensors
are placed as efficiently as possible, maximising the informativeness of their
measurements. Previous approaches for identifying salient placement locations
typically model the data with a Gaussian process (GP). However, designing a GP
covariance which captures the complex behaviour of non-stationary
spatiotemporal data is a difficult task. Further, the computational cost of
these models make them challenging to scale to large environmental datasets. In
this work, we explore using convolutional Gaussian neural processes (ConvGNPs)
to address these issues. A ConvGNP is a meta-learning model which uses a neural
network to parameterise a GP predictive. Our model is data-driven, flexible,
efficient, and permits gridded or off-grid input data. Using simulated surface
temperature fields over Antarctica as ground truth, we show that a ConvGNP
substantially outperforms a non-stationary GP baseline in terms of predictive
performance. We then use the ConvGNP in a temperature sensor placement toy
experiment, yielding promising results.</p>
  </details>
</details>
<details>
  <summary>86. <b>标题：Arbitrarily Accurate Classification Applied to Specific Emitter  Identification</b></summary>
  <p><b>编号</b>：[213]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10379</p>
  <p><b>作者</b>：Michael C. Kleder</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：obtaining arbitrary accuracy, article introduces, introduces a method, method of evaluating, obtaining arbitrary</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This article introduces a method of evaluating subsamples until any
prescribed level of classification accuracy is attained, thus obtaining
arbitrary accuracy. A logarithmic reduction in error rate is obtained with a
linear increase in sample count. The technique is applied to specific emitter
identification on a published dataset of physically recorded over-the-air
signals from 16 ostensibly identical high-performance radios. The technique
uses a multi-channel deep learning convolutional neural network acting on the
bispectra of I/Q signal subsamples each consisting of 56 parts per million
(ppm) of the original signal duration. High levels of accuracy are obtained
with minimal computation time: in this application, each addition of eight
samples decreases error by one order of magnitude.</p>
  </details>
</details>
<details>
  <summary>87. <b>标题：Heterogeneous Hidden Markov Models for Sleep Activity Recognition from  Multi-Source Passively Sensed Data</b></summary>
  <p><b>编号</b>：[214]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10371</p>
  <p><b>作者</b>：Fernando Moreno-Pino,  María Martínez-García,  Pablo M. Olmos,  Antonio Artés-Rodríguez</p>
  <p><b>备注</b>：Extended Abstract presented at Machine Learning for Health (ML4H) symposium 2022, November 28th, 2022, New Orleans, United States & Virtual, this http URL, 10 pages (6 pages + 4 pages of references and appendices)</p>
  <p><b>关键词</b>：passive activity monitoring, Psychiatric patients' passive, clinicians supervise patients', supervise patients' evolution, patients' passive activity</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Psychiatric patients' passive activity monitoring is crucial to detect
behavioural shifts in real-time, comprising a tool that helps clinicians
supervise patients' evolution over time and enhance the associated treatments'
outcomes. Frequently, sleep disturbances and mental health deterioration are
closely related, as mental health condition worsening regularly entails shifts
in the patients' circadian rhythms. Therefore, Sleep Activity Recognition
constitutes a behavioural marker to portray patients' activity cycles and to
detect behavioural changes among them. Moreover, mobile passively sensed data
captured from smartphones, thanks to these devices' ubiquity, constitute an
excellent alternative to profile patients' biorhythm.
In this work, we aim to identify major sleep episodes based on passively
sensed data. To do so, a Heterogeneous Hidden Markov Model is proposed to model
a discrete latent variable process associated with the Sleep Activity
Recognition task in a self-supervised way. We validate our results against
sleep metrics reported by clinically tested wearables, proving the
effectiveness of the proposed approach.</p>
  </details>
</details>
<details>
  <summary>88. <b>标题：Always Valid Risk Monitoring for Online Matrix Completion</b></summary>
  <p><b>编号</b>：[215]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10363</p>
  <p><b>作者</b>：Chi-Hua Wang,  Wenjie Li</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：inequalities are increasingly, performance measures, generative models, models and supervised, statistical learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Always-valid concentration inequalities are increasingly used as performance
measures for online statistical learning, notably in the learning of generative
models and supervised learning. Such inequality advances the online learning
algorithms design by allowing random, adaptively chosen sample sizes instead of
a fixed pre-specified size in offline statistical learning. However,
establishing such an always-valid type result for the task of matrix completion
is challenging and far from understood in the literature. Due to the importance
of such type of result, this work establishes and devises the always-valid risk
bound process for online matrix completion problems. Such theoretical advances
are made possible by a novel combination of non-asymptotic martingale
concentration and regularized low-rank matrix regression. Our result enables a
more sample-efficient online algorithm design and serves as a foundation to
evaluate online experiment policies on the task of online matrix completion.</p>
  </details>
</details>
<details>
  <summary>89. <b>标题：CRONOS: Colorization and Contrastive Learning Enhanced NLoS Human  Presence Detection using Wi-Fi CSI Signals</b></summary>
  <p><b>编号</b>：[217]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10354</p>
  <p><b>作者</b>：Li-Hsiang Shen,  Chia-Che Hsieh,  An-Hung Hsiao,  Kai-Ten Feng</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：applications increase explosively, pervasive smart services, recent years, demands of pervasive, increase explosively</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In recent years, demands of pervasive smart services and applications
increase explosively. Device-free human detection through sensors or cameras
has been widely adopted but with privacy issues as well as misdetection for
motionless people. To resolve these defects, channel state information (CSI)
captured from commercialized Wi-Fi devices is capable of providing plentiful
signal features for accurate detection. The existing systems has inaccurate
classification under a non-line-of-sight (NLoS) and stationery scenario of a
person standing still at corner in a room. In this work, we have proposed a
colorization and contrastive learning enhanced NLoS human presence detection
(CRONOS) system. CRONOS is capable of generating dynamic recurrence plots (RPs)
and coloring CSI ratios to distinguish mobile people and vacancy of a room,
respectively. Furthermore, supervised contrastive learning is conceived to
retrieve substantial representations, where consultation loss is formulated to
differentiate the representative distances between dynamic and stationery
cases. Furthermore, a self-switched static feature enhanced classifier (S3FEC)
is proposed to determine the utilization of either RPs or coloring CSI ratio.
Finally, comprehensive experimental results have revealed that our proposed
CRONOS outperforms the existing systems applying machine learning, non-learning
based methods as well as non-CSI based features in open literature, which
achieves the highest presence detection accuracy and moderate computational
complexity in vacancy, mobility, LoS and NLoS scenarios.</p>
  </details>
</details>
<details>
  <summary>90. <b>标题：Towards Fast Single-Trial Online ERP based Brain-Computer Interface  using dry EEG electrodes and neural networks: a pilot study</b></summary>
  <p><b>编号</b>：[218]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10352</p>
  <p><b>作者</b>：Okba Bekhelifi,  Nasr-Eddine Berrached</p>
  <p><b>备注</b>：24 pages, 9 figures</p>
  <p><b>关键词</b>：ERP based BCIs, spelling in event-related, event-related potentials, evoked potentials remains, potentials remains challenging</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Speeding up the spelling in event-related potentials (ERP) based
Brain-Computer Interfaces (BCI) requires eliciting strong brain responses in a
short span of time, as much as the accurate classification of such evoked
potentials remains challenging and imposes hard constraints for signal
processing and machine learning techniques. Recent advances in stimulus
presentation and deep learning showcased a promising direction in significantly
improving the efficacy of those systems, in this study we propose the
combination of colored inverted face stimulation with classification using
convolutional neural networks in the hard settings of dry electrodes and fast
flashing single-trial ERP-based BCI. The high online accuracy achieved, with
two subjects passing the 90 percent correct symbol detection bar and a transfer
rate above 60 bits per minute, demonstrates the approach potential in improving
the practicality of ERP based BCIs.</p>
  </details>
</details>
<details>
  <summary>91. <b>标题：Deep learning for structural health monitoring: An application to  heritage structures</b></summary>
  <p><b>编号</b>：[219]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10351</p>
  <p><b>作者</b>：Fabio Carrara,  Fabrizio Falchi,  Maria Girardi,  Nicola Messina,  Cristina Padovani,  Daniele Pellegrini</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：seismic ambient noise, numerical methods, seismic ambient, advancements in numerical, ambient noise</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Thanks to recent advancements in numerical methods, computer power, and
monitoring technology, seismic ambient noise provides precious information
about the structural behavior of old buildings. The measurement of the
vibrations produced by anthropic and environmental sources and their use for
dynamic identification and structural health monitoring of buildings initiated
an emerging, cross-disciplinary field engaging seismologists, engineers,
mathematicians, and computer scientists. In this work, we employ recent deep
learning techniques for time-series forecasting to inspect and detect anomalies
in the large dataset recorded during a long-term monitoring campaign conducted
on the San Frediano bell tower in Lucca. We frame the problem as an
unsupervised anomaly detection task and train a Temporal Fusion Transformer to
learn the normal dynamics of the structure. We then detect the anomalies by
looking at the differences between the predicted and observed frequencies.</p>
  </details>
</details>
<details>
  <summary>92. <b>标题：Large Scale Radio Frequency Wideband Signal Detection & Recognition</b></summary>
  <p><b>编号</b>：[220]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10335</p>
  <p><b>作者</b>：Luke Boegner,  Garrett Vanhoy,  Phillip Vallance,  Manbir Gulati,  Dresden Feitzinger,  Bradley Comar,  Robert D. Miller</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：narrowband signal classification, Applications of deep, domain have largely, largely concentrated, detected and extracted</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Applications of deep learning to the radio frequency (RF) domain have largely
concentrated on the task of narrowband signal classification after the signals
of interest have already been detected and extracted from a wideband capture.
To encourage broader research with wideband operations, we introduce the
WidebandSig53 (WBSig53) dataset which consists of 550 thousand
synthetically-generated samples from 53 different signal classes containing
approximately 2 million unique signals. We extend the TorchSig signal
processing machine learning toolkit for open-source and customizable
generation, augmentation, and processing of the WBSig53 dataset. We conduct
experiments using state of the art (SoTA) convolutional neural networks and
transformers with the WBSig53 dataset. We investigate the performance of signal
detection tasks, i.e. detect the presence, time, and frequency of all signals
present in the input data, as well as the performance of signal recognition
tasks, where networks detect the presence, time, frequency, and modulation
family of all signals present in the input data. Two main approaches to these
tasks are evaluated with segmentation networks and object detection networks
operating on complex input spectrograms. Finally, we conduct comparative
analysis of the various approaches in terms of the networks' mean average
precision, mean average recall, and the speed of inference.</p>
  </details>
</details>
<details>
  <summary>93. <b>标题：Neural Inference of Gaussian Processes for Time Series Data of Quasars</b></summary>
  <p><b>编号</b>：[222]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10305</p>
  <p><b>作者</b>：Egor Danilov,  Aleksandra Ćiprijanović,  Brian Nord</p>
  <p><b>备注</b>：Machine Learning and the Physical Sciences workshop, NeurIPS 2022</p>
  <p><b>关键词</b>：irregularly sampled time, sampled time series, time series, Damped Random Walk, Convolved Damped Random</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The study of quasar light curves poses two problems: inference of the power
spectrum and interpolation of an irregularly sampled time series. A baseline
approach to these tasks is to interpolate a time series with a Damped Random
Walk (DRW) model, in which the spectrum is inferred using Maximum Likelihood
Estimation (MLE). However, the DRW model does not describe the smoothness of
the time series, and MLE faces many problems in terms of optimization and
numerical precision. In this work, we introduce a new stochastic model that we
call $\textit{Convolved Damped Random Walk}$ (CDRW). This model introduces a
concept of smoothness to a DRW, which enables it to describe quasar spectra
completely. We also introduce a new method of inference of Gaussian process
parameters, which we call $\textit{Neural Inference}$. This method uses the
powers of state-of-the-art neural networks to improve the conventional MLE
inference technique. In our experiments, the Neural Inference method results in
significant improvement over the baseline MLE (RMSE: $0.318 \rightarrow 0.205$,
$0.464 \rightarrow 0.444$). Moreover, the combination of both the CDRW model
and Neural Inference significantly outperforms the baseline DRW and MLE in
interpolating a typical quasar light curve ($\chi^2$: $0.333 \rightarrow
0.998$, $2.695 \rightarrow 0.981$). The code is published on GitHub.</p>
  </details>
</details>
<details>
  <summary>94. <b>标题：On the Evaluation of Generative Models in High Energy Physics</b></summary>
  <p><b>编号</b>：[223]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10295</p>
  <p><b>作者</b>：Raghav Kansal,  Anni Li,  Javier Duarte,  Nadezda Chernyavskaya,  Maurizio Pierini,  Breno Orzari,  Thiago Tomei</p>
  <p><b>备注</b>：11 pages, 5 figures, 3 tables, and a 3 page appenidx</p>
  <p><b>关键词</b>：tackle computational challenges, recent explosion, explosion in research, modeling to tackle, tackle computational</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>There has been a recent explosion in research into machine-learning-based
generative modeling to tackle computational challenges for simulations in high
energy physics (HEP). In order to use such alternative simulators in practice,
we need well defined metrics to compare different generative models and
evaluate their discrepancy from the true distributions. We present the first
systematic review and investigation into evaluation metrics and their
sensitivity to failure modes of generative models, using the framework of
two-sample goodness-of-fit testing, and their relevance and viability for HEP.
Inspired by previous work in both physics and computer vision, we propose two
new metrics, the Fréchet and kernel physics distances (FPD and KPD), and
perform a variety of experiments measuring their performance on simple
Gaussian-distributed, and simulated high energy jet datasets. We find FPD, in
particular, to be the most sensitive metric to all alternative jet
distributions tested and recommend its adoption, along with the KPD and
Wasserstein distances between individual feature distributions, for evaluating
generative models in HEP. We finally demonstrate the efficacy of these proposed
metrics in evaluating and comparing a novel attention-based generative
adversarial particle transformer to the state-of-the-art message-passing
generative adversarial network jet simulation model.</p>
  </details>
</details>
<details>
  <summary>95. <b>标题：Joint nnU-Net and Radiomics Approaches for Segmentation and Prognosis of  Head and Neck Cancers with PET/CT images</b></summary>
  <p><b>编号</b>：[228]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10138</p>
  <p><b>作者</b>：Hui Xu,  Yihao Li,  Wei Zhao,  Gwenolé Quellec,  Lijun Lu,  Mathieu Hatt</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：optimization treatment strategy, Automatic segmentation, neck cancer, head and neck, plays a crucial</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Automatic segmentation of head and neck cancer (HNC) tumors and lymph nodes
plays a crucial role in the optimization treatment strategy and prognosis
analysis. This study aims to employ nnU-Net for automatic segmentation and
radiomics for recurrence-free survival (RFS) prediction using pretreatment
PET/CT images in multi-center HNC cohort. A multi-center HNC dataset with 883
patients (524 patients for training, 359 for testing) was provided in HECKTOR
2022. A bounding box of the extended oropharyngeal region was retrieved for
each patient with fixed size of 224 x 224 x 224 $mm^{3}$. Then 3D nnU-Net
architecture was adopted to automatic segmentation of primary tumor and lymph
nodes synchronously.Based on predicted segmentation, ten conventional features
and 346 standardized radiomics features were extracted for each patient. Three
prognostic models were constructed containing conventional and radiomics
features alone, and their combinations by multivariate CoxPH modelling. The
statistical harmonization method, ComBat, was explored towards reducing
multicenter variations. Dice score and C-index were used as evaluation metrics
for segmentation and prognosis task, respectively. For segmentation task, we
achieved mean dice score around 0.701 for primary tumor and lymph nodes by 3D
nnU-Net. For prognostic task, conventional and radiomics models obtained the
C-index of 0.658 and 0.645 in the test set, respectively, while the combined
model did not improve the prognostic performance with the C-index of 0.648.</p>
  </details>
</details>
<details>
  <summary>96. <b>标题：Global quantitative robustness of regression feed-forward neural  networks</b></summary>
  <p><b>编号</b>：[229]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10124</p>
  <p><b>作者</b>：Tino Werner</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：complex learning tasks, indispensable model class, Neural networks, learning tasks, neural network training</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Neural networks are an indispensable model class for many complex learning
tasks. Despite the popularity and importance of neural networks and many
different established techniques from literature for stabilization and
robustification of the training, the classical concepts from robust statistics
have rarely been considered so far in the context of neural networks.
Therefore, we adapt the notion of the regression breakdown point to regression
neural networks and compute the breakdown point for different feed-forward
network configurations and contamination settings. In an extensive simulation
study, we compare the performance, measured by the out-of-sample loss, by a
proxy of the breakdown rate and by the training steps, of non-robust and robust
regression feed-forward neural networks in a plethora of different
configurations. The results indeed motivate to use robust loss functions for
neural network training.</p>
  </details>
</details>
<details>
  <summary>97. <b>标题：Data-Adaptive Discriminative Feature Localization with Statistically  Guaranteed Interpretation</b></summary>
  <p><b>编号</b>：[231]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10061</p>
  <p><b>作者</b>：Ben Dai,  Xiaotong Shen,  Lin Yee Chen,  Chunlin Li,  Wei Pan</p>
  <p><b>备注</b>：27 pages, 11 figures</p>
  <p><b>关键词</b>：explainable artificial intelligence, blackbox model decision-making, model decision-making process, discriminative feature localization, artificial intelligence</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In explainable artificial intelligence, discriminative feature localization
is critical to reveal a blackbox model's decision-making process from raw data
to prediction. In this article, we use two real datasets, the MNIST handwritten
digits and MIT-BIH Electrocardiogram (ECG) signals, to motivate key
characteristics of discriminative features, namely adaptiveness, predictive
importance and effectiveness. Then, we develop a localization framework based
on adversarial attacks to effectively localize discriminative features. In
contrast to existing heuristic methods, we also provide a statistically
guaranteed interpretability of the localized features by measuring a
generalized partial $R^2$. We apply the proposed method to the MNIST dataset
and the MIT-BIH dataset with a convolutional auto-encoder. In the first, the
compact image regions localized by the proposed method are visually appealing.
Similarly, in the second, the identified ECG features are biologically
plausible and consistent with cardiac electrophysiological principles while
locating subtle anomalies in a QRS complex that may not be discernible by the
naked eye. Overall, the proposed method compares favorably with
state-of-the-art competitors. Accompanying this paper is a Python library
dnn-locate (this https URL) that implements the
proposed approach.</p>
  </details>
</details>
<details>
  <summary>98. <b>标题：Recent Advances in Algebraic Geometry and Bayesian Statistics</b></summary>
  <p><b>编号</b>：[232]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10049</p>
  <p><b>作者</b>：Sumio Watanabe</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：algebraic geometry, review of theoretical, Bayesian statistics, geometry, posterior distribution</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This article is a review of theoretical advances in the research field of
algebraic geometry and Bayesian statistics in the last two decades. Many
statistical models and learning machines which contain hierarchical structures
or latent variables are called nonidentifiable, because the map from a
parameter to a statistical model is not one-to-one. In nonidentifiable models,
both the likelihood function and the posterior distribution have singularities
in general, hence it was difficult to analyze their statistical properties.
However, from the end of the 20th century, new theory and methodology based on
algebraic geometry have been established which enables us to investigate such
models and machines in the real world. In this article, the following results
in recent advances are reported. First, we explain the framework of Bayesian
statistics and introduce a new perspective from the birational geometry.
Second, two mathematical solutions are derived based on algebraic geometry. An
appropriate parameter space can be found by a resolution map, which makes the
posterior distribution be normal crossing and the log likelihood ratio function
be well-defined. Third, three applications to statistics are introduced. The
posterior distribution is represented by the renormalized form, the asymptotic
free energy is derived, and the universal formula among the generalization
loss, the cross validation, and the information criterion is established. Two
mathematical solutions and three applications to statistics based on algebraic
geometry reported in this article are now being used in many practical fields
in data science and artificial intelligence.</p>
  </details>
</details>
<details>
  <summary>99. <b>标题：Asymptotics for The $k$-means</b></summary>
  <p><b>编号</b>：[234]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10015</p>
  <p><b>作者</b>：Tonglin Zhang</p>
  <p><b>备注</b>：Manuscript</p>
  <p><b>关键词</b>：important unsupervised learning, unsupervised learning techniques, computer science, important unsupervised, unsupervised learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The $k$-means is one of the most important unsupervised learning techniques
in statistics and computer science. The goal is to partition a data set into
many clusters, such that observations within clusters are the most homogeneous
and observations between clusters are the most heterogeneous. Although it is
well known, the investigation of the asymptotic properties is far behind,
leading to difficulties in developing more precise $k$-means methods in
practice. To address this issue, a new concept called clustering consistency is
proposed. Fundamentally, the proposed clustering consistency is more
appropriate than the previous criterion consistency for the clustering methods.
Using this concept, a new $k$-means method is proposed. It is found that the
proposed $k$-means method has lower clustering error rates and is more robust
to small clusters and outliers than existing $k$-means methods. When $k$ is
unknown, using the Gap statistics, the proposed method can also identify the
number of clusters. This is rarely achieved by existing $k$-means methods
adopted by many software packages.</p>
  </details>
</details>
<details>
  <summary>100. <b>标题：Active Learning by Query by Committee with Robust Divergences</b></summary>
  <p><b>编号</b>：[235]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10013</p>
  <p><b>作者</b>：Hideitsu Hino,  Shinto Eguchi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：high measurement costs, Leibler divergence, Active learning, divergence, widely used methodology</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Active learning is a widely used methodology for various problems with high
measurement costs. In active learning, the next object to be measured is
selected by an acquisition function, and measurements are performed
sequentially. The query by committee is a well-known acquisition function. In
conventional methods, committee disagreement is quantified by the
Kullback--Leibler divergence. In this paper, the measure of disagreement is
defined by the Bregman divergence, which includes the Kullback--Leibler
divergence as an instance, and the dual $\gamma$-power divergence. As a
particular class of the Bregman divergence, the $\beta$-divergence is
considered. By deriving the influence function, we show that the proposed
method using $\beta$-divergence and dual $\gamma$-power divergence are more
robust than the conventional method in which the measure of disagreement is
defined by the Kullback--Leibler divergence. Experimental results show that the
proposed method performs as well as or better than the conventional method.</p>
  </details>
</details>
<details>
  <summary>101. <b>标题：Distributed Deep Joint Source-Channel Coding over a Multiple Access  Channel</b></summary>
  <p><b>编号</b>：[238]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.09920</p>
  <p><b>作者</b>：Selim F. Yilmaz,  Can Karamanli,  Deniz Gunduz</p>
  <p><b>备注</b>：6 pages</p>
  <p><b>关键词</b>：deep joint source-channel, block length regime, noisy multiple access, length regime, joint source-channel coding</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We consider distributed image transmission over a noisy multiple access
channel (MAC) using deep joint source-channel coding (DeepJSCC). It is known
that Shannon's separation theorem holds when transmitting independent sources
over a MAC in the asymptotic infinite block length regime. However, we are
interested in the practical finite block length regime, in which case separate
source and channel coding is known to be suboptimal. We introduce a novel joint
image compression and transmission scheme, where the devices send their
compressed image representations in a non-orthogonal manner. While
non-orthogonal multiple access (NOMA) is known to achieve the capacity region,
to the best of our knowledge, non-orthogonal joint source channel coding (JSCC)
scheme for practical systems has not been studied before. Through extensive
experiments, we show significant improvements in terms of the quality of the
reconstructed images compared to orthogonal transmission employing current
DeepJSCC approaches particularly for low bandwidth ratios. We publicly share
source code to facilitate further research and reproducibility.</p>
  </details>
</details>
<details>
  <summary>102. <b>标题：Do graph neural networks learn traditional jet substructure?</b></summary>
  <p><b>编号</b>：[240]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.09912</p>
  <p><b>作者</b>：Farouk Mokhtar,  Raghav Kansal,  Javier Duarte</p>
  <p><b>备注</b>：5 pages, 4 figures. Accepted to Machine Learning for Physical Sciences NeurIPS 2022 workshop</p>
  <p><b>关键词</b>：CERN LHC, machine learning methods, learning methods, infer the origin, set of final-state</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>At the CERN LHC, the task of jet tagging, whose goal is to infer the origin
of a jet given a set of final-state particles, is dominated by machine learning
methods. Graph neural networks have been used to address this task by treating
jets as point clouds with underlying, learnable, edge connections between the
particles inside. We explore the decision-making process for one such
state-of-the-art network, ParticleNet, by looking for relevant edge connections
identified using the layerwise-relevance propagation technique. As the model is
trained, we observe changes in the distribution of relevant edges connecting
different intermediate clusters of particles, known as subjets. The resulting
distribution of subjet connections is different for signal jets originating
from top quarks, whose subjets typically correspond to its three decay
products, and background jets originating from lighter quarks and gluons. This
behavior indicates that the model is using traditional jet substructure
observables, such as the number of prongs -- energetic particle clusters --
within a jet, when identifying jets.</p>
  </details>
</details>
<details>
  <summary>103. <b>标题：Microstructural neuroimaging using spherical convolutional neural  networks</b></summary>
  <p><b>编号</b>：[246]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.09887</p>
  <p><b>作者</b>：Leevi Kerkelä,  Kiran Seunarine,  Filip Szczepankiewicz,  Chris A. Clark</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Diffusion-weighted magnetic resonance, magnetic resonance imaging, Diffusion-weighted magnetic, brain tissue, magnetic resonance</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Diffusion-weighted magnetic resonance imaging is sensitive to the
microstructural properties of brain tissue. However, estimating clinically and
scientifically relevant microstructural properties from the measured signals
remains a highly challenging inverse problem. This paper presents a novel
framework for estimating microstructural parameters using recently developed
orientationally invariant spherical convolutional neural networks and
efficiently simulated training data with a known ground truth. The network was
trained to predict the ground-truth parameter values from simulated noisy data
and applied to imaging data acquired in a clinical setting to generate
microstructural parameter maps. Our model could estimate model parameters from
spherical data more accurately than conventional non-linear least squares or a
multi-layer perceptron applied on powder-averaged data (i.e., the spherical
mean technique, a popular method for orientationally invariant microstructural
parameter estimation). Importantly, our method is generalizable and can be used
to estimate the parameters of any Gaussian compartment model.</p>
  </details>
</details>
<details>
  <summary>104. <b>标题：Fast Uncertainty Estimates in Deep Learning Interatomic Potentials</b></summary>
  <p><b>编号</b>：[247]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.09866</p>
  <p><b>作者</b>：Albert Zhu,  Simon Batzner,  Albert Musaelian,  Boris Kozinsky</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：highly accurate predictions, materials properties, promising paradigm, access to highly, highly accurate</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep learning has emerged as a promising paradigm to give access to highly
accurate predictions of molecular and materials properties. A common
short-coming shared by current approaches, however, is that neural networks
only give point estimates of their predictions and do not come with predictive
uncertainties associated with these estimates. Existing uncertainty
quantification efforts have primarily leveraged the standard deviation of
predictions across an ensemble of independently trained neural networks. This
incurs a large computational overhead in both training and prediction that
often results in order-of-magnitude more expensive predictions. Here, we
propose a method to estimate the predictive uncertainty based on a single
neural network without the need for an ensemble. This allows us to obtain
uncertainty estimates with virtually no additional computational overhead over
standard training and inference. We demonstrate that the quality of the
uncertainty estimates matches those obtained from deep ensembles. We further
examine the uncertainty estimates of our methods and deep ensembles across the
configuration space of our test system and compare the uncertainties to the
potential energy surface. Finally, we study the efficacy of the method in an
active learning setting and find the results to match an ensemble-based
strategy at order-of-magnitude reduced computational cost.</p>
  </details>
</details>
<details>
  <summary>105. <b>标题：Knowledge distillation for fast and accurate DNA sequence correction</b></summary>
  <p><b>编号</b>：[248]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.09862</p>
  <p><b>作者</b>：Anastasiya Belyaeva,  Joel Shor,  Daniel E. Cook,  Kishwar Shafin,  Daniel Liu,  Armin Töpfer,  Aaron M. Wenger,  William J. Rowell,  Howard Yang,  Alexey Kolesnikov,  Cory Y. McLean,  Maria Nattestad,  Andrew Carroll,  Pi-Chuan Chang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Accurate genome sequencing, basis of disease, understanding of biology, genetic basis, Distilled DeepConsensus</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Accurate genome sequencing can improve our understanding of biology and the
genetic basis of disease. The standard approach for generating DNA sequences
from PacBio instruments relies on HMM-based models. Here, we introduce
Distilled DeepConsensus - a distilled transformer-encoder model for sequence
correction, which improves upon the HMM-based methods with runtime constraints
in mind. Distilled DeepConsensus is 1.3x faster and 1.5x smaller than its
larger counterpart while improving the yield of high quality reads (Q30) over
the HMM-based method by 1.69x (vs. 1.73x for larger model). With improved
accuracy of genomic sequences, Distilled DeepConsensus improves downstream
applications of genomic sequence analysis such as reducing variant calling
errors by 39% (34% for larger model) and improving genome assembly quality by
3.8% (4.2% for larger model). We show that the representations learned by
Distilled DeepConsensus are similar between faster and slower models.</p>
  </details>
</details>
<h1>人工智能</h1>
<details>
  <summary>1. <b>标题：SmoothQuant: Accurate and Efficient Post-Training Quantization for Large  Language Models</b></summary>
  <p><b>编号</b>：[3]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10438</p>
  <p><b>作者</b>：Guangxuan Xiao,  Ji Lin,  Mickael Seznec,  Julien Demouth,  Song Han</p>
  <p><b>备注</b>：The first two authors contributed equally to this work</p>
  <p><b>关键词</b>：Large language models, show excellent performance, Large language, language models, show excellent</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large language models (LLMs) show excellent performance but are compute- and
memory-intensive. Quantization can reduce memory and accelerate inference.
However, for LLMs beyond 100 billion parameters, existing methods cannot
maintain accuracy or do not run efficiently on hardware. We propose
SmoothQuant, a training-free, accuracy-preserving, and general-purpose
post-training quantization (PTQ) solution to enable 8-bit weight, 8-bit
activation (W8A8) quantization for LLMs that can be implemented efficiently. We
observe that systematic outliers appear at fixed activation channels. Based on
the fact that weights are easy to quantize while activations are not,
SmoothQuant smooths the activation outliers by migrating the quantization
difficulty from activations to weights with a mathematically equivalent
transformation. SmoothQuant enables an INT8 quantization of both weights and
activations for all the GEMMs in LLMs, including OPT-175B, BLOOM-176B and
GLM-130B. SmoothQuant has better hardware efficiency than existing techniques
using mixed-precision activation quantization or weight-only quantization. We
demonstrate up to 1.56x speedup and 2x memory reduction for LLMs with
negligible loss in accuracy. Thanks to the hardware-friendly design, we
integrate SmoothQuant into FasterTransformer, a state-of-the-art LLM serving
framework, and achieve faster inference speed with half the number of GPUs
compared to FP16. Our work offers a turn-key solution that reduces hardware
costs and democratizes LLMs. Code will be released at:
this https URL.</p>
  </details>
</details>
<details>
  <summary>2. <b>标题：PAL: Program-aided Language Models</b></summary>
  <p><b>编号</b>：[5]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10435</p>
  <p><b>作者</b>：Luyu Gao,  Aman Madaan,  Shuyan Zhou,  Uri Alon,  Pengfei Liu,  Yiming Yang,  Jamie Callan,  Graham Neubig</p>
  <p><b>备注</b>：The first three authors contributed equally. Our code and data are publicly available at this http URL</p>
  <p><b>关键词</b>：reasoning, Large language models, test time, reasoning tasks, recently demonstrated</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large language models (LLMs) have recently demonstrated an impressive ability
to perform arithmetic and symbolic reasoning tasks when provided with a few
examples at test time (few-shot prompting). Much of this success can be
attributed to prompting methods for reasoning, such as chain-of-thought, that
employ LLMs for both understanding the problem description by decomposing it
into steps, as well as solving each step of the problem. While LLMs seem to be
adept at this sort of step-by-step decomposition, LLMs often make logical and
arithmetic mistakes in the solution part, even when the problem is correctly
decomposed. We present Program-Aided Language models (PaL): a new method that
uses the LLM to understand natural language problems and generate programs as
the intermediate reasoning steps, but offloads the solution step to a
programmatic runtime such as a Python interpreter. With PaL, decomposing the
natural language problem into runnable steps remains the only learning task for
the LLM, while solving is delegated to the interpreter. We experiment with 12
reasoning tasks from BIG-Bench Hard and other benchmarks, including
mathematical reasoning, symbolic reasoning, and algorithmic problems. In all
these natural language reasoning tasks, generating code using an LLM and
reasoning using a Python interpreter leads to more accurate results than much
larger models, and we set new state-of-the-art results in all 12 benchmarks.
For example, PaL using Codex achieves state-of-the-art few-shot accuracy on the
GSM benchmark of math word problems when the model is allowed only a single
decoding, surpassing PaLM-540B with chain-of-thought prompting by an absolute
8% .In three reasoning tasks from the BIG-Bench Hard benchmark, PaL outperforms
CoT by 11%. On GSM-hard, a more challenging version of GSM that we create, PaL
outperforms chain-of-thought by an absolute 40%.</p>
  </details>
</details>
<details>
  <summary>3. <b>标题：Indexing AI Risks with Incidents, Issues, and Variants</b></summary>
  <p><b>编号</b>：[17]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10384</p>
  <p><b>作者</b>：Sean McGregor,  Kevin Paeth,  Khoa Lam</p>
  <p><b>备注</b>：To be published in Human-Centered AI Workshop at NeurIPS 2022</p>
  <p><b>关键词</b>：incident ingestion criteria, review queue, years after publicly, publicly launching, database current criteria</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Two years after publicly launching the AI Incident Database (AIID) as a
collection of harms or near harms produced by AI in the world, a backlog of
"issues" that do not meet its incident ingestion criteria have accumulated in
its review queue. Despite not passing the database's current criteria for
incidents, these issues advance human understanding of where AI presents the
potential for harm. Similar to databases in aviation and computer security, the
AIID proposes to adopt a two-tiered system for indexing AI incidents (i.e., a
harm or near harm event) and issues (i.e., a risk of a harm event). Further, as
some machine learning-based systems will sometimes produce a large number of
incidents, the notion of an incident "variant" is introduced. These proposed
changes mark the transition of the AIID to a new version in response to lessons
learned from editing 2,000+ incident reports and additional reports that fall
under the new category of "issue."</p>
  </details>
</details>
<details>
  <summary>4. <b>标题：Comparing Explanation Methods for Traditional Machine Learning Models  Part 2: Quantifying Model Explainability Faithfulness and Improvements with  Dimensionality Reduction</b></summary>
  <p><b>编号</b>：[19]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10378</p>
  <p><b>作者</b>：Montgomery Flora,  Corey Potvin,  Amy McGovern,  Shawn Handler</p>
  <p><b>备注</b>：18 pages; 12 figures ; part I (arXiv:2211.08943)</p>
  <p><b>关键词</b>：atmospheric science community, methods, Machine learning, feature, range of applications</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Machine learning (ML) models are becoming increasingly common in the
atmospheric science community with a wide range of applications. To enable
users to understand what an ML model has learned, ML explainability has become
a field of active research. In Part I of this two-part study, we described
several explainability methods and demonstrated that feature rankings from
different methods can substantially disagree with each other. It is unclear,
though, whether the disagreement is overinflated due to some methods being less
faithful in assigning importance. Herein, "faithfulness" or "fidelity" refer to
the correspondence between the assigned feature importance and the contribution
of the feature to model performance. In the present study, we evaluate the
faithfulness of feature ranking methods using multiple methods. Given the
sensitivity of explanation methods to feature correlations, we also quantify
how much explainability faithfulness improves after correlated features are
limited. Before dimensionality reduction, the feature relevance methods [e.g.,
SHAP, LIME, ALE variance, and logistic regression (LR) coefficients] were
generally more faithful than the permutation importance methods due to the
negative impact of correlated features. Once correlated features were reduced,
traditional permutation importance became the most faithful method. In
addition, the ranking uncertainty (i.e., the spread in rank assigned to a
feature by the different ranking methods) was reduced by a factor of 2-10, and
excluding less faithful feature ranking methods reduces it further. This study
is one of the first to quantify the improvement in explainability from limiting
correlated features and knowing the relative fidelity of different
explainability methods.</p>
  </details>
</details>
<details>
  <summary>5. <b>标题：Data efficient surrogate modeling for engineering design: Ensemble-free  batch mode deep active learning for regression</b></summary>
  <p><b>编号</b>：[23]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10360</p>
  <p><b>作者</b>：Harsh Vardhan,  Umesh Timalsina,  Peter Volgyesi,  Janos Sztipanovits</p>
  <p><b>备注</b>：23 pages, 12 figures</p>
  <p><b>关键词</b>：involves notoriously complex, time-consuming simulator, cheaper cost, involves notoriously, data-driven surrogate</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In a computer-aided engineering design optimization problem that involves
notoriously complex and time-consuming simulator, the prevalent approach is to
replace these simulations with a data-driven surrogate that approximates the
simulator's behavior at a much cheaper cost. The main challenge in creating an
inexpensive data-driven surrogate is the generation of a sheer number of data
using these computationally expensive numerical simulations. In such cases,
Active Learning (AL) methods have been used that attempt to learn an
input--output behavior while labeling the fewest samples possible. The current
trend in AL for a regression problem is dominated by the Bayesian framework
that needs training an ensemble of learning models that makes surrogate
training computationally tedious if the underlying learning model is Deep
Neural Networks (DNNs). However, DNNs have an excellent capability to learn
highly nonlinear and complex relationships even for a very high dimensional
problem. To leverage the excellent learning capability of deep networks along
with avoiding the computational complexity of the Bayesian paradigm, in this
work we propose a simple and scalable approach for active learning that works
in a student-teacher manner to train a surrogate model. By using this proposed
approach, we are able to achieve the same level of surrogate accuracy as the
other baselines like DBAL and Monte Carlo sampling with up to 40 % fewer
samples. We empirically evaluated this method on multiple use cases including
three different engineering design domains:finite element analysis,
computational fluid dynamics, and propeller design.</p>
  </details>
</details>
<details>
  <summary>6. <b>标题：Tire-road friction estimation and uncertainty assessment to improve  electric aircraft braking system</b></summary>
  <p><b>编号</b>：[28]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10336</p>
  <p><b>作者</b>：Francesco Crocetti,  G. Costante,  M.L. Fravolini,  P. Valigi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：brake control system, advanced brake control, MLP Neural Net, accurate online estimation, control system</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The accurate online estimation of the road-friction coefficient is an
essential feature for any advanced brake control system. In this study, a
data-driven scheme based on a MLP Neural Net is proposed to estimate the
optimum friction coefficient as a function of windowed slip-friction
measurements. A stochastic NN weights drop-out mechanism is used to online
estimate the confidence interval of the estimated best friction coefficient
thus providing a characterization of the epistemic uncertainty associated to
the NN block. Open loop and closed loop simulations of the landing phase of an
aircraft on an unknown surface are used to show the potentiality and efficacy
of the proposed robust friction estimation approach.</p>
  </details>
</details>
<details>
  <summary>7. <b>标题：Reinforcement Learning Methods for Wordle: A POMDP/Adaptive Control  Approach</b></summary>
  <p><b>编号</b>：[39]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10298</p>
  <p><b>作者</b>：Siddhant Bhambri,  Amrita Bhattacharjee,  Dimitri Bertsekas</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Partially Observable Markov, Observable Markov Decision, Partially Observable, Observable Markov, classes of Partially</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper we address the solution of the popular Wordle puzzle, using new
reinforcement learning methods, which apply more generally to adaptive control
of dynamic systems and to classes of Partially Observable Markov Decision
Process (POMDP) problems. These methods are based on approximation in value
space and the rollout approach, admit a straightforward implementation, and
provide improved performance over various heuristic approaches. For the Wordle
puzzle, they yield on-line solution strategies that are very close to optimal
at relatively modest computational cost. Our methods are viable for more
complex versions of Wordle and related search problems, for which an optimal
strategy would be impossible to compute. They are also applicable to a wide
range of adaptive sequential decision problems that involve an unknown or
frequently changing environment whose parameters are estimated on-line.</p>
  </details>
</details>
<details>
  <summary>8. <b>标题：Evident: a Development Methodology and a Knowledge Base Topology for  Data Mining, Machine Learning and General Knowledge Management</b></summary>
  <p><b>编号</b>：[41]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10291</p>
  <p><b>作者</b>：Mingwu (Barton)Gao,  Samer Haidar</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：knowledge, years, EKB, prediction, methodologies</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Software has been developed for knowledge discovery, prediction and
management for over 30 years. However, there are still unresolved pain points
when using existing project development and artifact management methodologies.
Historically, there has been a lack of applicable methodologies. Further,
methodologies that have been applied, such as Agile, have several limitations
including scientific unfalsifiability that reduce their applicability. Evident,
a development methodology rooted in the philosophy of logical reasoning and
EKB, a knowledge base topology, are proposed. Many pain points in data mining,
machine learning and general knowledge management are alleviated conceptually.
Evident can be extended potentially to accelerate philosophical exploration,
science discovery, education as well as knowledge sharing & retention across
the globe. EKB offers one solution of storing information as knowledge, a
granular level above data. Related topics in computer history, software
engineering, database, sensor, philosophy, and project & organization &
military managements are also discussed.</p>
  </details>
</details>
<details>
  <summary>9. <b>标题：Context Variance Evaluation of Pretrained Language Models for  Prompt-based Biomedical Knowledge Probing</b></summary>
  <p><b>编号</b>：[53]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10265</p>
  <p><b>作者</b>：Zonghai Yao,  Yi Cao,  Zhichao Yang,  Hong Yu</p>
  <p><b>备注</b>：submitted to AMIA 2023 Informatics Summit</p>
  <p><b>关键词</b>：Pretrained language models, models learn, language models, Pretrained language, knowledge</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Pretrained language models (PLMs) have motivated research on what kinds of
knowledge these models learn. Fill-in-the-blanks problem (e.g., cloze tests) is
a natural approach for gauging such knowledge. BioLAMA generates prompts for
biomedical factual knowledge triples and uses the Top-k accuracy metric to
evaluate different PLMs' knowledge. However, existing research has shown that
such prompt-based knowledge probing methods can only probe a lower bound of
knowledge. Many factors like prompt-based probing biases make the LAMA
benchmark unreliable and unstable. This problem is more prominent in BioLAMA.
The severe long-tailed distribution in vocabulary and large-N-M relation make
the performance gap between LAMA and BioLAMA remain notable. To address these,
we introduce context variance into the prompt generation and propose a new
rank-change-based evaluation metric. Different from the previous known-unknown
evaluation criteria, we propose the concept of "Misunderstand" in LAMA for the
first time. Through experiments on 12 PLMs, our context variance prompts and
Understand-Confuse-Misunderstand (UCM) metric makes BioLAMA more friendly to
large-N-M relations and rare relations. We also conducted a set of control
experiments to disentangle "understand" from just "read and copy".</p>
  </details>
</details>
<details>
  <summary>10. <b>标题：HiveNAS: Neural Architecture Search using Artificial Bee Colony  Optimization</b></summary>
  <p><b>编号</b>：[58]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10250</p>
  <p><b>作者</b>：Mohamed Shahawy,  Elhadj Benkhelifa</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Network-development process requires, Neural Network-development process, traditional Neural Network-development, process requires substantial, requires substantial expert</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The traditional Neural Network-development process requires substantial
expert knowledge and relies heavily on intuition and trial-and-error. Neural
Architecture Search (NAS) frameworks were introduced to robustly search for
network topologies, as well as facilitate the automated development of Neural
Networks. While some optimization approaches -- such as Genetic Algorithms --
have been extensively explored in the NAS context, other Metaheuristic
Optimization algorithms have not yet been evaluated. In this paper, we propose
HiveNAS, the first Artificial Bee Colony-based NAS framework.</p>
  </details>
</details>
<details>
  <summary>11. <b>标题：Rationale-aware Autonomous Driving Policy utilizing Safety Force Field  implemented on CARLA Simulator</b></summary>
  <p><b>编号</b>：[63]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10237</p>
  <p><b>作者</b>：Ho Suk,  Taewoo Kim,  Hyungbin Park,  Pamul Yadav,  Junyong Lee,  Shiho Kim</p>
  <p><b>备注</b>：9 pages including appendices, 4 figures, NeurIPS 2022 Workshop: Machine Learning for Autonomous Driving (ML4AD)</p>
  <p><b>关键词</b>：commercialize autonomous passenger, autonomous passenger car, car of SAE, resolve liability issues, autonomous driving technology</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Despite the rapid improvement of autonomous driving technology in recent
years, automotive manufacturers must resolve liability issues to commercialize
autonomous passenger car of SAE J3016 Level 3 or higher. To cope with the
product liability law, manufacturers develop autonomous driving systems in
compliance with international standards for safety such as ISO 26262 and ISO
21448. Concerning the safety of the intended functionality (SOTIF) requirement
in ISO 26262, the driving policy recommends providing an explicit rational
basis for maneuver decisions. In this case, mathematical models such as Safety
Force Field (SFF) and Responsibility-Sensitive Safety (RSS) which have
interpretability on decision, may be suitable. In this work, we implement SFF
from scratch to substitute the undisclosed NVIDIA's source code and integrate
it with CARLA open-source simulator. Using SFF and CARLA, we present a
predictor for claimed sets of vehicles, and based on the predictor, propose an
integrated driving policy that consistently operates regardless of safety
conditions it encounters while passing through dynamic traffic. The policy does
not have a separate plan for each condition, but using safety potential, it
aims human-like driving blended in with traffic flow.</p>
  </details>
</details>
<details>
  <summary>12. <b>标题：Adversarial Detection by Approximation of Ensemble Boundary</b></summary>
  <p><b>编号</b>：[65]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10227</p>
  <p><b>作者</b>：T. Windeatt</p>
  <p><b>备注</b>：8 pages, 8 figures, 8 tables</p>
  <p><b>关键词</b>：Deep Neural Networks, pattern recognition problems, Neural Networks, Deep Neural, solving two-class pattern</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A spectral approximation of a Boolean function is proposed for approximating
the decision boundary of an ensemble of Deep Neural Networks (DNNs) solving
two-class pattern recognition problems. The Walsh combination of relatively
weak DNN classifiers is shown experimentally to be capable of detecting
adversarial attacks. By observing the difference in Walsh coefficient
approximation between clean and adversarial images, it appears that
transferability of attack may be used for detection. Approximating the decision
boundary may also aid in understanding the learning and transferability
properties of DNNs. While the experiments here use images, the proposed
approach of modelling two-class ensemble decision boundaries could in principle
be applied to any application area.</p>
  </details>
</details>
<details>
  <summary>13. <b>标题：Leveraging Multi-stream Information Fusion for Trajectory Prediction in  Low-illumination Scenarios: A Multi-channel Graph Convolutional Approach</b></summary>
  <p><b>编号</b>：[66]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10226</p>
  <p><b>作者</b>：Hailong Gong,  Zirui Li,  Chao Lu,  Guodong Du,  Jianwei Gong</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：fundamental problem, problem and challenge, challenge for autonomous, Long Short-term Memory, Trajectory prediction</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Trajectory prediction is a fundamental problem and challenge for autonomous
vehicles. Early works mainly focused on designing complicated architectures for
deep-learning-based prediction models in normal-illumination environments,
which fail in dealing with low-light conditions. This paper proposes a novel
approach for trajectory prediction in low-illumination scenarios by leveraging
multi-stream information fusion, which flexibly integrates image, optical flow,
and object trajectory information. The image channel employs Convolutional
Neural Network (CNN) and Long Short-term Memory (LSTM) networks to extract
temporal information from the camera. The optical flow channel is applied to
capture the pattern of relative motion between adjacent camera frames and
modelled by Spatial-Temporal Graph Convolutional Network (ST-GCN). The
trajectory channel is used to recognize high-level interactions between
vehicles. Finally, information from all the three channels is effectively fused
in the prediction module to generate future trajectories of surrounding
vehicles in low-illumination conditions. The proposed multi-channel graph
convolutional approach is validated on HEV-I and newly generated Dark-HEV-I,
egocentric vision datasets that primarily focus on urban intersection
scenarios. The results demonstrate that our method outperforms the baselines,
in standard and low-illumination scenarios. Additionally, our approach is
generic and applicable to scenarios with different types of perception data.
The source code of the proposed approach is available at
this https URL}{this https URL.</p>
  </details>
</details>
<details>
  <summary>14. <b>标题：Overview of the HASOC Subtrack at FIRE 2022: Offensive Language  Identification in Marathi</b></summary>
  <p><b>编号</b>：[81]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10163</p>
  <p><b>作者</b>：Tharindu Ranasinghe,  Kai North,  Damith Premasiri,  Marcos Zampieri</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：develop robust systems, robust systems capable, Offensive Content Identification, offensive content online, offensive content</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The widespread of offensive content online has become a reason for great
concern in recent years, motivating researchers to develop robust systems
capable of identifying such content automatically. With the goal of carrying
out a fair evaluation of these systems, several international competitions have
been organized, providing the community with important benchmark data and
evaluation methods for various languages. Organized since 2019, the HASOC (Hate
Speech and Offensive Content Identification) shared task is one of these
initiatives. In its fourth iteration, HASOC 2022 included three subtracks for
English, Hindi, and Marathi. In this paper, we report the results of the HASOC
2022 Marathi subtrack which provided participants with a dataset containing
data from Twitter manually annotated using the popular OLID taxonomy. The
Marathi track featured three additional subtracks, each corresponding to one
level of the taxonomy: Task A - offensive content identification (offensive vs.
non-offensive); Task B - categorization of offensive types (targeted vs.
untargeted), and Task C - offensive target identification (individual vs. group
vs. others). Overall, 59 runs were submitted by 10 teams. The best systems
obtained an F1 of 0.9745 for Subtrack 3A, an F1 of 0.9207 for Subtrack 3B, and
F1 of 0.9607 for Subtrack 3C. The best performing algorithms were a mixture of
traditional and deep learning approaches.</p>
  </details>
</details>
<details>
  <summary>15. <b>标题：UMFuse: Unified Multi View Fusion for Human Editing applications</b></summary>
  <p><b>编号</b>：[83]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10157</p>
  <p><b>作者</b>：Rishabh Jain,  Mayur Hemani,  Duygu Ceylan,  Krishna Kumar Singh,  Jingwan Lu,  Mausooom Sarkar,  Balaji Krishnamurthy</p>
  <p><b>备注</b>：10 pages, 10 figures</p>
  <p><b>关键词</b>：explored numerous pose, numerous pose guided, extensive practical applications, vision community, community has explored</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The vision community has explored numerous pose guided human editing methods
due to their extensive practical applications. Most of these methods still use
an image-to-image formulation in which a single image is given as input to
produce an edited image as output. However, the problem is ill-defined in cases
when the target pose is significantly different from the input pose. Existing
methods then resort to in-painting or style transfer to handle occlusions and
preserve content. In this paper, we explore the utilization of multiple views
to minimize the issue of missing information and generate an accurate
representation of the underlying human model. To fuse the knowledge from
multiple viewpoints, we design a selector network that takes the pose keypoints
and texture from images and generates an interpretable per-pixel selection map.
After that, the encodings from a separate network (trained on a single image
human reposing task) are merged in the latent space. This enables us to
generate accurate, precise, and visually coherent images for different editing
tasks. We show the application of our network on 2 newly proposed tasks -
Multi-view human reposing, and Mix-and-match human image generation.
Additionally, we study the limitations of single-view editing and scenarios in
which multi-view provides a much better alternative.</p>
  </details>
</details>
<details>
  <summary>16. <b>标题：Structured Pruning Adapters</b></summary>
  <p><b>编号</b>：[85]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10155</p>
  <p><b>作者</b>：Lukas Hedegaard,  Aman Alok,  Juby Jose,  Alexandros Iosifidis</p>
  <p><b>备注</b>：12 pages, 9 figures, 4 tables</p>
  <p><b>关键词</b>：task-switching network adapters, tiny parameter sets, task-switching network, family of compressing, propose Structured Pruning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose Structured Pruning Adapters (SPAs), a family of compressing,
task-switching network adapters, that accelerate and specialize networks using
tiny parameter sets. Specifically, we propose a channel- and a block-based SPA
and evaluate them with a suite of pruning methods on both computer vision and
natural language processing benchmarks. Compared to regular structured pruning
with fine-tuning, our channel-SPA improves accuracy by 6.9% on average while
using half the parameters at 90% pruned weights. Alternatively, it can learn
adaptations with 17x fewer parameters at 70% pruning with 1.6% lower accuracy.
Similarly, our block-SPA requires far fewer parameters than pruning with
fine-tuning. Our experimental code and Python library of adapters are available
at this http URL.</p>
  </details>
</details>
<details>
  <summary>17. <b>标题：CRAFT: Concept Recursive Activation FacTorization for Explainability</b></summary>
  <p><b>编号</b>：[86]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10154</p>
  <p><b>作者</b>：Thomas Fel,  Agustin Picard,  Louis Bethune,  Thibaut Boissin,  David Vigouroux,  Julien Colin,  Rémi Cadène,  Thomas Serre</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：popular class, heatmaps to depict, important areas, model decision, Concept Attribution Maps</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Attribution methods are a popular class of explainability methods that use
heatmaps to depict the most important areas of an image that drive a model
decision. Nevertheless, recent work has shown that these methods have limited
utility in practice, presumably because they only highlight the most salient
parts of an image (i.e., 'where' the model looked) and do not communicate any
information about 'what' the model saw at those locations. In this work, we try
to fill in this gap with CRAFT -- a novel approach to identify both 'what' and
'where' by generating concept-based explanations. We introduce 3 new
ingredients to the automatic concept extraction literature: (i) a recursive
strategy to detect and decompose concepts across layers, (ii) a novel method
for a more faithful estimation of concept importance using Sobol indices, and
(iii) the use of implicit differentiation to unlock Concept Attribution Maps.
We conduct both human and computer vision experiments to demonstrate the
benefits of the proposed approach. We show that our recursive decomposition
generates meaningful and accurate concepts and that the proposed concept
importance estimation technique is more faithful to the model than previous
methods. When evaluating the usefulness of the method for human experimenters
on a human-defined utility benchmark, we find that our approach significantly
improves on two of the three test scenarios (while none of the current methods
including ours help on the third). Overall, our study suggests that, while much
work remains toward the development of general explainability methods that are
useful in practical scenarios, the identification of meaningful concepts at the
proper level of granularity yields useful and complementary information beyond
that afforded by attribution methods.</p>
  </details>
</details>
<details>
  <summary>18. <b>标题：FiE: Building a Global Probability Space by Leveraging Early Fusion in  Encoder for Open-Domain Question Answering</b></summary>
  <p><b>编号</b>：[88]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10147</p>
  <p><b>作者</b>：Akhil Kedia,  Mohd Abbas Zaidi,  Haejun Lee</p>
  <p><b>备注</b>：Accepted at EMNLP 2022 Main Conference</p>
  <p><b>关键词</b>：Domain Question Answering, recently started, Open Domain Question, Exact Match, Question Answering</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Generative models have recently started to outperform extractive models in
Open Domain Question Answering, largely by leveraging their decoder to attend
over multiple encoded passages and combining their information. However,
generative models tend to be larger than extractive models due to the need for
a decoder, run slower during inference due to auto-regressive decoder beam
search, and their generated output often suffers from hallucinations. We
propose to extend transformer encoders with the ability to fuse information
from multiple passages, using global representation to provide cross-sample
attention over all tokens across samples. Furthermore, we propose an
alternative answer span probability calculation to better aggregate answer
scores in the global space of all samples. Using our proposed method, we
outperform the current state-of-the-art method by $2.5$ Exact Match score on
the Natural Question dataset while using only $25\%$ of parameters and $35\%$
of the latency during inference, and $4.4$ Exact Match on WebQuestions dataset.
When coupled with synthetic data augmentation, we outperform larger models on
the TriviaQA dataset as well. The latency and parameter savings of our method
make it particularly attractive for open-domain question answering, as these
models are often compute-intensive.</p>
  </details>
</details>
<details>
  <summary>19. <b>标题：Computational Short Cuts in Infinite Domain Constraint Satisfaction</b></summary>
  <p><b>编号</b>：[89]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10144</p>
  <p><b>作者</b>：Peter Jonsson,  Victor Lagerkvist,  Sebastian Ordyniak</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：polynomial-time solvable class, set of variables, instantiation moves, polynomial-time solvable, Backdoors</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A backdoor in a finite-domain CSP instance is a set of variables where each
possible instantiation moves the instance into a polynomial-time solvable
class. Backdoors have found many applications in artificial intelligence and
elsewhere, and the algorithmic problem of finding such backdoors has
consequently been intensively studied. Sioutis and Janhunen (Proc. 42nd German
Conference on AI (KI-2019)) have proposed a generalised backdoor concept
suitable for infinite-domain CSP instances over binary constraints. We
generalise their concept into a large class of CSPs that allow for higher-arity
constraints. We show that this kind of infinite-domain backdoors have many of
the positive computational properties that finite-domain backdoors have: the
associated computational problems are fixed-parameter tractable whenever the
underlying constraint language is finite. On the other hand, we show that
infinite languages make the problems considerably harder: the general backdoor
detection problem is W[2]-hard and fixed-parameter tractability is ruled out
under standard complexity-theoretic assumptions. We demonstrate that backdoors
may have suboptimal behaviour on binary constraints -- this is detrimental from
an AI perspective where binary constraints are predominant in, for instance,
spatiotemporal applications. In response to this, we introduce sidedoors as an
alternative to backdoors. The fundamental computational problems for sidedoors
remain fixed-parameter tractable for finite constraint language (possibly also
containing non-binary relations). Moreover, the sidedoor approach has appealing
computational properties that sometimes leads to faster algorithms than the
backdoor approach.</p>
  </details>
</details>
<details>
  <summary>20. <b>标题：Rare Yet Popular: Evidence and Implications from Labeled Datasets for  Network Anomaly Detection</b></summary>
  <p><b>编号</b>：[92]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10129</p>
  <p><b>作者</b>：Jose Manuel Navarro,  Alexis Huet,  Dario Rossi</p>
  <p><b>备注</b>：Published in the International Teletraffic Congress (ITC 34), 14-16 September 2022</p>
  <p><b>关键词</b>：research works generally, works generally propose, automatically discover outliers, generally propose algorithms, detection research works</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Anomaly detection research works generally propose algorithms or end-to-end
systems that are designed to automatically discover outliers in a dataset or a
stream. While literature abounds concerning algorithms or the definition of
metrics for better evaluation, the quality of the ground truth against which
they are evaluated is seldom questioned. In this paper, we present a systematic
analysis of available public (and additionally our private) ground truth for
anomaly detection in the context of network environments, where data is
intrinsically temporal, multivariate and, in particular, exhibits spatial
properties, which, to the best of our knowledge, we are the first to explore.
Our analysis reveals that, while anomalies are, by definition, temporally rare
events, their spatial characterization clearly shows some type of anomalies are
significantly more popular than others. We find that simple clustering can
reduce the need for human labeling by a factor of 2x-10x, that we are first to
quantitatively analyze in the wild.</p>
  </details>
</details>
<details>
  <summary>21. <b>标题：Identifying Unique Causal Network from Nonstationary Time Series</b></summary>
  <p><b>编号</b>：[105]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10085</p>
  <p><b>作者</b>：Mingyu Kang,  Duxin Chen,  Ning Meng,  Gang Yan,  Wenwu Yu</p>
  <p><b>备注</b>：Submit to AAAI-23</p>
  <p><b>关键词</b>：data-intensive scenarios, challenging task, time series, Markov equivalence class, UCN</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Identifying causality is a challenging task in many data-intensive scenarios.
Many algorithms have been proposed for this critical task. However, most of
them consider the learning algorithms for directed acyclic graph (DAG) of
Bayesian network (BN). These BN-based models only have limited causal
explainability because of the issue of Markov equivalence class. Moreover, they
are dependent on the assumption of stationarity, whereas many sampling time
series from complex system are nonstationary. The nonstationary time series
bring dataset shift problem, which leads to the unsatisfactory performances of
these algorithms. To fill these gaps, a novel causation model named Unique
Causal Network (UCN) is proposed in this paper. Different from the previous
BN-based models, UCN considers the influence of time delay, and proves the
uniqueness of obtained network structure, which addresses the issue of Markov
equivalence class. Furthermore, based on the decomposability property of UCN, a
higher-order causal entropy (HCE) algorithm is designed to identify the
structure of UCN in a distributed way. HCE algorithm measures the strength of
causality by using nearest-neighbors entropy estimator, which works well on
nonstationary time series. Finally, lots of experiments validate that HCE
algorithm achieves state-of-the-art accuracy when time series are
nonstationary, compared to the other baseline algorithms.</p>
  </details>
</details>
<details>
  <summary>22. <b>标题：Intrusion Detection in Internet of Things using Convolutional Neural  Networks</b></summary>
  <p><b>编号</b>：[114]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10062</p>
  <p><b>作者</b>：Martin Kodys,  Zhi Lu,  Kar Wai Fok,  Vrizlynn L. L. Thing</p>
  <p><b>备注</b>：Keywords: Cybersecurity, Intrusion Detection, IoT, Deep Learning, Convolutional Neural Networks; this https URL</p>
  <p><b>关键词</b>：Internet of Things, asset tracking, resource monitoring, monitoring and automation, popular paradigm</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Internet of Things (IoT) has become a popular paradigm to fulfil needs of the
industry such as asset tracking, resource monitoring and automation. As
security mechanisms are often neglected during the deployment of IoT devices,
they are more easily attacked by complicated and large volume intrusion attacks
using advanced techniques. Artificial Intelligence (AI) has been used by the
cyber security community in the past decade to automatically identify such
attacks. However, deep learning methods have yet to be extensively explored for
Intrusion Detection Systems (IDS) specifically for IoT. Most recent works are
based on time sequential models like LSTM and there is short of research in
CNNs as they are not naturally suited for this problem. In this article, we
propose a novel solution to the intrusion attacks against IoT devices using
CNNs. The data is encoded as the convolutional operations to capture the
patterns from the sensors data along time that are useful for attacks detection
by CNNs. The proposed method is integrated with two classical CNNs: ResNet and
EfficientNet, where the detection performance is evaluated. The experimental
results show significant improvement in both true positive rate and false
positive rate compared to the baseline using LSTM.</p>
  </details>
</details>
<details>
  <summary>23. <b>标题：Reference-Based Autoencoder for Surface Defect Detection</b></summary>
  <p><b>编号</b>：[115]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10060</p>
  <p><b>作者</b>：Wei Luo,  Haiming Yao,  Wenyong Yu,  Xue Wang</p>
  <p><b>备注</b>：13pages</p>
  <p><b>关键词</b>：product quality inspection, industrial automatic product, automatic product quality, visual anomaly detection, abnormal data</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Due to the extreme imbalance in the number of normal data and abnormal data,
visual anomaly detection is important for the development of industrial
automatic product quality inspection. Unsupervised methods based on
reconstruction and embedding have been widely studied for anomaly detection, of
which reconstruction-based methods are the most popular. However, establishing
a unified model for textured surface defect detection remains a challenge
because these surfaces can vary in homogeneous and non regularly ways.
Furthermore, existing reconstruction-based methods do not have a strong ability
to convert the defect feature to the normal feature. To address these
challenges, we propose a novel unsupervised reference-based autoencoder (RB-AE)
to accurately inspect a variety of textured defects. Unlike most
reconstruction-based methods, artificial defects and a novel pixel-level
discrimination loss function are utilized for training to enable the model to
obtain pixel-level discrimination ability. First, the RB-AE employs an encoding
module to extract multi-scale features of the textured surface. Subsequently, a
novel reference-based attention module (RBAM) is proposed to convert the defect
features to normal features to suppress the reconstruction of defects. In
addition, RBAM can also effectively suppress the defective feature residual
caused by skip-connection. Next, a decoding module utilizes the repaired
features to reconstruct the normal texture background. Finally, a novel
multiscale feature discrimination module (MSFDM) is employed to defect
detection and segmentation.</p>
  </details>
</details>
<details>
  <summary>24. <b>标题：Overview of the WANLP 2022 Shared Task on Propaganda Detection in Arabic</b></summary>
  <p><b>编号</b>：[116]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10057</p>
  <p><b>作者</b>：Firoj Alam,  Hamdy Mubarak,  Wajdi Zaghouani,  Giovanni Da San Martino,  Preslav Nakov</p>
  <p><b>备注</b>：Accepted at WANLP-22 (EMNLP-22), propaganda, disinformation, misinformation, fake news, memes, multimodality. arXiv admin note: text overlap with arXiv:2109.08013, arXiv:2105.09284</p>
  <p><b>关键词</b>：group deliberately designed, Propaganda techniques, group deliberately, predetermined ends, psychological devices</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Propaganda is the expression of an opinion or an action by an individual or a
group deliberately designed to influence the opinions or the actions of other
individuals or groups with reference to predetermined ends, which is achieved
by means of well-defined rhetorical and psychological devices. Propaganda
techniques are commonly used in social media to manipulate or to mislead users.
Thus, there has been a lot of recent research on automatic detection of
propaganda techniques in text as well as in memes. However, so far the focus
has been primarily on English. With the aim to bridge this language gap, we ran
a shared task on detecting propaganda techniques in Arabic tweets as part of
the WANLP 2022 workshop, which included two subtasks. Subtask~1 asks to
identify the set of propaganda techniques used in a tweet, which is a
multilabel classification problem, while Subtask~2 asks to detect the
propaganda techniques used in a tweet together with the exact span(s) of text
in which each propaganda technique appears. The task attracted 63 team
registrations, and eventually 14 and 3 teams made submissions for subtask 1 and
2, respectively. Finally, 11 teams submitted system description papers.</p>
  </details>
</details>
<details>
  <summary>25. <b>标题：Clustering based opcode graph generation for malware variant detection</b></summary>
  <p><b>编号</b>：[120]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10048</p>
  <p><b>作者</b>：Kar Wai Fok,  Vrizlynn L. L. Thing</p>
  <p><b>备注</b>：Keywords: malware detection and attribution, malware family, clustering, opcode graph, machine learning; this https URL</p>
  <p><b>关键词</b>：key means leveraged, leveraged by threat, threat actors, cyber space, malware</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Malwares are the key means leveraged by threat actors in the cyber space for
their attacks. There is a large array of commercial solutions in the market and
significant scientific research to tackle the challenge of the detection and
defense against malwares. At the same time, attackers also advance their
capabilities in creating polymorphic and metamorphic malwares to make it
increasingly challenging for existing solutions. To tackle this issue, we
propose a methodology to perform malware detection and family attribution. The
proposed methodology first performs the extraction of opcodes from malwares in
each family and constructs their respective opcode graphs. We explore the use
of clustering algorithms on the opcode graphs to detect clusters of malwares
within the same malware family. Such clusters can be seen as belonging to
different sub-family groups. Opcode graph signatures are built from each
detected cluster. Hence, for each malware family, a group of signatures is
generated to represent the family. These signatures are used to classify an
unknown sample as benign or belonging to one the malware families. We evaluate
our methodology by performing experiments on a dataset consisting of both
benign files and malware samples belonging to a number of different malware
families and comparing the results to existing approach.</p>
  </details>
</details>
<details>
  <summary>26. <b>标题：Vision Transformers in Medical Imaging: A Review</b></summary>
  <p><b>编号</b>：[122]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10043</p>
  <p><b>作者</b>：Emerald U. Henry,  Onyeka Emebob,  Conrad Asotie Omonhinmin</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：natural language processing, comprising attention-based encoder-decoder, model comprising attention-based, attention-based encoder-decoder architecture, computer vision</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Transformer, a model comprising attention-based encoder-decoder architecture,
have gained prevalence in the field of natural language processing (NLP) and
recently influenced the computer vision (CV) space. The similarities between
computer vision and medical imaging, reviewed the question among researchers if
the impact of transformers on computer vision be translated to medical imaging?
In this paper, we attempt to provide a comprehensive and recent review on the
application of transformers in medical imaging by; describing the transformer
model comparing it with a diversity of convolutional neural networks (CNNs),
detailing the transformer based approaches for medical image classification,
segmentation, registration and reconstruction with a focus on the image
modality, comparing the performance of state-of-the-art transformer
architectures to best performing CNNs on standard medical datasets.</p>
  </details>
</details>
<details>
  <summary>27. <b>标题：Why pseudo label based algorithm is effective? --from the perspective of  pseudo labeled data</b></summary>
  <p><b>编号</b>：[124]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10039</p>
  <p><b>作者</b>：Zeping Min,  Cheng Tai</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：label based semi-supervised, pseudo label based, based semi-supervised learning, label based, based semi-supervised</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recently, pseudo label based semi-supervised learning has achieved great
success in many fields. The core idea of the pseudo label based semi-supervised
learning algorithm is to use the model trained on the labeled data to generate
pseudo labels on the unlabeled data, and then train a model to fit the
previously generated pseudo labels. We give a theory analysis for why pseudo
label based semi-supervised learning is effective in this paper. We mainly
compare the generalization error of the model trained under two settings: (1)
There are N labeled data. (2) There are N unlabeled data and a suitable initial
model. Our analysis shows that, firstly, when the amount of unlabeled data
tends to infinity, the pseudo label based semi-supervised learning algorithm
can obtain model which have the same generalization error upper bound as model
obtained by normally training in the condition of the amount of labeled data
tends to infinity. More importantly, we prove that when the amount of unlabeled
data is large enough, the generalization error upper bound of the model
obtained by pseudo label based semi-supervised learning algorithm can converge
to the optimal upper bound with linear convergence rate. We also give the lower
bound on sampling complexity to achieve linear convergence rate. Our analysis
contributes to understanding the empirical successes of pseudo label-based
semi-supervised learning.</p>
  </details>
</details>
<details>
  <summary>28. <b>标题：Contrastive Knowledge Graph Error Detection</b></summary>
  <p><b>编号</b>：[126]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10030</p>
  <p><b>作者</b>：Qinggang Zhang,  Junnan Dong,  Keyu Duan,  Xiao Huang,  Yezi Liu,  Linchuan Xu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：severely affecting KG-related, KG-related downstream tasks, affecting KG-related downstream, introduce non-negligible noise, non-negligible noise</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Knowledge Graph (KG) errors introduce non-negligible noise, severely
affecting KG-related downstream tasks. Detecting errors in KGs is challenging
since the patterns of errors are unknown and diverse, while ground-truth labels
are rare or even unavailable. A traditional solution is to construct logical
rules to verify triples, but it is not generalizable since different KGs have
distinct rules with domain knowledge involved. Recent studies focus on
designing tailored detectors or ranking triples based on KG embedding loss.
However, they all rely on negative samples for training, which are generated by
randomly replacing the head or tail entity of existing triples. Such a negative
sampling strategy is not enough for prototyping practical KG errors, e.g.,
(Bruce_Lee, place_of_birth, China), in which the three elements are often
relevant, although mismatched. We desire a more effective unsupervised learning
mechanism tailored for KG error detection. To this end, we propose a novel
framework - ContrAstive knowledge Graph Error Detection (CAGED). It introduces
contrastive learning into KG learning and provides a novel way of modeling KG.
Instead of following the traditional setting, i.e., considering entities as
nodes and relations as semantic edges, CAGED augments a KG into different
hyper-views, by regarding each relational triple as a node. After joint
training with KG embedding and contrastive learning loss, CAGED assesses the
trustworthiness of each triple based on two learning signals, i.e., the
consistency of triple representations across multi-views and the
self-consistency within the triple. Extensive experiments on three real-world
KGs show that CAGED outperforms state-of-the-art methods in KG error detection.
Our codes and datasets are available at this https URL.</p>
  </details>
</details>
<details>
  <summary>29. <b>标题：Diagnostics for Deep Neural Networks with Automated Copy/Paste Attacks</b></summary>
  <p><b>编号</b>：[129]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10024</p>
  <p><b>作者</b>：Stephen Casper,  Kaivalya Hariharan,  Dylan Hadfield-Menell</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Deep neural networks, pose significant risks, Deep neural, neural networks, significant risks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep neural networks (DNNs) are powerful, but they can make mistakes that
pose significant risks. A model performing well on a test set does not imply
safety in deployment, so it is important to have additional tools to understand
its flaws. Adversarial examples can help reveal weaknesses, but they are often
difficult for a human to interpret or draw generalizable, actionable
conclusions from. Some previous works have addressed this by studying
human-interpretable attacks. We build on these with three contributions. First,
we introduce a method termed Search for Natural Adversarial Features Using
Embeddings (SNAFUE) which offers a fully-automated method for finding
"copy/paste" attacks in which one natural image can be pasted into another in
order to induce an unrelated misclassification. Second, we use this to red team
an ImageNet classifier and identify hundreds of easily-describable sets of
vulnerabilities. Third, we compare this approach with other interpretability
tools by attempting to rediscover trojans. Our results suggest that SNAFUE can
be useful for interpreting DNNs and generating adversarial data for them. Code
is available at this https URL</p>
  </details>
</details>
<details>
  <summary>30. <b>标题：Who Says Elephants Can't Run: Bringing Large Scale MoE Models into Cloud  Scale Production</b></summary>
  <p><b>编号</b>：[134]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10017</p>
  <p><b>作者</b>：Young Jin Kim,  Rawn Henry,  Raffy Fahim,  Hany Hassan Awadalla</p>
  <p><b>备注</b>：Accepted to SustaiNLP 2022 (EMNLP 2022)</p>
  <p><b>关键词</b>：sparsely activated layers, enabled training models, number of parameters, conditional execution, execution of sparsely</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Mixture of Experts (MoE) models with conditional execution of sparsely
activated layers have enabled training models with a much larger number of
parameters. As a result, these models have achieved significantly better
quality on various natural language processing tasks including machine
translation. However, it remains challenging to deploy such models in real-life
scenarios due to the large memory requirements and inefficient inference. In
this work, we introduce a highly efficient inference framework with several
optimization approaches to accelerate the computation of sparse models and cut
down the memory consumption significantly. While we achieve up to 26x speed-up
in terms of throughput, we also reduce the model size almost to one eighth of
the original 32-bit float model by quantizing expert weights into 4-bit
integers. As a result, we are able to deploy 136x larger models with 27% less
cost and significantly better quality compared to the existing solutions. This
enables a paradigm shift in deploying large scale multilingual MoE transformers
models replacing the traditional practice of distilling teacher models into
dozens of smaller models per language or task.</p>
  </details>
</details>
<details>
  <summary>31. <b>标题：Structural Quality Metrics to Evaluate Knowledge Graphs</b></summary>
  <p><b>编号</b>：[137]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10011</p>
  <p><b>作者</b>：Sumin Seo,  Heeseon Cheon,  Hyunho Kim,  Dongseok Hyun</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Naver integrated knowledge, Google Knowledge Graph, cross-domain knowledge graphs, integrated knowledge graph, Good Knowledge Graph</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This work presents six structural quality metrics that can measure the
quality of knowledge graphs and analyzes five cross-domain knowledge graphs on
the web (Wikidata, DBpedia, YAGO, Google Knowledge Graph, Freebase) as well as
'Raftel', Naver's integrated knowledge graph. The 'Good Knowledge Graph' should
define detailed classes and properties in its ontology so that knowledge in the
real world can be expressed abundantly. Also, instances and RDF triples should
use the classes and properties actively. Therefore, we tried to examine the
internal quality of knowledge graphs numerically by focusing on the structure
of the ontology, which is the schema of knowledge graphs, and the degree of use
thereof. As a result of the analysis, it was possible to find the
characteristics of a knowledge graph that could not be known only by
scale-related indicators such as the number of classes and properties.</p>
  </details>
</details>
<details>
  <summary>32. <b>标题：Confounder Balancing for Instrumental Variable Regression with Latent  Variable</b></summary>
  <p><b>编号</b>：[138]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10008</p>
  <p><b>作者</b>：Anpeng Wu,  Kun Kuang,  Ruoxuan Xiong,  Bo Li,  Fei Wu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：unbiased causal effect, causal effect estimation, observed confounders, paper studies, studies the confounding</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper studies the confounding effects from the unmeasured confounders
and the imbalance of observed confounders in IV regression and aims at unbiased
causal effect estimation. Recently, nonlinear IV estimators were proposed to
allow for nonlinear model in both stages. However, the observed confounders may
be imbalanced in stage 2, which could still lead to biased treatment effect
estimation in certain cases. To this end, we propose a Confounder Balanced IV
Regression (CB-IV) algorithm to jointly remove the bias from the unmeasured
confounders and the imbalance of observed confounders. Theoretically, by
redefining and solving an inverse problem for potential outcome function, we
show that our CB-IV algorithm can unbiasedly estimate treatment effects and
achieve lower variance. The IV methods have a major disadvantage in that little
prior or theory is currently available to pre-define a valid IV in real-world
scenarios. Thus, we study two more challenging settings without pre-defined
valid IVs: (1) indistinguishable IVs implicitly present in observations, i.e.,
mixed-variable challenge, and (2) latent IVs don't appear in observations,
i.e., latent-variable challenge. To address these two challenges, we extend our
CB-IV by a latent-variable module, namely CB-IV-L algorithm. Extensive
experiments demonstrate that our CB-IV(-L) outperforms the existing approaches.</p>
  </details>
</details>
<details>
  <summary>33. <b>标题：Influential Recommender System</b></summary>
  <p><b>编号</b>：[140]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10002</p>
  <p><b>作者</b>：Haoren Zhu,  Hao Ge,  Xiaodong Gu,  Pengfei Zhao,  Dik Lun Lee</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Traditional recommender systems, user historical interests, typically passive, Influential Recommender Network, user</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Traditional recommender systems are typically passive in that they try to
adapt their recommendations to the user's historical interests. However, it is
highly desirable for commercial applications, such as e-commerce, advertisement
placement, and news portals, to be able to expand the users' interests so that
they would accept items that they were not originally aware of or interested in
to increase customer interactions. In this paper, we present Influential
Recommender System (IRS), a new recommendation paradigm that aims to
proactively lead a user to like a given objective item by progressively
recommending to the user a sequence of carefully selected items (called an
influence path). We propose the Influential Recommender Network (IRN), which is
a Transformer-based sequential model to encode the items' sequential
dependencies. Since different people react to external influences differently,
we introduce the Personalized Impressionability Mask (PIM) to model how
receptive a user is to external influence to generate the most effective
influence path for the user. To evaluate IRN, we design several performance
metrics to measure whether or not the influence path can smoothly expand the
user interest to include the objective item while maintaining the user's
satisfaction with the recommendation. Experimental results show that IRN
significantly outperforms the baseline recommenders and demonstrates its
capability of influencing users' interests.</p>
  </details>
</details>
<details>
  <summary>34. <b>标题：Look More but Care Less in Video Recognition</b></summary>
  <p><b>编号</b>：[144]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.09992</p>
  <p><b>作者</b>：Yitian Zhang,  Yue Bai,  Huan Wang,  Yi Xu,  Yun Fu</p>
  <p><b>备注</b>：Accepted by NeurIPS 2022</p>
  <p><b>关键词</b>：Existing action recognition, action recognition methods, recognition methods typically, methods typically sample, recognition performance</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Existing action recognition methods typically sample a few frames to
represent each video to avoid the enormous computation, which often limits the
recognition performance. To tackle this problem, we propose Ample and Focal
Network (AFNet), which is composed of two branches to utilize more frames but
with less computation. Specifically, the Ample Branch takes all input frames to
obtain abundant information with condensed computation and provides the
guidance for Focal Branch by the proposed Navigation Module; the Focal Branch
squeezes the temporal size to only focus on the salient frames at each
convolution block; in the end, the results of two branches are adaptively fused
to prevent the loss of information. With this design, we can introduce more
frames to the network but cost less computation. Besides, we demonstrate AFNet
can utilize fewer frames while achieving higher accuracy as the dynamic
selection in intermediate features enforces implicit temporal modeling.
Further, we show that our method can be extended to reduce spatial redundancy
with even less cost. Extensive experiments on five datasets demonstrate the
effectiveness and efficiency of our method.</p>
  </details>
</details>
<details>
  <summary>35. <b>标题：Pandering in a Flexible Representative Democracy</b></summary>
  <p><b>编号</b>：[145]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.09986</p>
  <p><b>作者</b>：Xiaolin Sun,  Jacob Masur,  Ben Abramowitz,  Nicholas Mattei,  Zizhan Zheng</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：regular election cycles, meant to prevent, prevent corruption, accountable in service, Flexible Representative Democracy</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In representative democracies, the election of new representatives in regular
election cycles is meant to prevent corruption and other misbehavior by elected
officials and to keep them accountable in service of the ``will of the people."
This democratic ideal can be undermined when candidates are dishonest when
campaigning for election over these multiple cycles or rounds of voting. Much
of the work on COMSOC to date has investigated strategic actions in only a
single round. We introduce a novel formal model of \emph{pandering}, or
strategic preference reporting by candidates seeking to be elected, and examine
the resilience of two democratic voting systems to pandering within a single
round and across multiple rounds. The two voting systems we compare are
Representative Democracy (RD) and Flexible Representative Democracy (FRD). For
each voting system, our analysis centers on the types of strategies candidates
employ and how voters update their views of candidates based on how the
candidates have pandered in the past. We provide theoretical results on the
complexity of pandering in our setting for a single cycle, formulate our
problem for multiple cycles as a Markov Decision Process, and use reinforcement
learning to study the effects of pandering by both single candidates and groups
of candidates across a number of rounds.</p>
  </details>
</details>
<details>
  <summary>36. <b>标题：Weighted Ensemble Self-Supervised Learning</b></summary>
  <p><b>编号</b>：[148]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.09981</p>
  <p><b>作者</b>：Yangjun Ruan,  Saurabh Singh,  Warren Morningstar,  Alexander A. Alemi,  Sergey Ioffe,  Ian Fischer,  Joshua V. Dillon</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：boosting model performance, uncertainty estimation, supervised learning performance, boosting model, model performance</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Ensembling has proven to be a powerful technique for boosting model
performance, uncertainty estimation, and robustness in supervised learning.
Advances in self-supervised learning (SSL) enable leveraging large unlabeled
corpora for state-of-the-art few-shot and supervised learning performance. In
this paper, we explore how ensemble methods can improve recent SSL techniques
by developing a framework that permits data-dependent weighted cross-entropy
losses. We refrain from ensembling the representation backbone; this choice
yields an efficient ensemble method that incurs a small training cost and
requires no architectural changes or computational overhead to downstream
evaluation. The effectiveness of our method is demonstrated with two
state-of-the-art SSL methods, DINO (Caron et al., 2021) and MSN (Assran et al.,
2022). Our method outperforms both in multiple evaluation metrics on
ImageNet-1K, particularly in the few-shot setting. We explore several weighting
schemes and find that those which increase the diversity of ensemble heads lead
to better downstream evaluation results. Thorough experiments yield improved
prior art baselines which our method still surpasses; e.g., our overall
improvement with MSN ViT-B/16 is 3.9 p.p. for 1-shot learning.</p>
  </details>
</details>
<details>
  <summary>37. <b>标题：Estimating defection in subscription-type markets: empirical analysis  from the scholarly publishing industry</b></summary>
  <p><b>编号</b>：[153]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.09970</p>
  <p><b>作者</b>：Michael Roberts,  J. Ignacio Deza,  Hisham Ihshaish,  Yanhui Zhu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：scholarly publishing industry, empirical study, customer churn prediction, publishing industry, scholarly publishing business</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present the first empirical study on customer churn prediction in the
scholarly publishing industry. The study examines our proposed method for
prediction on a customer subscription data over a period of 6.5 years, which
was provided by a major academic publisher. We explore the subscription-type
market within the context of customer defection and modelling, and provide
analysis of the business model of such markets, and how these characterise the
academic publishing business. The proposed method for prediction attempts to
provide inference of customer's likelihood of defection on the basis of their
re-sampled use of provider resources -in this context, the volume and frequency
of content downloads. We show that this approach can be both accurate as well
as uniquely useful in the business-to-business context, with which the
scholarly publishing business model shares similarities. The main findings of
this work suggest that whilst all predictive models examined, especially
ensemble methods of machine learning, achieve substantially accurate prediction
of churn, nearly a year ahead, this can be furthermore achieved even when the
specific behavioural attributes that can be associated to each customer
probability to churn are overlooked. Allowing as such highly accurate inference
of churn from minimal possible data. We show that modelling churn on the basis
of re-sampling customers' use of resources over subscription time is a better
(simplified) approach than when considering the high granularity that can often
characterise consumption behaviour.</p>
  </details>
</details>
<details>
  <summary>38. <b>标题：Ask4Help: Learning to Leverage an Expert for Embodied Tasks</b></summary>
  <p><b>编号</b>：[158]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.09960</p>
  <p><b>作者</b>：Kunal Pratap Singh,  Luca Weihs,  Alvaro Herrasti,  Jonghyun Choi,  Aniruddha Kemhavi,  Roozbeh Mottaghi</p>
  <p><b>备注</b>：Accepted at NeurIPS, 2022</p>
  <p><b>关键词</b>：deployed in real, capable every year, performant and reliable, agents continue, agents</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Embodied AI agents continue to become more capable every year with the advent
of new models, environments, and benchmarks, but are still far away from being
performant and reliable enough to be deployed in real, user-facing,
applications. In this paper, we ask: can we bridge this gap by enabling agents
to ask for assistance from an expert such as a human being? To this end, we
propose the Ask4Help policy that augments agents with the ability to request,
and then use expert assistance. Ask4Help policies can be efficiently trained
without modifying the original agent's parameters and learn a desirable
trade-off between task performance and the amount of requested help, thereby
reducing the cost of querying the expert. We evaluate Ask4Help on two different
tasks -- object goal navigation and room rearrangement and see substantial
improvements in performance using minimal help. On object navigation, an agent
that achieves a $52\%$ success rate is raised to $86\%$ with $13\%$ help and
for rearrangement, the state-of-the-art model with a $7\%$ success rate is
dramatically improved to $90.4\%$ using $39\%$ help. Human trials with Ask4Help
demonstrate the efficacy of our approach in practical scenarios. We release the
code for Ask4Help here: this https URL.</p>
  </details>
</details>
<details>
  <summary>39. <b>标题：Potential Auto-driving Threat: Universal Rain-removal Attack</b></summary>
  <p><b>编号</b>：[159]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.09959</p>
  <p><b>作者</b>：Jinchegn Hu,  Jihao Li,  Zhuoran Hou,  Jingjing Jiang,  Cunjia Liu,  Yuanjian Zhang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：adverse weather conditions, computer vision algorithms, robustness in adverse, adverse weather, weather conditions</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The problem of robustness in adverse weather conditions is considered a
significant challenge for computer vision algorithms in the applicants of
autonomous driving. Image rain removal algorithms are a general solution to
this problem. They find a deep connection between raindrops/rain-streaks and
images by mining the hidden features and restoring information about the
rain-free environment based on the powerful representation capabilities of
neural networks. However, previous research has focused on architecture
innovations and has yet to consider the vulnerability issues that already exist
in neural networks. This research gap hints at a potential security threat
geared toward the intelligent perception of autonomous driving in the rain. In
this paper, we propose a universal rain-removal attack (URA) on the
vulnerability of image rain-removal algorithms by generating a non-additive
spatial perturbation that significantly reduces the similarity and image
quality of scene restoration. Notably, this perturbation is difficult to
recognise by humans and is also the same for different target images. Thus, URA
could be considered a critical tool for the vulnerability detection of image
rain-removal algorithms. It also could be developed as a real-world artificial
intelligence attack method. Experimental results show that URA can reduce the
scene repair capability by 39.5% and the image generation quality by 26.4%,
targeting the state-of-the-art (SOTA) single-image rain-removal algorithms
currently available.</p>
  </details>
</details>
<details>
  <summary>40. <b>标题：Explainability Via Causal Self-Talk</b></summary>
  <p><b>编号</b>：[170]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.09937</p>
  <p><b>作者</b>：Nicholas A. Roy,  Junkyung Kim,  Neil Rabinowitz</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：generally avoided, important problem, deep learning community, wider deep learning, deep learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Explaining the behavior of AI systems is an important problem that, in
practice, is generally avoided. While the XAI community has been developing an
abundance of techniques, most incur a set of costs that the wider deep learning
community has been unwilling to pay in most situations. We take a pragmatic
view of the issue, and define a set of desiderata that capture both the
ambitions of XAI and the practical constraints of deep learning. We describe an
effective way to satisfy all the desiderata: train the AI system to build a
causal model of itself. We develop an instance of this solution for Deep RL
agents: Causal Self-Talk. CST operates by training the agent to communicate
with itself across time. We implement this method in a simulated 3D
environment, and show how it enables agents to generate faithful and
semantically-meaningful explanations of their own behavior. Beyond
explanations, we also demonstrate that these learned models provide new ways of
building semantic control interfaces to AI systems.</p>
  </details>
</details>
<details>
  <summary>41. <b>标题：Planning with Large Language Models via Corrective Re-prompting</b></summary>
  <p><b>编号</b>：[171]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.09935</p>
  <p><b>作者</b>：Shreyas Sundara Raman,  Vanya Cohen,  Eric Rosen,  Ifrah Idrees,  David Paulius,  Stefanie Tellex</p>
  <p><b>备注</b>：21 pages, 7 figures, Accepted to Foundation Models for Decision Making Workshop at Neural Information Processing Systems 2022</p>
  <p><b>关键词</b>：Large Language Models, Language Models, Large Language, common sense knowledge, sense knowledge present</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Extracting the common sense knowledge present in Large Language Models (LLMs)
offers a path to designing intelligent, embodied agents. Related works have
queried LLMs with a wide-range of contextual information, such as goals, sensor
observations and scene descriptions, to generate high-level action plans for
specific tasks; however these approaches often involve human intervention or
additional machinery to enable sensor-motor interactions. In this work, we
propose a prompting-based strategy for extracting executable plans from an LLM,
which leverages a novel and readily-accessible source of information:
precondition errors. Our approach assumes that actions are only afforded
execution in certain contexts, i.e., implicit preconditions must be met for an
action to execute (e.g., a door must be unlocked to open it), and that the
embodied agent has the ability to determine if the action is/is not executable
in the current context (e.g., detect if a precondition error is present). When
an agent is unable to execute an action, our approach re-prompts the LLM with
precondition error information to extract an executable corrective action to
achieve the intended goal in the current context. We evaluate our approach in
the VirtualHome simulation environment on 88 different tasks and 7 scenes. We
evaluate different prompt templates and compare to methods that naively
re-sample actions from the LLM. Our approach, using precondition errors,
improves executability and semantic correctness of plans, while also reducing
the number of re-prompts required when querying actions.</p>
  </details>
</details>
<details>
  <summary>42. <b>标题：Proceedings of the 2nd Workshop on Logic and Practice of Programming  (LPOP)</b></summary>
  <p><b>编号</b>：[179]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.09923</p>
  <p><b>作者</b>：David S. Warren,  Peter Van Roy,  Yanhong A. Liu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：ACM SIGPLAN Conference, Practice of Programming, proceedings contains abstracts, abstracts and position, position papers</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This proceedings contains abstracts and position papers for the work
presented at the second Logic and Practice of Programming (LPOP) Workshop. The
workshop was held online, virtually in place of Chicago, USA, on November 15,
2010, in conjunction with the ACM SIGPLAN Conference on Systems, Programming,
Languages, and Applications: Software for Humanity (SPLASH) 2020. The purpose
of this workshop is to be a bridge between different areas of computer science
that use logic as a practical tool. We take advantage of the common language of
formal logic to exchange ideas between these different areas.</p>
  </details>
</details>
<details>
  <summary>43. <b>标题：Multi-source Domain Adaptation for Text-independent Forensic Speaker  Recognition</b></summary>
  <p><b>编号</b>：[182]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.09913</p>
  <p><b>作者</b>：Zhenyu Wang,  John H. L. Hansen</p>
  <p><b>备注</b>：IEEE/ACM TRANSACTIONS ON AUDIO, SPEECH, AND LANGUAGE PROCESSING</p>
  <p><b>关键词</b>：well-performing model learned, Adapting speaker recognition, speaker recognition, task-specific small-scale data, widely-used technique</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Adapting speaker recognition systems to new environments is a widely-used
technique to improve a well-performing model learned from large-scale data
towards a task-specific small-scale data scenarios. However, previous studies
focus on single domain adaptation, which neglects a more practical scenario
where training data are collected from multiple acoustic domains needed in
forensic scenarios. Audio analysis for forensic speaker recognition offers
unique challenges in model training with multi-domain training data due to
location/scenario uncertainty and diversity mismatch between reference and
naturalistic field recordings. It is also difficult to directly employ
small-scale domain-specific data to train complex neural network architectures
due to domain mismatch and performance loss. Fine-tuning is a commonly-used
method for adaptation in order to retrain the model with weights initialized
from a well-trained model. Alternatively, in this study, three novel adaptation
methods based on domain adversarial training, discrepancy minimization, and
moment-matching approaches are proposed to further promote adaptation
performance across multiple acoustic domains. A comprehensive set of
experiments are conducted to demonstrate that: 1) diverse acoustic environments
do impact speaker recognition performance, which could advance research in
audio forensics, 2) domain adversarial training learns the discriminative
features which are also invariant to shifts between domains, 3)
discrepancy-minimizing adaptation achieves effective performance simultaneously
across multiple acoustic domains, and 4) moment-matching adaptation along with
dynamic distribution alignment also significantly promotes speaker recognition
performance on each domain, especially for the LENA-field domain with noise
compared to all other systems.</p>
  </details>
</details>
<details>
  <summary>44. <b>标题：Summarizing Community-based Question-Answer Pairs</b></summary>
  <p><b>编号</b>：[186]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.09892</p>
  <p><b>作者</b>：Ting-Yao Hsu,  Yoshi Suhara,  Xiaolan Wang</p>
  <p><b>备注</b>：To appear in EMNLP 2022 main conference</p>
  <p><b>关键词</b>：Community-based Question Answering, Question Answering, Community-based Question, CQA summarization task, CQA pairs</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Community-based Question Answering (CQA), which allows users to acquire their
desired information, has increasingly become an essential component of online
services in various domains such as E-commerce, travel, and dining. However, an
overwhelming number of CQA pairs makes it difficult for users without
particular intent to find useful information spread over CQA pairs. To help
users quickly digest the key information, we propose the novel CQA
summarization task that aims to create a concise summary from CQA pairs. To
this end, we first design a multi-stage data annotation process and create a
benchmark dataset, CoQASUM, based on the Amazon QA corpus. We then compare a
collection of extractive and abstractive summarization methods and establish a
strong baseline approach DedupLED for the CQA summarization task. Our
experiment further confirms two key challenges, sentence-type transfer and
deduplication removal, towards the CQA summarization task. Our data and code
are publicly available.</p>
  </details>
</details>
<details>
  <summary>45. <b>标题：Robust Vocal Quality Feature Embeddings for Dysphonic Voice Detection</b></summary>
  <p><b>编号</b>：[193]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.09858</p>
  <p><b>作者</b>：Jianwei Zhang,  Julie Liss,  Suren Jayasuriya,  Visar Berisha</p>
  <p><b>备注</b>：This manuscript is submitted on July 06, 2022 to IEEE/ACM Transactions on Audio, Speech, and Language Processing for peer-review</p>
  <p><b>关键词</b>：impaired voice production, world population, population has impaired, voice production, voice</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Approximately 1.2% of the world's population has impaired voice production.
As a result, automatic dysphonic voice detection has attracted considerable
academic and clinical interest. However, existing methods for automated voice
assessment often fail to generalize outside the training conditions or to other
related applications. In this paper, we propose a deep learning framework for
generating acoustic feature embeddings sensitive to vocal quality and robust
across different corpora. A contrastive loss is combined with a classification
loss to train our deep learning model jointly. Data warping methods are used on
input voice samples to improve the robustness of our method. Empirical results
demonstrate that our method not only achieves high in-corpus and cross-corpus
classification accuracy but also generates good embeddings sensitive to voice
quality and robust across different corpora. We also compare our results
against three baseline methods on clean and three variations of deteriorated
in-corpus and cross-corpus datasets and demonstrate that the proposed model
consistently outperforms the baseline methods.</p>
  </details>
</details>
<details>
  <summary>46. <b>标题：CoLI-Machine Learning Approaches for Code-mixed Language Identification  at the Word Level in Kannada-English Texts</b></summary>
  <p><b>编号</b>：[197]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.09847</p>
  <p><b>作者</b>：H.L. Shashirekha,  F. Balouchzahi,  M.D. Anusha,  G. Sidorov</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：called Language Identification, Language Identification, learning, Identification, task of automatically</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The task of automatically identifying a language used in a given text is
called Language Identification (LI). India is a multilingual country and many
Indians especially youths are comfortable with Hindi and English, in addition
to their local languages. Hence, they often use more than one language to post
their comments on social media. Texts containing more than one language are
called "code-mixed texts" and are a good source of input for LI. Languages in
these texts may be mixed at sentence level, word level or even at sub-word
level. LI at word level is a sequence labeling problem where each and every
word in a sentence is tagged with one of the languages in the predefined set of
languages. In order to address word level LI in code-mixed Kannada-English
(Kn-En) texts, this work presents i) the construction of code-mixed Kn-En
dataset called CoLI-Kenglish dataset, ii) code-mixed Kn-En embedding and iii)
learning models using Machine Learning (ML), Deep Learning (DL) and Transfer
Learning (TL) approaches. Code-mixed Kn-En texts are extracted from Kannada
YouTube video comments to construct CoLI-Kenglish dataset and code-mixed Kn-En
embedding. The words in CoLI-Kenglish dataset are grouped into six major
categories, namely, "Kannada", "English", "Mixed-language", "Name", "Location"
and "Other". The learning models, namely, CoLI-vectors and CoLI-ngrams based on
ML, CoLI-BiLSTM based on DL and CoLI-ULMFiT based on TL approaches are built
and evaluated using CoLI-Kenglish dataset. The performances of the learning
models illustrated, the superiority of CoLI-ngrams model, compared to other
models with a macro average F1-score of 0.64. However, the results of all the
learning models were quite competitive with each other.</p>
  </details>
</details>
<details>
  <summary>47. <b>标题：Deep learning for Lagrangian drift simulation at the sea surface</b></summary>
  <p><b>编号</b>：[199]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.09818</p>
  <p><b>作者</b>：Daria Botvynko (Lab-STICC\_OSE, IMT Atlantique - MEE, ENIB),  Carlos Granero-Belinchon,  Simon Van Gennip,  Abdesslam Benzinou (ENIB),  Ronan Fablet</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：deep learning approaches, model-based and Markovian, Lagrangian drift simulation, address Lagrangian drift, Markovian approaches</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We address Lagrangian drift simulation in geophysical dynamics and explore
deep learning approaches to overcome known limitations of state-of-the-art
model-based and Markovian approaches in terms of computational complexity and
error propagation. We introduce a novel architecture, referred to as DriftNet,
inspired from the Eulerian Fokker-Planck representation of Lagrangian dynamics.
Numerical experiments for Lagrangian drift simulation at the sea surface
demonstrates the relevance of DriftNet w.r.t. state-of-the-art schemes.
Benefiting from the fully-convolutional nature of Drift-Net, we explore through
a neural inversion how to diagnose modelderived velocities w.r.t. real drifter
trajectories.</p>
  </details>
</details>
<details>
  <summary>48. <b>标题：Hierarchical Estimation for Effective and Efficient Sampling Graph  Neural Network</b></summary>
  <p><b>编号</b>：[202]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.09813</p>
  <p><b>作者</b>：Yang Li,  Bingbing Xu,  Qi Cao,  Yige Yuan,  Huawei Shen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：critical for large, sampling, node embeddings, node, variance</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Improving the scalability of GNNs is critical for large graphs. Existing
methods leverage three sampling paradigms including node-wise, layer-wise and
subgraph sampling, then design unbiased estimator for scalability. However, the
high variance still severely hinders GNNs' performance. On account that
previous studies either lacks variance analysis or only focus on a particular
sampling paradigm, we firstly propose an unified node sampling variance
analysis framework and analyze the core challenge "circular dependency" for
deriving the minimum variance sampler, i. e., sampling probability depends on
node embeddings while node embeddings can not be calculated until sampling is
finished. Existing studies either ignore the node embeddings or introduce
external parameters, resulting in the lack of a both efficient and effective
variance reduction methods. Therefore, we propose the \textbf{H}ierarchical
\textbf{E}stimation based \textbf{S}ampling GNN (HE-SGNN) with first level
estimating the node embeddings in sampling probability to break circular
dependency, and second level employing sampling GNN operator to estimate the
nodes' representations on the entire graph. Considering the technical
difference, we propose different first level estimator, i.e., a time series
simulation for layer-wise sampling and a feature based simulation for subgraph
sampling. The experimental results on seven representative datasets demonstrate
the effectiveness and efficiency of our method.</p>
  </details>
</details>
<details>
  <summary>49. <b>标题：GAMMT: Generative Ambiguity Modeling Using Multiple Transformers</b></summary>
  <p><b>编号</b>：[203]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.09812</p>
  <p><b>作者</b>：Xingcheng Xu</p>
  <p><b>备注</b>：10 pages, 2 figures, 3 algorithms</p>
  <p><b>关键词</b>：model based, Generative Ambiguity Models, sequential data, model, model GAMMT</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We introduce a new model based on sets of probabilities for sequential data.
We name the model GAMMT, which stands for Generative Ambiguity Models using
Multiple Transformers. We suppose that data generating process of a sequence is
ambiguous and determined by a set of probabilities rather than one as in the
conventional model. We use multiple parallel transformers connected by a
selection mechanism to approximate ambiguous probabilities. The GAMMT allows
for ambiguity modeling in a generative way and multiple representations of the
input tokens and the input sequence. This work explores the combination of
attention mechanism and ambiguity by deep neural networks. We expect that this
framework will facilitate new research into machine learning, improving our
understanding of the attention-ambiguity mechanism.</p>
  </details>
</details>
<details>
  <summary>50. <b>标题：Certifying Robustness of Convolutional Neural Networks with Tight Linear  Approximation</b></summary>
  <p><b>编号</b>：[204]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.09810</p>
  <p><b>作者</b>：Yuan Xiao,  Tongtong Bai,  Mingzheng Gu,  Chunrong Fang,  Zhenyu Chen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：neural network classifiers, Convolutional Neural Networks, safety-critical domain, robustness, Neuron-wise Tightest</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The robustness of neural network classifiers is becoming important in the
safety-critical domain and can be quantified by robustness verification.
However, at present, efficient and scalable verification techniques are always
sound but incomplete. Therefore, the improvement of certified robustness bounds
is the key criterion to evaluate the superiority of robustness verification
approaches. In this paper, we present a Tight Linear approximation approach for
robustness verification of Convolutional Neural Networks(Ti-Lin). For general
CNNs, we first provide a new linear constraints for S-shaped activation
functions, which is better than both existing Neuron-wise Tightest and
Network-wise Tightest tools. We then propose Neuron-wise Tightest linear bounds
for Maxpool function. We implement Ti-Lin, the resulting verification method.
We evaluate it with 48 different CNNs trained on MNIST, CIFAR-10, and Tiny
ImageNet datasets. Experimental results show that Ti-Lin significantly
outperforms other five state-of-the-art methods(CNN-Cert, DeepPoly, DeepCert,
VeriNet, Newise). Concretely, Ti-Lin certifies much more precise robustness
bounds on pure CNNs with Sigmoid/Tanh/Arctan functions and CNNs with Maxpooling
function with at most 63.70% and 253.54% improvement, respectively.</p>
  </details>
</details>
<details>
  <summary>51. <b>标题：A Neural Active Inference Model of Perceptual-Motor Learning</b></summary>
  <p><b>编号</b>：[207]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10419</p>
  <p><b>作者</b>：Zhizhuo Yang,  Gabriel J. Diaz,  Brett R. Fajen,  Reynold Bailey,  Alexander Ororbia</p>
  <p><b>备注</b>：16 pages including references, 6 figures. Submitted to Frontiers in Computational Neuroscience</p>
  <p><b>关键词</b>：active inference framework, computational framework grounded, produce human-like behavior, inference framework, computational framework</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The active inference framework (AIF) is a promising new computational
framework grounded in contemporary neuroscience that can produce human-like
behavior through reward-based learning. In this study, we test the ability for
the AIF to capture the role of anticipation in the visual guidance of action in
humans through the systematic investigation of a visual-motor task that has
been well-explored -- that of intercepting a target moving over a ground plane.
Previous research demonstrated that humans performing this task resorted to
anticipatory changes in speed intended to compensate for semi-predictable
changes in target speed later in the approach. To capture this behavior, our
proposed "neural" AIF agent uses artificial neural networks to select actions
on the basis of a very short term prediction of the information about the task
environment that these actions would reveal along with a long-term estimate of
the resulting cumulative expected free energy. Systematic variation revealed
that anticipatory behavior emerged only when required by limitations on the
agent's movement capabilities, and only when the agent was able to estimate
accumulated free energy over sufficiently long durations into the future. In
addition, we present a novel formulation of the prior function that maps a
multi-dimensional world-state to a uni-dimensional distribution of free-energy.
Together, these results demonstrate the use of AIF as a plausible model of
anticipatory visually guided behavior in humans.</p>
  </details>
</details>
<details>
  <summary>52. <b>标题：Arbitrarily Accurate Classification Applied to Specific Emitter  Identification</b></summary>
  <p><b>编号</b>：[213]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10379</p>
  <p><b>作者</b>：Michael C. Kleder</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：obtaining arbitrary accuracy, article introduces, introduces a method, method of evaluating, obtaining arbitrary</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This article introduces a method of evaluating subsamples until any
prescribed level of classification accuracy is attained, thus obtaining
arbitrary accuracy. A logarithmic reduction in error rate is obtained with a
linear increase in sample count. The technique is applied to specific emitter
identification on a published dataset of physically recorded over-the-air
signals from 16 ostensibly identical high-performance radios. The technique
uses a multi-channel deep learning convolutional neural network acting on the
bispectra of I/Q signal subsamples each consisting of 56 parts per million
(ppm) of the original signal duration. High levels of accuracy are obtained
with minimal computation time: in this application, each addition of eight
samples decreases error by one order of magnitude.</p>
  </details>
</details>
<details>
  <summary>53. <b>标题：Always Valid Risk Monitoring for Online Matrix Completion</b></summary>
  <p><b>编号</b>：[215]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10363</p>
  <p><b>作者</b>：Chi-Hua Wang,  Wenjie Li</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：inequalities are increasingly, performance measures, generative models, models and supervised, statistical learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Always-valid concentration inequalities are increasingly used as performance
measures for online statistical learning, notably in the learning of generative
models and supervised learning. Such inequality advances the online learning
algorithms design by allowing random, adaptively chosen sample sizes instead of
a fixed pre-specified size in offline statistical learning. However,
establishing such an always-valid type result for the task of matrix completion
is challenging and far from understood in the literature. Due to the importance
of such type of result, this work establishes and devises the always-valid risk
bound process for online matrix completion problems. Such theoretical advances
are made possible by a novel combination of non-asymptotic martingale
concentration and regularized low-rank matrix regression. Our result enables a
more sample-efficient online algorithm design and serves as a foundation to
evaluate online experiment policies on the task of online matrix completion.</p>
  </details>
</details>
<details>
  <summary>54. <b>标题：Discriminating sensor activation in activity recognition within  multi-occupancy environments based on nearby interaction</b></summary>
  <p><b>编号</b>：[216]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10355</p>
  <p><b>作者</b>：Aurora Polo-Rodriguez,  Javier Medina-Quero</p>
  <p><b>备注</b>：10 pages, 6 figures, 1 table</p>
  <p><b>关键词</b>：multi-occupancy environments based, presents a computer, environments based, based on proximity, discriminate sensor activation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This work presents a computer model to discriminate sensor activation in
multi-occupancy environments based on proximity interaction. Current
proximity-based and indoor location methods allow the estimation of the
positions or areas where inhabitants carry out their daily human activities.
The spatial-temporal relation between location and sensor activations is
described in this work to generate a sensor interaction matrix for each
inhabitant. This enables the use of classical HAR models to reduce the
complexity of the multi-occupancy problem. A case study deployed with UWB and
binary sensors is presented.</p>
  </details>
</details>
<details>
  <summary>55. <b>标题：Data-Adaptive Discriminative Feature Localization with Statistically  Guaranteed Interpretation</b></summary>
  <p><b>编号</b>：[231]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.10061</p>
  <p><b>作者</b>：Ben Dai,  Xiaotong Shen,  Lin Yee Chen,  Chunlin Li,  Wei Pan</p>
  <p><b>备注</b>：27 pages, 11 figures</p>
  <p><b>关键词</b>：explainable artificial intelligence, blackbox model decision-making, model decision-making process, discriminative feature localization, artificial intelligence</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In explainable artificial intelligence, discriminative feature localization
is critical to reveal a blackbox model's decision-making process from raw data
to prediction. In this article, we use two real datasets, the MNIST handwritten
digits and MIT-BIH Electrocardiogram (ECG) signals, to motivate key
characteristics of discriminative features, namely adaptiveness, predictive
importance and effectiveness. Then, we develop a localization framework based
on adversarial attacks to effectively localize discriminative features. In
contrast to existing heuristic methods, we also provide a statistically
guaranteed interpretability of the localized features by measuring a
generalized partial $R^2$. We apply the proposed method to the MNIST dataset
and the MIT-BIH dataset with a convolutional auto-encoder. In the first, the
compact image regions localized by the proposed method are visually appealing.
Similarly, in the second, the identified ECG features are biologically
plausible and consistent with cardiac electrophysiological principles while
locating subtle anomalies in a QRS complex that may not be discernible by the
naked eye. Overall, the proposed method compares favorably with
state-of-the-art competitors. Accompanying this paper is a Python library
dnn-locate (this https URL) that implements the
proposed approach.</p>
  </details>
</details>
<details>
  <summary>56. <b>标题：A Persian ASR-based SER: Modification of Sharif Emotional Speech  Database and Investigation of Persian Text Corpora</b></summary>
  <p><b>编号</b>：[237]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2211.09956</p>
  <p><b>作者</b>：Ali Yazdani,  Yasser Shekofteh</p>
  <p><b>备注</b>：7 pages, 4 figures, 8 tables</p>
  <p><b>关键词</b>：Speech Emotion Recognition, essential perceptual methods, recognize emotions, Emotion Recognition, human-machine communication systems</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Speech Emotion Recognition (SER) is one of the essential perceptual methods
of humans in understanding the situation and how to interact with others,
therefore, in recent years, it has been tried to add the ability to recognize
emotions to human-machine communication systems. Since the SER process relies
on labeled data, databases are essential for it. Incomplete, low-quality or
defective data may lead to inaccurate predictions. In this paper, we fixed the
inconsistencies in Sharif Emotional Speech Database (ShEMO), as a Persian
database, by using an Automatic Speech Recognition (ASR) system and
investigating the effect of Farsi language models obtained from accessible
Persian text corpora. We also introduced a Persian/Farsi ASR-based SER system
that uses linguistic features of the ASR outputs and Deep Learning-based
models.</p>
  </details>
</details>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">徐耀彬</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://louishsu.xyz/2022/11/22/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html">http://louishsu.xyz/2022/11/22/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://louishsu.xyz" target="_blank">LOUIS' BLOG</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"></div><div class="post_share"><div class="social-share" data-image="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="next-post pull-full"><a href="/2022/11/17/2022%E5%85%A8%E7%90%83%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%8A%80%E6%9C%AF%E5%88%9B%E6%96%B0%E5%A4%A7%E8%B5%9B(GAIIC2022)%EF%BC%9A%E5%95%86%E5%93%81%E6%A0%87%E9%A2%98%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB%E4%BA%8C%E7%AD%89%E5%A5%96.html"><img class="next-cover" src="https://cdn.kesci.com/upload/image/r7j60un866.png?imageView2/2/w/2500/h/2500" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">2022全球人工智能技术创新大赛(GAIIC2022)：商品标题实体识别二等奖</div></div></a></div></nav><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="twikoo-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="card-info-avatar is-center"><img class="avatar-img" src="/img/touxiang.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/><div class="author-info__name">徐耀彬</div><div class="author-info__description">做知识的原创者！</div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">12</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">标签</div><div class="length-num">3</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">分类</div><div class="length-num">7</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/isLouisHsu"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/isLouisHsu" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:is.louishsu@foxmail.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>公告</span></div><div class="announcement_content">记录和分享一些学习和开源内容，若有问题可通过邮箱is.louishsu@foxmail.com联系，欢迎交流！！</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">1.</span> <span class="toc-text">统计</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">2.</span> <span class="toc-text">计算机视觉</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">3.</span> <span class="toc-text">自然语言处理</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">4.</span> <span class="toc-text">机器学习</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">5.</span> <span class="toc-text">人工智能</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2022/11/22/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html" title="Arxiv每日速递(2022-11-22)"><img src="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Arxiv每日速递(2022-11-22)"/></a><div class="content"><a class="title" href="/2022/11/22/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html" title="Arxiv每日速递(2022-11-22)">Arxiv每日速递(2022-11-22)</a><time datetime="2022-11-22T00:48:15.880Z" title="发表于 2022-11-22 08:48:15">2022-11-22</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/11/17/2022%E5%85%A8%E7%90%83%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%8A%80%E6%9C%AF%E5%88%9B%E6%96%B0%E5%A4%A7%E8%B5%9B(GAIIC2022)%EF%BC%9A%E5%95%86%E5%93%81%E6%A0%87%E9%A2%98%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB%E4%BA%8C%E7%AD%89%E5%A5%96.html" title="2022全球人工智能技术创新大赛(GAIIC2022)：商品标题实体识别二等奖"><img src="https://cdn.kesci.com/upload/image/r7j60un866.png?imageView2/2/w/2500/h/2500" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="2022全球人工智能技术创新大赛(GAIIC2022)：商品标题实体识别二等奖"/></a><div class="content"><a class="title" href="/2022/11/17/2022%E5%85%A8%E7%90%83%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%8A%80%E6%9C%AF%E5%88%9B%E6%96%B0%E5%A4%A7%E8%B5%9B(GAIIC2022)%EF%BC%9A%E5%95%86%E5%93%81%E6%A0%87%E9%A2%98%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB%E4%BA%8C%E7%AD%89%E5%A5%96.html" title="2022全球人工智能技术创新大赛(GAIIC2022)：商品标题实体识别二等奖">2022全球人工智能技术创新大赛(GAIIC2022)：商品标题实体识别二等奖</a><time datetime="2022-11-17T14:29:06.000Z" title="发表于 2022-11-17 22:29:06">2022-11-17</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/10/22/%E4%B8%AD%E5%9B%BD%E6%B3%95%E5%BE%8B%E6%99%BA%E8%83%BD%E6%8A%80%E6%9C%AF%E8%AF%84%E6%B5%8B(CAIL2021)%EF%BC%9A%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96(Rank2).html" title="中国法律智能技术评测(CAIL2021)：信息抽取(Rank2)"><img src="http://cail.cipsc.org.cn/img/index_mainpic.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="中国法律智能技术评测(CAIL2021)：信息抽取(Rank2)"/></a><div class="content"><a class="title" href="/2021/10/22/%E4%B8%AD%E5%9B%BD%E6%B3%95%E5%BE%8B%E6%99%BA%E8%83%BD%E6%8A%80%E6%9C%AF%E8%AF%84%E6%B5%8B(CAIL2021)%EF%BC%9A%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96(Rank2).html" title="中国法律智能技术评测(CAIL2021)：信息抽取(Rank2)">中国法律智能技术评测(CAIL2021)：信息抽取(Rank2)</a><time datetime="2021-10-22T14:29:06.000Z" title="发表于 2021-10-22 22:29:06">2021-10-22</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/05/19/%E5%85%A8%E7%90%83%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%8A%80%E6%9C%AF%E5%88%9B%E6%96%B0%E5%A4%A7%E8%B5%9B%E3%80%90%E8%B5%9B%E9%81%93%E4%B8%80%E3%80%91%EF%BC%9A%E5%8C%BB%E5%AD%A6%E5%BD%B1%E5%83%8F%E6%8A%A5%E5%91%8A%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B.html" title="全球人工智能技术创新大赛【赛道一】：医学影像报告异常检测"><img src="https://tianchi-public.oss-cn-hangzhou.aliyuncs.com/public/files/forum/161037709574435991610377095138.jpeg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="全球人工智能技术创新大赛【赛道一】：医学影像报告异常检测"/></a><div class="content"><a class="title" href="/2021/05/19/%E5%85%A8%E7%90%83%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%8A%80%E6%9C%AF%E5%88%9B%E6%96%B0%E5%A4%A7%E8%B5%9B%E3%80%90%E8%B5%9B%E9%81%93%E4%B8%80%E3%80%91%EF%BC%9A%E5%8C%BB%E5%AD%A6%E5%BD%B1%E5%83%8F%E6%8A%A5%E5%91%8A%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B.html" title="全球人工智能技术创新大赛【赛道一】：医学影像报告异常检测">全球人工智能技术创新大赛【赛道一】：医学影像报告异常检测</a><time datetime="2021-05-19T09:57:06.000Z" title="发表于 2021-05-19 17:57:06">2021-05-19</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2020/09/16/%E8%AF%A6%E8%A7%A3%E5%91%BD%E5%90%8D%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB%E6%A8%A1%E5%9E%8B%EF%BC%9ALSTM-CRF.html" title="详解命名实体识别模型：LSTM-CRF"><img src="https://gimg2.baidu.com/image_search/src=http%3A%2F%2Fpic1.zhimg.com%2Fv2-1ed6a10dbb239a148e42df088c5870a6_1440w.jpg%3Fsource%3D172ae18b&amp;refer=http%3A%2F%2Fpic1.zhimg.com&amp;app=2002&amp;size=f9999,10000&amp;q=a80&amp;n=0&amp;g=0n&amp;fmt=jpeg?sec=1638183974&amp;t=4632f13fd487ed1cfcb12d67a6b71e52" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="详解命名实体识别模型：LSTM-CRF"/></a><div class="content"><a class="title" href="/2020/09/16/%E8%AF%A6%E8%A7%A3%E5%91%BD%E5%90%8D%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB%E6%A8%A1%E5%9E%8B%EF%BC%9ALSTM-CRF.html" title="详解命名实体识别模型：LSTM-CRF">详解命名实体识别模型：LSTM-CRF</a><time datetime="2020-09-16T09:26:44.000Z" title="发表于 2020-09-16 17:26:44">2020-09-16</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2022 By 徐耀彬</div><div class="footer_custom_text"><p><a style="margin-inline:5px"target="_blank"href="https://hexo.io/"><img src="https://img.shields.io/badge/Frame-Hexo-blue?style=flat&logo=hexo"title="博客框架为Hexo"alt="img"></a><a style="margin-inline:5px"target="_blank"href="https://butterfly.js.org/"><img src="https://img.shields.io/badge/Theme-Butterfly-6513df?style=flat&logo=bitdefender"title="主题采用butterfly"alt="img"></a><a style="margin-inline:5px"target="_blank"href="https://www.jsdelivr.com/"><img src="https://img.shields.io/badge/CDN-jsDelivr-orange?style=flat&logo=jsDelivr"title="本站使用JsDelivr为静态资源提供CDN加速"alt="img"></a><a style="margin-inline:5px"target="_blank"href="https://github.com/"><img src="https://img.shields.io/badge/Source-Github-d021d6?style=flat&logo=GitHub"title="本站项目由Gtihub托管"alt="img"></a><a style="margin-inline:5px"target="_blank"href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img src="https://img.shields.io/badge/Copyright-BY--NC--SA%204.0-d42328?style=flat&logo=Claris"alt="img"title="本站采用知识共享署名-非商业性使用-相同方式共享4.0国际许可协议进行许可"></a></br></p></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="font-plus" type="button" title="放大字体"><i class="fas fa-plus"></i></button><button id="font-minus" type="button" title="缩小字体"><i class="fas fa-minus"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div></div><hr/><div id="local-search-results"></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.css"><script>(() => {
  document.querySelectorAll('#article-container span.katex-display').forEach(item => {
    btf.wrap(item, 'div', '', 'katex-wrap')
  })
})()</script><script>(()=>{
  const $countDom = document.getElementById('twikoo-count')
  const init = () => {
    let initData = {
      el: '#twikoo-wrap',
      envId: 'blog-',
      region: ''
    }

    if (false) {
      const otherData = false
      initData = Object.assign(initData, otherData)
    }
    
    twikoo.init(initData)
  }

  const getCount = () => {
    twikoo.getCommentsCount({
      envId: 'blog-',
      region: '',
      urls: [window.location.pathname],
      includeReply: false
    }).then(function (res) {
      $countDom.innerText = res[0].count
    }).catch(function (err) {
      console.error(err);
    });
  }

  const loadTwikoo = (bool = false) => {
    if (typeof twikoo === 'object') {
      init()
      bool && $countDom && setTimeout(getCount,0)
    } else {
      getScript('https://cdn.jsdelivr.net/npm/twikoo/dist/twikoo.all.min.js').then(()=> {
        init()
        bool && $countDom && setTimeout(getCount,0)
      })
    }
  }

  if ('Twikoo' === 'Twikoo' || !false) {
    if (false) btf.loadComment(document.getElementById('twikoo-wrap'), loadTwikoo)
    else loadTwikoo(true)
  } else {
    window.loadOtherComment = () => {
      loadTwikoo()
    }
  }
})()</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><!-- hexo injector body_end start --> <script data-pjax>if(document.getElementById('recent-posts') && (location.pathname ==='/'|| '/' ==='all')){
    var parent = document.getElementById('recent-posts');
    var child = '<div class="recent-post-item" style="width:100%;height: auto"><div id="catalog_magnet"><div class="magnet_item"><a class="magnet_link" href="http://louishsu.xyz/categories/机器学习/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🐱 机器学习 (1)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://louishsu.xyz/categories/自然语言处理/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">📚 自然语言处理 (1)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://louishsu.xyz/categories/竞赛相关/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🎮 竞赛相关 (3)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://louishsu.xyz/categories/阅读笔记/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🎮 阅读笔记 (1)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><a class="magnet_link_more"  href="http://louishsu.xyz/categories" style="flex:1;text-align: center;margin-bottom: 10px;">查看更多...</a></div></div>';
    console.log('已挂载magnet')
    parent.insertAdjacentHTML("afterbegin",child)}
     </script><style>#catalog_magnet{flex-wrap: wrap;display: flex;width:100%;justify-content:space-between;padding: 10px 10px 0 10px;align-content: flex-start;}.magnet_item{flex-basis: calc(50% - 5px);background: #f2f2f2;margin-bottom: 10px;border-radius: 8px;transition: all 0.2s ease-in-out;}.magnet_item:hover{background: #b30070}.magnet_link_more{color:#555}.magnet_link{color:black}.magnet_link:hover{color:white}@media screen and (max-width: 600px) {.magnet_item {flex-basis: 100%;}}.magnet_link_context{display:flex;padding: 10px;font-size:16px;transition: all 0.2s ease-in-out;}.magnet_link_context:hover{padding: 10px 20px;}</style>
    <style></style>
  <script data-pjax src="https://cdn.jsdelivr.net/gh/Zfour/hexo-github-calendar@1.21/hexo_githubcalendar.js"></script>
  <script data-pjax>
        function GithubCalendarConfig(){
            var git_githubapiurl ="https://python-github-calendar-api.vercel.app/api?isLouisHsu";
            var git_color =['#ebedf0', '#fdcdec', '#fc9bd9', '#fa6ac5', '#f838b2', '#f5089f', '#c4067e', '#92055e', '#540336', '#48022f', '#30021f'];
            var git_user ="isLouisHsu";
            var parent_div_git = document.getElementById('recent-posts');
            var git_div_html = '<div class="recent-post-item" style="width:100%;height:auto;padding:10px;"><div id="github_loading" style="width:10%;height:100%;margin:0 auto;display: block"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"  viewBox="0 0 50 50" style="enable-background:new 0 0 50 50" xml:space="preserve"><path fill="#d0d0d0" d="M25.251,6.461c-10.318,0-18.683,8.365-18.683,18.683h4.068c0-8.071,6.543-14.615,14.615-14.615V6.461z" transform="rotate(275.098 25 25)"><animateTransform attributeType="xml" attributeName="transform" type="rotate" from="0 25 25" to="360 25 25" dur="0.6s" repeatCount="indefinite"></animateTransform></path></svg></div><div id="github_container"></div></div>';
            if(parent_div_git && location.pathname =='/'){
                console.log('已挂载github calendar')
                // parent_div_git.innerHTML=git_div_html+parent_div_git.innerHTML // 无报错，但不影响使用(支持pjax跳转)
                parent_div_git.insertAdjacentHTML("afterbegin",git_div_html) // 有报错，但不影响使用(支持pjax跳转)
            };
            GithubCalendar(git_githubapiurl,git_color,git_user)
        }
        if(document.getElementById('recent-posts')){
            GithubCalendarConfig()
        }
    </script>
    <style>#github_container{min-height:280px}@media screen and (max-width:650px) {#github_container{background-image:;min-height:0px}}</style>
    <style></style><script data-pjax>function electric_clock_injector_config(){
                var parent_div_git = document.getElementsByClassName('sticky_layout')[0];
                var item_html = '<div class="card-widget card-clock"><div class="card-glass"><div class="card-background"><div class="card-content"><div id="hexo_electric_clock"><img id="card-clock-loading" src="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-clock/clock/images/weather/loading.gif" style="height: 120px; width: 100%;" data-ll-status="loading" class="entered loading"></div></div></div></div></div>';
                console.log('已挂载electric_clock')
                // parent_div_git.innerHTML=item_html+parent_div_git.innerHTML // 无报错，但不影响使用(支持pjax跳转)
                parent_div_git.insertAdjacentHTML("afterbegin",item_html) // 有报错，但不影响使用(支持pjax跳转)
            }if( document.getElementsByClassName('sticky_layout')[0] && (location.pathname ==='all'|| 'all' ==='all')){

            electric_clock_injector_config()
        } </script><script src="https://pv.sohu.com/cityjson?ie=utf-8"></script><script data-pjax  src="https://cdn.jsdelivr.net/gh/Zfour/hexo-electric-clock@1.0.6/clock.js"></script><!-- hexo injector body_end end --><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"model":{"jsonPath":"/live2dw/assets/hijiki.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":false},"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body></html>