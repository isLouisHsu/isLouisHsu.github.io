<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Arxiv每日速递(2022-12-08) | LOUIS' BLOG</title><meta name="author" content="徐耀彬"><meta name="copyright" content="徐耀彬"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="本篇博文主要展示每日从Arxiv论文网站获取的最新论文列表，以计算机视觉、自然语言处理、机器学习、人工智能等大方向进行划分。 统计 今日共更新306篇论文，其中：  89篇计算机视觉（cs.CV） 26篇自然语言处理（cs.CL） 102篇机器学习（cs.LG） 68篇人工智能（cs.AI）  计算机视觉    1. 标题：Robust Point Cloud Segmentation with">
<meta property="og:type" content="article">
<meta property="og:title" content="Arxiv每日速递(2022-12-08)">
<meta property="og:url" content="http://louishsu.xyz/2022/12/08/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html">
<meta property="og:site_name" content="LOUIS&#39; BLOG">
<meta property="og:description" content="本篇博文主要展示每日从Arxiv论文网站获取的最新论文列表，以计算机视觉、自然语言处理、机器学习、人工智能等大方向进行划分。 统计 今日共更新306篇论文，其中：  89篇计算机视觉（cs.CV） 26篇自然语言处理（cs.CL） 102篇机器学习（cs.LG） 68篇人工智能（cs.AI）  计算机视觉    1. 标题：Robust Point Cloud Segmentation with">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png">
<meta property="article:published_time" content="2022-12-08T00:39:27.027Z">
<meta property="article:modified_time" content="2022-12-08T00:41:01.387Z">
<meta property="article:author" content="徐耀彬">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://louishsu.xyz/2022/12/08/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2022-12-08 08:41:01'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const fontSizeVal = saveToLocal.get('global-font-size')
    if (fontSizeVal !== undefined) {
      document.documentElement.style.setProperty('--global-font-size', fontSizeVal + 'px')
    }
    })(window)</script><link rel="stylesheet" href="/css/background.css"><script src="https://cdn.jsdelivr.net/npm/echarts@4.7.0/dist/echarts.min.js"></script><!-- hexo injector head_end start --><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Zfour/hexo-electric-clock@1.0.6/clock.css"><!-- hexo injector head_end end --><meta name="generator" content="Hexo 5.4.2"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="author-avatar"><img class="avatar-img" src="/img/touxiang.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">13</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">标签</div><div class="length-num">4</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">分类</div><div class="length-num">7</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/message/"><i class="fa-fw far fa-comment-dots"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa-fw fa fa-book"></i><span> 找文章</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></li><li><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></li><li><a class="site-page" href="/charts/"><i class="fa-fw fa fa-archive"></i><span> 统计</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-tools"></i><span> 工具</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/md_editor/"><i class="fa-fw fas fa-pen"></i><span> 在线markdown</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/isLouisHsu/blog/tree/master/source/_posts"><i class="fa-fw fa fa-star"></i><span> 在线push</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa-brands fa-app-store"></i><span> 利器</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" target="_blank" rel="noopener" href="https://code.visualstudio.com/"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> VSCode：微软旗下的跨平台代码编辑软件</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://mobaxterm.mobatek.net/"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> MobaXterm：超好用的全能远程终端</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://www.zotero.org/"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> Zotero：便于收集、组织、引用、共享的文献管理工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/CopyTranslator/CopyTranslator"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> CopyTranslator：“复制即翻译”的外文辅助阅读翻译解决方案</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://ditto-cp.sourceforge.io/"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> Ditto：强大的Windows剪贴板增强工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/indiff/qttabbar"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> QtTabBar：在Windows资源管理器中使用多标签功能扩展工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/sentialx/multrin"><i class="fa-fw fa-sharp fa-solid fa-star-half-stroke"></i><span> Multrin：“窗口合并”辅助小工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/Wox-launcher/Wox"><i class="fa-fw fa-sharp fa-solid fa-star-half-stroke"></i><span> Wox &amp; Everything：基于名称快速定位文件和文件夹的搜索工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/NickeManarin/ScreenToGif"><i class="fa-fw fa-regular fa-star"></i><span> ScreenToGif：快速录制屏幕指定区域并保存为动图文件</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://mathpix.com/"><i class="fa-fw fa-regular fa-star"></i><span> Mathpix Snipping：识别数学公式并转换成LaTeX</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">LOUIS' BLOG</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/message/"><i class="fa-fw far fa-comment-dots"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa-fw fa fa-book"></i><span> 找文章</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></li><li><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></li><li><a class="site-page" href="/charts/"><i class="fa-fw fa fa-archive"></i><span> 统计</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-tools"></i><span> 工具</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/md_editor/"><i class="fa-fw fas fa-pen"></i><span> 在线markdown</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/isLouisHsu/blog/tree/master/source/_posts"><i class="fa-fw fa fa-star"></i><span> 在线push</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa-brands fa-app-store"></i><span> 利器</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" target="_blank" rel="noopener" href="https://code.visualstudio.com/"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> VSCode：微软旗下的跨平台代码编辑软件</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://mobaxterm.mobatek.net/"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> MobaXterm：超好用的全能远程终端</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://www.zotero.org/"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> Zotero：便于收集、组织、引用、共享的文献管理工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/CopyTranslator/CopyTranslator"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> CopyTranslator：“复制即翻译”的外文辅助阅读翻译解决方案</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://ditto-cp.sourceforge.io/"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> Ditto：强大的Windows剪贴板增强工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/indiff/qttabbar"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> QtTabBar：在Windows资源管理器中使用多标签功能扩展工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/sentialx/multrin"><i class="fa-fw fa-sharp fa-solid fa-star-half-stroke"></i><span> Multrin：“窗口合并”辅助小工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/Wox-launcher/Wox"><i class="fa-fw fa-sharp fa-solid fa-star-half-stroke"></i><span> Wox &amp; Everything：基于名称快速定位文件和文件夹的搜索工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/NickeManarin/ScreenToGif"><i class="fa-fw fa-regular fa-star"></i><span> ScreenToGif：快速录制屏幕指定区域并保存为动图文件</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://mathpix.com/"><i class="fa-fw fa-regular fa-star"></i><span> Mathpix Snipping：识别数学公式并转换成LaTeX</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Arxiv每日速递(2022-12-08)<a class="post-edit-link" href="https://github.com/isLouisHsu/blog/tree/master/source_posts/Arxiv每日速递.md" title="编辑" target="_blank"><i class="fas fa-pencil-square"></i></a></h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-12-08T00:39:27.027Z" title="发表于 2022-12-08 08:39:27">2022-12-08</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2022-12-08T00:41:01.387Z" title="更新于 2022-12-08 08:41:01">2022-12-08</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">阅读笔记</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">23.6k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>141分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span><span class="post-meta-separator">|</span><span class="post-meta-commentcount"><i class="far fa-comments fa-fw post-meta-icon"></i><span class="post-meta-label">评论数:</span><a href="/2022/12/08/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html#post-comment"><span id="twikoo-count"></span></a></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><p>本篇博文主要展示每日从Arxiv论文网站获取的最新论文列表，以计算机视觉、自然语言处理、机器学习、人工智能等大方向进行划分。</p>
<h1>统计</h1>
<p>今日共更新306篇论文，其中：</p>
<ul>
<li>89篇计算机视觉（<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>）</li>
<li>26篇自然语言处理（<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>）</li>
<li>102篇机器学习（cs.LG）</li>
<li>68篇人工智能（<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>）</li>
</ul>
<h1>计算机视觉</h1>
<details>
  <summary>1. <b>标题：Robust Point Cloud Segmentation with Noisy Annotations</b></summary>
  <p><b>编号</b>：[1]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.03242</p>
  <p><b>作者</b>：Shuquan Ye,  Dongdong Chen,  Songfang Han,  Jing Liao</p>
  <p><b>备注</b>：To Appear at TPAMI 2022. arXiv admin note: substantial text overlap with arXiv:2107.14230</p>
  <p><b>关键词</b>：Point cloud segmentation, cloud segmentation, Point cloud, Point, label</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Point cloud segmentation is a fundamental task in 3D. Despite recent progress
on point cloud segmentation with the power of deep networks, current learning
methods based on the clean label assumptions may fail with noisy labels. Yet,
class labels are often mislabeled at both instance-level and boundary-level in
real-world datasets. In this work, we take the lead in solving the
instance-level label noise by proposing a Point Noise-Adaptive Learning (PNAL)
framework. Compared to noise-robust methods on image tasks, our framework is
noise-rate blind, to cope with the spatially variant noise rate specific to
point clouds. Specifically, we propose a point-wise confidence selection to
obtain reliable labels from the historical predictions of each point. A
cluster-wise label correction is proposed with a voting strategy to generate
the best possible label by considering the neighbor correlations. To handle
boundary-level label noise, we also propose a variant ``PNAL-boundary " with a
progressive boundary label cleaning strategy. Extensive experiments demonstrate
its effectiveness on both synthetic and real-world noisy datasets. Even with
$60\%$ symmetric noise and high-level boundary noise, our framework
significantly outperforms its baselines, and is comparable to the upper bound
trained on completely clean data. Moreover, we cleaned the popular real-world
dataset ScanNetV2 for rigorous experiment. Our code and data is available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>2. <b>标题：PØDA: Prompt-driven Zero-shot Domain Adaptation</b></summary>
  <p><b>编号</b>：[2]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.03241</p>
  <p><b>作者</b>：Mohammad Fahes,  Tuan-Hung Vu,  Andrei Bursuc,  Patrick Pérez,  Raoul de Charette</p>
  <p><b>备注</b>：Project page: this https URL</p>
  <p><b>关键词</b>：Zero-shot Domain Adaptation, Domain adaptation, train time, long-tail samples, vastly investigated</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Domain adaptation has been vastly investigated in computer vision but still
requires access to target images at train time, which might be intractable in
some conditions, especially for long-tail samples. In this paper, we propose
the task of `Prompt-driven Zero-shot Domain Adaptation', where we adapt a model
trained on a source domain using only a general textual description of the
target domain, i.e., a prompt. First, we leverage a pretrained contrastive
vision-language model (CLIP) to optimize affine transformations of source
features, bringing them closer to target text embeddings, while preserving
their content and semantics. Second, we show that augmented features can be
used to perform zero-shot domain adaptation for semantic segmentation.
Experiments demonstrate that our method significantly outperforms CLIP-based
style transfer baselines on several datasets for the downstream task at hand.
Our prompt-driven approach even outperforms one-shot unsupervised domain
adaptation on some datasets, and gives comparable results on others. The code
is available at this https URL.</p>
  </details>
</details>
<details>
  <summary>3. <b>标题：Perspective Fields for Single Image Camera Calibration</b></summary>
  <p><b>编号</b>：[3]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.03239</p>
  <p><b>作者</b>：Linyi Jin,  Jianming Zhang,  Yannick Hold-Geoffroy,  Oliver Wang,  Kevin Matzen,  Matthew Sticha,  David F. Fouhey</p>
  <p><b>备注</b>：Project Page this https URL</p>
  <p><b>关键词</b>：perspective fields, propose perspective fields, perspective, fields, Geometric camera calibration</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Geometric camera calibration is often required for applications that
understand the perspective of the image. We propose perspective fields as a
representation that models the local perspective properties of an image.
Perspective Fields contain per-pixel information about the camera view,
parameterized as an up vector and a latitude value. This representation has a
number of advantages as it makes minimal assumptions about the camera model and
is invariant or equivariant to common image editing operations like cropping,
warping, and rotation. It is also more interpretable and aligned with human
perception. We train a neural network to predict Perspective Fields and the
predicted Perspective Fields can be converted to calibration parameters easily.
We demonstrate the robustness of our approach under various scenarios compared
with camera calibration-based methods and show example applications in image
compositing.</p>
  </details>
</details>
<details>
  <summary>4. <b>标题：RANA: Relightable Articulated Neural Avatars</b></summary>
  <p><b>编号</b>：[5]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.03237</p>
  <p><b>作者</b>：Umar Iqbal,  Akin Caliskan,  Koki Nagano,  Sameh Khamis,  Pavlo Molchanov,  Jan Kautz</p>
  <p><b>备注</b>：project page: this https URL</p>
  <p><b>关键词</b>：arbitrary viewpoints, lighting environment, articulated neural avatar, lighting, articulated neural</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose RANA, a relightable and articulated neural avatar for the
photorealistic synthesis of humans under arbitrary viewpoints, body poses, and
lighting. We only require a short video clip of the person to create the avatar
and assume no knowledge about the lighting environment. We present a novel
framework to model humans while disentangling their geometry, texture, and also
lighting environment from monocular RGB videos. To simplify this otherwise
ill-posed task we first estimate the coarse geometry and texture of the person
via SMPL+D model fitting and then learn an articulated neural representation
for photorealistic image generation. RANA first generates the normal and albedo
maps of the person in any given target body pose and then uses spherical
harmonics lighting to generate the shaded image in the target lighting
environment. We also propose to pretrain RANA using synthetic images and
demonstrate that it leads to better disentanglement between geometry and
texture while also improving robustness to novel body poses. Finally, we also
present a new photorealistic synthetic dataset, Relighting Humans, to
quantitatively evaluate the performance of the proposed approach.</p>
  </details>
</details>
<details>
  <summary>5. <b>标题：Self-Supervised Correspondence Estimation via Multiview Registration</b></summary>
  <p><b>编号</b>：[6]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.03236</p>
  <p><b>作者</b>：Mohamed El Banani,  Ignacio Rocco,  David Novotny,  Andrea Vedaldi,  Natalia Neverova,  Justin Johnson,  Benjamin Graham</p>
  <p><b>备注</b>：Accepted to WACV 2023. Project page: this https URL</p>
  <p><b>关键词</b>：spatio-temporal consistency needed, visual learning, needed for visual, close-by frame pairs, correspondence estimation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Video provides us with the spatio-temporal consistency needed for visual
learning. Recent approaches have utilized this signal to learn correspondence
estimation from close-by frame pairs. However, by only relying on close-by
frame pairs, those approaches miss out on the richer long-range consistency
between distant overlapping frames. To address this, we propose a
self-supervised approach for correspondence estimation that learns from
multiview consistency in short RGB-D video sequences. Our approach combines
pairwise correspondence estimation and registration with a novel SE(3)
transformation synchronization algorithm. Our key insight is that
self-supervised multiview registration allows us to obtain correspondences over
longer time frames; increasing both the diversity and difficulty of sampled
pairs. We evaluate our approach on indoor scenes for correspondence estimation
and RGB-D pointcloud registration and find that we perform on-par with
supervised approaches.</p>
  </details>
</details>
<details>
  <summary>6. <b>标题：Towards A Most Probable Recovery in Optical Imaging</b></summary>
  <p><b>编号</b>：[7]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.03235</p>
  <p><b>作者</b>：Nadav Torem,  Roi Ronen,  Yoav Y. Schechner,  Michael Elad</p>
  <p><b>备注</b>：24 pages, 21 figures</p>
  <p><b>关键词</b>：complex-valued field, imaged objects, unknown imaged objects, imaged, field</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Light is a complex-valued field. The intensity and phase of the field are
affected by imaged objects. However, imaging sensors measure only real-valued
non-negative intensities. This results in a nonlinear relation between the
measurements and the unknown imaged objects. Moreover, the sensor readouts are
corrupted by Poissonian-distributed photon noise. In this work, we seek the
most probable object (or clear image), given noisy measurements, that is,
maximizing the a-posteriori probability of the sought variables. Hence, we
generalize annealed Langevin dynamics, tackling fundamental challenges in
optical imaging, including phase recovery and Poisson (photon) denoising. We
leverage deep neural networks, not for explicit recovery of the imaged object,
but as an approximate gradient for a prior term. We show results on empirical
data, acquired by a real experiment. We further show results of simulations.</p>
  </details>
</details>
<details>
  <summary>7. <b>标题：Switching to Discriminative Image Captioning by Relieving a Bottleneck  of Reinforcement Learning</b></summary>
  <p><b>编号</b>：[9]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.03230</p>
  <p><b>作者</b>：Ukyo Honda,  Taro Watanabe,  Yuji Matsumoto</p>
  <p><b>备注</b>：WACV 2023 (19 pages, 9 figures)</p>
  <p><b>关键词</b>：desirable feature, describe the characteristic, captions, characteristic details, Discriminativeness</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Discriminativeness is a desirable feature of image captions: captions should
describe the characteristic details of input images. However, recent
high-performing captioning models, which are trained with reinforcement
learning (RL), tend to generate overly generic captions despite their high
performance in various other criteria. First, we investigate the cause of the
unexpectedly low discriminativeness and show that RL has a deeply rooted side
effect of limiting the output words to high-frequency words. The limited
vocabulary is a severe bottleneck for discriminativeness as it is difficult for
a model to describe the details beyond its vocabulary. Then, based on this
identification of the bottleneck, we drastically recast discriminative image
captioning as a much simpler task of encouraging low-frequency word generation.
Hinted by long-tail classification and debiasing methods, we propose methods
that easily switch off-the-shelf RL models to discriminativeness-aware models
with only a single-epoch fine-tuning on the part of the parameters. Extensive
experiments demonstrate that our methods significantly enhance the
discriminativeness of off-the-shelf RL models and even outperform previous
discriminativeness-aware methods with much smaller computational costs.
Detailed analysis and human evaluation also verify that our methods boost the
discriminativeness without sacrificing the overall quality of captions.</p>
  </details>
</details>
<details>
  <summary>8. <b>标题：Rethinking Video ViTs: Sparse Video Tubes for Joint Image and Video  Learning</b></summary>
  <p><b>编号</b>：[10]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.03229</p>
  <p><b>作者</b>：AJ Piergiovanni,  Weicheng Kuo,  Anelia Angelova</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：efficient video model, efficient video, present a simple, simple approach, seamlessly work</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present a simple approach which can turn a ViT encoder into an efficient
video model, which can seamlessly work with both image and video inputs. By
sparsely sampling the inputs, the model is able to do training and inference
from both inputs. The model is easily scalable and can be adapted to
large-scale pre-trained ViTs without requiring full finetuning. The model
achieves SOTA results and the code will be open-sourced.</p>
  </details>
</details>
<details>
  <summary>9. <b>标题：ADIR: Adaptive Diffusion for Image Reconstruction</b></summary>
  <p><b>编号</b>：[13]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.03221</p>
  <p><b>作者</b>：Shady Abu-Hussein,  Tom Tirer,  Raja Giryes</p>
  <p><b>备注</b>：Our code and additional results are available online in the project page this https URL</p>
  <p><b>关键词</b>：image generation performance, demonstrated outstanding image, outstanding image generation, recent years, generation performance</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In recent years, denoising diffusion models have demonstrated outstanding
image generation performance. The information on natural images captured by
these models is useful for many image reconstruction applications, where the
task is to restore a clean image from its degraded observations. In this work,
we propose a conditional sampling scheme that exploits the prior learned by
diffusion models while retaining agreement with the observations. We then
combine it with a novel approach for adapting pretrained diffusion denoising
networks to their input. We examine two adaption strategies: the first uses
only the degraded image, while the second, which we advocate, is performed
using images that are ``nearest neighbors'' of the degraded image, retrieved
from a diverse dataset using an off-the-shelf visual-language model. To
evaluate our method, we test it on two state-of-the-art publicly available
diffusion models, Stable Diffusion and Guided Diffusion. We show that our
proposed `adaptive diffusion for image reconstruction' (ADIR) approach achieves
a significant improvement in the super-resolution, deblurring, and text-based
editing tasks.</p>
  </details>
</details>
<details>
  <summary>10. <b>标题：Visual Query Tuning: Towards Effective Usage of Intermediate  Representations for Parameter and Memory Efficient Transfer Learning</b></summary>
  <p><b>编号</b>：[14]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.03220</p>
  <p><b>作者</b>：Cheng-Hao Tu,  Zheda Mai,  Wei-Lun Chao</p>
  <p><b>备注</b>：Cheng-Hao Tu and Zheda Mai contributed equally to this work</p>
  <p><b>关键词</b>：Intermediate features, features, pre-trained model, VQT, shown informative</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Intermediate features of a pre-trained model have been shown informative for
making accurate predictions on downstream tasks, even if the model backbone is
kept frozen. The key challenge is how to utilize these intermediate features
given their gigantic amount. We propose visual query tuning (VQT), a simple yet
effective approach to aggregate intermediate features of Vision Transformers.
Through introducing a handful of learnable ``query'' tokens to each layer, VQT
leverages the inner workings of Transformers to ``summarize'' rich intermediate
features of each layer, which can then be used to train the prediction heads of
downstream tasks. As VQT keeps the intermediate features intact and only learns
to combine them, it enjoys memory efficiency in training, compared to many
other parameter-efficient fine-tuning approaches that learn to adapt features
and need back-propagation through the entire backbone. This also suggests the
complementary role between VQT and those approaches in transfer learning.
Empirically, VQT consistently surpasses the state-of-the-art approach that
utilizes intermediate features for transfer learning and outperforms full
fine-tuning in many cases. Compared to parameter-efficient approaches that
adapt features, VQT achieves much higher accuracy under memory constraints.
Most importantly, VQT is compatible with these approaches to attain even higher
accuracy, making it a simple add-on to further boost transfer learning.</p>
  </details>
</details>
<details>
  <summary>11. <b>标题：InternVideo: General Video Foundation Models via Generative and  Discriminative Learning</b></summary>
  <p><b>编号</b>：[20]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.03191</p>
  <p><b>作者</b>：Yi Wang,  Kunchang Li,  Yizhuo Li,  Yinan He,  Bingkun Huang,  Zhiyu Zhao,  Hongjie Zhang,  Jilan Xu,  Yi Liu,  Zun Wang,  Sen Xing,  Guo Chen,  Junting Pan,  Jiashuo Yu,  Yali Wang,  Limin Wang,  Yu Qiao</p>
  <p><b>备注</b>：technical report</p>
  <p><b>关键词</b>：recently shown excellent, shown excellent performance, foundation models, vision foundation models, recently shown</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The foundation models have recently shown excellent performance on a variety
of downstream tasks in computer vision. However, most existing vision
foundation models simply focus on image-level pretraining and adpation, which
are limited for dynamic and complex video-level understanding tasks. To fill
the gap, we present general video foundation models, InternVideo, by taking
advantage of both generative and discriminative self-supervised video learning.
Specifically, InternVideo efficiently explores masked video modeling and
video-language contrastive learning as the pretraining objectives, and
selectively coordinates video representations of these two complementary
frameworks in a learnable manner to boost various video applications. Without
bells and whistles, InternVideo achieves state-of-the-art performance on 39
video datasets from extensive tasks including video action
recognition/detection, video-language alignment, and open-world video
applications. Especially, our methods can obtain 91.1% and 77.2% top-1 accuracy
on the challenging Kinetics-400 and Something-Something V2 benchmarks,
respectively. All of these results effectively show the generality of our
InternVideo for video understanding. The code will be released at
this https URL .</p>
  </details>
</details>
<details>
  <summary>12. <b>标题：Towards Energy Efficient Mobile Eye Tracking for AR Glasses through  Optical Sensor Technology</b></summary>
  <p><b>编号</b>：[21]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.03189</p>
  <p><b>作者</b>：Johannes Meyer</p>
  <p><b>备注</b>：Accepted PhD Thesis at the University of T\"ubingen by Johannes Meyer</p>
  <p><b>关键词</b>：field of wearables, glasses, display, Eye-tracking, display technology</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>After the introduction of smartphones and smartwatches, AR glasses are
considered the next breakthrough in the field of wearables. While the
transition from smartphones to smartwatches was based mainly on established
display technologies, the display technology of AR glasses presents a
technological challenge. Many display technologies, such as retina projectors,
are based on continuous adaptive control of the display based on the user's
pupil position. Furthermore, head-mounted systems require an adaptation and
extension of established interaction concepts to provide the user with an
immersive experience. Eye-tracking is a crucial technology to help AR glasses
achieve a breakthrough through optimized display technology and gaze-based
interaction concepts. Available eye-tracking technologies, such as VOG, do not
meet the requirements of AR glasses, especially regarding power consumption,
robustness, and integrability. To further overcome these limitations and push
mobile eye-tracking for AR glasses forward, novel laser-based eye-tracking
sensor technologies are researched in this thesis. The thesis contributes to a
significant scientific advancement towards energy-efficient mobile eye-tracking
for AR glasses.</p>
  </details>
</details>
<details>
  <summary>13. <b>标题：Rethinking the Objectives of Vector-Quantized Tokenizers for Image  Synthesis</b></summary>
  <p><b>编号</b>：[23]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.03185</p>
  <p><b>作者</b>：Yuchao Gu,  Xintao Wang,  Yixiao Ge,  Ying Shan,  Xiaohu Qie,  Mike Zheng Shou</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：basic components, generative transformers, tokenizers, details preservation, reconstruction fidelity</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Vector-Quantized (VQ-based) generative models usually consist of two basic
components, i.e., VQ tokenizers and generative transformers. Prior research
focuses on improving the reconstruction fidelity of VQ tokenizers but rarely
examines how the improvement in reconstruction affects the generation ability
of generative transformers. In this paper, we surprisingly find that improving
the reconstruction fidelity of VQ tokenizers does not necessarily improve the
generation. Instead, learning to compress semantic features within VQ
tokenizers significantly improves generative transformers' ability to capture
textures and structures. We thus highlight two competing objectives of VQ
tokenizers for image synthesis: semantic compression and details preservation.
Different from previous work that only pursues better details preservation, we
propose Semantic-Quantized GAN (SeQ-GAN) with two learning phases to balance
the two objectives. In the first phase, we propose a semantic-enhanced
perceptual loss for better semantic compression. In the second phase, we fix
the encoder and codebook, but enhance and finetune the decoder to achieve
better details preservation. The proposed SeQ-GAN greatly improves VQ-based
generative models and surpasses the GAN and Diffusion Models on both
unconditional and conditional image generation. Our SeQ-GAN (364M) achieves
Frechet Inception Distance (FID) of 6.25 and Inception Score (IS) of 140.9 on
256x256 ImageNet generation, a remarkable improvement over VIT-VQGAN (714M),
which obtains 11.2 FID and 97.2 IS.</p>
  </details>
</details>
<details>
  <summary>14. <b>标题：Overlapping oriented imbalanced ensemble learning method based on  projective clustering and stagewise hybrid sampling</b></summary>
  <p><b>编号</b>：[26]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.03182</p>
  <p><b>作者</b>：Fan Li,  Bo Wang,  Pin Wang,  Yongming Li</p>
  <p><b>备注</b>：23 pages, 3 figures</p>
  <p><b>关键词</b>：class imbalance problem, imbalanced learning lies, imbalance problem, class overlapping problem, challenge of imbalanced</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The challenge of imbalanced learning lies not only in class imbalance
problem, but also in the class overlapping problem which is complex. However,
most of the existing algorithms mainly focus on the former. The limitation
prevents the existing methods from breaking through. To address this
limitation, this paper proposes an ensemble learning algorithm based on dual
clustering and stage-wise hybrid sampling (DCSHS). The DCSHS has three parts.
Firstly, we design a projection clustering combination framework (PCC) guided
by Davies-Bouldin clustering effectiveness index (DBI), which is used to obtain
high-quality clusters and combine them to obtain a set of cross-complete
subsets (CCS) with balanced class and low overlapping. Secondly, according to
the characteristics of subset classes, a stage-wise hybrid sampling algorithm
is designed to realize the de-overlapping and balancing of subsets. Finally, a
projective clustering transfer mapping mechanism (CTM) is constructed for all
processed subsets by means of transfer learning, thereby reducing class
overlapping and explore structure information of samples. The major advantage
of our algorithm is that it can exploit the intersectionality of the CCS to
realize the soft elimination of overlapping majority samples, and learn as much
information of overlapping samples as possible, thereby enhancing the class
overlapping while class balancing. In the experimental section, more than 30
public datasets and over ten representative algorithms are chosen for
verification. The experimental results show that the DCSHS is significantly
best in terms of various evaluation criteria.</p>
  </details>
</details>
<details>
  <summary>15. <b>标题：Privacy-Preserving Visual Localization with Event Cameras</b></summary>
  <p><b>编号</b>：[30]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.03177</p>
  <p><b>作者</b>：Junho Kim,  Young Min Kim,  Yicheng Wu,  Ramzi Zahreddine,  Weston A. Welge,  Gurunandan Krishnan,  Sizhuo Ma,  Jian Wang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：event cameras, privacy-preserving visual localization, visual localization algorithm, localization, image-based localization algorithms</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present a robust, privacy-preserving visual localization algorithm using
event cameras. While event cameras can potentially make robust localization due
to high dynamic range and small motion blur, the sensors exhibit large domain
gaps making it difficult to directly apply conventional image-based
localization algorithms. To mitigate the gap, we propose applying
event-to-image conversion prior to localization which leads to stable
localization. In the privacy perspective, event cameras capture only a fraction
of visual information compared to normal cameras, and thus can naturally hide
sensitive visual details. To further enhance the privacy protection in our
event-based pipeline, we introduce privacy protection at two levels, namely
sensor and network level. Sensor level protection aims at hiding facial details
with lightweight filtering while network level protection targets hiding the
entire user's view in private scene applications using a novel neural network
inference pipeline. Both levels of protection involve light-weight computation
and incur only a small performance loss. We thus project our method to serve as
a building block for practical location-based services using event cameras. The
code and dataset will be made public through the following link:
this https URL.</p>
  </details>
</details>
<details>
  <summary>16. <b>标题：FacT: Factor-Tuning for Lightweight Adaptation on Vision Transformer</b></summary>
  <p><b>编号</b>：[40]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.03145</p>
  <p><b>作者</b>：Shibo Jie,  Zhi-Hong Deng</p>
  <p><b>备注</b>：Accepted at AAAI 2023. Code: this https URL</p>
  <p><b>关键词</b>：pre-trained vision transformer, parameter-efficient transfer learning, called parameter-efficient transfer, improve storage efficiency, Recent work</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent work has explored the potential to adapt a pre-trained vision
transformer (ViT) by updating only a few parameters so as to improve storage
efficiency, called parameter-efficient transfer learning (PETL). Current PETL
methods have shown that by tuning only 0.5% of the parameters, ViT can be
adapted to downstream tasks with even better performance than full fine-tuning.
In this paper, we aim to further promote the efficiency of PETL to meet the
extreme storage constraint in real-world applications. To this end, we propose
a tensorization-decomposition framework to store the weight increments, in
which the weights of each ViT are tensorized into a single 3D tensor, and their
increments are then decomposed into lightweight factors. In the fine-tuning
process, only the factors need to be updated and stored, termed Factor-Tuning
(FacT). On VTAB-1K benchmark, our method performs on par with NOAH, the
state-of-the-art PETL method, while being 5x more parameter-efficient. We also
present a tiny version that only uses 8K (0.01% of ViT's parameters) trainable
parameters but outperforms full fine-tuning and many other PETL methods such as
VPT and BitFit. In few-shot settings, FacT also beats all PETL baselines using
the fewest parameters, demonstrating its strong capability in the low-data
regime.</p>
  </details>
</details>
<details>
  <summary>17. <b>标题：Self-supervised and Weakly Supervised Contrastive Learning for  Frame-wise Action Representations</b></summary>
  <p><b>编号</b>：[47]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.03125</p>
  <p><b>作者</b>：Minghao Chen,  Renbo Tu,  Chenxi Huang,  Yuqi Lin,  Boxi Wu,  Deng Cai</p>
  <p><b>备注</b>：13 pages, 8 figures</p>
  <p><b>关键词</b>：short video clips, representation learning focused, action representation learning, focused on global, action representation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Previous work on action representation learning focused on global
representations for short video clips. In contrast, many practical
applications, such as video alignment, strongly demand learning the intensive
representation of long videos. In this paper, we introduce a new framework of
contrastive action representation learning (CARL) to learn frame-wise action
representation in a self-supervised or weakly-supervised manner, especially for
long videos. Specifically, we introduce a simple but effective video encoder
that considers both spatial and temporal context by combining convolution and
transformer. Inspired by the recent massive progress in self-supervised
learning, we propose a new sequence contrast loss (SCL) applied to two related
views obtained by expanding a series of spatio-temporal data in two versions.
One is the self-supervised version that optimizes embedding space by minimizing
KL-divergence between sequence similarity of two augmented views and prior
Gaussian distribution of timestamp distance. The other is the weakly-supervised
version that builds more sample pairs among videos using video-level labels by
dynamic time wrapping (DTW). Experiments on FineGym, PennAction, and Pouring
datasets show that our method outperforms previous state-of-the-art by a large
margin for downstream fine-grained action classification and even faster
inference. Surprisingly, although without training on paired videos like in
previous works, our self-supervised version also shows outstanding performance
in video alignment and fine-grained frame retrieval tasks.</p>
  </details>
</details>
<details>
  <summary>18. <b>标题：A comparative study of emotion recognition methods using facial  expressions</b></summary>
  <p><b>编号</b>：[54]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.03102</p>
  <p><b>作者</b>：Rim EL Cheikh,  Hélène Tran,  Issam Falih,  Engelbert Mephu Nguifo</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：facial expression gives, Facial Emotion Recognition, expression gives insight, explicitly expressed, interlocutor is important</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Understanding the facial expressions of our interlocutor is important to
enrich the communication and to give it a depth that goes beyond the explicitly
expressed. In fact, studying one's facial expression gives insight into their
hidden emotion state. However, even as humans, and despite our empathy and
familiarity with the human emotional experience, we are only able to guess what
the other might be feeling. In the fields of artificial intelligence and
computer vision, Facial Emotion Recognition (FER) is a topic that is still in
full growth mostly with the advancement of deep learning approaches and the
improvement of data collection. The main purpose of this paper is to compare
the performance of three state-of-the-art networks, each having their own
approach to improve on FER tasks, on three FER datasets. The first and second
sections respectively describe the three datasets and the three studied network
architectures designed for an FER task. The experimental protocol, the results
and their interpretation are outlined in the remaining sections.</p>
  </details>
</details>
<details>
  <summary>19. <b>标题：Semantic-Conditional Diffusion Networks for Image Captioning</b></summary>
  <p><b>编号</b>：[55]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.03099</p>
  <p><b>作者</b>：Jianjie Luo,  Yehao Li,  Yingwei Pan,  Ting Yao,  Jianlin Feng,  Hongyang Chao,  Tao Mei</p>
  <p><b>备注</b>：Source code is available at \url{this https URL}</p>
  <p><b>关键词</b>：powerful generative models, Recent advances, generation have witnessed, witnessed the rise, act as powerful</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent advances on text-to-image generation have witnessed the rise of
diffusion models which act as powerful generative models. Nevertheless, it is
not trivial to exploit such latent variable models to capture the dependency
among discrete words and meanwhile pursue complex visual-language alignment in
image captioning. In this paper, we break the deeply rooted conventions in
learning Transformer-based encoder-decoder, and propose a new diffusion model
based paradigm tailored for image captioning, namely Semantic-Conditional
Diffusion Networks (SCD-Net). Technically, for each input image, we first
search the semantically relevant sentences via cross-modal retrieval model to
convey the comprehensive semantic information. The rich semantics are further
regarded as semantic prior to trigger the learning of Diffusion Transformer,
which produces the output sentence in a diffusion process. In SCD-Net, multiple
Diffusion Transformer structures are stacked to progressively strengthen the
output sentence with better visional-language alignment and linguistical
coherence in a cascaded manner. Furthermore, to stabilize the diffusion
process, a new self-critical sequence training strategy is designed to guide
the learning of SCD-Net with the knowledge of a standard autoregressive
Transformer model. Extensive experiments on COCO dataset demonstrate the
promising potential of using diffusion models in the challenging image
captioning task. Source code is available at
\url{this https URL}.</p>
  </details>
</details>
<details>
  <summary>20. <b>标题：Interpretation of Neural Networks is Susceptible to Universal  Adversarial Perturbations</b></summary>
  <p><b>编号</b>：[57]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.03095</p>
  <p><b>作者</b>：Haniyeh Ehsani Oskouie,  Farzan Farnia</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：deep learning literature, learning literature, standard image datasets, Interpreting neural network, extensively studied</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Interpreting neural network classifiers using gradient-based saliency maps
has been extensively studied in the deep learning literature. While the
existing algorithms manage to achieve satisfactory performance in application
to standard image recognition datasets, recent works demonstrate the
vulnerability of widely-used gradient-based interpretation schemes to
norm-bounded perturbations adversarially designed for every individual input
sample. However, such adversarial perturbations are commonly designed using the
knowledge of an input sample, and hence perform sub-optimally in application to
an unknown or constantly changing data point. In this paper, we show the
existence of a Universal Perturbation for Interpretation (UPI) for standard
image datasets, which can alter a gradient-based feature map of neural networks
over a significant fraction of test samples. To design such a UPI, we propose a
gradient-based optimization method as well as a principal component analysis
(PCA)-based approach to compute a UPI which can effectively alter a neural
network's gradient-based interpretation on different samples. We support the
proposed UPI approaches by presenting several numerical results of their
successful applications to standard image datasets.</p>
  </details>
</details>
<details>
  <summary>21. <b>标题：An Empirical Study on the Efficacy of Deep Active Learning for Image  Classification</b></summary>
  <p><b>编号</b>：[61]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.03088</p>
  <p><b>作者</b>：Yu Li,  Muxi Chen,  Yannan Liu,  Daojing He,  Qiang Xu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Deep Active Learning, Active Learning, reduce labeling costs, Deep Active, supervised learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep Active Learning (DAL) has been advocated as a promising method to reduce
labeling costs in supervised learning. However, existing evaluations of DAL
methods are based on different settings, and their results are controversial.
To tackle this issue, this paper comprehensively evaluates 19 existing DAL
methods in a uniform setting, including traditional
fully-\underline{s}upervised \underline{a}ctive \underline{l}earning (SAL)
strategies and emerging \underline{s}emi-\underline{s}upervised
\underline{a}ctive \underline{l}earning (SSAL) techniques. We have several
non-trivial findings. First, most SAL methods cannot achieve higher accuracy
than random selection. Second, semi-supervised training brings significant
performance improvement compared to pure SAL methods. Third, performing data
selection in the SSAL setting can achieve a significant and consistent
performance improvement, especially with abundant unlabeled data. Our findings
produce the following guidance for practitioners: one should (i) apply SSAL
early and (ii) collect more unlabeled data whenever possible, for better model
performance.</p>
  </details>
</details>
<details>
  <summary>22. <b>标题：Land Use Prediction using Electro-Optical to SAR Few-Shot Transfer  Learning</b></summary>
  <p><b>编号</b>：[64]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.03084</p>
  <p><b>作者</b>：Marcel Hussing,  Karen Li,  Eric Eaton</p>
  <p><b>备注</b>：Published at Tackling Climate Change with Machine Learning workshop at NeurIPS 2022</p>
  <p><b>关键词</b>：ecosystem monitoring, Satellite image analysis, important implications, implications for land, image analysis</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Satellite image analysis has important implications for land use,
urbanization, and ecosystem monitoring. Deep learning methods can facilitate
the analysis of different satellite modalities, such as electro-optical (EO)
and synthetic aperture radar (SAR) imagery, by supporting knowledge transfer
between the modalities to compensate for individual shortcomings. Recent
progress has shown how distributional alignment of neural network embeddings
can produce powerful transfer learning models by employing a sliced Wasserstein
distance (SWD) loss. We analyze how this method can be applied to Sentinel-1
and -2 satellite imagery and develop several extensions toward making it
effective in practice. In an application to few-shot Local Climate Zone (LCZ)
prediction, we show that these networks outperform multiple common baselines on
datasets with a large number of classes. Further, we provide evidence that
instance normalization can significantly stabilize the training process and
that explicitly shaping the embedding space using supervised contrastive
learning can lead to improved performance.</p>
  </details>
</details>
<details>
  <summary>23. <b>标题：Multiple Perturbation Attack: Attack Pixelwise Under Different  $\ell_p$-norms For Better Adversarial Performance</b></summary>
  <p><b>编号</b>：[72]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.03069</p>
  <p><b>作者</b>：Ngoc N. Tran,  Anh Tuan Bui,  Dinh Phung,  Trung Le</p>
  <p><b>备注</b>：19 pages, 8 figures, 7 tables</p>
  <p><b>关键词</b>：hot topic recently, Adversarial machine learning, deep neural networks, topic recently, machine learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Adversarial machine learning has been both a major concern and a hot topic
recently, especially with the ubiquitous use of deep neural networks in the
current landscape. Adversarial attacks and defenses are usually likened to a
cat-and-mouse game in which defenders and attackers evolve over the time. On
one hand, the goal is to develop strong and robust deep networks that are
resistant to malicious actors. On the other hand, in order to achieve that, we
need to devise even stronger adversarial attacks to challenge these defense
models. Most of existing attacks employs a single $\ell_p$ distance (commonly,
$p\in\{1,2,\infty\}$) to define the concept of closeness and performs steepest
gradient ascent w.r.t. this $p$-norm to update all pixels in an adversarial
example in the same way. These $\ell_p$ attacks each has its own pros and cons;
and there is no single attack that can successfully break through defense
models that are robust against multiple $\ell_p$ norms simultaneously.
Motivated by these observations, we come up with a natural approach: combining
various $\ell_p$ gradient projections on a pixel level to achieve a joint
adversarial perturbation. Specifically, we learn how to perturb each pixel to
maximize the attack performance, while maintaining the overall visual
imperceptibility of adversarial examples. Finally, through various experiments
with standardized benchmarks, we show that our method outperforms most current
strong attacks across state-of-the-art defense mechanisms, while retaining its
ability to remain clean visually.</p>
  </details>
</details>
<details>
  <summary>24. <b>标题：Front-door Adjustment via Style Transfer for Out-of-distribution  Generalisation</b></summary>
  <p><b>编号</b>：[75]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.03063</p>
  <p><b>作者</b>：Toan Nguyen,  Kien Do,  Duc Thanh Nguyen,  Bao Duong,  Thin Nguyen</p>
  <p><b>备注</b>：22 pages, 15 figures</p>
  <p><b>关键词</b>：generalisation aims, OOD image classification, aims to build, generalise its learnt, learnt knowledge</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Out-of-distribution (OOD) generalisation aims to build a model that can well
generalise its learnt knowledge from source domains to an unseen target domain.
However, current image classification models often perform poorly in the OOD
setting due to statistically spurious correlations learning from model
training. From causality-based perspective, we formulate the data generation
process in OOD image classification using a causal graph. On this graph, we
show that prediction P(Y|X) of a label Y given an image X in statistical
learning is formed by both causal effect P(Y|do(X)) and spurious effects caused
by confounding features (e.g., background). Since the spurious features are
domain-variant, the prediction P(Y|X) becomes unstable on unseen domains. In
this paper, we propose to mitigate the spurious effect of confounders using
front-door adjustment. In our method, the mediator variable is hypothesized as
semantic features that are essential to determine a label for an image.
Inspired by capability of style transfer in image generation, we interpret the
combination of the mediator variable with different generated images in the
front-door formula and propose novel algorithms to estimate it. Extensive
experimental results on widely used benchmark datasets verify the effectiveness
of our method.</p>
  </details>
</details>
<details>
  <summary>25. <b>标题：Unifying Short and Long-Term Tracking with Graph Hierarchies</b></summary>
  <p><b>编号</b>：[83]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.03038</p>
  <p><b>作者</b>：Orcun Cetintas,  Guillem Brasó,  Laura Leal-Taixé</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：long videos effectively, Tracking objects, short-term association, association for un-occluded, long-term association</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Tracking objects over long videos effectively means solving a spectrum of
problems, from short-term association for un-occluded objects to long-term
association for objects that are occluded and then reappear in the scene.
Methods tackling these two tasks are often disjoint and crafted for specific
scenarios, and top-performing approaches are often a mix of techniques, which
yields engineering-heavy solutions that lack generality. In this work, we
question the need for hybrid approaches and introduce SUSHI, a unified and
scalable multi-object tracker. Our approach processes long clips by splitting
them into a hierarchy of subclips, which enables high scalability. We leverage
graph neural networks to process all levels of the hierarchy, which makes our
model unified across temporal scales and highly general. As a result, we obtain
significant improvements over state-of-the-art on four diverse datasets. Our
code and models will be made available.</p>
  </details>
</details>
<details>
  <summary>26. <b>标题：IncepFormer: Efficient Inception Transformer with Pyramid Pooling for  Semantic Segmentation</b></summary>
  <p><b>编号</b>：[84]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.03035</p>
  <p><b>作者</b>：Lihua Fu,  Haoyue Tian,  Xiangping Bryce Zhai,  Pan Gao,  Xiaojiang Peng</p>
  <p><b>备注</b>：Preprint with 8 pages of main body and 3 pages of supplementary material</p>
  <p><b>关键词</b>：fine localisation information, Semantic segmentation, localisation information, fine localisation, features</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Semantic segmentation usually benefits from global contexts, fine
localisation information, multi-scale features, etc. To advance
Transformer-based segmenters with these aspects, we present a simple yet
powerful semantic segmentation architecture, termed as IncepFormer. IncepFormer
has two critical contributions as following. First, it introduces a novel
pyramid structured Transformer encoder which harvests global context and fine
localisation features simultaneously. These features are concatenated and fed
into a convolution layer for final per-pixel prediction. Second, IncepFormer
integrates an Inception-like architecture with depth-wise convolutions, and a
light-weight feed-forward module in each self-attention layer, efficiently
obtaining rich local multi-scale object features. Extensive experiments on five
benchmarks show that our IncepFormer is superior to state-of-the-art methods in
both accuracy and speed, e.g., 1) our IncepFormer-S achieves 47.7% mIoU on
ADE20K which outperforms the existing best method by 1% while only costs half
parameters and fewer FLOPs. 2) Our IncepFormer-B finally achieves 82.0% mIoU on
Cityscapes dataset with 39.6M parameters. Code is
available:this http URL.</p>
  </details>
</details>
<details>
  <summary>27. <b>标题：AbHE: All Attention-based Homography Estimation</b></summary>
  <p><b>编号</b>：[87]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.03029</p>
  <p><b>作者</b>：Mingxiao Huo,  Zhihao Zhang,  Xianqiang Yang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：basic computer vision, computer vision task, convolution neural network, image alignment, multi-view images</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Homography estimation is a basic computer vision task, which aims to obtain
the transformation from multi-view images for image alignment. Unsupervised
learning homography estimation trains a convolution neural network for feature
extraction and transformation matrix regression. While the state-of-the-art
homography method is based on convolution neural networks, few work focuses on
transformer which shows superiority in high-level vision tasks. In this paper,
we propose a strong-baseline model based on the Swin Transformer, which
combines convolution neural network for local features and transformer module
for global features. Moreover, a cross non-local layer is introduced to search
the matched features within the feature maps this http URL the homography
regression stage, we adopts an attention layer for the channels of correlation
volume, which can drop out some weak correlation feature points. The experiment
shows that in 8 Degree-of-Freedoms(DOFs) homography estimation our methods
overperform the state-of-the-art method.</p>
  </details>
</details>
<details>
  <summary>28. <b>标题：Iterative Next Boundary Detection for Instance Segmentation of Tree  Rings in Microscopy Images of Shrub Cross Sections</b></summary>
  <p><b>编号</b>：[88]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.03022</p>
  <p><b>作者</b>：Alexander Gillert,  Giulia Resente,  Alba Anadon-Rosell,  Martin Wilmking,  Uwe Freiherr von Lukas</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：detecting tree rings, analyze the problem, microscopy images, shrub cross sections, tree rings</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We analyze the problem of detecting tree rings in microscopy images of shrub
cross sections. This can be regarded as a special case of the instance
segmentation task with several particularities such as the concentric circular
ring shape of the objects and high precision requirements due to which existing
methods don't perform sufficiently well. We propose a new iterative method
which we term Iterative Next Boundary Detection (INBD). It intuitively models
the natural growth direction, starting from the center of the shrub cross
section and detecting the next ring boundary in each iteration step. In our
experiments, INBD shows superior performance to generic instance segmentation
methods and is the only one with a built-in notion of chronological order. Our
dataset and source code are available at this http URL.</p>
  </details>
</details>
<details>
  <summary>29. <b>标题：GD-MAE: Generative Decoder for MAE Pre-training on LiDAR Point Clouds</b></summary>
  <p><b>编号</b>：[93]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.03010</p>
  <p><b>作者</b>：Honghui Yang,  Tong He,  Jiaheng Liu,  Hua Chen,  Boxi Wu,  Binbin Lin,  Xiaofei He,  Wanli Ouyang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：point clouds remains, clouds remains challenging, remains challenging due, developing vision tasks, Masked Autoencoders</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Despite the tremendous progress of Masked Autoencoders (MAE) in developing
vision tasks such as image and video, exploring MAE in large-scale 3D point
clouds remains challenging due to the inherent irregularity. In contrast to
previous 3D MAE frameworks, which either design a complex decoder to infer
masked information from maintained regions or adopt sophisticated masking
strategies, we instead propose a much simpler paradigm. The core idea is to
apply a \textbf{G}enerative \textbf{D}ecoder for MAE (GD-MAE) to automatically
merges the surrounding context to restore the masked geometric knowledge in a
hierarchical fusion manner. In doing so, our approach is free from introducing
the heuristic design of decoders and enjoys the flexibility of exploring
various masking strategies. The corresponding part costs less than
\textbf{12\%} latency compared with conventional methods, while achieving
better performance. We demonstrate the efficacy of the proposed method on
several large-scale benchmarks: Waymo, KITTI, and ONCE. Consistent improvement
on downstream detection tasks illustrates strong robustness and generalization
capability. Not only our method reveals state-of-the-art results, but
remarkably, we achieve comparable accuracy even with \textbf{20\%} of the
labeled data on the Waymo dataset. The code will be released at
\url{this https URL}.</p>
  </details>
</details>
<details>
  <summary>30. <b>标题：Supervised Image Segmentation for High Dynamic Range Imaging</b></summary>
  <p><b>编号</b>：[95]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.03002</p>
  <p><b>作者</b>：Ali Reza Omrani,  Davide Moroni</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：capture limited luminosity, Regular cameras, limited luminosity, cameras and cell, cell phones</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Regular cameras and cell phones are able to capture limited luminosity. Thus,
in terms of quality, most of the produced images from such devices are not
similar to the real world. They are overly dark or too bright, and the details
are not perfectly visible. Various methods, which fall under the name of High
Dynamic Range (HDR) Imaging, can be utilised to cope with this problem. Their
objective is to produce an image with more details. However, unfortunately,
most methods for generating an HDR image from Multi-Exposure images only
concentrate on how to combine different exposures and do not have any focus on
choosing the best details of each image. Therefore, it is strived in this
research to extract the most visible areas of each image with the help of image
segmentation. Two methods of producing the Ground Truth were considered, as
manual threshold and Otsu threshold, and a neural network will be used to train
segment these areas. Finally, it will be shown that the neural network is able
to segment the visible parts of pictures acceptably.</p>
  </details>
</details>
<details>
  <summary>31. <b>标题：Super-resolution Probabilistic Rain Prediction from Satellite Data Using  3D U-Nets and EarthFormers</b></summary>
  <p><b>编号</b>：[97]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02998</p>
  <p><b>作者</b>：Yang Li,  Haiyu Dong,  Zuliang Fang,  Jonathan Weyn,  Pete Luferenko</p>
  <p><b>备注</b>：Weather4cast-2022 & NeurIPS</p>
  <p><b>关键词</b>：rain prediction, Accurate and timely, challenging task, timely rain prediction, crucial for decision</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Accurate and timely rain prediction is crucial for decision making and is
also a challenging task. This paper presents a solution which won the 2 nd
prize in the Weather4cast 2022 NeurIPS competition using 3D U-Nets and
EarthFormers for 8-hour probabilistic rain prediction based on multi-band
satellite images. The spatial context effect of the input satellite image has
been deeply explored and optimal context range has been found. Based on the
imbalanced rain distribution, we trained multiple models with different loss
functions. To further improve the model performance, multi-model ensemble and
threshold optimization were used to produce the final probabilistic rain
prediction. Experiment results and leaderboard scores demonstrate that optimal
spatial context, combined loss function, multi-model ensemble, and threshold
optimization all provide modest model gain. A permutation test was used to
analyze the effect of each satellite band on rain prediction, and results show
that satellite bands signifying cloudtop phase (8.7 um) and cloud-top height
(10.8 and 13.4 um) are the best predictors for rain prediction. The source code
is available at this https URL.</p>
  </details>
</details>
<details>
  <summary>32. <b>标题：Weakly-Supervised Gaze Estimation from Synthetic Views</b></summary>
  <p><b>编号</b>：[98]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02997</p>
  <p><b>作者</b>：Evangelos Ververas,  Polydefkis Gkagkos,  Jiankang Deng,  Jia Guo,  Michail Christos Doukas,  Stefanos Zafeiriou</p>
  <p><b>备注</b>：10 pages, 15 figures</p>
  <p><b>关键词</b>：direct mapping, mapping between input, spherical coordinates, gaze estimation, gaze</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>3D gaze estimation is most often tackled as learning a direct mapping between
input images and the gaze vector or its spherical coordinates. Recently, it has
been shown that pose estimation of the face, body and hands benefits from
revising the learning target from few pose parameters to dense 3D coordinates.
In this work, we leverage this observation and propose to tackle 3D gaze
estimation as regression of 3D eye meshes. We overcome the absence of
compatible ground truth by fitting a rigid 3D eyeball template on existing gaze
datasets and propose to improve generalization by making use of widely
available in-the-wild face images. To this end, we propose an automatic
pipeline to retrieve robust gaze pseudo-labels from arbitrary face images and
design a multi-view supervision framework to balance their effect during
training. In our experiments, our method achieves improvement of 30% compared
to state-of-the-art in cross-dataset gaze estimation, when no ground truth data
are available for training, and 7% when they are. We make our project publicly
available at this https URL.</p>
  </details>
</details>
<details>
  <summary>33. <b>标题：Sparse Message Passing Network with Feature Integration for Online  Multiple Object Tracking</b></summary>
  <p><b>编号</b>：[100]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02992</p>
  <p><b>作者</b>：Bisheng Wang,  Horst Possegger,  Horst Bischof,  Guo Cao</p>
  <p><b>备注</b>：8 pages, 2 figures</p>
  <p><b>关键词</b>：Existing Multiple Object, Multiple Object Tracking, Multiple Object, design complex architectures, Existing Multiple</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Existing Multiple Object Tracking (MOT) methods design complex architectures
for better tracking performance. However, without a proper organization of
input information, they still fail to perform tracking robustly and suffer from
frequent identity switches. In this paper, we propose two novel methods
together with a simple online Message Passing Network (MPN) to address these
limitations. First, we explore different integration methods for the graph node
and edge embeddings and put forward a new IoU (Intersection over Union) guided
function, which improves long term tracking and handles identity switches.
Second, we introduce a hierarchical sampling strategy to construct sparser
graphs which allows to focus the training on more difficult samples.
Experimental results demonstrate that a simple online MPN with these two
contributions can perform better than many state-of-the-art methods. In
addition, our association method generalizes well and can also improve the
results of private detection based methods.</p>
  </details>
</details>
<details>
  <summary>34. <b>标题：PRISM: Probabilistic Real-Time Inference in Spatial World Models</b></summary>
  <p><b>编号</b>：[101]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02988</p>
  <p><b>作者</b>：Atanas Mirchev,  Baris Kayalibay,  Ahmed Agha,  Patrick van der Smagt,  Daniel Cremers,  Justin Bayer</p>
  <p><b>备注</b>：Will appear in PMLR, CoRL 2022</p>
  <p><b>关键词</b>：introduce PRISM, visual perception, motion and visual, probabilistic generative model, model agent dynamics</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We introduce PRISM, a method for real-time filtering in a probabilistic
generative model of agent motion and visual perception. Previous approaches
either lack uncertainty estimates for the map and agent state, do not run in
real-time, do not have a dense scene representation or do not model agent
dynamics. Our solution reconciles all of these aspects. We start from a
predefined state-space model which combines differentiable rendering and 6-DoF
dynamics. Probabilistic inference in this model amounts to simultaneous
localisation and mapping (SLAM) and is intractable. We use a series of
approximations to Bayesian inference to arrive at probabilistic map and state
estimates. We take advantage of well-established methods and closed-form
updates, preserving accuracy and enabling real-time capability. The proposed
solution runs at 10Hz real-time and is similarly accurate to state-of-the-art
SLAM in small to medium-sized indoor environments, with high-speed UAV and
handheld camera agents (Blackbird, EuRoC and TUM-RGBD).</p>
  </details>
</details>
<details>
  <summary>35. <b>标题：Muscles in Action</b></summary>
  <p><b>编号</b>：[103]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02978</p>
  <p><b>作者</b>：Mia Chiquier,  Carl Vondrick</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Small differences, person motion, motion can engage, engage drastically, muscles</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Small differences in a person's motion can engage drastically different
muscles. While most visual representations of human activity are trained from
video, people learn from multimodal experiences, including from the
proprioception of their own muscles. We present a new visual perception task
and dataset to model muscle activation in human activities from monocular
video. Our Muscles in Action (MIA) dataset consists of 2 hours of synchronized
video and surface electromyography (sEMG) data of subjects performing various
exercises. Using this dataset, we learn visual representations that are
predictive of muscle activation from monocular video. We present several
models, including a transformer model, and measure their ability to generalize
to new exercises and subjects. Putting muscles into computer vision systems
will enable richer models of virtual humans, with applications in sports,
fitness, and AR/VR.</p>
  </details>
</details>
<details>
  <summary>36. <b>标题：Open World DETR: Transformer based Open World Object Detection</b></summary>
  <p><b>编号</b>：[107]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02969</p>
  <p><b>作者</b>：Na Dong,  Yongqiang Zhang,  Mingli Ding,  Gim Hee Lee</p>
  <p><b>备注</b>：13 pages, 6 figures</p>
  <p><b>关键词</b>：Open world object, world object detection, Open world, Open World DETR, world object</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Open world object detection aims at detecting objects that are absent in the
object classes of the training data as unknown objects without explicit
supervision. Furthermore, the exact classes of the unknown objects must be
identified without catastrophic forgetting of the previous known classes when
the corresponding annotations of unknown objects are given incrementally. In
this paper, we propose a two-stage training approach named Open World DETR for
open world object detection based on Deformable DETR. In the first stage, we
pre-train a model on the current annotated data to detect objects from the
current known classes, and concurrently train an additional binary classifier
to classify predictions into foreground or background classes. This helps the
model to build an unbiased feature representations that can facilitate the
detection of unknown classes in subsequent process. In the second stage, we
fine-tune the class-specific components of the model with a multi-view
self-labeling strategy and a consistency constraint. Furthermore, we alleviate
catastrophic forgetting when the annotations of the unknown classes becomes
available incrementally by using knowledge distillation and exemplar replay.
Experimental results on PASCAL VOC and MS-COCO show that our proposed method
outperforms other state-of-the-art open world object detection methods by a
large margin.</p>
  </details>
</details>
<details>
  <summary>37. <b>标题：Domain Generalization Strategy to Train Classifiers Robust to  Spatial-Temporal Shift</b></summary>
  <p><b>编号</b>：[108]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02968</p>
  <p><b>作者</b>：Minseok Seo,  Doyi Kim,  Seungheon Shin,  Eunbin Kim,  Sewoong Ahn,  Yeji Choi,</p>
  <p><b>备注</b>：Core Transfer Track 1st place solution in Weather4Cast competition at NeuIPS22</p>
  <p><b>关键词</b>：Deep learning-based weather, learning-based weather prediction, recent years, spatial-temporal shifts, advanced significantly</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep learning-based weather prediction models have advanced significantly in
recent years. However, data-driven models based on deep learning are difficult
to apply to real-world applications because they are vulnerable to
spatial-temporal shifts. A weather prediction task is especially susceptible to
spatial-temporal shifts when the model is overfitted to locality and
seasonality. In this paper, we propose a training strategy to make the weather
prediction model robust to spatial-temporal shifts. We first analyze the effect
of hyperparameters and augmentations of the existing training strategy on the
spatial-temporal shift robustness of the model. Next, we propose an optimal
combination of hyperparameters and augmentation based on the analysis results
and a test-time augmentation. We performed all experiments on the W4C22
Transfer dataset and achieved the 1st performance.</p>
  </details>
</details>
<details>
  <summary>38. <b>标题：SDM: Spatial Diffusion Model for Large Hole Image Inpainting</b></summary>
  <p><b>编号</b>：[109]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02963</p>
  <p><b>作者</b>：Wenbo Li,  Xin Yu,  Kun Zhou,  Yibing Song,  Zhe Lin,  Jiaya Jia</p>
  <p><b>备注</b>：18 pages, 14 figures</p>
  <p><b>关键词</b>：Generative adversarial networks, large missing regions, made great success, difficulties tackling large, tackling large missing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Generative adversarial networks (GANs) have made great success in image
inpainting yet still have difficulties tackling large missing regions. In
contrast, iterative algorithms, such as autoregressive and denoising diffusion
models, have to be deployed with massive computing resources for decent effect.
To overcome the respective limitations, we present a novel spatial diffusion
model (SDM) that uses a few iterations to gradually deliver informative pixels
to the entire image, largely enhancing the inference efficiency. Also, thanks
to the proposed decoupled probabilistic modeling and spatial diffusion scheme,
our method achieves high-quality large-hole completion. On multiple benchmarks,
we achieve new state-of-the-art performance. Code is released at
this https URL.</p>
  </details>
</details>
<details>
  <summary>39. <b>标题：Simple Baseline for Weather Forecasting Using Spatiotemporal Context  Aggregation Network</b></summary>
  <p><b>编号</b>：[112]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02952</p>
  <p><b>作者</b>：Minseok Seo,  Doyi Kim,  Seungheon Shin,  Eunbin Kim,  Sewoong Ahn,  Yeji Choi,</p>
  <p><b>备注</b>：1st place solution for stage1 and Core Transfer in the Weather4Cast competition on NeurIPS 22</p>
  <p><b>关键词</b>：numerical simulation systems, computationally intensive numerical, intensive numerical simulation, Traditional weather forecasting, weather forecasting</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Traditional weather forecasting relies on domain expertise and
computationally intensive numerical simulation systems. Recently, with the
development of a data-driven approach, weather forecasting based on deep
learning has been receiving attention. Deep learning-based weather forecasting
has made stunning progress, from various backbone studies using CNN, RNN, and
Transformer to training strategies using weather observations datasets with
auxiliary inputs. All of this progress has contributed to the field of weather
forecasting; however, many elements and complex structures of deep learning
models prevent us from reaching physical interpretations. This paper proposes a
SImple baseline with a spatiotemporal context Aggregation Network (SIANet) that
achieved state-of-the-art in 4 parts of 5 benchmarks of W4C22. This simple but
efficient structure uses only satellite images and CNNs in an end-to-end
fashion without using a multi-model ensemble or fine-tuning. This simplicity of
SIANet can be used as a solid baseline that can be easily applied in weather
forecasting using deep learning.</p>
  </details>
</details>
<details>
  <summary>40. <b>标题：M-VADER: A Model for Diffusion with Multimodal Context</b></summary>
  <p><b>编号</b>：[117]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02936</p>
  <p><b>作者</b>：Samuel Weinbach,  Marco Bellagente,  Constantin Eichenberg,  Andrew Dai,  Robert Baldock,  Souradeep Nanda,  Björn Deiseroth,  Koen Oostermeijer,  Hannah Teufel,  Andres Felipe Cruz-Salinas</p>
  <p><b>备注</b>：22 pages, 14 figures, 2 tables</p>
  <p><b>关键词</b>：arbitrary combinations, image generation, combinations, image, model</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We introduce M-VADER: a diffusion model (DM) for image generation where the
output can be specified using arbitrary combinations of images and text. We
show how M-VADER enables the generation of images specified using combinations
of image and text, and combinations of multiple images. Previously, a number of
successful DM image generation algorithms have been introduced that make it
possible to specify the output image using a text prompt. Inspired by the
success of those models, and led by the notion that language was already
developed to describe the elements of visual contexts that humans find most
important, we introduce an embedding model closely related to a vision-language
model. Specifically, we introduce the embedding model S-MAGMA: a 13 billion
parameter multimodal decoder combining components from an autoregressive
vision-language model MAGMA and biases finetuned for semantic search.</p>
  </details>
</details>
<details>
  <summary>41. <b>标题：Leveraging Different Learning Styles for Improved Knowledge Distillation</b></summary>
  <p><b>编号</b>：[121]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02931</p>
  <p><b>作者</b>：Usma Niyaz,  Deepti R. Bathula</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：training mechanism adopted, Learning style refers, style refers, training mechanism, mechanism adopted</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Learning style refers to a type of training mechanism adopted by an
individual to gain new knowledge. As suggested by the VARK model, humans have
different learning preferences like visual, auditory, etc., for acquiring and
effectively processing information. Inspired by this concept, our work explores
the idea of mixed information sharing with model compression in the context of
Knowledge Distillation (KD) and Mutual Learning (ML). Unlike conventional
techniques that share the same type of knowledge with all networks, we propose
to train individual networks with different forms of information to enhance the
learning process. We formulate a combined KD and ML framework with one teacher
and two student networks that share or exchange information in the form of
predictions and feature maps. Our comprehensive experiments with benchmark
classification and segmentation datasets demonstrate that with 15% compression,
the ensemble performance of networks trained with diverse forms of knowledge
outperforms the conventional techniques both quantitatively and qualitatively.</p>
  </details>
</details>
<details>
  <summary>42. <b>标题：G-MSM: Unsupervised Multi-Shape Matching with Graph-based Affinity  Priors</b></summary>
  <p><b>编号</b>：[129]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02910</p>
  <p><b>作者</b>：Marvin Eisenberger,  Aysim Toker,  Laura Leal-Taixé,  Daniel Cremers</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：unsupervised learning approach, Graph-based Multi-Shape Matching, Graph-based Multi-Shape, present G-MSM, unsupervised learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present G-MSM (Graph-based Multi-Shape Matching), a novel unsupervised
learning approach for non-rigid shape correspondence. Rather than treating a
collection of input poses as an unordered set of samples, we explicitly model
the underlying shape data manifold. To this end, we propose an adaptive
multi-shape matching architecture that constructs an affinity graph on a given
set of training shapes in a self-supervised manner. The key idea is to combine
putative, pairwise correspondences by propagating maps along shortest paths in
the underlying shape graph. During training, we enforce cycle-consistency
between such optimal paths and the pairwise matches which enables our model to
learn topology-aware shape priors. We explore different classes of shape graphs
and recover specific settings, like template-based matching (star graph) or
learnable ranking/sorting (TSP graph), as special cases in our framework.
Finally, we demonstrate state-of-the-art performance on several recent shape
correspondence benchmarks, including real-world 3D scan meshes with topological
noise and challenging inter-class pairs.</p>
  </details>
</details>
<details>
  <summary>43. <b>标题：Multimodal Tree Decoder for Table of Contents Extraction in Document  Images</b></summary>
  <p><b>编号</b>：[133]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02896</p>
  <p><b>作者</b>：Pengfei Hu,  Zhenrong Zhang,  Jianshu Zhang,  Jun Du,  Jiajia Wu</p>
  <p><b>备注</b>：Accepted by ICPR2022</p>
  <p><b>关键词</b>：extraction aims, aims to extract, understand the outline, extract headings, document understanding</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Table of contents (ToC) extraction aims to extract headings of different
levels in documents to better understand the outline of the contents, which can
be widely used for document understanding and information retrieval. Existing
works often use hand-crafted features and predefined rule-based functions to
detect headings and resolve the hierarchical relationship between headings.
Both the benchmark and research based on deep learning are still limited.
Accordingly, in this paper, we first introduce a standard dataset, HierDoc,
including image samples from 650 documents of scientific papers with their
content labels. Then we propose a novel end-to-end model by using the
multimodal tree decoder (MTD) for ToC as a benchmark for HierDoc. The MTD model
is mainly composed of three parts, namely encoder, classifier, and decoder. The
encoder fuses the multimodality features of vision, text, and layout
information for each entity of the document. Then the classifier recognizes and
selects the heading entities. Next, to parse the hierarchical relationship
between the heading entities, a tree-structured decoder is designed. To
evaluate the performance, both the metric of tree-edit-distance similarity
(TEDS) and F1-Measure are adopted. Finally, our MTD approach achieves an
average TEDS of 87.2% and an average F1-Measure of 88.1% on the test set of
HierDoc. The code and dataset will be released at:
this https URL.</p>
  </details>
</details>
<details>
  <summary>44. <b>标题：GAS-Net: Generative Artistic Style Neural Networks for Fonts</b></summary>
  <p><b>编号</b>：[136]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02886</p>
  <p><b>作者</b>：Haoyang He,  Xin Jin,  Angela Chen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：time-consuming and labor-intensive, huge amount, characters like Chinese, Chinese, Generating new fonts</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Generating new fonts is a time-consuming and labor-intensive, especially in a
language with a huge amount of characters like Chinese. Various deep learning
models have demonstrated the ability to efficiently generate new fonts with a
few reference characters of that style. This project aims to develop a few-shot
cross-lingual font generator based on AGIS-Net and improve the performance
metrics mentioned. Our approaches include redesigning the encoder and the loss
function. We will validate our method on multiple languages and datasets
mentioned.</p>
  </details>
</details>
<details>
  <summary>45. <b>标题：Multi-Task Edge Prediction in Temporally-Dynamic Video Graphs</b></summary>
  <p><b>编号</b>：[141]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02875</p>
  <p><b>作者</b>：Osman Ülger,  Julian Wiederer,  Mohsen Ghafoorian,  Vasileios Belagiannis,  Pascal Mettes</p>
  <p><b>备注</b>：BMVC2022</p>
  <p><b>关键词</b>：graph-level inference, learn effective node, effective node representations, Graph, Graph neural networks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Graph neural networks have shown to learn effective node representations,
enabling node-, link-, and graph-level inference. Conventional graph networks
assume static relations between nodes, while relations between entities in a
video often evolve over time, with nodes entering and exiting dynamically. In
such temporally-dynamic graphs, a core problem is inferring the future state of
spatio-temporal edges, which can constitute multiple types of relations. To
address this problem, we propose MTD-GNN, a graph network for predicting
temporally-dynamic edges for multiple types of relations. We propose a
factorized spatio-temporal graph attention layer to learn dynamic node
representations and present a multi-task edge prediction loss that models
multiple relations simultaneously. The proposed architecture operates on top of
scene graphs that we obtain from videos through object detection and
spatio-temporal linking. Experimental evaluations on ActionGenome and CLEVRER
show that modeling multiple relations in our temporally-dynamic graph network
can be mutually beneficial, outperforming existing static and spatio-temporal
graph neural networks, as well as state-of-the-art predicate classification
methods.</p>
  </details>
</details>
<details>
  <summary>46. <b>标题：Video Object of Interest Segmentation</b></summary>
  <p><b>编号</b>：[143]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02871</p>
  <p><b>作者</b>：Siyuan Zhou,  Chunru Zhan,  Biao Wang,  Tiezheng Ge,  Yuning Jiang,  Li Niu</p>
  <p><b>备注</b>：13 pages, 8 figures</p>
  <p><b>关键词</b>：computer vision task, vision task named, computer vision, VOIS, named video object</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this work, we present a new computer vision task named video object of
interest segmentation (VOIS). Given a video and a target image of interest, our
objective is to simultaneously segment and track all objects in the video that
are relevant to the target image. This problem combines the traditional video
object segmentation task with an additional image indicating the content that
users are concerned with. Since no existing dataset is perfectly suitable for
this new task, we specifically construct a large-scale dataset called
LiveVideos, which contains 2418 pairs of target images and live videos with
instance-level annotations. In addition, we propose a transformer-based method
for this task. We revisit Swin Transformer and design a dual-path structure to
fuse video and image features. Then, a transformer decoder is employed to
generate object proposals for segmentation and tracking from the fused
features. Extensive experiments on LiveVideos dataset show the superiority of
our proposed method.</p>
  </details>
</details>
<details>
  <summary>47. <b>标题：Evidential Deep Learning for Class-Incremental Semantic Segmentation</b></summary>
  <p><b>编号</b>：[145]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02863</p>
  <p><b>作者</b>：Karl Holmquist,  Lena Klasén,  Michael Felsberg</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：extend previously trained, previously trained neural, trained neural networks, aims to extend, extend previously</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Class-Incremental Learning is a challenging problem in machine learning that
aims to extend previously trained neural networks with new classes. This is
especially useful if the system is able to classify new objects despite the
original training data being unavailable. While the semantic segmentation
problem has received less attention than classification, it poses distinct
problems and challenges since previous and future target classes can be
unlabeled in the images of a single increment. In this case, the background,
past and future classes are correlated and there exist a background-shift. In
this paper, we address the problem of how to model unlabeled classes while
avoiding spurious feature clustering of future uncorrelated classes. We propose
to use Evidential Deep Learning to model the evidence of the classes as a
Dirichlet distribution. Our method factorizes the problem into a separate
foreground class probability, calculated by the expected value of the Dirichlet
distribution, and an unknown class (background) probability corresponding to
the uncertainty of the estimate. In our novel formulation, the background
probability is implicitly modeled, avoiding the feature space clustering that
comes from forcing the model to output a high background score for pixels that
are not labeled as objects. Experiments on the incremental Pascal VOC, and
ADE20k benchmarks show that our method is superior to state-of-the-art,
especially when repeatedly learning new classes with increasing number of
increments.</p>
  </details>
</details>
<details>
  <summary>48. <b>标题：SSDA3D: Semi-supervised Domain Adaptation for 3D Object Detection from  Point Cloud</b></summary>
  <p><b>编号</b>：[151]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02845</p>
  <p><b>作者</b>：Yan Wang,  Junbo Yin,  Wei Li,  Pascal Frossard,  Ruigang Yang,  Jianbing Shen</p>
  <p><b>备注</b>：Accepted by AAAI 2023</p>
  <p><b>关键词</b>：autonomous driving systems, advanced autonomous driving, driving systems, indispensable task, task in advanced</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>LiDAR-based 3D object detection is an indispensable task in advanced
autonomous driving systems. Though impressive detection results have been
achieved by superior 3D detectors, they suffer from significant performance
degeneration when facing unseen domains, such as different LiDAR
configurations, different cities, and weather conditions. The mainstream
approaches tend to solve these challenges by leveraging unsupervised domain
adaptation (UDA) techniques. However, these UDA solutions just yield
unsatisfactory 3D detection results when there is a severe domain shift, e.g.,
from Waymo (64-beam) to nuScenes (32-beam). To address this, we present a novel
Semi-Supervised Domain Adaptation method for 3D object detection (SSDA3D),
where only a few labeled target data is available, yet can significantly
improve the adaptation performance. In particular, our SSDA3D includes an
Inter-domain Adaptation stage and an Intra-domain Generalization stage. In the
first stage, an Inter-domain Point-CutMix module is presented to efficiently
align the point cloud distribution across domains. The Point-CutMix generates
mixed samples of an intermediate domain, thus encouraging to learn
domain-invariant knowledge. Then, in the second stage, we further enhance the
model for better generalization on the unlabeled target set. This is achieved
by exploring Intra-domain Point-MixUp in semi-supervised learning, which
essentially regularizes the pseudo label distribution. Experiments from Waymo
to nuScenes show that, with only 10% labeled target data, our SSDA3D can
surpass the fully-supervised oracle model with 100% target label. Our code is
available at this https URL.</p>
  </details>
</details>
<details>
  <summary>49. <b>标题：VISEM-Tracking: Human Spermatozoa Tracking Dataset</b></summary>
  <p><b>编号</b>：[152]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02842</p>
  <p><b>作者</b>：Vajira Thambawita,  Steven A. Hicks,  Andrea M. Storås,  Thu Nguyen,  Jorunn M. Andersen,  Oliwia Witczak,  Trine B. Haugen,  Hugo L. Hammer,  Pål Halvorsen,  Michael A. Riegler</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：causing inconsistencies, tremendous task, task for biologists, biologists due, Manually analyzing spermatozoa</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Manually analyzing spermatozoa is a tremendous task for biologists due to the
many fast-moving spermatozoa, causing inconsistencies in the quality of the
assessments. Therefore, computer-assisted sperm analysis (CASA) has become a
popular solution. Despite this, more data is needed to train supervised machine
learning approaches in order to improve accuracy and reliability. In this
regard, we provide a dataset called VISEM-Tracking with 20 video recordings of
30s of spermatozoa with manually annotated bounding-box coordinates and a set
of sperm characteristics analyzed by experts in the domain. VISEM-Tracking is
an extension of the previously published VISEM dataset. In addition to the
annotated data, we provide unlabeled video clips for easy-to-use access and
analysis of the data. As part of this paper, we present baseline sperm
detection performances using the YOLOv5 deep learning model trained on the
VISEM-Tracking dataset. As a result, the dataset can be used to train complex
deep-learning models to analyze spermatozoa. The dataset is publicly available
at this https URL.</p>
  </details>
</details>
<details>
  <summary>50. <b>标题：Pretrained Diffusion Models for Unified Human Motion Synthesis</b></summary>
  <p><b>编号</b>：[153]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02837</p>
  <p><b>作者</b>：Jianxin Ma,  Shuai Bai,  Chang Zhou</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：virtual reality, Generative modeling, computer animation, modeling of human, broad applications</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Generative modeling of human motion has broad applications in computer
animation, virtual reality, and robotics. Conventional approaches develop
separate models for different motion synthesis tasks, and typically use a model
of a small size to avoid overfitting the scarce data available in each setting.
It remains an open question whether developing a single unified model is
feasible, which may 1) benefit the acquirement of novel skills by combining
skills learned from multiple tasks, and 2) help in increasing the model
capacity without overfitting by combining multiple data sources. Unification is
challenging because 1) it involves diverse control signals as well as targets
of varying granularity, and 2) motion datasets may use different skeletons and
default poses. In this paper, we present MoFusion, a framework for unified
motion synthesis. MoFusion employs a Transformer backbone to ease the inclusion
of diverse control signals via cross attention, and pretrains the backbone as a
diffusion model to support multi-granularity synthesis ranging from motion
completion of a body part to whole-body motion generation. It uses a learnable
adapter to accommodate the differences between the default skeletons used by
the pretraining and the fine-tuning data. Empirical results show that
pretraining is vital for scaling the model size without overfitting, and
demonstrate MoFusion's potential in various tasks, e.g., text-to-motion, motion
completion, and zero-shot mixing of multiple control signals. Project page:
\url{this https URL}.</p>
  </details>
</details>
<details>
  <summary>51. <b>标题：An advanced YOLOv3 method for small object detection</b></summary>
  <p><b>编号</b>：[161]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02809</p>
  <p><b>作者</b>：Baokai Liu,  Fengjie He,  Shiqiang Du,  Jiacheng Li,  Wenjie Liu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：small objects, large performance improvement, small, objects, small object detection</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In recent years, object detection has achieved a very large performance
improvement, but the detection result of small objects is still not very
satisfactory. This work proposes a strategy based on feature fusion and dilated
convolution that employs dilated convolution to broaden the receptive field of
feature maps at various scales in order to address this issue. On the one hand,
it can improve the detection accuracy of larger objects. On the other hand, it
provides more contextual information for small objects, which is beneficial to
improving the detection accuracy of small objects. The shallow semantic
information of small objects is obtained by filtering out the noise in the
feature map, and the feature information of more small objects is preserved by
using multi-scale fusion feature module and attention mechanism. The fusion of
these shallow feature information and deep semantic information can generate
richer feature maps for small object detection. Experiments show that this
method can have higher accuracy than the traditional YOLOv3 network in the
detection of small objects and occluded objects. In addition, we achieve 32.8\%
Mean Average Precision on the detection of small objects on MS COCO2017 test
set. For 640*640 input, this method has 88.76\% mAP on the PASCAL VOC2012
dataset.</p>
  </details>
</details>
<details>
  <summary>52. <b>标题：MUS-CDB: Mixed Uncertainty Sampling with Class Distribution Balancing  for Active Annotation in Aerial Object Detection</b></summary>
  <p><b>编号</b>：[162]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02804</p>
  <p><b>作者</b>：Dong Liang,  Jing-Wei Zhang,  Ying-Peng Tang,  Sheng-Jun Hang</p>
  <p><b>备注</b>：13 pages, 7 figures</p>
  <p><b>关键词</b>：requires unaffordable manual, unaffordable manual labeling, aerial object detection, manual labeling costs, large aerial scenes</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent aerial object detection models rely on a large amount of labeled
training data, which requires unaffordable manual labeling costs in large
aerial scenes with dense objects. Active learning is effective in reducing the
data labeling cost by selectively querying the informative and representative
unlabelled samples. However, existing active learning methods are mainly with
class-balanced setting and image-based querying for generic object detection
tasks, which are less applicable to aerial object detection scenario due to the
long-tailed class distribution and dense small objects in aerial scenes. In
this paper, we propose a novel active learning method for cost-effective aerial
object detection. Specifically, both object-level and image-level
informativeness are considered in the object selection to refrain from
redundant and myopic querying. Besides, an easy-to-use class-balancing
criterion is incorporated to favor the minority objects to alleviate the
long-tailed class distribution problem in model training. To fully utilize the
queried information, we further devise a training loss to mine the latent
knowledge in the undiscovered image regions. Extensive experiments are
conducted on the DOTA-v1.0 and DOTA-v2.0 benchmarks to validate the
effectiveness of the proposed method. The results show that it can save more
than 75% of the labeling cost to reach the same performance compared to the
baselines and state-of-the-art active object detection methods. Code is
available at this https URL</p>
  </details>
</details>
<details>
  <summary>53. <b>标题：Diffusion Video Autoencoders: Toward Temporally Consistent Face Video  Editing via Disentangled Video Encoding</b></summary>
  <p><b>编号</b>：[163]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02802</p>
  <p><b>作者</b>：Gyeongman Kim,  Hajin Shim,  Hyunsu Kim,  Yunjey Choi,  Junho Kim,  Eunho Yang</p>
  <p><b>备注</b>：The code will be available soon</p>
  <p><b>关键词</b>：face video editing, recent face image, video editing task, face image editing, image editing methods</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Inspired by the impressive performance of recent face image editing methods,
several studies have been naturally proposed to extend these methods to the
face video editing task. One of the main challenges here is temporal
consistency among edited frames, which is still unresolved. To this end, we
propose a novel face video editing framework based on diffusion autoencoders
that can successfully extract the decomposed features - for the first time as a
face video editing model - of identity and motion from a given video. This
modeling allows us to edit the video by simply manipulating the temporally
invariant feature to the desired direction for the consistency. Another unique
strength of our model is that, since our model is based on diffusion models, it
can satisfy both reconstruction and edit capabilities at the same time, and is
robust to corner cases in wild face videos (e.g. occluded faces) unlike the
existing GAN-based methods.</p>
  </details>
</details>
<details>
  <summary>54. <b>标题：Dist-PU: Positive-Unlabeled Learning from a Label Distribution  Perspective</b></summary>
  <p><b>编号</b>：[164]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02801</p>
  <p><b>作者</b>：Yunrui Zhao,  Qianqian Xu,  Yangbangyan Jiang,  Peisong Wen,  Qingming Huang</p>
  <p><b>备注</b>：Accepted at CVPR 2022</p>
  <p><b>关键词</b>：learn binary classifiers, label distribution, label distribution consistency, learn binary, labeled positive</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Positive-Unlabeled (PU) learning tries to learn binary classifiers from a few
labeled positive examples with many unlabeled ones. Compared with ordinary
semi-supervised learning, this task is much more challenging due to the absence
of any known negative labels. While existing cost-sensitive-based methods have
achieved state-of-the-art performances, they explicitly minimize the risk of
classifying unlabeled data as negative samples, which might result in a
negative-prediction preference of the classifier. To alleviate this issue, we
resort to a label distribution perspective for PU learning in this paper.
Noticing that the label distribution of unlabeled data is fixed when the class
prior is known, it can be naturally used as learning supervision for the model.
Motivated by this, we propose to pursue the label distribution consistency
between predicted and ground-truth label distributions, which is formulated by
aligning their expectations. Moreover, we further adopt the entropy
minimization and Mixup regularization to avoid the trivial solution of the
label distribution consistency on unlabeled data and mitigate the consequent
confirmation bias. Experiments on three benchmark datasets validate the
effectiveness of the proposed method.Code available at:
this https URL.</p>
  </details>
</details>
<details>
  <summary>55. <b>标题：FlowFace: Semantic Flow-guided Shape-aware Face Swapping</b></summary>
  <p><b>编号</b>：[166]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02797</p>
  <p><b>作者</b>：Hao Zeng,  Wei Zhang,  Changjie Fan,  Tangjie Lv,  Suzhen Wang,  Zhimeng Zhang,  Bowen Ma,  Lincheng Li,  Yu Ding,  Xin Yu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：flow-guided two-stage framework, face, face swapping, shape-aware face swapping, face swapping network</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this work, we propose a semantic flow-guided two-stage framework for
shape-aware face swapping, namely FlowFace. Unlike most previous methods that
focus on transferring the source inner facial features but neglect facial
contours, our FlowFace can transfer both of them to a target face, thus leading
to more realistic face swapping. Concretely, our FlowFace consists of a face
reshaping network and a face swapping network. The face reshaping network
addresses the shape outline differences between the source and target faces. It
first estimates a semantic flow (i.e., face shape differences) between the
source and the target face, and then explicitly warps the target face shape
with the estimated semantic flow. After reshaping, the face swapping network
generates inner facial features that exhibit the identity of the source face.
We employ a pre-trained face masked autoencoder (MAE) to extract facial
features from both the source face and the target face. In contrast to previous
methods that use identity embedding to preserve identity information, the
features extracted by our encoder can better capture facial appearances and
identity information. Then, we develop a cross-attention fusion module to
adaptively fuse inner facial features from the source face with the target
facial attributes, thus leading to better identity preservation. Extensive
quantitative and qualitative experiments on in-the-wild faces demonstrate that
our FlowFace outperforms the state-of-the-art significantly.</p>
  </details>
</details>
<details>
  <summary>56. <b>标题：DiffuPose: Monocular 3D Human Pose Estimation via Denoising Diffusion  Probabilistic Model</b></summary>
  <p><b>编号</b>：[167]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02796</p>
  <p><b>作者</b>：Jeongjun Choi,  Dongseok Shim,  H. Jin Kim</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：achieved remarkable improvements, uplifting approaches, approaches have achieved, achieved remarkable, HPE</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Thanks to the development of 2D keypoint detectors, monocular 3D human pose
estimation (HPE) via 2D-to-3D uplifting approaches have achieved remarkable
improvements. Still, monocular 3D HPE is a challenging problem due to the
inherent depth ambiguities and occlusions. To handle this problem, many
previous works exploit temporal information to mitigate such difficulties.
However, there are many real-world applications where frame sequences are not
accessible. This paper focuses on reconstructing a 3D pose from a single 2D
keypoint detection. Rather than exploiting temporal information, we alleviate
the depth ambiguity by generating multiple 3D pose candidates which can be
mapped to an identical 2D keypoint. We build a novel diffusion-based framework
to effectively sample diverse 3D poses from an off-the-shelf 2D detector. By
considering the correlation between human joints by replacing the conventional
denoising U-Net with graph convolutional network, our approach accomplishes
further performance improvements. We evaluate our method on the widely adopted
Human3.6M and HumanEva-I datasets. Comprehensive experiments are conducted to
prove the efficacy of the proposed method, and they confirm that our model
outperforms state-of-the-art multi-hypothesis 3D HPE methods.</p>
  </details>
</details>
<details>
  <summary>57. <b>标题：Hybrid Model using Feature Extraction and Non-linear SVM for Brain Tumor  Classification</b></summary>
  <p><b>编号</b>：[169]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02794</p>
  <p><b>作者</b>：Lalita Mishra,  Shekhar Verma,  Shirshu Varma</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：magnetic resonance imaging, rbf kernel, resonance imaging, magnetic resonance, timely treatment</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>It is essential to classify brain tumors from magnetic resonance imaging
(MRI) accurately for better and timely treatment of the patients. In this
paper, we propose a hybrid model, using VGG along with Nonlinear-SVM (Soft and
Hard) to classify the brain tumors: glioma and pituitary and tumorous and
non-tumorous. The VGG-SVM model is trained for two different datasets of two
classes; thus, we perform binary classification. The VGG models are trained via
the PyTorch python library to obtain the highest testing accuracy of tumor
classification. The method is threefold, in the first step, we normalize and
resize the images, and the second step consists of feature extraction through
variants of the VGG model. The third step classified brain tumors using
non-linear SVM (soft and hard). We have obtained 98.18% accuracy for the first
dataset and 99.78% for the second dataset using VGG19. The classification
accuracies for non-linear SVM are 95.50% and 97.98% with linear and rbf kernel
and 97.95% for soft SVM with RBF kernel with D1, and 96.75% and 98.60% with
linear and RBF kernel and 98.38% for soft SVM with RBF kernel with D2. Results
indicate that the hybrid VGG-SVM model, especially VGG 19 with SVM, is able to
outperform existing techniques and achieve high accuracy.</p>
  </details>
</details>
<details>
  <summary>58. <b>标题：Event-based Monocular Dense Depth Estimation with Recurrent Transformers</b></summary>
  <p><b>编号</b>：[170]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02791</p>
  <p><b>作者</b>：Xu Liu,  Jianing Li,  Xiaopeng Fan,  Yonghong Tian</p>
  <p><b>备注</b>：10 pages, 5 figures</p>
  <p><b>关键词</b>：high dynamic ranges, address common challenges, offering high temporal, high temporal resolutions, monocular depth estimation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Event cameras, offering high temporal resolutions and high dynamic ranges,
have brought a new perspective to address common challenges (e.g., motion blur
and low light) in monocular depth estimation. However, how to effectively
exploit the sparse spatial information and rich temporal cues from asynchronous
events remains a challenging endeavor. To this end, we propose a novel
event-based monocular depth estimator with recurrent transformers, namely
EReFormer, which is the first pure transformer with a recursive mechanism to
process continuous event streams. Technically, for spatial modeling, a novel
transformer-based encoder-decoder with a spatial transformer fusion module is
presented, having better global context information modeling capabilities than
CNN-based methods. For temporal modeling, we design a gate recurrent vision
transformer unit that introduces a recursive mechanism into transformers,
improving temporal modeling capabilities while alleviating the expensive GPU
memory cost. The experimental results show that our EReFormer outperforms
state-of-the-art methods by a margin on both synthetic and real-world datasets.
We hope that our work will attract further research to develop stunning
transformers in the event-based vision community. Our open-source code can be
found in the supplemental material.</p>
  </details>
</details>
<details>
  <summary>59. <b>标题：Union-set Multi-source Model Adaptation for Semantic Segmentation</b></summary>
  <p><b>编号</b>：[172]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02785</p>
  <p><b>作者</b>：Zongyao Li,  Ren Togo,  Takahiro Ogawa,  Miki haseyama</p>
  <p><b>备注</b>：Accepted by ECCV2022</p>
  <p><b>关键词</b>：multi-source model adaptation, model adaptation, domain adaptation problem, semantic segmentation, source domain</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper solves a generalized version of the problem of multi-source model
adaptation for semantic segmentation. Model adaptation is proposed as a new
domain adaptation problem which requires access to a pre-trained model instead
of data for the source domain. A general multi-source setting of model
adaptation assumes strictly that each source domain shares a common label space
with the target domain. As a relaxation, we allow the label space of each
source domain to be a subset of that of the target domain and require the union
of the source-domain label spaces to be equal to the target-domain label space.
For the new setting named union-set multi-source model adaptation, we propose a
method with a novel learning strategy named model-invariant feature learning,
which takes full advantage of the diverse characteristics of the source-domain
models, thereby improving the generalization in the target domain. We conduct
extensive experiments in various adaptation settings to show the superiority of
our method. The code is available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>60. <b>标题：Adaptive Testing of Computer Vision Models</b></summary>
  <p><b>编号</b>：[176]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02774</p>
  <p><b>作者</b>：Irena Gao,  Gabriel Ilharco,  Scott Lundberg,  Marco Tulio Ribeiro</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：common semantic characteristics, share common semantic, semantic characteristics, unusual scenes, fail systematically</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Vision models often fail systematically on groups of data that share common
semantic characteristics (e.g., rare objects or unusual scenes), but
identifying these failure modes is a challenge. We introduce AdaVision, an
interactive process for testing vision models which helps users identify and
fix coherent failure modes. Given a natural language description of a coherent
group, AdaVision retrieves relevant images from LAION-5B with CLIP. The user
then labels a small amount of data for model correctness, which is used in
successive retrieval rounds to hill-climb towards high-error regions, refining
the group definition. Once a group is saturated, AdaVision uses GPT-3 to
suggest new group descriptions for the user to explore. We demonstrate the
usefulness and generality of AdaVision in user studies, where users find major
bugs in state-of-the-art classification, object detection, and image captioning
models. These user-discovered groups have failure rates 2-3x higher than those
surfaced by automatic error clustering methods. Finally, finetuning on examples
found with AdaVision fixes the discovered bugs when evaluated on unseen
examples, without degrading in-distribution accuracy, and while also improving
performance on out-of-distribution datasets.</p>
  </details>
</details>
<details>
  <summary>61. <b>标题：DiffusionInst: Diffusion Model for Instance Segmentation</b></summary>
  <p><b>编号</b>：[177]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02773</p>
  <p><b>作者</b>：Zhangxuan Gu,  Haoxing Chen,  Zhuoer Xu,  Jun Lan,  Changhua Meng,  Weiqiang Wang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：image generation models, image generation, achieved comparable performance, achieved comparable, Recently</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recently, diffusion frameworks have achieved comparable performance with
previous state-of-the-art image generation models. Researchers are curious
about its variants in discriminative tasks because of its powerful
noise-to-image denoising pipeline. This paper proposes DiffusionInst, a novel
framework that represents instances as instance-aware filters and formulates
instance segmentation as a noise-to-filter denoising process. The model is
trained to reverse the noisy groundtruth without any inductive bias from RPN.
During inference, it takes a randomly generated filter as input and outputs
mask in one-step or multi-step denoising. Extensive experimental results on
COCO and LVIS show that DiffusionInst achieves competitive performance compared
to existing instance segmentation models. We hope our work could serve as a
simple yet effective baseline, which could inspire designing more efficient
diffusion frameworks for challenging discriminative tasks. Our code is
available in this https URL.</p>
  </details>
</details>
<details>
  <summary>62. <b>标题：CSQ: Growing Mixed-Precision Quantization Scheme with Bi-level  Continuous Sparsification</b></summary>
  <p><b>编号</b>：[179]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02770</p>
  <p><b>作者</b>：Lirui Xiao,  Huanrui Yang,  Zhen Dong,  Kurt Keutzer,  Li Du,  Shanghang Zhang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：deep neural networks, neural networks, widely applied, applied on deep, deep neural</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Mixed-precision quantization has been widely applied on deep neural networks
(DNNs) as it leads to significantly better efficiency-accuracy tradeoffs
compared to uniform quantization. Meanwhile, determining the exact precision of
each layer remains challenging. Previous attempts on bit-level regularization
and pruning-based dynamic precision adjustment during training suffer from
noisy gradients and unstable convergence. In this work, we propose Continuous
Sparsification Quantization (CSQ), a bit-level training method to search for
mixed-precision quantization schemes with improved stability. CSQ stabilizes
the bit-level mixed-precision training process with a bi-level gradual
continuous sparsification on both the bit values of the quantized weights and
the bit selection in determining the quantization precision of each layer. The
continuous sparsification scheme enables fully-differentiable training without
gradient approximation while achieving an exact quantized model in the end.A
budget-aware regularization of total model size enables the dynamic growth and
pruning of each layer's precision towards a mixed-precision quantization scheme
of the desired size. Extensive experiments show CSQ achieves better
efficiency-accuracy tradeoff than previous methods on multiple models and
datasets.</p>
  </details>
</details>
<details>
  <summary>63. <b>标题：Ref-NPR: Reference-Based Non-Photorealistic Radiance Fields</b></summary>
  <p><b>编号</b>：[180]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02766</p>
  <p><b>作者</b>：Yuechen Zhang,  Zexin He,  Jinbo Xing,  Xufeng Yao,  Jiaya Jia</p>
  <p><b>备注</b>：15 pages, 16 figures, Project page: this https URL</p>
  <p><b>关键词</b>：establishing meaningful semantic, Radiance Fields, employ an arbitrary, transfer textures, textures and colors</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Existing 3D scene stylization methods employ an arbitrary style reference to
transfer textures and colors as styles without establishing meaningful semantic
correspondences. We present Reference-Based Non-Photorealistic Radiance Fields,
i.e., Ref-NPR. It is a controllable scene stylization method utilizing radiance
fields to stylize a 3D scene, with a single stylized 2D view taken as
reference. To achieve decent results, we propose a ray registration process
based on the stylized reference view to obtain pseudo-ray supervision in novel
views, and exploit the semantic correspondence in content images to fill
occluded regions with perceptually similar styles. Combining these operations,
Ref-NPR generates non-photorealistic and continuous novel view sequences with a
single reference while obtaining reasonable stylization in occluded regions.
Experiments show that Ref-NPR significantly outperforms other scene and video
stylization methods in terms of both visual quality and semantic
correspondence. Code and data will be made publicly available.</p>
  </details>
</details>
<details>
  <summary>64. <b>标题：Pixel2ISDF: Implicit Signed Distance Fields based Human Body Model from  Multi-view and Multi-pose Images</b></summary>
  <p><b>编号</b>：[181]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02765</p>
  <p><b>作者</b>：Jianchuan Chen,  Wentao Yi,  Tiantian Wang,  Xing Li,  Liqian Ma,  Yangyu Fan,  Huchuan Lu</p>
  <p><b>备注</b>：8 pages, 3 figures, published to ECCV2022 WCPA Workshop</p>
  <p><b>关键词</b>：canonical space, SMPLX mesh, canonical, posed mesh, mesh</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this report, we focus on reconstructing clothed humans in the canonical
space given multiple views and poses of a human as the input. To achieve this,
we utilize the geometric prior of the SMPLX model in the canonical space to
learn the implicit representation for geometry reconstruction. Based on the
observation that the topology between the posed mesh and the mesh in the
canonical space are consistent, we propose to learn latent codes on the posed
mesh by leveraging multiple input images and then assign the latent codes to
the mesh in the canonical space. Specifically, we first leverage normal and
geometry networks to extract the feature vector for each vertex on the SMPLX
mesh. Normal maps are adopted for better generalization to unseen images
compared to 2D images. Then, features for each vertex on the posed mesh from
multiple images are integrated by MLPs. The integrated features acting as the
latent code are anchored to the SMPLX mesh in the canonical space. Finally,
latent code for each 3D point is extracted and utilized to calculate the SDF.
Our work for reconstructing the human shape on canonical pose achieves 3rd
performance on WCPA MVP-Human Body Challenge.</p>
  </details>
</details>
<details>
  <summary>65. <b>标题：Semi-supervised Deep Large-baseline Homography Estimation with  Progressive Equivalence Constraint</b></summary>
  <p><b>编号</b>：[182]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02763</p>
  <p><b>作者</b>：Hai Jiang,  Haipeng Li,  Yuhang Lu,  Songchen Han,  Shuaicheng Liu</p>
  <p><b>备注</b>：Accepted by AAAI2023</p>
  <p><b>关键词</b>：limited receptive field, low image overlay, receptive field, low image, image overlay</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Homography estimation is erroneous in the case of large-baseline due to the
low image overlay and limited receptive field. To address it, we propose a
progressive estimation strategy by converting large-baseline homography into
multiple intermediate ones, cumulatively multiplying these intermediate items
can reconstruct the initial homography. Meanwhile, a semi-supervised homography
identity loss, which consists of two components: a supervised objective and an
unsupervised objective, is introduced. The first supervised loss is acting to
optimize intermediate homographies, while the second unsupervised one helps to
estimate a large-baseline homography without photometric losses. To validate
our method, we propose a large-scale dataset that covers regular and
challenging scenes. Experiments show that our method achieves state-of-the-art
performance in large-baseline scenes while keeping competitive performance in
small-baseline scenes. Code and dataset are available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>66. <b>标题：Learning Neural Parametric Head Models</b></summary>
  <p><b>编号</b>：[184]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02761</p>
  <p><b>作者</b>：Simon Giebenhain,  Tobias Kirschstein,  Markos Georgopoulos,  Martin Rünz,  Lourdes Agapito,  Matthias Nießner</p>
  <p><b>备注</b>：Project Page: this https URL ; Project Video: this https URL</p>
  <p><b>关键词</b>：complete human heads, human heads based, hybrid neural fields, complete human, based on hybrid</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose a novel 3D morphable model for complete human heads based on
hybrid neural fields. At the core of our model lies a neural parametric
representation which disentangles identity and expressions in disjoint latent
spaces. To this end, we capture a person's identity in a canonical space as a
signed distance field (SDF), and model facial expressions with a neural
deformation field. In addition, our representation achieves high-fidelity local
detail by introducing an ensemble of local fields centered around facial anchor
points. To facilitate generalization, we train our model on a newly-captured
dataset of over 2200 head scans from 124 different identities using a custom
high-end 3D scanning setup. Our dataset significantly exceeds comparable
existing datasets, both with respect to quality and completeness of geometry,
averaging around 3.5M mesh faces per scan. Finally, we demonstrate that our
approach outperforms state-of-the-art methods by a significant margin in terms
of fitting error and reconstruction quality.</p>
  </details>
</details>
<details>
  <summary>67. <b>标题：Attention-Enhanced Cross-modal Localization Between 360 Images and Point  Clouds</b></summary>
  <p><b>编号</b>：[186]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02757</p>
  <p><b>作者</b>：Zhipeng Zhao,  Huai Yu,  Chenwei Lyv,  Wen Yang,  Sebastian Scherer</p>
  <p><b>备注</b>：This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible</p>
  <p><b>关键词</b>：GNSS is unreliable, accuracy of GNSS, Visual localization plays, autonomous driving, plays an important</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Visual localization plays an important role for intelligent robots and
autonomous driving, especially when the accuracy of GNSS is unreliable.
Recently, camera localization in LiDAR maps has attracted more and more
attention for its low cost and potential robustness to illumination and weather
changes. However, the commonly used pinhole camera has a narrow Field-of-View,
thus leading to limited information compared with the omni-directional LiDAR
data. To overcome this limitation, we focus on correlating the information of
360 equirectangular images to point clouds, proposing an end-to-end learnable
network to conduct cross-modal visual localization by establishing similarity
in high-dimensional feature space. Inspired by the attention mechanism, we
optimize the network to capture the salient feature for comparing images and
point clouds. We construct several sequences containing 360 equirectangular
images and corresponding point clouds based on the KITTI-360 dataset and
conduct extensive experiments. The results demonstrate the effectiveness of our
approach.</p>
  </details>
</details>
<details>
  <summary>68. <b>标题：Objects as Spatio-Temporal 2.5D points</b></summary>
  <p><b>编号</b>：[187]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02755</p>
  <p><b>作者</b>：Paridhi Singh,  Gaurav Singh,  Arun Kumar</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：scenario extraction etc., Determining accurate bird, bird eye view, accurate bird eye, perception tasks including</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Determining accurate bird's eye view (BEV) positions of objects and tracks in
a scene is vital for various perception tasks including object interactions
mapping, scenario extraction etc., however, the level of supervision required
to accomplish that is extremely challenging to procure. We propose a
light-weight, weakly supervised method to estimate 3D position of objects by
jointly learning to regress the 2D object detections and scene's depth
prediction in a single feed-forward pass of a network. Our proposed method
extends a center-point based single-shot object detector
\cite{zhou2019objects}, and introduces a novel object representation where each
object is modeled as a BEV point spatio-temporally, without the need of any 3D
or BEV annotations for training and LiDAR data at query time. The approach
leverages readily available 2D object supervision along with LiDAR point clouds
(used only during training) to jointly train a single network, that learns to
predict 2D object detection alongside the whole scene's depth, to
spatio-temporally model object tracks as points in BEV. The proposed method is
computationally over $\sim$10x efficient compared to recent SOTA approaches [1,
38] while achieving comparable accuracies on KITTI tracking benchmark.</p>
  </details>
</details>
<details>
  <summary>69. <b>标题：A Hyperspectral and RGB Dataset for Building Facade Segmentation</b></summary>
  <p><b>编号</b>：[193]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02749</p>
  <p><b>作者</b>：Nariman Habili,  Ernest Kwan,  Weihao Li,  Christfried Webers,  Jeremy Oorloff,  Mohammad Ali Armin,  Lars Petersson</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：detailed spectral information, real-world applications, Hyperspectral Imaging, detailed spectral, spectral information</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Hyperspectral Imaging (HSI) provides detailed spectral information and has
been utilised in many real-world applications. This work introduces an HSI
dataset of building facades in a light industry environment with the aim of
classifying different building materials in a scene. The dataset is called the
Light Industrial Building HSI (LIB-HSI) dataset. This dataset consists of nine
categories and 44 classes. In this study, we investigated deep learning based
semantic segmentation algorithms on RGB and hyperspectral images to classify
various building materials, such as timber, brick and concrete.</p>
  </details>
</details>
<details>
  <summary>70. <b>标题：Semi-Supervised Object Detection with Object-wise Contrastive Learning  and Regression Uncertainty</b></summary>
  <p><b>编号</b>：[194]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02747</p>
  <p><b>作者</b>：Honggyu Choi,  Zhixiang Chen,  Xuepeng Shi,  Tae-Kyun Kim</p>
  <p><b>备注</b>：Accepted to BMVC 2022</p>
  <p><b>关键词</b>：leveraging extra unlabeled, extra unlabeled data, unlabeled data, aims to boost, leveraging extra</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Semi-supervised object detection (SSOD) aims to boost detection performance
by leveraging extra unlabeled data. The teacher-student framework has been
shown to be promising for SSOD, in which a teacher network generates
pseudo-labels for unlabeled data to assist the training of a student network.
Since the pseudo-labels are noisy, filtering the pseudo-labels is crucial to
exploit the potential of such framework. Unlike existing suboptimal methods, we
propose a two-step pseudo-label filtering for the classification and regression
heads in a teacher-student framework. For the classification head, OCL
(Object-wise Contrastive Learning) regularizes the object representation
learning that utilizes unlabeled data to improve pseudo-label filtering by
enhancing the discriminativeness of the classification score. This is designed
to pull together objects in the same class and push away objects from different
classes. For the regression head, we further propose RUPL
(Regression-Uncertainty-guided Pseudo-Labeling) to learn the aleatoric
uncertainty of object localization for label filtering. By jointly filtering
the pseudo-labels for the classification and regression heads, the student
network receives better guidance from the teacher network for object detection
task. Experimental results on Pascal VOC and MS-COCO datasets demonstrate the
superiority of our proposed method with competitive performance compared to
existing methods.</p>
  </details>
</details>
<details>
  <summary>71. <b>标题：Semantic-aware Message Broadcasting for Efficient Unsupervised Domain  Adaptation</b></summary>
  <p><b>编号</b>：[200]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02739</p>
  <p><b>作者</b>：Xin Li,  Cuiling Lan,  Guoqiang Wei,  Zhibo Chen</p>
  <p><b>备注</b>：13 pages, 5 figures</p>
  <p><b>关键词</b>：demonstrated great potential, abundant vision tasks, demonstrated great, great potential, potential in abundant</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Vision transformer has demonstrated great potential in abundant vision tasks.
However, it also inevitably suffers from poor generalization capability when
the distribution shift occurs in testing (i.e., out-of-distribution data). To
mitigate this issue, we propose a novel method, Semantic-aware Message
Broadcasting (SAMB), which enables more informative and flexible feature
alignment for unsupervised domain adaptation (UDA). Particularly, we study the
attention module in the vision transformer and notice that the alignment space
using one global class token lacks enough flexibility, where it interacts
information with all image tokens in the same manner but ignores the rich
semantics of different regions. In this paper, we aim to improve the richness
of the alignment features by enabling semantic-aware adaptive message
broadcasting. Particularly, we introduce a group of learned group tokens as
nodes to aggregate the global information from all image tokens, but encourage
different group tokens to adaptively focus on the message broadcasting to
different semantic regions. In this way, our message broadcasting encourages
the group tokens to learn more informative and diverse information for
effective domain alignment. Moreover, we systematically study the effects of
adversarial-based feature alignment (ADA) and pseudo-label based self-training
(PST) on UDA. We find that one simple two-stage training strategy with the
cooperation of ADA and PST can further improve the adaptation capability of the
vision transformer. Extensive experiments on DomainNet, OfficeHome, and
VisDA-2017 demonstrate the effectiveness of our methods for UDA.</p>
  </details>
</details>
<details>
  <summary>72. <b>标题：Beyond Object Recognition: A New Benchmark towards Object Concept  Learning</b></summary>
  <p><b>编号</b>：[211]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02710</p>
  <p><b>作者</b>：Yong-Lu Li,  Yue Xu,  Xinyu Xu,  Xiaohan Mao,  Yuan Yao,  Siqi Liu,  Cewu Lu</p>
  <p><b>备注</b>：Preprint. Webpage: this https URL</p>
  <p><b>关键词</b>：central building block, object, Object Concept Learning, artificial intelligence, Object Concept</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Understanding objects is a central building block of artificial intelligence,
especially for embodied AI. Even though object recognition excels with deep
learning, current machines still struggle to learn higher-level knowledge,
e.g., what attributes an object has, and what can we do with an object. In this
work, we propose a challenging Object Concept Learning (OCL) task to push the
envelope of object understanding. It requires machines to reason out object
affordances and simultaneously give the reason: what attributes make an object
possesses these affordances. To support OCL, we build a densely annotated
knowledge base including extensive labels for three levels of object concept
(category, attribute, affordance), and the causal relations of three levels. By
analyzing the causal structure of OCL, we present a baseline, Object Concept
Reasoning Network (OCRN). It leverages causal intervention and concept
instantiation to infer the three levels following their causal relations. In
experiments, OCRN effectively infers the object knowledge while following the
causalities well. Our data and code are available at this https URL.</p>
  </details>
</details>
<details>
  <summary>73. <b>标题：Enabling and Accelerating Dynamic Vision Transformer Inference for  Real-Time Applications</b></summary>
  <p><b>编号</b>：[219]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02687</p>
  <p><b>作者</b>：Kavya Sreedhar,  Jason Clemons,  Rangharajan Venkatesan,  Stephen W. Keckler,  Mark Horowitz</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：deep learning models, computer vision tasks, deep learning, tasks are based, models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Many state-of-the-art deep learning models for computer vision tasks are
based on the transformer architecture. Such models can be computationally
expensive and are typically statically set to meet the deployment scenario.
However, in real-time applications, the resources available for every inference
can vary considerably and be smaller than what state-of-the-art models use. We
can use dynamic models to adapt the model execution to meet real-time
application resource constraints. While prior dynamic work has primarily
minimized resource utilization for less complex input images while maintaining
accuracy and focused on CNNs and early transformer models such as BERT, we
adapt vision transformers to meet system dynamic resource constraints,
independent of the input image. We find that unlike early transformer models,
recent state-of-the-art vision transformers heavily rely on convolution layers.
We show that pretrained models are fairly resilient to skipping computation in
the convolution and self-attention layers, enabling us to create a low-overhead
system for dynamic real-time inference without additional training. Finally, we
create a optimized accelerator for these dynamic vision transformers in a 5nm
technology. The PE array occupies 2.26mm$^2$ and is 17 times faster than a
NVIDIA TITAN V GPU for state-of-the-art transformer-based models for semantic
segmentation.</p>
  </details>
</details>
<details>
  <summary>74. <b>标题：Attend Who is Weak: Pruning-assisted Medical Image Localization under  Sophisticated and Implicit Imbalances</b></summary>
  <p><b>编号</b>：[223]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02675</p>
  <p><b>作者</b>：Ajay Jaiswal,  Tianlong Chen,  Justin F. Rousseau,  Yifan Peng,  Ying Ding,  Zhangyang Wang</p>
  <p><b>备注</b>：Accepted in WACV 2023</p>
  <p><b>关键词</b>：medical image understanding, choice for medical, image understanding tasks, medical image, image understanding</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep neural networks (DNNs) have rapidly become a \textit{de facto} choice
for medical image understanding tasks. However, DNNs are notoriously fragile to
the class imbalance in image classification. We further point out that such
imbalance fragility can be amplified when it comes to more sophisticated tasks
such as pathology localization, as imbalances in such problems can have highly
complex and often implicit forms of presence. For example, different pathology
can have different sizes or colors (w.r.t.the background), different underlying
demographic distributions, and in general different difficulty levels to
recognize, even in a meticulously curated balanced distribution of training
data. In this paper, we propose to use pruning to automatically and adaptively
identify \textit{hard-to-learn} (HTL) training samples, and improve pathology
localization by attending them explicitly, during training in
\textit{supervised, semi-supervised, and weakly-supervised} settings. Our main
inspiration is drawn from the recent finding that deep classification models
have difficult-to-memorize samples and those may be effectively exposed through
network pruning \cite{hooker2019compressed} - and we extend such observation
beyond classification for the first time. We also present an interesting
demographic analysis which illustrates HTLs ability to capture complex
demographic imbalances. Our extensive experiments on the Skin Lesion
Localization task in multiple training settings by paying additional attention
to HTLs show significant improvement of localization performance by
$\sim$2-3\%.</p>
  </details>
</details>
<details>
  <summary>75. <b>标题：Continual learning on deployment pipelines for Machine Learning Systems</b></summary>
  <p><b>编号</b>：[228]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02659</p>
  <p><b>作者</b>：Qiang Li,  Chongyu Zhang</p>
  <p><b>备注</b>：36th Conference on Neural Information Processing Systems (NeurIPS 2022). Accepted by blind review at DMML Workshop this https URL</p>
  <p><b>关键词</b>：large Original, development of digitization, growing number, number of large, machine learning systems</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Following the development of digitization, a growing number of large Original
Equipment Manufacturers (OEMs) are adapting computer vision or natural language
processing in a wide range of applications such as anomaly detection and
quality inspection in plants. Deployment of such a system is becoming an
extremely important topic. Our work starts with the least-automated deployment
technologies of machine learning systems includes several iterations of
updates, and ends with a comparison of automated deployment techniques. The
objective is, on the one hand, to compare the advantages and disadvantages of
various technologies in theory and practice, so as to facilitate later adopters
to avoid making the generalized mistakes when implementing actual use cases,
and thereby choose a better strategy for their own enterprises. On the other
hand, to raise awareness of the evaluation framework for the deployment of
machine learning systems, to have more comprehensive and useful evaluation
metrics (e.g. table 2), rather than only focusing on a single factor (e.g.
company cost). This is especially important for decision-makers in the
industry.</p>
  </details>
</details>
<details>
  <summary>76. <b>标题：Spuriosity Rankings: Sorting Data for Spurious Correlation Robustness</b></summary>
  <p><b>编号</b>：[231]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02648</p>
  <p><b>作者</b>：Mazda Moayeri,  Wenxiao Wang,  Sahil Singla,  Soheil Feizi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：spurious, spurious features, class based, spurious cues, spurious cues present</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present a framework for ranking images within their class based on the
strength of spurious cues present. By measuring the gap in accuracy on the
highest and lowest ranked images (we call this spurious gap), we assess
spurious feature reliance for $89$ diverse ImageNet models, finding that even
the best models underperform in images with weak spurious presence. However,
the effect of spurious cues varies far more dramatically across classes,
emphasizing the crucial, often overlooked, class-dependence of the spurious
correlation problem. While most spurious features we observe are clarifying
(i.e. improving test-time accuracy when present, as is typically expected), we
surprisingly find many cases of confusing spurious features, where models
perform better when they are absent. We then close the spurious gap by training
new classification heads on lowly ranked (i.e. without common spurious cues)
images, resulting in improved effective robustness to distribution shifts
(ObjectNet, ImageNet-R, ImageNet-Sketch). We also propose a second metric to
assess feature reliability, finding that spurious features are generally less
reliable than non-spurious (core) ones, though again, spurious features can be
more reliable for certain classes. To enable our analysis, we annotated $5,000$
feature-class dependencies over {\it all} of ImageNet as core or spurious using
minimal human supervision. Finally, we show the feature discovery and
spuriosity ranking framework can be extended to other datasets like CelebA and
WaterBirds in a lightweight fashion with only linear layer training, leading to
discovering a previously unknown racial bias in the Celeb-A hair
classification.</p>
  </details>
</details>
<details>
  <summary>77. <b>标题：Unifying Vision, Text, and Layout for Universal Document Processing</b></summary>
  <p><b>编号</b>：[238]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02623</p>
  <p><b>作者</b>：Zineng Tang,  Ziyi Yang,  Guoxin Wang,  Yuwei Fang,  Yang Liu,  Chenguang Zhu,  Michael Zeng,  Cha Zhang,  Mohit Bansal</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Universal Document Processing, propose Universal Document, propose Universal, Document Processing, varied task formats</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose Universal Document Processing (UDOP), a foundation Document AI
model which unifies text, image, and layout modalities together with varied
task formats, including document understanding and generation. UDOP leverages
the spatial correlation between textual content and document image to model
image, text, and layout modalities with one uniform representation. With a
novel Vision-Text-Layout Transformer, UDOP unifies pretraining and multi-domain
downstream tasks into a prompt-based sequence generation scheme. UDOP is
pretrained on both large-scale unlabeled document corpora using innovative
self-supervised objectives and diverse labeled data. UDOP also learns to
generate document images from text and layout modalities via masked image
reconstruction. To the best of our knowledge, this is the first time in the
field of document AI that one model simultaneously achieves high-quality neural
document editing and content customization. Our method sets the
state-of-the-art on 9 Document AI tasks, e.g., document understanding and QA,
across diverse data domains like finance reports, academic papers, and
websites. UDOP ranks first on the leaderboard of the Document Understanding
Benchmark (DUE).</p>
  </details>
</details>
<details>
  <summary>78. <b>标题：StyleGAN as a Utility-Preserving Face De-identification Method</b></summary>
  <p><b>编号</b>：[243]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02611</p>
  <p><b>作者</b>：Seyyed Mohammad Sadegh Moosavi Khorzooghi,  Shirin Nilizadeh</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：preserve users' privacy, face de-identification methods, face, faces, preserve users'</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Several face de-identification methods have been proposed to preserve users'
privacy by obscuring their faces. These methods, however, can degrade the
quality of photos, and they usually do not preserve the utility of faces, e.g.,
their age, gender, pose, and facial expression. Recently, advanced generative
adversarial network models, such as StyleGAN, have been proposed, which
generate realistic, high-quality imaginary faces. In this paper, we investigate
the use of StyleGAN in generating de-identified faces through style mixing,
where the styles or features of the target face and an auxiliary face get mixed
to generate a de-identified face that carries the utilities of the target face.
We examined this de-identification method with respect to preserving utility
and privacy, by implementing several face detection, verification, and
identification attacks. Through extensive experiments and also comparing with
two state-of-the-art face de-identification methods, we show that StyleGAN
preserves the quality and utility of the faces much better than the other
approaches and also by choosing the style mixing levels correctly, it can
preserve the privacy of the faces much better than other methods.</p>
  </details>
</details>
<details>
  <summary>79. <b>标题：Domain-general Crowd Counting in Unseen Scenarios</b></summary>
  <p><b>编号</b>：[254]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02573</p>
  <p><b>作者</b>：Zhipeng Du,  Jiankang Deng,  Miaojing Shi</p>
  <p><b>备注</b>：Accepted to AAAI 2023</p>
  <p><b>关键词</b>：data severely hinders, severely hinders crowd, crowd data severely, crowd counting, hinders crowd counting</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Domain shift across crowd data severely hinders crowd counting models to
generalize to unseen scenarios. Although domain adaptive crowd counting
approaches close this gap to a certain extent, they are still dependent on the
target domain data to adapt (e.g. finetune) their models to the specific
domain. In this paper, we aim to train a model based on a single source domain
which can generalize well on any unseen domain. This falls into the realm of
domain generalization that remains unexplored in crowd counting. We first
introduce a dynamic sub-domain division scheme which divides the source domain
into multiple sub-domains such that we can initiate a meta-learning framework
for domain generalization. The sub-domain division is dynamically refined
during the meta-learning. Next, in order to disentangle domain-invariant
information from domain-specific information in image features, we design the
domain-invariant and -specific crowd memory modules to re-encode image
features. Two types of losses, i.e. feature reconstruction and orthogonal
losses, are devised to enable this disentanglement. Extensive experiments on
several standard crowd counting benchmarks i.e. SHA, SHB, QNRF, and NWPU, show
the strong generalizability of our method.</p>
  </details>
</details>
<details>
  <summary>80. <b>标题：A Dataless FaceSwap Detection Approach Using Synthetic Images</b></summary>
  <p><b>编号</b>：[255]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02571</p>
  <p><b>作者</b>：Anubhav Jain,  Nasir Memon,  Julian Togelius</p>
  <p><b>备注</b>：IJCB 2022</p>
  <p><b>关键词</b>：Face swapping technology, create realistic facial, realistic facial manipulations, create realistic, Face swapping</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Face swapping technology used to create "Deepfakes" has advanced
significantly over the past few years and now enables us to create realistic
facial manipulations. Current deep learning algorithms to detect deepfakes have
shown promising results, however, they require large amounts of training data,
and as we show they are biased towards a particular ethnicity. We propose a
deepfake detection methodology that eliminates the need for any real data by
making use of synthetically generated data using StyleGAN3. This not only
performs at par with the traditional training methodology of using real data
but it shows better generalization capabilities when finetuned with a small
amount of real data. Furthermore, this also reduces biases created by facial
image datasets that might have sparse data from particular ethnicities.</p>
  </details>
</details>
<details>
  <summary>81. <b>标题：This changes to that : Combining causal and non-causal explanations to  generate disease progression in capsule endoscopy</b></summary>
  <p><b>编号</b>：[262]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02506</p>
  <p><b>作者</b>：Anuja Vats,  Ahmed Mohammed,  Marius Pedersen,  Nirmalie Wiratunga</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：deep learning networks, learning networks, processes of deep, deep learning, decision processes</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Due to the unequivocal need for understanding the decision processes of deep
learning networks, both modal-dependent and model-agnostic techniques have
become very popular. Although both of these ideas provide transparency for
automated decision making, most methodologies focus on either using the
modal-gradients (model-dependent) or ignoring the model internal states and
reasoning with a model's behavior/outcome (model-agnostic) to instances. In
this work, we propose a unified explanation approach that given an instance
combines both model-dependent and agnostic explanations to produce an
explanation set. The generated explanations are not only consistent in the
neighborhood of a sample but can highlight causal relationships between image
content and the outcome. We use Wireless Capsule Endoscopy (WCE) domain to
illustrate the effectiveness of our explanations. The saliency maps generated
by our approach are comparable or better on the softmax information score.</p>
  </details>
</details>
<details>
  <summary>82. <b>标题：Relation-based Motion Prediction using Traffic Scene Graphs</b></summary>
  <p><b>编号</b>：[263]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02503</p>
  <p><b>作者</b>：Maximilian Zipfl,  Felix Hertlein,  Achim Rettinger,  Steffen Thoma,  Lavdim Halilaj,  Juergen Luettin,  Stefan Schmid,  Cory Henson</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Representing relevant information, Representing relevant, traffic, understanding its environment, environment is crucial</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Representing relevant information of a traffic scene and understanding its
environment is crucial for the success of autonomous driving. Modeling the
surrounding of an autonomous car using semantic relations, i.e., how different
traffic participants relate in the context of traffic rule based behaviors, is
hardly been considered in previous work. This stems from the fact that these
relations are hard to extract from real-world traffic scenes. In this work, we
model traffic scenes in a form of spatial semantic scene graphs for various
different predictions about the traffic participants, e.g., acceleration and
deceleration. Our learning and inference approach uses Graph Neural Networks
(GNNs) and shows that incorporating explicit information about the spatial
semantic relations between traffic participants improves the predicdtion
results. Specifically, the acceleration prediction of traffic participants is
improved by up to 12% compared to the baselines, which do not exploit this
explicit information. Furthermore, by including additional information about
previous scenes, we achieve 73% improvements.</p>
  </details>
</details>
<details>
  <summary>83. <b>标题：Domain Adaptation and Generalization on Functional Medical Images: A  Systematic Survey</b></summary>
  <p><b>编号</b>：[267]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.03176</p>
  <p><b>作者</b>：Gita Sarafraz,  Armin Behnamnia,  Mehran Hosseinzadeh,  Ali Balapour,  Amin Meghrazi,  Hamid R. Rabiee</p>
  <p><b>备注</b>：41 pages, 8 figures</p>
  <p><b>关键词</b>：natural language processing, including natural language, Machine learning algorithms, medical data processing, language processing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Machine learning algorithms have revolutionized different fields, including
natural language processing, computer vision, signal processing, and medical
data processing. Despite the excellent capabilities of machine learning
algorithms in various tasks and areas, the performance of these models mainly
deteriorates when there is a shift in the test and training data distributions.
This gap occurs due to the violation of the fundamental assumption that the
training and test data are independent and identically distributed (i.i.d). In
real-world scenarios where collecting data from all possible domains for
training is costly and even impossible, the i.i.d assumption can hardly be
satisfied. The problem is even more severe in the case of medical images and
signals because it requires either expensive equipment or a meticulous
experimentation setup to collect data, even for a single domain. Additionally,
the decrease in performance may have severe consequences in the analysis of
medical records. As a result of such problems, the ability to generalize and
adapt under distribution shifts (domain generalization (DG) and domain
adaptation (DA)) is essential for the analysis of medical data. This paper
provides the first systematic review of DG and DA on functional brain signals
to fill the gap of the absence of a comprehensive study in this era. We provide
detailed explanations and categorizations of datasets, approaches, and
architectures used in DG and DA on functional brain images. We further address
the attention-worthy future tracks in this field.</p>
  </details>
</details>
<details>
  <summary>84. <b>标题：Semi-supervised Learning with Robust Loss in Brain Segmentation</b></summary>
  <p><b>编号</b>：[274]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.03082</p>
  <p><b>作者</b>：Hedong Zhang,  Anand A. Joshi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：brain MRI images, train deep learning, MRI images, deep learning model, method to train</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this work, we used a semi-supervised learning method to train deep
learning model that can segment the brain MRI images. The semi-supervised model
uses less labeled data, and the performance is competitive with the supervised
model with full labeled data. This framework could reduce the cost of labeling
MRI images. We also introduced robust loss to reduce the noise effects of
inaccurate labels generated in semi-supervised learning.</p>
  </details>
</details>
<details>
  <summary>85. <b>标题：Proximal methods for point source localisation</b></summary>
  <p><b>编号</b>：[278]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02991</p>
  <p><b>作者</b>：Tuomo Valkonen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Lasso-type problem, Point source localisation, generally modelled, Lasso-type, Point source</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Point source localisation is generally modelled as a Lasso-type problem on
measures. However, optimisation methods in non-Hilbert spaces, such as the
space of Radon measures, are much less developed than in Hilbert spaces. Most
numerical algorithms for point source localisation are based on the Frank-Wolfe
conditional gradient method, for which ad hoc convergence theory is developed.
We develop extensions of proximal-type methods to spaces of measures. This
includes forward-backward splitting, its inertial version, and primal-dual
proximal splitting. Their convergence proofs follow standard patterns. We
demonstrate their numerical efficacy.</p>
  </details>
</details>
<details>
  <summary>86. <b>标题：A new eye segmentation method based on improved U2Net in TCM eye  diagnosis</b></summary>
  <p><b>编号</b>：[279]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02989</p>
  <p><b>作者</b>：Peng Hong</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：fairly mature point, Data Enhancement Toolkit, Enhancement Toolkit based, Chinese medicine, mature point</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>For the diagnosis of Chinese medicine, tongue segmentation has reached a
fairly mature point, but it has little application in the eye diagnosis of
Chinese medicine.First, this time we propose Res-UNet based on the architecture
of the U2Net network, and use the Data Enhancement Toolkit based on small
datasets, Finally, the feature blocks after noise reduction are fused with the
high-level features.Finally, the number of network parameters and inference
time are used as evaluation indicators to evaluate the model. At the same time,
different eye data segmentation frames were compared using Miou, Precision,
Recall, F1-Score and FLOPS. To convince people, we cite the UBIVIS. V1 public
dataset this time, in which Miou reaches 97.8%, S-measure reaches 97.7%,
F1-Score reaches 99.09% and for 320*320 RGB input images, the total parameter
volume is 167.83 MB,Due to the excessive number of parameters, we experimented
with a small-scale U2Net combined with a Res module with a parameter volume of
4.63 MB, which is similar to U2Net in related indicators, which verifies the
effectiveness of our structure.which achieves the best segmentation effect in
all the comparison networks and lays a foundation for the application of
subsequent visual apparatus recognition symptoms.</p>
  </details>
</details>
<details>
  <summary>87. <b>标题：Automated Segmentation of Computed Tomography Images with Submanifold  Sparse Convolutional Networks</b></summary>
  <p><b>编号</b>：[284]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02854</p>
  <p><b>作者</b>：Saúl Alonso-Monsalve,  Leigh H. Whitehead,  Adam Aurisano,  Lorena Escudero Sanchez</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：image analysis relies, time-consuming task, analysis relies, accurate delineation, specialised and time-consuming</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Quantitative cancer image analysis relies on the accurate delineation of
tumours, a very specialised and time-consuming task. For this reason, methods
for automated segmentation of tumours in medical imaging have been extensively
developed in recent years, being Computed Tomography one of the most popular
imaging modalities explored. However, the large amount of 3D voxels in a
typical scan is prohibitive for the entire volume to be analysed at once in
conventional hardware. To overcome this issue, the processes of downsampling
and/or resampling are generally implemented when using traditional
convolutional neural networks in medical imaging. In this paper, we propose a
new methodology that introduces a process of sparsification of the input images
and submanifold sparse convolutional networks as an alternative to
downsampling. As a proof of concept, we applied this new methodology to
Computed Tomography images of renal cancer patients, obtaining performances of
segmentations of kidneys and tumours competitive with previous methods (~84.6%
Dice similarity coefficient), while achieving a significant improvement in
computation time (2-3 min per training epoch).</p>
  </details>
</details>
<details>
  <summary>88. <b>标题：A Trustworthy Framework for Medical Image Analysis with Deep Learning</b></summary>
  <p><b>编号</b>：[291]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02764</p>
  <p><b>作者</b>：Kai Ma,  Siyuan He,  Pengcheng Xi,  Ashkan Ebadi,  Stéphane Tremblay,  Alexander Wong</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：increasingly important role, medical imaging, data imbalance, Computer vision, computer-assisted diagnosis</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Computer vision and machine learning are playing an increasingly important
role in computer-assisted diagnosis; however, the application of deep learning
to medical imaging has challenges in data availability and data imbalance, and
it is especially important that models for medical imaging are built to be
trustworthy. Therefore, we propose TRUDLMIA, a trustworthy deep learning
framework for medical image analysis, which adopts a modular design, leverages
self-supervised pre-training, and utilizes a novel surrogate loss function.
Experimental evaluations indicate that models generated from the framework are
both trustworthy and high-performing. It is anticipated that the framework will
support researchers and clinicians in advancing the use of deep learning for
dealing with public health crises including COVID-19.</p>
  </details>
</details>
<details>
  <summary>89. <b>标题：QFT: Post-training quantization via fast joint finetuning of all degrees  of freedom</b></summary>
  <p><b>编号</b>：[298]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02634</p>
  <p><b>作者</b>：Alex Finkelstein,  Ella Fuchs,  Idan Tal,  Mark Grobman,  Niv Vosco,  Eldad Meller</p>
  <p><b>备注</b>：Presented at CADL2022 workshop at ECCV2022</p>
  <p><b>关键词</b>：neural net accuracy, net accuracy close, bringing quantized neural, quantized neural net, challenge of bringing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The post-training quantization (PTQ) challenge of bringing quantized neural
net accuracy close to original has drawn much attention driven by industry
demand. Many of the methods emphasize optimization of a specific
degree-of-freedom (DoF), such as quantization step size, preconditioning
factors, bias fixing, often chained to others in multi-step solutions. Here we
rethink quantized network parameterization in HW-aware fashion, towards a
unified analysis of all quantization DoF, permitting for the first time their
joint end-to-end finetuning. Our single-step simple and extendable method,
dubbed quantization-aware finetuning (QFT), achieves 4-bit weight quantization
results on-par with SoTA within PTQ constraints of speed and resource.</p>
  </details>
</details>
<h1>自然语言处理</h1>
<details>
  <summary>1. <b>标题：Switching to Discriminative Image Captioning by Relieving a Bottleneck  of Reinforcement Learning</b></summary>
  <p><b>编号</b>：[9]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.03230</p>
  <p><b>作者</b>：Ukyo Honda,  Taro Watanabe,  Yuji Matsumoto</p>
  <p><b>备注</b>：WACV 2023 (19 pages, 9 figures)</p>
  <p><b>关键词</b>：desirable feature, describe the characteristic, captions, characteristic details, Discriminativeness</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Discriminativeness is a desirable feature of image captions: captions should
describe the characteristic details of input images. However, recent
high-performing captioning models, which are trained with reinforcement
learning (RL), tend to generate overly generic captions despite their high
performance in various other criteria. First, we investigate the cause of the
unexpectedly low discriminativeness and show that RL has a deeply rooted side
effect of limiting the output words to high-frequency words. The limited
vocabulary is a severe bottleneck for discriminativeness as it is difficult for
a model to describe the details beyond its vocabulary. Then, based on this
identification of the bottleneck, we drastically recast discriminative image
captioning as a much simpler task of encouraging low-frequency word generation.
Hinted by long-tail classification and debiasing methods, we propose methods
that easily switch off-the-shelf RL models to discriminativeness-aware models
with only a single-epoch fine-tuning on the part of the parameters. Extensive
experiments demonstrate that our methods significantly enhance the
discriminativeness of off-the-shelf RL models and even outperform previous
discriminativeness-aware methods with much smaller computational costs.
Detailed analysis and human evaluation also verify that our methods boost the
discriminativeness without sacrificing the overall quality of captions.</p>
  </details>
</details>
<details>
  <summary>2. <b>标题：LawngNLI: A Long-Premise Benchmark for In-Domain Generalization from  Short to Long Contexts and for Implication-Based Retrieval</b></summary>
  <p><b>编号</b>：[12]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.03222</p>
  <p><b>作者</b>：William Bruno,  Dan Roth</p>
  <p><b>备注</b>：Findings of EMNLP 2022</p>
  <p><b>关键词</b>：Natural language inference, Natural language, sentence level, language inference, inference has trended</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Natural language inference has trended toward studying contexts beyond the
sentence level. An important application area is law: past cases often do not
foretell how they apply to new situations and implications must be inferred.
This paper introduces LawngNLI, constructed from U.S. legal opinions with
automatic labels with high human-validated accuracy. Premises are long and
multigranular. Experiments show two use cases. First, LawngNLI can benchmark
for in-domain generalization from short to long contexts. It has remained
unclear if large-scale long-premise NLI datasets actually need to be
constructed: near-top performance on long premises could be achievable by
fine-tuning using short premises. Without multigranularity, benchmarks cannot
distinguish lack of fine-tuning on long premises versus domain shift between
short and long datasets. In contrast, our long and short premises share the
same examples and domain. Models fine-tuned using several past NLI datasets
and/or our short premises fall short of top performance on our long premises.
So for at least certain domains (such as ours), large-scale long-premise
datasets are needed. Second, LawngNLI can benchmark for implication-based
retrieval. Queries are entailed or contradicted by target documents, allowing
users to move between arguments and evidence. Leading retrieval models perform
reasonably zero shot on a LawngNLI-derived retrieval task. We compare different
systems for re-ranking, including lexical overlap and cross-encoders fine-tuned
using a modified LawngNLI or past NLI datasets. LawngNLI can train and test
systems for implication-based case retrieval and argumentation.</p>
  </details>
</details>
<details>
  <summary>3. <b>标题：Neural Machine Translation with Contrastive Translation Memories</b></summary>
  <p><b>编号</b>：[42]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.03140</p>
  <p><b>作者</b>：Xin Cheng,  Shen Gao,  Lemao Liu,  Dongyan Zhao,  Rui Yan</p>
  <p><b>备注</b>：EMNLP2022 Main Conference</p>
  <p><b>关键词</b>：Retrieval-augmented Neural Machine, Neural Machine Translation, Neural Machine, Machine Translation models, Retrieval-augmented Neural</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Retrieval-augmented Neural Machine Translation models have been successful in
many translation scenarios. Different from previous works that make use of
mutually similar but redundant translation memories~(TMs), we propose a new
retrieval-augmented NMT to model contrastively retrieved translation memories
that are holistically similar to the source sentence while individually
contrastive to each other providing maximal information gains in three phases.
First, in TM retrieval phase, we adopt a contrastive retrieval algorithm to
avoid redundancy and uninformativeness of similar translation pieces. Second,
in memory encoding stage, given a set of TMs we propose a novel Hierarchical
Group Attention module to gather both local context of each TM and global
context of the whole TM set. Finally, in training phase, a Multi-TM contrastive
learning objective is introduced to learn salient feature of each TM with
respect to target sentence. Experimental results show that our framework
obtains improvements over strong baselines on the benchmark datasets.</p>
  </details>
</details>
<details>
  <summary>4. <b>标题：Semantic-Conditional Diffusion Networks for Image Captioning</b></summary>
  <p><b>编号</b>：[55]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.03099</p>
  <p><b>作者</b>：Jianjie Luo,  Yehao Li,  Yingwei Pan,  Ting Yao,  Jianlin Feng,  Hongyang Chao,  Tao Mei</p>
  <p><b>备注</b>：Source code is available at \url{this https URL}</p>
  <p><b>关键词</b>：powerful generative models, Recent advances, generation have witnessed, witnessed the rise, act as powerful</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent advances on text-to-image generation have witnessed the rise of
diffusion models which act as powerful generative models. Nevertheless, it is
not trivial to exploit such latent variable models to capture the dependency
among discrete words and meanwhile pursue complex visual-language alignment in
image captioning. In this paper, we break the deeply rooted conventions in
learning Transformer-based encoder-decoder, and propose a new diffusion model
based paradigm tailored for image captioning, namely Semantic-Conditional
Diffusion Networks (SCD-Net). Technically, for each input image, we first
search the semantically relevant sentences via cross-modal retrieval model to
convey the comprehensive semantic information. The rich semantics are further
regarded as semantic prior to trigger the learning of Diffusion Transformer,
which produces the output sentence in a diffusion process. In SCD-Net, multiple
Diffusion Transformer structures are stacked to progressively strengthen the
output sentence with better visional-language alignment and linguistical
coherence in a cascaded manner. Furthermore, to stabilize the diffusion
process, a new self-critical sequence training strategy is designed to guide
the learning of SCD-Net with the knowledge of a standard autoregressive
Transformer model. Extensive experiments on COCO dataset demonstrate the
promising potential of using diffusion models in the challenging image
captioning task. Source code is available at
\url{this https URL}.</p>
  </details>
</details>
<details>
  <summary>5. <b>标题：ZeroKBC: A Comprehensive Benchmark for Zero-Shot Knowledge Base  Completion</b></summary>
  <p><b>编号</b>：[59]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.03091</p>
  <p><b>作者</b>：Pei Chen,  Wenlin Yao,  Hongming Zhang,  Xiaoman Pan,  Dian Yu,  Dong Yu,  Jianshu Chen</p>
  <p><b>备注</b>：ICDMW 2022</p>
  <p><b>关键词</b>：zero-shot KBC settings, aims to predict, KBC, zero-shot KBC, Knowledge base completion</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Knowledge base completion (KBC) aims to predict the missing links in
knowledge graphs. Previous KBC tasks and approaches mainly focus on the setting
where all test entities and relations have appeared in the training set.
However, there has been limited research on the zero-shot KBC settings, where
we need to deal with unseen entities and relations that emerge in a constantly
growing knowledge base. In this work, we systematically examine different
possible scenarios of zero-shot KBC and develop a comprehensive benchmark,
ZeroKBC, that covers these scenarios with diverse types of knowledge sources.
Our systematic analysis reveals several missing yet important zero-shot KBC
settings. Experimental results show that canonical and state-of-the-art KBC
systems cannot achieve satisfactory performance on this challenging benchmark.
By analyzing the strength and weaknesses of these systems on solving ZeroKBC,
we further present several important observations and promising future
directions.</p>
  </details>
</details>
<details>
  <summary>6. <b>标题：Style transfer and classification in hebrew news items</b></summary>
  <p><b>编号</b>：[89]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.03019</p>
  <p><b>作者</b>：Nir Weingarten</p>
  <p><b>备注</b>：Published at ISCOL2022 as a poster. For generated Hebrew fake news articles, visit this https URL</p>
  <p><b>关键词</b>：Morphological rich language, Morphological rich, making its modeling, modeling harder, harder than simpler</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Hebrew is a Morphological rich language, making its modeling harder than
simpler language. Recent developments such as Transformers in general and Bert
in particular opened a path for Hebrew models that reach SOTA results, not
falling short from other non-MRL languages. We explore the cutting edge in this
field performing style transfer, text generation and classification over news
articles collected from online archives. Furthermore, the news portals that
feed our collective consciousness are an interesting corpus to study, as their
analysis and tracing might reveal insights about our society and discourse.</p>
  </details>
</details>
<details>
  <summary>7. <b>标题：Document-Level Abstractive Summarization</b></summary>
  <p><b>编号</b>：[91]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.03013</p>
  <p><b>作者</b>：Gonçalo Raposo,  Afonso Raposo,  Ana Sofia Carmo</p>
  <p><b>备注</b>：This paper was made for an assignment of the Deep Structured Learning 2021/2022 course at Instituto Superior T\'ecnico</p>
  <p><b>关键词</b>：preserving key information, text summarization produces, produces a concise, concise and fluent, preserving key</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The task of automatic text summarization produces a concise and fluent text
summary while preserving key information and overall meaning. Recent approaches
to document-level summarization have seen significant improvements in recent
years by using models based on the Transformer architecture. However, the
quadratic memory and time complexities with respect to the sequence length make
them very expensive to use, especially with long sequences, as required by
document-level summarization. Our work addresses the problem of document-level
summarization by studying how efficient Transformer techniques can be used to
improve the automatic summarization of very long texts. In particular, we will
use the arXiv dataset, consisting of several scientific papers and the
corresponding abstracts, as baselines for this work. Then, we propose a novel
retrieval-enhanced approach based on the architecture which reduces the cost of
generating a summary of the entire document by processing smaller chunks. The
results were below the baselines but suggest a more efficient memory a
consumption and truthfulness.</p>
  </details>
</details>
<details>
  <summary>8. <b>标题：SODA: A Natural Language Processing Package to Extract Social  Determinants of Health for Cancer Studies</b></summary>
  <p><b>编号</b>：[96]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.03000</p>
  <p><b>作者</b>：Zehao Yu,  Xi Yang,  Chong Dang,  Prakash Adekkanattu,  Braja Gopal Patra,  Yifan Peng,  Jyotishman Pathak,  Debbie L. Wilson,  Ching-Yuan Chang,  Wei-Hsuan Lo-Ciganic,  Thomas J. George,  William R. Hogan,  Yi Guo,  Jiang Bian,  Yonghui Wu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：extract social determinants, natural language processing, SOcial DeterminAnts, open-source natural language, NLP models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Objective: We aim to develop an open-source natural language processing (NLP)
package, SODA (i.e., SOcial DeterminAnts), with pre-trained transformer models
to extract social determinants of health (SDoH) for cancer patients, examine
the generalizability of SODA to a new disease domain (i.e., opioid use), and
evaluate the extraction rate of SDoH using cancer populations.
Methods: We identified SDoH categories and attributes and developed an SDoH
corpus using clinical notes from a general cancer cohort. We compared four
transformer-based NLP models to extract SDoH, examined the generalizability of
NLP models to a cohort of patients prescribed with opioids, and explored
customization strategies to improve performance. We applied the best NLP model
to extract 19 categories of SDoH from the breast (n=7,971), lung (n=11,804),
and colorectal cancer (n=6,240) cohorts.
Results and Conclusion: We developed a corpus of 629 cancer patients notes
with annotations of 13,193 SDoH concepts/attributes from 19 categories of SDoH.
The Bidirectional Encoder Representations from Transformers (BERT) model
achieved the best strict/lenient F1 scores of 0.9216 and 0.9441 for SDoH
concept extraction, 0.9617 and 0.9626 for linking attributes to SDoH concepts.
Fine-tuning the NLP models using new annotations from opioid use patients
improved the strict/lenient F1 scores from 0.8172/0.8502 to 0.8312/0.8679. The
extraction rates among 19 categories of SDoH varied greatly, where 10 SDoH
could be extracted from >70% of cancer patients, but 9 SDoH had a low
extraction rate (<70% of cancer patients). the soda package with pre-trained transformer models is publicly available at this https url.< p>
  </70%></p></details>
</details>
<details>
  <summary>9. <b>标题：Knowledge-Bridged Causal Interaction Network for Causal Emotion  Entailment</b></summary>
  <p><b>编号</b>：[99]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02995</p>
  <p><b>作者</b>：Weixiang Zhao,  Yanyan Zhao,  Zhuojun Li,  Bing Qin</p>
  <p><b>备注</b>：Accepted by AAAI 2023</p>
  <p><b>关键词</b>：Emotion Entailment aims, Causal Emotion Entailment, Entailment aims, Emotion Entailment, Causal Interaction Network</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Causal Emotion Entailment aims to identify causal utterances that are
responsible for the target utterance with a non-neutral emotion in
conversations. Previous works are limited in thorough understanding of the
conversational context and accurate reasoning of the emotion cause. To this
end, we propose Knowledge-Bridged Causal Interaction Network (KBCIN) with
commonsense knowledge (CSK) leveraged as three bridges. Specifically, we
construct a conversational graph for each conversation and leverage the
event-centered CSK as the semantics-level bridge (S-bridge) to capture the deep
inter-utterance dependencies in the conversational context via the CSK-Enhanced
Graph Attention module. Moreover, social-interaction CSK serves as
emotion-level bridge (E-bridge) and action-level bridge (A-bridge) to connect
candidate utterances with the target one, which provides explicit causal clues
for the Emotional Interaction module and Actional Interaction module to reason
the target emotion. Experimental results show that our model achieves better
performance over most baseline models. Our source code is publicly available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>10. <b>标题：CySecBERT: A Domain-Adapted Language Model for the Cybersecurity Domain</b></summary>
  <p><b>编号</b>：[105]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02974</p>
  <p><b>作者</b>：Markus Bayer,  Philipp Kuehn,  Ramin Shanehsaz,  Christian Reuter</p>
  <p><b>备注</b>：13 Pages, 7 tables, 1 figure</p>
  <p><b>关键词</b>：evolving fast, model, language models, cybersecurity, models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The field of cybersecurity is evolving fast. Experts need to be informed
about past, current and - in the best case - upcoming threats, because attacks
are becoming more advanced, targets bigger and systems more complex. As this
cannot be addressed manually, cybersecurity experts need to rely on machine
learning techniques. In the texutual domain, pre-trained language models like
BERT have shown to be helpful, by providing a good baseline for further
fine-tuning. However, due to the domain-knowledge and many technical terms in
cybersecurity general language models might miss the gist of textual
information, hence doing more harm than good. For this reason, we create a
high-quality dataset and present a language model specifically tailored to the
cybersecurity domain, which can serve as a basic building block for
cybersecurity systems that deal with natural language. The model is compared
with other models based on 15 different domain-dependent extrinsic and
intrinsic tasks as well as general tasks from the SuperGLUE benchmark. On the
one hand, the results of the intrinsic tasks show that our model improves the
internal representation space of words compared to the other models. On the
other hand, the extrinsic, domain-dependent tasks, consisting of sequence
tagging and classification, show that the model is best in specific application
scenarios, in contrast to the others. Furthermore, we show that our approach
against catastrophic forgetting works, as the model is able to retrieve the
previously trained domain-independent knowledge. The used dataset and trained
model are made publicly available</p>
  </details>
</details>
<details>
  <summary>11. <b>标题：Controlled Text Generation using T5 based Encoder-Decoder Soft Prompt  Tuning and Analysis of the Utility of Generated Text in AI</b></summary>
  <p><b>编号</b>：[124]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02924</p>
  <p><b>作者</b>：Damith Chamalke Senadeera,  Julia Ive</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：natural language processing, language processing due, Controlled text generation, promising applications, Controlled text</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Controlled text generation is a very important task in the arena of natural
language processing due to its promising applications. In order to achieve this
task we mainly introduce the novel soft prompt tuning method of using soft
prompts at both encoder and decoder levels together in a T5 model and
investigate the performance as the behaviour of an additional soft prompt
related to the decoder of a T5 model in controlled text generation remained
unexplored. Then we also investigate the feasibility of steering the output of
this extended soft prompted T5 model at decoder level and finally analyse the
utility of generated text to be used in AI related tasks such as training AI
models with an interpretability analysis of the classifier trained with
synthetic text, as there is a lack of proper analysis of methodologies in
generating properly labelled data to be utilized in AI tasks. Through the
performed in-depth intrinsic and extrinsic evaluations of this generation model
along with the artificially generated data, we found that this model produced
better results compared to the T5 model with a single soft prompt at encoder
level and the sentiment classifier trained using this artificially generated
data can produce comparable classification results to the results of a
classifier trained with real labelled data and also the classifier decision is
interpretable with respect to the input text content.</p>
  </details>
</details>
<details>
  <summary>12. <b>标题：Modern French Poetry Generation with RoBERTa and GPT-2</b></summary>
  <p><b>编号</b>：[128]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02911</p>
  <p><b>作者</b>：Mika Hämäläinen,  Khalid Alnajjar,  Thierry Poibeau</p>
  <p><b>备注</b>：ICCC 2022</p>
  <p><b>关键词</b>：modern poetry generation, pretrained neural models, model, neural model, poem generation task</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present a novel neural model for modern poetry generation in French. The
model consists of two pretrained neural models that are fine-tuned for the poem
generation task. The encoder of the model is a RoBERTa based one while the
decoder is based on GPT-2. This way the model can benefit from the superior
natural language understanding performance of RoBERTa and the good natural
language generation performance of GPT-2. Our evaluation shows that the model
can create French poetry successfully. On a 5 point scale, the lowest score of
3.57 was given by human judges to typicality and emotionality of the output
poetry while the best score of 3.79 was given to understandability.</p>
  </details>
</details>
<details>
  <summary>13. <b>标题：Towards human-compatible autonomous car: A study of non-verbal Turing  test in automated driving with affective transition modelling</b></summary>
  <p><b>编号</b>：[131]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02908</p>
  <p><b>作者</b>：Zhaoning Li,  Qiaoli Jiang,  Zhengming Wu,  Anqi Liu,  Haiyan Wu,  Miner Huang,  Kai Huang,  Yixuan Ku</p>
  <p><b>备注</b>：16 pages, 9 figures, 3 tables</p>
  <p><b>关键词</b>：Autonomous cars, hands-free route, Autonomous, current autonomous cars, human</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Autonomous cars are indispensable when humans go further down the hands-free
route. Although existing literature highlights that the acceptance of the
autonomous car will increase if it drives in a human-like manner, sparse
research offers the naturalistic experience from a passenger's seat perspective
to examine the human likeness of current autonomous cars. The present study
tested whether the AI driver could create a human-like ride experience for
passengers based on 69 participants' feedback in a real-road scenario. We
designed a ride experience-based version of the non-verbal Turing test for
automated driving. Participants rode in autonomous cars (driven by either human
or AI drivers) as a passenger and judged whether the driver was human or AI.
The AI driver failed to pass our test because passengers detected the AI driver
above chance. In contrast, when the human driver drove the car, the passengers'
judgement was around chance. We further investigated how human passengers
ascribe humanness in our test. Based on Lewin's field theory, we advanced a
computational model combining signal detection theory with pre-trained language
models to predict passengers' humanness rating behaviour. We employed affective
transition between pre-study baseline emotions and corresponding post-stage
emotions as the signal strength of our model. Results showed that the
passengers' ascription of humanness would increase with the greater affective
transition. Our study suggested an important role of affective transition in
passengers' ascription of humanness, which might become a future direction for
autonomous driving.</p>
  </details>
</details>
<details>
  <summary>14. <b>标题：Emotion Conditioned Creative Dialog Generation</b></summary>
  <p><b>编号</b>：[132]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02907</p>
  <p><b>作者</b>：Khalid Alnajjar,  Mika Hämäläinen</p>
  <p><b>备注</b>：NLP4DH 2022</p>
  <p><b>关键词</b>：generating creative dialog, creative dialog responses, DialGPT based model, sadness and surprise, DialGPT based</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present a DialGPT based model for generating creative dialog responses
that are conditioned based on one of the following emotions: anger, disgust,
fear, happiness, pain, sadness and surprise. Our model is capable of producing
a contextually apt response given an input sentence and a desired emotion
label. Our model is capable of expressing the desired emotion with an accuracy
of 0.6. The best performing emotions are neutral, fear and disgust. When
measuring the strength of the expressed emotion, we find that anger, fear and
disgust are expressed in the most strong fashion by the model.</p>
  </details>
</details>
<details>
  <summary>15. <b>标题：Template-based Recruitment Email Generation For Job Recommendation</b></summary>
  <p><b>编号</b>：[137]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02885</p>
  <p><b>作者</b>：Qiuchi Li,  Christina Lioma</p>
  <p><b>备注</b>：Accepted by GEM2022 workshop</p>
  <p><b>关键词</b>：popular research topic, topic in NLP, Text generation, NLP, popular research</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Text generation has long been a popular research topic in NLP. However, the
task of generating recruitment emails from recruiters to candidates in the job
recommendation scenario has received little attention by the research
community. This work aims at defining the topic of automatic email generation
for job recommendation, identifying the challenges, and providing a baseline
template-based solution for Danish jobs. Evaluation by human experts shows that
our method is effective. We wrap up by discussing the future research
directions for better solving this task.</p>
  </details>
</details>
<details>
  <summary>16. <b>标题：DiSTRICT: Dialogue State Tracking with Retriever Driven In-Context  Tuning</b></summary>
  <p><b>编号</b>：[149]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02851</p>
  <p><b>作者</b>：Praveen Venkateswaran,  Evelyn Duesterwald,  Vatche Isahagian</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Dialogue State Tracking, State Tracking, represents user intentions, task-oriented conversation systems, conversation systems</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Dialogue State Tracking (DST), a key component of task-oriented conversation
systems, represents user intentions by determining the values of pre-defined
slots in an ongoing dialogue. Existing approaches use hand-crafted templates
and additional slot information to fine-tune and prompt large pre-trained
language models and elicit slot values from the dialogue context. Significant
manual effort and domain knowledge is required to design effective prompts,
limiting the generalizability of these approaches to new domains and tasks. In
this work, we propose DiSTRICT, a generalizable in-context tuning approach for
DST that retrieves highly relevant training examples for a given dialogue to
fine-tune the model without any hand-crafted templates. Experiments with the
MultiWOZ benchmark datasets show that DiSTRICT outperforms existing approaches
in various zero-shot and few-shot settings using a much smaller model, thereby
providing an important advantage for real-world deployments that often have
limited resource availability.</p>
  </details>
</details>
<details>
  <summary>17. <b>标题：Life-long Learning for Multilingual Neural Machine Translation with  Knowledge Distillation</b></summary>
  <p><b>编号</b>：[165]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02800</p>
  <p><b>作者</b>：Yang Zhao,  Junnan Zhu,  Lu Xiang,  Jiajun Zhang,  Yu Zhou,  Feifei Zhai,  Chengqing Zong</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Multilingual Neural Machine, Neural Machine Translation, Neural Machine, Multilingual Neural, Machine Translation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A common scenario of Multilingual Neural Machine Translation (MNMT) is that
each translation task arrives in a sequential manner, and the training data of
previous tasks is unavailable. In this scenario, the current methods suffer
heavily from catastrophic forgetting (CF). To alleviate the CF, we investigate
knowledge distillation based life-long learning methods. Specifically, in
one-tomany scenario, we propose a multilingual distillation method to make the
new model (student) jointly learn multilingual output from old model (teacher)
and new task. In many-to one scenario, we find that direct distillation faces
the extreme partial distillation problem, and we propose two different methods
to address it: pseudo input distillation and reverse teacher distillation. The
experimental results on twelve translation tasks show that the proposed methods
can better consolidate the previous knowledge and sharply alleviate the CF.</p>
  </details>
</details>
<details>
  <summary>18. <b>标题：Automated Identification of Eviction Status from Electronic Health  Record Notes</b></summary>
  <p><b>编号</b>：[183]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02762</p>
  <p><b>作者</b>：Zonghai Yao,  Jack Tsai,  Weisong Liu,  David A. Levy,  Emily Druhl,  Joel I Reisman,  Hong Yu</p>
  <p><b>备注</b>：submitted to JAMIA Focus Issue: Social Determinants of Health (SDOH) Extraction through Natural Language Processing</p>
  <p><b>关键词</b>：mental health problems, Veterans Health Administration, long-term poverty, lead to unemployment, cascade of negative</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Objective: Evictions are involved in a cascade of negative events that can
lead to unemployment, homelessness, long-term poverty, and mental health
problems. In this study, we developed a natural language processing system to
automatically detect eviction incidences and their attributes from electronic
health record (EHR) notes.
Materials and Methods: We annotated eviction status in 5000 EHR notes from
the Veterans Health Administration. We developed a novel model, called
Knowledge Injection based on Ripple Effects of Social and Behavioral
Determinants of Health (KIRESH), that has shown to substantially outperform
other state-of-the-art models such as fine-tuning pre-trained language models
like BioBERT and Bio_ClinicalBERT. Moreover, we designed a prompt to further
improve the model performance by using the intrinsic connection between the two
sub-tasks of eviction presence and period prediction. Finally, we used the
Temperature Scaling-based Calibration on our KIRESH-Prompt method to avoid
over-confidence issues arising from the imbalance dataset.
Results: KIRESH-Prompt achieved a Macro-F1 of 0.6273 (presence) and 0.7115
(period), which was significantly higher than 0.5382 (presence) and 0.67167
(period) for just fine-tuning Bio_ClinicalBERT model.
Conclusion and Future Work: KIRESH-Prompt has substantially improved eviction
status classification. In future work, we will evaluate the generalizability of
the model framework to other applications.</p>
  </details>
</details>
<details>
  <summary>19. <b>标题：Sources of Noise in Dialogue and How to Deal with Them</b></summary>
  <p><b>编号</b>：[196]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02745</p>
  <p><b>作者</b>：Derek Chen,  Zhou Yu</p>
  <p><b>备注</b>：23 pages, 6 Figures, 5 tables. Preprint</p>
  <p><b>关键词</b>：unexpected user inputs, Training dialogue systems, user inputs, noisy training, entails dealing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Training dialogue systems often entails dealing with noisy training examples
and unexpected user inputs. Despite their prevalence, there currently lacks an
accurate survey of dialogue noise, nor is there a clear sense of the impact of
each noise type on task performance. This paper addresses this gap by first
constructing a taxonomy of noise encountered by dialogue systems. In addition,
we run a series of experiments to show how different models behave when
subjected to varying levels of noise and types of noise. Our results reveal
that models are quite robust to label errors commonly tackled by existing
denoising algorithms, but that performance suffers from dialogue-specific
noise. Driven by these observations, we design a data cleaning algorithm
specialized for conversational settings and apply it as a proof-of-concept for
targeted dialogue denoising.</p>
  </details>
</details>
<details>
  <summary>20. <b>标题：Improved Beam Search for Hallucination Mitigation in Abstractive  Summarization</b></summary>
  <p><b>编号</b>：[210]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02712</p>
  <p><b>作者</b>：Arvind Krishna Sridhar,  Erik Visser</p>
  <p><b>备注</b>：8 pages, 2 figures</p>
  <p><b>关键词</b>：generation tasks including, large pretrained language, pretrained language models, tasks including summarization, including summarization albeit</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Advancement in large pretrained language models has significantly improved
their performance for conditional language generation tasks including
summarization albeit with hallucinations. To reduce hallucinations,
conventional methods proposed improving beam search or using a fact checker as
a postprocessing step. In this paper, we investigate the use of the Natural
Language Inference (NLI) entailment metric to detect and prevent hallucinations
in summary generation. We propose an NLI-assisted beam re-ranking mechanism by
computing entailment probability scores between the input context and
summarization model-generated beams during saliency-enhanced greedy decoding.
Moreover, a diversity metric is introduced to compare its effectiveness against
vanilla beam search. Our proposed algorithm significantly outperforms vanilla
beam decoding on XSum and CNN/DM datasets.</p>
  </details>
</details>
<details>
  <summary>21. <b>标题：LUNA: Language Understanding with Number Augmentations on Transformers  via Number Plugins and Pre-training</b></summary>
  <p><b>编号</b>：[217]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02691</p>
  <p><b>作者</b>：Hongwei Han,  Jialiang Xu,  Mengyu Zhou,  Yijia Shao,  Shi Han,  Dongmei Zhang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：NLP tasks, LUNA, NLP, Number, models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Transformers are widely used in NLP tasks. However, current approaches to
leveraging transformers to understand language expose one weak spot: Number
understanding. In some scenarios, numbers frequently occur, especially in
semi-structured data like tables. But current approaches to rich-number tasks
with transformer-based language models abandon or lose some of the numeracy
information - e.g., breaking numbers into sub-word tokens - which leads to many
number-related errors. In this paper, we propose the LUNA framework which
improves the numerical reasoning and calculation capabilities of
transformer-based language models. With the number plugin of NumTok and NumBed,
LUNA represents each number as a whole to model input. With number
pre-training, including regression loss and model distillation, LUNA bridges
the gap between number and vocabulary embeddings. To the best of our knowledge,
this is the first work that explicitly injects numeracy capability into
language models using Number Plugins. Besides evaluating toy models on toy
tasks, we evaluate LUNA on three large-scale transformer models (RoBERTa, BERT,
TabBERT) over three different downstream tasks (TATQA, TabFact, CrediTrans),
and observe the performances of language models are constantly improved by
LUNA. The augmented models also improve the official baseline of TAT-QA (EM:
50.15 -> 59.58) and achieve SOTA performance on CrediTrans (F1 = 86.17).</p>
  </details>
</details>
<details>
  <summary>22. <b>标题：POQue: Asking Participant-specific Outcome Questions for a Deeper  Understanding of Complex Events</b></summary>
  <p><b>编号</b>：[236]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02629</p>
  <p><b>作者</b>：Sai Vallurupalli,  Sayontan Ghosh,  Katrin Erk,  Niranjan Balasubramanian,  Francis Ferraro</p>
  <p><b>备注</b>：Accepted to EMNLP 2022 main conference as a long paper</p>
  <p><b>关键词</b>：complex event, hard to acquire, complex event understanding, weighted Fleiss Kappa, Participant Outcome Questions</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Knowledge about outcomes is critical for complex event understanding but is
hard to acquire. We show that by pre-identifying a participant in a complex
event, crowd workers are able to (1) infer the collective impact of salient
events that make up the situation, (2) annotate the volitional engagement of
participants in causing the situation, and (3) ground the outcome of the
situation in state changes of the participants. By creating a multi-step
interface and a careful quality control strategy, we collect a high quality
annotated dataset of 8K short newswire narratives and ROCStories with high
inter-annotator agreement (0.74-0.96 weighted Fleiss Kappa). Our dataset, POQue
(Participant Outcome Questions), enables the exploration and development of
models that address multiple aspects of semantic understanding. Experimentally,
we show that current language models lag behind human performance in subtle
ways through our task formulations that target abstract and specific
comprehension of a complex event, its outcome, and a participant's influence
over the event culmination.</p>
  </details>
</details>
<details>
  <summary>23. <b>标题：Unifying Vision, Text, and Layout for Universal Document Processing</b></summary>
  <p><b>编号</b>：[238]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02623</p>
  <p><b>作者</b>：Zineng Tang,  Ziyi Yang,  Guoxin Wang,  Yuwei Fang,  Yang Liu,  Chenguang Zhu,  Michael Zeng,  Cha Zhang,  Mohit Bansal</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Universal Document Processing, propose Universal Document, propose Universal, Document Processing, varied task formats</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose Universal Document Processing (UDOP), a foundation Document AI
model which unifies text, image, and layout modalities together with varied
task formats, including document understanding and generation. UDOP leverages
the spatial correlation between textual content and document image to model
image, text, and layout modalities with one uniform representation. With a
novel Vision-Text-Layout Transformer, UDOP unifies pretraining and multi-domain
downstream tasks into a prompt-based sequence generation scheme. UDOP is
pretrained on both large-scale unlabeled document corpora using innovative
self-supervised objectives and diverse labeled data. UDOP also learns to
generate document images from text and layout modalities via masked image
reconstruction. To the best of our knowledge, this is the first time in the
field of document AI that one model simultaneously achieves high-quality neural
document editing and content customization. Our method sets the
state-of-the-art on 9 Document AI tasks, e.g., document understanding and QA,
across diverse data domains like finance reports, academic papers, and
websites. UDOP ranks first on the leaderboard of the Document Understanding
Benchmark (DUE).</p>
  </details>
</details>
<details>
  <summary>24. <b>标题：Fine-tuning a Subtle Parsing Distinction Using a Probabilistic Decision  Tree: the Case of Postnominal "that" in Noun Complement Clauses vs. Relative  Clauses</b></summary>
  <p><b>编号</b>：[249]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02591</p>
  <p><b>作者</b>：Zineddine Tighidet,  Nicolas Ballier</p>
  <p><b>备注</b>：Published in the ACL anthology, ALTA 2022</p>
  <p><b>关键词</b>：clauses in English, English and resorted, noun complement clauses, methods to parse, resorted to distinct</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper we investigated two different methods to parse relative and
noun complement clauses in English and resorted to distinct tags for their
corresponding that as a relative pronoun and as a complementizer. We used an
algorithm to relabel a corpus parsed with the GUM Treebank using Universal
Dependency. Our second experiment consisted in using TreeTagger, a
Probabilistic Decision Tree, to learn the distinction between the two
complement and relative uses of postnominal "that". We investigated the effect
of the training set size on TreeTagger accuracy and how representative the GUM
Treebank files are for the two structures under scrutiny. We discussed some of
the linguistic and structural tenets of the learnability of this distinction.</p>
  </details>
</details>
<details>
  <summary>25. <b>标题：INCLUSIFY: A benchmark and a model for gender-inclusive German</b></summary>
  <p><b>编号</b>：[257]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02564</p>
  <p><b>作者</b>：David Pomerenke</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：achieving gender equality, gender inflections, achieving gender, gender equality, important for achieving</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Gender-inclusive language is important for achieving gender equality in
languages with gender inflections, such as German. While stirring some
controversy, it is increasingly adopted by companies and political
institutions. A handful of tools have been developed to help people use
gender-inclusive language by identifying instances of the generic masculine and
providing suggestions for more inclusive reformulations. In this report, we
define the underlying tasks in terms of natural language processing, and
present a dataset and measures for benchmarking them. We also present a model
that implements these tasks, by combining an inclusive language database with
an elaborate sequence of processing steps via standard pre-trained models. Our
model achieves a recall of 0.89 and a precision of 0.82 in our benchmark for
identifying exclusive language; and one of its top five suggestions is chosen
in real-world texts in 44% of cases. We sketch how the area could be further
advanced by training end-to-end models and using large language models; and we
urge the community to include more gender-inclusive texts in their training
data in order to not present an obstacle to the adoption of gender-inclusive
language. Through these efforts, we hope to contribute to restoring justice in
language and, to a small extent, in reality.</p>
  </details>
</details>
<details>
  <summary>26. <b>标题：Cross-Domain Few-Shot Relation Extraction via Representation Learning  and Domain Adaptation</b></summary>
  <p><b>编号</b>：[259]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02560</p>
  <p><b>作者</b>：Zhongju Yuan,  Zhenkun Wang,  Genghui Li</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：existing few-shot learning, source domain, relation extraction poses, Cross-domain few-shot relation, few-shot relation extraction</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Cross-domain few-shot relation extraction poses a great challenge for the
existing few-shot learning methods and domain adaptation methods when the
source domain and target domain have large discrepancies. This paper proposes a
method by combining the idea of few-shot learning and domain adaptation to deal
with this problem. In the proposed method, an encoder, learned by optimizing a
representation loss and an adversarial loss, is used to extract the relation of
sentences in the source and target domain. The representation loss, including a
cross-entropy loss and a contrastive loss, makes the encoder extract the
relation of the source domain and keep the geometric structure of the classes
in the source domain. And the adversarial loss is used to merge the source
domain and target domain. The experimental results on the benchmark FewRel
dataset demonstrate that the proposed method can outperform some
state-of-the-art methods.</p>
  </details>
</details>
<h1>机器学习</h1>
<details>
  <summary>1. <b>标题：Robust Point Cloud Segmentation with Noisy Annotations</b></summary>
  <p><b>编号</b>：[1]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.03242</p>
  <p><b>作者</b>：Shuquan Ye,  Dongdong Chen,  Songfang Han,  Jing Liao</p>
  <p><b>备注</b>：To Appear at TPAMI 2022. arXiv admin note: substantial text overlap with arXiv:2107.14230</p>
  <p><b>关键词</b>：Point cloud segmentation, cloud segmentation, Point cloud, Point, label</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Point cloud segmentation is a fundamental task in 3D. Despite recent progress
on point cloud segmentation with the power of deep networks, current learning
methods based on the clean label assumptions may fail with noisy labels. Yet,
class labels are often mislabeled at both instance-level and boundary-level in
real-world datasets. In this work, we take the lead in solving the
instance-level label noise by proposing a Point Noise-Adaptive Learning (PNAL)
framework. Compared to noise-robust methods on image tasks, our framework is
noise-rate blind, to cope with the spatially variant noise rate specific to
point clouds. Specifically, we propose a point-wise confidence selection to
obtain reliable labels from the historical predictions of each point. A
cluster-wise label correction is proposed with a voting strategy to generate
the best possible label by considering the neighbor correlations. To handle
boundary-level label noise, we also propose a variant ``PNAL-boundary " with a
progressive boundary label cleaning strategy. Extensive experiments demonstrate
its effectiveness on both synthetic and real-world noisy datasets. Even with
$60\%$ symmetric noise and high-level boundary noise, our framework
significantly outperforms its baselines, and is comparable to the upper bound
trained on completely clean data. Moreover, we cleaned the popular real-world
dataset ScanNetV2 for rigorous experiment. Our code and data is available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>2. <b>标题：PØDA: Prompt-driven Zero-shot Domain Adaptation</b></summary>
  <p><b>编号</b>：[2]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.03241</p>
  <p><b>作者</b>：Mohammad Fahes,  Tuan-Hung Vu,  Andrei Bursuc,  Patrick Pérez,  Raoul de Charette</p>
  <p><b>备注</b>：Project page: this https URL</p>
  <p><b>关键词</b>：Zero-shot Domain Adaptation, Domain adaptation, train time, long-tail samples, vastly investigated</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Domain adaptation has been vastly investigated in computer vision but still
requires access to target images at train time, which might be intractable in
some conditions, especially for long-tail samples. In this paper, we propose
the task of `Prompt-driven Zero-shot Domain Adaptation', where we adapt a model
trained on a source domain using only a general textual description of the
target domain, i.e., a prompt. First, we leverage a pretrained contrastive
vision-language model (CLIP) to optimize affine transformations of source
features, bringing them closer to target text embeddings, while preserving
their content and semantics. Second, we show that augmented features can be
used to perform zero-shot domain adaptation for semantic segmentation.
Experiments demonstrate that our method significantly outperforms CLIP-based
style transfer baselines on several datasets for the downstream task at hand.
Our prompt-driven approach even outperforms one-shot unsupervised domain
adaptation on some datasets, and gives comparable results on others. The code
is available at this https URL.</p>
  </details>
</details>
<details>
  <summary>3. <b>标题：Walk These Ways: Tuning Robot Control for Generalization with  Multiplicity of Behavior</b></summary>
  <p><b>编号</b>：[4]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.03238</p>
  <p><b>作者</b>：Gabriel B Margolis,  Pulkit Agrawal</p>
  <p><b>备注</b>：Oral presentation at CoRL 2022. Website at this https URL</p>
  <p><b>关键词</b>：Learned locomotion policies, policies can rapidly, rapidly adapt, lack a mechanism, diverse environments similar</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Learned locomotion policies can rapidly adapt to diverse environments similar
to those experienced during training but lack a mechanism for fast tuning when
they fail in an out-of-distribution test environment. This necessitates a slow
and iterative cycle of reward and environment redesign to achieve good
performance on a new task. As an alternative, we propose learning a single
policy that encodes a structured family of locomotion strategies that solve
training tasks in different ways, resulting in Multiplicity of Behavior (MoB).
Different strategies generalize differently and can be chosen in real-time for
new tasks or environments, bypassing the need for time-consuming retraining. We
release a fast, robust open-source MoB locomotion controller, Walk These Ways,
that can execute diverse gaits with variable footswing, posture, and speed,
unlocking diverse downstream tasks: crouching, hopping, high-speed running,
stair traversal, bracing against shoves, rhythmic dance, and more. Video and
code release: this https URL</p>
  </details>
</details>
<details>
  <summary>4. <b>标题：Learning the joint distribution of two sequences using little or no  paired data</b></summary>
  <p><b>编号</b>：[8]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.03232</p>
  <p><b>作者</b>：Soroosh Mariooryad,  Matt Shannon,  Siyuan Ma,  Tom Bagby,  David Kao,  Daisy Stanton,  Eric Battenberg,  RJ Skerry-Ryan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：noisy channel generative, channel generative model, limited paired data, text and speech, present a noisy</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present a noisy channel generative model of two sequences, for example
text and speech, which enables uncovering the association between the two
modalities when limited paired data is available. To address the intractability
of the exact model under a realistic data setup, we propose a variational
inference approximation. To train this variational model with categorical data,
we propose a KL encoder loss approach which has connections to the wake-sleep
algorithm. Identifying the joint or conditional distributions by only observing
unpaired samples from the marginals is only possible under certain conditions
in the data distribution and we discuss under what type of conditional
independence assumptions that might be achieved, which guides the architecture
designs. Experimental results show that even tiny amount of paired data (5
minutes) is sufficient to learn to relate the two modalities (graphemes and
phonemes here) when a massive amount of unpaired data is available, paving the
path to adopting this principled approach for all seq2seq models in low data
resource regimes.</p>
  </details>
</details>
<details>
  <summary>5. <b>标题：ISAACS: Iterative Soft Adversarial Actor-Critic for Safety</b></summary>
  <p><b>编号</b>：[11]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.03228</p>
  <p><b>作者</b>：Kai-Chieh Hsu,  Duy Phuong Nguyen,  Jaime Fernández Fisac</p>
  <p><b>备注</b>：Submitted to 5th L4DC for review</p>
  <p><b>关键词</b>：previously unseen scenarios, uncontrolled environments requires, unseen scenarios, deployment of robots, robots in uncontrolled</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The deployment of robots in uncontrolled environments requires them to
operate robustly under previously unseen scenarios, like irregular terrain and
wind conditions. Unfortunately, while rigorous safety frameworks from robust
optimal control theory scale poorly to high-dimensional nonlinear dynamics,
control policies computed by more tractable "deep" methods lack guarantees and
tend to exhibit little robustness to uncertain operating conditions. This work
introduces a novel approach enabling scalable synthesis of robust
safety-preserving controllers for robotic systems with general nonlinear
dynamics subject to bounded modeling error by combining game-theoretic safety
analysis with adversarial reinforcement learning in simulation. Following a
soft actor-critic scheme, a safety-seeking fallback policy is co-trained with
an adversarial "disturbance" agent that aims to invoke the worst-case
realization of model error and training-to-deployment discrepancy allowed by
the designer's uncertainty. While the learned control policy does not
intrinsically guarantee safety, it is used to construct a real-time safety
filter (or shield) with robust safety guarantees based on forward reachability
rollouts. This shield can be used in conjunction with a safety-agnostic control
policy, precluding any task-driven actions that could result in loss of safety.
We evaluate our learning-based safety approach in a 5D race car simulator,
compare the learned safety policy to the numerically obtained optimal solution,
and empirically validate the robust safety guarantee of our proposed safety
shield against worst-case model discrepancy.</p>
  </details>
</details>
<details>
  <summary>6. <b>标题：Visual Query Tuning: Towards Effective Usage of Intermediate  Representations for Parameter and Memory Efficient Transfer Learning</b></summary>
  <p><b>编号</b>：[14]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.03220</p>
  <p><b>作者</b>：Cheng-Hao Tu,  Zheda Mai,  Wei-Lun Chao</p>
  <p><b>备注</b>：Cheng-Hao Tu and Zheda Mai contributed equally to this work</p>
  <p><b>关键词</b>：Intermediate features, features, pre-trained model, VQT, shown informative</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Intermediate features of a pre-trained model have been shown informative for
making accurate predictions on downstream tasks, even if the model backbone is
kept frozen. The key challenge is how to utilize these intermediate features
given their gigantic amount. We propose visual query tuning (VQT), a simple yet
effective approach to aggregate intermediate features of Vision Transformers.
Through introducing a handful of learnable ``query'' tokens to each layer, VQT
leverages the inner workings of Transformers to ``summarize'' rich intermediate
features of each layer, which can then be used to train the prediction heads of
downstream tasks. As VQT keeps the intermediate features intact and only learns
to combine them, it enjoys memory efficiency in training, compared to many
other parameter-efficient fine-tuning approaches that learn to adapt features
and need back-propagation through the entire backbone. This also suggests the
complementary role between VQT and those approaches in transfer learning.
Empirically, VQT consistently surpasses the state-of-the-art approach that
utilizes intermediate features for transfer learning and outperforms full
fine-tuning in many cases. Compared to parameter-efficient approaches that
adapt features, VQT achieves much higher accuracy under memory constraints.
Most importantly, VQT is compatible with these approaches to attain even higher
accuracy, making it a simple add-on to further boost transfer learning.</p>
  </details>
</details>
<details>
  <summary>7. <b>标题：Misspecification in Inverse Reinforcement Learning</b></summary>
  <p><b>编号</b>：[17]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.03201</p>
  <p><b>作者</b>：Joar Skalse,  Alessandro Abate</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Inverse Reinforcement Learning, Reinforcement Learning, Inverse Reinforcement, aim of Inverse, IRL</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The aim of Inverse Reinforcement Learning (IRL) is to infer a reward function
$R$ from a policy $\pi$. To do this, we need a model of how $\pi$ relates to
$R$. In the current literature, the most common models are optimality,
Boltzmann rationality, and causal entropy maximisation. One of the primary
motivations behind IRL is to infer human preferences from human behaviour.
However, the true relationship between human preferences and human behaviour is
much more complex than any of the models currently used in IRL. This means that
they are misspecified, which raises the worry that they might lead to unsound
inferences if applied to real-world data. In this paper, we provide a
mathematical analysis of how robust different IRL models are to
misspecification, and answer precisely how the demonstrator policy may differ
from each of the standard models before that model leads to faulty inferences
about the reward function $R$. We also introduce a framework for reasoning
about misspecification in IRL, together with formal tools that can be used to
easily derive the misspecification robustness of new IRL models.</p>
  </details>
</details>
<details>
  <summary>8. <b>标题：The AI Definition and a Program Which Satisfies this Definition</b></summary>
  <p><b>编号</b>：[24]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.03184</p>
  <p><b>作者</b>：Dimiter Dobrev</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：performing policy, policy, program, performing, language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We will consider all policies of the agent and will prove that one of them is
the best performing policy. While that policy is not computable, computable
policies do exist in its proximity. We will define AI as a computable policy
which is sufficiently proximal to the best performing policy. Before we can
define the agent's best performing policy, we need a language for description
of the world. We will also use this language to develop a program which
satisfies the AI definition. The program will first understand the world by
describing it in the selected language. The program will then use the
description in order to predict the future and select the best possible move.
While this program is extremely inefficient and practically unusable, it can be
improved by refining both the language for description of the world and the
algorithm used to predict the future. This can yield a program which is both
efficient and consistent with the AI definition.</p>
  </details>
</details>
<details>
  <summary>9. <b>标题：Overlapping oriented imbalanced ensemble learning method based on  projective clustering and stagewise hybrid sampling</b></summary>
  <p><b>编号</b>：[26]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.03182</p>
  <p><b>作者</b>：Fan Li,  Bo Wang,  Pin Wang,  Yongming Li</p>
  <p><b>备注</b>：23 pages, 3 figures</p>
  <p><b>关键词</b>：class imbalance problem, imbalanced learning lies, imbalance problem, class overlapping problem, challenge of imbalanced</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The challenge of imbalanced learning lies not only in class imbalance
problem, but also in the class overlapping problem which is complex. However,
most of the existing algorithms mainly focus on the former. The limitation
prevents the existing methods from breaking through. To address this
limitation, this paper proposes an ensemble learning algorithm based on dual
clustering and stage-wise hybrid sampling (DCSHS). The DCSHS has three parts.
Firstly, we design a projection clustering combination framework (PCC) guided
by Davies-Bouldin clustering effectiveness index (DBI), which is used to obtain
high-quality clusters and combine them to obtain a set of cross-complete
subsets (CCS) with balanced class and low overlapping. Secondly, according to
the characteristics of subset classes, a stage-wise hybrid sampling algorithm
is designed to realize the de-overlapping and balancing of subsets. Finally, a
projective clustering transfer mapping mechanism (CTM) is constructed for all
processed subsets by means of transfer learning, thereby reducing class
overlapping and explore structure information of samples. The major advantage
of our algorithm is that it can exploit the intersectionality of the CCS to
realize the soft elimination of overlapping majority samples, and learn as much
information of overlapping samples as possible, thereby enhancing the class
overlapping while class balancing. In the experimental section, more than 30
public datasets and over ten representative algorithms are chosen for
verification. The experimental results show that the DCSHS is significantly
best in terms of various evaluation criteria.</p>
  </details>
</details>
<details>
  <summary>10. <b>标题：Reinforcement Learning for Signal Temporal Logic using Funnel-Based  Approach</b></summary>
  <p><b>编号</b>：[27]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.03181</p>
  <p><b>作者</b>：Naman Saxena,  Gorantla Sandeep,  Pushpak Jagtap</p>
  <p><b>备注</b>：11 pages, 6 figures</p>
  <p><b>关键词</b>：Signal Temporal Logic, Temporal Logic, Signal Temporal, complex temporal, continuous state space</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Signal Temporal Logic (STL) is a powerful framework for describing the
complex temporal and logical behaviour of the dynamical system. Several works
propose a method to find a controller for the satisfaction of STL specification
using reinforcement learning but fail to address either the issue of robust
satisfaction in continuous state space or ensure the tractability of the
approach. In this paper, leveraging the concept of funnel functions, we propose
a tractable reinforcement learning algorithm to learn a time-dependent policy
for robust satisfaction of STL specification in continuous state space. We
demonstrate the utility of our approach on several tasks using a pendulum and
mobile robot examples.</p>
  </details>
</details>
<details>
  <summary>11. <b>标题：Learning Representations that Enable Generalization in Assistive Tasks</b></summary>
  <p><b>编号</b>：[31]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.03175</p>
  <p><b>作者</b>：Jerry Zhi-Yang He,  Aditi Raghunathan,  Daniel S. Brown,  Zackory Erickson,  Anca D. Dragan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：successfully enabled robots, domain randomization, successfully enabled, Recent work, human</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent work in sim2real has successfully enabled robots to act in physical
environments by training in simulation with a diverse ''population'' of
environments (i.e. domain randomization). In this work, we focus on enabling
generalization in assistive tasks: tasks in which the robot is acting to assist
a user (e.g. helping someone with motor impairments with bathing or with
scratching an itch). Such tasks are particularly interesting relative to prior
sim2real successes because the environment now contains a human who is also
acting. This complicates the problem because the diversity of human users
(instead of merely physical environment parameters) is more difficult to
capture in a population, thus increasing the likelihood of encountering
out-of-distribution (OOD) human policies at test time. We advocate that
generalization to such OOD policies benefits from (1) learning a good latent
representation for human policies that test-time humans can accurately be
mapped to, and (2) making that representation adaptable with test-time
interaction data, instead of relying on it to perfectly capture the space of
human policies based on the simulated population only. We study how to best
learn such a representation by evaluating on purposefully constructed OOD test
policies. We find that sim2real methods that encode environment (or population)
parameters and work well in tasks that robots do in isolation, do not work well
in assistance. In assistance, it seems crucial to train the representation
based on the history of interaction directly, because that is what the robot
will have access to at test time. Further, training these representations to
then predict human actions not only gives them better structure, but also
enables them to be fine-tuned at test-time, when the robot observes the partner
act. this https URL.</p>
  </details>
</details>
<details>
  <summary>12. <b>标题：A Learned Simulation Environment to Model Plant Growth in Indoor Farming</b></summary>
  <p><b>编号</b>：[37]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.03155</p>
  <p><b>作者</b>：J. Amacker,  T. Kleiven,  M. Grigore,  P. Albrecht,  C. Horn</p>
  <p><b>备注</b>：8 pages, 6 figures, 1 table</p>
  <p><b>关键词</b>：precision farming, developed a simulator, simulator to quantify, quantify the effect, environmental parameters</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We developed a simulator to quantify the effect of changes in environmental
parameters on plant growth in precision farming. Our approach combines the
processing of plant images with deep convolutional neural networks (CNN),
growth curve modeling, and machine learning. As a result, our system is able to
predict growth rates based on environmental variables, which opens the door for
the development of versatile reinforcement learning agents.</p>
  </details>
</details>
<details>
  <summary>13. <b>标题：Explainability as statistical inference</b></summary>
  <p><b>编号</b>：[44]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.03131</p>
  <p><b>作者</b>：Hugo Henri Joseph Senetaire,  Damien Garreau,  Jes Frellsen,  Pierre-Alexandre Mattei</p>
  <p><b>备注</b>：10 pages, 22 figures, submitted at ICLR 2023</p>
  <p><b>关键词</b>：model explanation approaches, recent years, rationales and heuristics, wide variety, explanation approaches</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A wide variety of model explanation approaches have been proposed in recent
years, all guided by very different rationales and heuristics. In this paper,
we take a new route and cast interpretability as a statistical inference
problem. We propose a general deep probabilistic model designed to produce
interpretable predictions. The model parameters can be learned via maximum
likelihood, and the method can be adapted to any predictor network architecture
and any type of prediction problem. Our method is a case of amortized
interpretability models, where a neural network is used as a selector to allow
for fast interpretation at inference time. Several popular interpretability
methods are shown to be particular cases of regularised maximum likelihood for
our general model. We propose new datasets with ground truth selection which
allow for the evaluation of the features importance map. Using these datasets,
we show experimentally that using multiple imputation provides more reasonable
interpretations.</p>
  </details>
</details>
<details>
  <summary>14. <b>标题：Deep Learning Methods for Partial Differential Equations and Related  Parameter Identification Problems</b></summary>
  <p><b>编号</b>：[45]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.03130</p>
  <p><b>作者</b>：Derick Nganyu Tanyu,  Jianfeng Ning,  Tom Freudenberg,  Nick Heilenkötter,  Andreas Rademacher,  Uwe Iben,  Peter Maass</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：deep learning, deep learning algorithms, Recent years, mathematics, deep</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent years have witnessed a growth in mathematics for deep learning--which
seeks a deeper understanding of the concepts of deep learning with mathematics,
and explores how to make it more robust--and deep learning for mathematics,
where deep learning algorithms are used to solve problems in mathematics. The
latter has popularised the field of scientific machine learning where deep
learning is applied to problems in scientific computing. Specifically, more and
more neural network architectures have been developed to solve specific classes
of partial differential equations (PDEs). Such methods exploit properties that
are inherent to PDEs and thus solve the PDEs better than classical feed-forward
neural networks, recurrent neural networks, and convolutional neural networks.
This has had a great impact in the area of mathematical modeling where
parametric PDEs are widely used to model most natural and physical processes
arising in science and engineering, In this work, we review such methods and
extend them for parametric studies as well as for solving the related inverse
problems. We equally proceed to show their relevance in some industrial
applications.</p>
  </details>
</details>
<details>
  <summary>15. <b>标题：Q-Pensieve: Boosting Sample Efficiency of Multi-Objective RL Through  Memory Sharing of Q-Snapshots</b></summary>
  <p><b>编号</b>：[48]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.03117</p>
  <p><b>作者</b>：Wei Hung,  Bo-Kai Huang,  Ping-Chun Hsieh,  Xi Liu</p>
  <p><b>备注</b>：17 pages, 15 figures</p>
  <p><b>关键词</b>：multi-objective reinforcement learning, real-world continuous control, continuous control problems, learning control policies, learning control</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Many real-world continuous control problems are in the dilemma of weighing
the pros and cons, multi-objective reinforcement learning (MORL) serves as a
generic framework of learning control policies for different preferences over
objectives. However, the existing MORL methods either rely on multiple passes
of explicit search for finding the Pareto front and therefore are not
sample-efficient, or utilizes a shared policy network for coarse knowledge
sharing among policies. To boost the sample efficiency of MORL, we propose
Q-Pensieve, a policy improvement scheme that stores a collection of Q-snapshots
to jointly determine the policy update direction and thereby enables data
sharing at the policy level. We show that Q-Pensieve can be naturally
integrated with soft policy iteration with convergence guarantee. To
substantiate this concept, we propose the technique of Q replay buffer, which
stores the learned Q-networks from the past iterations, and arrive at a
practical actor-critic implementation. Through extensive experiments and an
ablation study, we demonstrate that with much fewer samples, the proposed
algorithm can outperform the benchmark MORL methods on a variety of MORL
benchmark tasks.</p>
  </details>
</details>
<details>
  <summary>16. <b>标题：Fast Online Hashing with Multi-Label Projection</b></summary>
  <p><b>编号</b>：[49]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.03112</p>
  <p><b>作者</b>：Wenzhe Jia,  Yuan Cao,  Junwei Liu,  Jie Gui</p>
  <p><b>备注</b>：This paper is accepted by AAAI Conference on Artificial Intelligence (AAAI), 2023</p>
  <p><b>关键词</b>：search problem owing, online hashing methods, large-scale approximate nearest, neighbor search problem, online hashing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Hashing has been widely researched to solve the large-scale approximate
nearest neighbor search problem owing to its time and storage superiority. In
recent years, a number of online hashing methods have emerged, which can update
the hash functions to adapt to the new stream data and realize dynamic
retrieval. However, existing online hashing methods are required to update the
whole database with the latest hash functions when a query arrives, which leads
to low retrieval efficiency with the continuous increase of the stream data. On
the other hand, these methods ignore the supervision relationship among the
examples, especially in the multi-label case. In this paper, we propose a novel
Fast Online Hashing (FOH) method which only updates the binary codes of a small
part of the database. To be specific, we first build a query pool in which the
nearest neighbors of each central point are recorded. When a new query arrives,
only the binary codes of the corresponding potential neighbors are updated. In
addition, we create a similarity matrix which takes the multi-label supervision
information into account and bring in the multi-label projection loss to
further preserve the similarity among the multi-label data. The experimental
results on two common benchmarks show that the proposed FOH can achieve
dramatic superiority on query time up to 6.28 seconds less than
state-of-the-art baselines with competitive retrieval accuracy.</p>
  </details>
</details>
<details>
  <summary>17. <b>标题：A Comprehensively Improved Hybrid Algorithm for Learning Bayesian  Networks: Multiple Compound Memory Erasing</b></summary>
  <p><b>编号</b>：[53]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.03103</p>
  <p><b>作者</b>：Baokui Mou</p>
  <p><b>备注</b>：Bayesian networks, Structure learning, Conditional independence tests, Scoring function</p>
  <p><b>关键词</b>：Bayesian network, hot spot, analyze the causal, causal relationship, network generation methods</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Using a Bayesian network to analyze the causal relationship between nodes is
a hot spot. The existing network learning algorithms are mainly
constraint-based and score-based network generation methods. The
constraint-based method is mainly the application of conditional independence
(CI) tests, but the inaccuracy of CI tests in the case of high dimensionality
and small samples has always been a problem for the constraint-based method.
The score-based method uses the scoring function and search strategy to find
the optimal candidate network structure, but the search space increases too
much with the increase of the number of nodes, and the learning efficiency is
very low. This paper presents a new hybrid algorithm, MCME (multiple compound
memory erasing). This method retains the advantages of the first two methods,
solves the shortcomings of the above CI tests, and makes innovations in the
scoring function in the direction discrimination stage. A large number of
experiments show that MCME has better or similar performance than some existing
algorithms.</p>
  </details>
</details>
<details>
  <summary>18. <b>标题：A comparative study of emotion recognition methods using facial  expressions</b></summary>
  <p><b>编号</b>：[54]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.03102</p>
  <p><b>作者</b>：Rim EL Cheikh,  Hélène Tran,  Issam Falih,  Engelbert Mephu Nguifo</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：facial expression gives, Facial Emotion Recognition, expression gives insight, explicitly expressed, interlocutor is important</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Understanding the facial expressions of our interlocutor is important to
enrich the communication and to give it a depth that goes beyond the explicitly
expressed. In fact, studying one's facial expression gives insight into their
hidden emotion state. However, even as humans, and despite our empathy and
familiarity with the human emotional experience, we are only able to guess what
the other might be feeling. In the fields of artificial intelligence and
computer vision, Facial Emotion Recognition (FER) is a topic that is still in
full growth mostly with the advancement of deep learning approaches and the
improvement of data collection. The main purpose of this paper is to compare
the performance of three state-of-the-art networks, each having their own
approach to improve on FER tasks, on three FER datasets. The first and second
sections respectively describe the three datasets and the three studied network
architectures designed for an FER task. The experimental protocol, the results
and their interpretation are outlined in the remaining sections.</p>
  </details>
</details>
<details>
  <summary>19. <b>标题：Interpretation of Neural Networks is Susceptible to Universal  Adversarial Perturbations</b></summary>
  <p><b>编号</b>：[57]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.03095</p>
  <p><b>作者</b>：Haniyeh Ehsani Oskouie,  Farzan Farnia</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：deep learning literature, learning literature, standard image datasets, Interpreting neural network, extensively studied</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Interpreting neural network classifiers using gradient-based saliency maps
has been extensively studied in the deep learning literature. While the
existing algorithms manage to achieve satisfactory performance in application
to standard image recognition datasets, recent works demonstrate the
vulnerability of widely-used gradient-based interpretation schemes to
norm-bounded perturbations adversarially designed for every individual input
sample. However, such adversarial perturbations are commonly designed using the
knowledge of an input sample, and hence perform sub-optimally in application to
an unknown or constantly changing data point. In this paper, we show the
existence of a Universal Perturbation for Interpretation (UPI) for standard
image datasets, which can alter a gradient-based feature map of neural networks
over a significant fraction of test samples. To design such a UPI, we propose a
gradient-based optimization method as well as a principal component analysis
(PCA)-based approach to compute a UPI which can effectively alter a neural
network's gradient-based interpretation on different samples. We support the
proposed UPI approaches by presenting several numerical results of their
successful applications to standard image datasets.</p>
  </details>
</details>
<details>
  <summary>20. <b>标题：Land Use Prediction using Electro-Optical to SAR Few-Shot Transfer  Learning</b></summary>
  <p><b>编号</b>：[64]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.03084</p>
  <p><b>作者</b>：Marcel Hussing,  Karen Li,  Eric Eaton</p>
  <p><b>备注</b>：Published at Tackling Climate Change with Machine Learning workshop at NeurIPS 2022</p>
  <p><b>关键词</b>：ecosystem monitoring, Satellite image analysis, important implications, implications for land, image analysis</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Satellite image analysis has important implications for land use,
urbanization, and ecosystem monitoring. Deep learning methods can facilitate
the analysis of different satellite modalities, such as electro-optical (EO)
and synthetic aperture radar (SAR) imagery, by supporting knowledge transfer
between the modalities to compensate for individual shortcomings. Recent
progress has shown how distributional alignment of neural network embeddings
can produce powerful transfer learning models by employing a sliced Wasserstein
distance (SWD) loss. We analyze how this method can be applied to Sentinel-1
and -2 satellite imagery and develop several extensions toward making it
effective in practice. In an application to few-shot Local Climate Zone (LCZ)
prediction, we show that these networks outperform multiple common baselines on
datasets with a large number of classes. Further, we provide evidence that
instance normalization can significantly stabilize the training process and
that explicitly shaping the embedding space using supervised contrastive
learning can lead to improved performance.</p>
  </details>
</details>
<details>
  <summary>21. <b>标题：Straggler-Resilient Differentially-Private Decentralized Learning</b></summary>
  <p><b>编号</b>：[66]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.03080</p>
  <p><b>作者</b>：Yauhen Yakimenka,  Chung-Wei Weng,  Hsuan-Yin Lin,  Eirik Rosnes,  Jörg Kliewer</p>
  <p><b>备注</b>：This paper was presented in part at the IEEE Information Theory Workshop (ITW), Mumbai, India, November 2022</p>
  <p><b>关键词</b>：preserving user data, user data privacy, problem in decentralized, decentralized learning, logical ring</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We consider the straggler problem in decentralized learning over a logical
ring while preserving user data privacy. Especially, we extend the recently
proposed framework of differential privacy (DP) amplification by
decentralization by Cyffers and Bellet to include overall training
latency--comprising both computation and communication latency. Analytical
results on both the convergence speed and the DP level are derived for both a
skipping scheme (which ignores the stragglers after a timeout) and a baseline
scheme that waits for each node to finish before the training continues. A
trade-off between overall training latency, accuracy, and privacy,
parameterized by the timeout of the skipping scheme, is identified and
empirically validated for logistic regression on a real-world dataset.</p>
  </details>
</details>
<details>
  <summary>22. <b>标题：Multiple Perturbation Attack: Attack Pixelwise Under Different  $\ell_p$-norms For Better Adversarial Performance</b></summary>
  <p><b>编号</b>：[72]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.03069</p>
  <p><b>作者</b>：Ngoc N. Tran,  Anh Tuan Bui,  Dinh Phung,  Trung Le</p>
  <p><b>备注</b>：19 pages, 8 figures, 7 tables</p>
  <p><b>关键词</b>：hot topic recently, Adversarial machine learning, deep neural networks, topic recently, machine learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Adversarial machine learning has been both a major concern and a hot topic
recently, especially with the ubiquitous use of deep neural networks in the
current landscape. Adversarial attacks and defenses are usually likened to a
cat-and-mouse game in which defenders and attackers evolve over the time. On
one hand, the goal is to develop strong and robust deep networks that are
resistant to malicious actors. On the other hand, in order to achieve that, we
need to devise even stronger adversarial attacks to challenge these defense
models. Most of existing attacks employs a single $\ell_p$ distance (commonly,
$p\in\{1,2,\infty\}$) to define the concept of closeness and performs steepest
gradient ascent w.r.t. this $p$-norm to update all pixels in an adversarial
example in the same way. These $\ell_p$ attacks each has its own pros and cons;
and there is no single attack that can successfully break through defense
models that are robust against multiple $\ell_p$ norms simultaneously.
Motivated by these observations, we come up with a natural approach: combining
various $\ell_p$ gradient projections on a pixel level to achieve a joint
adversarial perturbation. Specifically, we learn how to perturb each pixel to
maximize the attack performance, while maintaining the overall visual
imperceptibility of adversarial examples. Finally, through various experiments
with standardized benchmarks, we show that our method outperforms most current
strong attacks across state-of-the-art defense mechanisms, while retaining its
ability to remain clean visually.</p>
  </details>
</details>
<details>
  <summary>23. <b>标题：On the Importance of Clinical Notes in Multi-modal Learning for EHR Data</b></summary>
  <p><b>编号</b>：[80]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.03044</p>
  <p><b>作者</b>：Severin Husmann,  Hugo Yèche,  Gunnar Rätsch,  Rita Kuznetsova</p>
  <p><b>备注</b>：Workshop on Learning from Time Series for Health, 36th Conference on Neural Information Processing Systems (NeurIPS 2022) 15 pages (including appendices)</p>
  <p><b>关键词</b>：accepting machine learning-based, machine learning-based decision, learning-based decision support, decision support systems, medical community</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Understanding deep learning model behavior is critical to accepting machine
learning-based decision support systems in the medical community. Previous
research has shown that jointly using clinical notes with electronic health
record (EHR) data improved predictive performance for patient monitoring in the
intensive care unit (ICU). In this work, we explore the underlying reasons for
these improvements. While relying on a basic attention-based model to allow for
interpretability, we first confirm that performance significantly improves over
state-of-the-art EHR data models when combining EHR data and clinical notes. We
then provide an analysis showing improvements arise almost exclusively from a
subset of notes containing broader context on patient state rather than
clinician notes. We believe such findings highlight deep learning models for
EHR data to be more limited by partially-descriptive data than by modeling
choice, motivating a more data-centric approach in the field.</p>
  </details>
</details>
<details>
  <summary>24. <b>标题：Towards a more efficient computation of individual attribute and policy  contribution for post-hoc explanation of cooperative multi-agent systems  using Myerson values</b></summary>
  <p><b>编号</b>：[81]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.03041</p>
  <p><b>作者</b>：Giorgio Angelotti,  Natalia Díaz-Rodríguez</p>
  <p><b>备注</b>：Accepted for publication in Elsevier's Knowledge-Based Systems</p>
  <p><b>关键词</b>：gold for strategists, sports coaches, quantitative assessment, valuable as gold, agent</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A quantitative assessment of the global importance of an agent in a team is
as valuable as gold for strategists, decision-makers, and sports coaches. Yet,
retrieving this information is not trivial since in a cooperative task it is
hard to isolate the performance of an individual from the one of the whole
team. Moreover, it is not always clear the relationship between the role of an
agent and his personal attributes. In this work we conceive an application of
the Shapley analysis for studying the contribution of both agent policies and
attributes, putting them on equal footing. Since the computational complexity
is NP-hard and scales exponentially with the number of participants in a
transferable utility coalitional game, we resort to exploiting a-priori
knowledge about the rules of the game to constrain the relations between the
participants over a graph. We hence propose a method to determine a
Hierarchical Knowledge Graph of agents' policies and features in a Multi-Agent
System. Assuming a simulator of the system is available, the graph structure
allows to exploit dynamic programming to assess the importances in a much
faster way. We test the proposed approach in a proof-of-case environment
deploying both hardcoded policies and policies obtained via Deep Reinforcement
Learning. The proposed paradigm is less computationally demanding than
trivially computing the Shapley values and provides great insight not only into
the importance of an agent in a team but also into the attributes needed to
deploy the policy at its best.</p>
  </details>
</details>
<details>
  <summary>25. <b>标题：Integration of a systolic array based hardware accelerator into a DNN  operator auto-tuning framework</b></summary>
  <p><b>编号</b>：[85]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.03034</p>
  <p><b>作者</b>：F. N. Peccia,  O. Bringmann</p>
  <p><b>备注</b>：6 pages, 5 figures, submitted to the CODAI Workshop at the 2022 ESWEEK</p>
  <p><b>关键词</b>：heterogeneous SoCs coupled, software tools provided, software tools, deployment of neural, neural networks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The deployment of neural networks on heterogeneous SoCs coupled with custom
accelerators is a challenging task because of the lack of end-to-end software
tools provided for these systems. Moreover, the already available low level
schedules and mapping strategies provided by the accelerator developers for
typical tensor operations are not necessarily the best possible ones for each
particular use case. This is why frameworks which automatically test the
performance of the generated code on a specific hardware configuration are of
special interest. In this work, the integration between the code generation
framework TVM and the systolic array-based accelerator Gemmini is presented. A
generic schedule to offload the GEneral Matrix Multiply (GEMM) tensor operation
onto Gemmini is detailed, and its suitability is tested by executing the
AutoTVM tuning process on it. Our generated code achieves a peak throughput of
46 giga-operations per second (GOPs) under a 100 MHz clock on a Xilinx ZCU102
FPGA, outperforming previous work. Furthermore, the code generated by this
integration was able to surpass the default hand-tuned schedules provided by
the Gemmini developers in real-world workloads.</p>
  </details>
</details>
<details>
  <summary>26. <b>标题：Style transfer and classification in hebrew news items</b></summary>
  <p><b>编号</b>：[89]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.03019</p>
  <p><b>作者</b>：Nir Weingarten</p>
  <p><b>备注</b>：Published at ISCOL2022 as a poster. For generated Hebrew fake news articles, visit this https URL</p>
  <p><b>关键词</b>：Morphological rich language, Morphological rich, making its modeling, modeling harder, harder than simpler</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Hebrew is a Morphological rich language, making its modeling harder than
simpler language. Recent developments such as Transformers in general and Bert
in particular opened a path for Hebrew models that reach SOTA results, not
falling short from other non-MRL languages. We explore the cutting edge in this
field performing style transfer, text generation and classification over news
articles collected from online archives. Furthermore, the news portals that
feed our collective consciousness are an interesting corpus to study, as their
analysis and tracing might reveal insights about our society and discourse.</p>
  </details>
</details>
<details>
  <summary>27. <b>标题：Estimating Cardiac Tissue Conductivity from Electrograms with Fully  Convolutional Networks</b></summary>
  <p><b>编号</b>：[92]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.03012</p>
  <p><b>作者</b>：Konstantinos Ntagiantas (1),  Eduardo Pignatelli (1),  Nicholas S. Peters (2),  Chris D. Cantwell (3),  Rasheda A.Chowdhury (2),  Anil A. Bharath (1) ((1) Department of Bioengineering, Imperial College London, (2) National Heart and Lung Institute, Imperial College London, (3) Department of Aeronautics, Imperial College London)</p>
  <p><b>备注</b>：15 pages, 13 figures</p>
  <p><b>关键词</b>：functional cellular remodeling, disorganised electrical activity, Atrial Fibrillation, cellular remodeling, slow conduction</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Atrial Fibrillation (AF) is characterized by disorganised electrical activity
in the atria and is known to be sustained by the presence of regions of
fibrosis (scars) or functional cellular remodeling, both of which may lead to
areas of slow conduction. Estimating the effective conductivity of the
myocardium and identifying regions of abnormal propagation is therefore crucial
for the effective treatment of AF. We hypothesise that the spatial distribution
of tissue conductivity can be directly inferred from an array of concurrently
acquired contact electrograms (EGMs). We generate a dataset of simulated
cardiac AP propagation using randomised scar distributions and a
phenomenological cardiac model and calculate contact electrograms at various
positions on the field. A deep neural network, based on a modified U-net
architecture, is trained to estimate the location of the scar and quantify
conductivity of the tissue with a Jaccard index of $91$%. We adapt a
wavelet-based surrogate testing analysis to confirm that the inferred
conductivity distribution is an accurate representation of the ground truth
input to the model. We find that the root mean square error (RMSE) between the
ground truth and our predictions is significantly smaller ($p_{val}=0.007$)
than the RMSE between the ground truth and surrogate samples.</p>
  </details>
</details>
<details>
  <summary>28. <b>标题：A Strongly Polynomial Algorithm for Approximate Forster Transforms and  its Application to Halfspace Learning</b></summary>
  <p><b>编号</b>：[94]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.03008</p>
  <p><b>作者</b>：Ilias Diakonikolas,  Christos Tzamos,  Daniel M. Kane</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：radial isotropic position, isotropic position, essential properties, Forster transform, Forster</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The Forster transform is a method of regularizing a dataset by placing it in
{\em radial isotropic position} while maintaining some of its essential
properties. Forster transforms have played a key role in a diverse range of
settings spanning computer science and functional analysis. Prior work had
given {\em weakly} polynomial time algorithms for computing Forster transforms,
when they exist. Our main result is the first {\em strongly polynomial time}
algorithm to compute an approximate Forster transform of a given dataset or
certify that no such transformation exists. By leveraging our strongly
polynomial Forster algorithm, we obtain the first strongly polynomial time
algorithm for {\em distribution-free} PAC learning of halfspaces. This learning
result is surprising because {\em proper} PAC learning of halfspaces is {\em
equivalent} to linear programming. Our learning approach extends to give a
strongly polynomial halfspace learner in the presence of random classification
noise and, more generally, Massart noise.</p>
  </details>
</details>
<details>
  <summary>29. <b>标题：SODA: A Natural Language Processing Package to Extract Social  Determinants of Health for Cancer Studies</b></summary>
  <p><b>编号</b>：[96]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.03000</p>
  <p><b>作者</b>：Zehao Yu,  Xi Yang,  Chong Dang,  Prakash Adekkanattu,  Braja Gopal Patra,  Yifan Peng,  Jyotishman Pathak,  Debbie L. Wilson,  Ching-Yuan Chang,  Wei-Hsuan Lo-Ciganic,  Thomas J. George,  William R. Hogan,  Yi Guo,  Jiang Bian,  Yonghui Wu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：extract social determinants, natural language processing, SOcial DeterminAnts, open-source natural language, NLP models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Objective: We aim to develop an open-source natural language processing (NLP)
package, SODA (i.e., SOcial DeterminAnts), with pre-trained transformer models
to extract social determinants of health (SDoH) for cancer patients, examine
the generalizability of SODA to a new disease domain (i.e., opioid use), and
evaluate the extraction rate of SDoH using cancer populations.
Methods: We identified SDoH categories and attributes and developed an SDoH
corpus using clinical notes from a general cancer cohort. We compared four
transformer-based NLP models to extract SDoH, examined the generalizability of
NLP models to a cohort of patients prescribed with opioids, and explored
customization strategies to improve performance. We applied the best NLP model
to extract 19 categories of SDoH from the breast (n=7,971), lung (n=11,804),
and colorectal cancer (n=6,240) cohorts.
Results and Conclusion: We developed a corpus of 629 cancer patients notes
with annotations of 13,193 SDoH concepts/attributes from 19 categories of SDoH.
The Bidirectional Encoder Representations from Transformers (BERT) model
achieved the best strict/lenient F1 scores of 0.9216 and 0.9441 for SDoH
concept extraction, 0.9617 and 0.9626 for linking attributes to SDoH concepts.
Fine-tuning the NLP models using new annotations from opioid use patients
improved the strict/lenient F1 scores from 0.8172/0.8502 to 0.8312/0.8679. The
extraction rates among 19 categories of SDoH varied greatly, where 10 SDoH
could be extracted from >70% of cancer patients, but 9 SDoH had a low
extraction rate (<70% of cancer patients). the soda package with pre-trained transformer models is publicly available at this https url.< p>
  </70%></p></details>
</details>
<details>
  <summary>30. <b>标题：PRISM: Probabilistic Real-Time Inference in Spatial World Models</b></summary>
  <p><b>编号</b>：[101]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02988</p>
  <p><b>作者</b>：Atanas Mirchev,  Baris Kayalibay,  Ahmed Agha,  Patrick van der Smagt,  Daniel Cremers,  Justin Bayer</p>
  <p><b>备注</b>：Will appear in PMLR, CoRL 2022</p>
  <p><b>关键词</b>：introduce PRISM, visual perception, motion and visual, probabilistic generative model, model agent dynamics</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We introduce PRISM, a method for real-time filtering in a probabilistic
generative model of agent motion and visual perception. Previous approaches
either lack uncertainty estimates for the map and agent state, do not run in
real-time, do not have a dense scene representation or do not model agent
dynamics. Our solution reconciles all of these aspects. We start from a
predefined state-space model which combines differentiable rendering and 6-DoF
dynamics. Probabilistic inference in this model amounts to simultaneous
localisation and mapping (SLAM) and is intractable. We use a series of
approximations to Bayesian inference to arrive at probabilistic map and state
estimates. We take advantage of well-established methods and closed-form
updates, preserving accuracy and enabling real-time capability. The proposed
solution runs at 10Hz real-time and is similarly accurate to state-of-the-art
SLAM in small to medium-sized indoor environments, with high-speed UAV and
handheld camera agents (Blackbird, EuRoC and TUM-RGBD).</p>
  </details>
</details>
<details>
  <summary>31. <b>标题：Multi-Layer Personalized Federated Learning for Mitigating Biases in  Student Predictive Analytics</b></summary>
  <p><b>编号</b>：[102]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02985</p>
  <p><b>作者</b>：Yun-Wei Chu,  Seyyedali Hosseinalipour,  Elizabeth Tenorio,  Laura Cruz,  Kerrie Douglas,  Andrew Lan,  Christopher Brinton</p>
  <p><b>备注</b>：arXiv admin note: substantial text overlap with arXiv:2208.01182</p>
  <p><b>关键词</b>：Traditional learning-based approaches, predicting grades based, minority student groups, Personalized Federated Learning, student groups due</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Traditional learning-based approaches to student modeling (e.g., predicting
grades based on measured activities) generalize poorly to
underrepresented/minority student groups due to biases in data availability. In
this paper, we propose a Multi-Layer Personalized Federated Learning (MLPFL)
methodology which optimizes inference accuracy over different layers of student
grouping criteria, such as by course and by demographic subgroups within each
course. In our approach, personalized models for individual student subgroups
are derived from a global model, which is trained in a distributed fashion via
meta-gradient updates that account for subgroup heterogeneity while preserving
modeling commonalities that exist across the full dataset. To evaluate our
methodology, we consider case studies of two popular downstream student
modeling tasks, knowledge tracing and outcome prediction, which leverage
multiple modalities of student behavior (e.g., visits to lecture videos and
participation on forums) in model training. Experiments on three real-world
datasets from online courses demonstrate that our approach obtains substantial
improvements over existing student modeling baselines in terms of increasing
the average and decreasing the variance of prediction quality across different
student subgroups. Visual analysis of the resulting students' knowledge state
embeddings confirm that our personalization methodology extracts activity
patterns which cluster into different student subgroups, consistent with the
performance enhancements we obtain over the baselines.</p>
  </details>
</details>
<details>
  <summary>32. <b>标题：Denoising diffusion probabilistic models for probabilistic energy  forecasting</b></summary>
  <p><b>编号</b>：[104]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02977</p>
  <p><b>作者</b>：Esteban Hernandez,  Jonathan Dumas</p>
  <p><b>备注</b>：Version submitted to Powertech 2023. arXiv admin note: text overlap with arXiv:2106.09370, arXiv:2107.01034</p>
  <p><b>关键词</b>：Scenario-based probabilistic forecasts, renewable energies, vital tool, tool to equip, equip decision-makers</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Scenario-based probabilistic forecasts have become a vital tool to equip
decision-makers to address the uncertain nature of renewable energies. This
paper presents a recent promising deep learning generative approach: denoising
diffusion probabilistic models. It is a class of latent variable models that
have recently demonstrated impressive results in the computer vision community.
However, to the best of our knowledge, there has yet to be a demonstration that
they can generate high-quality samples of load, PV, or wind power time series
that are crucial to face the new challenges in power systems applications.
Thus, we propose the first implementation of this model for energy forecasting
using the open data of the Global Energy Forecasting Competition 2014. The
results demonstrate that this approach is competitive with other
state-of-the-art deep learning generative models: generative adversarial
networks, variational autoencoders, and normalizing flows.</p>
  </details>
</details>
<details>
  <summary>33. <b>标题：Safe Imitation Learning of Nonlinear Model Predictive Control for  Flexible Robots</b></summary>
  <p><b>编号</b>：[115]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02941</p>
  <p><b>作者</b>：Shamil Mamedov,  Rudolf Reiter,  Moritz Diehl,  Jan Swevers</p>
  <p><b>备注</b>：Submitted to L4DC conference</p>
  <p><b>关键词</b>：Flexible robots, safe human-robot collaboration, collaboration and increased, NMPC, human-robot collaboration</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Flexible robots may overcome the industry's major problems: safe human-robot
collaboration and increased load-to-mass ratio. However, oscillations and high
dimensional state space complicate the control of flexible robots. This work
investigates nonlinear model predictive control (NMPC) of flexible robots --
for simultaneous planning and control -- modeled via the rigid finite element
method. Although NMPC performs well in simulation, computational complexity
prevents its deployment in practice. We show that imitation learning of NMPC
with neural networks as function approximator can massively improve the
computation time of the controller at the cost of slight performance loss and,
more critically, loss of safety guarantees. We leverage a safety filter
formulated as a simpler NMPC to recover safety guarantees. Experiments on a
simulated three degrees of freedom flexible robot manipulator demonstrate that
the average computational time of the proposed safe approximate NMPC controller
is 3.6 ms while of the original NMPC is 11.8 ms. Fast and safe approximate NMPC
might facilitate the industry's adoption of flexible robots and new solutions
for similar problems, e.g., deformable object manipulation and soft robot
control.</p>
  </details>
</details>
<details>
  <summary>34. <b>标题：Yggdrasil Decision Forests: A Fast and Extensible Decision Forests  Library</b></summary>
  <p><b>编号</b>：[119]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02934</p>
  <p><b>作者</b>：Mathieu Guillame-Bert,  Sebastian Bruch,  Richard Stotz,  Jan Pfeifer</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Yggdrasil Decision Forests, decision forest models, TensorFlow Decision Forests, Decision Forests, command line interface</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Yggdrasil Decision Forests is a library for the training, serving and
interpretation of decision forest models, targeted both at research and
production work, implemented in C++, and available in C++, command line
interface, Python (under the name TensorFlow Decision Forests), JavaScript, and
Go. The library has been developed organically since 2018 following a set of
four design principles applicable to machine learning libraries and frameworks:
simplicity of use, safety of use, modularity and high-level abstraction, and
integration with other machine learning libraries. In this paper, we describe
those principles in detail and present how they have been used to guide the
design of the library. We then showcase the use of our library on a set of
classical machine learning problems. Finally, we report a benchmark comparing
our library to related solutions.</p>
  </details>
</details>
<details>
  <summary>35. <b>标题：Leveraging Different Learning Styles for Improved Knowledge Distillation</b></summary>
  <p><b>编号</b>：[121]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02931</p>
  <p><b>作者</b>：Usma Niyaz,  Deepti R. Bathula</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：training mechanism adopted, Learning style refers, style refers, training mechanism, mechanism adopted</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Learning style refers to a type of training mechanism adopted by an
individual to gain new knowledge. As suggested by the VARK model, humans have
different learning preferences like visual, auditory, etc., for acquiring and
effectively processing information. Inspired by this concept, our work explores
the idea of mixed information sharing with model compression in the context of
Knowledge Distillation (KD) and Mutual Learning (ML). Unlike conventional
techniques that share the same type of knowledge with all networks, we propose
to train individual networks with different forms of information to enhance the
learning process. We formulate a combined KD and ML framework with one teacher
and two student networks that share or exchange information in the form of
predictions and feature maps. Our comprehensive experiments with benchmark
classification and segmentation datasets demonstrate that with 15% compression,
the ensemble performance of networks trained with diverse forms of knowledge
outperforms the conventional techniques both quantitatively and qualitatively.</p>
  </details>
</details>
<details>
  <summary>36. <b>标题：Trajectory Flow Map: Graph-based Approach to Analysing Temporal  Evolution of Aggregated Traffic Flows in Large-scale Urban Networks</b></summary>
  <p><b>编号</b>：[123]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02927</p>
  <p><b>作者</b>：Jiwon Kim,  Kai Zheng,  Jonathan Corcoran,  Sanghyung Ahn,  Marty Papamanolis</p>
  <p><b>备注</b>：20 pages, 5 figures; Presented at the 96th Annual Meeting of the Transportation Research Board, January 2017</p>
  <p><b>关键词</b>：representing spatio-temporal trajectory, spatio-temporal trajectory data, paper proposes, proposes a graph-based, graph-based approach</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper proposes a graph-based approach to representing spatio-temporal
trajectory data that allows an effective visualization and characterization of
city-wide traffic dynamics. With the advance of sensor, mobile, and Internet of
Things (IoT) technologies, vehicle and passenger trajectories are being
increasingly collected on a massive scale and are becoming a critical source of
insight into traffic pattern and traveller behaviour. To leverage such
trajectory data to better understand traffic dynamics in a large-scale urban
network, this study develops a trajectory-based network traffic analysis method
that converts individual trajectory data into a sequence of graphs that evolve
over time (known as dynamic graphs or time-evolving graphs) and analyses
network-wide traffic patterns in terms of a compact and informative
graph-representation of aggregated traffic flows. First, we partition the
entire network into a set of cells based on the spatial distribution of data
points in individual trajectories, where the cells represent spatial regions
between which aggregated traffic flows can be measured. Next, dynamic flows of
moving objects are represented as a time-evolving graph, where regions are
graph vertices and flows between them are treated as weighted directed edges.
Given a fixed set of vertices, edges can be inserted or removed at every time
step depending on the presence of traffic flows between two regions at a given
time window. Once a dynamic graph is built, we apply graph mining algorithms to
detect change-points in time, which represent time points where the graph
exhibits significant changes in its overall structure and, thus, correspond to
change-points in city-wide mobility pattern throughout the day (e.g., global
transition points between peak and off-peak periods).</p>
  </details>
</details>
<details>
  <summary>37. <b>标题：Controlled Text Generation using T5 based Encoder-Decoder Soft Prompt  Tuning and Analysis of the Utility of Generated Text in AI</b></summary>
  <p><b>编号</b>：[124]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02924</p>
  <p><b>作者</b>：Damith Chamalke Senadeera,  Julia Ive</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：natural language processing, language processing due, Controlled text generation, promising applications, Controlled text</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Controlled text generation is a very important task in the arena of natural
language processing due to its promising applications. In order to achieve this
task we mainly introduce the novel soft prompt tuning method of using soft
prompts at both encoder and decoder levels together in a T5 model and
investigate the performance as the behaviour of an additional soft prompt
related to the decoder of a T5 model in controlled text generation remained
unexplored. Then we also investigate the feasibility of steering the output of
this extended soft prompted T5 model at decoder level and finally analyse the
utility of generated text to be used in AI related tasks such as training AI
models with an interpretability analysis of the classifier trained with
synthetic text, as there is a lack of proper analysis of methodologies in
generating properly labelled data to be utilized in AI tasks. Through the
performed in-depth intrinsic and extrinsic evaluations of this generation model
along with the artificially generated data, we found that this model produced
better results compared to the T5 model with a single soft prompt at encoder
level and the sentiment classifier trained using this artificially generated
data can produce comparable classification results to the results of a
classifier trained with real labelled data and also the classifier decision is
interpretable with respect to the input text content.</p>
  </details>
</details>
<details>
  <summary>38. <b>标题：Loss Adapted Plasticity in Deep Neural Networks to Learn from Data with  Unreliable Sources</b></summary>
  <p><b>编号</b>：[134]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02895</p>
  <p><b>作者</b>：Alexander Capstick,  Francesca Palermo,  Payam Barnaghi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：conventional training methods, data, sources, streaming from multiple, training methods update</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>When data is streaming from multiple sources, conventional training methods
update model weights often assuming the same level of reliability for each
source; that is: a model does not consider data quality of each source during
training. In many applications, sources can have varied levels of noise or
corruption that has negative effects on the learning of a robust deep learning
model. A key issue is that the quality of data or labels for individual sources
is often not available during training and could vary over time. Our solution
to this problem is to consider the mistakes made while training on data
originating from sources and utilise this to create a perceived data quality
for each source. This paper demonstrates a straight-forward and novel technique
that can be applied to any gradient descent optimiser: Update model weights as
a function of the perceived reliability of data sources within a wider data
set. The algorithm controls the plasticity of a given model to weight updates
based on the history of losses from individual data sources. We show that
applying this technique can significantly improve model performance when
trained on a mixture of reliable and unreliable data sources, and maintain
performance when models are trained on data sources that are all considered
reliable. All code to reproduce this work's experiments and implement the
algorithm in the reader's own models is made available.</p>
  </details>
</details>
<details>
  <summary>39. <b>标题：GAS-Net: Generative Artistic Style Neural Networks for Fonts</b></summary>
  <p><b>编号</b>：[136]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02886</p>
  <p><b>作者</b>：Haoyang He,  Xin Jin,  Angela Chen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：time-consuming and labor-intensive, huge amount, characters like Chinese, Chinese, Generating new fonts</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Generating new fonts is a time-consuming and labor-intensive, especially in a
language with a huge amount of characters like Chinese. Various deep learning
models have demonstrated the ability to efficiently generate new fonts with a
few reference characters of that style. This project aims to develop a few-shot
cross-lingual font generator based on AGIS-Net and improve the performance
metrics mentioned. Our approaches include redesigning the encoder and the loss
function. We will validate our method on multiple languages and datasets
mentioned.</p>
  </details>
</details>
<details>
  <summary>40. <b>标题：RBF-MGN:Solving spatiotemporal PDEs with Physics-informed Graph Neural  Network</b></summary>
  <p><b>编号</b>：[146]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02861</p>
  <p><b>作者</b>：Zixue Xiang,  Wei Peng,  Wen Yao</p>
  <p><b>备注</b>：21 pages,20 figures</p>
  <p><b>关键词</b>：received significant attention, representative deep learning-based, deep learning-based technique, solving partial differential, received significant</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Physics-informed neural networks (PINNs) have lately received significant
attention as a representative deep learning-based technique for solving partial
differential equations (PDEs). Most fully connected network-based PINNs use
automatic differentiation to construct loss functions that suffer from slow
convergence and difficult boundary enforcement. In addition, although
convolutional neural network (CNN)-based PINNs can significantly improve
training efficiency, CNNs have difficulty in dealing with irregular geometries
with unstructured meshes. Therefore, we propose a novel framework based on
graph neural networks (GNNs) and radial basis function finite difference
(RBF-FD). We introduce GNNs into physics-informed learning to better handle
irregular domains with unstructured meshes. RBF-FD is used to construct a
high-precision difference format of the differential equations to guide model
training. Finally, we perform numerical experiments on Poisson and wave
equations on irregular domains. We illustrate the generalizability, accuracy,
and efficiency of the proposed algorithms on different PDE parameters, numbers
of collection points, and several types of RBFs.</p>
  </details>
</details>
<details>
  <summary>41. <b>标题：VISEM-Tracking: Human Spermatozoa Tracking Dataset</b></summary>
  <p><b>编号</b>：[152]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02842</p>
  <p><b>作者</b>：Vajira Thambawita,  Steven A. Hicks,  Andrea M. Storås,  Thu Nguyen,  Jorunn M. Andersen,  Oliwia Witczak,  Trine B. Haugen,  Hugo L. Hammer,  Pål Halvorsen,  Michael A. Riegler</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：causing inconsistencies, tremendous task, task for biologists, biologists due, Manually analyzing spermatozoa</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Manually analyzing spermatozoa is a tremendous task for biologists due to the
many fast-moving spermatozoa, causing inconsistencies in the quality of the
assessments. Therefore, computer-assisted sperm analysis (CASA) has become a
popular solution. Despite this, more data is needed to train supervised machine
learning approaches in order to improve accuracy and reliability. In this
regard, we provide a dataset called VISEM-Tracking with 20 video recordings of
30s of spermatozoa with manually annotated bounding-box coordinates and a set
of sperm characteristics analyzed by experts in the domain. VISEM-Tracking is
an extension of the previously published VISEM dataset. In addition to the
annotated data, we provide unlabeled video clips for easy-to-use access and
analysis of the data. As part of this paper, we present baseline sperm
detection performances using the YOLOv5 deep learning model trained on the
VISEM-Tracking dataset. As a result, the dataset can be used to train complex
deep-learning models to analyze spermatozoa. The dataset is publicly available
at this https URL.</p>
  </details>
</details>
<details>
  <summary>42. <b>标题：Pretrained Diffusion Models for Unified Human Motion Synthesis</b></summary>
  <p><b>编号</b>：[153]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02837</p>
  <p><b>作者</b>：Jianxin Ma,  Shuai Bai,  Chang Zhou</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：virtual reality, Generative modeling, computer animation, modeling of human, broad applications</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Generative modeling of human motion has broad applications in computer
animation, virtual reality, and robotics. Conventional approaches develop
separate models for different motion synthesis tasks, and typically use a model
of a small size to avoid overfitting the scarce data available in each setting.
It remains an open question whether developing a single unified model is
feasible, which may 1) benefit the acquirement of novel skills by combining
skills learned from multiple tasks, and 2) help in increasing the model
capacity without overfitting by combining multiple data sources. Unification is
challenging because 1) it involves diverse control signals as well as targets
of varying granularity, and 2) motion datasets may use different skeletons and
default poses. In this paper, we present MoFusion, a framework for unified
motion synthesis. MoFusion employs a Transformer backbone to ease the inclusion
of diverse control signals via cross attention, and pretrains the backbone as a
diffusion model to support multi-granularity synthesis ranging from motion
completion of a body part to whole-body motion generation. It uses a learnable
adapter to accommodate the differences between the default skeletons used by
the pretraining and the fine-tuning data. Empirical results show that
pretraining is vital for scaling the model size without overfitting, and
demonstrate MoFusion's potential in various tasks, e.g., text-to-motion, motion
completion, and zero-shot mixing of multiple control signals. Project page:
\url{this https URL}.</p>
  </details>
</details>
<details>
  <summary>43. <b>标题：Mixer: DNN Watermarking using Image Mixup</b></summary>
  <p><b>编号</b>：[158]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02814</p>
  <p><b>作者</b>：Kassem Kallas,  Teddy Furon</p>
  <p><b>备注</b>：arXiv admin note: text overlap with arXiv:2206.11024</p>
  <p><b>关键词</b>：DNN models prior, crucial to protect, protect the intellectual, intellectual property, DNN</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>It is crucial to protect the intellectual property rights of DNN models prior
to their deployment. The DNN should perform two main tasks: its primary task
and watermarking task. This paper proposes a lightweight, reliable, and secure
DNN watermarking that attempts to establish strong ties between these two
tasks. The samples triggering the watermarking task are generated using image
Mixup either from training or testing samples. This means that there is an
infinity of triggers not limited to the samples used to embed the watermark in
the model at training. The extensive experiments on image classification models
for different datasets as well as exposing them to a variety of attacks, show
that the proposed watermarking provides protection with an adequate level of
security and robustness.</p>
  </details>
</details>
<details>
  <summary>44. <b>标题：Data Imputation with Iterative Graph Reconstruction</b></summary>
  <p><b>编号</b>：[160]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02810</p>
  <p><b>作者</b>：Jiajun Zhong,  Weiwei Ye,  Ning Gui</p>
  <p><b>备注</b>：Accepted by AAAI2023</p>
  <p><b>关键词</b>：demands rich latent, imputation demands rich, rich latent, discovery capabilities, demands rich</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Effective data imputation demands rich latent ``structure" discovery
capabilities from ``plain" tabular data. Recent advances in graph neural
networks-based data imputation solutions show their strong structure learning
potential by directly translating tabular data as bipartite graphs. However,
due to a lack of relations between samples, those solutions treat all samples
equally which is against one important observation: ``similar sample should
give more information about missing values." This paper presents a novel
Iterative graph Generation and Reconstruction framework for Missing data
imputation(IGRM). Instead of treating all samples equally, we introduce the
concept: ``friend networks" to represent different relations among samples. To
generate an accurate friend network with missing data, an end-to-end friend
network reconstruction solution is designed to allow for continuous friend
network optimization during imputation learning. The representation of the
optimized friend network, in turn, is used to further optimize the data
imputation process with differentiated message passing. Experiment results on
eight benchmark datasets show that IGRM yields 39.13% lower mean absolute error
compared with nine baselines and 9.04% lower than the second-best.</p>
  </details>
</details>
<details>
  <summary>45. <b>标题：Diffusion Video Autoencoders: Toward Temporally Consistent Face Video  Editing via Disentangled Video Encoding</b></summary>
  <p><b>编号</b>：[163]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02802</p>
  <p><b>作者</b>：Gyeongman Kim,  Hajin Shim,  Hyunsu Kim,  Yunjey Choi,  Junho Kim,  Eunho Yang</p>
  <p><b>备注</b>：The code will be available soon</p>
  <p><b>关键词</b>：face video editing, recent face image, video editing task, face image editing, image editing methods</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Inspired by the impressive performance of recent face image editing methods,
several studies have been naturally proposed to extend these methods to the
face video editing task. One of the main challenges here is temporal
consistency among edited frames, which is still unresolved. To this end, we
propose a novel face video editing framework based on diffusion autoencoders
that can successfully extract the decomposed features - for the first time as a
face video editing model - of identity and motion from a given video. This
modeling allows us to edit the video by simply manipulating the temporally
invariant feature to the desired direction for the consistency. Another unique
strength of our model is that, since our model is based on diffusion models, it
can satisfy both reconstruction and edit capabilities at the same time, and is
robust to corner cases in wild face videos (e.g. occluded faces) unlike the
existing GAN-based methods.</p>
  </details>
</details>
<details>
  <summary>46. <b>标题：Dist-PU: Positive-Unlabeled Learning from a Label Distribution  Perspective</b></summary>
  <p><b>编号</b>：[164]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02801</p>
  <p><b>作者</b>：Yunrui Zhao,  Qianqian Xu,  Yangbangyan Jiang,  Peisong Wen,  Qingming Huang</p>
  <p><b>备注</b>：Accepted at CVPR 2022</p>
  <p><b>关键词</b>：learn binary classifiers, label distribution, label distribution consistency, learn binary, labeled positive</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Positive-Unlabeled (PU) learning tries to learn binary classifiers from a few
labeled positive examples with many unlabeled ones. Compared with ordinary
semi-supervised learning, this task is much more challenging due to the absence
of any known negative labels. While existing cost-sensitive-based methods have
achieved state-of-the-art performances, they explicitly minimize the risk of
classifying unlabeled data as negative samples, which might result in a
negative-prediction preference of the classifier. To alleviate this issue, we
resort to a label distribution perspective for PU learning in this paper.
Noticing that the label distribution of unlabeled data is fixed when the class
prior is known, it can be naturally used as learning supervision for the model.
Motivated by this, we propose to pursue the label distribution consistency
between predicted and ground-truth label distributions, which is formulated by
aligning their expectations. Moreover, we further adopt the entropy
minimization and Mixup regularization to avoid the trivial solution of the
label distribution consistency on unlabeled data and mitigate the consequent
confirmation bias. Experiments on three benchmark datasets validate the
effectiveness of the proposed method.Code available at:
this https URL.</p>
  </details>
</details>
<details>
  <summary>47. <b>标题：A K-variate Time Series Is Worth K Words: Evolution of the Vanilla  Transformer Architecture for Long-term Multivariate Time Series Forecasting</b></summary>
  <p><b>编号</b>：[171]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02789</p>
  <p><b>作者</b>：Zanwei Zhou,  Ruizhe Zhong,  Chen Yang,  Yan Wang,  Xiaokang Yang,  Wei Shen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：vanilla MTSF transformer, MTSF Transformer, MTSF Transformer architectures, numerous real-world applications, MTSF</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Multivariate time series forecasting (MTSF) is a fundamental problem in
numerous real-world applications. Recently, Transformer has become the de facto
solution for MTSF, especially for the long-term cases. However, except for the
one forward operation, the basic configurations in existing MTSF Transformer
architectures were barely carefully verified. In this study, we point out that
the current tokenization strategy in MTSF Transformer architectures ignores the
token uniformity inductive bias of Transformers. Therefore, the vanilla MTSF
transformer struggles to capture details in time series and presents inferior
performance. Based on this observation, we make a series of evolution on the
basic architecture of the vanilla MTSF transformer. We vary the flawed
tokenization strategy, along with the decoder structure and embeddings.
Surprisingly, the evolved simple transformer architecture is highly effective,
which successfully avoids the over-smoothing phenomena in the vanilla MTSF
transformer, achieves a more detailed and accurate prediction, and even
substantially outperforms the state-of-the-art Transformers that are
well-designed for MTSF.</p>
  </details>
</details>
<details>
  <summary>48. <b>标题：QEBVerif: Quantization Error Bound Verification of Neural Networks</b></summary>
  <p><b>编号</b>：[173]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02781</p>
  <p><b>作者</b>：Yedi Zhang,  Fu Song,  Jun Sun</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：demonstrated impressive performance, resource-constrained devices owing, deep neural networks, neural networks, challenging tasks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>While deep neural networks (DNNs) have demonstrated impressive performance in
solving many challenging tasks, they are limited to resource-constrained
devices owing to their demand for computation power and storage space.
Quantization is one of the most promising techniques to address this issue by
quantizing the weights and/or activation tensors of a DNN into lower bit-width
fixed-point numbers. While quantization has been empirically shown to introduce
minor accuracy loss, it lacks formal guarantees on that, especially when the
resulting quantized neural networks (QNNs) are deployed in safety-critical
applications. A majority of existing verification methods focus exclusively on
individual neural networks, either DNNs or QNNs. While promising attempts have
been made to verify the quantization error bound between DNNs and their
quantized counterparts, they are not complete and more importantly do not
support fully quantified neural networks, namely, only weights are quantized.
To fill this gap, in this work, we propose a quantization error bound
verification method (QEBVerif), where both weights and activation tensors are
quantized. QEBVerif consists of two analyses: a differential reachability
analysis (DRA) and a mixed-integer linear programming (MILP) based verification
method. DRA performs difference analysis between the DNN and its quantized
counterpart layer-by-layer to efficiently compute a tight quantization error
interval. If it fails to prove the error bound, then we encode the verification
problem into an equivalent MILP problem which can be solved by off-the-shelf
solvers. Thus, QEBVerif is sound, complete, and arguably efficient. We
implement QEBVerif in a tool and conduct extensive experiments, showing its
effectiveness and efficiency.</p>
  </details>
</details>
<details>
  <summary>49. <b>标题：PrefRec: Preference-based Recommender Systems for Reinforcing Long-term  User Engagement</b></summary>
  <p><b>编号</b>：[175]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02779</p>
  <p><b>作者</b>：Wanqi Xue,  Qingpeng Cai,  Zhenghai Xue,  Shuo Sun,  Shuchang Liu,  Dong Zheng,  Peng Jiang,  Bo An</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：long-term user engagement, long-term user, user engagement, Current advances, remarkably successful</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Current advances in recommender systems have been remarkably successful in
optimizing immediate engagement. However, long-term user engagement, a more
desirable performance metric, remains difficult to improve. Meanwhile, recent
reinforcement learning (RL) algorithms have shown their effectiveness in a
variety of long-term goal optimization tasks. For this reason, RL is widely
considered as a promising framework for optimizing long-term user engagement in
recommendation. Despite being a promising approach, the application of RL
heavily relies on well-designed rewards, but designing rewards related to
long-term user engagement is quite difficult. To mitigate the problem, we
propose a novel paradigm, Preference-based Recommender systems (PrefRec), which
allows RL recommender systems to learn from preferences about users' historical
behaviors rather than explicitly defined rewards. Such preferences are easily
accessible through techniques such as crowdsourcing, as they do not require any
expert knowledge. With PrefRec, we can fully exploit the advantages of RL in
optimizing long-term goals, while avoiding complex reward engineering. PrefRec
uses the preferences to automatically train a reward function in an end-to-end
manner. The reward function is then used to generate learning signals to train
the recommendation policy. Furthermore, we design an effective optimization
method for PrefRec, which uses an additional value function, expectile
regression and reward model pre-training to improve the performance. Extensive
experiments are conducted on a variety of long-term user engagement
optimization tasks. The results show that PrefRec significantly outperforms
previous state-of-the-art methods in all the tasks.</p>
  </details>
</details>
<details>
  <summary>50. <b>标题：Tackling Data Heterogeneity in Federated Learning with Class Prototypes</b></summary>
  <p><b>编号</b>：[185]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02758</p>
  <p><b>作者</b>：Yutong Dai,  Zeyuan Chen,  Junnan Li,  Shelby Heinecke,  Lichao Sun,  Ran Xu</p>
  <p><b>备注</b>：Accepted for presentation at AAAI 2023. This is a technical report version that contains an appendix with additional details about experiments and proofs for technical results</p>
  <p><b>关键词</b>：widely acknowledged challenge, local models, federated learning, personalized federated learning, models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Data heterogeneity across clients in federated learning (FL) settings is a
widely acknowledged challenge. In response, personalized federated learning
(PFL) emerged as a framework to curate local models for clients' tasks. In PFL,
a common strategy is to develop local and global models jointly - the global
model (for generalization) informs the local models, and the local models (for
personalization) are aggregated to update the global model. A key observation
is that if we can improve the generalization ability of local models, then we
can improve the generalization of global models, which in turn builds better
personalized models. In this work, we consider class imbalance, an overlooked
type of data heterogeneity, in the classification setting. We propose FedNH, a
novel method that improves the local models' performance for both
personalization and generalization by combining the uniformity and semantics of
class prototypes. FedNH initially distributes class prototypes uniformly in the
latent space and smoothly infuses the class semantics into class prototypes. We
show that imposing uniformity helps to combat prototype collapse while infusing
class semantics improves local models. Extensive experiments were conducted on
popular classification datasets under the cross-device setting. Our results
demonstrate the effectiveness and stability of our method over recent works.</p>
  </details>
</details>
<details>
  <summary>51. <b>标题：Safe Inverse Reinforcement Learning via Control Barrier Function</b></summary>
  <p><b>编号</b>：[189]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02753</p>
  <p><b>作者</b>：Yue Yang,  Letian Chen,  Matthew Gombolay</p>
  <p><b>备注</b>：6 pages, 3 figures</p>
  <p><b>关键词</b>：Inverse Reinforcement Learning, reinforcement learning, desired skill, efficiently learn, Inverse Reinforcement</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Learning from Demonstration (LfD) is a powerful method for enabling robots to
perform novel tasks as it is often more tractable for a non-roboticist end-user
to demonstrate the desired skill and for the robot to efficiently learn from
the associated data than for a human to engineer a reward function for the
robot to learn the skill via reinforcement learning (RL). Safety issues arise
in modern LfD techniques, e.g., Inverse Reinforcement Learning (IRL), just as
they do for RL; yet, safe learning in LfD has received little attention. In the
context of agile robots, safety is especially vital due to the possibility of
robot-environment collision, robot-human collision, and damage to the robot. In
this paper, we propose a safe IRL framework, CBFIRL, that leverages the Control
Barrier Function (CBF) to enhance the safety of the IRL policy. The core idea
of CBFIRL is to combine a loss function inspired by CBF requirements with the
objective in an IRL method, both of which are jointly optimized via gradient
descent. In the experiments, we show our framework performs safer compared to
IRL methods without CBF, that is $\sim15\%$ and $\sim20\%$ improvement for two
levels of difficulty of a 2D racecar domain and $\sim 50\%$ improvement for a
3D drone domain.</p>
  </details>
</details>
<details>
  <summary>52. <b>标题：Improving Molecule Properties Through 2-Stage VAE</b></summary>
  <p><b>编号</b>：[192]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02750</p>
  <p><b>作者</b>：Chenghui Zhou,  Barnabas Poczos</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Variational autoencoder, great deal, deal of architectures, architectures and pipelines, pipelines proposed</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Variational autoencoder (VAE) is a popular method for drug discovery and
there had been a great deal of architectures and pipelines proposed to improve
its performance. But the VAE model itself suffers from deficiencies such as
poor manifold recovery when data lie on low-dimensional manifold embedded in
higher dimensional ambient space and they manifest themselves in each
applications differently. The consequences of it in drug discovery is somewhat
under-explored. In this paper, we study how to improve the similarity of the
data generated via VAE and the training dataset by improving manifold recovery
via a 2-stage VAE where the second stage VAE is trained on the latent space of
the first one. We experimentally evaluated our approach using the ChEMBL
dataset as well as a polymer datasets. In both dataset, the 2-stage VAE method
is able to improve the property statistics significantly from a pre-existing
method.</p>
  </details>
</details>
<details>
  <summary>53. <b>标题：UniGeo: Unifying Geometry Logical Reasoning via Reformulating  Mathematical Expression</b></summary>
  <p><b>编号</b>：[195]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02746</p>
  <p><b>作者</b>：Jiaqi Chen,  Tong Li,  Jinghui Qin,  Pan Lu,  Liang Lin,  Chongyu Chen,  Xiaodan Liang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：high-level multi-modal reasoning, multi-modal reasoning capability, Geometry problem solving, well-recognized testbed, testbed for evaluating</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Geometry problem solving is a well-recognized testbed for evaluating the
high-level multi-modal reasoning capability of deep models. In most existing
works, two main geometry problems: calculation and proving, are usually treated
as two specific tasks, hindering a deep model to unify its reasoning capability
on multiple math tasks. However, in essence, these two tasks have similar
problem representations and overlapped math knowledge which can improve the
understanding and reasoning ability of a deep model on both two tasks.
Therefore, we construct a large-scale Unified Geometry problem benchmark,
UniGeo, which contains 4,998 calculation problems and 9,543 proving problems.
Each proving problem is annotated with a multi-step proof with reasons and
mathematical expressions. The proof can be easily reformulated as a proving
sequence that shares the same formats with the annotated program sequence for
calculation problems. Naturally, we also present a unified multi-task Geometric
Transformer framework, Geoformer, to tackle calculation and proving problems
simultaneously in the form of sequence generation, which finally shows the
reasoning ability can be improved on both two tasks by unifying formulation.
Furthermore, we propose a Mathematical Expression Pretraining (MEP) method that
aims to predict the mathematical expressions in the problem solution, thus
improving the Geoformer model. Experiments on the UniGeo demonstrate that our
proposed Geoformer obtains state-of-the-art performance by outperforming
task-specific model NGS with over 5.6% and 3.2% accuracies on calculation and
proving problems, respectively.</p>
  </details>
</details>
<details>
  <summary>54. <b>标题：A Learning Based Hypothesis Test for Harmful Covariate Shift</b></summary>
  <p><b>编号</b>：[198]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02742</p>
  <p><b>作者</b>：Tom Ginsberg,  Zhongyuan Liang,  Rahul G. Krishnan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：safe machine learning, machine learning systems, learning systems deployed, accurately identify covariate, identify covariate shift</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The ability to quickly and accurately identify covariate shift at test time
is a critical and often overlooked component of safe machine learning systems
deployed in high-risk domains. While methods exist for detecting when
predictions should not be made on out-of-distribution test examples,
identifying distributional level differences between training and test time can
help determine when a model should be removed from the deployment setting and
retrained. In this work, we define harmful covariate shift (HCS) as a change in
distribution that may weaken the generalization of a predictive model. To
detect HCS, we use the discordance between an ensemble of classifiers trained
to agree on training data and disagree on test data. We derive a loss function
for training this ensemble and show that the disagreement rate and entropy
represent powerful discriminative statistics for HCS. Empirically, we
demonstrate the ability of our method to detect harmful covariate shift with
statistical certainty on a variety of high-dimensional datasets. Across
numerous domains and modalities, we show state-of-the-art performance compared
to existing methods, particularly when the number of observed test samples is
small.</p>
  </details>
</details>
<details>
  <summary>55. <b>标题：Curriculum Learning for Relative Overgeneralization</b></summary>
  <p><b>编号</b>：[202]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02733</p>
  <p><b>作者</b>：Lin Shi,  Bei Peng</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：multi-agent reinforcement learning, tasks, target task, multi-agent reinforcement, joint action</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In multi-agent reinforcement learning (MARL), many popular methods, such as
VDN and QMIX, are susceptible to a critical multi-agent pathology known as
relative overgeneralization (RO), which arises when the optimal joint action's
utility falls below that of a sub-optimal joint action in cooperative tasks. RO
can cause the agents to get stuck into local optima or fail to solve tasks that
require significant coordination between agents within a given timestep. Recent
value-based MARL algorithms such as QPLEX and WQMIX can overcome RO to some
extent. However, our experimental results show that they can still fail to
solve cooperative tasks that exhibit strong RO. In this work, we propose a
novel approach called curriculum learning for relative overgeneralization
(CURO) to better overcome RO. To solve a target task that exhibits strong RO,
in CURO, we first fine-tune the reward function of the target task to generate
source tasks that are tailored to the current ability of the learning agent and
train the agent on these source tasks first. Then, to effectively transfer the
knowledge acquired in one task to the next, we use a novel transfer learning
method that combines value function transfer with buffer transfer, which
enables more efficient exploration in the target task. We demonstrate that,
when applied to QMIX, CURO overcomes severe RO problem and significantly
improves performance, yielding state-of-the-art results in a variety of
cooperative multi-agent tasks, including the challenging StarCraft II
micromanagement benchmarks.</p>
  </details>
</details>
<details>
  <summary>56. <b>标题：Decentralized Stochastic Gradient Descent Ascent for Finite-Sum Minimax  Problems</b></summary>
  <p><b>编号</b>：[206]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02724</p>
  <p><b>作者</b>：Hongchang Gao</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：machine learning models, attracted significant attention, recent years due, numerous machine learning, minimax optimization problem</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Minimax optimization problems have attracted significant attention in recent
years due to their widespread application in numerous machine learning models.
To solve the minimax optimization problem, a wide variety of stochastic
optimization methods have been proposed. However, most of them ignore the
distributed setting where the training data is distributed on multiple workers.
In this paper, we developed a novel decentralized stochastic gradient descent
ascent method for the finite-sum minimax optimization problem. In particular,
by employing the variance-reduced gradient, our method can achieve
$O(\frac{\sqrt{n}\kappa^3}{(1-\lambda)^2\epsilon^2})$ sample complexity and
$O(\frac{\kappa^3}{(1-\lambda)^2\epsilon^2})$ communication complexity for the
nonconvex-strongly-concave minimax optimization problem. As far as we know, our
work is the first one to achieve such theoretical complexities for this kind of
problem. At last, we apply our method to optimize the AUC maximization problem
and the experimental results confirm the effectiveness of our method.</p>
  </details>
</details>
<details>
  <summary>57. <b>标题：Efficient Learning of Voltage Control Strategies via Model-based Deep  Reinforcement Learning</b></summary>
  <p><b>编号</b>：[209]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02715</p>
  <p><b>作者</b>：Ramij R. Hossain,  Tianzhixi Yin,  Yan Du,  Renke Huang,  Jie Tan,  Wenhao Yu,  Yuan Liu,  Qiuhua Huang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：design emergency control, emergency control strategies, short-term voltage stability, voltage stability problems, design emergency</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This article proposes a model-based deep reinforcement learning (DRL) method
to design emergency control strategies for short-term voltage stability
problems in power systems. Recent advances show promising results in model-free
DRL-based methods for power systems, but model-free methods suffer from poor
sample efficiency and training time, both critical for making state-of-the-art
DRL algorithms practically applicable. DRL-agent learns an optimal policy via a
trial-and-error method while interacting with the real-world environment. And
it is desirable to minimize the direct interaction of the DRL agent with the
real-world power grid due to its safety-critical nature. Additionally,
state-of-the-art DRL-based policies are mostly trained using a physics-based
grid simulator where dynamic simulation is computationally intensive, lowering
the training efficiency. We propose a novel model-based-DRL framework where a
deep neural network (DNN)-based dynamic surrogate model, instead of a
real-world power-grid or physics-based simulation, is utilized with the policy
learning framework, making the process faster and sample efficient. However,
stabilizing model-based DRL is challenging because of the complex system
dynamics of large-scale power systems. We solved these issues by incorporating
imitation learning to have a warm start in policy learning, reward-shaping, and
multi-step surrogate loss. Finally, we achieved 97.5% sample efficiency and
87.7% training efficiency for an application to the IEEE 300-bus test system.</p>
  </details>
</details>
<details>
  <summary>58. <b>标题：Improved Beam Search for Hallucination Mitigation in Abstractive  Summarization</b></summary>
  <p><b>编号</b>：[210]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02712</p>
  <p><b>作者</b>：Arvind Krishna Sridhar,  Erik Visser</p>
  <p><b>备注</b>：8 pages, 2 figures</p>
  <p><b>关键词</b>：generation tasks including, large pretrained language, pretrained language models, tasks including summarization, including summarization albeit</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Advancement in large pretrained language models has significantly improved
their performance for conditional language generation tasks including
summarization albeit with hallucinations. To reduce hallucinations,
conventional methods proposed improving beam search or using a fact checker as
a postprocessing step. In this paper, we investigate the use of the Natural
Language Inference (NLI) entailment metric to detect and prevent hallucinations
in summary generation. We propose an NLI-assisted beam re-ranking mechanism by
computing entailment probability scores between the input context and
summarization model-generated beams during saliency-enhanced greedy decoding.
Moreover, a diversity metric is introduced to compare its effectiveness against
vanilla beam search. Our proposed algorithm significantly outperforms vanilla
beam decoding on XSum and CNN/DM datasets.</p>
  </details>
</details>
<details>
  <summary>59. <b>标题：Beyond Object Recognition: A New Benchmark towards Object Concept  Learning</b></summary>
  <p><b>编号</b>：[211]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02710</p>
  <p><b>作者</b>：Yong-Lu Li,  Yue Xu,  Xinyu Xu,  Xiaohan Mao,  Yuan Yao,  Siqi Liu,  Cewu Lu</p>
  <p><b>备注</b>：Preprint. Webpage: this https URL</p>
  <p><b>关键词</b>：central building block, object, Object Concept Learning, artificial intelligence, Object Concept</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Understanding objects is a central building block of artificial intelligence,
especially for embodied AI. Even though object recognition excels with deep
learning, current machines still struggle to learn higher-level knowledge,
e.g., what attributes an object has, and what can we do with an object. In this
work, we propose a challenging Object Concept Learning (OCL) task to push the
envelope of object understanding. It requires machines to reason out object
affordances and simultaneously give the reason: what attributes make an object
possesses these affordances. To support OCL, we build a densely annotated
knowledge base including extensive labels for three levels of object concept
(category, attribute, affordance), and the causal relations of three levels. By
analyzing the causal structure of OCL, we present a baseline, Object Concept
Reasoning Network (OCRN). It leverages causal intervention and concept
instantiation to infer the three levels following their causal relations. In
experiments, OCRN effectively infers the object knowledge while following the
causalities well. Our data and code are available at this https URL.</p>
  </details>
</details>
<details>
  <summary>60. <b>标题：Benchmarking AutoML algorithms on a collection of binary problems</b></summary>
  <p><b>编号</b>：[214]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02704</p>
  <p><b>作者</b>：Pedro Henrique Ribeiro,  Patryk Orzechowski,  Joost Wagenaar,  Jason H. Moore</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：grown in popularity, popularity due, flexibility to adapt, AutoML algorithms, AutoML</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Automated machine learning (AutoML) algorithms have grown in popularity due
to their high performance and flexibility to adapt to different problems and
data sets. With the increasing number of AutoML algorithms, deciding which
would best suit a given problem becomes increasingly more work. Therefore, it
is essential to use complex and challenging benchmarks which would be able to
differentiate the AutoML algorithms from each other. This paper compares the
performance of four different AutoML algorithms: Tree-based Pipeline
Optimization Tool (TPOT), Auto-Sklearn, Auto-Sklearn 2, and H2O AutoML. We use
the Diverse and Generative ML benchmark (DIGEN), a diverse set of synthetic
datasets derived from generative functions designed to highlight the strengths
and weaknesses of the performance of common machine learning algorithms. We
confirm that AutoML can identify pipelines that perform well on all included
datasets. Most AutoML algorithms performed similarly without much room for
improvement; however, some were more consistent than others at finding
high-performing solutions for some datasets.</p>
  </details>
</details>
<details>
  <summary>61. <b>标题：Codex Hacks HackerRank: Memorization Issues and a Framework for Code  Synthesis Evaluation</b></summary>
  <p><b>编号</b>：[220]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02684</p>
  <p><b>作者</b>：Anjan Karmakar,  Julian Aron Prenner,  Marco D'Ambros,  Romain Robbes</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：demonstrated extraordinary competence, language problem descriptions, natural language problem, demonstrated extraordinary, extraordinary competence</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The Codex model has demonstrated extraordinary competence in synthesizing
code from natural language problem descriptions. However, in order to reveal
unknown failure modes and hidden biases, such large-scale models must be
systematically subjected to multiple and diverse evaluation studies.
In this work, we evaluate the code synthesis capabilities of the Codex model
based on a set of 115 Python problem statements from a popular competitive
programming portal: HackerRank. Our evaluation shows that Codex is indeed
proficient in Python, solving 96% of the problems in a zero-shot setting, and
100% of the problems in a few-shot setting. However, Codex exhibits clear signs
of generating memorized code based on our evaluation. This is alarming,
especially since the adoption and use of such models could directly impact how
code is written and produced in the foreseeable future. With this in mind, we
further discuss and highlight some of the prominent risks associated with
large-scale models of source code. Finally, we propose a framework for
code-synthesis evaluation using variations of problem statements based on
mutations.</p>
  </details>
</details>
<details>
  <summary>62. <b>标题：Transformers for End-to-End InfoSec Tasks: A Feasibility Study</b></summary>
  <p><b>编号</b>：[225]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02666</p>
  <p><b>作者</b>：Ethan M. Rudd,  Mohammad Saidur Rahman,  Philip Tully</p>
  <p><b>备注</b>：Post-print of a manuscript accepted to ACM Asia-CCS Workshop on Robust Malware Analysis (WoRMA) 2022. 11 Pages total. arXiv admin note: substantial text overlap with arXiv:2011.03040</p>
  <p><b>关键词</b>：assess the viability, models, transformer, transformer models, show</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we assess the viability of transformer models in end-to-end
InfoSec settings, in which no intermediate feature representations or
processing steps occur outside the model. We implement transformer models for
two distinct InfoSec data formats - specifically URLs and PE files - in a novel
end-to-end approach, and explore a variety of architectural designs, training
regimes, and experimental settings to determine the ingredients necessary for
performant detection models. We show that in contrast to conventional
transformers trained on more standard NLP-related tasks, our URL transformer
model requires a different training approach to reach high performance levels.
Specifically, we show that 1) pre-training on a massive corpus of unlabeled URL
data for an auto-regressive task does not readily transfer to binary
classification of malicious or benign URLs, but 2) that using an auxiliary
auto-regressive loss improves performance when training from scratch. We
introduce a method for mixed objective optimization, which dynamically balances
contributions from both loss terms so that neither one of them dominates. We
show that this method yields quantitative evaluation metrics comparable to that
of several top-performing benchmark classifiers. Unlike URLs, binary
executables contain longer and more distributed sequences of information-rich
bytes. To accommodate such lengthy byte sequences, we introduce additional
context length into the transformer by providing its self-attention layers with
an adaptive span similar to Sukhbaatar et al. We demonstrate that this approach
performs comparably to well-established malware detection models on benchmark
PE file datasets, but also point out the need for further exploration into
model improvements in scalability and compute efficiency.</p>
  </details>
</details>
<details>
  <summary>63. <b>标题：Efficient Malware Analysis Using Metric Embeddings</b></summary>
  <p><b>编号</b>：[226]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02663</p>
  <p><b>作者</b>：Ethan M. Rudd,  David Krisiloff,  Scott Coull,  Daniel Olszewski,  Edward Raff,  James Holt</p>
  <p><b>备注</b>：Pre-print of a manuscript submitted to the ACM Digital Threats: Research and Practice (DTRAP) Special Issue on Applied Machine Learning for Information Security. 19 Pages</p>
  <p><b>关键词</b>：including malware detection, malware attribute tagging, embed Windows, low-dimensional vector space, Windows PE files</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we explore the use of metric learning to embed Windows PE
files in a low-dimensional vector space for downstream use in a variety of
applications, including malware detection, family classification, and malware
attribute tagging. Specifically, we enrich labeling on malicious and benign PE
files using computationally expensive, disassembly-based malicious
capabilities. Using these capabilities, we derive several different types of
metric embeddings utilizing an embedding neural network trained via contrastive
loss, Spearman rank correlation, and combinations thereof. We then examine
performance on a variety of transfer tasks performed on the EMBER and SOREL
datasets, demonstrating that for several tasks, low-dimensional,
computationally efficient metric embeddings maintain performance with little
decay, which offers the potential to quickly retrain for a variety of transfer
tasks at significantly reduced storage overhead. We conclude with an
examination of practical considerations for the use of our proposed embedding
approach, such as robustness to adversarial evasion and introduction of
task-specific auxiliary objectives to improve performance on mission critical
tasks.</p>
  </details>
</details>
<details>
  <summary>64. <b>标题：Continual learning on deployment pipelines for Machine Learning Systems</b></summary>
  <p><b>编号</b>：[228]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02659</p>
  <p><b>作者</b>：Qiang Li,  Chongyu Zhang</p>
  <p><b>备注</b>：36th Conference on Neural Information Processing Systems (NeurIPS 2022). Accepted by blind review at DMML Workshop this https URL</p>
  <p><b>关键词</b>：large Original, development of digitization, growing number, number of large, machine learning systems</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Following the development of digitization, a growing number of large Original
Equipment Manufacturers (OEMs) are adapting computer vision or natural language
processing in a wide range of applications such as anomaly detection and
quality inspection in plants. Deployment of such a system is becoming an
extremely important topic. Our work starts with the least-automated deployment
technologies of machine learning systems includes several iterations of
updates, and ends with a comparison of automated deployment techniques. The
objective is, on the one hand, to compare the advantages and disadvantages of
various technologies in theory and practice, so as to facilitate later adopters
to avoid making the generalized mistakes when implementing actual use cases,
and thereby choose a better strategy for their own enterprises. On the other
hand, to raise awareness of the evaluation framework for the deployment of
machine learning systems, to have more comprehensive and useful evaluation
metrics (e.g. table 2), rather than only focusing on a single factor (e.g.
company cost). This is especially important for decision-makers in the
industry.</p>
  </details>
</details>
<details>
  <summary>65. <b>标题：Explaining Link Predictions in Knowledge Graph Embedding Models with  Influential Examples</b></summary>
  <p><b>编号</b>：[229]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02651</p>
  <p><b>作者</b>：Adrianna Janik,  Luca Costabello</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：explaining link predictions, Knowledge Graph, study the problem, problem of explaining, explaining link</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We study the problem of explaining link predictions in the Knowledge Graph
Embedding (KGE) models. We propose an example-based approach that exploits the
latent space representation of nodes and edges in a knowledge graph to explain
predictions. We evaluated the importance of identified triples by observing
progressing degradation of model performance upon influential triples removal.
Our experiments demonstrate that this approach to generate explanations
outperforms baselines on KGE models for two publicly available datasets.</p>
  </details>
</details>
<details>
  <summary>66. <b>标题：Thales: Formulating and Estimating Architectural Vulnerability Factors  for DNN Accelerators</b></summary>
  <p><b>编号</b>：[230]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02649</p>
  <p><b>作者</b>：Abhishek Tyagi,  Yiming Gan,  Shaoshan Liu,  Bo Yu,  Paul Whatmough,  Yuhao Zhu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Deep Neural Networks, Deep Neural, privacy sensitive applications, Neural Networks, Silent Data Corruption</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As Deep Neural Networks (DNNs) are increasingly deployed in safety critical
and privacy sensitive applications such as autonomous driving and biometric
authentication, it is critical to understand the fault-tolerance nature of
DNNs. Prior work primarily focuses on metrics such as Failures In Time (FIT)
rate and the Silent Data Corruption (SDC) rate, which quantify how often a
device fails. Instead, this paper focuses on quantifying the DNN accuracy given
that a transient error has occurred, which tells us how well a network behaves
when a transient error occurs. We call this metric Resiliency Accuracy (RA). We
show that existing RA formulation is fundamentally inaccurate, because it
incorrectly assumes that software variables (model weights/activations) have
equal faulty probability under hardware transient faults. We present an
algorithm that captures the faulty probabilities of DNN variables under
transient faults and, thus, provides correct RA estimations validated by
hardware. To accelerate RA estimation, we reformulate RA calculation as a Monte
Carlo integration problem, and solve it using importance sampling driven by DNN
specific heuristics. Using our lightweight RA estimation method, we show that
transient faults lead to far greater accuracy degradation than what todays DNN
resiliency tools estimate. We show how our RA estimation tool can help design
more resilient DNNs by integrating it with a Network Architecture Search
framework.</p>
  </details>
</details>
<details>
  <summary>67. <b>标题：Spuriosity Rankings: Sorting Data for Spurious Correlation Robustness</b></summary>
  <p><b>编号</b>：[231]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02648</p>
  <p><b>作者</b>：Mazda Moayeri,  Wenxiao Wang,  Sahil Singla,  Soheil Feizi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：spurious, spurious features, class based, spurious cues, spurious cues present</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present a framework for ranking images within their class based on the
strength of spurious cues present. By measuring the gap in accuracy on the
highest and lowest ranked images (we call this spurious gap), we assess
spurious feature reliance for $89$ diverse ImageNet models, finding that even
the best models underperform in images with weak spurious presence. However,
the effect of spurious cues varies far more dramatically across classes,
emphasizing the crucial, often overlooked, class-dependence of the spurious
correlation problem. While most spurious features we observe are clarifying
(i.e. improving test-time accuracy when present, as is typically expected), we
surprisingly find many cases of confusing spurious features, where models
perform better when they are absent. We then close the spurious gap by training
new classification heads on lowly ranked (i.e. without common spurious cues)
images, resulting in improved effective robustness to distribution shifts
(ObjectNet, ImageNet-R, ImageNet-Sketch). We also propose a second metric to
assess feature reliability, finding that spurious features are generally less
reliable than non-spurious (core) ones, though again, spurious features can be
more reliable for certain classes. To enable our analysis, we annotated $5,000$
feature-class dependencies over {\it all} of ImageNet as core or spurious using
minimal human supervision. Finally, we show the feature discovery and
spuriosity ranking framework can be extended to other datasets like CelebA and
WaterBirds in a lightweight fashion with only linear layer training, leading to
discovering a previously unknown racial bias in the Celeb-A hair
classification.</p>
  </details>
</details>
<details>
  <summary>68. <b>标题：AIDA: Analytic Isolation and Distance-based Anomaly Detection Algorithm</b></summary>
  <p><b>编号</b>：[232]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02645</p>
  <p><b>作者</b>：Luis Antonio Souto Arias,  Cornelis W. Oosterlee,  Pasquale Cirillo</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Analytic Isolation, AIDA, isolation metric, isolation, Analytic</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We combine the metrics of distance and isolation to develop the
\textit{Analytic Isolation and Distance-based Anomaly (AIDA) detection
algorithm}. AIDA is the first distance-based method that does not rely on the
concept of nearest-neighbours, making it a parameter-free model.
Differently from the prevailing literature, in which the isolation metric is
always computed via simulations, we show that AIDA admits an analytical
expression for the outlier score, providing new insights into the isolation
metric. Additionally, we present an anomaly explanation method based on AIDA,
the \textit{Tempered Isolation-based eXplanation (TIX)} algorithm, which finds
the most relevant outlier features even in data sets with hundreds of
dimensions. We test both algorithms on synthetic and empirical data: we show
that AIDA is competitive when compared to other state-of-the-art methods, and
it is superior in finding outliers hidden in multidimensional feature
subspaces. Finally, we illustrate how the TIX algorithm is able to find
outliers in multidimensional feature subspaces, and use these explanations to
analyze common benchmarks used in anomaly detection.</p>
  </details>
</details>
<details>
  <summary>69. <b>标题：Stars: Tera-Scale Graph Building for Clustering and Graph Learning</b></summary>
  <p><b>编号</b>：[234]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02635</p>
  <p><b>作者</b>：CJ Carey,  Jonathan Halcrow,  Rajesh Jayaram,  Vahab Mirrokni,  Warren Schudy,  Peilin Zhong</p>
  <p><b>备注</b>：NeurIPS 2022</p>
  <p><b>关键词</b>：fundamental procedure, analysis of massive, Stars, graphs, graph</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A fundamental procedure in the analysis of massive datasets is the
construction of similarity graphs. Such graphs play a key role for many
downstream tasks, including clustering, classification, graph learning, and
nearest neighbor search. For these tasks, it is critical to build graphs which
are sparse yet still representative of the underlying data. The benefits of
sparsity are twofold: firstly, constructing dense graphs is infeasible in
practice for large datasets, and secondly, the runtime of downstream tasks is
directly influenced by the sparsity of the similarity graph. In this work, we
present $\textit{Stars}$: a highly scalable method for building extremely
sparse graphs via two-hop spanners, which are graphs where similar points are
connected by a path of length at most two. Stars can construct two-hop spanners
with significantly fewer similarity comparisons, which are a major bottleneck
for learning based models where comparisons are expensive to evaluate.
Theoretically, we demonstrate that Stars builds a graph in nearly-linear time,
where approximate nearest neighbors are contained within two-hop neighborhoods.
In practice, we have deployed Stars for multiple data sets allowing for graph
building at the $\textit{Tera-Scale}$, i.e., for graphs with tens of trillions
of edges. We evaluate the performance of Stars for clustering and graph
learning, and demonstrate 10~1000-fold improvements in pairwise similarity
comparisons compared to different baselines, and 2~10-fold improvement in
running time without quality loss.</p>
  </details>
</details>
<details>
  <summary>70. <b>标题：Unifying Vision, Text, and Layout for Universal Document Processing</b></summary>
  <p><b>编号</b>：[238]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02623</p>
  <p><b>作者</b>：Zineng Tang,  Ziyi Yang,  Guoxin Wang,  Yuwei Fang,  Yang Liu,  Chenguang Zhu,  Michael Zeng,  Cha Zhang,  Mohit Bansal</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Universal Document Processing, propose Universal Document, propose Universal, Document Processing, varied task formats</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose Universal Document Processing (UDOP), a foundation Document AI
model which unifies text, image, and layout modalities together with varied
task formats, including document understanding and generation. UDOP leverages
the spatial correlation between textual content and document image to model
image, text, and layout modalities with one uniform representation. With a
novel Vision-Text-Layout Transformer, UDOP unifies pretraining and multi-domain
downstream tasks into a prompt-based sequence generation scheme. UDOP is
pretrained on both large-scale unlabeled document corpora using innovative
self-supervised objectives and diverse labeled data. UDOP also learns to
generate document images from text and layout modalities via masked image
reconstruction. To the best of our knowledge, this is the first time in the
field of document AI that one model simultaneously achieves high-quality neural
document editing and content customization. Our method sets the
state-of-the-art on 9 Document AI tasks, e.g., document understanding and QA,
across diverse data domains like finance reports, academic papers, and
websites. UDOP ranks first on the leaderboard of the Document Understanding
Benchmark (DUE).</p>
  </details>
</details>
<details>
  <summary>71. <b>标题：Towards a Taxonomy for the Use of Synthetic Data in Advanced Analytics</b></summary>
  <p><b>编号</b>：[239]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02622</p>
  <p><b>作者</b>：Peter Kowalczyk,  Giacomo Welsch,  Frédéric Thiesse</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：important business areas, learning techniques led, product recommendation, advanced analytics, techniques led</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The proliferation of deep learning techniques led to a wide range of advanced
analytics applications in important business areas such as predictive
maintenance or product recommendation. However, as the effectiveness of
advanced analytics naturally depends on the availability of sufficient data, an
organization's ability to exploit the benefits might be restricted by limited
data or likewise data access. These challenges could force organizations to
spend substantial amounts of money on data, accept constrained analytics
capacities, or even turn into a showstopper for analytics projects. Against
this backdrop, recent advances in deep learning to generate synthetic data may
help to overcome these barriers. Despite its great potential, however,
synthetic data are rarely employed. Therefore, we present a taxonomy
highlighting the various facets of deploying synthetic data for advanced
analytics systems. Furthermore, we identify typical application scenarios for
synthetic data to assess the current state of adoption and thereby unveil
missed opportunities to pave the way for further research.</p>
  </details>
</details>
<details>
  <summary>72. <b>标题：Benchmarking Offline Reinforcement Learning Algorithms for E-Commerce  Order Fraud Evaluation</b></summary>
  <p><b>编号</b>：[240]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02620</p>
  <p><b>作者</b>：Soysal Degirmenci,  Chris Jones</p>
  <p><b>备注</b>：2022 NeurIPS Offline Reinforcement Learning Workshop paper</p>
  <p><b>关键词</b>：order fraud evaluation, credit cards, order fraud, fraud, sites must employ</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Amazon and other e-commerce sites must employ mechanisms to protect their
millions of customers from fraud, such as unauthorized use of credit cards. One
such mechanism is order fraud evaluation, where systems evaluate orders for
fraud risk, and either "pass" the order, or take an action to mitigate high
risk. Order fraud evaluation systems typically use binary classification models
that distinguish fraudulent and legitimate orders, to assess risk and take
action. We seek to devise a system that considers both financial losses of
fraud and long-term customer satisfaction, which may be impaired when incorrect
actions are applied to legitimate customers. We propose that taking actions to
optimize long-term impact can be formulated as a Reinforcement Learning (RL)
problem. Standard RL methods require online interaction with an environment to
learn, but this is not desirable in high-stakes applications like order fraud
evaluation. Offline RL algorithms learn from logged data collected from the
environment, without the need for online interaction, making them suitable for
our use case. We show that offline RL methods outperform traditional binary
classification solutions in SimStore, a simplified e-commerce simulation that
incorporates order fraud risk. We also propose a novel approach to training
offline RL policies that adds a new loss term during training, to better align
policy exploration with taking correct actions.</p>
  </details>
</details>
<details>
  <summary>73. <b>标题：Can Ensembling Pre-processing Algorithms Lead to Better Machine Learning  Fairness?</b></summary>
  <p><b>编号</b>：[242]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02614</p>
  <p><b>作者</b>：Khaled Badran,  Pierre-Olivier Côté,  Amanda Kolopanis,  Rached Bouchoucha,  Antonio Collante,  Diego Elias Costa,  Emad Shihab,  Foutse Khomh</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：machine learning, critical areas, increasingly crucial, crucial to address, address the bias</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As machine learning (ML) systems get adopted in more critical areas, it has
become increasingly crucial to address the bias that could occur in these
systems. Several fairness pre-processing algorithms are available to alleviate
implicit biases during model training. These algorithms employ different
concepts of fairness, often leading to conflicting strategies with
consequential trade-offs between fairness and accuracy. In this work, we
evaluate three popular fairness pre-processing algorithms and investigate the
potential for combining all algorithms into a more robust pre-processing
ensemble. We report on lessons learned that can help practitioners better
select fairness algorithms for their models.</p>
  </details>
</details>
<details>
  <summary>74. <b>标题：StyleGAN as a Utility-Preserving Face De-identification Method</b></summary>
  <p><b>编号</b>：[243]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02611</p>
  <p><b>作者</b>：Seyyed Mohammad Sadegh Moosavi Khorzooghi,  Shirin Nilizadeh</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：preserve users' privacy, face de-identification methods, face, faces, preserve users'</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Several face de-identification methods have been proposed to preserve users'
privacy by obscuring their faces. These methods, however, can degrade the
quality of photos, and they usually do not preserve the utility of faces, e.g.,
their age, gender, pose, and facial expression. Recently, advanced generative
adversarial network models, such as StyleGAN, have been proposed, which
generate realistic, high-quality imaginary faces. In this paper, we investigate
the use of StyleGAN in generating de-identified faces through style mixing,
where the styles or features of the target face and an auxiliary face get mixed
to generate a de-identified face that carries the utilities of the target face.
We examined this de-identification method with respect to preserving utility
and privacy, by implementing several face detection, verification, and
identification attacks. Through extensive experiments and also comparing with
two state-of-the-art face de-identification methods, we show that StyleGAN
preserves the quality and utility of the faces much better than the other
approaches and also by choosing the style mixing levels correctly, it can
preserve the privacy of the faces much better than other methods.</p>
  </details>
</details>
<details>
  <summary>75. <b>标题：Audio Latent Space Cartography</b></summary>
  <p><b>编号</b>：[244]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02610</p>
  <p><b>作者</b>：Nicolas Jonason,  Bob L.T. Sturm</p>
  <p><b>备注</b>：Late Breaking / Demo, ISMIR 2022 (this https URL)</p>
  <p><b>关键词</b>：audio latent spaces, audio latent, generation pipeline, latent spaces, visualisations of audio</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We explore the generation of visualisations of audio latent spaces using an
audio-to-image generation pipeline. We believe this can help with the
interpretability of audio latent spaces. We demonstrate a variety of results on
the NSynth dataset. A web demo is available.</p>
  </details>
</details>
<details>
  <summary>76. <b>标题：Learning to Optimize in Model Predictive Control</b></summary>
  <p><b>编号</b>：[247]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02603</p>
  <p><b>作者</b>：Jacob Sacks,  Byron Boots</p>
  <p><b>备注</b>：Proceedings of the IEEE Conference on Robotics and Automation (ICRA), 2022. Paper is 6 pages with 2 figures and 2 tables</p>
  <p><b>关键词</b>：Model Predictive Control, Sampling-based Model Predictive, Model Predictive, flexible control framework, Predictive Control</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Sampling-based Model Predictive Control (MPC) is a flexible control framework
that can reason about non-smooth dynamics and cost functions. Recently,
significant work has focused on the use of machine learning to improve the
performance of MPC, often through learning or fine-tuning the dynamics or cost
function. In contrast, we focus on learning to optimize more effectively. In
other words, to improve the update rule within MPC. We show that this can be
particularly useful in sampling-based MPC, where we often wish to minimize the
number of samples for computational reasons. Unfortunately, the cost of
computational efficiency is a reduction in performance; fewer samples results
in noisier updates. We show that we can contend with this noise by learning how
to update the control distribution more effectively and make better use of the
few samples that we have. Our learned controllers are trained via imitation
learning to mimic an expert which has access to substantially more samples. We
test the efficacy of our approach on multiple simulated robotics tasks in
sample-constrained regimes and demonstrate that our approach can outperform a
MPC controller with the same number of samples.</p>
  </details>
</details>
<details>
  <summary>77. <b>标题：Automatic Anomalies Detection in Hydraulic Devices</b></summary>
  <p><b>编号</b>：[248]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02602</p>
  <p><b>作者</b>：Jose A. Solorio,  Jose M. Garcia,  Sudip Vhaduri</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：everyday environments, wide variety, hydraulic systems, hydraulic, systems</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Nowadays, the applications of hydraulic systems are present in a wide variety
of devices in both industrial and everyday environments. The implementation and
usage of hydraulic systems have been well documented; however, today, this
still faces a challenge, the integration of tools that allow more accurate
information about the functioning and operation of these systems for proactive
decision-making. In industrial applications, many sensors and methods exist to
measure and determine the status of process variables (e.g., flow, pressure,
force). Nevertheless, little has been done to have systems that can provide
users with device-health information related to hydraulic devices integrated
into the machinery. Implementing artificial intelligence (AI) technologies and
machine learning (ML) models in hydraulic system components has been identified
as a solution to the challenge many industries currently face: optimizing
processes and carrying them out more safely and efficiently. This paper
presents a solution for the characterization and estimation of anomalies in one
of the most versatile and used devices in hydraulic systems, cylinders. AI and
ML models were implemented to determine the current operating status of these
hydraulic components and whether they are working correctly or if a failure
mode or abnormal condition is present.</p>
  </details>
</details>
<details>
  <summary>78. <b>标题：Fine-tuning a Subtle Parsing Distinction Using a Probabilistic Decision  Tree: the Case of Postnominal "that" in Noun Complement Clauses vs. Relative  Clauses</b></summary>
  <p><b>编号</b>：[249]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02591</p>
  <p><b>作者</b>：Zineddine Tighidet,  Nicolas Ballier</p>
  <p><b>备注</b>：Published in the ACL anthology, ALTA 2022</p>
  <p><b>关键词</b>：clauses in English, English and resorted, noun complement clauses, methods to parse, resorted to distinct</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper we investigated two different methods to parse relative and
noun complement clauses in English and resorted to distinct tags for their
corresponding that as a relative pronoun and as a complementizer. We used an
algorithm to relabel a corpus parsed with the GUM Treebank using Universal
Dependency. Our second experiment consisted in using TreeTagger, a
Probabilistic Decision Tree, to learn the distinction between the two
complement and relative uses of postnominal "that". We investigated the effect
of the training set size on TreeTagger accuracy and how representative the GUM
Treebank files are for the two structures under scrutiny. We discussed some of
the linguistic and structural tenets of the learnability of this distinction.</p>
  </details>
</details>
<details>
  <summary>79. <b>标题：Rethinking Backdoor Data Poisoning Attacks in the Context of  Semi-Supervised Learning</b></summary>
  <p><b>编号</b>：[251]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02582</p>
  <p><b>作者</b>：Marissa Connor,  Vincent Emanuele</p>
  <p><b>备注</b>：18 pages, 14 figures</p>
  <p><b>关键词</b>：train high-accuracy machine, high-accuracy machine learning, machine learning models, traditional supervised learning, training samples required</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Semi-supervised learning methods can train high-accuracy machine learning
models with a fraction of the labeled training samples required for traditional
supervised learning. Such methods do not typically involve close review of the
unlabeled training samples, making them tempting targets for data poisoning
attacks. In this paper we investigate the vulnerabilities of semi-supervised
learning methods to backdoor data poisoning attacks on the unlabeled samples.
We show that simple poisoning attacks that influence the distribution of the
poisoned samples' predicted labels are highly effective - achieving an average
attack success rate as high as 96.9%. We introduce a generalized attack
framework targeting semi-supervised learning methods to better understand and
exploit their limitations and to motivate future defense strategies.</p>
  </details>
</details>
<details>
  <summary>80. <b>标题：Auxiliary Quantile Forecasting with Linear Networks</b></summary>
  <p><b>编号</b>：[252]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02578</p>
  <p><b>作者</b>：Shayan Jawed,  Lars Schmidt-Thieme</p>
  <p><b>备注</b>：Under submission</p>
  <p><b>关键词</b>：quantile, Implicit quantile, learning, forecast, forecasting</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose a novel multi-task method for quantile forecasting with shared
Linear layers. Our method is based on the Implicit quantile learning approach,
where samples from the Uniform distribution $\mathcal{U}(0, 1)$ are
reparameterized to quantile values of the target distribution. We combine the
implicit quantile and input time series representations to directly forecast
multiple quantile estimations for multiple horizons jointly. Prior works have
adopted a Linear layer for the direct estimation of all forecasting horizons in
a multi-task learning setup. We show that following similar intuition from
multi-task learning to exploit correlations among forecast horizons, we can
model multiple quantile estimates as auxiliary tasks for each of the forecast
horizon to improve forecast accuracy across the quantile estimates compared to
modeling only a single quantile estimate. We show learning auxiliary quantile
tasks leads to state-of-the-art performance on deterministic forecasting
benchmarks concerning the main-task of forecasting the 50$^{th}$ percentile
estimate.</p>
  </details>
</details>
<details>
  <summary>81. <b>标题：A Mobility-Aware Deep Learning Model for Long-Term COVID-19 Pandemic  Prediction and Policy Impact Analysis</b></summary>
  <p><b>编号</b>：[253]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02575</p>
  <p><b>作者</b>：Danfeng Guo,  Zijie Huang,  Junheng Hao,  Yizhou Sun,  Wei Wang,  Demetri Terzopoulos</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：popular research topic, disease spreading analysis, aiming at disease, disease spreading, popular research</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Pandemic(epidemic) modeling, aiming at disease spreading analysis, has always
been a popular research topic especially following the outbreak of COVID-19 in
2019. Some representative models including SIR-based deep learning prediction
models have shown satisfactory performance. However, one major drawback for
them is that they fall short in their long-term predictive ability. Although
graph convolutional networks (GCN) also perform well, their edge
representations do not contain complete information and it can lead to biases.
Another drawback is that they usually use input features which they are unable
to predict. Hence, those models are unable to predict further future. We
propose a model that can propagate predictions further into the future and it
has better edge representations. In particular, we model the pandemic as a
spatial-temporal graph whose edges represent the transition of infections and
are learned by our model. We use a two-stream framework that contains GCN and
recursive structures (GRU) with an attention mechanism. Our model enables
mobility analysis that provides an effective toolbox for public health
researchers and policy makers to predict how different lock-down strategies
that actively control mobility can influence the spread of pandemics.
Experiments show that our model outperforms others in its long-term predictive
power. Moreover, we simulate the effects of certain policies and predict their
impacts on infection control.</p>
  </details>
</details>
<details>
  <summary>82. <b>标题：cs-net: structural approach to time-series forecasting for  high-dimensional feature space data with limited observations</b></summary>
  <p><b>编号</b>：[256]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02567</p>
  <p><b>作者</b>：Weiyu Zong,  Mingqian Feng,  Griffin Heyrich,  Peter Chin</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：solving time-series forecasting-related, time-series forecasting-related problems, recent years, introduced to solving, forecasting-related problems</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In recent years, deep-learning-based approaches have been introduced to
solving time-series forecasting-related problems. These novel methods have
demonstrated impressive performance in univariate and low-dimensional
multivariate time-series forecasting tasks. However, when these novel methods
are used to handle high-dimensional multivariate forecasting problems, their
performance is highly restricted by a practical training time and a reasonable
GPU memory configuration. In this paper, inspired by a change of basis in the
Hilbert space, we propose a flexible data feature extraction technique that
excels in high-dimensional multivariate forecasting tasks. Our approach was
originally developed for the National Science Foundation (NSF) Algorithms for
Threat Detection (ATD) 2022 Challenge. Implemented using the attention
mechanism and Convolutional Neural Networks (CNN) architecture, our method
demonstrates great performance and compatibility. Our models trained on the
GDELT Dataset finished 1st and 2nd places in the ATD sprint series and hold
promise for other datasets for time series forecasting.</p>
  </details>
</details>
<details>
  <summary>83. <b>标题：MAP-Music2Vec: A Simple and Effective Baseline for Self-Supervised Music  Audio Representation Learning</b></summary>
  <p><b>编号</b>：[260]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02508</p>
  <p><b>作者</b>：Yizhi Li,  Ruibin Yuan,  Ge Zhang,  Yinghao Ma,  Chenghua Lin,  Xingran Chen,  Anton Ragni,  Hanzhi Yin,  Zhijie Hu,  Haoyu He,  Emmanouil Benetos,  Norbert Gyenge,  Ruibo Liu,  Jie Fu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：exponentially growing interest, deep learning community, community has witnessed, witnessed an exponentially, exponentially growing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The deep learning community has witnessed an exponentially growing interest
in self-supervised learning (SSL). However, it still remains unexplored how to
build a framework for learning useful representations of raw music waveforms in
a self-supervised manner. In this work, we design Music2Vec, a framework
exploring different SSL algorithmic components and tricks for music audio
recordings. Our model achieves comparable results to the state-of-the-art
(SOTA) music SSL model Jukebox, despite being significantly smaller with less
than 2% of parameters of the latter. The model will be released on
Huggingface(Please refer to: this https URL)</p>
  </details>
</details>
<details>
  <summary>84. <b>标题：FEMa-FS: Finite Element Machines for Feature Selection</b></summary>
  <p><b>编号</b>：[261]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02507</p>
  <p><b>作者</b>：Lucas Biaggi,  João P. Papa,  Kelton A. P Costa,  Danillo R. Pereira,  Leandro A. Passos</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Identifying anomalies, primary strategies, strategies towards security, security and protection, protection procedures</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Identifying anomalies has become one of the primary strategies towards
security and protection procedures in computer networks. In this context,
machine learning-based methods emerge as an elegant solution to identify such
scenarios and learn irrelevant information so that a reduction in the
identification time and possible gain in accuracy can be obtained. This paper
proposes a novel feature selection approach called Finite Element Machines for
Feature Selection (FEMa-FS), which uses the framework of finite elements to
identify the most relevant information from a given dataset. Although FEMa-FS
can be applied to any application domain, it has been evaluated in the context
of anomaly detection in computer networks. The outcomes over two datasets
showed promising results.</p>
  </details>
</details>
<details>
  <summary>85. <b>标题：This changes to that : Combining causal and non-causal explanations to  generate disease progression in capsule endoscopy</b></summary>
  <p><b>编号</b>：[262]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02506</p>
  <p><b>作者</b>：Anuja Vats,  Ahmed Mohammed,  Marius Pedersen,  Nirmalie Wiratunga</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：deep learning networks, learning networks, processes of deep, deep learning, decision processes</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Due to the unequivocal need for understanding the decision processes of deep
learning networks, both modal-dependent and model-agnostic techniques have
become very popular. Although both of these ideas provide transparency for
automated decision making, most methodologies focus on either using the
modal-gradients (model-dependent) or ignoring the model internal states and
reasoning with a model's behavior/outcome (model-agnostic) to instances. In
this work, we propose a unified explanation approach that given an instance
combines both model-dependent and agnostic explanations to produce an
explanation set. The generated explanations are not only consistent in the
neighborhood of a sample but can highlight causal relationships between image
content and the outcome. We use Wireless Capsule Endoscopy (WCE) domain to
illustrate the effectiveness of our explanations. The saliency maps generated
by our approach are comparable or better on the softmax information score.</p>
  </details>
</details>
<details>
  <summary>86. <b>标题：Relation-based Motion Prediction using Traffic Scene Graphs</b></summary>
  <p><b>编号</b>：[263]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02503</p>
  <p><b>作者</b>：Maximilian Zipfl,  Felix Hertlein,  Achim Rettinger,  Steffen Thoma,  Lavdim Halilaj,  Juergen Luettin,  Stefan Schmid,  Cory Henson</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Representing relevant information, Representing relevant, traffic, understanding its environment, environment is crucial</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Representing relevant information of a traffic scene and understanding its
environment is crucial for the success of autonomous driving. Modeling the
surrounding of an autonomous car using semantic relations, i.e., how different
traffic participants relate in the context of traffic rule based behaviors, is
hardly been considered in previous work. This stems from the fact that these
relations are hard to extract from real-world traffic scenes. In this work, we
model traffic scenes in a form of spatial semantic scene graphs for various
different predictions about the traffic participants, e.g., acceleration and
deceleration. Our learning and inference approach uses Graph Neural Networks
(GNNs) and shows that incorporating explicit information about the spatial
semantic relations between traffic participants improves the predicdtion
results. Specifically, the acceleration prediction of traffic participants is
improved by up to 12% compared to the baselines, which do not exploit this
explicit information. Furthermore, by including additional information about
previous scenes, we achieve 73% improvements.</p>
  </details>
</details>
<details>
  <summary>87. <b>标题：Financial Risk Management on a Neutral Atom Quantum Processor</b></summary>
  <p><b>编号</b>：[265]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.03223</p>
  <p><b>作者</b>：Lucas Leclerc,  Luis Ortiz-Guitierrez,  Sebastian Grijalva,  Boris Albrecht,  Julia R. K. Cline,  Vincent E. Elfving,  Adrien Signoles,  Loïc Henriet,  Gianni Del Bimbo,  Usman Ayub Sheikh,  Maitree Shah,  Luc Andrea,  Faysal Ishtiaq,  Andoni Duarte,  Samuel Mugel,  Irene Caceres,  Michel Kurek,  Roman Orus,  Achraf Seddik,  Oumaima Hammammi,  Hacene Isselnane,  Didier M'tamon</p>
  <p><b>备注</b>：17 pages, 11 figures, 2 tables</p>
  <p><b>关键词</b>：black boxes expensive, large datasets collected, Learning models capable, expensive to run, Machine Learning models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Machine Learning models capable of handling the large datasets collected in
the financial world can often become black boxes expensive to run. The quantum
computing paradigm suggests new optimization techniques, that combined with
classical algorithms, may deliver competitive, faster and more interpretable
models. In this work we propose a quantum-enhanced machine learning solution
for the prediction of credit rating downgrades, also known as fallen-angels
forecasting in the financial risk management field. We implement this solution
on a neutral atom Quantum Processing Unit with up to 60 qubits on a real-life
dataset. We report competitive performances against the state-of-the-art Random
Forest benchmark whilst our model achieves better interpretability and
comparable training times. We examine how to improve performance in the
near-term validating our ideas with Tensor Networks-based numerical
simulations.</p>
  </details>
</details>
<details>
  <summary>88. <b>标题：An Unsupervised Machine Learning Approach for Ground Motion Clustering  and Selection</b></summary>
  <p><b>编号</b>：[266]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.03188</p>
  <p><b>作者</b>：R. Bailey Bond,  Pu Ren,  Jerome F. Hajjar,  Hao Sun</p>
  <p><b>备注</b>：24 pages, 15 Figures</p>
  <p><b>关键词</b>：sequence data continues, engineering design, applied science, machine learning, unsupervised machine learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Clustering analysis of sequence data continues to address many applications
in engineering design, aided with the rapid growth of machine learning in
applied science. This paper presents an unsupervised machine learning algorithm
to extract defining characteristics of earthquake ground-motion records, also
called latent features, to aid in ground-motion clustering and selection. In
this context, a latent feature is a low dimensional machine-discovered spectral
characteristic learned through nonlinear relationships of a neural network
autoencoder. Clustering can be performed on the latent features and used to
select a representative archetypal subgroup from a large ground-motion suite.
The objective of efficient ground-motion selection is to choose records
representative of what the structure will probabilistically experience in its
lifetime. Three examples are presented to validate this approach, including a
synthetic spectral dataset and spectra from field recorded ground-motion
records. Deep embedding clustering of ground motion spectra improves on the
results of static feature extraction, utilizing characteristics that represent
the sparse spectral content of ground motions.</p>
  </details>
</details>
<details>
  <summary>89. <b>标题：Domain Adaptation and Generalization on Functional Medical Images: A  Systematic Survey</b></summary>
  <p><b>编号</b>：[267]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.03176</p>
  <p><b>作者</b>：Gita Sarafraz,  Armin Behnamnia,  Mehran Hosseinzadeh,  Ali Balapour,  Amin Meghrazi,  Hamid R. Rabiee</p>
  <p><b>备注</b>：41 pages, 8 figures</p>
  <p><b>关键词</b>：natural language processing, including natural language, Machine learning algorithms, medical data processing, language processing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Machine learning algorithms have revolutionized different fields, including
natural language processing, computer vision, signal processing, and medical
data processing. Despite the excellent capabilities of machine learning
algorithms in various tasks and areas, the performance of these models mainly
deteriorates when there is a shift in the test and training data distributions.
This gap occurs due to the violation of the fundamental assumption that the
training and test data are independent and identically distributed (i.i.d). In
real-world scenarios where collecting data from all possible domains for
training is costly and even impossible, the i.i.d assumption can hardly be
satisfied. The problem is even more severe in the case of medical images and
signals because it requires either expensive equipment or a meticulous
experimentation setup to collect data, even for a single domain. Additionally,
the decrease in performance may have severe consequences in the analysis of
medical records. As a result of such problems, the ability to generalize and
adapt under distribution shifts (domain generalization (DG) and domain
adaptation (DA)) is essential for the analysis of medical data. This paper
provides the first systematic review of DG and DA on functional brain signals
to fill the gap of the absence of a comprehensive study in this era. We provide
detailed explanations and categorizations of datasets, approaches, and
architectures used in DG and DA on functional brain images. We further address
the attention-worthy future tracks in this field.</p>
  </details>
</details>
<details>
  <summary>90. <b>标题：Which products activate a product? An explainable machine learning  approach</b></summary>
  <p><b>编号</b>：[273]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.03094</p>
  <p><b>作者</b>：Massimiliano Fessina,  Giambattista Albora,  Andrea Tacchella,  Andrea Zaccaria</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Tree-based machine learning, machine learning algorithms, learning algorithms provide, Tree-based machine, machine learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Tree-based machine learning algorithms provide the most precise assessment of
the feasibility for a country to export a target product given its export
basket. However, the high number of parameters involved prevents a
straightforward interpretation of the results and, in turn, the explainability
of policy indications. In this paper, we propose a procedure to statistically
validate the importance of the products used in the feasibility assessment. In
this way, we are able to identify which products, called explainers,
significantly increase the probability to export a target product in the near
future. The explainers naturally identify a low dimensional representation, the
Feature Importance Product Space, that enhances the interpretability of the
recommendations and provides out-of-sample forecasts of the export baskets of
countries. Interestingly, we detect a positive correlation between the
complexity of a product and the complexity of its explainers.</p>
  </details>
</details>
<details>
  <summary>91. <b>标题：FretNet: Continuous-Valued Pitch Contour Streaming for Polyphonic Guitar  Tablature Transcription</b></summary>
  <p><b>编号</b>：[276]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.03023</p>
  <p><b>作者</b>：Frank Cwitkowitz,  Toni Hirvonen,  Anssi Klapuri</p>
  <p><b>备注</b>：Submitted to ICASSP 2023</p>
  <p><b>关键词</b>：Automatic Music Transcription, received increasing attention, Automatic Music, recent years, estimated from audio</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In recent years, the task of Automatic Music Transcription (AMT), whereby
various attributes of music notes are estimated from audio, has received
increasing attention. At the same time, the related task of Multi-Pitch
Estimation (MPE) remains a challenging but necessary component of almost all
AMT approaches, even if only implicitly. In the context of AMT, pitch
information is typically quantized to the nominal pitches of the Western music
scale. Even in more general contexts, MPE systems typically produce pitch
predictions with some degree of quantization. In certain applications of AMT,
such as Guitar Tablature Transcription (GTT), it is more meaningful to estimate
continuous-valued pitch contours. Guitar tablature has the capacity to
represent various playing techniques, some of which involve pitch modulation.
Contemporary approaches to AMT do not adequately address pitch modulation, and
offer only less quantization at the expense of more model complexity. In this
paper, we present a GTT formulation that estimates continuous-valued pitch
contours, grouping them according to their string and fret of origin. We
demonstrate that for this task, the proposed method significantly improves the
resolution of MPE and simultaneously yields tablature estimation results
competitive with baseline models.</p>
  </details>
</details>
<details>
  <summary>92. <b>标题：Evaluation of particle motions in stabilized specimens of transparent  sand using deep learning segmentation</b></summary>
  <p><b>编号</b>：[280]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02939</p>
  <p><b>作者</b>：David Marx,  Krishna Kumar,  Jorge Zornberg</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：transparent sand stabilized, geogrid simulants, transparent sand, particle, measured particle displacements</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Individual particle rotation and displacement were measured in triaxial tests
on transparent sand stabilized with geogrid simulants. The Cellpose U-Net
model, originally developed to segment biological cells, was trained to segment
images of fused quartz particles. The Score-CAM metric from the field of
Explainable AI was used to validate the application of Cellpose to segment
particles of fused quartz. These segmented particles were characterized in
terms of Fourier shape descriptors and tracked across images. The measured
particle displacements in the monotonic triaxial tests correlated with
displacement fields from Digital Image Correlation (DIC). In contrast to DIC,
the new technique also allows for the measurement of individual particle
rotation. The particle rotation measurements were found to be repeatable across
different specimens. A state boundary line between probable and improbable
particle motions could be identified for a given test based on the measured
particle displacements and rotations. The size of the zone of probable motions
was used to quantify the effectiveness of the stabilizing inclusions. The
results of repeated load tests revealed that the honeycomb inclusions used
stabilized the specimens by reducing both particle displacements and rotations.</p>
  </details>
</details>
<details>
  <summary>93. <b>标题：A Time Series Approach to Explainability for Neural Nets with  Applications to Risk-Management and Fraud Detection</b></summary>
  <p><b>编号</b>：[282]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02906</p>
  <p><b>作者</b>：Marc Wildi,  Branka Hadji Misheva</p>
  <p><b>备注</b>：28 pages</p>
  <p><b>关键词</b>：driven application fields, technology driven application, Artificial intelligence, application fields, intelligence is creating</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Artificial intelligence is creating one of the biggest revolution across
technology driven application fields. For the finance sector, it offers many
opportunities for significant market innovation and yet broad adoption of AI
systems heavily relies on our trust in their outputs. Trust in technology is
enabled by understanding the rationale behind the predictions made. To this
end, the concept of eXplainable AI emerged introducing a suite of techniques
attempting to explain to users how complex models arrived at a certain
decision. For cross-sectional data classical XAI approaches can lead to
valuable insights about the models' inner workings, but these techniques
generally cannot cope well with longitudinal data (time series) in the presence
of dependence structure and non-stationarity. We here propose a novel XAI
technique for deep learning methods which preserves and exploits the natural
time ordering of the data.</p>
  </details>
</details>
<details>
  <summary>94. <b>标题：Statistical mechanics of continual learning: variational principle and  mean-field potential</b></summary>
  <p><b>编号</b>：[285]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02846</p>
  <p><b>作者</b>：Chan Li,  Zhenyue Huang,  Wenxuan Zou,  Haiping Huang</p>
  <p><b>备注</b>：45 pages, 7 figures</p>
  <p><b>关键词</b>：artificial general intelligence, obstacle to artificial, artificial general, general intelligence, intelligence is set</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>An obstacle to artificial general intelligence is set by the continual
learning of multiple tasks of different nature. Recently, various heuristic
tricks, both from machine learning and from neuroscience angles, were proposed,
but they lack a unified theory ground. Here, we focus on the continual learning
in single-layered and multi-layered neural networks of binary weights. A
variational Bayesian learning setting is thus proposed, where the neural
network is trained in a field-space, rather than the gradient-ill-defined
discrete-weight space, and furthermore, the weight uncertainty is naturally
incorporated, and modulates the synaptic resources among tasks. From a physics
perspective, we translate the variational continual learning into the
Franz-Parisi thermodynamic potential framework, where the previous task
knowledge acts as a prior and a reference as well. Therefore, the learning
performance can be analytically studied with mean-field order parameters, whose
predictions coincide with the numerical experiments using stochastic gradient
descent methods. Our proposed principled frameworks also connect to elastic
weight consolidation, and neuroscience inspired metaplasticity, providing a
theory-grounded method for the real-world multi-task learning with deep
networks.</p>
  </details>
</details>
<details>
  <summary>95. <b>标题：BALPA: A Balanced Primal-Dual Algorithm for Nonsmooth Optimization with  Application to Distributed Optimization</b></summary>
  <p><b>编号</b>：[286]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02835</p>
  <p><b>作者</b>：Luyao Guo,  Jinde Cao,  Xinli Shi,  Shaofu Yang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：nonsmooth term composed, primal-dual proximal splitting, loss function consists, proximal splitting algorithm, classic PD-PSAs</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we propose a novel primal-dual proximal splitting algorithm
(PD-PSA), named BALPA, for the composite optimization problem with equality
constraints, where the loss function consists of a smooth term and a nonsmooth
term composed with a linear mapping. In BALPA, the dual update is designed as a
proximal point for a time-varying quadratic function, which balances the
implementation of primal and dual update and retains the proximity-induced
feature of classic PD-PSAs. In addition, by this balance, BALPA eliminates the
inefficiency of classic PD-PSAs for composite optimization problems in which
the Euclidean norm of the linear mapping or the equality constraint mapping is
large. Therefore, BALPA not only inherits the advantages of simple structure
and easy implementation of classic PD-PSAs but also ensures a fast convergence
when these norms are large. Moreover, we propose a stochastic version of BALPA
(S-BALPA) and apply the developed BALPA to distributed optimization to devise a
new distributed optimization algorithm. Furthermore, a comprehensive
convergence analysis for BALPA and S-BALPA is conducted, respectively. Finally,
numerical experiments demonstrate the efficiency of the proposed algorithms.</p>
  </details>
</details>
<details>
  <summary>96. <b>标题：Interdisciplinary Discovery of Nanomaterials Based on Convolutional  Neural Networks</b></summary>
  <p><b>编号</b>：[288]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02805</p>
  <p><b>作者</b>：Tong Xie,  Yuwei Wan,  Weijian Li,  Qingyuan Linghu,  Shaozhou Wang,  Yalun Cai,  Han Liu,  Chunyu Kit,  Clara Grazian,  Bram Hoex</p>
  <p><b>备注</b>：Paper at NeurIPS 2022 AI for Science: Progress and Promises</p>
  <p><b>关键词</b>：material science literature, material science, comprehensive scientific knowledge, science literature, comprehensive scientific</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The material science literature contains up-to-date and comprehensive
scientific knowledge of materials. However, their content is unstructured and
diverse, resulting in a significant gap in providing sufficient information for
material design and synthesis. To this end, we used natural language processing
(NLP) and computer vision (CV) techniques based on convolutional neural
networks (CNN) to discover valuable experimental-based information about
nanomaterials and synthesis methods in energy-material-related publications.
Our first system, TextMaster, extracts opinions from texts and classifies them
into challenges and opportunities, achieving 94% and 92% accuracy,
respectively. Our second system, GraphMaster, realizes data extraction of
tables and figures from publications with 98.3\% classification accuracy and
4.3% data extraction mean square error. Our results show that these systems
could assess the suitability of materials for a certain application by
evaluation of synthesis insights and case analysis with detailed references.
This work offers a fresh perspective on mining knowledge from scientific
literature, providing a wide swatch to accelerate nanomaterial research through
CNN.</p>
  </details>
</details>
<details>
  <summary>97. <b>标题：A Trustworthy Framework for Medical Image Analysis with Deep Learning</b></summary>
  <p><b>编号</b>：[291]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02764</p>
  <p><b>作者</b>：Kai Ma,  Siyuan He,  Pengcheng Xi,  Ashkan Ebadi,  Stéphane Tremblay,  Alexander Wong</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：increasingly important role, medical imaging, data imbalance, Computer vision, computer-assisted diagnosis</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Computer vision and machine learning are playing an increasingly important
role in computer-assisted diagnosis; however, the application of deep learning
to medical imaging has challenges in data availability and data imbalance, and
it is especially important that models for medical imaging are built to be
trustworthy. Therefore, we propose TRUDLMIA, a trustworthy deep learning
framework for medical image analysis, which adopts a modular design, leverages
self-supervised pre-training, and utilizes a novel surrogate loss function.
Experimental evaluations indicate that models generated from the framework are
both trustworthy and high-performing. It is anticipated that the framework will
support researchers and clinicians in advancing the use of deep learning for
dealing with public health crises including COVID-19.</p>
  </details>
</details>
<details>
  <summary>98. <b>标题：QFT: Post-training quantization via fast joint finetuning of all degrees  of freedom</b></summary>
  <p><b>编号</b>：[298]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02634</p>
  <p><b>作者</b>：Alex Finkelstein,  Ella Fuchs,  Idan Tal,  Mark Grobman,  Niv Vosco,  Eldad Meller</p>
  <p><b>备注</b>：Presented at CADL2022 workshop at ECCV2022</p>
  <p><b>关键词</b>：neural net accuracy, net accuracy close, bringing quantized neural, quantized neural net, challenge of bringing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The post-training quantization (PTQ) challenge of bringing quantized neural
net accuracy close to original has drawn much attention driven by industry
demand. Many of the methods emphasize optimization of a specific
degree-of-freedom (DoF), such as quantization step size, preconditioning
factors, bias fixing, often chained to others in multi-step solutions. Here we
rethink quantized network parameterization in HW-aware fashion, towards a
unified analysis of all quantization DoF, permitting for the first time their
joint end-to-end finetuning. Our single-step simple and extendable method,
dubbed quantization-aware finetuning (QFT), achieves 4-bit weight quantization
results on-par with SoTA within PTQ constraints of speed and resource.</p>
  </details>
</details>
<details>
  <summary>99. <b>标题：Distributed Bayesian Learning of Dynamic States</b></summary>
  <p><b>编号</b>：[301]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02565</p>
  <p><b>作者</b>：Mert Kayaalp,  Virginia Bordignon,  Stefan Vlaski,  Vincenzo Matta,  Ali H. Sayed</p>
  <p><b>备注</b>：Submitted for publication</p>
  <p><b>关键词</b>：work studies networked, studies networked agents, networked agents cooperating, partial information, work studies</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This work studies networked agents cooperating to track a dynamical state of
nature under partial information. The proposed algorithm is a distributed
Bayesian filtering algorithm for finite-state hidden Markov models (HMMs). It
can be used for sequential state estimation tasks, as well as for modeling
opinion formation over social networks under dynamic environments. We show that
the disagreement with the optimal centralized solution is asymptotically
bounded for the class of geometrically ergodic state transition models, which
includes rapidly changing models. We also derive recursions for calculating the
probability of error and establish convergence under Gaussian observation
models. Simulations are provided to illustrate the theory and to compare
against alternative approaches.</p>
  </details>
</details>
<details>
  <summary>100. <b>标题：Enhancing Quantum Adversarial Robustness by Randomized Encodings</b></summary>
  <p><b>编号</b>：[303]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02531</p>
  <p><b>作者</b>：Weiyuan Gong,  Dong Yuan,  Weikang Li,  Dong-Ling Deng</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：quantum machine learning, machine learning, quantum, advanced quantum learning, quantum learning models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The interplay between quantum physics and machine learning gives rise to the
emergent frontier of quantum machine learning, where advanced quantum learning
models may outperform their classical counterparts in solving certain
challenging problems. However, quantum learning systems are vulnerable to
adversarial attacks: adding tiny carefully-crafted perturbations on legitimate
input samples can cause misclassifications. To address this issue, we propose a
general scheme to protect quantum learning systems from adversarial attacks by
randomly encoding the legitimate data samples through unitary or quantum error
correction encoders. In particular, we rigorously prove that both global and
local random unitary encoders lead to exponentially vanishing gradients (i.e.
barren plateaus) for any variational quantum circuits that aim to add
adversarial perturbations, independent of the input data and the inner
structures of adversarial circuits and quantum classifiers. In addition, we
prove a rigorous bound on the vulnerability of quantum classifiers under local
unitary adversarial attacks. We show that random black-box quantum error
correction encoders can protect quantum classifiers against local adversarial
noises and their robustness increases as we concatenate error correction codes.
To quantify the robustness enhancement, we adapt quantum differential privacy
as a measure of the prediction stability for quantum classifiers. Our results
establish versatile defense strategies for quantum classifiers against
adversarial perturbations, which provide valuable guidance to enhance the
reliability and security for both near-term and future quantum learning
technologies.</p>
  </details>
</details>
<details>
  <summary>101. <b>标题：COmic: Convolutional Kernel Networks for Interpretable End-to-End  Learning on (Multi-)Omics Data</b></summary>
  <p><b>编号</b>：[304]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02504</p>
  <p><b>作者</b>：Jonas C. Ditz,  Bernhard Reuter,  Nico Pfeifer</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：recent years, steadily increasing, increasing with technological, technological advancement, advancement in recent</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Motivation: The size of available omics datasets is steadily increasing with
technological advancement in recent years. While this increase in sample size
can be used to improve the performance of relevant prediction tasks in
healthcare, models that are optimized for large datasets usually operate as
black boxes. In high stakes scenarios, like healthcare, using a black-box model
poses safety and security issues. Without an explanation about molecular
factors and phenotypes that affected the prediction, healthcare providers are
left with no choice but to blindly trust the models. We propose a new type of
artificial neural networks, named Convolutional Omics Kernel Networks (COmic).
By combining convolutional kernel networks with pathway-induced kernels, our
method enables robust and interpretable end-to-end learning on omics datasets
ranging in size from a few hundred to several hundreds of thousands of samples.
Furthermore, COmic can be easily adapted to utilize multi-omics data.
Results: We evaluate the performance capabilities of COmic on six different
breast cancer cohorts. Additionally, we train COmic models on multi-omics data
using the METABRIC cohort. Our models perform either better or similar to
competitors on both tasks. We show how the use of pathway-induced Laplacian
kernels opens the black-box nature of neural networks and results in
intrinsically interpretable models that eliminate the need for
\textit{post-hoc} explanation models.</p>
  </details>
</details>
<details>
  <summary>102. <b>标题：Understanding Event-Generation Networks via Uncertainties</b></summary>
  <p><b>编号</b>：[306]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2104.04543</p>
  <p><b>作者</b>：Marco Bellagente,  Manuel Haußmann,  Michel Luchmann,  Tilman Plehn</p>
  <p><b>备注</b>：24 pages</p>
  <p><b>关键词</b>：LHC simulations, generative neural networks, growing success, success of generative, generative neural</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Following the growing success of generative neural networks in LHC
simulations, the crucial question is how to control the networks and assign
uncertainties to their event output. We show how Bayesian normalizing flow or
invertible networks capture uncertainties from the training and turn them into
an uncertainty on the event weight. Fundamentally, the interplay between
density and uncertainty estimates indicates that these networks learn functions
in analogy to parameter fits rather than binned event counts.</p>
  </details>
</details>
<h1>人工智能</h1>
<details>
  <summary>1. <b>标题：Walk These Ways: Tuning Robot Control for Generalization with  Multiplicity of Behavior</b></summary>
  <p><b>编号</b>：[4]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.03238</p>
  <p><b>作者</b>：Gabriel B Margolis,  Pulkit Agrawal</p>
  <p><b>备注</b>：Oral presentation at CoRL 2022. Website at this https URL</p>
  <p><b>关键词</b>：Learned locomotion policies, policies can rapidly, rapidly adapt, lack a mechanism, diverse environments similar</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Learned locomotion policies can rapidly adapt to diverse environments similar
to those experienced during training but lack a mechanism for fast tuning when
they fail in an out-of-distribution test environment. This necessitates a slow
and iterative cycle of reward and environment redesign to achieve good
performance on a new task. As an alternative, we propose learning a single
policy that encodes a structured family of locomotion strategies that solve
training tasks in different ways, resulting in Multiplicity of Behavior (MoB).
Different strategies generalize differently and can be chosen in real-time for
new tasks or environments, bypassing the need for time-consuming retraining. We
release a fast, robust open-source MoB locomotion controller, Walk These Ways,
that can execute diverse gaits with variable footswing, posture, and speed,
unlocking diverse downstream tasks: crouching, hopping, high-speed running,
stair traversal, bracing against shoves, rhythmic dance, and more. Video and
code release: this https URL</p>
  </details>
</details>
<details>
  <summary>2. <b>标题：Towards A Most Probable Recovery in Optical Imaging</b></summary>
  <p><b>编号</b>：[7]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.03235</p>
  <p><b>作者</b>：Nadav Torem,  Roi Ronen,  Yoav Y. Schechner,  Michael Elad</p>
  <p><b>备注</b>：24 pages, 21 figures</p>
  <p><b>关键词</b>：complex-valued field, imaged objects, unknown imaged objects, imaged, field</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Light is a complex-valued field. The intensity and phase of the field are
affected by imaged objects. However, imaging sensors measure only real-valued
non-negative intensities. This results in a nonlinear relation between the
measurements and the unknown imaged objects. Moreover, the sensor readouts are
corrupted by Poissonian-distributed photon noise. In this work, we seek the
most probable object (or clear image), given noisy measurements, that is,
maximizing the a-posteriori probability of the sought variables. Hence, we
generalize annealed Langevin dynamics, tackling fundamental challenges in
optical imaging, including phase recovery and Poisson (photon) denoising. We
leverage deep neural networks, not for explicit recovery of the imaged object,
but as an approximate gradient for a prior term. We show results on empirical
data, acquired by a real experiment. We further show results of simulations.</p>
  </details>
</details>
<details>
  <summary>3. <b>标题：Learning the joint distribution of two sequences using little or no  paired data</b></summary>
  <p><b>编号</b>：[8]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.03232</p>
  <p><b>作者</b>：Soroosh Mariooryad,  Matt Shannon,  Siyuan Ma,  Tom Bagby,  David Kao,  Daisy Stanton,  Eric Battenberg,  RJ Skerry-Ryan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：noisy channel generative, channel generative model, limited paired data, text and speech, present a noisy</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present a noisy channel generative model of two sequences, for example
text and speech, which enables uncovering the association between the two
modalities when limited paired data is available. To address the intractability
of the exact model under a realistic data setup, we propose a variational
inference approximation. To train this variational model with categorical data,
we propose a KL encoder loss approach which has connections to the wake-sleep
algorithm. Identifying the joint or conditional distributions by only observing
unpaired samples from the marginals is only possible under certain conditions
in the data distribution and we discuss under what type of conditional
independence assumptions that might be achieved, which guides the architecture
designs. Experimental results show that even tiny amount of paired data (5
minutes) is sufficient to learn to relate the two modalities (graphemes and
phonemes here) when a massive amount of unpaired data is available, paving the
path to adopting this principled approach for all seq2seq models in low data
resource regimes.</p>
  </details>
</details>
<details>
  <summary>4. <b>标题：Visual Query Tuning: Towards Effective Usage of Intermediate  Representations for Parameter and Memory Efficient Transfer Learning</b></summary>
  <p><b>编号</b>：[14]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.03220</p>
  <p><b>作者</b>：Cheng-Hao Tu,  Zheda Mai,  Wei-Lun Chao</p>
  <p><b>备注</b>：Cheng-Hao Tu and Zheda Mai contributed equally to this work</p>
  <p><b>关键词</b>：Intermediate features, features, pre-trained model, VQT, shown informative</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Intermediate features of a pre-trained model have been shown informative for
making accurate predictions on downstream tasks, even if the model backbone is
kept frozen. The key challenge is how to utilize these intermediate features
given their gigantic amount. We propose visual query tuning (VQT), a simple yet
effective approach to aggregate intermediate features of Vision Transformers.
Through introducing a handful of learnable ``query'' tokens to each layer, VQT
leverages the inner workings of Transformers to ``summarize'' rich intermediate
features of each layer, which can then be used to train the prediction heads of
downstream tasks. As VQT keeps the intermediate features intact and only learns
to combine them, it enjoys memory efficiency in training, compared to many
other parameter-efficient fine-tuning approaches that learn to adapt features
and need back-propagation through the entire backbone. This also suggests the
complementary role between VQT and those approaches in transfer learning.
Empirically, VQT consistently surpasses the state-of-the-art approach that
utilizes intermediate features for transfer learning and outperforms full
fine-tuning in many cases. Compared to parameter-efficient approaches that
adapt features, VQT achieves much higher accuracy under memory constraints.
Most importantly, VQT is compatible with these approaches to attain even higher
accuracy, making it a simple add-on to further boost transfer learning.</p>
  </details>
</details>
<details>
  <summary>5. <b>标题：The AI Definition and a Program Which Satisfies this Definition</b></summary>
  <p><b>编号</b>：[24]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.03184</p>
  <p><b>作者</b>：Dimiter Dobrev</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：performing policy, policy, program, performing, language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We will consider all policies of the agent and will prove that one of them is
the best performing policy. While that policy is not computable, computable
policies do exist in its proximity. We will define AI as a computable policy
which is sufficiently proximal to the best performing policy. Before we can
define the agent's best performing policy, we need a language for description
of the world. We will also use this language to develop a program which
satisfies the AI definition. The program will first understand the world by
describing it in the selected language. The program will then use the
description in order to predict the future and select the best possible move.
While this program is extremely inefficient and practically unusable, it can be
improved by refining both the language for description of the world and the
algorithm used to predict the future. This can yield a program which is both
efficient and consistent with the AI definition.</p>
  </details>
</details>
<details>
  <summary>6. <b>标题：Overlapping oriented imbalanced ensemble learning method based on  projective clustering and stagewise hybrid sampling</b></summary>
  <p><b>编号</b>：[26]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.03182</p>
  <p><b>作者</b>：Fan Li,  Bo Wang,  Pin Wang,  Yongming Li</p>
  <p><b>备注</b>：23 pages, 3 figures</p>
  <p><b>关键词</b>：class imbalance problem, imbalanced learning lies, imbalance problem, class overlapping problem, challenge of imbalanced</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The challenge of imbalanced learning lies not only in class imbalance
problem, but also in the class overlapping problem which is complex. However,
most of the existing algorithms mainly focus on the former. The limitation
prevents the existing methods from breaking through. To address this
limitation, this paper proposes an ensemble learning algorithm based on dual
clustering and stage-wise hybrid sampling (DCSHS). The DCSHS has three parts.
Firstly, we design a projection clustering combination framework (PCC) guided
by Davies-Bouldin clustering effectiveness index (DBI), which is used to obtain
high-quality clusters and combine them to obtain a set of cross-complete
subsets (CCS) with balanced class and low overlapping. Secondly, according to
the characteristics of subset classes, a stage-wise hybrid sampling algorithm
is designed to realize the de-overlapping and balancing of subsets. Finally, a
projective clustering transfer mapping mechanism (CTM) is constructed for all
processed subsets by means of transfer learning, thereby reducing class
overlapping and explore structure information of samples. The major advantage
of our algorithm is that it can exploit the intersectionality of the CCS to
realize the soft elimination of overlapping majority samples, and learn as much
information of overlapping samples as possible, thereby enhancing the class
overlapping while class balancing. In the experimental section, more than 30
public datasets and over ten representative algorithms are chosen for
verification. The experimental results show that the DCSHS is significantly
best in terms of various evaluation criteria.</p>
  </details>
</details>
<details>
  <summary>7. <b>标题：Reinforcement Learning for Signal Temporal Logic using Funnel-Based  Approach</b></summary>
  <p><b>编号</b>：[27]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.03181</p>
  <p><b>作者</b>：Naman Saxena,  Gorantla Sandeep,  Pushpak Jagtap</p>
  <p><b>备注</b>：11 pages, 6 figures</p>
  <p><b>关键词</b>：Signal Temporal Logic, Temporal Logic, Signal Temporal, complex temporal, continuous state space</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Signal Temporal Logic (STL) is a powerful framework for describing the
complex temporal and logical behaviour of the dynamical system. Several works
propose a method to find a controller for the satisfaction of STL specification
using reinforcement learning but fail to address either the issue of robust
satisfaction in continuous state space or ensure the tractability of the
approach. In this paper, leveraging the concept of funnel functions, we propose
a tractable reinforcement learning algorithm to learn a time-dependent policy
for robust satisfaction of STL specification in continuous state space. We
demonstrate the utility of our approach on several tasks using a pendulum and
mobile robot examples.</p>
  </details>
</details>
<details>
  <summary>8. <b>标题：Where the Bee Sucks -- A Dynamic Bayesian Network Approach to Decision  Support for Pollinator Abundance Strategies</b></summary>
  <p><b>编号</b>：[28]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.03179</p>
  <p><b>作者</b>：Martine J. Barons,  Aditi Shenvi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：make evidence-based decisions, wishing to make, make evidence-based, combine the relevant, coherent and defensible</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>For policymakers wishing to make evidence-based decisions, one of the
challenges is how to combine the relevant information and evidence in a
coherent and defensible manner in order to formulate and evaluate candidate
policies. Policymakers often need to rely on experts with disparate fields of
expertise when making policy choices in complex, multi-faceted, dynamic
environments such as those dealing with ecosystem services. The pressures
affecting the survival and pollination capabilities of honey bees (Apis
mellifera), wild bees and other pollinators is well-documented, but incomplete.
In order to estimate the potential effectiveness of various candidate policies
to support pollination services, there is an urgent need to quantify the effect
of various combinations of variables on the pollination ecosystem service,
utilising available information, models and expert judgement. In this paper, we
present a new application of the integrating decision support system
methodology for combining inputs from multiple panels of experts to evaluate
policies to support an abundant pollinator population.</p>
  </details>
</details>
<details>
  <summary>9. <b>标题：Longest Common Substring in Longest Common Subsequence's Solution  Service: A Novel Hyper-Heuristic</b></summary>
  <p><b>编号</b>：[29]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.03178</p>
  <p><b>作者</b>：Alireza Abdi,  Masih Hajsaeedi,  Mohsen Hooshmand</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Longest Common Subsequence, Longest Common, Common Subsequence, set, general longest common</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The Longest Common Subsequence (LCS) is the problem of finding a subsequence
among a set of strings that has two properties of being common to all and is
the longest. The LCS has applications in computational biology and text
editing, among many others. Due to the NP-hardness of the general longest
common subsequence, numerous heuristic algorithms and solvers have been
proposed to give the best possible solution for different sets of strings. None
of them has the best performance for all types of sets. In addition, there is
no method to specify the type of a given set of strings. Besides that, the
available hyper-heuristic is not efficient and fast enough to solve this
problem in real-world applications. This paper proposes a novel hyper-heuristic
to solve the longest common subsequence problem using a novel criterion to
classify a set of strings based on their similarity. To do this, we offer a
general stochastic framework to identify the type of a given set of strings.
Following that, we introduce the set similarity dichotomizer ($S^2D$) algorithm
based on the framework that divides the type of sets into two. This algorithm
is introduced for the first time in this paper and opens a new way to go beyond
the current LCS solvers. Then, we present a novel hyper-heuristic that exploits
the $S^2D$ and one of the internal properties of the set to choose the best
matching heuristic among a set of heuristics. We compare the results on
benchmark datasets with the best heuristics and hyper-heuristics. The results
show a higher performance of our proposed hyper-heuristic in both quality of
solutions and run time factors.</p>
  </details>
</details>
<details>
  <summary>10. <b>标题：Learning Representations that Enable Generalization in Assistive Tasks</b></summary>
  <p><b>编号</b>：[31]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.03175</p>
  <p><b>作者</b>：Jerry Zhi-Yang He,  Aditi Raghunathan,  Daniel S. Brown,  Zackory Erickson,  Anca D. Dragan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：successfully enabled robots, domain randomization, successfully enabled, Recent work, human</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent work in sim2real has successfully enabled robots to act in physical
environments by training in simulation with a diverse ''population'' of
environments (i.e. domain randomization). In this work, we focus on enabling
generalization in assistive tasks: tasks in which the robot is acting to assist
a user (e.g. helping someone with motor impairments with bathing or with
scratching an itch). Such tasks are particularly interesting relative to prior
sim2real successes because the environment now contains a human who is also
acting. This complicates the problem because the diversity of human users
(instead of merely physical environment parameters) is more difficult to
capture in a population, thus increasing the likelihood of encountering
out-of-distribution (OOD) human policies at test time. We advocate that
generalization to such OOD policies benefits from (1) learning a good latent
representation for human policies that test-time humans can accurately be
mapped to, and (2) making that representation adaptable with test-time
interaction data, instead of relying on it to perfectly capture the space of
human policies based on the simulated population only. We study how to best
learn such a representation by evaluating on purposefully constructed OOD test
policies. We find that sim2real methods that encode environment (or population)
parameters and work well in tasks that robots do in isolation, do not work well
in assistance. In assistance, it seems crucial to train the representation
based on the history of interaction directly, because that is what the robot
will have access to at test time. Further, training these representations to
then predict human actions not only gives them better structure, but also
enables them to be fine-tuned at test-time, when the robot observes the partner
act. this https URL.</p>
  </details>
</details>
<details>
  <summary>11. <b>标题：Neural Machine Translation with Contrastive Translation Memories</b></summary>
  <p><b>编号</b>：[42]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.03140</p>
  <p><b>作者</b>：Xin Cheng,  Shen Gao,  Lemao Liu,  Dongyan Zhao,  Rui Yan</p>
  <p><b>备注</b>：EMNLP2022 Main Conference</p>
  <p><b>关键词</b>：Retrieval-augmented Neural Machine, Neural Machine Translation, Neural Machine, Machine Translation models, Retrieval-augmented Neural</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Retrieval-augmented Neural Machine Translation models have been successful in
many translation scenarios. Different from previous works that make use of
mutually similar but redundant translation memories~(TMs), we propose a new
retrieval-augmented NMT to model contrastively retrieved translation memories
that are holistically similar to the source sentence while individually
contrastive to each other providing maximal information gains in three phases.
First, in TM retrieval phase, we adopt a contrastive retrieval algorithm to
avoid redundancy and uninformativeness of similar translation pieces. Second,
in memory encoding stage, given a set of TMs we propose a novel Hierarchical
Group Attention module to gather both local context of each TM and global
context of the whole TM set. Finally, in training phase, a Multi-TM contrastive
learning objective is introduced to learn salient feature of each TM with
respect to target sentence. Experimental results show that our framework
obtains improvements over strong baselines on the benchmark datasets.</p>
  </details>
</details>
<details>
  <summary>12. <b>标题：Explainability as statistical inference</b></summary>
  <p><b>编号</b>：[44]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.03131</p>
  <p><b>作者</b>：Hugo Henri Joseph Senetaire,  Damien Garreau,  Jes Frellsen,  Pierre-Alexandre Mattei</p>
  <p><b>备注</b>：10 pages, 22 figures, submitted at ICLR 2023</p>
  <p><b>关键词</b>：model explanation approaches, recent years, rationales and heuristics, wide variety, explanation approaches</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A wide variety of model explanation approaches have been proposed in recent
years, all guided by very different rationales and heuristics. In this paper,
we take a new route and cast interpretability as a statistical inference
problem. We propose a general deep probabilistic model designed to produce
interpretable predictions. The model parameters can be learned via maximum
likelihood, and the method can be adapted to any predictor network architecture
and any type of prediction problem. Our method is a case of amortized
interpretability models, where a neural network is used as a selector to allow
for fast interpretation at inference time. Several popular interpretability
methods are shown to be particular cases of regularised maximum likelihood for
our general model. We propose new datasets with ground truth selection which
allow for the evaluation of the features importance map. Using these datasets,
we show experimentally that using multiple imputation provides more reasonable
interpretations.</p>
  </details>
</details>
<details>
  <summary>13. <b>标题：A Comprehensively Improved Hybrid Algorithm for Learning Bayesian  Networks: Multiple Compound Memory Erasing</b></summary>
  <p><b>编号</b>：[53]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.03103</p>
  <p><b>作者</b>：Baokui Mou</p>
  <p><b>备注</b>：Bayesian networks, Structure learning, Conditional independence tests, Scoring function</p>
  <p><b>关键词</b>：Bayesian network, hot spot, analyze the causal, causal relationship, network generation methods</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Using a Bayesian network to analyze the causal relationship between nodes is
a hot spot. The existing network learning algorithms are mainly
constraint-based and score-based network generation methods. The
constraint-based method is mainly the application of conditional independence
(CI) tests, but the inaccuracy of CI tests in the case of high dimensionality
and small samples has always been a problem for the constraint-based method.
The score-based method uses the scoring function and search strategy to find
the optimal candidate network structure, but the search space increases too
much with the increase of the number of nodes, and the learning efficiency is
very low. This paper presents a new hybrid algorithm, MCME (multiple compound
memory erasing). This method retains the advantages of the first two methods,
solves the shortcomings of the above CI tests, and makes innovations in the
scoring function in the direction discrimination stage. A large number of
experiments show that MCME has better or similar performance than some existing
algorithms.</p>
  </details>
</details>
<details>
  <summary>14. <b>标题：Interpretation of Neural Networks is Susceptible to Universal  Adversarial Perturbations</b></summary>
  <p><b>编号</b>：[57]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.03095</p>
  <p><b>作者</b>：Haniyeh Ehsani Oskouie,  Farzan Farnia</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：deep learning literature, learning literature, standard image datasets, Interpreting neural network, extensively studied</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Interpreting neural network classifiers using gradient-based saliency maps
has been extensively studied in the deep learning literature. While the
existing algorithms manage to achieve satisfactory performance in application
to standard image recognition datasets, recent works demonstrate the
vulnerability of widely-used gradient-based interpretation schemes to
norm-bounded perturbations adversarially designed for every individual input
sample. However, such adversarial perturbations are commonly designed using the
knowledge of an input sample, and hence perform sub-optimally in application to
an unknown or constantly changing data point. In this paper, we show the
existence of a Universal Perturbation for Interpretation (UPI) for standard
image datasets, which can alter a gradient-based feature map of neural networks
over a significant fraction of test samples. To design such a UPI, we propose a
gradient-based optimization method as well as a principal component analysis
(PCA)-based approach to compute a UPI which can effectively alter a neural
network's gradient-based interpretation on different samples. We support the
proposed UPI approaches by presenting several numerical results of their
successful applications to standard image datasets.</p>
  </details>
</details>
<details>
  <summary>15. <b>标题：An Empirical Study on the Efficacy of Deep Active Learning for Image  Classification</b></summary>
  <p><b>编号</b>：[61]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.03088</p>
  <p><b>作者</b>：Yu Li,  Muxi Chen,  Yannan Liu,  Daojing He,  Qiang Xu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Deep Active Learning, Active Learning, reduce labeling costs, Deep Active, supervised learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep Active Learning (DAL) has been advocated as a promising method to reduce
labeling costs in supervised learning. However, existing evaluations of DAL
methods are based on different settings, and their results are controversial.
To tackle this issue, this paper comprehensively evaluates 19 existing DAL
methods in a uniform setting, including traditional
fully-\underline{s}upervised \underline{a}ctive \underline{l}earning (SAL)
strategies and emerging \underline{s}emi-\underline{s}upervised
\underline{a}ctive \underline{l}earning (SSAL) techniques. We have several
non-trivial findings. First, most SAL methods cannot achieve higher accuracy
than random selection. Second, semi-supervised training brings significant
performance improvement compared to pure SAL methods. Third, performing data
selection in the SSAL setting can achieve a significant and consistent
performance improvement, especially with abundant unlabeled data. Our findings
produce the following guidance for practitioners: one should (i) apply SSAL
early and (ii) collect more unlabeled data whenever possible, for better model
performance.</p>
  </details>
</details>
<details>
  <summary>16. <b>标题：Land Use Prediction using Electro-Optical to SAR Few-Shot Transfer  Learning</b></summary>
  <p><b>编号</b>：[64]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.03084</p>
  <p><b>作者</b>：Marcel Hussing,  Karen Li,  Eric Eaton</p>
  <p><b>备注</b>：Published at Tackling Climate Change with Machine Learning workshop at NeurIPS 2022</p>
  <p><b>关键词</b>：ecosystem monitoring, Satellite image analysis, important implications, implications for land, image analysis</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Satellite image analysis has important implications for land use,
urbanization, and ecosystem monitoring. Deep learning methods can facilitate
the analysis of different satellite modalities, such as electro-optical (EO)
and synthetic aperture radar (SAR) imagery, by supporting knowledge transfer
between the modalities to compensate for individual shortcomings. Recent
progress has shown how distributional alignment of neural network embeddings
can produce powerful transfer learning models by employing a sliced Wasserstein
distance (SWD) loss. We analyze how this method can be applied to Sentinel-1
and -2 satellite imagery and develop several extensions toward making it
effective in practice. In an application to few-shot Local Climate Zone (LCZ)
prediction, we show that these networks outperform multiple common baselines on
datasets with a large number of classes. Further, we provide evidence that
instance normalization can significantly stabilize the training process and
that explicitly shaping the embedding space using supervised contrastive
learning can lead to improved performance.</p>
  </details>
</details>
<details>
  <summary>17. <b>标题：Active Classification of Moving Targets with Learned Control Policies</b></summary>
  <p><b>编号</b>：[73]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.03068</p>
  <p><b>作者</b>：Álvaro Serra-Gómez (1),  Eduardo Montijano (2),  Wendelin Böhmer (3),  Javier Alonso-Mora (1) ((1) Department of Cognitive Robotics, Delft University of Technology, (2) Department of Informatics and Systems Engineering, Universidad de Zaragoza, (3) Department of Software Technology, Delft University of Technology)</p>
  <p><b>备注</b>：8 pages, 6 figures, Submitted to IEEE RA-L</p>
  <p><b>关键词</b>：classify multiple moving, collect semantic information, multiple moving targets, collect semantic, classify multiple</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we consider the problem where a drone has to collect semantic
information to classify multiple moving targets. In particular, we address the
challenge of computing control inputs that move the drone to informative
viewpoints, position and orientation, when the information is extracted using a
``black-box'' classifier, e.g., a deep learning neural network. These
algorithms typically lack of analytical relationships between the viewpoints
and their associated outputs, preventing their use in information-gathering
schemes. To fill this gap, we propose a novel attention-based architecture,
trained via Reinforcement Learning (RL), that outputs the next viewpoint for
the drone favoring the acquisition of evidence from as many unclassified
targets as possible while reasoning about their movement, orientation, and
occlusions. Then, we use a low-level MPC controller to move the drone to the
desired viewpoint taking into account its actual dynamics. We show that our
approach not only outperforms a variety of baselines but also generalizes to
scenarios unseen during training. Additionally, we show that the network scales
to large numbers of targets and generalizes well to different movement dynamics
of the targets.</p>
  </details>
</details>
<details>
  <summary>18. <b>标题：Front-door Adjustment via Style Transfer for Out-of-distribution  Generalisation</b></summary>
  <p><b>编号</b>：[75]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.03063</p>
  <p><b>作者</b>：Toan Nguyen,  Kien Do,  Duc Thanh Nguyen,  Bao Duong,  Thin Nguyen</p>
  <p><b>备注</b>：22 pages, 15 figures</p>
  <p><b>关键词</b>：generalisation aims, OOD image classification, aims to build, generalise its learnt, learnt knowledge</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Out-of-distribution (OOD) generalisation aims to build a model that can well
generalise its learnt knowledge from source domains to an unseen target domain.
However, current image classification models often perform poorly in the OOD
setting due to statistically spurious correlations learning from model
training. From causality-based perspective, we formulate the data generation
process in OOD image classification using a causal graph. On this graph, we
show that prediction P(Y|X) of a label Y given an image X in statistical
learning is formed by both causal effect P(Y|do(X)) and spurious effects caused
by confounding features (e.g., background). Since the spurious features are
domain-variant, the prediction P(Y|X) becomes unstable on unseen domains. In
this paper, we propose to mitigate the spurious effect of confounders using
front-door adjustment. In our method, the mediator variable is hypothesized as
semantic features that are essential to determine a label for an image.
Inspired by capability of style transfer in image generation, we interpret the
combination of the mediator variable with different generated images in the
front-door formula and propose novel algorithms to estimate it. Extensive
experimental results on widely used benchmark datasets verify the effectiveness
of our method.</p>
  </details>
</details>
<details>
  <summary>19. <b>标题：Towards a more efficient computation of individual attribute and policy  contribution for post-hoc explanation of cooperative multi-agent systems  using Myerson values</b></summary>
  <p><b>编号</b>：[81]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.03041</p>
  <p><b>作者</b>：Giorgio Angelotti,  Natalia Díaz-Rodríguez</p>
  <p><b>备注</b>：Accepted for publication in Elsevier's Knowledge-Based Systems</p>
  <p><b>关键词</b>：gold for strategists, sports coaches, quantitative assessment, valuable as gold, agent</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A quantitative assessment of the global importance of an agent in a team is
as valuable as gold for strategists, decision-makers, and sports coaches. Yet,
retrieving this information is not trivial since in a cooperative task it is
hard to isolate the performance of an individual from the one of the whole
team. Moreover, it is not always clear the relationship between the role of an
agent and his personal attributes. In this work we conceive an application of
the Shapley analysis for studying the contribution of both agent policies and
attributes, putting them on equal footing. Since the computational complexity
is NP-hard and scales exponentially with the number of participants in a
transferable utility coalitional game, we resort to exploiting a-priori
knowledge about the rules of the game to constrain the relations between the
participants over a graph. We hence propose a method to determine a
Hierarchical Knowledge Graph of agents' policies and features in a Multi-Agent
System. Assuming a simulator of the system is available, the graph structure
allows to exploit dynamic programming to assess the importances in a much
faster way. We test the proposed approach in a proof-of-case environment
deploying both hardcoded policies and policies obtained via Deep Reinforcement
Learning. The proposed paradigm is less computationally demanding than
trivially computing the Shapley values and provides great insight not only into
the importance of an agent in a team but also into the attributes needed to
deploy the policy at its best.</p>
  </details>
</details>
<details>
  <summary>20. <b>标题：SODA: A Natural Language Processing Package to Extract Social  Determinants of Health for Cancer Studies</b></summary>
  <p><b>编号</b>：[96]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.03000</p>
  <p><b>作者</b>：Zehao Yu,  Xi Yang,  Chong Dang,  Prakash Adekkanattu,  Braja Gopal Patra,  Yifan Peng,  Jyotishman Pathak,  Debbie L. Wilson,  Ching-Yuan Chang,  Wei-Hsuan Lo-Ciganic,  Thomas J. George,  William R. Hogan,  Yi Guo,  Jiang Bian,  Yonghui Wu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：extract social determinants, natural language processing, SOcial DeterminAnts, open-source natural language, NLP models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Objective: We aim to develop an open-source natural language processing (NLP)
package, SODA (i.e., SOcial DeterminAnts), with pre-trained transformer models
to extract social determinants of health (SDoH) for cancer patients, examine
the generalizability of SODA to a new disease domain (i.e., opioid use), and
evaluate the extraction rate of SDoH using cancer populations.
Methods: We identified SDoH categories and attributes and developed an SDoH
corpus using clinical notes from a general cancer cohort. We compared four
transformer-based NLP models to extract SDoH, examined the generalizability of
NLP models to a cohort of patients prescribed with opioids, and explored
customization strategies to improve performance. We applied the best NLP model
to extract 19 categories of SDoH from the breast (n=7,971), lung (n=11,804),
and colorectal cancer (n=6,240) cohorts.
Results and Conclusion: We developed a corpus of 629 cancer patients notes
with annotations of 13,193 SDoH concepts/attributes from 19 categories of SDoH.
The Bidirectional Encoder Representations from Transformers (BERT) model
achieved the best strict/lenient F1 scores of 0.9216 and 0.9441 for SDoH
concept extraction, 0.9617 and 0.9626 for linking attributes to SDoH concepts.
Fine-tuning the NLP models using new annotations from opioid use patients
improved the strict/lenient F1 scores from 0.8172/0.8502 to 0.8312/0.8679. The
extraction rates among 19 categories of SDoH varied greatly, where 10 SDoH
could be extracted from >70% of cancer patients, but 9 SDoH had a low
extraction rate (<70% of cancer patients). the soda package with pre-trained transformer models is publicly available at this https url.< p>
  </70%></p></details>
</details>
<details>
  <summary>21. <b>标题：Super-resolution Probabilistic Rain Prediction from Satellite Data Using  3D U-Nets and EarthFormers</b></summary>
  <p><b>编号</b>：[97]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02998</p>
  <p><b>作者</b>：Yang Li,  Haiyu Dong,  Zuliang Fang,  Jonathan Weyn,  Pete Luferenko</p>
  <p><b>备注</b>：Weather4cast-2022 & NeurIPS</p>
  <p><b>关键词</b>：rain prediction, Accurate and timely, challenging task, timely rain prediction, crucial for decision</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Accurate and timely rain prediction is crucial for decision making and is
also a challenging task. This paper presents a solution which won the 2 nd
prize in the Weather4cast 2022 NeurIPS competition using 3D U-Nets and
EarthFormers for 8-hour probabilistic rain prediction based on multi-band
satellite images. The spatial context effect of the input satellite image has
been deeply explored and optimal context range has been found. Based on the
imbalanced rain distribution, we trained multiple models with different loss
functions. To further improve the model performance, multi-model ensemble and
threshold optimization were used to produce the final probabilistic rain
prediction. Experiment results and leaderboard scores demonstrate that optimal
spatial context, combined loss function, multi-model ensemble, and threshold
optimization all provide modest model gain. A permutation test was used to
analyze the effect of each satellite band on rain prediction, and results show
that satellite bands signifying cloudtop phase (8.7 um) and cloud-top height
(10.8 and 13.4 um) are the best predictors for rain prediction. The source code
is available at this https URL.</p>
  </details>
</details>
<details>
  <summary>22. <b>标题：Multi-Layer Personalized Federated Learning for Mitigating Biases in  Student Predictive Analytics</b></summary>
  <p><b>编号</b>：[102]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02985</p>
  <p><b>作者</b>：Yun-Wei Chu,  Seyyedali Hosseinalipour,  Elizabeth Tenorio,  Laura Cruz,  Kerrie Douglas,  Andrew Lan,  Christopher Brinton</p>
  <p><b>备注</b>：arXiv admin note: substantial text overlap with arXiv:2208.01182</p>
  <p><b>关键词</b>：Traditional learning-based approaches, predicting grades based, minority student groups, Personalized Federated Learning, student groups due</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Traditional learning-based approaches to student modeling (e.g., predicting
grades based on measured activities) generalize poorly to
underrepresented/minority student groups due to biases in data availability. In
this paper, we propose a Multi-Layer Personalized Federated Learning (MLPFL)
methodology which optimizes inference accuracy over different layers of student
grouping criteria, such as by course and by demographic subgroups within each
course. In our approach, personalized models for individual student subgroups
are derived from a global model, which is trained in a distributed fashion via
meta-gradient updates that account for subgroup heterogeneity while preserving
modeling commonalities that exist across the full dataset. To evaluate our
methodology, we consider case studies of two popular downstream student
modeling tasks, knowledge tracing and outcome prediction, which leverage
multiple modalities of student behavior (e.g., visits to lecture videos and
participation on forums) in model training. Experiments on three real-world
datasets from online courses demonstrate that our approach obtains substantial
improvements over existing student modeling baselines in terms of increasing
the average and decreasing the variance of prediction quality across different
student subgroups. Visual analysis of the resulting students' knowledge state
embeddings confirm that our personalization methodology extracts activity
patterns which cluster into different student subgroups, consistent with the
performance enhancements we obtain over the baselines.</p>
  </details>
</details>
<details>
  <summary>23. <b>标题：Denoising diffusion probabilistic models for probabilistic energy  forecasting</b></summary>
  <p><b>编号</b>：[104]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02977</p>
  <p><b>作者</b>：Esteban Hernandez,  Jonathan Dumas</p>
  <p><b>备注</b>：Version submitted to Powertech 2023. arXiv admin note: text overlap with arXiv:2106.09370, arXiv:2107.01034</p>
  <p><b>关键词</b>：Scenario-based probabilistic forecasts, renewable energies, vital tool, tool to equip, equip decision-makers</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Scenario-based probabilistic forecasts have become a vital tool to equip
decision-makers to address the uncertain nature of renewable energies. This
paper presents a recent promising deep learning generative approach: denoising
diffusion probabilistic models. It is a class of latent variable models that
have recently demonstrated impressive results in the computer vision community.
However, to the best of our knowledge, there has yet to be a demonstration that
they can generate high-quality samples of load, PV, or wind power time series
that are crucial to face the new challenges in power systems applications.
Thus, we propose the first implementation of this model for energy forecasting
using the open data of the Global Energy Forecasting Competition 2014. The
results demonstrate that this approach is competitive with other
state-of-the-art deep learning generative models: generative adversarial
networks, variational autoencoders, and normalizing flows.</p>
  </details>
</details>
<details>
  <summary>24. <b>标题：State Space Closure: Revisiting Endless Online Level Generation via  Reinforcement Learning</b></summary>
  <p><b>编号</b>：[113]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02951</p>
  <p><b>作者</b>：Ziqi Wang,  Tianye Shu,  Jialin Liu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：generate recurrent patterns, recently proposed experience-driven, proposed experience-driven procedural, state space closure, revisit endless online</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper we revisit endless online level generation with the recently
proposed experience-driven procedural content generation via reinforcement
learning (EDRL) framework, from an observation that EDRL tends to generate
recurrent patterns. Inspired by this phenomenon, we formulate a notion of state
space closure, which means that any state that may appear in an
infinite-horizon online generation process can be found in a finite horizon.
Through theoretical analysis we find that though state space closure arises a
concern about diversity, it makes the EDRL trained on a finite-horizon
generalised to the infinite-horizon scenario without deterioration of content
quality. Moreover, we verify the quality and diversity of contents generated by
EDRL via empirical studies on the widely used Super Mario Bros. benchmark.
Experimental results reveal that the current EDRL approach's ability of
generating diverse game levels is limited due to the state space closure,
whereas it does not suffer from reward deterioration given a horizon longer
than the one of training. Concluding our findings and analysis, we argue that
future works in generating online diverse and high-quality contents via EDRL
should address the issue of diversity on the premise of state space closure
which ensures the quality.</p>
  </details>
</details>
<details>
  <summary>25. <b>标题：Learning to Bound Counterfactual Inference in Structural Causal Models  from Observational and Randomised Data</b></summary>
  <p><b>编号</b>：[120]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02932</p>
  <p><b>作者</b>：Marco Zaffalon,  Alessandro Antonucci,  David Huber,  Rafael Cabañas</p>
  <p><b>备注</b>：13 pages</p>
  <p><b>关键词</b>：structural causal models, observational and interventional, interventional studies, studies to eventually, structural causal</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We address the problem of integrating data from multiple observational and
interventional studies to eventually compute counterfactuals in structural
causal models. We derive a likelihood characterisation for the overall data
that leads us to extend a previous EM-based algorithm from the case of a single
study to that of multiple ones. The new algorithm learns to approximate the
(unidentifiability) region of model parameters from such mixed data sources. On
this basis, it delivers interval approximations to counterfactual results,
which collapse to points in the identifiable case. The algorithm is very
general, it works on semi-Markovian models with discrete variables and can
compute any counterfactual. Moreover, it automatically determines if a problem
is feasible (the parameter region being nonempty), which is a necessary step
not to yield incorrect results. Systematic numerical experiments show the
effectiveness and accuracy of the algorithm, while hinting at the benefits of
integrating heterogeneous data to get informative bounds in case of
unidentifiability.</p>
  </details>
</details>
<details>
  <summary>26. <b>标题：Scalable Planning and Learning Framework Development for Swarm-to-Swarm  Engagement Problems</b></summary>
  <p><b>编号</b>：[130]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02909</p>
  <p><b>作者</b>：Umut Demir,  A. Sadik Satir,  Gulay Goktas Sever,  Cansu Yikilmaz,  Nazim Kemal Ure</p>
  <p><b>备注</b>：Accepted to SciTech2023</p>
  <p><b>关键词</b>：attracted significant attention, swarms attracted significant, Development of guidance, navigation and control, recent years</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Development of guidance, navigation and control frameworks/algorithms for
swarms attracted significant attention in recent years. That being said,
algorithms for planning swarm allocations/trajectories for engaging with enemy
swarms is largely an understudied problem. Although small-scale scenarios can
be addressed with tools from differential game theory, existing approaches fail
to scale for large-scale multi-agent pursuit evasion (PE) scenarios. In this
work, we propose a reinforcement learning (RL) based framework to decompose to
large-scale swarm engagement problems into a number of independent multi-agent
pursuit-evasion games. We simulate a variety of multi-agent PE scenarios, where
finite time capture is guaranteed under certain conditions. The calculated PE
statistics are provided as a reward signal to the high level allocation layer,
which uses an RL algorithm to allocate controlled swarm units to eliminate
enemy swarm units with maximum efficiency. We verify our approach in
large-scale swarm-to-swarm engagement simulations.</p>
  </details>
</details>
<details>
  <summary>27. <b>标题：Towards human-compatible autonomous car: A study of non-verbal Turing  test in automated driving with affective transition modelling</b></summary>
  <p><b>编号</b>：[131]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02908</p>
  <p><b>作者</b>：Zhaoning Li,  Qiaoli Jiang,  Zhengming Wu,  Anqi Liu,  Haiyan Wu,  Miner Huang,  Kai Huang,  Yixuan Ku</p>
  <p><b>备注</b>：16 pages, 9 figures, 3 tables</p>
  <p><b>关键词</b>：Autonomous cars, hands-free route, Autonomous, current autonomous cars, human</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Autonomous cars are indispensable when humans go further down the hands-free
route. Although existing literature highlights that the acceptance of the
autonomous car will increase if it drives in a human-like manner, sparse
research offers the naturalistic experience from a passenger's seat perspective
to examine the human likeness of current autonomous cars. The present study
tested whether the AI driver could create a human-like ride experience for
passengers based on 69 participants' feedback in a real-road scenario. We
designed a ride experience-based version of the non-verbal Turing test for
automated driving. Participants rode in autonomous cars (driven by either human
or AI drivers) as a passenger and judged whether the driver was human or AI.
The AI driver failed to pass our test because passengers detected the AI driver
above chance. In contrast, when the human driver drove the car, the passengers'
judgement was around chance. We further investigated how human passengers
ascribe humanness in our test. Based on Lewin's field theory, we advanced a
computational model combining signal detection theory with pre-trained language
models to predict passengers' humanness rating behaviour. We employed affective
transition between pre-study baseline emotions and corresponding post-stage
emotions as the signal strength of our model. Results showed that the
passengers' ascription of humanness would increase with the greater affective
transition. Our study suggested an important role of affective transition in
passengers' ascription of humanness, which might become a future direction for
autonomous driving.</p>
  </details>
</details>
<details>
  <summary>28. <b>标题：Multimodal Tree Decoder for Table of Contents Extraction in Document  Images</b></summary>
  <p><b>编号</b>：[133]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02896</p>
  <p><b>作者</b>：Pengfei Hu,  Zhenrong Zhang,  Jianshu Zhang,  Jun Du,  Jiajia Wu</p>
  <p><b>备注</b>：Accepted by ICPR2022</p>
  <p><b>关键词</b>：extraction aims, aims to extract, understand the outline, extract headings, document understanding</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Table of contents (ToC) extraction aims to extract headings of different
levels in documents to better understand the outline of the contents, which can
be widely used for document understanding and information retrieval. Existing
works often use hand-crafted features and predefined rule-based functions to
detect headings and resolve the hierarchical relationship between headings.
Both the benchmark and research based on deep learning are still limited.
Accordingly, in this paper, we first introduce a standard dataset, HierDoc,
including image samples from 650 documents of scientific papers with their
content labels. Then we propose a novel end-to-end model by using the
multimodal tree decoder (MTD) for ToC as a benchmark for HierDoc. The MTD model
is mainly composed of three parts, namely encoder, classifier, and decoder. The
encoder fuses the multimodality features of vision, text, and layout
information for each entity of the document. Then the classifier recognizes and
selects the heading entities. Next, to parse the hierarchical relationship
between the heading entities, a tree-structured decoder is designed. To
evaluate the performance, both the metric of tree-edit-distance similarity
(TEDS) and F1-Measure are adopted. Finally, our MTD approach achieves an
average TEDS of 87.2% and an average F1-Measure of 88.1% on the test set of
HierDoc. The code and dataset will be released at:
this https URL.</p>
  </details>
</details>
<details>
  <summary>29. <b>标题：Generation and Prediction of Difficult Model Counting Instances</b></summary>
  <p><b>编号</b>：[135]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02893</p>
  <p><b>作者</b>：Guillaume Escamocher,  Barry O'Sullivan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：difficult model counting, model counting instances, model counting, Model Counting Competition, number</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present a way to create small yet difficult model counting instances. Our
generator is highly parameterizable: the number of variables of the instances
it produces, as well as their number of clauses and the number of literals in
each clause, can all be set to any value. Our instances have been tested on
state of the art model counters, against other difficult model counting
instances, in the Model Counting Competition. The smallest unsolved instances
of the competition, both in terms of number of variables and number of clauses,
were ours. We also observe a peak of difficulty when fixing the number of
variables and varying the number of clauses, in both random instances and
instances built by our generator. Using these results, we predict the parameter
values for which the hardest to count instances will occur.</p>
  </details>
</details>
<details>
  <summary>30. <b>标题：GAS-Net: Generative Artistic Style Neural Networks for Fonts</b></summary>
  <p><b>编号</b>：[136]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02886</p>
  <p><b>作者</b>：Haoyang He,  Xin Jin,  Angela Chen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：time-consuming and labor-intensive, huge amount, characters like Chinese, Chinese, Generating new fonts</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Generating new fonts is a time-consuming and labor-intensive, especially in a
language with a huge amount of characters like Chinese. Various deep learning
models have demonstrated the ability to efficiently generate new fonts with a
few reference characters of that style. This project aims to develop a few-shot
cross-lingual font generator based on AGIS-Net and improve the performance
metrics mentioned. Our approaches include redesigning the encoder and the loss
function. We will validate our method on multiple languages and datasets
mentioned.</p>
  </details>
</details>
<details>
  <summary>31. <b>标题：SignNet: Single Channel Sign Generation using Metric Embedded Learning</b></summary>
  <p><b>编号</b>：[150]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02848</p>
  <p><b>作者</b>：Tejaswini Ananthanarayana,  Lipisha Chaudhary,  Ifeoma Nwogu</p>
  <p><b>备注</b>：9 pages, 4 figures, 4 tables - IEEE Face and Gestures, 2023</p>
  <p><b>关键词</b>：true interpreting agent, understands sign language, true interpreting, interpreting agent, understands text</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A true interpreting agent not only understands sign language and translates
to text, but also understands text and translates to signs. Much of the AI work
in sign language translation to date has focused mainly on translating from
signs to text. Towards the latter goal, we propose a text-to-sign translation
model, SignNet, which exploits the notion of similarity (and dissimilarity) of
visual signs in translating. This module presented is only one part of a
dual-learning two task process involving text-to-sign (T2S) as well as
sign-to-text (S2T). We currently implement SignNet as a single channel
architecture so that the output of the T2S task can be fed into S2T in a
continuous dual learning framework. By single channel, we refer to a single
modality, the body pose joints.
In this work, we present SignNet, a T2S task using a novel metric embedding
learning process, to preserve the distances between sign embeddings relative to
their dissimilarity. We also describe how to choose positive and negative
examples of signs for similarity testing. From our analysis, we observe that
metric embedding learning-based model perform significantly better than the
other models with traditional losses, when evaluated using BLEU scores. In the
task of gloss to pose, SignNet performed as well as its state-of-the-art (SoTA)
counterparts and outperformed them in the task of text to pose, by showing
noteworthy enhancements in BLEU 1 - BLEU 4 scores (BLEU 1: 31->39; ~26%
improvement and BLEU 4: 10.43->11.84; ~14\% improvement) when tested on the
popular RWTH PHOENIX-Weather-2014T benchmark dataset</p>
  </details>
</details>
<details>
  <summary>32. <b>标题：SSDA3D: Semi-supervised Domain Adaptation for 3D Object Detection from  Point Cloud</b></summary>
  <p><b>编号</b>：[151]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02845</p>
  <p><b>作者</b>：Yan Wang,  Junbo Yin,  Wei Li,  Pascal Frossard,  Ruigang Yang,  Jianbing Shen</p>
  <p><b>备注</b>：Accepted by AAAI 2023</p>
  <p><b>关键词</b>：autonomous driving systems, advanced autonomous driving, driving systems, indispensable task, task in advanced</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>LiDAR-based 3D object detection is an indispensable task in advanced
autonomous driving systems. Though impressive detection results have been
achieved by superior 3D detectors, they suffer from significant performance
degeneration when facing unseen domains, such as different LiDAR
configurations, different cities, and weather conditions. The mainstream
approaches tend to solve these challenges by leveraging unsupervised domain
adaptation (UDA) techniques. However, these UDA solutions just yield
unsatisfactory 3D detection results when there is a severe domain shift, e.g.,
from Waymo (64-beam) to nuScenes (32-beam). To address this, we present a novel
Semi-Supervised Domain Adaptation method for 3D object detection (SSDA3D),
where only a few labeled target data is available, yet can significantly
improve the adaptation performance. In particular, our SSDA3D includes an
Inter-domain Adaptation stage and an Intra-domain Generalization stage. In the
first stage, an Inter-domain Point-CutMix module is presented to efficiently
align the point cloud distribution across domains. The Point-CutMix generates
mixed samples of an intermediate domain, thus encouraging to learn
domain-invariant knowledge. Then, in the second stage, we further enhance the
model for better generalization on the unlabeled target set. This is achieved
by exploring Intra-domain Point-MixUp in semi-supervised learning, which
essentially regularizes the pseudo label distribution. Experiments from Waymo
to nuScenes show that, with only 10% labeled target data, our SSDA3D can
surpass the fully-supervised oracle model with 100% target label. Our code is
available at this https URL.</p>
  </details>
</details>
<details>
  <summary>33. <b>标题：VISEM-Tracking: Human Spermatozoa Tracking Dataset</b></summary>
  <p><b>编号</b>：[152]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02842</p>
  <p><b>作者</b>：Vajira Thambawita,  Steven A. Hicks,  Andrea M. Storås,  Thu Nguyen,  Jorunn M. Andersen,  Oliwia Witczak,  Trine B. Haugen,  Hugo L. Hammer,  Pål Halvorsen,  Michael A. Riegler</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：causing inconsistencies, tremendous task, task for biologists, biologists due, Manually analyzing spermatozoa</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Manually analyzing spermatozoa is a tremendous task for biologists due to the
many fast-moving spermatozoa, causing inconsistencies in the quality of the
assessments. Therefore, computer-assisted sperm analysis (CASA) has become a
popular solution. Despite this, more data is needed to train supervised machine
learning approaches in order to improve accuracy and reliability. In this
regard, we provide a dataset called VISEM-Tracking with 20 video recordings of
30s of spermatozoa with manually annotated bounding-box coordinates and a set
of sperm characteristics analyzed by experts in the domain. VISEM-Tracking is
an extension of the previously published VISEM dataset. In addition to the
annotated data, we provide unlabeled video clips for easy-to-use access and
analysis of the data. As part of this paper, we present baseline sperm
detection performances using the YOLOv5 deep learning model trained on the
VISEM-Tracking dataset. As a result, the dataset can be used to train complex
deep-learning models to analyze spermatozoa. The dataset is publicly available
at this https URL.</p>
  </details>
</details>
<details>
  <summary>34. <b>标题：Hierarchical Termination Analysis for Generalized Planning</b></summary>
  <p><b>编号</b>：[155]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02823</p>
  <p><b>作者</b>：Siddharth Srivastava</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：generalized plans, analyzing and identifying, identifying potentially, generalized, paper presents</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper presents a new approach for analyzing and identifying potentially
useful generalized plans. It presents a new conceptual framework along with an
algorithmic process for assessing termination and reachability related
properties of generalized plans. The presented framework builds upon classic
results on the analysis of graphs to decompose generalized plans into smaller
components in a novel algorithm for conducting a hierarchical analysis for
termination of arbitrary generalized plans. Theoretical analysis of the new
framework establishes soundness of the presented algorithms and shows how it
goes beyond existing approaches; empirical analysis illustrates the scope of
this approach. Our analysis shows that this new approach can effectively
identify termination for a significantly larger class of generalized plans than
was possible using existing methods.</p>
  </details>
</details>
<details>
  <summary>35. <b>标题：Diffusion Video Autoencoders: Toward Temporally Consistent Face Video  Editing via Disentangled Video Encoding</b></summary>
  <p><b>编号</b>：[163]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02802</p>
  <p><b>作者</b>：Gyeongman Kim,  Hajin Shim,  Hyunsu Kim,  Yunjey Choi,  Junho Kim,  Eunho Yang</p>
  <p><b>备注</b>：The code will be available soon</p>
  <p><b>关键词</b>：face video editing, recent face image, video editing task, face image editing, image editing methods</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Inspired by the impressive performance of recent face image editing methods,
several studies have been naturally proposed to extend these methods to the
face video editing task. One of the main challenges here is temporal
consistency among edited frames, which is still unresolved. To this end, we
propose a novel face video editing framework based on diffusion autoencoders
that can successfully extract the decomposed features - for the first time as a
face video editing model - of identity and motion from a given video. This
modeling allows us to edit the video by simply manipulating the temporally
invariant feature to the desired direction for the consistency. Another unique
strength of our model is that, since our model is based on diffusion models, it
can satisfy both reconstruction and edit capabilities at the same time, and is
robust to corner cases in wild face videos (e.g. occluded faces) unlike the
existing GAN-based methods.</p>
  </details>
</details>
<details>
  <summary>36. <b>标题：FlowFace: Semantic Flow-guided Shape-aware Face Swapping</b></summary>
  <p><b>编号</b>：[166]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02797</p>
  <p><b>作者</b>：Hao Zeng,  Wei Zhang,  Changjie Fan,  Tangjie Lv,  Suzhen Wang,  Zhimeng Zhang,  Bowen Ma,  Lincheng Li,  Yu Ding,  Xin Yu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：flow-guided two-stage framework, face, face swapping, shape-aware face swapping, face swapping network</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this work, we propose a semantic flow-guided two-stage framework for
shape-aware face swapping, namely FlowFace. Unlike most previous methods that
focus on transferring the source inner facial features but neglect facial
contours, our FlowFace can transfer both of them to a target face, thus leading
to more realistic face swapping. Concretely, our FlowFace consists of a face
reshaping network and a face swapping network. The face reshaping network
addresses the shape outline differences between the source and target faces. It
first estimates a semantic flow (i.e., face shape differences) between the
source and the target face, and then explicitly warps the target face shape
with the estimated semantic flow. After reshaping, the face swapping network
generates inner facial features that exhibit the identity of the source face.
We employ a pre-trained face masked autoencoder (MAE) to extract facial
features from both the source face and the target face. In contrast to previous
methods that use identity embedding to preserve identity information, the
features extracted by our encoder can better capture facial appearances and
identity information. Then, we develop a cross-attention fusion module to
adaptively fuse inner facial features from the source face with the target
facial attributes, thus leading to better identity preservation. Extensive
quantitative and qualitative experiments on in-the-wild faces demonstrate that
our FlowFace outperforms the state-of-the-art significantly.</p>
  </details>
</details>
<details>
  <summary>37. <b>标题：Union-set Multi-source Model Adaptation for Semantic Segmentation</b></summary>
  <p><b>编号</b>：[172]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02785</p>
  <p><b>作者</b>：Zongyao Li,  Ren Togo,  Takahiro Ogawa,  Miki haseyama</p>
  <p><b>备注</b>：Accepted by ECCV2022</p>
  <p><b>关键词</b>：multi-source model adaptation, model adaptation, domain adaptation problem, semantic segmentation, source domain</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper solves a generalized version of the problem of multi-source model
adaptation for semantic segmentation. Model adaptation is proposed as a new
domain adaptation problem which requires access to a pre-trained model instead
of data for the source domain. A general multi-source setting of model
adaptation assumes strictly that each source domain shares a common label space
with the target domain. As a relaxation, we allow the label space of each
source domain to be a subset of that of the target domain and require the union
of the source-domain label spaces to be equal to the target-domain label space.
For the new setting named union-set multi-source model adaptation, we propose a
method with a novel learning strategy named model-invariant feature learning,
which takes full advantage of the diverse characteristics of the source-domain
models, thereby improving the generalization in the target domain. We conduct
extensive experiments in various adaptation settings to show the superiority of
our method. The code is available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>38. <b>标题：QEBVerif: Quantization Error Bound Verification of Neural Networks</b></summary>
  <p><b>编号</b>：[173]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02781</p>
  <p><b>作者</b>：Yedi Zhang,  Fu Song,  Jun Sun</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：demonstrated impressive performance, resource-constrained devices owing, deep neural networks, neural networks, challenging tasks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>While deep neural networks (DNNs) have demonstrated impressive performance in
solving many challenging tasks, they are limited to resource-constrained
devices owing to their demand for computation power and storage space.
Quantization is one of the most promising techniques to address this issue by
quantizing the weights and/or activation tensors of a DNN into lower bit-width
fixed-point numbers. While quantization has been empirically shown to introduce
minor accuracy loss, it lacks formal guarantees on that, especially when the
resulting quantized neural networks (QNNs) are deployed in safety-critical
applications. A majority of existing verification methods focus exclusively on
individual neural networks, either DNNs or QNNs. While promising attempts have
been made to verify the quantization error bound between DNNs and their
quantized counterparts, they are not complete and more importantly do not
support fully quantified neural networks, namely, only weights are quantized.
To fill this gap, in this work, we propose a quantization error bound
verification method (QEBVerif), where both weights and activation tensors are
quantized. QEBVerif consists of two analyses: a differential reachability
analysis (DRA) and a mixed-integer linear programming (MILP) based verification
method. DRA performs difference analysis between the DNN and its quantized
counterpart layer-by-layer to efficiently compute a tight quantization error
interval. If it fails to prove the error bound, then we encode the verification
problem into an equivalent MILP problem which can be solved by off-the-shelf
solvers. Thus, QEBVerif is sound, complete, and arguably efficient. We
implement QEBVerif in a tool and conduct extensive experiments, showing its
effectiveness and efficiency.</p>
  </details>
</details>
<details>
  <summary>39. <b>标题：PrefRec: Preference-based Recommender Systems for Reinforcing Long-term  User Engagement</b></summary>
  <p><b>编号</b>：[175]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02779</p>
  <p><b>作者</b>：Wanqi Xue,  Qingpeng Cai,  Zhenghai Xue,  Shuo Sun,  Shuchang Liu,  Dong Zheng,  Peng Jiang,  Bo An</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：long-term user engagement, long-term user, user engagement, Current advances, remarkably successful</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Current advances in recommender systems have been remarkably successful in
optimizing immediate engagement. However, long-term user engagement, a more
desirable performance metric, remains difficult to improve. Meanwhile, recent
reinforcement learning (RL) algorithms have shown their effectiveness in a
variety of long-term goal optimization tasks. For this reason, RL is widely
considered as a promising framework for optimizing long-term user engagement in
recommendation. Despite being a promising approach, the application of RL
heavily relies on well-designed rewards, but designing rewards related to
long-term user engagement is quite difficult. To mitigate the problem, we
propose a novel paradigm, Preference-based Recommender systems (PrefRec), which
allows RL recommender systems to learn from preferences about users' historical
behaviors rather than explicitly defined rewards. Such preferences are easily
accessible through techniques such as crowdsourcing, as they do not require any
expert knowledge. With PrefRec, we can fully exploit the advantages of RL in
optimizing long-term goals, while avoiding complex reward engineering. PrefRec
uses the preferences to automatically train a reward function in an end-to-end
manner. The reward function is then used to generate learning signals to train
the recommendation policy. Furthermore, we design an effective optimization
method for PrefRec, which uses an additional value function, expectile
regression and reward model pre-training to improve the performance. Extensive
experiments are conducted on a variety of long-term user engagement
optimization tasks. The results show that PrefRec significantly outperforms
previous state-of-the-art methods in all the tasks.</p>
  </details>
</details>
<details>
  <summary>40. <b>标题：Tackling Data Heterogeneity in Federated Learning with Class Prototypes</b></summary>
  <p><b>编号</b>：[185]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02758</p>
  <p><b>作者</b>：Yutong Dai,  Zeyuan Chen,  Junnan Li,  Shelby Heinecke,  Lichao Sun,  Ran Xu</p>
  <p><b>备注</b>：Accepted for presentation at AAAI 2023. This is a technical report version that contains an appendix with additional details about experiments and proofs for technical results</p>
  <p><b>关键词</b>：widely acknowledged challenge, local models, federated learning, personalized federated learning, models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Data heterogeneity across clients in federated learning (FL) settings is a
widely acknowledged challenge. In response, personalized federated learning
(PFL) emerged as a framework to curate local models for clients' tasks. In PFL,
a common strategy is to develop local and global models jointly - the global
model (for generalization) informs the local models, and the local models (for
personalization) are aggregated to update the global model. A key observation
is that if we can improve the generalization ability of local models, then we
can improve the generalization of global models, which in turn builds better
personalized models. In this work, we consider class imbalance, an overlooked
type of data heterogeneity, in the classification setting. We propose FedNH, a
novel method that improves the local models' performance for both
personalization and generalization by combining the uniformity and semantics of
class prototypes. FedNH initially distributes class prototypes uniformly in the
latent space and smoothly infuses the class semantics into class prototypes. We
show that imposing uniformity helps to combat prototype collapse while infusing
class semantics improves local models. Extensive experiments were conducted on
popular classification datasets under the cross-device setting. Our results
demonstrate the effectiveness and stability of our method over recent works.</p>
  </details>
</details>
<details>
  <summary>41. <b>标题：Objects as Spatio-Temporal 2.5D points</b></summary>
  <p><b>编号</b>：[187]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02755</p>
  <p><b>作者</b>：Paridhi Singh,  Gaurav Singh,  Arun Kumar</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：scenario extraction etc., Determining accurate bird, bird eye view, accurate bird eye, perception tasks including</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Determining accurate bird's eye view (BEV) positions of objects and tracks in
a scene is vital for various perception tasks including object interactions
mapping, scenario extraction etc., however, the level of supervision required
to accomplish that is extremely challenging to procure. We propose a
light-weight, weakly supervised method to estimate 3D position of objects by
jointly learning to regress the 2D object detections and scene's depth
prediction in a single feed-forward pass of a network. Our proposed method
extends a center-point based single-shot object detector
\cite{zhou2019objects}, and introduces a novel object representation where each
object is modeled as a BEV point spatio-temporally, without the need of any 3D
or BEV annotations for training and LiDAR data at query time. The approach
leverages readily available 2D object supervision along with LiDAR point clouds
(used only during training) to jointly train a single network, that learns to
predict 2D object detection alongside the whole scene's depth, to
spatio-temporally model object tracks as points in BEV. The proposed method is
computationally over $\sim$10x efficient compared to recent SOTA approaches [1,
38] while achieving comparable accuracies on KITTI tracking benchmark.</p>
  </details>
</details>
<details>
  <summary>42. <b>标题：Safe Inverse Reinforcement Learning via Control Barrier Function</b></summary>
  <p><b>编号</b>：[189]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02753</p>
  <p><b>作者</b>：Yue Yang,  Letian Chen,  Matthew Gombolay</p>
  <p><b>备注</b>：6 pages, 3 figures</p>
  <p><b>关键词</b>：Inverse Reinforcement Learning, reinforcement learning, desired skill, efficiently learn, Inverse Reinforcement</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Learning from Demonstration (LfD) is a powerful method for enabling robots to
perform novel tasks as it is often more tractable for a non-roboticist end-user
to demonstrate the desired skill and for the robot to efficiently learn from
the associated data than for a human to engineer a reward function for the
robot to learn the skill via reinforcement learning (RL). Safety issues arise
in modern LfD techniques, e.g., Inverse Reinforcement Learning (IRL), just as
they do for RL; yet, safe learning in LfD has received little attention. In the
context of agile robots, safety is especially vital due to the possibility of
robot-environment collision, robot-human collision, and damage to the robot. In
this paper, we propose a safe IRL framework, CBFIRL, that leverages the Control
Barrier Function (CBF) to enhance the safety of the IRL policy. The core idea
of CBFIRL is to combine a loss function inspired by CBF requirements with the
objective in an IRL method, both of which are jointly optimized via gradient
descent. In the experiments, we show our framework performs safer compared to
IRL methods without CBF, that is $\sim15\%$ and $\sim20\%$ improvement for two
levels of difficulty of a 2D racecar domain and $\sim 50\%$ improvement for a
3D drone domain.</p>
  </details>
</details>
<details>
  <summary>43. <b>标题：UniGeo: Unifying Geometry Logical Reasoning via Reformulating  Mathematical Expression</b></summary>
  <p><b>编号</b>：[195]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02746</p>
  <p><b>作者</b>：Jiaqi Chen,  Tong Li,  Jinghui Qin,  Pan Lu,  Liang Lin,  Chongyu Chen,  Xiaodan Liang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：high-level multi-modal reasoning, multi-modal reasoning capability, Geometry problem solving, well-recognized testbed, testbed for evaluating</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Geometry problem solving is a well-recognized testbed for evaluating the
high-level multi-modal reasoning capability of deep models. In most existing
works, two main geometry problems: calculation and proving, are usually treated
as two specific tasks, hindering a deep model to unify its reasoning capability
on multiple math tasks. However, in essence, these two tasks have similar
problem representations and overlapped math knowledge which can improve the
understanding and reasoning ability of a deep model on both two tasks.
Therefore, we construct a large-scale Unified Geometry problem benchmark,
UniGeo, which contains 4,998 calculation problems and 9,543 proving problems.
Each proving problem is annotated with a multi-step proof with reasons and
mathematical expressions. The proof can be easily reformulated as a proving
sequence that shares the same formats with the annotated program sequence for
calculation problems. Naturally, we also present a unified multi-task Geometric
Transformer framework, Geoformer, to tackle calculation and proving problems
simultaneously in the form of sequence generation, which finally shows the
reasoning ability can be improved on both two tasks by unifying formulation.
Furthermore, we propose a Mathematical Expression Pretraining (MEP) method that
aims to predict the mathematical expressions in the problem solution, thus
improving the Geoformer model. Experiments on the UniGeo demonstrate that our
proposed Geoformer obtains state-of-the-art performance by outperforming
task-specific model NGS with over 5.6% and 3.2% accuracies on calculation and
proving problems, respectively.</p>
  </details>
</details>
<details>
  <summary>44. <b>标题：Semantic-aware Message Broadcasting for Efficient Unsupervised Domain  Adaptation</b></summary>
  <p><b>编号</b>：[200]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02739</p>
  <p><b>作者</b>：Xin Li,  Cuiling Lan,  Guoqiang Wei,  Zhibo Chen</p>
  <p><b>备注</b>：13 pages, 5 figures</p>
  <p><b>关键词</b>：demonstrated great potential, abundant vision tasks, demonstrated great, great potential, potential in abundant</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Vision transformer has demonstrated great potential in abundant vision tasks.
However, it also inevitably suffers from poor generalization capability when
the distribution shift occurs in testing (i.e., out-of-distribution data). To
mitigate this issue, we propose a novel method, Semantic-aware Message
Broadcasting (SAMB), which enables more informative and flexible feature
alignment for unsupervised domain adaptation (UDA). Particularly, we study the
attention module in the vision transformer and notice that the alignment space
using one global class token lacks enough flexibility, where it interacts
information with all image tokens in the same manner but ignores the rich
semantics of different regions. In this paper, we aim to improve the richness
of the alignment features by enabling semantic-aware adaptive message
broadcasting. Particularly, we introduce a group of learned group tokens as
nodes to aggregate the global information from all image tokens, but encourage
different group tokens to adaptively focus on the message broadcasting to
different semantic regions. In this way, our message broadcasting encourages
the group tokens to learn more informative and diverse information for
effective domain alignment. Moreover, we systematically study the effects of
adversarial-based feature alignment (ADA) and pseudo-label based self-training
(PST) on UDA. We find that one simple two-stage training strategy with the
cooperation of ADA and PST can further improve the adaptation capability of the
vision transformer. Extensive experiments on DomainNet, OfficeHome, and
VisDA-2017 demonstrate the effectiveness of our methods for UDA.</p>
  </details>
</details>
<details>
  <summary>45. <b>标题：Curriculum Learning for Relative Overgeneralization</b></summary>
  <p><b>编号</b>：[202]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02733</p>
  <p><b>作者</b>：Lin Shi,  Bei Peng</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：multi-agent reinforcement learning, tasks, target task, multi-agent reinforcement, joint action</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In multi-agent reinforcement learning (MARL), many popular methods, such as
VDN and QMIX, are susceptible to a critical multi-agent pathology known as
relative overgeneralization (RO), which arises when the optimal joint action's
utility falls below that of a sub-optimal joint action in cooperative tasks. RO
can cause the agents to get stuck into local optima or fail to solve tasks that
require significant coordination between agents within a given timestep. Recent
value-based MARL algorithms such as QPLEX and WQMIX can overcome RO to some
extent. However, our experimental results show that they can still fail to
solve cooperative tasks that exhibit strong RO. In this work, we propose a
novel approach called curriculum learning for relative overgeneralization
(CURO) to better overcome RO. To solve a target task that exhibits strong RO,
in CURO, we first fine-tune the reward function of the target task to generate
source tasks that are tailored to the current ability of the learning agent and
train the agent on these source tasks first. Then, to effectively transfer the
knowledge acquired in one task to the next, we use a novel transfer learning
method that combines value function transfer with buffer transfer, which
enables more efficient exploration in the target task. We demonstrate that,
when applied to QMIX, CURO overcomes severe RO problem and significantly
improves performance, yielding state-of-the-art results in a variety of
cooperative multi-agent tasks, including the challenging StarCraft II
micromanagement benchmarks.</p>
  </details>
</details>
<details>
  <summary>46. <b>标题：Efficient Learning of Voltage Control Strategies via Model-based Deep  Reinforcement Learning</b></summary>
  <p><b>编号</b>：[209]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02715</p>
  <p><b>作者</b>：Ramij R. Hossain,  Tianzhixi Yin,  Yan Du,  Renke Huang,  Jie Tan,  Wenhao Yu,  Yuan Liu,  Qiuhua Huang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：design emergency control, emergency control strategies, short-term voltage stability, voltage stability problems, design emergency</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This article proposes a model-based deep reinforcement learning (DRL) method
to design emergency control strategies for short-term voltage stability
problems in power systems. Recent advances show promising results in model-free
DRL-based methods for power systems, but model-free methods suffer from poor
sample efficiency and training time, both critical for making state-of-the-art
DRL algorithms practically applicable. DRL-agent learns an optimal policy via a
trial-and-error method while interacting with the real-world environment. And
it is desirable to minimize the direct interaction of the DRL agent with the
real-world power grid due to its safety-critical nature. Additionally,
state-of-the-art DRL-based policies are mostly trained using a physics-based
grid simulator where dynamic simulation is computationally intensive, lowering
the training efficiency. We propose a novel model-based-DRL framework where a
deep neural network (DNN)-based dynamic surrogate model, instead of a
real-world power-grid or physics-based simulation, is utilized with the policy
learning framework, making the process faster and sample efficient. However,
stabilizing model-based DRL is challenging because of the complex system
dynamics of large-scale power systems. We solved these issues by incorporating
imitation learning to have a warm start in policy learning, reward-shaping, and
multi-step surrogate loss. Finally, we achieved 97.5% sample efficiency and
87.7% training efficiency for an application to the IEEE 300-bus test system.</p>
  </details>
</details>
<details>
  <summary>47. <b>标题：Improved Beam Search for Hallucination Mitigation in Abstractive  Summarization</b></summary>
  <p><b>编号</b>：[210]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02712</p>
  <p><b>作者</b>：Arvind Krishna Sridhar,  Erik Visser</p>
  <p><b>备注</b>：8 pages, 2 figures</p>
  <p><b>关键词</b>：generation tasks including, large pretrained language, pretrained language models, tasks including summarization, including summarization albeit</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Advancement in large pretrained language models has significantly improved
their performance for conditional language generation tasks including
summarization albeit with hallucinations. To reduce hallucinations,
conventional methods proposed improving beam search or using a fact checker as
a postprocessing step. In this paper, we investigate the use of the Natural
Language Inference (NLI) entailment metric to detect and prevent hallucinations
in summary generation. We propose an NLI-assisted beam re-ranking mechanism by
computing entailment probability scores between the input context and
summarization model-generated beams during saliency-enhanced greedy decoding.
Moreover, a diversity metric is introduced to compare its effectiveness against
vanilla beam search. Our proposed algorithm significantly outperforms vanilla
beam decoding on XSum and CNN/DM datasets.</p>
  </details>
</details>
<details>
  <summary>48. <b>标题：Beyond Object Recognition: A New Benchmark towards Object Concept  Learning</b></summary>
  <p><b>编号</b>：[211]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02710</p>
  <p><b>作者</b>：Yong-Lu Li,  Yue Xu,  Xinyu Xu,  Xiaohan Mao,  Yuan Yao,  Siqi Liu,  Cewu Lu</p>
  <p><b>备注</b>：Preprint. Webpage: this https URL</p>
  <p><b>关键词</b>：central building block, object, Object Concept Learning, artificial intelligence, Object Concept</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Understanding objects is a central building block of artificial intelligence,
especially for embodied AI. Even though object recognition excels with deep
learning, current machines still struggle to learn higher-level knowledge,
e.g., what attributes an object has, and what can we do with an object. In this
work, we propose a challenging Object Concept Learning (OCL) task to push the
envelope of object understanding. It requires machines to reason out object
affordances and simultaneously give the reason: what attributes make an object
possesses these affordances. To support OCL, we build a densely annotated
knowledge base including extensive labels for three levels of object concept
(category, attribute, affordance), and the causal relations of three levels. By
analyzing the causal structure of OCL, we present a baseline, Object Concept
Reasoning Network (OCRN). It leverages causal intervention and concept
instantiation to infer the three levels following their causal relations. In
experiments, OCRN effectively infers the object knowledge while following the
causalities well. Our data and code are available at this https URL.</p>
  </details>
</details>
<details>
  <summary>49. <b>标题：What is the Solution for State Adversarial Multi-Agent Reinforcement  Learning?</b></summary>
  <p><b>编号</b>：[213]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02705</p>
  <p><b>作者</b>：Songyang Han,  Sanbao Su,  Sihong He,  Shuo Han,  Haizhao Yang,  Fei Miao</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Multi-Agent Reinforcement Learning, Reinforcement Learning, adversarial state perturbations, Multi-Agent Reinforcement, MARL</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Various types of Multi-Agent Reinforcement Learning (MARL) methods have been
developed, assuming that agents' policies are based on true states. Recent
works have improved the robustness of MARL under uncertainties from the reward,
transition probability, or other partners' policies. However, in real-world
multi-agent systems, state estimations may be perturbed by sensor measurement
noise or even adversaries. Agents' policies trained with only true state
information will deviate from optimal solutions when facing adversarial state
perturbations during execution. MARL under adversarial state perturbations has
limited study. Hence, in this work, we propose a State-Adversarial Markov Game
(SAMG) and make the first attempt to study the fundamental properties of MARL
under state uncertainties. We prove that the optimal agent policy and the
robust Nash equilibrium do not always exist for an SAMG. Instead, we define the
solution concept, robust agent policy, of the proposed SAMG under adversarial
state perturbations, where agents want to maximize the worst-case expected
state value. We then design a gradient descent ascent-based robust MARL
algorithm to learn the robust policies for the MARL agents. Our experiments
show that adversarial state perturbations decrease agents' rewards for several
baselines from the existing literature, while our algorithm outperforms
baselines with state perturbations and significantly improves the robustness of
the MARL policies under state uncertainties.</p>
  </details>
</details>
<details>
  <summary>50. <b>标题：On the Discredibility of Membership Inference Attacks</b></summary>
  <p><b>编号</b>：[215]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02701</p>
  <p><b>作者</b>：Shahbaz Rezaei,  Xin Liu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：machine learning models, potential data leakage, learning models, models trained, membership inference attacks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>With the wide-spread application of machine learning models, it has become
critical to study the potential data leakage of models trained on sensitive
data. Recently, various membership inference (MI) attacks are proposed that
determines if a sample was part of the training set or not. Although the first
generation of MI attacks has been proven to be ineffective in practice, a few
recent studies proposed practical MI attacks that achieve reasonable true
positive rate at low false positive rate. The question is whether these attacks
can be reliably used in practice. We showcase a practical application of
membership inference attacks where it is used by an auditor (investigator) to
prove to a judge/jury that an auditee unlawfully used sensitive data during
training. Then, we show that the auditee can provide a dataset (with
potentially unlimited number of samples) to a judge where MI attacks
catastrophically fail. Hence, the auditee challenges the credibility of the
auditor and can get the case dismissed. More importantly, we show that the
auditee does not need to know anything about the MI attack neither a query
access to it. In other words, all currently SOTA MI attacks in literature
suffer from the same issue. Through comprehensive experimental evaluation, we
show that our algorithms can increase the false positive rate from ten to
thousands times larger than what auditor claim to the judge. Lastly, we argue
that the implication of our algorithms is beyond discredibility: Current
membership inference attacks can identify the memorized subpopulations, but
they cannot reliably identify which exact sample in the subpopulation was used
during training.</p>
  </details>
</details>
<details>
  <summary>51. <b>标题：Self-supervised Graph Representation Learning for Black Market Account  Detection</b></summary>
  <p><b>编号</b>：[222]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02679</p>
  <p><b>作者</b>：Zequan Xu,  Lianyun Li,  Hui Li,  Qihang Sun,  Shaofeng Hu,  Rongrong Ji</p>
  <p><b>备注</b>：WSDM 2023. This is the complete version containing the appendix</p>
  <p><b>关键词</b>：Messaging Mobile App, Multi-purpose Messaging Mobile, Multi-purpose Messaging, Mobile App, Messaging Mobile</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Nowadays, Multi-purpose Messaging Mobile App (MMMA) has become increasingly
prevalent. MMMAs attract fraudsters and some cybercriminals provide support for
frauds via black market accounts (BMAs). Compared to fraudsters, BMAs are not
directly involved in frauds and are more difficult to detect. This paper
illustrates our BMA detection system SGRL (Self-supervised Graph Representation
Learning) used in WeChat, a representative MMMA with over a billion users. We
tailor Graph Neural Network and Graph Self-supervised Learning in SGRL for BMA
detection. The workflow of SGRL contains a pretraining phase that utilizes
structural information, node attribute information and available human
knowledge, and a lightweight detection phase. In offline experiments, SGRL
outperforms state-of-the-art methods by 16.06%-58.17% on offline evaluation
measures. We deploy SGRL in the online environment to detect BMAs on the
billion-scale WeChat graph, and it exceeds the alternative by 7.27% on the
online evaluation measure. In conclusion, SGRL can alleviate label reliance,
generalize well to unseen data, and effectively detect BMAs in WeChat.</p>
  </details>
</details>
<details>
  <summary>52. <b>标题：Transformers for End-to-End InfoSec Tasks: A Feasibility Study</b></summary>
  <p><b>编号</b>：[225]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02666</p>
  <p><b>作者</b>：Ethan M. Rudd,  Mohammad Saidur Rahman,  Philip Tully</p>
  <p><b>备注</b>：Post-print of a manuscript accepted to ACM Asia-CCS Workshop on Robust Malware Analysis (WoRMA) 2022. 11 Pages total. arXiv admin note: substantial text overlap with arXiv:2011.03040</p>
  <p><b>关键词</b>：assess the viability, models, transformer, transformer models, show</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we assess the viability of transformer models in end-to-end
InfoSec settings, in which no intermediate feature representations or
processing steps occur outside the model. We implement transformer models for
two distinct InfoSec data formats - specifically URLs and PE files - in a novel
end-to-end approach, and explore a variety of architectural designs, training
regimes, and experimental settings to determine the ingredients necessary for
performant detection models. We show that in contrast to conventional
transformers trained on more standard NLP-related tasks, our URL transformer
model requires a different training approach to reach high performance levels.
Specifically, we show that 1) pre-training on a massive corpus of unlabeled URL
data for an auto-regressive task does not readily transfer to binary
classification of malicious or benign URLs, but 2) that using an auxiliary
auto-regressive loss improves performance when training from scratch. We
introduce a method for mixed objective optimization, which dynamically balances
contributions from both loss terms so that neither one of them dominates. We
show that this method yields quantitative evaluation metrics comparable to that
of several top-performing benchmark classifiers. Unlike URLs, binary
executables contain longer and more distributed sequences of information-rich
bytes. To accommodate such lengthy byte sequences, we introduce additional
context length into the transformer by providing its self-attention layers with
an adaptive span similar to Sukhbaatar et al. We demonstrate that this approach
performs comparably to well-established malware detection models on benchmark
PE file datasets, but also point out the need for further exploration into
model improvements in scalability and compute efficiency.</p>
  </details>
</details>
<details>
  <summary>53. <b>标题：Efficient Malware Analysis Using Metric Embeddings</b></summary>
  <p><b>编号</b>：[226]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02663</p>
  <p><b>作者</b>：Ethan M. Rudd,  David Krisiloff,  Scott Coull,  Daniel Olszewski,  Edward Raff,  James Holt</p>
  <p><b>备注</b>：Pre-print of a manuscript submitted to the ACM Digital Threats: Research and Practice (DTRAP) Special Issue on Applied Machine Learning for Information Security. 19 Pages</p>
  <p><b>关键词</b>：including malware detection, malware attribute tagging, embed Windows, low-dimensional vector space, Windows PE files</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we explore the use of metric learning to embed Windows PE
files in a low-dimensional vector space for downstream use in a variety of
applications, including malware detection, family classification, and malware
attribute tagging. Specifically, we enrich labeling on malicious and benign PE
files using computationally expensive, disassembly-based malicious
capabilities. Using these capabilities, we derive several different types of
metric embeddings utilizing an embedding neural network trained via contrastive
loss, Spearman rank correlation, and combinations thereof. We then examine
performance on a variety of transfer tasks performed on the EMBER and SOREL
datasets, demonstrating that for several tasks, low-dimensional,
computationally efficient metric embeddings maintain performance with little
decay, which offers the potential to quickly retrain for a variety of transfer
tasks at significantly reduced storage overhead. We conclude with an
examination of practical considerations for the use of our proposed embedding
approach, such as robustness to adversarial evasion and introduction of
task-specific auxiliary objectives to improve performance on mission critical
tasks.</p>
  </details>
</details>
<details>
  <summary>54. <b>标题：Spuriosity Rankings: Sorting Data for Spurious Correlation Robustness</b></summary>
  <p><b>编号</b>：[231]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02648</p>
  <p><b>作者</b>：Mazda Moayeri,  Wenxiao Wang,  Sahil Singla,  Soheil Feizi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：spurious, spurious features, class based, spurious cues, spurious cues present</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present a framework for ranking images within their class based on the
strength of spurious cues present. By measuring the gap in accuracy on the
highest and lowest ranked images (we call this spurious gap), we assess
spurious feature reliance for $89$ diverse ImageNet models, finding that even
the best models underperform in images with weak spurious presence. However,
the effect of spurious cues varies far more dramatically across classes,
emphasizing the crucial, often overlooked, class-dependence of the spurious
correlation problem. While most spurious features we observe are clarifying
(i.e. improving test-time accuracy when present, as is typically expected), we
surprisingly find many cases of confusing spurious features, where models
perform better when they are absent. We then close the spurious gap by training
new classification heads on lowly ranked (i.e. without common spurious cues)
images, resulting in improved effective robustness to distribution shifts
(ObjectNet, ImageNet-R, ImageNet-Sketch). We also propose a second metric to
assess feature reliability, finding that spurious features are generally less
reliable than non-spurious (core) ones, though again, spurious features can be
more reliable for certain classes. To enable our analysis, we annotated $5,000$
feature-class dependencies over {\it all} of ImageNet as core or spurious using
minimal human supervision. Finally, we show the feature discovery and
spuriosity ranking framework can be extended to other datasets like CelebA and
WaterBirds in a lightweight fashion with only linear layer training, leading to
discovering a previously unknown racial bias in the Celeb-A hair
classification.</p>
  </details>
</details>
<details>
  <summary>55. <b>标题：Unifying Vision, Text, and Layout for Universal Document Processing</b></summary>
  <p><b>编号</b>：[238]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02623</p>
  <p><b>作者</b>：Zineng Tang,  Ziyi Yang,  Guoxin Wang,  Yuwei Fang,  Yang Liu,  Chenguang Zhu,  Michael Zeng,  Cha Zhang,  Mohit Bansal</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Universal Document Processing, propose Universal Document, propose Universal, Document Processing, varied task formats</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose Universal Document Processing (UDOP), a foundation Document AI
model which unifies text, image, and layout modalities together with varied
task formats, including document understanding and generation. UDOP leverages
the spatial correlation between textual content and document image to model
image, text, and layout modalities with one uniform representation. With a
novel Vision-Text-Layout Transformer, UDOP unifies pretraining and multi-domain
downstream tasks into a prompt-based sequence generation scheme. UDOP is
pretrained on both large-scale unlabeled document corpora using innovative
self-supervised objectives and diverse labeled data. UDOP also learns to
generate document images from text and layout modalities via masked image
reconstruction. To the best of our knowledge, this is the first time in the
field of document AI that one model simultaneously achieves high-quality neural
document editing and content customization. Our method sets the
state-of-the-art on 9 Document AI tasks, e.g., document understanding and QA,
across diverse data domains like finance reports, academic papers, and
websites. UDOP ranks first on the leaderboard of the Document Understanding
Benchmark (DUE).</p>
  </details>
</details>
<details>
  <summary>56. <b>标题：Towards a Taxonomy for the Use of Synthetic Data in Advanced Analytics</b></summary>
  <p><b>编号</b>：[239]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02622</p>
  <p><b>作者</b>：Peter Kowalczyk,  Giacomo Welsch,  Frédéric Thiesse</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：important business areas, learning techniques led, product recommendation, advanced analytics, techniques led</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The proliferation of deep learning techniques led to a wide range of advanced
analytics applications in important business areas such as predictive
maintenance or product recommendation. However, as the effectiveness of
advanced analytics naturally depends on the availability of sufficient data, an
organization's ability to exploit the benefits might be restricted by limited
data or likewise data access. These challenges could force organizations to
spend substantial amounts of money on data, accept constrained analytics
capacities, or even turn into a showstopper for analytics projects. Against
this backdrop, recent advances in deep learning to generate synthetic data may
help to overcome these barriers. Despite its great potential, however,
synthetic data are rarely employed. Therefore, we present a taxonomy
highlighting the various facets of deploying synthetic data for advanced
analytics systems. Furthermore, we identify typical application scenarios for
synthetic data to assess the current state of adoption and thereby unveil
missed opportunities to pave the way for further research.</p>
  </details>
</details>
<details>
  <summary>57. <b>标题：Can Ensembling Pre-processing Algorithms Lead to Better Machine Learning  Fairness?</b></summary>
  <p><b>编号</b>：[242]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02614</p>
  <p><b>作者</b>：Khaled Badran,  Pierre-Olivier Côté,  Amanda Kolopanis,  Rached Bouchoucha,  Antonio Collante,  Diego Elias Costa,  Emad Shihab,  Foutse Khomh</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：machine learning, critical areas, increasingly crucial, crucial to address, address the bias</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As machine learning (ML) systems get adopted in more critical areas, it has
become increasingly crucial to address the bias that could occur in these
systems. Several fairness pre-processing algorithms are available to alleviate
implicit biases during model training. These algorithms employ different
concepts of fairness, often leading to conflicting strategies with
consequential trade-offs between fairness and accuracy. In this work, we
evaluate three popular fairness pre-processing algorithms and investigate the
potential for combining all algorithms into a more robust pre-processing
ensemble. We report on lessons learned that can help practitioners better
select fairness algorithms for their models.</p>
  </details>
</details>
<details>
  <summary>58. <b>标题：Learning to Optimize in Model Predictive Control</b></summary>
  <p><b>编号</b>：[247]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02603</p>
  <p><b>作者</b>：Jacob Sacks,  Byron Boots</p>
  <p><b>备注</b>：Proceedings of the IEEE Conference on Robotics and Automation (ICRA), 2022. Paper is 6 pages with 2 figures and 2 tables</p>
  <p><b>关键词</b>：Model Predictive Control, Sampling-based Model Predictive, Model Predictive, flexible control framework, Predictive Control</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Sampling-based Model Predictive Control (MPC) is a flexible control framework
that can reason about non-smooth dynamics and cost functions. Recently,
significant work has focused on the use of machine learning to improve the
performance of MPC, often through learning or fine-tuning the dynamics or cost
function. In contrast, we focus on learning to optimize more effectively. In
other words, to improve the update rule within MPC. We show that this can be
particularly useful in sampling-based MPC, where we often wish to minimize the
number of samples for computational reasons. Unfortunately, the cost of
computational efficiency is a reduction in performance; fewer samples results
in noisier updates. We show that we can contend with this noise by learning how
to update the control distribution more effectively and make better use of the
few samples that we have. Our learned controllers are trained via imitation
learning to mimic an expert which has access to substantially more samples. We
test the efficacy of our approach on multiple simulated robotics tasks in
sample-constrained regimes and demonstrate that our approach can outperform a
MPC controller with the same number of samples.</p>
  </details>
</details>
<details>
  <summary>59. <b>标题：Learning Sampling Distributions for Model Predictive Control</b></summary>
  <p><b>编号</b>：[250]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02587</p>
  <p><b>作者</b>：Jacob Sacks,  Byron Boots</p>
  <p><b>备注</b>：Accepted at the Conference on Robot Learning (CoRL), 2022. Main paper is 9 pages with 4 figures. Appendix is 12 pages with 11 figures and 1 table</p>
  <p><b>关键词</b>：Model Predictive Control, Model Predictive, approaches to Model, Predictive Control, straightforward to parallelize</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Sampling-based methods have become a cornerstone of contemporary approaches
to Model Predictive Control (MPC), as they make no restrictions on the
differentiability of the dynamics or cost function and are straightforward to
parallelize. However, their efficacy is highly dependent on the quality of the
sampling distribution itself, which is often assumed to be simple, like a
Gaussian. This restriction can result in samples which are far from optimal,
leading to poor performance. Recent work has explored improving the performance
of MPC by sampling in a learned latent space of controls. However, these
methods ultimately perform all MPC parameter updates and warm-starting between
time steps in the control space. This requires us to rely on a number of
heuristics for generating samples and updating the distribution and may lead to
sub-optimal performance. Instead, we propose to carry out all operations in the
latent space, allowing us to take full advantage of the learned distribution.
Specifically, we frame the learning problem as bi-level optimization and show
how to train the controller with backpropagation-through-time. By using a
normalizing flow parameterization of the distribution, we can leverage its
tractable density to avoid requiring differentiability of the dynamics and cost
function. Finally, we evaluate the proposed approach on simulated robotics
tasks and demonstrate its ability to surpass the performance of prior methods
and scale better with a reduced number of samples.</p>
  </details>
</details>
<details>
  <summary>60. <b>标题：A Mobility-Aware Deep Learning Model for Long-Term COVID-19 Pandemic  Prediction and Policy Impact Analysis</b></summary>
  <p><b>编号</b>：[253]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02575</p>
  <p><b>作者</b>：Danfeng Guo,  Zijie Huang,  Junheng Hao,  Yizhou Sun,  Wei Wang,  Demetri Terzopoulos</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：popular research topic, disease spreading analysis, aiming at disease, disease spreading, popular research</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Pandemic(epidemic) modeling, aiming at disease spreading analysis, has always
been a popular research topic especially following the outbreak of COVID-19 in
2019. Some representative models including SIR-based deep learning prediction
models have shown satisfactory performance. However, one major drawback for
them is that they fall short in their long-term predictive ability. Although
graph convolutional networks (GCN) also perform well, their edge
representations do not contain complete information and it can lead to biases.
Another drawback is that they usually use input features which they are unable
to predict. Hence, those models are unable to predict further future. We
propose a model that can propagate predictions further into the future and it
has better edge representations. In particular, we model the pandemic as a
spatial-temporal graph whose edges represent the transition of infections and
are learned by our model. We use a two-stream framework that contains GCN and
recursive structures (GRU) with an attention mechanism. Our model enables
mobility analysis that provides an effective toolbox for public health
researchers and policy makers to predict how different lock-down strategies
that actively control mobility can influence the spread of pandemics.
Experiments show that our model outperforms others in its long-term predictive
power. Moreover, we simulate the effects of certain policies and predict their
impacts on infection control.</p>
  </details>
</details>
<details>
  <summary>61. <b>标题：Cross-Domain Few-Shot Relation Extraction via Representation Learning  and Domain Adaptation</b></summary>
  <p><b>编号</b>：[259]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02560</p>
  <p><b>作者</b>：Zhongju Yuan,  Zhenkun Wang,  Genghui Li</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：existing few-shot learning, source domain, relation extraction poses, Cross-domain few-shot relation, few-shot relation extraction</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Cross-domain few-shot relation extraction poses a great challenge for the
existing few-shot learning methods and domain adaptation methods when the
source domain and target domain have large discrepancies. This paper proposes a
method by combining the idea of few-shot learning and domain adaptation to deal
with this problem. In the proposed method, an encoder, learned by optimizing a
representation loss and an adversarial loss, is used to extract the relation of
sentences in the source and target domain. The representation loss, including a
cross-entropy loss and a contrastive loss, makes the encoder extract the
relation of the source domain and keep the geometric structure of the classes
in the source domain. And the adversarial loss is used to merge the source
domain and target domain. The experimental results on the benchmark FewRel
dataset demonstrate that the proposed method can outperform some
state-of-the-art methods.</p>
  </details>
</details>
<details>
  <summary>62. <b>标题：MAP-Music2Vec: A Simple and Effective Baseline for Self-Supervised Music  Audio Representation Learning</b></summary>
  <p><b>编号</b>：[260]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02508</p>
  <p><b>作者</b>：Yizhi Li,  Ruibin Yuan,  Ge Zhang,  Yinghao Ma,  Chenghua Lin,  Xingran Chen,  Anton Ragni,  Hanzhi Yin,  Zhijie Hu,  Haoyu He,  Emmanouil Benetos,  Norbert Gyenge,  Ruibo Liu,  Jie Fu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：exponentially growing interest, deep learning community, community has witnessed, witnessed an exponentially, exponentially growing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The deep learning community has witnessed an exponentially growing interest
in self-supervised learning (SSL). However, it still remains unexplored how to
build a framework for learning useful representations of raw music waveforms in
a self-supervised manner. In this work, we design Music2Vec, a framework
exploring different SSL algorithmic components and tricks for music audio
recordings. Our model achieves comparable results to the state-of-the-art
(SOTA) music SSL model Jukebox, despite being significantly smaller with less
than 2% of parameters of the latter. The model will be released on
Huggingface(Please refer to: this https URL)</p>
  </details>
</details>
<details>
  <summary>63. <b>标题：FEMa-FS: Finite Element Machines for Feature Selection</b></summary>
  <p><b>编号</b>：[261]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02507</p>
  <p><b>作者</b>：Lucas Biaggi,  João P. Papa,  Kelton A. P Costa,  Danillo R. Pereira,  Leandro A. Passos</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Identifying anomalies, primary strategies, strategies towards security, security and protection, protection procedures</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Identifying anomalies has become one of the primary strategies towards
security and protection procedures in computer networks. In this context,
machine learning-based methods emerge as an elegant solution to identify such
scenarios and learn irrelevant information so that a reduction in the
identification time and possible gain in accuracy can be obtained. This paper
proposes a novel feature selection approach called Finite Element Machines for
Feature Selection (FEMa-FS), which uses the framework of finite elements to
identify the most relevant information from a given dataset. Although FEMa-FS
can be applied to any application domain, it has been evaluated in the context
of anomaly detection in computer networks. The outcomes over two datasets
showed promising results.</p>
  </details>
</details>
<details>
  <summary>64. <b>标题：This changes to that : Combining causal and non-causal explanations to  generate disease progression in capsule endoscopy</b></summary>
  <p><b>编号</b>：[262]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02506</p>
  <p><b>作者</b>：Anuja Vats,  Ahmed Mohammed,  Marius Pedersen,  Nirmalie Wiratunga</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：deep learning networks, learning networks, processes of deep, deep learning, decision processes</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Due to the unequivocal need for understanding the decision processes of deep
learning networks, both modal-dependent and model-agnostic techniques have
become very popular. Although both of these ideas provide transparency for
automated decision making, most methodologies focus on either using the
modal-gradients (model-dependent) or ignoring the model internal states and
reasoning with a model's behavior/outcome (model-agnostic) to instances. In
this work, we propose a unified explanation approach that given an instance
combines both model-dependent and agnostic explanations to produce an
explanation set. The generated explanations are not only consistent in the
neighborhood of a sample but can highlight causal relationships between image
content and the outcome. We use Wireless Capsule Endoscopy (WCE) domain to
illustrate the effectiveness of our explanations. The saliency maps generated
by our approach are comparable or better on the softmax information score.</p>
  </details>
</details>
<details>
  <summary>65. <b>标题：Relation-based Motion Prediction using Traffic Scene Graphs</b></summary>
  <p><b>编号</b>：[263]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02503</p>
  <p><b>作者</b>：Maximilian Zipfl,  Felix Hertlein,  Achim Rettinger,  Steffen Thoma,  Lavdim Halilaj,  Juergen Luettin,  Stefan Schmid,  Cory Henson</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Representing relevant information, Representing relevant, traffic, understanding its environment, environment is crucial</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Representing relevant information of a traffic scene and understanding its
environment is crucial for the success of autonomous driving. Modeling the
surrounding of an autonomous car using semantic relations, i.e., how different
traffic participants relate in the context of traffic rule based behaviors, is
hardly been considered in previous work. This stems from the fact that these
relations are hard to extract from real-world traffic scenes. In this work, we
model traffic scenes in a form of spatial semantic scene graphs for various
different predictions about the traffic participants, e.g., acceleration and
deceleration. Our learning and inference approach uses Graph Neural Networks
(GNNs) and shows that incorporating explicit information about the spatial
semantic relations between traffic participants improves the predicdtion
results. Specifically, the acceleration prediction of traffic participants is
improved by up to 12% compared to the baselines, which do not exploit this
explicit information. Furthermore, by including additional information about
previous scenes, we achieve 73% improvements.</p>
  </details>
</details>
<details>
  <summary>66. <b>标题：An Unsupervised Machine Learning Approach for Ground Motion Clustering  and Selection</b></summary>
  <p><b>编号</b>：[266]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.03188</p>
  <p><b>作者</b>：R. Bailey Bond,  Pu Ren,  Jerome F. Hajjar,  Hao Sun</p>
  <p><b>备注</b>：24 pages, 15 Figures</p>
  <p><b>关键词</b>：sequence data continues, engineering design, applied science, machine learning, unsupervised machine learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Clustering analysis of sequence data continues to address many applications
in engineering design, aided with the rapid growth of machine learning in
applied science. This paper presents an unsupervised machine learning algorithm
to extract defining characteristics of earthquake ground-motion records, also
called latent features, to aid in ground-motion clustering and selection. In
this context, a latent feature is a low dimensional machine-discovered spectral
characteristic learned through nonlinear relationships of a neural network
autoencoder. Clustering can be performed on the latent features and used to
select a representative archetypal subgroup from a large ground-motion suite.
The objective of efficient ground-motion selection is to choose records
representative of what the structure will probabilistically experience in its
lifetime. Three examples are presented to validate this approach, including a
synthetic spectral dataset and spectra from field recorded ground-motion
records. Deep embedding clustering of ground motion spectra improves on the
results of static feature extraction, utilizing characteristics that represent
the sparse spectral content of ground motions.</p>
  </details>
</details>
<details>
  <summary>67. <b>标题：A Novel Deep Reinforcement Learning Based Automated Stock Trading System  Using Cascaded LSTM Networks</b></summary>
  <p><b>编号</b>：[294]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02721</p>
  <p><b>作者</b>：Jie Zou,  Jiashu Lou,  Baohua Wang,  Sixue Liu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：methods originally widely, DRL methods originally, deep reinforcement learning, stock trading strategies, performance shortcomings</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>More and more stock trading strategies are constructed using deep
reinforcement learning (DRL) algorithms, but DRL methods originally widely used
in the gaming community are not directly adaptable to financial data with low
signal-to-noise ratios and unevenness, and thus suffer from performance
shortcomings. In this paper, to capture the hidden information, we propose a
DRL based stock trading system using cascaded LSTM, which first uses LSTM to
extract the time-series features from stock daily data, and then the features
extracted are fed to the agent for training, while the strategy functions in
reinforcement learning also use another LSTM for training. Experiments in DJI
in the US market and SSE50 in the Chinese stock market show that our model
outperforms previous baseline models in terms of cumulative returns and Sharp
ratio, and this advantage is more significant in the Chinese stock market, a
merging market. It indicates that our proposed method is a promising way to
build a automated stock trading system.</p>
  </details>
</details>
<details>
  <summary>68. <b>标题：Enhancing Quantum Adversarial Robustness by Randomized Encodings</b></summary>
  <p><b>编号</b>：[303]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2212.02531</p>
  <p><b>作者</b>：Weiyuan Gong,  Dong Yuan,  Weikang Li,  Dong-Ling Deng</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：quantum machine learning, machine learning, quantum, advanced quantum learning, quantum learning models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The interplay between quantum physics and machine learning gives rise to the
emergent frontier of quantum machine learning, where advanced quantum learning
models may outperform their classical counterparts in solving certain
challenging problems. However, quantum learning systems are vulnerable to
adversarial attacks: adding tiny carefully-crafted perturbations on legitimate
input samples can cause misclassifications. To address this issue, we propose a
general scheme to protect quantum learning systems from adversarial attacks by
randomly encoding the legitimate data samples through unitary or quantum error
correction encoders. In particular, we rigorously prove that both global and
local random unitary encoders lead to exponentially vanishing gradients (i.e.
barren plateaus) for any variational quantum circuits that aim to add
adversarial perturbations, independent of the input data and the inner
structures of adversarial circuits and quantum classifiers. In addition, we
prove a rigorous bound on the vulnerability of quantum classifiers under local
unitary adversarial attacks. We show that random black-box quantum error
correction encoders can protect quantum classifiers against local adversarial
noises and their robustness increases as we concatenate error correction codes.
To quantify the robustness enhancement, we adapt quantum differential privacy
as a measure of the prediction stability for quantum classifiers. Our results
establish versatile defense strategies for quantum classifiers against
adversarial perturbations, which provide valuable guidance to enhance the
reliability and security for both near-term and future quantum learning
technologies.</p>
  </details>
</details>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">徐耀彬</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://louishsu.xyz/2022/12/08/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html">http://louishsu.xyz/2022/12/08/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://louishsu.xyz" target="_blank">LOUIS' BLOG</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"></div><div class="post_share"><div class="social-share" data-image="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="next-post pull-full"><a href="/2022/11/26/%E5%8D%87%E7%BA%A7%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E5%85%A8%E6%94%BB%E7%95%A5.html"><img class="next-cover" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">升级深度学习开发环境全攻略</div></div></a></div></nav><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="twikoo-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="card-info-avatar is-center"><img class="avatar-img" src="/img/touxiang.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/><div class="author-info__name">徐耀彬</div><div class="author-info__description">专注于自然语言处理前沿技术与应用价值！</div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">13</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">标签</div><div class="length-num">4</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">分类</div><div class="length-num">7</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/isLouisHsu"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/isLouisHsu" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:is.louishsu@foxmail.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>公告</span></div><div class="announcement_content">记录和分享一些学习和开源内容，若有问题可通过邮箱is.louishsu@foxmail.com联系，欢迎交流！！</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">1.</span> <span class="toc-text">统计</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">2.</span> <span class="toc-text">计算机视觉</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">3.</span> <span class="toc-text">自然语言处理</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">4.</span> <span class="toc-text">机器学习</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">5.</span> <span class="toc-text">人工智能</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2022/12/08/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html" title="Arxiv每日速递(2022-12-08)"><img src="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Arxiv每日速递(2022-12-08)"/></a><div class="content"><a class="title" href="/2022/12/08/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html" title="Arxiv每日速递(2022-12-08)">Arxiv每日速递(2022-12-08)</a><time datetime="2022-12-08T00:39:27.027Z" title="发表于 2022-12-08 08:39:27">2022-12-08</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/11/26/%E5%8D%87%E7%BA%A7%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E5%85%A8%E6%94%BB%E7%95%A5.html" title="升级深度学习开发环境全攻略"><img src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="升级深度学习开发环境全攻略"/></a><div class="content"><a class="title" href="/2022/11/26/%E5%8D%87%E7%BA%A7%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E5%85%A8%E6%94%BB%E7%95%A5.html" title="升级深度学习开发环境全攻略">升级深度学习开发环境全攻略</a><time datetime="2022-11-26T15:29:06.000Z" title="发表于 2022-11-26 23:29:06">2022-11-26</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/11/17/2022%E5%85%A8%E7%90%83%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%8A%80%E6%9C%AF%E5%88%9B%E6%96%B0%E5%A4%A7%E8%B5%9B(GAIIC2022)%EF%BC%9A%E5%95%86%E5%93%81%E6%A0%87%E9%A2%98%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB(%E4%BA%8C%E7%AD%89%E5%A5%96).html" title="2022全球人工智能技术创新大赛(GAIIC2022)：商品标题实体识别(二等奖)"><img src="https://cdn.kesci.com/upload/image/r7j60un866.png?imageView2/2/w/2500/h/2500" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="2022全球人工智能技术创新大赛(GAIIC2022)：商品标题实体识别(二等奖)"/></a><div class="content"><a class="title" href="/2022/11/17/2022%E5%85%A8%E7%90%83%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%8A%80%E6%9C%AF%E5%88%9B%E6%96%B0%E5%A4%A7%E8%B5%9B(GAIIC2022)%EF%BC%9A%E5%95%86%E5%93%81%E6%A0%87%E9%A2%98%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB(%E4%BA%8C%E7%AD%89%E5%A5%96).html" title="2022全球人工智能技术创新大赛(GAIIC2022)：商品标题实体识别(二等奖)">2022全球人工智能技术创新大赛(GAIIC2022)：商品标题实体识别(二等奖)</a><time datetime="2022-11-17T14:29:06.000Z" title="发表于 2022-11-17 22:29:06">2022-11-17</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/10/22/%E4%B8%AD%E5%9B%BD%E6%B3%95%E5%BE%8B%E6%99%BA%E8%83%BD%E6%8A%80%E6%9C%AF%E8%AF%84%E6%B5%8B(CAIL2021)%EF%BC%9A%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96(Rank2).html" title="中国法律智能技术评测(CAIL2021)：信息抽取(Rank2)"><img src="http://cail.cipsc.org.cn/img/index_mainpic.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="中国法律智能技术评测(CAIL2021)：信息抽取(Rank2)"/></a><div class="content"><a class="title" href="/2021/10/22/%E4%B8%AD%E5%9B%BD%E6%B3%95%E5%BE%8B%E6%99%BA%E8%83%BD%E6%8A%80%E6%9C%AF%E8%AF%84%E6%B5%8B(CAIL2021)%EF%BC%9A%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96(Rank2).html" title="中国法律智能技术评测(CAIL2021)：信息抽取(Rank2)">中国法律智能技术评测(CAIL2021)：信息抽取(Rank2)</a><time datetime="2021-10-22T14:29:06.000Z" title="发表于 2021-10-22 22:29:06">2021-10-22</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/05/19/%E5%85%A8%E7%90%83%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%8A%80%E6%9C%AF%E5%88%9B%E6%96%B0%E5%A4%A7%E8%B5%9B%E3%80%90%E8%B5%9B%E9%81%93%E4%B8%80%E3%80%91%EF%BC%9A%E5%8C%BB%E5%AD%A6%E5%BD%B1%E5%83%8F%E6%8A%A5%E5%91%8A%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B(%E4%B8%89%E7%AD%89%E5%A5%96).html" title="全球人工智能技术创新大赛【赛道一】：医学影像报告异常检测(三等奖)"><img src="https://tianchi-public.oss-cn-hangzhou.aliyuncs.com/public/files/forum/161037709574435991610377095138.jpeg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="全球人工智能技术创新大赛【赛道一】：医学影像报告异常检测(三等奖)"/></a><div class="content"><a class="title" href="/2021/05/19/%E5%85%A8%E7%90%83%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%8A%80%E6%9C%AF%E5%88%9B%E6%96%B0%E5%A4%A7%E8%B5%9B%E3%80%90%E8%B5%9B%E9%81%93%E4%B8%80%E3%80%91%EF%BC%9A%E5%8C%BB%E5%AD%A6%E5%BD%B1%E5%83%8F%E6%8A%A5%E5%91%8A%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B(%E4%B8%89%E7%AD%89%E5%A5%96).html" title="全球人工智能技术创新大赛【赛道一】：医学影像报告异常检测(三等奖)">全球人工智能技术创新大赛【赛道一】：医学影像报告异常检测(三等奖)</a><time datetime="2021-05-19T09:57:06.000Z" title="发表于 2021-05-19 17:57:06">2021-05-19</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2022 By 徐耀彬</div><div class="footer_custom_text"><p><a style="margin-inline:5px"target="_blank"href="https://hexo.io/"><img src="https://img.shields.io/badge/Frame-Hexo-blue?style=flat&logo=hexo"title="博客框架为Hexo"alt="img"></a><a style="margin-inline:5px"target="_blank"href="https://butterfly.js.org/"><img src="https://img.shields.io/badge/Theme-Butterfly-6513df?style=flat&logo=bitdefender"title="主题采用butterfly"alt="img"></a><a style="margin-inline:5px"target="_blank"href="https://www.jsdelivr.com/"><img src="https://img.shields.io/badge/CDN-jsDelivr-orange?style=flat&logo=jsDelivr"title="本站使用JsDelivr为静态资源提供CDN加速"alt="img"></a><a style="margin-inline:5px"target="_blank"href="https://github.com/"><img src="https://img.shields.io/badge/Source-Github-d021d6?style=flat&logo=GitHub"title="本站项目由Gtihub托管"alt="img"></a><a style="margin-inline:5px"target="_blank"href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img src="https://img.shields.io/badge/Copyright-BY--NC--SA%204.0-d42328?style=flat&logo=Claris"alt="img"title="本站采用知识共享署名-非商业性使用-相同方式共享4.0国际许可协议进行许可"></a></br></p></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="font-plus" type="button" title="放大字体"><i class="fas fa-plus"></i></button><button id="font-minus" type="button" title="缩小字体"><i class="fas fa-minus"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div></div><hr/><div id="local-search-results"></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.css"><script>(() => {
  document.querySelectorAll('#article-container span.katex-display').forEach(item => {
    btf.wrap(item, 'div', '', 'katex-wrap')
  })
})()</script><script>(()=>{
  const $countDom = document.getElementById('twikoo-count')
  const init = () => {
    let initData = {
      el: '#twikoo-wrap',
      envId: 'blog-',
      region: ''
    }

    if (false) {
      const otherData = false
      initData = Object.assign(initData, otherData)
    }
    
    twikoo.init(initData)
  }

  const getCount = () => {
    twikoo.getCommentsCount({
      envId: 'blog-',
      region: '',
      urls: [window.location.pathname],
      includeReply: false
    }).then(function (res) {
      $countDom.innerText = res[0].count
    }).catch(function (err) {
      console.error(err);
    });
  }

  const loadTwikoo = (bool = false) => {
    if (typeof twikoo === 'object') {
      init()
      bool && $countDom && setTimeout(getCount,0)
    } else {
      getScript('https://cdn.jsdelivr.net/npm/twikoo/dist/twikoo.all.min.js').then(()=> {
        init()
        bool && $countDom && setTimeout(getCount,0)
      })
    }
  }

  if ('Twikoo' === 'Twikoo' || !false) {
    if (false) btf.loadComment(document.getElementById('twikoo-wrap'), loadTwikoo)
    else loadTwikoo(true)
  } else {
    window.loadOtherComment = () => {
      loadTwikoo()
    }
  }
})()</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><!-- hexo injector body_end start --> <script data-pjax>if(document.getElementById('recent-posts') && (location.pathname ==='/'|| '/' ==='all')){
    var parent = document.getElementById('recent-posts');
    var child = '<div class="recent-post-item" style="width:100%;height: auto"><div id="catalog_magnet"><div class="magnet_item"><a class="magnet_link" href="http://louishsu.xyz/categories/机器学习/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🐱 机器学习 (1)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://louishsu.xyz/categories/自然语言处理/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">📚 自然语言处理 (1)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://louishsu.xyz/categories/竞赛相关/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🎮 竞赛相关 (3)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://louishsu.xyz/categories/阅读笔记/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🎮 阅读笔记 (1)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><a class="magnet_link_more"  href="http://louishsu.xyz/categories" style="flex:1;text-align: center;margin-bottom: 10px;">查看更多...</a></div></div>';
    console.log('已挂载magnet')
    parent.insertAdjacentHTML("afterbegin",child)}
     </script><style>#catalog_magnet{flex-wrap: wrap;display: flex;width:100%;justify-content:space-between;padding: 10px 10px 0 10px;align-content: flex-start;}.magnet_item{flex-basis: calc(50% - 5px);background: #f2f2f2;margin-bottom: 10px;border-radius: 8px;transition: all 0.2s ease-in-out;}.magnet_item:hover{background: #b30070}.magnet_link_more{color:#555}.magnet_link{color:black}.magnet_link:hover{color:white}@media screen and (max-width: 600px) {.magnet_item {flex-basis: 100%;}}.magnet_link_context{display:flex;padding: 10px;font-size:16px;transition: all 0.2s ease-in-out;}.magnet_link_context:hover{padding: 10px 20px;}</style>
    <style></style>
  <script data-pjax src="https://cdn.jsdelivr.net/gh/Zfour/hexo-github-calendar@1.21/hexo_githubcalendar.js"></script>
  <script data-pjax>
        function GithubCalendarConfig(){
            var git_githubapiurl ="https://python-github-calendar-api.vercel.app/api?isLouisHsu";
            var git_color =['#ebedf0', '#fdcdec', '#fc9bd9', '#fa6ac5', '#f838b2', '#f5089f', '#c4067e', '#92055e', '#540336', '#48022f', '#30021f'];
            var git_user ="isLouisHsu";
            var parent_div_git = document.getElementById('recent-posts');
            var git_div_html = '<div class="recent-post-item" style="width:100%;height:auto;padding:10px;"><div id="github_loading" style="width:10%;height:100%;margin:0 auto;display: block"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"  viewBox="0 0 50 50" style="enable-background:new 0 0 50 50" xml:space="preserve"><path fill="#d0d0d0" d="M25.251,6.461c-10.318,0-18.683,8.365-18.683,18.683h4.068c0-8.071,6.543-14.615,14.615-14.615V6.461z" transform="rotate(275.098 25 25)"><animateTransform attributeType="xml" attributeName="transform" type="rotate" from="0 25 25" to="360 25 25" dur="0.6s" repeatCount="indefinite"></animateTransform></path></svg></div><div id="github_container"></div></div>';
            if(parent_div_git && location.pathname =='/'){
                console.log('已挂载github calendar')
                // parent_div_git.innerHTML=git_div_html+parent_div_git.innerHTML // 无报错，但不影响使用(支持pjax跳转)
                parent_div_git.insertAdjacentHTML("afterbegin",git_div_html) // 有报错，但不影响使用(支持pjax跳转)
            };
            GithubCalendar(git_githubapiurl,git_color,git_user)
        }
        if(document.getElementById('recent-posts')){
            GithubCalendarConfig()
        }
    </script>
    <style>#github_container{min-height:280px}@media screen and (max-width:650px) {#github_container{background-image:;min-height:0px}}</style>
    <style></style><script data-pjax>function electric_clock_injector_config(){
                var parent_div_git = document.getElementsByClassName('sticky_layout')[0];
                var item_html = '<div class="card-widget card-clock"><div class="card-glass"><div class="card-background"><div class="card-content"><div id="hexo_electric_clock"><img id="card-clock-loading" src="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-clock/clock/images/weather/loading.gif" style="height: 120px; width: 100%;" data-ll-status="loading" class="entered loading"></div></div></div></div></div>';
                console.log('已挂载electric_clock')
                // parent_div_git.innerHTML=item_html+parent_div_git.innerHTML // 无报错，但不影响使用(支持pjax跳转)
                parent_div_git.insertAdjacentHTML("afterbegin",item_html) // 有报错，但不影响使用(支持pjax跳转)
            }if( document.getElementsByClassName('sticky_layout')[0] && (location.pathname ==='all'|| 'all' ==='all')){

            electric_clock_injector_config()
        } </script><script src="https://pv.sohu.com/cityjson?ie=utf-8"></script><script data-pjax  src="https://cdn.jsdelivr.net/gh/Zfour/hexo-electric-clock@1.0.6/clock.js"></script><!-- hexo injector body_end end --><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"model":{"jsonPath":"/live2dw/assets/hijiki.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":false},"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body></html>