<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Arxiv每日速递(2023-02-10) | LOUIS' BLOG</title><meta name="author" content="徐耀彬"><meta name="copyright" content="徐耀彬"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="本篇博文主要展示每日从Arxiv论文网站获取的最新论文列表，以计算机视觉、自然语言处理、机器学习、人工智能等大方向进行划分。 统计 今日共更新253篇论文，其中：  45篇计算机视觉（cs.CV） 27篇自然语言处理（cs.CL） 114篇机器学习（cs.LG） 53篇人工智能（cs.AI）  计算机视觉    1. 标题：Diagnosing and Rectifying Vision Mode">
<meta property="og:type" content="article">
<meta property="og:title" content="Arxiv每日速递(2023-02-10)">
<meta property="og:url" content="http://louishsu.xyz/2023/02/10/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html">
<meta property="og:site_name" content="LOUIS&#39; BLOG">
<meta property="og:description" content="本篇博文主要展示每日从Arxiv论文网站获取的最新论文列表，以计算机视觉、自然语言处理、机器学习、人工智能等大方向进行划分。 统计 今日共更新253篇论文，其中：  45篇计算机视觉（cs.CV） 27篇自然语言处理（cs.CL） 114篇机器学习（cs.LG） 53篇人工智能（cs.AI）  计算机视觉    1. 标题：Diagnosing and Rectifying Vision Mode">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png">
<meta property="article:published_time" content="2023-02-10T00:43:44.400Z">
<meta property="article:modified_time" content="2023-02-10T00:45:30.305Z">
<meta property="article:author" content="徐耀彬">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://louishsu.xyz/2023/02/10/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2023-02-10 08:45:30'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const fontSizeVal = saveToLocal.get('global-font-size')
    if (fontSizeVal !== undefined) {
      document.documentElement.style.setProperty('--global-font-size', fontSizeVal + 'px')
    }
    })(window)</script><link rel="stylesheet" href="/css/background.css"><script src="https://cdn.jsdelivr.net/npm/echarts@4.7.0/dist/echarts.min.js"></script><!-- hexo injector head_end start --><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Zfour/hexo-electric-clock@1.0.6/clock.css"><!-- hexo injector head_end end --><meta name="generator" content="Hexo 5.4.2"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="author-avatar"><img class="avatar-img" src="/img/touxiang.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">13</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">标签</div><div class="length-num">4</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">分类</div><div class="length-num">7</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/message/"><i class="fa-fw far fa-comment-dots"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa-fw fa fa-book"></i><span> 找文章</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></li><li><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></li><li><a class="site-page" href="/charts/"><i class="fa-fw fa fa-archive"></i><span> 统计</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-tools"></i><span> 工具</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/md_editor/"><i class="fa-fw fas fa-pen"></i><span> 在线markdown</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/isLouisHsu/blog/tree/master/source/_posts"><i class="fa-fw fa fa-star"></i><span> 在线push</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa-brands fa-app-store"></i><span> 利器</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" target="_blank" rel="noopener" href="https://code.visualstudio.com/"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> VSCode：微软旗下的跨平台代码编辑软件</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://mobaxterm.mobatek.net/"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> MobaXterm：超好用的全能远程终端</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://www.zotero.org/"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> Zotero：便于收集、组织、引用、共享的文献管理工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/CopyTranslator/CopyTranslator"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> CopyTranslator：“复制即翻译”的外文辅助阅读翻译解决方案</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://ditto-cp.sourceforge.io/"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> Ditto：强大的Windows剪贴板增强工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/indiff/qttabbar"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> QtTabBar：在Windows资源管理器中使用多标签功能扩展工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/sentialx/multrin"><i class="fa-fw fa-sharp fa-solid fa-star-half-stroke"></i><span> Multrin：“窗口合并”辅助小工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/Wox-launcher/Wox"><i class="fa-fw fa-sharp fa-solid fa-star-half-stroke"></i><span> Wox &amp; Everything：基于名称快速定位文件和文件夹的搜索工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/NickeManarin/ScreenToGif"><i class="fa-fw fa-regular fa-star"></i><span> ScreenToGif：快速录制屏幕指定区域并保存为动图文件</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://mathpix.com/"><i class="fa-fw fa-regular fa-star"></i><span> Mathpix Snipping：识别数学公式并转换成LaTeX</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">LOUIS' BLOG</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/message/"><i class="fa-fw far fa-comment-dots"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa-fw fa fa-book"></i><span> 找文章</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></li><li><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></li><li><a class="site-page" href="/charts/"><i class="fa-fw fa fa-archive"></i><span> 统计</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-tools"></i><span> 工具</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/md_editor/"><i class="fa-fw fas fa-pen"></i><span> 在线markdown</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/isLouisHsu/blog/tree/master/source/_posts"><i class="fa-fw fa fa-star"></i><span> 在线push</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa-brands fa-app-store"></i><span> 利器</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" target="_blank" rel="noopener" href="https://code.visualstudio.com/"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> VSCode：微软旗下的跨平台代码编辑软件</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://mobaxterm.mobatek.net/"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> MobaXterm：超好用的全能远程终端</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://www.zotero.org/"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> Zotero：便于收集、组织、引用、共享的文献管理工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/CopyTranslator/CopyTranslator"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> CopyTranslator：“复制即翻译”的外文辅助阅读翻译解决方案</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://ditto-cp.sourceforge.io/"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> Ditto：强大的Windows剪贴板增强工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/indiff/qttabbar"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> QtTabBar：在Windows资源管理器中使用多标签功能扩展工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/sentialx/multrin"><i class="fa-fw fa-sharp fa-solid fa-star-half-stroke"></i><span> Multrin：“窗口合并”辅助小工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/Wox-launcher/Wox"><i class="fa-fw fa-sharp fa-solid fa-star-half-stroke"></i><span> Wox &amp; Everything：基于名称快速定位文件和文件夹的搜索工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/NickeManarin/ScreenToGif"><i class="fa-fw fa-regular fa-star"></i><span> ScreenToGif：快速录制屏幕指定区域并保存为动图文件</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://mathpix.com/"><i class="fa-fw fa-regular fa-star"></i><span> Mathpix Snipping：识别数学公式并转换成LaTeX</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Arxiv每日速递(2023-02-10)<a class="post-edit-link" href="https://github.com/isLouisHsu/blog/tree/master/source_posts/Arxiv每日速递.md" title="编辑" target="_blank"><i class="fas fa-pencil-square"></i></a></h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-02-10T00:43:44.400Z" title="发表于 2023-02-10 08:43:44">2023-02-10</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-02-10T00:45:30.305Z" title="更新于 2023-02-10 08:45:30">2023-02-10</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">阅读笔记</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">60.2k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>360分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span><span class="post-meta-separator">|</span><span class="post-meta-commentcount"><i class="far fa-comments fa-fw post-meta-icon"></i><span class="post-meta-label">评论数:</span><a href="/2023/02/10/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html#post-comment"><span id="twikoo-count"></span></a></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><p>本篇博文主要展示每日从Arxiv论文网站获取的最新论文列表，以计算机视觉、自然语言处理、机器学习、人工智能等大方向进行划分。</p>
<h1>统计</h1>
<p>今日共更新253篇论文，其中：</p>
<ul>
<li><a href="#%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89">45篇计算机视觉（cs.CV）</a></li>
<li><a href="#%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86">27篇自然语言处理（cs.CL）</a></li>
<li><a href="#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0">114篇机器学习（cs.LG）</a></li>
<li><a href="#%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD">53篇人工智能（cs.AI）</a></li>
</ul>
<h1>计算机视觉</h1>
<details>
  <summary>1. <b>标题：Diagnosing and Rectifying Vision Models using Language</b></summary>
  <p><b>编号</b>：[1]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04269</p>
  <p><b>作者</b>：Yuhui Zhang,  Jeff Z. HaoChen,  Shih-Cheng Huang,  Kuan-Chieh Wang,  James Zou,  Serena Yeung</p>
  <p><b>备注</b>：Published at ICLR 2023</p>
  <p><b>关键词</b>：Recent multi-modal contrastive, building strong vision, multi-modal contrastive learning, contrastive learning models, embedding space suitable</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent multi-modal contrastive learning models have demonstrated the ability
to learn an embedding space suitable for building strong vision classifiers, by
leveraging the rich information in large-scale image-caption datasets. Our work
highlights a distinct advantage of this multi-modal embedding space: the
ability to diagnose vision classifiers through natural language. The
traditional process of diagnosing model behaviors in deployment settings
involves labor-intensive data acquisition and annotation. Our proposed method
can discover high-error data slices, identify influential attributes and
further rectify undesirable model behaviors, without requiring any visual data.
Through a combination of theoretical explanation and empirical verification, we
present conditions under which classifiers trained on embeddings from one
modality can be equivalently applied to embeddings from another modality. On a
range of image datasets with known error slices, we demonstrate that our method
can effectively identify the error slices and influential attributes, and can
further use language to rectify failure modes of the classifier.</p>
  </details>
</details>
<details>
  <summary>2. <b>标题：PFGM++: Unlocking the Potential of Physics-Inspired Generative Models</b></summary>
  <p><b>编号</b>：[2]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04265</p>
  <p><b>作者</b>：Yilun Xu,  Ziming Liu,  Yonglong Tian,  Shangyuan Tong,  Max Tegmark,  Tommi Jaakkola</p>
  <p><b>备注</b>：Code is available at this https URL</p>
  <p><b>关键词</b>：Poisson Flow Generative, Poisson Flow, Flow Generative Models, Flow Generative, physics-inspired generative models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We introduce a new family of physics-inspired generative models termed PFGM++
that unifies diffusion models and Poisson Flow Generative Models (PFGM). These
models realize generative trajectories for $N$ dimensional data by embedding
paths in $N{+}D$ dimensional space while still controlling the progression with
a simple scalar norm of the $D$ additional variables. The new models reduce to
PFGM when $D{=}1$ and to diffusion models when $D{\to}\infty$. The flexibility
of choosing $D$ allows us to trade off robustness against rigidity as
increasing $D$ results in more concentrated coupling between the data and the
additional variable norms. We dispense with the biased large batch field
targets used in PFGM and instead provide an unbiased perturbation-based
objective similar to diffusion models. To explore different choices of $D$, we
provide a direct alignment method for transferring well-tuned hyperparameters
from diffusion models ($D{\to} \infty$) to any finite $D$ values. Our
experiments show that models with finite $D$ can be superior to previous
state-of-the-art diffusion models on CIFAR-10/FFHQ $64{\times}64$ datasets,
with FID scores of $1.91/2.43$ when $D{=}2048/128$. In addition, we demonstrate
that models with smaller $D$ exhibit improved robustness against modeling
errors. Code is available at this https URL</p>
  </details>
</details>
<details>
  <summary>3. <b>标题：Nerfstudio: A Modular Framework for Neural Radiance Field Development</b></summary>
  <p><b>编号</b>：[3]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04264</p>
  <p><b>作者</b>：Matthew Tancik,  Ethan Weber,  Evonne Ng,  Ruilong Li,  Brent Yi,  Justin Kerr,  Terrance Wang,  Alexander Kristoffersen,  Jake Austin,  Kamyar Salahi,  Abhik Ahuja,  David McAllister,  Angjoo Kanazawa</p>
  <p><b>备注</b>：Project page at this https URL</p>
  <p><b>关键词</b>：Neural Radiance Fields, Radiance Fields, rapidly growing area, Neural Radiance, computer vision</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Neural Radiance Fields (NeRF) are a rapidly growing area of research with
wide-ranging applications in computer vision, graphics, robotics, and more. In
order to streamline the development and deployment of NeRF research, we propose
a modular PyTorch framework, Nerfstudio. Our framework includes plug-and-play
components for implementing NeRF-based methods, which make it easy for
researchers and practitioners to incorporate NeRF into their projects.
Additionally, the modular design enables support for extensive real-time
visualization tools, streamlined pipelines for importing captured in-the-wild
data, and tools for exporting to video, point cloud and mesh representations.
The modularity of Nerfstudio enables the development of Nerfacto, our method
that combines components from recent papers to achieve a balance between speed
and quality, while also remaining flexible to future modifications. To promote
community-driven development, all associated code and data are made publicly
available with open-source licensing at https://nerf.studio.</p>
  </details>
</details>
<details>
  <summary>4. <b>标题：Shortcut Detection with Variational Autoencoders</b></summary>
  <p><b>编号</b>：[7]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04246</p>
  <p><b>作者</b>：Nicolas M. Müller,  Simon Roschmann,  Shahbaz Khan,  Philip Sperl,  Konstantin Böttinger</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：models make predictions, make predictions based, machine learning, applications of machine, essential that models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>For real-world applications of machine learning (ML), it is essential that
models make predictions based on well-generalizing features rather than
spurious correlations in the data. The identification of such spurious
correlations, also known as shortcuts, is a challenging problem and has so far
been scarcely addressed. In this work, we present a novel approach to detect
shortcuts in image and audio datasets by leveraging variational autoencoders
(VAEs). The disentanglement of features in the latent space of VAEs allows us
to discover correlations in datasets and semi-automatically evaluate them for
ML shortcuts. We demonstrate the applicability of our method on several
real-world datasets and identify shortcuts that have not been discovered
before. Based on these findings, we also investigate the construction of
shortcut adversarial examples.</p>
  </details>
</details>
<details>
  <summary>5. <b>标题：SkyEye: Self-Supervised Bird's-Eye-View Semantic Mapping Using Monocular  Frontal View Images</b></summary>
  <p><b>编号</b>：[10]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04233</p>
  <p><b>作者</b>：Nikhil Gosala,  Kürsat Petek,  Paulo L. J. Drews-Jr,  Wolfram Burgard,  Abhinav Valada</p>
  <p><b>备注</b>：14 pages, 7 figures</p>
  <p><b>关键词</b>：automated driving pipelines, driving pipelines due, BEV semantic map, BEV, decision-making tasks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Bird's-Eye-View (BEV) semantic maps have become an essential component of
automated driving pipelines due to the rich representation they provide for
decision-making tasks. However, existing approaches for generating these maps
still follow a fully supervised training paradigm and hence rely on large
amounts of annotated BEV data. In this work, we address this limitation by
proposing the first self-supervised approach for generating a BEV semantic map
using a single monocular image from the frontal view (FV). During training, we
overcome the need for BEV ground truth annotations by leveraging the more
easily available FV semantic annotations of video sequences. Thus, we propose
the SkyEye architecture that learns based on two modes of self-supervision,
namely, implicit supervision and explicit supervision. Implicit supervision
trains the model by enforcing spatial consistency of the scene over time based
on FV semantic sequences, while explicit supervision exploits BEV pseudolabels
generated from FV semantic annotations and self-supervised depth estimates.
Extensive evaluations on the KITTI-360 dataset demonstrate that our
self-supervised approach performs on par with the state-of-the-art fully
supervised methods and achieves competitive results using only 1% of direct
supervision in the BEV compared to fully supervised approaches. Finally, we
publicly release both our code and the BEV datasets generated from the
KITTI-360 and Waymo datasets.</p>
  </details>
</details>
<details>
  <summary>6. <b>标题：A Dynamic Graph CNN with Cross-Representation Distillation for  Event-Based Recognition</b></summary>
  <p><b>编号</b>：[29]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04177</p>
  <p><b>作者</b>：Yongjian Deng,  Hao Chen,  Bochen Xie,  Hai Liu,  Youfu Li</p>
  <p><b>备注</b>：10 pages, 7 figures</p>
  <p><b>关键词</b>：popular solution, solution to convert, convert events, well-pretrained CNNs, graph</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>It is a popular solution to convert events into dense frame-based
representations to use the well-pretrained CNNs in hand. Although with
appealing performance, this line of work sacrifices the sparsity/temporal
precision of events and usually necessitates heavy-weight models, thereby
largely weakening the advantages and real-life application potential of event
cameras. A more application-friendly way is to design deep graph models for
learning sparse point-based representations from events. Yet, the efficacy of
these graph models is far behind the frame-based counterpart with two key
limitations: ($i$) simple graph construction strategies without carefully
integrating the variant attributes (i.e., semantics, spatial and temporal
coordinates) for each vertex, leading to biased graph representation; ($ii$)
deficient learning because the lack of well pretraining models available. Here
we solve the first problem by introducing a new event-based graph CNN (EDGCN),
with a dynamic aggregation module to integrate all attributes of vertices
adaptively. To alleviate the learning difficulty, we propose to leverage the
dense representation counterpart of events as a cross-representation auxiliary
to supply additional supervision and prior knowledge for the event graph. To
this end, we form a frame-to-graph transfer learning framework with a
customized hybrid distillation loss to well respect the varying
cross-representation gaps across layers. Extensive experiments on multiple
vision tasks validate the effectiveness and high generalization ability of our
proposed model and distillation strategy (Core components of our codes are
submitted with supplementary material and will be made publicly available upon
acceptance)</p>
  </details>
</details>
<details>
  <summary>7. <b>标题：Domain Adaptation of Synthetic Driving Datasets for Real-World  Autonomous Driving</b></summary>
  <p><b>编号</b>：[38]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04149</p>
  <p><b>作者</b>：Koustav Mullick,  Harshil Jain,  Sanchit Gupta,  Amit Arvind Kale</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：developing perception based, perception based deep, based deep learning, deep learning models, developing perception</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>While developing perception based deep learning models, the benefit of
synthetic data is enormous. However, performance of networks trained with
synthetic data for certain computer vision tasks degrade significantly when
tested on real world data due to the domain gap between them. One of the
popular solutions in bridging this gap between synthetic and actual world data
is to frame it as a domain adaptation task. In this paper, we propose and
evaluate novel ways for the betterment of such approaches. In particular we
build upon the method of UNIT-GAN.
In normal GAN training for the task of domain translation, pairing of images
from both the domains (viz, real and synthetic) is done randomly. We propose a
novel method to efficiently incorporate semantic supervision into this pair
selection, which helps in boosting the performance of the model along with
improving the visual quality of such transformed images. We illustrate our
empirical findings on Cityscapes \cite{cityscapes} and challenging synthetic
dataset Synscapes. Though the findings are reported on the base network of
UNIT-GAN, they can be easily extended to any other similar network.</p>
  </details>
</details>
<details>
  <summary>8. <b>标题：Multi-Modal Evaluation Approach for Medical Image Segmentation</b></summary>
  <p><b>编号</b>：[40]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04135</p>
  <p><b>作者</b>：Seyed M.R. Modaresi,  Aomar Osmani,  Mohammadreza Razzazi,  Abdelghani Chibani</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：machine learning techniques, medical image segmentation, medical image, learning techniques, high-effort task</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Manual segmentation of medical images (e.g., segmenting tumors in CT scans)
is a high-effort task that can be accelerated with machine learning techniques.
However, selecting the right segmentation approach depends on the evaluation
function, particularly in medical image segmentation where we must deal with
dependency between voxels. For instance, in contrast to classical systems where
the predictions are either correct or incorrect, predictions in medical image
segmentation may be partially correct and incorrect simultaneously. In this
paper, we explore this expressiveness to extract the useful properties of these
systems and formally define a novel multi-modal evaluation (MME) approach to
measure the effectiveness of different segmentation methods. This approach
improves the segmentation evaluation by introducing new relevant and
interpretable characteristics, including detection property, boundary
alignment, uniformity, total volume, and relative volume. Our proposed approach
is open-source and publicly available for use. We have conducted several
reproducible experiments, including the segmentation of pancreas, liver tumors,
and multi-organs datasets, to show the applicability of the proposed approach.</p>
  </details>
</details>
<details>
  <summary>9. <b>标题：Hyperspectral Image Compression Using Implicit Neural Representation</b></summary>
  <p><b>编号</b>：[42]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04129</p>
  <p><b>作者</b>：Shima Rezasoltani,  Faisal Z. Qureshi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：typical similarly-sized color, similarly-sized color image, record the electromagnetic, electromagnetic spectrum, store hundreds</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Hyperspectral images, which record the electromagnetic spectrum for a pixel
in the image of a scene, often store hundreds of channels per pixel and contain
an order of magnitude more information than a typical similarly-sized color
image. Consequently, concomitant with the decreasing cost of capturing these
images, there is a need to develop efficient techniques for storing,
transmitting, and analyzing hyperspectral images. This paper develops a method
for hyperspectral image compression using implicit neural representations where
a multilayer perceptron network $\Phi_\theta$ with sinusoidal activation
functions ``learns'' to map pixel locations to pixel intensities for a given
hyperspectral image $I$. $\Phi_\theta$ thus acts as a compressed encoding of
this image. The original image is reconstructed by evaluating $\Phi_\theta$ at
each pixel location. We have evaluated our method on four benchmarks -- Indian
Pines, Cuprite, Pavia University, and Jasper Ridge -- and we show the proposed
method achieves better compression than JPEG, JPEG2000, PCA-DCT, and HVEC at
low bitrates.</p>
  </details>
</details>
<details>
  <summary>10. <b>标题：Triplet Loss-less Center Loss Sampling Strategies in Facial Expression  Recognition Scenarios</b></summary>
  <p><b>编号</b>：[54]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04108</p>
  <p><b>作者</b>：Hossein Rajoli,  Fatemeh Lotfi,  Adham Atyabi,  Fatemeh Afghah</p>
  <p><b>备注</b>：The paper has been accepted in the CISS 2023 and will be published very soon</p>
  <p><b>关键词</b>：convey massive information, expressions convey massive, Facial expressions convey, facial expression recognition, convey massive</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Facial expressions convey massive information and play a crucial role in
emotional expression. Deep neural network (DNN) accompanied by deep metric
learning (DML) techniques boost the discriminative ability of the model in
facial expression recognition (FER) applications. DNN, equipped with only
classification loss functions such as Cross-Entropy cannot compact intra-class
feature variation or separate inter-class feature distance as well as when it
gets fortified by a DML supporting loss item. The triplet center loss (TCL)
function is applied on all dimensions of the sample's embedding in the
embedding space. In our work, we developed three strategies: fully-synthesized,
semi-synthesized, and prediction-based negative sample selection strategies. To
achieve better results, we introduce a selective attention module that provides
a combination of pixel-wise and element-wise attention coefficients using
high-semantic deep features of input samples. We evaluated the proposed method
on the RAF-DB, a highly imbalanced dataset. The experimental results reveal
significant improvements in comparison to the baseline for all three negative
sample selection strategies.</p>
  </details>
</details>
<details>
  <summary>11. <b>标题：Revisiting Deep Active Learning for Semantic Segmentation</b></summary>
  <p><b>编号</b>：[69]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04075</p>
  <p><b>作者</b>：Sudhanshu Mittal,  Joshua Niemeijer,  Jörg P. Schäfer,  Thomas Brox</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：automatically selects samples, minimum annotation cost, learning automatically selects, Active learning, automatically selects</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Active learning automatically selects samples for annotation from a data pool
to achieve maximum performance with minimum annotation cost. This is
particularly critical for semantic segmentation, where annotations are costly.
In this work, we show in the context of semantic segmentation that the data
distribution is decisive for the performance of the various active learning
objectives proposed in the literature. Particularly, redundancy in the data, as
it appears in most driving scenarios and video datasets, plays a large role. We
demonstrate that the integration of semi-supervised learning with active
learning can improve performance when the two objectives are aligned. Our
experimental study shows that current active learning benchmarks for
segmentation in driving scenarios are not realistic since they operate on data
that is already curated for maximum diversity. Accordingly, we propose a more
realistic evaluation scheme in which the value of active learning becomes
clearly visible, both by itself and in combination with semi-supervised
learning.</p>
  </details>
</details>
<details>
  <summary>12. <b>标题：Weakly-supervised Representation Learning for Video Alignment and  Analysis</b></summary>
  <p><b>编号</b>：[73]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04064</p>
  <p><b>作者</b>：Guy Bar-Shalom,  George Leifman,  Michael Elad,  Ehud Rivlin</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：easier subsequent processing, relevant visual content, frame-based feature learning, aiming to encapsulate, subsequent processing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Many tasks in video analysis and understanding boil down to the need for
frame-based feature learning, aiming to encapsulate the relevant visual content
so as to enable simpler and easier subsequent processing. While supervised
strategies for this learning task can be envisioned, self and weakly-supervised
alternatives are preferred due to the difficulties in getting labeled data.
This paper introduces LRProp -- a novel weakly-supervised representation
learning approach, with an emphasis on the application of temporal alignment
between pairs of videos of the same action category. The proposed approach uses
a transformer encoder for extracting frame-level features, and employs the DTW
algorithm within the training iterations in order to identify the alignment
path between video pairs. Through a process referred to as ``pair-wise position
propagation'', the probability distributions of these correspondences per
location are matched with the similarity of the frame-level features via
KL-divergence minimization. The proposed algorithm uses also a regularized
SoftDTW loss for better tuning the learned features. Our novel representation
learning paradigm consistently outperforms the state of the art on temporal
alignment tasks, establishing a new performance bar over several downstream
video analysis applications.</p>
  </details>
</details>
<details>
  <summary>13. <b>标题：From Zero-Shot to Few-Shot Learning: A Step of Embedding-Aware  Generative Models</b></summary>
  <p><b>编号</b>：[76]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04060</p>
  <p><b>作者</b>：Liangjun Feng,  Jiancheng Zhao,  Chunhui Zhao</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：data insufficiency problem, visual embedding spaces, addresses the data, ZSL, data insufficiency</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Embedding-aware generative model (EAGM) addresses the data insufficiency
problem for zero-shot learning (ZSL) by constructing a generator between
semantic and visual embedding spaces. Thanks to the predefined benchmark and
protocols, the number of proposed EAGMs for ZSL is increasing rapidly. We argue
that it is time to take a step back and reconsider the embedding-aware
generative paradigm. The purpose of this paper is three-fold. First, given the
fact that the current embedding features in benchmark datasets are somehow
out-of-date, we improve the performance of EAGMs for ZSL remarkably with
embarrassedly simple modifications on the embedding features. This is an
important contribution, since the results reveal that the embedding of EAGMs
deserves more attention. Second, we compare and analyze a significant number of
EAGMs in depth. Based on five benchmark datasets, we update the
state-of-the-art results for ZSL and give a strong baseline for few-shot
learning (FSL), including the classic unseen-class few-shot learning (UFSL) and
the more challenging seen-class few-shot learning (SFSL). Finally, a
comprehensive generative model repository, namely, generative any-shot learning
(GASL) repository, is provided, which contains the models, features,
parameters, and settings of EAGMs for ZSL and FSL. Any results in this paper
can be readily reproduced with only one command line based on GASL.</p>
  </details>
</details>
<details>
  <summary>14. <b>标题：A Systematic Performance Analysis of Deep Perceptual Loss Networks  Breaks Transfer Learning Conventions</b></summary>
  <p><b>编号</b>：[86]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04032</p>
  <p><b>作者</b>：Gustav Grund Pihlgren,  Konstantina Nikolaidou,  Prakash Chandra Chhipa,  Nosheen Abid,  Rajkumar Saini,  Fredrik Sandin,  Marcus Liwicki</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Deep perceptual loss, mimic human perception, perceptual loss, Deep perceptual, loss</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep perceptual loss is a type of loss function in computer vision that aims
to mimic human perception by using the deep features extracted from neural
networks. In recent years the method has been applied to great effect on a host
of interesting computer vision tasks, especially for tasks with image or
image-like outputs. Many applications of the method use pretrained networks,
often convolutional networks, for loss calculation. Despite the increased
interest and broader use, more effort is needed toward exploring which networks
to use for calculating deep perceptual loss and from which layers to extract
the features.
This work aims to rectify this by systematically evaluating a host of
commonly used and readily available, pretrained networks for a number of
different feature extraction points on four existing use cases of deep
perceptual loss. The four use cases are implementations of previous works where
the selected networks and extraction points are evaluated instead of the
networks and extraction points used in the original work. The experimental
tasks are dimensionality reduction, image segmentation, super-resolution, and
perceptual similarity. The performance on these four tasks, attributes of the
networks, and extraction points are then used as a basis for an in-depth
analysis. This analysis uncovers essential information regarding which
architectures provide superior performance for deep perceptual loss and how to
choose an appropriate extraction point for a particular task and dataset.
Furthermore, the work discusses the implications of the results for deep
perceptual loss and the broader field of transfer learning. The results break
commonly held assumptions in transfer learning, which imply that deep
perceptual loss deviates from most transfer learning settings or that these
assumptions need a thorough re-evaluation.</p>
  </details>
</details>
<details>
  <summary>15. <b>标题：The Devil is in the Wrongly-classified Samples: Towards Unified Open-set  Recognition</b></summary>
  <p><b>编号</b>：[98]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04002</p>
  <p><b>作者</b>：Jun Cen,  Di Luan,  Shiwei Zhang,  Yixuan Pei,  Yingya Zhang,  Deli Zhao,  Shaojie Shen,  Qifeng Chen</p>
  <p><b>备注</b>：Accepted by ICLR 2023</p>
  <p><b>关键词</b>：Unified Open-set Recognition, Open-set Recognition, wrongly classified samples, UOSR, classified samples</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Open-set Recognition (OSR) aims to identify test samples whose classes are
not seen during the training process. Recently, Unified Open-set Recognition
(UOSR) has been proposed to reject not only unknown samples but also known but
wrongly classified samples, which tends to be more practical in real-world
applications. The UOSR draws little attention since it is proposed, but we find
sometimes it is even more practical than OSR in the real world applications, as
evaluation results of known but wrongly classified samples are also wrong like
unknown samples. In this paper, we deeply analyze the UOSR task under different
training and evaluation settings to shed light on this promising research
direction. For this purpose, we first evaluate the UOSR performance of several
OSR methods and show a significant finding that the UOSR performance
consistently surpasses the OSR performance by a large margin for the same
method. We show that the reason lies in the known but wrongly classified
samples, as their uncertainty distribution is extremely close to unknown
samples rather than known and correctly classified samples. Second, we analyze
how the two training settings of OSR (i.e., pre-training and outlier exposure)
influence the UOSR. We find although they are both beneficial for
distinguishing known and correctly classified samples from unknown samples,
pre-training is also helpful for identifying known but wrongly classified
samples while outlier exposure is not. In addition to different training
settings, we also formulate a new evaluation setting for UOSR which is called
few-shot UOSR, where only one or five samples per unknown class are available
during evaluation to help identify unknown samples. We propose FS-KNNS for the
few-shot UOSR to achieve state-of-the-art performance under all settings.</p>
  </details>
</details>
<details>
  <summary>16. <b>标题：Convolutional Neural Networks Trained to Identify Words Provide a Good  Account of Visual Form Priming Effects</b></summary>
  <p><b>编号</b>：[103]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03992</p>
  <p><b>作者</b>：Dong Yin,  Valerio Biscione,  Jeffrey Bowers</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：masked priming data, Form Priming Project, orthographic coding schemes, coding schemes, form priming</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A wide variety of orthographic coding schemes and models of visual word
identification have been developed to account for masked priming data that
provide a measure of orthographic similarity between letter strings. These
models tend to include hand-coded orthographic representations with single unit
coding for specific forms of knowledge (e.g., units coding for a letter in a
given position or a letter sequence). Here we assess how well a range of these
coding schemes and models account for the pattern of form priming effects taken
from the Form Priming Project and compare these findings to results observed in
with 11 standard deep neural network models (DNNs) developed in computer
science. We find that deep convolutional networks perform as well or better
than the coding schemes and word recognition models, whereas transformer
networks did less well. The success of convolutional networks is remarkable as
their architectures were not developed to support word recognition (they were
designed to perform well on object recognition) and they classify pixel images
of words (rather artificial encodings of letter strings). The findings add to
the recent work of (Hannagan et al., 2021) suggesting that convolutional
networks may capture key aspects of visual word identification.</p>
  </details>
</details>
<details>
  <summary>17. <b>标题：Multiview Representation Learning from Crowdsourced Triplet Comparisons</b></summary>
  <p><b>编号</b>：[105]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03987</p>
  <p><b>作者</b>：Xiaotian Lu,  Jiyi Li,  Koh Takeuchi,  Hisashi Kashima</p>
  <p><b>备注</b>：10 pages, 3 figures, 7 tables, Accepted for WWW 2023</p>
  <p><b>关键词</b>：numerous fields, collect data, data at scale, scale in numerous, multiview embeddings</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Crowdsourcing has been used to collect data at scale in numerous fields.
Triplet similarity comparison is a type of crowdsourcing task, in which crowd
workers are asked the question ``among three given objects, which two are more
similar?'', which is relatively easy for humans to answer. However, the
comparison can be sometimes based on multiple views, i.e., different
independent attributes such as color and shape. Each view may lead to different
results for the same three objects. Although an algorithm was proposed in prior
work to produce multiview embeddings, it involves at least two problems: (1)
the existing algorithm cannot independently predict multiview embeddings for a
new sample, and (2) different people may prefer different views. In this study,
we propose an end-to-end inductive deep learning framework to solve the
multiview representation learning problem. The results show that our proposed
method can obtain multiview embeddings of any object, in which each view
corresponds to an independent attribute of the object. We collected two
datasets from a crowdsourcing platform to experimentally investigate the
performance of our proposed approach compared to conventional baseline methods.</p>
  </details>
</details>
<details>
  <summary>18. <b>标题：Cross-Layer Retrospective Retrieving via Layer Attention</b></summary>
  <p><b>编号</b>：[106]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03985</p>
  <p><b>作者</b>：Yanwen Fang,  Yuxi Cai,  Jintai Chen,  Jingyu Zhao,  Guangjian Tian,  Guodong Li</p>
  <p><b>备注</b>：Published as a conference paper at ICLR 2023</p>
  <p><b>关键词</b>：retrieving query-activated information, deep neural network, strengthening layer interactions, evidence has shown, shown that strengthening</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>More and more evidence has shown that strengthening layer interactions can
enhance the representation power of a deep neural network, while self-attention
excels at learning interdependencies by retrieving query-activated information.
Motivated by this, we devise a cross-layer attention mechanism, called
multi-head recurrent layer attention (MRLA), that sends a query representation
of the current layer to all previous layers to retrieve query-related
information from different levels of receptive fields. A light-weighted version
of MRLA is also proposed to reduce the quadratic computation cost. The proposed
layer attention mechanism can enrich the representation power of many
state-of-the-art vision networks, including CNNs and vision transformers. Its
effectiveness has been extensively evaluated in image classification, object
detection and instance segmentation tasks, where improvements can be
consistently observed. For example, our MRLA can improve 1.6\% Top-1 accuracy
on ResNet-50, while only introducing 0.16M parameters and 0.07B FLOPs.
Surprisingly, it can boost the performances by a large margin of 3-4\% box AP
and mask AP in dense prediction tasks. Our code is available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>19. <b>标题：Neural Congealing: Aligning Images to a Joint Semantic Atlas</b></summary>
  <p><b>编号</b>：[116]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03956</p>
  <p><b>作者</b>：Dolev Ofri-Amar,  Michal Geyer,  Yoni Kasten,  Tali Dekel</p>
  <p><b>备注</b>：Project page: this https URL</p>
  <p><b>关键词</b>：present Neural Congealing, Neural Congealing, present Neural, jointly aligning semantically-common, detecting and jointly</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present Neural Congealing -- a zero-shot self-supervised framework for
detecting and jointly aligning semantically-common content across a given set
of images. Our approach harnesses the power of pre-trained DINO-ViT features to
learn: (i) a joint semantic atlas -- a 2D grid that captures the mode of
DINO-ViT features in the input set, and (ii) dense mappings from the unified
atlas to each of the input images. We derive a new robust self-supervised
framework that optimizes the atlas representation and mappings per image set,
requiring only a few real-world images as input without any additional input
information (e.g., segmentation masks). Notably, we design our losses and
training paradigm to account only for the shared content under severe
variations in appearance, pose, background clutter or other distracting
objects. We demonstrate results on a plethora of challenging image sets
including sets of mixed domains (e.g., aligning images depicting sculpture and
artwork of cats), sets depicting related yet different object categories (e.g.,
dogs and tigers), or domains for which large-scale training data is scarce
(e.g., coffee mugs). We thoroughly evaluate our method and show that our
test-time optimization approach performs favorably compared to a
state-of-the-art method that requires extensive training on large-scale
datasets.</p>
  </details>
</details>
<details>
  <summary>20. <b>标题：Spatiotemporal Deformation Perception for Fisheye Video Rectification</b></summary>
  <p><b>编号</b>：[125]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03934</p>
  <p><b>作者</b>：Shangrong Yang,  Chunyu Lin,  Kang Liao,  Yao Zhao</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：fisheye video, extensively studied, elusive challenge, fisheye, correction</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Although the distortion correction of fisheye images has been extensively
studied, the correction of fisheye videos is still an elusive challenge. For
different frames of the fisheye video, the existing image correction methods
ignore the correlation of sequences, resulting in temporal jitter in the
corrected video. To solve this problem, we propose a temporal weighting scheme
to get a plausible global optical flow, which mitigates the jitter effect by
progressively reducing the weight of frames. Subsequently, we observe that the
inter-frame optical flow of the video is facilitated to perceive the local
spatial deformation of the fisheye video. Therefore, we derive the spatial
deformation through the flows of fisheye and distorted-free videos, thereby
enhancing the local accuracy of the predicted result. However, the independent
correction for each frame disrupts the temporal correlation. Due to the
property of fisheye video, a distorted moving object may be able to find its
distorted-free pattern at another moment. To this end, a temporal deformation
aggregator is designed to reconstruct the deformation correlation between
frames and provide a reliable global feature. Our method achieves an end-to-end
correction and demonstrates superiority in correction quality and stability
compared with the SOTA correction methods.</p>
  </details>
</details>
<details>
  <summary>21. <b>标题：Multi-view Feature Extraction based on Dual Contrastive Head</b></summary>
  <p><b>编号</b>：[127]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03932</p>
  <p><b>作者</b>：Hongjie Zhang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：highdimensional multi-view data, multi-view data, highdimensional multi-view, Multi-view feature extraction, efficient approach</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Multi-view feature extraction is an efficient approach for alleviating the
issue of dimensionality in highdimensional multi-view data. Contrastive
learning (CL), which is a popular self-supervised learning method, has recently
attracted considerable attention. Most CL-based methods were constructed only
from the sample level. In this study, we propose a novel multiview feature
extraction method based on dual contrastive head, which introduce
structural-level contrastive loss into sample-level CL-based method.
Structural-level CL push the potential subspace structures consistent in any
two cross views, which assists sample-level CL to extract discriminative
features more effectively. Furthermore, it is proven that the relationships
between structural-level CL and mutual information and probabilistic intraand
inter-scatter, which provides the theoretical support for the excellent
performance. Finally, numerical experiments on six real datasets demonstrate
the superior performance of the proposed method compared to existing methods.</p>
  </details>
</details>
<details>
  <summary>22. <b>标题：Gestalt-Guided Image Understanding for Few-Shot Learning</b></summary>
  <p><b>编号</b>：[131]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03922</p>
  <p><b>作者</b>：Kun Song,  Yuchen Wu,  Jiansheng Chen,  Tianyu Hu,  Huimin Ma</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：few-shot learning tasks, Image Understanding, few-shot learning, deep learning, learning tasks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Due to the scarcity of available data, deep learning does not perform well on
few-shot learning tasks. However, human can quickly learn the feature of a new
category from very few samples. Nevertheless, previous work has rarely
considered how to mimic human cognitive behavior and apply it to few-shot
learning. This paper introduces Gestalt psychology to few-shot learning and
proposes Gestalt-Guided Image Understanding, a plug-and-play method called
GGIU. Referring to the principle of totality and the law of closure in Gestalt
psychology, we design Totality-Guided Image Understanding and Closure-Guided
Image Understanding to extract image features. After that, a feature estimation
module is used to estimate the accurate features of images. Extensive
experiments demonstrate that our method can improve the performance of existing
models effectively and flexibly without retraining or fine-tuning. Our code is
released on this https URL.</p>
  </details>
</details>
<details>
  <summary>23. <b>标题：Generalized Few-Shot 3D Object Detection of LiDAR Point Cloud for  Autonomous Driving</b></summary>
  <p><b>编号</b>：[138]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03914</p>
  <p><b>作者</b>：Jiawei Liu,  Xingping Dong,  Sanyuan Zhao,  Jianbing Shen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：witnessed huge successes, vehicles and pedestrians, Recent years, years have witnessed, witnessed huge</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent years have witnessed huge successes in 3D object detection to
recognize common objects for autonomous driving (e.g., vehicles and
pedestrians). However, most methods rely heavily on a large amount of
well-labeled training data. This limits their capability of detecting rare
fine-grained objects (e.g., police cars and ambulances), which is important for
special cases, such as emergency rescue, and so on. To achieve simultaneous
detection for both common and rare objects, we propose a novel task, called
generalized few-shot 3D object detection, where we have a large amount of
training data for common (base) objects, but only a few data for rare (novel)
classes. Specifically, we analyze in-depth differences between images and point
clouds, and then present a practical principle for the few-shot setting in the
3D LiDAR dataset. To solve this task, we propose a simple and effective
detection framework, including (1) an incremental fine-tuning method to extend
existing 3D detection models to recognize both common and rare objects, and (2)
a sample adaptive balance loss to alleviate the issue of long-tailed data
distribution in autonomous driving scenarios. On the nuScenes dataset, we
conduct sufficient experiments to demonstrate that our approach can
successfully detect the rare (novel) classes that contain only a few training
data, while also maintaining the detection accuracy of common objects.</p>
  </details>
</details>
<details>
  <summary>24. <b>标题：Multi-site Organ Segmentation with Federated Partial Supervision and  Site Adaptation</b></summary>
  <p><b>编号</b>：[139]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03911</p>
  <p><b>作者</b>：Pengbo Liu,  Mengke Sun,  S. Kevin Zhou</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Impact Statement, specific application requirements, Accurate organ segmentation, Objective and Impact, Accurate organ</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Objective and Impact Statement: Accurate organ segmentation is critical for
many clinical applications at different clinical sites, which may have their
specific application requirements that concern different organs. Introduction:
However, learning high-quality, site-specific organ segmentation models is
challenging as it often needs on-site curation of a large number of annotated
images. Security concerns further complicate the matter. Methods: The paper
aims to tackle these challenges via a two-phase aggregation-then-adaptation
approach. The first phase of federated aggregation learns a single multi-organ
segmentation model by leveraging the strength of 'bigger data', which are
formed by (i) aggregating together datasets from multiple sites that with
different organ labels to provide partial supervision, and (ii) conducting
partially supervised learning without data breach. The second phase of site
adaptation is to transfer the federated multi-organ segmentation model to
site-specific organ segmentation models, one model per site, in order to
further improve the performance of each site's organ segmentation task.
Furthermore, improved marginal loss and exclusion loss functions are used to
avoid 'knowledge conflict' problem in a partially supervision mechanism.
Results and Conclusion: Extensive experiments on five organ segmentation
datasets demonstrate the effectiveness of our multi-site approach,
significantly outperforming the site-per-se learned models and achieving the
performance comparable to the centrally learned models.</p>
  </details>
</details>
<details>
  <summary>25. <b>标题：Zero-shot Generation of Coherent Storybook from Plain Text Story using  Diffusion Models</b></summary>
  <p><b>编号</b>：[144]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03900</p>
  <p><b>作者</b>：Hyeonho Jeong,  Gihyun Kwon,  Jong Chul Ye</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：human-devised natural language, Recent advancements, opened new possibilities, possibilities for guiding, guiding the creation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent advancements in large scale text-to-image models have opened new
possibilities for guiding the creation of images through human-devised natural
language. However, while prior literature has primarily focused on the
generation of individual images, it is essential to consider the capability of
these models to ensure coherency within a sequence of images to fulfill the
demands of real-world applications such as storytelling. To address this, here
we present a novel neural pipeline for generating a coherent storybook from the
plain text of a story. Specifically, we leverage a combination of a pre-trained
Large Language Model and a text-guided Latent Diffusion Model to generate
coherent images. While previous story synthesis frameworks typically require a
large-scale text-to-image model trained on expensive image-caption pairs to
maintain the coherency, we employ simple textual inversion techniques along
with detector-based semantic image editing which allows zero-shot generation of
the coherent storybook. Experimental results show that our proposed method
outperforms state-of-the-art image editing baselines.</p>
  </details>
</details>
<details>
  <summary>26. <b>标题：Neural Artistic Style Transfer with Conditional Adversaria</b></summary>
  <p><b>编号</b>：[153]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03875</p>
  <p><b>作者</b>：P. N. Deelaka</p>
  <p><b>备注</b>：Conditional Adversarial Generative Network based novel style transfer model</p>
  <p><b>关键词</b>：artistic style transformation, style, modify the appearance, image, model</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A neural artistic style transformation (NST) model can modify the appearance
of a simple image by adding the style of a famous image. Even though the
transformed images do not look precisely like artworks by the same artist of
the respective style images, the generated images are appealing. Generally, a
trained NST model specialises in a style, and a single image represents that
style. However, generating an image under a new style is a tedious process,
which includes full model training. In this paper, we present two methods that
step toward the style image independent neural style transfer model. In other
words, the trained model could generate semantically accurate generated image
under any content, style image input pair. Our novel contribution is a
unidirectional-GAN model that ensures the Cyclic consistency by the model
architecture.Furthermore, this leads to much smaller model size and an
efficient training and validation phase.</p>
  </details>
</details>
<details>
  <summary>27. <b>标题：Geometric Perception based Efficient Text Recognition</b></summary>
  <p><b>编号</b>：[155]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03873</p>
  <p><b>作者</b>：P.N.Deelaka,  D.R.Jayakodi,  D.Y.Silva</p>
  <p><b>备注</b>：high efficient scene text recognition model introduction</p>
  <p><b>关键词</b>：Scene Text Recognition, Text Recognition, Scene Text, regular scene text, prominent sub-tasks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Every Scene Text Recognition (STR) task consists of text localization \& text
recognition as the prominent sub-tasks. However, in real-world applications
with fixed camera positions such as equipment monitor reading, image-based data
entry, and printed document data extraction, the underlying data tends to be
regular scene text. Hence, in these tasks, the use of generic, bulky models
comes up with significant disadvantages compared to customized, efficient
models in terms of model deployability, data privacy \& model reliability.
Therefore, this paper introduces the underlying concepts, theory,
implementation, and experiment results to develop models, which are highly
specialized for the task itself, to achieve not only the SOTA performance but
also to have minimal model weights, shorter inference time, and high model
reliability. We introduce a novel deep learning architecture (GeoTRNet),
trained to identify digits in a regular scene image, only using the geometrical
features present, mimicking human perception over text recognition. The code is
publicly available at this https URL</p>
  </details>
</details>
<details>
  <summary>28. <b>标题：EVEN: An Event-Based Framework for Monocular Depth Estimation at Adverse  Night Conditions</b></summary>
  <p><b>编号</b>：[157]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03860</p>
  <p><b>作者</b>：Peilun Shi,  Jiachuan Peng,  Jianing Qiu,  Xinwei Ju,  Frank Po Wen Lo,  Benny Lo</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：adverse night conditions, Accurate depth estimation, rescue robots, autonomous driving, driving and rescue</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Accurate depth estimation under adverse night conditions has practical impact
and applications, such as on autonomous driving and rescue robots. In this
work, we studied monocular depth estimation at night time in which various
adverse weather, light, and different road conditions exist, with data captured
in both RGB and event modalities. Event camera can better capture intensity
changes by virtue of its high dynamic range (HDR), which is particularly
suitable to be applied at adverse night conditions in which the amount of light
is limited in the scene. Although event data can retain visual perception that
conventional RGB camera may fail to capture, the lack of texture and color
information of event data hinders its applicability to accurately estimate
depth alone. To tackle this problem, we propose an event-vision based framework
that integrates low-light enhancement for the RGB source, and exploits the
complementary merits of RGB and event data. A dataset that includes paired RGB
and event streams, and ground truth depth maps has been constructed.
Comprehensive experiments have been conducted, and the impact of different
adverse weather combinations on the performance of framework has also been
investigated. The results have shown that our proposed framework can better
estimate monocular depth at adverse nights than six baselines.</p>
  </details>
</details>
<details>
  <summary>29. <b>标题：MMPD: Multi-Domain Mobile Video Physiology Dataset</b></summary>
  <p><b>编号</b>：[163]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03840</p>
  <p><b>作者</b>：Jiankai Tang,  Kequan Chen,  Yuntao Wang,  Yuanchun Shi,  Shwetak Patel,  Daniel McDuff,  Xin Liu</p>
  <p><b>备注</b>：GitHub : this https URL</p>
  <p><b>关键词</b>：physiological vital signals, Remote photoplethysmography, method for noninvasive, convenient and concomitant, vital signals</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Remote photoplethysmography (rPPG) is an attractive method for noninvasive,
convenient and concomitant measurement of physiological vital signals. Public
benchmark datasets have served a valuable role in the development of this
technology and improvements in accuracy over recent years.However, there remain
gaps the public datasets.First, despite the ubiquity of cameras on mobile
devices, there are few datasets recorded specifically with mobile phones
cameras. Second, most datasets are relatively small and therefore are limited
in diversity, both in appearance (e.g., skin tone), behaviors (e.g., motion)
and enivornment (e.g., lighting conditions). In an effort to help the field
advance, we present the Multi-domain Mobile Video Physiology Dataset (MMPD),
comprising 11 hours of recordings from mobile phones of 33 subjects. The
dataset was designed to capture videos with greater representation across skin
tone, body motion, and lighting conditions. MMPD is comprehensive with eight
descriptive labels and can be used in conjunction with the rPPG-toolbox. The
Github repository of our dataset:
{this https URL}</p>
  </details>
</details>
<details>
  <summary>30. <b>标题：TetCNN: Convolutional Neural Networks on Tetrahedral Meshes</b></summary>
  <p><b>编号</b>：[166]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03830</p>
  <p><b>作者</b>：Mohammad Farazi,  Zhangsihao Yang,  Wenhui Zhu,  Peijie Qiu,  Yalin Wang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Convolutional neural networks, Convolutional neural, neural networks, interpretable graph CNN, graph CNN framework</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Convolutional neural networks (CNN) have been broadly studied on images,
videos, graphs, and triangular meshes. However, it has seldom been studied on
tetrahedral meshes. Given the merits of using volumetric meshes in applications
like brain image analysis, we introduce a novel interpretable graph CNN
framework for the tetrahedral mesh structure. Inspired by ChebyNet, our model
exploits the volumetric Laplace-Beltrami Operator (LBO) to define filters over
commonly used graph Laplacian which lacks the Riemannian metric information of
3D manifolds. For pooling adaptation, we introduce new objective functions for
localized minimum cuts in the Graclus algorithm based on the LBO. We employ a
piece-wise constant approximation scheme that uses the clustering assignment
matrix to estimate the LBO on sampled meshes after each pooling. Finally,
adapting the Gradient-weighted Class Activation Mapping algorithm for
tetrahedral meshes, we use the obtained heatmaps to visualize discovered
regions-of-interest as biomarkers. We demonstrate the effectiveness of our
model on cortical tetrahedral meshes from patients with Alzheimer's disease, as
there is scientific evidence showing the correlation of cortical thickness to
neurodegenerative disease progression. Our results show the superiority of our
LBO-based convolution layer and adapted pooling over the conventionally used
unitary cortical thickness, graph Laplacian, and point cloud representation.</p>
  </details>
</details>
<details>
  <summary>31. <b>标题：A Unified Multi-view Multi-person Tracking Framework</b></summary>
  <p><b>编号</b>：[170]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03820</p>
  <p><b>作者</b>：Fan Yang,  Shigeyuki Odashima,  Sosuke Yamao,  Hiroaki Fujimoto,  Shoichi Masui,  Shan Jiang</p>
  <p><b>备注</b>：Accepted to Computational Visual Media</p>
  <p><b>关键词</b>：pose tracking, Tracking, footprint tracking, significant development, footprint</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Although there is a significant development in 3D Multi-view Multi-person
Tracking (3D MM-Tracking), current 3D MM-Tracking frameworks are designed
separately for footprint and pose tracking. Specifically, frameworks designed
for footprint tracking cannot be utilized in 3D pose tracking, because they
directly obtain 3D positions on the ground plane with a homography projection,
which is inapplicable to 3D poses above the ground. In contrast, frameworks
designed for pose tracking generally isolate multi-view and multi-frame
associations and may not be robust to footprint tracking, since footprint
tracking utilizes fewer key points than pose tracking, which weakens multi-view
association cues in a single frame. This study presents a Unified Multi-view
Multi-person Tracking framework to bridge the gap between footprint tracking
and pose tracking. Without additional modifications, the framework can adopt
monocular 2D bounding boxes and 2D poses as the input to produce robust 3D
trajectories for multiple persons. Importantly, multi-frame and multi-view
information are jointly employed to improve the performance of association and
triangulation. The effectiveness of our framework is verified by accomplishing
state-of-the-art performance on the Campus and Shelf datasets for 3D pose
tracking, and by comparable results on the WILDTRACK and MMPTRACK datasets for
3D footprint tracking.</p>
  </details>
</details>
<details>
  <summary>32. <b>标题：The XPRESS Challenge: Xray Projectomic Reconstruction -- Extracting  Segmentation with Skeletons</b></summary>
  <p><b>编号</b>：[171]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03819</p>
  <p><b>作者</b>：Tri Nguyen,  Mukul Narwani,  Mark Larson,  Yicong Li,  Shuhan Xie,  Hanspeter Pfister,  Donglai Wei,  Nir Shavit,  Lu Mi,  Alexandra Pacureanu,  Wei-Chung Lee,  Aaron T. Kuan</p>
  <p><b>备注</b>：6 pages, 2 figures</p>
  <p><b>关键词</b>：nervous system, neurons form, form a structural, structural basis, XNH</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The wiring and connectivity of neurons form a structural basis for the
function of the nervous system. Advances in volume electron microscopy (EM) and
image segmentation have enabled mapping of circuit diagrams (connectomics)
within local regions of the mouse brain. However, applying volume EM over the
whole brain is not currently feasible due to technological challenges. As a
result, comprehensive maps of long-range connections between brain regions are
lacking. Recently, we demonstrated that X-ray holographic nanotomography (XNH)
can provide high-resolution images of brain tissue at a much larger scale than
EM. In particular, XNH is wellsuited to resolve large, myelinated axon tracts
(white matter) that make up the bulk of long-range connections (projections)
and are critical for inter-region communication. Thus, XNH provides an imaging
solution for brain-wide projectomics. However, because XNH data is typically
collected at lower resolutions and larger fields-of-view than EM, accurate
segmentation of XNH images remains an important challenge that we present here.
In this task, we provide volumetric XNH images of cortical white matter axons
from the mouse brain along with ground truth annotations for axon trajectories.
Manual voxel-wise annotation of ground truth is a time-consuming bottleneck for
training segmentation networks. On the other hand, skeleton-based ground truth
is much faster to annotate, and sufficient to determine connectivity.
Therefore, we encourage participants to develop methods to leverage
skeleton-based training. To this end, we provide two types of ground-truth
annotations: a small volume of voxel-wise annotations and a larger volume with
skeleton-based annotations. Entries will be evaluated on how accurately the
submitted segmentations agree with the ground-truth skeleton annotations.</p>
  </details>
</details>
<details>
  <summary>33. <b>标题：Standing Between Past and Future: Spatio-Temporal Modeling for  Multi-Camera 3D Multi-Object Tracking</b></summary>
  <p><b>编号</b>：[180]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03802</p>
  <p><b>作者</b>：Ziqi Pang,  Jie Li,  Pavel Tokmakov,  Dian Chen,  Sergey Zagoruyko,  Yu-Xiong Wang</p>
  <p><b>备注</b>：15 pages, 8 figures</p>
  <p><b>关键词</b>：work proposes, MOT, multi-object tracking, future reasoning, reasoning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This work proposes an end-to-end multi-camera 3D multi-object tracking (MOT)
framework. It emphasizes spatio-temporal continuity and integrates both past
and future reasoning for tracked objects. Thus, we name it "Past-and-Future
reasoning for Tracking" (PF-Track). Specifically, our method adapts the
"tracking by attention" framework and represents tracked instances coherently
over time with object queries. To explicitly use historical cues, our "Past
Reasoning" module learns to refine the tracks and enhance the object features
by cross-attending to queries from previous frames and other objects. The
"Future Reasoning" module digests historical information and predicts robust
future trajectories. In the case of long-term occlusions, our method maintains
the object positions and enables re-association by integrating motion
predictions. On the nuScenes dataset, our method improves AMOTA by a large
margin and remarkably reduces ID-Switches by 90% compared to prior approaches,
which is an order of magnitude less. The code and models are made available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>34. <b>标题：Self-Supervised Unseen Object Instance Segmentation via Long-Term Robot  Interaction</b></summary>
  <p><b>编号</b>：[183]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03793</p>
  <p><b>作者</b>：Yangxiao Lu,  Ninad Khargonkar,  Zesheng Xu,  Charles Averill,  Kamalesh Palanisamy,  Kaiyu Hang,  Yunhui Guo,  Nicholas Ruozzi,  Yu Xiang</p>
  <p><b>备注</b>：11 pages, 7 figures, 5 tables</p>
  <p><b>关键词</b>：long-term robot interaction, leveraging long-term robot, segmentation, leveraging long-term, object instance segmentation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We introduce a novel robotic system for improving unseen object instance
segmentation in the real world by leveraging long-term robot interaction with
objects. Previous approaches either grasp or push an object and then obtain the
segmentation mask of the grasped or pushed object after one action. Instead,
our system defers the decision on segmenting objects after a sequence of robot
pushing actions. By applying multi-object tracking and video object
segmentation on the images collected via robot pushing, our system can generate
segmentation masks of all the objects in these images in a self-supervised way.
These include images where objects are very close to each other, and
segmentation errors usually occur on these images for existing object
segmentation networks. We demonstrate the usefulness of our system by
fine-tuning segmentation networks trained on synthetic data with real-world
data collected by our system. We show that, after fine-tuning, the segmentation
accuracy of the networks is significantly improved both in the same domain and
across different domains. In addition, we verify that the fine-tuned networks
improve top-down robotic grasping of unseen objects in the real world.</p>
  </details>
</details>
<details>
  <summary>35. <b>标题：Understanding Why ViT Trains Badly on Small Datasets: An Intuitive  Perspective</b></summary>
  <p><b>编号</b>：[204]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03751</p>
  <p><b>作者</b>：Haoran Zhu,  Boyuan Chen,  Carter Yang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：computer vision tasks, neural network architecture, attention neural network, Vision transformer, vision tasks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Vision transformer (ViT) is an attention neural network architecture that is
shown to be effective for computer vision tasks. However, compared to ResNet-18
with a similar number of parameters, ViT has a significantly lower evaluation
accuracy when trained on small datasets. To facilitate studies in related
fields, we provide a visual intuition to help understand why it is the case. We
first compare the performance of the two models and confirm that ViT has less
accuracy than ResNet-18 when trained on small datasets. We then interpret the
results by showing attention map visualization for ViT and feature map
visualization for ResNet-18. The difference is further analyzed through a
representation similarity perspective. We conclude that the representation of
ViT trained on small datasets is hugely different from ViT trained on large
datasets, which may be the reason why the performance drops a lot on small
datasets.</p>
  </details>
</details>
<details>
  <summary>36. <b>标题：Towards causally linking architectural parametrizations to algorithmic  bias in neural networks</b></summary>
  <p><b>编号</b>：[205]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03750</p>
  <p><b>作者</b>：Hao Liang,  Josue Ortega Caro,  Vikram Maheshri,  Ankit B. Patel,  Guha Balakrishnan</p>
  <p><b>备注</b>：23 pages, 15 figures, 2 tables</p>
  <p><b>关键词</b>：Training dataset biases, explaining algorithmic biases, scrutinized factors, factors when explaining, neural network architecture</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Training dataset biases are by far the most scrutinized factors when
explaining algorithmic biases of neural networks. In contrast, hyperparameters
related to the neural network architecture, e.g., the number of layers or
choice of activation functions, have largely been ignored even though different
network parameterizations are known to induce different implicit biases over
learned features. For example, convolutional kernel size has been shown to bias
CNNs towards different frequencies. In order to study the effect of these
hyperparameters, we designed a causal framework for linking an architectural
hyperparameter to algorithmic bias. Our framework is experimental, in that
several versions of a network are trained with an intervention to a specific
hyperparameter, and the resulting causal effect of this choice on performance
bias is measured. We focused on the causal relationship between sensitivity to
high-frequency image details and face analysis classification performance
across different subpopulations (race/gender). In this work, we show that
modifying a CNN hyperparameter (convolutional kernel size), even in one layer
of a CNN, will not only change a fundamental characteristic of the learned
features (frequency content) but that this change can vary significantly across
data subgroups (race/gender populations) leading to biased generalization
performance even in the presence of a balanced dataset.</p>
  </details>
</details>
<details>
  <summary>37. <b>标题：3D Neural Embedding Likelihood for Robust Sim-to-Real Transfer in  Inverse Graphics</b></summary>
  <p><b>编号</b>：[207]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03744</p>
  <p><b>作者</b>：Guangyao Zhou,  Nishad Gothoskar,  Lirui Wang,  Joshua B. Tenenbaum,  Dan Gutfreund,  Miguel Lázaro-Gredilla,  Dileep George,  Vikash K. Mansinghka</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：central challenge, robustly modeling, Neural Embedding Likelihood, real-world data, Embedding Likelihood</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A central challenge in 3D scene perception via inverse graphics is robustly
modeling the gap between 3D graphics and real-world data. We propose a novel 3D
Neural Embedding Likelihood (3DNEL) over RGB-D images to address this gap.
3DNEL uses neural embeddings to predict 2D-3D correspondences from RGB and
combines this with depth in a principled manner. 3DNEL is trained entirely from
synthetic images and generalizes to real-world data. To showcase this
capability, we develop a multi-stage inverse graphics pipeline that uses 3DNEL
for 6D object pose estimation from real RGB-D images. Our method outperforms
the previous state-of-the-art in sim-to-real pose estimation on the YCB-Video
dataset, and improves robustness, with significantly fewer large-error
predictions. Unlike existing bottom-up, discriminative approaches that are
specialized for pose estimation, 3DNEL adopts a probabilistic generative
formulation that jointly models multi-object scenes. This generative
formulation enables easy extension of 3DNEL to additional tasks like object and
camera tracking from video, using principled inference in the same
probabilistic model without task specific retraining.</p>
  </details>
</details>
<details>
  <summary>38. <b>标题：KENGIC: KEyword-driven and N-Gram Graph based Image Captioning</b></summary>
  <p><b>编号</b>：[213]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03729</p>
  <p><b>作者</b>：Brandon Birmingham,  Adrian Muscat</p>
  <p><b>备注</b>：Published in the Digital Image Computing: Techniques and Applications, 2022 (DICTA 2022)</p>
  <p><b>关键词</b>：presents a Keyword-driven, paper presents, Image, image caption generators, Keyword-driven</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper presents a Keyword-driven and N-gram Graph based approach for
Image Captioning (KENGIC). Most current state-of-the-art image caption
generators are trained end-to-end on large scale paired image-caption datasets
which are very laborious and expensive to collect. Such models are limited in
terms of their explainability and their applicability across different domains.
To address these limitations, a simple model based on N-Gram graphs which does
not require any end-to-end training on paired image captions is proposed.
Starting with a set of image keywords considered as nodes, the generator is
designed to form a directed graph by connecting these nodes through overlapping
n-grams as found in a given text corpus. The model then infers the caption by
maximising the most probable n-gram sequences from the constructed graph. To
analyse the use and choice of keywords in context of this approach, this study
analysed the generation of image captions based on (a) keywords extracted from
gold standard captions and (b) from automatically detected keywords. Both
quantitative and qualitative analyses demonstrated the effectiveness of KENGIC.
The performance achieved is very close to that of current state-of-the-art
image caption generators that are trained in the unpaired setting. The analysis
of this approach could also shed light on the generation process behind current
top performing caption generators trained in the paired setting, and in
addition, provide insights on the limitations of the current most widely used
evaluation metrics in automatic image captioning.</p>
  </details>
</details>
<details>
  <summary>39. <b>标题：A Survey of Feature detection methods for localisation of plain sections  of Axial Brain Magnetic Resonance Imaging</b></summary>
  <p><b>编号</b>：[226]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04173</p>
  <p><b>作者</b>：Jiří Martinů,  Jan Novotný,  Karel Adámek,  Petr Čermák,  Jiří Kozel,  David Školoudík</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：mapping patients' MRI, patients' MRI slices, MRI, Matching MRI brain, brain MRI</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Matching MRI brain images between patients or mapping patients' MRI slices to
the simulated atlas of a brain is key to the automatic registration of MRI of a
brain. The ability to match MRI images would also enable such applications as
indexing and searching MRI images among multiple patients or selecting images
from the region of interest. In this work, we have introduced robustness,
accuracy and cumulative distance metrics and methodology that allows us to
compare different techniques and approaches in matching brain MRI of different
patients or matching MRI brain slice to a position in the brain atlas. To that
end, we have used feature detection methods AGAST, AKAZE, BRISK, GFTT, HardNet,
and ORB, which are established methods in image processing, and compared them
on their resistance to image degradation and their ability to match the same
brain MRI slice of different patients. We have demonstrated that some of these
techniques can correctly match most of the brain MRI slices of different
patients. When matching is performed with the atlas of the human brain, their
performance is significantly lower. The best performing feature detection
method was a combination of SIFT detector and HardNet descriptor that achieved
93% accuracy in matching images with other patients and only 52% accurately
matched images when compared to atlas.</p>
  </details>
</details>
<details>
  <summary>40. <b>标题：Predicting Thrombectomy Recanalization from CT Imaging Using Deep  Learning Models</b></summary>
  <p><b>编号</b>：[230]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04143</p>
  <p><b>作者</b>：Haoyue Zhang,  Jennifer S. Polson,  Eric J. Yang,  Kambiz Nael,  William Speier,  Corey W. Arnold</p>
  <p><b>备注</b>：Medical Imaging with Deep Learning 2022 accepted short paper Jun 2022</p>
  <p><b>关键词</b>：acute ischemic stroke, large vessel occlusions, ischemic stroke, clinicians must decide, mechanical thrombectomy</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>For acute ischemic stroke (AIS) patients with large vessel occlusions,
clinicians must decide if the benefit of mechanical thrombectomy (MTB)
outweighs the risks and potential complications following an invasive
procedure. Pre-treatment computed tomography (CT) and angiography (CTA) are
widely used to characterize occlusions in the brain vasculature. If a patient
is deemed eligible, a modified treatment in cerebral ischemia (mTICI) score
will be used to grade how well blood flow is reestablished throughout and
following the MTB procedure. An estimation of the likelihood of successful
recanalization can support treatment decision-making. In this study, we
proposed a fully automated prediction of a patient's recanalization score using
pre-treatment CT and CTA imaging. We designed a spatial cross attention network
(SCANet) that utilizes vision transformers to localize to pertinent slices and
brain regions. Our top model achieved an average cross-validated ROC-AUC of
77.33 $\pm$ 3.9\%. This is a promising result that supports future applications
of deep learning on CT and CTA for the identification of eligible AIS patients
for MTB.</p>
  </details>
</details>
<details>
  <summary>41. <b>标题：A FPGA-based architecture for real-time cluster finding in the LHCb  silicon pixel detector</b></summary>
  <p><b>编号</b>：[238]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03972</p>
  <p><b>作者</b>：G. Bassi,  L. Giambastiani,  K. Hennessy,  F. Lazzari,  M. J. Morello,  T. Pajero,  A. Fernandez Prieto,  G. Punzi</p>
  <p><b>备注</b>：13 pages, 22 figures. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible</p>
  <p><b>关键词</b>：custom VHDL firmware, two-dimensional cluster-finder architecture, reconstructing VELO hits, VHDL firmware implementation, reconstructing hit positions</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This article describes a custom VHDL firmware implementation of a
two-dimensional cluster-finder architecture for reconstructing hit positions in
the new vertex pixel detector (VELO) that is part of the LHCb Upgrade. This
firmware has been deployed to the existing FPGA cards that perform the readout
of the VELO, as a further enhancement of the DAQ system, and will run in real
time during physics data taking, reconstructing VELO hits coordinates
on-the-fly at the LHC collision rate. This pre-processing allows the first
level of the software trigger to accept a 11% higher rate of events, as the
ready-made hits coordinates accelerate the track reconstruction and consumes
significantly less electrical power. It additionally allows the raw pixel data
to be dropped at the readout level, thus saving approximately 14% of the DAQ
bandwidth. Detailed simulation studies have shown that the use of this
real-time cluster finding does not introduce any appreciable degradation in the
tracking performance in comparison to a full-fledged software implementation.
This work is part of a wider effort aimed at boosting the real-time processing
capability of HEP experiments by delegating intensive tasks to dedicated
computing accelerators deployed at the earliest stages of the data acquisition
chain.</p>
  </details>
</details>
<details>
  <summary>42. <b>标题：A Weighted Normalized Boundary Loss for Reducing the Hausdorff Distance  in Medical Imaging Segmentation</b></summary>
  <p><b>编号</b>：[243]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03868</p>
  <p><b>作者</b>：Adrian Celaya,  Alejandro Diaz,  Alex Balsells,  Beatrice Riviere,  David Fuentes</p>
  <p><b>备注</b>：Submitted to 26th International Conference on Medical Image Computing and Computer Assisted Intervention</p>
  <p><b>关键词</b>：deep learning models, Dice coefficient, Hausdorff-based metrics, learning models, measures of success</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Within medical imaging segmentation, the Dice coefficient and Hausdorff-based
metrics are standard measures of success for deep learning models. However,
modern loss functions for medical image segmentation often only consider the
Dice coefficient or similar region-based metrics during training. As a result,
segmentation architectures trained over such loss functions run the risk of
achieving high accuracy for the Dice coefficient but low accuracy for
Hausdorff-based metrics. Low accuracy on Hausdorff-based metrics can be
problematic for applications such as tumor segmentation, where such benchmarks
are crucial. For example, high Dice scores accompanied by significant Hausdorff
errors could indicate that the predictions fail to detect small tumors. We
propose the Weighted Normalized Boundary Loss, a novel loss function to
minimize Hausdorff-based metrics with more desirable numerical properties than
current methods and with weighting terms for class imbalance. Our loss function
outperforms other losses when tested on the BraTS dataset using a standard 3D
U-Net and the state-of-the-art nnUNet architectures. These results suggest we
can improve segmentation accuracy with our novel loss function.</p>
  </details>
</details>
<details>
  <summary>43. <b>标题：SwinCross: Cross-modal Swin Transformer for Head-and-Neck Tumor  Segmentation in PET/CT Images</b></summary>
  <p><b>编号</b>：[244]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03861</p>
  <p><b>作者</b>：Gary Y. Li,  Junyu Chen,  Se-In Jang,  Kuang Gong,  Quanzheng Li</p>
  <p><b>备注</b>：9 pages, 3 figures</p>
  <p><b>关键词</b>：head and neck, combined with cetuximab, treatment for patients, patients with inoperable, neck cancers</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Radiotherapy (RT) combined with cetuximab is the standard treatment for
patients with inoperable head and neck cancers. Segmentation of head and neck
(H&N) tumors is a prerequisite for radiotherapy planning but a time-consuming
process. In recent years, deep convolutional neural networks have become the de
facto standard for automated image segmentation. However, due to the expensive
computational cost associated with enlarging the field of view in DCNNs, their
ability to model long-range dependency is still limited, and this can result in
sub-optimal segmentation performance for objects with background context
spanning over long distances. On the other hand, Transformer models have
demonstrated excellent capabilities in capturing such long-range information in
several semantic segmentation tasks performed on medical images. Inspired by
the recent success of Vision Transformers and advances in multi-modal image
analysis, we propose a novel segmentation model, debuted, Cross-Modal Swin
Transformer (SwinCross), with cross-modal attention (CMA) module to incorporate
cross-modal feature extraction at multiple this http URL validate the
effectiveness of the proposed method, we performed experiments on the HECKTOR
2021 challenge dataset and compared it with the nnU-Net (the backbone of the
top-5 methods in HECKTOR 2021) and other state-of-the-art transformer-based
methods such as UNETR, and Swin UNETR. The proposed method is experimentally
shown to outperform these comparing methods thanks to the ability of the CMA
module to capture better inter-modality complimentary feature representations
between PET and CT, for the task of head-and-neck tumor segmentation.</p>
  </details>
</details>
<details>
  <summary>44. <b>标题：Futuristic Variations and Analysis in Fundus Images Corresponding to  Biological Traits</b></summary>
  <p><b>编号</b>：[247]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03839</p>
  <p><b>作者</b>：Muhammad Hassan,  Hao Zhang,  Ahmed Fateh Ameen,  Home Wu Zeng,  Shuye Ma,  Wen Liang,  Dingqi Shang,  Jiaming Ding,  Ziheng Zhan,  Tsz Kwan Lam,  Ming Xu,  Qiming Huang,  Dongmei Wu,  Can Yang Zhang,  Zhou You,  Awiwu Ain,  Pei Wu Qin</p>
  <p><b>备注</b>：10 pages, 4 figures, 3 tables</p>
  <p><b>关键词</b>：biological traits, image captures rear, deep learning methods, estimate biological traits, traits</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Fundus image captures rear of an eye, and which has been studied for the
diseases identification, classification, segmentation, generation, and
biological traits association using handcrafted, conventional, and deep
learning methods. In biological traits estimation, most of the studies have
been carried out for the age prediction and gender classification with
convincing results. However, the current study utilizes the cutting-edge deep
learning (DL) algorithms to estimate biological traits in terms of age and
gender together with associating traits to retinal visuals. For the traits
association, our study embeds aging as the label information into the proposed
DL model to learn knowledge about the effected regions with aging. Our proposed
DL models, named FAG-Net and FGC-Net, correspondingly estimate biological
traits (age and gender) and generates fundus images. FAG-Net can generate
multiple variants of an input fundus image given a list of ages as conditions.
Our study analyzes fundus images and their corresponding association with
biological traits, and predicts of possible spreading of ocular disease on
fundus images given age as condition to the generative model. Our proposed
models outperform the randomly selected state of-the-art DL models.</p>
  </details>
</details>
<details>
  <summary>45. <b>标题：How to Trust Your Diffusion Model: A Convex Optimization Approach to  Conformal Risk Control</b></summary>
  <p><b>编号</b>：[249]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03791</p>
  <p><b>作者</b>：Jacopo Teneggi,  Matt Tivnan,  J Webster Stayman,  Jeremias Sulam</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Score-based generative modeling, Score-based generative, generative modeling, informally referred, continue to grow</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Score-based generative modeling, informally referred to as diffusion models,
continue to grow in popularity across several important domains and tasks.
While they provide high-quality and diverse samples from empirical
distributions, important questions remain on the reliability and
trustworthiness of these sampling procedures for their responsible use in
critical scenarios. Conformal prediction is a modern tool to construct
finite-sample, distribution-free uncertainty guarantees for any black-box
predictor. In this work, we focus on image-to-image regression tasks and we
present a generalization of the Risk-Controlling Prediction Sets (RCPS)
procedure, that we term $K$-RCPS, which allows to $(i)$ provide entrywise
calibrated intervals for future samples of any diffusion model, and $(ii)$
control a certain notion of risk with respect to a ground truth image with
minimal mean interval length. Differently from existing conformal risk control
procedures, ours relies on a novel convex optimization approach that allows for
multidimensional risk control while provably minimizing the mean interval
length. We illustrate our approach on two real-world image denoising problems:
on natural images of faces as well as on computed tomography (CT) scans of the
abdomen, demonstrating state of the art performance.</p>
  </details>
</details>
<h1>自然语言处理</h1>
<details>
  <summary>1. <b>标题：Diagnosing and Rectifying Vision Models using Language</b></summary>
  <p><b>编号</b>：[1]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04269</p>
  <p><b>作者</b>：Yuhui Zhang,  Jeff Z. HaoChen,  Shih-Cheng Huang,  Kuan-Chieh Wang,  James Zou,  Serena Yeung</p>
  <p><b>备注</b>：Published at ICLR 2023</p>
  <p><b>关键词</b>：Recent multi-modal contrastive, building strong vision, multi-modal contrastive learning, contrastive learning models, embedding space suitable</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent multi-modal contrastive learning models have demonstrated the ability
to learn an embedding space suitable for building strong vision classifiers, by
leveraging the rich information in large-scale image-caption datasets. Our work
highlights a distinct advantage of this multi-modal embedding space: the
ability to diagnose vision classifiers through natural language. The
traditional process of diagnosing model behaviors in deployment settings
involves labor-intensive data acquisition and annotation. Our proposed method
can discover high-error data slices, identify influential attributes and
further rectify undesirable model behaviors, without requiring any visual data.
Through a combination of theoretical explanation and empirical verification, we
present conditions under which classifiers trained on embeddings from one
modality can be equivalently applied to embeddings from another modality. On a
range of image datasets with known error slices, we demonstrate that our method
can effectively identify the error slices and influential attributes, and can
further use language to rectify failure modes of the classifier.</p>
  </details>
</details>
<details>
  <summary>2. <b>标题：Hierarchical Event Grounding</b></summary>
  <p><b>编号</b>：[21]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04197</p>
  <p><b>作者</b>：Jiefu Ou,  Adithya Pratapa,  Rishubh Gupta,  Teruko Mitamura</p>
  <p><b>备注</b>：Accepted to AAAI 2023</p>
  <p><b>关键词</b>：knowledge base, text corpora, Event grounding aims, hierarchical, Event</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Event grounding aims at linking mention references in text corpora to events
from a knowledge base (KB). Previous work on this task focused primarily on
linking to a single KB event, thereby overlooking the hierarchical aspects of
events. Events in documents are typically described at various levels of
spatio-temporal granularity (Glavas et al. 2014). These hierarchical relations
are utilized in downstream tasks of narrative understanding and schema
construction. In this work, we present an extension to the event grounding task
that requires tackling hierarchical event structures from the KB. Our proposed
task involves linking a mention reference to a set of event labels from a
subevent hierarchy in the KB. We propose a retrieval methodology that leverages
event hierarchy through an auxiliary hierarchical loss (Murty et al. 2018). On
an automatically created multilingual dataset from Wikipedia and Wikidata, our
experiments demonstrate the effectiveness of the hierarchical loss against
retrieve and re-rank baselines (Wu et al. 2020; Pratapa, Gupta, and Mitamura
2022). Furthermore, we demonstrate the systems' ability to aid hierarchical
discovery among unseen events.</p>
  </details>
</details>
<details>
  <summary>3. <b>标题：Efficient Joint Learning for Clinical Named Entity Recognition and  Relation Extraction Using Fourier Networks: A Use Case in Adverse Drug Events</b></summary>
  <p><b>编号</b>：[23]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04185</p>
  <p><b>作者</b>：Anthony Yazdani,  Dimitrios Proios,  Hossein Rouhizadeh,  Douglas Teodoro</p>
  <p><b>备注</b>：International Conference on Natural Language Processing (ICON 2022)</p>
  <p><b>关键词</b>：electronic health records, large-scale electronic health, hindering their application, health records, clinical information extraction</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Current approaches for clinical information extraction are inefficient in
terms of computational costs and memory consumption, hindering their
application to process large-scale electronic health records (EHRs). We propose
an efficient end-to-end model, the Joint-NER-RE-Fourier (JNRF), to jointly
learn the tasks of named entity recognition and relation extraction for
documents of variable length. The architecture uses positional encoding and
unitary batch sizes to process variable length documents and uses a
weight-shared Fourier network layer for low-complexity token mixing. Finally,
we reach the theoretical computational complexity lower bound for relation
extraction using a selective pooling strategy and distance-aware attention
weights with trainable polynomial distance functions. We evaluated the JNRF
architecture using the 2018 N2C2 ADE benchmark to jointly extract
medication-related entities and relations in variable-length EHR summaries.
JNRF outperforms rolling window BERT with selective pooling by 0.42%, while
being twice as fast to train. Compared to state-of-the-art BiLSTM-CRF
architectures on the N2C2 ADE benchmark, results show that the proposed
approach trains 22 times faster and reduces GPU memory consumption by 1.75
folds, with a reasonable performance tradeoff of 90%, without the use of
external tools, hand-crafted rules or post-processing. Given the significant
carbon footprint of deep learning models and the current energy crises, these
methods could support efficient and cleaner information extraction in EHRs and
other types of large-scale document databases.</p>
  </details>
</details>
<details>
  <summary>4. <b>标题：GPTScore: Evaluate as You Desire</b></summary>
  <p><b>编号</b>：[34]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04166</p>
  <p><b>作者</b>：Jinlan Fu,  See-Kiong Ng,  Zhengbao Jiang,  Pengfei Liu</p>
  <p><b>备注</b>：22 pages</p>
  <p><b>关键词</b>：Generative Artificial Intelligence, Artificial Intelligence, producing high-caliber text, Generative Artificial, enabled the development</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Generative Artificial Intelligence (AI) has enabled the development of
sophisticated models that are capable of producing high-caliber text, images,
and other outputs through the utilization of large pre-trained models.
Nevertheless, assessing the quality of the generation is an even more arduous
task than the generation itself, and this issue has not been given adequate
consideration recently. This paper proposes a novel evaluation framework,
GPTScore, which utilizes the emergent abilities (e.g., zero-shot instruction)
from generative pre-trained models to score generated texts. Experimental
results on four text generation tasks, 22 evaluation aspects, and corresponding
37 datasets demonstrate that this approach can effectively allow us to achieve
what one desires to evaluate for texts simply by natural language instructions.
This nature helps us overcome several long-standing challenges in text
evaluation--how to achieve customized, multi-faceted evaluation without the
need for annotated samples. We make our code publicly available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>5. <b>标题：Prompting for Multimodal Hateful Meme Classification</b></summary>
  <p><b>编号</b>：[36]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04156</p>
  <p><b>作者</b>：Rui Cao,  Roy Ka-Wei Lee,  Wen-Haw Chong,  Jing Jiang</p>
  <p><b>备注</b>：Accepted in EMNLP, 2022</p>
  <p><b>关键词</b>：requires complex reasoning, Hateful meme classification, Hateful meme, meme classification, challenging multimodal task</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Hateful meme classification is a challenging multimodal task that requires
complex reasoning and contextual background knowledge. Ideally, we could
leverage an explicit external knowledge base to supplement contextual and
cultural information in hateful memes. However, there is no known explicit
external knowledge base that could provide such hate speech contextual
information. To address this gap, we propose PromptHate, a simple yet effective
prompt-based model that prompts pre-trained language models (PLMs) for hateful
meme classification. Specifically, we construct simple prompts and provide a
few in-context examples to exploit the implicit knowledge in the pre-trained
RoBERTa language model for hateful meme classification. We conduct extensive
experiments on two publicly available hateful and offensive meme datasets. Our
experimental results show that PromptHate is able to achieve a high AUC of
90.96, outperforming state-of-the-art baselines on the hateful meme
classification task. We also perform fine-grained analyses and case studies on
various prompt settings and demonstrate the effectiveness of the prompts on
hateful meme classification.</p>
  </details>
</details>
<details>
  <summary>6. <b>标题：Training-free Lexical Backdoor Attacks on Language Models</b></summary>
  <p><b>编号</b>：[48]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04116</p>
  <p><b>作者</b>：Yujin Huang,  Terry Yue Zhuo,  Qiongkai Xu,  Han Hu,  Xingliang Yuan,  Chunyang Chen</p>
  <p><b>备注</b>：Accepted to International World Wide Web Conference 2023, Security, Privacy & Trust Track</p>
  <p><b>关键词</b>：natural language processing, language models, Large-scale language models, achieved tremendous success, language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large-scale language models have achieved tremendous success across various
natural language processing (NLP) applications. Nevertheless, language models
are vulnerable to backdoor attacks, which inject stealthy triggers into models
for steering them to undesirable behaviors. Most existing backdoor attacks,
such as data poisoning, require further (re)training or fine-tuning language
models to learn the intended backdoor patterns. The additional training process
however diminishes the stealthiness of the attacks, as training a language
model usually requires long optimization time, a massive amount of data, and
considerable modifications to the model parameters. In this work, we propose
Training-Free Lexical Backdoor Attack (TFLexAttack) as the first training-free
backdoor attack on language models. Our attack is achieved by injecting lexical
triggers into the tokenizer of a language model via manipulating its embedding
dictionary using carefully designed rules. These rules are explainable to human
developers which inspires attacks from a wider range of hackers. The sparse
manipulation of the dictionary also habilitates the stealthiness of our attack.
We conduct extensive experiments on three dominant NLP tasks based on nine
language models to demonstrate the effectiveness and universality of our
attack. The code of this work is available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>7. <b>标题：Real-Word Error Correction with Trigrams: Correcting Multiple Errors in  a Sentence</b></summary>
  <p><b>编号</b>：[60]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04096</p>
  <p><b>作者</b>：Seyed MohammadSadegh Dashti</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Text Mining, task in Text, fundamental task, Spelling correction, Budanitsky fixed windows</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Spelling correction is a fundamental task in Text Mining. In this study, we
assess the real-word error correction model proposed by Mays, Damerau and
Mercer and describe several drawbacks of the model. We propose a new variation
which focuses on detecting and correcting multiple real-word errors in a
sentence, by manipulating a Probabilistic Context-Free Grammar (PCFG) to
discriminate between items in the search space. We test our approach on the
Wall Street Journal corpus and show that it outperforms Hirst and Budanitsky's
WordNet-based method and Wilcox-O'Hearn, Hirst, and Budanitsky's fixed windows
size method.-O'Hearn, Hirst, and Budanitsky's fixed windows size method.</p>
  </details>
</details>
<details>
  <summary>8. <b>标题：ZipLM: Hardware-Aware Structured Pruning of Language Models</b></summary>
  <p><b>编号</b>：[63]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04089</p>
  <p><b>作者</b>：Eldar Kurtic,  Elias Frantar,  Dan Alistarh</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：large computational footprints, high deployment costs, large language models, large language, large computational</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The breakthrough performance of large language models (LLMs) comes with large
computational footprints and high deployment costs. In this paper, we progress
towards resolving this problem by proposing a new structured compression
approach for LLMs, called ZipLM, which provides state-of-the-art
compression-vs-accuracy results, while guaranteeing to match a set of
(achievable) target speedups on any given target hardware. Specifically, given
a task, a model, an inference environment, as well as a set of speedup targets,
ZipLM identifies and removes redundancies in the model through iterative
structured shrinking of the model's weight matrices. Importantly, ZipLM works
in both, the post-training/one-shot and the gradual compression setting, where
it produces a set of accurate models in a single run, making it
highly-efficient in practice. Our approach is based on new structured pruning
and knowledge distillation techniques, and consistently outperforms prior
structured compression methods in terms of accuracy-versus-speedup in
experiments on BERT- and GPT-family models. In particular, when compressing
GPT2 model, it outperforms DistilGPT2 while being 60% smaller and 30% faster.
Further, ZipLM matches performance of heavily optimized MobileBERT model,
obtained via extensive architecture search, by simply pruning the baseline
BERT-large architecture, and outperforms all prior BERT-base compression
techniques like CoFi, MiniLM and TinyBERT.</p>
  </details>
</details>
<details>
  <summary>9. <b>标题：Reception Reader: Exploring Text Reuse in Early Modern British  Publications</b></summary>
  <p><b>编号</b>：[67]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04084</p>
  <p><b>作者</b>：David Rosson,  Eetu Mäkelä,  Ville Vaara,  Ananth Mahadevan,  Yann Ryan,  Mikko Tolonen</p>
  <p><b>备注</b>：16 pages, 6 figures, 1 table</p>
  <p><b>关键词</b>：Century Collections Online, studying text reuse, Eighteenth Century Collections, English Books Online, Reception Reader</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The Reception Reader is a web tool for studying text reuse in the Early
English Books Online (EEBO-TCP) and Eighteenth Century Collections Online
(ECCO) data. Users can: 1) explore a visual overview of the reception of a
work, or its incoming connections, across time based on shared text segments,
2) interactively survey the details of connected documents, and 3) examine the
context of reused text for "close reading". We show examples of how the tool
streamlines research and exploration tasks, and discuss the utility and
limitations of the user interface along with its current data sources.</p>
  </details>
</details>
<details>
  <summary>10. <b>标题：Towards Inferential Reproducibility of Machine Learning Research</b></summary>
  <p><b>编号</b>：[77]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04054</p>
  <p><b>作者</b>：Michael Hagmann,  Stefan Riezler</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：model training runs, replicated model training, machine learning evaluation, observed evaluation scores, training runs</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Reliability of machine learning evaluation -- the consistency of observed
evaluation scores across replicated model training runs -- is affected by
several sources of nondeterminism which can be regarded as measurement noise.
Current tendencies to remove noise in order to enforce reproducibility of
research results neglect inherent nondeterminism at the implementation level
and disregard crucial interaction effects between algorithmic noise factors and
data properties. This limits the scope of conclusions that can be drawn from
such experiments. Instead of removing noise, we propose to incorporate several
sources of variance, including their interaction with data properties, into an
analysis of significance and reliability of machine learning evaluation, with
the aim to draw inferences beyond particular instances of trained models. We
show how to use linear mixed effects models (LMEMs) to analyze performance
evaluation scores, and to conduct statistical inference with a generalized
likelihood ratio test (GLRT). This allows us to incorporate arbitrary sources
of noise like meta-parameter variations into statistical significance testing,
and to assess performance differences conditional on data properties.
Furthermore, a variance component analysis (VCA) enables the analysis of the
contribution of noise sources to overall variance and the computation of a
reliability coefficient by the ratio of substantial to total variance.</p>
  </details>
</details>
<details>
  <summary>11. <b>标题：Revisiting Offline Compression: Going Beyond Factorization-based Methods  for Transformer Language Models</b></summary>
  <p><b>编号</b>：[81]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04045</p>
  <p><b>作者</b>：Mohammadreza Banaei,  Klaudia Bałazy,  Artur Kasymov,  Rémi Lebret,  Jacek Tabor,  Karl Aberer</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Recent transformer language, natural language processing, achieve outstanding results, transformer language models, language models achieve</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent transformer language models achieve outstanding results in many
natural language processing (NLP) tasks. However, their enormous size often
makes them impractical on memory-constrained devices, requiring practitioners
to compress them to smaller networks. In this paper, we explore offline
compression methods, meaning computationally-cheap approaches that do not
require further fine-tuning of the compressed model. We challenge the classical
matrix factorization methods by proposing a novel, better-performing
autoencoder-based framework. We perform a comprehensive ablation study of our
approach, examining its different aspects over a diverse set of evaluation
settings. Moreover, we show that enabling collaboration between modules across
layers by compressing certain modules together positively impacts the final
model performance. Experiments on various NLP tasks demonstrate that our
approach significantly outperforms commonly used factorization-based offline
compression methods.</p>
  </details>
</details>
<details>
  <summary>12. <b>标题：A Multitask, Multilingual, Multimodal Evaluation of ChatGPT on  Reasoning, Hallucination, and Interactivity</b></summary>
  <p><b>编号</b>：[92]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04023</p>
  <p><b>作者</b>：Yejin Bang,  Samuel Cahyawijaya,  Nayeon Lee,  Wenliang Dai,  Dan Su,  Bryan Wilie,  Holy Lovenia,  Ziwei Ji,  Tiezheng Yu,  Willy Chung,  Quyet V. Do,  Yan Xu,  Pascale Fung</p>
  <p><b>备注</b>：52 pages</p>
  <p><b>关键词</b>：quantitatively evaluating interactive, paper proposes, proposes a framework, framework for quantitatively, quantitatively evaluating</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper proposes a framework for quantitatively evaluating interactive
LLMs such as ChatGPT using publicly available data sets. We carry out an
extensive technical evaluation of ChatGPT using 21 data sets covering 8
different common NLP application tasks. We evaluate the multitask, multilingual
and multi-modal aspects of ChatGPT based on these data sets and a newly
designed multimodal dataset. We find that ChatGPT outperforms LLMs with
zero-shot learning on most tasks and even outperforms fine-tuned models on some
tasks. We find that it is better at understanding non-Latin script languages
than generating them. It is able to generate multimodal content from textual
prompts, via an intermediate code generation step. Moreover, we find that
ChatGPT is 64.33% accurate on average in 10 different reasoning categories
under logical reasoning, non-textual reasoning, and commonsense reasoning,
hence making it an unreliable reasoner. It is, for example, better at deductive
than inductive reasoning. ChatGPT suffers from hallucination problems like
other LLMs and it generates more extrinsic hallucinations from its parametric
memory as it does not have access to an external knowledge base. Finally, the
interactive feature of ChatGPT enables human collaboration with the underlying
LLM to improve its performance, i.e, 8% ROUGE-1 on summarization and 2% ChrF++
on machine translation, in a multi-turn "prompt engineering" fashion.</p>
  </details>
</details>
<details>
  <summary>13. <b>标题：Systematically Finding Security Vulnerabilities in Black-Box Code  Generation Models</b></summary>
  <p><b>编号</b>：[96]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04012</p>
  <p><b>作者</b>：Hossein Hajipour,  Thorsten Holz,  Lea Schönherr,  Mario Fritz</p>
  <p><b>备注</b>：14 pages, 12 figures</p>
  <p><b>关键词</b>：models, code generation, achieved breakthroughs, programming language tasks, generation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recently, large language models for code generation have achieved
breakthroughs in several programming language tasks. Their advances in
competition-level programming problems have made them an emerging pillar in
AI-assisted pair programming. Tools such as GitHub Copilot are already part of
the daily programming workflow and are used by more than a million developers.
The training data for these models is usually collected from open-source
repositories (e.g., GitHub) that contain software faults and security
vulnerabilities. This unsanitized training data can lead language models to
learn these vulnerabilities and propagate them in the code generation
procedure. Given the wide use of these models in the daily workflow of
developers, it is crucial to study the security aspects of these models
systematically.
In this work, we propose the first approach to automatically finding security
vulnerabilities in black-box code generation models. To achieve this, we
propose a novel black-box inversion approach based on few-shot prompting. We
evaluate the effectiveness of our approach by examining code generation models
in the generation of high-risk security weaknesses. We show that our approach
automatically and systematically finds 1000s of security vulnerabilities in
various code generation models, including the commercial black-box model GitHub
Copilot.</p>
  </details>
</details>
<details>
  <summary>14. <b>标题：Leveraging Summary Guidance on Medical Report Summarization</b></summary>
  <p><b>编号</b>：[99]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04001</p>
  <p><b>作者</b>：Yunqi Zhu,  Xuebing Yang,  Yuanyuan Wu,  Wensheng Zhang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：deidentified large medical, large medical text, medical text datasets, study presents, presents three deidentified</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This study presents three deidentified large medical text datasets, named
DISCHARGE, ECHO and RADIOLOGY, which contain 50K, 16K and 378K pairs of report
and summary that are derived from MIMIC-III, respectively. We implement
convincing baselines of automated abstractive summarization on the proposed
datasets with pre-trained encoder-decoder language models, including BERT2BERT,
T5-large and BART. Further, based on the BART model, we leverage the sampled
summaries from the train set as prior knowledge guidance, for encoding
additional contextual representations of the guidance with the encoder and
enhancing the decoding representations in the decoder. The experimental results
confirm the improvement of ROUGE scores and BERTScore made by the proposed
method, outperforming the larger model T5-large.</p>
  </details>
</details>
<details>
  <summary>15. <b>标题：Improving (Dis)agreement Detection with Inductive Social Relation  Information From Comment-Reply Interactions</b></summary>
  <p><b>编号</b>：[120]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03950</p>
  <p><b>作者</b>：Yun Luo,  Zihan Liu,  Stan Z. Li,  Yue Zhang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Social relation, Social relation information, social relation graph, Dis, agreement detection aims</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>(Dis)agreement detection aims to identify the authors' attitudes or positions
(\textit{agree, disagree, neutral}) towards a specific text. It is limited
for existing methods merely using textual information for identifying
(dis)agreements, especially for cross-domain settings. Social relation
information can play an assistant role in the (dis)agreement task besides
textual information. We propose a novel method to extract such relation
information from (dis)agreement data into an inductive social relation graph,
merely using the comment-reply pairs without any additional platform-specific
information. The inductive social relation globally considers the historical
discussion and the relation between authors. Textual information based on a
pre-trained language model and social relation information encoded by
pre-trained RGCN are jointly considered for (dis)agreement detection.
Experimental results show that our model achieves state-of-the-art performance
for both the in-domain and cross-domain tasks on the benchmark -- DEBAGREEMENT.
We find social relations can boost the performance of the (dis)agreement
detection model, especially for the long-token comment-reply pairs,
demonstrating the effectiveness of the social relation graph. We also explore
the effect of the knowledge graph embedding methods, the information fusing
method, and the time interval in constructing the social relation graph, which
shows the effectiveness of our model.</p>
  </details>
</details>
<details>
  <summary>16. <b>标题：COMBO: A Complete Benchmark for Open KG Canonicalization</b></summary>
  <p><b>编号</b>：[141]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03905</p>
  <p><b>作者</b>：Chengyue Jiang,  Yong Jiang,  Weiqi Wu,  Yuting Zheng,  Pengjun Xie,  Kewei Tu</p>
  <p><b>备注</b>：18 pages</p>
  <p><b>关键词</b>：Open knowledge graph, knowledge graph, raw text, canonicalization, millions of raw</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Open knowledge graph (KG) consists of (subject, relation, object) triples
extracted from millions of raw text. The subject and object noun phrases and
the relation in open KG have severe redundancy and ambiguity and need to be
canonicalized. Existing datasets for open KG canonicalization only provide gold
entity-level canonicalization for noun phrases. In this paper, we present
COMBO, a Complete Benchmark for Open KG canonicalization. Compared with
existing datasets, we additionally provide gold canonicalization for relation
phrases, gold ontology-level canonicalization for noun phrases, as well as
source sentences from which triples are extracted. We also propose metrics for
evaluating each type of canonicalization. On the COMBO dataset, we empirically
compare previously proposed canonicalization methods as well as a few simple
baseline methods based on pretrained language models. We find that properly
encoding the phrases in a triple using pretrained language models results in
better relation canonicalization and ontology-level canonicalization of the
noun phrase. We release our dataset, baselines, and evaluation scripts at
this https URL.</p>
  </details>
</details>
<details>
  <summary>17. <b>标题：Auto-Learning: An Adversarial Process of Two Pre-trained Models for  Natural Language Generation</b></summary>
  <p><b>编号</b>：[145]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03896</p>
  <p><b>作者</b>：Zhengqing Yuan,  Yuelin Lu,  Chao Zhang,  Huiwen Xue</p>
  <p><b>备注</b>：10 pages, 4 figures</p>
  <p><b>关键词</b>：natural language generation, natural language understanding, natural language, language generation, language generation models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Pre-trained models have been used in many fields in recent years, ranging
from natural language understanding to computer vision and natural language
generation. However, the performance of these natural language generation
models is overly dependent on the scale of the model and the size of the
dataset. While the larger language model is excellent in some respects, it
cannot learn up-to-date knowledge and is relatively difficult to relearn. In
this paper, a new adversarial process learning method called Auto-Learning.
This can improve the performance of any natural language generation model
without the help of additional datasets. Auto-Learning includes two models: $G$
is a text generation model and $D$ can test whether the data generated by G is
legitimate. Firstly, the fine-tuned $D$ model is used as the brain's knowledge
base before the process. Then the text generated by the $G$ model is used as
the input of $D$ to determine whether the text is legitimate or not. Finally,
$G$ is fine-tuned according to the output of $D$. This adversarial process is
like a self-escalation of the brain through some a priori knowledge. When this
adversarial system wants to learn something new, simply fine-tune the $D$
model. Our approach applies to Autoregressive Language Modeling for all
Transformer classes. The results are good in existing experimental tasks,
including more grammatical text generation and better performance on some text
comprehension tasks.</p>
  </details>
</details>
<details>
  <summary>18. <b>标题：Controlling Personality Style in Dialogue with Zero-Shot Prompt-Based  Learning</b></summary>
  <p><b>编号</b>：[161]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03848</p>
  <p><b>作者</b>：Angela Ramirez,  Mamon Alsalihy,  Kartik Aggarwal,  Cecilia Li,  Liren Wu,  Marilyn Walker</p>
  <p><b>备注</b>：To appear at International Workshop on Spoken Dialogue Systems Technology, 2023</p>
  <p><b>关键词</b>：natural language generation, achieved high zero-shot, high zero-shot performance, prompt-based learning, language generation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Prompt-based or in-context learning has achieved high zero-shot performance
on many natural language generation (NLG) tasks. Here we explore the
performance of prompt-based learning for simultaneously controlling the
personality and the semantic accuracy of an NLG for task-oriented dialogue. We
experiment with prompt-based learning on the PERSONAGE restaurant
recommendation corpus to generate semantically and stylistically-controlled
text for 5 different Big-5 personality types: agreeable, disagreeable,
conscientious, unconscientious, and extravert. We test two different classes of
discrete prompts to generate utterances for a particular personality style: (1)
prompts that demonstrate generating directly from a meaning representation that
includes a personality specification; and (2) prompts that rely on first
converting the meaning representation to a textual pseudo-reference, and then
using the pseudo-reference in a textual style transfer (TST) prompt. In each
case, we show that we can vastly improve performance by over-generating outputs
and ranking them, testing several ranking functions based on automatic metrics
for semantic accuracy, personality-match, and fluency. We also test whether NLG
personality demonstrations from the restaurant domain can be used with meaning
representations for the video game domain to generate personality stylized
utterances about video games. Our findings show that the TST prompts produces
the highest semantic accuracy (78.46% for restaurants and 87.6% for video
games) and personality accuracy (100% for restaurants and 97% for video games).
Our results on transferring personality style to video game utterances are
surprisingly good. To our knowledge, there is no previous work testing the
application of prompt-based learning to simultaneously controlling both style
and semantic accuracy in NLG.</p>
  </details>
</details>
<details>
  <summary>19. <b>标题：Clinical BioBERT Hyperparameter Optimization using Genetic Algorithm  Clinical BioBERT Hyperparameter Optimization using Genetic Algorithm</b></summary>
  <p><b>编号</b>：[168]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03822</p>
  <p><b>作者</b>：Navya Martin Kollapally,  James Geller</p>
  <p><b>备注</b>：Under review as regular paper</p>
  <p><b>关键词</b>：individual health outcomes, small portion, Clinical factors account, affect an individual, health outcomes</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Clinical factors account only for a small portion, about 10-30%, of the
controllable factors that affect an individual's health outcomes. The remaining
factors include where a person was born and raised, where he/she pursued their
education, what their work and family environment is like, etc. These factors
are collectively referred to as Social Determinants of Health (SDoH). The
majority of SDoH data is recorded in unstructured clinical notes by physicians
and practitioners. Recording SDoH data in a structured manner (in an EHR) could
greatly benefit from a dedicated ontology of SDoH terms. Our research focuses
on extracting sentences from clinical notes, making use of such an SDoH
ontology (called SOHO) to provide appropriate concepts. We utilize recent
advancements in Deep Learning to optimize the hyperparameters of a Clinical
BioBERT model for SDoH text. A genetic algorithm-based hyperparameter tuning
regimen was implemented to identify optimal parameter settings. To implement a
complete classifier, we pipelined Clinical BioBERT with two subsequent linear
layers and two dropout layers. The output predicts whether a text fragment
describes an SDoH issue of the patient. We compared the AdamW, Adafactor, and
LAMB optimizers. In our experiments, AdamW outperformed the others in terms of
accuracy.</p>
  </details>
</details>
<details>
  <summary>20. <b>标题：Long Text and Multi-Table Summarization: Dataset and Method</b></summary>
  <p><b>编号</b>：[173]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03815</p>
  <p><b>作者</b>：Shuaiqi Liu,  Jiannong Cao,  Ruosong Yang,  Zhiyuan Wen</p>
  <p><b>备注</b>：EMNLP 2022 Findings</p>
  <p><b>关键词</b>：concise summary covering, document salient information, Automatic document summarization, document summarization aims, aims to produce</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Automatic document summarization aims to produce a concise summary covering
the input document's salient information. Within a report document, the salient
information can be scattered in the textual and non-textual content. However,
existing document summarization datasets and methods usually focus on the text
and filter out the non-textual content. Missing tabular data can limit produced
summaries' informativeness, especially when summaries require covering
quantitative descriptions of critical metrics in tables. Existing datasets and
methods cannot meet the requirements of summarizing long text and multiple
tables in each report. To deal with the scarcity of available data, we propose
FINDSum, the first large-scale dataset for long text and multi-table
summarization. Built on 21,125 annual reports from 3,794 companies, it has two
subsets for summarizing each company's results of operations and liquidity. To
summarize the long text and dozens of tables in each report, we present three
types of summarization methods. Besides, we propose a set of evaluation metrics
to assess the usage of numerical information in produced summaries. Dataset
analyses and experimental results indicate the importance of jointly
considering input textual and tabular data when summarizing report documents.</p>
  </details>
</details>
<details>
  <summary>21. <b>标题：Reliable Natural Language Understanding with Large Language Models and  Answer Set Programming</b></summary>
  <p><b>编号</b>：[193]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03780</p>
  <p><b>作者</b>：Abhiramon Rajasekharan,  Yankai Zeng,  Parth Padalkar,  Gopal Gupta</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：existing commonsense knowledge, extracting information, draw conclusions, existing commonsense, Humans understand language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Humans understand language by extracting information (meaning) from
sentences, combining it with existing commonsense knowledge, and then
performing reasoning to draw conclusions. While large language models (LLMs)
such as GPT-3 and ChatGPT are able to leverage patterns in the text to solve a
variety of NLP tasks, they fall short in problems that require reasoning. They
also cannot reliably explain the answers generated for a given question. In
order to emulate humans better, we propose STAR, a framework that combines LLMs
with Answer Set Programming (ASP). We show how LLMs can be used to effectively
extract knowledge -- represented as predicates -- from language. Goal-directed
ASP is then employed to reliably reason over this knowledge. We apply the STAR
framework to three different NLU tasks requiring reasoning: qualitative
reasoning, mathematical reasoning, and goal-directed conversation. Our
experiments reveal that STAR is able to bridge the gap of reasoning in NLU
tasks, leading to significant performance improvements, especially for smaller
LLMs, i.e., LLMs with a smaller number of parameters. NLU applications
developed using the STAR framework are also explainable: along with the
predicates generated, a justification in the form of a proof tree can be
produced for a given output.</p>
  </details>
</details>
<details>
  <summary>22. <b>标题：What Matters In The Structured Pruning of Generative Language Models?</b></summary>
  <p><b>编号</b>：[198]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03773</p>
  <p><b>作者</b>：Michael Santacroce,  Zixin Wen,  Yelong Shen,  Yuanzhi Li</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：require enormous computational, enormous computational resources, Auto-regressive large language, Auto-regressive large, require enormous</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Auto-regressive large language models such as GPT-3 require enormous
computational resources to use. Traditionally, structured pruning methods are
employed to reduce resource usage. However, their application to and efficacy
for generative language models is heavily under-explored. In this paper we
conduct an comprehensive evaluation of common structured pruning methods,
including magnitude, random, and movement pruning on the feed-forward layers in
GPT-type models. Unexpectedly, random pruning results in performance that is
comparable to the best established methods, across multiple natural language
generation tasks. To understand these results, we provide a framework for
measuring neuron-level redundancy of models pruned by different methods, and
discover that established structured pruning methods do not take into account
the distinctiveness of neurons, leaving behind excess redundancies. In view of
this, we introduce Globally Unique Movement (GUM) to improve the uniqueness of
neurons in pruned models. We then discuss the effects of our techniques on
different redundancy metrics to explain the improved performance.</p>
  </details>
</details>
<details>
  <summary>23. <b>标题：Transformer-based Models for Long-Form Document Matching: Challenges and  Empirical Analysis</b></summary>
  <p><b>编号</b>：[202]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03765</p>
  <p><b>作者</b>：Akshita Jha,  Adithya Samavedhi,  Vineeth Rakesh,  Jaideep Chandrashekar,  Chandan K. Reddy</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：long document encoding, Recent advances, long document, primarily focused, long document matching</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent advances in the area of long document matching have primarily focused
on using transformer-based models for long document encoding and matching.
There are two primary challenges associated with these models. Firstly, the
performance gain provided by transformer-based models comes at a steep cost -
both in terms of the required training time and the resource (memory and
energy) consumption. The second major limitation is their inability to handle
more than a pre-defined input token length at a time. In this work, we
empirically demonstrate the effectiveness of simple neural models (such as
feed-forward networks, and CNNs) and simple embeddings (like GloVe, and
Paragraph Vector) over transformer-based models on the task of document
matching. We show that simple models outperform the more complex BERT-based
models while taking significantly less training time, energy, and memory. The
simple models are also more robust to variations in document length and text
perturbations.</p>
  </details>
</details>
<details>
  <summary>24. <b>标题：Augmenting Zero-Shot Dense Retrievers with Plug-in Mixture-of-Memories</b></summary>
  <p><b>编号</b>：[203]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03754</p>
  <p><b>作者</b>：Suyu Ge,  Chenyan Xiong,  Corby Rosset,  Arnold Overwijk,  Jiawei Han,  Paul Bennett</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：multiple information corpora, retrieves augmentation documents, external memories, information corpora, paper we improve</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper we improve the zero-shot generalization ability of language
models via Mixture-Of-Memory Augmentation (MoMA), a mechanism that retrieves
augmentation documents from multiple information corpora ("external memories"),
with the option to "plug in" new memory at inference time. We develop a joint
learning mechanism that trains the augmentation component with latent labels
derived from the end retrieval task, paired with hard negatives from the memory
mixture. We instantiate the model in a zero-shot dense retrieval setting by
augmenting a strong T5-based retriever with MoMA. Our model, MoMA, obtains
strong zero-shot retrieval accuracy on the eighteen tasks included in the
standard BEIR benchmark. It outperforms systems that seek generalization from
increased model parameters and computation steps. Our analysis further
illustrates the necessity of augmenting with mixture-of-memory for robust
generalization, the benefits of augmentation learning, and how MoMA utilizes
the plug-in memory at inference time without changing its parameters. We plan
to open source our code.</p>
  </details>
</details>
<details>
  <summary>25. <b>标题：Mining Effective Features Using Quantum Entropy for Humor Recognition</b></summary>
  <p><b>编号</b>：[218]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03716</p>
  <p><b>作者</b>：Yang Liu,  Yuexian Hou</p>
  <p><b>备注</b>：6 pages, 2 figures, conference</p>
  <p><b>关键词</b>：Humor recognition, past years, extensively studied, Humor, recognition</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Humor recognition has been extensively studied with different methods in the
past years. However, existing studies on humor recognition do not understand
the mechanisms that generate humor. In this paper, inspired by the incongruity
theory, any joke can be divided into two components (the setup and the
punchline). Both components have multiple possible semantics, and there is an
incongruous relationship between them. We use density matrices to represent the
semantic uncertainty of the setup and the punchline, respectively, and design
QE-Uncertainty and QE-Incongruity with the help of quantum entropy as features
for humor recognition. The experimental results on the SemEval2021 Task 7
dataset show that the proposed features are more effective than the baselines
for recognizing humorous and non-humorous texts.</p>
  </details>
</details>
<details>
  <summary>26. <b>标题：Concept Algebra for Text-Controlled Vision Models</b></summary>
  <p><b>编号</b>：[220]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03693</p>
  <p><b>作者</b>：Zihao Wang,  Lin Gui,  Jeffrey Negrea,  Victor Veitch</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：generates samples based, text-guided generative models, model generates samples, natural language prompt, concerns the control</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper concerns the control of text-guided generative models, where a
user provides a natural language prompt and the model generates samples based
on this input. Prompting is intuitive, general, and flexible. However, there
are significant limitations: prompting can fail in surprising ways, and it is
often unclear how to find a prompt that will elicit some desired target
behavior. A core difficulty for developing methods to overcome these issues is
that failures are know-it-when-you-see-it -- it's hard to fix bugs if you can't
state precisely what the model should have done! In this paper, we introduce a
formalization of "what the user intended" in terms of latent concepts implicit
to the data generating process that the model was trained on. This
formalization allows us to identify some fundamental limitations of prompting.
We then use the formalism to develop concept algebra to overcome these
limitations. Concept algebra is a way of directly manipulating the concepts
expressed in the output through algebraic operations on a suitably defined
representation of input prompts. We give examples using concept algebra to
overcome limitations of prompting, including concept transfer through
arithmetic, and concept nullification through projection. Code available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>27. <b>标题：Characterizing Financial Market Coverage using Artificial Intelligence</b></summary>
  <p><b>编号</b>：[253]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03694</p>
  <p><b>作者</b>：Jean Marie Tshimula,  D'Jeff K. Nkashama,  Patrick Owusu,  Marc Frappier,  Pierre-Martin Tardif,  Froduald Kabanza,  Armelle Brun,  Jean-Marc Patenaude,  Shengrui Wang,  Belkacem Chikhaoui</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：financial market coverage, market coverage, financial market, characterize financial market, scrutinizes a database</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper scrutinizes a database of over 4900 YouTube videos to characterize
financial market coverage. Financial market coverage generates a large number
of videos. Therefore, watching these videos to derive actionable insights could
be challenging and complex. In this paper, we leverage Whisper, a
speech-to-text model from OpenAI, to generate a text corpus of market coverage
videos from Bloomberg and Yahoo Finance. We employ natural language processing
to extract insights regarding language use from the market coverage. Moreover,
we examine the prominent presence of trending topics and their evolution over
time, and the impacts that some individuals and organizations have on the
financial market. Our characterization highlights the dynamics of the financial
market coverage and provides valuable insights reflecting broad discussions
regarding recent financial events and the world economy.</p>
  </details>
</details>
<h1>机器学习</h1>
<details>
  <summary>1. <b>标题：Diagnosing and Rectifying Vision Models using Language</b></summary>
  <p><b>编号</b>：[1]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04269</p>
  <p><b>作者</b>：Yuhui Zhang,  Jeff Z. HaoChen,  Shih-Cheng Huang,  Kuan-Chieh Wang,  James Zou,  Serena Yeung</p>
  <p><b>备注</b>：Published at ICLR 2023</p>
  <p><b>关键词</b>：Recent multi-modal contrastive, building strong vision, multi-modal contrastive learning, contrastive learning models, embedding space suitable</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent multi-modal contrastive learning models have demonstrated the ability
to learn an embedding space suitable for building strong vision classifiers, by
leveraging the rich information in large-scale image-caption datasets. Our work
highlights a distinct advantage of this multi-modal embedding space: the
ability to diagnose vision classifiers through natural language. The
traditional process of diagnosing model behaviors in deployment settings
involves labor-intensive data acquisition and annotation. Our proposed method
can discover high-error data slices, identify influential attributes and
further rectify undesirable model behaviors, without requiring any visual data.
Through a combination of theoretical explanation and empirical verification, we
present conditions under which classifiers trained on embeddings from one
modality can be equivalently applied to embeddings from another modality. On a
range of image datasets with known error slices, we demonstrate that our method
can effectively identify the error slices and influential attributes, and can
further use language to rectify failure modes of the classifier.</p>
  </details>
</details>
<details>
  <summary>2. <b>标题：PFGM++: Unlocking the Potential of Physics-Inspired Generative Models</b></summary>
  <p><b>编号</b>：[2]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04265</p>
  <p><b>作者</b>：Yilun Xu,  Ziming Liu,  Yonglong Tian,  Shangyuan Tong,  Max Tegmark,  Tommi Jaakkola</p>
  <p><b>备注</b>：Code is available at this https URL</p>
  <p><b>关键词</b>：Poisson Flow Generative, Poisson Flow, Flow Generative Models, Flow Generative, physics-inspired generative models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We introduce a new family of physics-inspired generative models termed PFGM++
that unifies diffusion models and Poisson Flow Generative Models (PFGM). These
models realize generative trajectories for $N$ dimensional data by embedding
paths in $N{+}D$ dimensional space while still controlling the progression with
a simple scalar norm of the $D$ additional variables. The new models reduce to
PFGM when $D{=}1$ and to diffusion models when $D{\to}\infty$. The flexibility
of choosing $D$ allows us to trade off robustness against rigidity as
increasing $D$ results in more concentrated coupling between the data and the
additional variable norms. We dispense with the biased large batch field
targets used in PFGM and instead provide an unbiased perturbation-based
objective similar to diffusion models. To explore different choices of $D$, we
provide a direct alignment method for transferring well-tuned hyperparameters
from diffusion models ($D{\to} \infty$) to any finite $D$ values. Our
experiments show that models with finite $D$ can be superior to previous
state-of-the-art diffusion models on CIFAR-10/FFHQ $64{\times}64$ datasets,
with FID scores of $1.91/2.43$ when $D{=}2048/128$. In addition, we demonstrate
that models with smaller $D$ exhibit improved robustness against modeling
errors. Code is available at this https URL</p>
  </details>
</details>
<details>
  <summary>3. <b>标题：Algorithmic Collective Action in Machine Learning</b></summary>
  <p><b>编号</b>：[4]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04262</p>
  <p><b>作者</b>：Moritz Hardt,  Eric Mazumdar,  Celestine Mendler-Dünner,  Tijana Zrnic</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：deploy machine learning, machine learning algorithms, learning algorithm, algorithmic collective action, firm learning algorithm</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We initiate a principled study of algorithmic collective action on digital
platforms that deploy machine learning algorithms. We propose a simple
theoretical model of a collective interacting with a firm's learning algorithm.
The collective pools the data of participating individuals and executes an
algorithmic strategy by instructing participants how to modify their own data
to achieve a collective goal. We investigate the consequences of this model in
three fundamental learning-theoretic settings: the case of a nonparametric
optimal learning algorithm, a parametric risk minimizer, and gradient-based
optimization. In each setting, we come up with coordinated algorithmic
strategies and characterize natural success criteria as a function of the
collective's size. Complementing our theory, we conduct systematic experiments
on a skill classification task involving tens of thousands of resumes from a
gig platform for freelancers. Through more than two thousand model training
runs of a BERT-like language model, we see a striking correspondence emerge
between our empirical observations and the predictions made by our theory.
Taken together, our theory and experiments broadly support the conclusion that
algorithmic collectives of exceedingly small fractional size can exert
significant control over a platform's learning algorithm.</p>
  </details>
</details>
<details>
  <summary>4. <b>标题：Learning How to Infer Partial MDPs for In-Context Adaptation and  Exploration</b></summary>
  <p><b>编号</b>：[5]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04250</p>
  <p><b>作者</b>：Chentian Jiang,  Nan Rosemary Ke,  Hado van Hasselt</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：acquire knowledge, knowledge from past, facilitate adaptation, adaptation and exploration, past tasks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>To generalize across tasks, an agent should acquire knowledge from past tasks
that facilitate adaptation and exploration in future tasks. We focus on the
problem of in-context adaptation and exploration, where an agent only relies on
context, i.e., history of states, actions and/or rewards, rather than
gradient-based updates. Posterior sampling (extension of Thompson sampling) is
a promising approach, but it requires Bayesian inference and dynamic
programming, which often involve unknowns (e.g., a prior) and costly
computations. To address these difficulties, we use a transformer to learn an
inference process from training tasks and consider a hypothesis space of
partial models, represented as small Markov decision processes that are cheap
for dynamic programming. In our version of the Symbolic Alchemy benchmark, our
method's adaptation speed and exploration-exploitation balance approach those
of an exact posterior sampling oracle. We also show that even though partial
models exclude relevant information from the environment, they can nevertheless
lead to good policies.</p>
  </details>
</details>
<details>
  <summary>5. <b>标题：Federated Minimax Optimization with Client Heterogeneity</b></summary>
  <p><b>编号</b>：[6]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04249</p>
  <p><b>作者</b>：Pranay Sharma,  Rohan Panda,  Gauri Joshi</p>
  <p><b>备注</b>：52 pages, 8 figures</p>
  <p><b>关键词</b>：surge in interest, advent of modern, modern applications, inherently more challenging, challenging than simple</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Minimax optimization has seen a surge in interest with the advent of modern
applications such as GANs, and it is inherently more challenging than simple
minimization. The difficulty is exacerbated by the training data residing at
multiple edge devices or \textit{clients}, especially when these clients can
have heterogeneous datasets and local computation capabilities. We propose a
general federated minimax optimization framework that subsumes such settings
and several existing methods like Local SGDA. We show that naive aggregation of
heterogeneous local progress results in optimizing a mismatched objective
function -- a phenomenon previously observed in standard federated
minimization. To fix this problem, we propose normalizing the client updates by
the number of local steps undertaken between successive communication rounds.
We analyze the convergence of the proposed algorithm for classes of
nonconvex-concave and nonconvex-nonconcave functions and characterize the
impact of heterogeneous client data, partial client participation, and
heterogeneous local computations. Our analysis works under more general
assumptions on the intra-client noise and inter-client heterogeneity than so
far considered in the literature. For all the function classes considered, we
significantly improve the existing computation and communication complexity
results. Experimental results support our theoretical claims.</p>
  </details>
</details>
<details>
  <summary>6. <b>标题：Shortcut Detection with Variational Autoencoders</b></summary>
  <p><b>编号</b>：[7]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04246</p>
  <p><b>作者</b>：Nicolas M. Müller,  Simon Roschmann,  Shahbaz Khan,  Philip Sperl,  Konstantin Böttinger</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：models make predictions, make predictions based, machine learning, applications of machine, essential that models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>For real-world applications of machine learning (ML), it is essential that
models make predictions based on well-generalizing features rather than
spurious correlations in the data. The identification of such spurious
correlations, also known as shortcuts, is a challenging problem and has so far
been scarcely addressed. In this work, we present a novel approach to detect
shortcuts in image and audio datasets by leveraging variational autoencoders
(VAEs). The disentanglement of features in the latent space of VAEs allows us
to discover correlations in datasets and semi-automatically evaluate them for
ML shortcuts. We demonstrate the applicability of our method on several
real-world datasets and identify shortcuts that have not been discovered
before. Based on these findings, we also investigate the construction of
shortcut adversarial examples.</p>
  </details>
</details>
<details>
  <summary>7. <b>标题：Adversarial Prompting for Black Box Foundation Models</b></summary>
  <p><b>编号</b>：[9]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04237</p>
  <p><b>作者</b>：Natalie Maus,  Patrick Chao,  Eric Wong,  Jacob Gardner</p>
  <p><b>备注</b>：11 pages of main text, supplementary material after references</p>
  <p><b>关键词</b>：Prompting interfaces, vision and language, interfaces allow users, users to quickly, quickly adjust</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Prompting interfaces allow users to quickly adjust the output of generative
models in both vision and language. However, small changes and design choices
in the prompt can lead to significant differences in the output. In this work,
we develop a black-box framework for generating adversarial prompts for
unstructured image and text generation. These prompts, which can be standalone
or prepended to benign prompts, induce specific behaviors into the generative
process, such as generating images of a particular object or biasing the
frequency of specific letters in the generated text.</p>
  </details>
</details>
<details>
  <summary>8. <b>标题：Federated Learning as Variational Inference: A Scalable Expectation  Propagation Approach</b></summary>
  <p><b>编号</b>：[12]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04228</p>
  <p><b>作者</b>：Han Guo,  Philip Greengard,  Hongyi Wang,  Andrew Gelman,  Yoon Kim,  Eric P. Xing</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：global loss function, client loss functions, distributed optimization problem, loss function, federated learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The canonical formulation of federated learning treats it as a distributed
optimization problem where the model parameters are optimized against a global
loss function that decomposes across client loss functions. A recent
alternative formulation instead treats federated learning as a distributed
inference problem, where the goal is to infer a global posterior from
partitioned client data (Al-Shedivat et al., 2021). This paper extends the
inference view and describes a variational inference formulation of federated
learning where the goal is to find a global variational posterior that
well-approximates the true posterior. This naturally motivates an expectation
propagation approach to federated learning (FedEP), where approximations to the
global posterior are iteratively refined through probabilistic message-passing
between the central server and the clients. We conduct an extensive empirical
study across various algorithmic considerations and describe practical
strategies for scaling up expectation propagation to the modern federated
setting. We apply FedEP on standard federated learning benchmarks and find that
it outperforms strong baselines in terms of both convergence speed and
accuracy.</p>
  </details>
</details>
<details>
  <summary>9. <b>标题：Combining Variational Autoencoders and Physical Bias for Improved  Microscopy Data Analysis</b></summary>
  <p><b>编号</b>：[18]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04216</p>
  <p><b>作者</b>：Arpan Biswas,  Maxim Ziatdinov,  Sergei V. Kalinin</p>
  <p><b>备注</b>：20 pages, 7 figures in main text, 4 figures in Supp Mat</p>
  <p><b>关键词</b>：scanning probe microscopy, probe microscopy produce, microscopy produce vast, produce vast amounts, Electron and scanning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Electron and scanning probe microscopy produce vast amounts of data in the
form of images or hyperspectral data, such as EELS or 4D STEM, that contain
information on a wide range of structural, physical, and chemical properties of
materials. To extract valuable insights from these data, it is crucial to
identify physically separate regions in the data, such as phases, ferroic
variants, and boundaries between them. In order to derive an easily
interpretable feature analysis, combining with well-defined boundaries in a
principled and unsupervised manner, here we present a physics augmented machine
learning method which combines the capability of Variational Autoencoders to
disentangle factors of variability within the data and the physics driven loss
function that seeks to minimize the total length of the discontinuities in
images corresponding to latent representations. Our method is applied to
various materials, including NiO-LSMO, BiFeO3, and graphene. The results
demonstrate the effectiveness of our approach in extracting meaningful
information from large volumes of imaging data. The fully notebook containing
implementation of the code and analysis workflow is available at
this https URL</p>
  </details>
</details>
<details>
  <summary>10. <b>标题：Exploratory Analysis of Federated Learning Methods with Differential  Privacy on MIMIC-III</b></summary>
  <p><b>编号</b>：[19]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04208</p>
  <p><b>作者</b>：Aron N. Horvath,  Matteo Berchier,  Farhad Nooralahzadeh,  Ahmed Allam,  Michael Krauthammer</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：machine learning models, learning methods offer, training machine learning, Federated learning methods, differential privacy</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Background: Federated learning methods offer the possibility of training
machine learning models on privacy-sensitive data sets, which cannot be easily
shared. Multiple regulations pose strict requirements on the storage and usage
of healthcare data, leading to data being in silos (i.e. locked-in at
healthcare facilities). The application of federated algorithms on these
datasets could accelerate disease diagnostic, drug development, as well as
improve patient care.
Methods: We present an extensive evaluation of the impact of different
federation and differential privacy techniques when training models on the
open-source MIMIC-III dataset. We analyze a set of parameters influencing a
federated model performance, namely data distribution (homogeneous and
heterogeneous), communication strategies (communication rounds vs. local
training epochs), federation strategies (FedAvg vs. FedProx). Furthermore, we
assess and compare two differential privacy (DP) techniques during model
training: a stochastic gradient descent-based differential privacy algorithm
(DP-SGD), and a sparse vector differential privacy technique (DP-SVT).
Results: Our experiments show that extreme data distributions across sites
(imbalance either in the number of patients or the positive label ratios
between sites) lead to a deterioration of model performance when trained using
the FedAvg strategy. This issue is resolved when using FedProx with the use of
appropriate hyperparameter tuning. Furthermore, the results show that both
differential privacy techniques can reach model performances similar to those
of models trained without DP, however at the expense of a large quantifiable
privacy leakage.
Conclusions: We evaluate empirically the benefits of two federation
strategies and propose optimal strategies for the choice of parameters when
using differential privacy techniques.</p>
  </details>
</details>
<details>
  <summary>11. <b>标题：Efficient Joint Learning for Clinical Named Entity Recognition and  Relation Extraction Using Fourier Networks: A Use Case in Adverse Drug Events</b></summary>
  <p><b>编号</b>：[23]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04185</p>
  <p><b>作者</b>：Anthony Yazdani,  Dimitrios Proios,  Hossein Rouhizadeh,  Douglas Teodoro</p>
  <p><b>备注</b>：International Conference on Natural Language Processing (ICON 2022)</p>
  <p><b>关键词</b>：electronic health records, large-scale electronic health, hindering their application, health records, clinical information extraction</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Current approaches for clinical information extraction are inefficient in
terms of computational costs and memory consumption, hindering their
application to process large-scale electronic health records (EHRs). We propose
an efficient end-to-end model, the Joint-NER-RE-Fourier (JNRF), to jointly
learn the tasks of named entity recognition and relation extraction for
documents of variable length. The architecture uses positional encoding and
unitary batch sizes to process variable length documents and uses a
weight-shared Fourier network layer for low-complexity token mixing. Finally,
we reach the theoretical computational complexity lower bound for relation
extraction using a selective pooling strategy and distance-aware attention
weights with trainable polynomial distance functions. We evaluated the JNRF
architecture using the 2018 N2C2 ADE benchmark to jointly extract
medication-related entities and relations in variable-length EHR summaries.
JNRF outperforms rolling window BERT with selective pooling by 0.42%, while
being twice as fast to train. Compared to state-of-the-art BiLSTM-CRF
architectures on the N2C2 ADE benchmark, results show that the proposed
approach trains 22 times faster and reduces GPU memory consumption by 1.75
folds, with a reasonable performance tradeoff of 90%, without the use of
external tools, hand-crafted rules or post-processing. Given the significant
carbon footprint of deep learning models and the current energy crises, these
methods could support efficient and cleaner information extraction in EHRs and
other types of large-scale document databases.</p>
  </details>
</details>
<details>
  <summary>12. <b>标题：Non-Stationary Bandits with Knapsack Problems with Advice</b></summary>
  <p><b>编号</b>：[24]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04182</p>
  <p><b>作者</b>：Lixing Lyu,  Wang Chi Cheung</p>
  <p><b>备注</b>：33 pages, 4 figures</p>
  <p><b>关键词</b>：Bandits with Knapsack, Knapsack problem, non-stationary Bandits, Bandits, Knapsack</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We consider a non-stationary Bandits with Knapsack problem. The outcome
distribution at each time is scaled by a non-stationary quantity that signifies
changing demand volumes. Instead of studying settings with limited
non-stationarity, we investigate how online predictions on the total demand
volume $Q$ allows us to improve our performance guarantees. We show that,
without any prediction, any online algorithm incurs a linear-in-$T$ regret. In
contrast, with online predictions on $Q$, we propose an online algorithm that
judiciously incorporates the predictions, and achieve regret bounds that
depends on the accuracy of the predictions. These bounds are shown to be tight
in settings when prediction accuracy improves across time. Our theoretical
results are corroborated by our numerical findings.</p>
  </details>
</details>
<details>
  <summary>13. <b>标题：Attending to Graph Transformers</b></summary>
  <p><b>编号</b>：[25]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04181</p>
  <p><b>作者</b>：Luis Müller,  Mikhail Galkin,  Christopher Morris,  Ladislav Rampášek</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：graph neural networks, alternative to established, established techniques, techniques for machine, machine learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recently, transformer architectures for graphs emerged as an alternative to
established techniques for machine learning with graphs, such as graph neural
networks. So far, they have shown promising empirical results, e.g., on
molecular prediction datasets, often attributed to their ability to circumvent
graph neural networks' shortcomings, such as over-smoothing and over-squashing.
Here, we derive a taxonomy of graph transformer architectures, bringing some
order to this emerging field. We overview their theoretical properties, survey
structural and positional encodings, and discuss extensions for important graph
classes, e.g., 3D molecular graphs. Empirically, we probe how well graph
transformers can recover various graph properties, how well they can deal with
heterophilic graphs, and to what extent they prevent over-squashing. Further,
we outline open challenges and research direction to stimulate future work. Our
code is available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>14. <b>标题：A Scale-Independent Multi-Objective Reinforcement Learning with  Convergence Analysis</b></summary>
  <p><b>编号</b>：[27]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04179</p>
  <p><b>作者</b>：Mohsen Amidzadeh</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：sequential decision-making problems, sequential decision-making, possibly conflict, decision-making problems, multi-task problem</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Many sequential decision-making problems need optimization of different
objectives which possibly conflict with each other. The conventional way to
deal with a multi-task problem is to establish a scalar objective function
based on a linear combination of different objectives. However, for the case of
having conflicting objectives with different scales, this method needs a
trial-and-error approach to properly find proper weights for the combination.
As such, in most cases, this approach cannot guarantee an optimal Pareto
solution. In this paper, we develop a single-agent scale-independent
multi-objective reinforcement learning on the basis of the Advantage
Actor-Critic (A2C) algorithm. A convergence analysis is then done for the
devised multi-objective algorithm providing a convergence-in-mean guarantee. We
then perform some experiments over a multi-task problem to evaluate the
performance of the proposed algorithm. Simulation results show the superiority
of developed multi-objective A2C approach against the single-objective
algorithm.</p>
  </details>
</details>
<details>
  <summary>15. <b>标题：DynGFN: Bayesian Dynamic Causal Discovery using Generative Flow Networks</b></summary>
  <p><b>编号</b>：[28]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04178</p>
  <p><b>作者</b>：Lazar Atanackovic,  Alexander Tong,  Jason Hartford,  Leo J. Lee,  Bo Wang,  Yoshua Bengio</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Bayesian causal discovery, causal, causal discovery, Bayesian causal, scientific discovery</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Learning the causal structure of observable variables is a central focus for
scientific discovery. Bayesian causal discovery methods tackle this problem by
learning a posterior over the set of admissible graphs given our priors and
observations. Existing methods primarily consider observations from static
systems and assume the underlying causal structure takes the form of a directed
acyclic graph (DAG). In settings with dynamic feedback mechanisms that regulate
the trajectories of individual variables, this acyclicity assumption fails
unless we account for time. We focus on learning Bayesian posteriors over
cyclic graphs and treat causal discovery as a problem of sparse identification
of a dynamical system. This imposes a natural temporal causal order between
variables and captures cyclic feedback loops through time. Under this lens, we
propose a new framework for Bayesian causal discovery for dynamical systems and
present a novel generative flow network architecture (DynGFN) tailored for this
task. Our results indicate that DynGFN learns posteriors that better
encapsulate the distributions over admissible cyclic causal structures compared
to counterpart state-of-the-art approaches.</p>
  </details>
</details>
<details>
  <summary>16. <b>标题：The Hardware Impact of Quantization and Pruning for Weights in Spiking  Neural Networks</b></summary>
  <p><b>编号</b>：[31]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04174</p>
  <p><b>作者</b>：Clemens JS Schaefer,  Pooria Taheri,  Mark Horeni,  Siddharth Joshi</p>
  <p><b>备注</b>：Code this https URL</p>
  <p><b>关键词</b>：Spiking neural networks, great interest due, developing artificial systems, Spiking neural, deployments of Spiking</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Energy efficient implementations and deployments of Spiking neural networks
(SNNs) have been of great interest due to the possibility of developing
artificial systems that can achieve the computational powers and energy
efficiency of the biological brain. Efficient implementations of SNNs on modern
digital hardware are also inspired by advances in machine learning and deep
neural networks (DNNs). Two techniques widely employed in the efficient
deployment of DNNs -- the quantization and pruning of parameters, can both
compress the model size, reduce memory footprints, and facilitate low-latency
execution. The interaction between quantization and pruning and how they might
impact model performance on SNN accelerators is currently unknown. We study
various combinations of pruning and quantization in isolation, cumulatively,
and simultaneously (jointly) to a state-of-the-art SNN targeting gesture
recognition for dynamic vision sensor cameras (DVS). We show that this
state-of-the-art model is amenable to aggressive parameter quantization, not
suffering from any loss in accuracy down to ternary weights. However, pruning
only maintains iso-accuracy up to 80% sparsity, which results in 45% more
energy than the best quantization on our architectural model. Applying both
pruning and quantization can result in an accuracy loss to offer a favourable
trade-off on the energy-accuracy Pareto-frontier for the given hardware
configuration.</p>
  </details>
</details>
<details>
  <summary>17. <b>标题：Generalizing Neural Wave Functions</b></summary>
  <p><b>编号</b>：[33]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04168</p>
  <p><b>作者</b>：Nicholas Gao,  Stephan Günnemann</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：potential energy surface, modeling ab-initio ground-state, ab-initio ground-state potential, ground-state potential energy, energy surface</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent neural network-based wave functions have achieved state-of-the-art
accuracies in modeling ab-initio ground-state potential energy surface.
However, these networks can only solve different spatial arrangements of the
same set of atoms. To overcome this limitation, we present Graph-learned
Orbital Embeddings (Globe), a neural network-based reparametrization method
that can adapt neural wave functions to different molecules. We achieve this by
combining a localization method for molecular orbitals with spatial
message-passing networks. Further, we propose a locality-driven wave function,
the Molecular Oribtal Network (Moon), tailored to solving Schrödinger
equations of different molecules jointly. In our experiments, we find Moon
requiring 8 times fewer steps to converge to similar accuracies as previous
methods when trained on different molecules jointly while Globe enabling the
transfer from smaller to larger molecules. Further, our analysis shows that
Moon converges similarly to recent transformer-based wave functions on larger
molecules. In both the computational chemistry and machine learning literature,
we are the first to demonstrate that a single wave function can solve the
Schrödinger equation of molecules with different atoms jointly.</p>
  </details>
</details>
<details>
  <summary>18. <b>标题：Policy Evaluation in Decentralized POMDPs with Belief Sharing</b></summary>
  <p><b>编号</b>：[37]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04151</p>
  <p><b>作者</b>：Mert Kayaalp,  Fatima Ghadieh,  Ali H. Sayed</p>
  <p><b>备注</b>：Submitted for publication</p>
  <p><b>关键词</b>：reinforcement learning focus, multi-agent reinforcement learning, environment state directly, reinforcement learning, learning focus</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Most works on multi-agent reinforcement learning focus on scenarios where the
state of the environment is fully observable. In this work, we consider a
cooperative policy evaluation task in which agents are not assumed to observe
the environment state directly. Instead, agents can only have access to noisy
observations and to belief vectors. It is well-known that finding global
posterior distributions under multi-agent settings is generally NP-hard. As a
remedy, we propose a fully decentralized belief forming strategy that relies on
individual updates and on localized interactions over a communication network.
In addition to the exchange of the beliefs, agents exploit the communication
network by exchanging value function parameter estimates as well. We
analytically show that the proposed strategy allows information to diffuse over
the network, which in turn allows the agents' parameters to have a bounded
difference with a centralized baseline. A multi-sensor target tracking
application is considered in the simulations.</p>
  </details>
</details>
<details>
  <summary>19. <b>标题：Combining self-labeling and demand based active learning for  non-stationary data streams</b></summary>
  <p><b>编号</b>：[39]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04141</p>
  <p><b>作者</b>：Valerie Vaquet,  Fabian Hinder,  Johannes Brinkrolf,  Barbara Hammer</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：industrial process monitoring, gains increasing interest, social media, process monitoring, research direction</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Learning from non-stationary data streams is a research direction that gains
increasing interest as more data in form of streams becomes available, for
example from social media, smartphones, or industrial process monitoring. Most
approaches assume that the ground truth of the samples becomes available
(possibly with some delay) and perform supervised online learning in the
test-then-train scheme. While this assumption might be valid in some scenarios,
it does not apply to all settings. In this work, we focus on scarcely labeled
data streams and explore the potential of self-labeling in gradually drifting
data streams. We formalize this setup and propose a novel online $k$-nn
classifier that combines self-labeling and demand-based active learning.</p>
  </details>
</details>
<details>
  <summary>20. <b>标题：Robustness to Spurious Correlations Improves Semantic  Out-of-Distribution Detection</b></summary>
  <p><b>编号</b>：[41]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04132</p>
  <p><b>作者</b>：Lily H. Zhang,  Rajesh Ranganath</p>
  <p><b>备注</b>：AAAI 2023</p>
  <p><b>关键词</b>：nuisance-aware OOD detection, OOD, nuisance-aware OOD, OOD detection, predictive models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Methods which utilize the outputs or feature representations of predictive
models have emerged as promising approaches for out-of-distribution (OOD)
detection of image inputs. However, these methods struggle to detect OOD inputs
that share nuisance values (e.g. background) with in-distribution inputs. The
detection of shared-nuisance out-of-distribution (SN-OOD) inputs is
particularly relevant in real-world applications, as anomalies and
in-distribution inputs tend to be captured in the same settings during
deployment. In this work, we provide a possible explanation for SN-OOD
detection failures and propose nuisance-aware OOD detection to address them.
Nuisance-aware OOD detection substitutes a classifier trained via empirical
risk minimization and cross-entropy loss with one that 1. is trained under a
distribution where the nuisance-label relationship is broken and 2. yields
representations that are independent of the nuisance under this distribution,
both marginally and conditioned on the label. We can train a classifier to
achieve these objectives using Nuisance-Randomized Distillation (NuRD), an
algorithm developed for OOD generalization under spurious correlations. Output-
and feature-based nuisance-aware OOD detection perform substantially better
than their original counterparts, succeeding even when detection based on
domain generalization algorithms fails to improve performance.</p>
  </details>
</details>
<details>
  <summary>21. <b>标题：Predicting the performance of hybrid ventilation in buildings using a  multivariate attention-based biLSTM Encoder-Decoder neural network</b></summary>
  <p><b>编号</b>：[43]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04126</p>
  <p><b>作者</b>：Gaurav Chaudhary,  Hicham Johra,  Laurent Georges,  Bjørn Austbø</p>
  <p><b>备注</b>：11 pages, 8 figures</p>
  <p><b>关键词</b>：reliable control system, provide fresh air, coupling natural, natural and mechanical, energy-efficient solution</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Hybrid ventilation (coupling natural and mechanical ventilation) is an
energy-efficient solution to provide fresh air for most climates, given that it
has a reliable control system. To operate such systems optimally, a
high-fidelity control-oriented model is required. It should enable near-real
time forecast of the indoor air temperature and humidity based on operational
conditions such as window opening and HVAC schedules. However, widely used
physics-based simulation models (i.e., white-box models) are labour-intensive
and computationally expensive. Alternatively, black-box models based on
artificial neural networks can be trained to be good estimators for building
dynamics. This paper investigates the capabilities of a multivariate multi-head
attention-based long short-term memory (LSTM) encoder-decoder neural network to
predict indoor air conditions of a building equipped with hybrid ventilation.
The deep neural network used for this study aims to predict indoor air
temperature dynamics when a window is opened and closed, respectively. Training
and test data were generated from detailed multi-zone office building model
(EnergyPlus). The deep neural network is able to accurately predict indoor air
temperature of five zones whenever a window was opened and closed.</p>
  </details>
</details>
<details>
  <summary>22. <b>标题：Intrinsic Rewards from Self-Organizing Feature Maps for Exploration in  Reinforcement Learning</b></summary>
  <p><b>编号</b>：[44]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04125</p>
  <p><b>作者</b>：Marius Lindegaard,  Hjalmar Jacob Vinje,  Odin Aleksander Severinsen</p>
  <p><b>备注</b>：10 pages, 4 figures. Code publicly available at this https URL</p>
  <p><b>关键词</b>：self-organising feature maps, deep reinforcement learning, reinforcement learning methods, learning methods calculated, feature maps</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We introduce an exploration bonus for deep reinforcement learning methods
calculated using self-organising feature maps. Our method uses adaptive
resonance theory (ART) providing online, unsupervised clustering to quantify
the novelty of a state. This heuristic is used to add an intrinsic reward to
the extrinsic reward signal for then to optimize the agent to maximize the sum
of these two rewards. We find that this method was able to play the game Ordeal
at a human level after a comparable number of training epochs to ICM
arXiv:1705.05464. Agents augmented with RND arXiv:1810.12894 were unable to
achieve the same level of performance in our space of hyperparameters.</p>
  </details>
</details>
<details>
  <summary>23. <b>标题：Local Law 144: A Critical Analysis of Regression Metrics</b></summary>
  <p><b>编号</b>：[46]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04119</p>
  <p><b>作者</b>：Giulio Filippi,  Sara Zannone,  Airlie Hilliard,  Adriano Koshiyama</p>
  <p><b>备注</b>：12 pages, 5 figures</p>
  <p><b>关键词</b>：York City Council, City Council passed, Local Law, amount of attention, York City</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The use of automated decision tools in recruitment has received an increasing
amount of attention. In November 2021, the New York City Council passed a
legislation (Local Law 144) that mandates bias audits of Automated Employment
Decision Tools. From 15th April 2023, companies that use automated tools for
hiring or promoting employees are required to have these systems audited by an
independent entity. Auditors are asked to compute bias metrics that compare
outcomes for different groups, based on sex/gender and race/ethnicity
categories at a minimum. Local Law 144 proposes novel bias metrics for
regression tasks (scenarios where the automated system scores candidates with a
continuous range of values). A previous version of the legislation proposed a
bias metric that compared the mean scores of different groups. The new revised
bias metric compares the proportion of candidates in each group that falls
above the median. In this paper, we argue that both metrics fail to capture
distributional differences over the whole domain, and therefore cannot reliably
detect bias. We first introduce two metrics, as possible alternatives to the
legislation metrics. We then compare these metrics over a range of theoretical
examples, for which the legislation proposed metrics seem to underestimate
bias. Finally, we study real data and show that the legislation metrics can
similarly fail in a real-world recruitment application.</p>
  </details>
</details>
<details>
  <summary>24. <b>标题：On the Richness of Calibration</b></summary>
  <p><b>编号</b>：[47]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04118</p>
  <p><b>作者</b>：Benedikt Höltgen,  Robert C Williamson</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：observed label frequencies, label frequencies, evaluated through comparisons, comparisons with observed, observed label</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Probabilistic predictions can be evaluated through comparisons with observed
label frequencies, that is, through the lens of calibration. Recent scholarship
on algorithmic fairness has started to look at a growing variety of
calibration-based objectives under the name of multi-calibration but has still
remained fairly restricted. In this paper, we explore and analyse forms of
evaluation through calibration by making explicit the choices involved in
designing calibration scores. We organise these into three grouping choices and
a choice concerning the agglomeration of group errors. This provides a
framework for comparing previously proposed calibration scores and helps to
formulate novel ones with desirable mathematical properties. In particular, we
explore the possibility of grouping datapoints based on their input features
rather than on predictions and formally demonstrate advantages of such
approaches. We also characterise the space of suitable agglomeration functions
for group errors, generalising previously proposed calibration scores.
Complementary to such population-level scores, we explore calibration scores at
the individual level and analyse their relationship to choices of grouping. We
draw on these insights to introduce and axiomatise fairness deviation measures
for population-level scores. We demonstrate that with appropriate choices of
grouping, these novel global fairness scores can provide notions of (sub-)group
or individual fairness.</p>
  </details>
</details>
<details>
  <summary>25. <b>标题：Explainable Label-flipping Attacks on Human Emotion Assessment System</b></summary>
  <p><b>编号</b>：[53]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04109</p>
  <p><b>作者</b>：Zhibo Zhang,  Ahmed Y. Al Hammadi,  Ernesto Damiani,  Chan Yeob Yeun</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：paper main goal, evaluate human emotion, Random Forest dedicated, data poisoning assaults, main goal</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper's main goal is to provide an attacker's point of view on data
poisoning assaults that use label-flipping during the training phase of systems
that use electroencephalogram (EEG) signals to evaluate human emotion. To
attack different machine learning classifiers such as Adaptive Boosting
(AdaBoost) and Random Forest dedicated to the classification of 4 different
human emotions using EEG signals, this paper proposes two scenarios of
label-flipping methods. The results of the studies show that the proposed data
poison attacksm based on label-flipping are successful regardless of the model,
but different models show different degrees of resistance to the assaults. In
addition, numerous Explainable Artificial Intelligence (XAI) techniques are
used to explain the data poison attacks on EEG signal-based human emotion
evaluation systems.</p>
  </details>
</details>
<details>
  <summary>26. <b>标题：Can Physics-Informed Neural Networks beat the Finite Element Method?</b></summary>
  <p><b>编号</b>：[55]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04107</p>
  <p><b>作者</b>：Tamara G. Grossmann,  Urszula Julia Komorowska,  Jonas Latz,  Carola-Bibiane Schönlieb</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：physics-informed neural networks, processes and systems, Partial differential equations, neural networks, finite element method</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Partial differential equations play a fundamental role in the mathematical
modelling of many processes and systems in physical, biological and other
sciences. To simulate such processes and systems, the solutions of PDEs often
need to be approximated numerically. The finite element method, for instance,
is a usual standard methodology to do so. The recent success of deep neural
networks at various approximation tasks has motivated their use in the
numerical solution of PDEs. These so-called physics-informed neural networks
and their variants have shown to be able to successfully approximate a large
range of partial differential equations. So far, physics-informed neural
networks and the finite element method have mainly been studied in isolation of
each other. In this work, we compare the methodologies in a systematic
computational study. Indeed, we employ both methods to numerically solve
various linear and nonlinear partial differential equations: Poisson in 1D, 2D,
and 3D, Allen-Cahn in 1D, semilinear Schrödinger in 1D and 2D. We then
compare computational costs and approximation accuracies. In terms of solution
time and accuracy, physics-informed neural networks have not been able to
outperform the finite element method in our study. In some experiments, they
were faster at evaluating the solved PDE.</p>
  </details>
</details>
<details>
  <summary>27. <b>标题：WF-UNet: Weather Fusion UNet for Precipitation Nowcasting</b></summary>
  <p><b>编号</b>：[57]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04102</p>
  <p><b>作者</b>：Christos Kaparakis,  Siamak Mehrkanoon</p>
  <p><b>备注</b>：8 pages, 8 figures</p>
  <p><b>关键词</b>：Designing early warning, requires accurate short-term, accurate short-term forecasts, early warning systems, Designing early</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Designing early warning systems for harsh weather and its effects, such as
urban flooding or landslides, requires accurate short-term forecasts (nowcasts)
of precipitation. Nowcasting is a significant task with several environmental
applications, such as agricultural management or increasing flight safety. In
this study, we investigate the use of a UNet core-model and its extension for
precipitation nowcasting in western Europe for up to 3 hours ahead. In
particular, we propose the Weather Fusion UNet (WF-UNet) model, which utilizes
the Core 3D-UNet model and integrates precipitation and wind speed variables as
input in the learning process and analyze its influences on the precipitation
target task. We have collected six years of precipitation and wind radar images
from Jan 2016 to Dec 2021 of 14 European countries, with 1-hour temporal
resolution and 31 square km spatial resolution based on the ERA5 dataset,
provided by Copernicus, the European Union's Earth observation programme. We
compare the proposed WF-UNet model to persistence model as well as other UNet
based architectures that are trained only using precipitation radar input data.
The obtained results show that WF-UNet outperforms the other examined
best-performing architectures by 22%, 8% and 6% lower MSE at a horizon of 1, 2
and 3 hours respectively.</p>
  </details>
</details>
<details>
  <summary>28. <b>标题：ASTRIDE: Adaptive Symbolization for Time Series Databases</b></summary>
  <p><b>编号</b>：[59]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04097</p>
  <p><b>作者</b>：Sylvain W. Combettes,  Charles Truong,  Laurent Oudre</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：accelerated variant FASTRIDE, Fast ASTRIDE, General Edit Distance, Time seRIes DatabasEs, Adaptive Brownian Bridge-based</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We introduce ASTRIDE (Adaptive Symbolization for Time seRIes DatabasEs), a
novel symbolic representation of time series, along with its accelerated
variant FASTRIDE (Fast ASTRIDE). Unlike most symbolization procedures, ASTRIDE
is adaptive during both the segmentation step by performing change-point
detection and the quantization step by using quantiles. Instead of proceeding
signal by signal, ASTRIDE builds a dictionary of symbols that is common to all
signals in a data set. We also introduce D-GED (Dynamic General Edit Distance),
a novel similarity measure on symbolic representations based on the general
edit distance. We demonstrate the performance of the ASTRIDE and FASTRIDE
representations compared to SAX (Symbolic Aggregate approXimation), 1d-SAX, SFA
(Symbolic Fourier Approximation), and ABBA (Adaptive Brownian Bridge-based
Aggregation) on reconstruction and, when applicable, on classification tasks.
These algorithms are evaluated on 86 univariate equal-size data sets from the
UCR Time Series Classification Archive. An open source GitHub repository called
astride is made available to reproduce all the experiments in Python.</p>
  </details>
</details>
<details>
  <summary>29. <b>标题：ZipLM: Hardware-Aware Structured Pruning of Language Models</b></summary>
  <p><b>编号</b>：[63]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04089</p>
  <p><b>作者</b>：Eldar Kurtic,  Elias Frantar,  Dan Alistarh</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：large computational footprints, high deployment costs, large language models, large language, large computational</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The breakthrough performance of large language models (LLMs) comes with large
computational footprints and high deployment costs. In this paper, we progress
towards resolving this problem by proposing a new structured compression
approach for LLMs, called ZipLM, which provides state-of-the-art
compression-vs-accuracy results, while guaranteeing to match a set of
(achievable) target speedups on any given target hardware. Specifically, given
a task, a model, an inference environment, as well as a set of speedup targets,
ZipLM identifies and removes redundancies in the model through iterative
structured shrinking of the model's weight matrices. Importantly, ZipLM works
in both, the post-training/one-shot and the gradual compression setting, where
it produces a set of accurate models in a single run, making it
highly-efficient in practice. Our approach is based on new structured pruning
and knowledge distillation techniques, and consistently outperforms prior
structured compression methods in terms of accuracy-versus-speedup in
experiments on BERT- and GPT-family models. In particular, when compressing
GPT2 model, it outperforms DistilGPT2 while being 60% smaller and 30% faster.
Further, ZipLM matches performance of heavily optimized MobileBERT model,
obtained via extensive architecture search, by simply pruning the baseline
BERT-large architecture, and outperforms all prior BERT-base compression
techniques like CoFi, MiniLM and TinyBERT.</p>
  </details>
</details>
<details>
  <summary>30. <b>标题：FFHR: Fully and Flexible Hyperbolic Representation for Knowledge Graph  Completion</b></summary>
  <p><b>编号</b>：[64]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04088</p>
  <p><b>作者</b>：Wentao Shi,  Junkang Wu,  Xuezhi Cao,  Jiawei Chen,  Wenqiang Lei,  Wei Wu,  Xiangnan He</p>
  <p><b>备注</b>：submit to TKDE</p>
  <p><b>关键词</b>：gained increasing attention, increasing attention due, hyperbolic space, hyperbolic, capturing hierarchies</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Learning hyperbolic embeddings for knowledge graph (KG) has gained increasing
attention due to its superiority in capturing hierarchies. However, some
important operations in hyperbolic space still lack good definitions, making
existing methods unable to fully leverage the merits of hyperbolic space.
Specifically, they suffer from two main limitations: 1) existing Graph
Convolutional Network (GCN) methods in hyperbolic space rely on tangent space
approximation, which would incur approximation error in representation
learning, and 2) due to the lack of inner product operation definition in
hyperbolic space, existing methods can only measure the plausibility of facts
(links) with hyperbolic distance, which is difficult to capture complex data
patterns. In this work, we contribute: 1) a Full Poincaré Multi-relational
GCN that achieves graph information propagation in hyperbolic space without
requiring any approximation, and 2) a hyperbolic generalization of Euclidean
inner product that is beneficial to capture both hierarchical and complex
patterns. On this basis, we further develop a \textbf{F}ully and
\textbf{F}lexible \textbf{H}yperbolic \textbf{R}epresentation framework
(\textbf{FFHR}) that is able to transfer recent Euclidean-based advances to
hyperbolic space. We demonstrate it by instantiating FFHR with four
representative KGC methods. Extensive experiments on benchmark datasets
validate the superiority of our FFHRs over their Euclidean counterparts as well
as state-of-the-art hyperbolic embedding methods.</p>
  </details>
</details>
<details>
  <summary>31. <b>标题：Improving the Model Consistency of Decentralized Federated Learning</b></summary>
  <p><b>编号</b>：[68]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04083</p>
  <p><b>作者</b>：Yifan Shi,  Li Shen,  Kang Wei,  Yan Sun,  Bo Yuan,  Xueqian Wang,  Dacheng Tao</p>
  <p><b>备注</b>：21 pages</p>
  <p><b>关键词</b>：burdens of Federated, frac, DFL, mitigate the privacy, privacy leakages</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>To mitigate the privacy leakages and communication burdens of Federated
Learning (FL), decentralized FL (DFL) discards the central server and each
client only communicates with its neighbors in a decentralized communication
network. However, existing DFL suffers from high inconsistency among local
clients, which results in severe distribution shift and inferior performance
compared with centralized FL (CFL), especially on heterogeneous data or sparse
communication topology. To alleviate this issue, we propose two DFL algorithms
named DFedSAM and DFedSAM-MGS to improve the performance of DFL. Specifically,
DFedSAM leverages gradient perturbation to generate local flat models via
Sharpness Aware Minimization (SAM), which searches for models with uniformly
low loss values. DFedSAM-MGS further boosts DFedSAM by adopting Multiple Gossip
Steps (MGS) for better model consistency, which accelerates the aggregation of
local flat models and better balances communication complexity and
generalization. Theoretically, we present improved convergence rates $\small
\mathcal{O}\big(\frac{1}{\sqrt{KT}}+\frac{1}{T}+\frac{1}{K^{1/2}T^{3/2}(1-\lambda)^2}\big)$
and $\small
\mathcal{O}\big(\frac{1}{\sqrt{KT}}+\frac{1}{T}+\frac{\lambda^Q+1}{K^{1/2}T^{3/2}(1-\lambda^Q)^2}\big)$
in non-convex setting for DFedSAM and DFedSAM-MGS, respectively, where
$1-\lambda$ is the spectral gap of gossip matrix and $Q$ is the number of MGS.
Empirically, our methods can achieve competitive performance compared with CFL
methods and outperform existing DFL methods.</p>
  </details>
</details>
<details>
  <summary>32. <b>标题：Taming Local Effects in Graph-based Spatiotemporal Forecasting</b></summary>
  <p><b>编号</b>：[70]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04071</p>
  <p><b>作者</b>：Andrea Cini,  Ivan Marisca,  Daniele Zambon,  Cesare Alippi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：standard univariate predictors, graph neural networks, Spatiotemporal graph neural, time series, series forecasting applications</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Spatiotemporal graph neural networks have shown to be effective in time
series forecasting applications, achieving better performance than standard
univariate predictors in several settings. These architectures take advantage
of a graph structure and relational inductive biases to learn a single (global)
inductive model to predict any number of the input time series, each associated
with a graph node. Despite the gain achieved in computational and data
efficiency w.r.t. fitting a set of local models, relying on a single global
model can be a limitation whenever some of the time series are generated by a
different spatiotemporal stochastic process. The main objective of this paper
is to understand the interplay between globality and locality in graph-based
spatiotemporal forecasting, while contextually proposing a methodological
framework to rationalize the practice of including trainable node embeddings in
such architectures. We ascribe to trainable node embeddings the role of
amortizing the learning of specialized components. Moreover, embeddings allow
for 1) effectively combining the advantages of shared message-passing layers
with node-specific parameters and 2) efficiently transferring the learned model
to new node sets. Supported by strong empirical evidence, we provide insights
and guidelines for specializing graph-based models to the dynamics of each time
series and show how this aspect plays a crucial role in obtaining accurate
predictions.</p>
  </details>
</details>
<details>
  <summary>33. <b>标题：Machine Learning for Synthetic Data Generation: a Review</b></summary>
  <p><b>编号</b>：[74]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04062</p>
  <p><b>作者</b>：Yingzhou Lu,  Huazheng Wang,  Wenqi Wei</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：machine learning, Synthetic data generation, plays a crucial, crucial role, Data</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Data plays a crucial role in machine learning. However, in real-world
applications, there are several problems with data, e.g., data are of low
quality; a limited number of data points lead to under-fitting of the machine
learning model; it is hard to access the data due to privacy, safety and
regulatory concerns. \textit{Synthetic data generation} offers a promising new
avenue, as it can be shared and used in ways that real-world data cannot. This
paper systematically reviews the existing works that leverage machine learning
models for synthetic data generation. Specifically, we discuss the synthetic
data generation works from several perspectives: (i) applications, including
computer vision, speech, natural language, healthcare, and business; (ii)
machine learning methods, particularly neural network architectures and deep
generative models; (iii) privacy and fairness issue. In addition, we identify
the challenges and opportunities in this emerging field and suggest future
research directions.</p>
  </details>
</details>
<details>
  <summary>34. <b>标题：Probabilistic Attention based on Gaussian Processes for Deep Multiple  Instance Learning</b></summary>
  <p><b>编号</b>：[75]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04061</p>
  <p><b>作者</b>：Arne Schmidt,  Pablo Morales-Álvarez,  Rafael Molina</p>
  <p><b>备注</b>：\c{opyright} 2023 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works</p>
  <p><b>关键词</b>：Multiple Instance Learning, Multiple Instance, weakly supervised learning, supervised learning paradigm, Instance Learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Multiple Instance Learning (MIL) is a weakly supervised learning paradigm
that is becoming increasingly popular because it requires less labeling effort
than fully supervised methods. This is especially interesting for areas where
the creation of large annotated datasets remains challenging, as in medicine.
Although recent deep learning MIL approaches have obtained state-of-the-art
results, they are fully deterministic and do not provide uncertainty
estimations for the predictions. In this work, we introduce the Attention
Gaussian Process (AGP) model, a novel probabilistic attention mechanism based
on Gaussian Processes for deep MIL. AGP provides accurate bag-level predictions
as well as instance-level explainability, and can be trained end-to-end.
Moreover, its probabilistic nature guarantees robustness to overfitting on
small datasets and uncertainty estimations for the predictions. The latter is
especially important in medical applications, where decisions have a direct
impact on the patient's health. The proposed model is validated experimentally
as follows. First, its behavior is illustrated in two synthetic MIL experiments
based on the well-known MNIST and CIFAR-10 datasets, respectively. Then, it is
evaluated in three different real-world cancer detection experiments. AGP
outperforms state-of-the-art MIL approaches, including deterministic deep
learning ones. It shows a strong performance even on a small dataset with less
than 100 labels and generalizes better than competing methods on an external
test set. Moreover, we experimentally show that predictive uncertainty
correlates with the risk of wrong predictions, and therefore it is a good
indicator of reliability in practice. Our code is publicly available.</p>
  </details>
</details>
<details>
  <summary>35. <b>标题：Towards Inferential Reproducibility of Machine Learning Research</b></summary>
  <p><b>编号</b>：[77]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04054</p>
  <p><b>作者</b>：Michael Hagmann,  Stefan Riezler</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：model training runs, replicated model training, machine learning evaluation, observed evaluation scores, training runs</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Reliability of machine learning evaluation -- the consistency of observed
evaluation scores across replicated model training runs -- is affected by
several sources of nondeterminism which can be regarded as measurement noise.
Current tendencies to remove noise in order to enforce reproducibility of
research results neglect inherent nondeterminism at the implementation level
and disregard crucial interaction effects between algorithmic noise factors and
data properties. This limits the scope of conclusions that can be drawn from
such experiments. Instead of removing noise, we propose to incorporate several
sources of variance, including their interaction with data properties, into an
analysis of significance and reliability of machine learning evaluation, with
the aim to draw inferences beyond particular instances of trained models. We
show how to use linear mixed effects models (LMEMs) to analyze performance
evaluation scores, and to conduct statistical inference with a generalized
likelihood ratio test (GLRT). This allows us to incorporate arbitrary sources
of noise like meta-parameter variations into statistical significance testing,
and to assess performance differences conditional on data properties.
Furthermore, a variance component analysis (VCA) enables the analysis of the
contribution of noise sources to overall variance and the computation of a
reliability coefficient by the ratio of substantial to total variance.</p>
  </details>
</details>
<details>
  <summary>36. <b>标题：Finding Short Signals in Long Irregular Time Series with Continuous-Time  Attention Policy Networks</b></summary>
  <p><b>编号</b>：[78]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04052</p>
  <p><b>作者</b>：Thomas Hartvigsen,  Jidapa Thadajarassiri,  Xiangnan Kong,  Elke Rundensteiner</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：domains like healthcare, uneven intervals, Irregularly-sampled time series, native to high-impact, high-impact domains</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Irregularly-sampled time series (ITS) are native to high-impact domains like
healthcare, where measurements are collected over time at uneven intervals.
However, for many classification problems, only small portions of long time
series are often relevant to the class label. In this case, existing ITS models
often fail to classify long series since they rely on careful imputation, which
easily over- or under-samples the relevant regions. Using this insight, we then
propose CAT, a model that classifies multivariate ITS by explicitly seeking
highly-relevant portions of an input series' timeline. CAT achieves this by
integrating three components: (1) A Moment Network learns to seek relevant
moments in an ITS's continuous timeline using reinforcement learning. (2) A
Receptor Network models the temporal dynamics of both observations and their
timing localized around predicted moments. (3) A recurrent Transition Model
models the sequence of transitions between these moments, cultivating a
representation with which the series is classified. Using synthetic and real
data, we find that CAT outperforms ten state-of-the-art methods by finding
short signals in long irregular time series.</p>
  </details>
</details>
<details>
  <summary>37. <b>标题：Automating Code-Related Tasks Through Transformers: The Impact of  Pre-training</b></summary>
  <p><b>编号</b>：[79]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04048</p>
  <p><b>作者</b>：Rosalia Tufano,  Luca Pascarella,  Gabriele Bavota</p>
  <p><b>备注</b>：Paper accepted at ICSE'23</p>
  <p><b>关键词</b>：pre-training objectives, pre-training, objectives, pre-training objectives tailored, software engineering</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Transformers have gained popularity in the software engineering (SE)
literature. These deep learning models are usually pre-trained through a
self-supervised objective, meant to provide the model with basic knowledge
about a language of interest (e.g., Java). A classic pre-training objective is
the masked language model (MLM), in which a percentage of tokens from the input
(e.g., a Java method) is masked, with the model in charge of predicting them.
Once pre-trained, the model is then fine-tuned to support the specific
downstream task of interest (e.g., code summarization). While there is evidence
suggesting the boost in performance provided by pre-training, little is known
about the impact of the specific pre-training objective(s) used. Indeed, MLM is
just one of the possible pre-training objectives and recent work from the
natural language processing field suggest that pre-training objectives tailored
for the specific downstream task of interest may substantially boost the
model's performance. In this study, we focus on the impact of pre-training
objectives on the performance of transformers when automating code-related
tasks. We start with a systematic literature review aimed at identifying the
pre-training objectives used in SE. Then, we pre-train 32 transformers using
both (i) generic pre-training objectives usually adopted in SE; and (ii)
pre-training objectives tailored to specific code-related tasks subject of our
experimentation, namely bug-fixing, code summarization, and code completion. We
also compare the pre-trained models with non pre-trained ones. Our results show
that: (i) pre-training helps in boosting performance only if the amount of
fine-tuning data available is small; (ii) the MLM objective is usually
sufficient to maximize the prediction performance of the model, even when
comparing it with pre-training objectives specialized for the downstream task
at hand.</p>
  </details>
</details>
<details>
  <summary>38. <b>标题：Rover: An online Spark SQL tuning service via generalized transfer  learning</b></summary>
  <p><b>编号</b>：[80]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04046</p>
  <p><b>作者</b>：Yu Shen,  Xinyuyang Ren,  Yupeng Lu,  Huaijun Jiang,  Huanyong Xu,  Di Peng,  Yang Li,  Wentao Zhang,  Bin Cui</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Distributed data analytic, data analytic engines, Spark SQL tuning, Spark SQL, process massive data</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Distributed data analytic engines like Spark are common choices to process
massive data in industry. However, the performance of Spark SQL highly depends
on the choice of configurations, where the optimal ones vary with the executed
workloads. Among various alternatives for Spark SQL tuning, Bayesian
optimization (BO) is a popular framework that finds near-optimal configurations
given sufficient budget, but it suffers from the re-optimization issue and is
not practical in real production. When applying transfer learning to accelerate
the tuning process, we notice two domain-specific challenges: 1) most previous
work focus on transferring tuning history, while expert knowledge from Spark
engineers is of great potential to improve the tuning performance but is not
well studied so far; 2) history tasks should be carefully utilized, where using
dissimilar ones lead to a deteriorated performance in production. In this
paper, we present Rover, a deployed online Spark SQL tuning service for
efficient and safe search on industrial workloads. To address the challenges,
we propose generalized transfer learning to boost the tuning performance based
on external knowledge, including expert-assisted Bayesian optimization and
controlled history transfer. Experiments on public benchmarks and real-world
tasks show the superiority of Rover over competitive baselines. Notably, Rover
saves an average of 50.1% of the memory cost on 12k real-world Spark SQL tasks
in 20 iterations, among which 76.2% of the tasks achieve a significant memory
reduction of over 60%.</p>
  </details>
</details>
<details>
  <summary>39. <b>标题：Sample-efficient Multi-objective Molecular Optimization with GFlowNets</b></summary>
  <p><b>编号</b>：[82]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04040</p>
  <p><b>作者</b>：Yiheng Zhu,  Jialu Wu,  Chaowen Hu,  Jiahuan Yan,  Chang-Yu Hsieh,  Tingjun Hou,  Jian Wu</p>
  <p><b>备注</b>：15 pages, 6 figures</p>
  <p><b>关键词</b>：discrete chemical space, crucial scientific problems, scientific problems involve, problems involve designing, black-box optimization problem</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Many crucial scientific problems involve designing novel molecules with
desired properties, which can be formulated as an expensive black-box
optimization problem over the discrete chemical space. Computational methods
have achieved initial success but still struggle with simultaneously optimizing
multiple competing properties in a sample-efficient manner. In this work, we
propose a multi-objective Bayesian optimization (MOBO) algorithm leveraging the
hypernetwork-based GFlowNets (HN-GFN) as an acquisition function optimizer,
with the purpose of sampling a diverse batch of candidate molecular graphs from
an approximate Pareto front. Using a single preference-conditioned
hypernetwork, HN-GFN learns to explore various trade-offs between objectives.
Inspired by reinforcement learning, we further propose a hindsight-like
off-policy strategy to share high-performing molecules among different
preferences in order to speed up learning for HN-GFN. Through synthetic
experiments, we illustrate that HN-GFN has adequate capacity to generalize over
preferences. Extensive experiments show that our framework outperforms the best
baselines by a large margin in terms of hypervolume in various real-world MOBO
settings.</p>
  </details>
</details>
<details>
  <summary>40. <b>标题：Revisit the Algorithm Selection Problem for TSP with Spatial Information  Enhanced Graph Neural Networks</b></summary>
  <p><b>编号</b>：[84]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04035</p>
  <p><b>作者</b>：Ya Song,  Laurens Bliek,  Yingqian Zhang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Traveling Salesman Problem, TSP, researchers investigate, problem, Euclidean Traveling Salesman</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Algorithm selection is a well-known problem where researchers investigate how
to construct useful features representing the problem instances and then apply
feature-based machine learning models to predict which algorithm works best
with the given instance. However, even for simple optimization problems such as
Euclidean Traveling Salesman Problem (TSP), there lacks a general and effective
feature representation for problem instances. The important features of TSP are
relatively well understood in the literature, based on extensive domain
knowledge and post-analysis of the solutions. In recent years, Convolutional
Neural Network (CNN) has become a popular approach to select algorithms for
TSP. Compared to traditional feature-based machine learning models, CNN has an
automatic feature-learning ability and demands less domain expertise. However,
it is still required to generate intermediate representations, i.e., multiple
images to represent TSP instances first. In this paper, we revisit the
algorithm selection problem for TSP, and propose a novel Graph Neural Network
(GNN), called GINES. GINES takes the coordinates of cities and distances
between cities as input. It is composed of a new message-passing mechanism and
a local neighborhood feature extractor to learn spatial information of TSP
instances. We evaluate GINES on two benchmark datasets. The results show that
GINES outperforms CNN and the original GINE models. It is better than the
traditional handcrafted feature-based approach on one dataset. The code and
dataset will be released in the final version of this paper.</p>
  </details>
</details>
<details>
  <summary>41. <b>标题：A Systematic Performance Analysis of Deep Perceptual Loss Networks  Breaks Transfer Learning Conventions</b></summary>
  <p><b>编号</b>：[86]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04032</p>
  <p><b>作者</b>：Gustav Grund Pihlgren,  Konstantina Nikolaidou,  Prakash Chandra Chhipa,  Nosheen Abid,  Rajkumar Saini,  Fredrik Sandin,  Marcus Liwicki</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Deep perceptual loss, mimic human perception, perceptual loss, Deep perceptual, loss</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep perceptual loss is a type of loss function in computer vision that aims
to mimic human perception by using the deep features extracted from neural
networks. In recent years the method has been applied to great effect on a host
of interesting computer vision tasks, especially for tasks with image or
image-like outputs. Many applications of the method use pretrained networks,
often convolutional networks, for loss calculation. Despite the increased
interest and broader use, more effort is needed toward exploring which networks
to use for calculating deep perceptual loss and from which layers to extract
the features.
This work aims to rectify this by systematically evaluating a host of
commonly used and readily available, pretrained networks for a number of
different feature extraction points on four existing use cases of deep
perceptual loss. The four use cases are implementations of previous works where
the selected networks and extraction points are evaluated instead of the
networks and extraction points used in the original work. The experimental
tasks are dimensionality reduction, image segmentation, super-resolution, and
perceptual similarity. The performance on these four tasks, attributes of the
networks, and extraction points are then used as a basis for an in-depth
analysis. This analysis uncovers essential information regarding which
architectures provide superior performance for deep perceptual loss and how to
choose an appropriate extraction point for a particular task and dataset.
Furthermore, the work discusses the implications of the results for deep
perceptual loss and the broader field of transfer learning. The results break
commonly held assumptions in transfer learning, which imply that deep
perceptual loss deviates from most transfer learning settings or that these
assumptions need a thorough re-evaluation.</p>
  </details>
</details>
<details>
  <summary>42. <b>标题：WAT: Improve the Worst-class Robustness in Adversarial Training</b></summary>
  <p><b>编号</b>：[90]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04025</p>
  <p><b>作者</b>：Boqi Li,  Weiwei Liu</p>
  <p><b>备注</b>：Accepted to AAAI 2023</p>
  <p><b>关键词</b>：Deep Neural Networks, Deep Neural, Neural Networks, DNN, Neural</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep Neural Networks (DNN) have been shown to be vulnerable to adversarial
examples. Adversarial training (AT) is a popular and effective strategy to
defend against adversarial attacks. Recent works (Benz et al., 2020; Xu et al.,
2021; Tian et al., 2021) have shown that a robust model well-trained by AT
exhibits a remarkable robustness disparity among classes, and propose various
methods to obtain consistent robust accuracy across classes. Unfortunately,
these methods sacrifice a good deal of the average robust accuracy.
Accordingly, this paper proposes a novel framework of worst-class adversarial
training and leverages no-regret dynamics to solve this problem. Our goal is to
obtain a classifier with great performance on worst-class and sacrifice just a
little average robust accuracy at the same time. We then rigorously analyze the
theoretical properties of our proposed algorithm, and the generalization error
bound in terms of the worst-class robust risk. Furthermore, we propose a
measurement to evaluate the proposed method in terms of both the average and
worst-class accuracies. Experiments on various datasets and networks show that
our proposed method outperforms the state-of-the-art approaches.</p>
  </details>
</details>
<details>
  <summary>43. <b>标题：InMyFace: Inertial and Mechanomyography-Based Sensor Fusion for Wearable  Facial Activity Recognition</b></summary>
  <p><b>编号</b>：[91]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04024</p>
  <p><b>作者</b>：Hymalai Bello,  Luis Alfredo Sanchez Marin,  Sungho Suh,  Bo Zhou,  Paul Lukowicz</p>
  <p><b>备注</b>：Submitted to Information Fusion, Elsevier</p>
  <p><b>关键词</b>：computer vision problem, Recognizing facial activity, computer vision, vision problem, Recognizing facial</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recognizing facial activity is a well-understood (but non-trivial) computer
vision problem. However, reliable solutions require a camera with a good view
of the face, which is often unavailable in wearable settings. Furthermore, in
wearable applications, where systems accompany users throughout their daily
activities, a permanently running camera can be problematic for privacy (and
legal) reasons. This work presents an alternative solution based on the fusion
of wearable inertial sensors, planar pressure sensors, and acoustic
mechanomyography (muscle sounds). The sensors were placed unobtrusively in a
sports cap to monitor facial muscle activities related to facial expressions.
We present our integrated wearable sensor system, describe data fusion and
analysis methods, and evaluate the system in an experiment with thirteen
subjects from different cultural backgrounds (eight countries) and both sexes
(six women and seven men). In a one-model-per-user scheme and using a late
fusion approach, the system yielded an average F1 score of 85.00% for the case
where all sensing modalities are combined. With a cross-user validation and a
one-model-for-all-user scheme, an F1 score of 79.00% was obtained for thirteen
participants (six females and seven males). Moreover, in a hybrid fusion
(cross-user) approach and six classes, an average F1 score of 82.00% was
obtained for eight users. The results are competitive with state-of-the-art
non-camera-based solutions for a cross-user study. In addition, our unique set
of participants demonstrates the inclusiveness and generalizability of the
approach.</p>
  </details>
</details>
<details>
  <summary>44. <b>标题：Fortuna: A Library for Uncertainty Quantification in Deep Learning</b></summary>
  <p><b>编号</b>：[93]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04019</p>
  <p><b>作者</b>：Gianluca Detommaso,  Alberto Gasparin,  Michele Donini,  Matthias Seeger,  Andrew Gordon Wilson,  Cedric Archambeau</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：open-source library, Flax-based deep neural, uncertainty quantification, deep learning, present Fortuna</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present Fortuna, an open-source library for uncertainty quantification in
deep learning. Fortuna supports a range of calibration techniques, such as
conformal prediction that can be applied to any trained neural network to
generate reliable uncertainty estimates, and scalable Bayesian inference
methods that can be applied to Flax-based deep neural networks trained from
scratch for improved uncertainty quantification and accuracy. By providing a
coherent framework for advanced uncertainty quantification methods, Fortuna
simplifies the process of benchmarking and helps practitioners build robust AI
systems.</p>
  </details>
</details>
<details>
  <summary>45. <b>标题：A Survey on Event Prediction Methods from a Systems Perspective:  Bringing Together Disparate Research Areas</b></summary>
  <p><b>编号</b>：[94]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04018</p>
  <p><b>作者</b>：Janik-Vasily Benzin,  Stefanie Rinderle-Ma</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Event prediction, event prediction methods, future real-world occurrences, future events, future</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Event prediction is the ability of anticipating future events, i.e., future
real-world occurrences, and aims to support the user in deciding on actions
that change future events towards a desired state. An event prediction method
learns the relation between features of past events and future events. It is
applied to newly observed events to predict corresponding future events that
are evaluated with respect to the user's desired future state. If the predicted
future events do not comply with this state, actions are taken towards
achieving desirable future states. Evidently, event prediction is valuable in
many application domains such as business and natural disasters. The diversity
of application domains results in a diverse range of methods that are scattered
across various research areas which, in turn, use different terminology for
event prediction methods. Consequently, sharing methods and knowledge for
developing future event prediction methods is restricted. To facilitate
knowledge sharing on account of a comprehensive classification, integration,
and assessment of event prediction methods, we combine taxonomies and take a
systems perspective to integrate event prediction methods into a single system,
elicit requirements and assess existing work with respect to the requirements.
Based on the assessment, we identify open challenges and discuss future
research directions.</p>
  </details>
</details>
<details>
  <summary>46. <b>标题：Zero-shot Sim2Real Adaptation Across Environments</b></summary>
  <p><b>编号</b>：[95]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04013</p>
  <p><b>作者</b>：Buddhika Laknath Semage,  Thommen George Karimpanal,  Santu Rana,  Svetha Venkatesh</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Simulation based learning, reinforcement learning applications, based learning, Simulation based, applications in robotics</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Simulation based learning often provides a cost-efficient recourse to
reinforcement learning applications in robotics. However, simulators are
generally incapable of accurately replicating real-world dynamics, and thus
bridging the sim2real gap is an important problem in simulation based learning.
Current solutions to bridge the sim2real gap involve hybrid simulators that are
augmented with neural residual models. Unfortunately, they require a separate
residual model for each individual environment configuration (i.e., a fixed
setting of environment variables such as mass, friction etc.), and thus are not
transferable to new environments quickly. To address this issue, we propose a
Reverse Action Transformation (RAT) policy which learns to imitate simulated
policies in the real-world. Once learnt from a single environment, RAT can then
be deployed on top of a Universal Policy Network to achieve zero-shot
adaptation to new environments. We empirically evaluate our approach in a set
of continuous control tasks and observe its advantage as a few-shot and
zero-shot learner over competing baselines.</p>
  </details>
</details>
<details>
  <summary>47. <b>标题：Systematically Finding Security Vulnerabilities in Black-Box Code  Generation Models</b></summary>
  <p><b>编号</b>：[96]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04012</p>
  <p><b>作者</b>：Hossein Hajipour,  Thorsten Holz,  Lea Schönherr,  Mario Fritz</p>
  <p><b>备注</b>：14 pages, 12 figures</p>
  <p><b>关键词</b>：models, code generation, achieved breakthroughs, programming language tasks, generation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recently, large language models for code generation have achieved
breakthroughs in several programming language tasks. Their advances in
competition-level programming problems have made them an emerging pillar in
AI-assisted pair programming. Tools such as GitHub Copilot are already part of
the daily programming workflow and are used by more than a million developers.
The training data for these models is usually collected from open-source
repositories (e.g., GitHub) that contain software faults and security
vulnerabilities. This unsanitized training data can lead language models to
learn these vulnerabilities and propagate them in the code generation
procedure. Given the wide use of these models in the daily workflow of
developers, it is crucial to study the security aspects of these models
systematically.
In this work, we propose the first approach to automatically finding security
vulnerabilities in black-box code generation models. To achieve this, we
propose a novel black-box inversion approach based on few-shot prompting. We
evaluate the effectiveness of our approach by examining code generation models
in the generation of high-risk security weaknesses. We show that our approach
automatically and systematically finds 1000s of security vulnerabilities in
various code generation models, including the commercial black-box model GitHub
Copilot.</p>
  </details>
</details>
<details>
  <summary>48. <b>标题：Investigating the role of model-based learning in exploration and  transfer</b></summary>
  <p><b>编号</b>：[97]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04009</p>
  <p><b>作者</b>：Jacob Walker,  Eszter Vértes,  Yazhe Li,  Gabriel Dulac-Arnold,  Ankesh Anand,  Théophane Weber,  Jessica B. Hamrick</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：art reinforcement learning, enabled training agents, increasing complexity, art reinforcement, enabled training</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>State of the art reinforcement learning has enabled training agents on tasks
of ever increasing complexity. However, the current paradigm tends to favor
training agents from scratch on every new task or on collections of tasks with
a view towards generalizing to novel task configurations. The former suffers
from poor data efficiency while the latter is difficult when test tasks are
out-of-distribution. Agents that can effectively transfer their knowledge about
the world pose a potential solution to these issues. In this paper, we
investigate transfer learning in the context of model-based agents.
Specifically, we aim to understand when exactly environment models have an
advantage and why. We find that a model-based approach outperforms controlled
model-free baselines for transfer learning. Through ablations, we show that
both the policy and dynamics model learnt through exploration matter for
successful transfer. We demonstrate our results across three domains which vary
in their requirements for transfer: in-distribution procedural (Crafter),
in-distribution identical (RoboDesk), and out-of-distribution (Meta-World). Our
results show that intrinsic exploration combined with environment models
present a viable direction towards agents that are self-supervised and able to
generalize to novel reward functions.</p>
  </details>
</details>
<details>
  <summary>49. <b>标题：Fully-Dynamic Approximate Decision Trees With Worst-Case Update Time  Guarantees</b></summary>
  <p><b>编号</b>：[102]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03994</p>
  <p><b>作者</b>：Marco Bressan,  Mauro Sozio</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：worst-case running time, decision tree, decision, arbitrary sequence, sequence of insertions</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We give the first algorithm that maintains an approximate decision tree over
an arbitrary sequence of insertions and deletions of labeled examples, with
strong guarantees on the worst-case running time per update request. For
instance, we show how to maintain a decision tree where every vertex has Gini
gain within an additive $\alpha$ of the optimum by performing
$O\Big(\frac{d\,(\log n)^4}{\alpha^3}\Big)$ elementary operations per update,
where $d$ is the number of features and $n$ the maximum size of the active set
(the net result of the update requests). We give similar bounds for the
information gain and the variance gain. In fact, all these bounds are
corollaries of a more general result, stated in terms of decision rules --
functions that, given a set $S$ of labeled examples, decide whether to split
$S$ or predict a label. Decision rules give a unified view of greedy decision
tree algorithms regardless of the example and label domains, and lead to a
general notion of $\epsilon$-approximate decision trees that, for natural
decision rules such as those used by ID3 or C4.5, implies the gain
approximation guarantees above. The heart of our work provides a deterministic
algorithm that, given any decision rule and any $\epsilon > 0$, maintains an
$\epsilon$-approximate tree using $O\!\left(\frac{d\, f(n)}{n}
\operatorname{poly}\frac{h}{\epsilon}\right)$ operations per update, where
$f(n)$ is the complexity of evaluating the rule over a set of $n$ examples and
$h$ is the maximum height of the maintained tree.</p>
  </details>
</details>
<details>
  <summary>50. <b>标题：Structural hierarchical learning for energy networks</b></summary>
  <p><b>编号</b>：[109]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03978</p>
  <p><b>作者</b>：Julien Leprince,  Waqas Khan,  Henrik Madsen,  Jan Kloppenborg Møller,  Wim Zeiler</p>
  <p><b>备注</b>：arXiv admin note: text overlap with arXiv:2301.12967</p>
  <p><b>关键词</b>：nowadays require accurate, sectors nowadays require, effectively operate, nowadays require, require accurate</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Many sectors nowadays require accurate and coherent predictions across their
organization to effectively operate. Otherwise, decision-makers would be
planning using disparate views of the future, resulting in inconsistent
decisions across their sectors. To secure coherency across hierarchies, recent
research has put forward hierarchical learning, a coherency-informed
hierarchical regressor leveraging the power of machine learning thanks to a
custom loss function founded on optimal reconciliation methods. While promising
potentials were outlined, results exhibited discordant performances in which
coherency information only improved hierarchical forecasts in one setting. This
work proposes to tackle these obstacles by investigating custom neural network
designs inspired by the topological structures of hierarchies. Results unveil
that, in a data-limited setting, structural models with fewer connections
perform overall best and demonstrate the coherency information value for both
accuracy and coherency forecasting performances, provided individual forecasts
were generated within reasonable accuracy limits. Overall, this work expands
and improves hierarchical learning methods thanks to a structurally-scaled
learning mechanism extension coupled with tailored network designs, producing a
resourceful, data-efficient, and information-rich learning process.</p>
  </details>
</details>
<details>
  <summary>51. <b>标题：Non-zero-sum Game Control for Multi-vehicle Driving via Reinforcement  Learning</b></summary>
  <p><b>编号</b>：[114]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03958</p>
  <p><b>作者</b>：Xujie Song,  Zexi Lin</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：affected by surrounding, surrounding vehicles, vehicles, Nash equilibrium, driving</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>When a vehicle drives on the road, its behaviors will be affected by
surrounding vehicles. Prediction and decision should not be considered as two
separate stages because all vehicles make decisions interactively. This paper
constructs the multi-vehicle driving scenario as a non-zero-sum game and
proposes a novel game control framework, which consider prediction, decision
and control as a whole. The mutual influence of interactions between vehicles
is considered in this framework because decisions are made by Nash equilibrium
strategy. To efficiently obtain the strategy, ADP, a model-based reinforcement
learning method, is used to solve coupled Hamilton-Jacobi-Bellman equations.
Driving performance is evaluated by tracking, efficiency, safety and comfort
indices. Experiments show that our algorithm could drive perfectly by directly
controlling acceleration and steering angle. Vehicles could learn interactive
behaviors such as overtaking and pass. In summary, we propose a non-zero-sum
game framework for modeling multi-vehicle driving, provide an effective way to
solve the Nash equilibrium driving strategy, and validate at non-signalized
intersections.</p>
  </details>
</details>
<details>
  <summary>52. <b>标题：Cut your Losses with Squentropy</b></summary>
  <p><b>编号</b>：[119]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03952</p>
  <p><b>作者</b>：Like Hui,  Mikhail Belkin,  Stephen Wright</p>
  <p><b>备注</b>：18 pages, 16 figures, 6 tables</p>
  <p><b>关键词</b>：practical neural models, square loss, loss, practical neural, cross-entropy loss</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Nearly all practical neural models for classification are trained using
cross-entropy loss. Yet this ubiquitous choice is supported by little
theoretical or empirical evidence. Recent work (Hui & Belkin, 2020) suggests
that training using the (rescaled) square loss is often superior in terms of
the classification accuracy. In this paper we propose the "squentropy" loss,
which is the sum of two terms: the cross-entropy loss and the average square
loss over the incorrect classes. We provide an extensive set of experiments on
multi-class classification problems showing that the squentropy loss
outperforms both the pure cross entropy and rescaled square losses in terms of
the classification accuracy. We also demonstrate that it provides significantly
better model calibration than either of these alternative losses and,
furthermore, has less variance with respect to the random initialization.
Additionally, in contrast to the square loss, squentropy loss can typically be
trained using exactly the same optimization parameters, including the learning
rate, as the standard cross-entropy loss, making it a true "plug-and-play"
replacement. Finally, unlike the rescaled square loss, multiclass squentropy
contains no parameters that need to be adjusted.</p>
  </details>
</details>
<details>
  <summary>53. <b>标题：Graph Signal Sampling for Inductive One-Bit Matrix Completion: a  Closed-form Solution</b></summary>
  <p><b>编号</b>：[126]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03933</p>
  <p><b>作者</b>：Chao Chen,  Haoyu Geng,  Gang Zeng,  Zhaobing Han,  Hua Chai,  Xiaokang Yang,  Junchi Yan</p>
  <p><b>备注</b>：Published in ICLR 2023</p>
  <p><b>关键词</b>：Inductive one-bit matrix, one-bit matrix completion, graph signal sampling, graph signal, Inductive one-bit</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Inductive one-bit matrix completion is motivated by modern applications such
as recommender systems, where new users would appear at test stage with the
ratings consisting of only ones and no zeros. We propose a unified graph signal
sampling framework which enjoys the benefits of graph signal analysis and
processing. The key idea is to transform each user's ratings on the items to a
function (signal) on the vertices of an item-item graph, then learn structural
graph properties to recover the function from its values on certain vertices --
the problem of graph signal sampling. We propose a class of regularization
functionals that takes into account discrete random label noise in the graph
vertex domain, then develop the GS-IMC approach which biases the reconstruction
towards functions that vary little between adjacent vertices for noise
reduction. Theoretical result shows that accurate reconstructions can be
achieved under mild conditions. For the online setting, we develop a Bayesian
extension, i.e., BGS-IMC which considers continuous random Gaussian noise in
the graph Fourier domain and builds upon a prediction-correction update
algorithm to obtain the unbiased and minimum-variance reconstruction. Both
GS-IMC and BGS-IMC have closed-form solutions and thus are highly scalable in
large data. Experiments show that our methods achieve state-of-the-art
performance on public benchmarks.</p>
  </details>
</details>
<details>
  <summary>54. <b>标题：Multi-view Feature Extraction based on Dual Contrastive Head</b></summary>
  <p><b>编号</b>：[127]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03932</p>
  <p><b>作者</b>：Hongjie Zhang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：highdimensional multi-view data, multi-view data, highdimensional multi-view, Multi-view feature extraction, efficient approach</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Multi-view feature extraction is an efficient approach for alleviating the
issue of dimensionality in highdimensional multi-view data. Contrastive
learning (CL), which is a popular self-supervised learning method, has recently
attracted considerable attention. Most CL-based methods were constructed only
from the sample level. In this study, we propose a novel multiview feature
extraction method based on dual contrastive head, which introduce
structural-level contrastive loss into sample-level CL-based method.
Structural-level CL push the potential subspace structures consistent in any
two cross views, which assists sample-level CL to extract discriminative
features more effectively. Furthermore, it is proven that the relationships
between structural-level CL and mutual information and probabilistic intraand
inter-scatter, which provides the theoretical support for the excellent
performance. Finally, numerical experiments on six real datasets demonstrate
the superior performance of the proposed method compared to existing methods.</p>
  </details>
</details>
<details>
  <summary>55. <b>标题：A Model for Forecasting Air Quality Index in Port Harcourt Nigeria Using  Bi-LSTM Algorithm</b></summary>
  <p><b>编号</b>：[128]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03930</p>
  <p><b>作者</b>：O. E. Taylor,  P. S. Ezekiel</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：toxic gases, harmful gases, Bi-directional LSTM model, release of toxic, concentration of harmful</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The release of toxic gases by industries, emissions from vehicles, and an
increase in the concentration of harmful gases and particulate matter in the
atmosphere are all contributing factors to the deterioration of the quality of
the air. Factors such as industries, urbanization, population growth, and the
increased use of vehicles contribute to the rapid increase in pollution levels,
which can adversely impact human health. This paper presents a model for
forecasting the air quality index in Nigeria using the Bi-directional LSTM
model. The air pollution data was downloaded from an online database (UCL). The
dataset was pre-processed using both pandas tools in python. The pre-processed
result was used as input features in training a Bi-LSTM model in making future
forecasts of the values of the particulate matter Pm2.5, and Pm10. The Bi-LSTM
model was evaluated using some evaluation parameters such as mean square error,
mean absolute error, absolute mean square, and R^2 square. The result of the
Bi-LSTM shows a mean square error of 52.99%, relative mean square error of
7.28%, mean absolute error of 3.4%, and R^2 square of 97%. The model. This
shows that the model follows a seamless trend in forecasting the air quality in
Port Harcourt, Nigeria.</p>
  </details>
</details>
<details>
  <summary>56. <b>标题：Predictable MDP Abstraction for Unsupervised Model-Based RL</b></summary>
  <p><b>编号</b>：[132]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03921</p>
  <p><b>作者</b>：Seohong Park,  Sergey Levine</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：key component, predicts the outcomes, model-based reinforcement learning, Markov decision processes, complex Markov decision</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A key component of model-based reinforcement learning (RL) is a dynamics
model that predicts the outcomes of actions. Errors in this predictive model
can degrade the performance of model-based controllers, and complex Markov
decision processes (MDPs) can present exceptionally difficult prediction
problems. To mitigate this issue, we propose predictable MDP abstraction (PMA):
instead of training a predictive model on the original MDP, we train a model on
a transformed MDP with a learned action space that only permits predictable,
easy-to-model actions, while covering the original state-action space as much
as possible. As a result, model learning becomes easier and more accurate,
which allows robust, stable model-based planning or model-based RL. This
transformation is learned in an unsupervised manner, before any task is
specified by the user. Downstream tasks can then be solved with model-based
control in a zero-shot fashion, without additional environment interactions. We
theoretically analyze PMA and empirically demonstrate that PMA leads to
significant improvements over prior unsupervised model-based RL approaches in a
range of benchmark environments. Our code and videos are available at
this https URL</p>
  </details>
</details>
<details>
  <summary>57. <b>标题：Noise2Music: Text-conditioned Music Generation with Diffusion Models</b></summary>
  <p><b>编号</b>：[135]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03917</p>
  <p><b>作者</b>：Qingqing Huang,  Daniel S. Park,  Tao Wang,  Timo I. Denk,  Andy Ly,  Nanxin Chen,  Zhengdong Zhang,  Zhishuai Zhang,  Jiahui Yu,  Christian Frank,  Jesse Engel,  Quoc V. Le,  William Chan,  Wei Han</p>
  <p><b>备注</b>：15 pages</p>
  <p><b>关键词</b>：diffusion models, generate high-fidelity music, intermediate representation, generate high-quality, text</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We introduce Noise2Music, where a series of diffusion models is trained to
generate high-quality 30-second music clips from text prompts. Two types of
diffusion models, a generator model, which generates an intermediate
representation conditioned on text, and a cascader model, which generates
high-fidelity audio conditioned on the intermediate representation and possibly
the text, are trained and utilized in succession to generate high-fidelity
music. We explore two options for the intermediate representation, one using a
spectrogram and the other using audio with lower fidelity. We find that the
generated audio is not only able to faithfully reflect key elements of the text
prompt such as genre, tempo, instruments, mood, and era, but goes beyond to
ground fine-grained semantics of the prompt. Pretrained large language models
play a key role in this story -- they are used to generate paired text for the
audio of the training set and to extract embeddings of the text prompts
ingested by the diffusion models.
Generated examples: this https URL</p>
  </details>
</details>
<details>
  <summary>58. <b>标题：QS-ADN: Quasi-Supervised Artifact Disentanglement Network for Low-Dose  CT Image Denoising by Local Similarity Among Unpaired Data</b></summary>
  <p><b>编号</b>：[136]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03916</p>
  <p><b>作者</b>：Yuhui Ruan,  Qiao Yuan,  Chuang Niu,  Chen Li,  Yudong Yao,  Ge Wang,  Yueyang Teng</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：potential radiation risk, reducing potential radiation, LDCT denoising, LDCT, supervised LDCT denoising</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep learning has been successfully applied to low-dose CT (LDCT) image
denoising for reducing potential radiation risk. However, the widely reported
supervised LDCT denoising networks require a training set of paired images,
which is expensive to obtain and cannot be perfectly simulated. Unsupervised
learning utilizes unpaired data and is highly desirable for LDCT denoising. As
an example, an artifact disentanglement network (ADN) relies on unparied images
and obviates the need for supervision but the results of artifact reduction are
not as good as those through supervised this http URL important observation is
that there is often hidden similarity among unpaired data that can be utilized.
This paper introduces a new learning mode, called quasi-supervised learning, to
empower the ADN for LDCT image denoising.For every LDCT image, the best matched
image is first found from an unpaired normal-dose CT (NDCT) dataset. Then, the
matched pairs and the corresponding matching degree as prior information are
used to construct and train our ADN-type network for LDCT denoising.The
proposed method is different from (but compatible with) supervised and
semi-supervised learning modes and can be easily implemented by modifying
existing networks. The experimental results show that the method is competitive
with state-of-the-art methods in terms of noise suppression and contextual
fidelity. The code and working dataset are publicly available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>59. <b>标题：Zero-shot Generation of Coherent Storybook from Plain Text Story using  Diffusion Models</b></summary>
  <p><b>编号</b>：[144]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03900</p>
  <p><b>作者</b>：Hyeonho Jeong,  Gihyun Kwon,  Jong Chul Ye</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：human-devised natural language, Recent advancements, opened new possibilities, possibilities for guiding, guiding the creation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent advancements in large scale text-to-image models have opened new
possibilities for guiding the creation of images through human-devised natural
language. However, while prior literature has primarily focused on the
generation of individual images, it is essential to consider the capability of
these models to ensure coherency within a sequence of images to fulfill the
demands of real-world applications such as storytelling. To address this, here
we present a novel neural pipeline for generating a coherent storybook from the
plain text of a story. Specifically, we leverage a combination of a pre-trained
Large Language Model and a text-guided Latent Diffusion Model to generate
coherent images. While previous story synthesis frameworks typically require a
large-scale text-to-image model trained on expensive image-caption pairs to
maintain the coherency, we employ simple textual inversion techniques along
with detector-based semantic image editing which allows zero-shot generation of
the coherent storybook. Experimental results show that our proposed method
outperforms state-of-the-art image editing baselines.</p>
  </details>
</details>
<details>
  <summary>60. <b>标题：Approximately Optimal Core Shapes for Tensor Decompositions</b></summary>
  <p><b>编号</b>：[147]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03886</p>
  <p><b>作者</b>：Mehrdad Ghadiri,  Matthew Fahrbach,  Gang Fu,  Vahab Mirrokni</p>
  <p><b>备注</b>：18 pages, 4 figures</p>
  <p><b>关键词</b>：called multilinear rank, core tensor shape, combinatorial optimization problem, optimal core tensor, multilinear rank</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This work studies the combinatorial optimization problem of finding an
optimal core tensor shape, also called multilinear rank, for a size-constrained
Tucker decomposition. We give an algorithm with provable approximation
guarantees for its reconstruction error via connections to higher-order
singular values. Specifically, we introduce a novel Tucker packing problem,
which we prove is NP-hard, and give a polynomial-time approximation scheme
based on a reduction to the 2-dimensional knapsack problem with a matroid
constraint. We also generalize our techniques to tree tensor network
decompositions. We implement our algorithm using an integer programming solver,
and show that its solution quality is competitive with (and sometimes better
than) the greedy algorithm that uses the true Tucker decomposition loss at each
step, while also running up to 1000x faster.</p>
  </details>
</details>
<details>
  <summary>61. <b>标题：Classification of Methods to Reduce Clinical Alarm Signals for Remote  Patient Monitoring: A Critical Review</b></summary>
  <p><b>编号</b>：[148]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03885</p>
  <p><b>作者</b>：Teena Arora,  Venki Balasubramanian,  Andrew Stranieri,  Shenhan Mai,  Rajkumar Buyya,  Sardar Islam</p>
  <p><b>备注</b>：25 pages, 6 figures</p>
  <p><b>关键词</b>：Remote Patient Monitoring, Patient Monitoring, emerging technology paradigm, reduce clinician workload, Remote Patient</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Remote Patient Monitoring (RPM) is an emerging technology paradigm that helps
reduce clinician workload by automated monitoring and raising intelligent alarm
signals. High sensitivity and intelligent data-processing algorithms used in
RPM devices result in frequent false-positive alarms, resulting in alarm
fatigue. This study aims to critically review the existing literature to
identify the causes of these false-positive alarms and categorize the various
interventions used in the literature to eliminate these causes. That act as a
catalog and helps in false alarm reduction algorithm design. A step-by-step
approach to building an effective alarm signal generator for clinical use has
been proposed in this work. Second, the possible causes of false-positive
alarms amongst RPM applications were analyzed from the literature. Third, a
critical review has been done of the various interventions used in the
literature depending on causes and classification based on four major
approaches: clinical knowledge, physiological data, medical sensor devices, and
clinical environments. A practical clinical alarm strategy could be developed
by following our pentagon approach. The first phase of this approach emphasizes
identifying the various causes for the high number of false-positive alarms.
Future research will focus on developing a false alarm reduction method using
data mining.</p>
  </details>
</details>
<details>
  <summary>62. <b>标题：DIFF2: Differential Private Optimization via Gradient Differences for  Nonconvex Distributed Learning</b></summary>
  <p><b>编号</b>：[149]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03884</p>
  <p><b>作者</b>：Tomoya Murata,  Taiji Suzuki</p>
  <p><b>备注</b>：24 pages, 980.31 KB</p>
  <p><b>关键词</b>：Differential private optimization, Differential private, private optimization, Differential Private Gradient, Private Gradient Descent</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Differential private optimization for nonconvex smooth objective is
considered. In the previous work, the best known utility bound is $\widetilde
O(\sqrt{d}/(n\varepsilon_\mathrm{DP}))$ in terms of the squared full gradient
norm, which is achieved by Differential Private Gradient Descent (DP-GD) as an
instance, where $n$ is the sample size, $d$ is the problem dimensionality and
$\varepsilon_\mathrm{DP}$ is the differential privacy parameter. To improve the
best known utility bound, we propose a new differential private optimization
framework called \emph{DIFF2 (DIFFerential private optimization via gradient
DIFFerences)} that constructs a differential private global gradient estimator
with possibly quite small variance based on communicated \emph{gradient
differences} rather than gradients themselves. It is shown that DIFF2 with a
gradient descent subroutine achieves the utility of $\widetilde
O(d^{2/3}/(n\varepsilon_\mathrm{DP})^{4/3})$, which can be significantly better
than the previous one in terms of the dependence on the sample size $n$. To the
best of our knowledge, this is the first fundamental result to improve the
standard utility $\widetilde O(\sqrt{d}/(n\varepsilon_\mathrm{DP}))$ for
nonconvex objectives. Additionally, a more computational and communication
efficient subroutine is combined with DIFF2 and its theoretical analysis is
also given. Numerical experiments are conducted to validate the superiority of
DIFF2 framework.</p>
  </details>
</details>
<details>
  <summary>63. <b>标题：On Generalized Degree Fairness in Graph Neural Networks</b></summary>
  <p><b>编号</b>：[151]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03881</p>
  <p><b>作者</b>：Zemin Liu,  Trung-Kien Nguyen,  Yuan Fang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：including node attributes, Conventional graph neural, node, neighbors surrounding, Conventional graph</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Conventional graph neural networks (GNNs) are often confronted with fairness
issues that may stem from their input, including node attributes and neighbors
surrounding a node. While several recent approaches have been proposed to
eliminate the bias rooted in sensitive attributes, they ignore the other key
input of GNNs, namely the neighbors of a node, which can introduce bias since
GNNs hinge on neighborhood structures to generate node representations. In
particular, the varying neighborhood structures across nodes, manifesting
themselves in drastically different node degrees, give rise to the diverse
behaviors of nodes and biased outcomes. In this paper, we first define and
generalize the degree bias using a generalized definition of node degree as a
manifestation and quantification of different multi-hop structures around
different nodes. To address the bias in the context of node classification, we
propose a novel GNN framework called Generalized Degree Fairness-centric Graph
Neural Network (Deg-FairGNN). Specifically, in each GNN layer, we employ a
learnable debiasing function to generate debiasing contexts, which modulate the
layer-wise neighborhood aggregation to eliminate the degree bias originating
from the diverse degrees among nodes. Extensive experiments on three benchmark
datasets demonstrate the effectiveness of our model on both accuracy and
fairness metrics.</p>
  </details>
</details>
<details>
  <summary>64. <b>标题：Neural Artistic Style Transfer with Conditional Adversaria</b></summary>
  <p><b>编号</b>：[153]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03875</p>
  <p><b>作者</b>：P. N. Deelaka</p>
  <p><b>备注</b>：Conditional Adversarial Generative Network based novel style transfer model</p>
  <p><b>关键词</b>：artistic style transformation, style, modify the appearance, image, model</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A neural artistic style transformation (NST) model can modify the appearance
of a simple image by adding the style of a famous image. Even though the
transformed images do not look precisely like artworks by the same artist of
the respective style images, the generated images are appealing. Generally, a
trained NST model specialises in a style, and a single image represents that
style. However, generating an image under a new style is a tedious process,
which includes full model training. In this paper, we present two methods that
step toward the style image independent neural style transfer model. In other
words, the trained model could generate semantically accurate generated image
under any content, style image input pair. Our novel contribution is a
unidirectional-GAN model that ensures the Cyclic consistency by the model
architecture.Furthermore, this leads to much smaller model size and an
efficient training and validation phase.</p>
  </details>
</details>
<details>
  <summary>65. <b>标题：Participatory Systems for Personalized Prediction</b></summary>
  <p><b>编号</b>：[154]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03874</p>
  <p><b>作者</b>：Hailey James,  Chirag Nagpal,  Katherine Heller,  Berk Ustun</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：costly to acquire, Machine learning models, participatory systems, Machine learning, participatory</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Machine learning models are often personalized based on information that is
protected, sensitive, self-reported, or costly to acquire. These models use
information about people, but do not facilitate nor inform their
\emph{consent}. Individuals cannot opt out of reporting information that a
model needs to personalize their predictions, nor tell if they would benefit
from personalization in the first place. In this work, we introduce a new
family of prediction models, called \emph{participatory systems}, that allow
individuals to opt into personalization at prediction time. We present a
model-agnostic algorithm to learn participatory systems for supervised learning
tasks where models are personalized with categorical group attributes. We
conduct a comprehensive empirical study of participatory systems in clinical
prediction tasks, comparing them to common approaches for personalization and
imputation. Our results demonstrate that participatory systems can facilitate
and inform consent in a way that improves performance and privacy across all
groups who report personal data.</p>
  </details>
</details>
<details>
  <summary>66. <b>标题：DeepVATS: Deep Visual Analytics for Time Series</b></summary>
  <p><b>编号</b>：[158]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03858</p>
  <p><b>作者</b>：Victor Rodriguez-Fernandez,  David Montalvo,  Francesco Piccialli,  Grzegorz J. Nalepa,  David Camacho</p>
  <p><b>备注</b>：Submitted to Elsevier's Knowledge Based Systems journal. Code available at this https URL</p>
  <p><b>关键词</b>：Deep Visual Analytics, Visual Interactive Systems, deep learning techniques, developing Visual Interactive, Interactive Systems supported</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The field of Deep Visual Analytics (DVA) has recently arisen from the idea of
developing Visual Interactive Systems supported by deep learning techniques, in
order to provide them with large-scale data processing capabilities and to
unify their implementation across different data modalities and domains of
application. In this paper we present DeepVATS, an open-source tool that brings
the field of DVA into time series data. DeepVATS trains, in a self-supervised
way, a masked time series autoencoder that reconstructs patches of a time
series, and projects the knowledge contained in the embeddings of that model in
an interactive plot, from which time series patterns and anomalies emerge and
can be easily spotted. The tool has been tested on both synthetic and real
datasets, and its code is publicly available on
this https URL</p>
  </details>
</details>
<details>
  <summary>67. <b>标题：Efficient Adversarial Contrastive Learning via Robustness-Aware Coreset  Selection</b></summary>
  <p><b>编号</b>：[159]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03857</p>
  <p><b>作者</b>：Xilie Xu,  Jingfeng Zhang,  Feng Liu,  Masashi Sugiyama,  Mohan Kankanhalli</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Adversarial contrastive learning, withstands adversarial attacks, expensive data annotations, require expensive data, contrastive learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Adversarial contrastive learning (ACL) does not require expensive data
annotations but outputs a robust representation that withstands adversarial
attacks and also generalizes to a wide range of downstream tasks. However, ACL
needs tremendous running time to generate the adversarial variants of all
training data, which limits its scalability to large datasets. To speed up ACL,
this paper proposes a robustness-aware coreset selection (RCS) method. RCS does
not require label information and searches for an informative subset that
minimizes a representational divergence, which is the distance of the
representation between natural data and their virtual adversarial variants. The
vanilla solution of RCS via traversing all possible subsets is computationally
prohibitive. Therefore, we theoretically transform RCS into a surrogate problem
of submodular maximization, of which the greedy search is an efficient solution
with an optimality guarantee for the original problem. Empirically, our
comprehensive results corroborate that RCS can speed up ACL by a large margin
without significantly hurting the robustness and standard transferability.
Notably, to the best of our knowledge, we are the first to conduct ACL
efficiently on the large-scale ImageNet-1K dataset to obtain an effective
robust representation via RCS.</p>
  </details>
</details>
<details>
  <summary>68. <b>标题：ED-Batch: Efficient Automatic Batching of Dynamic Neural Networks via  Learned Finite State Machines</b></summary>
  <p><b>编号</b>：[160]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03851</p>
  <p><b>作者</b>：Siyuan Chen,  Pratik Fegade,  Tianqi Chen,  Phillip B. Gibbons,  Todd C. Mowry</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：deep neural network, neural network, fundamental influence, efficiency of deep, deep neural</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Batching has a fundamental influence on the efficiency of deep neural network
(DNN) execution. However, for dynamic DNNs, efficient batching is particularly
challenging as the dataflow graph varies per input instance. As a result,
state-of-the-art frameworks use heuristics that result in suboptimal batching
decisions. Further, batching puts strict restrictions on memory adjacency and
can lead to high data movement costs. In this paper, we provide an approach for
batching dynamic DNNs based on finite state machines, which enables the
automatic discovery of batching policies specialized for each DNN via
reinforcement learning. Moreover, we find that memory planning that is aware of
the batching policy can save significant data movement overheads, which is
automated by a PQ tree-based algorithm we introduce. Experimental results show
that our framework speeds up state-of-the-art frameworks by on average 1.15x,
1.39x, and 2.45x for chain-based, tree-based, and lattice-based DNNs across CPU
and GPU.</p>
  </details>
</details>
<details>
  <summary>69. <b>标题：Two-step hyperparameter optimization method: Accelerating hyperparameter  search by using a fraction of a training dataset</b></summary>
  <p><b>编号</b>：[162]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03845</p>
  <p><b>作者</b>：Sungduk Yu,  Mike Pritchard,  Po-Lun Ma,  Balwinder Singh,  Sam Silva</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：two-step HPO method, HPO, two-step HPO, HPO method, practice is archaic</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Hyperparameter optimization (HPO) can be an important step in machine
learning model development, but our common practice is archaic -- primarily
using a manual or grid search. This is partly because adopting an advanced HPO
algorithm entails extra complexity to workflow and longer computation time.
This imposes a significant hurdle to machine learning (ML) applications since
the choice of suboptimal hyperparameters limits the performance of ML models,
ultimately failing to harness the full potential of ML techniques. In this
article, we present a two-step HPO method as a strategy to minimize compute and
wait time as a lesson learned during applied ML parameterization work. A
preliminary evaluation of hyperparameters is first conducted on a small subset
of a training dataset, then top-performing candidate models are re-evaluated
after retraining with an entire training dataset. This two-step HPO method can
be applied to any HPO search algorithm, and we argue it has attractive
efficiencies. As a case study, we present our recent application of the
two-step HPO method to the development of neural network emulators of aerosol
activation. Using only 5% of a training dataset in the initial step is
sufficient to find optimal hyperparameter configurations from much more
extensive sampling. The benefits of HPO are then revealed by analysis of
hyperparameters and model performance, revealing a minimal model complexity
required to achieve the best performance, and the diversity of top-performing
models harvested from the HPO process allows us to choose a high-performing
model with a low inference cost for efficient use in GCMs.</p>
  </details>
</details>
<details>
  <summary>70. <b>标题：Topological Deep Learning: A Review of an Emerging Paradigm</b></summary>
  <p><b>编号</b>：[165]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03836</p>
  <p><b>作者</b>：Ali Zia,  Abdelwahed Khamis,  James Nichols,  Zeeshan Hayder,  Vivien Rolland,  Lars Petersson</p>
  <p><b>备注</b>：7 pages and 2 references</p>
  <p><b>关键词</b>：deep learning, Topological data analysis, deep, learning, TDA</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Topological data analysis (TDA) provides insight into data shape. The
summaries obtained by these methods are principled global descriptions of
multi-dimensional data whilst exhibiting stable properties such as robustness
to deformation and noise. Such properties are desirable in deep learning
pipelines but they are typically obtained using non-TDA strategies. This is
partly caused by the difficulty of combining TDA constructs (e.g. barcode and
persistence diagrams) with current deep learning algorithms. Fortunately, we
are now witnessing a growth of deep learning applications embracing
topologically-guided components. In this survey, we review the nascent field of
topological deep learning by first revisiting the core concepts of TDA. We then
explore how the use of TDA techniques has evolved over time to support deep
learning frameworks, and how they can be integrated into different aspects of
deep learning. Furthermore, we touch on TDA usage for analyzing existing deep
models; deep topological analytics. Finally, we discuss the challenges and
future prospects of topological deep learning.</p>
  </details>
</details>
<details>
  <summary>71. <b>标题：Decentralized Riemannian Algorithm for Nonconvex Minimax Problems</b></summary>
  <p><b>编号</b>：[167]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03825</p>
  <p><b>作者</b>：Xidong Wu,  Zhengmian Hu,  Heng Huang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：robust dimensionality reduction, possibly nonconvex constraints, nonconvex constraints, Riemannian minimax problems, nonconvex minimax problems</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The minimax optimization over Riemannian manifolds (possibly nonconvex
constraints) has been actively applied to solve many problems, such as robust
dimensionality reduction and deep neural networks with orthogonal weights
(Stiefel manifold). Although many optimization algorithms for minimax problems
have been developed in the Euclidean setting, it is difficult to convert them
into Riemannian cases, and algorithms for nonconvex minimax problems with
nonconvex constraints are even rare. On the other hand, to address the big data
challenges, decentralized (serverless) training techniques have recently been
emerging since they can reduce communications overhead and avoid the bottleneck
problem on the server node. Nonetheless, the algorithm for decentralized
Riemannian minimax problems has not been studied. In this paper, we study the
distributed nonconvex-strongly-concave minimax optimization problem over the
Stiefel manifold and propose both deterministic and stochastic minimax methods.
The local model is non-convex strong-concave and the Steifel manifold is a
non-convex set. The global function is represented as the finite sum of local
functions. For the deterministic setting, we propose DRGDA and prove that our
deterministic method achieves a gradient complexity of $O( \epsilon^{-2})$
under mild conditions. For the stochastic setting, we propose DRSGDA and prove
that our stochastic method achieves a gradient complexity of
$O(\epsilon^{-4})$. The DRGDA and DRSGDA are the first algorithms for
distributed minimax optimization with nonconvex constraints with exact
convergence. Extensive experimental results on the Deep Neural Networks (DNNs)
training over the Stiefel manifold demonstrate the efficiency of our
algorithms.</p>
  </details>
</details>
<details>
  <summary>72. <b>标题：Clinical BioBERT Hyperparameter Optimization using Genetic Algorithm  Clinical BioBERT Hyperparameter Optimization using Genetic Algorithm</b></summary>
  <p><b>编号</b>：[168]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03822</p>
  <p><b>作者</b>：Navya Martin Kollapally,  James Geller</p>
  <p><b>备注</b>：Under review as regular paper</p>
  <p><b>关键词</b>：individual health outcomes, small portion, Clinical factors account, affect an individual, health outcomes</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Clinical factors account only for a small portion, about 10-30%, of the
controllable factors that affect an individual's health outcomes. The remaining
factors include where a person was born and raised, where he/she pursued their
education, what their work and family environment is like, etc. These factors
are collectively referred to as Social Determinants of Health (SDoH). The
majority of SDoH data is recorded in unstructured clinical notes by physicians
and practitioners. Recording SDoH data in a structured manner (in an EHR) could
greatly benefit from a dedicated ontology of SDoH terms. Our research focuses
on extracting sentences from clinical notes, making use of such an SDoH
ontology (called SOHO) to provide appropriate concepts. We utilize recent
advancements in Deep Learning to optimize the hyperparameters of a Clinical
BioBERT model for SDoH text. A genetic algorithm-based hyperparameter tuning
regimen was implemented to identify optimal parameter settings. To implement a
complete classifier, we pipelined Clinical BioBERT with two subsequent linear
layers and two dropout layers. The output predicts whether a text fragment
describes an SDoH issue of the patient. We compared the AdamW, Adafactor, and
LAMB optimizers. In our experiments, AdamW outperformed the others in terms of
accuracy.</p>
  </details>
</details>
<details>
  <summary>73. <b>标题：PASTA: Pessimistic Assortment Optimization</b></summary>
  <p><b>编号</b>：[169]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03821</p>
  <p><b>作者</b>：Juncheng Dong,  Weibin Mo,  Zhengling Qi,  Cong Shi,  Ethan X. Fang,  Vahid Tarokh</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：assortment optimization, Pessimistic ASsortment opTimizAtion, assortment optimization problem, offline assortment optimization, assortment</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We consider a class of assortment optimization problems in an offline
data-driven setting. A firm does not know the underlying customer choice model
but has access to an offline dataset consisting of the historically offered
assortment set, customer choice, and revenue. The objective is to use the
offline dataset to find an optimal assortment. Due to the combinatorial nature
of assortment optimization, the problem of insufficient data coverage is likely
to occur in the offline dataset. Therefore, designing a provably efficient
offline learning algorithm becomes a significant challenge. To this end, we
propose an algorithm referred to as Pessimistic ASsortment opTimizAtion (PASTA
for short) designed based on the principle of pessimism, that can correctly
identify the optimal assortment by only requiring the offline data to cover the
optimal assortment under general settings. In particular, we establish a regret
bound for the offline assortment optimization problem under the celebrated
multinomial logit model. We also propose an efficient computational procedure
to solve our pessimistic assortment optimization problem. Numerical studies
demonstrate the superiority of the proposed method over the existing baseline
method.</p>
  </details>
</details>
<details>
  <summary>74. <b>标题：The XPRESS Challenge: Xray Projectomic Reconstruction -- Extracting  Segmentation with Skeletons</b></summary>
  <p><b>编号</b>：[171]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03819</p>
  <p><b>作者</b>：Tri Nguyen,  Mukul Narwani,  Mark Larson,  Yicong Li,  Shuhan Xie,  Hanspeter Pfister,  Donglai Wei,  Nir Shavit,  Lu Mi,  Alexandra Pacureanu,  Wei-Chung Lee,  Aaron T. Kuan</p>
  <p><b>备注</b>：6 pages, 2 figures</p>
  <p><b>关键词</b>：nervous system, neurons form, form a structural, structural basis, XNH</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The wiring and connectivity of neurons form a structural basis for the
function of the nervous system. Advances in volume electron microscopy (EM) and
image segmentation have enabled mapping of circuit diagrams (connectomics)
within local regions of the mouse brain. However, applying volume EM over the
whole brain is not currently feasible due to technological challenges. As a
result, comprehensive maps of long-range connections between brain regions are
lacking. Recently, we demonstrated that X-ray holographic nanotomography (XNH)
can provide high-resolution images of brain tissue at a much larger scale than
EM. In particular, XNH is wellsuited to resolve large, myelinated axon tracts
(white matter) that make up the bulk of long-range connections (projections)
and are critical for inter-region communication. Thus, XNH provides an imaging
solution for brain-wide projectomics. However, because XNH data is typically
collected at lower resolutions and larger fields-of-view than EM, accurate
segmentation of XNH images remains an important challenge that we present here.
In this task, we provide volumetric XNH images of cortical white matter axons
from the mouse brain along with ground truth annotations for axon trajectories.
Manual voxel-wise annotation of ground truth is a time-consuming bottleneck for
training segmentation networks. On the other hand, skeleton-based ground truth
is much faster to annotate, and sufficient to determine connectivity.
Therefore, we encourage participants to develop methods to leverage
skeleton-based training. To this end, we provide two types of ground-truth
annotations: a small volume of voxel-wise annotations and a larger volume with
skeleton-based annotations. Entries will be evaluated on how accurately the
submitted segmentations agree with the ground-truth skeleton annotations.</p>
  </details>
</details>
<details>
  <summary>75. <b>标题：A Multimodal Sensing Ring for Quantification of Scratch Intensity</b></summary>
  <p><b>编号</b>：[174]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03813</p>
  <p><b>作者</b>：Akhil Padmanabha,  Sonal Choudhary,  Carmel Majidi,  Zackory Erickson</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：numerous medical conditions, debilitating symptom, medical conditions, improvements in patient, patient care</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>An objective measurement of the debilitating symptom, chronic itch, is
necessary for improvements in patient care for numerous medical conditions.
While wearable devices have shown promise for scratch detection, they are
currently unable to estimate scratch intensity, preventing a comprehensive
understanding of the effect of itch on an individual. In this work, we present
a framework for the estimation of scratch intensity in addition to scratch
detection consisting of a multimodal wearable ring device and machine learning
algorithms for regression of scratch intensity on a 0-600 mW mechanical power
scale that can be mapped to a 0-10 continuous scale. We evaluate the
performance of our algorithms on 20 individuals using Leave One Subject Out
(LOSO) Cross Validation (CV) and using data from 14 additional participants, we
show that our algorithms achieve clinically-relevant discrimination of
scratching intensity levels. This work demonstrates that a finger-worn device
can provide multidimensional, objective, real-time measures for the action of
scratching.</p>
  </details>
</details>
<details>
  <summary>76. <b>标题：Modified Policy Iteration for Exponential Cost Risk Sensitive MDPs</b></summary>
  <p><b>编号</b>：[175]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03811</p>
  <p><b>作者</b>：Yashaswini Murthy,  Mehrdad Moharrami,  R. Srikant</p>
  <p><b>备注</b>：30 pages</p>
  <p><b>关键词</b>：reinforcement learning algorithms, policy iteration, Modified policy iteration, optimistic policy iteration, iteration</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Modified policy iteration (MPI) also known as optimistic policy iteration is
at the core of many reinforcement learning algorithms. It works by combining
elements of policy iteration and value iteration. The convergence of MPI has
been well studied in the case of discounted and average-cost MDPs. In this
work, we consider the exponential cost risk-sensitive MDP formulation, which is
known to provide some robustness to model parameters. Although policy iteration
and value iteration have been well studied in the context of risk sensitive
MDPs, modified policy iteration is relatively unexplored. We provide the first
proof that MPI also converges for the risk-sensitive problem in the case of
finite state and action spaces. Since the exponential cost formulation deals
with the multiplicative Bellman equation, our main contribution is a
convergence proof which is quite different than existing results for discounted
and risk-neutral average-cost problems. The proof of approximate modified
policy iteration for risk sensitive MDPs is also provided in the appendix.</p>
  </details>
</details>
<details>
  <summary>77. <b>标题：Fairness in Matching under Uncertainty</b></summary>
  <p><b>编号</b>：[176]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03810</p>
  <p><b>作者</b>：Siddartha Devic,  David Kempe,  Vatsal Sharan,  Aleksandra Korolova</p>
  <p><b>备注</b>：20 pages, 1 figure</p>
  <p><b>关键词</b>：prevalence and importance, drawn attention, algorithmic two-sided marketplaces, two-sided marketplace setting, importance of algorithmic</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The prevalence and importance of algorithmic two-sided marketplaces has drawn
attention to the issue of fairness in such settings. Algorithmic decisions are
used in assigning students to schools, users to advertisers, and applicants to
job interviews. These decisions should heed the preferences of individuals, and
simultaneously be fair with respect to their merits (synonymous with fit,
future performance, or need). Merits conditioned on observable features are
always uncertain, a fact that is exacerbated by the widespread use of machine
learning algorithms to infer merit from the observables. As our key
contribution, we carefully axiomatize a notion of individual fairness in the
two-sided marketplace setting which respects the uncertainty in the merits;
indeed, it simultaneously recognizes uncertainty as the primary potential cause
of unfairness and an approach to address it. We design a linear programming
framework to find fair utility-maximizing distributions over allocations, and
we show that the linear program is robust to perturbations in the estimated
parameters of the uncertain merit distributions, a key property in combining
the approach with machine learning techniques.</p>
  </details>
</details>
<details>
  <summary>78. <b>标题：A prototype-oriented clustering for domain shift with source privacy</b></summary>
  <p><b>编号</b>：[177]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03807</p>
  <p><b>作者</b>：Korawat Tanwisuth,  Shujian Zhang,  Pengcheng He,  Mingyuan Zhou</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：abundant unlabeled data, unlabeled data, abundant unlabeled, target domain data, source clustering model</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Unsupervised clustering under domain shift (UCDS) studies how to transfer the
knowledge from abundant unlabeled data from multiple source domains to learn
the representation of the unlabeled data in a target domain. In this paper, we
introduce Prototype-oriented Clustering with Distillation (PCD) to not only
improve the performance and applicability of existing methods for UCDS, but
also address the concerns on protecting the privacy of both the data and model
of the source domains. PCD first constructs a source clustering model by
aligning the distributions of prototypes and data. It then distills the
knowledge to the target model through cluster labels provided by the source
model while simultaneously clustering the target data. Finally, it refines the
target model on the target domain data without guidance from the source model.
Experiments across multiple benchmarks show the effectiveness and
generalizability of our source-private clustering method.</p>
  </details>
</details>
<details>
  <summary>79. <b>标题：SLaM: Student-Label Mixing for Semi-Supervised Knowledge Distillation</b></summary>
  <p><b>编号</b>：[178]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03806</p>
  <p><b>作者</b>：Vasilis Kontonis,  Fotis Iliopoulos,  Khoa Trinh,  Cenk Baykal,  Gaurav Menghani,  Erik Vee</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：powerful training paradigm, lightweight student models, large teacher model, Semi-supervised knowledge distillation, labeled data</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Semi-supervised knowledge distillation is a powerful training paradigm for
generating compact and lightweight student models in settings where the amount
of labeled data is limited but one has access to a large pool of unlabeled
data. The idea is that a large teacher model is utilized to generate
``smoothed'' pseudo-labels for the unlabeled dataset which are then used for
training the student model. Despite its success in a wide variety of
applications, a shortcoming of this approach is that the teacher's
pseudo-labels are often noisy, leading to impaired student performance. In this
paper, we present a principled method for semi-supervised knowledge
distillation that we call Student-Label Mixing (SLaM) and we show that it
consistently improves over prior approaches by evaluating it on several
standard benchmarks. Finally, we show that SLaM comes with theoretical
guarantees; along the way we give an algorithm improving the best-known sample
complexity for learning halfspaces with margin under random classification
noise, and provide the first convergence analysis for so-called ``forward
loss-adjustment" methods.</p>
  </details>
</details>
<details>
  <summary>80. <b>标题：Eliciting User Preferences for Personalized Multi-Objective Decision  Making through Comparative Feedback</b></summary>
  <p><b>编号</b>：[179]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03805</p>
  <p><b>作者</b>：Han Shao,  Lee Cohen,  Avrim Blum,  Yishay Mansour,  Aadirupa Saha,  Matthew R. Walter</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：classic reinforcement learning, user, reinforcement learning, classic reinforcement, evaluated with respect</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In classic reinforcement learning (RL) and decision making problems, policies
are evaluated with respect to a scalar reward function, and all optimal
policies are the same with regards to their expected return. However, many
real-world problems involve balancing multiple, sometimes conflicting,
objectives whose relative priority will vary according to the preferences of
each user. Consequently, a policy that is optimal for one user might be
sub-optimal for another. In this work, we propose a multi-objective decision
making framework that accommodates different user preferences over objectives,
where preferences are learned via policy comparisons. Our model consists of a
Markov decision process with a vector-valued reward function, with each user
having an unknown preference vector that expresses the relative importance of
each objective. The goal is to efficiently compute a near-optimal policy for a
given user. We consider two user feedback models. We first address the case
where a user is provided with two policies and returns their preferred policy
as feedback. We then move to a different user feedback model, where a user is
instead provided with two small weighted sets of representative trajectories
and selects the preferred one. In both cases, we suggest an algorithm that
finds a nearly optimal policy for the user using a small number of comparison
queries.</p>
  </details>
</details>
<details>
  <summary>81. <b>标题：Standing Between Past and Future: Spatio-Temporal Modeling for  Multi-Camera 3D Multi-Object Tracking</b></summary>
  <p><b>编号</b>：[180]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03802</p>
  <p><b>作者</b>：Ziqi Pang,  Jie Li,  Pavel Tokmakov,  Dian Chen,  Sergey Zagoruyko,  Yu-Xiong Wang</p>
  <p><b>备注</b>：15 pages, 8 figures</p>
  <p><b>关键词</b>：work proposes, MOT, multi-object tracking, future reasoning, reasoning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This work proposes an end-to-end multi-camera 3D multi-object tracking (MOT)
framework. It emphasizes spatio-temporal continuity and integrates both past
and future reasoning for tracked objects. Thus, we name it "Past-and-Future
reasoning for Tracking" (PF-Track). Specifically, our method adapts the
"tracking by attention" framework and represents tracked instances coherently
over time with object queries. To explicitly use historical cues, our "Past
Reasoning" module learns to refine the tracks and enhance the object features
by cross-attending to queries from previous frames and other objects. The
"Future Reasoning" module digests historical information and predicts robust
future trajectories. In the case of long-term occlusions, our method maintains
the object positions and enables re-association by integrating motion
predictions. On the nuScenes dataset, our method improves AMOTA by a large
margin and remarkably reduces ID-Switches by 90% compared to prior approaches,
which is an order of magnitude less. The code and models are made available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>82. <b>标题：Self-Supervised Unseen Object Instance Segmentation via Long-Term Robot  Interaction</b></summary>
  <p><b>编号</b>：[183]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03793</p>
  <p><b>作者</b>：Yangxiao Lu,  Ninad Khargonkar,  Zesheng Xu,  Charles Averill,  Kamalesh Palanisamy,  Kaiyu Hang,  Yunhui Guo,  Nicholas Ruozzi,  Yu Xiang</p>
  <p><b>备注</b>：11 pages, 7 figures, 5 tables</p>
  <p><b>关键词</b>：long-term robot interaction, leveraging long-term robot, segmentation, leveraging long-term, object instance segmentation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We introduce a novel robotic system for improving unseen object instance
segmentation in the real world by leveraging long-term robot interaction with
objects. Previous approaches either grasp or push an object and then obtain the
segmentation mask of the grasped or pushed object after one action. Instead,
our system defers the decision on segmenting objects after a sequence of robot
pushing actions. By applying multi-object tracking and video object
segmentation on the images collected via robot pushing, our system can generate
segmentation masks of all the objects in these images in a self-supervised way.
These include images where objects are very close to each other, and
segmentation errors usually occur on these images for existing object
segmentation networks. We demonstrate the usefulness of our system by
fine-tuning segmentation networks trained on synthetic data with real-world
data collected by our system. We show that, after fine-tuning, the segmentation
accuracy of the networks is significantly improved both in the same domain and
across different domains. In addition, we verify that the fine-tuned networks
improve top-down robotic grasping of unseen objects in the real world.</p>
  </details>
</details>
<details>
  <summary>83. <b>标题：Information-Theoretic Diffusion</b></summary>
  <p><b>编号</b>：[184]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03792</p>
  <p><b>作者</b>：Xianghao Kong,  Rob Brekelmans,  Greg Ver Steeg</p>
  <p><b>备注</b>：26 pages, 7 figures, International Conference on Learning Representations (ICLR), 2023. Code is at this http URL and this http URL</p>
  <p><b>关键词</b>：spurred significant gains, image generation, art generation, precipitating an industrial, spurred significant</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Denoising diffusion models have spurred significant gains in density modeling
and image generation, precipitating an industrial revolution in text-guided AI
art generation. We introduce a new mathematical foundation for diffusion models
inspired by classic results in information theory that connect Information with
Minimum Mean Square Error regression, the so-called I-MMSE relations. We
generalize the I-MMSE relations to exactly relate the data distribution to an
optimal denoising regression problem, leading to an elegant refinement of
existing diffusion bounds. This new insight leads to several improvements for
probability distribution estimation, including theoretical justification for
diffusion model ensembling. Remarkably, our framework shows how continuous and
discrete probabilities can be learned with the same regression objective,
avoiding domain-specific generative models used in variational methods. Code to
reproduce experiments is provided at this http URL and
simplified demonstration code is at
this http URL.</p>
  </details>
</details>
<details>
  <summary>84. <b>标题：GraphGUIDE: interpretable and controllable conditional graph generation  with discrete Bernoulli diffusion</b></summary>
  <p><b>编号</b>：[185]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03790</p>
  <p><b>作者</b>：Alex M. Tseng,  Nathaniel Diamant,  Tommaso Biancalani,  Gabriele Scalia</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：generating realistic objects, performance in generating, applied to images, Diffusion models achieve, generating realistic</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Diffusion models achieve state-of-the-art performance in generating realistic
objects and have been successfully applied to images, text, and videos. Recent
work has shown that diffusion can also be defined on graphs, including graph
representations of drug-like molecules. Unfortunately, it remains difficult to
perform conditional generation on graphs in a way which is interpretable and
controllable. In this work, we propose GraphGUIDE, a novel framework for graph
generation using diffusion models, where edges in the graph are flipped or set
at each discrete time step. We demonstrate GraphGUIDE on several graph
datasets, and show that it enables full control over the conditional generation
of arbitrary structural properties without relying on predefined labels. Our
framework for graph diffusion can have a large impact on the interpretable
conditional generation of graphs, including the generation of drug-like
molecules with desired properties in a way which is informed by experimental
evidence.</p>
  </details>
</details>
<details>
  <summary>85. <b>标题：Layered State Discovery for Incremental Autonomous Exploration</b></summary>
  <p><b>编号</b>：[186]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03789</p>
  <p><b>作者</b>：Liyu Chen,  Andrea Tirinzoni,  Alessandro Lazaric,  Matteo Pirotta</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：proposed by Lim, epsilon, Layered Autonomous Exploration, autonomous exploration, rightarrow</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We study the autonomous exploration (AX) problem proposed by Lim & Auer
(2012). In this setting, the objective is to discover a set of
$\epsilon$-optimal policies reaching a set $\mathcal{S}_L^{\rightarrow}$ of
incrementally $L$-controllable states. We introduce a novel layered
decomposition of the set of incrementally $L$-controllable states that is based
on the iterative application of a state-expansion operator. We leverage these
results to design Layered Autonomous Exploration (LAE), a novel algorithm for
AX that attains a sample complexity of
$\tilde{\mathcal{O}}(LS^{\rightarrow}_{L(1+\epsilon)}\Gamma_{L(1+\epsilon)} A
\ln^{12}(S^{\rightarrow}_{L(1+\epsilon)})/\epsilon^2)$, where
$S^{\rightarrow}_{L(1+\epsilon)}$ is the number of states that are
incrementally $L(1+\epsilon)$-controllable, $A$ is the number of actions, and
$\Gamma_{L(1+\epsilon)}$ is the branching factor of the transitions over such
states. LAE improves over the algorithm of Tarbouriech et al. (2020a) by a
factor of $L^2$ and it is the first algorithm for AX that works in a
countably-infinite state space. Moreover, we show that, under a certain
identifiability assumption, LAE achieves minimax-optimal sample complexity of
$\tilde{\mathcal{O}}(LS^{\rightarrow}_{L}A\ln^{12}(S^{\rightarrow}_{L})/\epsilon^2)$,
outperforming existing algorithms and matching for the first time the lower
bound proved by Cai et al. (2022) up to logarithmic factors.</p>
  </details>
</details>
<details>
  <summary>86. <b>标题：Toward a Theory of Causation for Interpreting Neural Code Models</b></summary>
  <p><b>编号</b>：[187]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03788</p>
  <p><b>作者</b>：David N. Palacio,  Nathan Cooper,  Alvaro Rodriguez,  Kevin Moran,  Denys Poshyvanyk</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：commercial developer tools, Neural Code Models, Neural Language Models, Neural Code, Neural Language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Neural Language Models of Code, or Neural Code Models (NCMs), are rapidly
progressing from research prototypes to commercial developer tools. As such,
understanding the capabilities and limitations of such models is becoming
critical. However, the abilities of these models are typically measured using
automated metrics that often only reveal a portion of their real-world
performance. While, in general, the performance of NCMs appears promising,
currently much is unknown about how such models arrive at decisions. To this
end, this paper introduces $do_{code}$, a post-hoc interpretability methodology
specific to NCMs that is capable of explaining model predictions. $do_{code}$
is based upon causal inference to enable programming language-oriented
explanations. While the theoretical underpinnings of $do_{code}$ are extensible
to exploring different model properties, we provide a concrete instantiation
that aims to mitigate the impact of spurious correlations by grounding
explanations of model behavior in properties of programming languages. To
demonstrate the practical benefit of $do_{code}$, we illustrate the insights
that our framework can provide by performing a case study on two popular deep
learning architectures and nine NCMs. The results of this case study illustrate
that our studied NCMs are sensitive to changes in code syntax and statistically
learn to predict tokens related to blocks of code (e.g., brackets, parenthesis,
semicolon) with less confounding bias as compared to other programming language
constructs. These insights demonstrate the potential of $do_{code}$ as a useful
model debugging mechanism that may aid in discovering biases and limitations in
NCMs.</p>
  </details>
</details>
<details>
  <summary>87. <b>标题：Analyzing the Performance of Deep Encoder-Decoder Networks as Surrogates  for a Diffusion Equation</b></summary>
  <p><b>编号</b>：[188]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03786</p>
  <p><b>作者</b>：J. Quetzalcoatl Toledo-Marin,  James A. Glazier,  Geoffrey Fox</p>
  <p><b>备注</b>：21 ps, 17 figs, 8 ts</p>
  <p><b>关键词</b>：traditional direct numerical, direct numerical algorithms, training set, accelerate computational time, training set size</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Neural networks (NNs) have proven to be a viable alternative to traditional
direct numerical algorithms, with the potential to accelerate computational
time by several orders of magnitude. In the present paper we study the use of
encoder-decoder convolutional neural network (CNN) as surrogates for
steady-state diffusion solvers. The construction of such surrogates requires
the selection of an appropriate task, network architecture, training set
structure and size, loss function, and training algorithm hyperparameters. It
is well known that each of these factors can have a significant impact on the
performance of the resultant model. Our approach employs an encoder-decoder CNN
architecture, which we posit is particularly well-suited for this task due to
its ability to effectively transform data, as opposed to merely compressing it.
We systematically evaluate a range of loss functions, hyperparameters, and
training set sizes. Our results indicate that increasing the size of the
training set has a substantial effect on reducing performance fluctuations and
overall error. Additionally, we observe that the performance of the model
exhibits a logarithmic dependence on the training set size. Furthermore, we
investigate the effect on model performance by using different subsets of data
with varying features. Our results highlight the importance of sampling the
configurational space in an optimal manner, as this can have a significant
impact on the performance of the model and the required training time. In
conclusion, our results suggest that training a model with a pre-determined
error performance bound is not a viable approach, as it does not guarantee that
edge cases with errors larger than the bound do not exist. Furthermore, as most
surrogate tasks involve a high dimensional landscape, an ever increasing
training set size is, in principle, needed, however it is not a practical
solution.</p>
  </details>
</details>
<details>
  <summary>88. <b>标题：Leveraging User-Triggered Supervision in Contextual Bandits</b></summary>
  <p><b>编号</b>：[189]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03784</p>
  <p><b>作者</b>：Alekh Agarwal,  Claudio Gentile,  Teodor V. Marinov</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：study contextual bandit, contextual bandit, study contextual, user enters, problems</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We study contextual bandit (CB) problems, where the user can sometimes
respond with the best action in a given context. Such an interaction arises,
for example, in text prediction or autocompletion settings, where a poor
suggestion is simply ignored and the user enters the desired text instead.
Crucially, this extra feedback is user-triggered on only a subset of the
contexts. We develop a new framework to leverage such signals, while being
robust to their biased nature. We also augment standard CB algorithms to
leverage the signal, and show improved regret guarantees for the resulting
algorithms under a variety of conditions on the helpfulness of and bias
inherent in this feedback.</p>
  </details>
</details>
<details>
  <summary>89. <b>标题：Optimal Stochastic Non-smooth Non-convex Optimization through  Online-to-Non-convex Conversion</b></summary>
  <p><b>编号</b>：[196]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03775</p>
  <p><b>作者</b>：Ashok Cutkosky,  Harsh Mehta,  Francesco Orabona</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：epsilon, delta, present new algorithms, algorithms for optimizing, stochastic objectives based</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present new algorithms for optimizing non-smooth, non-convex stochastic
objectives based on a novel analysis technique. This improves the current
best-known complexity for finding a $(\delta,\epsilon)$-stationary point from
$O(\epsilon^{-4}\delta^{-1})$ stochastic gradient queries to
$O(\epsilon^{-3}\delta^{-1})$, which we also show to be optimal. Our primary
technique is a reduction from non-smooth non-convex optimization to online
learning, after which our results follow from standard regret bounds in online
learning. For deterministic and second-order smooth objectives, applying more
advanced optimistic online learning techniques enables a new complexity of
$O(\epsilon^{-1.5}\delta^{-0.5})$. Our techniques also recover all optimal or
best-known results for finding $\epsilon$ stationary points of smooth or
second-order smooth objectives in both stochastic and deterministic settings.</p>
  </details>
</details>
<details>
  <summary>90. <b>标题：AI and Core Electoral Processes: Mapping the Horizons</b></summary>
  <p><b>编号</b>：[197]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03774</p>
  <p><b>作者</b>：Deepak P,  Stanley Simoes,  Muiris MacCarthaigh</p>
  <p><b>备注</b>：19 pages, 7 figures, to be published in AI Magazine (Fall 2023)</p>
  <p><b>关键词</b>：Significant enthusiasm, societies globally, witnessed across societies, electoral process, electoral</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Significant enthusiasm around AI uptake has been witnessed across societies
globally. The electoral process -- the time, place and manner of elections
within democratic nations -- has been among those very rare sectors in which AI
has not penetrated much. Electoral management bodies in many countries have
recently started exploring and deliberating over the use of AI in the electoral
process. In this paper, we consider five representative avenues within the core
electoral process which have potential for AI usage, and map the challenges
involved in using AI within them. These five avenues are: voter list
maintenance, determining polling booth locations, polling booth protection
processes, voter authentication and video monitoring of elections. Within each
of these avenues, we lay down the context, illustrate current or potential
usage of AI, and discuss extant or potential ramifications of AI usage, and
potential directions for mitigating risks while considering AI usage. We
believe that the scant current usage of AI within electoral processes provides
a very rare opportunity, that of being able to deliberate on the risks and
mitigation possibilities, prior to real and widespread AI deployment. This
paper is an attempt to map the horizons of risks and opportunities in using AI
within the electoral processes and to help shape the debate around the topic.</p>
  </details>
</details>
<details>
  <summary>91. <b>标题：What Matters In The Structured Pruning of Generative Language Models?</b></summary>
  <p><b>编号</b>：[198]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03773</p>
  <p><b>作者</b>：Michael Santacroce,  Zixin Wen,  Yelong Shen,  Yuanzhi Li</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：require enormous computational, enormous computational resources, Auto-regressive large language, Auto-regressive large, require enormous</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Auto-regressive large language models such as GPT-3 require enormous
computational resources to use. Traditionally, structured pruning methods are
employed to reduce resource usage. However, their application to and efficacy
for generative language models is heavily under-explored. In this paper we
conduct an comprehensive evaluation of common structured pruning methods,
including magnitude, random, and movement pruning on the feed-forward layers in
GPT-type models. Unexpectedly, random pruning results in performance that is
comparable to the best established methods, across multiple natural language
generation tasks. To understand these results, we provide a framework for
measuring neuron-level redundancy of models pruned by different methods, and
discover that established structured pruning methods do not take into account
the distinctiveness of neurons, leaving behind excess redundancies. In view of
this, we introduce Globally Unique Movement (GUM) to improve the uniqueness of
neurons in pruned models. We then discuss the effects of our techniques on
different redundancy metrics to explain the improved performance.</p>
  </details>
</details>
<details>
  <summary>92. <b>标题：Provably Efficient Offline Goal-Conditioned Reinforcement Learning with  General Function Approximation and Single-Policy Concentrability</b></summary>
  <p><b>编号</b>：[200]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03770</p>
  <p><b>作者</b>：Hanlin Zhu,  Amy Zhang</p>
  <p><b>备注</b>：26 pages</p>
  <p><b>关键词</b>：reach diverse goals, Goal-conditioned reinforcement learning, learning general-purpose skills, Goal-conditioned reinforcement, diverse goals</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Goal-conditioned reinforcement learning (GCRL) refers to learning
general-purpose skills which aim to reach diverse goals. In particular, offline
GCRL only requires purely pre-collected datasets to perform training tasks
without additional interactions with the environment. Although offline GCRL has
become increasingly prevalent and many previous works have demonstrated its
empirical success, the theoretical understanding of efficient offline GCRL
algorithms is not well established, especially when the state space is huge and
the offline dataset only covers the policy we aim to learn. In this paper, we
propose a novel provably efficient algorithm (the sample complexity is
$\tilde{O}({\rm poly}(1/\epsilon))$ where $\epsilon$ is the desired
suboptimality of the learned policy) with general function approximation. Our
algorithm only requires nearly minimal assumptions of the dataset
(single-policy concentrability) and the function class (realizability).
Moreover, our algorithm consists of two uninterleaved optimization steps, which
we refer to as $V$-learning and policy learning, and is computationally stable
since it does not involve minimax optimization. To the best of our knowledge,
this is the first algorithm with general function approximation and
single-policy concentrability that is both statistically efficient and
computationally stable.</p>
  </details>
</details>
<details>
  <summary>93. <b>标题：Understanding Why ViT Trains Badly on Small Datasets: An Intuitive  Perspective</b></summary>
  <p><b>编号</b>：[204]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03751</p>
  <p><b>作者</b>：Haoran Zhu,  Boyuan Chen,  Carter Yang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：computer vision tasks, neural network architecture, attention neural network, Vision transformer, vision tasks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Vision transformer (ViT) is an attention neural network architecture that is
shown to be effective for computer vision tasks. However, compared to ResNet-18
with a similar number of parameters, ViT has a significantly lower evaluation
accuracy when trained on small datasets. To facilitate studies in related
fields, we provide a visual intuition to help understand why it is the case. We
first compare the performance of the two models and confirm that ViT has less
accuracy than ResNet-18 when trained on small datasets. We then interpret the
results by showing attention map visualization for ViT and feature map
visualization for ResNet-18. The difference is further analyzed through a
representation similarity perspective. We conclude that the representation of
ViT trained on small datasets is hugely different from ViT trained on large
datasets, which may be the reason why the performance drops a lot on small
datasets.</p>
  </details>
</details>
<details>
  <summary>94. <b>标题：Towards causally linking architectural parametrizations to algorithmic  bias in neural networks</b></summary>
  <p><b>编号</b>：[205]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03750</p>
  <p><b>作者</b>：Hao Liang,  Josue Ortega Caro,  Vikram Maheshri,  Ankit B. Patel,  Guha Balakrishnan</p>
  <p><b>备注</b>：23 pages, 15 figures, 2 tables</p>
  <p><b>关键词</b>：Training dataset biases, explaining algorithmic biases, scrutinized factors, factors when explaining, neural network architecture</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Training dataset biases are by far the most scrutinized factors when
explaining algorithmic biases of neural networks. In contrast, hyperparameters
related to the neural network architecture, e.g., the number of layers or
choice of activation functions, have largely been ignored even though different
network parameterizations are known to induce different implicit biases over
learned features. For example, convolutional kernel size has been shown to bias
CNNs towards different frequencies. In order to study the effect of these
hyperparameters, we designed a causal framework for linking an architectural
hyperparameter to algorithmic bias. Our framework is experimental, in that
several versions of a network are trained with an intervention to a specific
hyperparameter, and the resulting causal effect of this choice on performance
bias is measured. We focused on the causal relationship between sensitivity to
high-frequency image details and face analysis classification performance
across different subpopulations (race/gender). In this work, we show that
modifying a CNN hyperparameter (convolutional kernel size), even in one layer
of a CNN, will not only change a fundamental characteristic of the learned
features (frequency content) but that this change can vary significantly across
data subgroups (race/gender populations) leading to biased generalization
performance even in the presence of a balanced dataset.</p>
  </details>
</details>
<details>
  <summary>95. <b>标题：MMA-RNN: A Multi-level Multi-task Attention-based Recurrent Neural  Network for Discrimination and Localization of Atrial Fibrillation</b></summary>
  <p><b>编号</b>：[211]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03731</p>
  <p><b>作者</b>：Yifan Sun,  Jingyan Shen,  Yunfan Jiang,  Zhaohui Huang,  Minsheng Hao,  Xuegong Zhang</p>
  <p><b>备注</b>：9 pages, 5 figures</p>
  <p><b>关键词</b>：received wide attention, process ECG signals, atrial fibrillation, clinically and practically, atrial fibrillation based</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The automatic detection of atrial fibrillation based on electrocardiograph
(ECG) signals has received wide attention both clinically and practically. It
is challenging to process ECG signals with cyclical pattern, varying length and
unstable quality due to noise and distortion. Besides, there has been
insufficient research on separating persistent atrial fibrillation from
paroxysmal atrial fibrillation, and little discussion on locating the onsets
and end points of AF episodes. It is even more arduous to perform well on these
two distinct but interrelated tasks, while avoiding the mistakes inherent from
stage-by-stage approaches. This paper proposes the Multi-level Multi-task
Attention-based Recurrent Neural Network for three-class discrimination on
patients and localization of the exact timing of AF episodes. Our model
captures three-level sequential features based on a hierarchical architecture
utilizing Bidirectional Long and Short-Term Memory Network (Bi-LSTM) and
attention layers, and accomplishes the two tasks simultaneously with a
multi-head classifier. The model is designed as an end-to-end framework to
enhance information interaction and reduce error accumulation. Finally, we
conduct experiments on CPSC 2021 dataset and the result demonstrates the
superior performance of our method, indicating the potential application of
MMA-RNN to wearable mobile devices for routine AF monitoring and early
diagnosis.</p>
  </details>
</details>
<details>
  <summary>96. <b>标题：Persuading a Behavioral Agent: Approximately Best Responding and  Learning</b></summary>
  <p><b>编号</b>：[217]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03719</p>
  <p><b>作者</b>：Yiling Chen,  Tao Lin</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Bayesian persuasion model, Bayesian persuasion, sender signaling scheme, Bayesian persuasion scheme, classic Bayesian persuasion</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The classic Bayesian persuasion model assumes a Bayesian and best-responding
receiver. We study a relaxation of the Bayesian persuasion model where the
receiver can approximately best respond to the sender's signaling scheme. We
show that, under natural assumptions, (1) the sender can find a signaling
scheme that guarantees itself an expected utility almost as good as its optimal
utility in the classic model, no matter what approximately best-responding
strategy the receiver uses; (2) on the other hand, there is no signaling scheme
that gives the sender much more utility than its optimal utility in the classic
model, even if the receiver uses the approximately best-responding strategy
that is best for the sender. Together, (1) and (2) imply that the approximately
best-responding behavior of the receiver does not affect the sender's maximal
achievable utility a lot in the Bayesian persuasion problem. The proofs of both
results rely on the idea of robustification of a Bayesian persuasion scheme:
given a pair of the sender's signaling scheme and the receiver's strategy, we
can construct another signaling scheme such that the receiver prefers to use
that strategy in the new scheme more than in the original scheme, and the two
schemes give the sender similar utilities. As an application of our main result
(1), we show that, in a repeated Bayesian persuasion model where the receiver
learns to respond to the sender by some algorithms, the sender can do almost as
well as in the classic model. Interestingly, unlike (2), with a learning
receiver the sender can sometimes do much better than in the classic model.</p>
  </details>
</details>
<details>
  <summary>97. <b>标题：Concept Algebra for Text-Controlled Vision Models</b></summary>
  <p><b>编号</b>：[220]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03693</p>
  <p><b>作者</b>：Zihao Wang,  Lin Gui,  Jeffrey Negrea,  Victor Veitch</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：generates samples based, text-guided generative models, model generates samples, natural language prompt, concerns the control</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper concerns the control of text-guided generative models, where a
user provides a natural language prompt and the model generates samples based
on this input. Prompting is intuitive, general, and flexible. However, there
are significant limitations: prompting can fail in surprising ways, and it is
often unclear how to find a prompt that will elicit some desired target
behavior. A core difficulty for developing methods to overcome these issues is
that failures are know-it-when-you-see-it -- it's hard to fix bugs if you can't
state precisely what the model should have done! In this paper, we introduce a
formalization of "what the user intended" in terms of latent concepts implicit
to the data generating process that the model was trained on. This
formalization allows us to identify some fundamental limitations of prompting.
We then use the formalism to develop concept algebra to overcome these
limitations. Concept algebra is a way of directly manipulating the concepts
expressed in the output through algebraic operations on a suitably defined
representation of input prompts. We give examples using concept algebra to
overcome limitations of prompting, including concept transfer through
arithmetic, and concept nullification through projection. Code available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>98. <b>标题：The Test of Tests: A Framework For Differentially Private Hypothesis  Testing</b></summary>
  <p><b>编号</b>：[222]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04260</p>
  <p><b>作者</b>：Zeki Kazan,  Kaiyan Shi,  Adam Groce,  Andrew Bray</p>
  <p><b>备注</b>：The main text is 14 pages and 4 figures. Appendices are 10 pages and 12 figures</p>
  <p><b>关键词</b>：differentially private versions, creating differentially private, creating differentially, differentially private, private versions</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present a generic framework for creating differentially private versions
of any hypothesis test in a black-box way. We analyze the resulting tests
analytically and experimentally. Most crucially, we show good practical
performance for small data sets, showing that at epsilon = 1 we only need 5-6
times as much data as in the fully public setting. We compare our work to the
one existing framework of this type, as well as to several
individually-designed private hypothesis tests. Our framework is higher power
than other generic solutions and at least competitive with (and often better
than) individually-designed tests.</p>
  </details>
</details>
<details>
  <summary>99. <b>标题：A Vector Quantized Approach for Text to Speech Synthesis on Real-World  Spontaneous Speech</b></summary>
  <p><b>编号</b>：[223]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04215</p>
  <p><b>作者</b>：Li-Wei Chen,  Shinji Watanabe,  Alexander Rudnicky</p>
  <p><b>备注</b>：Accepted to AAAI 2023</p>
  <p><b>关键词</b>：trained on reading, reading or acted, acted corpora, human-level naturalness, TTS systems</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent Text-to-Speech (TTS) systems trained on reading or acted corpora have
achieved near human-level naturalness. The diversity of human speech, however,
often goes beyond the coverage of these corpora. We believe the ability to
handle such diversity is crucial for AI systems to achieve human-level
communication. Our work explores the use of more abundant real-world data for
building speech synthesizers. We train TTS systems using real-world speech from
YouTube and podcasts. We observe the mismatch between training and inference
alignments in mel-spectrogram based autoregressive models, leading to
unintelligible synthesis, and demonstrate that learned discrete codes within
multiple code groups effectively resolves this issue. We introduce our MQTTS
system whose architecture is designed for multiple code generation and
monotonic alignment, along with the use of a clean silence prompt to improve
synthesis quality. We conduct ablation analyses to identify the efficacy of our
methods. We show that MQTTS outperforms existing TTS systems in several
objective and subjective measures.</p>
  </details>
</details>
<details>
  <summary>100. <b>标题：On the Complexity of Computing Gödel Numbers</b></summary>
  <p><b>编号</b>：[224]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04213</p>
  <p><b>作者</b>：Vasco Brattka</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：find a Gödel, Gödel number, task to find, program that generates, Gödel</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Given a computable sequence of natural numbers, it is a natural task to find
a Gödel number of a program that generates this sequence. It is easy to see
that this problem is neither continuous nor computable. In algorithmic learning
theory this problem is well studied from several perspectives and one question
studied there is for which sequences this problem is at least learnable in the
limit. Here we study the problem on all computable sequences and we classify
the Weihrauch complexity of it. For this purpose we can, among other methods,
utilize the amalgamation technique known from learning theory. As a benchmark
for the classification we use closed and compact choice problems and their
jumps on natural numbers, and we argue that these problems correspond to
induction and boundedness principles, as they are known from the Kirby-Paris
hierarchy in reverse mathematics. We provide a topological as well as a
computability-theoretic classification, which reveal some significant
differences.</p>
  </details>
</details>
<details>
  <summary>101. <b>标题：IRTCI: Item Response Theory for Categorical Imputation</b></summary>
  <p><b>编号</b>：[227]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04165</p>
  <p><b>作者</b>：Adrienne Kline,  Yuan Luo</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：suffer from partial, partial or complete, downstream limitations, statistical inferences, Amazon Web Services</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Most datasets suffer from partial or complete missing values, which has
downstream limitations on the available models on which to test the data and on
any statistical inferences that can be made from the data. Several imputation
techniques have been designed to replace missing data with stand in values. The
various approaches have implications for calculating clinical scores, model
building and model testing. The work showcased here offers a novel means for
categorical imputation based on item response theory (IRT) and compares it
against several methodologies currently used in the machine learning field
including k-nearest neighbors (kNN), multiple imputed chained equations (MICE)
and Amazon Web Services (AWS) deep learning method, Datawig. Analyses comparing
these techniques were performed on three different datasets that represented
ordinal, nominal and binary categories. The data were modified so that they
also varied on both the proportion of data missing and the systematization of
the missing data. Two different assessments of performance were conducted:
accuracy in reproducing the missing values, and predictive performance using
the imputed data. Results demonstrated that the new method, Item Response
Theory for Categorical Imputation (IRTCI), fared quite well compared to
currently used methods, outperforming several of them in many conditions. Given
the theoretical basis for the new approach, and the unique generation of
probabilistic terms for determining category belonging for missing cells, IRTCI
offers a viable alternative to current approaches.</p>
  </details>
</details>
<details>
  <summary>102. <b>标题：Decision trees compensate for model misspecification</b></summary>
  <p><b>编号</b>：[232]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04081</p>
  <p><b>作者</b>：Hugh Panton,  Gavin Leech,  Laurence Aitchison</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：best-performing models, tree depth, interactions, tree, depth</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The best-performing models in ML are not interpretable. If we can explain why
they outperform, we may be able to replicate these mechanisms and obtain both
interpretability and performance. One example are decision trees and their
descendent gradient boosting machines (GBMs). These perform well in the
presence of complex interactions, with tree depth governing the order of
interactions. However, interactions cannot fully account for the depth of trees
found in practice. We confirm 5 alternative hypotheses about the role of tree
depth in performance in the absence of true interactions, and present results
from experiments on a battery of datasets. Part of the success of tree models
is due to their robustness to various forms of mis-specification. We present
two methods for robust generalized linear models (GLMs) addressing the
composite and mixed response scenarios.</p>
  </details>
</details>
<details>
  <summary>103. <b>标题：Monge, Bregman and Occam: Interpretable Optimal Transport in  High-Dimensions with Feature-Sparse Maps</b></summary>
  <p><b>编号</b>：[234]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04065</p>
  <p><b>作者</b>：Marco Cuturi,  Michal Klein,  Pierre Ablin</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：theory focuses, morph a probability, probability measure, mathbb, averaged cost</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Optimal transport (OT) theory focuses, among all maps
$T:\mathbb{R}^d\rightarrow \mathbb{R}^d$ that can morph a probability measure
onto another, on those that are the ``thriftiest'', i.e. such that the averaged
cost $c(x, T(x))$ between $x$ and its image $T(x)$ be as small as possible.
Many computational approaches have been proposed to estimate such Monge maps
when $c$ is the $\ell_2^2$ distance, e.g., using entropic maps [Pooladian'22],
or neural networks [Makkuva'20, Korotin'20]. We propose a new model for
transport maps, built on a family of translation invariant costs $c(x,
y):=h(x-y)$, where $h:=\tfrac{1}{2}\|\cdot\|_2^2+\tau$ and $\tau$ is a
regularizer. We propose a generalization of the entropic map suitable for $h$,
and highlight a surprising link tying it with the Bregman centroids of the
divergence $D_h$ generated by $h$, and the proximal operator of $\tau$. We show
that choosing a sparsity-inducing norm for $\tau$ results in maps that apply
Occam's razor to transport, in the sense that the displacement vectors
$\Delta(x):= T(x)-x$ they induce are sparse, with a sparsity pattern that
varies depending on $x$. We showcase the ability of our method to estimate
meaningful OT maps for high-dimensional single-cell transcription data, in the
$34000$-$d$ space of gene counts for cells, without using dimensionality
reduction, thus retaining the ability to interpret all displacements at the
gene level.</p>
  </details>
</details>
<details>
  <summary>104. <b>标题：Prediction approaches for partly missing multi-omics covariate data: A  literature review and an empirical comparison study</b></summary>
  <p><b>编号</b>：[236]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03991</p>
  <p><b>作者</b>：Roman Hornung,  Frederik Ludwigs,  Jonas Hagenberg,  Anne-Laure Boulesteix</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：high-dimensional molecular data, molecular data consisting, data, high-dimensional molecular, omics data</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As the availability of omics data has increased in the last few years, more
multi-omics data have been generated, that is, high-dimensional molecular data
consisting of several types such as genomic, transcriptomic, or proteomic data,
all obtained from the same patients. Such data lend themselves to being used as
covariates in automatic outcome prediction because each omics type may
contribute unique information, possibly improving predictions compared to using
only one omics data type. Frequently, however, in the training data and the
data to which automatic prediction rules should be applied, the test data, the
different omics data types are not available for all patients. We refer to this
type of data as block-wise missing multi-omics data. First, we provide a
literature review on existing prediction methods applicable to such data.
Subsequently, using a collection of 13 publicly available multi-omics data
sets, we compare the predictive performances of several of these approaches for
different block-wise missingness patterns. Finally, we discuss the results of
this empirical comparison study and draw some tentative conclusions.</p>
  </details>
</details>
<details>
  <summary>105. <b>标题：Improved Langevin Monte Carlo for stochastic optimization via landscape  modification</b></summary>
  <p><b>编号</b>：[237]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03973</p>
  <p><b>作者</b>：Michael C. H. Choi,  Youjia Wang</p>
  <p><b>备注</b>：30 pages</p>
  <p><b>关键词</b>：Langevin Monte Carlo, target Gibbs distribution, analyze Langevin Monte, modified Gibbs distribution, Gibbs distribution</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Given a target function $H$ to minimize or a target Gibbs distribution
$\pi_{\beta}^0 \propto e^{-\beta H}$ to sample from in the low temperature, in
this paper we propose and analyze Langevin Monte Carlo (LMC) algorithms that
run on an alternative landscape as specified by $H^f_{\beta,c,1}$ and target a
modified Gibbs distribution $\pi^f_{\beta,c,1} \propto e^{-\beta
H^f_{\beta,c,1}}$, where the landscape of $H^f_{\beta,c,1}$ is a transformed
version of that of $H$ which depends on the parameters $f,\beta$ and $c$. While
the original Log-Sobolev constant affiliated with $\pi^0_{\beta}$ exhibits
exponential dependence on both $\beta$ and the energy barrier $M$ in the low
temperature regime, with appropriate tuning of these parameters and subject to
assumptions on $H$, we prove that the energy barrier of the transformed
landscape is reduced which consequently leads to polynomial dependence on both
$\beta$ and $M$ in the modified Log-Sobolev constant associated with
$\pi^f_{\beta,c,1}$. This yield improved total variation mixing time bounds and
improved convergence toward a global minimum of $H$. We stress that the
technique developed in this paper is not only limited to LMC and is broadly
applicable to other gradient-based optimization or sampling algorithms.</p>
  </details>
</details>
<details>
  <summary>106. <b>标题：Learning-based Online Optimization for Autonomous Mobility-on-Demand  Fleet Control</b></summary>
  <p><b>编号</b>：[239]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03963</p>
  <p><b>作者</b>：Kai Jungel,  Axel Parmentier,  Maximilian Schiffer,  Thibaut Vidal</p>
  <p><b>备注</b>：31 pages, 17 figures</p>
  <p><b>关键词</b>：rising vehicle volumes, transportation-related pollution, externalities in cities, transportation-related externalities, viable alternative</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Autonomous mobility-on-demand systems are a viable alternative to mitigate
many transportation-related externalities in cities, such as rising vehicle
volumes in urban areas and transportation-related pollution. However, the
success of these systems heavily depends on efficient and effective fleet
control strategies. In this context, we study online control algorithms for
autonomous mobility-on-demand systems and develop a novel hybrid combinatorial
optimization enriched machine learning pipeline which learns online dispatching
and rebalancing policies from optimal full-information solutions. We test our
hybrid pipeline on large-scale real-world scenarios with different vehicle
fleet sizes and various request densities. We show that our approach
outperforms state-of-the-art greedy, and model-predictive control approaches
with respect to various KPIs, e.g., by up to 17.1% and on average by 6.3% in
terms of realized profit.</p>
  </details>
</details>
<details>
  <summary>107. <b>标题：Fast Linear Model Trees by PILOT</b></summary>
  <p><b>编号</b>：[240]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03931</p>
  <p><b>作者</b>：Jakob Raymaekers,  Peter J. Rousseeuw,  Tim Verdonck,  Ruicong Yao</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Linear model trees, trees, model trees, Linear model, Linear</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Linear model trees are regression trees that incorporate linear models in the
leaf nodes. This preserves the intuitive interpretation of decision trees and
at the same time enables them to better capture linear relationships, which is
hard for standard decision trees. But most existing methods for fitting linear
model trees are time consuming and therefore not scalable to large data sets.
In addition, they are more prone to overfitting and extrapolation issues than
standard regression trees. In this paper we introduce PILOT, a new algorithm
for linear model trees that is fast, regularized, stable and interpretable.
PILOT trains in a greedy fashion like classic regression trees, but
incorporates an $L^2$ boosting approach and a model selection rule for fitting
linear models in the nodes. The abbreviation PILOT stands for $PI$ecewise
$L$inear $O$rganic $T$ree, where `organic' refers to the fact that no pruning
is carried out. PILOT has the same low time and space complexity as CART
without its pruning. An empirical study indicates that PILOT tends to
outperform standard decision trees and other linear model trees on a variety of
data sets. Moreover, we prove its consistency in an additive model setting
under weak assumptions. When the data is generated by a linear model, the
convergence rate is polynomial.</p>
  </details>
</details>
<details>
  <summary>108. <b>标题：DDeMON: Ontology-based function prediction by Deep Learning from Dynamic  Multiplex Networks</b></summary>
  <p><b>编号</b>：[242]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03907</p>
  <p><b>作者</b>：Jan Kralj,  Blaž Škrlj,  Živa Ramšak,  Nada Lavrač,  Kristina Gruden</p>
  <p><b>备注</b>：Submitted to BMC Bioinformatics</p>
  <p><b>关键词</b>：interaction networks levels, studied at multiple, multiple levels, systems' level information, temporal Multiplex Ontology-annotated</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Biological systems can be studied at multiple levels of information,
including gene, protein, RNA and different interaction networks levels. The
goal of this work is to explore how the fusion of systems' level information
with temporal dynamics of gene expression can be used in combination with
non-linear approximation power of deep neural networks to predict novel gene
functions in a non-model organism potato \emph{Solanum tuberosum}. We propose
DDeMON (Dynamic Deep learning from temporal Multiplex Ontology-annotated
Networks), an approach for scalable, systems-level inference of function
annotation using time-dependent multiscale biological information. The proposed
method, which is capable of considering billions of potential links between the
genes of interest, was applied on experimental gene expression data and the
background knowledge network to reliably classify genes with unknown function
into five different functional ontology categories, linked to the experimental
data set. Predicted novel functions of genes were validated using extensive
protein domain search approach.</p>
  </details>
</details>
<details>
  <summary>109. <b>标题：A Weighted Normalized Boundary Loss for Reducing the Hausdorff Distance  in Medical Imaging Segmentation</b></summary>
  <p><b>编号</b>：[243]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03868</p>
  <p><b>作者</b>：Adrian Celaya,  Alejandro Diaz,  Alex Balsells,  Beatrice Riviere,  David Fuentes</p>
  <p><b>备注</b>：Submitted to 26th International Conference on Medical Image Computing and Computer Assisted Intervention</p>
  <p><b>关键词</b>：deep learning models, Dice coefficient, Hausdorff-based metrics, learning models, measures of success</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Within medical imaging segmentation, the Dice coefficient and Hausdorff-based
metrics are standard measures of success for deep learning models. However,
modern loss functions for medical image segmentation often only consider the
Dice coefficient or similar region-based metrics during training. As a result,
segmentation architectures trained over such loss functions run the risk of
achieving high accuracy for the Dice coefficient but low accuracy for
Hausdorff-based metrics. Low accuracy on Hausdorff-based metrics can be
problematic for applications such as tumor segmentation, where such benchmarks
are crucial. For example, high Dice scores accompanied by significant Hausdorff
errors could indicate that the predictions fail to detect small tumors. We
propose the Weighted Normalized Boundary Loss, a novel loss function to
minimize Hausdorff-based metrics with more desirable numerical properties than
current methods and with weighting terms for class imbalance. Our loss function
outperforms other losses when tested on the BraTS dataset using a standard 3D
U-Net and the state-of-the-art nnUNet architectures. These results suggest we
can improve segmentation accuracy with our novel loss function.</p>
  </details>
</details>
<details>
  <summary>110. <b>标题：Futuristic Variations and Analysis in Fundus Images Corresponding to  Biological Traits</b></summary>
  <p><b>编号</b>：[247]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03839</p>
  <p><b>作者</b>：Muhammad Hassan,  Hao Zhang,  Ahmed Fateh Ameen,  Home Wu Zeng,  Shuye Ma,  Wen Liang,  Dingqi Shang,  Jiaming Ding,  Ziheng Zhan,  Tsz Kwan Lam,  Ming Xu,  Qiming Huang,  Dongmei Wu,  Can Yang Zhang,  Zhou You,  Awiwu Ain,  Pei Wu Qin</p>
  <p><b>备注</b>：10 pages, 4 figures, 3 tables</p>
  <p><b>关键词</b>：biological traits, image captures rear, deep learning methods, estimate biological traits, traits</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Fundus image captures rear of an eye, and which has been studied for the
diseases identification, classification, segmentation, generation, and
biological traits association using handcrafted, conventional, and deep
learning methods. In biological traits estimation, most of the studies have
been carried out for the age prediction and gender classification with
convincing results. However, the current study utilizes the cutting-edge deep
learning (DL) algorithms to estimate biological traits in terms of age and
gender together with associating traits to retinal visuals. For the traits
association, our study embeds aging as the label information into the proposed
DL model to learn knowledge about the effected regions with aging. Our proposed
DL models, named FAG-Net and FGC-Net, correspondingly estimate biological
traits (age and gender) and generates fundus images. FAG-Net can generate
multiple variants of an input fundus image given a list of ages as conditions.
Our study analyzes fundus images and their corresponding association with
biological traits, and predicts of possible spreading of ocular disease on
fundus images given age as condition to the generative model. Our proposed
models outperform the randomly selected state of-the-art DL models.</p>
  </details>
</details>
<details>
  <summary>111. <b>标题：Data-driven Protection of Transformers, Phase Angle Regulators, and  Transmission Lines in Interconnected Power Systems</b></summary>
  <p><b>编号</b>：[248]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03826</p>
  <p><b>作者</b>：Pallav Kumar Bera</p>
  <p><b>备注</b>：Ph.D. thesis, Syracuse University, published by ProQuest. arXiv admin note: text overlap with arXiv:2004.06003</p>
  <p><b>关键词</b>：modern power grids, Phase Angle Regulators, machine learning, dissertation highlights, highlights the growing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This dissertation highlights the growing interest in and adoption of machine
learning (ML) approaches for fault detection in modern power grids. Once a
fault has occurred, it must be identified quickly and preventative steps must
be taken to remove or insulate it. As a result, detecting, locating, and
classifying faults early and accurately can improve safety and dependability
while reducing downtime and hardware damage. ML-based solutions and tools to
carry out effective data processing and analysis to aid power system operations
and decision-making are becoming preeminent with better system condition
awareness and data availability. Power transformers, Phase Shift Transformers
or Phase Angle Regulators, and transmission lines are critical components in
power systems, and ensuring their safety is a primary issue. Differential
relays are commonly employed to protect transformers, whereas distance relays
are utilized to protect transmission lines. Magnetizing inrush, overexcitation,
and current transformer saturation make transformer protection a challenge.
Furthermore, non-standard phase shift, series core saturation, low
turn-to-turn, and turn-to-ground fault currents are non-traditional problems
associated with Phase Angle Regulators. Faults during symmetrical power swings
and unstable power swings may cause mal-operation of distance relays and
unintentional and uncontrolled islanding. The distance relays also mal-operate
for transmission lines connected to type-3 wind farms. The conventional
protection techniques would no longer be adequate to address the above
challenges due to limitations in handling and analyzing massive amounts of
data, limited generalizability, incapability to model non-linear systems, etc.
These limitations of differential and distance protection methods bring forward
the motivation of using ML in addressing various protection challenges.</p>
  </details>
</details>
<details>
  <summary>112. <b>标题：How to Trust Your Diffusion Model: A Convex Optimization Approach to  Conformal Risk Control</b></summary>
  <p><b>编号</b>：[249]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03791</p>
  <p><b>作者</b>：Jacopo Teneggi,  Matt Tivnan,  J Webster Stayman,  Jeremias Sulam</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Score-based generative modeling, Score-based generative, generative modeling, informally referred, continue to grow</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Score-based generative modeling, informally referred to as diffusion models,
continue to grow in popularity across several important domains and tasks.
While they provide high-quality and diverse samples from empirical
distributions, important questions remain on the reliability and
trustworthiness of these sampling procedures for their responsible use in
critical scenarios. Conformal prediction is a modern tool to construct
finite-sample, distribution-free uncertainty guarantees for any black-box
predictor. In this work, we focus on image-to-image regression tasks and we
present a generalization of the Risk-Controlling Prediction Sets (RCPS)
procedure, that we term $K$-RCPS, which allows to $(i)$ provide entrywise
calibrated intervals for future samples of any diffusion model, and $(ii)$
control a certain notion of risk with respect to a ground truth image with
minimal mean interval length. Differently from existing conformal risk control
procedures, ours relies on a novel convex optimization approach that allows for
multidimensional risk control while provably minimizing the mean interval
length. We illustrate our approach on two real-world image denoising problems:
on natural images of faces as well as on computed tomography (CT) scans of the
abdomen, demonstrating state of the art performance.</p>
  </details>
</details>
<details>
  <summary>113. <b>标题：Sketchy: Memory-efficient Adaptive Regularization with Frequent  Directions</b></summary>
  <p><b>编号</b>：[252]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03764</p>
  <p><b>作者</b>：Vladimir Feinberg,  Xinyi Chen,  Y. Jennifer Sun,  Rohan Anil,  Elad Hazan</p>
  <p><b>备注</b>：22 pages, 6 figures, 7 tables, under review</p>
  <p><b>关键词</b>：diagonal entries exhibit, entries exhibit state, Adaptive regularization methods, Adaptive regularization, running time</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Adaptive regularization methods that exploit more than the diagonal entries
exhibit state of the art performance for many tasks, but can be prohibitive in
terms of memory and running time. We find the spectra of the Kronecker-factored
gradient covariance matrix in deep learning (DL) training tasks are
concentrated on a small leading eigenspace that changes throughout training,
motivating a low-rank sketching approach. We describe a generic method for
reducing memory and compute requirements of maintaining a matrix preconditioner
using the Frequent Directions (FD) sketch. Our technique allows interpolation
between resource requirements and the degradation in regret guarantees with
rank $k$: in the online convex optimization (OCO) setting over dimension $d$,
we match full-matrix $d^2$ memory regret using only $dk$ memory up to additive
error in the bottom $d-k$ eigenvalues of the gradient covariance. Further, we
show extensions of our work to Shampoo, placing the method on the
memory-quality Pareto frontier of several large scale benchmarks.</p>
  </details>
</details>
<details>
  <summary>114. <b>标题：Characterizing Financial Market Coverage using Artificial Intelligence</b></summary>
  <p><b>编号</b>：[253]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03694</p>
  <p><b>作者</b>：Jean Marie Tshimula,  D'Jeff K. Nkashama,  Patrick Owusu,  Marc Frappier,  Pierre-Martin Tardif,  Froduald Kabanza,  Armelle Brun,  Jean-Marc Patenaude,  Shengrui Wang,  Belkacem Chikhaoui</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：financial market coverage, market coverage, financial market, characterize financial market, scrutinizes a database</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper scrutinizes a database of over 4900 YouTube videos to characterize
financial market coverage. Financial market coverage generates a large number
of videos. Therefore, watching these videos to derive actionable insights could
be challenging and complex. In this paper, we leverage Whisper, a
speech-to-text model from OpenAI, to generate a text corpus of market coverage
videos from Bloomberg and Yahoo Finance. We employ natural language processing
to extract insights regarding language use from the market coverage. Moreover,
we examine the prominent presence of trending topics and their evolution over
time, and the impacts that some individuals and organizations have on the
financial market. Our characterization highlights the dynamics of the financial
market coverage and provides valuable insights reflecting broad discussions
regarding recent financial events and the world economy.</p>
  </details>
</details>
<h1>人工智能</h1>
<details>
  <summary>1. <b>标题：Diagnosing and Rectifying Vision Models using Language</b></summary>
  <p><b>编号</b>：[1]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04269</p>
  <p><b>作者</b>：Yuhui Zhang,  Jeff Z. HaoChen,  Shih-Cheng Huang,  Kuan-Chieh Wang,  James Zou,  Serena Yeung</p>
  <p><b>备注</b>：Published at ICLR 2023</p>
  <p><b>关键词</b>：Recent multi-modal contrastive, building strong vision, multi-modal contrastive learning, contrastive learning models, embedding space suitable</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent multi-modal contrastive learning models have demonstrated the ability
to learn an embedding space suitable for building strong vision classifiers, by
leveraging the rich information in large-scale image-caption datasets. Our work
highlights a distinct advantage of this multi-modal embedding space: the
ability to diagnose vision classifiers through natural language. The
traditional process of diagnosing model behaviors in deployment settings
involves labor-intensive data acquisition and annotation. Our proposed method
can discover high-error data slices, identify influential attributes and
further rectify undesirable model behaviors, without requiring any visual data.
Through a combination of theoretical explanation and empirical verification, we
present conditions under which classifiers trained on embeddings from one
modality can be equivalently applied to embeddings from another modality. On a
range of image datasets with known error slices, we demonstrate that our method
can effectively identify the error slices and influential attributes, and can
further use language to rectify failure modes of the classifier.</p>
  </details>
</details>
<details>
  <summary>2. <b>标题：Computational Models of Solving Raven's Progressive Matrices: A  Comprehensive Introduction</b></summary>
  <p><b>编号</b>：[8]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04238</p>
  <p><b>作者</b>：Yuan Yang,  Mathilee Kunda</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Raven Progressive, RPM, solving RPM, computational models, measure human intelligence</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As being widely used to measure human intelligence, Raven's Progressive
Matrices (RPM) tests also pose a great challenge for AI systems. There is a
long line of computational models for solving RPM, starting from 1960s, either
to understand the involved cognitive processes or solely for problem-solving
purposes. Due to the dramatic paradigm shifts in AI researches, especially the
advent of deep learning models in the last decade, the computational studies on
RPM have also changed a lot. Therefore, now is a good time to look back at this
long line of research. As the title -- ``a comprehensive introduction'' --
indicates, this paper provides an all-in-one presentation of computational
models for solving RPM, including the history of RPM, intelligence testing
theories behind RPM, item design and automatic item generation of RPM-like
tasks, a conceptual chronicle of computational models for solving RPM, which
reveals the philosophy behind the technology evolution of these models, and
suggestions for transferring human intelligence testing and AI testing.</p>
  </details>
</details>
<details>
  <summary>3. <b>标题：SkyEye: Self-Supervised Bird's-Eye-View Semantic Mapping Using Monocular  Frontal View Images</b></summary>
  <p><b>编号</b>：[10]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04233</p>
  <p><b>作者</b>：Nikhil Gosala,  Kürsat Petek,  Paulo L. J. Drews-Jr,  Wolfram Burgard,  Abhinav Valada</p>
  <p><b>备注</b>：14 pages, 7 figures</p>
  <p><b>关键词</b>：automated driving pipelines, driving pipelines due, BEV semantic map, BEV, decision-making tasks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Bird's-Eye-View (BEV) semantic maps have become an essential component of
automated driving pipelines due to the rich representation they provide for
decision-making tasks. However, existing approaches for generating these maps
still follow a fully supervised training paradigm and hence rely on large
amounts of annotated BEV data. In this work, we address this limitation by
proposing the first self-supervised approach for generating a BEV semantic map
using a single monocular image from the frontal view (FV). During training, we
overcome the need for BEV ground truth annotations by leveraging the more
easily available FV semantic annotations of video sequences. Thus, we propose
the SkyEye architecture that learns based on two modes of self-supervision,
namely, implicit supervision and explicit supervision. Implicit supervision
trains the model by enforcing spatial consistency of the scene over time based
on FV semantic sequences, while explicit supervision exploits BEV pseudolabels
generated from FV semantic annotations and self-supervised depth estimates.
Extensive evaluations on the KITTI-360 dataset demonstrate that our
self-supervised approach performs on par with the state-of-the-art fully
supervised methods and achieves competitive results using only 1% of direct
supervision in the BEV compared to fully supervised approaches. Finally, we
publicly release both our code and the BEV datasets generated from the
KITTI-360 and Waymo datasets.</p>
  </details>
</details>
<details>
  <summary>4. <b>标题：On the Computational Complexity of Ethics: Moral Tractability for Minds  and Machines</b></summary>
  <p><b>编号</b>：[16]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04218</p>
  <p><b>作者</b>：Jakob Stenseke</p>
  <p><b>备注</b>：102 pages, 4 figures, 3 tables</p>
  <p><b>关键词</b>：machine ethicists care, computational complexity, ethicists care, computational, complexity</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Why should moral philosophers, moral psychologists, and machine ethicists
care about computational complexity? Debates on whether artificial intelligence
(AI) can or should be used to solve problems in ethical domains have mainly
been driven by what AI can or cannot do in terms of human capacities. In this
paper, we tackle the problem from the other end by exploring what kind of moral
machines are possible based on what computational systems can or cannot do. To
do so, we analyze normative ethics through the lens of computational
complexity. First, we introduce computational complexity for the uninitiated
reader and discuss how the complexity of ethical problems can be framed within
Marr's three levels of analysis. We then study a range of ethical problems
based on consequentialism, deontology, and virtue ethics, with the aim of
elucidating the complexity associated with the problems themselves (e.g., due
to combinatorics, uncertainty, strategic dynamics), the computational methods
employed (e.g., probability, logic, learning), and the available resources
(e.g., time, knowledge, learning). The results indicate that most problems the
normative frameworks pose lead to tractability issues in every category
analyzed. Our investigation also provides several insights about the
computational nature of normative ethics, including the differences between
rule- and outcome-based moral strategies, and the implementation-variance with
regard to moral resources. We then discuss the consequences complexity results
have for the prospect of moral machines in virtue of the trade-off between
optimality and efficiency. Finally, we elucidate how computational complexity
can be used to inform both philosophical and cognitive-psychological research
on human morality by advancing the Moral Tractability Thesis (MTT).</p>
  </details>
</details>
<details>
  <summary>5. <b>标题：Attending to Graph Transformers</b></summary>
  <p><b>编号</b>：[25]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04181</p>
  <p><b>作者</b>：Luis Müller,  Mikhail Galkin,  Christopher Morris,  Ladislav Rampášek</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：graph neural networks, alternative to established, established techniques, techniques for machine, machine learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recently, transformer architectures for graphs emerged as an alternative to
established techniques for machine learning with graphs, such as graph neural
networks. So far, they have shown promising empirical results, e.g., on
molecular prediction datasets, often attributed to their ability to circumvent
graph neural networks' shortcomings, such as over-smoothing and over-squashing.
Here, we derive a taxonomy of graph transformer architectures, bringing some
order to this emerging field. We overview their theoretical properties, survey
structural and positional encodings, and discuss extensions for important graph
classes, e.g., 3D molecular graphs. Empirically, we probe how well graph
transformers can recover various graph properties, how well they can deal with
heterophilic graphs, and to what extent they prevent over-squashing. Further,
we outline open challenges and research direction to stimulate future work. Our
code is available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>6. <b>标题：DynGFN: Bayesian Dynamic Causal Discovery using Generative Flow Networks</b></summary>
  <p><b>编号</b>：[28]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04178</p>
  <p><b>作者</b>：Lazar Atanackovic,  Alexander Tong,  Jason Hartford,  Leo J. Lee,  Bo Wang,  Yoshua Bengio</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Bayesian causal discovery, causal, causal discovery, Bayesian causal, scientific discovery</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Learning the causal structure of observable variables is a central focus for
scientific discovery. Bayesian causal discovery methods tackle this problem by
learning a posterior over the set of admissible graphs given our priors and
observations. Existing methods primarily consider observations from static
systems and assume the underlying causal structure takes the form of a directed
acyclic graph (DAG). In settings with dynamic feedback mechanisms that regulate
the trajectories of individual variables, this acyclicity assumption fails
unless we account for time. We focus on learning Bayesian posteriors over
cyclic graphs and treat causal discovery as a problem of sparse identification
of a dynamical system. This imposes a natural temporal causal order between
variables and captures cyclic feedback loops through time. Under this lens, we
propose a new framework for Bayesian causal discovery for dynamical systems and
present a novel generative flow network architecture (DynGFN) tailored for this
task. Our results indicate that DynGFN learns posteriors that better
encapsulate the distributions over admissible cyclic causal structures compared
to counterpart state-of-the-art approaches.</p>
  </details>
</details>
<details>
  <summary>7. <b>标题：Multi-Modal Evaluation Approach for Medical Image Segmentation</b></summary>
  <p><b>编号</b>：[40]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04135</p>
  <p><b>作者</b>：Seyed M.R. Modaresi,  Aomar Osmani,  Mohammadreza Razzazi,  Abdelghani Chibani</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：machine learning techniques, medical image segmentation, medical image, learning techniques, high-effort task</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Manual segmentation of medical images (e.g., segmenting tumors in CT scans)
is a high-effort task that can be accelerated with machine learning techniques.
However, selecting the right segmentation approach depends on the evaluation
function, particularly in medical image segmentation where we must deal with
dependency between voxels. For instance, in contrast to classical systems where
the predictions are either correct or incorrect, predictions in medical image
segmentation may be partially correct and incorrect simultaneously. In this
paper, we explore this expressiveness to extract the useful properties of these
systems and formally define a novel multi-modal evaluation (MME) approach to
measure the effectiveness of different segmentation methods. This approach
improves the segmentation evaluation by introducing new relevant and
interpretable characteristics, including detection property, boundary
alignment, uniformity, total volume, and relative volume. Our proposed approach
is open-source and publicly available for use. We have conducted several
reproducible experiments, including the segmentation of pancreas, liver tumors,
and multi-organs datasets, to show the applicability of the proposed approach.</p>
  </details>
</details>
<details>
  <summary>8. <b>标题：Robustness to Spurious Correlations Improves Semantic  Out-of-Distribution Detection</b></summary>
  <p><b>编号</b>：[41]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04132</p>
  <p><b>作者</b>：Lily H. Zhang,  Rajesh Ranganath</p>
  <p><b>备注</b>：AAAI 2023</p>
  <p><b>关键词</b>：nuisance-aware OOD detection, OOD, nuisance-aware OOD, OOD detection, predictive models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Methods which utilize the outputs or feature representations of predictive
models have emerged as promising approaches for out-of-distribution (OOD)
detection of image inputs. However, these methods struggle to detect OOD inputs
that share nuisance values (e.g. background) with in-distribution inputs. The
detection of shared-nuisance out-of-distribution (SN-OOD) inputs is
particularly relevant in real-world applications, as anomalies and
in-distribution inputs tend to be captured in the same settings during
deployment. In this work, we provide a possible explanation for SN-OOD
detection failures and propose nuisance-aware OOD detection to address them.
Nuisance-aware OOD detection substitutes a classifier trained via empirical
risk minimization and cross-entropy loss with one that 1. is trained under a
distribution where the nuisance-label relationship is broken and 2. yields
representations that are independent of the nuisance under this distribution,
both marginally and conditioned on the label. We can train a classifier to
achieve these objectives using Nuisance-Randomized Distillation (NuRD), an
algorithm developed for OOD generalization under spurious correlations. Output-
and feature-based nuisance-aware OOD detection perform substantially better
than their original counterparts, succeeding even when detection based on
domain generalization algorithms fails to improve performance.</p>
  </details>
</details>
<details>
  <summary>9. <b>标题：A Parametric Similarity Method: Comparative Experiments based on  Semantically Annotated Large Datasets</b></summary>
  <p><b>编号</b>：[45]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04123</p>
  <p><b>作者</b>：Antonio De Nicola,  Anna Formica,  Michele Missikoff,  Elaheh Pourabbas,  Francesco Taglino</p>
  <p><b>备注</b>：32 pages, 9 figures, 11 tables</p>
  <p><b>关键词</b>：parametric method SemSimp, method SemSimp aimed, measuring semantic similarity, reference ontology, present the parametric</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present the parametric method SemSimp aimed at measuring semantic
similarity of digital resources. SemSimp is based on the notion of information
content, and it leverages a reference ontology and taxonomic reasoning,
encompassing different approaches for weighting the concepts of the ontology.
In particular, weights can be computed by considering either the available
digital resources or the structure of the reference ontology of a given domain.
SemSimp is assessed against six representative semantic similarity methods for
comparing sets of concepts proposed in the literature, by carrying out an
experimentation that includes both a statistical analysis and an expert
judgement evaluation. To the purpose of achieving a reliable assessment, we
used a real-world large dataset based on the Digital Library of the Association
for Computing Machinery (ACM), and a reference ontology derived from the ACM
Computing Classification System (ACM-CCS). For each method, we considered two
indicators. The first concerns the degree of confidence to identify the
similarity among the papers belonging to some special issues selected from the
ACM Transactions on Information Systems journal, the second the Pearson
correlation with human judgement. The results reveal that one of the
configurations of SemSimp outperforms the other assessed methods. An additional
experiment performed in the domain of physics shows that, in general, SemSimp
provides better results than the other similarity methods.</p>
  </details>
</details>
<details>
  <summary>10. <b>标题：Local Law 144: A Critical Analysis of Regression Metrics</b></summary>
  <p><b>编号</b>：[46]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04119</p>
  <p><b>作者</b>：Giulio Filippi,  Sara Zannone,  Airlie Hilliard,  Adriano Koshiyama</p>
  <p><b>备注</b>：12 pages, 5 figures</p>
  <p><b>关键词</b>：York City Council, City Council passed, Local Law, amount of attention, York City</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The use of automated decision tools in recruitment has received an increasing
amount of attention. In November 2021, the New York City Council passed a
legislation (Local Law 144) that mandates bias audits of Automated Employment
Decision Tools. From 15th April 2023, companies that use automated tools for
hiring or promoting employees are required to have these systems audited by an
independent entity. Auditors are asked to compute bias metrics that compare
outcomes for different groups, based on sex/gender and race/ethnicity
categories at a minimum. Local Law 144 proposes novel bias metrics for
regression tasks (scenarios where the automated system scores candidates with a
continuous range of values). A previous version of the legislation proposed a
bias metric that compared the mean scores of different groups. The new revised
bias metric compares the proportion of candidates in each group that falls
above the median. In this paper, we argue that both metrics fail to capture
distributional differences over the whole domain, and therefore cannot reliably
detect bias. We first introduce two metrics, as possible alternatives to the
legislation metrics. We then compare these metrics over a range of theoretical
examples, for which the legislation proposed metrics seem to underestimate
bias. Finally, we study real data and show that the legislation metrics can
similarly fail in a real-world recruitment application.</p>
  </details>
</details>
<details>
  <summary>11. <b>标题：Training-free Lexical Backdoor Attacks on Language Models</b></summary>
  <p><b>编号</b>：[48]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04116</p>
  <p><b>作者</b>：Yujin Huang,  Terry Yue Zhuo,  Qiongkai Xu,  Han Hu,  Xingliang Yuan,  Chunyang Chen</p>
  <p><b>备注</b>：Accepted to International World Wide Web Conference 2023, Security, Privacy & Trust Track</p>
  <p><b>关键词</b>：natural language processing, language models, Large-scale language models, achieved tremendous success, language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large-scale language models have achieved tremendous success across various
natural language processing (NLP) applications. Nevertheless, language models
are vulnerable to backdoor attacks, which inject stealthy triggers into models
for steering them to undesirable behaviors. Most existing backdoor attacks,
such as data poisoning, require further (re)training or fine-tuning language
models to learn the intended backdoor patterns. The additional training process
however diminishes the stealthiness of the attacks, as training a language
model usually requires long optimization time, a massive amount of data, and
considerable modifications to the model parameters. In this work, we propose
Training-Free Lexical Backdoor Attack (TFLexAttack) as the first training-free
backdoor attack on language models. Our attack is achieved by injecting lexical
triggers into the tokenizer of a language model via manipulating its embedding
dictionary using carefully designed rules. These rules are explainable to human
developers which inspires attacks from a wider range of hackers. The sparse
manipulation of the dictionary also habilitates the stealthiness of our attack.
We conduct extensive experiments on three dominant NLP tasks based on nine
language models to demonstrate the effectiveness and universality of our
attack. The code of this work is available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>12. <b>标题：Assessing the impact of regulations and standards on innovation in the  field of AI</b></summary>
  <p><b>编号</b>：[52]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04110</p>
  <p><b>作者</b>：Alessio Tartaro,  Adam Leon Smith,  Patricia Shaw</p>
  <p><b>备注</b>：10 pages</p>
  <p><b>关键词</b>：regulation stifles innovation, artificial intelligence, maximise benefits, stifles innovation, minimise risks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Regulations and standards in the field of artificial intelligence (AI) are
necessary to minimise risks and maximise benefits, yet some argue that they
stifle innovation. This paper critically examines the idea that regulation
stifles innovation in the field of AI. Current trends in AI regulation,
particularly the proposed European AI Act and the standards supporting its
implementation, are discussed. Arguments in support of the idea that regulation
stifles innovation are analysed and criticised, and an alternative point of
view is offered, showing how regulation and standards can foster innovation in
the field of AI.</p>
  </details>
</details>
<details>
  <summary>13. <b>标题：Triplet Loss-less Center Loss Sampling Strategies in Facial Expression  Recognition Scenarios</b></summary>
  <p><b>编号</b>：[54]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04108</p>
  <p><b>作者</b>：Hossein Rajoli,  Fatemeh Lotfi,  Adham Atyabi,  Fatemeh Afghah</p>
  <p><b>备注</b>：The paper has been accepted in the CISS 2023 and will be published very soon</p>
  <p><b>关键词</b>：convey massive information, expressions convey massive, Facial expressions convey, facial expression recognition, convey massive</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Facial expressions convey massive information and play a crucial role in
emotional expression. Deep neural network (DNN) accompanied by deep metric
learning (DML) techniques boost the discriminative ability of the model in
facial expression recognition (FER) applications. DNN, equipped with only
classification loss functions such as Cross-Entropy cannot compact intra-class
feature variation or separate inter-class feature distance as well as when it
gets fortified by a DML supporting loss item. The triplet center loss (TCL)
function is applied on all dimensions of the sample's embedding in the
embedding space. In our work, we developed three strategies: fully-synthesized,
semi-synthesized, and prediction-based negative sample selection strategies. To
achieve better results, we introduce a selective attention module that provides
a combination of pixel-wise and element-wise attention coefficients using
high-semantic deep features of input samples. We evaluated the proposed method
on the RAF-DB, a highly imbalanced dataset. The experimental results reveal
significant improvements in comparison to the baseline for all three negative
sample selection strategies.</p>
  </details>
</details>
<details>
  <summary>14. <b>标题：Real-Word Error Correction with Trigrams: Correcting Multiple Errors in  a Sentence</b></summary>
  <p><b>编号</b>：[60]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04096</p>
  <p><b>作者</b>：Seyed MohammadSadegh Dashti</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Text Mining, task in Text, fundamental task, Spelling correction, Budanitsky fixed windows</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Spelling correction is a fundamental task in Text Mining. In this study, we
assess the real-word error correction model proposed by Mays, Damerau and
Mercer and describe several drawbacks of the model. We propose a new variation
which focuses on detecting and correcting multiple real-word errors in a
sentence, by manipulating a Probabilistic Context-Free Grammar (PCFG) to
discriminate between items in the search space. We test our approach on the
Wall Street Journal corpus and show that it outperforms Hirst and Budanitsky's
WordNet-based method and Wilcox-O'Hearn, Hirst, and Budanitsky's fixed windows
size method.-O'Hearn, Hirst, and Budanitsky's fixed windows size method.</p>
  </details>
</details>
<details>
  <summary>15. <b>标题：Learning Graph-Enhanced Commander-Executor for Multi-Agent Navigation</b></summary>
  <p><b>编号</b>：[61]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04094</p>
  <p><b>作者</b>：Xinyi Yang,  Shiyu Huang,  Yiwen Sun,  Yuxiang Yang,  Chao Yu,  Wei-Wei Tu,  Huazhong Yang,  Yu Wang</p>
  <p><b>备注</b>：This paper is accepted by aamas 2023</p>
  <p><b>关键词</b>：requires multiple agents, multi-agent navigation problem, limited time, requires multiple, Goal Commander</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper investigates the multi-agent navigation problem, which requires
multiple agents to reach the target goals in a limited time. Multi-agent
reinforcement learning (MARL) has shown promising results for solving this
issue. However, it is inefficient for MARL to directly explore the (nearly)
optimal policy in the large search space, which is exacerbated as the agent
number increases (e.g., 10+ agents) or the environment is more complex (e.g.,
3D simulator). Goal-conditioned hierarchical reinforcement learning (HRL)
provides a promising direction to tackle this challenge by introducing a
hierarchical structure to decompose the search space, where the low-level
policy predicts primitive actions in the guidance of the goals derived from the
high-level policy. In this paper, we propose Multi-Agent Graph-Enhanced
Commander-Executor (MAGE-X), a graph-based goal-conditioned hierarchical method
for multi-agent navigation tasks. MAGE-X comprises a high-level Goal Commander
and a low-level Action Executor. The Goal Commander predicts the probability
distribution of goals and leverages them to assign each agent the most
appropriate final target. The Action Executor utilizes graph neural networks
(GNN) to construct a subgraph for each agent that only contains crucial
partners to improve cooperation. Additionally, the Goal Encoder in the Action
Executor captures the relationship between the agent and the designated goal to
encourage the agent to reach the final target. The results show that MAGE-X
outperforms the state-of-the-art MARL baselines with a 100% success rate with
only 3 million training steps in multi-agent particle environments (MPE) with
50 agents, and at least a 12% higher success rate and 2x higher data efficiency
in a more complicated quadrotor 3D navigation task.</p>
  </details>
</details>
<details>
  <summary>16. <b>标题：Taming Local Effects in Graph-based Spatiotemporal Forecasting</b></summary>
  <p><b>编号</b>：[70]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04071</p>
  <p><b>作者</b>：Andrea Cini,  Ivan Marisca,  Daniele Zambon,  Cesare Alippi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：standard univariate predictors, graph neural networks, Spatiotemporal graph neural, time series, series forecasting applications</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Spatiotemporal graph neural networks have shown to be effective in time
series forecasting applications, achieving better performance than standard
univariate predictors in several settings. These architectures take advantage
of a graph structure and relational inductive biases to learn a single (global)
inductive model to predict any number of the input time series, each associated
with a graph node. Despite the gain achieved in computational and data
efficiency w.r.t. fitting a set of local models, relying on a single global
model can be a limitation whenever some of the time series are generated by a
different spatiotemporal stochastic process. The main objective of this paper
is to understand the interplay between globality and locality in graph-based
spatiotemporal forecasting, while contextually proposing a methodological
framework to rationalize the practice of including trainable node embeddings in
such architectures. We ascribe to trainable node embeddings the role of
amortizing the learning of specialized components. Moreover, embeddings allow
for 1) effectively combining the advantages of shared message-passing layers
with node-specific parameters and 2) efficiently transferring the learned model
to new node sets. Supported by strong empirical evidence, we provide insights
and guidelines for specializing graph-based models to the dynamics of each time
series and show how this aspect plays a crucial role in obtaining accurate
predictions.</p>
  </details>
</details>
<details>
  <summary>17. <b>标题：Probabilistic Attention based on Gaussian Processes for Deep Multiple  Instance Learning</b></summary>
  <p><b>编号</b>：[75]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04061</p>
  <p><b>作者</b>：Arne Schmidt,  Pablo Morales-Álvarez,  Rafael Molina</p>
  <p><b>备注</b>：\c{opyright} 2023 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works</p>
  <p><b>关键词</b>：Multiple Instance Learning, Multiple Instance, weakly supervised learning, supervised learning paradigm, Instance Learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Multiple Instance Learning (MIL) is a weakly supervised learning paradigm
that is becoming increasingly popular because it requires less labeling effort
than fully supervised methods. This is especially interesting for areas where
the creation of large annotated datasets remains challenging, as in medicine.
Although recent deep learning MIL approaches have obtained state-of-the-art
results, they are fully deterministic and do not provide uncertainty
estimations for the predictions. In this work, we introduce the Attention
Gaussian Process (AGP) model, a novel probabilistic attention mechanism based
on Gaussian Processes for deep MIL. AGP provides accurate bag-level predictions
as well as instance-level explainability, and can be trained end-to-end.
Moreover, its probabilistic nature guarantees robustness to overfitting on
small datasets and uncertainty estimations for the predictions. The latter is
especially important in medical applications, where decisions have a direct
impact on the patient's health. The proposed model is validated experimentally
as follows. First, its behavior is illustrated in two synthetic MIL experiments
based on the well-known MNIST and CIFAR-10 datasets, respectively. Then, it is
evaluated in three different real-world cancer detection experiments. AGP
outperforms state-of-the-art MIL approaches, including deterministic deep
learning ones. It shows a strong performance even on a small dataset with less
than 100 labels and generalizes better than competing methods on an external
test set. Moreover, we experimentally show that predictive uncertainty
correlates with the risk of wrong predictions, and therefore it is a good
indicator of reliability in practice. Our code is publicly available.</p>
  </details>
</details>
<details>
  <summary>18. <b>标题：Towards Inferential Reproducibility of Machine Learning Research</b></summary>
  <p><b>编号</b>：[77]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04054</p>
  <p><b>作者</b>：Michael Hagmann,  Stefan Riezler</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：model training runs, replicated model training, machine learning evaluation, observed evaluation scores, training runs</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Reliability of machine learning evaluation -- the consistency of observed
evaluation scores across replicated model training runs -- is affected by
several sources of nondeterminism which can be regarded as measurement noise.
Current tendencies to remove noise in order to enforce reproducibility of
research results neglect inherent nondeterminism at the implementation level
and disregard crucial interaction effects between algorithmic noise factors and
data properties. This limits the scope of conclusions that can be drawn from
such experiments. Instead of removing noise, we propose to incorporate several
sources of variance, including their interaction with data properties, into an
analysis of significance and reliability of machine learning evaluation, with
the aim to draw inferences beyond particular instances of trained models. We
show how to use linear mixed effects models (LMEMs) to analyze performance
evaluation scores, and to conduct statistical inference with a generalized
likelihood ratio test (GLRT). This allows us to incorporate arbitrary sources
of noise like meta-parameter variations into statistical significance testing,
and to assess performance differences conditional on data properties.
Furthermore, a variance component analysis (VCA) enables the analysis of the
contribution of noise sources to overall variance and the computation of a
reliability coefficient by the ratio of substantial to total variance.</p>
  </details>
</details>
<details>
  <summary>19. <b>标题：CrossCodeBench: Benchmarking Cross-Task Generalization of Source Code  Models</b></summary>
  <p><b>编号</b>：[88]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04030</p>
  <p><b>作者</b>：Changan Niu,  Chuanyi Li,  Vincent Ng,  Bin Luo</p>
  <p><b>备注</b>：ICSE 2023</p>
  <p><b>关键词</b>：recent advances showing, source code data, appreciable generalization capability, gain appreciable generalization, large-scale source code</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Despite the recent advances showing that a model pre-trained on large-scale
source code data is able to gain appreciable generalization capability, it
still requires a sizeable amount of data on the target task for fine-tuning.
And the effectiveness of the model generalization is largely affected by the
size and quality of the fine-tuning data, which is detrimental for target tasks
with limited or unavailable resources. Therefore, cross-task generalization,
with the goal of improving the generalization of the model to unseen tasks that
have not been seen before, is of strong research and application value.
In this paper, we propose a large-scale benchmark that includes 216 existing
code-related tasks. Then, we annotate each task with the corresponding meta
information such as task description and instruction, which contains detailed
information about the task and a solution guide. This also helps us to easily
create a wide variety of ``training/evaluation'' task splits to evaluate the
various cross-task generalization capabilities of the model. Then we perform
some preliminary experiments to demonstrate that the cross-task generalization
of models can be largely improved by in-context learning methods such as
few-shot learning and learning from task instructions, which shows the
promising prospects of conducting cross-task learning research on our
benchmark. We hope that the collection of the datasets and our benchmark will
facilitate future work that is not limited to cross-task generalization.</p>
  </details>
</details>
<details>
  <summary>20. <b>标题：A Multitask, Multilingual, Multimodal Evaluation of ChatGPT on  Reasoning, Hallucination, and Interactivity</b></summary>
  <p><b>编号</b>：[92]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04023</p>
  <p><b>作者</b>：Yejin Bang,  Samuel Cahyawijaya,  Nayeon Lee,  Wenliang Dai,  Dan Su,  Bryan Wilie,  Holy Lovenia,  Ziwei Ji,  Tiezheng Yu,  Willy Chung,  Quyet V. Do,  Yan Xu,  Pascale Fung</p>
  <p><b>备注</b>：52 pages</p>
  <p><b>关键词</b>：quantitatively evaluating interactive, paper proposes, proposes a framework, framework for quantitatively, quantitatively evaluating</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper proposes a framework for quantitatively evaluating interactive
LLMs such as ChatGPT using publicly available data sets. We carry out an
extensive technical evaluation of ChatGPT using 21 data sets covering 8
different common NLP application tasks. We evaluate the multitask, multilingual
and multi-modal aspects of ChatGPT based on these data sets and a newly
designed multimodal dataset. We find that ChatGPT outperforms LLMs with
zero-shot learning on most tasks and even outperforms fine-tuned models on some
tasks. We find that it is better at understanding non-Latin script languages
than generating them. It is able to generate multimodal content from textual
prompts, via an intermediate code generation step. Moreover, we find that
ChatGPT is 64.33% accurate on average in 10 different reasoning categories
under logical reasoning, non-textual reasoning, and commonsense reasoning,
hence making it an unreliable reasoner. It is, for example, better at deductive
than inductive reasoning. ChatGPT suffers from hallucination problems like
other LLMs and it generates more extrinsic hallucinations from its parametric
memory as it does not have access to an external knowledge base. Finally, the
interactive feature of ChatGPT enables human collaboration with the underlying
LLM to improve its performance, i.e, 8% ROUGE-1 on summarization and 2% ChrF++
on machine translation, in a multi-turn "prompt engineering" fashion.</p>
  </details>
</details>
<details>
  <summary>21. <b>标题：A Survey on Event Prediction Methods from a Systems Perspective:  Bringing Together Disparate Research Areas</b></summary>
  <p><b>编号</b>：[94]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04018</p>
  <p><b>作者</b>：Janik-Vasily Benzin,  Stefanie Rinderle-Ma</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Event prediction, event prediction methods, future real-world occurrences, future events, future</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Event prediction is the ability of anticipating future events, i.e., future
real-world occurrences, and aims to support the user in deciding on actions
that change future events towards a desired state. An event prediction method
learns the relation between features of past events and future events. It is
applied to newly observed events to predict corresponding future events that
are evaluated with respect to the user's desired future state. If the predicted
future events do not comply with this state, actions are taken towards
achieving desirable future states. Evidently, event prediction is valuable in
many application domains such as business and natural disasters. The diversity
of application domains results in a diverse range of methods that are scattered
across various research areas which, in turn, use different terminology for
event prediction methods. Consequently, sharing methods and knowledge for
developing future event prediction methods is restricted. To facilitate
knowledge sharing on account of a comprehensive classification, integration,
and assessment of event prediction methods, we combine taxonomies and take a
systems perspective to integrate event prediction methods into a single system,
elicit requirements and assess existing work with respect to the requirements.
Based on the assessment, we identify open challenges and discuss future
research directions.</p>
  </details>
</details>
<details>
  <summary>22. <b>标题：Zero-shot Sim2Real Adaptation Across Environments</b></summary>
  <p><b>编号</b>：[95]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04013</p>
  <p><b>作者</b>：Buddhika Laknath Semage,  Thommen George Karimpanal,  Santu Rana,  Svetha Venkatesh</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Simulation based learning, reinforcement learning applications, based learning, Simulation based, applications in robotics</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Simulation based learning often provides a cost-efficient recourse to
reinforcement learning applications in robotics. However, simulators are
generally incapable of accurately replicating real-world dynamics, and thus
bridging the sim2real gap is an important problem in simulation based learning.
Current solutions to bridge the sim2real gap involve hybrid simulators that are
augmented with neural residual models. Unfortunately, they require a separate
residual model for each individual environment configuration (i.e., a fixed
setting of environment variables such as mass, friction etc.), and thus are not
transferable to new environments quickly. To address this issue, we propose a
Reverse Action Transformation (RAT) policy which learns to imitate simulated
policies in the real-world. Once learnt from a single environment, RAT can then
be deployed on top of a Universal Policy Network to achieve zero-shot
adaptation to new environments. We empirically evaluate our approach in a set
of continuous control tasks and observe its advantage as a few-shot and
zero-shot learner over competing baselines.</p>
  </details>
</details>
<details>
  <summary>23. <b>标题：Systematically Finding Security Vulnerabilities in Black-Box Code  Generation Models</b></summary>
  <p><b>编号</b>：[96]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04012</p>
  <p><b>作者</b>：Hossein Hajipour,  Thorsten Holz,  Lea Schönherr,  Mario Fritz</p>
  <p><b>备注</b>：14 pages, 12 figures</p>
  <p><b>关键词</b>：models, code generation, achieved breakthroughs, programming language tasks, generation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recently, large language models for code generation have achieved
breakthroughs in several programming language tasks. Their advances in
competition-level programming problems have made them an emerging pillar in
AI-assisted pair programming. Tools such as GitHub Copilot are already part of
the daily programming workflow and are used by more than a million developers.
The training data for these models is usually collected from open-source
repositories (e.g., GitHub) that contain software faults and security
vulnerabilities. This unsanitized training data can lead language models to
learn these vulnerabilities and propagate them in the code generation
procedure. Given the wide use of these models in the daily workflow of
developers, it is crucial to study the security aspects of these models
systematically.
In this work, we propose the first approach to automatically finding security
vulnerabilities in black-box code generation models. To achieve this, we
propose a novel black-box inversion approach based on few-shot prompting. We
evaluate the effectiveness of our approach by examining code generation models
in the generation of high-risk security weaknesses. We show that our approach
automatically and systematically finds 1000s of security vulnerabilities in
various code generation models, including the commercial black-box model GitHub
Copilot.</p>
  </details>
</details>
<details>
  <summary>24. <b>标题：Leveraging Summary Guidance on Medical Report Summarization</b></summary>
  <p><b>编号</b>：[99]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04001</p>
  <p><b>作者</b>：Yunqi Zhu,  Xuebing Yang,  Yuanyuan Wu,  Wensheng Zhang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：deidentified large medical, large medical text, medical text datasets, study presents, presents three deidentified</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This study presents three deidentified large medical text datasets, named
DISCHARGE, ECHO and RADIOLOGY, which contain 50K, 16K and 378K pairs of report
and summary that are derived from MIMIC-III, respectively. We implement
convincing baselines of automated abstractive summarization on the proposed
datasets with pre-trained encoder-decoder language models, including BERT2BERT,
T5-large and BART. Further, based on the BART model, we leverage the sampled
summaries from the train set as prior knowledge guidance, for encoding
additional contextual representations of the guidance with the encoder and
enhancing the decoding representations in the decoder. The experimental results
confirm the improvement of ROUGE scores and BERTScore made by the proposed
method, outperforming the larger model T5-large.</p>
  </details>
</details>
<details>
  <summary>25. <b>标题：SimCGNN: Simple Contrastive Graph Neural Network for Session-based  Recommendation</b></summary>
  <p><b>编号</b>：[100]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03997</p>
  <p><b>作者</b>：Yuan Cao,  Xudong Zhang,  Fan Zhang,  Feifei Kou,  Josiah Poon,  Xiongnan Jin,  Yongheng Wang,  Jinpeng Chen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：anonymous users, attention from researchers, focuses on next-item, received increasingly, increasingly more attention</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Session-based recommendation (SBR) problem, which focuses on next-item
prediction for anonymous users, has received increasingly more attention from
researchers. Existing graph-based SBR methods all lack the ability to
differentiate between sessions with the same last item, and suffer from severe
popularity bias. Inspired by nowadays emerging contrastive learning methods,
this paper presents a Simple Contrastive Graph Neural Network for Session-based
Recommendation (SimCGNN). In SimCGNN, we first obtain normalized session
embeddings on constructed session graphs. We next construct positive and
negative samples of the sessions by two forward propagation and a novel
negative sample selection strategy, and then calculate the constructive loss.
Finally, session embeddings are used to give prediction. Extensive experiments
conducted on two real-word datasets show our SimCGNN achieves a significant
improvement over state-of-the-art methods.</p>
  </details>
</details>
<details>
  <summary>26. <b>标题：Fully-Dynamic Approximate Decision Trees With Worst-Case Update Time  Guarantees</b></summary>
  <p><b>编号</b>：[102]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03994</p>
  <p><b>作者</b>：Marco Bressan,  Mauro Sozio</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：worst-case running time, decision tree, decision, arbitrary sequence, sequence of insertions</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We give the first algorithm that maintains an approximate decision tree over
an arbitrary sequence of insertions and deletions of labeled examples, with
strong guarantees on the worst-case running time per update request. For
instance, we show how to maintain a decision tree where every vertex has Gini
gain within an additive $\alpha$ of the optimum by performing
$O\Big(\frac{d\,(\log n)^4}{\alpha^3}\Big)$ elementary operations per update,
where $d$ is the number of features and $n$ the maximum size of the active set
(the net result of the update requests). We give similar bounds for the
information gain and the variance gain. In fact, all these bounds are
corollaries of a more general result, stated in terms of decision rules --
functions that, given a set $S$ of labeled examples, decide whether to split
$S$ or predict a label. Decision rules give a unified view of greedy decision
tree algorithms regardless of the example and label domains, and lead to a
general notion of $\epsilon$-approximate decision trees that, for natural
decision rules such as those used by ID3 or C4.5, implies the gain
approximation guarantees above. The heart of our work provides a deterministic
algorithm that, given any decision rule and any $\epsilon > 0$, maintains an
$\epsilon$-approximate tree using $O\!\left(\frac{d\, f(n)}{n}
\operatorname{poly}\frac{h}{\epsilon}\right)$ operations per update, where
$f(n)$ is the complexity of evaluating the rule over a set of $n$ examples and
$h$ is the maximum height of the maintained tree.</p>
  </details>
</details>
<details>
  <summary>27. <b>标题：Non-zero-sum Game Control for Multi-vehicle Driving via Reinforcement  Learning</b></summary>
  <p><b>编号</b>：[114]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03958</p>
  <p><b>作者</b>：Xujie Song,  Zexi Lin</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：affected by surrounding, surrounding vehicles, vehicles, Nash equilibrium, driving</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>When a vehicle drives on the road, its behaviors will be affected by
surrounding vehicles. Prediction and decision should not be considered as two
separate stages because all vehicles make decisions interactively. This paper
constructs the multi-vehicle driving scenario as a non-zero-sum game and
proposes a novel game control framework, which consider prediction, decision
and control as a whole. The mutual influence of interactions between vehicles
is considered in this framework because decisions are made by Nash equilibrium
strategy. To efficiently obtain the strategy, ADP, a model-based reinforcement
learning method, is used to solve coupled Hamilton-Jacobi-Bellman equations.
Driving performance is evaluated by tracking, efficiency, safety and comfort
indices. Experiments show that our algorithm could drive perfectly by directly
controlling acceleration and steering angle. Vehicles could learn interactive
behaviors such as overtaking and pass. In summary, we propose a non-zero-sum
game framework for modeling multi-vehicle driving, provide an effective way to
solve the Nash equilibrium driving strategy, and validate at non-signalized
intersections.</p>
  </details>
</details>
<details>
  <summary>28. <b>标题：Improving (Dis)agreement Detection with Inductive Social Relation  Information From Comment-Reply Interactions</b></summary>
  <p><b>编号</b>：[120]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03950</p>
  <p><b>作者</b>：Yun Luo,  Zihan Liu,  Stan Z. Li,  Yue Zhang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Social relation, Social relation information, social relation graph, Dis, agreement detection aims</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>(Dis)agreement detection aims to identify the authors' attitudes or positions
(\textit{agree, disagree, neutral}) towards a specific text. It is limited
for existing methods merely using textual information for identifying
(dis)agreements, especially for cross-domain settings. Social relation
information can play an assistant role in the (dis)agreement task besides
textual information. We propose a novel method to extract such relation
information from (dis)agreement data into an inductive social relation graph,
merely using the comment-reply pairs without any additional platform-specific
information. The inductive social relation globally considers the historical
discussion and the relation between authors. Textual information based on a
pre-trained language model and social relation information encoded by
pre-trained RGCN are jointly considered for (dis)agreement detection.
Experimental results show that our model achieves state-of-the-art performance
for both the in-domain and cross-domain tasks on the benchmark -- DEBAGREEMENT.
We find social relations can boost the performance of the (dis)agreement
detection model, especially for the long-token comment-reply pairs,
demonstrating the effectiveness of the social relation graph. We also explore
the effect of the knowledge graph embedding methods, the information fusing
method, and the time interval in constructing the social relation graph, which
shows the effectiveness of our model.</p>
  </details>
</details>
<details>
  <summary>29. <b>标题：A Model for Forecasting Air Quality Index in Port Harcourt Nigeria Using  Bi-LSTM Algorithm</b></summary>
  <p><b>编号</b>：[128]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03930</p>
  <p><b>作者</b>：O. E. Taylor,  P. S. Ezekiel</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：toxic gases, harmful gases, Bi-directional LSTM model, release of toxic, concentration of harmful</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The release of toxic gases by industries, emissions from vehicles, and an
increase in the concentration of harmful gases and particulate matter in the
atmosphere are all contributing factors to the deterioration of the quality of
the air. Factors such as industries, urbanization, population growth, and the
increased use of vehicles contribute to the rapid increase in pollution levels,
which can adversely impact human health. This paper presents a model for
forecasting the air quality index in Nigeria using the Bi-directional LSTM
model. The air pollution data was downloaded from an online database (UCL). The
dataset was pre-processed using both pandas tools in python. The pre-processed
result was used as input features in training a Bi-LSTM model in making future
forecasts of the values of the particulate matter Pm2.5, and Pm10. The Bi-LSTM
model was evaluated using some evaluation parameters such as mean square error,
mean absolute error, absolute mean square, and R^2 square. The result of the
Bi-LSTM shows a mean square error of 52.99%, relative mean square error of
7.28%, mean absolute error of 3.4%, and R^2 square of 97%. The model. This
shows that the model follows a seamless trend in forecasting the air quality in
Port Harcourt, Nigeria.</p>
  </details>
</details>
<details>
  <summary>30. <b>标题：CCRep: Learning Code Change Representations via Pre-Trained Code Model  and Query Back</b></summary>
  <p><b>编号</b>：[130]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03924</p>
  <p><b>作者</b>：Zhongxin Liu,  Zhijie Tang,  Xin Xia,  Xiaohu Yang</p>
  <p><b>备注</b>：Accepted by ICSE 2023</p>
  <p><b>关键词</b>：code, software engineering tasks, engineering tasks related, numeric feature vectors, essential step</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Representing code changes as numeric feature vectors, i.e., code change
representations, is usually an essential step to automate many software
engineering tasks related to code changes, e.g., commit message generation and
just-in-time defect prediction. Intuitively, the quality of code change
representations is crucial for the effectiveness of automated approaches. Prior
work on code changes usually designs and evaluates code change representation
approaches for a specific task, and little work has investigated code change
encoders that can be used and jointly trained on various tasks. To fill this
gap, this work proposes a novel Code Change Representation learning approach
named CCRep, which can learn to encode code changes as feature vectors for
diverse downstream tasks. Specifically, CCRep regards a code change as the
combination of its before-change and after-change code, leverages a pre-trained
code model to obtain high-quality contextual embeddings of code, and uses a
novel mechanism named query back to extract and encode the changed code
fragments and make them explicitly interact with the whole code change. To
evaluate CCRep and demonstrate its applicability to diverse code-change-related
tasks, we apply it to three tasks: commit message generation, patch correctness
assessment, and just-in-time defect prediction. Experimental results show that
CCRep outperforms the state-of-the-art techniques on each task.</p>
  </details>
</details>
<details>
  <summary>31. <b>标题：Predictable MDP Abstraction for Unsupervised Model-Based RL</b></summary>
  <p><b>编号</b>：[132]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03921</p>
  <p><b>作者</b>：Seohong Park,  Sergey Levine</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：key component, predicts the outcomes, model-based reinforcement learning, Markov decision processes, complex Markov decision</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A key component of model-based reinforcement learning (RL) is a dynamics
model that predicts the outcomes of actions. Errors in this predictive model
can degrade the performance of model-based controllers, and complex Markov
decision processes (MDPs) can present exceptionally difficult prediction
problems. To mitigate this issue, we propose predictable MDP abstraction (PMA):
instead of training a predictive model on the original MDP, we train a model on
a transformed MDP with a learned action space that only permits predictable,
easy-to-model actions, while covering the original state-action space as much
as possible. As a result, model learning becomes easier and more accurate,
which allows robust, stable model-based planning or model-based RL. This
transformation is learned in an unsupervised manner, before any task is
specified by the user. Downstream tasks can then be solved with model-based
control in a zero-shot fashion, without additional environment interactions. We
theoretically analyze PMA and empirically demonstrate that PMA leads to
significant improvements over prior unsupervised model-based RL approaches in a
range of benchmark environments. Our code and videos are available at
this https URL</p>
  </details>
</details>
<details>
  <summary>32. <b>标题：Syntax and Domain Aware Model for Unsupervised Program Translation</b></summary>
  <p><b>编号</b>：[140]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03908</p>
  <p><b>作者</b>：Fang Liu,  Jia Li,  Li Zhang</p>
  <p><b>备注</b>：Accepted by International Conference on Software Engineering (ICSE-2023)</p>
  <p><b>关键词</b>：software migration, growing interest, software and society, software, interest in software</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>There is growing interest in software migration as the development of
software and society. Manually migrating projects between languages is
error-prone and expensive. In recent years, researchers have begun to explore
automatic program translation using supervised deep learning techniques by
learning from large-scale parallel code corpus. However, parallel resources are
scarce in the programming language domain, and it is costly to collect
bilingual data manually. To address this issue, several unsupervised
programming translation systems are proposed. However, these systems still rely
on huge monolingual source code to train, which is very expensive. Besides,
these models cannot perform well for translating the languages that are not
seen during the pre-training procedure. In this paper, we propose SDA-Trans, a
syntax and domain-aware model for program translation, which leverages the
syntax structure and domain knowledge to enhance the cross-lingual transfer
ability. SDA-Trans adopts unsupervised training on a smaller-scale corpus,
including Python and Java monolingual programs. The experimental results on
function translation tasks between Python, Java, and C++ show that SDA-Trans
outperforms many large-scale pre-trained models, especially for unseen language
translation.</p>
  </details>
</details>
<details>
  <summary>33. <b>标题：COMBO: A Complete Benchmark for Open KG Canonicalization</b></summary>
  <p><b>编号</b>：[141]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03905</p>
  <p><b>作者</b>：Chengyue Jiang,  Yong Jiang,  Weiqi Wu,  Yuting Zheng,  Pengjun Xie,  Kewei Tu</p>
  <p><b>备注</b>：18 pages</p>
  <p><b>关键词</b>：Open knowledge graph, knowledge graph, raw text, canonicalization, millions of raw</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Open knowledge graph (KG) consists of (subject, relation, object) triples
extracted from millions of raw text. The subject and object noun phrases and
the relation in open KG have severe redundancy and ambiguity and need to be
canonicalized. Existing datasets for open KG canonicalization only provide gold
entity-level canonicalization for noun phrases. In this paper, we present
COMBO, a Complete Benchmark for Open KG canonicalization. Compared with
existing datasets, we additionally provide gold canonicalization for relation
phrases, gold ontology-level canonicalization for noun phrases, as well as
source sentences from which triples are extracted. We also propose metrics for
evaluating each type of canonicalization. On the COMBO dataset, we empirically
compare previously proposed canonicalization methods as well as a few simple
baseline methods based on pretrained language models. We find that properly
encoding the phrases in a triple using pretrained language models results in
better relation canonicalization and ontology-level canonicalization of the
noun phrase. We release our dataset, baselines, and evaluation scripts at
this https URL.</p>
  </details>
</details>
<details>
  <summary>34. <b>标题：Zero-shot Generation of Coherent Storybook from Plain Text Story using  Diffusion Models</b></summary>
  <p><b>编号</b>：[144]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03900</p>
  <p><b>作者</b>：Hyeonho Jeong,  Gihyun Kwon,  Jong Chul Ye</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：human-devised natural language, Recent advancements, opened new possibilities, possibilities for guiding, guiding the creation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent advancements in large scale text-to-image models have opened new
possibilities for guiding the creation of images through human-devised natural
language. However, while prior literature has primarily focused on the
generation of individual images, it is essential to consider the capability of
these models to ensure coherency within a sequence of images to fulfill the
demands of real-world applications such as storytelling. To address this, here
we present a novel neural pipeline for generating a coherent storybook from the
plain text of a story. Specifically, we leverage a combination of a pre-trained
Large Language Model and a text-guided Latent Diffusion Model to generate
coherent images. While previous story synthesis frameworks typically require a
large-scale text-to-image model trained on expensive image-caption pairs to
maintain the coherency, we employ simple textual inversion techniques along
with detector-based semantic image editing which allows zero-shot generation of
the coherent storybook. Experimental results show that our proposed method
outperforms state-of-the-art image editing baselines.</p>
  </details>
</details>
<details>
  <summary>35. <b>标题：Multimodal Recommender Systems: A Survey</b></summary>
  <p><b>编号</b>：[150]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03883</p>
  <p><b>作者</b>：Qidong Liu,  Jiaxi Hu,  Yutian Xiao,  Jingtong Gao,  Xiangyu Zhao</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：integral toolkit, toolkit of online, recommender system, Multimodal Recommender System, online services</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The recommender system (RS) has been an integral toolkit of online services.
They are equipped with various deep learning techniques to model user
preference based on identifier and attribute information. With the emergence of
multimedia services, such as short video, news and etc., understanding these
contents while recommending becomes critical. Besides, multimodal features are
also helpful in alleviating the problem of data sparsity in RS. Thus,
Multimodal Recommender System (MRS) has attracted much attention from both
academia and industry recently. In this paper, we will give a comprehensive
survey of the MRS models, mainly from technical views. First, we conclude the
general procedures and major challenges for MRS. Then, we introduce the
existing MRS models according to three categories, i.e., Feature Interaction,
Feature Enhancement and Model Optimization. To make it convenient for those who
want to research this field, we also summarize the dataset and code resources.
Finally, we discuss some promising future directions of MRS and conclude this
paper.</p>
  </details>
</details>
<details>
  <summary>36. <b>标题：Neural Artistic Style Transfer with Conditional Adversaria</b></summary>
  <p><b>编号</b>：[153]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03875</p>
  <p><b>作者</b>：P. N. Deelaka</p>
  <p><b>备注</b>：Conditional Adversarial Generative Network based novel style transfer model</p>
  <p><b>关键词</b>：artistic style transformation, style, modify the appearance, image, model</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A neural artistic style transformation (NST) model can modify the appearance
of a simple image by adding the style of a famous image. Even though the
transformed images do not look precisely like artworks by the same artist of
the respective style images, the generated images are appealing. Generally, a
trained NST model specialises in a style, and a single image represents that
style. However, generating an image under a new style is a tedious process,
which includes full model training. In this paper, we present two methods that
step toward the style image independent neural style transfer model. In other
words, the trained model could generate semantically accurate generated image
under any content, style image input pair. Our novel contribution is a
unidirectional-GAN model that ensures the Cyclic consistency by the model
architecture.Furthermore, this leads to much smaller model size and an
efficient training and validation phase.</p>
  </details>
</details>
<details>
  <summary>37. <b>标题：Geometric Perception based Efficient Text Recognition</b></summary>
  <p><b>编号</b>：[155]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03873</p>
  <p><b>作者</b>：P.N.Deelaka,  D.R.Jayakodi,  D.Y.Silva</p>
  <p><b>备注</b>：high efficient scene text recognition model introduction</p>
  <p><b>关键词</b>：Scene Text Recognition, Text Recognition, Scene Text, regular scene text, prominent sub-tasks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Every Scene Text Recognition (STR) task consists of text localization \& text
recognition as the prominent sub-tasks. However, in real-world applications
with fixed camera positions such as equipment monitor reading, image-based data
entry, and printed document data extraction, the underlying data tends to be
regular scene text. Hence, in these tasks, the use of generic, bulky models
comes up with significant disadvantages compared to customized, efficient
models in terms of model deployability, data privacy \& model reliability.
Therefore, this paper introduces the underlying concepts, theory,
implementation, and experiment results to develop models, which are highly
specialized for the task itself, to achieve not only the SOTA performance but
also to have minimal model weights, shorter inference time, and high model
reliability. We introduce a novel deep learning architecture (GeoTRNet),
trained to identify digits in a regular scene image, only using the geometrical
features present, mimicking human perception over text recognition. The code is
publicly available at this https URL</p>
  </details>
</details>
<details>
  <summary>38. <b>标题：Topological Deep Learning: A Review of an Emerging Paradigm</b></summary>
  <p><b>编号</b>：[165]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03836</p>
  <p><b>作者</b>：Ali Zia,  Abdelwahed Khamis,  James Nichols,  Zeeshan Hayder,  Vivien Rolland,  Lars Petersson</p>
  <p><b>备注</b>：7 pages and 2 references</p>
  <p><b>关键词</b>：deep learning, Topological data analysis, deep, learning, TDA</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Topological data analysis (TDA) provides insight into data shape. The
summaries obtained by these methods are principled global descriptions of
multi-dimensional data whilst exhibiting stable properties such as robustness
to deformation and noise. Such properties are desirable in deep learning
pipelines but they are typically obtained using non-TDA strategies. This is
partly caused by the difficulty of combining TDA constructs (e.g. barcode and
persistence diagrams) with current deep learning algorithms. Fortunately, we
are now witnessing a growth of deep learning applications embracing
topologically-guided components. In this survey, we review the nascent field of
topological deep learning by first revisiting the core concepts of TDA. We then
explore how the use of TDA techniques has evolved over time to support deep
learning frameworks, and how they can be integrated into different aspects of
deep learning. Furthermore, we touch on TDA usage for analyzing existing deep
models; deep topological analytics. Finally, we discuss the challenges and
future prospects of topological deep learning.</p>
  </details>
</details>
<details>
  <summary>39. <b>标题：Clinical BioBERT Hyperparameter Optimization using Genetic Algorithm  Clinical BioBERT Hyperparameter Optimization using Genetic Algorithm</b></summary>
  <p><b>编号</b>：[168]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03822</p>
  <p><b>作者</b>：Navya Martin Kollapally,  James Geller</p>
  <p><b>备注</b>：Under review as regular paper</p>
  <p><b>关键词</b>：individual health outcomes, small portion, Clinical factors account, affect an individual, health outcomes</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Clinical factors account only for a small portion, about 10-30%, of the
controllable factors that affect an individual's health outcomes. The remaining
factors include where a person was born and raised, where he/she pursued their
education, what their work and family environment is like, etc. These factors
are collectively referred to as Social Determinants of Health (SDoH). The
majority of SDoH data is recorded in unstructured clinical notes by physicians
and practitioners. Recording SDoH data in a structured manner (in an EHR) could
greatly benefit from a dedicated ontology of SDoH terms. Our research focuses
on extracting sentences from clinical notes, making use of such an SDoH
ontology (called SOHO) to provide appropriate concepts. We utilize recent
advancements in Deep Learning to optimize the hyperparameters of a Clinical
BioBERT model for SDoH text. A genetic algorithm-based hyperparameter tuning
regimen was implemented to identify optimal parameter settings. To implement a
complete classifier, we pipelined Clinical BioBERT with two subsequent linear
layers and two dropout layers. The output predicts whether a text fragment
describes an SDoH issue of the patient. We compared the AdamW, Adafactor, and
LAMB optimizers. In our experiments, AdamW outperformed the others in terms of
accuracy.</p>
  </details>
</details>
<details>
  <summary>40. <b>标题：A Unified Multi-view Multi-person Tracking Framework</b></summary>
  <p><b>编号</b>：[170]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03820</p>
  <p><b>作者</b>：Fan Yang,  Shigeyuki Odashima,  Sosuke Yamao,  Hiroaki Fujimoto,  Shoichi Masui,  Shan Jiang</p>
  <p><b>备注</b>：Accepted to Computational Visual Media</p>
  <p><b>关键词</b>：pose tracking, Tracking, footprint tracking, significant development, footprint</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Although there is a significant development in 3D Multi-view Multi-person
Tracking (3D MM-Tracking), current 3D MM-Tracking frameworks are designed
separately for footprint and pose tracking. Specifically, frameworks designed
for footprint tracking cannot be utilized in 3D pose tracking, because they
directly obtain 3D positions on the ground plane with a homography projection,
which is inapplicable to 3D poses above the ground. In contrast, frameworks
designed for pose tracking generally isolate multi-view and multi-frame
associations and may not be robust to footprint tracking, since footprint
tracking utilizes fewer key points than pose tracking, which weakens multi-view
association cues in a single frame. This study presents a Unified Multi-view
Multi-person Tracking framework to bridge the gap between footprint tracking
and pose tracking. Without additional modifications, the framework can adopt
monocular 2D bounding boxes and 2D poses as the input to produce robust 3D
trajectories for multiple persons. Importantly, multi-frame and multi-view
information are jointly employed to improve the performance of association and
triangulation. The effectiveness of our framework is verified by accomplishing
state-of-the-art performance on the Campus and Shelf datasets for 3D pose
tracking, and by comparable results on the WILDTRACK and MMPTRACK datasets for
3D footprint tracking.</p>
  </details>
</details>
<details>
  <summary>41. <b>标题：Intend-Wait-Perceive-Cross: Exploring the Effects of Perceptual  Limitations on Pedestrian Decision-Making</b></summary>
  <p><b>编号</b>：[172]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03816</p>
  <p><b>作者</b>：Iuliia Kotseruba,  Amir Rasouli</p>
  <p><b>备注</b>：6 pages, 5 figures, 2 tables</p>
  <p><b>关键词</b>：makes strong assumptions, behavior understanding focuses, Current research, understanding focuses, makes strong</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Current research on pedestrian behavior understanding focuses on the dynamics
of pedestrians and makes strong assumptions about their perceptual abilities.
For instance, it is often presumed that pedestrians have omnidirectional view
of the scene around them. In practice, human visual system has a number of
limitations, such as restricted field of view (FoV) and range of sensing, which
consequently affect decision-making and overall behavior of the pedestrians. By
including explicit modeling of pedestrian perception, we can better understand
its effect on their decision-making. To this end, we propose an agent-based
pedestrian behavior model Intend-Wait-Perceive-Cross with three novel elements:
field of vision, working memory, and scanning strategy, all motivated by
findings from behavioral literature. Through extensive experimentation we
investigate the effects of perceptual limitations on safe crossing decisions
and demonstrate how they contribute to detectable changes in pedestrian
behaviors.</p>
  </details>
</details>
<details>
  <summary>42. <b>标题：Long Text and Multi-Table Summarization: Dataset and Method</b></summary>
  <p><b>编号</b>：[173]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03815</p>
  <p><b>作者</b>：Shuaiqi Liu,  Jiannong Cao,  Ruosong Yang,  Zhiyuan Wen</p>
  <p><b>备注</b>：EMNLP 2022 Findings</p>
  <p><b>关键词</b>：concise summary covering, document salient information, Automatic document summarization, document summarization aims, aims to produce</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Automatic document summarization aims to produce a concise summary covering
the input document's salient information. Within a report document, the salient
information can be scattered in the textual and non-textual content. However,
existing document summarization datasets and methods usually focus on the text
and filter out the non-textual content. Missing tabular data can limit produced
summaries' informativeness, especially when summaries require covering
quantitative descriptions of critical metrics in tables. Existing datasets and
methods cannot meet the requirements of summarizing long text and multiple
tables in each report. To deal with the scarcity of available data, we propose
FINDSum, the first large-scale dataset for long text and multi-table
summarization. Built on 21,125 annual reports from 3,794 companies, it has two
subsets for summarizing each company's results of operations and liquidity. To
summarize the long text and dozens of tables in each report, we present three
types of summarization methods. Besides, we propose a set of evaluation metrics
to assess the usage of numerical information in produced summaries. Dataset
analyses and experimental results indicate the importance of jointly
considering input textual and tabular data when summarizing report documents.</p>
  </details>
</details>
<details>
  <summary>43. <b>标题：Modified Policy Iteration for Exponential Cost Risk Sensitive MDPs</b></summary>
  <p><b>编号</b>：[175]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03811</p>
  <p><b>作者</b>：Yashaswini Murthy,  Mehrdad Moharrami,  R. Srikant</p>
  <p><b>备注</b>：30 pages</p>
  <p><b>关键词</b>：reinforcement learning algorithms, policy iteration, Modified policy iteration, optimistic policy iteration, iteration</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Modified policy iteration (MPI) also known as optimistic policy iteration is
at the core of many reinforcement learning algorithms. It works by combining
elements of policy iteration and value iteration. The convergence of MPI has
been well studied in the case of discounted and average-cost MDPs. In this
work, we consider the exponential cost risk-sensitive MDP formulation, which is
known to provide some robustness to model parameters. Although policy iteration
and value iteration have been well studied in the context of risk sensitive
MDPs, modified policy iteration is relatively unexplored. We provide the first
proof that MPI also converges for the risk-sensitive problem in the case of
finite state and action spaces. Since the exponential cost formulation deals
with the multiplicative Bellman equation, our main contribution is a
convergence proof which is quite different than existing results for discounted
and risk-neutral average-cost problems. The proof of approximate modified
policy iteration for risk sensitive MDPs is also provided in the appendix.</p>
  </details>
</details>
<details>
  <summary>44. <b>标题：Standing Between Past and Future: Spatio-Temporal Modeling for  Multi-Camera 3D Multi-Object Tracking</b></summary>
  <p><b>编号</b>：[180]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03802</p>
  <p><b>作者</b>：Ziqi Pang,  Jie Li,  Pavel Tokmakov,  Dian Chen,  Sergey Zagoruyko,  Yu-Xiong Wang</p>
  <p><b>备注</b>：15 pages, 8 figures</p>
  <p><b>关键词</b>：work proposes, MOT, multi-object tracking, future reasoning, reasoning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This work proposes an end-to-end multi-camera 3D multi-object tracking (MOT)
framework. It emphasizes spatio-temporal continuity and integrates both past
and future reasoning for tracked objects. Thus, we name it "Past-and-Future
reasoning for Tracking" (PF-Track). Specifically, our method adapts the
"tracking by attention" framework and represents tracked instances coherently
over time with object queries. To explicitly use historical cues, our "Past
Reasoning" module learns to refine the tracks and enhance the object features
by cross-attending to queries from previous frames and other objects. The
"Future Reasoning" module digests historical information and predicts robust
future trajectories. In the case of long-term occlusions, our method maintains
the object positions and enables re-association by integrating motion
predictions. On the nuScenes dataset, our method improves AMOTA by a large
margin and remarkably reduces ID-Switches by 90% compared to prior approaches,
which is an order of magnitude less. The code and models are made available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>45. <b>标题：MACOptions: Multi-Agent Learning with Centralized Controller and Options  Framework</b></summary>
  <p><b>编号</b>：[181]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03800</p>
  <p><b>作者</b>：Alakh Aggarwal,  Rishita Bansal,  Parth Padalkar,  Sriraam Natarajan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：days automation, Q-learning, Options Framework, planning, days</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>These days automation is being applied everywhere. In every environment,
planning for the actions to be taken by the agents is an important aspect. In
this paper, we plan to implement planning for multi-agents with a centralized
controller. We compare three approaches: random policy, Q-learning, and
Q-learning with Options Framework. We also show the effectiveness of planners
by showing performance comparison between Q-Learning with Planner and without
Planner.</p>
  </details>
</details>
<details>
  <summary>46. <b>标题：Toward a Theory of Causation for Interpreting Neural Code Models</b></summary>
  <p><b>编号</b>：[187]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03788</p>
  <p><b>作者</b>：David N. Palacio,  Nathan Cooper,  Alvaro Rodriguez,  Kevin Moran,  Denys Poshyvanyk</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：commercial developer tools, Neural Code Models, Neural Language Models, Neural Code, Neural Language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Neural Language Models of Code, or Neural Code Models (NCMs), are rapidly
progressing from research prototypes to commercial developer tools. As such,
understanding the capabilities and limitations of such models is becoming
critical. However, the abilities of these models are typically measured using
automated metrics that often only reveal a portion of their real-world
performance. While, in general, the performance of NCMs appears promising,
currently much is unknown about how such models arrive at decisions. To this
end, this paper introduces $do_{code}$, a post-hoc interpretability methodology
specific to NCMs that is capable of explaining model predictions. $do_{code}$
is based upon causal inference to enable programming language-oriented
explanations. While the theoretical underpinnings of $do_{code}$ are extensible
to exploring different model properties, we provide a concrete instantiation
that aims to mitigate the impact of spurious correlations by grounding
explanations of model behavior in properties of programming languages. To
demonstrate the practical benefit of $do_{code}$, we illustrate the insights
that our framework can provide by performing a case study on two popular deep
learning architectures and nine NCMs. The results of this case study illustrate
that our studied NCMs are sensitive to changes in code syntax and statistically
learn to predict tokens related to blocks of code (e.g., brackets, parenthesis,
semicolon) with less confounding bias as compared to other programming language
constructs. These insights demonstrate the potential of $do_{code}$ as a useful
model debugging mechanism that may aid in discovering biases and limitations in
NCMs.</p>
  </details>
</details>
<details>
  <summary>47. <b>标题：Reliable Natural Language Understanding with Large Language Models and  Answer Set Programming</b></summary>
  <p><b>编号</b>：[193]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03780</p>
  <p><b>作者</b>：Abhiramon Rajasekharan,  Yankai Zeng,  Parth Padalkar,  Gopal Gupta</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：existing commonsense knowledge, extracting information, draw conclusions, existing commonsense, Humans understand language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Humans understand language by extracting information (meaning) from
sentences, combining it with existing commonsense knowledge, and then
performing reasoning to draw conclusions. While large language models (LLMs)
such as GPT-3 and ChatGPT are able to leverage patterns in the text to solve a
variety of NLP tasks, they fall short in problems that require reasoning. They
also cannot reliably explain the answers generated for a given question. In
order to emulate humans better, we propose STAR, a framework that combines LLMs
with Answer Set Programming (ASP). We show how LLMs can be used to effectively
extract knowledge -- represented as predicates -- from language. Goal-directed
ASP is then employed to reliably reason over this knowledge. We apply the STAR
framework to three different NLU tasks requiring reasoning: qualitative
reasoning, mathematical reasoning, and goal-directed conversation. Our
experiments reveal that STAR is able to bridge the gap of reasoning in NLU
tasks, leading to significant performance improvements, especially for smaller
LLMs, i.e., LLMs with a smaller number of parameters. NLU applications
developed using the STAR framework are also explainable: along with the
predicates generated, a justification in the form of a proof tree can be
produced for a given output.</p>
  </details>
</details>
<details>
  <summary>48. <b>标题：Provably Efficient Offline Goal-Conditioned Reinforcement Learning with  General Function Approximation and Single-Policy Concentrability</b></summary>
  <p><b>编号</b>：[200]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03770</p>
  <p><b>作者</b>：Hanlin Zhu,  Amy Zhang</p>
  <p><b>备注</b>：26 pages</p>
  <p><b>关键词</b>：reach diverse goals, Goal-conditioned reinforcement learning, learning general-purpose skills, Goal-conditioned reinforcement, diverse goals</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Goal-conditioned reinforcement learning (GCRL) refers to learning
general-purpose skills which aim to reach diverse goals. In particular, offline
GCRL only requires purely pre-collected datasets to perform training tasks
without additional interactions with the environment. Although offline GCRL has
become increasingly prevalent and many previous works have demonstrated its
empirical success, the theoretical understanding of efficient offline GCRL
algorithms is not well established, especially when the state space is huge and
the offline dataset only covers the policy we aim to learn. In this paper, we
propose a novel provably efficient algorithm (the sample complexity is
$\tilde{O}({\rm poly}(1/\epsilon))$ where $\epsilon$ is the desired
suboptimality of the learned policy) with general function approximation. Our
algorithm only requires nearly minimal assumptions of the dataset
(single-policy concentrability) and the function class (realizability).
Moreover, our algorithm consists of two uninterleaved optimization steps, which
we refer to as $V$-learning and policy learning, and is computationally stable
since it does not involve minimax optimization. To the best of our knowledge,
this is the first algorithm with general function approximation and
single-policy concentrability that is both statistically efficient and
computationally stable.</p>
  </details>
</details>
<details>
  <summary>49. <b>标题：Catch Me If You Can: Improving Adversaries in Cyber-Security With  Q-Learning Algorithms</b></summary>
  <p><b>编号</b>：[201]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03768</p>
  <p><b>作者</b>：Arti Bandhana,  Ondřej Lukáš,  Sebastian Garcia,  Tomáš Kroupa</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：automated tools capable, ongoing rise, rise in cyberattacks, lack of skilled, skilled professionals</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The ongoing rise in cyberattacks and the lack of skilled professionals in the
cybersecurity domain to combat these attacks show the need for automated tools
capable of detecting an attack with good performance. Attackers disguise their
actions and launch attacks that consist of multiple actions, which are
difficult to detect. Therefore, improving defensive tools requires their
calibration against a well-trained attacker. In this work, we propose a model
of an attacking agent and environment and evaluate its performance using basic
Q-Learning, Naive Q-learning, and DoubleQ-Learning, all of which are variants
of Q-Learning. The attacking agent is trained with the goal of exfiltrating
data whereby all the hosts in the network have a non-zero detection
probability. Results show that the DoubleQ-Learning agent has the best overall
performance rate by successfully achieving the goal in $70\%$ of the
interactions.</p>
  </details>
</details>
<details>
  <summary>50. <b>标题：A Vector Quantized Approach for Text to Speech Synthesis on Real-World  Spontaneous Speech</b></summary>
  <p><b>编号</b>：[223]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.04215</p>
  <p><b>作者</b>：Li-Wei Chen,  Shinji Watanabe,  Alexander Rudnicky</p>
  <p><b>备注</b>：Accepted to AAAI 2023</p>
  <p><b>关键词</b>：trained on reading, reading or acted, acted corpora, human-level naturalness, TTS systems</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent Text-to-Speech (TTS) systems trained on reading or acted corpora have
achieved near human-level naturalness. The diversity of human speech, however,
often goes beyond the coverage of these corpora. We believe the ability to
handle such diversity is crucial for AI systems to achieve human-level
communication. Our work explores the use of more abundant real-world data for
building speech synthesizers. We train TTS systems using real-world speech from
YouTube and podcasts. We observe the mismatch between training and inference
alignments in mel-spectrogram based autoregressive models, leading to
unintelligible synthesis, and demonstrate that learned discrete codes within
multiple code groups effectively resolves this issue. We introduce our MQTTS
system whose architecture is designed for multiple code generation and
monotonic alignment, along with the use of a clean silence prompt to improve
synthesis quality. We conduct ablation analyses to identify the efficacy of our
methods. We show that MQTTS outperforms existing TTS systems in several
objective and subjective measures.</p>
  </details>
</details>
<details>
  <summary>51. <b>标题：Prediction approaches for partly missing multi-omics covariate data: A  literature review and an empirical comparison study</b></summary>
  <p><b>编号</b>：[236]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03991</p>
  <p><b>作者</b>：Roman Hornung,  Frederik Ludwigs,  Jonas Hagenberg,  Anne-Laure Boulesteix</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：high-dimensional molecular data, molecular data consisting, data, high-dimensional molecular, omics data</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As the availability of omics data has increased in the last few years, more
multi-omics data have been generated, that is, high-dimensional molecular data
consisting of several types such as genomic, transcriptomic, or proteomic data,
all obtained from the same patients. Such data lend themselves to being used as
covariates in automatic outcome prediction because each omics type may
contribute unique information, possibly improving predictions compared to using
only one omics data type. Frequently, however, in the training data and the
data to which automatic prediction rules should be applied, the test data, the
different omics data types are not available for all patients. We refer to this
type of data as block-wise missing multi-omics data. First, we provide a
literature review on existing prediction methods applicable to such data.
Subsequently, using a collection of 13 publicly available multi-omics data
sets, we compare the predictive performances of several of these approaches for
different block-wise missingness patterns. Finally, we discuss the results of
this empirical comparison study and draw some tentative conclusions.</p>
  </details>
</details>
<details>
  <summary>52. <b>标题：Sketchy: Memory-efficient Adaptive Regularization with Frequent  Directions</b></summary>
  <p><b>编号</b>：[252]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03764</p>
  <p><b>作者</b>：Vladimir Feinberg,  Xinyi Chen,  Y. Jennifer Sun,  Rohan Anil,  Elad Hazan</p>
  <p><b>备注</b>：22 pages, 6 figures, 7 tables, under review</p>
  <p><b>关键词</b>：diagonal entries exhibit, entries exhibit state, Adaptive regularization methods, Adaptive regularization, running time</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Adaptive regularization methods that exploit more than the diagonal entries
exhibit state of the art performance for many tasks, but can be prohibitive in
terms of memory and running time. We find the spectra of the Kronecker-factored
gradient covariance matrix in deep learning (DL) training tasks are
concentrated on a small leading eigenspace that changes throughout training,
motivating a low-rank sketching approach. We describe a generic method for
reducing memory and compute requirements of maintaining a matrix preconditioner
using the Frequent Directions (FD) sketch. Our technique allows interpolation
between resource requirements and the degradation in regret guarantees with
rank $k$: in the online convex optimization (OCO) setting over dimension $d$,
we match full-matrix $d^2$ memory regret using only $dk$ memory up to additive
error in the bottom $d-k$ eigenvalues of the gradient covariance. Further, we
show extensions of our work to Shampoo, placing the method on the
memory-quality Pareto frontier of several large scale benchmarks.</p>
  </details>
</details>
<details>
  <summary>53. <b>标题：Characterizing Financial Market Coverage using Artificial Intelligence</b></summary>
  <p><b>编号</b>：[253]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.03694</p>
  <p><b>作者</b>：Jean Marie Tshimula,  D'Jeff K. Nkashama,  Patrick Owusu,  Marc Frappier,  Pierre-Martin Tardif,  Froduald Kabanza,  Armelle Brun,  Jean-Marc Patenaude,  Shengrui Wang,  Belkacem Chikhaoui</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：financial market coverage, market coverage, financial market, characterize financial market, scrutinizes a database</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper scrutinizes a database of over 4900 YouTube videos to characterize
financial market coverage. Financial market coverage generates a large number
of videos. Therefore, watching these videos to derive actionable insights could
be challenging and complex. In this paper, we leverage Whisper, a
speech-to-text model from OpenAI, to generate a text corpus of market coverage
videos from Bloomberg and Yahoo Finance. We employ natural language processing
to extract insights regarding language use from the market coverage. Moreover,
we examine the prominent presence of trending topics and their evolution over
time, and the impacts that some individuals and organizations have on the
financial market. Our characterization highlights the dynamics of the financial
market coverage and provides valuable insights reflecting broad discussions
regarding recent financial events and the world economy.</p>
  </details>
</details>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">徐耀彬</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://louishsu.xyz/2023/02/10/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html">http://louishsu.xyz/2023/02/10/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://louishsu.xyz" target="_blank">LOUIS' BLOG</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"></div><div class="post_share"><div class="social-share" data-image="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="next-post pull-full"><a href="/2022/11/26/%E5%8D%87%E7%BA%A7%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E5%85%A8%E6%94%BB%E7%95%A5.html"><img class="next-cover" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">升级深度学习开发环境全攻略</div></div></a></div></nav><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="twikoo-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="card-info-avatar is-center"><img class="avatar-img" src="/img/touxiang.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/><div class="author-info__name">徐耀彬</div><div class="author-info__description">专注于自然语言处理前沿技术与应用价值！</div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">13</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">标签</div><div class="length-num">4</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">分类</div><div class="length-num">7</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/isLouisHsu"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/isLouisHsu" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:is.louishsu@foxmail.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>公告</span></div><div class="announcement_content">记录和分享一些学习和开源内容，若有问题可通过邮箱is.louishsu@foxmail.com联系，欢迎交流！！</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">1.</span> <span class="toc-text">统计</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">2.</span> <span class="toc-text">计算机视觉</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">3.</span> <span class="toc-text">自然语言处理</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">4.</span> <span class="toc-text">机器学习</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">5.</span> <span class="toc-text">人工智能</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2023/02/10/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html" title="Arxiv每日速递(2023-02-10)"><img src="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Arxiv每日速递(2023-02-10)"/></a><div class="content"><a class="title" href="/2023/02/10/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html" title="Arxiv每日速递(2023-02-10)">Arxiv每日速递(2023-02-10)</a><time datetime="2023-02-10T00:43:44.400Z" title="发表于 2023-02-10 08:43:44">2023-02-10</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/11/26/%E5%8D%87%E7%BA%A7%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E5%85%A8%E6%94%BB%E7%95%A5.html" title="升级深度学习开发环境全攻略"><img src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="升级深度学习开发环境全攻略"/></a><div class="content"><a class="title" href="/2022/11/26/%E5%8D%87%E7%BA%A7%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E5%85%A8%E6%94%BB%E7%95%A5.html" title="升级深度学习开发环境全攻略">升级深度学习开发环境全攻略</a><time datetime="2022-11-26T15:29:06.000Z" title="发表于 2022-11-26 23:29:06">2022-11-26</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/11/17/2022%E5%85%A8%E7%90%83%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%8A%80%E6%9C%AF%E5%88%9B%E6%96%B0%E5%A4%A7%E8%B5%9B(GAIIC2022)%EF%BC%9A%E5%95%86%E5%93%81%E6%A0%87%E9%A2%98%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB(%E4%BA%8C%E7%AD%89%E5%A5%96).html" title="2022全球人工智能技术创新大赛(GAIIC2022)：商品标题实体识别(二等奖)"><img src="https://cdn.kesci.com/upload/image/r7j60un866.png?imageView2/2/w/2500/h/2500" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="2022全球人工智能技术创新大赛(GAIIC2022)：商品标题实体识别(二等奖)"/></a><div class="content"><a class="title" href="/2022/11/17/2022%E5%85%A8%E7%90%83%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%8A%80%E6%9C%AF%E5%88%9B%E6%96%B0%E5%A4%A7%E8%B5%9B(GAIIC2022)%EF%BC%9A%E5%95%86%E5%93%81%E6%A0%87%E9%A2%98%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB(%E4%BA%8C%E7%AD%89%E5%A5%96).html" title="2022全球人工智能技术创新大赛(GAIIC2022)：商品标题实体识别(二等奖)">2022全球人工智能技术创新大赛(GAIIC2022)：商品标题实体识别(二等奖)</a><time datetime="2022-11-17T14:29:06.000Z" title="发表于 2022-11-17 22:29:06">2022-11-17</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/10/22/%E4%B8%AD%E5%9B%BD%E6%B3%95%E5%BE%8B%E6%99%BA%E8%83%BD%E6%8A%80%E6%9C%AF%E8%AF%84%E6%B5%8B(CAIL2021)%EF%BC%9A%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96(Rank2).html" title="中国法律智能技术评测(CAIL2021)：信息抽取(Rank2)"><img src="http://cail.cipsc.org.cn/img/index_mainpic.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="中国法律智能技术评测(CAIL2021)：信息抽取(Rank2)"/></a><div class="content"><a class="title" href="/2021/10/22/%E4%B8%AD%E5%9B%BD%E6%B3%95%E5%BE%8B%E6%99%BA%E8%83%BD%E6%8A%80%E6%9C%AF%E8%AF%84%E6%B5%8B(CAIL2021)%EF%BC%9A%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96(Rank2).html" title="中国法律智能技术评测(CAIL2021)：信息抽取(Rank2)">中国法律智能技术评测(CAIL2021)：信息抽取(Rank2)</a><time datetime="2021-10-22T14:29:06.000Z" title="发表于 2021-10-22 22:29:06">2021-10-22</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/05/19/%E5%85%A8%E7%90%83%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%8A%80%E6%9C%AF%E5%88%9B%E6%96%B0%E5%A4%A7%E8%B5%9B%E3%80%90%E8%B5%9B%E9%81%93%E4%B8%80%E3%80%91%EF%BC%9A%E5%8C%BB%E5%AD%A6%E5%BD%B1%E5%83%8F%E6%8A%A5%E5%91%8A%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B(%E4%B8%89%E7%AD%89%E5%A5%96).html" title="全球人工智能技术创新大赛【赛道一】：医学影像报告异常检测(三等奖)"><img src="https://tianchi-public.oss-cn-hangzhou.aliyuncs.com/public/files/forum/161037709574435991610377095138.jpeg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="全球人工智能技术创新大赛【赛道一】：医学影像报告异常检测(三等奖)"/></a><div class="content"><a class="title" href="/2021/05/19/%E5%85%A8%E7%90%83%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%8A%80%E6%9C%AF%E5%88%9B%E6%96%B0%E5%A4%A7%E8%B5%9B%E3%80%90%E8%B5%9B%E9%81%93%E4%B8%80%E3%80%91%EF%BC%9A%E5%8C%BB%E5%AD%A6%E5%BD%B1%E5%83%8F%E6%8A%A5%E5%91%8A%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B(%E4%B8%89%E7%AD%89%E5%A5%96).html" title="全球人工智能技术创新大赛【赛道一】：医学影像报告异常检测(三等奖)">全球人工智能技术创新大赛【赛道一】：医学影像报告异常检测(三等奖)</a><time datetime="2021-05-19T09:57:06.000Z" title="发表于 2021-05-19 17:57:06">2021-05-19</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2023 By 徐耀彬</div><div class="footer_custom_text"><p><a style="margin-inline:5px"target="_blank"href="https://hexo.io/"><img src="https://img.shields.io/badge/Frame-Hexo-blue?style=flat&logo=hexo"title="博客框架为Hexo"alt="img"></a><a style="margin-inline:5px"target="_blank"href="https://butterfly.js.org/"><img src="https://img.shields.io/badge/Theme-Butterfly-6513df?style=flat&logo=bitdefender"title="主题采用butterfly"alt="img"></a><a style="margin-inline:5px"target="_blank"href="https://www.jsdelivr.com/"><img src="https://img.shields.io/badge/CDN-jsDelivr-orange?style=flat&logo=jsDelivr"title="本站使用JsDelivr为静态资源提供CDN加速"alt="img"></a><a style="margin-inline:5px"target="_blank"href="https://github.com/"><img src="https://img.shields.io/badge/Source-Github-d021d6?style=flat&logo=GitHub"title="本站项目由Gtihub托管"alt="img"></a><a style="margin-inline:5px"target="_blank"href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img src="https://img.shields.io/badge/Copyright-BY--NC--SA%204.0-d42328?style=flat&logo=Claris"alt="img"title="本站采用知识共享署名-非商业性使用-相同方式共享4.0国际许可协议进行许可"></a></br></p></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="font-plus" type="button" title="放大字体"><i class="fas fa-plus"></i></button><button id="font-minus" type="button" title="缩小字体"><i class="fas fa-minus"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div></div><hr/><div id="local-search-results"></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.css"><script>(() => {
  document.querySelectorAll('#article-container span.katex-display').forEach(item => {
    btf.wrap(item, 'div', '', 'katex-wrap')
  })
})()</script><script>(()=>{
  const $countDom = document.getElementById('twikoo-count')
  const init = () => {
    let initData = {
      el: '#twikoo-wrap',
      envId: 'blog-',
      region: ''
    }

    if (false) {
      const otherData = false
      initData = Object.assign(initData, otherData)
    }
    
    twikoo.init(initData)
  }

  const getCount = () => {
    twikoo.getCommentsCount({
      envId: 'blog-',
      region: '',
      urls: [window.location.pathname],
      includeReply: false
    }).then(function (res) {
      $countDom.innerText = res[0].count
    }).catch(function (err) {
      console.error(err);
    });
  }

  const loadTwikoo = (bool = false) => {
    if (typeof twikoo === 'object') {
      init()
      bool && $countDom && setTimeout(getCount,0)
    } else {
      getScript('https://cdn.jsdelivr.net/npm/twikoo/dist/twikoo.all.min.js').then(()=> {
        init()
        bool && $countDom && setTimeout(getCount,0)
      })
    }
  }

  if ('Twikoo' === 'Twikoo' || !false) {
    if (false) btf.loadComment(document.getElementById('twikoo-wrap'), loadTwikoo)
    else loadTwikoo(true)
  } else {
    window.loadOtherComment = () => {
      loadTwikoo()
    }
  }
})()</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><!-- hexo injector body_end start --> <script data-pjax>if(document.getElementById('recent-posts') && (location.pathname ==='/'|| '/' ==='all')){
    var parent = document.getElementById('recent-posts');
    var child = '<div class="recent-post-item" style="width:100%;height: auto"><div id="catalog_magnet"><div class="magnet_item"><a class="magnet_link" href="http://louishsu.xyz/categories/机器学习/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🐱 机器学习 (1)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://louishsu.xyz/categories/自然语言处理/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">📚 自然语言处理 (1)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://louishsu.xyz/categories/竞赛相关/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🎮 竞赛相关 (3)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://louishsu.xyz/categories/阅读笔记/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🎮 阅读笔记 (1)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><a class="magnet_link_more"  href="http://louishsu.xyz/categories" style="flex:1;text-align: center;margin-bottom: 10px;">查看更多...</a></div></div>';
    console.log('已挂载magnet')
    parent.insertAdjacentHTML("afterbegin",child)}
     </script><style>#catalog_magnet{flex-wrap: wrap;display: flex;width:100%;justify-content:space-between;padding: 10px 10px 0 10px;align-content: flex-start;}.magnet_item{flex-basis: calc(50% - 5px);background: #f2f2f2;margin-bottom: 10px;border-radius: 8px;transition: all 0.2s ease-in-out;}.magnet_item:hover{background: #b30070}.magnet_link_more{color:#555}.magnet_link{color:black}.magnet_link:hover{color:white}@media screen and (max-width: 600px) {.magnet_item {flex-basis: 100%;}}.magnet_link_context{display:flex;padding: 10px;font-size:16px;transition: all 0.2s ease-in-out;}.magnet_link_context:hover{padding: 10px 20px;}</style>
    <style></style>
  <script data-pjax src="https://cdn.jsdelivr.net/gh/Zfour/hexo-github-calendar@1.21/hexo_githubcalendar.js"></script>
  <script data-pjax>
        function GithubCalendarConfig(){
            var git_githubapiurl ="https://python-github-calendar-api.vercel.app/api?isLouisHsu";
            var git_color =['#ebedf0', '#fdcdec', '#fc9bd9', '#fa6ac5', '#f838b2', '#f5089f', '#c4067e', '#92055e', '#540336', '#48022f', '#30021f'];
            var git_user ="isLouisHsu";
            var parent_div_git = document.getElementById('recent-posts');
            var git_div_html = '<div class="recent-post-item" style="width:100%;height:auto;padding:10px;"><div id="github_loading" style="width:10%;height:100%;margin:0 auto;display: block"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"  viewBox="0 0 50 50" style="enable-background:new 0 0 50 50" xml:space="preserve"><path fill="#d0d0d0" d="M25.251,6.461c-10.318,0-18.683,8.365-18.683,18.683h4.068c0-8.071,6.543-14.615,14.615-14.615V6.461z" transform="rotate(275.098 25 25)"><animateTransform attributeType="xml" attributeName="transform" type="rotate" from="0 25 25" to="360 25 25" dur="0.6s" repeatCount="indefinite"></animateTransform></path></svg></div><div id="github_container"></div></div>';
            if(parent_div_git && location.pathname =='/'){
                console.log('已挂载github calendar')
                // parent_div_git.innerHTML=git_div_html+parent_div_git.innerHTML // 无报错，但不影响使用(支持pjax跳转)
                parent_div_git.insertAdjacentHTML("afterbegin",git_div_html) // 有报错，但不影响使用(支持pjax跳转)
            };
            GithubCalendar(git_githubapiurl,git_color,git_user)
        }
        if(document.getElementById('recent-posts')){
            GithubCalendarConfig()
        }
    </script>
    <style>#github_container{min-height:280px}@media screen and (max-width:650px) {#github_container{background-image:;min-height:0px}}</style>
    <style></style><script data-pjax>function electric_clock_injector_config(){
                var parent_div_git = document.getElementsByClassName('sticky_layout')[0];
                var item_html = '<div class="card-widget card-clock"><div class="card-glass"><div class="card-background"><div class="card-content"><div id="hexo_electric_clock"><img id="card-clock-loading" src="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-clock/clock/images/weather/loading.gif" style="height: 120px; width: 100%;" data-ll-status="loading" class="entered loading"></div></div></div></div></div>';
                console.log('已挂载electric_clock')
                // parent_div_git.innerHTML=item_html+parent_div_git.innerHTML // 无报错，但不影响使用(支持pjax跳转)
                parent_div_git.insertAdjacentHTML("afterbegin",item_html) // 有报错，但不影响使用(支持pjax跳转)
            }if( document.getElementsByClassName('sticky_layout')[0] && (location.pathname ==='all'|| 'all' ==='all')){

            electric_clock_injector_config()
        } </script><script src="https://pv.sohu.com/cityjson?ie=utf-8"></script><script data-pjax  src="https://cdn.jsdelivr.net/gh/Zfour/hexo-electric-clock@1.0.6/clock.js"></script><!-- hexo injector body_end end --><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"model":{"jsonPath":"/live2dw/assets/hijiki.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":false},"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body></html>