<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Arxiv每日速递(2023-02-15) | LOUIS' BLOG</title><meta name="author" content="徐耀彬"><meta name="copyright" content="徐耀彬"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="本篇博文主要展示每日从Arxiv论文网站获取的最新论文列表，以计算机视觉、自然语言处理、机器学习、人工智能等大方向进行划分。 统计 今日共更新565篇论文，其中：  105篇计算机视觉（cs.CV） 67篇自然语言处理（cs.CL） 195篇机器学习（cs.LG） 112篇人工智能（cs.AI）  计算机视觉    1. 标题：3D-aware Blending with Generative N">
<meta property="og:type" content="article">
<meta property="og:title" content="Arxiv每日速递(2023-02-15)">
<meta property="og:url" content="http://louishsu.xyz/2023/02/15/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html">
<meta property="og:site_name" content="LOUIS&#39; BLOG">
<meta property="og:description" content="本篇博文主要展示每日从Arxiv论文网站获取的最新论文列表，以计算机视觉、自然语言处理、机器学习、人工智能等大方向进行划分。 统计 今日共更新565篇论文，其中：  105篇计算机视觉（cs.CV） 67篇自然语言处理（cs.CL） 195篇机器学习（cs.LG） 112篇人工智能（cs.AI）  计算机视觉    1. 标题：3D-aware Blending with Generative N">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png">
<meta property="article:published_time" content="2023-02-15T00:44:26.223Z">
<meta property="article:modified_time" content="2023-02-15T00:45:52.766Z">
<meta property="article:author" content="徐耀彬">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://louishsu.xyz/2023/02/15/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2023-02-15 08:45:52'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const fontSizeVal = saveToLocal.get('global-font-size')
    if (fontSizeVal !== undefined) {
      document.documentElement.style.setProperty('--global-font-size', fontSizeVal + 'px')
    }
    })(window)</script><link rel="stylesheet" href="/css/background.css"><script src="https://cdn.jsdelivr.net/npm/echarts@4.7.0/dist/echarts.min.js"></script><!-- hexo injector head_end start --><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Zfour/hexo-electric-clock@1.0.6/clock.css"><!-- hexo injector head_end end --><meta name="generator" content="Hexo 5.4.2"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="author-avatar"><img class="avatar-img" src="/img/touxiang.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">13</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">标签</div><div class="length-num">4</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">分类</div><div class="length-num">7</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/message/"><i class="fa-fw far fa-comment-dots"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa-fw fa fa-book"></i><span> 找文章</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></li><li><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></li><li><a class="site-page" href="/charts/"><i class="fa-fw fa fa-archive"></i><span> 统计</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-tools"></i><span> 工具</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/md_editor/"><i class="fa-fw fas fa-pen"></i><span> 在线markdown</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/isLouisHsu/blog/tree/master/source/_posts"><i class="fa-fw fa fa-star"></i><span> 在线push</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa-brands fa-app-store"></i><span> 利器</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" target="_blank" rel="noopener" href="https://code.visualstudio.com/"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> VSCode：微软旗下的跨平台代码编辑软件</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://mobaxterm.mobatek.net/"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> MobaXterm：超好用的全能远程终端</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://www.zotero.org/"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> Zotero：便于收集、组织、引用、共享的文献管理工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/CopyTranslator/CopyTranslator"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> CopyTranslator：“复制即翻译”的外文辅助阅读翻译解决方案</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://ditto-cp.sourceforge.io/"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> Ditto：强大的Windows剪贴板增强工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/indiff/qttabbar"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> QtTabBar：在Windows资源管理器中使用多标签功能扩展工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/sentialx/multrin"><i class="fa-fw fa-sharp fa-solid fa-star-half-stroke"></i><span> Multrin：“窗口合并”辅助小工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/Wox-launcher/Wox"><i class="fa-fw fa-sharp fa-solid fa-star-half-stroke"></i><span> Wox &amp; Everything：基于名称快速定位文件和文件夹的搜索工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/NickeManarin/ScreenToGif"><i class="fa-fw fa-regular fa-star"></i><span> ScreenToGif：快速录制屏幕指定区域并保存为动图文件</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://mathpix.com/"><i class="fa-fw fa-regular fa-star"></i><span> Mathpix Snipping：识别数学公式并转换成LaTeX</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">LOUIS' BLOG</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/message/"><i class="fa-fw far fa-comment-dots"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa-fw fa fa-book"></i><span> 找文章</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></li><li><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></li><li><a class="site-page" href="/charts/"><i class="fa-fw fa fa-archive"></i><span> 统计</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-tools"></i><span> 工具</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/md_editor/"><i class="fa-fw fas fa-pen"></i><span> 在线markdown</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/isLouisHsu/blog/tree/master/source/_posts"><i class="fa-fw fa fa-star"></i><span> 在线push</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa-brands fa-app-store"></i><span> 利器</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" target="_blank" rel="noopener" href="https://code.visualstudio.com/"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> VSCode：微软旗下的跨平台代码编辑软件</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://mobaxterm.mobatek.net/"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> MobaXterm：超好用的全能远程终端</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://www.zotero.org/"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> Zotero：便于收集、组织、引用、共享的文献管理工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/CopyTranslator/CopyTranslator"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> CopyTranslator：“复制即翻译”的外文辅助阅读翻译解决方案</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://ditto-cp.sourceforge.io/"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> Ditto：强大的Windows剪贴板增强工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/indiff/qttabbar"><i class="fa-fw fa-sharp fa-solid fa-star"></i><span> QtTabBar：在Windows资源管理器中使用多标签功能扩展工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/sentialx/multrin"><i class="fa-fw fa-sharp fa-solid fa-star-half-stroke"></i><span> Multrin：“窗口合并”辅助小工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/Wox-launcher/Wox"><i class="fa-fw fa-sharp fa-solid fa-star-half-stroke"></i><span> Wox &amp; Everything：基于名称快速定位文件和文件夹的搜索工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/NickeManarin/ScreenToGif"><i class="fa-fw fa-regular fa-star"></i><span> ScreenToGif：快速录制屏幕指定区域并保存为动图文件</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://mathpix.com/"><i class="fa-fw fa-regular fa-star"></i><span> Mathpix Snipping：识别数学公式并转换成LaTeX</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Arxiv每日速递(2023-02-15)<a class="post-edit-link" href="https://github.com/isLouisHsu/blog/tree/master/source_posts/Arxiv每日速递.md" title="编辑" target="_blank"><i class="fas fa-pencil-square"></i></a></h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-02-15T00:44:26.223Z" title="发表于 2023-02-15 08:44:26">2023-02-15</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-02-15T00:45:52.766Z" title="更新于 2023-02-15 08:45:52">2023-02-15</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">阅读笔记</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">118.3k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>707分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span><span class="post-meta-separator">|</span><span class="post-meta-commentcount"><i class="far fa-comments fa-fw post-meta-icon"></i><span class="post-meta-label">评论数:</span><a href="/2023/02/15/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html#post-comment"><span id="twikoo-count"></span></a></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><p>本篇博文主要展示每日从Arxiv论文网站获取的最新论文列表，以计算机视觉、自然语言处理、机器学习、人工智能等大方向进行划分。</p>
<h1>统计</h1>
<p>今日共更新565篇论文，其中：</p>
<ul>
<li><a href="#%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89">105篇计算机视觉（cs.CV）</a></li>
<li><a href="#%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86">67篇自然语言处理（cs.CL）</a></li>
<li><a href="#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0">195篇机器学习（cs.LG）</a></li>
<li><a href="#%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD">112篇人工智能（cs.AI）</a></li>
</ul>
<h1>计算机视觉</h1>
<details>
  <summary>1. <b>标题：3D-aware Blending with Generative NeRFs</b></summary>
  <p><b>编号</b>：[1]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06608</p>
  <p><b>作者</b>：Hyunsu Kim,  Gayoung Lee,  Yunjey Choi,  Jin-Hwa Kim,  Jun-Yan Zhu</p>
  <p><b>备注</b>：Project page: this https URL</p>
  <p><b>关键词</b>：multiple images seamlessly, combine multiple images, aims to combine, combine multiple, images seamlessly</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Image blending aims to combine multiple images seamlessly. It remains
challenging for existing 2D-based methods, especially when input images are
misaligned due to differences in 3D camera poses and object shapes. To tackle
these issues, we propose a 3D-aware blending method using generative Neural
Radiance Fields (NeRF), including two key components: 3D-aware alignment and
3D-aware blending. For 3D-aware alignment, we first estimate the camera pose of
the reference image with respect to generative NeRFs and then perform 3D local
alignment for each part. To further leverage 3D information of the generative
NeRF, we propose 3D-aware blending that directly blends images on the NeRF's
latent representation space, rather than raw pixel space. Collectively, our
method outperforms existing 2D baselines, as validated by extensive
quantitative and qualitative evaluations with FFHQ and AFHQ-Cat.</p>
  </details>
</details>
<details>
  <summary>2. <b>标题：UniAdapter: Unified Parameter-Efficient Transfer Learning for  Cross-modal Modeling</b></summary>
  <p><b>编号</b>：[4]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06605</p>
  <p><b>作者</b>：Haoyu Lu,  Mingyu Ding,  Yuqi Huo,  Guoxing Yang,  Zhiwu Lu,  Masayoshi Tomizuka,  Wei Zhan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：shown promising transferability, Large-scale vision-language pre-trained, shown promising, promising transferability, downstream tasks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large-scale vision-language pre-trained models have shown promising
transferability to various downstream tasks. As the size of these foundation
models and the number of downstream tasks grow, the standard full fine-tuning
paradigm becomes unsustainable due to heavy computational and storage costs.
This paper proposes UniAdapter, which unifies unimodal and multimodal adapters
for parameter-efficient cross-modal adaptation on pre-trained vision-language
models. Specifically, adapters are distributed to different modalities and
their interactions, with the total number of tunable parameters reduced by
partial weight sharing. The unified and knowledge-sharing design enables
powerful cross-modal representations that can benefit various downstream tasks,
requiring only 1.0%-2.0% tunable parameters of the pre-trained model. Extensive
experiments on 6 cross-modal downstream benchmarks (including video-text
retrieval, image-text retrieval, VideoQA, and VQA) show that in most cases,
UniAdapter not only outperforms the state-of-the-arts, but even beats the full
fine-tuning strategy. Particularly, on the MSRVTT retrieval task, UniAdapter
achieves 49.7% recall@1 with 2.2% model parameters, outperforming the latest
competitors by 2.0%. The code and models are available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>3. <b>标题：ALAN: Autonomously Exploring Robotic Agents in the Real World</b></summary>
  <p><b>编号</b>：[5]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06604</p>
  <p><b>作者</b>：Russell Mendonca,  Shikhar Bahl,  Deepak Pathak</p>
  <p><b>备注</b>：ICRA 2023. Website at this https URL</p>
  <p><b>关键词</b>：minimal human supervision, real world, data collected, minimal human, human supervision</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Robotic agents that operate autonomously in the real world need to
continuously explore their environment and learn from the data collected, with
minimal human supervision. While it is possible to build agents that can learn
in such a manner without supervision, current methods struggle to scale to the
real world. Thus, we propose ALAN, an autonomously exploring robotic agent,
that can perform tasks in the real world with little training and interaction
time. This is enabled by measuring environment change, which reflects object
movement and ignores changes in the robot position. We use this metric directly
as an environment-centric signal, and also maximize the uncertainty of
predicted environment change, which provides agent-centric exploration signal.
We evaluate our approach on two different real-world play kitchen settings,
enabling a robot to efficiently explore and discover manipulation skills, and
perform tasks specified via goal images. Website at
this https URL</p>
  </details>
</details>
<details>
  <summary>4. <b>标题：Geometric Clifford Algebra Networks</b></summary>
  <p><b>编号</b>：[11]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06594</p>
  <p><b>作者</b>：David Ruhe,  Jayesh K. Gupta,  Steven de Keninck,  Max Welling,  Johannes Brandstetter</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Clifford Algebra Networks, Geometric Clifford Algebra, Algebra Networks, propose Geometric Clifford, Clifford Algebra</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose Geometric Clifford Algebra Networks (GCANs) that are based on
symmetry group transformations using geometric (Clifford) algebras. GCANs are
particularly well-suited for representing and manipulating geometric
transformations, often found in dynamical systems. We first review the
quintessence of modern (plane-based) geometric algebra, which builds on
isometries encoded as elements of the $\mathrm{Pin}(p,q,r)$ group. We then
propose the concept of group action layers, which linearly combine object
transformations using pre-specified group actions. Together with a new
activation and normalization scheme, these layers serve as adjustable geometric
templates that can be refined via gradient descent. Theoretical advantages are
strongly reflected in the modeling of three-dimensional rigid body
transformations as well as large-scale fluid dynamics simulations, showing
significantly improved performance over traditional methods.</p>
  </details>
</details>
<details>
  <summary>5. <b>标题：Stitchable Neural Networks</b></summary>
  <p><b>编号</b>：[17]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06586</p>
  <p><b>作者</b>：Zizheng Pan,  Jianfei Cai,  Bohan Zhuang</p>
  <p><b>备注</b>：Project is available at this https URL</p>
  <p><b>关键词</b>：enormous powerful pretrained, pretrained model families, powerful pretrained model, deep learning, enormous powerful</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The public model zoo containing enormous powerful pretrained model families
(e.g., DeiT/Swin) has reached an unprecedented scope than ever, which
significantly contributes to the success of deep learning. As each model family
consists of pretrained models with diverse scales (e.g., DeiT-Ti/S/B), it
naturally arises a fundamental question of how to effectively assemble these
readily available models in a family for dynamic accuracy-efficiency trade-offs
at runtime. In this work, we present Stitchable Neural Networks (SN-Net), a
novel scalable and efficient framework for model deployment which cheaply
produces numerous networks with different complexity and performance
trade-offs. Specifically, SN-Net splits a family of pretrained neural networks,
which we call anchors, across the blocks/layers and then stitches them together
with simple stitching layers to map the activations from one anchor to another.
With only a few epochs of training, SN-Net effectively interpolates between the
performance of anchors with varying scales. At runtime, SN-Net can instantly
adapt to dynamic resource constraints by switching the stitching positions.
Furthermore, we provide a comprehensive study on what, how and where to stitch
as well as a simple strategy for effectively and efficiently training SN-Net.
Extensive experiments on ImageNet classification demonstrate that SN-Net can
obtain on-par or even better performance than many individually trained
networks while supporting diverse deployment scenarios. For example, by
stitching Swin Transformers, we challenge hundreds of models in Timm model zoo
with a single network. We believe this new elastic model framework can serve as
a strong baseline for further research in wider communities.</p>
  </details>
</details>
<details>
  <summary>6. <b>标题：Comp2Comp: Open-Source Body Composition Assessment on Computed  Tomography</b></summary>
  <p><b>编号</b>：[24]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06568</p>
  <p><b>作者</b>：Louis Blankemeier,  Arjun Desai,  Juan Manuel Zambrano Chaves,  Andrew Wentland,  Sally Yao,  Eduardo Reis,  Malte Jensen,  Bhanushree Bahl,  Khushboo Arora,  Bhavik N. Patel,  Leon Lenchik,  Marc Willis,  Robert D. Boutin,  Akshay S. Chaudhari</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：body composition, body composition measures, quantitative body composition, Computed tomography, automated body composition</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Computed tomography (CT) is routinely used in clinical practice to evaluate a
wide variety of medical conditions. While CT scans provide diagnoses, they also
offer the ability to extract quantitative body composition metrics to analyze
tissue volume and quality. Extracting quantitative body composition measures
manually from CT scans is a cumbersome and time-consuming task. Proprietary
software has been developed recently to automate this process, but the
closed-source nature impedes widespread use. There is a growing need for fully
automated body composition software that is more accessible and easier to use,
especially for clinicians and researchers who are not experts in medical image
processing. To this end, we have built Comp2Comp, an open-source Python package
for rapid and automated body composition analysis of CT scans. This package
offers models, post-processing heuristics, body composition metrics, automated
batching, and polychromatic visualizations. Comp2Comp currently computes body
composition measures for bone, skeletal muscle, visceral adipose tissue, and
subcutaneous adipose tissue on CT scans of the abdomen. We have created two
pipelines for this purpose. The first pipeline computes vertebral measures, as
well as muscle and adipose tissue measures, at the T12 - L5 vertebral levels
from abdominal CT scans. The second pipeline computes muscle and adipose tissue
measures on user-specified 2D axial slices. In this guide, we discuss the
architecture of the Comp2Comp pipelines, provide usage instructions, and report
internal and external validation results to measure the quality of
segmentations and body composition measures. Comp2Comp can be found at
this https URL.</p>
  </details>
</details>
<details>
  <summary>7. <b>标题：A Domain Decomposition-Based CNN-DNN Architecture for Model Parallel  Training Applied to Image Recognition Problems</b></summary>
  <p><b>编号</b>：[26]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06564</p>
  <p><b>作者</b>：Axel Klawonn,  Martin Lanser,  Janine Weber</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Deep neural networks, convolutional neural networks, brought significant advances, modern computer application, neural networks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep neural networks (DNNs) and, in particular, convolutional neural networks
(CNNs) have brought significant advances in a wide range of modern computer
application problems. However, the increasing availability of large amounts of
datasets as well as the increasing available computational power of modern
computers lead to a steady growth in the complexity and size of DNN and CNN
models, and thus, to longer training times. Hence, various methods and attempts
have been developed to accelerate and parallelize the training of complex
network architectures. In this work, a novel CNN-DNN architecture is proposed
that naturally supports a model parallel training strategy and that is loosely
inspired by two-level domain decomposition methods (DDM). First, local CNN
models, that is, subnetworks, are defined that operate on overlapping or
nonoverlapping parts of the input data, for example, sub-images. The
subnetworks can be trained completely in parallel. Each subnetwork outputs a
local decision for the given machine learning problem which is exclusively
based on the respective local input data. Subsequently, an additional DNN model
is trained which evaluates the local decisions of the local subnetworks and
generates a final, global decision. With respect to the analogy to DDM, the DNN
can be interpreted as a coarse problem and hence, the new approach can be
interpreted as a two-level domain decomposition. In this paper, solely image
classification problems using CNNs are considered. Experimental results for
different 2D image classification problems are provided as well as a face
recognition problem, and a classification problem for 3D computer tomography
(CT) scans. The results show that the proposed approach can significantly
accelerate the required training time compared to the global model and,
additionally, can also help to improve the accuracy of the underlying
classification problem.</p>
  </details>
</details>
<details>
  <summary>8. <b>标题：VA-DepthNet: A Variational Approach to Single Image Depth Prediction</b></summary>
  <p><b>编号</b>：[32]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06556</p>
  <p><b>作者</b>：Ce Liu,  Suryansh Kumar,  Shuhang Gu,  Radu Timofte,  Luc Van Gool</p>
  <p><b>备注</b>：Accepted for publication at ICLR 2023 (Spotlight Oral Presentation). Draft info: 21 pages, 13 tables, 8 figures</p>
  <p><b>关键词</b>：deep neural network, first-order variational constraints, scene space, neural network, variational constraints</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We introduce VA-DepthNet, a simple, effective, and accurate deep neural
network approach for the single-image depth prediction (SIDP) problem. The
proposed approach advocates using classical first-order variational constraints
for this problem. While state-of-the-art deep neural network methods for SIDP
learn the scene depth from images in a supervised setting, they often overlook
the invaluable invariances and priors in the rigid scene space, such as the
regularity of the scene. The paper's main contribution is to reveal the benefit
of classical and well-founded variational constraints in the neural network
design for the SIDP task. It is shown that imposing first-order variational
constraints in the scene space together with popular encoder-decoder-based
network architecture design provides excellent results for the supervised SIDP
task. The imposed first-order variational constraint makes the network aware of
the depth gradient in the scene space, i.e., regularity. The paper demonstrates
the usefulness of the proposed approach via extensive evaluation and ablation
analysis over several benchmark datasets, such as KITTI, NYU Depth V2, and SUN
RGB-D. The VA-DepthNet at test time shows considerable improvements in depth
prediction accuracy compared to the prior art and is accurate also at
high-frequency regions in the scene space. At the time of writing this paper,
our method -- labeled as VA-DepthNet, when tested on the KITTI depth-prediction
evaluation set benchmarks, shows state-of-the-art results, and is the
top-performing published approach.</p>
  </details>
</details>
<details>
  <summary>9. <b>标题：Transferable Deep Metric Learning for Clustering</b></summary>
  <p><b>编号</b>：[45]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06523</p>
  <p><b>作者</b>：Simo Alami.C,  Rim Kaddah,  Jesse Read</p>
  <p><b>备注</b>：Published in Symposium of Intelligent Data Analysis (IDA), 2023</p>
  <p><b>关键词</b>：usual distance metrics, high dimension spaces, difficult task, curse of dimensionality, high dimension</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Clustering in high dimension spaces is a difficult task; the usual distance
metrics may no longer be appropriate under the curse of dimensionality. Indeed,
the choice of the metric is crucial, and it is highly dependent on the dataset
characteristics. However a single metric could be used to correctly perform
clustering on multiple datasets of different domains. We propose to do so,
providing a framework for learning a transferable metric. We show that we can
learn a metric on a labelled dataset, then apply it to cluster a different
dataset, using an embedding space that characterises a desired clustering in
the generic sense. We learn and test such metrics on several datasets of
variable complexity (synthetic, MNIST, SVHN, omniglot) and achieve results
competitive with the state-of-the-art while using only a small number of
labelled training datasets and shallow networks.</p>
  </details>
</details>
<details>
  <summary>10. <b>标题：Multiple Facial Reaction Generation in Dyadic Interaction Settings:  What, Why and How?</b></summary>
  <p><b>编号</b>：[47]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06514</p>
  <p><b>作者</b>：Siyang Song,  Micol Spitale,  Yiming Luo,  Batuhan Bal,  Hatice Gunes</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Stimulus Organism Response, Organism Response, Stimulus Organism, human behavioral reactions, people will process</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>According to the Stimulus Organism Response (SOR) theory, all human
behavioral reactions are stimulated by context, where people will process the
received stimulus and produce an appropriate reaction. This implies that in a
specific context for a given input stimulus, a person can react differently
according to their internal state and other contextual factors. Analogously, in
dyadic interactions, humans communicate using verbal and nonverbal cues, where
a broad spectrum of listeners' non-verbal reactions might be appropriate for
responding to a specific speaker behaviour. There already exists a body of work
that investigated the problem of automatically generating an appropriate
reaction for a given input. However, none attempted to automatically generate
multiple appropriate reactions in the context of dyadic interactions and
evaluate the appropriateness of those reactions using objective measures. This
paper starts by defining the facial Multiple Appropriate Reaction Generation
(fMARG) task for the first time in the literature and proposes a new set of
objective evaluation metrics to evaluate the appropriateness of the generated
reactions. The paper subsequently introduces a framework to predict, generate,
and evaluate multiple appropriate facial reactions.</p>
  </details>
</details>
<details>
  <summary>11. <b>标题：Preconditioned Score-based Generative Models</b></summary>
  <p><b>编号</b>：[50]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06504</p>
  <p><b>作者</b>：Li Zhang,  Hengyuan Ma,  Xiatian Zhu,  Jianfeng Feng</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：sampling process, sampling, PDS, recently emerged, promising class</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Score-based generative models (SGMs) have recently emerged as a promising
class of generative models. However, a fundamental limitation is that their
sampling process is slow due to a need for many (\eg, $2000$) iterations of
sequential computations. An intuitive acceleration method is to reduce the
sampling iterations which however causes severe performance degradation. We
assault this problem to the ill-conditioned issues of the Langevin dynamics and
reverse diffusion in the sampling process. Under this insight, we propose a
model-agnostic {\bf\em preconditioned diffusion sampling} (PDS) method that
leverages matrix preconditioning to alleviate the aforementioned problem. PDS
alters the sampling process of a vanilla SGM at marginal extra computation
cost, and without model retraining. Theoretically, we prove that PDS preserves
the output distribution of the SGM, no risk of inducing systematical bias to
the original sampling process. We further theoretically reveal a relation
between the parameter of PDS and the sampling iterations,easing the parameter
estimation under varying sampling iterations. Extensive experiments on various
image datasets with a variety of resolutions and diversity validate that our
PDS consistently accelerates off-the-shelf SGMs whilst maintaining the
synthesis quality. In particular, PDS can accelerate by up to $29\times$ on
more challenging high resolution (1024$\times$1024) image generation. Compared
with the latest generative models (\eg, CLD-SGM, DDIM, and Analytic-DDIM), PDS
can achieve the best sampling quality on CIFAR-10 at a FID score of 1.99. Our
code is made publicly available to foster any further research
this https URL.</p>
  </details>
</details>
<details>
  <summary>12. <b>标题：Explicit3D: Graph Network with Spatial Inference \\for Single Image 3D  Object Detection</b></summary>
  <p><b>编号</b>：[54]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06494</p>
  <p><b>作者</b>：Yanjun Liu,  Yehu Shen,  Qingmin Liao,  Wenming Yang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：impacting spatial cognition, image scene understanding, spatial cognition fundamentally, visual reasoning, single image</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Indoor 3D object detection is an essential task in single image scene
understanding, impacting spatial cognition fundamentally in visual reasoning.
Existing works on 3D object detection from a single image either pursue this
goal through independent predictions of each object or implicitly reason over
all possible objects, failing to harness relational geometric information
between objects. To address this problem, we propose a dynamic sparse graph
pipeline named Explicit3D based on object geometry and semantics features.
Taking the efficiency into consideration, we further define a relatedness score
and design a novel dynamic pruning algorithm followed by a cluster sampling
method for sparse scene graph generation and updating. Furthermore, our
Explicit3D introduces homogeneous matrices and defines new relative loss and
corner loss to model the spatial difference between target pairs explicitly.
Instead of using ground-truth labels as direct supervision, our relative and
corner loss are derived from the homogeneous transformation, which renders the
model to learn the geometric consistency between objects. The experimental
results on the SUN RGB-D dataset demonstrate that our Explicit3D achieves
better performance balance than the-state-of-the-art.</p>
  </details>
</details>
<details>
  <summary>13. <b>标题：Optical Flow estimation with Event-based Cameras and Spiking Neural  Networks</b></summary>
  <p><b>编号</b>：[55]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06492</p>
  <p><b>作者</b>：Javier Cuadrado,  Ulysse Rançon,  Benoît Cottereau,  Francisco Barranco,  Timothée Masquelier</p>
  <p><b>备注</b>：9 pages, 3 figures and 3 tables, plus Supplementary Materials</p>
  <p><b>关键词</b>：computer vision community, vision community, cameras are raising, raising interest, computer vision</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Event-based cameras are raising interest within the computer vision
community. These sensors operate with asynchronous pixels, emitting events, or
"spikes", when the luminance change at a given pixel since the last event
surpasses a certain threshold. Thanks to their inherent qualities, such as
their low power consumption, low latency and high dynamic range, they seem
particularly tailored to applications with challenging temporal constraints and
safety requirements. Event-based sensors are an excellent fit for Spiking
Neural Networks (SNNs), since the coupling of an asynchronous sensor with
neuromorphic hardware can yield real-time systems with minimal power
requirements. In this work, we seek to develop one such system, using both
event sensor data from the DSEC dataset and spiking neural networks to estimate
optical flow for driving scenarios. We propose a U-Net-like SNN which, after
supervised training, is able to make dense optical flow estimations. To do so,
we encourage both minimal norm for the error vector and minimal angle between
ground-truth and predicted flow, training our model with back-propagation using
a surrogate gradient. In addition, the use of 3d convolutions allows us to
capture the dynamic nature of the data by increasing the temporal receptive
fields. Upsampling after each decoding stage ensures that each decoder's output
contributes to the final estimation. Thanks to separable convolutions, we have
been able to develop a light model (when compared to competitors) that can
nonetheless yield reasonably accurate optical flow estimates.</p>
  </details>
</details>
<details>
  <summary>14. <b>标题：Geometric Constraints Enable Self-Supervised Sinogram Inpainting in  Sparse-View Tomography</b></summary>
  <p><b>编号</b>：[78]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06436</p>
  <p><b>作者</b>：Fabian Wagner,  Mareike Thies,  Noah Maul,  Laura Pfaff,  Oliver Aust,  Sabrina Pechmann,  Christopher Syben,  Andreas Maier</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：induced patient dose, computed tomography, patient dose, induced patient, scan speed</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The diagnostic quality of computed tomography (CT) scans is usually
restricted by the induced patient dose, scan speed, and image quality.
Sparse-angle tomographic scans reduce radiation exposure and accelerate data
acquisition, but suffer from image artifacts and noise. Existing image
processing algorithms can restore CT reconstruction quality but often require
large training data sets or can not be used for truncated objects. This work
presents a self-supervised projection inpainting method that allows learning
missing projective views via gradient-based optimization. By reconstructing
independent stacks of projection data, a self-supervised loss is calculated in
the CT image domain and used to directly optimize projection image intensities
to match the missing tomographic views constrained by the projection geometry.
Our experiments on real X-ray microscope (XRM) tomographic mouse tibia bone
scans show that our method improves reconstructions by 3.1-7.4%/7.7-17.6% in
terms of PSNR/SSIM with respect to the interpolation baseline. Our approach is
applicable as a flexible self-supervised projection inpainting tool for
tomographic applications.</p>
  </details>
</details>
<details>
  <summary>15. <b>标题：A Deep Learning-based Global and Segmentation-based Semantic Feature  Fusion Approach for Indoor Scene Classification</b></summary>
  <p><b>编号</b>：[82]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06432</p>
  <p><b>作者</b>：Ricardo Pereira,  Tiago Barros,  Luís Garrote,  Ana Lopes,  Urbano J. Nunes</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Indoor scene classification, important task, task in perception, perception modules, semantic segmentation mask</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Indoor scene classification has become an important task in perception
modules and has been widely used in various applications. However, problems
such as intra-category variability and inter-category similarity have been
holding back the models' performance, which leads to the need for new types of
features to obtain a more meaningful scene representation. A semantic
segmentation mask provides pixel-level information about the objects available
in the scene, which makes it a promising source of information to obtain a more
meaningful local representation of the scene. Therefore, in this work, a novel
approach that uses a semantic segmentation mask to obtain a 2D spatial layout
of the object categories across the scene, designated by segmentation-based
semantic features (SSFs), is proposed. These features represent, per object
category, the pixel count, as well as the 2D average position and respective
standard deviation values. Moreover, a two-branch network, GS2F2App, that
exploits CNN-based global features extracted from RGB images and the
segmentation-based features extracted from the proposed SSFs, is also proposed.
GS2F2App was evaluated in two indoor scene benchmark datasets: the SUN RGB-D
and the NYU Depth V2, achieving state-of-the-art results on both datasets.</p>
  </details>
</details>
<details>
  <summary>16. <b>标题：LAPTNet-FPN: Multi-scale LiDAR-aided Projective Transform Network for  Real Time Semantic Grid Prediction</b></summary>
  <p><b>编号</b>：[91]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06414</p>
  <p><b>作者</b>：Manuel Alejandro Diaz-Zapata (CHROMA),  David Sierra González (CHROMA),  Özgür Erkent (CHROMA),  Jilles Dibangoye (CHROMA),  Christian Laugier (CHROMA, E-MOTION, Inria)</p>
  <p><b>备注</b>：2023 IEEE International Conference on Robotics and Automation (ICRA), IEEE Robotics and Automation Society, May 2023, London, United Kingdom</p>
  <p><b>关键词</b>：autonomous system, semantic grid generation, information, Semantic grids, representation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Semantic grids can be useful representations of the scene around an
autonomous system. By having information about the layout of the space around
itself, a robot can leverage this type of representation for crucial tasks such
as navigation or tracking. By fusing information from multiple sensors,
robustness can be increased and the computational load for the task can be
lowered, achieving real time performance. Our multi-scale LiDAR-Aided
Perspective Transform network uses information available in point clouds to
guide the projection of image features to a top-view representation, resulting
in a relative improvement in the state of the art for semantic grid generation
for human (+8.67%) and movable object (+49.07%) classes in the nuScenes
dataset, as well as achieving results close to the state of the art for the
vehicle, drivable area and walkway classes, while performing inference at 25
FPS.</p>
  </details>
</details>
<details>
  <summary>17. <b>标题：An Optical XNOR-Bitcount Based Accelerator for Efficient Inference of  Binary Neural Networks</b></summary>
  <p><b>编号</b>：[95]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06405</p>
  <p><b>作者</b>：Sairam Sri Vatsavai,  Venkata Sai Praneeth Karempudi,  Ishan Thakkar</p>
  <p><b>备注</b>：To Appear at IEEE ISQED 2023</p>
  <p><b>关键词</b>：Binary Neural Networks, Neural Networks, Convolutional Neural Networks, Binary Neural, preferred over full-precision</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Binary Neural Networks (BNNs) are increasingly preferred over full-precision
Convolutional Neural Networks(CNNs) to reduce the memory and computational
requirements of inference processing with minimal accuracy drop. BNNs convert
CNN model parameters to 1-bit precision, allowing inference of BNNs to be
processed with simple XNOR and bitcount operations. This makes BNNs amenable to
hardware acceleration. Several photonic integrated circuits (PICs) based BNN
accelerators have been proposed. Although these accelerators provide remarkably
higher throughput and energy efficiency than their electronic counterparts, the
utilized XNOR and bitcount circuits in these accelerators need to be further
enhanced to improve their area, energy efficiency, and throughput. This paper
aims to fulfill this need. For that, we invent a single-MRR-based optical XNOR
gate (OXG). Moreover, we present a novel design of bitcount circuit which we
refer to as Photo-Charge Accumulator (PCA). We employ multiple OXGs in a
cascaded manner using dense wavelength division multiplexing (DWDM) and connect
them to the PCA, to forge a novel Optical XNOR-Bitcount based Binary Neural
Network Accelerator (OXBNN). Our evaluation for the inference of four modern
BNNs indicates that OXBNN provides improvements of up to 62x and 7.6x in
frames-per-second (FPS) and FPS/W (energy efficiency), respectively, on
geometric mean over two PIC-based BNN accelerators from prior work. We
developed a transaction-level, event-driven python-based simulator for
evaluation of accelerators (this https URL).</p>
  </details>
</details>
<details>
  <summary>18. <b>标题：Deep-Learning Quantitative Structural Characterization in Additive  Manufacturing</b></summary>
  <p><b>编号</b>：[99]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06389</p>
  <p><b>作者</b>：Amra Peles,  Vincent C. Paquit,  Ryan R. Dehoff</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：additively manufactured components, additively manufactured materials, additively manufactured, Generative Adversarial Neural, Adversarial Neural Network</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>With a goal of accelerating fabrication of additively manufactured components
with precise microstructures, we developed a method for structural
characterization of key features in additively manufactured materials and
parts. The method utilizes deep learning based on an image-to-image translation
conditional Generative Adversarial Neural Network architecture and enables fast
and incrementally more accurate predictions of the prevalent geometric
features, including melt pool boundaries and printing induced defects visible
in etched optical images. These structural details are heterogeneous in nature.
Our method specifies the microstructure state of an additive built via
statistical distribution of structural details, based on an ensemble of
collected images. Extensions of the method are proposed to address Artificial
Intelligence implementation of developed machine learning model for in real
time control of additive manufacturing.</p>
  </details>
</details>
<details>
  <summary>19. <b>标题：Semantic Image Segmentation: Two Decades of Research</b></summary>
  <p><b>编号</b>：[102]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06378</p>
  <p><b>作者</b>：Gabriela Csurka,  Riccardo Volpi,  Boris Chidlovskii</p>
  <p><b>备注</b>：Pre-print of the book: G. Csurka, R. Volpi and B. Chidlovski: Semantic Image Segmentation: Two Decades of Research, FTCGV (14): No. 1-2, this http URL The authors retained the copyright and are allowed to post it on arXiv. Research only use, commercial use or systematic downloading (by robots or other automatic processes) is prohibited</p>
  <p><b>关键词</b>：Semantic image segmentation, providing key information, computer vision applications, image segmentation, plays a fundamental</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Semantic image segmentation (SiS) plays a fundamental role in a broad variety
of computer vision applications, providing key information for the global
understanding of an image. This survey is an effort to summarize two decades of
research in the field of SiS, where we propose a literature review of solutions
starting from early historical methods followed by an overview of more recent
deep learning methods including the latest trend of using transformers. We
complement the review by discussing particular cases of the weak supervision
and side machine learning techniques that can be used to improve the semantic
segmentation such as curriculum, incremental or self-supervised learning.
State-of-the-art SiS models rely on a large amount of annotated samples,
which are more expensive to obtain than labels for tasks such as image
classification. Since unlabeled data is instead significantly cheaper to
obtain, it is not surprising that Unsupervised Domain Adaptation (UDA) reached
a broad success within the semantic segmentation community. Therefore, a second
core contribution of this book is to summarize five years of a rapidly growing
field, Domain Adaptation for Semantic Image Segmentation (DASiS) which embraces
the importance of semantic segmentation itself and a critical need of adapting
segmentation models to new environments. In addition to providing a
comprehensive survey on DASiS techniques, we unveil also newer trends such as
multi-domain learning, domain generalization, domain incremental learning,
test-time adaptation and source-free domain adaptation. Finally, we conclude
this survey by describing datasets and benchmarks most widely used in SiS and
DASiS and briefly discuss related tasks such as instance and panoptic image
segmentation, as well as applications such as medical image segmentation.</p>
  </details>
</details>
<details>
  <summary>20. <b>标题：Anticipating Next Active Objects for Egocentric Videos</b></summary>
  <p><b>编号</b>：[113]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06358</p>
  <p><b>作者</b>：Sanket Thakur,  Cigdem Beyan,  Pietro Morerio,  Vittorio Murino,  Alessio Del Bue</p>
  <p><b>备注</b>：13 pages, 13 figures</p>
  <p><b>关键词</b>：egocentric video clip, addresses the problem, video clip, egocentric video, action segment</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper addresses the problem of anticipating the next-active-object
location in the future, for a given egocentric video clip where the contact
might happen, before any action takes place. The problem is considerably hard,
as we aim at estimating the position of such objects in a scenario where the
observed clip and the action segment are separated by the so-called ``time to
contact'' (TTC) segment. Many methods have been proposed to anticipate the
action of a person based on previous hand movements and interactions with the
surroundings. However, there have been no attempts to investigate the next
possible interactable object, and its future location with respect to the
first-person's motion and the field-of-view drift during the TTC window. We
define this as the task of Anticipating the Next ACTive Object (ANACTO). To
this end, we propose a transformer-based self-attention framework to identify
and locate the next-active-object in an egocentric clip.
We benchmark our method on three datasets: EpicKitchens-100, EGTEA+ and
Ego4D. We also provide annotations for the first two datasets. Our approach
performs best compared to relevant baseline methods. We also conduct ablation
studies to understand the effectiveness of the proposed and baseline methods on
varying conditions. Code and ANACTO task annotations will be made available
upon paper acceptance.</p>
  </details>
</details>
<details>
  <summary>21. <b>标题：Detection and Segmentation of Pancreas using Morphological Snakes and  Deep Convolutional Neural Networks</b></summary>
  <p><b>编号</b>：[115]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06356</p>
  <p><b>作者</b>：Agapi Davradou</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：diagnosed patients surviving, Pancreatic cancer, deadliest types, segmentation, pancreas</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Pancreatic cancer is one of the deadliest types of cancer, with 25% of the
diagnosed patients surviving for only one year and 6% of them for five.
Computed tomography (CT) screening trials have played a key role in improving
early detection of pancreatic cancer, which has shown significant improvement
in patient survival rates. However, advanced analysis of such images often
requires manual segmentation of the pancreas, which is a time-consuming task.
Moreover, pancreas presents high variability in shape, while occupying only a
very small area of the entire abdominal CT scans, which increases the
complexity of the problem. The rapid development of deep learning can
contribute to offering robust algorithms that provide inexpensive, accurate,
and user-independent segmentation results that can guide the domain experts.
This dissertation addresses this task by investigating a two-step approach for
pancreas segmentation, by assisting the task with a prior rough localization or
detection of pancreas. This rough localization of the pancreas is provided by
an estimated probability map and the detection task is achieved by using the
YOLOv4 deep learning algorithm. The segmentation task is tackled by a modified
U-Net model applied on cropped data, as well as by using a morphological active
contours algorithm. For comparison, the U-Net model was also applied on the
full CT images, which provide a coarse pancreas segmentation to serve as
reference. Experimental results of the detection network on the National
Institutes of Health (NIH) dataset and the pancreas tumour task dataset within
the Medical Segmentation Decathlon show 50.67% mean Average Precision. The best
segmentation network achieved good segmentation results on the NIH dataset,
reaching 67.67% Dice score.</p>
  </details>
</details>
<details>
  <summary>22. <b>标题：Contour-based Interactive Segmentation</b></summary>
  <p><b>编号</b>：[118]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06353</p>
  <p><b>作者</b>：Danil Galeev,  Polina Popenova,  Anna Vorontsova,  Anton Konushin</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：simplifying image editing, Recent advances, labeling greatly, advances in interactive, simplifying image</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent advances in interactive segmentation (IS) allow speeding up and
simplifying image editing and labeling greatly. The majority of modern IS
approaches accept user input in the form of clicks. However, using clicks may
require too many user interactions, especially when selecting small objects,
minor parts of an object, or a group of objects of the same type. In this
paper, we consider such a natural form of user interaction as a loose contour,
and introduce a contour-based IS method. We evaluate the proposed method on the
standard segmentation benchmarks, our novel UserContours dataset, and its
subset UserContours-G containing difficult segmentation cases. Through
experiments, we demonstrate that a single contour provides the same accuracy as
multiple clicks, thus reducing the required amount of user interactions.</p>
  </details>
</details>
<details>
  <summary>23. <b>标题：CLIP-RR: Improved CLIP Network for Relation-Focused Cross-Modal  Information Retrieval</b></summary>
  <p><b>编号</b>：[120]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06350</p>
  <p><b>作者</b>：Yan Gong,  Georgina Cosma</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：next-generation search engines, cross-modal information retrieval, retrieving information based, Contrastive Language-Image Pre-training, Relation-focused cross-modal information</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Relation-focused cross-modal information retrieval focuses on retrieving
information based on relations expressed in user queries, and it is
particularly important in information retrieval applications and
next-generation search engines. To date, CLIP (Contrastive Language-Image
Pre-training) achieved state-of-the-art performance in cross-modal learning
tasks due to its efficient learning of visual concepts from natural language
supervision. However, CLIP learns visual representations from natural language
at a global level without the capability of focusing on image-object relations.
This paper proposes a novel CLIP-based network for Relation Reasoning, CLIP-RR,
that tackles relation-focused cross-modal information retrieval. The proposed
network utilises CLIP to leverage its pre-trained knowledge, and it
additionally comprises two main parts: (1) extends the capabilities of CLIP to
extract and reason with object relations in images; and (2) aggregates the
reasoned results for predicting the similarity scores between images and
descriptions. Experiments were carried out by applying the proposed network to
relation-focused cross-modal information retrieval tasks on the RefCOCOg,
CLEVR, and Flickr30K datasets. The results revealed that the proposed network
outperformed various other state-of-the-art networks including CLIP,
VSE$\infty$, and VSRN++ on both image-to-text and text-to-image cross-modal
information retrieval tasks.</p>
  </details>
</details>
<details>
  <summary>24. <b>标题：Online Arbitrary Shaped Clustering through Correlated Gaussian Functions</b></summary>
  <p><b>编号</b>：[126]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06335</p>
  <p><b>作者</b>：Ole Christian Eidheim</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：alternative learning methods, biologically plausible mechanism, convincing evidence, studies of alternative, alternative learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>There is no convincing evidence that backpropagation is a biologically
plausible mechanism, and further studies of alternative learning methods are
needed. A novel online clustering algorithm is presented that can produce
arbitrary shaped clusters from inputs in an unsupervised manner, and requires
no prior knowledge of the number of clusters in the input data. This is
achieved by finding correlated outputs from functions that capture commonly
occurring input patterns. The algorithm can be deemed more biologically
plausible than model optimization through backpropagation, although practical
applicability may require additional research. However, the method yields
satisfactory results on several toy datasets on a noteworthy range of
hyperparameters.</p>
  </details>
</details>
<details>
  <summary>25. <b>标题：Towards Writing Style Adaptation in Handwriting Recognition</b></summary>
  <p><b>编号</b>：[131]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06318</p>
  <p><b>作者</b>：Jan Kohút,  Michal Hradiš,  Martin Kišš</p>
  <p><b>备注</b>：Submitted to ICDAR2023 conference</p>
  <p><b>关键词</b>：Writer Style Block, challenges of handwriting, handwriting recognition, transcribe a large, large number</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>One of the challenges of handwriting recognition is to transcribe a large
number of vastly different writing styles. State-of-the-art approaches do not
explicitly use information about the writer's style, which may be limiting
overall accuracy due to various ambiguities. We explore models with
writer-dependent parameters which take the writer's identity as an additional
input. The proposed models can be trained on datasets with partitions likely
written by a single author (e.g. single letter, diary, or chronicle). We
propose a Writer Style Block (WSB), an adaptive instance normalization layer
conditioned on learned embeddings of the partitions. We experimented with
various placements and settings of WSB and contrastively pre-trained
embeddings. We show that our approach outperforms a baseline with no WSB in a
writer-dependent scenario and that it is possible to estimate embeddings for
new writers. However, domain adaptation using simple finetuning in a
writer-independent setting provides superior accuracy at a similar
computational cost. The proposed approach should be further investigated in
terms of training stability and embedding regularization to overcome such a
baseline.</p>
  </details>
</details>
<details>
  <summary>26. <b>标题：Finetuning Is a Surprisingly Effective Domain Adaptation Baseline in  Handwriting Recognition</b></summary>
  <p><b>编号</b>：[133]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06308</p>
  <p><b>作者</b>：Jan Kohút,  Michal Hradiš</p>
  <p><b>备注</b>：Submitted to ICDAR2023 conference</p>
  <p><b>关键词</b>：machine learning tasks, learning tasks, machine learning, small specialized dataset, small specialized</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In many machine learning tasks, a large general dataset and a small
specialized dataset are available. In such situations, various domain
adaptation methods can be used to adapt a general model to the target dataset.
We show that in the case of neural networks trained for handwriting recognition
using CTC, simple finetuning with data augmentation works surprisingly well in
such scenarios and that it is resistant to overfitting even for very small
target domain datasets. We evaluated the behavior of finetuning with respect to
augmentation, training data size, and quality of the pre-trained network, both
in writer-dependent and writer-independent settings. On a large real-world
dataset, finetuning provided an average relative CER improvement of 25 % with
16 text lines for new writers and 50 % for 256 text lines.</p>
  </details>
</details>
<details>
  <summary>27. <b>标题：A Neuromorphic Dataset for Object Segmentation in Indoor Cluttered  Environment</b></summary>
  <p><b>编号</b>：[135]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06301</p>
  <p><b>作者</b>：Xiaoqian Huang,  Kachole Sanket,  Abdulla Ayyad,  Fariborz Baghaei Naeini,  Dimitrios Makris,  Yahya Zweir</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：low dynamic range, low time sampling, Taking advantage, motion blur, low dynamic</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Taking advantage of an event-based camera, the issues of motion blur, low
dynamic range and low time sampling of standard cameras can all be addressed.
However, there is a lack of event-based datasets dedicated to the benchmarking
of segmentation algorithms, especially those that provide depth information
which is critical for segmentation in occluded scenes. This paper proposes a
new Event-based Segmentation Dataset (ESD), a high-quality 3D spatial and
temporal dataset for object segmentation in an indoor cluttered environment.
Our proposed dataset ESD comprises 145 sequences with 14,166 RGB frames that
are manually annotated with instance masks. Overall 21.88 million and 20.80
million events from two event-based cameras in a stereo-graphic configuration
are collected, respectively. To the best of our knowledge, this densely
annotated and 3D spatial-temporal event-based segmentation benchmark of
tabletop objects is the first of its kind. By releasing ESD, we expect to
provide the community with a challenging segmentation benchmark with high
quality.</p>
  </details>
</details>
<details>
  <summary>28. <b>标题：Hyperspectral Image Super Resolution with Real Unaligned RGB Guidance</b></summary>
  <p><b>编号</b>：[137]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06298</p>
  <p><b>作者</b>：Zeqiang Lai,  Ying Fu,  Jun Zhang</p>
  <p><b>备注</b>：The code and dataset are publicly available at this https URL</p>
  <p><b>关键词</b>：RGB reference, RGB reference images, integrate high-frequency spatial, high-frequency spatial information, RGB</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Fusion-based hyperspectral image (HSI) super-resolution has become
increasingly prevalent for its capability to integrate high-frequency spatial
information from the paired high-resolution (HR) RGB reference image. However,
most of the existing methods either heavily rely on the accurate alignment
between low-resolution (LR) HSIs and RGB images, or can only deal with
simulated unaligned RGB images generated by rigid geometric transformations,
which weakens their effectiveness for real scenes. In this paper, we explore
the fusion-based HSI super-resolution with real RGB reference images that have
both rigid and non-rigid misalignments. To properly address the limitations of
existing methods for unaligned reference images, we propose an HSI fusion
network with heterogenous feature extractions, multi-stage feature alignments,
and attentive feature fusion. Specifically, our network first transforms the
input HSI and RGB images into two sets of multi-scale features with an HSI
encoder and an RGB encoder, respectively. The features of RGB reference images
are then processed by a multi-stage alignment module to explicitly align the
features of RGB reference with the LR HSI. Finally, the aligned features of RGB
reference are further adjusted by an adaptive attention module to focus more on
discriminative regions before sending them to the fusion decoder to generate
the reconstructed HR HSI. Additionally, we collect a real-world HSI fusion
dataset, consisting of paired HSI and unaligned RGB reference, to support the
evaluation of the proposed model for real scenes. Extensive experiments are
conducted on both simulated and our real-world datasets, and it shows that our
method obtains a clear improvement over existing single-image and fusion-based
super-resolution methods on quantitative assessment as well as visual
comparison.</p>
  </details>
</details>
<details>
  <summary>29. <b>标题：Surface-biased Multi-Level Context 3D Object Detection</b></summary>
  <p><b>编号</b>：[138]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06291</p>
  <p><b>作者</b>：Sultan Abu Ghazal,  Jean Lahoud,  Rao Anwer</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：applications including robotics, computer vision applications, vision applications including, autonomous cars, including robotics</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Object detection in 3D point clouds is a crucial task in a range of computer
vision applications including robotics, autonomous cars, and augmented reality.
This work addresses the object detection task in 3D point clouds using a highly
efficient, surface-biased, feature extraction method (wang2022rbgnet), that
also captures contextual cues on multiple levels. We propose a 3D object
detector that extracts accurate feature representations of object candidates
and leverages self-attention on point patches, object candidates, and on the
global scene in 3D scene. Self-attention is proven to be effective in encoding
correlation information in 3D point clouds by (xie2020mlcvnet). While other 3D
detectors focus on enhancing point cloud feature extraction by selectively
obtaining more meaningful local features (wang2022rbgnet) where contextual
information is overlooked. To this end, the proposed architecture uses
ray-based surface-biased feature extraction and multi-level context encoding to
outperform the state-of-the-art 3D object detector. In this work, 3D detection
experiments are performed on scenes from the ScanNet dataset whereby the
self-attention modules are introduced one after the other to isolate the effect
of self-attention at each level.</p>
  </details>
</details>
<details>
  <summary>30. <b>标题：Render-and-Compare: Cross-View 6 DoF Localization from Noisy Prior</b></summary>
  <p><b>编号</b>：[139]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06287</p>
  <p><b>作者</b>：Shen Yan,  Xiaoya Cheng,  Yuxiang Liu,  Juelin Zhu,  Rouwan Wu,  Yu Liu,  Maojun Zhang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：significant progress, visual localization, aerial oblique photography, ground-level map collection, ground-level</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Despite the significant progress in 6-DoF visual localization, researchers
are mostly driven by ground-level benchmarks. Compared with aerial oblique
photography, ground-level map collection lacks scalability and complete
coverage. In this work, we propose to go beyond the traditional ground-level
setting and exploit the cross-view localization from aerial to ground. We solve
this problem by formulating camera pose estimation as an iterative
render-and-compare pipeline and enhancing the robustness through augmenting
seeds from noisy initial priors. As no public dataset exists for the studied
problem, we collect a new dataset that provides a variety of cross-view images
from smartphones and drones and develop a semi-automatic system to acquire
ground-truth poses for query images. We benchmark our method as well as several
state-of-the-art baselines and demonstrate that our method outperforms other
approaches by a large margin.</p>
  </details>
</details>
<details>
  <summary>31. <b>标题：Sneaky Spikes: Uncovering Stealthy Backdoor Attacks in Spiking Neural  Networks with Neuromorphic Data</b></summary>
  <p><b>编号</b>：[143]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06279</p>
  <p><b>作者</b>：Gorka Abad,  Oguzhan Ersoy,  Stjepan Picek,  Aitor Urbieta</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：achieved excellent results, speech recognition, achieved excellent, excellent results, Deep neural networks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep neural networks (DNNs) have achieved excellent results in various tasks,
including image and speech recognition. However, optimizing the performance of
DNNs requires careful tuning of multiple hyperparameters and network parameters
via training. High-performance DNNs utilize a large number of parameters,
corresponding to high energy consumption during training. To address these
limitations, researchers have developed spiking neural networks (SNNs), which
are more energy-efficient and can process data in a biologically plausible
manner, making them well-suited for tasks involving sensory data processing,
i.e., neuromorphic data. Like DNNs, SNNs are vulnerable to various threats,
such as adversarial examples and backdoor attacks. Yet, the attacks and
countermeasures for SNNs have been almost fully unexplored.
This paper investigates the application of backdoor attacks in SNNs using
neuromorphic datasets and different triggers. More precisely, backdoor triggers
in neuromorphic data can change their position and color, allowing a larger
range of possibilities than common triggers in, e.g., the image domain. We
propose different attacks achieving up to 100\% attack success rate without
noticeable clean accuracy degradation. We also evaluate the stealthiness of the
attacks via the structural similarity metric, showing our most powerful attacks
being also stealthy. Finally, we adapt the state-of-the-art defenses from the
image domain, demonstrating they are not necessarily effective for neuromorphic
data resulting in inaccurate performance.</p>
  </details>
</details>
<details>
  <summary>32. <b>标题：A Simple Zero-shot Prompt Weighting Technique to Improve Prompt  Ensembling in Text-Image Models</b></summary>
  <p><b>编号</b>：[162]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06235</p>
  <p><b>作者</b>：James Urquhart Allingham,  Jie Ren,  Michael W Dusenberry,  Jeremiah Zhe Liu,  Xiuye Gu,  Yin Cui,  Dustin Tran,  Balaji Lakshminarayanan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：trained text-image models, Contrastively trained text-image, classifying previously unseen, previously unseen images, Contrastively trained</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Contrastively trained text-image models have the remarkable ability to
perform zero-shot classification, that is, classifying previously unseen images
into categories that the model has never been explicitly trained to identify.
However, these zero-shot classifiers need prompt engineering to achieve high
accuracy. Prompt engineering typically requires hand-crafting a set of prompts
for individual downstream tasks. In this work, we aim to automate this prompt
engineering and improve zero-shot accuracy through prompt ensembling. In
particular, we ask "Given a large pool of prompts, can we automatically score
the prompts and ensemble those that are most suitable for a particular
downstream dataset, without needing access to labeled validation data?". We
demonstrate that this is possible. In doing so, we identify several pathologies
in a naive prompt scoring method where the score can be easily overconfident
due to biases in pre-training and test data, and we propose a novel prompt
scoring method that corrects for the biases. Using our proposed scoring method
to create a weighted average prompt ensemble, our method outperforms equal
average ensemble, as well as hand-crafted prompts, on ImageNet, 4 of its
variants, and 11 fine-grained classification benchmarks, all while being fully
automatic, optimization-free, and not requiring access to labeled validation
data.</p>
  </details>
</details>
<details>
  <summary>33. <b>标题：Exploring Navigation Maps for Learning-Based Motion Prediction</b></summary>
  <p><b>编号</b>：[175]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06195</p>
  <p><b>作者</b>：Julian Schmidt,  Julian Jordan,  Franz Gritschneder,  Thomas Monninger,  Klaus Dietmayer</p>
  <p><b>备注</b>：Accepted to the 2023 IEEE International Conference on Robotics and Automation (ICRA 2023)</p>
  <p><b>关键词</b>：safe autonomous driving, surrounding agents' motion, predominant High Definition, navigation maps, learning-based motion prediction</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The prediction of surrounding agents' motion is a key for safe autonomous
driving. In this paper, we explore navigation maps as an alternative to the
predominant High Definition (HD) maps for learning-based motion prediction.
Navigation maps provide topological and geometrical information on road-level,
HD maps additionally have centimeter-accurate lane-level information. As a
result, HD maps are costly and time-consuming to obtain, while navigation maps
with near-global coverage are freely available. We describe an approach to
integrate navigation maps into learning-based motion prediction models. To
exploit locally available HD maps during training, we additionally propose a
model-agnostic method for knowledge distillation. In experiments on the
publicly available Argoverse dataset with navigation maps obtained from
OpenStreetMap, our approach shows a significant improvement over not using a
map at all. Combined with our method for knowledge distillation, we achieve
results that are close to the original HD map-reliant models. Our publicly
available navigation map API for Argoverse enables researchers to develop and
evaluate their own approaches using navigation maps.</p>
  </details>
</details>
<details>
  <summary>34. <b>标题：Capsules as viewpoint learners for human pose estimation</b></summary>
  <p><b>编号</b>：[176]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06194</p>
  <p><b>作者</b>：Nicola Garau,  Nicola Conci</p>
  <p><b>备注</b>：16 pages, 9 figures. arXiv admin note: substantial text overlap with arXiv:2108.08557</p>
  <p><b>关键词</b>：images and videos, directly from images, human pose estimation, viewpoint, human joints directly</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The task of human pose estimation (HPE) deals with the ill-posed problem of
estimating the 3D position of human joints directly from images and videos. In
recent literature, most of the works tackle the problem mostly by using
convolutional neural networks (CNNs), which are capable of achieving
state-of-the-art results in most datasets. We show how most neural networks are
not able to generalize well when the camera is subject to significant viewpoint
changes. This behaviour emerges because CNNs lack the capability of modelling
viewpoint equivariance, while they rather rely on viewpoint invariance,
resulting in high data dependency. Recently, capsule networks (CapsNets) have
been proposed in the multi-class classification field as a solution to the
viewpoint equivariance issue, reducing both the size and complexity of both the
training datasets and the network itself. In this work, we show how capsule
networks can be adopted to achieve viewpoint equivariance in human pose
estimation. We propose a novel end-to-end viewpoint-equivariant capsule
autoencoder that employs a fast Variational Bayes routing and matrix capsules.
We achieve state-of-the-art results for multiple tasks and datasets while
retaining other desirable properties, such as greater generalization
capabilities when changing viewpoints, lower data dependency and fast
inference. Additionally, by modelling each joint as a capsule, the hierarchical
and geometrical structure of the overall pose is retained in the feature space,
independently from the viewpoint. We further test our network on multiple
datasets, both in the RGB and depth domain, from seen and unseen viewpoints and
in the viewpoint transfer task.</p>
  </details>
</details>
<details>
  <summary>35. <b>标题：PUPS: Point Cloud Unified Panoptic Segmentation</b></summary>
  <p><b>编号</b>：[179]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06185</p>
  <p><b>作者</b>：Shihao Su,  Jianyun Xu,  Huanyu Wang,  Zhenwei Miao,  Xin Zhan,  Dayang Hao,  Xi Li</p>
  <p><b>备注</b>：accepted by AAAI2023</p>
  <p><b>关键词</b>：instance segmentation, instance segmentation task, panoptic segmentation, seeks a holistic, holistic solution</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Point cloud panoptic segmentation is a challenging task that seeks a holistic
solution for both semantic and instance segmentation to predict groupings of
coherent points. Previous approaches treat semantic and instance segmentation
as surrogate tasks, and they either use clustering methods or bounding boxes to
gather instance groupings with costly computation and hand-crafted designs in
the instance segmentation task. In this paper, we propose a simple but
effective point cloud unified panoptic segmentation (PUPS) framework, which use
a set of point-level classifiers to directly predict semantic and instance
groupings in an end-to-end manner. To realize PUPS, we introduce bipartite
matching to our training pipeline so that our classifiers are able to
exclusively predict groupings of instances, getting rid of hand-crafted
designs, e.g. anchors and Non-Maximum Suppression (NMS). In order to achieve
better grouping results, we utilize a transformer decoder to iteratively refine
the point classifiers and develop a context-aware CutMix augmentation to
overcome the class imbalance problem. As a result, PUPS achieves 1st place on
the leader board of SemanticKITTI panoptic segmentation task and
state-of-the-art results on nuScenes.</p>
  </details>
</details>
<details>
  <summary>36. <b>标题：Anti-Compression Contrastive Facial Forgery Detection</b></summary>
  <p><b>编号</b>：[181]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06183</p>
  <p><b>作者</b>：Jiajun Huang,  Xinqi Zhu,  Chengbin Du,  Siqi Ma,  Surya Nepal,  Chang Xu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：strong compressed data, compressed data, data, compressed, strong compressed</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Forgery facial images and videos have increased the concern of digital
security. It leads to the significant development of detecting forgery data
recently. However, the data, especially the videos published on the Internet,
are usually compressed with lossy compression algorithms such as H.264. The
compressed data could significantly degrade the performance of recent detection
algorithms. The existing anti-compression algorithms focus on enhancing the
performance in detecting heavily compressed data but less consider the
compression adaption to the data from various compression levels. We believe
creating a forgery detection model that can handle the data compressed with
unknown levels is important. To enhance the performance for such models, we
consider the weak compressed and strong compressed data as two views of the
original data and they should have similar representation and relationships
with other samples. We propose a novel anti-compression forgery detection
framework by maintaining closer relations within data under different
compression levels. Specifically, the algorithm measures the pair-wise
similarity within data as the relations, and forcing the relations of weak and
strong compressed data close to each other, thus improving the discriminate
power for detecting strong compressed data. To achieve a better strong
compressed data relation guided by the less compressed one, we apply video
level contrastive learning for weak compressed data, which forces the model to
produce similar representations within the same video and far from the negative
samples. The experiment results show that the proposed algorithm could boost
performance for strong compressed data while improving the accuracy rate when
detecting the clean data.</p>
  </details>
</details>
<details>
  <summary>37. <b>标题：Learning and Aggregating Lane Graphs for Urban Automated Driving</b></summary>
  <p><b>编号</b>：[184]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06175</p>
  <p><b>作者</b>：Martin Büchner,  Jannik Zürn,  Ion-George Todoran,  Abhinav Valada,  Wolfram Burgard</p>
  <p><b>备注</b>：22 pages, 17 figures</p>
  <p><b>关键词</b>：Lane graph, Lane, Lane graph estimation, graph, map learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Lane graph estimation is an essential and highly challenging task in
automated driving and HD map learning. Existing methods using either onboard or
aerial imagery struggle with complex lane topologies, out-of-distribution
scenarios, or significant occlusions in the image space. Moreover, merging
overlapping lane graphs to obtain consistent large-scale graphs remains
difficult. To overcome these challenges, we propose a novel bottom-up approach
to lane graph estimation from aerial imagery that aggregates multiple
overlapping graphs into a single consistent graph. Due to its modular design,
our method allows us to address two complementary tasks: predicting
ego-respective successor lane graphs from arbitrary vehicle positions using a
graph neural network and aggregating these predictions into a consistent global
lane graph. Extensive experiments on a large-scale lane graph dataset
demonstrate that our approach yields highly accurate lane graphs, even in
regions with severe occlusions. The presented approach to graph aggregation
proves to eliminate inconsistent predictions while increasing the overall graph
quality. We make our large-scale urban lane graph dataset and code publicly
available at this http URL.</p>
  </details>
</details>
<details>
  <summary>38. <b>标题：Contour Context: Abstract Structural Distribution for 3D LiDAR Loop  Detection and Metric Pose Estimation</b></summary>
  <p><b>编号</b>：[194]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06149</p>
  <p><b>作者</b>：Binqian Jiang,  Shaojie Shen</p>
  <p><b>备注</b>：7 pages, 7 figures, accepted by ICRA 2023</p>
  <p><b>关键词</b>：metric pose estimation, utonomous driving scenario, efficient topological loop, topological loop closure, loop closure detection</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper proposes \textit{Contour Context}, a simple, effective, and
efficient topological loop closure detection pipeline with accurate 3-DoF
metric pose estimation, targeting the urban utonomous driving scenario. We
interpret the Cartesian birds' eye view (BEV) image projected from 3D LiDAR
points as layered distribution of structures. To recover elevation information
from BEVs, we slice them at different heights, and connected pixels at each
level will form contours. Each contour is parameterized by abstract
information, e.g., pixel count, center position, covariance, and mean height.
The similarity of two BEVs is calculated in sequential discrete and continuous
steps. The first step considers the geometric consensus of graph-like
constellations formed by contours in particular localities. The second step
models the majority of contours as a 2.5D Gaussian mixture model, which is used
to calculate correlation and optimize relative transform in continuous space. A
retrieval key is designed to accelerate the search of a database indexed by
layered KD-trees. We validate the efficacy of our method by comparing it with
recent works on public datasets.</p>
  </details>
</details>
<details>
  <summary>39. <b>标题：CoMAE: Single Model Hybrid Pre-training on Small-Scale RGB-D Datasets</b></summary>
  <p><b>编号</b>：[195]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06148</p>
  <p><b>作者</b>：Jiange Yang,  Sheng Guo,  Gangshan Wu,  Limin Wang</p>
  <p><b>备注</b>：10 pages(including references),5 figures, Accept by Thirty-Seventh AAAI Conference on Artificial Intelligence (AAAI 2023)</p>
  <p><b>关键词</b>：scene recognition approaches, Places or ImageNet, Current RGB-D scene, RGB-D scene recognition, scene recognition</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Current RGB-D scene recognition approaches often train two standalone
backbones for RGB and depth modalities with the same Places or ImageNet
pre-training. However, the pre-trained depth network is still biased by
RGB-based models which may result in a suboptimal solution. In this paper, we
present a single-model self-supervised hybrid pre-training framework for RGB
and depth modalities, termed as CoMAE. Our CoMAE presents a curriculum learning
strategy to unify the two popular self-supervised representation learning
algorithms: contrastive learning and masked image modeling. Specifically, we
first build a patch-level alignment task to pre-train a single encoder shared
by two modalities via cross-modal contrastive learning. Then, the pre-trained
contrastive encoder is passed to a multi-modal masked autoencoder to capture
the finer context features from a generative perspective. In addition, our
single-model design without requirement of fusion module is very flexible and
robust to generalize to unimodal scenario in both training and testing phases.
Extensive experiments on SUN RGB-D and NYUDv2 datasets demonstrate the
effectiveness of our CoMAE for RGB and depth representation learning. In
addition, our experiment results reveal that CoMAE is a data-efficient
representation learner. Although we only use the small-scale and unlabeled
training set for pre-training, our CoMAE pre-trained models are still
competitive to the state-of-the-art methods with extra large-scale and
supervised RGB dataset pre-training. Code will be released at
this https URL.</p>
  </details>
</details>
<details>
  <summary>40. <b>标题：RFC-Net: Learning High Resolution Global Features for Medical Image  Segmentation on a Computational Budget</b></summary>
  <p><b>编号</b>：[201]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06134</p>
  <p><b>作者</b>：Sourajit Saha,  Shaswati Saha,  Md Osman Gani,  Tim Oates,  David Chapman</p>
  <p><b>备注</b>：In Proceedings of AAAI Conference on Artificial Intelligence 2023</p>
  <p><b>关键词</b>：Learning High-Resolution representations, Learning High-Resolution, High-Resolution representations, representations is essential, essential for semantic</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Learning High-Resolution representations is essential for semantic
segmentation. Convolutional neural network (CNN)architectures with downstream
and upstream propagation flow are popular for segmentation in medical
diagnosis. However, due to performing spatial downsampling and upsampling in
multiple stages, information loss is inexorable. On the contrary, connecting
layers densely on high spatial resolution is computationally expensive. In this
work, we devise a Loose Dense Connection Strategy to connect neurons in
subsequent layers with reduced parameters. On top of that, using a m-way Tree
structure for feature propagation we propose Receptive Field Chain Network
(RFC-Net) that learns high resolution global features on a compressed
computational space. Our experiments demonstrates that RFC-Net achieves
state-of-the-art performance on Kvasir and CVC-ClinicDB benchmarks for Polyp
segmentation.</p>
  </details>
</details>
<details>
  <summary>41. <b>标题：Deep Transfer Tensor Factorization for Multi-View Learning</b></summary>
  <p><b>编号</b>：[202]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06133</p>
  <p><b>作者</b>：Penghao Jiang,  Ke Xin,  Chunxi Li</p>
  <p><b>备注</b>：International Conference on Data Mining 2022 Workshop MRL</p>
  <p><b>关键词</b>：data sparsity problem, sparsity problem, data sparsity, solve data sparsity, tensor factorization</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper studies the data sparsity problem in multi-view learning. To solve
data sparsity problem in multiview ratings, we propose a generic architecture
of deep transfer tensor factorization (DTTF) by integrating deep learning and
cross-domain tensor factorization, where the side information is embedded to
provide effective compensation for the tensor sparsity. Then we exhibit
instantiation of our architecture by combining stacked denoising autoencoder
(SDAE) and CANDECOMP/ PARAFAC (CP) tensor factorization in both source and
target domains, where the side information of both users and items is tightly
coupled with the sparse multi-view ratings and the latent factors are learned
based on the joint optimization. We tightly couple the multi-view ratings and
the side information to improve cross-domain tensor factorization based
recommendations. Experimental results on real-world datasets demonstrate that
our DTTF schemes outperform state-of-the-art methods on multi-view rating
predictions.</p>
  </details>
</details>
<details>
  <summary>42. <b>标题：Learning to Scale Temperature in Masked Self-Attention for Image  Inpainting</b></summary>
  <p><b>编号</b>：[204]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06130</p>
  <p><b>作者</b>：Xiang Zhou,  Yuan Zeng,  Yi Gong</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：deep generative adversarial, large missing regions, generative adversarial networks, inpainting large missing, self-attention mechanism</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent advances in deep generative adversarial networks (GAN) and
self-attention mechanism have led to significant improvements in the
challenging task of inpainting large missing regions in an image. These methods
integrate self-attention mechanism in neural networks to utilize surrounding
neural elements based on their correlation and help the networks capture
long-range dependencies. Temperature is a parameter in the Softmax function
used in the self-attention, and it enables biasing the distribution of
attention scores towards a handful of similar patches. Most existing
self-attention mechanisms in image inpainting are convolution-based and set the
temperature as a constant, performing patch matching in a limited feature
space. In this work, we analyze the artifacts and training problems in previous
self-attention mechanisms, and redesign the temperature learning network as
well as the self-attention mechanism to address them. We present an image
inpainting framework with a multi-head temperature masked self-attention
mechanism, which provides stable and efficient temperature learning and uses
multiple distant contextual information for high quality image inpainting. In
addition to improving image quality of inpainting results, we generalize the
proposed model to user-guided image editing by introducing a new sketch
generation method. Extensive experiments on various datasets such as Paris
StreetView, CelebA-HQ and Places2 clearly demonstrate that our method not only
generates more natural inpainting results than previous works both in terms of
perception image quality and quantitative metrics, but also enables to help
users to generate more flexible results that are related to their sketch
guidance.</p>
  </details>
</details>
<details>
  <summary>43. <b>标题：How to Use Dropout Correctly on Residual Networks with Batch  Normalization</b></summary>
  <p><b>编号</b>：[212]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06112</p>
  <p><b>作者</b>：Bum Jun Kim,  Hyeyeon Choi,  Hyeonah Jang,  Donggeon Lee,  Sang Woo Kim</p>
  <p><b>备注</b>：10 pages, 4 figures</p>
  <p><b>关键词</b>：deep neural networks, apply dropout, correct position, dropout, regularization methods</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>For the stable optimization of deep neural networks, regularization methods
such as dropout and batch normalization have been used in various tasks.
Nevertheless, the correct position to apply dropout has rarely been discussed,
and different positions have been employed depending on the practitioners. In
this study, we investigate the correct position to apply dropout. We
demonstrate that for a residual network with batch normalization, applying
dropout at certain positions increases the performance, whereas applying
dropout at other positions decreases the performance. Based on theoretical
analysis, we provide the following guideline for the correct position to apply
dropout: apply one dropout after the last batch normalization but before the
last weight layer in the residual branch. We provide detailed theoretical
explanations to support this claim and demonstrate them through module tests.
In addition, we investigate the correct position of dropout in the head that
produces the final prediction. Although the current consensus is to apply
dropout after global average pooling, we prove that applying dropout before
global average pooling leads to a more stable output. The proposed guidelines
are validated through experiments using different datasets and models.</p>
  </details>
</details>
<details>
  <summary>44. <b>标题：Towards Local Visual Modeling for Image Captioning</b></summary>
  <p><b>编号</b>：[217]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06098</p>
  <p><b>作者</b>：Yiwei Ma,  Jiayi Ji,  Xiaoshuai Sun,  Yiyi Zhou,  Rongrong Ji</p>
  <p><b>备注</b>：Preprint</p>
  <p><b>关键词</b>：detailed captions, critical for generating, generating accurate, accurate and detailed, local visual modeling</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we study the local visual modeling with grid features for
image captioning, which is critical for generating accurate and detailed
captions. To achieve this target, we propose a Locality-Sensitive Transformer
Network (LSTNet) with two novel designs, namely Locality-Sensitive Attention
(LSA) and Locality-Sensitive Fusion (LSF). LSA is deployed for the intra-layer
interaction in Transformer via modeling the relationship between each grid and
its neighbors. It reduces the difficulty of local object recognition during
captioning. LSF is used for inter-layer information fusion, which aggregates
the information of different encoder layers for cross-layer semantical
complementarity. With these two novel designs, the proposed LSTNet can model
the local visual information of grid features to improve the captioning
quality. To validate LSTNet, we conduct extensive experiments on the
competitive MS-COCO benchmark. The experimental results show that LSTNet is not
only capable of local visual modeling, but also outperforms a bunch of
state-of-the-art captioning models on offline and online testings, i.e., 134.8
CIDEr and 136.3 CIDEr, respectively. Besides, the generalization of LSTNet is
also verified on the Flickr8k and Flickr30k datasets</p>
  </details>
</details>
<details>
  <summary>45. <b>标题：Learning-Based Defect Recognitions for Autonomous UAV Inspections</b></summary>
  <p><b>编号</b>：[218]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06093</p>
  <p><b>作者</b>：Kangcheng Liu</p>
  <p><b>备注</b>：ROBIO 2019 Oral</p>
  <p><b>关键词</b>：crack detection, deep learning framework, play a significant, significant role, crack</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Automatic crack detection and segmentation play a significant role in the
whole system of unmanned aerial vehicle inspections. In this paper, we have
implemented a deep learning framework for crack detection based on classical
network architectures including Alexnet, VGG, and Resnet. Moreover, inspired by
the feature pyramid network architecture, a hierarchical convolutional neural
network (CNN) deep learning framework which is efficient in crack segmentation
is also proposed, and its performance of it is compared with other
state-of-the-art network architecture. We have summarized the existing crack
detection and segmentation datasets and established the largest existing
benchmark dataset on the internet for crack detection and segmentation, which
is open-sourced for the research community. Our feature pyramid crack
segmentation network is tested on the benchmark dataset and gives satisfactory
segmentation results. A framework for automatic unmanned aerial vehicle
inspections is also proposed and will be established for the crack inspection
tasks of various concrete structures. All our self-established datasets and
codes are open-sourced at:
this https URL</p>
  </details>
</details>
<details>
  <summary>46. <b>标题：Boosted ab initio Cryo-EM 3D Reconstruction with ACE-EM</b></summary>
  <p><b>编号</b>：[220]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06091</p>
  <p><b>作者</b>：Lin Yao (1),  Ruihan Xu (2),  Zhifeng Gao (1),  Guolin Ke (1),  Yuhang Wang (1) ((1) DP Technology, Ltd., Beijing, China (2) Peking University, Beijing, China)</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：missing projection angles, projection angles, projection images, missing projection, structure from noisy</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The central problem in cryo-electron microscopy (cryo-EM) is to recover the
3D structure from noisy 2D projection images which requires estimating the
missing projection angles (poses). Recent methods attempted to solve the 3D
reconstruction problem with the autoencoder architecture, which suffers from
the latent vector space sampling problem and frequently produces suboptimal
pose inferences and inferior 3D reconstructions. Here we present an improved
autoencoder architecture called ACE (Asymmetric Complementary autoEncoder),
based on which we designed the ACE-EM method for cryo-EM 3D reconstructions.
Compared to previous methods, ACE-EM reached higher pose space coverage within
the same training time and boosted the reconstruction performance regardless of
the choice of decoders. With this method, the Nyquist resolution (highest
possible resolution) was reached for 3D reconstructions of both simulated and
experimental cryo-EM datasets. Furthermore, ACE-EM is the only amortized
inference method that reached the Nyquist resolution.</p>
  </details>
</details>
<details>
  <summary>47. <b>标题：Federated contrastive learning models for prostate cancer diagnosis and  Gleason grading</b></summary>
  <p><b>编号</b>：[221]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06089</p>
  <p><b>作者</b>：Fei Kong,  Jinxi Xiang,  Xiyue Wang,  Xinran Wang,  Meng Yue,  Jun Zhang,  Sen Yang,  Junhan Zhao,  Xiao Han,  Yuhan Dong,  Yueping Liu</p>
  <p><b>备注</b>：11 pages</p>
  <p><b>关键词</b>：model, FCL, artificial intelligence, imaging is remarkable, Gleason grading task</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The application effect of artificial intelligence(AI) in the field of medical
imaging is remarkable. Robust AI model training requires large datasets, but
data collection faces constraints in communication, ethics, and privacy
protection. Federated learning can solve the above problems by coordinating
multiple clients to train the model without sharing the original data. In this
study, we design a federated contrastive learning framework(FCL) for
large-scale pathology images and the heterogeneity challenges. It enhances the
generalization ability of the model by maximizing the attention consistency
between the local client model and the server model. To alleviate the privacy
leakage problem when transferring weights and verify the robustness of FCL, we
use differential privacy to further protect the model by adding noise. We
evaluate the effectiveness of FCL on the cancer diagnosis task and Gleason
grading task on 19,635 prostate cancer WSIs from multiple clients. In the
diagnosis task, the average AUC of 7 clients is 95\% when the categories are
relatively balanced, and our FCL achieves 97\%. In the Gleason grading task,
the average Kappa of 6 clients is 0.74, and the Kappa of FCL reaches 0.84.
Furthermore, we also validate the robustness of the model on external
datasets(one public dataset and two private datasets). In addition, to better
explain the classification effect of the model, we show whether the model
focuses on the lesion area by drawing a heatmap. FCL brings a robust, accurate,
and low-cost AI training model to biomedical research, effectively protecting
the privacy of medical data.</p>
  </details>
</details>
<details>
  <summary>48. <b>标题：Correspondence-Free Domain Alignment for Unsupervised Cross-Domain Image  Retrieval</b></summary>
  <p><b>编号</b>：[227]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06081</p>
  <p><b>作者</b>：Xu Wang,  Dezhong Peng,  Ming Yan,  Peng Hu</p>
  <p><b>备注</b>：AAAI 2023</p>
  <p><b>关键词</b>：Cross-domain image retrieval, image retrieval aims, image retrieval, excavate cross-domain classificatory, Cross-domain image</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Cross-domain image retrieval aims at retrieving images across different
domains to excavate cross-domain classificatory or correspondence
relationships. This paper studies a less-touched problem of cross-domain image
retrieval, i.e., unsupervised cross-domain image retrieval, considering the
following practical assumptions: (i) no correspondence relationship, and (ii)
no category annotations. It is challenging to align and bridge distinct domains
without cross-domain correspondence. To tackle the challenge, we present a
novel Correspondence-free Domain Alignment (CoDA) method to effectively
eliminate the cross-domain gap through In-domain Self-matching Supervision
(ISS) and Cross-domain Classifier Alignment (CCA). To be specific, ISS is
presented to encapsulate discriminative information into the latent common
space by elaborating a novel self-matching supervision mechanism. To alleviate
the cross-domain discrepancy, CCA is proposed to align distinct domain-specific
classifiers. Thanks to the ISS and CCA, our method could encode the
discrimination into the domain-invariant embedding space for unsupervised
cross-domain image retrieval. To verify the effectiveness of the proposed
method, extensive experiments are conducted on four benchmark datasets compared
with six state-of-the-art methods.</p>
  </details>
</details>
<details>
  <summary>49. <b>标题：NYCU-TWO at Memotion 3: Good Foundation, Good Teacher, then you have  Good Meme Analysis</b></summary>
  <p><b>编号</b>：[229]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06078</p>
  <p><b>作者</b>：Yu-Chien Tang,  Kuang-Da Wang,  Ting-Yun Ou,  Wen-Chih Peng</p>
  <p><b>备注</b>：De-Factify 2: Second Workshop on Multimodal Fact Checking and Hate Speech Detection, co-located with AAAI 2023</p>
  <p><b>关键词</b>：Shared Task, Task, Cooperative Teaching Model, paper presents, presents a robust</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper presents a robust solution to the Memotion 3.0 Shared Task. The
goal of this task is to classify the emotion and the corresponding intensity
expressed by memes, which are usually in the form of images with short captions
on social media. Understanding the multi-modal features of the given memes will
be the key to solving the task. In this work, we use CLIP to extract aligned
image-text features and propose a novel meme sentiment analysis framework,
consisting of a Cooperative Teaching Model (CTM) for Task A and a Cascaded
Emotion Classifier (CEC) for Tasks B&C. CTM is based on the idea of knowledge
distillation, and can better predict the sentiment of a given meme in Task A;
CEC can leverage the emotion intensity suggestion from the prediction of Task C
to classify the emotion more precisely in Task B. Experiments show that we
achieved the 2nd place ranking for both Task A and Task B and the 4th place
ranking for Task C, with weighted F1-scores of 0.342, 0.784, and 0.535
respectively. The results show the robustness and effectiveness of our
framework. Our code is released at github.</p>
  </details>
</details>
<details>
  <summary>50. <b>标题：Actional Atomic-Concept Learning for Demystifying Vision-Language  Navigation</b></summary>
  <p><b>编号</b>：[230]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06072</p>
  <p><b>作者</b>：Bingqian Lin,  Yi Zhu,  Xiaodan Liang,  Liang Lin,  Jianzhuang Liu</p>
  <p><b>备注</b>：Accepted by AAAI 2023</p>
  <p><b>关键词</b>：align complex visual, complex visual observations, actional atomic concepts, actional atomic, goal position</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Vision-Language Navigation (VLN) is a challenging task which requires an
agent to align complex visual observations to language instructions to reach
the goal position. Most existing VLN agents directly learn to align the raw
directional features and visual features trained using one-hot labels to
linguistic instruction features. However, the big semantic gap among these
multi-modal inputs makes the alignment difficult and therefore limits the
navigation performance. In this paper, we propose Actional Atomic-Concept
Learning (AACL), which maps visual observations to actional atomic concepts for
facilitating the alignment. Specifically, an actional atomic concept is a
natural language phrase containing an atomic action and an object, e.g., ``go
up stairs''. These actional atomic concepts, which serve as the bridge between
observations and instructions, can effectively mitigate the semantic gap and
simplify the alignment. AACL contains three core components: 1) a concept
mapping module to map the observations to the actional atomic concept
representations through the VLN environment and the recently proposed
Contrastive Language-Image Pretraining (CLIP) model, 2) a concept refining
adapter to encourage more instruction-oriented object concept extraction by
re-ranking the predicted object concepts by CLIP, and 3) an observation
co-embedding module which utilizes concept representations to regularize the
observation representations. Our AACL establishes new state-of-the-art results
on both fine-grained (R2R) and high-level (REVERIE and R2R-Last) VLN
benchmarks. Moreover, the visualization shows that AACL significantly improves
the interpretability in action decision.</p>
  </details>
</details>
<details>
  <summary>51. <b>标题：Threatening Patch Attacks on Object Detection in Optical Remote Sensing  Images</b></summary>
  <p><b>编号</b>：[236]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06060</p>
  <p><b>作者</b>：Xuxiang Sun,  Gong Cheng,  Lei Pei,  Hongda Li,  Junwei Han</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Advanced Patch Attacks, deep neural networks, great safety vulnerability, Patch Attacks, neural networks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Advanced Patch Attacks (PAs) on object detection in natural images have
pointed out the great safety vulnerability in methods based on deep neural
networks. However, little attention has been paid to this topic in Optical
Remote Sensing Images (O-RSIs). To this end, we focus on this research, i.e.,
PAs on object detection in O-RSIs, and propose a more Threatening PA without
the scarification of the visual quality, dubbed TPA. Specifically, to address
the problem of inconsistency between local and global landscapes in existing
patch selection schemes, we propose leveraging the First-Order Difference (FOD)
of the objective function before and after masking to select the sub-patches to
be attacked. Further, considering the problem of gradient inundation when
applying existing coordinate-based loss to PAs directly, we design an IoU-based
objective function specific for PAs, dubbed Bounding box Drifting Loss (BDL),
which pushes the detected bounding boxes far from the initial ones until there
are no intersections between them. Finally, on two widely used benchmarks,
i.e., DIOR and DOTA, comprehensive evaluations of our TPA with four typical
detectors (Faster R-CNN, FCOS, RetinaNet, and YOLO-v4) witness its remarkable
effectiveness. To the best of our knowledge, this is the first attempt to study
the PAs on object detection in O-RSIs, and we hope this work can get our
readers interested in studying this topic.</p>
  </details>
</details>
<details>
  <summary>52. <b>标题：Bi-directional Masks for Efficient N:M Sparse Training</b></summary>
  <p><b>编号</b>：[237]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06058</p>
  <p><b>作者</b>：Yuxin Zhang,  Yiting Luo,  Mingbao Lin,  Yunshan Zhong,  Jingjing Xie,  Fei Chao,  Rongrong Ji</p>
  <p><b>备注</b>：10 pages, 4 figures</p>
  <p><b>关键词</b>：practical speedups supported, sparse tensor core, backward propagation issue, achieves practical speedups, Separate sparse masks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We focus on addressing the dense backward propagation issue for training
efficiency of N:M fine-grained sparsity that preserves at most N out of M
consecutive weights and achieves practical speedups supported by the N:M sparse
tensor core. Therefore, we present a novel method of Bi-directional Masks
(Bi-Mask) with its two central innovations in: 1) Separate sparse masks in the
two directions of forward and backward propagation to obtain training
acceleration. It disentangles the forward and backward weight sparsity and
overcomes the very dense gradient computation. 2) An efficient weight row
permutation method to maintain performance. It picks up the permutation
candidate with the most eligible N:M weight blocks in the backward to minimize
the gradient gap between traditional uni-directional masks and our
bi-directional masks. Compared with existing uni-directional scenario that
applies a transposable mask and enables backward acceleration, our Bi-Mask is
experimentally demonstrated to be more superior in performance. Also, our
Bi-Mask performs on par with or even better than methods that fail to achieve
backward acceleration. Project of this paper is available at
\url{this https URL}.</p>
  </details>
</details>
<details>
  <summary>53. <b>标题：CFNet: Cascade Fusion Network for Dense Prediction</b></summary>
  <p><b>编号</b>：[240]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06052</p>
  <p><b>作者</b>：Gang Zhang,  Ziyi Li,  Jianmin Li,  Xiaolin Hu</p>
  <p><b>备注</b>：Technical report; Code: this https URL</p>
  <p><b>关键词</b>：Multi-scale features, dense prediction tasks, Cascade Fusion Network, features, including object detection</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Multi-scale features are essential for dense prediction tasks, including
object detection, instance segmentation, and semantic segmentation. Existing
state-of-the-art methods usually first extract multi-scale features by a
classification backbone and then fuse these features by a lightweight module
(e.g. the fusion module in FPN). However, we argue that it may not be
sufficient to fuse the multi-scale features through such a paradigm, because
the parameters allocated for feature fusion are limited compared with the heavy
classification backbone. In order to address this issue, we propose a new
architecture named Cascade Fusion Network (CFNet) for dense prediction. Besides
the stem and several blocks used to extract initial high-resolution features,
we introduce several cascaded stages to generate multi-scale features in CFNet.
Each stage includes a sub-backbone for feature extraction and an extremely
lightweight transition block for feature integration. This design makes it
possible to fuse features more deeply and effectively with a large proportion
of parameters of the whole backbone. Extensive experiments on object detection,
instance segmentation, and semantic segmentation validated the effectiveness of
the proposed CFNet. Codes will be available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>54. <b>标题：Predicting Class Distribution Shift for Reliable Domain Adaptive Object  Detection</b></summary>
  <p><b>编号</b>：[244]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06039</p>
  <p><b>作者</b>：Nicolas Harvey Chapman,  Feras Dayoub,  Will Browne,  Christopher Lehnert</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Adaptive Object Detection, Unsupervised Domain Adaptive, Domain Adaptive Object, Object Detection, Adaptive Object</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Unsupervised Domain Adaptive Object Detection (UDA-OD) uses unlabelled data
to improve the reliability of robotic vision systems in open-world
environments. Previous approaches to UDA-OD based on self-training have been
effective in overcoming changes in the general appearance of images. However,
shifts in a robot's deployment environment can also impact the likelihood that
different objects will occur, termed class distribution shift. Motivated by
this, we propose a framework for explicitly addressing class distribution shift
to improve pseudo-label reliability in self-training. Our approach uses the
domain invariance and contextual understanding of a pre-trained joint vision
and language model to predict the class distribution of unlabelled data. By
aligning the class distribution of pseudo-labels with this prediction, we
provide weak supervision of pseudo-label accuracy. To further account for low
quality pseudo-labels early in self-training, we propose an approach to
dynamically adjust the number of pseudo-labels per image based on model
confidence. Our method outperforms state-of-the-art approaches on several
benchmarks, including a 4.7 mAP improvement when facing challenging class
distribution shift.</p>
  </details>
</details>
<details>
  <summary>55. <b>标题：A Correct-and-Certify Approach to Self-Supervise Object Pose Estimators  via Ensemble Self-Training</b></summary>
  <p><b>编号</b>：[252]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06019</p>
  <p><b>作者</b>：Jingnan Shi,  Rajat Talak,  Dominic Maggio,  Luca Carlone</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Real-world robotics applications, robotics applications demand, applications demand object, demand object pose, object pose estimation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Real-world robotics applications demand object pose estimation methods that
work reliably across a variety of scenarios. Modern learning-based approaches
require large labeled datasets and tend to perform poorly outside the training
domain. Our first contribution is to develop a robust corrector module that
corrects pose estimates using depth information, thus enabling existing methods
to better generalize to new test domains; the corrector operates on semantic
keypoints (but is also applicable to other pose estimators) and is fully
differentiable. Our second contribution is an ensemble self-training approach
that simultaneously trains multiple pose estimators in a self-supervised
manner. Our ensemble self-training architecture uses the robust corrector to
refine the output of each pose estimator; then, it evaluates the quality of the
outputs using observable correctness certificates; finally, it uses the
observably correct outputs for further training, without requiring external
supervision. As an additional contribution, we propose small improvements to a
regression-based keypoint detection architecture, to enhance its robustness to
outliers; these improvements include a robust pooling scheme and a robust
centroid computation. Experiments on the YCBV and TLESS datasets show the
proposed ensemble self-training outperforms fully supervised baselines while
not requiring 3D annotations on real data.</p>
  </details>
</details>
<details>
  <summary>56. <b>标题：A Theoretical Understanding of shallow Vision Transformers: Learning,  Generalization, and Sample Complexity</b></summary>
  <p><b>编号</b>：[254]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06015</p>
  <p><b>作者</b>：Hongkang Li,  Meng Wang,  Sijia Liu,  Pin-yu Chen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：recently achieved great, Vision Transformers, achieved great empirical, modules have recently, recently achieved</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Vision Transformers (ViTs) with self-attention modules have recently achieved
great empirical success in many vision tasks. Due to non-convex interactions
across layers, however, theoretical learning and generalization analysis is
mostly elusive. Based on a data model characterizing both label-relevant and
label-irrelevant tokens, this paper provides the first theoretical analysis of
training a shallow ViT, i.e., one self-attention layer followed by a two-layer
perceptron, for a classification task. We characterize the sample complexity to
achieve a zero generalization error. Our sample complexity bound is positively
correlated with the inverse of the fraction of label-relevant tokens, the token
noise level, and the initial model error. We also prove that a training process
using stochastic gradient descent (SGD) leads to a sparse attention map, which
is a formal verification of the general intuition about the success of
attention. Moreover, this paper indicates that a proper token sparsification
can improve the test performance by removing label-irrelevant and/or noisy
tokens, including spurious correlations. Empirical experiments on synthetic
data and CIFAR-10 dataset justify our theoretical results and generalize to
deeper ViTs.</p>
  </details>
</details>
<details>
  <summary>57. <b>标题：Policy-Induced Self-Supervision Improves Representation Finetuning in  Visual RL</b></summary>
  <p><b>编号</b>：[257]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06009</p>
  <p><b>作者</b>：Sébastien M. R. Arnold,  Fei Sha</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：visual percept based, visual percept, percept based, transfer representations pretrained, pretrained</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We study how to transfer representations pretrained on source tasks to target
tasks in visual percept based RL. We analyze two popular approaches: freezing
or finetuning the pretrained representations. Empirical studies on a set of
popular tasks reveal several properties of pretrained representations. First,
finetuning is required even when pretrained representations perfectly capture
the information required to solve the target task. Second, finetuned
representations improve learnability and are more robust to noise. Third,
pretrained bottom layers are task-agnostic and readily transferable to new
tasks, while top layers encode task-specific information and require
adaptation. Building on these insights, we propose a self-supervised objective
that clusters representations according to the policy they induce, as opposed
to traditional representation similarity measures which are policy-agnostic
(e.g. Euclidean norm, cosine similarity). Together with freezing the bottom
layers, this objective results in significantly better representation than
frozen, finetuned, and self-supervised alternatives on a wide range of
benchmarks.</p>
  </details>
</details>
<details>
  <summary>58. <b>标题：Digital Twin Tracking Dataset (DTTD): A New RGB+Depth 3D Dataset for  Longer-Range Object Tracking Applications</b></summary>
  <p><b>编号</b>：[266]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05991</p>
  <p><b>作者</b>：Weiyu Feng,  Seth Z. Zhao,  Chuanyu Pan,  Adam Chang,  Yichen Chen,  Zekun Wang,  Allen Y. Yang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：augmenting real objects, augmenting real, Digital twin, digital counterparts, object tracking</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Digital twin is a problem of augmenting real objects with their digital
counterparts. It can underpin a wide range of applications in augmented reality
(AR), autonomy, and UI/UX. A critical component in a good digital twin system
is real-time, accurate 3D object tracking. Most existing works solve 3D object
tracking through the lens of robotic grasping, employ older generations of
depth sensors, and measure performance metrics that may not apply to other
digital twin applications such as in AR. In this work, we create a novel RGB-D
dataset, called Digital-Twin Tracking Dataset (DTTD), to enable further
research of the problem and extend potential solutions towards longer ranges
and mm localization accuracy. To reduce point cloud noise from the input
source, we select the latest Microsoft Azure Kinect as the state-of-the-art
time-of-flight (ToF) camera. In total, 103 scenes of 10 common off-the-shelf
objects with rich textures are recorded, with each frame annotated with a
per-pixel semantic segmentation and ground-truth object poses provided by a
commercial motion capturing system. Through experiments, we demonstrate that
DTTD can help researchers develop future object tracking methods and analyze
new challenges. We provide the dataset, data generation, annotation, and model
evaluation pipeline as open source code at: this https URL.</p>
  </details>
</details>
<details>
  <summary>59. <b>标题：Self-supervised Pseudo-colorizing of Masked Cells</b></summary>
  <p><b>编号</b>：[276]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05968</p>
  <p><b>作者</b>：Royden Wagner,  Carlos Fernandez Lopez,  Christoph Stiller</p>
  <p><b>备注</b>：9 pages, 2 figures</p>
  <p><b>关键词</b>：matter of intelligence, strikingly referred, dark matter, gaining more attention, attention in biomedical</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Self-supervised learning, which is strikingly referred to as the dark matter
of intelligence, is gaining more attention in biomedical applications of deep
learning. In this work, we introduce a novel self-supervision objective for the
analysis of cells in biomedical microscopy images. We propose training deep
learning models to pseudo-colorize masked cells. We use a physics-informed
pseudo-spectral colormap that is well suited for colorizing cell topology. Our
experiments reveal that approximating semantic segmentation by
pseudo-colorization is beneficial for subsequent fine-tuning on cell detection.
Inspired by the recent success of masked image modeling, we additionally mask
out cell parts and train to reconstruct these parts to further enrich the
learned representations. We compare our pre-training method with
self-supervised frameworks including contrastive learning (SimCLR), masked
autoencoders (MAEs), and edge-based self-supervision. We build upon our
previous work and train hybrid models for cell detection, which contain both
convolutional and vision transformer modules. Our pre-training method can
outperform SimCLR, MAE-like masked image modeling, and edge-based
self-supervision when pre-training on a diverse set of six fluorescence
microscopy datasets. Code is available at:
this https URL</p>
  </details>
</details>
<details>
  <summary>60. <b>标题：Generalized Few-Shot Continual Learning with Contrastive Mixture of  Adapters</b></summary>
  <p><b>编号</b>：[292]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05936</p>
  <p><b>作者</b>：Yawen Cui,  Zitong Yu,  Rizhao Cai,  Xun Wang,  Alex C. Kot,  Li Liu</p>
  <p><b>备注</b>：Submitted to International Journal of Computer Vision (IJCV)</p>
  <p><b>关键词</b>：previous capabilities simultaneously, limited labeled samples, preserve previous capabilities, current FSCL methods, Few-Shot Continual Learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The goal of Few-Shot Continual Learning (FSCL) is to incrementally learn
novel tasks with limited labeled samples and preserve previous capabilities
simultaneously, while current FSCL methods are all for the class-incremental
purpose. Moreover, the evaluation of FSCL solutions is only the cumulative
performance of all encountered tasks, but there is no work on exploring the
domain generalization ability. Domain generalization is a challenging yet
practical task that aims to generalize beyond training domains. In this paper,
we set up a Generalized FSCL (GFSCL) protocol involving both class- and
domain-incremental situations together with the domain generalization
assessment. Firstly, two benchmark datasets and protocols are newly arranged,
and detailed baselines are provided for this unexplored configuration. We find
that common continual learning methods have poor generalization ability on
unseen domains and cannot better cope with the catastrophic forgetting issue in
cross-incremental tasks. In this way, we further propose a rehearsal-free
framework based on Vision Transformer (ViT) named Contrastive Mixture of
Adapters (CMoA). Due to different optimization targets of class increment and
domain increment, the CMoA contains two parts: (1) For the class-incremental
issue, the Mixture of Adapters (MoA) module is incorporated into ViT, then
cosine similarity regularization and the dynamic weighting are designed to make
each adapter learn specific knowledge and concentrate on particular classes.
(2) For the domain-related issues and domain-invariant representation learning,
we alleviate the inner-class variation by prototype-calibrated contrastive
learning. The codes and protocols are available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>61. <b>标题：Uncertainty-Aware AB3DMOT by Variational 3D Object Detection</b></summary>
  <p><b>编号</b>：[297]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05923</p>
  <p><b>作者</b>：Illia Oleksiienko,  Alexandros Iosifidis</p>
  <p><b>备注</b>：5 pages, 1 figure</p>
  <p><b>关键词</b>：ensure safe navigation, safe navigation, safe navigation protocol, Autonomous driving, rely on high-quality</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Autonomous driving needs to rely on high-quality 3D object detection to
ensure safe navigation in the world. Uncertainty estimation is an effective
tool to provide statistically accurate predictions, while the associated
detection uncertainty can be used to implement a more safe navigation protocol
or include the user in the loop. In this paper, we propose a Variational Neural
Network-based TANet 3D object detector to generate 3D object detections with
uncertainty and introduce these detections to an uncertainty-aware AB3DMOT
tracker. This is done by applying a linear transformation to the estimated
uncertainty matrix, which is subsequently used as a measurement noise for the
adopted Kalman filter. We implement two ways to estimate output uncertainty,
i.e., internally, by computing the variance of the CNNs outputs and then
propagating the uncertainty through the post-processing, and externally, by
associating the final predictions of different samples and computing the
covariance of each predicted box. In experiments, we show that the external
uncertainty estimation leads to better results, outperforming both internal
uncertainty estimation and classical tracking approaches. Furthermore, we
propose a method to initialize the Variational 3D object detector with a
pretrained TANet model, which leads to the best performing models.</p>
  </details>
</details>
<details>
  <summary>62. <b>标题：Video Waterdrop Removal via Spatio-Temporal Fusion in Driving Scenes</b></summary>
  <p><b>编号</b>：[300]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05916</p>
  <p><b>作者</b>：Qiang Wen,  Yue Wu,  Qifeng Chen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：severe visual obstructions, car accidents, lead to car, visual obstructions, severe visual</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The waterdrops on windshields during driving can cause severe visual
obstructions, which may lead to car accidents. Meanwhile, the waterdrops can
also degrade the performance of a computer vision system in autonomous driving.
To address these issues, we propose an attention-based framework that fuses the
spatio-temporal representations from multiple frames to restore visual
information occluded by waterdrops. Due to the lack of training data for video
waterdrop removal, we propose a large-scale synthetic dataset with simulated
waterdrops in complex driving scenes on rainy days. To improve the generality
of our proposed method, we adopt a cross-modality training strategy that
combines synthetic videos and real-world images. Extensive experiments show
that our proposed method can generalize well and achieve the best waterdrop
removal performance in complex real-world driving scenes.</p>
  </details>
</details>
<details>
  <summary>63. <b>标题：Variational Voxel Pseudo Image Tracking</b></summary>
  <p><b>编号</b>：[302]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05914</p>
  <p><b>作者</b>：Illia Oleksiienko,  Paraskevi Nousi,  Nikolaos Passalis,  Anastasios Tefas,  Alexandros Iosifidis</p>
  <p><b>备注</b>：5 pages, 2 figures, 1 table</p>
  <p><b>关键词</b>：perception models, model certainty, Voxel Pseudo Image, critical problems, autonomous driving</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Uncertainty estimation is an important task for critical problems, such as
robotics and autonomous driving, because it allows creating statistically
better perception models and signaling the model's certainty in its predictions
to the decision method or a human supervisor. In this paper, we propose a
Variational Neural Network-based version of a Voxel Pseudo Image Tracking
(VPIT) method for 3D Single Object Tracking. The Variational Feature Generation
Network of the proposed Variational VPIT computes features for target and
search regions and the corresponding uncertainties, which are later combined
using an uncertainty-aware cross-correlation module in one of two ways: by
computing similarity between the corresponding uncertainties and adding it to
the regular cross-correlation values, or by penalizing the uncertain feature
channels to increase influence of the certain features. In experiments, we show
that both methods improve tracking performance, while penalization of uncertain
features provides the best uncertainty quality.</p>
  </details>
</details>
<details>
  <summary>64. <b>标题：Single Motion Diffusion</b></summary>
  <p><b>编号</b>：[307]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05905</p>
  <p><b>作者</b>：Sigal Raab,  Inbal Leibovitch,  Guy Tevet,  Moab Arar,  Amit H. Bermano,  Daniel Cohen-Or</p>
  <p><b>备注</b>：Video: this https URL, Project page: this https URL, Code: this https URL</p>
  <p><b>关键词</b>：computer graphics professionals, Synthesizing realistic animations, Synthesizing realistic, graphics professionals, goal for artists</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Synthesizing realistic animations of humans, animals, and even imaginary
creatures, has long been a goal for artists and computer graphics
professionals. Compared to the imaging domain, which is rich with large
available datasets, the number of data instances for the motion domain is
limited, particularly for the animation of animals and exotic creatures (e.g.,
dragons), which have unique skeletons and motion patterns. In this work, we
present a Single Motion Diffusion Model, dubbed SinMDM, a model designed to
learn the internal motifs of a single motion sequence with arbitrary topology
and synthesize motions of arbitrary length that are faithful to them. We
harness the power of diffusion models and present a denoising network designed
specifically for the task of learning from a single input motion. Our
transformer-based architecture avoids overfitting by using local attention
layers that narrow the receptive field, and encourages motion diversity by
using relative positional embedding. SinMDM can be applied in a variety of
contexts, including spatial and temporal in-betweening, motion expansion, style
transfer, and crowd animation. Our results show that SinMDM outperforms
existing methods both in quality and time-space efficiency. Moreover, while
current approaches require additional training for different applications, our
work facilitates these applications at inference time. Our code and trained
models are available at this https URL.</p>
  </details>
</details>
<details>
  <summary>65. <b>标题：Low-Rank Tensor Completion With Generalized CP Decomposition and  Nonnegative Integer Tensor Completion</b></summary>
  <p><b>编号</b>：[318]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05881</p>
  <p><b>作者</b>：Shiran Yuan</p>
  <p><b>备注</b>：10 pages, 2 figures, and 1 table</p>
  <p><b>关键词</b>：tensor completion, signal processing, computer vision, tensor, low-rank tensor completion</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The problem of tensor completion is important to many areas such as computer
vision, data analysis, signal processing, etc. Previously, a category of
methods known as low-rank tensor completion has been proposed and developed,
involving the enforcement of low-rank structures on completed tensors. While
such methods have been constantly improved, none have previously considered
exploiting the numerical properties of tensor elements. This work attempts to
construct a new methodological framework called GCDTC (Generalized CP
Decomposition Tensor Completion) based on these properties. In this newly
introduced framework, the CP Decomposition is reformulated as a Maximum
Likelihood Estimate (MLE) problem, and generalized via the introduction of
differing loss functions. The generalized decomposition is subsequently applied
to low-rank tensor completion. Such loss functions can also be easily adjusted
to consider additional factors in completion, such as smoothness,
standardization, etc. An example of nonnegative integer tensor decomposition
via the Poisson CP Decomposition is given to demonstrate the new methodology's
potentials. Through experimentation with real-life data, it is confirmed that
this method could produce results superior to current state-of-the-art
methodologies. It is expected that the proposed notion would inspire a new set
of tensor completion methods based on the generalization of decompositions,
thus contributing to related fields.</p>
  </details>
</details>
<details>
  <summary>66. <b>标题：I$^2$SB: Image-to-Image Schrödinger Bridge</b></summary>
  <p><b>编号</b>：[319]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05872</p>
  <p><b>作者</b>：Guan-Horng Liu,  Arash Vahdat,  De-An Huang,  Evangelos A. Theodorou,  Weili Nie,  Anima Anandkumar</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Schrödinger Bridge, directly learn, diffusion models, diffusion, conditional diffusion models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose Image-to-Image Schrödinger Bridge (I$^2$SB), a new class of
conditional diffusion models that directly learn the nonlinear diffusion
processes between two given distributions. These diffusion bridges are
particularly useful for image restoration, as the degraded images are
structurally informative priors for reconstructing the clean images. I$^2$SB
belongs to a tractable class of Schrödinger bridge, the nonlinear extension
to score-based models, whose marginal distributions can be computed
analytically given boundary pairs. This results in a simulation-free framework
for nonlinear diffusions, where the I$^2$SB training becomes scalable by
adopting practical techniques used in standard diffusion models. We validate
I$^2$SB in solving various image restoration tasks, including inpainting,
super-resolution, deblurring, and JPEG restoration on ImageNet 256x256 and show
that I$^2$SB surpasses standard conditional diffusion models with more
interpretable generative processes. Moreover, I$^2$SB matches the performance
of inverse methods that additionally require the knowledge of the corruption
operators. Our work opens up new algorithmic opportunities for developing
efficient nonlinear diffusion models on a large scale. scale. Project page:
this https URL</p>
  </details>
</details>
<details>
  <summary>67. <b>标题：OAMatcher: An Overlapping Areas-based Network for Accurate Local Feature  Matching</b></summary>
  <p><b>编号</b>：[328]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05846</p>
  <p><b>作者</b>：Kun Dai,  Tao Xie,  Ke Wang,  Zhiqiang Jiang,  Ruifeng Li,  Lijun Zhao</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：visual applications, overlapping areas, essential component, entire images, match labels</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Local feature matching is an essential component in many visual applications.
In this work, we propose OAMatcher, a Tranformer-based detector-free method
that imitates humans behavior to generate dense and accurate matches. Firstly,
OAMatcher predicts overlapping areas to promote effective and clean global
context aggregation, with the key insight that humans focus on the overlapping
areas instead of the entire images after multiple observations when matching
keypoints in image pairs. Technically, we first perform global information
integration across all keypoints to imitate the humans behavior of observing
the entire images at the beginning of feature matching. Then, we propose
Overlapping Areas Prediction Module (OAPM) to capture the keypoints in
co-visible regions and conduct feature enhancement among them to simulate that
humans transit the focus regions from the entire images to overlapping regions,
hence realizeing effective information exchange without the interference coming
from the keypoints in non overlapping areas. Besides, since humans tend to
leverage probability to determine whether the match labels are correct or not,
we propose a Match Labels Weight Strategy (MLWS) to generate the coefficients
used to appraise the reliability of the ground-truth match labels, while
alleviating the influence of measurement noise coming from the data. Moreover,
we integrate depth-wise convolution into Tranformer encoder layers to ensure
OAMatcher extracts local and global feature representation concurrently.
Comprehensive experiments demonstrate that OAMatcher outperforms the
state-of-the-art methods on several benchmarks, while exhibiting excellent
robustness to extreme appearance variants. The source code is available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>68. <b>标题：Point Cloud Registration Based on Graph Matching Optimization</b></summary>
  <p><b>编号</b>：[329]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05844</p>
  <p><b>作者</b>：Qianliang Wu,  Yaqi Shen,  Guofeng Mei,  Yaqing Ding,  Lei Luo,  Jin Xie,  Jian Yang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Point Clouds Registration, rigid point cloud, feature learning stage, computer vision, Clouds Registration</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Point Clouds Registration is a fundamental and challenging problem in 3D
computer vision. It has been shown that the isometric transformation is an
essential property in rigid point cloud registration, but the existing methods
only utilize it in the outlier rejection stage. In this paper, we emphasize
that the isometric transformation is also important in the feature learning
stage for improving registration quality. We propose a \underline{G}raph
\underline{M}atching \underline{O}ptimization based \underline{Net}work
(denoted as GMONet for short), which utilizes the graph matching method to
explicitly exert the isometry preserving constraints in the point feature
learning stage to improve %refine the point representation. Specifically, we
%use exploit the partial graph matching constraint to enhance the overlap
region detection abilities of super points ($i.e.,$ down-sampled key points)
and full graph matching to refine the registration accuracy at the fine-level
overlap region. Meanwhile, we leverage the mini-batch sampling to improve the
efficiency of the full graph matching optimization. Given high discriminative
point features in the evaluation stage, we utilize the RANSAC approach to
estimate the transformation between the scanned pairs. The proposed method has
been evaluated on the 3DMatch/3DLoMatch benchmarks and the KITTI benchmark. The
experimental results show that our method achieves competitive performance
compared with the existing state-of-the-art baselines.</p>
  </details>
</details>
<details>
  <summary>69. <b>标题：TPE-Net: Track Point Extraction and Association Network for Rail Path  Proposal Generation</b></summary>
  <p><b>编号</b>：[349]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05803</p>
  <p><b>作者</b>：Jungwon Kang,  Mohammadjavad Ghorbanalivakili,  Gunho Sohn,  David Beach,  Veronica Marin</p>
  <p><b>备注</b>：7 pages, 6 figures, and 1 table Jungwon Kang and Mohammadjavad Ghorbanalivakili have equal contribution</p>
  <p><b>关键词</b>：minimizing collision risks, third-party objects, rail, essential feature, minimizing collision</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>One essential feature of an autonomous train is minimizing collision risks
with third-party objects. To estimate the risk, the control system must
identify topological information of all the rail routes ahead on which the
train can possibly move, especially within merging or diverging rails. This
way, the train can figure out the status of potential obstacles with respect to
its route and hence, make a timely decision. Numerous studies have successfully
extracted all rail tracks as a whole within forward-looking images without
considering element instances. Still, some image-based methods have employed
hard-coded prior knowledge of railway geometry on 3D data to associate
left-right rails and generate rail route instances. However, we propose a rail
path extraction pipeline in which left-right rail pixels of each rail route
instance are extracted and associated through a fully convolutional
encoder-decoder architecture called TPE-Net. Two different regression branches
for TPE-Net are proposed to regress the locations of center points of each rail
route, along with their corresponding left-right pixels. Extracted rail pixels
are then spatially clustered to generate topological information of all the
possible train routes (ego-paths), discarding non-ego-path ones. Experimental
results on a challenging, publicly released benchmark show true-positive-pixel
level average precision and recall of 0.9207 and 0.8721, respectively, at about
12 frames per second. Even though our evaluation results are not higher than
the SOTA, the proposed regression pipeline performs remarkably in extracting
the correspondences by looking once at the image. It generates strong rail
route hypotheses without reliance on camera parameters, 3D data, and
geometrical constraints.</p>
  </details>
</details>
<details>
  <summary>70. <b>标题：Fairness-aware Multi-view Clustering</b></summary>
  <p><b>编号</b>：[354]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05788</p>
  <p><b>作者</b>：Lecheng Zheng,  Yada Zhu,  Jingrui He</p>
  <p><b>备注</b>：Accepted by SDM23</p>
  <p><b>关键词</b>：label information simultaneously, era of big, data, label information, information simultaneously</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In the era of big data, we are often facing the challenge of data
heterogeneity and the lack of label information simultaneously. In the
financial domain (e.g., fraud detection), the heterogeneous data may include
not only numerical data (e.g., total debt and yearly income), but also text and
images (e.g., financial statement and invoice images). At the same time, the
label information (e.g., fraud transactions) may be missing for building
predictive models. To address these challenges, many state-of-the-art
multi-view clustering methods have been proposed and achieved outstanding
performance. However, these methods typically do not take into consideration
the fairness aspect and are likely to generate biased results using sensitive
information such as race and gender. Therefore, in this paper, we propose a
fairness-aware multi-view clustering method named FairMVC. It incorporates the
group fairness constraint into the soft membership assignment for each cluster
to ensure that the fraction of different groups in each cluster is
approximately identical to the entire data set. Meanwhile, we adopt the idea of
both contrastive learning and non-contrastive learning and propose novel
regularizers to handle heterogeneous data in complex scenarios with missing
data or noisy features. Experimental results on real-world data sets
demonstrate the effectiveness and efficiency of the proposed framework. We also
derive insights regarding the relative performance of the proposed regularizers
in various scenarios.</p>
  </details>
</details>
<details>
  <summary>71. <b>标题：Stochastic Surprisal: An inferential measurement of Free Energy in  Neural Networks</b></summary>
  <p><b>编号</b>：[358]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05776</p>
  <p><b>作者</b>：Mohit Prabhushankar,  Ghassan AlRegib</p>
  <p><b>备注</b>：Paper accepted at Frontiers in Neuroscience</p>
  <p><b>关键词</b>：supervised neural networks, supervised neural, conjectures and validates, neural networks, neural</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper conjectures and validates a framework that allows for action
during inference in supervised neural networks. Supervised neural networks are
constructed with the objective to maximize their performance metric in any
given task. This is done by reducing free energy and its associated surprisal
during training. However, the bottom-up inference nature of supervised networks
is a passive process that renders them fallible to noise. In this paper, we
provide a thorough background of supervised neural networks, both generative
and discriminative, and discuss their functionality from the perspective of
free energy principle. We then provide a framework for introducing action
during inference. We introduce a new measurement called stochastic surprisal
that is a function of the network, the input, and any possible action. This
action can be any one of the outputs that the neural network has learnt,
thereby lending stochasticity to the measurement. Stochastic surprisal is
validated on two applications: Image Quality Assessment and Recognition under
noisy conditions. We show that, while noise characteristics are ignored to make
robust recognition, they are analyzed to estimate image quality scores. We
apply stochastic surprisal on two applications, three datasets, and as a
plug-in on twelve networks. In all, it provides a statistically significant
increase among all measures. We conclude by discussing the implications of the
proposed stochastic surprisal in other areas of cognitive psychology including
expectancy-mismatch and abductive reasoning.</p>
  </details>
</details>
<details>
  <summary>72. <b>标题：Improving Sign Recognition with Phonology</b></summary>
  <p><b>编号</b>：[364]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05759</p>
  <p><b>作者</b>：Lee Kezar,  Jesse Thomason,  Zed Sevcikova Sehyr</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：American Sign Language, American Sign, sign language understanding, isolated sign language, automatic sign language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We use insights from research on American Sign Language (ASL) phonology to
train models for isolated sign language recognition (ISLR), a step towards
automatic sign language understanding. Our key insight is to explicitly
recognize the role of phonology in sign production to achieve more accurate
ISLR than existing work which does not consider sign language phonology. We
train ISLR models that take in pose estimations of a signer producing a single
sign to predict not only the sign but additionally its phonological
characteristics, such as the handshape. These auxiliary predictions lead to a
nearly 9% absolute gain in sign recognition accuracy on the WLASL benchmark,
with consistent improvements in ISLR regardless of the underlying prediction
model architecture. This work has the potential to accelerate linguistic
research in the domain of signed languages and reduce communication barriers
between deaf and hearing people.</p>
  </details>
</details>
<details>
  <summary>73. <b>标题：Multispectral Self-Supervised Learning with Viewmaker Networks</b></summary>
  <p><b>编号</b>：[365]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05757</p>
  <p><b>作者</b>：Jasmine Bayrooti,  Noah Goodman,  Alex Tamkin</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：identify similar, data points, training models, models to identify, Contrastive learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Contrastive learning methods have been applied to a range of domains and
modalities by training models to identify similar ``views'' of data points.
However, specialized scientific modalities pose a challenge for this paradigm,
as identifying good views for each scientific instrument is complex and
time-intensive. In this paper, we focus on applying contrastive learning
approaches to a variety of remote sensing datasets. We show that Viewmaker
networks, a recently proposed method for generating views, are promising for
producing views in this setting without requiring extensive domain knowledge
and trial and error. We apply Viewmaker to four multispectral imaging problems,
each with a different format, finding that Viewmaker can outperform cropping-
and reflection-based methods for contrastive learning in every case when
evaluated on downstream classification tasks. This provides additional evidence
that domain-agnostic methods can empower contrastive learning to scale to
real-world scientific domains. Open source code can be found at
this https URL.</p>
  </details>
</details>
<details>
  <summary>74. <b>标题：DaliID: Distortion-Adaptive Learned Invariance for Identification Models</b></summary>
  <p><b>编号</b>：[367]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05753</p>
  <p><b>作者</b>：Wes Robbins,  Gabriel Bertocco,  Terrance E. Boult</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：atmospheric turbulence, motion blur, upsampling artifacts, unconstrained scenarios, Distortion-Adaptive Learned Invariance</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In unconstrained scenarios, face recognition and person re-identification are
subject to distortions such as motion blur, atmospheric turbulence, or
upsampling artifacts. To improve robustness in these scenarios, we propose a
methodology called Distortion-Adaptive Learned Invariance for Identification
(DaliID) models. We contend that distortion augmentations, which degrade image
quality, can be successfully leveraged to a greater degree than has been shown
in the literature. Aided by an adaptive weighting schedule, a novel distortion
augmentation is applied at severe levels during training. This training
strategy increases feature-level invariance to distortions and decreases domain
shift to unconstrained scenarios. At inference, we use a magnitude-weighted
fusion of features from parallel models to retain robustness across the range
of images. DaliID models achieve state-of-the-art (SOTA) for both face
recognition and person re-identification on seven benchmark datasets, including
IJB-S, TinyFace, DeepChange, and MSMT17. Additionally, we provide recaptured
evaluation data at a distance of 750+ meters and further validate on real
long-distance face imagery.</p>
  </details>
</details>
<details>
  <summary>75. <b>标题：Removing Image Artifacts From Scratched Lens Protectors</b></summary>
  <p><b>编号</b>：[369]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05746</p>
  <p><b>作者</b>：Yufei Wang,  Renjie Wan,  Wenhan Yang,  Bihan Wen,  Lap-pui Chau,  Alex C. Kot</p>
  <p><b>备注</b>：Accepted by ISCAS 2023</p>
  <p><b>关键词</b>：easily scratched accidentally, avoid damage, mobile devices, devices to avoid, scratched lens protector</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A protector is placed in front of the camera lens for mobile devices to avoid
damage, while the protector itself can be easily scratched accidentally,
especially for plastic ones. The artifacts appear in a wide variety of
patterns, making it difficult to see through them clearly. Removing image
artifacts from the scratched lens protector is inherently challenging due to
the occasional flare artifacts and the co-occurring interference within mixed
artifacts. Though different methods have been proposed for some specific
distortions, they seldom consider such inherent challenges. In our work, we
consider the inherent challenges in a unified framework with two cooperative
modules, which facilitate the performance boost of each other. We also collect
a new dataset from the real world to facilitate training and evaluation
purposes. The experimental results demonstrate that our method outperforms the
baselines qualitatively and quantitatively. The code and datasets will be
released after acceptance.</p>
  </details>
</details>
<details>
  <summary>76. <b>标题：Rethinking Vision Transformer and Masked Autoencoder in Multimodal Face  Anti-Spoofing</b></summary>
  <p><b>编号</b>：[371]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05744</p>
  <p><b>作者</b>：Zitong Yu,  Rizhao Cai,  Yawen Cui,  Xin Liu,  Yongjian Hu,  Alex Kot</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：multimodal FAS, FAS, based multimodal learning, multimodal, vision transformer</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recently, vision transformer (ViT) based multimodal learning methods have
been proposed to improve the robustness of face anti-spoofing (FAS) systems.
However, there are still no works to explore the fundamental natures
(\textit{e.g.}, modality-aware inputs, suitable multimodal pre-training, and
efficient finetuning) in vanilla ViT for multimodal FAS. In this paper, we
investigate three key factors (i.e., inputs, pre-training, and finetuning) in
ViT for multimodal FAS with RGB, Infrared (IR), and Depth. First, in terms of
the ViT inputs, we find that leveraging local feature descriptors benefits the
ViT on IR modality but not RGB or Depth modalities. Second, in observation of
the inefficiency on direct finetuning the whole or partial ViT, we design an
adaptive multimodal adapter (AMA), which can efficiently aggregate local
multimodal features while freezing majority of ViT parameters. Finally, in
consideration of the task (FAS vs. generic object classification) and modality
(multimodal vs. unimodal) gaps, ImageNet pre-trained models might be
sub-optimal for the multimodal FAS task. To bridge these gaps, we propose the
modality-asymmetric masked autoencoder (M$^{2}$A$^{2}$E) for multimodal FAS
self-supervised pre-training without costly annotated labels. Compared with the
previous modality-symmetric autoencoder, the proposed M$^{2}$A$^{2}$E is able
to learn more intrinsic task-aware representation and compatible with
modality-agnostic (e.g., unimodal, bimodal, and trimodal) downstream settings.
Extensive experiments with both unimodal (RGB, Depth, IR) and multimodal
(RGB+Depth, RGB+IR, Depth+IR, RGB+Depth+IR) settings conducted on multimodal
FAS benchmarks demonstrate the superior performance of the proposed methods. We
hope these findings and solutions can facilitate the future research for
ViT-based multimodal FAS.</p>
  </details>
</details>
<details>
  <summary>77. <b>标题：Flexible-modal Deception Detection with Audio-Visual Adapter</b></summary>
  <p><b>编号</b>：[384]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05727</p>
  <p><b>作者</b>：Zhaoxu Li,  Zitong Yu,  Nithish Muthuchamy Selvaraj,  Xiaobao Guo,  Bingquan Shen,  Adams Wai-Kin Kong,  Alex Kot</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：multimedia anti-fraud, human behaviors, behaviors is vital, custom security, security and multimedia</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Detecting deception by human behaviors is vital in many fields such as custom
security and multimedia anti-fraud. Recently, audio-visual deception detection
attracts more attention due to its better performance than using only a single
modality. However, in real-world multi-modal settings, the integrity of data
can be an issue (e.g., sometimes only partial modalities are available). The
missing modality might lead to a decrease in performance, but the model still
learns the features of the missed modality. In this paper, to further improve
the performance and overcome the missing modality problem, we propose a novel
Transformer-based framework with an Audio-Visual Adapter (AVA) to fuse temporal
features across two modalities efficiently. Extensive experiments conducted on
two benchmark datasets demonstrate that the proposed method can achieve
superior performance compared with other multi-modal fusion methods under
flexible-modal (multiple and missing modalities) settings.</p>
  </details>
</details>
<details>
  <summary>78. <b>标题：ConMAE: Contour Guided MAE for Unsupervised Vehicle Re-Identification</b></summary>
  <p><b>编号</b>：[407]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05673</p>
  <p><b>作者</b>：Jing Yang,  Jianwu Fang,  Hongke Xu</p>
  <p><b>备注</b>：Accepted by CCDC2023</p>
  <p><b>关键词</b>：unsupervised vehicle re-identification, cross-view search task, Vehicle re-identification, unsupervised vehicle, search task</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Vehicle re-identification is a cross-view search task by matching the same
target vehicle from different perspectives. It serves an important role in
road-vehicle collaboration and intelligent road control. With the large-scale
and dynamic road environment, the paradigm of supervised vehicle
re-identification shows limited scalability because of the heavy reliance on
large-scale annotated datasets. Therefore, the unsupervised vehicle
re-identification with stronger cross-scene generalization ability has
attracted more attention. Considering that Masked Autoencoder (MAE) has shown
excellent performance in self-supervised learning, this work designs a Contour
Guided Masked Autoencoder for Unsupervised Vehicle Re-Identification (ConMAE),
which is inspired by extracting the informative contour clue to highlight the
key regions for cross-view correlation. ConMAE is implemented by preserving the
image blocks with contour pixels and randomly masking the blocks with smooth
textures. In addition, to improve the quality of pseudo labels of vehicles for
unsupervised re-identification, we design a label softening strategy and
adaptively update the label with the increase of training steps. We carry out
experiments on VeRi-776 and VehicleID datasets, and a significant performance
improvement is obtained by the comparison with the state-of-the-art
unsupervised vehicle re-identification methods. The code is available on the
website of this https URL.</p>
  </details>
</details>
<details>
  <summary>79. <b>标题：Jaccard Metric Losses: Optimizing the Jaccard Index with Soft Labels</b></summary>
  <p><b>编号</b>：[409]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05666</p>
  <p><b>作者</b>：Zifu Wang,  Matthew B. Blaschko</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：soft Jaccard loss, Jaccard index, Jaccard index measure, Jaccard, soft Jaccard</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>IoU losses are surrogates that directly optimize the Jaccard index. In
semantic segmentation, IoU losses are shown to perform better with respect to
the Jaccard index measure than pixel-wise losses such as the cross-entropy
loss. The most notable IoU losses are the soft Jaccard loss and the
Lovasz-Softmax loss. However, these losses are incompatible with soft labels
which are ubiquitous in machine learning. In this paper, we propose Jaccard
metric losses (JMLs), which are variants of the soft Jaccard loss, and are
compatible with soft labels. With JMLs, we study two of the most popular use
cases of soft labels: label smoothing and knowledge distillation. With a
variety of architectures, our experiments show significant improvements over
the cross-entropy loss on three semantic segmentation datasets (Cityscapes,
PASCAL VOC and DeepGlobe Land), and our simple approach outperforms
state-of-the-art knowledge distillation methods by a large margin. Our source
code is available at:
\href{this https URL}{this https URL}.</p>
  </details>
</details>
<details>
  <summary>80. <b>标题：Dual Relation Knowledge Distillation for Object Detection</b></summary>
  <p><b>编号</b>：[419]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05637</p>
  <p><b>作者</b>：Zhenliang Ni,  Fukui Yang,  Shengzhao Wen,  Gang Zhang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：relation, distillation, Knowledge distillation, model compression, relation knowledge distillation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Knowledge distillation is an effective method for model compression. However,
it is still a challenging topic to apply knowledge distillation to detection
tasks. There are two key points resulting poor distillation performance for
detection tasks. One is the serious imbalance between foreground and background
features, another one is that small object lacks enough feature representation.
To solve the above issues, we propose a new distillation method named dual
relation knowledge distillation (DRKD), including pixel-wise relation
distillation and instance-wise relation distillation.The pixel-wise relation
distillation embeds pixel-wise features in the graph space and applies graph
convolution to capture the global pixel relation. By distilling the global
pixel relation, the student detector can learn the relation between foreground
and background features, avoid the difficulty of distilling feature directly
for feature imbalance issue.Besides, we find that instance-wise relation
supplements valuable knowledge beyond independent features for small objects.
Thus, the instance-wise relation distillation is designed, which calculates the
similarity of different instances to obtain a relation matrix. More
importantly, a relation filter module is designed to highlight valuable
instance relations.The proposed dual relation knowledge distillation is general
and can be easily applied for both one-stage and two-stage detectors. Our
method achieves state-of-the-art performance, which improves Faster R-CNN based
on ResNet50 from 38.4\% to 41.6\% mAP and improves RetinaNet based on ResNet50
from 37.4% to 40.3% mAP on COCO 2017.</p>
  </details>
</details>
<details>
  <summary>81. <b>标题：Operation-level Progressive Differentiable Architecture Search</b></summary>
  <p><b>编号</b>：[421]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05632</p>
  <p><b>作者</b>：Xunyu Zhu,  Jian Li,  Yong Liu,  Weiping Wang</p>
  <p><b>备注</b>：To appear in ICDM 2021</p>
  <p><b>关键词</b>：Neural Architecture Search, low compute cost, Differentiable Neural Architecture, high search efficiency, Neural Architecture</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Differentiable Neural Architecture Search (DARTS) is becoming more and more
popular among Neural Architecture Search (NAS) methods because of its high
search efficiency and low compute cost. However, the stability of DARTS is very
inferior, especially skip connections aggregation that leads to performance
collapse. Though existing methods leverage Hessian eigenvalues to alleviate
skip connections aggregation, they make DARTS unable to explore architectures
with better performance. In the paper, we propose operation-level progressive
differentiable neural architecture search (OPP-DARTS) to avoid skip connections
aggregation and explore better architectures simultaneously. We first divide
the search process into several stages during the search phase and increase
candidate operations into the search space progressively at the beginning of
each stage. It can effectively alleviate the unfair competition between
operations during the search phase of DARTS by offsetting the inherent unfair
advantage of the skip connection over other operations. Besides, to keep the
competition between operations relatively fair and select the operation from
the candidate operations set that makes training loss of the supernet largest.
The experiment results indicate that our method is effective and efficient. Our
method's performance on CIFAR-10 is superior to the architecture found by
standard DARTS, and the transferability of our method also surpasses standard
DARTS. We further demonstrate the robustness of our method on three simple
search spaces, i.e., S2, S3, S4, and the results show us that our method is
more robust than standard DARTS. Our code is available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>82. <b>标题：Improving Differentiable Architecture Search via Self-Distillation</b></summary>
  <p><b>编号</b>：[424]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05629</p>
  <p><b>作者</b>：Xunyu Zhu,  Jian Li,  Yong Liu,  Weiping Wang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Architecture Search, Differentiable Architecture Search, Neural Architecture Search, Architecture, optimal architecture</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Differentiable Architecture Search (DARTS) is a simple yet efficient Neural
Architecture Search (NAS) method. During the search stage, DARTS trains a
supernet by jointly optimizing architecture parameters and network parameters.
During the evaluation stage, DARTS derives the optimal architecture based on
architecture parameters. However, the loss landscape of the supernet is not
smooth, and it results in a performance gap between the supernet and the
optimal architecture. In the paper, we propose Self-Distillation Differentiable
Neural Architecture Search (SD-DARTS) by utilizing self-distillation to
transfer knowledge of the supernet in previous steps to guide the training of
the supernet in the current steps. SD-DARTS can minimize the loss difference
for the two consecutive iterations so that minimize the sharpness of the
supernet's loss to bridge the performance gap between the supernet and the
optimal architecture. Furthermore, we propose voted teachers, which select
multiple previous supernets as teachers and vote teacher output probabilities
as the final teacher prediction. The knowledge of several teachers is more
abundant than a single teacher, thus, voted teachers can be more suitable to
lead the training of the supernet. Experimental results on real datasets
illustrate the advantages of our novel self-distillation-based NAS method
compared to state-of-the-art alternatives.</p>
  </details>
</details>
<details>
  <summary>83. <b>标题：A novel approach to generate datasets with XAI ground truth to evaluate  image models</b></summary>
  <p><b>编号</b>：[426]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05624</p>
  <p><b>作者</b>：Miquel Miró-Nicolau,  Antoni Jaume-i-Capó,  Gabriel Moyà-Alcover</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：models work internally, eXplainable artificial intelligence, artificial intelligence, work internally, increased usage</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>With the increased usage of artificial intelligence (AI), it is imperative to
understand how these models work internally. These needs have led to the
development of a new field called eXplainable artificial intelligence (XAI).
This field consists of on a set of techniques that allows us to theoretically
determine the cause of the AI decisions. One unsolved question about XAI is how
to measure the quality of explanations. In this study, we propose a new method
to generate datasets with ground truth (GT). These datasets allow us to measure
how faithful is a method without ad hoc solutions. We conducted a set of
experiments that compared our GT with real model explanations and obtained
excellent results confirming that our proposed method is correct.</p>
  </details>
</details>
<details>
  <summary>84. <b>标题：Dive into the Resolution Augmentations and Metrics in Low Resolution  Face Recognition: A Plain yet Effective New Baseline</b></summary>
  <p><b>编号</b>：[428]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05621</p>
  <p><b>作者</b>：Xu Ling,  Yichen Lu,  Wenqi Xu,  Weihong Deng,  Yingjie Zhang,  Xingchen Cui,  Hongzhi Shi,  Dongchao Wen</p>
  <p><b>备注</b>：AAAI 2023 R2HCAI Workshop</p>
  <p><b>关键词</b>：improved Face Recognition, processing Low Resolution, Face Recognition, dramatic performance deterioration, significantly improved Face</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Although deep learning has significantly improved Face Recognition (FR),
dramatic performance deterioration may occur when processing Low Resolution
(LR) faces. To alleviate this, approaches based on unified feature space are
proposed with the sacrifice under High Resolution (HR) circumstances. To deal
with the huge domain gap between HR and LR domains and achieve the best on both
domains, we first took a closer look at the impacts of several resolution
augmentations and then analyzed the difficulty of LR samples from the
perspective of the model gradient produced by different resolution samples.
Besides, we also find that the introduction of some resolutions could help the
learning of lower resolutions. Based on these, we divide the LR samples into
three difficulties according to the resolution and propose a more effective
Multi-Resolution Augmentation. Then, due to the rapidly increasing domain gap
as the resolution decreases, we carefully design a novel and effective metric
loss based on a LogExp distance function that provides decent gradients to
prevent oscillation near the convergence point or tolerance to small distance
errors; it could also dynamically adjust the penalty for errors in different
dimensions, allowing for more optimization of dimensions with large errors.
Combining these two insights, our model could learn more general knowledge in a
wide resolution range of images and balanced results can be achieved by our
extremely simple framework. Moreover, the augmentations and metrics are the
cornerstones of LRFR, so our method could be considered a new baseline for the
LRFR task. Experiments on the LRFR datasets: SCface, XQLFW, and large-scale
LRFR dataset: TinyFace demonstrate the effectiveness of our methods, while the
degradation on HRFR datasets is significantly reduced.</p>
  </details>
</details>
<details>
  <summary>85. <b>标题：Anatomical Invariance Modeling and Semantic Alignment for  Self-supervised Learning in 3D Medical Image Segmentation</b></summary>
  <p><b>编号</b>：[433]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05615</p>
  <p><b>作者</b>：Yankai Jiang,  Mingze Sun,  Heng Guo,  Ke Yan,  Le Lu,  Minfeng Xu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：recently achieved promising, achieved promising performance, recently achieved, achieved promising, image segmentation tasks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Self-supervised learning (SSL) has recently achieved promising performance
for 3D medical image segmentation tasks. Most current methods follow existing
SSL paradigm originally designed for photographic or natural images, which
cannot explicitly and thoroughly exploit the intrinsic similar anatomical
structures across varying medical images. This may in fact degrade the quality
of learned deep representations by maximizing the similarity among features
containing spatial misalignment information and different anatomical semantics.
In this work, we propose a new self-supervised learning framework, namely
Alice, that explicitly fulfills Anatomical invariance modeling and semantic
alignment via elaborately combining discriminative and generative objectives.
Alice introduces a new contrastive learning strategy which encourages the
similarity between views that are diversely mined but with consistent
high-level semantics, in order to learn invariant anatomical features.
Moreover, we design a conditional anatomical feature alignment module to
complement corrupted embeddings with globally matched semantics and inter-patch
topology information, conditioned by the distribution of local image content,
which permits to create better contrastive pairs. Our extensive quantitative
experiments on two public 3D medical image segmentation benchmarks of FLARE
2022 and BTCV demonstrate and validate the performance superiority of Alice,
surpassing the previous best SSL counterpart methods by 2.11% and 1.77% in Dice
coefficients, respectively.</p>
  </details>
</details>
<details>
  <summary>86. <b>标题：Differentiable Outlier Detection Enable Robust Deep Multimodal Analysis</b></summary>
  <p><b>编号</b>：[437]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05608</p>
  <p><b>作者</b>：Zhu Wang,  Sourav Medya,  Sathya N. Ravi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：unseen data, purely inductive, performing inference, inference on unseen, deep network models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Often, deep network models are purely inductive during training and while
performing inference on unseen data. Thus, when such models are used for
predictions, it is well known that they often fail to capture the semantic
information and implicit dependencies that exist among objects (or concepts) on
a population level. Moreover, it is still unclear how domain or prior modal
knowledge can be specified in a backpropagation friendly manner, especially in
large-scale and noisy settings. In this work, we propose an end-to-end vision
and language model incorporating explicit knowledge graphs. We also introduce
an interactive out-of-distribution (OOD) layer using implicit network operator.
The layer is used to filter noise that is brought by external knowledge base.
In practice, we apply our model on several vision and language downstream tasks
including visual question answering, visual reasoning, and image-text retrieval
on different datasets. Our experiments show that it is possible to design
models that perform similarly to state-of-art results but with significantly
fewer samples and training time.</p>
  </details>
</details>
<details>
  <summary>87. <b>标题：Sketch Less Face Image Retrieval: A New Challenge</b></summary>
  <p><b>编号</b>：[449]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05576</p>
  <p><b>作者</b>：Dawei Dai,  Yutang Li,  Liang Wang,  Shiyu Fu,  Shuyin Xia,  Guoyin Wang</p>
  <p><b>备注</b>：5 pages, 6 figs</p>
  <p><b>关键词</b>：specific scenarios, identify a person, sketch, face sketch, target face photo</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In some specific scenarios, face sketch was used to identify a person.
However, drawing a complete face sketch often needs skills and takes time,
which hinder its widespread applicability in the practice. In this study, we
proposed a new task named sketch less face image retrieval (SLFIR), in which
the retrieval was carried out at each stroke and aim to retrieve the target
face photo using a partial sketch with as few strokes as possible (see Fig.1).
Firstly, we developed a method to generate the data of sketch with drawing
process, and opened such dataset; Secondly, we proposed a two-stage method as
the baseline for SLFIR that (1) A triplet network, was first adopt to learn the
joint embedding space shared between the complete sketch and its target face
photo; (2) Regarding the sketch drawing episode as a sequence, we designed a
LSTM module to optimize the representation of the incomplete face sketch.
Experiments indicate that the new framework can finish the retrieval using a
partial or pool drawing sketch.</p>
  </details>
</details>
<details>
  <summary>88. <b>标题：3D Colored Shape Reconstruction from a Single RGB Image through  Diffusion</b></summary>
  <p><b>编号</b>：[452]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05573</p>
  <p><b>作者</b>：Bo Li,  Xiaolin Wei,  Fengwei Chen,  Bin Liu</p>
  <p><b>备注</b>：9 pages, 8 figures</p>
  <p><b>关键词</b>：single RGB image, RGB image, single RGB, diffusion model, shape</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose a novel 3d colored shape reconstruction method from a single RGB
image through diffusion model. Diffusion models have shown great development
potentials for high-quality 3D shape generation. However, most existing work
based on diffusion models only focus on geometric shape generation, they cannot
either accomplish 3D reconstruction from a single image, or produce 3D
geometric shape with color information. In this work, we propose to reconstruct
a 3D colored shape from a single RGB image through a novel conditional
diffusion model. The reverse process of the proposed diffusion model is
consisted of three modules, shape prediction module, color prediction module
and NeRF-like rendering module. In shape prediction module, the reference RGB
image is first encoded into a high-level shape feature and then the shape
feature is utilized as a condition to predict the reverse geometric noise in
diffusion model. Then the color of each 3D point updated in shape prediction
module is predicted by color prediction module. Finally, a NeRF-like rendering
module is designed to render the colored point cloud predicted by the former
two modules to 2D image space to guide the training conditioned only on a
reference image. As far as the authors know, the proposed method is the first
diffusion model for 3D colored shape reconstruction from a single RGB image.
Experimental results demonstrate that the proposed method achieves competitive
performance on colored 3D shape reconstruction, and the ablation study
validates the positive role of the color prediction module in improving the
reconstruction quality of 3D geometric point cloud.</p>
  </details>
</details>
<details>
  <summary>89. <b>标题：Adding Conditional Control to Text-to-Image Diffusion Models</b></summary>
  <p><b>编号</b>：[464]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05543</p>
  <p><b>作者</b>：Lvmin Zhang,  Maneesh Agrawala</p>
  <p><b>备注</b>：33 pages</p>
  <p><b>关键词</b>：neural network structure, support additional input, network structure, present a neural, neural network</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present a neural network structure, ControlNet, to control pretrained
large diffusion models to support additional input conditions. The ControlNet
learns task-specific conditions in an end-to-end way, and the learning is
robust even when the training dataset is small (< 50k). Moreover, training a
ControlNet is as fast as fine-tuning a diffusion model, and the model can be
trained on a personal devices. Alternatively, if powerful computation clusters
are available, the model can scale to large amounts (millions to billions) of
data. We report that large diffusion models like Stable Diffusion can be
augmented with ControlNets to enable conditional inputs like edge maps,
segmentation maps, keypoints, etc. This may enrich the methods to control large
diffusion models and further facilitate related applications.</p>
  </details>
</details>
<details>
  <summary>90. <b>标题：Semi-supervised Large-scale Fiber Detection in Material Images with  Synthetic Data</b></summary>
  <p><b>编号</b>：[465]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05541</p>
  <p><b>作者</b>：Lan Fu,  Zhiyuan Liu,  Jinlong Li,  Jeff Simmons,  Hongkai Yu,  Song Wang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：cross-sectioned image slices, orientation and major, minor axes, including their parameters, parameters of center</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Accurate detection of large-scale, elliptical-shape fibers, including their
parameters of center, orientation and major/minor axes, on the 2D
cross-sectioned image slices is very important for characterizing the
underlying cylinder 3D structures in microscopic material images. Detecting
fibers in a degraded image poses a challenge to both current fiber detection
and ellipse detection methods. This paper proposes a new semi-supervised deep
learning method for large-scale elliptical fiber detection with synthetic data,
which frees people from heavy data annotations and is robust to various kinds
of image degradations. A domain adaptation strategy is utilized to reduce the
domain distribution discrepancy between the synthetic data and the real data,
and a new Region of Interest (RoI)-ellipse learning and a novel RoI ranking
with the symmetry constraint are embedded in the proposed method. Experiments
on real microscopic material images demonstrate the effectiveness of the
proposed approach in large-scale fiber detection.</p>
  </details>
</details>
<details>
  <summary>91. <b>标题：CUDA: Curriculum of Data Augmentation for Long-Tailed Recognition</b></summary>
  <p><b>编号</b>：[484]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05499</p>
  <p><b>作者</b>：Sumyeong Ahn,  Jongwoo Ko,  Se-Young Yun</p>
  <p><b>备注</b>：ICLR'23 Spotlight, 23 pages</p>
  <p><b>关键词</b>：problems frequently occur, conventional deep learning, deep learning algorithms, imbalance problems frequently, real-world tasks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Class imbalance problems frequently occur in real-world tasks, and
conventional deep learning algorithms are well known for performance
degradation on imbalanced training datasets. To mitigate this problem, many
approaches have aimed to balance among given classes by re-weighting or
re-sampling training samples. These re-balancing methods increase the impact of
minority classes and reduce the influence of majority classes on the output of
models. However, the extracted representations may be of poor quality owing to
the limited number of minority samples. To handle this restriction, several
methods have been developed that increase the representations of minority
samples by leveraging the features of the majority samples. Despite extensive
recent studies, no deep analysis has been conducted on determination of classes
to be augmented and strength of augmentation has been conducted. In this study,
we first investigate the correlation between the degree of augmentation and
class-wise performance, and find that the proper degree of augmentation must be
allocated for each class to mitigate class imbalance problems. Motivated by
this finding, we propose a simple and efficient novel curriculum, which is
designed to find the appropriate per-class strength of data augmentation,
called CUDA: CUrriculum of Data Augmentation for long-tailed recognition. CUDA
can simply be integrated into existing long-tailed recognition methods. We
present the results of experiments showing that CUDA effectively achieves
better generalization performance compared to the state-of-the-art method on
various imbalanced datasets such as CIFAR-100-LT, ImageNet-LT, and iNaturalist
2018.</p>
  </details>
</details>
<details>
  <summary>92. <b>标题：MaskSketch: Unpaired Structure-guided Masked Image Generation</b></summary>
  <p><b>编号</b>：[485]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05496</p>
  <p><b>作者</b>：Dina Bashkirova,  Jose Lezama,  Kihyuk Sohn,  Kate Saenko,  Irfan Essa</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Recent conditional image, generation methods produce, Recent conditional, remarkable diversity, conditional image generation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent conditional image generation methods produce images of remarkable
diversity, fidelity and realism. However, the majority of these methods allow
conditioning only on labels or text prompts, which limits their level of
control over the generation result. In this paper, we introduce MaskSketch, an
image generation method that allows spatial conditioning of the generation
result using a guiding sketch as an extra conditioning signal during sampling.
MaskSketch utilizes a pre-trained masked generative transformer, requiring no
model training or paired supervision, and works with input sketches of
different levels of abstraction. We show that intermediate self-attention maps
of a masked generative transformer encode important structural information of
the input image, such as scene layout and object shape, and we propose a novel
sampling method based on this observation to enable structure-guided
generation. Our results show that MaskSketch achieves high image realism and
fidelity to the guiding structure. Evaluated on standard benchmark datasets,
MaskSketch outperforms state-of-the-art methods for sketch-to-image
translation, as well as unpaired image-to-image translation approaches.</p>
  </details>
</details>
<details>
  <summary>93. <b>标题：Element-Wise Attention Layers: an option for optimization</b></summary>
  <p><b>编号</b>：[488]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05488</p>
  <p><b>作者</b>：Giovanni Araujo Bacochina,  Rodrigo Clemente Thom de Souza</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Deep Learning Field, Attention Layers, Transformer-based models, recent years, key element</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The use of Attention Layers has become a trend since the popularization of
the Transformer-based models, being the key element for many state-of-the-art
models that have been developed through recent years. However, one of the
biggest obstacles in implementing these architectures - as well as many others
in Deep Learning Field - is the enormous amount of optimizing parameters they
possess, which make its use conditioned on the availability of robust hardware.
In this paper, it's proposed a new method of attention mechanism that adapts
the Dot-Product Attention, which uses matrices multiplications, to become
element-wise through the use of arrays multiplications. To test the
effectiveness of such approach, two models (one with a VGG-like architecture
and one with the proposed method) have been trained in a classification task
using Fashion MNIST and CIFAR10 datasets. Each model has been trained for 10
epochs in a single Tesla T4 GPU from Google Colaboratory. The results show that
this mechanism allows for an accuracy of 92% of the VGG-like counterpart in
Fashion MNIST dataset, while reducing the number of parameters in 97%. For
CIFAR10, the accuracy is still equivalent to 60% of the VGG-like counterpart
while using 50% less parameters.</p>
  </details>
</details>
<details>
  <summary>94. <b>标题：RAFaRe: Learning Robust and Accurate Non-parametric 3D Face  Reconstruction from Pseudo 2D&3D Pairs</b></summary>
  <p><b>编号</b>：[489]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05486</p>
  <p><b>作者</b>：Longwei Guo,  Hao Zhu,  Yuanxun Lu,  Menghua Wu,  Xun Cao</p>
  <p><b>备注</b>：Accepted to AAAI 2023 (Oral)</p>
  <p><b>关键词</b>：robust and accurate, accurate non-parametric method, SVFR, face reconstruction, parametric SVFR</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose a robust and accurate non-parametric method for single-view 3D
face reconstruction (SVFR). While tremendous efforts have been devoted to
parametric SVFR, a visible gap still lies between the result 3D shape and the
ground truth. We believe there are two major obstacles: 1) the representation
of the parametric model is limited to a certain face database; 2) 2D images and
3D shapes in the fitted datasets are distinctly misaligned. To resolve these
issues, a large-scale pseudo 2D\&3D dataset is created by first rendering the
detailed 3D faces, then swapping the face in the wild images with the rendered
face. These pseudo 2D&3D pairs are created from publicly available datasets
which eliminate the gaps between 2D and 3D data while covering diverse
appearances, poses, scenes, and illumination. We further propose a
non-parametric scheme to learn a well-generalized SVFR model from the created
dataset, and the proposed hierarchical signed distance function turns out to be
effective in predicting middle-scale and small-scale 3D facial geometry. Our
model outperforms previous methods on FaceScape-wild/lab and MICC benchmarks
and is well generalized to various appearances, poses, expressions, and
in-the-wild environments. The code is released at
this http URL .</p>
  </details>
</details>
<details>
  <summary>95. <b>标题：Between Generating Noise and Generating Images: Noise in the Correct  Frequency Improves the Quality of Synthetic Histopathology Images for Digital  Pathology</b></summary>
  <p><b>编号</b>：[501]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06549</p>
  <p><b>作者</b>：Nati Daniel,  Eliel Aknin,  Ariel Larey,  Yoni Peretz,  Guy Sela,  Yael Fisher,  Yonatan Savir</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：machine learning techniques, Synthetic images, Artificial intelligence, digital pathology, intelligence and machine</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Artificial intelligence and machine learning techniques have the promise to
revolutionize the field of digital pathology. However, these models demand
considerable amounts of data, while the availability of unbiased training data
is limited. Synthetic images can augment existing datasets, to improve and
validate AI algorithms. Yet, controlling the exact distribution of cellular
features within them is still challenging. One of the solutions is harnessing
conditional generative adversarial networks that take a semantic mask as an
input rather than a random noise. Unlike other domains, outlining the exact
cellular structure of tissues is hard, and most of the input masks depict
regions of cell types. However, using polygon-based masks introduce inherent
artifacts within the synthetic images - due to the mismatch between the polygon
size and the single-cell size. In this work, we show that introducing random
single-pixel noise with the appropriate spatial frequency into a polygon
semantic mask can dramatically improve the quality of the synthetic images. We
used our platform to generate synthetic images of immunohistochemistry-treated
lung biopsies. We test the quality of the images using a three-fold validation
procedure. First, we show that adding the appropriate noise frequency yields
87% of the similarity metrics improvement that is obtained by adding the actual
single-cell features. Second, we show that the synthetic images pass the Turing
test. Finally, we show that adding these synthetic images to the train set
improves AI performance in terms of PD-L1 semantic segmentation performances.
Our work suggests a simple and powerful approach for generating synthetic data
on demand to unbias limited datasets to improve the algorithms' accuracy and
validate their robustness.</p>
  </details>
</details>
<details>
  <summary>96. <b>标题：DEPAS: De-novo Pathology Semantic Masks using a Generative Model</b></summary>
  <p><b>编号</b>：[502]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06513</p>
  <p><b>作者</b>：Ariel Larey,  Nati Daniel,  Eliel Aknin,  Yael Fisher,  Yonatan Savir</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：semantic masks, diagnostic decision-making, integration of artificial, artificial intelligence, intelligence into digital</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The integration of artificial intelligence into digital pathology has the
potential to automate and improve various tasks, such as image analysis and
diagnostic decision-making. Yet, the inherent variability of tissues, together
with the need for image labeling, lead to biased datasets that limit the
generalizability of algorithms trained on them. One of the emerging solutions
for this challenge is synthetic histological images. However, debiasing real
datasets require not only generating photorealistic images but also the ability
to control the features within them. A common approach is to use generative
methods that perform image translation between semantic masks that reflect
prior knowledge of the tissue and a histological image. However, unlike other
image domains, the complex structure of the tissue prevents a simple creation
of histology semantic masks that are required as input to the image translation
model, while semantic masks extracted from real images reduce the process's
scalability. In this work, we introduce a scalable generative model, coined as
DEPAS, that captures tissue structure and generates high-resolution semantic
masks with state-of-the-art quality. We demonstrate the ability of DEPAS to
generate realistic semantic maps of tissue for three types of organs: skin,
prostate, and lung. Moreover, we show that these masks can be processed using a
generative image translation model to produce photorealistic histology images
of two types of cancer with two different types of staining techniques.
Finally, we harness DEPAS to generate multi-label semantic masks that capture
different cell types distributions and use them to produce histological images
with on-demand cellular features. Overall, our work provides a state-of-the-art
solution for the challenging task of generating synthetic histological images
while controlling their semantic information in a scalable way.</p>
  </details>
</details>
<details>
  <summary>97. <b>标题：ContrasInver: Voxel-wise Contrastive Semi-supervised Learning for  Seismic Inversion</b></summary>
  <p><b>编号</b>：[509]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06441</p>
  <p><b>作者</b>：Yimin Dou,  Timing Li,  Kewen Li,  Hongjie Duan,  Zhifeng Xu</p>
  <p><b>备注</b>：This work has been submitted to journal for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible</p>
  <p><b>关键词</b>：Recent studies, studies have shown, successful in hydrocarbon, hydrocarbon exploration, acoustic impedance inversion</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent studies have shown that learning theories have been very successful in
hydrocarbon exploration. Inversion of seismic into various attributes through
the relationship of 1D well-logs and 3D seismic is an essential step in
reservoir description, among which, acoustic impedance is one of the most
critical attributes, and although current deep learningbased impedance
inversion obtains promising results, it relies on a large number of logs (1D
labels, typically more than 30 well-logs are required per inversion), which is
unacceptable in many practical explorations. In this work, we define acoustic
impedance inversion as a regression task for learning sparse 1D labels from 3D
volume data and propose a voxel-wise semisupervised contrastive learning
framework, ContrasInver, for regression tasks under sparse labels. ConstraInver
consists of several key components, including a novel pre-training method for
3D seismic data inversion, a contrastive semi-supervised strategy for diffusing
well-log information to the global, and a continuous-value vectorized
characterization method for a contrastive learning-based regression task, and
also designed the distance TopK sampling method for improving the training
efficiency. We performed a complete ablation study on SEAM Phase I synthetic
data to verify the effectiveness of each component and compared our approach
with the current mainstream methods on this data, and our approach demonstrated
very significant advantages. In this data we achieved an SSIM of 0.92 and an
MSE of 0.079 with only four well-logs. ConstraInver is the first purely
data-driven approach to invert two classic field data, F3 Netherlands (only
four well-logs) and Delft (only three well-logs) and achieves very reasonable
and reliable results.</p>
  </details>
</details>
<details>
  <summary>98. <b>标题：Self-supervised phase unwrapping in fringe projection profilometry</b></summary>
  <p><b>编号</b>：[515]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06381</p>
  <p><b>作者</b>：Xiaomin Gao,  Wanzhong Song,  Chunqian Tan,  Junzhe Lei</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：fringe projection profilometry, Fast-speed and high-accuracy, high-accuracy three-dimensional, projection profilometry, phase unwrapping method</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Fast-speed and high-accuracy three-dimensional (3D) shape measurement has
been the goal all along in fringe projection profilometry (FPP). The
dual-frequency temporal phase unwrapping method (DF-TPU) is one of the
prominent technologies to achieve this goal. However, the period number of the
high-frequency pattern of existing DF-TPU approaches is usually limited by the
inevitable phase errors, setting a limit to measurement accuracy.
Deep-learning-based phase unwrapping methods for single-camera FPP usually
require labeled data for training. In this letter, a novel self-supervised
phase unwrapping method for single-camera FPP systems is proposed. The trained
network can retrieve the absolute fringe order from one phase map of 64-period
and overperform DF-TPU approaches in terms of depth accuracy. Experimental
results demonstrate the validation of the proposed method on real scenes of
motion blur, isolated objects, low reflectivity, and phase discontinuity.</p>
  </details>
</details>
<details>
  <summary>99. <b>标题：Deep Anatomical Federated Network (Dafne): an open client/server  framework for the continuous collaborative improvement of deep-learning-based  medical image segmentation</b></summary>
  <p><b>编号</b>：[517]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06352</p>
  <p><b>作者</b>：Francesco Santini,  Jakob Wasserthal,  Abramo Agosti,  Xeni Deligianni,  Kevin R. Keene,  Hermien E. Kan,  Stefan Sommer,  Christoph Stuprich,  Fengdan Wang,  Claudia Weidensteiner,  Giulia Manco,  Valentina Mazzoli,  Arjun Desai,  Anna Pichiecchio</p>
  <p><b>备注</b>：10 pages (main body), 5 figures. Work partially presented at the 2021 RSNA conference and at the 2023 ISMRM conference</p>
  <p><b>关键词</b>：extract quantitative information, clinical research, images to aid, diagnostic process, crucial step</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Semantic segmentation is a crucial step to extract quantitative information
from medical (and, specifically, radiological) images to aid the diagnostic
process, clinical follow-up. and to generate biomarkers for clinical research.
In recent years, machine learning algorithms have become the primary tool for
this task. However, its real-world performance is heavily reliant on the
comprehensiveness of training data. Dafne is the first decentralized,
collaborative solution that implements continuously evolving deep learning
models exploiting the collective knowledge of the users of the system. In the
Dafne workflow, the result of each automated segmentation is refined by the
user through an integrated interface, so that the new information is used to
continuously expand the training pool via federated incremental learning. The
models deployed through Dafne are able to improve their performance over time
and to generalize to data types not seen in the training sets, thus becoming a
viable and practical solution for real-life medical segmentation tasks.</p>
  </details>
</details>
<details>
  <summary>100. <b>标题：CholecTriplet2022: Show me a tool and tell me the triplet -- an  endoscopic vision challenge for surgical action triplet detection</b></summary>
  <p><b>编号</b>：[520]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06294</p>
  <p><b>作者</b>：Chinedu Innocent Nwoye,  Tong Yu,  Saurav Sharma,  Aditya Murali,  Deepak Alapatt,  Armine Vardazaryan,  Kun Yuan,  Jonas Hajek,  Wolfgang Reiter,  Amine Yamlahi,  Finn-Henri Smidt,  Xiaoyang Zou,  Guoyan Zheng,  Bruno Oliveira,  Helena R. Torres,  Satoshi Kondo,  Satoshi Kasai,  Felix Holm,  Ege Özsoy,  Shuangchun Gui,  Han Li,  Sista Raviteja,  Rachana Sathish,  Pranav Poudel,  Binod Bhattarai,  Ziheng Wang,  Guo Rui,  Melanie Schellenberg,  João L. Vilaça,  Tobias Czempiel,  Zhenkun Wang,  Debdoot Sheet,  Shrawan Kumar Thapa,  Max Berniker,  Patrick Godau,  Pedro Morais,  Sudarshan Regmi,  Thuy Nuong Tran,  Jaime Fonseca,  Jan-Hinrich Nölke,  Estevão Lima,  Eduard Vazquez,  Lena Maier-Hein,  Nassir Navab,  Pietro Mascagni,  Barbara Seeliger,  Cristians Gonzalez,  Didier Mutter,  Nicolas Padoy</p>
  <p><b>备注</b>：MICCAI EndoVis CholecTriplet2022 challenge report. Submitted to journal of Medical Image Analysis. 22 pages, 14 figures, 6 tables</p>
  <p><b>关键词</b>：gold standard approach, Formalizing surgical activities, Artificial Intelligence assistance, gold standard, standard approach</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Formalizing surgical activities as triplets of the used instruments, actions
performed, and target anatomies is becoming a gold standard approach for
surgical activity modeling. The benefit is that this formalization helps to
obtain a more detailed understanding of tool-tissue interaction which can be
used to develop better Artificial Intelligence assistance for image-guided
surgery. Earlier efforts and the CholecTriplet challenge introduced in 2021
have put together techniques aimed at recognizing these triplets from surgical
footage. Estimating also the spatial locations of the triplets would offer a
more precise intraoperative context-aware decision support for
computer-assisted intervention. This paper presents the CholecTriplet2022
challenge, which extends surgical action triplet modeling from recognition to
detection. It includes weakly-supervised bounding box localization of every
visible surgical instrument (or tool), as the key actors, and the modeling of
each tool-activity in the form of <instrument, verb, target> triplet. The paper
describes a baseline method and 10 new deep learning algorithms presented at
the challenge to solve the task. It also provides thorough methodological
comparisons of the methods, an in-depth analysis of the obtained results, their
significance, and useful insights for future research directions and
applications in surgery.</instrument,></p>
  </details>
</details>
<details>
  <summary>101. <b>标题：Content-Adaptive Motion Rate Adaption for Learned Video Compression</b></summary>
  <p><b>编号</b>：[521]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06293</p>
  <p><b>作者</b>：Chih-Hsuan Lin,  Yi-Hsin Chen,  Wen-Hsiao Peng</p>
  <p><b>备注</b>：Accepted by PCS 2022</p>
  <p><b>关键词</b>：achieving content-adaptive coding, motion rate adaptation, paper introduces, aim of achieving, achieving content-adaptive</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper introduces an online motion rate adaptation scheme for learned
video compression, with the aim of achieving content-adaptive coding on
individual test sequences to mitigate the domain gap between training and test
data. It features a patch-level bit allocation map, termed the $\alpha$-map, to
trade off between the bit rates for motion and inter-frame coding in a
spatially-adaptive manner. We optimize the $\alpha$-map through an online
back-propagation scheme at inference time. Moreover, we incorporate a
look-ahead mechanism to consider its impact on future frames. Extensive
experimental results confirm that the proposed scheme, when integrated into a
conditional learned video codec, is able to adapt motion bit rate effectively,
showing much improved rate-distortion performance particularly on test
sequences with complicated motion characteristics.</p>
  </details>
</details>
<details>
  <summary>102. <b>标题：Optimizing CT Scan Geometries With and Without Gradients</b></summary>
  <p><b>编号</b>：[524]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06251</p>
  <p><b>作者</b>：Mareike Thies,  Fabian Wagner,  Noah Maul,  Laura Pfaff,  Linda-Sophie Schneider,  Christopher Syben,  Andreas Maier</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：clear reconstructed image, computed tomography, precisely to obtain, obtain a clear, projection geometry</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In computed tomography (CT), the projection geometry used for data
acquisition needs to be known precisely to obtain a clear reconstructed image.
Rigid patient motion is a cause for misalignment between measured data and
employed geometry. Commonly, such motion is compensated by solving an
optimization problem that, e.g., maximizes the quality of the reconstructed
image with respect to the projection geometry. So far, gradient-free
optimization algorithms have been utilized to find the solution for this
problem. Here, we show that gradient-based optimization algorithms are a
possible alternative and compare the performance to their gradient-free
counterparts on a benchmark motion compensation problem. Gradient-based
algorithms converge substantially faster while being comparable to
gradient-free algorithms in terms of capture range and robustness to the number
of free parameters. Hence, gradient-based optimization is a viable alternative
for the given type of problems.</p>
  </details>
</details>
<details>
  <summary>103. <b>标题：Dual-layer Image Compression via Adaptive Downsampling and Spatially  Varying Upconversion</b></summary>
  <p><b>编号</b>：[530]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06096</p>
  <p><b>作者</b>：Xi Zhang,  Xiaolin Wu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：fit small displays, mobile end devices, Ultra high resolution, small displays, high-resolution displays</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Ultra high resolution (UHR) images are almost always downsampled to fit small
displays of mobile end devices and upsampled to its original resolution when
exhibited on very high-resolution displays. This observation motivates us on
jointly optimizing operation pairs of downsampling and upsampling that are
spatially adaptive to image contents for maximal rate-distortion performance.
In this paper, we propose an adaptive downsampled dual-layer (ADDL) image
compression system. In the ADDL compression system, an image is reduced in
resolution by learned content-adaptive downsampling kernels and compressed to
form a coded base layer. For decompression the base layer is decoded and
upconverted to the original resolution using a deep upsampling neural network,
aided by the prior knowledge of the learned adaptive downsampling kernels. We
restrict the downsampling kernels to the form of Gabor filters in order to
reduce the complexity of filter optimization and also reduce the amount of side
information needed by the decoder for adaptive upsampling. Extensive
experiments demonstrate that the proposed ADDL compression approach of jointly
optimized, spatially adaptive downsampling and upconversion outperforms the
state of the art image compression methods.</p>
  </details>
</details>
<details>
  <summary>104. <b>标题：NephroNet: A Novel Program for Identifying Renal Cell Carcinoma and  Generating Synthetic Training Images with Convolutional Neural Networks and  Diffusion Models</b></summary>
  <p><b>编号</b>：[546]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05830</p>
  <p><b>作者</b>：Yashvir Sabharwal</p>
  <p><b>备注</b>：22 pages, 5 figures, 2 tables</p>
  <p><b>关键词</b>：RCC, Renal cell carcinoma, RCC surgical resection, RCC surgical, kidney cancer</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Renal cell carcinoma (RCC) is a type of cancer that originates in the kidneys
and is the most common type of kidney cancer in adults. It can be classified
into several subtypes, including clear cell RCC, papillary RCC, and chromophobe
RCC. In this study, an artificial intelligence model was developed and trained
for classifying different subtypes of RCC using ResNet-18, a convolutional
neural network that has been widely used for image classification tasks. The
model was trained on a dataset of RCC histopathology images, which consisted of
digital images of RCC surgical resection slides that were annotated with the
corresponding subtype labels. The performance of the trained model was
evaluated using several metrics, including accuracy, precision, and recall.
Additionally, in this research, a novel synthetic image generation tool,
NephroNet, is developed on diffusion models that are used to generate original
images of RCC surgical resection slides. Diffusion models are a class of
generative models capable of synthesizing high-quality images from noise.
Several diffusers such as Stable Diffusion, Dreambooth Text-to-Image, and
Textual Inversion were trained on a dataset of RCC images and were used to
generate a series of original images that resembled RCC surgical resection
slides, all within the span of fewer than four seconds. The generated images
were visually realistic and could be used for creating new training datasets,
testing the performance of image analysis algorithms, and training medical
professionals. NephroNet is provided as an open-source software package and
contains files for data preprocessing, training, and visualization. Overall,
this study demonstrates the potential of artificial intelligence and diffusion
models for classifying and generating RCC images, respectively. These methods
could be useful for improving the diagnosis and treatment of RCC and more.</p>
  </details>
</details>
<details>
  <summary>105. <b>标题：Multi-class Brain Tumor Segmentation using Graph Attention Network</b></summary>
  <p><b>编号</b>：[558]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05598</p>
  <p><b>作者</b>：Dhrumil Patel,  Dhruv Patel,  Rudra Saxena,  Thangarajah Akilan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：magnetic resonance imaging, resonance imaging, plays an important, diagnostic radiology, tumor segmentation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Brain tumor segmentation from magnetic resonance imaging (MRI) plays an
important role in diagnostic radiology. To overcome the practical issues in
manual approaches, there is a huge demand for building automatic tumor
segmentation algorithms. This work introduces an efficient brain tumor
summation model by exploiting the advancement in MRI and graph neural networks
(GNNs). The model represents the volumetric MRI as a region adjacency graph
(RAG) and learns to identify the type of tumors through a graph attention
network (GAT) -- a variant of GNNs. The ablation analysis conducted on two
benchmark datasets proves that the proposed model can produce competitive
results compared to the leading-edge solutions. It achieves mean dice scores of
0.91, 0.86, 0.79, and mean Hausdorff distances in the 95th percentile (HD95) of
5.91, 6.08, and 9.52 mm, respectively, for whole tumor, core tumor, and
enhancing tumor segmentation on BraTS2021 validation dataset. On average, these
performances are >6\% and >50%, compared to a GNN-based baseline model,
respectively, on dice score and HD95 evaluation metrics.</p>
  </details>
</details>
<h1>自然语言处理</h1>
<details>
  <summary>1. <b>标题：UniAdapter: Unified Parameter-Efficient Transfer Learning for  Cross-modal Modeling</b></summary>
  <p><b>编号</b>：[4]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06605</p>
  <p><b>作者</b>：Haoyu Lu,  Mingyu Ding,  Yuqi Huo,  Guoxing Yang,  Zhiwu Lu,  Masayoshi Tomizuka,  Wei Zhan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：shown promising transferability, Large-scale vision-language pre-trained, shown promising, promising transferability, downstream tasks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large-scale vision-language pre-trained models have shown promising
transferability to various downstream tasks. As the size of these foundation
models and the number of downstream tasks grow, the standard full fine-tuning
paradigm becomes unsustainable due to heavy computational and storage costs.
This paper proposes UniAdapter, which unifies unimodal and multimodal adapters
for parameter-efficient cross-modal adaptation on pre-trained vision-language
models. Specifically, adapters are distributed to different modalities and
their interactions, with the total number of tunable parameters reduced by
partial weight sharing. The unified and knowledge-sharing design enables
powerful cross-modal representations that can benefit various downstream tasks,
requiring only 1.0%-2.0% tunable parameters of the pre-trained model. Extensive
experiments on 6 cross-modal downstream benchmarks (including video-text
retrieval, image-text retrieval, VideoQA, and VQA) show that in most cases,
UniAdapter not only outperforms the state-of-the-arts, but even beats the full
fine-tuning strategy. Particularly, on the MSRVTT retrieval task, UniAdapter
achieves 49.7% recall@1 with 2.2% model parameters, outperforming the latest
competitors by 2.0%. The code and models are available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>2. <b>标题：Task-Specific Skill Localization in Fine-tuned Language Models</b></summary>
  <p><b>编号</b>：[7]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06600</p>
  <p><b>作者</b>：Abhishek Panigrahi,  Nikunj Saunshi,  Haoyu Zhao,  Sanjeev Arora</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：solve diverse NLP, diverse NLP tasks, diverse NLP, NLP tasks, including in few-shot</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Pre-trained language models can be fine-tuned to solve diverse NLP tasks,
including in few-shot settings. Thus fine-tuning allows the model to quickly
pick up task-specific ``skills,'' but there has been limited study of where
these newly-learnt skills reside inside the massive model. This paper
introduces the term skill localization for this problem and proposes a
solution. Given the downstream task and a model fine-tuned on that task, a
simple optimization is used to identify a very small subset of parameters
($\sim0.01$% of model parameters) responsible for ($>95$%) of the model's
performance, in the sense that grafting the fine-tuned values for just this
tiny subset onto the pre-trained model gives performance almost as well as the
fine-tuned model. While reminiscent of recent works on parameter-efficient
fine-tuning, the novel aspects here are that: (i) No further re-training is
needed on the subset (unlike, say, with lottery tickets). (ii) Notable
improvements are seen over vanilla fine-tuning with respect to calibration of
predictions in-distribution ($40$-$90$% error reduction) as well as the quality
of predictions out-of-distribution (OOD). In models trained on multiple tasks,
a stronger notion of skill localization is observed, where the sparse regions
corresponding to different tasks are almost disjoint, and their overlap (when
it happens) is a proxy for task similarity. Experiments suggest that
localization via grafting can assist certain forms of continual learning.</p>
  </details>
</details>
<details>
  <summary>3. <b>标题：Gradient-Based Automated Iterative Recovery for Parameter-Efficient  Tuning</b></summary>
  <p><b>编号</b>：[9]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06598</p>
  <p><b>作者</b>：Maximilian Mozes,  Tolga Bolukbasi,  Ann Yuan,  Frederick Liu,  Nithum Thain,  Lucas Dixon</p>
  <p><b>备注</b>：Pre-print</p>
  <p><b>关键词</b>：Pretrained large language, large language models, Pretrained large, large language, solve a wide</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Pretrained large language models (LLMs) are able to solve a wide variety of
tasks through transfer learning. Various explainability methods have been
developed to investigate their decision making process. TracIn (Pruthi et al.,
2020) is one such gradient-based method which explains model inferences based
on the influence of training examples. In this paper, we explore the use of
TracIn to improve model performance in the parameter-efficient tuning (PET)
setting. We develop conversational safety classifiers via the prompt-tuning PET
method and show how the unique characteristics of the PET regime enable TracIn
to identify the cause for certain misclassifications by LLMs. We develop a new
methodology for using gradient-based explainability techniques to improve model
performance, G-BAIR: gradient-based automated iterative recovery. We show that
G-BAIR can recover LLM performance on benchmarks after manually corrupting
training labels. This suggests that influence methods like TracIn can be used
to automatically perform data cleaning, and introduces the potential for
interactive debugging and relabeling for PET-based transfer learning methods.</p>
  </details>
</details>
<details>
  <summary>4. <b>标题：Improving Out-of-Distribution Generalization of Neural Rerankers with  Contextualized Late Interaction</b></summary>
  <p><b>编号</b>：[14]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06589</p>
  <p><b>作者</b>：Xinyu Zhang,  Minghan Li,  Jimmy Lin</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：robust bi-encoder retriever, information retrieval finds, Recent progress, embedding query, query and document</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent progress in information retrieval finds that embedding query and
document representation into multi-vector yields a robust bi-encoder retriever
on out-of-distribution datasets. In this paper, we explore whether late
interaction, the simplest form of multi-vector, is also helpful to neural
rerankers that only use the [CLS] vector to compute the similarity score.
Although intuitively, the attention mechanism of rerankers at the previous
layers already gathers the token-level information, we find adding late
interaction still brings an extra 5% improvement in average on
out-of-distribution datasets, with little increase in latency and no
degradation in in-domain effectiveness. Through extensive experiments and
analysis, we show that the finding is consistent across different model sizes
and first-stage retrievers of diverse natures and that the improvement is more
prominent on longer queries.</p>
  </details>
</details>
<details>
  <summary>5. <b>标题：AbLit: A Resource for Analyzing and Generating Abridged Versions of  English Literature</b></summary>
  <p><b>编号</b>：[20]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06579</p>
  <p><b>作者</b>：Melissa Roemmele,  Kyle Shaffer,  Katrina Olsen,  Yiyi Wang,  Steve DeNeefe</p>
  <p><b>备注</b>：Accepted at EACL 2023</p>
  <p><b>关键词</b>：text involves shortening, involves shortening, linguistic qualities, versions of English, NLP perspective</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Creating an abridged version of a text involves shortening it while
maintaining its linguistic qualities. In this paper, we examine this task from
an NLP perspective for the first time. We present a new resource, AbLit, which
is derived from abridged versions of English literature books. The dataset
captures passage-level alignments between the original and abridged texts. We
characterize the linguistic relations of these alignments, and create automated
models to predict these relations as well as to generate abridgements for new
texts. Our findings establish abridgement as a challenging task, motivating
future resources and research. The dataset is available at
this http URL.</p>
  </details>
</details>
<details>
  <summary>6. <b>标题：Large Scale Multi-Lingual Multi-Modal Summarization Dataset</b></summary>
  <p><b>编号</b>：[29]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06560</p>
  <p><b>作者</b>：Yash Verma,  Anubhav Jangra,  Raghvendra Kumar,  Sriparna Saha</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：comprising multiple modalities, represent information comprising, information comprising multiple, Significant developments, multiple modalities</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Significant developments in techniques such as encoder-decoder models have
enabled us to represent information comprising multiple modalities. This
information can further enhance many downstream tasks in the field of
information retrieval and natural language processing; however, improvements in
multi-modal techniques and their performance evaluation require large-scale
multi-modal data which offers sufficient diversity. Multi-lingual modeling for
a variety of tasks like multi-modal summarization, text generation, and
translation leverages information derived from high-quality multi-lingual
annotated data. In this work, we present the current largest multi-lingual
multi-modal summarization dataset (M3LS), and it consists of over a million
instances of document-image pairs along with a professionally annotated
multi-modal summary for each pair. It is derived from news articles published
by British Broadcasting Corporation(BBC) over a decade and spans 20 languages,
targeting diversity across five language roots, it is also the largest
summarization dataset for 13 languages and consists of cross-lingual
summarization data for 2 languages. We formally define the multi-lingual
multi-modal summarization task utilizing our dataset and report baseline scores
from various state-of-the-art summarization techniques in a multi-lingual
setting. We also compare it with many similar datasets to analyze the
uniqueness and difficulty of M3LS.</p>
  </details>
</details>
<details>
  <summary>7. <b>标题：Implications of the Convergence of Language and Vision Model Geometries</b></summary>
  <p><b>编号</b>：[33]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06555</p>
  <p><b>作者</b>：Jiaang Li,  Yova Kementchedjhieva,  Anders Søgaard</p>
  <p><b>备注</b>：work in progress</p>
  <p><b>关键词</b>：Bender and Koller, Large-scale pretrained language, computer vision models, pretrained language models, Large-scale pretrained</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large-scale pretrained language models (LMs) are said to ``lack the ability
to connect [their] utterances to the world'' (Bender and Koller, 2020). If so,
we would expect LM representations to be unrelated to representations in
computer vision models. To investigate this, we present an empirical evaluation
across three different LMs (BERT, GPT2, and OPT) and three computer vision
models (VMs, including ResNet, SegFormer, and MAE). Our experiments show that
LMs converge towards representations that are partially isomorphic to those of
VMs, with dispersion, and polysemy both factoring into the alignability of
vision and language spaces. We discuss the implications of this finding.</p>
  </details>
</details>
<details>
  <summary>8. <b>标题：Towards Agile Text Classifiers for Everyone</b></summary>
  <p><b>编号</b>：[38]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06541</p>
  <p><b>作者</b>：Maximilian Mozes,  Jessica Hoffmann,  Katrin Tomanek,  Muhamed Kouate,  Nithum Thain,  Ann Yuan,  Tolga Bolukbasi,  Lucas Dixon</p>
  <p><b>备注</b>：Pre-print</p>
  <p><b>关键词</b>：tune generative language, Text-based safety classifiers, assistants and chatbots, language model behavior, content moderation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Text-based safety classifiers are widely used for content moderation and
increasingly to tune generative language model behavior - a topic of growing
concern for the safety of digital assistants and chatbots. However, different
policies require different classifiers, and safety policies themselves improve
from iteration and adaptation. This paper introduces and evaluates methods for
agile text classification, whereby classifiers are trained using small,
targeted datasets that can be quickly developed for a particular policy.
Experimenting with 7 datasets from three safety-related domains, comprising 15
annotation schemes, led to our key finding: prompt-tuning large language
models, like PaLM 62B, with a labeled dataset of as few as 80 examples can
achieve state-of-the-art performance. We argue that this enables a paradigm
shift for text classification, especially for models supporting safer online
discourse. Instead of collecting millions of examples to attempt to create
universal safety classifiers over months or years, classifiers could be tuned
using small datasets, created by individuals or small organizations, tailored
for specific use cases, and iterated on and adapted in the time-span of a day.</p>
  </details>
</details>
<details>
  <summary>9. <b>标题：Why Can't Discourse Parsing Generalize? A Thorough Investigation of the  Impact of Data Diversity</b></summary>
  <p><b>编号</b>：[56]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06488</p>
  <p><b>作者</b>：Yang Janet Liu,  Amir Zeldes</p>
  <p><b>备注</b>：Accepted at EACL 2023 (main, long); camera-ready version</p>
  <p><b>关键词</b>：NLP tasks, Recent advances, finally becoming reliable, advances in discourse, create the impression</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent advances in discourse parsing performance create the impression that,
as in other NLP tasks, performance for high-resource languages such as English
is finally becoming reliable. In this paper we demonstrate that this is not the
case, and thoroughly investigate the impact of data diversity on RST parsing
stability. We show that state-of-the-art architectures trained on the standard
English newswire benchmark do not generalize well, even within the news domain.
Using the two largest RST corpora of English with text from multiple genres, we
quantify the impact of genre diversity in training data for achieving
generalization to text types unseen during training. Our results show that a
heterogeneous training regime is critical for stable and generalizable models,
across parser architectures. We also provide error analyses of model outputs
and out-of-domain performance. To our knowledge, this study is the first to
fully evaluate cross-corpus RST parsing generalizability on complete trees,
examine between-genre degradation within an RST corpus, and investigate the
impact of genre diversity in training data composition.</p>
  </details>
</details>
<details>
  <summary>10. <b>标题：Is ChatGPT a General-Purpose Natural Language Processing Task Solver?</b></summary>
  <p><b>编号</b>：[60]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06476</p>
  <p><b>作者</b>：Chengwei Qin,  Aston Zhang,  Zhuosheng Zhang,  Jiaao Chen,  Michihiro Yasunaga,  Diyi Yang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：natural language processing, large language models, language processing, Spurred by advancements, advancements in scale</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Spurred by advancements in scale, large language models (LLMs) have
demonstrated the ability to perform a variety of natural language processing
(NLP) tasks zero-shot -- i.e., without adaptation on downstream data. Recently,
the debut of ChatGPT has drawn a great deal of attention from the natural
language processing (NLP) community due to the fact that it can generate
high-quality responses to human input and self-correct previous mistakes based
on subsequent conversations. However, it is not yet known whether ChatGPT can
serve as a generalist model that can perform many NLP tasks zero-shot. In this
work, we empirically analyze the zero-shot learning ability of ChatGPT by
evaluating it on 20 popular NLP datasets covering 7 representative task
categories. With extensive empirical studies, we demonstrate both the
effectiveness and limitations of the current version of ChatGPT. We find that
ChatGPT performs well on many tasks favoring reasoning capabilities (e.g.,
arithmetic reasoning) while it still faces challenges when solving specific
tasks such as sequence tagging. We additionally provide in-depth analysis
through qualitative case studies.</p>
  </details>
</details>
<details>
  <summary>11. <b>标题：Applying BERT and ChatGPT for Sentiment Analysis of Lyme Disease in  Scientific Literature</b></summary>
  <p><b>编号</b>：[61]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06474</p>
  <p><b>作者</b>：Teo Susnjak</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Natural Language Processing, tick-borne disease text, conducting Sentiment Analysis, Language Processing, Natural Language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This chapter presents a practical guide for conducting Sentiment Analysis
using Natural Language Processing (NLP) techniques in the domain of tick-borne
disease text. The aim is to demonstrate the process of how the presence of bias
in the discourse surrounding chronic manifestations of the disease can be
evaluated. The goal is to use a dataset of 5643 abstracts collected from
scientific journals on the topic of chronic Lyme disease to demonstrate using
Python, the steps for conducting sentiment analysis using pre-trained language
models and the process of validating the preliminary results using both
interpretable machine learning tools, as well as a novel methodology of using
emerging state-of-the-art large language models like ChatGPT. This serves as a
useful resource for researchers and practitioners interested in using NLP
techniques for sentiment analysis in the medical domain.</p>
  </details>
</details>
<details>
  <summary>12. <b>标题：POSGen: Personalized Opening Sentence Generation for Online Insurance  Sales</b></summary>
  <p><b>编号</b>：[63]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06470</p>
  <p><b>作者</b>：Yu Li,  Yi Zhang,  Weijia Wu,  Zimu Zhou,  Qiang Li</p>
  <p><b>备注</b>：IEEE BigData 2022</p>
  <p><b>关键词</b>：reach massive potential, massive potential customers, opening sentence generation, personalized opening sentence, digitization era</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The insurance industry is shifting their sales mode from offline to online,
in expectation to reach massive potential customers in the digitization era.
Due to the complexity and the nature of insurance products, a cost-effective
online sales solution is to exploit chatbot AI to raise customers' attention
and pass those with interests to human agents for further sales. For high
response and conversion rates of customers, it is crucial for the chatbot to
initiate a conversation with personalized opening sentences, which are
generated with user-specific topic selection and ordering. Such personalized
opening sentence generation is challenging because (i) there are limited
historical samples for conversation topic recommendation in online insurance
sales and (ii) existing text generation schemes often fail to support
customized topic ordering based on user preferences. We design POSGen, a
personalized opening sentence generation scheme dedicated for online insurance
sales. It transfers user embeddings learned from auxiliary online user
behaviours to enhance conversation topic recommendation, and exploits a context
management unit to arrange the recommended topics in user-specific ordering for
opening sentence generation. POSGen is deployed on a real-world online
insurance platform. It achieves 2.33x total insurance premium improvement
through a two-month global test.</p>
  </details>
</details>
<details>
  <summary>13. <b>标题：ChatGPT versus Traditional Question Answering for Knowledge Graphs:  Current Status and Future Directions Towards Knowledge Graph Chatbots</b></summary>
  <p><b>编号</b>：[65]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06466</p>
  <p><b>作者</b>：Reham Omar,  Omij Mangukiya,  Panos Kalnis,  Essam Mansour</p>
  <p><b>备注</b>：9 pages</p>
  <p><b>关键词</b>：extracting information easily, emerging research areas, natural language interfaces, knowledge graphs, easily and effectively</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Conversational AI and Question-Answering systems (QASs) for knowledge graphs
(KGs) are both emerging research areas: they empower users with natural
language interfaces for extracting information easily and effectively.
Conversational AI simulates conversations with humans; however, it is limited
by the data captured in the training datasets. In contrast, QASs retrieve the
most recent information from a KG by understanding and translating the natural
language question into a formal query supported by the database engine.
In this paper, we present a comprehensive study of the characteristics of the
existing alternatives towards combining both worlds into novel KG chatbots. Our
framework compares two representative conversational models, ChatGPT and
Galactica, against KGQAN, the current state-of-the-art QAS. We conduct a
thorough evaluation using four real KGs across various application domains to
identify the current limitations of each category of systems. Based on our
findings, we propose open research opportunities to empower QASs with chatbot
capabilities for KGs. All benchmarks and all raw results are available1 for
further analysis.</p>
  </details>
</details>
<details>
  <summary>14. <b>标题：A Study on ReLU and Softmax in Transformer</b></summary>
  <p><b>编号</b>：[67]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06461</p>
  <p><b>作者</b>：Kai Shen,  Junliang Guo,  Xu Tan,  Siliang Tang,  Rui Wang,  Jiang Bian</p>
  <p><b>备注</b>：work in progress</p>
  <p><b>关键词</b>：Softmax, previous works, FFN, Transformer architecture consists, FFN and key-value</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The Transformer architecture consists of self-attention and feed-forward
networks (FFNs) which can be viewed as key-value memories according to previous
works. However, FFN and traditional memory utilize different activation
functions (i.e., ReLU and Softmax respectively), which makes them not
equivalent. In this paper, we first rebuild the connections between FFN and
key-value memory by conducting extensive studies on ReLU and Softmax, and find
they are equivalent when adding an additional layer normalization module on
Softmax. In addition, ReLU outperforms Softmax on both FFN and key-value memory
when the number of value slots is large. We analyze the reasons and then
explore this good property of ReLU on the self-attention network where the
original Softmax activation performs poorly on long input sequences. We then
propose a full ReLU architecture named ReLUFormer which performs better than
the baseline Transformer on long sequence tasks such as document translation.
This paper sheds light on the following points: 1) Softmax and ReLU use
different normalization methods over elements which lead to different variances
of results, and ReLU is good at dealing with a large number of key-value slots;
2) FFN and key-value memory are equivalent, and thus the Transformer can be
viewed as a memory network where FFNs and self-attention networks are both
key-value memories.</p>
  </details>
</details>
<details>
  <summary>15. <b>标题：Encoding Sentence Position in Context-Aware Neural Machine Translation  with Concatenation</b></summary>
  <p><b>编号</b>：[68]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06459</p>
  <p><b>作者</b>：Lorenzo Lupo,  Marco Dinarelli,  Laurent Besacier</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：standard translation approach, Context-aware translation, standard translation, achieved by processing, translation approach</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Context-aware translation can be achieved by processing a concatenation of
consecutive sentences with the standard translation approach. This paper
investigates the intuitive idea of adopting segment embeddings for this task to
help the Transformer discern the position of each sentence in the concatenation
sequence. We compare various segment embeddings and propose novel methods to
encode sentence position into token representations, showing that they do not
benefit the vanilla concatenation approach except in a specific setting.</p>
  </details>
</details>
<details>
  <summary>16. <b>标题：Ordered Memory Baselines</b></summary>
  <p><b>编号</b>：[73]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06451</p>
  <p><b>作者</b>：Daniel Borisov,  Matthew D'Iorio,  Jeffrey Hyacinthe</p>
  <p><b>备注</b>：9 pages, 6 figures. Submitted for the NeurIPS 2019 Reproducibility Challenge</p>
  <p><b>关键词</b>：Ordered Memory model, Natural language, Ordered Memory, Natural language semantics, natural language processing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Natural language semantics can be modeled using the phrase-structured model,
which can be represented using a tree-type architecture. As a result, recent
advances in natural language processing have been made utilising recursive
neural networks using memory models that allow them to infer tree-type
representations of the input sentence sequence. These new tree models have
allowed for improvements in sentiment analysis and semantic recognition. Here
we review the Ordered Memory model proposed by Shen et al. (2019) at the
NeurIPS 2019 conference, and try to either create baselines that can perform
better or create simpler models that can perform equally as well. We found that
the Ordered Memory model performs on par with the state-of-the-art models used
in tree-type modelling, and performs better than simplified baselines that
require fewer parameters.</p>
  </details>
</details>
<details>
  <summary>17. <b>标题：Joint Span Segmentation and Rhetorical Role Labeling with Data  Augmentation for Legal Documents</b></summary>
  <p><b>编号</b>：[75]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06448</p>
  <p><b>作者</b>：T.Y.S.S. Santosh,  Philipp Bock,  Matthias Grabmair</p>
  <p><b>备注</b>：Accepted to ECIR 2023</p>
  <p><b>关键词</b>：including case summarization, legal judgements play, Rhetorical Role Labeling, semantic search, including case</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Segmentation and Rhetorical Role Labeling of legal judgements play a crucial
role in retrieval and adjacent tasks, including case summarization, semantic
search, argument mining etc. Previous approaches have formulated this task
either as independent classification or sequence labeling of sentences. In this
work, we reformulate the task at span level as identifying spans of multiple
consecutive sentences that share the same rhetorical role label to be assigned
via classification. We employ semi-Markov Conditional Random Fields (CRF) to
jointly learn span segmentation and span label assignment. We further explore
three data augmentation strategies to mitigate the data scarcity in the
specialized domain of law where individual documents tend to be very long and
annotation cost is high. Our experiments demonstrate improvement of span-level
prediction metrics with a semi-Markov CRF model over a CRF baseline. This
benefit is contingent on the presence of multi sentence spans in the document.</p>
  </details>
</details>
<details>
  <summary>18. <b>标题：Linguistic ambiguity analysis in ChatGPT</b></summary>
  <p><b>编号</b>：[86]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06426</p>
  <p><b>作者</b>：Miguel Ortega-Martín,  Óscar García-Sierra,  Alfonso Ardoiz,  Jorge Álvarez,  Juan Carlos Armenteros,  Adrián Alonso</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Natural Language Processing, main challenges, Language Processing, Natural Language, NLP</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Linguistic ambiguity is and has always been one of the main challenges in
Natural Language Processing (NLP) systems. Modern Transformer architectures
like BERT, T5 or more recently InstructGPT have achieved some impressive
improvements in many NLP fields, but there is still plenty of work to do.
Motivated by the uproar caused by ChatGPT, in this paper we provide an
introduction to linguistic ambiguity, its varieties and their relevance in
modern NLP, and perform an extensive empiric analysis. ChatGPT strengths and
weaknesses are revealed, as well as strategies to get the most of this model.</p>
  </details>
</details>
<details>
  <summary>19. <b>标题：Correcting Real-Word Spelling Errors: A New Hybrid Approach</b></summary>
  <p><b>编号</b>：[93]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06407</p>
  <p><b>作者</b>：Seyed MohammadSadegh Dashti,  Amid Khatibi Bardsiri,  Vahid Khatibi Bardsiri</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Natural Language, field of Natural, main tasks, Language, Damerau and Mercer</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Spelling correction is one of the main tasks in the field of Natural Language
Processing. Contrary to common spelling errors, real-word errors cannot be
detected by conventional spelling correction methods. The real-word correction
model proposed by Mays, Damerau and Mercer showed a great performance in
different evaluations. In this research, however, a new hybrid approach is
proposed which relies on statistical and syntactic knowledge to detect and
correct real-word errors. In this model, Constraint Grammar (CG) is used to
discriminate among sets of correction candidates in the search space. Mays,
Damerau and Mercer's trigram approach is manipulated to estimate the
probability of syntactically well-formed correction candidates. The approach
proposed here is tested on the Wall Street Journal corpus. The model can prove
to be more practical than some other models, such as WordNet-based method of
Hirst and Budanitsky and fixed windows size method of Wilcox-O'Hearn and Hirst.</p>
  </details>
</details>
<details>
  <summary>20. <b>标题：Type-Aware Decomposed Framework for Few-Shot Named Entity Recognition</b></summary>
  <p><b>编号</b>：[97]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06397</p>
  <p><b>作者</b>：Yongqi Li,  Tieyun Qian</p>
  <p><b>备注</b>：8 pages, 4 figures</p>
  <p><b>关键词</b>：named entity recognition, recent success achieved, two-stage prototypical networks, few-shot named entity, classification stage remain</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Despite the recent success achieved by several two-stage prototypical
networks in few-shot named entity recognition (NER) task, the over-detected
false spans at span detection stage and the inaccurate and unstable prototypes
at type classification stage remain to be challenging problems. In this paper,
we propose a novel Type-Aware Decomposed framework, namely TadNER, to solve
these problems. We first present a type-aware span filtering strategy to filter
out false spans by removing those semantically far away from type names. We
then present a type-aware contrastive learning strategy to construct more
accurate and stable prototypes by jointly exploiting support samples and type
names as references. Extensive experiments on various benchmarks prove that our
proposed TadNER framework yields a new state-of-the-art performance.</p>
  </details>
</details>
<details>
  <summary>21. <b>标题：Text2shape Deep Retrieval Model: Generating Initial Cases for Mechanical  Part Redesign under the Context of Case-Based Reasoning</b></summary>
  <p><b>编号</b>：[124]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06341</p>
  <p><b>作者</b>：Tianshuo Zang,  Maolin Yang,  Wentao Yong,  Pingyu Jiang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：historical case base, structural features, target mechanical parts, mechanical part redesign, key structural features</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Retrieving the similar solutions from the historical case base for new design
requirements is the first step in mechanical part redesign under the context of
case-based reasoning. However, the manual retrieving method has the problem of
low efficiency when the case base is large. Additionally, it is difficult for
simple reasoning algorithms (e.g., rule-based reasoning, decision tree) to
cover all the features in complicated design solutions. In this regard, a
text2shape deep retrieval model is established in order to support text
description-based mechanical part shapes retrieval, where the texts are for
describing the structural features of the target mechanical parts. More
specifically, feature engineering is applied to identify the key structural
features of the target mechanical parts. Based on the identified key structural
features, a training set of 1000 samples was constructed, where each sample
consisted of a paragraph of text description of a group of structural features
and the corresponding 3D shape of the structural features. RNN and 3D CNN
algorithms were customized to build the text2shape deep retrieval model.
Orthogonal experiments were used for modeling turning. Eventually, the highest
accuracy of the model was 0.98; therefore, the model can be effective for
retrieving initial cases for mechanical part redesign.</p>
  </details>
</details>
<details>
  <summary>22. <b>标题：Learning from Noisy Crowd Labels with Logics</b></summary>
  <p><b>编号</b>：[125]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06337</p>
  <p><b>作者</b>：Zhijun Chen,  Hailong Sun,  Haoqian He,  Pengpeng Chen</p>
  <p><b>备注</b>：12 pages, 7 figures, accepted by ICDE-2023. arXiv admin note: text overlap with arXiv:1603.06318 by other authors</p>
  <p><b>关键词</b>：noisy crowd labels, deep neural networks, crowd labels, noisy crowd, symbolic logic knowledge</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper explores the integration of symbolic logic knowledge into deep
neural networks for learning from noisy crowd labels. We introduce Logic-guided
Learning from Noisy Crowd Labels (Logic-LNCL), an EM-alike iterative logic
knowledge distillation framework that learns from both noisy labeled data and
logic rules of interest. Unlike traditional EM methods, our framework contains
a ``pseudo-E-step'' that distills from the logic rules a new type of learning
target, which is then used in the ``pseudo-M-step'' for training the
classifier. Extensive evaluations on two real-world datasets for text sentiment
classification and named entity recognition demonstrate that the proposed
framework improves the state-of-the-art and provides a new solution to learning
from noisy crowd labels.</p>
  </details>
</details>
<details>
  <summary>23. <b>标题：Parameter-efficient Modularised Bias Mitigation via AdapterFusion</b></summary>
  <p><b>编号</b>：[130]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06321</p>
  <p><b>作者</b>：Deepak Kumar,  Oleg Lesota,  George Zerveas,  Daniel Cohen,  Carsten Eickhoff,  Markus Schedl,  Navid Rekabsaz</p>
  <p><b>备注</b>：Accepted at EACL 2023</p>
  <p><b>关键词</b>：pre-trained language models, Large pre-trained language, societal biases, pre-trained language, model</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large pre-trained language models contain societal biases and carry along
these biases to downstream tasks. Current in-processing bias mitigation
approaches (like adversarial training) impose debiasing by updating a model's
parameters, effectively transferring the model to a new, irreversible debiased
state. In this work, we propose a novel approach to develop stand-alone
debiasing functionalities separate from the model, which can be integrated into
the model on-demand, while keeping the core model untouched. Drawing from the
concept of AdapterFusion in multi-task learning, we introduce DAM (Debiasing
with Adapter Modules) - a debiasing approach to first encapsulate arbitrary
bias mitigation functionalities into separate adapters, and then add them to
the model on-demand in order to deliver fairness qualities. We conduct a large
set of experiments on three classification tasks with gender, race, and age as
protected attributes. Our results show that DAM improves or maintains the
effectiveness of bias mitigation, avoids catastrophic forgetting in a
multi-attribute scenario, and maintains on-par task performance, while granting
parameter-efficiency and easy switching between the original and debiased
models.</p>
  </details>
</details>
<details>
  <summary>24. <b>标题：Distinguishability Calibration to In-Context Learning</b></summary>
  <p><b>编号</b>：[174]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06198</p>
  <p><b>作者</b>：Hongjing Li,  Hanqi Yan,  Yanran Li,  Li Qian,  Yulan He,  Lin Gui</p>
  <p><b>备注</b>：EACL23-Findings</p>
  <p><b>关键词</b>：witnessed increasing interests, Recent years, annotated instances, years have witnessed, witnessed increasing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent years have witnessed increasing interests in prompt-based learning in
which models can be trained on only a few annotated instances, making them
suitable in low-resource settings. When using prompt-based learning for text
classification, the goal is to use a pre-trained language model (PLM) to
predict a missing token in a pre-defined template given an input text, which
can be mapped to a class label. However, PLMs built on the transformer
architecture tend to generate similar output embeddings, making it difficult to
discriminate between different class labels. The problem is further exacerbated
when dealing with classification tasks involving many fine-grained class
labels. In this work, we alleviate this information diffusion issue, i.e.,
different tokens share a large proportion of similar information after going
through stacked multiple self-attention layers in a transformer, by proposing a
calibration method built on feature transformations through rotation and
scaling to map a PLM-encoded embedding into a new metric space to guarantee the
distinguishability of the resulting embeddings. Furthermore, we take the
advantage of hyperbolic embeddings to capture the hierarchical relations among
fine-grained class-associated token embedding by a coarse-to-fine metric
learning strategy to enhance the distinguishability of the learned output
embeddings. Extensive experiments on the three datasets under various settings
demonstrate the effectiveness of our approach. Our code can be found at
this https URL.</p>
  </details>
</details>
<details>
  <summary>25. <b>标题：Evaluation of Word Embeddings for the Social Sciences</b></summary>
  <p><b>编号</b>：[185]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06174</p>
  <p><b>作者</b>：Ricardo Schiffers,  Dagmar Kern,  Daniel Hienert</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：NLP tasks, essential instrument, NLP, Wikipedia dumps, social science</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Word embeddings are an essential instrument in many NLP tasks. Most available
resources are trained on general language from Web corpora or Wikipedia dumps.
However, word embeddings for domain-specific language are rare, in particular
for the social science domain. Therefore, in this work, we describe the
creation and evaluation of word embedding models based on 37,604 open-access
social science research papers. In the evaluation, we compare domain-specific
and general language models for (i) language coverage, (ii) diversity, and
(iii) semantic relationships. We found that the created domain-specific model,
even with a relatively small vocabulary size, covers a large part of social
science concepts, their neighborhoods are diverse in comparison to more general
models. Across all relation types, we found a more extensive coverage of
semantic relationships.</p>
  </details>
</details>
<details>
  <summary>26. <b>标题：Identifying Semantically Difficult Samples to Improve Text  Classification</b></summary>
  <p><b>编号</b>：[193]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06155</p>
  <p><b>作者</b>：Shashank Mujumdar,  Stuti Mehta,  Hima Patel,  Suman Mitra</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：text classification task, downstream text classification, addressing difficult samples, text classification, investigate the effect</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we investigate the effect of addressing difficult samples from
a given text dataset on the downstream text classification task. We define
difficult samples as being non-obvious cases for text classification by
analysing them in the semantic embedding space; specifically - (i) semantically
similar samples that belong to different classes and (ii) semantically
dissimilar samples that belong to the same class. We propose a penalty function
to measure the overall difficulty score of every sample in the dataset. We
conduct exhaustive experiments on 13 standard datasets to show a consistent
improvement of up to 9% and discuss qualitative results to show effectiveness
of our approach in identifying difficult samples for a text classification
model.</p>
  </details>
</details>
<details>
  <summary>27. <b>标题：NNKGC: Improving Knowledge Graph Completion with Node Neighborhoods</b></summary>
  <p><b>编号</b>：[203]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06132</p>
  <p><b>作者</b>：Zihui Li,  Boming Yang,  Toyotaro Suzumura</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：discover missing relations, aims to discover, query entities, head entity, discover missing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Knowledge graph completion (KGC) aims to discover missing relations of query
entities. Current text-based models utilize the entity name and description to
infer the tail entity given the head entity and a certain relation. Existing
approaches also consider the neighborhood of the head entity. However, these
methods tend to model the neighborhood using a flat structure and are only
restricted to 1-hop neighbors. In this work, we propose a node
neighborhood-enhanced framework for knowledge graph completion. It models the
head entity neighborhood from multiple hops using graph neural networks to
enrich the head node information. Moreover, we introduce an additional edge
link prediction task to improve KGC. Evaluation on two public datasets shows
that this framework is simple yet effective. The case study also shows that the
model is able to predict explainable predictions.</p>
  </details>
</details>
<details>
  <summary>28. <b>标题：Can GPT-3 Perform Statutory Reasoning?</b></summary>
  <p><b>编号</b>：[216]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06100</p>
  <p><b>作者</b>：Andrew Blair-Stanek,  Nils Holzenberger,  Benjamin Van Durme</p>
  <p><b>备注</b>：9 pages</p>
  <p><b>关键词</b>：Statutory reasoning, natural language, reasoning with facts, task of reasoning, reasoning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Statutory reasoning is the task of reasoning with facts and statutes, which
are rules written in natural language by a legislature. It is a basic legal
skill. In this paper we explore the capabilities of the most capable GPT-3
model, text-davinci-003, on an established statutory-reasoning dataset called
SARA. We consider a variety of approaches, including dynamic few-shot
prompting, chain-of-thought prompting, and zero-shot prompting. While we
achieve results with GPT-3 that are better than the previous best published
results, we also identify several types of clear errors it makes. In
investigating why these happen, we discover that GPT-3 has imperfect prior
knowledge of the actual U.S. statutes on which SARA is based. More importantly,
GPT-3 performs poorly at answering straightforward questions about simple
synthetic statutes. By also posing the same questions when the synthetic
statutes are written in sentence form, we find that some of GPT-3's poor
performance results from difficulty in parsing the typical structure of
statutes, containing subsections and paragraphs.</p>
  </details>
</details>
<details>
  <summary>29. <b>标题：NYCU-TWO at Memotion 3: Good Foundation, Good Teacher, then you have  Good Meme Analysis</b></summary>
  <p><b>编号</b>：[229]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06078</p>
  <p><b>作者</b>：Yu-Chien Tang,  Kuang-Da Wang,  Ting-Yun Ou,  Wen-Chih Peng</p>
  <p><b>备注</b>：De-Factify 2: Second Workshop on Multimodal Fact Checking and Hate Speech Detection, co-located with AAAI 2023</p>
  <p><b>关键词</b>：Shared Task, Task, Cooperative Teaching Model, paper presents, presents a robust</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper presents a robust solution to the Memotion 3.0 Shared Task. The
goal of this task is to classify the emotion and the corresponding intensity
expressed by memes, which are usually in the form of images with short captions
on social media. Understanding the multi-modal features of the given memes will
be the key to solving the task. In this work, we use CLIP to extract aligned
image-text features and propose a novel meme sentiment analysis framework,
consisting of a Cooperative Teaching Model (CTM) for Task A and a Cascaded
Emotion Classifier (CEC) for Tasks B&C. CTM is based on the idea of knowledge
distillation, and can better predict the sentiment of a given meme in Task A;
CEC can leverage the emotion intensity suggestion from the prediction of Task C
to classify the emotion more precisely in Task B. Experiments show that we
achieved the 2nd place ranking for both Task A and Task B and the 4th place
ranking for Task C, with weighted F1-scores of 0.342, 0.784, and 0.535
respectively. The results show the robustness and effectiveness of our
framework. Our code is released at github.</p>
  </details>
</details>
<details>
  <summary>30. <b>标题：Emotion Detection in Unfix-length-Context Conversation</b></summary>
  <p><b>编号</b>：[251]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06029</p>
  <p><b>作者</b>：Xiaochen Zhang,  Daniel Tang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：context windows, proper context windows, context, conversational context, distilled conversational context</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We leverage different context windows when predicting the emotion of
different utterances. New modules are included to realize variable-length
context: 1) two speaker-aware units, which explicitly model inner- and
inter-speaker dependencies to form distilled conversational context, and 2) a
top-k normalization layer, which determines the most proper context windows
from the conversational context to predict emotion. Experiments and ablation
studies show that our approach outperforms several strong baselines on three
public datasets.</p>
  </details>
</details>
<details>
  <summary>31. <b>标题：ASR Bundestag: A Large-Scale political debate dataset in German</b></summary>
  <p><b>编号</b>：[258]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06008</p>
  <p><b>作者</b>：Johannes Wirth,  René Peinl</p>
  <p><b>备注</b>：13 pages, 2 tables, 4 figures</p>
  <p><b>关键词</b>：present ASR Bundestag, ASR Bundestag, automatic speech recognition, present ASR, automatic speech</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present ASR Bundestag, a dataset for automatic speech recognition in
German, consisting of 610 hours of aligned audio-transcript pairs for
supervised training as well as 1,038 hours of unlabeled audio snippets for
self-supervised learning, based on raw audio data and transcriptions from
plenary sessions and committee meetings of the German parliament. In addition,
we discuss utilized approaches for the automated creation of speech datasets
and assess the quality of the resulting dataset based on evaluations and
finetuning of a pre-trained state of the art model. We make the dataset
publicly available, including all subsets.</p>
  </details>
</details>
<details>
  <summary>32. <b>标题：MarioGPT: Open-Ended Text2Level Generation through Large Language Models</b></summary>
  <p><b>编号</b>：[271]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05981</p>
  <p><b>作者</b>：Shyam Sudhakaran,  Miguel González-Duque,  Claire Glanois,  Matthias Freiberger,  Elias Najarro,  Sebastian Risi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：PCG, Content, Procedural Content Generation, generate, Large Language Models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Procedural Content Generation (PCG) algorithms provide a technique to
generate complex and diverse environments in an automated way. However, while
generating content with PCG methods is often straightforward, generating
meaningful content that reflects specific intentions and constraints remains
challenging. Furthermore, many PCG algorithms lack the ability to generate
content in an open-ended manner. Recently, Large Language Models (LLMs) have
shown to be incredibly effective in many diverse domains. These trained LLMs
can be fine-tuned, re-using information and accelerating training for new
tasks. In this work, we introduce MarioGPT, a fine-tuned GPT2 model trained to
generate tile-based game levels, in our case Super Mario Bros levels. We show
that MarioGPT can not only generate diverse levels, but can be text-prompted
for controllable level generation, addressing one of the key challenges of
current PCG techniques. As far as we know, MarioGPT is the first text-to-level
model. We also combine MarioGPT with novelty search, enabling it to generate
diverse levels with varying play-style dynamics (i.e. player paths). This
combination allows for the open-ended generation of an increasingly diverse
range of content.</p>
  </details>
</details>
<details>
  <summary>33. <b>标题：Decoupling the Skeleton Parsing and Schema Linking for Text-to-SQL</b></summary>
  <p><b>编号</b>：[278]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05965</p>
  <p><b>作者</b>：Haoyang Li,  Jing Zhang,  Cuiping Li,  Hong Chen</p>
  <p><b>备注</b>：Accepted to AAAI 2023 main conference (oral)</p>
  <p><b>关键词</b>：pre-trained language model, SQL parsing, SQL, SQL queries, schema items</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>One of the recent best attempts at Text-to-SQL is the pre-trained language
model. Due to the structural property of the SQL queries, the seq2seq model
takes the responsibility of parsing both the schema items (i.e., tables and
columns) and the skeleton (i.e., SQL keywords). Such coupled targets increase
the difficulty of parsing the correct SQL queries especially when they involve
many schema items and logic operators. This paper proposes a ranking-enhanced
encoding and skeleton-aware decoding framework to decouple the schema linking
and the skeleton parsing. Specifically, for a seq2seq encoder-decode model, its
encoder is injected by the most relevant schema items instead of the whole
unordered ones, which could alleviate the schema linking effort during SQL
parsing, and its decoder first generates the skeleton and then the actual SQL
query, which could implicitly constrain the SQL parsing. We evaluate our
proposed framework on Spider and its three robustness variants: Spider-DK,
Spider-Syn, and Spider-Realistic. The experimental results show that our
framework delivers promising performance and robustness. Our code is available
at this https URL.</p>
  </details>
</details>
<details>
  <summary>34. <b>标题：Analyzing the Effectiveness of the Underlying Reasoning Tasks in  Multi-hop Question Answering</b></summary>
  <p><b>编号</b>：[279]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05963</p>
  <p><b>作者</b>：Xanh Ho,  Anh-Khoa Duong Nguyen,  Saku Sugawara,  Akiko Aizawa</p>
  <p><b>备注</b>：Accepted by EACL 2023 (Findings)</p>
  <p><b>关键词</b>：utilized underlying reasoning, tasks, reasoning, explain the predicted, utilized underlying</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>To explain the predicted answers and evaluate the reasoning abilities of
models, several studies have utilized underlying reasoning (UR) tasks in
multi-hop question answering (QA) datasets. However, it remains an open
question as to how effective UR tasks are for the QA task when training models
on both tasks in an end-to-end manner. In this study, we address this question
by analyzing the effectiveness of UR tasks (including both sentence-level and
entity-level tasks) in three aspects: (1) QA performance, (2) reasoning
shortcuts, and (3) robustness. While the previous models have not been
explicitly trained on an entity-level reasoning prediction task, we build a
multi-task model that performs three tasks together: sentence-level supporting
facts prediction, entity-level reasoning prediction, and answer prediction.
Experimental results on 2WikiMultiHopQA and HotpotQA-small datasets reveal that
(1) UR tasks can improve QA performance. Using four debiased datasets that are
newly created, we demonstrate that (2) UR tasks are helpful in preventing
reasoning shortcuts in the multi-hop QA task. However, we find that (3) UR
tasks do not contribute to improving the robustness of the model on adversarial
questions, such as sub-questions and inverted questions. We encourage future
studies to investigate the effectiveness of entity-level reasoning in the form
of natural language questions (e.g., sub-question forms).</p>
  </details>
</details>
<details>
  <summary>35. <b>标题：Stabilized In-Context Learning with Pre-trained Language Models for Few  Shot Dialogue State Tracking</b></summary>
  <p><b>编号</b>：[293]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05932</p>
  <p><b>作者</b>：Derek Chen,  Kun Qian,  Zhou Yu</p>
  <p><b>备注</b>：14 pages, 3 figures, 7 tables. Accepted at EACL 2023</p>
  <p><b>关键词</b>：large pre-trained language, shown impressive unaided, impressive unaided performance, pre-trained language models, NLP tasks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Prompt-based methods with large pre-trained language models (PLMs) have shown
impressive unaided performance across many NLP tasks. These models improve even
further with the addition of a few labeled in-context exemplars to guide output
generation. However, for more complex tasks such as dialogue state tracking
(DST), designing prompts that reliably convey the desired intent is nontrivial,
leading to unstable results. Furthermore, building in-context exemplars for
dialogue tasks is difficult because conversational contexts are long while
model input lengths are relatively short. To overcome these issues we first
adapt a meta-learning scheme to the dialogue domain which stabilizes the
ability of the model to perform well under various prompts. We additionally
design a novel training method to improve upon vanilla retrieval mechanisms to
find ideal in-context examples. Finally, we introduce a saliency model to limit
dialogue text length, allowing us to include more exemplars per query. In
effect, we are able to achieve highly competitive results for few-shot DST on
MultiWOZ.</p>
  </details>
</details>
<details>
  <summary>36. <b>标题：An Extended Sequence Tagging Vocabulary for Grammatical Error Correction</b></summary>
  <p><b>编号</b>：[303]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05913</p>
  <p><b>作者</b>：Stuart Mesham,  Christopher Bryant,  Marek Rei,  Zheng Yuan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Grammatical Error Correction, current sequence-tagging approach, introducing specialised tags, spelling correction, Grammatical Error</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We extend a current sequence-tagging approach to Grammatical Error Correction
(GEC) by introducing specialised tags for spelling correction and morphological
inflection using the SymSpell and LemmInflect algorithms. Our approach improves
generalisation: the proposed new tagset allows a smaller number of tags to
correct a larger range of errors. Our results show a performance improvement
both overall and in the targeted error categories. We further show that
ensembles trained with our new tagset outperform those trained with the
baseline tagset on the public BEA benchmark.</p>
  </details>
</details>
<details>
  <summary>37. <b>标题：Investigating the Effect of Relative Positional Embeddings on  AMR-to-Text Generation with Structural Adapters</b></summary>
  <p><b>编号</b>：[308]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05900</p>
  <p><b>作者</b>：Sebastien Montella,  Alexis Nasr,  Johannes Heinecke,  Frederic Bechet,  Lina M. Rojas-Barahona</p>
  <p><b>备注</b>：Accepted to EACL 2023 (Main)</p>
  <p><b>关键词</b>：Pretrained Language Models, popularized Pretrained Language, Abstract Meaning Representation, Language Models, Abstract Meaning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Text generation from Abstract Meaning Representation (AMR) has substantially
benefited from the popularized Pretrained Language Models (PLMs). Myriad
approaches have linearized the input graph as a sequence of tokens to fit the
PLM tokenization requirements. Nevertheless, this transformation jeopardizes
the structural integrity of the graph and is therefore detrimental to its
resulting representation. To overcome this issue, Ribeiro et al. have recently
proposed StructAdapt, a structure-aware adapter which injects the input graph
connectivity within PLMs using Graph Neural Networks (GNNs). In this paper, we
investigate the influence of Relative Position Embeddings (RPE) on AMR-to-Text,
and, in parallel, we examine the robustness of StructAdapt. Through ablation
studies, graph attack and link prediction, we reveal that RPE might be
partially encoding input graphs. We suggest further research regarding the role
of RPE will provide valuable insights for Graph-to-Text generation.</p>
  </details>
</details>
<details>
  <summary>38. <b>标题：Discourse Structure Extraction from Pre-Trained and Fine-Tuned Language  Models in Dialogues</b></summary>
  <p><b>编号</b>：[310]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05895</p>
  <p><b>作者</b>：Chuyuan Li,  Patrick Huber,  Wen Xiao,  Maxime Amblard,  Chloé Braud,  Giuseppe Carenini</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Pre-trained Language Models, Discourse processing suffers, data sparsity, processing suffers, suffers from data</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Discourse processing suffers from data sparsity, especially for dialogues. As
a result, we explore approaches to build discourse structures for dialogues,
based on attention matrices from Pre-trained Language Models (PLMs). We
investigate multiple tasks for fine-tuning and show that the dialogue-tailored
Sentence Ordering task performs best. To locate and exploit discourse
information in PLMs, we propose an unsupervised and a semi-supervised method.
Our proposals achieve encouraging results on the STAC corpus, with F1 scores of
57.2 and 59.3 for unsupervised and semi-supervised methods, respectively. When
restricted to projective trees, our scores improved to 63.3 and 68.1.</p>
  </details>
</details>
<details>
  <summary>39. <b>标题：TextDefense: Adversarial Text Detection based on Word Importance Entropy</b></summary>
  <p><b>编号</b>：[312]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05892</p>
  <p><b>作者</b>：Lujia Shen,  Xuhong Zhang,  Shouling Ji,  Yuwen Pu,  Chunpeng Ge,  Xing Yang,  Yanghe Feng</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：natural language processing, natural language, language processing, target model, NLP</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Currently, natural language processing (NLP) models are wildly used in
various scenarios. However, NLP models, like all deep models, are vulnerable to
adversarially generated text. Numerous works have been working on mitigating
the vulnerability from adversarial attacks. Nevertheless, there is no
comprehensive defense in existing works where each work targets a specific
attack category or suffers from the limitation of computation overhead,
irresistible to adaptive attack, etc.
In this paper, we exhaustively investigate the adversarial attack algorithms
in NLP, and our empirical studies have discovered that the attack algorithms
mainly disrupt the importance distribution of words in a text. A well-trained
model can distinguish subtle importance distribution differences between clean
and adversarial texts. Based on this intuition, we propose TextDefense, a new
adversarial example detection framework that utilizes the target model's
capability to defend against adversarial attacks while requiring no prior
knowledge. TextDefense differs from previous approaches, where it utilizes the
target model for detection and thus is attack type agnostic. Our extensive
experiments show that TextDefense can be applied to different architectures,
datasets, and attack methods and outperforms existing methods. We also discover
that the leading factor influencing the performance of TextDefense is the
target model's generalizability. By analyzing the property of the target model
and the property of the adversarial example, we provide our insights into the
adversarial attacks in NLP and the principles of our defense method.</p>
  </details>
</details>
<details>
  <summary>40. <b>标题：Position Matters! Empirical Study of Order Effect in Knowledge-grounded  Dialogue</b></summary>
  <p><b>编号</b>：[315]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05888</p>
  <p><b>作者</b>：Hsuan Su,  Shachi H Kumar,  Sahisnu Mazumder,  Wenda Chen,  Ramesh Manuvinakurike,  Eda Okur,  Saurav Sahay,  Lama Nachman,  Shang-Tse Chen,  Hung-yi Lee</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：large pretrained language, pretrained language models, power of large, large pretrained, pretrained language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>With the power of large pretrained language models, various research works
have integrated knowledge into dialogue systems. The traditional techniques
treat knowledge as part of the input sequence for the dialogue system,
prepending a set of knowledge statements in front of dialogue history. However,
such a mechanism forces knowledge sets to be concatenated in an ordered manner,
making models implicitly pay imbalanced attention to the sets during training.
In this paper, we first investigate how the order of the knowledge set can
influence autoregressive dialogue systems' responses. We conduct experiments on
two commonly used dialogue datasets with two types of transformer-based models
and find that models view the input knowledge unequally. To this end, we
propose a simple and novel technique to alleviate the order effect by modifying
the position embeddings of knowledge input in these models. With the proposed
position embedding method, the experimental results show that each knowledge
statement is uniformly considered to generate responses.</p>
  </details>
</details>
<details>
  <summary>41. <b>标题："Why is this misleading?": Detecting News Headline Hallucinations with  Explanations</b></summary>
  <p><b>编号</b>：[326]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05852</p>
  <p><b>作者</b>：Jiaming Shen,  Jialu Liu,  Dan Finnie,  Negar Rahmati,  Michael Bendersky,  Marc Najork</p>
  <p><b>备注</b>：WWW 2023, 12 pages</p>
  <p><b>关键词</b>：generation enables users, Automatic headline generation, headline generation enables, natural language processing, enables users</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Automatic headline generation enables users to comprehend ongoing news events
promptly and has recently become an important task in web mining and natural
language processing. With the growing need for news headline generation, we
argue that the hallucination issue, namely the generated headlines being not
supported by the original news stories, is a critical challenge for the
deployment of this feature in web-scale systems Meanwhile, due to the
infrequency of hallucination cases and the requirement of careful reading for
raters to reach the correct consensus, it is difficult to acquire a large
dataset for training a model to detect such hallucinations through human
curation. In this work, we present a new framework named ExHalder to address
this challenge for headline hallucination detection. ExHalder adapts the
knowledge from public natural language inference datasets into the news domain
and learns to generate natural language sentences to explain the hallucination
detection results. To evaluate the model performance, we carefully collect a
dataset with more than six thousand labeled <article, headline> pairs.
Extensive experiments on this dataset and another six public ones demonstrate
that ExHalder can identify hallucinated headlines accurately and justifies its
predictions with human-readable natural language explanations.</article,></p>
  </details>
</details>
<details>
  <summary>42. <b>标题：Level Generation Through Large Language Models</b></summary>
  <p><b>编号</b>：[343]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05817</p>
  <p><b>作者</b>：Graham Todd,  Sam Earle,  Muhammad Umair Nasir,  Michael Cerny Green,  Julian Togelius</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Large Language Models, Large Language, natural language, Language Models, powerful tools</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large Language Models (LLMs) are powerful tools, capable of leveraging their
training on natural language to write stories, generate code, and answer
questions. But can they generate functional video game levels? Game levels,
with their complex functional constraints and spatial relationships in more
than one dimension, are very different from the kinds of data an LLM typically
sees during training. Datasets of game levels are also hard to come by,
potentially taxing the abilities of these data-hungry models. We investigate
the use of LLMs to generate levels for the game Sokoban, finding that LLMs are
indeed capable of doing so, and that their performance scales dramatically with
dataset size. We also perform preliminary experiments on controlling LLM level
generators and discuss promising areas for future work.</p>
  </details>
</details>
<details>
  <summary>43. <b>标题：Improving Sign Recognition with Phonology</b></summary>
  <p><b>编号</b>：[364]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05759</p>
  <p><b>作者</b>：Lee Kezar,  Jesse Thomason,  Zed Sevcikova Sehyr</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：American Sign Language, American Sign, sign language understanding, isolated sign language, automatic sign language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We use insights from research on American Sign Language (ASL) phonology to
train models for isolated sign language recognition (ISLR), a step towards
automatic sign language understanding. Our key insight is to explicitly
recognize the role of phonology in sign production to achieve more accurate
ISLR than existing work which does not consider sign language phonology. We
train ISLR models that take in pose estimations of a signer producing a single
sign to predict not only the sign but additionally its phonological
characteristics, such as the handshape. These auxiliary predictions lead to a
nearly 9% absolute gain in sign recognition accuracy on the WLASL benchmark,
with consistent improvements in ISLR regardless of the underlying prediction
model architecture. This work has the potential to accelerate linguistic
research in the domain of signed languages and reduce communication barriers
between deaf and hearing people.</p>
  </details>
</details>
<details>
  <summary>44. <b>标题：A Reparameterized Discrete Diffusion Model for Text Generation</b></summary>
  <p><b>编号</b>：[376]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05737</p>
  <p><b>作者</b>：Lin Zheng,  Jianbo Yuan,  Lei Yu,  Lingpeng Kong</p>
  <p><b>备注</b>：27 pages, 4 figures</p>
  <p><b>关键词</b>：work studies discrete, natural language generation, studies discrete diffusion, discrete diffusion probabilistic, discrete diffusion</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This work studies discrete diffusion probabilistic models with applications
to natural language generation. We derive an alternative yet equivalent
formulation of the sampling from discrete diffusion processes and leverage this
insight to develop a family of reparameterized discrete diffusion models. The
derived generic framework is highly flexible, offers a fresh perspective of the
generation process in discrete diffusion models, and features more effective
training and decoding techniques. We conduct extensive experiments to evaluate
the text generation capability of our model, demonstrating significant
improvements over existing diffusion models.</p>
  </details>
</details>
<details>
  <summary>45. <b>标题：Divergence-Based Domain Transferability for Zero-Shot Classification</b></summary>
  <p><b>编号</b>：[378]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05735</p>
  <p><b>作者</b>：Alexander Pugantsov,  Richard McCreadie</p>
  <p><b>备注</b>：Accepted at EACL 2023</p>
  <p><b>关键词</b>：Transferring learned patterns, pretrained neural language, neural language models, significantly improve effectiveness, Transferring learned</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Transferring learned patterns from pretrained neural language models has been
shown to significantly improve effectiveness across a variety of language-based
tasks, meanwhile further tuning on intermediate tasks has been demonstrated to
provide additional performance benefits, provided the intermediate task is
sufficiently related to the target task. However, how to identify related tasks
is an open problem, and brute-force searching effective task combinations is
prohibitively expensive. Hence, the question arises, are we able to improve the
effectiveness and efficiency of tasks with no training examples through
selective fine-tuning? In this paper, we explore statistical measures that
approximate the divergence between domain representations as a means to
estimate whether tuning using one task pair will exhibit performance benefits
over tuning another. This estimation can then be used to reduce the number of
task pairs that need to be tested by eliminating pairs that are unlikely to
provide benefits. Through experimentation over 58 tasks and over 6,600 task
pair combinations, we demonstrate that statistical measures can distinguish
effective task pairs, and the resulting estimates can reduce end-to-end runtime
by up to 40%.</p>
  </details>
</details>
<details>
  <summary>46. <b>标题：A Brief Report on LawGPT 1.0: A Virtual Legal Assistant Based on GPT-3</b></summary>
  <p><b>编号</b>：[382]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05729</p>
  <p><b>作者</b>：Ha-Thanh Nguyen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：virtual legal assistant, legal assistant built, assistant built, legal, language model</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>LawGPT 1.0 is a virtual legal assistant built on the state-of-the-art
language model GPT-3, fine-tuned for the legal domain. The system is designed
to provide legal assistance to users in a conversational manner, helping them
with tasks such as answering legal questions, generating legal documents, and
providing legal advice. In this paper, we provide a brief overview of LawGPT
1.0, its architecture, and its performance on a set of legal benchmark tasks.
Please note that the detailed information about the model is protected by a
non-disclosure agreement (NDA) and cannot be disclosed in this report.</p>
  </details>
</details>
<details>
  <summary>47. <b>标题：Synthesizing Human Gaze Feedback for Improved NLP Performance</b></summary>
  <p><b>编号</b>：[388]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05721</p>
  <p><b>作者</b>：Varun Khurana,  Yaman Kumar Singla,  Nora Hollenstein,  Rajesh Kumar,  Balaji Krishnamurthy</p>
  <p><b>备注</b>：Accepted at European Chapter of the Association for Computational Linguistics (EACL)</p>
  <p><b>关键词</b>：natural language processing, NLP, Integrating human feedback, NLP tasks, language processing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Integrating human feedback in models can improve the performance of natural
language processing (NLP) models. Feedback can be either explicit (e.g. ranking
used in training language models) or implicit (e.g. using human cognitive
signals in the form of eyetracking). Prior eye tracking and NLP research reveal
that cognitive processes, such as human scanpaths, gleaned from human gaze
patterns aid in the understanding and performance of NLP models. However, the
collection of real eyetracking data for NLP tasks is challenging due to the
requirement of expensive and precise equipment coupled with privacy invasion
issues. To address this challenge, we propose ScanTextGAN, a novel model for
generating human scanpaths over text. We show that ScanTextGAN-generated
scanpaths can approximate meaningful cognitive signals in human gaze patterns.
We include synthetically generated scanpaths in four popular NLP tasks spanning
six different datasets as proof of concept and show that the models augmented
with generated scanpaths improve the performance of all downstream NLP tasks.</p>
  </details>
</details>
<details>
  <summary>48. <b>标题：Learning by Applying: A General Framework for Mathematical Reasoning via  Enhancing Explicit Knowledge Learning</b></summary>
  <p><b>编号</b>：[390]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05717</p>
  <p><b>作者</b>：Jiayu Liu,  Zhenya Huang,  Chengxiang Zhai,  Qi Liu</p>
  <p><b>备注</b>：Accepted by AAAI 2023</p>
  <p><b>关键词</b>：general artificial intelligence, knowledge, master mathematical logic, artificial intelligence, requires machines</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Mathematical reasoning is one of the crucial abilities of general artificial
intelligence, which requires machines to master mathematical logic and
knowledge from solving problems. However, existing approaches are not
transparent (thus not interpretable) in terms of what knowledge has been
learned and applied in the reasoning process. In this paper, we propose a
general Learning by Applying (LeAp) framework to enhance existing models
(backbones) in a principled way by explicit knowledge learning. In LeAp, we
perform knowledge learning in a novel problem-knowledge-expression paradigm,
with a Knowledge Encoder to acquire knowledge from problem data and a Knowledge
Decoder to apply knowledge for expression reasoning. The learned mathematical
knowledge, including word-word relations and word-operator relations, forms an
explicit knowledge graph, which bridges the knowledge "learning" and "applying"
organically. Moreover, for problem solving, we design a semantics-enhanced
module and a reasoning-enhanced module that apply knowledge to improve the
problem comprehension and symbol reasoning abilities of any backbone,
respectively. We theoretically prove the superiority of LeAp's autonomous
learning mechanism. Experiments on three real-world datasets show that LeAp
improves all backbones' performances, learns accurate knowledge, and achieves a
more interpretable reasoning process.</p>
  </details>
</details>
<details>
  <summary>49. <b>标题：Fair Enough: Standardizing Evaluation and Model Selection for Fairness  Research in NLP</b></summary>
  <p><b>编号</b>：[391]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05711</p>
  <p><b>作者</b>：Xudong Han,  Timothy Baldwin,  Trevor Cohn</p>
  <p><b>备注</b>：EACL 2023</p>
  <p><b>关键词</b>：Modern NLP systems, NLP systems exhibit, Modern NLP, NLP systems, model debiasing attempts</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Modern NLP systems exhibit a range of biases, which a growing literature on
model debiasing attempts to correct. However current progress is hampered by a
plurality of definitions of bias, means of quantification, and oftentimes vague
relation between debiasing algorithms and theoretical measures of bias. This
paper seeks to clarify the current situation and plot a course for meaningful
progress in fair learning, with two key contributions: (1) making clear
inter-relations among the current gamut of methods, and their relation to
fairness theory; and (2) addressing the practical problem of model selection,
which involves a trade-off between fairness and accuracy and has led to
systemic issues in fairness research. Putting them together, we make several
recommendations to help shape future work.</p>
  </details>
</details>
<details>
  <summary>50. <b>标题：MTTM: Metamorphic Testing for Textual Content Moderation Software</b></summary>
  <p><b>编号</b>：[394]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05706</p>
  <p><b>作者</b>：Wenxuan Wang,  Jen-tse Huang,  Weibin Wu,  Jianping Zhang,  Yizhan Huang,  Shuqing Li,  Pinjia He,  Michael Lyu</p>
  <p><b>备注</b>：Accepted by ICSE 2023</p>
  <p><b>关键词</b>：Twitter and Facebook, social media platforms, Facebook has revolutionized, revolutionized textual communication, content moderation software</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The exponential growth of social media platforms such as Twitter and Facebook
has revolutionized textual communication and textual content publication in
human society. However, they have been increasingly exploited to propagate
toxic content, such as hate speech, malicious advertisement, and pornography,
which can lead to highly negative impacts (e.g., harmful effects on teen mental
health). Researchers and practitioners have been enthusiastically developing
and extensively deploying textual content moderation software to address this
problem. However, we find that malicious users can evade moderation by changing
only a few words in the toxic content. Moreover, modern content moderation
software performance against malicious inputs remains underexplored. To this
end, we propose MTTM, a Metamorphic Testing framework for Textual content
Moderation software. Specifically, we conduct a pilot study on 2,000 text
messages collected from real users and summarize eleven metamorphic relations
across three perturbation levels: character, word, and sentence. MTTM employs
these metamorphic relations on toxic textual contents to generate test cases,
which are still toxic yet likely to evade moderation. In our evaluation, we
employ MTTM to test three commercial textual content moderation software and
two state-of-the-art moderation algorithms against three kinds of toxic
content. The results show that MTTM achieves up to 83.9%, 51%, and 82.5% error
finding rates (EFR) when testing commercial moderation software provided by
Google, Baidu, and Huawei, respectively, and it obtains up to 91.2% EFR when
testing the state-of-the-art algorithms from the academy. In addition, we
leverage the test cases generated by MTTM to retrain the model we explored,
which largely improves model robustness (0% to 5.9% EFR) while maintaining the
accuracy on the original test set.</p>
  </details>
</details>
<details>
  <summary>51. <b>标题：HateProof: Are Hateful Meme Detection Systems really Robust?</b></summary>
  <p><b>编号</b>：[395]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05703</p>
  <p><b>作者</b>：Piush Aggarwal,  Pranit Chawla,  Mithun Das,  Punyajoy Saha,  Binny Mathew,  Torsten Zesch,  Animesh Mukherjee</p>
  <p><b>备注</b>：Accepted at TheWebConf'2023 (WWW'2023)</p>
  <p><b>关键词</b>：Exploiting social media, Exploiting social, social media, media to spread, spread hate</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Exploiting social media to spread hate has tremendously increased over the
years. Lately, multi-modal hateful content such as memes has drawn relatively
more traction than uni-modal content. Moreover, the availability of implicit
content payloads makes them fairly challenging to be detected by existing
hateful meme detection systems. In this paper, we present a use case study to
analyze such systems' vulnerabilities against external adversarial attacks. We
find that even very simple perturbations in uni-modal and multi-modal settings
performed by humans with little knowledge about the model can make the existing
detection models highly vulnerable. Empirically, we find a noticeable
performance drop of as high as 10% in the macro-F1 score for certain attacks.
As a remedy, we attempt to boost the model's robustness using contrastive
learning as well as an adversarial training-based method - VILLA. Using an
ensemble of the above two approaches, in two of our high resolution datasets,
we are able to (re)gain back the performance to a large extent for certain
attacks. We believe that ours is a first step toward addressing this crucial
problem in an adversarial setting and would inspire more such investigations in
the future.</p>
  </details>
</details>
<details>
  <summary>52. <b>标题：Compositional Exemplars for In-context Learning</b></summary>
  <p><b>编号</b>：[397]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05698</p>
  <p><b>作者</b>：Jiacheng Ye,  Zhiyong Wu,  Jiangtao Feng,  Tao Yu,  Lingpeng Kong</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：shown impressive In-Context, Large pretrained language, Large pretrained, shown impressive, pretrained language models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large pretrained language models (LMs) have shown impressive In-Context
Learning (ICL) ability, where the model learns to do an unseen task via a
prompt consisting of input-output examples as the demonstration, without any
parameter updates. The performance of ICL is highly dominated by the quality of
the selected in-context examples. However, previous selection methods are
mostly based on simple heuristics, leading to sub-optimal performance. In this
work, we formulate in-context example selection as a subset selection problem.
We propose CEIL(Compositional Exemplars for In-context Learning), which is
instantiated by Determinantal Point Processes (DPPs) to model the interaction
between the given input and in-context examples, and optimized through a
carefully-designed contrastive learning objective to obtain preference from
LMs. We validate CEIL on 12 classification and generation datasets from 7
distinct NLP tasks, including sentiment analysis, paraphrase detection, natural
language inference, commonsense reasoning, open-domain question answering, code
generation, and semantic parsing. Extensive experiments demonstrate not only
the state-of-the-art performance but also the transferability and
compositionality of CEIL, shedding new light on effective and efficient
in-context learning. Our code is released at
this https URL.</p>
  </details>
</details>
<details>
  <summary>53. <b>标题：Counter-GAP: Counterfactual Bias Evaluation through Gendered Ambiguous  Pronouns</b></summary>
  <p><b>编号</b>：[406]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05674</p>
  <p><b>作者</b>：Zhongbin Xie,  Vid Kocijan,  Thomas Lukasiewicz,  Oana-Maria Camburu</p>
  <p><b>备注</b>：Long Paper at EACL 2023</p>
  <p><b>关键词</b>：detecting biased behavior, Bias-measuring datasets play, play a critical, critical role, role in detecting</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Bias-measuring datasets play a critical role in detecting biased behavior of
language models and in evaluating progress of bias mitigation methods. In this
work, we focus on evaluating gender bias through coreference resolution, where
previous datasets are either hand-crafted or fail to reliably measure an
explicitly defined bias. To overcome these shortcomings, we propose a novel
method to collect diverse, natural, and minimally distant text pairs via
counterfactual generation, and construct Counter-GAP, an annotated dataset
consisting of 4008 instances grouped into 1002 quadruples. We further identify
a bias cancellation problem in previous group-level metrics on Counter-GAP, and
propose to use the difference between inconsistency across genders and within
genders to measure bias at a quadruple level. Our results show that four
pre-trained language models are significantly more inconsistent across
different gender groups than within each group, and that a name-based
counterfactual data augmentation method is more effective to mitigate such bias
than an anonymization-based method.</p>
  </details>
</details>
<details>
  <summary>54. <b>标题：DocILE Benchmark for Document Information Localization and Extraction</b></summary>
  <p><b>编号</b>：[413]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05658</p>
  <p><b>作者</b>：Štěpán Šimsa,  Milan Šulc,  Michal Uřičář,  Yash Patel,  Ahmed Hamdi,  Matěj Kocián,  Matyáš Skalický,  Jiří Matas,  Antoine Doucet,  Mickaël Coustaty,  Dimosthenis Karatzas</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Key Information Localization, Line Item Recognition, Information Localization, Line Item, Key Information</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper introduces the DocILE benchmark with the largest dataset of
business documents for the tasks of Key Information Localization and Extraction
and Line Item Recognition. It contains 6.7k annotated business documents, 100k
synthetically generated documents, and nearly~1M unlabeled documents for
unsupervised pre-training. The dataset has been built with knowledge of domain-
and task-specific aspects, resulting in the following key features: (i)
annotations in 55 classes, which surpasses the granularity of previously
published key information extraction datasets by a large margin; (ii) Line Item
Recognition represents a highly practical information extraction task, where
key information has to be assigned to items in a table; (iii) documents come
from numerous layouts and the test set includes zero- and few-shot cases as
well as layouts commonly seen in the training set. The benchmark comes with
several baselines, including RoBERTa, LayoutLMv3 and DETR-based Table
Transformer. These baseline models were applied to both tasks of the DocILE
benchmark, with results shared in this paper, offering a quick starting point
for future work. The dataset and baselines are available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>55. <b>标题：Dialectograms: Machine Learning Differences between Discursive  Communities</b></summary>
  <p><b>编号</b>：[414]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05657</p>
  <p><b>作者</b>：Thyge Enggaard (1),  August Lohse (1),  Morten Axel Pedersen (1 and 2),  Sune Lehmann (1 and 3) ((1) Copenhagen Center for Social Data Science, University of Copenhagen, Denmark, (2) Department of Anthropology, University of Copenhagen, Denmark, (3) DTU Compute, Technical University of Denmark, Denmark)</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：usage between discursive, discursive communities, Word embeddings, Word, understand differences</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Word embeddings provide an unsupervised way to understand differences in word
usage between discursive communities. A number of recent papers have focused on
identifying words that are used differently by two or more communities. But
word embeddings are complex, high-dimensional spaces and a focus on identifying
differences only captures a fraction of their richness. Here, we take a step
towards leveraging the richness of the full embedding space, by using word
embeddings to map out how words are used differently. Specifically, we describe
the construction of dialectograms, an unsupervised way to visually explore the
characteristic ways in which each community use a focal word. Based on these
dialectograms, we provide a new measure of the degree to which words are used
differently that overcomes the tendency for existing measures to pick out low
frequent or polysemous words. We apply our methods to explore the discourses of
two US political subreddits and show how our methods identify stark affective
polarisation of politicians and political entities, differences in the
assessment of proper political action as well as disagreement about whether
certain issues require political intervention at all.</p>
  </details>
</details>
<details>
  <summary>56. <b>标题：Evaluating the Robustness of Discrete Prompts</b></summary>
  <p><b>编号</b>：[430]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05619</p>
  <p><b>作者</b>：Yoichi Ishibashi,  Danushka Bollegala,  Katsuhito Sudoh,  Satoshi Nakamura</p>
  <p><b>备注</b>：Accepted at EACL 2023</p>
  <p><b>关键词</b>：Pre-trained Language Models, fine-tuning Pre-trained Language, diverse NLP tasks, fine-tuning Pre-trained, Models for diverse</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Discrete prompts have been used for fine-tuning Pre-trained Language Models
for diverse NLP tasks. In particular, automatic methods that generate discrete
prompts from a small set of training instances have reported superior
performance. However, a closer look at the learnt prompts reveals that they
contain noisy and counter-intuitive lexical constructs that would not be
encountered in manually-written prompts. This raises an important yet
understudied question regarding the robustness of automatically learnt discrete
prompts when used in downstream tasks. To address this question, we conduct a
systematic study of the robustness of discrete prompts by applying carefully
designed perturbations into an application using AutoPrompt and then measure
their performance in two Natural Language Inference (NLI) datasets. Our
experimental results show that although the discrete prompt-based method
remains relatively robust against perturbations to NLI inputs, they are highly
sensitive to other types of perturbations such as shuffling and deletion of
prompt tokens. Moreover, they generalize poorly across different NLI datasets.
We hope our findings will inspire future work on robust discrete prompt
learning.</p>
  </details>
</details>
<details>
  <summary>57. <b>标题：Metaphor Detection with Effective Context Denoising</b></summary>
  <p><b>编号</b>：[435]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05611</p>
  <p><b>作者</b>：Shun Wang,  Yucheng Li,  Chenghua Lin,  Loïc Barrault,  Frank Guerin</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：target-oriented parse tree, parse tree structure, introduces a target-oriented, target-oriented parse, parse tree</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose a novel RoBERTa-based model, RoPPT, which introduces a
target-oriented parse tree structure in metaphor detection. Compared to
existing models, RoPPT focuses on semantically relevant information and
achieves the state-of-the-art on several main metaphor datasets. We also
compare our approach against several popular denoising and pruning methods,
demonstrating the effectiveness of our approach in context denoising. Our code
and dataset can be found at this https URL</p>
  </details>
</details>
<details>
  <summary>58. <b>标题：Emotion Detection From Social Media Posts</b></summary>
  <p><b>编号</b>：[436]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05610</p>
  <p><b>作者</b>：Md Mahbubur Rahman,  Shaila Shova</p>
  <p><b>备注</b>：Course Project</p>
  <p><b>关键词</b>：expressing personal views, personal views, political proposals, social media, Support Vector Machines</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Over the last few years, social media has evolved into a medium for
expressing personal views, emotions, and even business and political proposals,
recommendations, and advertisements. We address the topic of identifying
emotions from text data obtained from social media posts like Twitter in this
research. We have deployed different traditional machine learning techniques
such as Support Vector Machines (SVM), Naive Bayes, Decision Trees, and Random
Forest, as well as deep neural network models such as LSTM, CNN, GRU, BiLSTM,
BiGRU to classify these tweets into four emotion categories (Fear, Anger, Joy,
and Sadness). Furthermore, we have constructed a BiLSTM and BiGRU ensemble
model. The evaluation result shows that the deep neural network models(BiGRU,
to be specific) produce the most promising results compared to traditional
machine learning models, with an 87.53 % accuracy rate. The ensemble model
performs even better (87.66 %), albeit the difference is not significant. This
result will aid in the development of a decision-making tool that visualizes
emotional fluctuations.</p>
  </details>
</details>
<details>
  <summary>59. <b>标题：MatKB: Semantic Search for Polycrystalline Materials Synthesis  Procedures</b></summary>
  <p><b>编号</b>：[443]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05597</p>
  <p><b>作者</b>：Xianjun Yang,  Stephen Wilson,  Linda Petzold</p>
  <p><b>备注</b>：Work in Progress</p>
  <p><b>关键词</b>：Natural Language Processing, Language Processing, Natural Language, retrieval using Natural, extraction and retrieval</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we present a novel approach to knowledge extraction and
retrieval using Natural Language Processing (NLP) techniques for material
science. Our goal is to automatically mine structured knowledge from millions
of research articles in the field of polycrystalline materials and make it
easily accessible to the broader community. The proposed method leverages NLP
techniques such as entity recognition and document classification to extract
relevant information and build an extensive knowledge base, from a collection
of 9.5 Million publications. The resulting knowledge base is integrated into a
search engine, which enables users to search for information about specific
materials, properties, and experiments with greater precision than traditional
search engines like Google. We hope our results can enable material scientists
quickly locate desired experimental procedures, compare their differences, and
even inspire them to design new experiments. Our website will be available at
Github \footnote{this https URL} soon.</p>
  </details>
</details>
<details>
  <summary>60. <b>标题：Characterizing Attribution and Fluency Tradeoffs for Retrieval-Augmented  Large Language Models</b></summary>
  <p><b>编号</b>：[448]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05578</p>
  <p><b>作者</b>：Renat Aksitov,  Chung-Ching Chang,  David Reitter,  Siamak Shakeri,  Yunhsuan Sung</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：prevent semantic hallucinations, generative Large Language, recent progress, difficult to prevent, prevent semantic</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Despite recent progress, it has been difficult to prevent semantic
hallucinations in generative Large Language Models. One common solution to this
is augmenting LLMs with a retrieval system and making sure that the generated
output is attributable to the retrieved information. Given this new added
constraint, it is plausible to expect that the overall quality of the output
will be affected, for example, in terms of fluency. Can scaling language models
help?
Here we examine the relationship between fluency and attribution in LLMs
prompted with retrieved evidence in knowledge-heavy dialog settings. Our
experiments were implemented with a set of auto-metrics that are aligned with
human preferences. They were used to evaluate a large set of generations,
produced under varying parameters of LLMs and supplied context.
We show that larger models tend to do much better in both fluency and
attribution, and that (naively) using top-k retrieval versus top-1 retrieval
improves attribution but hurts fluency. We next propose a recipe that could
allow smaller models to both close the gap with larger models and preserve the
benefits of top-k retrieval while avoiding its drawbacks.</p>
  </details>
</details>
<details>
  <summary>61. <b>标题：NapSS: Paragraph-level Medical Text Simplification via Narrative  Prompting and Sentence-matching Summarization</b></summary>
  <p><b>编号</b>：[451]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05574</p>
  <p><b>作者</b>：Junru Lu,  Jiazheng Li,  Byron C. Wallace,  Yulan He,  Gabriele Pergola</p>
  <p><b>备注</b>：Findings of EACL 2023</p>
  <p><b>关键词</b>：Accessing medical literature, literature is difficult, difficult for laypeople, written for specialists, Accessing medical</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Accessing medical literature is difficult for laypeople as the content is
written for specialists and contains medical jargon. Automated text
simplification methods offer a potential means to address this issue. In this
work, we propose a summarize-then-simplify two-stage strategy, which we call
NapSS, identifying the relevant content to simplify while ensuring that the
original narrative flow is preserved. In this approach, we first generate
reference summaries via sentence matching between the original and the
simplified abstracts. These summaries are then used to train an extractive
summarizer, learning the most relevant content to be simplified. Then, to
ensure the narrative consistency of the simplified text, we synthesize
auxiliary narrative prompts combining key phrases derived from the syntactical
analyses of the original text. Our model achieves results significantly better
than the seq2seq baseline on an English medical corpus, yielding 3%~4% absolute
improvements in terms of lexical similarity, and providing a further 1.1%
improvement of SARI score when combined with the baseline. We also highlight
shortcomings of existing evaluation methods, and introduce new metrics that
take into account both lexical and high-level semantic similarity. A human
evaluation conducted on a random sample of the test set further establishes the
effectiveness of the proposed approach. Codes and models are released here:
this https URL.</p>
  </details>
</details>
<details>
  <summary>62. <b>标题：FairPy: A Toolkit for Evaluation of Social Biases and their Mitigation  in Large Language Models</b></summary>
  <p><b>编号</b>：[480]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05508</p>
  <p><b>作者</b>：Hrishikesh Viswanath,  Tianyi Zhang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：social groups based, Studies have shown, social groups, groups based, pretrained language models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Studies have shown that large pretrained language models exhibit biases
against social groups based on race, gender etc, which they inherit from the
datasets they are trained on. Various researchers have proposed mathematical
tools for quantifying and identifying these biases. There have been methods
proposed to mitigate such biases. In this paper, we present a comprehensive
quantitative evaluation of different kinds of biases such as race, gender,
ethnicity, age etc. exhibited by popular pretrained language models such as
BERT, GPT-2 etc. and also present a toolkit that provides plug-and-play
interfaces to connect mathematical tools to identify biases with large
pretrained language models such as BERT, GPT-2 etc. and also present users with
the opportunity to test custom models against these metrics. The toolkit also
allows users to debias existing and custom models using the debiasing
techniques proposed so far. The toolkit is available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>63. <b>标题：Long-Context Language Decision Transformers and Exponential Tilt for  Interactive Text Environments</b></summary>
  <p><b>编号</b>：[481]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05507</p>
  <p><b>作者</b>：Nicolas Gontier,  Pau Rodriguez,  Issam Laradji,  David Vazquez,  Christopher Pal</p>
  <p><b>备注</b>：12 pages, 5 figures, 3 tables</p>
  <p><b>关键词</b>：execute compositional actions, Text-based game environments, execute compositional, compositional actions, learn from sparse</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Text-based game environments are challenging because agents must deal with
long sequences of text, execute compositional actions using text and learn from
sparse rewards. We address these challenges by proposing Long-Context Language
Decision Transformers (LLDTs), a framework that is based on long transformer
language models and decision transformers (DTs). LLDTs extend DTs with 3
components: (1) exponential tilt to guide the agent towards high obtainable
goals, (2) novel goal conditioning methods yielding significantly better
results than the traditional return-to-go (sum of all future rewards), and (3)
a model of future observations. Our ablation results show that predicting
future observations improves agent performance. To the best of our knowledge,
LLDTs are the first to address offline RL with DTs on these challenging games.
Our experiments show that LLDTs achieve the highest scores among many different
types of agents on some of the most challenging Jericho games, such as
Enchanter.</p>
  </details>
</details>
<details>
  <summary>64. <b>标题：Distillation of encoder-decoder transformers for sequence labelling</b></summary>
  <p><b>编号</b>：[492]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05454</p>
  <p><b>作者</b>：Marco Farina,  Duccio Pappadopulo,  Anant Gupta,  Leslie Huang,  Ozan İrsoy,  Thamar Solorio</p>
  <p><b>备注</b>：Accepted to Findings of EACL 2023</p>
  <p><b>关键词</b>：develop bigger language, field of NLP, NLP is experiencing, bigger language models, Driven by encouraging</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Driven by encouraging results on a wide range of tasks, the field of NLP is
experiencing an accelerated race to develop bigger language models. This race
for bigger models has also underscored the need to continue the pursuit of
practical distillation approaches that can leverage the knowledge acquired by
these big models in a compute-efficient manner. Having this goal in mind, we
build on recent work to propose a hallucination-free framework for sequence
tagging that is especially suited for distillation. We show empirical results
of new state-of-the-art performance across multiple sequence labelling datasets
and validate the usefulness of this framework for distilling a large model in a
few-shot learning scenario.</p>
  </details>
</details>
<details>
  <summary>65. <b>标题：AV-data2vec: Self-supervised Learning of Audio-Visual Speech  Representations with Contextualized Target Representations</b></summary>
  <p><b>编号</b>：[510]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06419</p>
  <p><b>作者</b>：Jiachen Lian,  Alexei Baevski,  Wei-Ning Hsu,  Michael Auli</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：shown great potential, labeled data required, build good systems, Self-supervision has shown, good systems</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Self-supervision has shown great potential for audio-visual speech
recognition by vastly reducing the amount of labeled data required to build
good systems. However, existing methods are either not entirely end-to-end or
do not train joint representations of both modalities. In this paper, we
introduce AV-data2vec which addresses these challenges and builds audio-visual
representations based on predicting contextualized representations which has
been successful in the uni-modal case. The model uses a shared transformer
encoder for both audio and video and can combine both modalities to improve
speech recognition. Results on LRS3 show that AV-data2vec consistently
outperforms existing methods under most settings.</p>
  </details>
</details>
<details>
  <summary>66. <b>标题：Entanglement as a Method to Reduce Uncertainty</b></summary>
  <p><b>编号</b>：[540]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05898</p>
  <p><b>作者</b>：Diederik Aerts,  Jonito Aerts Argëlles,  Lester Beltran,  Suzette Geriente,  Sandro Sozzo</p>
  <p><b>备注</b>：15 pages</p>
  <p><b>关键词</b>：composite entity, composite bipartite entity, entropy, entity, reduces' the entropy</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In physics, entanglement 'reduces' the entropy of an entity, because the (von
Neumann) entropy of, e.g., a composite bipartite entity in a pure entangled
state is systematically lower than the entropy of the component sub-entities.
We show here that this 'genuinely non-classical reduction of entropy as a
result of composition' also holds whenever two concepts combine in human
cognition and, more generally, it is valid in human culture. We exploit these
results and make a 'new hypothesis' on the nature of entanglement, namely, the
production of entanglement in the preparation of a composite entity can be seen
as a 'dynamical process of collaboration between its sub-entities to reduce
uncertainty', because the composite entity is in a pure state while its
sub-entities are in a non-pure, or density, state, as a result of the
preparation. We identify within the nature of this entanglement a mechanism of
contextual updating and illustrate the mechanism in the example we analyze. Our
hypothesis naturally explains the 'non-classical nature' of some quantum
logical connectives, as due to Bell-type correlations.</p>
  </details>
</details>
<details>
  <summary>67. <b>标题：ASDF: A Differential Testing Framework for Automatic Speech Recognition  Systems</b></summary>
  <p><b>编号</b>：[560]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05582</p>
  <p><b>作者</b>：Daniel Hao Xian Yuen,  Andrew Yong Chen Pang,  Zhou Yang,  Chun Yong Chong,  Mei Kuan Lim,  David Lo</p>
  <p><b>备注</b>：Accpeted by ICST 2023 Tool Demo Track</p>
  <p><b>关键词</b>：Automated Speech Recognition, ASR systems, Speech Recognition Differential, witnessed wider adoption, ASR</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent years have witnessed wider adoption of Automated Speech Recognition
(ASR) techniques in various domains. Consequently, evaluating and enhancing the
quality of ASR systems is of great importance. This paper proposes ASDF, an
Automated Speech Recognition Differential Testing Framework for testing ASR
systems. ASDF extends an existing ASR testing tool, the CrossASR++, which
synthesizes test cases from a text corpus. However, CrossASR++ fails to make
use of the text corpus efficiently and provides limited information on how the
failed test cases can improve ASR systems. To address these limitations, our
tool incorporates two novel features: (1) a text transformation module to boost
the number of generated test cases and uncover more errors in ASR systems and
(2) a phonetic analysis module to identify on which phonemes the ASR system
tend to produce errors. ASDF generates more high-quality test cases by applying
various text transformation methods (e.g., change tense) to the texts in failed
test cases. By doing so, ASDF can utilize a small text corpus to generate a
large number of audio test cases, something which CrossASR++ is not capable of.
In addition, ASDF implements more metrics to evaluate the performance of ASR
systems from multiple perspectives. ASDF performs phonetic analysis on the
identified failed test cases to identify the phonemes that ASR systems tend to
transcribe incorrectly, providing useful information for developers to improve
ASR systems. The demonstration video of our tool is made online at
this https URL. The implementation is available at
this https URL.</p>
  </details>
</details>
<h1>机器学习</h1>
<details>
  <summary>1. <b>标题：3D-aware Blending with Generative NeRFs</b></summary>
  <p><b>编号</b>：[1]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06608</p>
  <p><b>作者</b>：Hyunsu Kim,  Gayoung Lee,  Yunjey Choi,  Jin-Hwa Kim,  Jun-Yan Zhu</p>
  <p><b>备注</b>：Project page: this https URL</p>
  <p><b>关键词</b>：multiple images seamlessly, combine multiple images, aims to combine, combine multiple, images seamlessly</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Image blending aims to combine multiple images seamlessly. It remains
challenging for existing 2D-based methods, especially when input images are
misaligned due to differences in 3D camera poses and object shapes. To tackle
these issues, we propose a 3D-aware blending method using generative Neural
Radiance Fields (NeRF), including two key components: 3D-aware alignment and
3D-aware blending. For 3D-aware alignment, we first estimate the camera pose of
the reference image with respect to generative NeRFs and then perform 3D local
alignment for each part. To further leverage 3D information of the generative
NeRF, we propose 3D-aware blending that directly blends images on the NeRF's
latent representation space, rather than raw pixel space. Collectively, our
method outperforms existing 2D baselines, as validated by extensive
quantitative and qualitative evaluations with FFHQ and AFHQ-Cat.</p>
  </details>
</details>
<details>
  <summary>2. <b>标题：Breaking the Curse of Multiagency: Provably Efficient Decentralized  Multi-Agent RL with Function Approximation</b></summary>
  <p><b>编号</b>：[3]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06606</p>
  <p><b>作者</b>：Yuanhao Wang,  Qinghua Liu,  Yu Bai,  Chi Jin</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Multi-Agent Reinforcement Learning, Multi-Agent Reinforcement, algorithms scale exponentially, Reinforcement Learning, Markov Games</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A unique challenge in Multi-Agent Reinforcement Learning (MARL) is the curse
of multiagency, where the description length of the game as well as the
complexity of many existing learning algorithms scale exponentially with the
number of agents. While recent works successfully address this challenge under
the model of tabular Markov Games, their mechanisms critically rely on the
number of states being finite and small, and do not extend to practical
scenarios with enormous state spaces where function approximation must be used
to approximate value functions or policies.
This paper presents the first line of MARL algorithms that provably resolve
the curse of multiagency under function approximation. We design a new
decentralized algorithm -- V-Learning with Policy Replay, which gives the first
polynomial sample complexity results for learning approximate Coarse Correlated
Equilibria (CCEs) of Markov Games under decentralized linear function
approximation. Our algorithm always outputs Markov CCEs, and achieves an
optimal rate of $\widetilde{\mathcal{O}}(\epsilon^{-2})$ for finding
$\epsilon$-optimal solutions. Also, when restricted to the tabular case, our
result improves over the current best decentralized result
$\widetilde{\mathcal{O}}(\epsilon^{-3})$ for finding Markov CCEs. We further
present an alternative algorithm -- Decentralized Optimistic Policy Mirror
Descent, which finds policy-class-restricted CCEs using a polynomial number of
samples. In exchange for learning a weaker version of CCEs, this algorithm
applies to a wider range of problems under generic function approximation, such
as linear quadratic games and MARL problems with low ''marginal'' Eluder
dimension.</p>
  </details>
</details>
<details>
  <summary>3. <b>标题：ALAN: Autonomously Exploring Robotic Agents in the Real World</b></summary>
  <p><b>编号</b>：[5]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06604</p>
  <p><b>作者</b>：Russell Mendonca,  Shikhar Bahl,  Deepak Pathak</p>
  <p><b>备注</b>：ICRA 2023. Website at this https URL</p>
  <p><b>关键词</b>：minimal human supervision, real world, data collected, minimal human, human supervision</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Robotic agents that operate autonomously in the real world need to
continuously explore their environment and learn from the data collected, with
minimal human supervision. While it is possible to build agents that can learn
in such a manner without supervision, current methods struggle to scale to the
real world. Thus, we propose ALAN, an autonomously exploring robotic agent,
that can perform tasks in the real world with little training and interaction
time. This is enabled by measuring environment change, which reflects object
movement and ignores changes in the robot position. We use this metric directly
as an environment-centric signal, and also maximize the uncertainty of
predicted environment change, which provides agent-centric exploration signal.
We evaluate our approach on two different real-world play kitchen settings,
enabling a robot to efficiently explore and discover manipulation skills, and
perform tasks specified via goal images. Website at
this https URL</p>
  </details>
</details>
<details>
  <summary>4. <b>标题：Multiple Instance Learning with Trainable Decision Tree Ensembles</b></summary>
  <p><b>编号</b>：[6]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06601</p>
  <p><b>作者</b>：Andrei V. Konstantinov,  Lev V. Utkin</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Tree Ensemble MIL, Multiple Instance Learning, Ensemble MIL, Soft Tree Ensemble, random forest based</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A new random forest based model for solving the Multiple Instance Learning
(MIL) problem under small tabular data, called Soft Tree Ensemble MIL
(STE-MIL), is proposed. A new type of soft decision trees is considered, which
is similar to the well-known soft oblique trees, but with a smaller number of
trainable parameters. In order to train the trees, it is proposed to convert
them into neural networks of a specific form, which approximate the tree
functions. It is also proposed to aggregate the instance and bag embeddings
(output vectors) by using the attention mechanism. The whole STE-MIL model,
including soft decision trees, neural networks, the attention mechanism and a
classifier, is trained in an end-to-end manner. Numerical experiments with
tabular datasets illustrate STE-MIL. The corresponding code implementing the
model is publicly available.</p>
  </details>
</details>
<details>
  <summary>5. <b>标题：Task-Specific Skill Localization in Fine-tuned Language Models</b></summary>
  <p><b>编号</b>：[7]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06600</p>
  <p><b>作者</b>：Abhishek Panigrahi,  Nikunj Saunshi,  Haoyu Zhao,  Sanjeev Arora</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：solve diverse NLP, diverse NLP tasks, diverse NLP, NLP tasks, including in few-shot</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Pre-trained language models can be fine-tuned to solve diverse NLP tasks,
including in few-shot settings. Thus fine-tuning allows the model to quickly
pick up task-specific ``skills,'' but there has been limited study of where
these newly-learnt skills reside inside the massive model. This paper
introduces the term skill localization for this problem and proposes a
solution. Given the downstream task and a model fine-tuned on that task, a
simple optimization is used to identify a very small subset of parameters
($\sim0.01$% of model parameters) responsible for ($>95$%) of the model's
performance, in the sense that grafting the fine-tuned values for just this
tiny subset onto the pre-trained model gives performance almost as well as the
fine-tuned model. While reminiscent of recent works on parameter-efficient
fine-tuning, the novel aspects here are that: (i) No further re-training is
needed on the subset (unlike, say, with lottery tickets). (ii) Notable
improvements are seen over vanilla fine-tuning with respect to calibration of
predictions in-distribution ($40$-$90$% error reduction) as well as the quality
of predictions out-of-distribution (OOD). In models trained on multiple tasks,
a stronger notion of skill localization is observed, where the sparse regions
corresponding to different tasks are almost disjoint, and their overlap (when
it happens) is a proxy for task similarity. Experiments suggest that
localization via grafting can assist certain forms of continual learning.</p>
  </details>
</details>
<details>
  <summary>6. <b>标题：FilFL: Accelerating Federated Learning via Client Filtering</b></summary>
  <p><b>编号</b>：[8]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06599</p>
  <p><b>作者</b>：Fares Fourati,  Salma Kharrat,  Vaneet Aggarwal,  Mohamed-Slim Alouini,  Marco Canini</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：emerging machine learning, machine learning paradigm, local data, emerging machine, paradigm that enables</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Federated learning is an emerging machine learning paradigm that enables
devices to train collaboratively without exchanging their local data. The
clients participating in the training process are a random subset selected from
the pool of clients. The above procedure is called client selection which is an
important area in federated learning as it highly impacts the convergence rate,
learning efficiency, and generalization. In this work, we introduce client
filtering in federated learning (FilFL), a new approach to optimize client
selection and training. FilFL first filters the active clients by choosing a
subset of them that maximizes a specific objective function; then, a client
selection method is applied to that subset. We provide a thorough analysis of
its convergence in a heterogeneous setting. Empirical results demonstrate
several benefits to our approach, including improved learning efficiency,
accelerated convergence, $2$-$3\times$ faster, and higher test accuracy, around
$2$-$10$ percentage points higher.</p>
  </details>
</details>
<details>
  <summary>7. <b>标题：When Can We Track Significant Preference Shifts in Dueling Bandits?</b></summary>
  <p><b>编号</b>：[10]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06595</p>
  <p><b>作者</b>：Joe Suk,  Arpit Agarwal</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：widely studied due, noisy pairwise preferences, armed dueling bandits, dueling bandits problem, recommendation systems</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The $K$-armed dueling bandits problem, where the feedback is in the form of
noisy pairwise preferences, has been widely studied due its applications in
information retrieval, recommendation systems, etc. Motivated by concerns that
user preferences/tastes can evolve over time, we consider the problem of
dueling bandits with distribution shifts. Specifically, we study the recent
notion of significant shifts (Suk and Kpotufe, 2022), and ask whether one can
design an adaptive algorithm for the dueling problem with
$O(\sqrt{K\tilde{L}T})$ dynamic regret, where $\tilde{L}$ is the (unknown)
number of significant shifts in preferences. We show that the answer to this
question depends on the properties of underlying preference distributions.
Firstly, we give an impossibility result that rules out any algorithm with
$O(\sqrt{K\tilde{L}T})$ dynamic regret under the well-studied Condorcet and SST
classes of preference distributions. Secondly, we show that $\text{SST} \cap
\text{STI}$ is the largest amongst popular classes of preference distributions
where it is possible to design such an algorithm. Overall, our results provides
an almost complete resolution of the above question for the hierarchy of
distribution classes.</p>
  </details>
</details>
<details>
  <summary>8. <b>标题：Geometric Clifford Algebra Networks</b></summary>
  <p><b>编号</b>：[11]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06594</p>
  <p><b>作者</b>：David Ruhe,  Jayesh K. Gupta,  Steven de Keninck,  Max Welling,  Johannes Brandstetter</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Clifford Algebra Networks, Geometric Clifford Algebra, Algebra Networks, propose Geometric Clifford, Clifford Algebra</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose Geometric Clifford Algebra Networks (GCANs) that are based on
symmetry group transformations using geometric (Clifford) algebras. GCANs are
particularly well-suited for representing and manipulating geometric
transformations, often found in dynamical systems. We first review the
quintessence of modern (plane-based) geometric algebra, which builds on
isometries encoded as elements of the $\mathrm{Pin}(p,q,r)$ group. We then
propose the concept of group action layers, which linearly combine object
transformations using pre-specified group actions. Together with a new
activation and normalization scheme, these layers serve as adjustable geometric
templates that can be refined via gradient descent. Theoretical advantages are
strongly reflected in the modeling of three-dimensional rigid body
transformations as well as large-scale fluid dynamics simulations, showing
significantly improved performance over traditional methods.</p>
  </details>
</details>
<details>
  <summary>9. <b>标题：Raising the Cost of Malicious AI-Powered Image Editing</b></summary>
  <p><b>编号</b>：[15]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06588</p>
  <p><b>作者</b>：Hadi Salman,  Alaa Khaddaj,  Guillaume Leclerc,  Andrew Ilyas,  Aleksander Madry</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：malicious image editing, image editing posed, large diffusion models, diffusion models, mitigating the risks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present an approach to mitigating the risks of malicious image editing
posed by large diffusion models. The key idea is to immunize images so as to
make them resistant to manipulation by these models. This immunization relies
on injection of imperceptible adversarial perturbations designed to disrupt the
operation of the targeted diffusion models, forcing them to generate
unrealistic images. We provide two methods for crafting such perturbations, and
then demonstrate their efficacy. Finally, we discuss a policy component
necessary to make our approach fully effective and practical -- one that
involves the organizations developing diffusion models, rather than individual
users, to implement (and support) the immunization process.</p>
  </details>
</details>
<details>
  <summary>10. <b>标题：Stitchable Neural Networks</b></summary>
  <p><b>编号</b>：[17]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06586</p>
  <p><b>作者</b>：Zizheng Pan,  Jianfei Cai,  Bohan Zhuang</p>
  <p><b>备注</b>：Project is available at this https URL</p>
  <p><b>关键词</b>：enormous powerful pretrained, pretrained model families, powerful pretrained model, deep learning, enormous powerful</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The public model zoo containing enormous powerful pretrained model families
(e.g., DeiT/Swin) has reached an unprecedented scope than ever, which
significantly contributes to the success of deep learning. As each model family
consists of pretrained models with diverse scales (e.g., DeiT-Ti/S/B), it
naturally arises a fundamental question of how to effectively assemble these
readily available models in a family for dynamic accuracy-efficiency trade-offs
at runtime. In this work, we present Stitchable Neural Networks (SN-Net), a
novel scalable and efficient framework for model deployment which cheaply
produces numerous networks with different complexity and performance
trade-offs. Specifically, SN-Net splits a family of pretrained neural networks,
which we call anchors, across the blocks/layers and then stitches them together
with simple stitching layers to map the activations from one anchor to another.
With only a few epochs of training, SN-Net effectively interpolates between the
performance of anchors with varying scales. At runtime, SN-Net can instantly
adapt to dynamic resource constraints by switching the stitching positions.
Furthermore, we provide a comprehensive study on what, how and where to stitch
as well as a simple strategy for effectively and efficiently training SN-Net.
Extensive experiments on ImageNet classification demonstrate that SN-Net can
obtain on-par or even better performance than many individually trained
networks while supporting diverse deployment scenarios. For example, by
stitching Swin Transformers, we challenge hundreds of models in Timm model zoo
with a single network. We believe this new elastic model framework can serve as
a strong baseline for further research in wider communities.</p>
  </details>
</details>
<details>
  <summary>11. <b>标题：GFlowNet-EM for learning compositional latent variable models</b></summary>
  <p><b>编号</b>：[21]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06576</p>
  <p><b>作者</b>：Edward Hu,  Nikolay Malkin,  Moksh Jain,  Katie Everett,  Alexandros Graikos,  Yoshua Bengio</p>
  <p><b>备注</b>：Code: this https URL</p>
  <p><b>关键词</b>：challenging setting due, combinatorially large number, Latent variable models, variable models, important but challenging</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Latent variable models (LVMs) with discrete compositional latents are an
important but challenging setting due to a combinatorially large number of
possible configurations of the latents. A key tradeoff in modeling the
posteriors over latents is between expressivity and tractable optimization. For
algorithms based on expectation-maximization (EM), the E-step is often
intractable without restrictive approximations to the posterior. We propose the
use of GFlowNets, algorithms for sampling from an unnormalized density by
learning a stochastic policy for sequential construction of samples, for this
intractable E-step. By training GFlowNets to sample from the posterior over
latents, we take advantage of their strengths as amortized variational
inference algorithms for complex distributions over discrete structures. Our
approach, GFlowNet-EM, enables the training of expressive LVMs with discrete
compositional latents, as shown by experiments on non-context-free grammar
induction and on images using discrete variational autoencoders (VAEs) without
conditional independence enforced in the encoder.</p>
  </details>
</details>
<details>
  <summary>12. <b>标题：EnergyShield: Provably-Safe Offloading of Neural Network Controllers for  Energy Efficiency</b></summary>
  <p><b>编号</b>：[22]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06572</p>
  <p><b>作者</b>：Mohanad Odema,  James Ferlez,  Goli Vaisi,  Yasser Shoukry,  Mohammad Abdullah Al Faruque</p>
  <p><b>备注</b>：Accepted to be published in the proceedings of the 14th ACM/IEEE International Conference on Cyber-Physical Systems (ICCPS 2023)</p>
  <p><b>关键词</b>：Neural Network, based Autonomous, demand of Neural, high energy demand, mitigate the high</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>To mitigate the high energy demand of Neural Network (NN) based Autonomous
Driving Systems (ADSs), we consider the problem of offloading NN controllers
from the ADS to nearby edge-computing infrastructure, but in such a way that
formal vehicle safety properties are guaranteed. In particular, we propose the
EnergyShield framework, which repurposes a controller ''shield'' as a low-power
runtime safety monitor for the ADS vehicle. Specifically, the shield in
EnergyShield provides not only safety interventions but also a formal,
state-based quantification of the tolerable edge response time before vehicle
safety is compromised. Using EnergyShield, an ADS can then save energy by
wirelessly offloading NN computations to edge computers, while still
maintaining a formal guarantee of safety until it receives a response
(on-vehicle hardware provides a just-in-time fail safe). To validate the
benefits of EnergyShield, we implemented and tested it in the Carla simulation
environment. Our results show that EnergyShield maintains safe vehicle
operation while providing significant energy savings compared to on-vehicle NN
evaluation: from 24% to 54% less energy across a range of wireless conditions
and edge delays.</p>
  </details>
</details>
<details>
  <summary>13. <b>标题：Inferring Player Location in Sports Matches: Multi-Agent Spatial  Imputation from Limited Observations</b></summary>
  <p><b>编号</b>：[23]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06569</p>
  <p><b>作者</b>：Gregory Everett,  Ryan J. Beal,  Tim Matthews,  Joseph Early,  Timothy J. Norman,  Sarvapali D. Ramchurn</p>
  <p><b>备注</b>：11 Pages (8 main, 1 references, 2 appendix), 8 figures (7 main, 1 appendix). Accepted at AAMAS 2023 Main Track</p>
  <p><b>关键词</b>：Multi-Agent Systems, Understanding agent behaviour, disaster response, MAS problems typically, Existing MAS problems</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Understanding agent behaviour in Multi-Agent Systems (MAS) is an important
problem in domains such as autonomous driving, disaster response, and sports
analytics. Existing MAS problems typically use uniform timesteps with
observations for all agents. In this work, we analyse the problem of agent
location imputation, specifically posed in environments with non-uniform
timesteps and limited agent observability (~95% missing values). Our approach
uses Long Short-Term Memory and Graph Neural Network components to learn
temporal and inter-agent patterns to predict the location of all agents at
every timestep. We apply this to the domain of football (soccer) by imputing
the location of all players in a game from sparse event data (e.g., shots and
passes). Our model estimates player locations to within ~6.9m; a ~62% reduction
in error from the best performing baseline. This approach facilitates
downstream analysis tasks such as player physical metrics, player coverage, and
team pitch control. Existing solutions to these tasks often require optical
tracking data, which is expensive to obtain and only available to elite clubs.
By imputing player locations from easy to obtain event data, we increase the
accessibility of downstream tasks.</p>
  </details>
</details>
<details>
  <summary>14. <b>标题：A Domain Decomposition-Based CNN-DNN Architecture for Model Parallel  Training Applied to Image Recognition Problems</b></summary>
  <p><b>编号</b>：[26]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06564</p>
  <p><b>作者</b>：Axel Klawonn,  Martin Lanser,  Janine Weber</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Deep neural networks, convolutional neural networks, brought significant advances, modern computer application, neural networks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep neural networks (DNNs) and, in particular, convolutional neural networks
(CNNs) have brought significant advances in a wide range of modern computer
application problems. However, the increasing availability of large amounts of
datasets as well as the increasing available computational power of modern
computers lead to a steady growth in the complexity and size of DNN and CNN
models, and thus, to longer training times. Hence, various methods and attempts
have been developed to accelerate and parallelize the training of complex
network architectures. In this work, a novel CNN-DNN architecture is proposed
that naturally supports a model parallel training strategy and that is loosely
inspired by two-level domain decomposition methods (DDM). First, local CNN
models, that is, subnetworks, are defined that operate on overlapping or
nonoverlapping parts of the input data, for example, sub-images. The
subnetworks can be trained completely in parallel. Each subnetwork outputs a
local decision for the given machine learning problem which is exclusively
based on the respective local input data. Subsequently, an additional DNN model
is trained which evaluates the local decisions of the local subnetworks and
generates a final, global decision. With respect to the analogy to DDM, the DNN
can be interpreted as a coarse problem and hence, the new approach can be
interpreted as a two-level domain decomposition. In this paper, solely image
classification problems using CNNs are considered. Experimental results for
different 2D image classification problems are provided as well as a face
recognition problem, and a classification problem for 3D computer tomography
(CT) scans. The results show that the proposed approach can significantly
accelerate the required training time compared to the global model and,
additionally, can also help to improve the accuracy of the underlying
classification problem.</p>
  </details>
</details>
<details>
  <summary>15. <b>标题：Transient Hemodynamics Prediction Using an Efficient Octree-Based Deep  Learning Model</b></summary>
  <p><b>编号</b>：[31]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06557</p>
  <p><b>作者</b>：Noah Maul (1,2),  Katharina Zinn (1,2),  Fabian Wagner (1),  Mareike Thies (1),  Maximilian Rohleder (1,2),  Laura Pfaff (1,2),  Markus Kowarschik (2),  Annette Birkhold (2),  Andreas Maier (1) ((1) Pattern Recognition Lab, FAU Erlangen-Nürnberg, Germany, (2) Siemens Healthcare GmbH, Forchheim, Germany)</p>
  <p><b>备注</b>：13 pages, 5 figures</p>
  <p><b>关键词</b>：Patient-specific hemodynamics assessment, CFD simulations, assessment could support, support diagnosis, diagnosis and treatment</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Patient-specific hemodynamics assessment could support diagnosis and
treatment of neurovascular diseases. Currently, conventional medical imaging
modalities are not able to accurately acquire high-resolution hemodynamic
information that would be required to assess complex neurovascular pathologies.
Therefore, computational fluid dynamics (CFD) simulations can be applied to
tomographic reconstructions to obtain clinically relevant information. However,
three-dimensional (3D) CFD simulations require enormous computational resources
and simulation-related expert knowledge that are usually not available in
clinical environments. Recently, deep-learning-based methods have been proposed
as CFD surrogates to improve computational efficiency. Nevertheless, the
prediction of high-resolution transient CFD simulations for complex vascular
geometries poses a challenge to conventional deep learning models. In this
work, we present an architecture that is tailored to predict high-resolution
(spatial and temporal) velocity fields for complex synthetic vascular
geometries. For this, an octree-based spatial discretization is combined with
an implicit neural function representation to efficiently handle the prediction
of the 3D velocity field for each time step. The presented method is evaluated
for the task of cerebral hemodynamics prediction before and during the
injection of contrast agent in the internal carotid artery (ICA). Compared to
CFD simulations, the velocity field can be estimated with a mean absolute error
of 0.024 m/s, whereas the run time reduces from several hours on a
high-performance cluster to a few seconds on a consumer graphical processing
unit.</p>
  </details>
</details>
<details>
  <summary>16. <b>标题：VA-DepthNet: A Variational Approach to Single Image Depth Prediction</b></summary>
  <p><b>编号</b>：[32]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06556</p>
  <p><b>作者</b>：Ce Liu,  Suryansh Kumar,  Shuhang Gu,  Radu Timofte,  Luc Van Gool</p>
  <p><b>备注</b>：Accepted for publication at ICLR 2023 (Spotlight Oral Presentation). Draft info: 21 pages, 13 tables, 8 figures</p>
  <p><b>关键词</b>：deep neural network, first-order variational constraints, scene space, neural network, variational constraints</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We introduce VA-DepthNet, a simple, effective, and accurate deep neural
network approach for the single-image depth prediction (SIDP) problem. The
proposed approach advocates using classical first-order variational constraints
for this problem. While state-of-the-art deep neural network methods for SIDP
learn the scene depth from images in a supervised setting, they often overlook
the invaluable invariances and priors in the rigid scene space, such as the
regularity of the scene. The paper's main contribution is to reveal the benefit
of classical and well-founded variational constraints in the neural network
design for the SIDP task. It is shown that imposing first-order variational
constraints in the scene space together with popular encoder-decoder-based
network architecture design provides excellent results for the supervised SIDP
task. The imposed first-order variational constraint makes the network aware of
the depth gradient in the scene space, i.e., regularity. The paper demonstrates
the usefulness of the proposed approach via extensive evaluation and ablation
analysis over several benchmark datasets, such as KITTI, NYU Depth V2, and SUN
RGB-D. The VA-DepthNet at test time shows considerable improvements in depth
prediction accuracy compared to the prior art and is accurate also at
high-frequency regions in the scene space. At the time of writing this paper,
our method -- labeled as VA-DepthNet, when tested on the KITTI depth-prediction
evaluation set benchmarks, shows state-of-the-art results, and is the
top-performing published approach.</p>
  </details>
</details>
<details>
  <summary>17. <b>标题：Automatic Noise Filtering with Dynamic Sparse Training in Deep  Reinforcement Learning</b></summary>
  <p><b>编号</b>：[35]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06548</p>
  <p><b>作者</b>：Bram Grooten,  Ghada Sokar,  Shibhansh Dohare,  Elena Mocanu,  Matthew E. Taylor,  Mykola Pechenizkiy,  Decebal Constantin Mocanu</p>
  <p><b>备注</b>：Accepted as full-paper at AAMAS 2023</p>
  <p><b>关键词</b>：performing different tasks, Tomorrow robots, reinforcement learning, Automatic Noise Filtering, information</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Tomorrow's robots will need to distinguish useful information from noise when
performing different tasks. A household robot for instance may continuously
receive a plethora of information about the home, but needs to focus on just a
small subset to successfully execute its current chore. Filtering distracting
inputs that contain irrelevant data has received little attention in the
reinforcement learning literature. To start resolving this, we formulate a
problem setting in reinforcement learning called the $\textit{extremely noisy
environment}$ (ENE), where up to $99\%$ of the input features are pure noise.
Agents need to detect which features provide task-relevant information about
the state of the environment. Consequently, we propose a new method termed
$\textit{Automatic Noise Filtering}$ (ANF), which uses the principles of
dynamic sparse training in synergy with various deep reinforcement learning
algorithms. The sparse input layer learns to focus its connectivity on
task-relevant features, such that ANF-SAC and ANF-TD3 outperform standard SAC
and TD3 by a large margin, while using up to $95\%$ fewer weights. Furthermore,
we devise a transfer learning setting for ENEs, by permuting all features of
the environment after 1M timesteps to simulate the fact that other information
sources can become relevant as the world evolves. Again, ANF surpasses the
baselines in final performance and sample complexity. Our code is available at
this https URL</p>
  </details>
</details>
<details>
  <summary>18. <b>标题：Probabilistic Circuits That Know What They Don't Know</b></summary>
  <p><b>编号</b>：[37]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06544</p>
  <p><b>作者</b>：Fabrizio Ventola,  Steven Braun,  Zhongjie Yu,  Martin Mundt,  Kristian Kersting</p>
  <p><b>备注</b>：22 pages, 8 figures, 1 table, 1 algorithm</p>
  <p><b>关键词</b>：Probabilistic circuits, OOD data, tractable probabilistic inference, data, OOD</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Probabilistic circuits (PCs) are models that allow exact and tractable
probabilistic inference. In contrast to neural networks, they are often assumed
to be well-calibrated and robust to out-of-distribution (OOD) data. In this
paper, we show that PCs are in fact not robust to OOD data, i.e., they don't
know what they don't know. We then show how this challenge can be overcome by
model uncertainty quantification. To this end, we propose tractable dropout
inference (TDI), an inference procedure to estimate uncertainty by deriving an
analytical solution to Monte Carlo dropout (MCD) through variance propagation.
Unlike MCD in neural networks, which comes at the cost of multiple network
evaluations, TDI provides tractable sampling-free uncertainty estimates in a
single forward pass. TDI improves the robustness of PCs to distribution shift
and OOD data, demonstrated through a series of experiments evaluating the
classification confidence and uncertainty estimates on real-world data.</p>
  </details>
</details>
<details>
  <summary>19. <b>标题：Imitation from Observation With Bootstrapped Contrastive Learning</b></summary>
  <p><b>编号</b>：[39]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06540</p>
  <p><b>作者</b>：Medric Sonwa,  Johanna Hansen,  Eugene Belilovsky</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Markov Decision Process, Decision Process, Markov Decision, training autonomous agents, observing expert demonstrations</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Imitation from observation (IfO) is a learning paradigm that consists of
training autonomous agents in a Markov Decision Process (MDP) by observing
expert demonstrations without access to its actions. These demonstrations could
be sequences of environment states or raw visual observations of the
environment. Recent work in IfO has focused on this problem in the case of
observations of low-dimensional environment states, however, access to these
highly-specific observations is unlikely in practice. In this paper, we adopt a
challenging, but more realistic problem formulation, learning control policies
that operate on a learned latent space with access only to visual
demonstrations of an expert completing a task. We present BootIfOL, an IfO
algorithm that aims to learn a reward function that takes an agent trajectory
and compares it to an expert, providing rewards based on similarity to agent
behavior and implicit goal. We consider this reward function to be a distance
metric between trajectories of agent behavior and learn it via contrastive
learning. The contrastive learning objective aims to closely represent expert
trajectories and to distance them from non-expert trajectories. The set of
non-expert trajectories used in contrastive learning is made progressively more
complex by bootstrapping from roll-outs of the agent learned through RL using
the current reward function. We evaluate our approach on a variety of control
tasks showing that we can train effective policies using a limited number of
demonstrative trajectories, greatly improving on prior approaches that consider
raw observations.</p>
  </details>
</details>
<details>
  <summary>20. <b>标题：Fourier-RNNs for Modelling Noisy Physics Data</b></summary>
  <p><b>编号</b>：[40]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06534</p>
  <p><b>作者</b>：Vignesh Gopakumar,  Stanislas Pamela,  Lorenzo Zanisi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：time-series prediction rely, Classical sequential models, Hidden states characterise, hidden state, Fourier Neural Operators</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Classical sequential models employed in time-series prediction rely on
learning the mappings from the past to the future instances by way of a hidden
state. The Hidden states characterise the historical information and encode the
required temporal dependencies. However, most existing sequential models
operate within finite-dimensional Euclidean spaces which offer limited
functionality when employed in modelling physics relevant data. Alternatively
recent work with neural operator learning within the Fourier space has shown
efficient strategies for parameterising Partial Differential Equations (PDE).
In this work, we propose a novel sequential model, built to handle Physics
relevant data by way of amalgamating the conventional RNN architecture with
that of the Fourier Neural Operators (FNO). The Fourier-RNN allows for learning
the mappings from the input to the output as well as to the hidden state within
the Fourier space associated with the temporal data. While the Fourier-RNN
performs identical to the FNO when handling PDE data, it outperforms the FNO
and the conventional RNN when deployed in modelling noisy, non-Markovian data.</p>
  </details>
</details>
<details>
  <summary>21. <b>标题：Unleashing the Power of Electrocardiograms: A novel approach for Patient  Identification in Healthcare Systems with ECG Signals</b></summary>
  <p><b>编号</b>：[42]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06529</p>
  <p><b>作者</b>：Caterina Fuster-Barceló,  Carmen Cámara,  Pedro Peris-López</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：utilising cardiac signals, past two decades, biometric modality, substantial body, body of research</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Over the course of the past two decades, a substantial body of research has
substantiated the viability of utilising cardiac signals as a biometric
modality. This paper presents a novel approach for patient identification in
healthcare systems using electrocardiogram signals. A convolutional neural
network is used to classify users based on images extracted from ECG signals.
The proposed identification system is evaluated in multiple databases,
providing a comprehensive understanding of its potential in real-world
scenarios. The impact of Cardiovascular Diseases on generic user identification
has been largely overlooked in previous studies. The presented method takes
into account the cardiovascular condition of the patients, ensuring that the
results obtained are not biased or limited. Furthermore, the results obtained
are consistent and reliable, with lower error rates and higher accuracy
metrics, as demonstrated through extensive experimentation. All these features
make the proposed method a valuable contribution to the field of patient
identification in healthcare systems, and make it a strong contender for
practical applications.</p>
  </details>
</details>
<details>
  <summary>22. <b>标题：Low-dimensional Data-based Surrogate Model of a Continuum-mechanical  Musculoskeletal System Based on Non-intrusive Model Order Reduction</b></summary>
  <p><b>编号</b>：[43]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06528</p>
  <p><b>作者</b>：Jonas Kneifl,  David Rosin,  Oliver Röhrle,  Jörg Fehr</p>
  <p><b>备注</b>：29 pages, 12 figures. Submitted to Archive of Applied Mechanics</p>
  <p><b>关键词</b>：recent decades, engineering prototyes, medical rehabilitation, supporting the design, design and development</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In recent decades, the main focus of computer modeling has been on supporting
the design and development of engineering prototyes, but it is now ubiquitous
in non-traditional areas such as medical rehabilitation. Conventional modeling
approaches like the finite element~(FE) method are computationally costly when
dealing with complex models, making them of limited use for purposes like
real-time simulation or deployment on low-end hardware, if the model at hand
cannot be simplified in a useful manner. Consequently, non-traditional
approaches such as surrogate modeling using data-driven model order reduction
are used to make complex high-fidelity models more widely available anyway.
They often involve a dimensionality reduction step, in which the
high-dimensional system state is transformed onto a low-dimensional subspace or
manifold, and a regression approach to capture the reduced system behavior.
While most publications focus on one dimensionality reduction, such as
principal component analysis~(PCA) (linear) or autoencoder (nonlinear), we
consider and compare PCA, kernel PCA, autoencoders, as well as variational
autoencoders for the approximation of a structural dynamical system. In detail,
we demonstrate the benefits of the surrogate modeling approach on a complex FE
model of a human upper-arm. We consider both the models deformation and the
internal stress as the two main quantities of interest in a FE context. By
doing so we are able to create a computationally low cost surrogate model which
captures the system behavior with high approximation quality and fast
evaluations.</p>
  </details>
</details>
<details>
  <summary>23. <b>标题：Transferable Deep Metric Learning for Clustering</b></summary>
  <p><b>编号</b>：[45]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06523</p>
  <p><b>作者</b>：Simo Alami.C,  Rim Kaddah,  Jesse Read</p>
  <p><b>备注</b>：Published in Symposium of Intelligent Data Analysis (IDA), 2023</p>
  <p><b>关键词</b>：usual distance metrics, high dimension spaces, difficult task, curse of dimensionality, high dimension</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Clustering in high dimension spaces is a difficult task; the usual distance
metrics may no longer be appropriate under the curse of dimensionality. Indeed,
the choice of the metric is crucial, and it is highly dependent on the dataset
characteristics. However a single metric could be used to correctly perform
clustering on multiple datasets of different domains. We propose to do so,
providing a framework for learning a transferable metric. We show that we can
learn a metric on a labelled dataset, then apply it to cluster a different
dataset, using an embedding space that characterises a desired clustering in
the generic sense. We learn and test such metrics on several datasets of
variable complexity (synthetic, MNIST, SVHN, omniglot) and achieve results
competitive with the state-of-the-art while using only a small number of
labelled training datasets and shallow networks.</p>
  </details>
</details>
<details>
  <summary>24. <b>标题：Near-Optimal Cryptographic Hardness of Agnostically Learning Halfspaces  and ReLU Regression under Gaussian Marginals</b></summary>
  <p><b>编号</b>：[48]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06512</p>
  <p><b>作者</b>：Ilias Diakonikolas,  Daniel M. Kane,  Lisheng Ren</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：agnostically learning halfspaces, Gaussian distribution, standard Gaussian, OPT, Gaussian</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We study the task of agnostically learning halfspaces under the Gaussian
distribution. Specifically, given labeled examples $(\mathbf{x},y)$ from an
unknown distribution on $\mathbb{R}^n \times \{ \pm 1\}$, whose marginal
distribution on $\mathbf{x}$ is the standard Gaussian and the labels $y$ can be
arbitrary, the goal is to output a hypothesis with 0-1 loss
$\mathrm{OPT}+\epsilon$, where $\mathrm{OPT}$ is the 0-1 loss of the
best-fitting halfspace. We prove a near-optimal computational hardness result
for this task, under the widely believed sub-exponential time hardness of the
Learning with Errors (LWE) problem. Prior hardness results are either
qualitatively suboptimal or apply to restricted families of algorithms. Our
techniques extend to yield near-optimal lower bounds for related problems,
including ReLU regression.</p>
  </details>
</details>
<details>
  <summary>25. <b>标题：Density-Softmax: Scalable and Distance-Aware Uncertainty Estimation  under Distribution Shifts</b></summary>
  <p><b>编号</b>：[53]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06495</p>
  <p><b>作者</b>：Ha Manh Bui,  Anqi Liu</p>
  <p><b>备注</b>：26 pages, 5 tables, 20 figures, under review version</p>
  <p><b>关键词</b>：learning models suffer, models suffer, suffer from significant, significant over-confidence, Prevalent deep learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Prevalent deep learning models suffer from significant over-confidence under
distribution shifts. In this paper, we propose Density-Softmax, a single
deterministic approach for uncertainty estimation via a combination of density
function with the softmax layer. By using the latent representation's
likelihood value, our approach produces more uncertain predictions when test
samples are distant from the training samples. Theoretically, we prove that
Density-Softmax is distance aware, which means its associated uncertainty
metrics are monotonic functions of distance metrics. This has been shown to be
a necessary condition for a neural network to produce high-quality uncertainty
estimation. Empirically, our method enjoys similar computational efficiency as
standard softmax on shifted CIFAR-10, CIFAR-100, and ImageNet dataset across
modern deep learning architectures. Notably, Density-Softmax uses 4 times fewer
parameters than Deep Ensembles and 6 times lower latency than Rank-1 Bayesian
Neural Network, while obtaining competitive predictive performance and lower
calibration errors under distribution shifts.</p>
  </details>
</details>
<details>
  <summary>26. <b>标题：A Study on ReLU and Softmax in Transformer</b></summary>
  <p><b>编号</b>：[67]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06461</p>
  <p><b>作者</b>：Kai Shen,  Junliang Guo,  Xu Tan,  Siliang Tang,  Rui Wang,  Jiang Bian</p>
  <p><b>备注</b>：work in progress</p>
  <p><b>关键词</b>：Softmax, previous works, FFN, Transformer architecture consists, FFN and key-value</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The Transformer architecture consists of self-attention and feed-forward
networks (FFNs) which can be viewed as key-value memories according to previous
works. However, FFN and traditional memory utilize different activation
functions (i.e., ReLU and Softmax respectively), which makes them not
equivalent. In this paper, we first rebuild the connections between FFN and
key-value memory by conducting extensive studies on ReLU and Softmax, and find
they are equivalent when adding an additional layer normalization module on
Softmax. In addition, ReLU outperforms Softmax on both FFN and key-value memory
when the number of value slots is large. We analyze the reasons and then
explore this good property of ReLU on the self-attention network where the
original Softmax activation performs poorly on long input sequences. We then
propose a full ReLU architecture named ReLUFormer which performs better than
the baseline Transformer on long sequence tasks such as document translation.
This paper sheds light on the following points: 1) Softmax and ReLU use
different normalization methods over elements which lead to different variances
of results, and ReLU is good at dealing with a large number of key-value slots;
2) FFN and key-value memory are equivalent, and thus the Transformer can be
viewed as a memory network where FFNs and self-attention networks are both
key-value memories.</p>
  </details>
</details>
<details>
  <summary>27. <b>标题：Ordered Memory Baselines</b></summary>
  <p><b>编号</b>：[73]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06451</p>
  <p><b>作者</b>：Daniel Borisov,  Matthew D'Iorio,  Jeffrey Hyacinthe</p>
  <p><b>备注</b>：9 pages, 6 figures. Submitted for the NeurIPS 2019 Reproducibility Challenge</p>
  <p><b>关键词</b>：Ordered Memory model, Natural language, Ordered Memory, Natural language semantics, natural language processing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Natural language semantics can be modeled using the phrase-structured model,
which can be represented using a tree-type architecture. As a result, recent
advances in natural language processing have been made utilising recursive
neural networks using memory models that allow them to infer tree-type
representations of the input sentence sequence. These new tree models have
allowed for improvements in sentiment analysis and semantic recognition. Here
we review the Ordered Memory model proposed by Shen et al. (2019) at the
NeurIPS 2019 conference, and try to either create baselines that can perform
better or create simpler models that can perform equally as well. We found that
the Ordered Memory model performs on par with the state-of-the-art models used
in tree-type modelling, and performs better than simplified baselines that
require fewer parameters.</p>
  </details>
</details>
<details>
  <summary>28. <b>标题：Efficient Graph Laplacian Estimation by a Proximal Newton Approach</b></summary>
  <p><b>编号</b>：[80]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06434</p>
  <p><b>作者</b>：Yakov Medvedovsky,  Eran Treister,  Tirza Routtenberg</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Markov Random Field, Laplacian-constrained Gaussian Markov, Gaussian Markov Random, Random Field, Laplacian-constrained Gaussian</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The Laplacian-constrained Gaussian Markov Random Field (LGMRF) is a common
multivariate statistical model for learning a weighted sparse dependency graph
from given data. This graph learning problem is formulated as a maximum
likelihood estimation (MLE) of the precision matrix, subject to Laplacian
structural constraints, with a sparsity-inducing penalty term. This paper aims
to solve this learning problem accurately and efficiently. First, since the
commonly-used $\ell_1$-norm penalty is less appropriate in this setting, we
employ the nonconvex minimax concave penalty (MCP), which promotes sparse
solutions with lower estimation bias. Second, as opposed to most existing
first-order methods for this problem, we base our method on the second-order
proximal Newton approach to obtain an efficient solver for large-scale
networks. This approach is considered the most efficient for the related
graphical LASSO problem and allows for several algorithmic features we exploit,
such as using Conjugate Gradients, preconditioning, and splitting to
active/free sets. Numerical experiments demonstrate the advantages of the
proposed method in terms of \emph{both} computational complexity and graph
learning accuracy compared to existing methods.</p>
  </details>
</details>
<details>
  <summary>29. <b>标题：Label-efficient Time Series Representation Learning: A Review</b></summary>
  <p><b>编号</b>：[81]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06433</p>
  <p><b>作者</b>：Emadeldeen Eldele,  Mohamed Ragab,  Zhenghua Chen,  Min Wu,  Chee-Keong Kwoh,  Xiaoli Li</p>
  <p><b>备注</b>：Under Review</p>
  <p><b>关键词</b>：deep learning models, time series data, applying deep learning, time series, time series labels</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The scarcity of labeled data is one of the main challenges of applying deep
learning models on time series data in the real world. Therefore, several
approaches, e.g., transfer learning, self-supervised learning, and
semi-supervised learning, have been recently developed to promote the learning
capability of deep learning models from the limited time series labels. In this
survey, for the first time, we provide a novel taxonomy to categorize existing
approaches that address the scarcity of labeled data problem in time series
data based on their reliance on external data sources. Moreover, we present a
review of the recent advances in each approach and conclude the limitations of
the current works and provide future directions that could yield better
progress in the field.</p>
  </details>
</details>
<details>
  <summary>30. <b>标题：Deep Graph-Level Orthogonal Hypersphere Compression for Anomaly  Detection</b></summary>
  <p><b>编号</b>：[84]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06430</p>
  <p><b>作者</b>：Yunhe Zhang,  Yan Sun,  Jinyu Cai,  Jicong Fan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Graph-level anomaly detection, anomaly detection aims, anomaly detection, unsupervised manner, aims to identify</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Graph-level anomaly detection aims to identify anomalous graphs from a
collection of graphs in an unsupervised manner. A common assumption of anomaly
detection is that a reasonable decision boundary has a hypersphere shape, but
may appear some non-conforming phenomena in high dimensions. Towards this end,
we firstly propose a novel deep graph-level anomaly detection model, which
learns the graph representation with maximum mutual information between
substructure and global structure features while exploring a hypersphere
anomaly decision boundary. The idea is to ensure the training data distribution
consistent with the decision hypersphere via an orthogonal projection layer.
Moreover, we further perform the bi-hypersphere compression to emphasize the
discrimination of anomalous graphs from normal graphs. Note that our method is
not confined to graph data and is applicable to anomaly detection of other data
such as images. The numerical and visualization results on benchmark datasets
demonstrate the effectiveness and superiority of our methods in comparison to
many baselines and state-of-the-arts.</p>
  </details>
</details>
<details>
  <summary>31. <b>标题：An Optical XNOR-Bitcount Based Accelerator for Efficient Inference of  Binary Neural Networks</b></summary>
  <p><b>编号</b>：[95]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06405</p>
  <p><b>作者</b>：Sairam Sri Vatsavai,  Venkata Sai Praneeth Karempudi,  Ishan Thakkar</p>
  <p><b>备注</b>：To Appear at IEEE ISQED 2023</p>
  <p><b>关键词</b>：Binary Neural Networks, Neural Networks, Convolutional Neural Networks, Binary Neural, preferred over full-precision</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Binary Neural Networks (BNNs) are increasingly preferred over full-precision
Convolutional Neural Networks(CNNs) to reduce the memory and computational
requirements of inference processing with minimal accuracy drop. BNNs convert
CNN model parameters to 1-bit precision, allowing inference of BNNs to be
processed with simple XNOR and bitcount operations. This makes BNNs amenable to
hardware acceleration. Several photonic integrated circuits (PICs) based BNN
accelerators have been proposed. Although these accelerators provide remarkably
higher throughput and energy efficiency than their electronic counterparts, the
utilized XNOR and bitcount circuits in these accelerators need to be further
enhanced to improve their area, energy efficiency, and throughput. This paper
aims to fulfill this need. For that, we invent a single-MRR-based optical XNOR
gate (OXG). Moreover, we present a novel design of bitcount circuit which we
refer to as Photo-Charge Accumulator (PCA). We employ multiple OXGs in a
cascaded manner using dense wavelength division multiplexing (DWDM) and connect
them to the PCA, to forge a novel Optical XNOR-Bitcount based Binary Neural
Network Accelerator (OXBNN). Our evaluation for the inference of four modern
BNNs indicates that OXBNN provides improvements of up to 62x and 7.6x in
frames-per-second (FPS) and FPS/W (energy efficiency), respectively, on
geometric mean over two PIC-based BNN accelerators from prior work. We
developed a transaction-level, event-driven python-based simulator for
evaluation of accelerators (this https URL).</p>
  </details>
</details>
<details>
  <summary>32. <b>标题：One Transformer for All Time Series: Representing and Training with  Time-Dependent Heterogeneous Tabular Data</b></summary>
  <p><b>编号</b>：[104]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06375</p>
  <p><b>作者</b>：Simone Luetto,  Fabrizio Garuti,  Enver Sangineto,  Lorenzo Forni,  Rita Cucchiara</p>
  <p><b>备注</b>：9 pages, 2 figures, 7 tables</p>
  <p><b>关键词</b>：applying Deep Learning, Deep Learning techniques, recent growing interest, Deep Learning, applying Deep</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>There is a recent growing interest in applying Deep Learning techniques to
tabular data, in order to replicate the success of other Artificial
Intelligence areas in this structured domain. Specifically interesting is the
case in which tabular data have a time dependence, such as, for instance
financial transactions. However, the heterogeneity of the tabular values, in
which categorical elements are mixed with numerical items, makes this
adaptation difficult. In this paper we propose a Transformer architecture to
represent heterogeneous time-dependent tabular data, in which numerical
features are represented using a set of frequency functions and the whole
network is uniformly trained with a unique loss function.</p>
  </details>
</details>
<details>
  <summary>33. <b>标题：DASH: Accelerating Distributed Private Machine Learning Inference with  Arithmetic Garbled Circuits</b></summary>
  <p><b>编号</b>：[110]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06361</p>
  <p><b>作者</b>：Jonas Sander,  Sebastian Berndt,  Ida Bruhns,  Thomas Eisenbarth</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Amazon Web Services, machine learning, machine learning solutions, Google Cloud Platform, parts of society</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The adoption of machine learning solutions is rapidly increasing across all
parts of society. Cloud service providers such as Amazon Web Services,
Microsoft Azure and the Google Cloud Platform aggressively expand their
Machine-Learning-as-a-Service offerings. While the widespread adoption of
machine learning has huge potential for both research and industry, the
large-scale evaluation of possibly sensitive data on untrusted platforms bears
inherent data security and privacy risks. Since computation time is expensive,
performance is a critical factor for machine learning. However, prevailing
security measures proposed in the past years come with a significant
performance overhead. We investigate the current state of protected distributed
machine learning systems, focusing on deep convolutional neural networks. The
most common and best-performing mixed MPC approaches are based on homomorphic
encryption, secret sharing, and garbled circuits. They commonly suffer from
communication overheads that grow linearly in the depth of the neural network.
We present Dash, a fast and distributed private machine learning inference
scheme. Dash is based purely on arithmetic garbled circuits. It requires only a
single communication round per inference step, regardless of the depth of the
neural network, and a very small constant communication volume. Dash thus
significantly reduces performance requirements and scales better than previous
approaches. In addition, we introduce the concept of LabelTensors. This allows
us to efficiently use GPUs while using garbled circuits, which further reduces
the runtime. Dash offers security against a malicious attacker and is up to 140
times faster than previous arithmetic garbling schemes.</p>
  </details>
</details>
<details>
  <summary>34. <b>标题：Fixing Overconfidence in Dynamic Neural Networks</b></summary>
  <p><b>编号</b>：[112]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06359</p>
  <p><b>作者</b>：Lassi Meronen,  Martin Trapp,  Andrea Pilzer,  Le Yang,  Arno Solin</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：deep learning models, modern deep learning, Dynamic neural networks, recent technique, technique that promises</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Dynamic neural networks are a recent technique that promises a remedy for the
increasing size of modern deep learning models by dynamically adapting their
computational cost to the difficulty of the input samples. In this way, the
model can adjust to a limited computational budget. However, the poor quality
of uncertainty estimates in deep learning models makes it difficult to
distinguish between hard and easy samples. To address this challenge, we
present a computationally efficient approach for post-hoc uncertainty
quantification in dynamic neural networks. We show that adequately quantifying
and accounting for both aleatoric and epistemic uncertainty through a
probabilistic treatment of the last layers improves the predictive performance
and aids decision-making when determining the computational budget. In the
experiments, we show improvements on CIFAR-100 and ImageNet in terms of
accuracy, capturing uncertainty, and calibration error.</p>
  </details>
</details>
<details>
  <summary>35. <b>标题：SubTuning: Efficient Finetuning for Multi-Task Learning</b></summary>
  <p><b>编号</b>：[117]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06354</p>
  <p><b>作者</b>：Gal Kaplun,  Andrey Gurevich,  Tal Swisa,  Mazor David,  Shai Shalev-Shwartz,  Eran Malach</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：training neural networks, resulting in fast, standard approach, fast convergence, convergence and improved</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Finetuning a pretrained model has become a standard approach for training
neural networks on novel tasks, resulting in fast convergence and improved
performance. In this work, we study an alternative finetuning method, where
instead of finetuning all the weights of the network, we only train a carefully
chosen subset of layers, keeping the rest of the weights frozen at their
initial (pretrained) values. We demonstrate that \emph{subset finetuning} (or
SubTuning) often achieves accuracy comparable to full finetuning of the model,
and even surpasses the performance of full finetuning when training data is
scarce. Therefore, SubTuning allows deploying new tasks at minimal
computational cost, while enjoying the benefits of finetuning the entire model.
This yields a simple and effective method for multi-task learning, where
different tasks do not interfere with one another, and yet share most of the
resources at inference time. We demonstrate the efficiency of SubTuning across
multiple tasks, using different network architectures and pretraining methods.</p>
  </details>
</details>
<details>
  <summary>36. <b>标题：The Possibility of Fairness: Revisiting the Impossibility Theorem in  Practice</b></summary>
  <p><b>编号</b>：[122]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06347</p>
  <p><b>作者</b>：Andrew Bell,  Lucius Bynum,  Nazarii Drushchak,  Tetiana Herasymova,  Lucas Rosenblatt,  Julia Stoyanovich</p>
  <p><b>备注</b>：14 pages, 3 figures, 1 table</p>
  <p><b>关键词</b>：perfectly accurate predictor, algorithmic fairness literature, fitting statistical models, special cases, considered foundational</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The ``impossibility theorem'' -- which is considered foundational in
algorithmic fairness literature -- asserts that there must be trade-offs
between common notions of fairness and performance when fitting statistical
models, except in two special cases: when the prevalence of the outcome being
predicted is equal across groups, or when a perfectly accurate predictor is
used. However, theory does not always translate to practice. In this work, we
challenge the implications of the impossibility theorem in practical settings.
First, we show analytically that, by slightly relaxing the impossibility
theorem (to accommodate a \textit{practitioner's} perspective of fairness), it
becomes possible to identify a large set of models that satisfy seemingly
incompatible fairness constraints. Second, we demonstrate the existence of
these models through extensive experiments on five real-world datasets. We
conclude by offering tools and guidance for practitioners to understand when --
and to what degree -- fairness along multiple criteria can be achieved. For
example, if one allows only a small margin-of-error between metrics, there
exists a large set of models simultaneously satisfying \emph{False Negative
Rate Parity}, \emph{False Positive Rate Parity}, and \emph{Positive Predictive
Value Parity}, even when there is a moderate prevalence difference between
groups. This work has an important implication for the community: achieving
fairness along multiple metrics for multiple groups (and their intersections)
is much more possible than was previously believed.</p>
  </details>
</details>
<details>
  <summary>37. <b>标题：Learning from Noisy Crowd Labels with Logics</b></summary>
  <p><b>编号</b>：[125]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06337</p>
  <p><b>作者</b>：Zhijun Chen,  Hailong Sun,  Haoqian He,  Pengpeng Chen</p>
  <p><b>备注</b>：12 pages, 7 figures, accepted by ICDE-2023. arXiv admin note: text overlap with arXiv:1603.06318 by other authors</p>
  <p><b>关键词</b>：noisy crowd labels, deep neural networks, crowd labels, noisy crowd, symbolic logic knowledge</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper explores the integration of symbolic logic knowledge into deep
neural networks for learning from noisy crowd labels. We introduce Logic-guided
Learning from Noisy Crowd Labels (Logic-LNCL), an EM-alike iterative logic
knowledge distillation framework that learns from both noisy labeled data and
logic rules of interest. Unlike traditional EM methods, our framework contains
a ``pseudo-E-step'' that distills from the logic rules a new type of learning
target, which is then used in the ``pseudo-M-step'' for training the
classifier. Extensive evaluations on two real-world datasets for text sentiment
classification and named entity recognition demonstrate that the proposed
framework improves the state-of-the-art and provides a new solution to learning
from noisy crowd labels.</p>
  </details>
</details>
<details>
  <summary>38. <b>标题：Online Arbitrary Shaped Clustering through Correlated Gaussian Functions</b></summary>
  <p><b>编号</b>：[126]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06335</p>
  <p><b>作者</b>：Ole Christian Eidheim</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：alternative learning methods, biologically plausible mechanism, convincing evidence, studies of alternative, alternative learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>There is no convincing evidence that backpropagation is a biologically
plausible mechanism, and further studies of alternative learning methods are
needed. A novel online clustering algorithm is presented that can produce
arbitrary shaped clusters from inputs in an unsupervised manner, and requires
no prior knowledge of the number of clusters in the input data. This is
achieved by finding correlated outputs from functions that capture commonly
occurring input patterns. The algorithm can be deemed more biologically
plausible than model optimization through backpropagation, although practical
applicability may require additional research. However, the method yields
satisfactory results on several toy datasets on a noteworthy range of
hyperparameters.</p>
  </details>
</details>
<details>
  <summary>39. <b>标题：Improving Recommendation Fairness via Data Augmentation</b></summary>
  <p><b>编号</b>：[127]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06333</p>
  <p><b>作者</b>：Lei Chen,  Le Wu,  Kun Zhang,  Richang Hong,  Defu Lian,  Zhiqiang Zhang,  Jun Zhou,  Meng Wang</p>
  <p><b>备注</b>：The paper is accepted by WWW 2023</p>
  <p><b>关键词</b>：Collaborative filtering based, facilitate decision making, learns users' preferences, users' historical behavior, historical behavior data</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Collaborative filtering based recommendation learns users' preferences from
all users' historical behavior data, and has been popular to facilitate
decision making. R Recently, the fairness issue of recommendation has become
more and more essential. A recommender system is considered unfair when it does
not perform equally well for different user groups according to users'
sensitive attributes~(e.g., gender, race). Plenty of methods have been proposed
to alleviate unfairness by optimizing a predefined fairness goal or changing
the distribution of unbalanced training data. However, they either suffered
from the specific fairness optimization metrics or relied on redesigning the
current recommendation architecture. In this paper, we study how to improve
recommendation fairness from the data augmentation perspective. The
recommendation model amplifies the inherent unfairness of imbalanced training
data. We augment imbalanced training data towards balanced data distribution to
improve fairness. The proposed framework is generally applicable to any
embedding-based recommendation, and does not need to pre-define a fairness
metric. Extensive experiments on two real-world datasets clearly demonstrate
the superiority of our proposed framework. We publish the source code at
this https URL.</p>
  </details>
</details>
<details>
  <summary>40. <b>标题：Homophily-oriented Heterogeneous Graph Rewiring</b></summary>
  <p><b>编号</b>：[136]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06299</p>
  <p><b>作者</b>：Jiayan Guo,  Lun Du,  Wendong Bi,  Qiang Fu,  Xiaojun Ma,  Xu Chen,  Shi Han,  Dongmei Zhang,  Yan Zhang</p>
  <p><b>备注</b>：Accepted by WWW 2023;</p>
  <p><b>关键词</b>：World Wide Web, Wide Web, World Wide, explosive growth, rapid development</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>With the rapid development of the World Wide Web (WWW), heterogeneous graphs
(HG) have explosive growth. Recently, heterogeneous graph neural network (HGNN)
has shown great potential in learning on HG. Current studies of HGNN mainly
focus on some HGs with strong homophily properties (nodes connected by
meta-path tend to have the same labels), while few discussions are made in
those that are less homophilous. Recently, there have been many works on
homogeneous graphs with heterophily. However, due to heterogeneity, it is
non-trivial to extend their approach to deal with HGs with heterophily. In this
work, based on empirical observations, we propose a meta-path-induced metric to
measure the homophily degree of a HG. We also find that current HGNNs may have
degenerated performance when handling HGs with less homophilous properties.
Thus it is essential to increase the generalization ability of HGNNs on
non-homophilous HGs. To this end, we propose HDHGR, a homophily-oriented deep
heterogeneous graph rewiring approach that modifies the HG structure to
increase the performance of HGNN. We theoretically verify HDHGR. In addition,
experiments on real-world HGs demonstrate the effectiveness of HDHGR, which
brings at most more than 10% relative gain.</p>
  </details>
</details>
<details>
  <summary>41. <b>标题：Do PAC-Learners Learn the Marginal Distribution?</b></summary>
  <p><b>编号</b>：[140]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06285</p>
  <p><b>作者</b>：Max Hopkins,  Daniel M. Kane,  Shachar Lovett,  Gaurav Mahajan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Vapnik and Chervonenkis', Valiant and Vapnik, mathscr, emph, Approximately Correct</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We study a foundational variant of Valiant and Vapnik and Chervonenkis'
Probably Approximately Correct (PAC)-Learning in which the adversary is
restricted to a known family of marginal distributions $\mathscr{P}$. In
particular, we study how the PAC-learnability of a triple $(\mathscr{P},X,H)$
relates to the learners ability to infer \emph{distributional} information
about the adversary's choice of $D \in \mathscr{P}$. To this end, we introduce
the `unsupervised' notion of \emph{TV-Learning}, which, given a class
$(\mathscr{P},X,H)$, asks the learner to approximate $D$ from unlabeled samples
with respect to a natural class-conditional total variation metric.
In the classical distribution-free setting, we show that TV-learning is
\emph{equivalent} to PAC-Learning: in other words, any learner must infer
near-maximal information about $D$. On the other hand, we show this
characterization breaks down for general $\mathscr{P}$, where PAC-Learning is
strictly sandwiched between two approximate variants we call `Strong' and
`Weak' TV-learning, roughly corresponding to unsupervised learners that
estimate most relevant distances in $D$ with respect to $H$, but differ in
whether the learner \emph{knows} the set of well-estimated events. Finally, we
observe that TV-learning is in fact equivalent to the classical notion of
\emph{uniform estimation}, and thereby give a strong refutation of the uniform
convergence paradigm in supervised learning.</p>
  </details>
</details>
<details>
  <summary>42. <b>标题：Causal Strategic Classification: A Tale of Two Shifts</b></summary>
  <p><b>编号</b>：[142]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06280</p>
  <p><b>作者</b>：Guy Horowitz,  Nir Rosenfeld</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：prone to act, act to achieve, strategically modifying, train predictive models, predictive</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>When users can benefit from certain predictive outcomes, they may be prone to
act to achieve those outcome, e.g., by strategically modifying their features.
The goal in strategic classification is therefore to train predictive models
that are robust to such behavior. However, the conventional framework assumes
that changing features does not change actual outcomes, which depicts users as
"gaming" the system. Here we remove this assumption, and study learning in a
causal strategic setting where true outcomes do change. Focusing on accuracy as
our primary objective, we show how strategic behavior and causal effects
underlie two complementing forms of distribution shift. We characterize these
shifts, and propose a learning algorithm that balances between these two forces
and over time, and permits end-to-end training. Experiments on synthetic and
semi-synthetic data demonstrate the utility of our approach.</p>
  </details>
</details>
<details>
  <summary>43. <b>标题：Sneaky Spikes: Uncovering Stealthy Backdoor Attacks in Spiking Neural  Networks with Neuromorphic Data</b></summary>
  <p><b>编号</b>：[143]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06279</p>
  <p><b>作者</b>：Gorka Abad,  Oguzhan Ersoy,  Stjepan Picek,  Aitor Urbieta</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：achieved excellent results, speech recognition, achieved excellent, excellent results, Deep neural networks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep neural networks (DNNs) have achieved excellent results in various tasks,
including image and speech recognition. However, optimizing the performance of
DNNs requires careful tuning of multiple hyperparameters and network parameters
via training. High-performance DNNs utilize a large number of parameters,
corresponding to high energy consumption during training. To address these
limitations, researchers have developed spiking neural networks (SNNs), which
are more energy-efficient and can process data in a biologically plausible
manner, making them well-suited for tasks involving sensory data processing,
i.e., neuromorphic data. Like DNNs, SNNs are vulnerable to various threats,
such as adversarial examples and backdoor attacks. Yet, the attacks and
countermeasures for SNNs have been almost fully unexplored.
This paper investigates the application of backdoor attacks in SNNs using
neuromorphic datasets and different triggers. More precisely, backdoor triggers
in neuromorphic data can change their position and color, allowing a larger
range of possibilities than common triggers in, e.g., the image domain. We
propose different attacks achieving up to 100\% attack success rate without
noticeable clean accuracy degradation. We also evaluate the stealthiness of the
attacks via the structural similarity metric, showing our most powerful attacks
being also stealthy. Finally, we adapt the state-of-the-art defenses from the
image domain, demonstrating they are not necessarily effective for neuromorphic
data resulting in inaccurate performance.</p>
  </details>
</details>
<details>
  <summary>44. <b>标题：Unlabeled Imperfect Demonstrations in Adversarial Imitation Learning</b></summary>
  <p><b>编号</b>：[147]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06271</p>
  <p><b>作者</b>：Yunke Wang,  Bo Du,  Chang Xu</p>
  <p><b>备注</b>：AAAI 2023</p>
  <p><b>关键词</b>：expert demonstrations, demonstrations, expert, imperfect expert demonstrations, Adversarial imitation learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Adversarial imitation learning has become a widely used imitation learning
framework. The discriminator is often trained by taking expert demonstrations
and policy trajectories as examples respectively from two categories (positive
vs. negative) and the policy is then expected to produce trajectories that are
indistinguishable from the expert demonstrations. But in the real world, the
collected expert demonstrations are more likely to be imperfect, where only an
unknown fraction of the demonstrations are optimal. Instead of treating
imperfect expert demonstrations as absolutely positive or negative, we
investigate unlabeled imperfect expert demonstrations as they are. A
positive-unlabeled adversarial imitation learning algorithm is developed to
dynamically sample expert demonstrations that can well match the trajectories
from the constantly optimized agent policy. The trajectories of an initial
agent policy could be closer to those non-optimal expert demonstrations, but
within the framework of adversarial imitation learning, agent policy will be
optimized to cheat the discriminator and produce trajectories that are similar
to those optimal expert demonstrations. Theoretical analysis shows that our
method learns from the imperfect demonstrations via a self-paced way.
Experimental results on MuJoCo and RoboSuite platforms demonstrate the
effectiveness of our method from different aspects.</p>
  </details>
</details>
<details>
  <summary>45. <b>标题：Continuous-time convolutions model of event sequences</b></summary>
  <p><b>编号</b>：[152]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06247</p>
  <p><b>作者</b>：Vladislav Zhuzhel,  Vsevolod Grabar,  Galina Boeva,  Artem Zabolotnyi,  Alexander Stepikin,  Vladimir Zholobov,  Maria Ivanova,  Mikhail Orlov,  Ivan Kireev,  Evgeny Burnaev,  Rodrigo Rivera-Castro,  Alexey Zaytsev</p>
  <p><b>备注</b>：9 pages, 3 figures</p>
  <p><b>关键词</b>：Massive samples, sequences data occur, event sequences, event, data occur</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Massive samples of event sequences data occur in various domains, including
e-commerce, healthcare, and finance. There are two main challenges regarding
inference of such data: computational and methodological. The amount of
available data and the length of event sequences per client are typically
large, thus it requires long-term modelling. Moreover, this data is often
sparse and non-uniform, making classic approaches for time series processing
inapplicable. Existing solutions include recurrent and transformer
architectures in such cases. To allow continuous time, the authors introduce
specific parametric intensity functions defined at each moment on top of
existing models. Due to the parametric nature, these intensities represent only
a limited class of event sequences.
We propose the COTIC method based on a continuous convolution neural network
suitable for non-uniform occurrence of events in time. In COTIC, dilations and
multi-layer architecture efficiently handle dependencies between events.
Furthermore, the model provides general intensity dynamics in continuous time -
including self-excitement encountered in practice.
The COTIC model outperforms existing approaches on majority of the considered
datasets, producing embeddings for an event sequence that can be used to solve
downstream tasks - e.g. predicting next event type and return time. The code of
the proposed method can be found in the GitHub repository
(this https URL).</p>
  </details>
</details>
<details>
  <summary>46. <b>标题：Calibrating a Deep Neural Network with Its Predecessors</b></summary>
  <p><b>编号</b>：[154]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06245</p>
  <p><b>作者</b>：Linwei Tao,  Minjing Dong,  Daochang Liu,  Changming Sun,  Chang Xu</p>
  <p><b>备注</b>：8 pages</p>
  <p><b>关键词</b>：output probability distribution, output probability, essential for safety-critical, safety-critical applications, process to calibrate</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Confidence calibration - the process to calibrate the output probability
distribution of neural networks - is essential for safety-critical applications
of such networks. Recent works verify the link between mis-calibration and
overfitting. However, early stopping, as a well-known technique to mitigate
overfitting, fails to calibrate networks. In this work, we study the limitions
of early stopping and comprehensively analyze the overfitting problem of a
network considering each individual block. We then propose a novel
regularization method, predecessor combination search (PCS), to improve
calibration by searching a combination of best-fitting block predecessors,
where block predecessors are the corresponding network blocks with weight
parameters from earlier training stages. PCS achieves the state-of-the-art
calibration performance on multiple datasets and architectures. In addition,
PCS improves model robustness under dataset distribution shift.</p>
  </details>
</details>
<details>
  <summary>47. <b>标题：An Order-Invariant and Interpretable Hierarchical Dilated Convolution  Neural Network for Chemical Fault Detection and Diagnosis</b></summary>
  <p><b>编号</b>：[156]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06243</p>
  <p><b>作者</b>：Mengxuan Li,  Peng Peng,  Min Wang,  Hongwei Wang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：reducing maintenance costs, chemical fault detection, detection and diagnosis, CNN, Fault detection</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Fault detection and diagnosis is significant for reducing maintenance costs
and improving health and safety in chemical processes. Convolution neural
network (CNN) is a popular deep learning algorithm with many successful
applications in chemical fault detection and diagnosis tasks. However,
convolution layers in CNN are very sensitive to the order of features, which
can lead to instability in the processing of tabular data. Optimal order of
features result in better performance of CNN models but it is expensive to seek
such optimal order. In addition, because of the encapsulation mechanism of
feature extraction, most CNN models are opaque and have poor interpretability,
thus failing to identify root-cause features without human supervision. These
difficulties inevitably limit the performance and credibility of CNN methods.
In this paper, we propose an order-invariant and interpretable hierarchical
dilated convolution neural network (HDLCNN), which is composed by feature
clustering, dilated convolution and the shapley additive explanations (SHAP)
method. The novelty of HDLCNN lies in its capability of processing tabular data
with features of arbitrary order without seeking the optimal order, due to the
ability to agglomerate correlated features of feature clustering and the large
receptive field of dilated convolution. Then, the proposed method provides
interpretability by including the SHAP values to quantify feature contribution.
Therefore, the root-cause features can be identified as the features with the
highest contribution. Computational experiments are conducted on the Tennessee
Eastman chemical process benchmark dataset. Compared with the other methods,
the proposed HDLCNN-SHAP method achieves better performance on processing
tabular data with features of arbitrary order, detecting faults, and
identifying the root-cause features.</p>
  </details>
</details>
<details>
  <summary>48. <b>标题：A Lifetime Extended Energy Management Strategy for Fuel Cell Hybrid  Electric Vehicles via Self-Learning Fuzzy Reinforcement Learning</b></summary>
  <p><b>编号</b>：[161]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06236</p>
  <p><b>作者</b>：Liang Guo (PECASE, AMU),  Zhongliang Li (FEMTO-ST, UTBM),  Rachid Outbib (PECASE, AMU)</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：fuel cells system, fuel cell hybrid, cell hybrid electric, hybrid electric vehicles, fuel cells</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Modeling difficulty, time-varying model, and uncertain external inputs are
the main challenges for energy management of fuel cell hybrid electric
vehicles. In the paper, a fuzzy reinforcement learning-based energy management
strategy for fuel cell hybrid electric vehicles is proposed to reduce fuel
consumption, maintain the batteries' long-term operation, and extend the
lifetime of the fuel cells system. Fuzzy Q-learning is a model-free
reinforcement learning that can learn itself by interacting with the
environment, so there is no need for modeling the fuel cells system. In
addition, frequent startup of the fuel cells will reduce the remaining useful
life of the fuel cells system. The proposed method suppresses frequent fuel
cells startup by considering the penalty for the times of fuel cell startups in
the reward of reinforcement learning. Moreover, applying fuzzy logic to
approximate the value function in Q-Learning can solve continuous state and
action space problems. Finally, a python-based training and testing platform
verify the effectiveness and self-learning improvement of the proposed method
under conditions of initial state change, model change and driving condition
change.</p>
  </details>
</details>
<details>
  <summary>49. <b>标题：A Simple Zero-shot Prompt Weighting Technique to Improve Prompt  Ensembling in Text-Image Models</b></summary>
  <p><b>编号</b>：[162]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06235</p>
  <p><b>作者</b>：James Urquhart Allingham,  Jie Ren,  Michael W Dusenberry,  Jeremiah Zhe Liu,  Xiuye Gu,  Yin Cui,  Dustin Tran,  Balaji Lakshminarayanan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：trained text-image models, Contrastively trained text-image, classifying previously unseen, previously unseen images, Contrastively trained</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Contrastively trained text-image models have the remarkable ability to
perform zero-shot classification, that is, classifying previously unseen images
into categories that the model has never been explicitly trained to identify.
However, these zero-shot classifiers need prompt engineering to achieve high
accuracy. Prompt engineering typically requires hand-crafting a set of prompts
for individual downstream tasks. In this work, we aim to automate this prompt
engineering and improve zero-shot accuracy through prompt ensembling. In
particular, we ask "Given a large pool of prompts, can we automatically score
the prompts and ensemble those that are most suitable for a particular
downstream dataset, without needing access to labeled validation data?". We
demonstrate that this is possible. In doing so, we identify several pathologies
in a naive prompt scoring method where the score can be easily overconfident
due to biases in pre-training and test data, and we propose a novel prompt
scoring method that corrects for the biases. Using our proposed scoring method
to create a weighted average prompt ensemble, our method outperforms equal
average ensemble, as well as hand-crafted prompts, on ImageNet, 4 of its
variants, and 11 fine-grained classification benchmarks, all while being fully
automatic, optimization-free, and not requiring access to labeled validation
data.</p>
  </details>
</details>
<details>
  <summary>50. <b>标题：Understanding Multimodal Contrastive Learning and Incorporating Unpaired  Data</b></summary>
  <p><b>编号</b>：[164]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06232</p>
  <p><b>作者</b>：Ryumei Nakada,  Halil Ibrahim Gulluk,  Zhun Deng,  Wenlong Ji,  James Zou,  Linjun Zhang</p>
  <p><b>备注</b>：43 pages, 3 figures, accepted by AISTATS 2023</p>
  <p><b>关键词</b>：Language-supervised vision models, recently attracted great, attracted great attention, Language-supervised vision, computer vision</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Language-supervised vision models have recently attracted great attention in
computer vision. A common approach to build such models is to use contrastive
learning on paired data across the two modalities, as exemplified by
Contrastive Language-Image Pre-Training (CLIP). In this paper, under linear
representation settings, (i) we initiate the investigation of a general class
of nonlinear loss functions for multimodal contrastive learning (MMCL)
including CLIP loss and show its connection to singular value decomposition
(SVD). Namely, we show that each step of loss minimization by gradient descent
can be seen as performing SVD on a contrastive cross-covariance matrix. Based
on this insight, (ii) we analyze the performance of MMCL. We quantitatively
show that the feature learning ability of MMCL can be better than that of
unimodal contrastive learning applied to each modality even under the presence
of wrongly matched pairs. This characterizes the robustness of MMCL to noisy
data. Furthermore, when we have access to additional unpaired data, (iii) we
propose a new MMCL loss that incorporates additional unpaired datasets. We show
that the algorithm can detect the ground-truth pairs and improve performance by
fully exploiting unpaired datasets. The performance of the proposed algorithm
was verified by numerical experiments.</p>
  </details>
</details>
<details>
  <summary>51. <b>标题：Link Prediction with Attention Applied on Multiple Knowledge Graph  Embedding Models</b></summary>
  <p><b>编号</b>：[165]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06229</p>
  <p><b>作者</b>：Cosimo Gregucci,  Mojtaba Nayyeri,  Daniel Hernández,  Steffen Staab</p>
  <p><b>备注</b>：ACM Web Conference 2023</p>
  <p><b>关键词</b>：Predicting missing links, Predicting missing, fundamental task, task to deal, incompleteness of data</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Predicting missing links between entities in a knowledge graph is a
fundamental task to deal with the incompleteness of data on the Web. Knowledge
graph embeddings map nodes into a vector space to predict new links, scoring
them according to geometric criteria. Relations in the graph may follow
patterns that can be learned, e.g., some relations might be symmetric and
others might be hierarchical. However, the learning capability of different
embedding models varies for each pattern and, so far, no single model can learn
all patterns equally well. In this paper, we combine the query representations
from several models in a unified one to incorporate patterns that are
independently captured by each model. Our combination uses attention to select
the most suitable model to answer each query. The models are also mapped onto a
non-Euclidean manifold, the Poincaré ball, to capture structural patterns,
such as hierarchies, besides relational patterns, such as symmetry. We prove
that our combination provides a higher expressiveness and inference power than
each model on its own. As a result, the combined model can learn relational and
structural patterns. We conduct extensive experimental analysis with various
link prediction benchmarks showing that the combined model outperforms
individual models, including state-of-the-art approaches.</p>
  </details>
</details>
<details>
  <summary>52. <b>标题：Unsupervised Detection of Behavioural Drifts with Dynamic Clustering and  Trajectory Analysis</b></summary>
  <p><b>编号</b>：[166]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06228</p>
  <p><b>作者</b>：Bardh Prenkaj,  Paola Velardi</p>
  <p><b>备注</b>：18 pages, 12 pages of main material, 6 pages of appendices, 4 tables, 11 figures, 2 algorithm pseudocodes</p>
  <p><b>关键词</b>：e-Health applications, past decades, monitoring of human, active area, area of research</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Real-time monitoring of human behaviours, especially in e-Health
applications, has been an active area of research in the past decades. On top
of IoT-based sensing environments, anomaly detection algorithms have been
proposed for the early detection of abnormalities. Gradual change procedures,
commonly referred to as drift anomalies, have received much less attention in
the literature because they represent a much more challenging scenario than
sudden temporary changes (point anomalies). In this paper, we propose, for the
first time, a fully unsupervised real-time drift detection algorithm named
DynAmo, which can identify drift periods as they are happening. DynAmo
comprises a dynamic clustering component to capture the overall trends of
monitored behaviours and a trajectory generation component, which extracts
features from the densest cluster centroids. Finally, we apply an ensemble of
divergence tests on sliding reference and detection windows to detect drift
periods in the behavioural sequence.</p>
  </details>
</details>
<details>
  <summary>53. <b>标题：Variational Mixture of HyperGenerators for Learning Distributions Over  Functions</b></summary>
  <p><b>编号</b>：[168]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06223</p>
  <p><b>作者</b>：Batuhan Koyuncu,  Pablo Sanchez-Martin,  Ignacio Peis,  Pablo M. Olmos,  Isabel Valera</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：implicit neural representations, Recent approaches build, neural representations, build on implicit, implicit neural</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent approaches build on implicit neural representations (INRs) to propose
generative models over function spaces. However, they are computationally
intensive when dealing with inference tasks, such as missing data imputation,
or directly cannot tackle them. In this work, we propose a novel deep
generative model, named VAMoH. VAMoH combines the capabilities of modeling
continuous functions using INRs and the inference capabilities of Variational
Autoencoders (VAEs). In addition, VAMoH relies on a normalizing flow to define
the prior, and a mixture of hypernetworks to parametrize the data
log-likelihood. This gives VAMoH a high expressive capability and
interpretability. Through experiments on a diverse range of data types, such as
images, voxels, and climate data, we show that VAMoH can effectively learn rich
distributions over continuous functions. Furthermore, it can perform
inference-related tasks, such as conditional super-resolution generation and
in-painting, as well or better than previous approaches, while being less
computationally demanding.</p>
  </details>
</details>
<details>
  <summary>54. <b>标题：A Unified View of Long-Sequence Models towards Million-Scale  Dependencies</b></summary>
  <p><b>编号</b>：[169]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06218</p>
  <p><b>作者</b>：Hongyu Hè,  Marko Kabic</p>
  <p><b>备注</b>：20 pages, 7 figures</p>
  <p><b>关键词</b>：image classification, audio processing, fast training, training and superior, NLP</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Ever since their conception, Transformers have taken over traditional
sequence models in many tasks, such as NLP, image classification, and
video/audio processing, for their fast training and superior performance. Much
of these merits result from positional encoding and multi-head attention.
However, Transformers fall short in learning long-range dependencies mainly due
to the quadratic complexity scaled with context length, in terms of both time
and space. Consequently, over the past five years, a myriad of methods has been
proposed to make Transformers more efficient. In this work, we first take a
step back, study and compare existing solutions to long-sequence modeling in
terms of their pure mathematical formulation. Specifically, we summarize them
using a unified template, given their shared nature of token mixing. Through
benchmarks, we then demonstrate that long context length does yield better
performance, albeit application-dependent, and traditional Transformer models
fall short in taking advantage of long-range dependencies. Next, inspired by
emerging sparse models of huge capacity, we propose a machine learning system
for handling million-scale dependencies. As a proof of concept, we evaluate the
performance of one essential component of this system, namely, the distributed
multi-head attention. We show that our algorithm can scale up attention
computation by almost $40\times$ using four GeForce RTX 4090 GPUs, compared to
vanilla multi-head attention mechanism. We believe this study is an
instrumental step towards modeling million-scale dependencies.</p>
  </details>
</details>
<details>
  <summary>55. <b>标题：Order Matters: Agent-by-agent Policy Optimization</b></summary>
  <p><b>编号</b>：[171]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06205</p>
  <p><b>作者</b>：Xihuai Wang,  Zheng Tian,  Ziyu Wan,  Ying Wen,  Jun Wang,  Weinan Zhang</p>
  <p><b>备注</b>：Accepted by ICLR2023, this https URL</p>
  <p><b>关键词</b>：solving coordination tasks, achieved great success, great success empirically, coordination tasks, achieved great</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>While multi-agent trust region algorithms have achieved great success
empirically in solving coordination tasks, most of them, however, suffer from a
non-stationarity problem since agents update their policies simultaneously. In
contrast, a sequential scheme that updates policies agent-by-agent provides
another perspective and shows strong performance. However, sample inefficiency
and lack of monotonic improvement guarantees for each agent are still the two
significant challenges for the sequential scheme. In this paper, we propose the
\textbf{A}gent-by-\textbf{a}gent \textbf{P}olicy \textbf{O}ptimization (A2PO)
algorithm to improve the sample efficiency and retain the guarantees of
monotonic improvement for each agent during training. We justify the tightness
of the monotonic improvement bound compared with other trust region algorithms.
From the perspective of sequentially updating agents, we further consider the
effect of agent updating order and extend the theory of non-stationarity into
the sequential update scheme. To evaluate A2PO, we conduct a comprehensive
empirical study on four benchmarks: StarCraftII, Multi-agent MuJoCo,
Multi-agent Particle Environment, and Google Research Football full game
scenarios. A2PO consistently outperforms strong baselines.</p>
  </details>
</details>
<details>
  <summary>56. <b>标题：Exploring Navigation Maps for Learning-Based Motion Prediction</b></summary>
  <p><b>编号</b>：[175]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06195</p>
  <p><b>作者</b>：Julian Schmidt,  Julian Jordan,  Franz Gritschneder,  Thomas Monninger,  Klaus Dietmayer</p>
  <p><b>备注</b>：Accepted to the 2023 IEEE International Conference on Robotics and Automation (ICRA 2023)</p>
  <p><b>关键词</b>：safe autonomous driving, surrounding agents' motion, predominant High Definition, navigation maps, learning-based motion prediction</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The prediction of surrounding agents' motion is a key for safe autonomous
driving. In this paper, we explore navigation maps as an alternative to the
predominant High Definition (HD) maps for learning-based motion prediction.
Navigation maps provide topological and geometrical information on road-level,
HD maps additionally have centimeter-accurate lane-level information. As a
result, HD maps are costly and time-consuming to obtain, while navigation maps
with near-global coverage are freely available. We describe an approach to
integrate navigation maps into learning-based motion prediction models. To
exploit locally available HD maps during training, we additionally propose a
model-agnostic method for knowledge distillation. In experiments on the
publicly available Argoverse dataset with navigation maps obtained from
OpenStreetMap, our approach shows a significant improvement over not using a
map at all. Combined with our method for knowledge distillation, we achieve
results that are close to the original HD map-reliant models. Our publicly
available navigation map API for Argoverse enables researchers to develop and
evaluate their own approaches using navigation maps.</p>
  </details>
</details>
<details>
  <summary>57. <b>标题：Multiscale Graph Neural Network Autoencoders for Interpretable  Scientific Machine Learning</b></summary>
  <p><b>编号</b>：[178]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06186</p>
  <p><b>作者</b>：Shivam Barwey,  Varun Shankar,  Romit Maulik</p>
  <p><b>备注</b>：30 pages, 17 figures</p>
  <p><b>关键词</b>：latent graph, limitations in autoencoder-based, latent space interpretability, graph reduction procedure, masked fields</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The goal of this work is to address two limitations in autoencoder-based
models: latent space interpretability and compatibility with unstructured
meshes. This is accomplished here with the development of a novel graph neural
network (GNN) autoencoding architecture with demonstrations on complex fluid
flow applications. To address the first goal of interpretability, the GNN
autoencoder achieves reduction in the number nodes in the encoding stage
through an adaptive graph reduction procedure. This reduction procedure
essentially amounts to flowfield-conditioned node sampling and sensor
identification, and produces interpretable latent graph representations
tailored to the flowfield reconstruction task in the form of so-called masked
fields. These masked fields allow the user to (a) visualize where in physical
space a given latent graph is active, and (b) interpret the time-evolution of
the latent graph connectivity in accordance with the time-evolution of unsteady
flow features (e.g. recirculation zones, shear layers) in the domain. To
address the goal of unstructured mesh compatibility, the autoencoding
architecture utilizes a series of multi-scale message passing (MMP) layers,
each of which models information exchange among node neighborhoods at various
lengthscales. The MMP layer, which augments standard single-scale message
passing with learnable coarsening operations, allows the decoder to more
efficiently reconstruct the flowfield from the identified regions in the masked
fields. Analysis of latent graphs produced by the autoencoder for various model
settings are conducted using using unstructured snapshot data sourced from
large-eddy simulations in a backward-facing step (BFS) flow configuration with
an OpenFOAM-based flow solver at high Reynolds numbers.</p>
  </details>
</details>
<details>
  <summary>58. <b>标题：Sparse Dimensionality Reduction Revisited</b></summary>
  <p><b>编号</b>：[189]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06165</p>
  <p><b>作者</b>：Mikael Møller Høgsgaard,  Lion Kamma,  Kasper Green Larsen,  Jelani Nelson,  Chris Schwiegelshohn</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：varepsilon, sparse Johnson-Lindenstrauss transform, Johnson-Lindenstrauss transform, central techniques, Nelson and Nguyen</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The sparse Johnson-Lindenstrauss transform is one of the central techniques
in dimensionality reduction. It supports embedding a set of $n$ points in
$\mathbb{R}^d$ into $m=O(\varepsilon^{-2} \lg n)$ dimensions while preserving
all pairwise distances to within $1 \pm \varepsilon$. Each input point $x$ is
embedded to $Ax$, where $A$ is an $m \times d$ matrix having $s$ non-zeros per
column, allowing for an embedding time of $O(s \|x\|_0)$.
Since the sparsity of $A$ governs the embedding time, much work has gone into
improving the sparsity $s$. The current state-of-the-art by Kane and Nelson
(JACM'14) shows that $s = O(\varepsilon ^{-1} \lg n)$ suffices. This is almost
matched by a lower bound of $s = \Omega(\varepsilon ^{-1} \lg
n/\lg(1/\varepsilon))$ by Nelson and Nguyen (STOC'13). Previous work thus
suggests that we have near-optimal embeddings.
In this work, we revisit sparse embeddings and identify a loophole in the
lower bound. Concretely, it requires $d \geq n$, which in many applications is
unrealistic. We exploit this loophole to give a sparser embedding when $d =
o(n)$, achieving $s = O(\varepsilon^{-1}(\lg n/\lg(1/\varepsilon)+\lg^{2/3}n
\lg^{1/3} d))$. We also complement our analysis by strengthening the lower
bound of Nelson and Nguyen to hold also when $d \ll n$, thereby matching the
first term in our new sparsity upper bound. Finally, we also improve the
sparsity of the best oblivious subspace embeddings for optimal embedding
dimensionality.</p>
  </details>
</details>
<details>
  <summary>59. <b>标题：RFC-Net: Learning High Resolution Global Features for Medical Image  Segmentation on a Computational Budget</b></summary>
  <p><b>编号</b>：[201]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06134</p>
  <p><b>作者</b>：Sourajit Saha,  Shaswati Saha,  Md Osman Gani,  Tim Oates,  David Chapman</p>
  <p><b>备注</b>：In Proceedings of AAAI Conference on Artificial Intelligence 2023</p>
  <p><b>关键词</b>：Learning High-Resolution representations, Learning High-Resolution, High-Resolution representations, representations is essential, essential for semantic</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Learning High-Resolution representations is essential for semantic
segmentation. Convolutional neural network (CNN)architectures with downstream
and upstream propagation flow are popular for segmentation in medical
diagnosis. However, due to performing spatial downsampling and upsampling in
multiple stages, information loss is inexorable. On the contrary, connecting
layers densely on high spatial resolution is computationally expensive. In this
work, we devise a Loose Dense Connection Strategy to connect neurons in
subsequent layers with reduced parameters. On top of that, using a m-way Tree
structure for feature propagation we propose Receptive Field Chain Network
(RFC-Net) that learns high resolution global features on a compressed
computational space. Our experiments demonstrates that RFC-Net achieves
state-of-the-art performance on Kvasir and CVC-ClinicDB benchmarks for Polyp
segmentation.</p>
  </details>
</details>
<details>
  <summary>60. <b>标题：Expediting Distributed DNN Training with Device Topology-Aware Graph  Deployment</b></summary>
  <p><b>编号</b>：[205]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06126</p>
  <p><b>作者</b>：Shiwei Zhang,  Xiaodong Yi,  Lansong Diao,  Chuan Wu,  Siyu Wang,  Wei Lin</p>
  <p><b>备注</b>：Accepted by IEEE Transactions on Parallel and Distributed Systems (TPDS) 2023</p>
  <p><b>关键词</b>：paper presents TAG, derive optimized DNN, paper presents, automatic system, system to derive</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper presents TAG, an automatic system to derive optimized DNN training
graph and its deployment onto any device topology, for expedited training in
device- and topology- heterogeneous ML clusters. We novelly combine both the
DNN computation graph and the device topology graph as input to a graph neural
network (GNN), and join the GNN with a search-based method to quickly identify
optimized distributed training strategies. To reduce communication in a
heterogeneous cluster, we further explore a lossless gradient compression
technique and solve a combinatorial optimization problem to automatically apply
the technique for training time minimization. We evaluate TAG with various
representative DNN models and device topologies, showing that it can achieve up
to 4.56x training speed-up as compared to existing schemes. TAG can produce
efficient deployment strategies for both unseen DNN models and unseen device
topologies, without heavy fine-tuning.</p>
  </details>
</details>
<details>
  <summary>61. <b>标题：The Framework Tax: Disparities Between Inference Efficiency in Research  and Deployment</b></summary>
  <p><b>编号</b>：[209]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06117</p>
  <p><b>作者</b>：Jared Fernandez,  Jacob Kahn,  Clara Na,  Yonatan Bisk,  Emma Strubell</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：machine learning systems, network model efficiency, neural network model, Increased focus, hardware accelerator performance</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Increased focus on the deployment of machine learning systems has led to
rapid improvements in hardware accelerator performance and neural network model
efficiency. However, the resulting reductions in floating point operations and
increases in computational throughput of accelerators have not directly
translated to improvements in real-world inference latency. We demonstrate that
these discrepancies can be largely attributed to mis-alignments between model
architectures and the capabilities of underlying hardware due to bottlenecks
introduced by deep learning frameworks. We denote this phenomena as the
\textit{framework tax}, and observe that the disparity is growing as hardware
speed increases over time. In this work, we examine this phenomena through a
series of case studies analyzing the effects of model design decisions,
framework paradigms, and hardware platforms on total model latency. Based on
our findings, we provide actionable recommendations to ML researchers and
practitioners aimed at narrowing the gap between efficient ML model research
and practice.</p>
  </details>
</details>
<details>
  <summary>62. <b>标题：A Survey on Graph Neural Networks for Graph Summarization</b></summary>
  <p><b>编号</b>：[210]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06114</p>
  <p><b>作者</b>：Nasrin Shabani,  Jia Wu,  Amin Beheshti,  Jin Foo,  Ambreen Hanif,  Maryam Shahabikargar</p>
  <p><b>备注</b>：9 pages, 2 figures, 1 table, IJCAI Conference</p>
  <p><b>关键词</b>：large graph data, interpret large graph, exposes computational challenges, widespread today, exposes computational</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As large-scale graphs become more widespread today, it exposes computational
challenges to extract, process, and interpret large graph data. It is therefore
natural to search for ways to summarize the original graph while maintaining
its key characteristics. In this survey, we outline the most current progress
of deep learning on graphs for graph summarization explicitly concentrating on
Graph Neural Networks (GNNs) methods. We structure the paper into four
categories, including graph recurrent networks, graph convolutional networks,
graph autoencoders, and graph attention networks. We also discuss a new booming
line of research which is elaborating on using graph reinforcement learning for
evaluating and improving the quality of graph summaries. Finally, we conclude
this survey and discuss a number of open research challenges that would
motivate further study in this area.</p>
  </details>
</details>
<details>
  <summary>63. <b>标题：How to Use Dropout Correctly on Residual Networks with Batch  Normalization</b></summary>
  <p><b>编号</b>：[212]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06112</p>
  <p><b>作者</b>：Bum Jun Kim,  Hyeyeon Choi,  Hyeonah Jang,  Donggeon Lee,  Sang Woo Kim</p>
  <p><b>备注</b>：10 pages, 4 figures</p>
  <p><b>关键词</b>：deep neural networks, apply dropout, correct position, dropout, regularization methods</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>For the stable optimization of deep neural networks, regularization methods
such as dropout and batch normalization have been used in various tasks.
Nevertheless, the correct position to apply dropout has rarely been discussed,
and different positions have been employed depending on the practitioners. In
this study, we investigate the correct position to apply dropout. We
demonstrate that for a residual network with batch normalization, applying
dropout at certain positions increases the performance, whereas applying
dropout at other positions decreases the performance. Based on theoretical
analysis, we provide the following guideline for the correct position to apply
dropout: apply one dropout after the last batch normalization but before the
last weight layer in the residual branch. We provide detailed theoretical
explanations to support this claim and demonstrate them through module tests.
In addition, we investigate the correct position of dropout in the head that
produces the final prediction. Although the current consensus is to apply
dropout after global average pooling, we prove that applying dropout before
global average pooling leads to a more stable output. The proposed guidelines
are validated through experiments using different datasets and models.</p>
  </details>
</details>
<details>
  <summary>64. <b>标题：FedDA: Faster Framework of Local Adaptive Gradient Methods via Restarted  Dual Averaging</b></summary>
  <p><b>编号</b>：[214]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06103</p>
  <p><b>作者</b>：Junyi Li,  Feihu Huang,  Heng Huang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：massively distributed data, tackle massively distributed, emerging learning paradigm, Federated learning, learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Federated learning (FL) is an emerging learning paradigm to tackle massively
distributed data. In Federated Learning, a set of clients jointly perform a
machine learning task under the coordination of a server. The FedAvg algorithm
is one of the most widely used methods to solve Federated Learning problems. In
FedAvg, the learning rate is a constant rather than changing adaptively. The
adaptive gradient methods show superior performance over the constant learning
rate schedule; however, there is still no general framework to incorporate
adaptive gradient methods into the federated setting. In this paper, we propose
\textbf{FedDA}, a novel framework for local adaptive gradient methods. The
framework adopts a restarted dual averaging technique and is flexible with
various gradient estimation methods and adaptive learning rate formulations. In
particular, we analyze \textbf{FedDA-MVR}, an instantiation of our framework,
and show that it achieves gradient complexity $\tilde{O}(\epsilon^{-1.5})$ and
communication complexity $\tilde{O}(\epsilon^{-1})$ for finding a stationary
point $\epsilon$. This matches the best known rate for first-order FL
algorithms and \textbf{FedDA-MVR} is the first adaptive FL algorithm that
achieves this rate. We also perform extensive numerical experiments to verify
the efficacy of our method.</p>
  </details>
</details>
<details>
  <summary>65. <b>标题：Boosted ab initio Cryo-EM 3D Reconstruction with ACE-EM</b></summary>
  <p><b>编号</b>：[220]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06091</p>
  <p><b>作者</b>：Lin Yao (1),  Ruihan Xu (2),  Zhifeng Gao (1),  Guolin Ke (1),  Yuhang Wang (1) ((1) DP Technology, Ltd., Beijing, China (2) Peking University, Beijing, China)</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：missing projection angles, projection angles, projection images, missing projection, structure from noisy</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The central problem in cryo-electron microscopy (cryo-EM) is to recover the
3D structure from noisy 2D projection images which requires estimating the
missing projection angles (poses). Recent methods attempted to solve the 3D
reconstruction problem with the autoencoder architecture, which suffers from
the latent vector space sampling problem and frequently produces suboptimal
pose inferences and inferior 3D reconstructions. Here we present an improved
autoencoder architecture called ACE (Asymmetric Complementary autoEncoder),
based on which we designed the ACE-EM method for cryo-EM 3D reconstructions.
Compared to previous methods, ACE-EM reached higher pose space coverage within
the same training time and boosted the reconstruction performance regardless of
the choice of decoders. With this method, the Nyquist resolution (highest
possible resolution) was reached for 3D reconstructions of both simulated and
experimental cryo-EM datasets. Furthermore, ACE-EM is the only amortized
inference method that reached the Nyquist resolution.</p>
  </details>
</details>
<details>
  <summary>66. <b>标题：Federated contrastive learning models for prostate cancer diagnosis and  Gleason grading</b></summary>
  <p><b>编号</b>：[221]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06089</p>
  <p><b>作者</b>：Fei Kong,  Jinxi Xiang,  Xiyue Wang,  Xinran Wang,  Meng Yue,  Jun Zhang,  Sen Yang,  Junhan Zhao,  Xiao Han,  Yuhan Dong,  Yueping Liu</p>
  <p><b>备注</b>：11 pages</p>
  <p><b>关键词</b>：model, FCL, artificial intelligence, imaging is remarkable, Gleason grading task</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The application effect of artificial intelligence(AI) in the field of medical
imaging is remarkable. Robust AI model training requires large datasets, but
data collection faces constraints in communication, ethics, and privacy
protection. Federated learning can solve the above problems by coordinating
multiple clients to train the model without sharing the original data. In this
study, we design a federated contrastive learning framework(FCL) for
large-scale pathology images and the heterogeneity challenges. It enhances the
generalization ability of the model by maximizing the attention consistency
between the local client model and the server model. To alleviate the privacy
leakage problem when transferring weights and verify the robustness of FCL, we
use differential privacy to further protect the model by adding noise. We
evaluate the effectiveness of FCL on the cancer diagnosis task and Gleason
grading task on 19,635 prostate cancer WSIs from multiple clients. In the
diagnosis task, the average AUC of 7 clients is 95\% when the categories are
relatively balanced, and our FCL achieves 97\%. In the Gleason grading task,
the average Kappa of 6 clients is 0.74, and the Kappa of FCL reaches 0.84.
Furthermore, we also validate the robustness of the model on external
datasets(one public dataset and two private datasets). In addition, to better
explain the classification effect of the model, we show whether the model
focuses on the lesion area by drawing a heatmap. FCL brings a robust, accurate,
and low-cost AI training model to biomedical research, effectively protecting
the privacy of medical data.</p>
  </details>
</details>
<details>
  <summary>67. <b>标题：Reliability Assurance for Deep Neural Network Architectures Against  Numerical Defects</b></summary>
  <p><b>编号</b>：[223]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06086</p>
  <p><b>作者</b>：Linyi Li,  Yuhao Zhang,  Luyao Ren,  Yingfei Xiong,  Tao Xie</p>
  <p><b>备注</b>：To appear at 45th International Conference on Software Engineering (ICSE 2023)</p>
  <p><b>关键词</b>：deep neural networks, neural networks, great importance, widespread deployment, deployment of deep</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>With the widespread deployment of deep neural networks (DNNs), ensuring the
reliability of DNN-based systems is of great importance. Serious reliability
issues such as system failures can be caused by numerical defects, one of the
most frequent defects in DNNs. To assure high reliability against numerical
defects, in this paper, we propose the RANUM approach including novel
techniques for three reliability assurance tasks: detection of potential
numerical defects, confirmation of potential-defect feasibility, and suggestion
of defect fixes. To the best of our knowledge, RANUM is the first approach that
confirms potential-defect feasibility with failure-exhibiting tests and
suggests fixes automatically. Extensive experiments on the benchmarks of 63
real-world DNN architectures show that RANUM outperforms state-of-the-art
approaches across the three reliability assurance tasks. In addition, when the
RANUM-generated fixes are compared with developers' fixes on open-source
projects, in 37 out of 40 cases, RANUM-generated fixes are equivalent to or
even better than human fixes.</p>
  </details>
</details>
<details>
  <summary>68. <b>标题：Algorithmic Aspects of the Log-Laplace Transform and a Non-Euclidean  Proximal Sampler</b></summary>
  <p><b>编号</b>：[224]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06085</p>
  <p><b>作者</b>：Sivakanth Gopi,  Yin Tat Lee,  Daogao Liu,  Ruoqi Shen,  Kevin Tian</p>
  <p><b>备注</b>：Comments welcome!</p>
  <p><b>关键词</b>：efficient sampling algorithms, sampling algorithms catering, challenging endeavor, development of efficient, efficient sampling</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The development of efficient sampling algorithms catering to non-Euclidean
geometries has been a challenging endeavor, as discretization techniques which
succeed in the Euclidean setting do not readily carry over to more general
settings. We develop a non-Euclidean analog of the recent proximal sampler of
[LST21], which naturally induces regularization by an object known as the
log-Laplace transform (LLT) of a density. We prove new mathematical properties
(with an algorithmic flavor) of the LLT, such as strong convexity-smoothness
duality and an isoperimetric inequality, which are used to prove a mixing time
on our proximal sampler matching [LST21] under a warm start. As our main
application, we show our warm-started sampler improves the value oracle
complexity of differentially private convex optimization in $\ell_p$ and
Schatten-$p$ norms for $p \in [1, 2]$ to match the Euclidean setting [GLL22],
while retaining state-of-the-art excess risk bounds [GLLST23]. We find our
investigation of the LLT to be a promising proof-of-concept of its utility as a
tool for designing samplers, and outline directions for future exploration.</p>
  </details>
</details>
<details>
  <summary>69. <b>标题：GAIN: Enhancing Byzantine Robustness in Federated Learning with Gradient  Decomposition</b></summary>
  <p><b>编号</b>：[228]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06079</p>
  <p><b>作者</b>：Yuchen Liu,  Chen Chen,  Lingjuan Lyu,  Fangzhao Wu,  Sai Wu,  Gang Chen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：privacy-aware learning framework, jointly train models, Federated learning, private data, framework by enabling</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Federated learning provides a privacy-aware learning framework by enabling
participants to jointly train models without exposing their private data.
However, federated learning has exhibited vulnerabilities to Byzantine attacks,
where the adversary aims to destroy the convergence and performance of the
global model. Meanwhile, we observe that most existing robust AGgregation Rules
(AGRs) fail to stop the aggregated gradient deviating from the optimal gradient
(the average of honest gradients) in the non-IID setting. We attribute the
reason of the failure of these AGRs to two newly proposed concepts:
identification failure and integrity failure. The identification failure mainly
comes from the exacerbated curse of dimensionality in the non-IID setting. The
integrity failure is a combined result of conservative filtering strategy and
gradient heterogeneity. In order to address both failures, we propose GAIN, a
gradient decomposition scheme that can help adapt existing robust algorithms to
heterogeneous datasets. We also provide convergence analysis for integrating
existing robust AGRs into GAIN. Experiments on various real-world datasets
verify the efficacy of our proposed GAIN.</p>
  </details>
</details>
<details>
  <summary>70. <b>标题：Universal Online Optimization in Dynamic Environments via Uniclass  Prediction</b></summary>
  <p><b>编号</b>：[232]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06066</p>
  <p><b>作者</b>：Arnold Salas</p>
  <p><b>备注</b>：Under review for COLT 2023</p>
  <p><b>关键词</b>：exponentially concave cost, exponentially concave, cost functions simultaneously, concave cost functions, functions simultaneously</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recently, several universal methods have been proposed for online convex
optimization which can handle convex, strongly convex and exponentially concave
cost functions simultaneously. However, most of these algorithms have been
designed with static regret minimization in mind, but this notion of regret may
not be suitable for changing environments. To address this shortcoming, we
propose a novel and intuitive framework for universal online optimization in
dynamic environments. Unlike existing universal algorithms, our strategy does
not rely on the construction of a set of experts and an accompanying
meta-algorithm. Instead, we show that the problem of dynamic online
optimization can be reduced to a uniclass prediction problem. By leaving the
choice of uniclass loss function in the user's hands, they are able to control
and optimize dynamic regret bounds, which in turn carry over into the original
problem. To the best of our knowledge, this is the first paper proposing a
universal approach with state-of-the-art dynamic regret guarantees even for
general convex cost functions.</p>
  </details>
</details>
<details>
  <summary>71. <b>标题：Provably Safe Reinforcement Learning with Step-wise Violation  Constraints</b></summary>
  <p><b>编号</b>：[234]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06064</p>
  <p><b>作者</b>：Nuoya Xiong,  Yihan du,  Longbo huang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：step-wise violation constraints, safe reinforcement learning, step-wise violation, reinforcement learning problem, violation constraints</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we investigate a novel safe reinforcement learning problem
with step-wise violation constraints. Our problem differs from existing works
in that we consider stricter step-wise violation constraints and do not assume
the existence of safe actions, making our formulation more suitable for
safety-critical applications which need to ensure safety in all decision steps
and may not always possess safe actions, e.g., robot control and autonomous
driving. We propose a novel algorithm SUCBVI, which guarantees
$\widetilde{O}(\sqrt{ST})$ step-wise violation and
$\widetilde{O}(\sqrt{H^3SAT})$ regret. Lower bounds are provided to validate
the optimality in both violation and regret performance with respect to $S$ and
$T$. Moreover, we further study a novel safe reward-free exploration problem
with step-wise violation constraints. For this problem, we design an
$(\varepsilon,\delta)$-PAC algorithm SRF-UCRL, which achieves nearly
state-of-the-art sample complexity
$\widetilde{O}((\frac{S^2AH^2}{\varepsilon}+\frac{H^4SA}{\varepsilon^2})(\log(\frac{1}{\delta})+S))$,
and guarantees $\widetilde{O}(\sqrt{ST})$ violation during the exploration. The
experimental results demonstrate the superiority of our algorithms in safety
performance, and corroborate our theoretical results.</p>
  </details>
</details>
<details>
  <summary>72. <b>标题：Threatening Patch Attacks on Object Detection in Optical Remote Sensing  Images</b></summary>
  <p><b>编号</b>：[236]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06060</p>
  <p><b>作者</b>：Xuxiang Sun,  Gong Cheng,  Lei Pei,  Hongda Li,  Junwei Han</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Advanced Patch Attacks, deep neural networks, great safety vulnerability, Patch Attacks, neural networks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Advanced Patch Attacks (PAs) on object detection in natural images have
pointed out the great safety vulnerability in methods based on deep neural
networks. However, little attention has been paid to this topic in Optical
Remote Sensing Images (O-RSIs). To this end, we focus on this research, i.e.,
PAs on object detection in O-RSIs, and propose a more Threatening PA without
the scarification of the visual quality, dubbed TPA. Specifically, to address
the problem of inconsistency between local and global landscapes in existing
patch selection schemes, we propose leveraging the First-Order Difference (FOD)
of the objective function before and after masking to select the sub-patches to
be attacked. Further, considering the problem of gradient inundation when
applying existing coordinate-based loss to PAs directly, we design an IoU-based
objective function specific for PAs, dubbed Bounding box Drifting Loss (BDL),
which pushes the detected bounding boxes far from the initial ones until there
are no intersections between them. Finally, on two widely used benchmarks,
i.e., DIOR and DOTA, comprehensive evaluations of our TPA with four typical
detectors (Faster R-CNN, FCOS, RetinaNet, and YOLO-v4) witness its remarkable
effectiveness. To the best of our knowledge, this is the first attempt to study
the PAs on object detection in O-RSIs, and we hope this work can get our
readers interested in studying this topic.</p>
  </details>
</details>
<details>
  <summary>73. <b>标题：TIGER: Temporal Interaction Graph Embedding with Restarts</b></summary>
  <p><b>编号</b>：[238]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06057</p>
  <p><b>作者</b>：Yao Zhang,  Yun Xiong,  Yongxiang Liao,  Yiheng Sun,  Yucheng Jin,  Xuehao Zheng,  Yangyong Zhu</p>
  <p><b>备注</b>：WWW 2023. Codes: this https URL</p>
  <p><b>关键词</b>：timestamped interaction events, Temporal interaction graphs, timestamped interaction, prevalent in fields, fields like e-commerce</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Temporal interaction graphs (TIGs), consisting of sequences of timestamped
interaction events, are prevalent in fields like e-commerce and social
networks. To better learn dynamic node embeddings that vary over time,
researchers have proposed a series of temporal graph neural networks for TIGs.
However, due to the entangled temporal and structural dependencies, existing
methods have to process the sequence of events chronologically and
consecutively to ensure node representations are up-to-date. This prevents
existing models from parallelization and reduces their flexibility in
industrial applications. To tackle the above challenge, in this paper, we
propose TIGER, a TIG embedding model that can restart at any timestamp. We
introduce a restarter module that generates surrogate representations acting as
the warm initialization of node representations. By restarting from multiple
timestamps simultaneously, we divide the sequence into multiple chunks and
naturally enable the parallelization of the model. Moreover, in contrast to
previous models that utilize a single memory unit, we introduce a dual memory
module to better exploit neighborhood information and alleviate the staleness
problem. Extensive experiments on four public datasets and one industrial
dataset are conducted, and the results verify both the effectiveness and the
efficiency of our work.</p>
  </details>
</details>
<details>
  <summary>74. <b>标题：Computation Offloading for Uncertain Marine Tasks by Cooperation of UAVs  and Vessels</b></summary>
  <p><b>编号</b>：[239]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06055</p>
  <p><b>作者</b>：Jiahao You,  Ziye Jia,  Chao Dong,  Lijun He,  Yilu Cao,  Qihui Wu</p>
  <p><b>备注</b>：6 pages, 6 figures, conference</p>
  <p><b>关键词</b>：continuous increment, limited maritime network, maritime network resources, maritime applications, maritime task offloading</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>With the continuous increment of maritime applications, the development of
marine networks for data offloading becomes necessary. However, the limited
maritime network resources are very difficult to satisfy real-time demands.
Besides, how to effectively handle multiple compute-intensive tasks becomes
another intractable issue. Hence, in this paper, we focus on the decision of
maritime task offloading by the cooperation of unmanned aerial vehicles (UAVs)
and vessels. Specifically, we first propose a cooperative offloading framework,
including the demands from marine Internet of Things (MIoTs) devices and
resource providers from UAVs and vessels. Due to the limited energy and
computation ability of UAVs, it is necessary to help better apply the vessels
to computation offloading. Then, we formulate the studied problem into a Markov
decision process, aiming to minimize the total execution time and energy cost.
Then, we leverage Lyapunov optimization to convert the long-term constraints of
the total execution time and energy cost into their short-term constraints,
further yielding a set of per-time-slot optimization problems. Furthermore, we
propose a Q-learning based approach to solve the short-term problem
efficiently. Finally, simulation results are conducted to verify the
correctness and effectiveness of the proposed algorithm.</p>
  </details>
</details>
<details>
  <summary>75. <b>标题：Unsupervised Deep One-Class Classification with Adaptive Threshold based  on Training Dynamics</b></summary>
  <p><b>编号</b>：[242]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06048</p>
  <p><b>作者</b>：Minkyung Kim,  Junsik Kim,  Jongmin Yu,  Jun Kyun Choi</p>
  <p><b>备注</b>：8 pages, 6 figures, 2022 IEEE International Conference on Data Mining Workshops (ICDMW)</p>
  <p><b>关键词</b>：building deep anomaly, dataset consisting, One-class classification, normal samples, deep</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>One-class classification has been a prevailing method in building deep
anomaly detection models under the assumption that a dataset consisting of
normal samples is available. In practice, however, abnormal samples are often
mixed in a training dataset, and they detrimentally affect the training of deep
models, which limits their applicability. For robust normality learning of deep
practical models, we propose an unsupervised deep one-class classification that
learns normality from pseudo-labeled normal samples, i.e., outlier detection in
single cluster scenarios. To this end, we propose a pseudo-labeling method by
an adaptive threshold selected by ranking-based training dynamics. The
experiments on 10 anomaly detection benchmarks show that our method effectively
improves performance on anomaly detection by sizable margins.</p>
  </details>
</details>
<details>
  <summary>76. <b>标题：Near-Optimal High-Probability Convergence for Non-Convex Stochastic  Optimization with Variance Reduction</b></summary>
  <p><b>编号</b>：[249]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06032</p>
  <p><b>作者</b>：Zijian Liu,  Perry Dong,  Srikanth Jagabathula,  Zhengyuan Zhou</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：non-convex stochastic optimization, Traditional analyses, single run, stochastic optimization, optimization problems characterize</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Traditional analyses for non-convex stochastic optimization problems
characterize convergence bounds in expectation, which is inadequate as it does
not supply a useful performance guarantee on a single run. Motivated by its
importance, an emerging line of literature has recently studied the
high-probability convergence behavior of several algorithms, including the
classic stochastic gradient descent (SGD). However, no high-probability results
are established for optimization algorithms with variance reduction, which is
known to accelerate the convergence process and has been the de facto
algorithmic technique for stochastic optimization at large. To close this
important gap, we introduce a new variance-reduced algorithm for non-convex
stochastic optimization, which we call Generalized SignSTORM. We show that with
probability at least $1-\delta$, our algorithm converges at the rate of
$O(\log(dT/\delta)/T^{1/3})$ after $T$ iterations where $d$ is the problem
dimension. This convergence guarantee matches the existing lower bound up to a
log factor, and to our best knowledge, is the first high-probability minimax
(near-)optimal result. Finally, we demonstrate the effectiveness of our
algorithm through numerical experiments.</p>
  </details>
</details>
<details>
  <summary>77. <b>标题：Time-to-event modeling of subreddits transitions to r/SuicideWatch</b></summary>
  <p><b>编号</b>：[250]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06030</p>
  <p><b>作者</b>：Xueying Liu,  Shiaofen Fang,  George Mohler,  Joan Carlson,  Yunyu Xiao</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Recent data mining, suicide ideation online, data mining research, social media text, identify suicide ideation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent data mining research has focused on the analysis of social media text,
content and networks to identify suicide ideation online. However, there has
been limited research on the temporal dynamics of users and suicide ideation.
In this work, we use time-to-event modeling to identify which subreddits have a
higher association with users transitioning to posting on r/suicidewatch. For
this purpose we use a Cox proportional hazards model that takes as input text
and subreddit network features and outputs a probability distribution for the
time until a Reddit user posts on r/suicidewatch. In our analysis we find a
number of statistically significant features that predict earlier transitions
to r/suicidewatch. While some patterns match existing intuition, for example
r/depression is positively associated with posting sooner on r/suicidewatch,
others were more surprising (for example, the average time between a high risk
post on r/Wishlist and a post on r/suicidewatch is 10.2 days). We then discuss
these results as well as directions for future research.</p>
  </details>
</details>
<details>
  <summary>78. <b>标题：Emotion Detection in Unfix-length-Context Conversation</b></summary>
  <p><b>编号</b>：[251]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06029</p>
  <p><b>作者</b>：Xiaochen Zhang,  Daniel Tang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：context windows, proper context windows, context, conversational context, distilled conversational context</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We leverage different context windows when predicting the emotion of
different utterances. New modules are included to realize variable-length
context: 1) two speaker-aware units, which explicitly model inner- and
inter-speaker dependencies to form distilled conversational context, and 2) a
top-k normalization layer, which determines the most proper context windows
from the conversational context to predict emotion. Experiments and ablation
studies show that our approach outperforms several strong baselines on three
public datasets.</p>
  </details>
</details>
<details>
  <summary>79. <b>标题：A Correct-and-Certify Approach to Self-Supervise Object Pose Estimators  via Ensemble Self-Training</b></summary>
  <p><b>编号</b>：[252]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06019</p>
  <p><b>作者</b>：Jingnan Shi,  Rajat Talak,  Dominic Maggio,  Luca Carlone</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Real-world robotics applications, robotics applications demand, applications demand object, demand object pose, object pose estimation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Real-world robotics applications demand object pose estimation methods that
work reliably across a variety of scenarios. Modern learning-based approaches
require large labeled datasets and tend to perform poorly outside the training
domain. Our first contribution is to develop a robust corrector module that
corrects pose estimates using depth information, thus enabling existing methods
to better generalize to new test domains; the corrector operates on semantic
keypoints (but is also applicable to other pose estimators) and is fully
differentiable. Our second contribution is an ensemble self-training approach
that simultaneously trains multiple pose estimators in a self-supervised
manner. Our ensemble self-training architecture uses the robust corrector to
refine the output of each pose estimator; then, it evaluates the quality of the
outputs using observable correctness certificates; finally, it uses the
observably correct outputs for further training, without requiring external
supervision. As an additional contribution, we propose small improvements to a
regression-based keypoint detection architecture, to enhance its robustness to
outliers; these improvements include a robust pooling scheme and a robust
centroid computation. Experiments on the YCBV and TLESS datasets show the
proposed ensemble self-training outperforms fully supervised baselines while
not requiring 3D annotations on real data.</p>
  </details>
</details>
<details>
  <summary>80. <b>标题：Yahoo Ad Exchange: Optimizing Floors in First Price Auctions</b></summary>
  <p><b>编号</b>：[253]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06018</p>
  <p><b>作者</b>：Miguel Alcobendas,  Amado Diaz,  Oriol Diaz,  Hermakumar Gokulakannan,  Jonathan Ji,  Boris Kapchits,  Rabi Kavoori,  Maria Rosario Levy Roman,  Emilien Pouradier-Duteil,  Korby Satow,  Swarna Veerapaneni,  Dawit Wami</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Yahoo, paper we outline, outline the methodology, Yahoo display, highest bid</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper we outline the methodology and impact of optimizing floors in
Yahoo display and video ad exchange. This marketplace uses a first price
auction mechanism to allocate ads. As a result, the highest bid wins the
auction and the winner pays its bid. This is different from the previously used
second price auction rule, where the highest bid also wins the auction but the
winner pays the maximum of the second highest bid and the floor. Our solution
induces Demand Side Platforms to change their bidding behavior as a response to
the floors enclosed in the bid request, helping Yahoo properties to increase
their ad revenue.
In June 2021, we deployed the Dynamic Floors feature to production on display
ad inventory in Yahoo properties located in North-America. Afterwards, we
rolled out the feature in other markets and properties, and in October 2022 we
started optimizing floors on Yahoo video ad inventory.
The impact of this feature is estimated at +1.3% in annualized incremental
revenue on Yahoo Display inventory, and +2.5% on video ad inventory. These are
non-negligible numbers in a multi-million Yahoo ad business.</p>
  </details>
</details>
<details>
  <summary>81. <b>标题：A Theoretical Understanding of shallow Vision Transformers: Learning,  Generalization, and Sample Complexity</b></summary>
  <p><b>编号</b>：[254]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06015</p>
  <p><b>作者</b>：Hongkang Li,  Meng Wang,  Sijia Liu,  Pin-yu Chen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：recently achieved great, Vision Transformers, achieved great empirical, modules have recently, recently achieved</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Vision Transformers (ViTs) with self-attention modules have recently achieved
great empirical success in many vision tasks. Due to non-convex interactions
across layers, however, theoretical learning and generalization analysis is
mostly elusive. Based on a data model characterizing both label-relevant and
label-irrelevant tokens, this paper provides the first theoretical analysis of
training a shallow ViT, i.e., one self-attention layer followed by a two-layer
perceptron, for a classification task. We characterize the sample complexity to
achieve a zero generalization error. Our sample complexity bound is positively
correlated with the inverse of the fraction of label-relevant tokens, the token
noise level, and the initial model error. We also prove that a training process
using stochastic gradient descent (SGD) leads to a sparse attention map, which
is a formal verification of the general intuition about the success of
attention. Moreover, this paper indicates that a proper token sparsification
can improve the test performance by removing label-irrelevant and/or noisy
tokens, including spurious correlations. Empirical experiments on synthetic
data and CIFAR-10 dataset justify our theoretical results and generalize to
deeper ViTs.</p>
  </details>
</details>
<details>
  <summary>82. <b>标题：Online Recommendations for Agents with Discounted Adaptive Preferences</b></summary>
  <p><b>编号</b>：[255]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06014</p>
  <p><b>作者</b>：Arpit Agarwal,  William Brown</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：repeated content suggestions, content suggestions, long-run optimization, repeated content, evolve over time</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>For domains in which a recommender provides repeated content suggestions,
agent preferences may evolve over time as a function of prior recommendations,
and algorithms must take this into account for long-run optimization. Recently,
Agarwal and Brown (2022) introduced a model for studying recommendations when
agents' preferences are adaptive, and gave a series of results for the case
when agent preferences depend {\it uniformly} on their history of past
selections. Here, the recommender shows a $k$-item menu (out of $n$) to the
agent at each round, who selects one of the $k$ items via their
history-dependent {\it preference model}, yielding a per-item adversarial
reward for the recommender.
We expand this setting to {\it non-uniform} preferences, and give a series of
results for {\it $\gamma$-discounted} histories. For this problem, the feasible
regret benchmarks can depend drastically on varying conditions. In the ``large
$\gamma$'' regime, we show that the previously considered benchmark, the ``EIRD
set'', is attainable for any {\it smooth} model, relaxing the ``local
learnability'' requirement from the uniform memory case. We introduce
``pseudo-increasing'' preference models, for which we give an algorithm which
can compete against any item distribution with small uniform noise (the
``smoothed simplex''). We show NP-hardness results for larger regret benchmarks
in each case. We give another algorithm for pseudo-increasing models (under a
restriction on the adversarial nature of the reward functions), which works for
any $\gamma$ and is faster when $\gamma$ is sufficiently small, and we show a
super-polynomial regret lower bound with respect to EIRD for general models in
the ``small $\gamma$'' regime. We conclude with a pair of algorithms for the
memoryless case.</p>
  </details>
</details>
<details>
  <summary>83. <b>标题：Policy-Induced Self-Supervision Improves Representation Finetuning in  Visual RL</b></summary>
  <p><b>编号</b>：[257]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06009</p>
  <p><b>作者</b>：Sébastien M. R. Arnold,  Fei Sha</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：visual percept based, visual percept, percept based, transfer representations pretrained, pretrained</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We study how to transfer representations pretrained on source tasks to target
tasks in visual percept based RL. We analyze two popular approaches: freezing
or finetuning the pretrained representations. Empirical studies on a set of
popular tasks reveal several properties of pretrained representations. First,
finetuning is required even when pretrained representations perfectly capture
the information required to solve the target task. Second, finetuned
representations improve learnability and are more robust to noise. Third,
pretrained bottom layers are task-agnostic and readily transferable to new
tasks, while top layers encode task-specific information and require
adaptation. Building on these insights, we propose a self-supervised objective
that clusters representations according to the policy they induce, as opposed
to traditional representation similarity measures which are policy-agnostic
(e.g. Euclidean norm, cosine similarity). Together with freezing the bottom
layers, this objective results in significantly better representation than
frozen, finetuned, and self-supervised alternatives on a wide range of
benchmarks.</p>
  </details>
</details>
<details>
  <summary>84. <b>标题：ASR Bundestag: A Large-Scale political debate dataset in German</b></summary>
  <p><b>编号</b>：[258]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06008</p>
  <p><b>作者</b>：Johannes Wirth,  René Peinl</p>
  <p><b>备注</b>：13 pages, 2 tables, 4 figures</p>
  <p><b>关键词</b>：present ASR Bundestag, ASR Bundestag, automatic speech recognition, present ASR, automatic speech</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present ASR Bundestag, a dataset for automatic speech recognition in
German, consisting of 610 hours of aligned audio-transcript pairs for
supervised training as well as 1,038 hours of unlabeled audio snippets for
self-supervised learning, based on raw audio data and transcriptions from
plenary sessions and committee meetings of the German parliament. In addition,
we discuss utilized approaches for the automated creation of speech datasets
and assess the quality of the resulting dataset based on evaluations and
finetuning of a pre-trained state of the art model. We make the dataset
publicly available, including all subsets.</p>
  </details>
</details>
<details>
  <summary>85. <b>标题：Near-optimal learning with average Hölder smoothness</b></summary>
  <p><b>编号</b>：[260]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06005</p>
  <p><b>作者</b>：Steve Hanneke,  Aryeh Kontorovich,  Guy Kornowski</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：proposed by Ashlagi, Lipschitz smoothness proposed, average Lipschitz smoothness, Hölder smoothness, Lipschitz smoothness</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We generalize the notion of average Lipschitz smoothness proposed by Ashlagi
et al. (COLT 2021) by extending it to Hölder smoothness. This measure of the
``effective smoothness'' of a function is sensitive to the underlying
distribution and can be dramatically smaller than its classic ``worst-case''
Hölder constant. We prove nearly tight upper and lower risk bounds in terms
of the average Hölder smoothness, establishing the minimax rate in the
realizable regression setting up to log factors; this was not previously known
even in the special case of average Lipschitz smoothness. From an algorithmic
perspective, since our notion of average smoothness is defined with respect to
the unknown sampling distribution, the learner does not have an explicit
representation of the function class, hence is unable to execute ERM.
Nevertheless, we provide a learning algorithm that achieves the (nearly)
optimal learning rate. Our results hold in any totally bounded metric space,
and are stated in terms of its intrinsic geometry. Overall, our results show
that the classic worst-case notion of Hölder smoothness can be essentially
replaced by its average, yielding considerably sharper guarantees.</p>
  </details>
</details>
<details>
  <summary>86. <b>标题：Multi-dimensional discrimination in Law and Machine Learning -- A  comparative overview</b></summary>
  <p><b>编号</b>：[265]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05995</p>
  <p><b>作者</b>：Arjun Roy,  Jan Horstmann,  Eirini Ntoutsi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：social groups based, AI-driven decision-making, decision-making can lead, individuals or social, social groups</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>AI-driven decision-making can lead to discrimination against certain
individuals or social groups based on protected characteristics/attributes such
as race, gender, or age. The domain of fairness-aware machine learning focuses
on methods and algorithms for understanding, mitigating, and accounting for
bias in AI/ML models. Still, thus far, the vast majority of the proposed
methods assess fairness based on a single protected attribute, e.g. only gender
or race. In reality, though, human identities are multi-dimensional, and
discrimination can occur based on more than one protected characteristic,
leading to the so-called ``multi-dimensional discrimination'' or
``multi-dimensional fairness'' problem. While well-elaborated in legal
literature, the multi-dimensionality of discrimination is less explored in the
machine learning community. Recent approaches in this direction mainly follow
the so-called intersectional fairness definition from the legal domain, whereas
other notions like additive and sequential discrimination are less studied or
not considered thus far. In this work, we overview the different definitions of
multi-dimensional discrimination/fairness in the legal domain as well as how
they have been transferred/ operationalized (if) in the fairness-aware machine
learning domain. By juxtaposing these two domains, we draw the connections,
identify the limitations, and point out open research directions.</p>
  </details>
</details>
<details>
  <summary>87. <b>标题：Quantum Neuron Selection: Finding High Performing Subnetworks With  Quantum Algorithms</b></summary>
  <p><b>编号</b>：[270]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05984</p>
  <p><b>作者</b>：Tim Whitaker</p>
  <p><b>备注</b>：7 Pages, 3 Figures, Accepted to GECCO-22 Quantum Optimization Workshop</p>
  <p><b>关键词</b>：Gradient descent methods, Gradient descent, facto standard, training deep neural, deep neural networks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Gradient descent methods have long been the de facto standard for training
deep neural networks. Millions of training samples are fed into models with
billions of parameters, which are slowly updated over hundreds of epochs.
Recently, it's been shown that large, randomly initialized neural networks
contain subnetworks that perform as well as fully trained models. This insight
offers a promising avenue for training future neural networks by simply pruning
weights from large, random models. However, this problem is combinatorically
hard and classical algorithms are not efficient at finding the best subnetwork.
In this paper, we explore how quantum algorithms could be formulated and
applied to this neuron selection problem. We introduce several methods for
local quantum neuron selection that reduce the entanglement complexity that
large scale neuron selection would require, making this problem more tractable
for current quantum hardware.</p>
  </details>
</details>
<details>
  <summary>88. <b>标题：Review of Extreme Multilabel Classification</b></summary>
  <p><b>编号</b>：[275]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05971</p>
  <p><b>作者</b>：Arpan Dasgupta,  Siddhant Katyan,  Shrutimoy Das,  Pawan Kumar</p>
  <p><b>备注</b>：46 pages, 13 figures</p>
  <p><b>关键词</b>：Extreme multilabel classification, multilabel classification, Extreme multilabel, traditional multilabel classification, subtopic of interest</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Extreme multilabel classification or XML, in short, has emerged as a new
subtopic of interest in machine learning. Compared to traditional multilabel
classification, here the number of labels is extremely large, hence the name
extreme multilabel classification. Using classical one versus all
classification wont scale in this case due to large number of labels, same is
true for any other classifiers. Embedding of labels as well as features into
smaller label space is an essential first step. Moreover, other issues include
existance of head and tail labels, where tail labels are labels which exist in
relatively smaller number of given samples. The existence of tail labels
creates issues during embedding. This area has invited application of wide
range of approaches ranging from bit compression motivated from compressed
sensing, tree based embeddings, deep learning based latent space embedding
including using attention weights, linear algebra based embeddings such as SVD,
clustering, hashing, to name a few. The community has come up with a useful set
of metrics to identify the correctly the prediction for head or tail labels.</p>
  </details>
</details>
<details>
  <summary>89. <b>标题：Autoselection of the Ensemble of Convolutional Neural Networks with  Second-Order Cone Programming</b></summary>
  <p><b>编号</b>：[285]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05950</p>
  <p><b>作者</b>：Buse Çisil Güldoğuş,  Abdullah Nazhat Abdullah,  Muhammad Ammar Ali,  Süreyya Özöğür-Akyüz</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：optimal predictive solution, predictive solution, techniques are frequently, frequently encountered, encountered in machine</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Ensemble techniques are frequently encountered in machine learning and
engineering problems since the method combines different models and produces an
optimal predictive solution. The ensemble concept can be adapted to deep
learning models to provide robustness and reliability. Due to the growth of the
models in deep learning, using ensemble pruning is highly important to deal
with computational complexity. Hence, this study proposes a mathematical model
which prunes the ensemble of Convolutional Neural Networks (CNN) consisting of
different depths and layers that maximizes accuracy and diversity
simultaneously with a sparse second order conic optimization model. The
proposed model is tested on CIFAR-10, CIFAR-100 and MNIST data sets which gives
promising results while reducing the complexity of models, significantly.</p>
  </details>
</details>
<details>
  <summary>90. <b>标题：SpReME: Sparse Regression for Multi-Environment Dynamic Systems</b></summary>
  <p><b>编号</b>：[288]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05942</p>
  <p><b>作者</b>：MoonJeong Park,  Youngbin Choi,  Namhoon Lee,  Dongwoo Kim</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Learning dynamical systems, Learning dynamical, scientific discoveries, promising avenue, avenue for scientific</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Learning dynamical systems is a promising avenue for scientific discoveries.
However, capturing the governing dynamics in multiple environments still
remains a challenge: model-based approaches rely on the fidelity of assumptions
made for a single environment, whereas data-driven approaches based on neural
networks are often fragile on extrapolating into the future. In this work, we
develop a method of sparse regression dubbed SpReME to discover the major
dynamics that underlie multiple environments. Specifically, SpReME shares a
sparse structure of ordinary differential equation (ODE) across different
environments in common while allowing each environment to keep the coefficients
of ODE terms independently. We demonstrate that the proposed model captures the
correct dynamics from multiple environments over four different dynamic systems
with improved prediction performance.</p>
  </details>
</details>
<details>
  <summary>91. <b>标题：SCLIFD:Supervised Contrastive Knowledge Distillation for Incremental  Fault Diagnosis under Limited Fault Data</b></summary>
  <p><b>编号</b>：[294]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05929</p>
  <p><b>作者</b>：Peng Peng,  Hanrong Zhang,  Mengxuan Li,  Gongzhuang Peng,  Hongwei Wang,  Weiming Shen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：made extraordinary advancements, limited fault data, fault diagnosis, Intelligent fault diagnosis, fault data</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Intelligent fault diagnosis has made extraordinary advancements currently.
Nonetheless, few works tackle class-incremental learning for fault diagnosis
under limited fault data, i.e., imbalanced and long-tailed fault diagnosis,
which brings about various notable challenges. Initially, it is difficult to
extract discriminative features from limited fault data. Moreover, a
well-trained model must be retrained from scratch to classify the samples from
new classes, thus causing a high computational burden and time consumption.
Furthermore, the model may suffer from catastrophic forgetting when trained
incrementally. Finally, the model decision is biased toward the new classes due
to the class imbalance. The problems can consequently lead to performance
degradation of fault diagnosis models. Accordingly, we introduce a supervised
contrastive knowledge distillation for incremental fault diagnosis under
limited fault data (SCLIFD) framework to address these issues, which extends
the classical incremental classifier and representation learning (iCaRL)
framework from three perspectives. Primarily, we adopt supervised contrastive
knowledge distillation (KD) to enhance its representation learning capability
under limited fault data. Moreover, we propose a novel prioritized exemplar
selection method adaptive herding (AdaHerding) to restrict the increase of the
computational burden, which is also combined with KD to alleviate catastrophic
forgetting. Additionally, we adopt the cosine classifier to mitigate the
adverse impact of class imbalance. We conduct extensive experiments on
simulated and real-world industrial processes under different imbalance ratios.
Experimental results show that our SCLIFD outperforms the existing methods by a
large margin.</p>
  </details>
</details>
<details>
  <summary>92. <b>标题：Transfer Learning for Bayesian Optimization: A Survey</b></summary>
  <p><b>编号</b>：[296]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05927</p>
  <p><b>作者</b>：Tianyi Bai,  Yang Li,  Yu Shen,  Xinyi Zhang,  Wentao Zhang,  Bin Cui</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：including parameter tuning, including parameter, parameter tuning, Bayesian optimization, optimization</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A wide spectrum of design and decision problems, including parameter tuning,
A/B testing and drug design, intrinsically are instances of black-box
optimization. Bayesian optimization (BO) is a powerful tool that models and
optimizes such expensive "black-box" functions. However, at the beginning of
optimization, vanilla Bayesian optimization methods often suffer from slow
convergence issue due to inaccurate modeling based on few trials. To address
this issue, researchers in the BO community propose to incorporate the spirit
of transfer learning to accelerate optimization process, which could borrow
strength from the past tasks (source tasks) to accelerate the current
optimization problem (target task). This survey paper first summarizes transfer
learning methods for Bayesian optimization from four perspectives: initial
points design, search space design, surrogate model, and acquisition function.
Then it highlights its methodological aspects and technical details for each
approach. Finally, it showcases a wide range of applications and proposes
promising future directions.</p>
  </details>
</details>
<details>
  <summary>93. <b>标题：Vector Quantized Wasserstein Auto-Encoder</b></summary>
  <p><b>编号</b>：[299]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05917</p>
  <p><b>作者</b>：Tung-Long Vuong,  Trung Le,  He Zhao,  Chuanxia Zheng,  Mehrtash Harandi,  Jianfei Cai,  Dinh Phung</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：subsequent downstream tasks, latent presentations offers, Learning deep discrete, Vector Quantized Variational, deep discrete representations</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Learning deep discrete latent presentations offers a promise of better
symbolic and summarized abstractions that are more useful to subsequent
downstream tasks. Inspired by the seminal Vector Quantized Variational
Auto-Encoder (VQ-VAE), most of work in learning deep discrete representations
has mainly focused on improving the original VQ-VAE form and none of them has
studied learning deep discrete representations from the generative viewpoint.
In this work, we study learning deep discrete representations from the
generative viewpoint. Specifically, we endow discrete distributions over
sequences of codewords and learn a deterministic decoder that transports the
distribution over the sequences of codewords to the data distribution via
minimizing a WS distance between them. We develop further theories to connect
it with the clustering viewpoint of WS distance, allowing us to have a better
and more controllable clustering solution. Finally, we empirically evaluate our
method on several well-known benchmarks, where it achieves better qualitative
and quantitative performances than the other VQ-VAE variants in terms of the
codebook utilization and image reconstruction/generation.</p>
  </details>
</details>
<details>
  <summary>94. <b>标题：Variational Voxel Pseudo Image Tracking</b></summary>
  <p><b>编号</b>：[302]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05914</p>
  <p><b>作者</b>：Illia Oleksiienko,  Paraskevi Nousi,  Nikolaos Passalis,  Anastasios Tefas,  Alexandros Iosifidis</p>
  <p><b>备注</b>：5 pages, 2 figures, 1 table</p>
  <p><b>关键词</b>：perception models, model certainty, Voxel Pseudo Image, critical problems, autonomous driving</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Uncertainty estimation is an important task for critical problems, such as
robotics and autonomous driving, because it allows creating statistically
better perception models and signaling the model's certainty in its predictions
to the decision method or a human supervisor. In this paper, we propose a
Variational Neural Network-based version of a Voxel Pseudo Image Tracking
(VPIT) method for 3D Single Object Tracking. The Variational Feature Generation
Network of the proposed Variational VPIT computes features for target and
search regions and the corresponding uncertainties, which are later combined
using an uncertainty-aware cross-correlation module in one of two ways: by
computing similarity between the corresponding uncertainties and adding it to
the regular cross-correlation values, or by penalizing the uncertain feature
channels to increase influence of the certain features. In experiments, we show
that both methods improve tracking performance, while penalization of uncertain
features provides the best uncertainty quality.</p>
  </details>
</details>
<details>
  <summary>95. <b>标题：LipLearner: Customizable Silent Speech Interactions on Mobile Devices</b></summary>
  <p><b>编号</b>：[305]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05907</p>
  <p><b>作者</b>：Zixiong Su,  Shitao Fang,  Jun Rekimoto</p>
  <p><b>备注</b>：21 pages, 14 figures, 4 tables</p>
  <p><b>关键词</b>：enables private communications, natural language, promising technology, technology that enables, enables private</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Silent speech interface is a promising technology that enables private
communications in natural language. However, previous approaches only support a
small and inflexible vocabulary, which leads to limited expressiveness. We
leverage contrastive learning to learn efficient lipreading representations,
enabling few-shot command customization with minimal user effort. Our model
exhibits high robustness to different lighting, posture, and gesture conditions
on an in-the-wild dataset. For 25-command classification, an F1-score of 0.8947
is achievable only using one shot, and its performance can be further boosted
by adaptively learning from more data. This generalizability allowed us to
develop a mobile silent speech interface empowered with on-device fine-tuning
and visual keyword spotting. A user study demonstrated that with LipLearner,
users could define their own commands with high reliability guaranteed by an
online incremental learning scheme. Subjective feedback indicated that our
system provides essential functionalities for customizable silent speech
interactions with high usability and learnability.</p>
  </details>
</details>
<details>
  <summary>96. <b>标题：On Testing and Comparing Fair classifiers under Data Bias</b></summary>
  <p><b>编号</b>：[306]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05906</p>
  <p><b>作者</b>：Mohit Sharma,  Amit Deshpande,  Rajiv Ratn Shah</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：fair classifiers, data, training data, Blum, Stangl</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we consider a theoretical model for injecting data bias,
namely, under-representation and label bias (Blum & Stangl, 2019). We
theoretically and empirically study its effect on the accuracy and fairness of
fair classifiers. Theoretically, we prove that the Bayes optimal group-aware
fair classifier on the original data distribution can be recovered by simply
minimizing a carefully chosen reweighed loss on the bias-injected distribution.
Through extensive experiments on both synthetic and real-world datasets (e.g.,
Adult, German Credit, Bank Marketing, COMPAS), we empirically audit pre-, in-,
and post-processing fair classifiers from standard fairness toolkits for their
fairness and accuracy by injecting varying amounts of under-representation and
label bias in their training data (but not the test data). Our main
observations are: (1) The fairness and accuracy of many standard fair
classifiers degrade severely as the bias injected in their training data
increases, (2) A simple logistic regression model trained on the right data can
often outperform, in both accuracy and fairness, most fair classifiers trained
on biased training data, and (3) A few, simple fairness techniques (e.g.,
reweighing, exponentiated gradients) seem to offer stable accuracy and fairness
guarantees even when their training data is injected with under-representation
and label bias. Our experiments also show how to integrate a measure of data
bias risk in the existing fairness dashboards for real-world deployments</p>
  </details>
</details>
<details>
  <summary>97. <b>标题：Neural Architecture Search with Multimodal Fusion Methods for Diagnosing  Dementia</b></summary>
  <p><b>编号</b>：[311]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05894</p>
  <p><b>作者</b>：Michail Chatzianastasis,  Loukas Ilias,  Dimitris Askounis,  Michalis Vazirgiannis</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：deteriorating person life, affects memory, Convolutional Neural Networks, deteriorating person, person life</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Alzheimer's dementia (AD) affects memory, thinking, and language,
deteriorating person's life. An early diagnosis is very important as it enables
the person to receive medical help and ensure quality of life. Therefore,
leveraging spontaneous speech in conjunction with machine learning methods for
recognizing AD patients has emerged into a hot topic. Most of the previous
works employ Convolutional Neural Networks (CNNs), to process the input signal.
However, finding a CNN architecture is a time-consuming process and requires
domain expertise. Moreover, the researchers introduce early and late fusion
approaches for fusing different modalities or concatenate the representations
of the different modalities during training, thus the inter-modal interactions
are not captured. To tackle these limitations, first we exploit a Neural
Architecture Search (NAS) method to automatically find a high performing CNN
architecture. Next, we exploit several fusion methods, including Multimodal
Factorized Bilinear Pooling and Tucker Decomposition, to combine both speech
and text modalities. To the best of our knowledge, there is no prior work
exploiting a NAS approach and these fusion methods in the task of dementia
detection from spontaneous speech. We perform extensive experiments on the
ADReSS Challenge dataset and show the effectiveness of our approach over
state-of-the-art methods.</p>
  </details>
</details>
<details>
  <summary>98. <b>标题：USER: Unsupervised Structural Entropy-based Robust Graph Neural Network</b></summary>
  <p><b>编号</b>：[314]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05889</p>
  <p><b>作者</b>：Yifei Wang,  Yupan Wang,  Zeyu Zhang,  Song Yang,  Kaiqi Zhao,  Jiamou Liu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：input graph data, self-supervised graph neural, graph neural networks, vulnerable to inherent, data which greatly</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Unsupervised/self-supervised graph neural networks (GNN) are vulnerable to
inherent randomness in the input graph data which greatly affects the
performance of the model in downstream tasks. In this paper, we alleviate the
interference of graph randomness and learn appropriate representations of nodes
without label information. To this end, we propose USER, an unsupervised robust
version of graph neural networks that is based on structural entropy. We
analyze the property of intrinsic connectivity and define intrinsic
connectivity graph. We also identify the rank of the adjacency matrix as a
crucial factor in revealing a graph that provides the same embeddings as the
intrinsic connectivity graph. We then introduce structural entropy in the
objective function to capture such a graph. Extensive experiments conducted on
clustering and link prediction tasks under random-noises and meta-attack over
three datasets show USER outperforms benchmarks and is robust to heavier
randomness.</p>
  </details>
</details>
<details>
  <summary>99. <b>标题：Position Matters! Empirical Study of Order Effect in Knowledge-grounded  Dialogue</b></summary>
  <p><b>编号</b>：[315]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05888</p>
  <p><b>作者</b>：Hsuan Su,  Shachi H Kumar,  Sahisnu Mazumder,  Wenda Chen,  Ramesh Manuvinakurike,  Eda Okur,  Saurav Sahay,  Lama Nachman,  Shang-Tse Chen,  Hung-yi Lee</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：large pretrained language, pretrained language models, power of large, large pretrained, pretrained language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>With the power of large pretrained language models, various research works
have integrated knowledge into dialogue systems. The traditional techniques
treat knowledge as part of the input sequence for the dialogue system,
prepending a set of knowledge statements in front of dialogue history. However,
such a mechanism forces knowledge sets to be concatenated in an ordered manner,
making models implicitly pay imbalanced attention to the sets during training.
In this paper, we first investigate how the order of the knowledge set can
influence autoregressive dialogue systems' responses. We conduct experiments on
two commonly used dialogue datasets with two types of transformer-based models
and find that models view the input knowledge unequally. To this end, we
propose a simple and novel technique to alleviate the order effect by modifying
the position embeddings of knowledge input in these models. With the proposed
position embedding method, the experimental results show that each knowledge
statement is uniformly considered to generate responses.</p>
  </details>
</details>
<details>
  <summary>100. <b>标题：Exploration of carbonate aggregates in road construction using  ultrasonic and artificial intelligence approaches</b></summary>
  <p><b>编号</b>：[316]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05884</p>
  <p><b>作者</b>：Mohamed Abdelhedi,  Rateb Jabbar,  Chedly Abbes</p>
  <p><b>备注</b>：8 pages, 4 figures</p>
  <p><b>关键词</b>：pandemic has significantly, economic cycles, significantly impacted, impacted the construction, sensitive to economic</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The COVID-19 pandemic has significantly impacted the construction sector,
which is sensitive to economic cycles. In order to boost value and efficiency
in this sector, the use of innovative exploration technologies such as
ultrasonic and Artificial Intelligence techniques in building material research
is becoming increasingly crucial. In this study, we developed two models for
predicting the Los Angeles (LA) and Micro Deval (MDE) coefficients, two
important geotechnical tests used to determine the quality of rock aggregates.
These coefficients describe the resistance of aggregates to fragmentation and
abrasion. The ultrasound velocity, porosity, and density of the rocks were
determined and used as inputs to develop prediction models using multiple
regression and an artificial neural network. These models may be used to assess
the quality of rock aggregates at the exploration stage without the need for
tedious laboratory analysis.</p>
  </details>
</details>
<details>
  <summary>101. <b>标题：I$^2$SB: Image-to-Image Schrödinger Bridge</b></summary>
  <p><b>编号</b>：[319]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05872</p>
  <p><b>作者</b>：Guan-Horng Liu,  Arash Vahdat,  De-An Huang,  Evangelos A. Theodorou,  Weili Nie,  Anima Anandkumar</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Schrödinger Bridge, directly learn, diffusion models, diffusion, conditional diffusion models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose Image-to-Image Schrödinger Bridge (I$^2$SB), a new class of
conditional diffusion models that directly learn the nonlinear diffusion
processes between two given distributions. These diffusion bridges are
particularly useful for image restoration, as the degraded images are
structurally informative priors for reconstructing the clean images. I$^2$SB
belongs to a tractable class of Schrödinger bridge, the nonlinear extension
to score-based models, whose marginal distributions can be computed
analytically given boundary pairs. This results in a simulation-free framework
for nonlinear diffusions, where the I$^2$SB training becomes scalable by
adopting practical techniques used in standard diffusion models. We validate
I$^2$SB in solving various image restoration tasks, including inpainting,
super-resolution, deblurring, and JPEG restoration on ImageNet 256x256 and show
that I$^2$SB surpasses standard conditional diffusion models with more
interpretable generative processes. Moreover, I$^2$SB matches the performance
of inverse methods that additionally require the knowledge of the corruption
operators. Our work opens up new algorithmic opportunities for developing
efficient nonlinear diffusion models on a large scale. scale. Project page:
this https URL</p>
  </details>
</details>
<details>
  <summary>102. <b>标题：Flag Aggregator: Scalable Distributed Training under Failures and  Augmented Losses using Convex Optimization</b></summary>
  <p><b>编号</b>：[321]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05865</p>
  <p><b>作者</b>：Hamidreza Almasi,  Harsh Mishra,  Balajee Vamanan,  Sathya N. Ravi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：applications increasingly rely, complex deep learning, deep learning models, Modern ML applications, large datasets</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Modern ML applications increasingly rely on complex deep learning models and
large datasets. There has been an exponential growth in the amount of
computation needed to train the largest models. Therefore, to scale computation
and data, these models are inevitably trained in a distributed manner in
clusters of nodes, and their updates are aggregated before being applied to the
model. However, a distributed setup is prone to byzantine failures of
individual nodes, components, and software. With data augmentation added to
these settings, there is a critical need for robust and efficient aggregation
systems. We extend the current state-of-the-art aggregators and propose an
optimization-based subspace estimator by modeling pairwise distances as
quadratic functions by utilizing the recently introduced Flag Median problem.
The estimator in our loss function favors the pairs that preserve the norm of
the difference vector. We theoretically show that our approach enhances the
robustness of state-of-the-art byzantine resilient aggregators. Also, we
evaluate our method with different tasks in a distributed setup with a
parameter server architecture and show its communication efficiency while
maintaining similar accuracy. The code is publicly available at
this https URL</p>
  </details>
</details>
<details>
  <summary>103. <b>标题：Maneuver Decision-Making For Autonomous Air Combat Through Curriculum  Learning And Reinforcement Learning With Sparse Rewards</b></summary>
  <p><b>编号</b>：[332]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05838</p>
  <p><b>作者</b>：Yu-Jie Wei,  Hong-Peng Zhang,  Chang-Qiang Huang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：combat maneuver decision-making, air combat maneuver, Reinforcement learning, air combat, maneuver decision-making</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Reinforcement learning is an effective way to solve the decision-making
problems. It is a meaningful and valuable direction to investigate autonomous
air combat maneuver decision-making method based on reinforcement learning.
However, when using reinforcement learning to solve the decision-making
problems with sparse rewards, such as air combat maneuver decision-making, it
costs too much time for training and the performance of the trained agent may
not be satisfactory. In order to solve these problems, the method based on
curriculum learning is proposed. First, three curricula of air combat maneuver
decision-making are designed: angle curriculum, distance curriculum and hybrid
curriculum. These courses are used to train air combat agents respectively, and
compared with the original method without any curriculum. The training results
show that angle curriculum can increase the speed and stability of training,
and improve the performance of the agent; distance curriculum can increase the
speed and stability of agent training; hybrid curriculum has a negative impact
on training, because it makes the agent get stuck at local optimum. The
simulation results show that after training, the agent can handle the
situations where targets come from different directions, and the maneuver
decision results are consistent with the characteristics of missile.</p>
  </details>
</details>
<details>
  <summary>104. <b>标题：Theory on Forgetting and Generalization of Continual Learning</b></summary>
  <p><b>编号</b>：[333]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05836</p>
  <p><b>作者</b>：Sen Lin,  Peizhong Ju,  Yingbin Liang,  Ness Shroff</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：significant recent attention, attracted significant recent, Continual learning, aims to learn, learn a sequence</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Continual learning (CL), which aims to learn a sequence of tasks, has
attracted significant recent attention. However, most work has focused on the
experimental performance of CL, and theoretical studies of CL are still
limited. In particular, there is a lack of understanding on what factors are
important and how they affect "catastrophic forgetting" and generalization
performance. To fill this gap, our theoretical analysis, under
overparameterized linear models, provides the first-known explicit form of the
expected forgetting and generalization error. Further analysis of such a key
result yields a number of theoretical explanations about how
overparameterization, task similarity, and task ordering affect both forgetting
and generalization error of CL. More interestingly, by conducting experiments
on real datasets using deep neural networks (DNNs), we show that some of these
insights even go beyond the linear models and can be carried over to practical
setups. In particular, we use concrete examples to show that our results not
only explain some interesting empirical observations in recent studies, but
also motivate better practical algorithm designs of CL.</p>
  </details>
</details>
<details>
  <summary>105. <b>标题：Sparse Mutation Decompositions: Fine Tuning Deep Neural Networks with  Subspace Evolution</b></summary>
  <p><b>编号</b>：[334]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05832</p>
  <p><b>作者</b>：Tim Whitaker,  Darrell Whitley</p>
  <p><b>备注</b>：8 Pages, 3 Figures</p>
  <p><b>关键词</b>：combines evolutionary algorithms, promising area, networks, area of research, combines evolutionary</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Neuroevolution is a promising area of research that combines evolutionary
algorithms with neural networks. A popular subclass of neuroevolutionary
methods, called evolution strategies, relies on dense noise perturbations to
mutate networks, which can be sample inefficient and challenging for large
models with millions of parameters. We introduce an approach to alleviating
this problem by decomposing dense mutations into low-dimensional subspaces.
Restricting mutations in this way can significantly reduce variance as networks
can handle stronger perturbations while maintaining performance, which enables
a more controlled and targeted evolution of deep networks. This approach is
uniquely effective for the task of fine tuning pre-trained models, which is an
increasingly valuable area of research as networks continue to scale in size
and open source models become more widely available. Furthermore, we show how
this work naturally connects to ensemble learning where sparse mutations
encourage diversity among children such that their combined predictions can
reliably improve performance. We conduct the first large scale exploration of
neuroevolutionary fine tuning and ensembling on the notoriously difficult
ImageNet dataset, where we see small generalization improvements with only a
single evolutionary generation using nearly a dozen different deep neural
network architectures.</p>
  </details>
</details>
<details>
  <summary>106. <b>标题：Tighter PAC-Bayes Bounds Through Coin-Betting</b></summary>
  <p><b>编号</b>：[335]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05829</p>
  <p><b>作者</b>：Kyoungseok Jang,  Kwang-Sung Jun,  Ilja Kuzborskij,  Francesco Orabona</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：independent random variables, fixed scalar function, theta, random elements, random variables</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We consider the problem of estimating the mean of a sequence of random
elements $f(X_1, \theta)$ $, \ldots, $ $f(X_n, \theta)$ where $f$ is a fixed
scalar function, $S=(X_1, \ldots, X_n)$ are independent random variables, and
$\theta$ is a possibly $S$-dependent parameter. An example of such a problem
would be to estimate the generalization error of a neural network trained on
$n$ examples where $f$ is a loss function. Classically, this problem is
approached through concentration inequalities holding uniformly over compact
parameter sets of functions $f$, for example as in Rademacher or VC type
analysis. However, in many problems, such inequalities often yield numerically
vacuous estimates. Recently, the \emph{PAC-Bayes} framework has been proposed
as a better alternative for this class of problems for its ability to often
give numerically non-vacuous bounds. In this paper, we show that we can do even
better: we show how to refine the proof strategy of the PAC-Bayes bounds and
achieve \emph{even tighter} guarantees. Our approach is based on the
\emph{coin-betting} framework that derives the numerically tightest known
time-uniform concentration inequalities from the regret guarantees of online
gambling algorithms. In particular, we derive the first PAC-Bayes concentration
inequality based on the coin-betting approach that holds simultaneously for all
sample sizes. We demonstrate its tightness showing that by \emph{relaxing} it
we obtain a number of previous results in a closed form including Bernoulli-KL
and empirical Bernstein inequalities. Finally, we propose an efficient
algorithm to numerically calculate confidence sequences from our bound, which
often generates nonvacuous confidence bounds even with one sample, unlike the
state-of-the-art PAC-Bayes bounds.</p>
  </details>
</details>
<details>
  <summary>107. <b>标题：Graph Neural Network-Inspired Kernels for Gaussian Processes in  Semi-Supervised Learning</b></summary>
  <p><b>编号</b>：[336]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05828</p>
  <p><b>作者</b>：Zehao Niu,  Mihai Anitescu,  Jie Chen</p>
  <p><b>备注</b>：ICLR 2023. Code is available at this https URL</p>
  <p><b>关键词</b>：Gaussian processes, machine learning models, simplicity and flexibility, flexibility as building, building blocks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Gaussian processes (GPs) are an attractive class of machine learning models
because of their simplicity and flexibility as building blocks of more complex
Bayesian models. Meanwhile, graph neural networks (GNNs) emerged recently as a
promising class of models for graph-structured data in semi-supervised learning
and beyond. Their competitive performance is often attributed to a proper
capturing of the graph inductive bias. In this work, we introduce this
inductive bias into GPs to improve their predictive performance for
graph-structured data. We show that a prominent example of GNNs, the graph
convolutional network, is equivalent to some GP when its layers are infinitely
wide; and we analyze the kernel universality and the limiting behavior in
depth. We further present a programmable procedure to compose covariance
kernels inspired by this equivalence and derive example kernels corresponding
to several interesting members of the GNN family. We also propose a
computationally efficient approximation of the covariance matrix for scalable
posterior inference with large-scale data. We demonstrate that these
graph-based kernels lead to competitive classification and regression
performance, as well as advantages in computation time, compared with the
respective GNNs.</p>
  </details>
</details>
<details>
  <summary>108. <b>标题：Koopman-Based Bound for Generalization: New Aspect of Neural Networks  Regarding Nonlinear Noise Filtering</b></summary>
  <p><b>编号</b>：[338]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05825</p>
  <p><b>作者</b>：Yuka Hashimoto,  Sho Sonoda,  Isao Ishikawa,  Atsushi Nitanda,  Taiji Suzuki</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：weight matrices, neural networks, Koopman operators, final nonlinear transformation, weight</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose a new bound for generalization of neural networks using Koopman
operators. Unlike most of the existing works, we focus on the role of the final
nonlinear transformation of the networks. Our bound is described by the
reciprocal of the determinant of the weight matrices and is tighter than
existing norm-based bounds when the weight matrices do not have small singular
values. According to existing theories about the low-rankness of the weight
matrices, it may be counter-intuitive that we focus on the case where singular
values of weight matrices are not small. However, motivated by the final
nonlinear transformation, we can see that our result sheds light on a new
perspective regarding a noise filtering property of neural networks. Since our
bound comes from Koopman operators, this work also provides a connection
between operator-theoretic analysis and generalization of neural networks.
Numerical results support the validity of our theoretical results.</p>
  </details>
</details>
<details>
  <summary>109. <b>标题：Data efficiency and extrapolation trends in neural network interatomic  potentials</b></summary>
  <p><b>编号</b>：[340]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05823</p>
  <p><b>作者</b>：Joshua A. Vita,  Daniel Schwalbe-Koda</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：incorporating message-passing networks, neural network interatomic, many-body expansion terms, key architectural advances, network interatomic potentials</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Over the last few years, key architectural advances have been proposed for
neural network interatomic potentials (NNIPs), such as incorporating
message-passing networks, equivariance, or many-body expansion terms. Although
modern NNIP models exhibit nearly negligible differences in energy/forces
errors, improvements in accuracy are still considered the main target when
developing new NNIP architectures. In this work, we investigate how
architectural choices influence the trainability and generalization error in
NNIPs, revealing trends in extrapolation, data efficiency, and loss landscapes.
First, we show that modern NNIP architectures recover the underlying potential
energy surface (PES) of the training data even when trained to corrupted
labels. Second, generalization metrics such as errors on high-temperature
samples from the 3BPA dataset are demonstrated to follow a scaling relation for
a variety of models. Thus, improvements in accuracy metrics may not bring
independent information on the robust generalization of NNIPs. To circumvent
this problem, we relate loss landscapes to model generalization across
datasets. Using this probe, we explain why NNIPs with similar accuracy metrics
exhibit different abilities to extrapolate and how training to forces improves
the optimization landscape of a model. As an example, we show that MACE can
predict PESes with reasonable error after being trained to as few as five data
points, making it an example of a "few-shot" model for learning PESes. On the
other hand, models with similar accuracy metrics such as NequIP show smaller
ability to extrapolate in this extremely low-data regime. Our work provides a
deep learning justification for the performance of many common NNIPs, and
introduces tools beyond accuracy metrics that can be used to inform the
development of next-generation models.</p>
  </details>
</details>
<details>
  <summary>110. <b>标题：Interpretable Diversity Analysis: Visualizing Feature Representations In  Low-Cost Ensembles</b></summary>
  <p><b>编号</b>：[341]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05822</p>
  <p><b>作者</b>：Tim Whitaker,  Darrell Whitley</p>
  <p><b>备注</b>：8 pages, 4 figures, Submitted to IJCNN-23</p>
  <p><b>关键词</b>：robust neural network, construction of robust, robust neural, Diversity, neural network ensembles</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Diversity is an important consideration in the construction of robust neural
network ensembles. A collection of well trained models will generalize better
if they are diverse in the patterns they respond to and the predictions they
make. Diversity is especially important for low-cost ensemble methods because
members often share network structure in order to avoid training several
independent models from scratch. Diversity is traditionally analyzed by
measuring differences between the outputs of models. However, this gives little
insight into how knowledge representations differ between ensemble members.
This paper introduces several interpretability methods that can be used to
qualitatively analyze diversity. We demonstrate these techniques by comparing
the diversity of feature representations between child networks using two
low-cost ensemble algorithms, Snapshot Ensembles and Prune and Tune Ensembles.
We use the same pre-trained parent network as a starting point for both methods
which allows us to explore how feature representations evolve over time. This
approach to diversity analysis can lead to valuable insights and new
perspectives for how we measure and promote diversity in ensemble methods.</p>
  </details>
</details>
<details>
  <summary>111. <b>标题：Synaptic Stripping: How Pruning Can Bring Dead Neurons Back To Life</b></summary>
  <p><b>编号</b>：[342]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05818</p>
  <p><b>作者</b>：Tim Whitaker,  Darrell Whitley</p>
  <p><b>备注</b>：8 pages, 5 figures, Submitted to IJCNN-23</p>
  <p><b>关键词</b>：Rectified Linear Units, Linear Units, Rectified Linear, deep neural networks, default choice</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Rectified Linear Units (ReLU) are the default choice for activation functions
in deep neural networks. While they demonstrate excellent empirical
performance, ReLU activations can fall victim to the dead neuron problem. In
these cases, the weights feeding into a neuron end up being pushed into a state
where the neuron outputs zero for all inputs. Consequently, the gradient is
also zero for all inputs, which means that the weights which feed into the
neuron cannot update. The neuron is not able to recover from direct back
propagation and model capacity is reduced as those parameters can no longer be
further optimized. Inspired by a neurological process of the same name, we
introduce Synaptic Stripping as a means to combat this dead neuron problem. By
automatically removing problematic connections during training, we can
regenerate dead neurons and significantly improve model capacity and parametric
utilization. Synaptic Stripping is easy to implement and results in sparse
networks that are more efficient than the dense networks they are derived from.
We conduct several ablation studies to investigate these dynamics as a function
of network width and depth and we conduct an exploration of Synaptic Stripping
with Vision Transformers on a variety of benchmark datasets.</p>
  </details>
</details>
<details>
  <summary>112. <b>标题：Pushing the Accuracy-Group Robustness Frontier with Introspective  Self-play</b></summary>
  <p><b>编号</b>：[348]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05807</p>
  <p><b>作者</b>：Jeremiah Zhe Liu,  Krishnamurthy Dj Dvijotham,  Jihyeon Lee,  Quan Yuan,  Martin Strobel,  Balaji Lakshminarayanan,  Deepak Ramachandran</p>
  <p><b>备注</b>：Accepted to ICLR 2023. Included additional contribution from Martin Strobel</p>
  <p><b>关键词</b>：Standard empirical risk, empirical risk minimization, under-represented population subgroups, imbalanced group distributions, Standard empirical</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Standard empirical risk minimization (ERM) training can produce deep neural
network (DNN) models that are accurate on average but under-perform in
under-represented population subgroups, especially when there are imbalanced
group distributions in the long-tailed training data. Therefore, approaches
that improve the accuracy-group robustness trade-off frontier of a DNN model
(i.e. improving worst-group accuracy without sacrificing average accuracy, or
vice versa) is of crucial importance. Uncertainty-based active learning (AL)
can potentially improve the frontier by preferentially sampling
underrepresented subgroups to create a more balanced training dataset. However,
the quality of uncertainty estimates from modern DNNs tend to degrade in the
presence of spurious correlations and dataset bias, compromising the
effectiveness of AL for sampling tail groups. In this work, we propose
Introspective Self-play (ISP), a simple approach to improve the uncertainty
estimation of a deep neural network under dataset bias, by adding an auxiliary
introspection task requiring a model to predict the bias for each data point in
addition to the label. We show that ISP provably improves the bias-awareness of
the model representation and the resulting uncertainty estimates. On two
real-world tabular and language tasks, ISP serves as a simple "plug-in" for AL
model training, consistently improving both the tail-group sampling rate and
the final accuracy-fairness trade-off frontier of popular AL methods.</p>
  </details>
</details>
<details>
  <summary>113. <b>标题：Distributional GFlowNets with Quantile Flows</b></summary>
  <p><b>编号</b>：[352]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05793</p>
  <p><b>作者</b>：Dinghuai Zhang,  Ling Pan,  Ricky T. Q. Chen,  Aaron Courville,  Yoshua Bengio</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Generative Flow Networks, generating complex combinatorial, complex combinatorial structure, Flow Networks, decision-making steps</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Generative Flow Networks (GFlowNets) are a new family of probabilistic
samplers where an agent learns a stochastic policy for generating complex
combinatorial structure through a series of decision-making steps. Despite
being inspired from reinforcement learning, the current GFlowNet framework is
relatively limited in its applicability and cannot handle stochasticity in the
reward function. In this work, we adopt a distributional paradigm for
GFlowNets, turning each flow function into a distribution, thus providing more
informative learning signals during training. By parameterizing each edge flow
through their quantile functions, our proposed \textit{quantile matching}
GFlowNet learning algorithm is able to learn a risk-sensitive policy, an
essential component for handling scenarios with risk uncertainty. Moreover, we
find that the distributional approach can achieve substantial improvement on
existing benchmarks compared to prior methods due to our enhanced training
algorithm, even in settings with deterministic rewards.</p>
  </details>
</details>
<details>
  <summary>114. <b>标题：Fairness-aware Multi-view Clustering</b></summary>
  <p><b>编号</b>：[354]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05788</p>
  <p><b>作者</b>：Lecheng Zheng,  Yada Zhu,  Jingrui He</p>
  <p><b>备注</b>：Accepted by SDM23</p>
  <p><b>关键词</b>：label information simultaneously, era of big, data, label information, information simultaneously</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In the era of big data, we are often facing the challenge of data
heterogeneity and the lack of label information simultaneously. In the
financial domain (e.g., fraud detection), the heterogeneous data may include
not only numerical data (e.g., total debt and yearly income), but also text and
images (e.g., financial statement and invoice images). At the same time, the
label information (e.g., fraud transactions) may be missing for building
predictive models. To address these challenges, many state-of-the-art
multi-view clustering methods have been proposed and achieved outstanding
performance. However, these methods typically do not take into consideration
the fairness aspect and are likely to generate biased results using sensitive
information such as race and gender. Therefore, in this paper, we propose a
fairness-aware multi-view clustering method named FairMVC. It incorporates the
group fairness constraint into the soft membership assignment for each cluster
to ensure that the fraction of different groups in each cluster is
approximately identical to the entire data set. Meanwhile, we adopt the idea of
both contrastive learning and non-contrastive learning and propose novel
regularizers to handle heterogeneous data in complex scenarios with missing
data or noisy features. Experimental results on real-world data sets
demonstrate the effectiveness and efficiency of the proposed framework. We also
derive insights regarding the relative performance of the proposed regularizers
in various scenarios.</p>
  </details>
</details>
<details>
  <summary>115. <b>标题：ConCerNet: A Contrastive Learning Based Framework for Automated  Conservation Law Discovery and Trustworthy Dynamical System Prediction</b></summary>
  <p><b>编号</b>：[355]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05783</p>
  <p><b>作者</b>：Wang Zhang,  Tsui-Wei Weng,  Subhro Das,  Alexandre Megretski,  Luca Daniel,  Lam M. Nguyen</p>
  <p><b>备注</b>：22 pages, 7 figures</p>
  <p><b>关键词</b>：shown great capacity, obey physics constraints, Deep neural networks, DNN based dynamics, shown great</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep neural networks (DNN) have shown great capacity of modeling a dynamical
system; nevertheless, they usually do not obey physics constraints such as
conservation laws. This paper proposes a new learning framework named ConCerNet
to improve the trustworthiness of the DNN based dynamics modeling to endow the
invariant properties. ConCerNet consists of two steps: (i) a contrastive
learning method to automatically capture the system invariants (i.e.
conservation properties) along the trajectory observations; (ii) a neural
projection layer to guarantee that the learned dynamics models preserve the
learned invariants. We theoretically prove the functional relationship between
the learned latent representation and the unknown system invariant function.
Experiments show that our method consistently outperforms the baseline neural
networks in both coordinate error and conservation metrics by a large margin.
With neural network based parameterization and no dependence on prior
knowledge, our method can be extended to complex and large-scale dynamics by
leveraging an autoencoder.</p>
  </details>
</details>
<details>
  <summary>116. <b>标题：Predicting municipalities in financial distress: a machine learning  approach enhanced by domain expertise</b></summary>
  <p><b>编号</b>：[356]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05780</p>
  <p><b>作者</b>：Dario Piermarini,  Antonio M. Sudoso,  Veronica Piccialli</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Financial distress, private companies, comparable to bankruptcy, bankruptcy of private, Financial</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Financial distress of municipalities, although comparable to bankruptcy of
private companies, has a far more serious impact on the well-being of
communities. For this reason, it is essential to detect deficits as soon as
possible. Predicting financial distress in municipalities can be a complex
task, as it involves understanding a wide range of factors that can affect a
municipality's financial health. In this paper, we evaluate machine learning
models to predict financial distress in Italian municipalities. Accounting
judiciary experts have specialized knowledge and experience in evaluating the
financial performance of municipalities, and they use a range of financial and
general indicators to make their assessments. By incorporating these indicators
in the feature extraction process, we can ensure that the predictive model is
taking into account a wide range of information that is relevant to the
financial health of municipalities. The results of this study indicate that
using machine learning models in combination with the knowledge of accounting
judiciary experts can aid in the early detection of financial distress in
municipalities, leading to better outcomes for the communities they serve.</p>
  </details>
</details>
<details>
  <summary>117. <b>标题：How to prepare your task head for finetuning</b></summary>
  <p><b>编号</b>：[357]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05779</p>
  <p><b>作者</b>：Yi Ren,  Shangmin Guo,  Wonho Bae,  Danica J. Sutherland</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：transferring information, task head, pretrained network, task head plays, downstream task</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In deep learning, transferring information from a pretrained network to a
downstream task by finetuning has many benefits. The choice of task head plays
an important role in fine-tuning, as the pretrained and downstream tasks are
usually different. Although there exist many different designs for finetuning,
a full understanding of when and why these algorithms work has been elusive. We
analyze how the choice of task head controls feature adaptation and hence
influences the downstream performance. By decomposing the learning dynamics of
adaptation, we find that the key aspect is the training accuracy and loss at
the beginning of finetuning, which determines the "energy" available for the
feature's adaptation. We identify a significant trend in the effect of changes
in this initial energy on the resulting features after fine-tuning.
Specifically, as the energy increases, the Euclidean and cosine distances
between the resulting and original features increase, while their dot products
(and the resulting features' norm) first increase and then decrease. Inspired
by this, we give several practical principles that lead to better downstream
performance. We analytically prove this trend in an overparamterized linear
setting and verify its applicability to different experimental settings.</p>
  </details>
</details>
<details>
  <summary>118. <b>标题：Stochastic Surprisal: An inferential measurement of Free Energy in  Neural Networks</b></summary>
  <p><b>编号</b>：[358]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05776</p>
  <p><b>作者</b>：Mohit Prabhushankar,  Ghassan AlRegib</p>
  <p><b>备注</b>：Paper accepted at Frontiers in Neuroscience</p>
  <p><b>关键词</b>：supervised neural networks, supervised neural, conjectures and validates, neural networks, neural</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper conjectures and validates a framework that allows for action
during inference in supervised neural networks. Supervised neural networks are
constructed with the objective to maximize their performance metric in any
given task. This is done by reducing free energy and its associated surprisal
during training. However, the bottom-up inference nature of supervised networks
is a passive process that renders them fallible to noise. In this paper, we
provide a thorough background of supervised neural networks, both generative
and discriminative, and discuss their functionality from the perspective of
free energy principle. We then provide a framework for introducing action
during inference. We introduce a new measurement called stochastic surprisal
that is a function of the network, the input, and any possible action. This
action can be any one of the outputs that the neural network has learnt,
thereby lending stochasticity to the measurement. Stochastic surprisal is
validated on two applications: Image Quality Assessment and Recognition under
noisy conditions. We show that, while noise characteristics are ignored to make
robust recognition, they are analyzed to estimate image quality scores. We
apply stochastic surprisal on two applications, three datasets, and as a
plug-in on twelve networks. In all, it provides a statistically significant
increase among all measures. We conclude by discussing the implications of the
proposed stochastic surprisal in other areas of cognitive psychology including
expectancy-mismatch and abductive reasoning.</p>
  </details>
</details>
<details>
  <summary>119. <b>标题：Regret Guarantees for Adversarial Online Collaborative Filtering</b></summary>
  <p><b>编号</b>：[361]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05765</p>
  <p><b>作者</b>：Stephen Pasteris,  Fabio Vitale,  Mark Herbster,  Claudio Gentile</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：preference matrix, served content, user-item preference matrix, investigate the problem, online collaborative filtering</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We investigate the problem of online collaborative filtering under
no-repetition constraints, whereby users need to be served content in an online
fashion and a given user cannot be recommended the same content item more than
once. We design and analyze a fully adaptive algorithm that works under
biclustering assumptions on the user-item preference matrix, and show that this
algorithm exhibits an optimal regret guarantee, while being oblivious to any
prior knowledge about the sequence of users, the universe of items, as well as
the biclustering parameters of the preference matrix. We further propose a more
robust version of the algorithm which addresses the scenario when the
preference matrix is adversarially perturbed. We then give regret guarantees
that scale with the amount by which the preference matrix is perturbed from a
biclustered structure. To our knowledge, these are the first results on online
collaborative filtering that hold at this level of generality and adaptivity
under no-repetition constraints.</p>
  </details>
</details>
<details>
  <summary>120. <b>标题：Towards Multi-User Activity Recognition through Facilitated Training  Data and Deep Learning for Human-Robot Collaboration Applications</b></summary>
  <p><b>编号</b>：[362]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05763</p>
  <p><b>作者</b>：Francesco Semeraro,  Jon Carberry,  Angelo Cangelosi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：addressing multi-party scenarios, progressively addressing multi-party, multi-party scenarios, progressively addressing, addressing multi-party</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Human-robot interaction (HRI) research is progressively addressing
multi-party scenarios, where a robot interacts with more than one human user at
the same time. Conversely, research is still at an early stage for human-robot
collaboration (HRC). The use of machine learning techniques to handle such type
of collaboration requires data that are less feasible to produce than in a
typical HRC setup. This work outlines concepts of design of concurrent tasks
for non-dyadic HRC applications. Based upon these concepts, this study also
proposes an alternative way of gathering data regarding multiuser activity, by
collecting data related to single subjects and merging them in post-processing,
to reduce the effort involved in producing recordings of pair settings. To
validate this statement, 3D skeleton poses of activity of single subjects were
collected and merged in pairs. After this, the datapoints were used to
separately train a long short-term memory (LSTM) network and a variational
autoencoder (VAE) composed of spatio-temporal graph convolutional networks
(STGCN) to recognise the joint activities of the pairs of people. The results
showed that it is possible to make use of data collected in this way for pair
HRC settings and get similar performances compared to using data regarding
groups of users recorded under the same settings, relieving from the technical
difficulties involved in producing these data.</p>
  </details>
</details>
<details>
  <summary>121. <b>标题：Interpretable Deep Learning for Forecasting Online Advertising Costs:  Insights from the Competitive Bidding Landscape</b></summary>
  <p><b>编号</b>：[363]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05762</p>
  <p><b>作者</b>：Fynn Oldenburg,  Qiwei Han,  Maximilian Kaiser</p>
  <p><b>备注</b>：Acceptd at AAAI 2023 Web for Advertising Workshop, 12 pages, 8 figures, 4 tables</p>
  <p><b>关键词</b>：marketing campaign returns, optimize marketing campaign, making budget plans, advertisers increasingly shift, campaign returns</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As advertisers increasingly shift their budgets toward digital advertising,
forecasting advertising costs is essential for making budget plans to optimize
marketing campaign returns. In this paper, we perform a comprehensive study
using a variety of time-series forecasting methods to predict daily average
cost-per-click (CPC) in the online advertising market. We show that forecasting
advertising costs would benefit from multivariate models using covariates from
competitors' CPC development identified through time-series clustering. We
further interpret the results by analyzing feature importance and temporal
attention. Finally, we show that our approach has several advantages over
models that individual advertisers might build based solely on their collected
data.</p>
  </details>
</details>
<details>
  <summary>122. <b>标题：Informing clinical assessment by contextualizing post-hoc explanations  of risk prediction models in type-2 diabetes</b></summary>
  <p><b>编号</b>：[368]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05752</p>
  <p><b>作者</b>：Shruthi Chari,  Prasant Acharya,  Daniel M. Gruen,  Olivia Zhang,  Elif K. Eyigoz,  Mohamed Ghalwash,  Oshani Seneviratne,  Fernando Suarez Saiz,  Pablo Meyer,  Prithwish Chakraborty,  Deborah L. McGuinness</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Artificial Intelligence, practitioner connect system, connect system inferences, connect system, greater trust</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Medical experts may use Artificial Intelligence (AI) systems with greater
trust if these are supported by contextual explanations that let the
practitioner connect system inferences to their context of use. However, their
importance in improving model usage and understanding has not been extensively
studied. Hence, we consider a comorbidity risk prediction scenario and focus on
contexts regarding the patients clinical state, AI predictions about their risk
of complications, and algorithmic explanations supporting the predictions. We
explore how relevant information for such dimensions can be extracted from
Medical guidelines to answer typical questions from clinical practitioners. We
identify this as a question answering (QA) task and employ several
state-of-the-art LLMs to present contexts around risk prediction model
inferences and evaluate their acceptability. Finally, we study the benefits of
contextual explanations by building an end-to-end AI pipeline including data
cohorting, AI risk modeling, post-hoc model explanations, and prototyped a
visual dashboard to present the combined insights from different context
dimensions and data sources, while predicting and identifying the drivers of
risk of Chronic Kidney Disease - a common type-2 diabetes comorbidity. All of
these steps were performed in engagement with medical experts, including a
final evaluation of the dashboard results by an expert medical panel. We show
that LLMs, in particular BERT and SciBERT, can be readily deployed to extract
some relevant explanations to support clinical usage. To understand the
value-add of the contextual explanations, the expert panel evaluated these
regarding actionable insights in the relevant clinical setting. Overall, our
paper is one of the first end-to-end analyses identifying the feasibility and
benefits of contextual explanations in a real-world clinical use case.</p>
  </details>
</details>
<details>
  <summary>123. <b>标题：Verifying Generalization in Deep Learning</b></summary>
  <p><b>编号</b>：[370]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05745</p>
  <p><b>作者</b>：Guy Amir,  Osher Maayan,  Tom Zelazny,  Guy Katz,  Michael Schapira</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Deep neural networks, numerous application domains, neural networks, constitutes the state, art in numerous</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep neural networks (DNNs) are the workhorses of deep learning, which
constitutes the state of the art in numerous application domains. However,
DNN-based decision rules are notoriously prone to poor generalization, i.e.,
may prove inadequate on inputs not encountered during training. This limitation
poses a significant obstacle to employing deep learning for mission-critical
tasks, and also in real-world environments that exhibit high variability.
We propose a novel, verification-driven methodology for identifying DNN-based
decision rules that generalize well to new input domains. Our approach
quantifies generalization to an input domain by the extent to which decisions
reached by independently trained DNNs are in agreement for inputs in this
domain. We show how, by harnessing the power of DNN verification, our approach
can be efficiently and effectively realized.
We evaluate our verification-based approach on three deep reinforcement
learning (DRL) benchmarks, including a system for real-world Internet
congestion control. Our results establish the usefulness of our approach, and,
in particular, its superiority over gradient-based methods.
More broadly, our work puts forth a novel objective for formal verification,
with the potential for mitigating the risks associated with deploying DNN-based
systems in the wild.</p>
  </details>
</details>
<details>
  <summary>124. <b>标题：Is Distance Matrix Enough for Geometric Deep Learning?</b></summary>
  <p><b>编号</b>：[372]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05743</p>
  <p><b>作者</b>：Zian Li,  Xiyuan Wang,  Yinan Huang,  Muhan Zhang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：molecular dynamics simulation, Message Passing Neural, Graph Neural Networks, dynamics simulation, distance matrix</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Graph Neural Networks (GNNs) are often used for tasks involving the geometry
of a given graph, such as molecular dynamics simulation. While the distance
matrix of a graph contains the complete geometric structure information,
whether GNNs can learn this geometry solely from the distance matrix has yet to
be studied. In this work, we first demonstrate that Message Passing Neural
Networks (MPNNs) are insufficient for learning the geometry of a graph from its
distance matrix by constructing families of geometric graphs which cannot be
distinguished by MPNNs. We then propose $k$-DisGNNs, which can effectively
exploit the rich geometry contained in the distance matrix. We demonstrate the
high expressive power of our models and prove that some existing well-designed
geometric models can be unified by $k$-DisGNNs as special cases. Most
importantly, we establish a connection between geometric deep learning and
traditional graph representation learning, showing that those highly expressive
GNN models originally designed for graph structure learning can also be applied
to geometric deep learning problems with impressive performance, and that
existing complex, equivariant models are not the only solution. Experimental
results verify our theory.</p>
  </details>
</details>
<details>
  <summary>125. <b>标题：UGAE: A Novel Approach to Non-exponential Discounting</b></summary>
  <p><b>编号</b>：[374]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05740</p>
  <p><b>作者</b>：Ariel Kwiatkowski,  Vicky Kalogeiton,  Julien Pettré,  Marie-Paule Cani</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Reinforcement Learning determines, Reinforcement Learning, mechanism in Reinforcement, Learning determines, discounting</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The discounting mechanism in Reinforcement Learning determines the relative
importance of future and present rewards. While exponential discounting is
widely used in practice, non-exponential discounting methods that align with
human behavior are often desirable for creating human-like agents. However,
non-exponential discounting methods cannot be directly applied in modern
on-policy actor-critic algorithms. To address this issue, we propose Universal
Generalized Advantage Estimation (UGAE), which allows for the computation of
GAE advantage values with arbitrary discounting. Additionally, we introduce
Beta-weighted discounting, a continuous interpolation between exponential and
hyperbolic discounting, to increase flexibility in choosing a discounting
method. To showcase the utility of UGAE, we provide an analysis of the
properties of various discounting methods. We also show experimentally that
agents with non-exponential discounting trained via UGAE outperform variants
trained with Monte Carlo advantage estimation. Through analysis of various
discounting methods and experiments, we demonstrate the superior performance of
UGAE with Beta-weighted discounting over the Monte Carlo baseline on standard
RL benchmarks. UGAE is simple and easily integrated into any advantage-based
algorithm as a replacement for the standard recursive GAE.</p>
  </details>
</details>
<details>
  <summary>126. <b>标题：Cross-Modal Fine-Tuning: Align then Refine</b></summary>
  <p><b>编号</b>：[375]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05738</p>
  <p><b>作者</b>：Junhong Shen,  Liam Li,  Lucio M. Dery,  Corey Staten,  Mikhail Khodak,  Graham Neubig,  Ameet Talwalkar</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：vision and NLP, large-scale pretrained models, led to tremendous, tremendous progress, progress in well-studied</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Fine-tuning large-scale pretrained models has led to tremendous progress in
well-studied modalities such as vision and NLP. However, similar gains have not
been observed in many other modalities due to a lack of relevant pretrained
models. In this work, we propose ORCA, a general cross-modal fine-tuning
framework that extends the applicability of a single large-scale pretrained
model to diverse modalities. ORCA adapts to a target task via an
align-then-refine workflow: given the target input, ORCA first learns an
embedding network that aligns the embedded feature distribution with the
pretraining modality. The pretrained model is then fine-tuned on the embedded
data to exploit the knowledge shared across modalities. Through extensive
experiments, we show that ORCA obtains state-of-the-art results on 3 benchmarks
containing over 60 datasets from 12 modalities, outperforming a wide range of
hand-designed, AutoML, general-purpose, and task-specific methods. We highlight
the importance of data alignment via a series of ablation studies and
demonstrate ORCA's utility in data-limited regimes.</p>
  </details>
</details>
<details>
  <summary>127. <b>标题：A Reparameterized Discrete Diffusion Model for Text Generation</b></summary>
  <p><b>编号</b>：[376]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05737</p>
  <p><b>作者</b>：Lin Zheng,  Jianbo Yuan,  Lei Yu,  Lingpeng Kong</p>
  <p><b>备注</b>：27 pages, 4 figures</p>
  <p><b>关键词</b>：work studies discrete, natural language generation, studies discrete diffusion, discrete diffusion probabilistic, discrete diffusion</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This work studies discrete diffusion probabilistic models with applications
to natural language generation. We derive an alternative yet equivalent
formulation of the sampling from discrete diffusion processes and leverage this
insight to develop a family of reparameterized discrete diffusion models. The
derived generic framework is highly flexible, offers a fresh perspective of the
generation process in discrete diffusion models, and features more effective
training and decoding techniques. We conduct extensive experiments to evaluate
the text generation capability of our model, demonstrating significant
improvements over existing diffusion models.</p>
  </details>
</details>
<details>
  <summary>128. <b>标题：Exploiting Programmatic Behavior of LLMs: Dual-Use Through Standard  Security Attacks</b></summary>
  <p><b>编号</b>：[379]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05733</p>
  <p><b>作者</b>：Daniel Kang,  Xuechen Li,  Ion Stoica,  Carlos Guestrin,  Matei Zaharia,  Tatsunori Hashimoto</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：NLP tasks, large language models, range of NLP, instruction-following large language, Recent advances</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent advances in instruction-following large language models (LLMs) have
led to dramatic improvements in a range of NLP tasks. Unfortunately, we find
that the same improved capabilities amplify the dual-use risks for malicious
purposes of these models. Dual-use is difficult to prevent as
instruction-following capabilities now enable standard attacks from computer
security. The capabilities of these instruction-following LLMs provide strong
economic incentives for dual-use by malicious actors. In particular, we show
that instruction-following LLMs can produce targeted malicious content,
including hate speech and scams, bypassing in-the-wild defenses implemented by
LLM API vendors. Our analysis shows that this content can be generated
economically and at cost likely lower than with human effort alone. Together,
our findings suggest that LLMs will increasingly attract more sophisticated
adversaries and attacks, and addressing these attacks may require new
approaches to mitigations.</p>
  </details>
</details>
<details>
  <summary>129. <b>标题：Sequential Embedding-based Attentive (SEA) classifier for malware  classification</b></summary>
  <p><b>编号</b>：[383]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05728</p>
  <p><b>作者</b>：Muhammad Ahmed,  Anam Qureshi,  Jawwad Ahmed Shamsi,  Murk Marvi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：tremendous growth, growth in smart, uplifted several security, security threats, malware</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The tremendous growth in smart devices has uplifted several security threats.
One of the most prominent threats is malicious software also known as malware.
Malware has the capability of corrupting a device and collapsing an entire
network. Therefore, its early detection and mitigation are extremely important
to avoid catastrophic effects. In this work, we came up with a solution for
malware detection using state-of-the-art natural language processing (NLP)
techniques. Our main focus is to provide a lightweight yet effective classifier
for malware detection which can be used for heterogeneous devices, be it a
resource constraint device or a resourceful machine. Our proposed model is
tested on the benchmark data set with an accuracy and log loss score of 99.13
percent and 0.04 respectively.</p>
  </details>
</details>
<details>
  <summary>130. <b>标题：Learning by Applying: A General Framework for Mathematical Reasoning via  Enhancing Explicit Knowledge Learning</b></summary>
  <p><b>编号</b>：[390]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05717</p>
  <p><b>作者</b>：Jiayu Liu,  Zhenya Huang,  Chengxiang Zhai,  Qi Liu</p>
  <p><b>备注</b>：Accepted by AAAI 2023</p>
  <p><b>关键词</b>：general artificial intelligence, knowledge, master mathematical logic, artificial intelligence, requires machines</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Mathematical reasoning is one of the crucial abilities of general artificial
intelligence, which requires machines to master mathematical logic and
knowledge from solving problems. However, existing approaches are not
transparent (thus not interpretable) in terms of what knowledge has been
learned and applied in the reasoning process. In this paper, we propose a
general Learning by Applying (LeAp) framework to enhance existing models
(backbones) in a principled way by explicit knowledge learning. In LeAp, we
perform knowledge learning in a novel problem-knowledge-expression paradigm,
with a Knowledge Encoder to acquire knowledge from problem data and a Knowledge
Decoder to apply knowledge for expression reasoning. The learned mathematical
knowledge, including word-word relations and word-operator relations, forms an
explicit knowledge graph, which bridges the knowledge "learning" and "applying"
organically. Moreover, for problem solving, we design a semantics-enhanced
module and a reasoning-enhanced module that apply knowledge to improve the
problem comprehension and symbol reasoning abilities of any backbone,
respectively. We theoretically prove the superiority of LeAp's autonomous
learning mechanism. Experiments on three real-world datasets show that LeAp
improves all backbones' performances, learns accurate knowledge, and achieves a
more interpretable reasoning process.</p>
  </details>
</details>
<details>
  <summary>131. <b>标题：Fair Enough: Standardizing Evaluation and Model Selection for Fairness  Research in NLP</b></summary>
  <p><b>编号</b>：[391]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05711</p>
  <p><b>作者</b>：Xudong Han,  Timothy Baldwin,  Trevor Cohn</p>
  <p><b>备注</b>：EACL 2023</p>
  <p><b>关键词</b>：Modern NLP systems, NLP systems exhibit, Modern NLP, NLP systems, model debiasing attempts</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Modern NLP systems exhibit a range of biases, which a growing literature on
model debiasing attempts to correct. However current progress is hampered by a
plurality of definitions of bias, means of quantification, and oftentimes vague
relation between debiasing algorithms and theoretical measures of bias. This
paper seeks to clarify the current situation and plot a course for meaningful
progress in fair learning, with two key contributions: (1) making clear
inter-relations among the current gamut of methods, and their relation to
fairness theory; and (2) addressing the practical problem of model selection,
which involves a trade-off between fairness and accuracy and has led to
systemic issues in fairness research. Putting them together, we make several
recommendations to help shape future work.</p>
  </details>
</details>
<details>
  <summary>132. <b>标题：On Differential Privacy and Adaptive Data Analysis with Bounded Space</b></summary>
  <p><b>编号</b>：[393]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05707</p>
  <p><b>作者</b>：Itai Dinur,  Uri Stemmer,  David P. Woodruff,  Samson Zhou</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：adaptive data analysis, differential privacy, related fields, space complexity, space</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We study the space complexity of the two related fields of differential
privacy and adaptive data analysis. Specifically,
(1) Under standard cryptographic assumptions, we show that there exists a
problem P that requires exponentially more space to be solved efficiently with
differential privacy, compared to the space needed without privacy. To the best
of our knowledge, this is the first separation between the space complexity of
private and non-private algorithms.
(2) The line of work on adaptive data analysis focuses on understanding the
number of samples needed for answering a sequence of adaptive queries. We
revisit previous lower bounds at a foundational level, and show that they are a
consequence of a space bottleneck rather than a sampling bottleneck.
To obtain our results, we define and construct an encryption scheme with
multiple keys that is built to withstand a limited amount of key leakage in a
very particular way.</p>
  </details>
</details>
<details>
  <summary>133. <b>标题：Cross-center Early Sepsis Recognition by Medical Knowledge Guided  Collaborative Learning for Data-scarce Hospitals</b></summary>
  <p><b>编号</b>：[396]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05702</p>
  <p><b>作者</b>：Ruiqing Ding,  Fangjie Rong,  Xiao Han,  Leye Wang</p>
  <p><b>备注</b>：7 pages, 2 figures</p>
  <p><b>关键词</b>：significant regional inequities, significant regional, regional inequities, health, health resources</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>There are significant regional inequities in health resources around the
world. It has become one of the most focused topics to improve health services
for data-scarce hospitals and promote health equity through knowledge sharing
among medical institutions. Because electronic medical records (EMRs) contain
sensitive personal information, privacy protection is unavoidable and essential
for multi-hospital collaboration. In this paper, for a common disease in ICU
patients, sepsis, we propose a novel cross-center collaborative learning
framework guided by medical knowledge, SofaNet, to achieve early recognition of
this disease. The Sepsis-3 guideline, published in 2016, defines that sepsis
can be diagnosed by satisfying both suspicion of infection and Sequential Organ
Failure Assessment (SOFA) greater than or equal to 2. Based on this knowledge,
SofaNet adopts a multi-channel GRU structure to predict SOFA values of
different systems, which can be seen as an auxiliary task to generate better
health status representations for sepsis recognition. Moreover, we only achieve
feature distribution alignment in the hidden space during cross-center
collaborative learning, which ensures secure and compliant knowledge transfer
without raw data exchange. Extensive experiments on two open clinical datasets,
MIMIC-III and Challenge, demonstrate that SofaNet can benefit early sepsis
recognition when hospitals only have limited EMRs.</p>
  </details>
</details>
<details>
  <summary>134. <b>标题：Compositional Exemplars for In-context Learning</b></summary>
  <p><b>编号</b>：[397]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05698</p>
  <p><b>作者</b>：Jiacheng Ye,  Zhiyong Wu,  Jiangtao Feng,  Tao Yu,  Lingpeng Kong</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：shown impressive In-Context, Large pretrained language, Large pretrained, shown impressive, pretrained language models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large pretrained language models (LMs) have shown impressive In-Context
Learning (ICL) ability, where the model learns to do an unseen task via a
prompt consisting of input-output examples as the demonstration, without any
parameter updates. The performance of ICL is highly dominated by the quality of
the selected in-context examples. However, previous selection methods are
mostly based on simple heuristics, leading to sub-optimal performance. In this
work, we formulate in-context example selection as a subset selection problem.
We propose CEIL(Compositional Exemplars for In-context Learning), which is
instantiated by Determinantal Point Processes (DPPs) to model the interaction
between the given input and in-context examples, and optimized through a
carefully-designed contrastive learning objective to obtain preference from
LMs. We validate CEIL on 12 classification and generation datasets from 7
distinct NLP tasks, including sentiment analysis, paraphrase detection, natural
language inference, commonsense reasoning, open-domain question answering, code
generation, and semantic parsing. Extensive experiments demonstrate not only
the state-of-the-art performance but also the transferability and
compositionality of CEIL, shedding new light on effective and efficient
in-context learning. Our code is released at
this https URL.</p>
  </details>
</details>
<details>
  <summary>135. <b>标题：Vertical Federated Knowledge Transfer via Representation Distillation  for Healthcare Collaboration Networks</b></summary>
  <p><b>编号</b>：[405]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05675</p>
  <p><b>作者</b>：Chung-ju Huang,  Leye Wang,  Xiao Han</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：geographic areas, significantly lessen, lessen the imbalance, federated, healthcare institutions</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Collaboration between healthcare institutions can significantly lessen the
imbalance in medical resources across various geographic areas. However,
directly sharing diagnostic information between institutions is typically not
permitted due to the protection of patients' highly sensitive privacy. As a
novel privacy-preserving machine learning paradigm, federated learning (FL)
makes it possible to maximize the data utility among multiple medical
institutions. These feature-enrichment FL techniques are referred to as
vertical FL (VFL). Traditional VFL can only benefit multi-parties' shared
samples, which strongly restricts its application scope. In order to improve
the information-sharing capability and innovation of various healthcare-related
institutions, and then to establish a next-generation open medical
collaboration network, we propose a unified framework for vertical federated
knowledge transfer mechanism (VFedTrans) based on a novel cross-hospital
representation distillation component. Specifically, our framework includes
three steps. First, shared samples' federated representations are extracted by
collaboratively modeling multi-parties' joint features with current efficient
vertical federated representation learning methods. Second, for each hospital,
we learn a local-representation-distilled module, which can transfer the
knowledge from shared samples' federated representations to enrich local
samples' representations. Finally, each hospital can leverage local samples'
representations enriched by the distillation module to boost arbitrary
downstream machine learning tasks. The experiments on real-life medical
datasets verify the knowledge transfer effectiveness of our framework.</p>
  </details>
</details>
<details>
  <summary>136. <b>标题：Jaccard Metric Losses: Optimizing the Jaccard Index with Soft Labels</b></summary>
  <p><b>编号</b>：[409]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05666</p>
  <p><b>作者</b>：Zifu Wang,  Matthew B. Blaschko</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：soft Jaccard loss, Jaccard index, Jaccard index measure, Jaccard, soft Jaccard</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>IoU losses are surrogates that directly optimize the Jaccard index. In
semantic segmentation, IoU losses are shown to perform better with respect to
the Jaccard index measure than pixel-wise losses such as the cross-entropy
loss. The most notable IoU losses are the soft Jaccard loss and the
Lovasz-Softmax loss. However, these losses are incompatible with soft labels
which are ubiquitous in machine learning. In this paper, we propose Jaccard
metric losses (JMLs), which are variants of the soft Jaccard loss, and are
compatible with soft labels. With JMLs, we study two of the most popular use
cases of soft labels: label smoothing and knowledge distillation. With a
variety of architectures, our experiments show significant improvements over
the cross-entropy loss on three semantic segmentation datasets (Cityscapes,
PASCAL VOC and DeepGlobe Land), and our simple approach outperforms
state-of-the-art knowledge distillation methods by a large margin. Our source
code is available at:
\href{this https URL}{this https URL}.</p>
  </details>
</details>
<details>
  <summary>137. <b>标题：DocILE Benchmark for Document Information Localization and Extraction</b></summary>
  <p><b>编号</b>：[413]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05658</p>
  <p><b>作者</b>：Štěpán Šimsa,  Milan Šulc,  Michal Uřičář,  Yash Patel,  Ahmed Hamdi,  Matěj Kocián,  Matyáš Skalický,  Jiří Matas,  Antoine Doucet,  Mickaël Coustaty,  Dimosthenis Karatzas</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Key Information Localization, Line Item Recognition, Information Localization, Line Item, Key Information</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper introduces the DocILE benchmark with the largest dataset of
business documents for the tasks of Key Information Localization and Extraction
and Line Item Recognition. It contains 6.7k annotated business documents, 100k
synthetically generated documents, and nearly~1M unlabeled documents for
unsupervised pre-training. The dataset has been built with knowledge of domain-
and task-specific aspects, resulting in the following key features: (i)
annotations in 55 classes, which surpasses the granularity of previously
published key information extraction datasets by a large margin; (ii) Line Item
Recognition represents a highly practical information extraction task, where
key information has to be assigned to items in a table; (iii) documents come
from numerous layouts and the test set includes zero- and few-shot cases as
well as layouts commonly seen in the training set. The benchmark comes with
several baselines, including RoBERTa, LayoutLMv3 and DETR-based Table
Transformer. These baseline models were applied to both tasks of the DocILE
benchmark, with results shared in this paper, offering a quick starting point
for future work. The dataset and baselines are available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>138. <b>标题：SLOTH: Structured Learning and Task-based Optimization for Time Series  Forecasting on Hierarchies</b></summary>
  <p><b>编号</b>：[415]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05650</p>
  <p><b>作者</b>：Fan Zhou,  Chen Pan,  Lintao Ma,  Yu Liu,  Shiyu Wang,  James Zhang,  Xinxin Zhu,  Xuanwei Hu,  Yunhua Hu,  Yangfei Zheng,  Lei Lei,  Yun Hu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：geographical hierarchy formed, Multivariate time series, hierarchical time series, sales predictions, formed by cities</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Multivariate time series forecasting with hierarchical structure is widely
used in real-world applications, e.g., sales predictions for the geographical
hierarchy formed by cities, states, and countries. The hierarchical time series
(HTS) forecasting includes two sub-tasks, i.e., forecasting and reconciliation.
In the previous works, hierarchical information is only integrated in the
reconciliation step to maintain coherency, but not in forecasting step for
accuracy improvement. In this paper, we propose two novel tree-based feature
integration mechanisms, i.e., top-down convolution and bottom-up attention to
leverage the information of the hierarchical structure to improve the
forecasting performance. Moreover, unlike most previous reconciliation methods
which either rely on strong assumptions or focus on coherent constraints
only,we utilize deep neural optimization networks, which not only achieve
coherency without any assumptions, but also allow more flexible and realistic
constraints to achieve task-based targets, e.g., lower under-estimation penalty
and meaningful decision-making loss to facilitate the subsequent downstream
tasks. Experiments on real-world datasets demonstrate that our tree-based
feature integration mechanism achieves superior performances on hierarchical
forecasting tasks compared to the state-of-the-art methods, and our neural
optimization networks can be applied to real-world tasks effectively without
any additional effort under coherence and task-based constraints</p>
  </details>
</details>
<details>
  <summary>139. <b>标题：Meta-Learning Based Knowledge Extrapolation for Temporal Knowledge Graph</b></summary>
  <p><b>编号</b>：[418]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05640</p>
  <p><b>作者</b>：Zhongwu Chen,  Chengjin Xu,  Fenglong Su,  Zhen Huang,  You Dou</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Knowledge Graph, Knowledge Graph Extrapolation, temporal knowledge graph, completion via learning, surge of interest</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In the last few years, the solution to Knowledge Graph (KG) completion via
learning embeddings of entities and relations has attracted a surge of
interest. Temporal KGs(TKGs) extend traditional Knowledge Graphs (KGs) by
associating static triples with timestamps forming quadruples. Different from
KGs and TKGs in the transductive setting, constantly emerging entities and
relations in incomplete TKGs create demand to predict missing facts with unseen
components, which is the extrapolation setting. Traditional temporal knowledge
graph embedding (TKGE) methods are limited in the extrapolation setting since
they are trained within a fixed set of components. In this paper, we propose a
Meta-Learning based Temporal Knowledge Graph Extrapolation (MTKGE) model, which
is trained on link prediction tasks sampled from the existing TKGs and tested
in the emerging TKGs with unseen entities and relations. Specifically, we
meta-train a GNN framework that captures relative position patterns and
temporal sequence patterns between relations. The learned embeddings of
patterns can be transferred to embed unseen components. Experimental results on
two different TKG extrapolation datasets show that MTKGE consistently
outperforms both the existing state-of-the-art models for knowledge graph
extrapolation and specifically adapted KGE and TKGE baselines.</p>
  </details>
</details>
<details>
  <summary>140. <b>标题：Operation-level Progressive Differentiable Architecture Search</b></summary>
  <p><b>编号</b>：[421]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05632</p>
  <p><b>作者</b>：Xunyu Zhu,  Jian Li,  Yong Liu,  Weiping Wang</p>
  <p><b>备注</b>：To appear in ICDM 2021</p>
  <p><b>关键词</b>：Neural Architecture Search, low compute cost, Differentiable Neural Architecture, high search efficiency, Neural Architecture</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Differentiable Neural Architecture Search (DARTS) is becoming more and more
popular among Neural Architecture Search (NAS) methods because of its high
search efficiency and low compute cost. However, the stability of DARTS is very
inferior, especially skip connections aggregation that leads to performance
collapse. Though existing methods leverage Hessian eigenvalues to alleviate
skip connections aggregation, they make DARTS unable to explore architectures
with better performance. In the paper, we propose operation-level progressive
differentiable neural architecture search (OPP-DARTS) to avoid skip connections
aggregation and explore better architectures simultaneously. We first divide
the search process into several stages during the search phase and increase
candidate operations into the search space progressively at the beginning of
each stage. It can effectively alleviate the unfair competition between
operations during the search phase of DARTS by offsetting the inherent unfair
advantage of the skip connection over other operations. Besides, to keep the
competition between operations relatively fair and select the operation from
the candidate operations set that makes training loss of the supernet largest.
The experiment results indicate that our method is effective and efficient. Our
method's performance on CIFAR-10 is superior to the architecture found by
standard DARTS, and the transferability of our method also surpasses standard
DARTS. We further demonstrate the robustness of our method on three simple
search spaces, i.e., S2, S3, S4, and the results show us that our method is
more robust than standard DARTS. Our code is available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>141. <b>标题：A Survey on Spectral Graph Neural Networks</b></summary>
  <p><b>编号</b>：[422]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05631</p>
  <p><b>作者</b>：Deyu Bo,  Xiao Wang,  Yang Liu,  Yuan Fang,  Yawen Li,  Chuan Shi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：attracted considerable attention, spectral GNNs, Graph neural networks, GNNs, spectral</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Graph neural networks (GNNs) have attracted considerable attention from the
research community. It is well established that GNNs are usually roughly
divided into spatial and spectral methods. Despite that spectral GNNs play an
important role in both graph signal processing and graph representation
learning, existing studies are biased toward spatial approaches, and there is
no comprehensive review on spectral GNNs so far. In this paper, we summarize
the recent development of spectral GNNs, including model, theory, and
application. Specifically, we first discuss the connection between spatial GNNs
and spectral GNNs, which shows that spectral GNNs can capture global
information and have better expressiveness and interpretability. Next, we
categorize existing spectral GNNs according to the spectrum information they
use, \ie, eigenvalues or eigenvectors. In addition, we review major theoretical
results and applications of spectral GNNs, followed by a quantitative
experiment to benchmark some popular spectral GNNs. Finally, we conclude the
paper with some future directions.</p>
  </details>
</details>
<details>
  <summary>142. <b>标题：CILP: Co-simulation based Imitation Learner for Dynamic Resource  Provisioning in Cloud Computing Environments</b></summary>
  <p><b>编号</b>：[423]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05630</p>
  <p><b>作者</b>：Shreshth Tuli,  Giuliano Casale,  Nicholas R. Jennings</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Intelligent Virtual Machine, Virtual Machine, Intelligent Virtual, cloud computing environments, resource efficient computation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Intelligent Virtual Machine (VM) provisioning is central to cost and resource
efficient computation in cloud computing environments. As bootstrapping VMs is
time-consuming, a key challenge for latency-critical tasks is to predict future
workload demands to provision VMs proactively. However, existing AI-based
solutions \blue{tend to not holistically consider} all crucial aspects such as
provisioning overheads, heterogeneous VM costs and Quality of Service (QoS) of
the cloud system. To address this, we propose a novel method, called CILP, that
formulates the VM provisioning problem as two sub-problems of prediction and
optimization, where the provisioning plan is optimized based on predicted
workload demands. CILP leverages a neural network as a surrogate model to
predict future workload demands with a co-simulated digital-twin of the
infrastructure to compute QoS scores. We extend the neural network to also act
as an imitation learner that dynamically decides the optimal VM provisioning
plan. A transformer based neural model reduces training and inference overheads
while our novel two-phase decision making loop facilitates in making informed
provisioning decisions. Crucially, we address limitations of prior work by
including resource utilization, deployment costs and provisioning overheads to
inform the provisioning decisions in our imitation learning framework.
Experiments with three public benchmarks demonstrate that CILP gives up to 22%
higher resource utilization, 14% higher QoS scores and 44% lower execution
costs compared to the current online and offline optimization based
state-of-the-art methods.</p>
  </details>
</details>
<details>
  <summary>143. <b>标题：Improving Differentiable Architecture Search via Self-Distillation</b></summary>
  <p><b>编号</b>：[424]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05629</p>
  <p><b>作者</b>：Xunyu Zhu,  Jian Li,  Yong Liu,  Weiping Wang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Architecture Search, Differentiable Architecture Search, Neural Architecture Search, Architecture, optimal architecture</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Differentiable Architecture Search (DARTS) is a simple yet efficient Neural
Architecture Search (NAS) method. During the search stage, DARTS trains a
supernet by jointly optimizing architecture parameters and network parameters.
During the evaluation stage, DARTS derives the optimal architecture based on
architecture parameters. However, the loss landscape of the supernet is not
smooth, and it results in a performance gap between the supernet and the
optimal architecture. In the paper, we propose Self-Distillation Differentiable
Neural Architecture Search (SD-DARTS) by utilizing self-distillation to
transfer knowledge of the supernet in previous steps to guide the training of
the supernet in the current steps. SD-DARTS can minimize the loss difference
for the two consecutive iterations so that minimize the sharpness of the
supernet's loss to bridge the performance gap between the supernet and the
optimal architecture. Furthermore, we propose voted teachers, which select
multiple previous supernets as teachers and vote teacher output probabilities
as the final teacher prediction. The knowledge of several teachers is more
abundant than a single teacher, thus, voted teachers can be more suitable to
lead the training of the supernet. Experimental results on real datasets
illustrate the advantages of our novel self-distillation-based NAS method
compared to state-of-the-art alternatives.</p>
  </details>
</details>
<details>
  <summary>144. <b>标题：A novel approach to generate datasets with XAI ground truth to evaluate  image models</b></summary>
  <p><b>编号</b>：[426]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05624</p>
  <p><b>作者</b>：Miquel Miró-Nicolau,  Antoni Jaume-i-Capó,  Gabriel Moyà-Alcover</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：models work internally, eXplainable artificial intelligence, artificial intelligence, work internally, increased usage</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>With the increased usage of artificial intelligence (AI), it is imperative to
understand how these models work internally. These needs have led to the
development of a new field called eXplainable artificial intelligence (XAI).
This field consists of on a set of techniques that allows us to theoretically
determine the cause of the AI decisions. One unsolved question about XAI is how
to measure the quality of explanations. In this study, we propose a new method
to generate datasets with ground truth (GT). These datasets allow us to measure
how faithful is a method without ad hoc solutions. We conducted a set of
experiments that compared our GT with real model explanations and obtained
excellent results confirming that our proposed method is correct.</p>
  </details>
</details>
<details>
  <summary>145. <b>标题：Improved Dynamic Regret for Online Frank-Wolfe</b></summary>
  <p><b>编号</b>：[429]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05620</p>
  <p><b>作者</b>：Yuanyu Wan,  Lijun Zhang,  Mingli Song</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：dynamic regret bound, dynamic regret, efficient projection-free algorithm, OFW, regret bound</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>To deal with non-stationary online problems with complex constraints, we
investigate the dynamic regret of online Frank-Wolfe (OFW), which is an
efficient projection-free algorithm for online convex optimization. It is
well-known that in the setting of offline optimization, the smoothness of
functions and the strong convexity of functions accompanying specific
properties of constraint sets can be utilized to achieve fast convergence rates
for the Frank-Wolfe (FW) algorithm. However, for OFW, previous studies only
establish a dynamic regret bound of $O(\sqrt{T}(1+V_T+\sqrt{D_T}))$ by
utilizing the convexity of problems, where $T$ is the number of rounds, $V_T$
is the function variation, and $D_T$ is the gradient variation. In this paper,
we derive improved dynamic regret bounds for OFW by extending the fast
convergence rates of FW from offline optimization to online optimization. The
key technique for this extension is to set the step size of OFW with a line
search rule. In this way, we first show that the dynamic regret bound of OFW
can be improved to $O(\sqrt{T(1+V_T)})$ for smooth functions. Second, we
achieve a better dynamic regret bound of $O((1+V_T)^{2/3}T^{1/3})$ when
functions are smooth and strongly convex, and the constraint set is strongly
convex. Finally, for smooth and strongly convex functions with minimizers in
the interior of the constraint set, we demonstrate that the dynamic regret of
OFW reduces to $O(1+V_T)$, and can be further strengthened to
$O(\min\{P_T^\ast,S_T^\ast,V_T\}+1)$ by performing a constant number of FW
iterations per round, where $P_T^\ast$ and $S_T^\ast$ denote the path length
and squared path length of minimizers, respectively.</p>
  </details>
</details>
<details>
  <summary>146. <b>标题：Cross-domain Random Pre-training with Prototypes for Reinforcement  Learning</b></summary>
  <p><b>编号</b>：[434]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05614</p>
  <p><b>作者</b>：Xin Liu,  Yaran Chen,  Haoran Li,  Boyu Li,  Dongbin Zhao</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：shows great potential, pre-training shows great, shows great, great potential, cross-domain</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Task-agnostic cross-domain pre-training shows great potential in image-based
Reinforcement Learning (RL) but poses a big challenge. In this paper, we
propose CRPTpro, a Cross-domain self-supervised Random Pre-Training framework
with prototypes for image-based RL. CRPTpro employs cross-domain random policy
to easily and quickly sample diverse data from multiple domains, to improve
pre-training efficiency. Moreover, prototypical representation learning with a
novel intrinsic loss is proposed to pre-train an effective and generic encoder
across different domains. Without finetuning, the cross-domain encoder can be
implemented for challenging downstream visual-control RL tasks defined in
different domains efficiently. Compared with prior arts like APT and Proto-RL,
CRPTpro achieves better performance on cross-domain downstream RL tasks without
extra training on exploration agents for expert data collection, greatly
reducing the burden of pre-training. Experiments on DeepMind Control suite
(DMControl) demonstrate that CRPTpro outperforms APT significantly on 11/12
cross-domain RL tasks with only 39% pre-training hours, becoming a
state-of-the-art cross-domain pre-training method in both policy learning
performance and pre-training efficiency. The complete code will be released at
this https URL.</p>
  </details>
</details>
<details>
  <summary>147. <b>标题：Emotion Detection From Social Media Posts</b></summary>
  <p><b>编号</b>：[436]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05610</p>
  <p><b>作者</b>：Md Mahbubur Rahman,  Shaila Shova</p>
  <p><b>备注</b>：Course Project</p>
  <p><b>关键词</b>：expressing personal views, personal views, political proposals, social media, Support Vector Machines</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Over the last few years, social media has evolved into a medium for
expressing personal views, emotions, and even business and political proposals,
recommendations, and advertisements. We address the topic of identifying
emotions from text data obtained from social media posts like Twitter in this
research. We have deployed different traditional machine learning techniques
such as Support Vector Machines (SVM), Naive Bayes, Decision Trees, and Random
Forest, as well as deep neural network models such as LSTM, CNN, GRU, BiLSTM,
BiGRU to classify these tweets into four emotion categories (Fear, Anger, Joy,
and Sadness). Furthermore, we have constructed a BiLSTM and BiGRU ensemble
model. The evaluation result shows that the deep neural network models(BiGRU,
to be specific) produce the most promising results compared to traditional
machine learning models, with an 87.53 % accuracy rate. The ensemble model
performs even better (87.66 %), albeit the difference is not significant. This
result will aid in the development of a decision-making tool that visualizes
emotional fluctuations.</p>
  </details>
</details>
<details>
  <summary>148. <b>标题：Predicting Participants' Performance in Programming Contests using Deep  Learning Techniques</b></summary>
  <p><b>编号</b>：[440]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05602</p>
  <p><b>作者</b>：Md Mahbubur Rahman,  Badhan Chandra Das,  Al Amin Biswas,  Md. Musfique Anwar</p>
  <p><b>备注</b>：Camera Ready Version</p>
  <p><b>关键词</b>：recent days, increasing day, number of technology, technology enthusiasts, enthusiasts is increasing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In recent days, the number of technology enthusiasts is increasing day by day
with the prevalence of technological products and easy access to the internet.
Similarly, the amount of people working behind this rapid development is rising
tremendously. Computer programmers consist of a large portion of those
tech-savvy people. Codeforces, an online programming and contest hosting
platform used by many competitive programmers worldwide. It is regarded as one
of the most standardized platforms for practicing programming problems and
participate in programming contests. In this research, we propose a framework
that predicts the performance of any particular contestant in the upcoming
competitions as well as predicts the rating after that contest based on their
practice and the performance of their previous contests.</p>
  </details>
</details>
<details>
  <summary>149. <b>标题：Pruning Deep Neural Networks from a Sparsity Perspective</b></summary>
  <p><b>编号</b>：[441]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05601</p>
  <p><b>作者</b>：Enmao Diao,  Ganghua Wang,  Jiawei Zhan,  Yuhong Yang,  Jie Ding,  Vahid Tarokh</p>
  <p><b>备注</b>：ICLR 2023</p>
  <p><b>关键词</b>：attracted significant attention, recent years, memory constraints, attention in order, order to enable</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In recent years, deep network pruning has attracted significant attention in
order to enable the rapid deployment of AI into small devices with computation
and memory constraints. Pruning is often achieved by dropping redundant
weights, neurons, or layers of a deep network while attempting to retain a
comparable test performance. Many deep pruning algorithms have been proposed
with impressive empirical success. However, existing approaches lack a
quantifiable measure to estimate the compressibility of a sub-network during
each pruning iteration and thus may under-prune or over-prune the model. In
this work, we propose PQ Index (PQI) to measure the potential compressibility
of deep neural networks and use this to develop a Sparsity-informed Adaptive
Pruning (SAP) algorithm. Our extensive experiments corroborate the hypothesis
that for a generic pruning procedure, PQI decreases first when a large model is
being effectively regularized and then increases when its compressibility
reaches a limit that appears to correspond to the beginning of underfitting.
Subsequently, PQI decreases again when the model collapse and significant
deterioration in the performance of the model start to occur. Additionally, our
experiments demonstrate that the proposed adaptive pruning algorithm with
proper choice of hyper-parameters is superior to the iterative pruning
algorithms such as the lottery ticket-based pruning methods, in terms of both
compression efficiency and robustness.</p>
  </details>
</details>
<details>
  <summary>150. <b>标题：Communication and Storage Efficient Federated Split Learning</b></summary>
  <p><b>编号</b>：[442]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05599</p>
  <p><b>作者</b>：Yujia Mu,  Cong Shen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：distributed machine learning, popular distributed machine, device computation capabilities, edge device computation, Federated Split Learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Federated learning (FL) is a popular distributed machine learning (ML)
paradigm, but is often limited by significant communication costs and edge
device computation capabilities. Federated Split Learning (FSL) preserves the
parallel model training principle of FL, with a reduced device computation
requirement thanks to splitting the ML model between the server and clients.
However, FSL still incurs very high communication overhead due to transmitting
the smashed data and gradients between the clients and the server in each
global round. Furthermore, the server has to maintain separate models for every
client, resulting in a significant computation and storage requirement that
grows linearly with the number of clients. This paper tries to solve these two
issues by proposing a communication and storage efficient federated and split
learning (CSE-FSL) strategy, which utilizes an auxiliary network to locally
update the client models while keeping only a single model at the server, hence
avoiding the communication of gradients from the server and greatly reducing
the server resource requirement. Communication cost is further reduced by only
sending the smashed data in selected epochs from the clients. We provide a
rigorous theoretical analysis of CSE-FSL that guarantees its convergence for
non-convex loss functions. Extensive experimental results demonstrate that
CSE-FSL has a significant communication reduction over existing FSL techniques
while achieving state-of-the-art convergence and model accuracy, using several
real-world FL tasks.</p>
  </details>
</details>
<details>
  <summary>151. <b>标题：ReMIX: Regret Minimization for Monotonic Value Function Factorization in  Multiagent Reinforcement Learning</b></summary>
  <p><b>编号</b>：[445]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05593</p>
  <p><b>作者</b>：Yongsheng Mei,  Hanhan Zhou,  Tian Lan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：decentralized execution paradigm, cooperative multiagent reinforcement, multiagent reinforcement learning, monotonic mixing functions, execution paradigm</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Value function factorization methods have become a dominant approach for
cooperative multiagent reinforcement learning under a centralized training and
decentralized execution paradigm. By factorizing the optimal joint action-value
function using a monotonic mixing function of agents' utilities, these
algorithms ensure the consistency between joint and local action selections for
decentralized decision-making. Nevertheless, the use of monotonic mixing
functions also induces representational limitations. Finding the optimal
projection of an unrestricted mixing function onto monotonic function classes
is still an open problem. To this end, we propose ReMIX, formulating this
optimal projection problem for value function factorization as a regret
minimization over the projection weights of different state-action values. Such
an optimization problem can be relaxed and solved using the Lagrangian
multiplier method to obtain the close-form optimal projection weights. By
minimizing the resulting policy regret, we can narrow the gap between the
optimal and the restricted monotonic mixing functions, thus obtaining an
improved monotonic value function factorization. Our experimental results on
Predator-Prey and StarCraft Multiagent Challenge environments demonstrate the
effectiveness of our method, indicating the better capabilities of handling
environments with non-monotonic value functions.</p>
  </details>
</details>
<details>
  <summary>152. <b>标题：Hierarchical Optimization-Derived Learning</b></summary>
  <p><b>编号</b>：[446]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05587</p>
  <p><b>作者</b>：Risheng Liu,  Xuan Liu,  Shangzhi Zeng,  Jin Zhang,  Yixuan Zhang</p>
  <p><b>备注</b>：15 pages</p>
  <p><b>关键词</b>：address diverse learning, utilizing optimization techniques, existing ODL methods, ODL methods, ODL</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In recent years, by utilizing optimization techniques to formulate the
propagation of deep model, a variety of so-called Optimization-Derived Learning
(ODL) approaches have been proposed to address diverse learning and vision
tasks. Although having achieved relatively satisfying practical performance,
there still exist fundamental issues in existing ODL methods. In particular,
current ODL methods tend to consider model construction and learning as two
separate phases, and thus fail to formulate their underlying coupling and
depending relationship. In this work, we first establish a new framework, named
Hierarchical ODL (HODL), to simultaneously investigate the intrinsic behaviors
of optimization-derived model construction and its corresponding learning
process. Then we rigorously prove the joint convergence of these two sub-tasks,
from the perspectives of both approximation quality and stationary analysis. To
our best knowledge, this is the first theoretical guarantee for these two
coupled ODL components: optimization and learning. We further demonstrate the
flexibility of our framework by applying HODL to challenging learning tasks,
which have not been properly addressed by existing ODL methods. Finally, we
conduct extensive experiments on both synthetic data and real applications in
vision and other learning tasks to verify the theoretical properties and
practical performance of HODL in various application scenarios.</p>
  </details>
</details>
<details>
  <summary>153. <b>标题：A large parametrized space of meta-reinforcement learning tasks</b></summary>
  <p><b>编号</b>：[447]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05583</p>
  <p><b>作者</b>：Thomas Miconi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：tasks, arbitrary stimuli, meta-RL tasks, describe a parametrized, meta-RL</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We describe a parametrized space for simple meta-reinforcement-learning
(meta-RL) tasks with arbitrary stimuli. The parametrization allows us to
randomly generate an arbitrary number of novel simple meta-learning tasks. The
space of meta-RL tasks covered by this parametrization includes many well-known
meta-RL tasks, such as bandit tasks, the Harlow task, T-mazes, the Daw two-step
task and others. Simple extensions allow it to capture tasks based on
two-dimensional topological spaces, such as find-the-spot or key-door tasks. We
describe a number of randomly generated meta-RL tasks and discuss potential
issues arising from random generation.</p>
  </details>
</details>
<details>
  <summary>154. <b>标题：MSDC: Exploiting Multi-State Power Consumption in Non-intrusive Load  Monitoring based on A Dual-CNN Model</b></summary>
  <p><b>编号</b>：[455]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05565</p>
  <p><b>作者</b>：Jialing He,  Jiamou Liu,  Zijian Zhang,  Yang Chen,  Yiwei Liu,  Bakh Khoussainov,  Liehuang Zhu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Non-intrusive load monitoring, source separation tasks, decompose aggregated electrical, aggregated electrical usage, blind source separation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Non-intrusive load monitoring (NILM) aims to decompose aggregated electrical
usage signal into appliance-specific power consumption and it amounts to a
classical example of blind source separation tasks. Leveraging recent progress
on deep learning techniques, we design a new neural NILM model Multi-State Dual
CNN (MSDC). Different from previous models, MSDC explicitly extracts
information about the appliance's multiple states and state transitions, which
in turn regulates the prediction of signals for appliances. More specifically,
we employ a dual-CNN architecture: one CNN for outputting state distributions
and the other for predicting the power of each state. A new technique is
invented that utilizes conditional random fields (CRF) to capture state
transitions. Experiments on two real-world datasets REDD and UK-DALE
demonstrate that our model significantly outperform state-of-the-art models
while having good generalization capacity, achieving 6%-10% MAE gain and
33%-51% SAE gain to unseen appliances.</p>
  </details>
</details>
<details>
  <summary>155. <b>标题：PDSum: Prototype-driven Continuous Summarization of Evolving  Multi-document Sets Stream</b></summary>
  <p><b>编号</b>：[461]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05550</p>
  <p><b>作者</b>：Susik Yoon,  Hou Pong Chan,  Jiawei Han</p>
  <p><b>备注</b>：Accepted by WWW'23</p>
  <p><b>关键词</b>：evolving multi-document sets, multi-document set, predefined multi-document set, multi-document, long studied</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Summarizing text-rich documents has been long studied in the literature, but
most of the existing efforts have been made to summarize a static and
predefined multi-document set. With the rapid development of online platforms
for generating and distributing text-rich documents, there arises an urgent
need for continuously summarizing dynamically evolving multi-document sets
where the composition of documents and sets is changing over time. This is
especially challenging as the summarization should be not only effective in
incorporating relevant, novel, and distinctive information from each concurrent
multi-document set, but also efficient in serving online applications. In this
work, we propose a new summarization problem, Evolving Multi-Document sets
stream Summarization (EMDS), and introduce a novel unsupervised algorithm PDSum
with the idea of prototype-driven continuous summarization. PDSum builds a
lightweight prototype of each multi-document set and exploits it to adapt to
new documents while preserving accumulated knowledge from previous documents.
To update new summaries, the most representative sentences for each
multi-document set are extracted by measuring their similarities to the
prototypes. A thorough evaluation with real multi-document sets streams
demonstrates that PDSum outperforms state-of-the-art unsupervised
multi-document summarization algorithms in EMDS in terms of relevance, novelty,
and distinctiveness and is also robust to various evaluation settings.</p>
  </details>
</details>
<details>
  <summary>156. <b>标题：Privacy Against Agnostic Inference Attack in Vertical Federated Learning</b></summary>
  <p><b>编号</b>：[463]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05545</p>
  <p><b>作者</b>：Morteza Varasteh</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：vertical federated learning, active party, passive party, party, inference attack</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A novel form of inference attack in vertical federated learning (VFL) is
proposed, where two parties collaborate in training a machine learning (ML)
model. Logistic regression is considered for the VFL model. One party, referred
to as the active party, possesses the ground truth labels of the samples in the
training phase, while the other, referred to as the passive party, only shares
a separate set of features corresponding to these samples. It is shown that the
active party can carry out inference attacks on both training and prediction
phase samples by acquiring an ML model independently trained on the training
samples available to them. This type of inference attack does not require the
active party to be aware of the score of a specific sample, hence it is
referred to as an agnostic inference attack. It is shown that utilizing the
observed confidence scores during the prediction phase, before the time of the
attack, can improve the performance of the active party's autonomous model, and
thus improve the quality of the agnostic inference attack. As a countermeasure,
privacy-preserving schemes (PPSs) are proposed. While the proposed schemes
preserve the utility of the VFL model, they systematically distort the VFL
parameters corresponding to the passive party's features. The level of the
distortion imposed on the passive party's parameters is adjustable, giving rise
to a trade-off between privacy of the passive party and interpretabiliy of the
VFL outcomes by the active party. The distortion level of the passive party's
parameters could be chosen carefully according to the privacy and
interpretabiliy concerns of the passive and active parties, respectively, with
the hope of keeping both parties (partially) satisfied. Finally, experimental
results demonstrate the effectiveness of the proposed attack and the PPSs.</p>
  </details>
</details>
<details>
  <summary>157. <b>标题：Robust Knowledge Transfer in Tiered Reinforcement Learning</b></summary>
  <p><b>编号</b>：[468]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05534</p>
  <p><b>作者</b>：Jiawei Huang,  Niao He</p>
  <p><b>备注</b>：56 Pages</p>
  <p><b>关键词</b>：Tiered Reinforcement Learning, Tiered Reinforcement, Reinforcement Learning setting, parallel transfer learning, transfer learning framework</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we study the Tiered Reinforcement Learning setting, a parallel
transfer learning framework, where the goal is to transfer knowledge from the
low-tier (source) task to the high-tier (target) task to reduce the exploration
risk of the latter while solving the two tasks in parallel. Unlike previous
work, we do not assume the low-tier and high-tier tasks share the same dynamics
or reward functions, and focus on robust knowledge transfer without prior
knowledge on the task similarity. We identify a natural and necessary condition
called the "Optimal Value Dominance" for our objective. Under this condition,
we propose novel online learning algorithms such that, for the high-tier task,
it can achieve constant regret on partial states depending on the task
similarity and retain near-optimal regret when the two tasks are dissimilar,
while for the low-tier task, it can keep near-optimal without making sacrifice.
Moreover, we further study the setting with multiple low-tier tasks, and
propose a novel transfer source selection mechanism, which can ensemble the
information from all low-tier tasks and allow provable benefits on a much
larger state-action space.</p>
  </details>
</details>
<details>
  <summary>158. <b>标题：Machine Learning Based Approach to Recommend MITRE ATT&CK Framework for  Software Requirements and Design Specifications</b></summary>
  <p><b>编号</b>：[469]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05530</p>
  <p><b>作者</b>：Nicholas Lasky,  Benjamin Hallis,  Mounika Vanamala,  Rushit Dave,  Jim Seliya</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：software, cyber world, secure software, critical challenge, Common Weakness Enumeration</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Engineering more secure software has become a critical challenge in the cyber
world. It is very important to develop methodologies, techniques, and tools for
developing secure software. To develop secure software, software developers
need to think like an attacker through mining software repositories. These aim
to analyze and understand the data repositories related to software
development. The main goal is to use these software repositories to support the
decision-making process of software development. There are different
vulnerability databases like Common Weakness Enumeration (CWE), Common
Vulnerabilities and Exposures database (CVE), and CAPEC. We utilized a database
called MITRE. MITRE ATT&CK tactics and techniques have been used in various
ways and methods, but tools for utilizing these tactics and techniques in the
early stages of the software development life cycle (SDLC) are lacking. In this
paper, we use machine learning algorithms to map requirements to the MITRE
ATT&CK database and determine the accuracy of each mapping depending on the
data split.</p>
  </details>
</details>
<details>
  <summary>159. <b>标题：CodeBERTScore: Evaluating Code Generation with Pretrained Models of Code</b></summary>
  <p><b>编号</b>：[471]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05527</p>
  <p><b>作者</b>：Shuyan Zhou,  Uri Alon,  Sumit Agarwal,  Graham Neubig</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：generate long expressions, single next-token, rise of neural, generate long, long expressions</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Since the rise of neural models of code that can generate long expressions
and statements rather than a single next-token, one of the major problems has
been reliably evaluating their generated output. In this paper, we propose
CodeBERTScore: an automatic evaluation metric for code generation, which builds
on BERTScore (Zhang et al., 2020). Instead of measuring exact token matching as
BLEU, CodeBERTScore computes a soft similarity score between each token in the
generated code and in the reference code, using the contextual encodings of
large pretrained models. Further, instead of encoding only the generated tokens
as in BERTScore, CodeBERTScore also encodes the programmatic context
surrounding the generated code. We perform an extensive evaluation of
CodeBERTScore across four programming languages. We find that CodeBERTScore
achieves a higher correlation with human preference and with functional
correctness than all existing metrics. That is, generated code that receives a
higher score by CodeBERTScore is more likely to be preferred by humans, as well
as to function correctly when executed. Finally, while CodeBERTScore can be
used with a multilingual CodeBERT as its base model, we release five
language-specific pretrained models to use with our publicly available code at
this https URL . Our language-specific models have
been downloaded more than 25,000 times from the Huggingface Hub.</p>
  </details>
</details>
<details>
  <summary>160. <b>标题：Satellite Anomaly Detection Using Variance Based Genetic Ensemble of  Neural Networks</b></summary>
  <p><b>编号</b>：[473]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05525</p>
  <p><b>作者</b>：Mohammad Amin Maleki Sadr,  Yeying Zhu,  Peng Hu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：multiple Recurrent Neural, variance-based genetic ensemble, Recurrent Neural, VGE, variance-based genetic</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we use a variance-based genetic ensemble (VGE) of Neural
Networks (NNs) to detect anomalies in the satellite's historical data. We use
an efficient ensemble of the predictions from multiple Recurrent Neural
Networks (RNNs) by leveraging each model's uncertainty level (variance). For
prediction, each RNN is guided by a Genetic Algorithm (GA) which constructs the
optimal structure for each RNN model. However, finding the model uncertainty
level is challenging in many cases. Although the Bayesian NNs (BNNs)-based
methods are popular for providing the confidence bound of the models, they
cannot be employed in complex NN structures as they are computationally
intractable. This paper uses the Monte Carlo (MC) dropout as an approximation
version of BNNs. Then these uncertainty levels and each predictive model
suggested by GA are used to generate a new model, which is then used for
forecasting the TS and AD. Simulation results show that the forecasting and AD
capability of the ensemble model outperforms existing approaches.</p>
  </details>
</details>
<details>
  <summary>161. <b>标题：FairPy: A Toolkit for Evaluation of Social Biases and their Mitigation  in Large Language Models</b></summary>
  <p><b>编号</b>：[480]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05508</p>
  <p><b>作者</b>：Hrishikesh Viswanath,  Tianyi Zhang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：social groups based, Studies have shown, social groups, groups based, pretrained language models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Studies have shown that large pretrained language models exhibit biases
against social groups based on race, gender etc, which they inherit from the
datasets they are trained on. Various researchers have proposed mathematical
tools for quantifying and identifying these biases. There have been methods
proposed to mitigate such biases. In this paper, we present a comprehensive
quantitative evaluation of different kinds of biases such as race, gender,
ethnicity, age etc. exhibited by popular pretrained language models such as
BERT, GPT-2 etc. and also present a toolkit that provides plug-and-play
interfaces to connect mathematical tools to identify biases with large
pretrained language models such as BERT, GPT-2 etc. and also present users with
the opportunity to test custom models against these metrics. The toolkit also
allows users to debias existing and custom models using the debiasing
techniques proposed so far. The toolkit is available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>162. <b>标题：Long-Context Language Decision Transformers and Exponential Tilt for  Interactive Text Environments</b></summary>
  <p><b>编号</b>：[481]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05507</p>
  <p><b>作者</b>：Nicolas Gontier,  Pau Rodriguez,  Issam Laradji,  David Vazquez,  Christopher Pal</p>
  <p><b>备注</b>：12 pages, 5 figures, 3 tables</p>
  <p><b>关键词</b>：execute compositional actions, Text-based game environments, execute compositional, compositional actions, learn from sparse</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Text-based game environments are challenging because agents must deal with
long sequences of text, execute compositional actions using text and learn from
sparse rewards. We address these challenges by proposing Long-Context Language
Decision Transformers (LLDTs), a framework that is based on long transformer
language models and decision transformers (DTs). LLDTs extend DTs with 3
components: (1) exponential tilt to guide the agent towards high obtainable
goals, (2) novel goal conditioning methods yielding significantly better
results than the traditional return-to-go (sum of all future rewards), and (3)
a model of future observations. Our ablation results show that predicting
future observations improves agent performance. To the best of our knowledge,
LLDTs are the first to address offline RL with DTs on these challenging games.
Our experiments show that LLDTs achieve the highest scores among many different
types of agents on some of the most challenging Jericho games, such as
Enchanter.</p>
  </details>
</details>
<details>
  <summary>163. <b>标题：CUDA: Curriculum of Data Augmentation for Long-Tailed Recognition</b></summary>
  <p><b>编号</b>：[484]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05499</p>
  <p><b>作者</b>：Sumyeong Ahn,  Jongwoo Ko,  Se-Young Yun</p>
  <p><b>备注</b>：ICLR'23 Spotlight, 23 pages</p>
  <p><b>关键词</b>：problems frequently occur, conventional deep learning, deep learning algorithms, imbalance problems frequently, real-world tasks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Class imbalance problems frequently occur in real-world tasks, and
conventional deep learning algorithms are well known for performance
degradation on imbalanced training datasets. To mitigate this problem, many
approaches have aimed to balance among given classes by re-weighting or
re-sampling training samples. These re-balancing methods increase the impact of
minority classes and reduce the influence of majority classes on the output of
models. However, the extracted representations may be of poor quality owing to
the limited number of minority samples. To handle this restriction, several
methods have been developed that increase the representations of minority
samples by leveraging the features of the majority samples. Despite extensive
recent studies, no deep analysis has been conducted on determination of classes
to be augmented and strength of augmentation has been conducted. In this study,
we first investigate the correlation between the degree of augmentation and
class-wise performance, and find that the proper degree of augmentation must be
allocated for each class to mitigate class imbalance problems. Motivated by
this finding, we propose a simple and efficient novel curriculum, which is
designed to find the appropriate per-class strength of data augmentation,
called CUDA: CUrriculum of Data Augmentation for long-tailed recognition. CUDA
can simply be integrated into existing long-tailed recognition methods. We
present the results of experiments showing that CUDA effectively achieves
better generalization performance compared to the state-of-the-art method on
various imbalanced datasets such as CIFAR-100-LT, ImageNet-LT, and iNaturalist
2018.</p>
  </details>
</details>
<details>
  <summary>164. <b>标题：Element-Wise Attention Layers: an option for optimization</b></summary>
  <p><b>编号</b>：[488]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05488</p>
  <p><b>作者</b>：Giovanni Araujo Bacochina,  Rodrigo Clemente Thom de Souza</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Deep Learning Field, Attention Layers, Transformer-based models, recent years, key element</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The use of Attention Layers has become a trend since the popularization of
the Transformer-based models, being the key element for many state-of-the-art
models that have been developed through recent years. However, one of the
biggest obstacles in implementing these architectures - as well as many others
in Deep Learning Field - is the enormous amount of optimizing parameters they
possess, which make its use conditioned on the availability of robust hardware.
In this paper, it's proposed a new method of attention mechanism that adapts
the Dot-Product Attention, which uses matrices multiplications, to become
element-wise through the use of arrays multiplications. To test the
effectiveness of such approach, two models (one with a VGG-like architecture
and one with the proposed method) have been trained in a classification task
using Fashion MNIST and CIFAR10 datasets. Each model has been trained for 10
epochs in a single Tesla T4 GPU from Google Colaboratory. The results show that
this mechanism allows for an accuracy of 92% of the VGG-like counterpart in
Fashion MNIST dataset, while reducing the number of parameters in 97%. For
CIFAR10, the accuracy is still equivalent to 60% of the VGG-like counterpart
while using 50% less parameters.</p>
  </details>
</details>
<details>
  <summary>165. <b>标题：Brain Effective Connectome based on fMRI and DTI Data: Bayesian Causal  Learning and Assessment</b></summary>
  <p><b>编号</b>：[493]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05451</p>
  <p><b>作者</b>：Abdolmahdi Bagheri,  Mahdi Dehshiri,  Yamin Bagheri,  Alireza Akhondi-Asl,  Babak Nadjar Araabi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：brain Effective Connectome, Human Connectome Project, reliable brain Effective, Effective Connectome, brain Effective</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The ambitious goal of neuroscientific studies is to find an accurate and
reliable brain Effective Connectome (EC). Although current EC discovery methods
have contributed to our understanding of brain organization, their performances
are severely constrained by the short sample size and poor temporal resolution
of fMRI data, and high dimensionality of the brain connectome. By leveraging
the DTI data as prior knowledge, we introduce two Bayesian casual discovery
frameworks -- the Bayesian GOLEM (BGOLEM) and Bayesian FGES (BFGES) methods --
as the most reliable and accurate methods in discovering EC that address the
shortcomings of the current causal discovery methods in discovering ECs based
on only fMRI data. Through a series of simulation studies on synthetic and
hybrid (DTI of the Human Connectome Project (HCP) subjects and synthetic fMRI)
data, we first demonstrate the effectiveness and importance of the proposed
methods in discovering EC. We also introduce the Pseudo False Discovery Rate
(PFDR) as a new accuracy metric for causal discovery in the brain and show that
our Bayesian methods achieve higher accuracy than traditional methods on
empirical data (DTI and fMRI of the Human Connectome Project (HCP) subjects).
Additionally, we measure the reliability of discovered ECs using the
Rogers-Tanimoto index for test-retest data and show that our Bayesian methods
provide significantly more reproducible ECs compared to traditional methods.</p>
  </details>
</details>
<details>
  <summary>166. <b>标题：Robust Scheduling with GFlowNets</b></summary>
  <p><b>编号</b>：[497]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05446</p>
  <p><b>作者</b>：David W. Zhang,  Corrado Rainone,  Markus Peschl,  Roberto Bondesan</p>
  <p><b>备注</b>：An earlier version appeared at the NeurIPS 2022 workshop ML4Systems</p>
  <p><b>关键词</b>：classical NP-hard problem, classical NP-hard, schedule operations, target hardware, NP-hard problem</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Finding the best way to schedule operations in a computation graph is a
classical NP-hard problem which is central to compiler optimization. However,
evaluating the goodness of a schedule on the target hardware can be very
time-consuming. Traditional approaches as well as previous machine learning
ones typically optimize proxy metrics, which are fast to evaluate but can lead
to bad schedules when tested on the target hardware. In this work, we propose a
new approach to scheduling by sampling proportionally to the proxy metric using
a novel GFlowNet method. We introduce a technique to control the trade-off
between diversity and goodness of the proposed schedules at inference time and
demonstrate empirically that the pure optimization baselines can lead to subpar
performance with respect to our approach when tested on a target model.
Furthermore, we show that conditioning the GFlowNet on the computation graph
enables generalization to unseen scheduling problems for both synthetic and
real-world compiler datasets.</p>
  </details>
</details>
<details>
  <summary>167. <b>标题：Kernel Ridge Regression Inference</b></summary>
  <p><b>编号</b>：[498]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06578</p>
  <p><b>作者</b>：Rahul Singh,  Suhas Vijaykumar</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：finite sample guarantees, uniform confidence bands, provide uniform confidence, kernel ridge regression, uniform confidence</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We provide uniform confidence bands for kernel ridge regression (KRR), with
finite sample guarantees. KRR is ubiquitous, yet--to our knowledge--this paper
supplies the first exact, uniform confidence bands for KRR in the
non-parametric regime where the regularization parameter $\lambda$ converges to
0, for general data distributions. Our proposed uniform confidence band is
based on a new, symmetrized multiplier bootstrap procedure with a closed form
solution, which allows for valid uncertainty quantification without assumptions
on the bias. To justify the procedure, we derive non-asymptotic, uniform
Gaussian and bootstrap couplings for partial sums in a reproducing kernel
Hilbert space (RKHS) with bounded kernel. Our results imply strong
approximation for empirical processes indexed by the RKHS unit ball, with
sharp, logarithmic dependence on the covering number.</p>
  </details>
</details>
<details>
  <summary>168. <b>标题：Beyond Uniform Smoothness: A Stopped Analysis of Adaptive SGD</b></summary>
  <p><b>编号</b>：[500]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06570</p>
  <p><b>作者</b>：Matthew Faw,  Litu Rout,  Constantine Caramanis,  Sanjay Shakkottai</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：first-order stationary point, potentially unbounded smoothness, finding a first-order, first-order stationary, stationary point</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This work considers the problem of finding a first-order stationary point of
a non-convex function with potentially unbounded smoothness constant using a
stochastic gradient oracle. We focus on the class of $(L_0,L_1)$-smooth
functions proposed by Zhang et al. (ICLR'20). Empirical evidence suggests that
these functions more closely captures practical machine learning problems as
compared to the pervasive $L_0$-smoothness. This class is rich enough to
include highly non-smooth functions, such as $\exp(L_1 x)$ which is
$(0,\mathcal{O}(L_1))$-smooth. Despite the richness, an emerging line of works
achieves the $\widetilde{\mathcal{O}}(\frac{1}{\sqrt{T}})$ rate of convergence
when the noise of the stochastic gradients is deterministically and uniformly
bounded. This noise restriction is not required in the $L_0$-smooth setting,
and in many practical settings is either not satisfied, or results in weaker
convergence rates with respect to the noise scaling of the convergence rate.
We develop a technique that allows us to prove
$\mathcal{O}(\frac{\mathrm{poly}\log(T)}{\sqrt{T}})$ convergence rates for
$(L_0,L_1)$-smooth functions without assuming uniform bounds on the noise
support. The key innovation behind our results is a carefully constructed
stopping time $\tau$ which is simultaneously "large" on average, yet also
allows us to treat the adaptive step sizes before $\tau$ as (roughly)
independent of the gradients. For general $(L_0,L_1)$-smooth functions, our
analysis requires the mild restriction that the multiplicative noise parameter
$\sigma_1 < 1$. For a broad subclass of $(L_0,L_1)$-smooth functions, our
convergence rate continues to hold when $\sigma_1 \geq 1$. By contrast, we
prove that many algorithms analyzed by prior works on $(L_0,L_1)$-smooth
optimization diverge with constant probability even for smooth and
strongly-convex functions when $\sigma_1 > 1$.</p>
  </details>
</details>
<details>
  <summary>169. <b>标题：Between Generating Noise and Generating Images: Noise in the Correct  Frequency Improves the Quality of Synthetic Histopathology Images for Digital  Pathology</b></summary>
  <p><b>编号</b>：[501]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06549</p>
  <p><b>作者</b>：Nati Daniel,  Eliel Aknin,  Ariel Larey,  Yoni Peretz,  Guy Sela,  Yael Fisher,  Yonatan Savir</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：machine learning techniques, Synthetic images, Artificial intelligence, digital pathology, intelligence and machine</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Artificial intelligence and machine learning techniques have the promise to
revolutionize the field of digital pathology. However, these models demand
considerable amounts of data, while the availability of unbiased training data
is limited. Synthetic images can augment existing datasets, to improve and
validate AI algorithms. Yet, controlling the exact distribution of cellular
features within them is still challenging. One of the solutions is harnessing
conditional generative adversarial networks that take a semantic mask as an
input rather than a random noise. Unlike other domains, outlining the exact
cellular structure of tissues is hard, and most of the input masks depict
regions of cell types. However, using polygon-based masks introduce inherent
artifacts within the synthetic images - due to the mismatch between the polygon
size and the single-cell size. In this work, we show that introducing random
single-pixel noise with the appropriate spatial frequency into a polygon
semantic mask can dramatically improve the quality of the synthetic images. We
used our platform to generate synthetic images of immunohistochemistry-treated
lung biopsies. We test the quality of the images using a three-fold validation
procedure. First, we show that adding the appropriate noise frequency yields
87% of the similarity metrics improvement that is obtained by adding the actual
single-cell features. Second, we show that the synthetic images pass the Turing
test. Finally, we show that adding these synthetic images to the train set
improves AI performance in terms of PD-L1 semantic segmentation performances.
Our work suggests a simple and powerful approach for generating synthetic data
on demand to unbias limited datasets to improve the algorithms' accuracy and
validate their robustness.</p>
  </details>
</details>
<details>
  <summary>170. <b>标题：DEPAS: De-novo Pathology Semantic Masks using a Generative Model</b></summary>
  <p><b>编号</b>：[502]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06513</p>
  <p><b>作者</b>：Ariel Larey,  Nati Daniel,  Eliel Aknin,  Yael Fisher,  Yonatan Savir</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：semantic masks, diagnostic decision-making, integration of artificial, artificial intelligence, intelligence into digital</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The integration of artificial intelligence into digital pathology has the
potential to automate and improve various tasks, such as image analysis and
diagnostic decision-making. Yet, the inherent variability of tissues, together
with the need for image labeling, lead to biased datasets that limit the
generalizability of algorithms trained on them. One of the emerging solutions
for this challenge is synthetic histological images. However, debiasing real
datasets require not only generating photorealistic images but also the ability
to control the features within them. A common approach is to use generative
methods that perform image translation between semantic masks that reflect
prior knowledge of the tissue and a histological image. However, unlike other
image domains, the complex structure of the tissue prevents a simple creation
of histology semantic masks that are required as input to the image translation
model, while semantic masks extracted from real images reduce the process's
scalability. In this work, we introduce a scalable generative model, coined as
DEPAS, that captures tissue structure and generates high-resolution semantic
masks with state-of-the-art quality. We demonstrate the ability of DEPAS to
generate realistic semantic maps of tissue for three types of organs: skin,
prostate, and lung. Moreover, we show that these masks can be processed using a
generative image translation model to produce photorealistic histology images
of two types of cancer with two different types of staining techniques.
Finally, we harness DEPAS to generate multi-label semantic masks that capture
different cell types distributions and use them to produce histological images
with on-demand cellular features. Overall, our work provides a state-of-the-art
solution for the challenging task of generating synthetic histological images
while controlling their semantic information in a scalable way.</p>
  </details>
</details>
<details>
  <summary>171. <b>标题：Outlier-Based Domain of Applicability Identification for Materials  Property Prediction Models</b></summary>
  <p><b>编号</b>：[508]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06454</p>
  <p><b>作者</b>：Gihan Panapitiya,  Emily Saldanha</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：material property prediction, widely applied, Machine learning models, Machine learning, learning model predictions</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Machine learning models have been widely applied for material property
prediction. However, practical application of these models can be hindered by a
lack of information about how well they will perform on previously unseen types
of materials. Because machine learning model predictions depend on the quality
of the available training data, different domains of the material feature space
are predicted with different accuracy levels by such models. The ability to
identify such domains enables the ability to find the confidence level of each
prediction, to determine when and how the model should be employed depending on
the prediction accuracy requirements of different tasks, and to improve the
model for domains with high errors. In this work, we propose a method to find
domains of applicability using a large feature space and also introduce
analysis techniques to gain more insight into the detected domains and
subdomains.</p>
  </details>
</details>
<details>
  <summary>172. <b>标题：Deep Anatomical Federated Network (Dafne): an open client/server  framework for the continuous collaborative improvement of deep-learning-based  medical image segmentation</b></summary>
  <p><b>编号</b>：[517]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06352</p>
  <p><b>作者</b>：Francesco Santini,  Jakob Wasserthal,  Abramo Agosti,  Xeni Deligianni,  Kevin R. Keene,  Hermien E. Kan,  Stefan Sommer,  Christoph Stuprich,  Fengdan Wang,  Claudia Weidensteiner,  Giulia Manco,  Valentina Mazzoli,  Arjun Desai,  Anna Pichiecchio</p>
  <p><b>备注</b>：10 pages (main body), 5 figures. Work partially presented at the 2021 RSNA conference and at the 2023 ISMRM conference</p>
  <p><b>关键词</b>：extract quantitative information, clinical research, images to aid, diagnostic process, crucial step</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Semantic segmentation is a crucial step to extract quantitative information
from medical (and, specifically, radiological) images to aid the diagnostic
process, clinical follow-up. and to generate biomarkers for clinical research.
In recent years, machine learning algorithms have become the primary tool for
this task. However, its real-world performance is heavily reliant on the
comprehensiveness of training data. Dafne is the first decentralized,
collaborative solution that implements continuously evolving deep learning
models exploiting the collective knowledge of the users of the system. In the
Dafne workflow, the result of each automated segmentation is refined by the
user through an integrated interface, so that the new information is used to
continuously expand the training pool via federated incremental learning. The
models deployed through Dafne are able to improve their performance over time
and to generalize to data types not seen in the training sets, thus becoming a
viable and practical solution for real-life medical segmentation tasks.</p>
  </details>
</details>
<details>
  <summary>173. <b>标题：CholecTriplet2022: Show me a tool and tell me the triplet -- an  endoscopic vision challenge for surgical action triplet detection</b></summary>
  <p><b>编号</b>：[520]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06294</p>
  <p><b>作者</b>：Chinedu Innocent Nwoye,  Tong Yu,  Saurav Sharma,  Aditya Murali,  Deepak Alapatt,  Armine Vardazaryan,  Kun Yuan,  Jonas Hajek,  Wolfgang Reiter,  Amine Yamlahi,  Finn-Henri Smidt,  Xiaoyang Zou,  Guoyan Zheng,  Bruno Oliveira,  Helena R. Torres,  Satoshi Kondo,  Satoshi Kasai,  Felix Holm,  Ege Özsoy,  Shuangchun Gui,  Han Li,  Sista Raviteja,  Rachana Sathish,  Pranav Poudel,  Binod Bhattarai,  Ziheng Wang,  Guo Rui,  Melanie Schellenberg,  João L. Vilaça,  Tobias Czempiel,  Zhenkun Wang,  Debdoot Sheet,  Shrawan Kumar Thapa,  Max Berniker,  Patrick Godau,  Pedro Morais,  Sudarshan Regmi,  Thuy Nuong Tran,  Jaime Fonseca,  Jan-Hinrich Nölke,  Estevão Lima,  Eduard Vazquez,  Lena Maier-Hein,  Nassir Navab,  Pietro Mascagni,  Barbara Seeliger,  Cristians Gonzalez,  Didier Mutter,  Nicolas Padoy</p>
  <p><b>备注</b>：MICCAI EndoVis CholecTriplet2022 challenge report. Submitted to journal of Medical Image Analysis. 22 pages, 14 figures, 6 tables</p>
  <p><b>关键词</b>：gold standard approach, Formalizing surgical activities, Artificial Intelligence assistance, gold standard, standard approach</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Formalizing surgical activities as triplets of the used instruments, actions
performed, and target anatomies is becoming a gold standard approach for
surgical activity modeling. The benefit is that this formalization helps to
obtain a more detailed understanding of tool-tissue interaction which can be
used to develop better Artificial Intelligence assistance for image-guided
surgery. Earlier efforts and the CholecTriplet challenge introduced in 2021
have put together techniques aimed at recognizing these triplets from surgical
footage. Estimating also the spatial locations of the triplets would offer a
more precise intraoperative context-aware decision support for
computer-assisted intervention. This paper presents the CholecTriplet2022
challenge, which extends surgical action triplet modeling from recognition to
detection. It includes weakly-supervised bounding box localization of every
visible surgical instrument (or tool), as the key actors, and the modeling of
each tool-activity in the form of <instrument, verb, target> triplet. The paper
describes a baseline method and 10 new deep learning algorithms presented at
the challenge to solve the task. It also provides thorough methodological
comparisons of the methods, an in-depth analysis of the obtained results, their
significance, and useful insights for future research directions and
applications in surgery.</instrument,></p>
  </details>
</details>
<details>
  <summary>174. <b>标题：Precise Asymptotic Analysis of Deep Random Feature Models</b></summary>
  <p><b>编号</b>：[526]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06210</p>
  <p><b>作者</b>：David Bosch,  Ashkan Panahi,  Babak Hassibi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：non-linear activation functions, deep random feature, provide exact asymptotic, exact asymptotic expressions, multiple random embedding</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We provide exact asymptotic expressions for the performance of regression by
an $L-$layer deep random feature (RF) model, where the input is mapped through
multiple random embedding and non-linear activation functions. For this
purpose, we establish two key steps: First, we prove a novel universality
result for RF models and deterministic data, by which we demonstrate that a
deep random feature model is equivalent to a deep linear Gaussian model that
matches it in the first and second moments, at each layer. Second, we make use
of the convex Gaussian Min-Max theorem multiple times to obtain the exact
behavior of deep RF models. We further characterize the variation of the
eigendistribution in different layers of the equivalent Gaussian model,
demonstrating that depth has a tangible effect on model performance despite the
fact that only the last layer of the model is being trained.</p>
  </details>
</details>
<details>
  <summary>175. <b>标题：Restoring the saturation response of a PMT using pulse-shape and  artificial-neural-networks</b></summary>
  <p><b>编号</b>：[527]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06170</p>
  <p><b>作者</b>：Hyun-Gi Lee,  Jungsic Park,  Byeongsu Yang</p>
  <p><b>备注</b>：10 pages, 8 figures</p>
  <p><b>关键词</b>：photomultiplier tube, neutrino energy, required property, property for photon, photon counting</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The linear response of a photomultiplier tube (PMT) is a required property
for photon counting and reconstruction of the neutrino energy. The linearity
valid region and the saturation response of PMT were investigated using a
linear-alkyl-benzene (LAB)-based liquid scintillator. A correlation was
observed between the two different saturation responses, with pulse-shape
distortion and pulse-area decrease. The observed pulse-shape provides useful
information for the estimation of the linearity region relative to the
pulse-area. This correlation-based diagnosis allows an ${in}$-${situ}$
estimation of the linearity range, which was previously challenging. The
measured correlation between the two saturation responses was employed to train
an artificial-neural-network (ANN) to predict the decrease in pulse-area from
the observed pulse-shape. The ANN-predicted pulse-area decrease enables the
prediction of the ideal number of photoelectrons irrelevant to the saturation
behavior. This pulse-shape-based machine learning technique offers a novel
method for restoring the saturation response of PMTs.</p>
  </details>
</details>
<details>
  <summary>176. <b>标题：Knowledge from Large-Scale Protein Contact Prediction Models Can Be  Transferred to the Data-Scarce RNA Contact Prediction Task</b></summary>
  <p><b>编号</b>：[529]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06120</p>
  <p><b>作者</b>：Yiren Jian,  Chongyang Gao,  Chen Zeng,  Yunjie Zhao,  Soroush Vosoughi</p>
  <p><b>备注</b>：The code is available at this https URL</p>
  <p><b>关键词</b>：RNA contact prediction, plays an important, biological activities, RNA contact, functionality is largely</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>RNA, whose functionality is largely determined by its structure, plays an
important role in many biological activities. The prediction of pairwise
structural proximity between each nucleotide of an RNA sequence can
characterize the structural information of the RNA. Historically, this problem
has been tackled by machine learning models using expert-engineered features
and trained on scarce labeled datasets. Here, we find that the knowledge
learned by a protein-coevolution Transformer-based deep neural network can be
transferred to the RNA contact prediction task. As protein datasets are orders
of magnitude larger than those for RNA contact prediction, our findings and the
subsequent framework greatly reduce the data scarcity bottleneck. Experiments
confirm that RNA contact prediction through transfer learning using a publicly
available protein model is greatly improved. Our findings indicate that the
learned structural patterns of proteins can be transferred to RNAs, opening up
potential new avenues for research.</p>
  </details>
</details>
<details>
  <summary>177. <b>标题：A Graphical Point Process Framework for Understanding Removal Effects in  Multi-Touch Attribution</b></summary>
  <p><b>编号</b>：[531]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06075</p>
  <p><b>作者</b>：Jun Tao,  Qian Chen,  James W. Snyder Jr.,  Arava Sai Kumar,  Amirhossein Meisami,  Lingzhou Xue</p>
  <p><b>备注</b>：38 pages, 10 figures</p>
  <p><b>关键词</b>：online advertising channels, individual touchpoints contribute, Marketers employ, measuring the degree, attribution</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Marketers employ various online advertising channels to reach customers, and
they are particularly interested in attribution for measuring the degree to
which individual touchpoints contribute to an eventual conversion. The
availability of individual customer-level path-to-purchase data and the
increasing number of online marketing channels and types of touchpoints bring
new challenges to this fundamental problem. We aim to tackle the attribution
problem with finer granularity by conducting attribution at the path level. To
this end, we develop a novel graphical point process framework to study the
direct conversion effects and the full relational structure among numerous
types of touchpoints simultaneously. Utilizing the temporal point process of
conversion and the graphical structure, we further propose graphical
attribution methods to allocate proper path-level conversion credit, called the
attribution score, to individual touchpoints or corresponding channels for each
customer's path to purchase. Our proposed attribution methods consider the
attribution score as the removal effect, and we use the rigorous probabilistic
definition to derive two types of removal effects. We examine the performance
of our proposed methods in extensive simulation studies and compare their
performance with commonly used attribution models. We also demonstrate the
performance of the proposed methods in a real-world attribution application.</p>
  </details>
</details>
<details>
  <summary>178. <b>标题：Isotopic envelope identification by analysis of the spatial distribution  of components in MALDI-MSI data</b></summary>
  <p><b>编号</b>：[532]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06051</p>
  <p><b>作者</b>：Anna Glodek,  Joanna Polańska,  Marta Gawin</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：identification of proteins, structure of proteins, significant steps, obtaining information, mass spectrometry</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>One of the significant steps in the process leading to the identification of
proteins is mass spectrometry, which allows for obtaining information about the
structure of proteins. Removing isotope peaks from the mass spectrum is vital
and it is done in a process called deisotoping. There are different algorithms
for deisotoping, but they have their limitations, they are dedicated to
different methods of mass spectrometry. Data from experiments performed with
the MALDI-ToF technique are characterized by high dimensionality. This paper
presents a method for identifying isotope envelopes in MALDI-ToF molecular
imaging data based on the Mamdani-Assilan fuzzy system and spatial maps of the
molecular distribution of peaks included in the isotopic envelope. Several
image texture measures were used to evaluate spatial molecular distribution
maps. The algorithm was tested on eight datasets obtained from the MALDI-ToF
experiment on samples from the National Institute of Oncology in Gliwice from
patients with cancer of the head and neck region. The data were subjected to
pre-processing and feature extraction. The results were collected and compared
with three existing deisotoping algorithms. The analysis of the obtained
results showed that the method for identifying isotopic envelopes proposed in
this paper enables the detection of overlapping envelopes by using the approach
oriented to study peak pairs. Moreover, the proposed algorithm enables the
analysis of large data sets.</p>
  </details>
</details>
<details>
  <summary>179. <b>标题：Variational Bayesian Neural Networks via Resolution of Singularities</b></summary>
  <p><b>编号</b>：[533]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06035</p>
  <p><b>作者</b>：Susan Wei,  Edmund Lau</p>
  <p><b>备注</b>：32 pages, 13 figures</p>
  <p><b>关键词</b>：singular learning theory, learning theory, theory and practice, variational, variational inference</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this work, we advocate for the importance of singular learning theory
(SLT) as it pertains to the theory and practice of variational inference in
Bayesian neural networks (BNNs). To begin, using SLT, we lay to rest some of
the confusion surrounding discrepancies between downstream predictive
performance measured via e.g., the test log predictive density, and the
variational objective. Next, we use the SLT-corrected asymptotic form for
singular posterior distributions to inform the design of the variational family
itself. Specifically, we build upon the idealized variational family introduced
in \citet{bhattacharya_evidence_2020} which is theoretically appealing but
practically intractable. Our proposal takes shape as a normalizing flow where
the base distribution is a carefully-initialized generalized gamma. We conduct
experiments comparing this to the canonical Gaussian base distribution and show
improvements in terms of variational free energy and variational generalization
error.</p>
  </details>
</details>
<details>
  <summary>180. <b>标题：Beyond UCB: Statistical Complexity and Optimal Algorithms for Non-linear  Ridge Bandits</b></summary>
  <p><b>编号</b>：[534]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06025</p>
  <p><b>作者</b>：Nived Rajaraman,  Yanjun Han,  Jiantao Jiao,  Kannan Ramchandran</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：sequential decision-making problem, sequential decision-making, non-linear function, non-linear functions named, burn-in cost</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We consider the sequential decision-making problem where the mean outcome is
a non-linear function of the chosen action. Compared with the linear model, two
curious phenomena arise in non-linear models: first, in addition to the
"learning phase" with a standard parametric rate for estimation or regret,
there is an "burn-in period" with a fixed cost determined by the non-linear
function; second, achieving the smallest burn-in cost requires new exploration
algorithms. For a special family of non-linear functions named ridge functions
in the literature, we derive upper and lower bounds on the optimal burn-in
cost, and in addition, on the entire learning trajectory during the burn-in
period via differential equations. In particular, a two-stage algorithm that
first finds a good initial action and then treats the problem as locally linear
is statistically optimal. In contrast, several classical algorithms, such as
UCB and algorithms relying on regression oracles, are provably suboptimal.</p>
  </details>
</details>
<details>
  <summary>181. <b>标题：Recursive Estimation of Conditional Kernel Mean Embeddings</b></summary>
  <p><b>编号</b>：[536]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05955</p>
  <p><b>作者</b>：Ambrus Tamás,  Balázs Csanád Csáji</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：reproducing kernel Hilbert, map probability distributions, Hilbert space valued, Hilbert space, conditional kernel</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Kernel mean embeddings, a widely used technique in machine learning, map
probability distributions to elements of a reproducing kernel Hilbert space
(RKHS). For supervised learning problems, where input-output pairs are
observed, the conditional distribution of outputs given the inputs is a key
object. The input dependent conditional distribution of an output can be
encoded with an RKHS valued function, the conditional kernel mean map. In this
paper we present a new recursive algorithm to estimate the conditional kernel
mean map in a Hilbert space valued $L_2$ space, that is in a Bochner space. We
prove the weak and strong $L_2$ consistency of our recursive estimator under
mild conditions. The idea is to generalize Stone's theorem for Hilbert space
valued regression in a locally compact Polish space. We present new insights
about conditional kernel mean embeddings and give strong asymptotic bounds
regarding the convergence of the proposed recursive method. Finally, the
results are demonstrated on three application domains: for inputs coming from
Euclidean spaces, Riemannian manifolds and locally compact subsets of function
spaces.</p>
  </details>
</details>
<details>
  <summary>182. <b>标题：Generalization Ability of Wide Neural Networks on $\mathbb{R}$</b></summary>
  <p><b>编号</b>：[537]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05933</p>
  <p><b>作者</b>：Jianfa Lai,  Manyun Xu,  Rui Chen,  Qian Lin</p>
  <p><b>备注</b>：47 pages, 4 figures</p>
  <p><b>关键词</b>：two-layer ReLU neural, neural network, ReLU neural network, wide two-layer ReLU, resulting neural network</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We perform a study on the generalization ability of the wide two-layer ReLU
neural network on $\mathbb{R}$. We first establish some spectral properties of
the neural tangent kernel (NTK): $a)$ $K_{d}$, the NTK defined on
$\mathbb{R}^{d}$, is positive definite; $b)$ $\lambda_{i}(K_{1})$, the $i$-th
largest eigenvalue of $K_{1}$, is proportional to $i^{-2}$. We then show that:
$i)$ when the width $m\rightarrow\infty$, the neural network kernel (NNK)
uniformly converges to the NTK; $ii)$ the minimax rate of regression over the
RKHS associated to $K_{1}$ is $n^{-2/3}$; $iii)$ if one adopts the early
stopping strategy in training a wide neural network, the resulting neural
network achieves the minimax rate; $iv)$ if one trains the neural network till
it overfits the data, the resulting neural network can not generalize well.
Finally, we provide an explanation to reconcile our theory and the widely
observed ``benign overfitting phenomenon''.</p>
  </details>
</details>
<details>
  <summary>183. <b>标题：Physics informed WNO</b></summary>
  <p><b>编号</b>：[538]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05925</p>
  <p><b>作者</b>：Navaneeth N,  Tapas Tripura,  Souvik Chakraborty</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：partial differential equations, complex partial differential, Deep neural operators, Wavelet Neural Operator, differential equations</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Deep neural operators are recognized as an effective tool for learning
solution operators of complex partial differential equations (PDEs). As
compared to laborious analytical and computational tools, a single neural
operator can predict solutions of PDEs for varying initial or boundary
conditions and different inputs. A recently proposed Wavelet Neural Operator
(WNO) is one such operator that harnesses the advantage of time-frequency
localization of wavelets to capture the manifolds in the spatial domain
effectively. While WNO has proven to be a promising method for operator
learning, the data-hungry nature of the framework is a major shortcoming. In
this work, we propose a physics-informed WNO for learning the solution
operators of families of parametric PDEs without labeled training data. The
efficacy of the framework is validated and illustrated with four nonlinear
spatiotemporal systems relevant to various fields of engineering and science.</p>
  </details>
</details>
<details>
  <summary>184. <b>标题：Efficient Fraud Detection using Deep Boosting Decision Trees</b></summary>
  <p><b>编号</b>：[539]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05918</p>
  <p><b>作者</b>：Biao Xu,  Yao Wang,  Xiuwu Liao,  Kaidong Wang</p>
  <p><b>备注</b>：34 pages, 8 figures</p>
  <p><b>关键词</b>：prevent potentially fraudulent, potentially fraudulent activities, Fraud detection, Fraud, prevent potentially</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Fraud detection is to identify, monitor, and prevent potentially fraudulent
activities from complex data. The recent development and success in AI,
especially machine learning, provides a new data-driven way to deal with fraud.
From a methodological point of view, machine learning based fraud detection can
be divided into two categories, i.e., conventional methods (decision tree,
boosting...) and deep learning, both of which have significant limitations in
terms of the lack of representation learning ability for the former and
interpretability for the latter. Furthermore, due to the rarity of detected
fraud cases, the associated data is usually imbalanced, which seriously
degrades the performance of classification algorithms. In this paper, we
propose deep boosting decision trees (DBDT), a novel approach for fraud
detection based on gradient boosting and neural networks. In order to combine
the advantages of both conventional methods and deep learning, we first
construct soft decision tree (SDT), a decision tree structured model with
neural networks as its nodes, and then ensemble SDTs using the idea of gradient
boosting. In this way we embed neural networks into gradient boosting to
improve its representation learning capability and meanwhile maintain the
interpretability. Furthermore, aiming at the rarity of detected fraud cases, in
the model training phase we propose a compositional AUC maximization approach
to deal with data imbalances at algorithm level. Extensive experiments on
several real-life fraud detection datasets show that DBDT can significantly
improve the performance and meanwhile maintain good interpretability. Our code
is available at this https URL.</p>
  </details>
</details>
<details>
  <summary>185. <b>标题：An unsupervised learning approach for predicting wind farm power and  downstream wakes using weather patterns</b></summary>
  <p><b>编号</b>：[541]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05886</p>
  <p><b>作者</b>：Mariana C A Clare,  Simon C Warder,  Robert Neal,  B Bhaskaran,  Matthew D Piggott</p>
  <p><b>备注</b>：18 pages, 18 figures</p>
  <p><b>关键词</b>：resource assessment typically, energy resource assessment, assessment typically requires, Wind, Wind energy resource</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Wind energy resource assessment typically requires numerical models, but such
models are too computationally intensive to consider multi-year timescales.
Increasingly, unsupervised machine learning techniques are used to identify a
small number of representative weather patterns to simulate long-term
behaviour. Here we develop a novel wind energy workflow that for the first time
combines weather patterns derived from unsupervised clustering techniques with
numerical weather prediction models (here WRF) to obtain efficient and accurate
long-term predictions of power and downstream wakes from an entire wind farm.
We use ERA5 reanalysis data clustering not only on low altitude pressure but
also, for the first time, on the more relevant variable of wind velocity. We
also compare the use of large-scale and local-scale domains for clustering. A
WRF simulation is run at each of the cluster centres and the results are
aggregated using a novel post-processing technique. By applying our workflow to
two different regions, we show that our long-term predictions agree with those
from a year of WRF simulations but require less than 2% of the computational
time. The most accurate results are obtained when clustering on wind velocity.
Moreover, clustering over the Europe-wide domain is sufficient for predicting
wind farm power output, but downstream wake predictions benefit from the use of
smaller domains. Finally, we show that these downstream wakes can affect the
local weather patterns.
Our approach facilitates multi-year predictions of power output and
downstream farm wakes, by providing a fast, accurate and flexible methodology
that is applicable to any global region. Moreover, these accurate long-term
predictions of downstream wakes provide the first tool to help mitigate the
effects of wind energy loss downstream of wind farms, since they can be used to
determine optimum wind farm locations.</p>
  </details>
</details>
<details>
  <summary>186. <b>标题：From high-dimensional & mean-field dynamics to dimensionless ODEs: A  unifying approach to SGD in two-layers networks</b></summary>
  <p><b>编号</b>：[542]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05882</p>
  <p><b>作者</b>：Luca Arnaboldi,  Ludovic Stephan,  Florent Krzakala,  Bruno Loureiro</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：stochastic gradient descent, one-pass stochastic gradient, two-layer neural network, neural network trained, trained on Gaussian</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This manuscript investigates the one-pass stochastic gradient descent (SGD)
dynamics of a two-layer neural network trained on Gaussian data and labels
generated by a similar, though not necessarily identical, target function. We
rigorously analyse the limiting dynamics via a deterministic and
low-dimensional description in terms of the sufficient statistics for the
population risk. Our unifying analysis bridges different regimes of interest,
such as the classical gradient-flow regime of vanishing learning rate, the
high-dimensional regime of large input dimension, and the overparameterised
"mean-field" regime of large network width, covering as well the intermediate
regimes where the limiting dynamics is determined by the interplay between
these behaviours. In particular, in the high-dimensional limit, the
infinite-width dynamics is found to remain close to a low-dimensional subspace
spanned by the target principal directions. Our results therefore provide a
unifying picture of the limiting SGD dynamics with synthetic data.</p>
  </details>
</details>
<details>
  <summary>187. <b>标题：NephroNet: A Novel Program for Identifying Renal Cell Carcinoma and  Generating Synthetic Training Images with Convolutional Neural Networks and  Diffusion Models</b></summary>
  <p><b>编号</b>：[546]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05830</p>
  <p><b>作者</b>：Yashvir Sabharwal</p>
  <p><b>备注</b>：22 pages, 5 figures, 2 tables</p>
  <p><b>关键词</b>：RCC, Renal cell carcinoma, RCC surgical resection, RCC surgical, kidney cancer</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Renal cell carcinoma (RCC) is a type of cancer that originates in the kidneys
and is the most common type of kidney cancer in adults. It can be classified
into several subtypes, including clear cell RCC, papillary RCC, and chromophobe
RCC. In this study, an artificial intelligence model was developed and trained
for classifying different subtypes of RCC using ResNet-18, a convolutional
neural network that has been widely used for image classification tasks. The
model was trained on a dataset of RCC histopathology images, which consisted of
digital images of RCC surgical resection slides that were annotated with the
corresponding subtype labels. The performance of the trained model was
evaluated using several metrics, including accuracy, precision, and recall.
Additionally, in this research, a novel synthetic image generation tool,
NephroNet, is developed on diffusion models that are used to generate original
images of RCC surgical resection slides. Diffusion models are a class of
generative models capable of synthesizing high-quality images from noise.
Several diffusers such as Stable Diffusion, Dreambooth Text-to-Image, and
Textual Inversion were trained on a dataset of RCC images and were used to
generate a series of original images that resembled RCC surgical resection
slides, all within the span of fewer than four seconds. The generated images
were visually realistic and could be used for creating new training datasets,
testing the performance of image analysis algorithms, and training medical
professionals. NephroNet is provided as an open-source software package and
contains files for data preprocessing, training, and visualization. Overall,
this study demonstrates the potential of artificial intelligence and diffusion
models for classifying and generating RCC images, respectively. These methods
could be useful for improving the diagnosis and treatment of RCC and more.</p>
  </details>
</details>
<details>
  <summary>188. <b>标题：A Policy Gradient Framework for Stochastic Optimal Control Problems with  Global Convergence Guarantee</b></summary>
  <p><b>编号</b>：[547]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05816</p>
  <p><b>作者</b>：Mo Zhou,  Jianfeng Lu</p>
  <p><b>备注</b>：54 pages</p>
  <p><b>关键词</b>：policy gradient method, stochastic optimal control, optimal control problem, continuous time limit, policy gradient</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this work, we consider the stochastic optimal control problem in
continuous time and a policy gradient method to solve it. In particular, we
study the gradient flow for the control, viewed as a continuous time limit of
the policy gradient. We prove the global convergence of the gradient flow and
establish a convergence rate under some regularity assumptions. The main
novelty in the analysis is the notion of local optimal control function, which
is introduced to compare the local optimality of the iterate.</p>
  </details>
</details>
<details>
  <summary>189. <b>标题：Global Convergence Rate of Deep Equilibrium Models with General  Activations</b></summary>
  <p><b>编号</b>：[549]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05797</p>
  <p><b>作者</b>：Lan V. Truong</p>
  <p><b>备注</b>：39 pages</p>
  <p><b>关键词</b>：over-parametrized Deep, investigated the over-parametrized, recent paper, Ling, Deep</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In a recent paper, Ling et al. investigated the over-parametrized Deep
Equilibrium Model (DEQ) with ReLU activation and proved that the gradient
descent converges to a globally optimal solution at a linear convergence rate
for the quadratic loss function. In this paper, we show that this fact still
holds for DEQs with any general activation which has bounded first and second
derivatives. Since the new activation function is generally non-linear, a
general population Gram matrix is designed, and a new form of dual activation
with Hermite polynomial expansion is developed.</p>
  </details>
</details>
<details>
  <summary>190. <b>标题：Differentially Private Normalizing Flows for Density Estimation, Data  Synthesis, and Variational Inference with Application to Electronic Health  Records</b></summary>
  <p><b>编号</b>：[550]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05787</p>
  <p><b>作者</b>：Bingyue Su,  Yu Wang,  Daniele E. Schiavazzi,  Fang Liu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Electronic health records, posing significant limitations, sensitive medical information, releasing EHR data, Electronic health</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Electronic health records (EHR) often contain sensitive medical information
about individual patients, posing significant limitations to sharing or
releasing EHR data for downstream learning and inferential tasks. We use
normalizing flows (NF), a family of deep generative models, to estimate the
probability density of a dataset with differential privacy (DP) guarantees,
from which privacy-preserving synthetic data are generated. We apply the
technique to an EHR dataset containing patients with pulmonary hypertension. We
assess the learning and inferential utility of the synthetic data by comparing
the accuracy in the prediction of the hypertension status and variational
posterior distribution of the parameters of a physics-based model. In addition,
we use a simulated dataset from a nonlinear model to compare the results from
variational inference (VI) based on privacy-preserving synthetic data, and
privacy-preserving VI obtained from directly privatizing NFs for VI with DP
guarantees given the original non-private dataset. The results suggest that
synthetic data generated through differentially private density estimation with
NF can yield good utility at a reasonable privacy cost. We also show that VI
obtained from differentially private NF based on the free energy bound loss may
produce variational approximations with significantly altered correlation
structure, and loss formulations based on alternative dissimilarity metrics
between two distributions might provide improved results.</p>
  </details>
</details>
<details>
  <summary>191. <b>标题：A High-dimensional Convergence Theorem for U-statistics with  Applications to Kernel-based Testing</b></summary>
  <p><b>编号</b>：[554]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05686</p>
  <p><b>作者</b>：Kevin H. Huang,  Xing Liu,  Andrew B. Duncan,  Axel Gandy</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：sample size, prove a convergence, convergence theorem, non-degenerate Gaussian limit, data dimension</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We prove a convergence theorem for U-statistics of degree two, where the data
dimension $d$ is allowed to scale with sample size $n$. We find that the
limiting distribution of a U-statistic undergoes a phase transition from the
non-degenerate Gaussian limit to the degenerate limit, regardless of its
degeneracy and depending only on a moment ratio. A surprising consequence is
that a non-degenerate U-statistic in high dimensions can have a non-Gaussian
limit with a larger variance and asymmetric distribution. Our bounds are valid
for any finite $n$ and $d$, independent of individual eigenvalues of the
underlying function, and dimension-independent under a mild assumption. As an
application, we apply our theory to two popular kernel-based distribution
tests, MMD and KSD, whose high-dimensional performance has been challenging to
study. In a simple empirical setting, our results correctly predict how the
test power at a fixed threshold scales with $d$ and the bandwidth.</p>
  </details>
</details>
<details>
  <summary>192. <b>标题：Sequential Underspecified Instrument Selection for Cause-Effect  Estimation</b></summary>
  <p><b>编号</b>：[555]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05684</p>
  <p><b>作者</b>：Elisabeth Ailer,  Jason Hartford,  Niki Kilbertus</p>
  <p><b>备注</b>：Code for this paper is available at this https URL</p>
  <p><b>关键词</b>：unobserved confounding, treatment variable, settings with unobserved, Instrumental variable, treatment effect</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Instrumental variable (IV) methods are used to estimate causal effects in
settings with unobserved confounding, where we cannot directly experiment on
the treatment variable. Instruments are variables which only affect the outcome
indirectly via the treatment variable(s). Most IV applications focus on
low-dimensional treatments and crucially require at least as many instruments
as treatments. This assumption is restrictive: in the natural sciences we often
seek to infer causal effects of high-dimensional treatments (e.g., the effect
of gene expressions or microbiota on health and disease), but can only run few
experiments with a limited number of instruments (e.g., drugs or antibiotics).
In such underspecified problems, the full treatment effect is not identifiable
in a single experiment even in the linear case. We show that one can still
reliably recover the projection of the treatment effect onto the instrumented
subspace and develop techniques to consistently combine such partial estimates
from different sets of instruments. We then leverage our combined estimators in
an algorithm that iteratively proposes the most informative instruments at each
round of experimentation to maximize the overall information about the full
causal effect.</p>
  </details>
</details>
<details>
  <summary>193. <b>标题：Multi-class Brain Tumor Segmentation using Graph Attention Network</b></summary>
  <p><b>编号</b>：[558]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05598</p>
  <p><b>作者</b>：Dhrumil Patel,  Dhruv Patel,  Rudra Saxena,  Thangarajah Akilan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：magnetic resonance imaging, resonance imaging, plays an important, diagnostic radiology, tumor segmentation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Brain tumor segmentation from magnetic resonance imaging (MRI) plays an
important role in diagnostic radiology. To overcome the practical issues in
manual approaches, there is a huge demand for building automatic tumor
segmentation algorithms. This work introduces an efficient brain tumor
summation model by exploiting the advancement in MRI and graph neural networks
(GNNs). The model represents the volumetric MRI as a region adjacency graph
(RAG) and learns to identify the type of tumors through a graph attention
network (GAT) -- a variant of GNNs. The ablation analysis conducted on two
benchmark datasets proves that the proposed model can produce competitive
results compared to the leading-edge solutions. It achieves mean dice scores of
0.91, 0.86, 0.79, and mean Hausdorff distances in the 95th percentile (HD95) of
5.91, 6.08, and 9.52 mm, respectively, for whole tumor, core tumor, and
enhancing tumor segmentation on BraTS2021 validation dataset. On average, these
performances are >6\% and >50%, compared to a GNN-based baseline model,
respectively, on dice score and HD95 evaluation metrics.</p>
  </details>
</details>
<details>
  <summary>194. <b>标题：Cyclic and Randomized Stepsizes Invoke Heavier Tails in SGD</b></summary>
  <p><b>编号</b>：[563]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05516</p>
  <p><b>作者</b>：Mert Gürbüzbalaban,  Yuanhan Hu,  Umut Şimşekli,  Lingjiong Zhu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：outperform standard stepsize, standard stepsize choices, outperform standard, stepsize, deep learning practice</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Cyclic and randomized stepsizes are widely used in the deep learning practice
and can often outperform standard stepsize choices such as constant stepsize in
SGD. Despite their empirical success, not much is currently known about when
and why they can theoretically improve the generalization performance. We
consider a general class of Markovian stepsizes for learning, which contain
i.i.d. random stepsize, cyclic stepsize as well as the constant stepsize as
special cases, and motivated by the literature which shows that heaviness of
the tails (measured by the so-called "tail-index") in the SGD iterates is
correlated with generalization, we study tail-index and provide a number of
theoretical results that demonstrate how the tail-index varies on the stepsize
scheduling. Our results bring a new understanding of the benefits of cyclic and
randomized stepsizes compared to constant stepsize in terms of the tail
behavior. We illustrate our theory on linear regression experiments and show
through deep learning experiments that Markovian stepsizes can achieve even a
heavier tail and be a viable alternative to cyclic and i.i.d. randomized
stepsize rules.</p>
  </details>
</details>
<details>
  <summary>195. <b>标题：Achieving acceleration despite very noisy gradients</b></summary>
  <p><b>编号</b>：[564]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05515</p>
  <p><b>作者</b>：Kanan Gupta,  Jonathan Siegel,  Stephan Wojtowytsch</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：order optimization method, provably achieves acceleration, convex minimization, order optimization, acceleration for convex</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present a novel momentum-based first order optimization method (AGNES)
which provably achieves acceleration for convex minimization, even if the
stochastic noise in the gradient estimates is many orders of magnitude larger
than the gradient itself. Here we model the noise as having a variance which is
proportional to the magnitude of the underlying gradient. We argue, based upon
empirical evidence, that this is appropriate for mini-batch gradients in
overparameterized deep learning. Furthermore, we demonstrate that the method
achieves competitive performance in the training of CNNs on MNIST and CIFAR-10.</p>
  </details>
</details>
<h1>人工智能</h1>
<details>
  <summary>1. <b>标题：Breaking the Curse of Multiagency: Provably Efficient Decentralized  Multi-Agent RL with Function Approximation</b></summary>
  <p><b>编号</b>：[3]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06606</p>
  <p><b>作者</b>：Yuanhao Wang,  Qinghua Liu,  Yu Bai,  Chi Jin</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Multi-Agent Reinforcement Learning, Multi-Agent Reinforcement, algorithms scale exponentially, Reinforcement Learning, Markov Games</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A unique challenge in Multi-Agent Reinforcement Learning (MARL) is the curse
of multiagency, where the description length of the game as well as the
complexity of many existing learning algorithms scale exponentially with the
number of agents. While recent works successfully address this challenge under
the model of tabular Markov Games, their mechanisms critically rely on the
number of states being finite and small, and do not extend to practical
scenarios with enormous state spaces where function approximation must be used
to approximate value functions or policies.
This paper presents the first line of MARL algorithms that provably resolve
the curse of multiagency under function approximation. We design a new
decentralized algorithm -- V-Learning with Policy Replay, which gives the first
polynomial sample complexity results for learning approximate Coarse Correlated
Equilibria (CCEs) of Markov Games under decentralized linear function
approximation. Our algorithm always outputs Markov CCEs, and achieves an
optimal rate of $\widetilde{\mathcal{O}}(\epsilon^{-2})$ for finding
$\epsilon$-optimal solutions. Also, when restricted to the tabular case, our
result improves over the current best decentralized result
$\widetilde{\mathcal{O}}(\epsilon^{-3})$ for finding Markov CCEs. We further
present an alternative algorithm -- Decentralized Optimistic Policy Mirror
Descent, which finds policy-class-restricted CCEs using a polynomial number of
samples. In exchange for learning a weaker version of CCEs, this algorithm
applies to a wider range of problems under generic function approximation, such
as linear quadratic games and MARL problems with low ''marginal'' Eluder
dimension.</p>
  </details>
</details>
<details>
  <summary>2. <b>标题：ALAN: Autonomously Exploring Robotic Agents in the Real World</b></summary>
  <p><b>编号</b>：[5]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06604</p>
  <p><b>作者</b>：Russell Mendonca,  Shikhar Bahl,  Deepak Pathak</p>
  <p><b>备注</b>：ICRA 2023. Website at this https URL</p>
  <p><b>关键词</b>：minimal human supervision, real world, data collected, minimal human, human supervision</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Robotic agents that operate autonomously in the real world need to
continuously explore their environment and learn from the data collected, with
minimal human supervision. While it is possible to build agents that can learn
in such a manner without supervision, current methods struggle to scale to the
real world. Thus, we propose ALAN, an autonomously exploring robotic agent,
that can perform tasks in the real world with little training and interaction
time. This is enabled by measuring environment change, which reflects object
movement and ignores changes in the robot position. We use this metric directly
as an environment-centric signal, and also maximize the uncertainty of
predicted environment change, which provides agent-centric exploration signal.
We evaluate our approach on two different real-world play kitchen settings,
enabling a robot to efficiently explore and discover manipulation skills, and
perform tasks specified via goal images. Website at
this https URL</p>
  </details>
</details>
<details>
  <summary>3. <b>标题：FilFL: Accelerating Federated Learning via Client Filtering</b></summary>
  <p><b>编号</b>：[8]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06599</p>
  <p><b>作者</b>：Fares Fourati,  Salma Kharrat,  Vaneet Aggarwal,  Mohamed-Slim Alouini,  Marco Canini</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：emerging machine learning, machine learning paradigm, local data, emerging machine, paradigm that enables</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Federated learning is an emerging machine learning paradigm that enables
devices to train collaboratively without exchanging their local data. The
clients participating in the training process are a random subset selected from
the pool of clients. The above procedure is called client selection which is an
important area in federated learning as it highly impacts the convergence rate,
learning efficiency, and generalization. In this work, we introduce client
filtering in federated learning (FilFL), a new approach to optimize client
selection and training. FilFL first filters the active clients by choosing a
subset of them that maximizes a specific objective function; then, a client
selection method is applied to that subset. We provide a thorough analysis of
its convergence in a heterogeneous setting. Empirical results demonstrate
several benefits to our approach, including improved learning efficiency,
accelerated convergence, $2$-$3\times$ faster, and higher test accuracy, around
$2$-$10$ percentage points higher.</p>
  </details>
</details>
<details>
  <summary>4. <b>标题：Geometric Clifford Algebra Networks</b></summary>
  <p><b>编号</b>：[11]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06594</p>
  <p><b>作者</b>：David Ruhe,  Jayesh K. Gupta,  Steven de Keninck,  Max Welling,  Johannes Brandstetter</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Clifford Algebra Networks, Geometric Clifford Algebra, Algebra Networks, propose Geometric Clifford, Clifford Algebra</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We propose Geometric Clifford Algebra Networks (GCANs) that are based on
symmetry group transformations using geometric (Clifford) algebras. GCANs are
particularly well-suited for representing and manipulating geometric
transformations, often found in dynamical systems. We first review the
quintessence of modern (plane-based) geometric algebra, which builds on
isometries encoded as elements of the $\mathrm{Pin}(p,q,r)$ group. We then
propose the concept of group action layers, which linearly combine object
transformations using pre-specified group actions. Together with a new
activation and normalization scheme, these layers serve as adjustable geometric
templates that can be refined via gradient descent. Theoretical advantages are
strongly reflected in the modeling of three-dimensional rigid body
transformations as well as large-scale fluid dynamics simulations, showing
significantly improved performance over traditional methods.</p>
  </details>
</details>
<details>
  <summary>5. <b>标题：Stitchable Neural Networks</b></summary>
  <p><b>编号</b>：[17]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06586</p>
  <p><b>作者</b>：Zizheng Pan,  Jianfei Cai,  Bohan Zhuang</p>
  <p><b>备注</b>：Project is available at this https URL</p>
  <p><b>关键词</b>：enormous powerful pretrained, pretrained model families, powerful pretrained model, deep learning, enormous powerful</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The public model zoo containing enormous powerful pretrained model families
(e.g., DeiT/Swin) has reached an unprecedented scope than ever, which
significantly contributes to the success of deep learning. As each model family
consists of pretrained models with diverse scales (e.g., DeiT-Ti/S/B), it
naturally arises a fundamental question of how to effectively assemble these
readily available models in a family for dynamic accuracy-efficiency trade-offs
at runtime. In this work, we present Stitchable Neural Networks (SN-Net), a
novel scalable and efficient framework for model deployment which cheaply
produces numerous networks with different complexity and performance
trade-offs. Specifically, SN-Net splits a family of pretrained neural networks,
which we call anchors, across the blocks/layers and then stitches them together
with simple stitching layers to map the activations from one anchor to another.
With only a few epochs of training, SN-Net effectively interpolates between the
performance of anchors with varying scales. At runtime, SN-Net can instantly
adapt to dynamic resource constraints by switching the stitching positions.
Furthermore, we provide a comprehensive study on what, how and where to stitch
as well as a simple strategy for effectively and efficiently training SN-Net.
Extensive experiments on ImageNet classification demonstrate that SN-Net can
obtain on-par or even better performance than many individually trained
networks while supporting diverse deployment scenarios. For example, by
stitching Swin Transformers, we challenge hundreds of models in Timm model zoo
with a single network. We believe this new elastic model framework can serve as
a strong baseline for further research in wider communities.</p>
  </details>
</details>
<details>
  <summary>6. <b>标题：Thermodynamic AI and the fluctuation frontier</b></summary>
  <p><b>编号</b>：[18]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06584</p>
  <p><b>作者</b>：Patrick J. Coles</p>
  <p><b>备注</b>：46 pages, 18 figures</p>
  <p><b>关键词</b>：Artificial Intelligence, Thermodynamic, hardware, Artificial, algorithms</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Many Artificial Intelligence (AI) algorithms are inspired by physics and
employ stochastic fluctuations. We connect these physics-inspired AI algorithms
by unifying them under a single mathematical framework that we call
Thermodynamic AI. Seemingly disparate algorithmic classes can be described by
this framework, for example, (1) Generative diffusion models, (2) Bayesian
neural networks, (3) Monte Carlo sampling and (4) Simulated annealing. Such
Thermodynamic AI algorithms are currently run on digital hardware, ultimately
limiting their scalability and overall potential. Stochastic fluctuations
naturally occur in physical thermodynamic systems, and such fluctuations can be
viewed as a computational resource. Hence, we propose a novel computing
paradigm, where software and hardware become inseparable. Our algorithmic
unification allows us to identify a single full-stack paradigm, involving
Thermodynamic AI hardware, that could accelerate such algorithms. We contrast
Thermodynamic AI hardware with quantum computing where noise is a roadblock
rather than a resource. Thermodynamic AI hardware can be viewed as a novel form
of computing, since it uses a novel fundamental building block. We identify
stochastic bits (s-bits) and stochastic modes (s-modes) as the respective
building blocks for discrete and continuous Thermodynamic AI hardware. In
addition to these stochastic units, Thermodynamic AI hardware employs a
Maxwell's demon device that guides the system to produce non-trivial states. We
provide a few simple physical architectures for building these devices and we
develop a formalism for programming the hardware via gate sequences. We hope to
stimulate discussion around this new computing paradigm. Beyond acceleration,
we believe it will impact the design of both hardware and algorithms, while
also deepening our understanding of the connection between physics and
intelligence.</p>
  </details>
</details>
<details>
  <summary>7. <b>标题：A Convex Hull Cheapest Insertion Heuristic for the Non-Euclidean and  Precedence Constrained TSPs</b></summary>
  <p><b>编号</b>：[19]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06582</p>
  <p><b>作者</b>：Mithun Goutham,  Meghna Menon,  Sarah Garrow,  Stephanie Stockar</p>
  <p><b>备注</b>：Manuscript submitted 4 February 2023 to the IEEE Transactions on Intelligent Transportation Systems (T-ITS)</p>
  <p><b>关键词</b>：Euclidean Traveling Salesperson, Traveling Salesperson Problem, Euclidean Traveling, Traveling Salesperson, Sequential Ordering Problem</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The convex hull cheapest insertion heuristic is known to generate good
solutions to the Euclidean Traveling Salesperson Problem. This paper presents
an adaptation of this heuristic to the non-Euclidean version of the problem and
further extends it to the problem with precedence constraints, also known as
the Sequential Ordering Problem. To test the proposed algorithm, the well-known
TSPLIB benchmark data-set is modified in a replicable manner to create
non-Euclidean instances and precedence constraints. The proposed algorithm is
shown to outperform the commonly used Nearest Neighbor algorithm in 97% of the
cases that do not have precedence constraints. When precedence constraints
exist such that the child nodes are centrally located, the algorithm again
outperforms the Nearest Neighbor algorithm in 98% of the studied instances.
Considering all spatial layouts of precedence constraints, the algorithm
outperforms the Nearest Neighbor heuristic 68% of the time.</p>
  </details>
</details>
<details>
  <summary>8. <b>标题：Comp2Comp: Open-Source Body Composition Assessment on Computed  Tomography</b></summary>
  <p><b>编号</b>：[24]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06568</p>
  <p><b>作者</b>：Louis Blankemeier,  Arjun Desai,  Juan Manuel Zambrano Chaves,  Andrew Wentland,  Sally Yao,  Eduardo Reis,  Malte Jensen,  Bhanushree Bahl,  Khushboo Arora,  Bhavik N. Patel,  Leon Lenchik,  Marc Willis,  Robert D. Boutin,  Akshay S. Chaudhari</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：body composition, body composition measures, quantitative body composition, Computed tomography, automated body composition</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Computed tomography (CT) is routinely used in clinical practice to evaluate a
wide variety of medical conditions. While CT scans provide diagnoses, they also
offer the ability to extract quantitative body composition metrics to analyze
tissue volume and quality. Extracting quantitative body composition measures
manually from CT scans is a cumbersome and time-consuming task. Proprietary
software has been developed recently to automate this process, but the
closed-source nature impedes widespread use. There is a growing need for fully
automated body composition software that is more accessible and easier to use,
especially for clinicians and researchers who are not experts in medical image
processing. To this end, we have built Comp2Comp, an open-source Python package
for rapid and automated body composition analysis of CT scans. This package
offers models, post-processing heuristics, body composition metrics, automated
batching, and polychromatic visualizations. Comp2Comp currently computes body
composition measures for bone, skeletal muscle, visceral adipose tissue, and
subcutaneous adipose tissue on CT scans of the abdomen. We have created two
pipelines for this purpose. The first pipeline computes vertebral measures, as
well as muscle and adipose tissue measures, at the T12 - L5 vertebral levels
from abdominal CT scans. The second pipeline computes muscle and adipose tissue
measures on user-specified 2D axial slices. In this guide, we discuss the
architecture of the Comp2Comp pipelines, provide usage instructions, and report
internal and external validation results to measure the quality of
segmentations and body composition measures. Comp2Comp can be found at
this https URL.</p>
  </details>
</details>
<details>
  <summary>9. <b>标题：Automatic Noise Filtering with Dynamic Sparse Training in Deep  Reinforcement Learning</b></summary>
  <p><b>编号</b>：[35]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06548</p>
  <p><b>作者</b>：Bram Grooten,  Ghada Sokar,  Shibhansh Dohare,  Elena Mocanu,  Matthew E. Taylor,  Mykola Pechenizkiy,  Decebal Constantin Mocanu</p>
  <p><b>备注</b>：Accepted as full-paper at AAMAS 2023</p>
  <p><b>关键词</b>：performing different tasks, Tomorrow robots, reinforcement learning, Automatic Noise Filtering, information</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Tomorrow's robots will need to distinguish useful information from noise when
performing different tasks. A household robot for instance may continuously
receive a plethora of information about the home, but needs to focus on just a
small subset to successfully execute its current chore. Filtering distracting
inputs that contain irrelevant data has received little attention in the
reinforcement learning literature. To start resolving this, we formulate a
problem setting in reinforcement learning called the $\textit{extremely noisy
environment}$ (ENE), where up to $99\%$ of the input features are pure noise.
Agents need to detect which features provide task-relevant information about
the state of the environment. Consequently, we propose a new method termed
$\textit{Automatic Noise Filtering}$ (ANF), which uses the principles of
dynamic sparse training in synergy with various deep reinforcement learning
algorithms. The sparse input layer learns to focus its connectivity on
task-relevant features, such that ANF-SAC and ANF-TD3 outperform standard SAC
and TD3 by a large margin, while using up to $95\%$ fewer weights. Furthermore,
we devise a transfer learning setting for ENEs, by permuting all features of
the environment after 1M timesteps to simulate the fact that other information
sources can become relevant as the world evolves. Again, ANF surpasses the
baselines in final performance and sample complexity. Our code is available at
this https URL</p>
  </details>
</details>
<details>
  <summary>10. <b>标题：Probabilistic Circuits That Know What They Don't Know</b></summary>
  <p><b>编号</b>：[37]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06544</p>
  <p><b>作者</b>：Fabrizio Ventola,  Steven Braun,  Zhongjie Yu,  Martin Mundt,  Kristian Kersting</p>
  <p><b>备注</b>：22 pages, 8 figures, 1 table, 1 algorithm</p>
  <p><b>关键词</b>：Probabilistic circuits, OOD data, tractable probabilistic inference, data, OOD</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Probabilistic circuits (PCs) are models that allow exact and tractable
probabilistic inference. In contrast to neural networks, they are often assumed
to be well-calibrated and robust to out-of-distribution (OOD) data. In this
paper, we show that PCs are in fact not robust to OOD data, i.e., they don't
know what they don't know. We then show how this challenge can be overcome by
model uncertainty quantification. To this end, we propose tractable dropout
inference (TDI), an inference procedure to estimate uncertainty by deriving an
analytical solution to Monte Carlo dropout (MCD) through variance propagation.
Unlike MCD in neural networks, which comes at the cost of multiple network
evaluations, TDI provides tractable sampling-free uncertainty estimates in a
single forward pass. TDI improves the robustness of PCs to distribution shift
and OOD data, demonstrated through a series of experiments evaluating the
classification confidence and uncertainty estimates on real-world data.</p>
  </details>
</details>
<details>
  <summary>11. <b>标题：Imitation from Observation With Bootstrapped Contrastive Learning</b></summary>
  <p><b>编号</b>：[39]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06540</p>
  <p><b>作者</b>：Medric Sonwa,  Johanna Hansen,  Eugene Belilovsky</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Markov Decision Process, Decision Process, Markov Decision, training autonomous agents, observing expert demonstrations</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Imitation from observation (IfO) is a learning paradigm that consists of
training autonomous agents in a Markov Decision Process (MDP) by observing
expert demonstrations without access to its actions. These demonstrations could
be sequences of environment states or raw visual observations of the
environment. Recent work in IfO has focused on this problem in the case of
observations of low-dimensional environment states, however, access to these
highly-specific observations is unlikely in practice. In this paper, we adopt a
challenging, but more realistic problem formulation, learning control policies
that operate on a learned latent space with access only to visual
demonstrations of an expert completing a task. We present BootIfOL, an IfO
algorithm that aims to learn a reward function that takes an agent trajectory
and compares it to an expert, providing rewards based on similarity to agent
behavior and implicit goal. We consider this reward function to be a distance
metric between trajectories of agent behavior and learn it via contrastive
learning. The contrastive learning objective aims to closely represent expert
trajectories and to distance them from non-expert trajectories. The set of
non-expert trajectories used in contrastive learning is made progressively more
complex by bootstrapping from roll-outs of the agent learned through RL using
the current reward function. We evaluate our approach on a variety of control
tasks showing that we can train effective policies using a limited number of
demonstrative trajectories, greatly improving on prior approaches that consider
raw observations.</p>
  </details>
</details>
<details>
  <summary>12. <b>标题：Adaptive Test Generation Using a Large Language Model</b></summary>
  <p><b>编号</b>：[44]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06527</p>
  <p><b>作者</b>：Max Schäfer,  Sarah Nadi,  Aryaz Eghbali,  Frank Tip</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Unit tests play, Large Language Models, tests, Unit tests, correctness of software</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Unit tests play a key role in ensuring the correctness of software. However,
manually creating unit tests is a laborious task, motivating the need for
automation. This paper presents TestPilot, an adaptive test generation
technique that leverages Large Language Models (LLMs). TestPilot uses Codex, an
off-the-shelf LLM, to automatically generate unit tests for a given program
without requiring additional training or few-shot learning on examples of
existing tests. In our approach, Codex is provided with prompts that include
the signature and implementation of a function under test, along with usage
examples extracted from documentation. If a generated test fails, TestPilot's
adaptive component attempts to generate a new test that fixes the problem by
re-prompting the model with the failing test and error message. We created an
implementation of TestPilot for JavaScript and evaluated it on 25 npm packages
with a total of 1,684 API functions to generate tests for. Our results show
that the generated tests achieve up to 93.1% statement coverage (median 68.2%).
Moreover, on average, 58.5% of the generated tests contain at least one
assertion that exercises functionality from the package under test. Our
experiments with excluding parts of the information included in the prompts
show that all components contribute towards the generation of effective test
suites. Finally, we find that TestPilot does not generate memorized tests:
92.7% of our generated tests have $\leq$ 50% similarity with existing tests (as
measured by normalized edit distance), with none of them being exact copies.</p>
  </details>
</details>
<details>
  <summary>13. <b>标题：Transferable Deep Metric Learning for Clustering</b></summary>
  <p><b>编号</b>：[45]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06523</p>
  <p><b>作者</b>：Simo Alami.C,  Rim Kaddah,  Jesse Read</p>
  <p><b>备注</b>：Published in Symposium of Intelligent Data Analysis (IDA), 2023</p>
  <p><b>关键词</b>：usual distance metrics, high dimension spaces, difficult task, curse of dimensionality, high dimension</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Clustering in high dimension spaces is a difficult task; the usual distance
metrics may no longer be appropriate under the curse of dimensionality. Indeed,
the choice of the metric is crucial, and it is highly dependent on the dataset
characteristics. However a single metric could be used to correctly perform
clustering on multiple datasets of different domains. We propose to do so,
providing a framework for learning a transferable metric. We show that we can
learn a metric on a labelled dataset, then apply it to cluster a different
dataset, using an embedding space that characterises a desired clustering in
the generic sense. We learn and test such metrics on several datasets of
variable complexity (synthetic, MNIST, SVHN, omniglot) and achieve results
competitive with the state-of-the-art while using only a small number of
labelled training datasets and shallow networks.</p>
  </details>
</details>
<details>
  <summary>14. <b>标题：Ground(less) Truth: A Causal Framework for Proxy Labels in  Human-Algorithm Decision-Making</b></summary>
  <p><b>编号</b>：[51]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06503</p>
  <p><b>作者</b>：Luke Guerdan,  Amanda Coston,  Zhiwei Steven Wu,  Kenneth Holstein</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：combining human judgment, growing literature, human-AI decision-making, target variable bias, human-AI decision-making tasks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A growing literature on human-AI decision-making investigates strategies for
combining human judgment with statistical models to improve decision-making.
Research in this area often evaluates proposed improvements to models,
interfaces, or workflows by demonstrating improved predictive performance on
"ground truth" labels. However, this practice overlooks a key difference
between human judgments and model predictions. Whereas humans reason about
broader phenomena of interest in a decision - including latent constructs that
are not directly observable, such as disease status, the "toxicity" of online
comments, or future "job performance" - predictive models target proxy labels
that are readily available in existing datasets. Predictive models' reliance on
simplistic proxies makes them vulnerable to various sources of statistical
bias. In this paper, we identify five sources of target variable bias that can
impact the validity of proxy labels in human-AI decision-making tasks. We
develop a causal framework to disentangle the relationship between each bias
and clarify which are of concern in specific human-AI decision-making tasks. We
demonstrate how our framework can be used to articulate implicit assumptions
made in prior modeling work, and we recommend evaluation strategies for
verifying whether these assumptions hold in practice. We then leverage our
framework to re-examine the designs of prior human subjects experiments that
investigate human-AI decision-making, finding that only a small fraction of
studies examine factors related to target variable bias. We conclude by
discussing opportunities to better address target variable bias in future
research.</p>
  </details>
</details>
<details>
  <summary>15. <b>标题：Is ChatGPT a General-Purpose Natural Language Processing Task Solver?</b></summary>
  <p><b>编号</b>：[60]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06476</p>
  <p><b>作者</b>：Chengwei Qin,  Aston Zhang,  Zhuosheng Zhang,  Jiaao Chen,  Michihiro Yasunaga,  Diyi Yang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：natural language processing, large language models, language processing, Spurred by advancements, advancements in scale</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Spurred by advancements in scale, large language models (LLMs) have
demonstrated the ability to perform a variety of natural language processing
(NLP) tasks zero-shot -- i.e., without adaptation on downstream data. Recently,
the debut of ChatGPT has drawn a great deal of attention from the natural
language processing (NLP) community due to the fact that it can generate
high-quality responses to human input and self-correct previous mistakes based
on subsequent conversations. However, it is not yet known whether ChatGPT can
serve as a generalist model that can perform many NLP tasks zero-shot. In this
work, we empirically analyze the zero-shot learning ability of ChatGPT by
evaluating it on 20 popular NLP datasets covering 7 representative task
categories. With extensive empirical studies, we demonstrate both the
effectiveness and limitations of the current version of ChatGPT. We find that
ChatGPT performs well on many tasks favoring reasoning capabilities (e.g.,
arithmetic reasoning) while it still faces challenges when solving specific
tasks such as sequence tagging. We additionally provide in-depth analysis
through qualitative case studies.</p>
  </details>
</details>
<details>
  <summary>16. <b>标题：ChatGPT versus Traditional Question Answering for Knowledge Graphs:  Current Status and Future Directions Towards Knowledge Graph Chatbots</b></summary>
  <p><b>编号</b>：[65]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06466</p>
  <p><b>作者</b>：Reham Omar,  Omij Mangukiya,  Panos Kalnis,  Essam Mansour</p>
  <p><b>备注</b>：9 pages</p>
  <p><b>关键词</b>：extracting information easily, emerging research areas, natural language interfaces, knowledge graphs, easily and effectively</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Conversational AI and Question-Answering systems (QASs) for knowledge graphs
(KGs) are both emerging research areas: they empower users with natural
language interfaces for extracting information easily and effectively.
Conversational AI simulates conversations with humans; however, it is limited
by the data captured in the training datasets. In contrast, QASs retrieve the
most recent information from a KG by understanding and translating the natural
language question into a formal query supported by the database engine.
In this paper, we present a comprehensive study of the characteristics of the
existing alternatives towards combining both worlds into novel KG chatbots. Our
framework compares two representative conversational models, ChatGPT and
Galactica, against KGQAN, the current state-of-the-art QAS. We conduct a
thorough evaluation using four real KGs across various application domains to
identify the current limitations of each category of systems. Based on our
findings, we propose open research opportunities to empower QASs with chatbot
capabilities for KGs. All benchmarks and all raw results are available1 for
further analysis.</p>
  </details>
</details>
<details>
  <summary>17. <b>标题：A Study on ReLU and Softmax in Transformer</b></summary>
  <p><b>编号</b>：[67]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06461</p>
  <p><b>作者</b>：Kai Shen,  Junliang Guo,  Xu Tan,  Siliang Tang,  Rui Wang,  Jiang Bian</p>
  <p><b>备注</b>：work in progress</p>
  <p><b>关键词</b>：Softmax, previous works, FFN, Transformer architecture consists, FFN and key-value</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The Transformer architecture consists of self-attention and feed-forward
networks (FFNs) which can be viewed as key-value memories according to previous
works. However, FFN and traditional memory utilize different activation
functions (i.e., ReLU and Softmax respectively), which makes them not
equivalent. In this paper, we first rebuild the connections between FFN and
key-value memory by conducting extensive studies on ReLU and Softmax, and find
they are equivalent when adding an additional layer normalization module on
Softmax. In addition, ReLU outperforms Softmax on both FFN and key-value memory
when the number of value slots is large. We analyze the reasons and then
explore this good property of ReLU on the self-attention network where the
original Softmax activation performs poorly on long input sequences. We then
propose a full ReLU architecture named ReLUFormer which performs better than
the baseline Transformer on long sequence tasks such as document translation.
This paper sheds light on the following points: 1) Softmax and ReLU use
different normalization methods over elements which lead to different variances
of results, and ReLU is good at dealing with a large number of key-value slots;
2) FFN and key-value memory are equivalent, and thus the Transformer can be
viewed as a memory network where FFNs and self-attention networks are both
key-value memories.</p>
  </details>
</details>
<details>
  <summary>18. <b>标题：Incremental Satisfiability Modulo Theory for Verification of Deep Neural  Networks</b></summary>
  <p><b>编号</b>：[71]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06455</p>
  <p><b>作者</b>：Pengfei Yang,  Zhiming Chi,  Zongxin Liu,  Mengyu Zhao,  Cheng-Chao Huang,  Shaowei Cai,  Lijun Zhang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：deep neural networks, DNN, incremental DNN verification, deep neural, DNN verification problem</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Constraint solving is an elementary way for verification of deep neural
networks (DNN). In the domain of AI safety, a DNN might be modified in its
structure and parameters for its repair or attack. For such situations, we
propose the incremental DNN verification problem, which asks whether a safety
property still holds after the DNN is modified. To solve the problem, we
present an incremental satisfiability modulo theory (SMT) algorithm based on
the Reluplex framework. We simulate the most important features of the
configurations that infers the verification result of the searching branches in
the old solving procedure (with respect to the original network), and
heuristically check whether the proofs are still valid for the modified DNN. We
implement our algorithm as an incremental solver called DeepInc, and
exerimental results show that DeepInc is more efficient in most cases. For the
cases that the property holds both before and after modification, the
acceleration can be faster by several orders of magnitude, showing that DeepInc
is outstanding in incrementally searching for counterexamples. Moreover, based
on the framework, we propose the multi-objective DNN repair problem and give an
algorithm based on our incremental SMT solving algorithm. Our repair method
preserves more potential safety properties on the repaired DNNs compared with
state-of-the-art.</p>
  </details>
</details>
<details>
  <summary>19. <b>标题：Mixed Multi-Model Semantic Interaction for Graph-based Narrative  Visualizations</b></summary>
  <p><b>编号</b>：[72]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06452</p>
  <p><b>作者</b>：Brian Keith Norambuena,  Tanushree Mitra,  Chris North</p>
  <p><b>备注</b>：24 pages, 9 figures, IUI 2023</p>
  <p><b>关键词</b>：understanding sequential data, sequential data, Narrative maps, essential part, part of understanding</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Narrative sensemaking is an essential part of understanding sequential data.
Narrative maps are a visual representation model that can assist analysts to
understand narratives. In this work, we present a semantic interaction (SI)
framework for narrative maps that can support analysts through their
sensemaking process. In contrast to traditional SI systems which rely on
dimensionality reduction and work on a projection space, our approach has an
additional abstraction layer -- the structure space -- that builds upon the
projection space and encodes the narrative in a discrete structure. This extra
layer introduces additional challenges that must be addressed when integrating
SI with the narrative extraction pipeline. We address these challenges by
presenting the general concept of Mixed Multi-Model Semantic Interaction (3MSI)
-- an SI pipeline, where the highest-level model corresponds to an abstract
discrete structure and the lower-level models are continuous. To evaluate the
performance of our 3MSI models for narrative maps, we present a quantitative
simulation-based evaluation and a qualitative evaluation with case studies and
expert feedback. We find that our SI system can model the analysts' intent and
support incremental formalism for narrative maps.</p>
  </details>
</details>
<details>
  <summary>20. <b>标题：Deep Graph-Level Orthogonal Hypersphere Compression for Anomaly  Detection</b></summary>
  <p><b>编号</b>：[84]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06430</p>
  <p><b>作者</b>：Yunhe Zhang,  Yan Sun,  Jinyu Cai,  Jicong Fan</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Graph-level anomaly detection, anomaly detection aims, anomaly detection, unsupervised manner, aims to identify</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Graph-level anomaly detection aims to identify anomalous graphs from a
collection of graphs in an unsupervised manner. A common assumption of anomaly
detection is that a reasonable decision boundary has a hypersphere shape, but
may appear some non-conforming phenomena in high dimensions. Towards this end,
we firstly propose a novel deep graph-level anomaly detection model, which
learns the graph representation with maximum mutual information between
substructure and global structure features while exploring a hypersphere
anomaly decision boundary. The idea is to ensure the training data distribution
consistent with the decision hypersphere via an orthogonal projection layer.
Moreover, we further perform the bi-hypersphere compression to emphasize the
discrimination of anomalous graphs from normal graphs. Note that our method is
not confined to graph data and is applicable to anomaly detection of other data
such as images. The numerical and visualization results on benchmark datasets
demonstrate the effectiveness and superiority of our methods in comparison to
many baselines and state-of-the-arts.</p>
  </details>
</details>
<details>
  <summary>21. <b>标题：Linguistic ambiguity analysis in ChatGPT</b></summary>
  <p><b>编号</b>：[86]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06426</p>
  <p><b>作者</b>：Miguel Ortega-Martín,  Óscar García-Sierra,  Alfonso Ardoiz,  Jorge Álvarez,  Juan Carlos Armenteros,  Adrián Alonso</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Natural Language Processing, main challenges, Language Processing, Natural Language, NLP</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Linguistic ambiguity is and has always been one of the main challenges in
Natural Language Processing (NLP) systems. Modern Transformer architectures
like BERT, T5 or more recently InstructGPT have achieved some impressive
improvements in many NLP fields, but there is still plenty of work to do.
Motivated by the uproar caused by ChatGPT, in this paper we provide an
introduction to linguistic ambiguity, its varieties and their relevance in
modern NLP, and perform an extensive empiric analysis. ChatGPT strengths and
weaknesses are revealed, as well as strategies to get the most of this model.</p>
  </details>
</details>
<details>
  <summary>22. <b>标题：AISYN: AI-driven Reinforcement Learning-Based Logic Synthesis Framework</b></summary>
  <p><b>编号</b>：[90]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06415</p>
  <p><b>作者</b>：Ghasem Pasandi,  Sreedhar Pratty,  James Forsyth</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Quality of Results, Directed Acyclic Graph, final Quality, Acyclic Graph, steps in design</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Logic synthesis is one of the most important steps in design and
implementation of digital chips with a big impact on final Quality of Results
(QoR). For a most general input circuit modeled by a Directed Acyclic Graph
(DAG), many logic synthesis problems such as delay or area minimization are
NP-Complete, hence, no optimal solution is available. This is why many
classical logic optimization functions tend to follow greedy approaches that
are easily trapped in local minima that does not allow improving QoR as much as
needed. We believe that Artificial Intelligence (AI) and more specifically
Reinforcement Learning (RL) algorithms can help in solving this problem. This
is because AI and RL can help minimizing QoR further by exiting from local
minima. Our experiments on both open source and industrial benchmark circuits
show that significant improvements on important metrics such as area, delay,
and power can be achieved by making logic synthesis optimization functions
AI-driven. For example, our RL-based rewriting algorithm could improve total
cell area post-synthesis by up to 69.3% when compared to a classical rewriting
algorithm with no AI awareness.</p>
  </details>
</details>
<details>
  <summary>23. <b>标题：LAPTNet-FPN: Multi-scale LiDAR-aided Projective Transform Network for  Real Time Semantic Grid Prediction</b></summary>
  <p><b>编号</b>：[91]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06414</p>
  <p><b>作者</b>：Manuel Alejandro Diaz-Zapata (CHROMA),  David Sierra González (CHROMA),  Özgür Erkent (CHROMA),  Jilles Dibangoye (CHROMA),  Christian Laugier (CHROMA, E-MOTION, Inria)</p>
  <p><b>备注</b>：2023 IEEE International Conference on Robotics and Automation (ICRA), IEEE Robotics and Automation Society, May 2023, London, United Kingdom</p>
  <p><b>关键词</b>：autonomous system, semantic grid generation, information, Semantic grids, representation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Semantic grids can be useful representations of the scene around an
autonomous system. By having information about the layout of the space around
itself, a robot can leverage this type of representation for crucial tasks such
as navigation or tracking. By fusing information from multiple sensors,
robustness can be increased and the computational load for the task can be
lowered, achieving real time performance. Our multi-scale LiDAR-Aided
Perspective Transform network uses information available in point clouds to
guide the projection of image features to a top-view representation, resulting
in a relative improvement in the state of the art for semantic grid generation
for human (+8.67%) and movable object (+49.07%) classes in the nuScenes
dataset, as well as achieving results close to the state of the art for the
vehicle, drivable area and walkway classes, while performing inference at 25
FPS.</p>
  </details>
</details>
<details>
  <summary>24. <b>标题：Correcting Real-Word Spelling Errors: A New Hybrid Approach</b></summary>
  <p><b>编号</b>：[93]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06407</p>
  <p><b>作者</b>：Seyed MohammadSadegh Dashti,  Amid Khatibi Bardsiri,  Vahid Khatibi Bardsiri</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Natural Language, field of Natural, main tasks, Language, Damerau and Mercer</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Spelling correction is one of the main tasks in the field of Natural Language
Processing. Contrary to common spelling errors, real-word errors cannot be
detected by conventional spelling correction methods. The real-word correction
model proposed by Mays, Damerau and Mercer showed a great performance in
different evaluations. In this research, however, a new hybrid approach is
proposed which relies on statistical and syntactic knowledge to detect and
correct real-word errors. In this model, Constraint Grammar (CG) is used to
discriminate among sets of correction candidates in the search space. Mays,
Damerau and Mercer's trigram approach is manipulated to estimate the
probability of syntactically well-formed correction candidates. The approach
proposed here is tested on the Wall Street Journal corpus. The model can prove
to be more practical than some other models, such as WordNet-based method of
Hirst and Budanitsky and fixed windows size method of Wilcox-O'Hearn and Hirst.</p>
  </details>
</details>
<details>
  <summary>25. <b>标题：One Transformer for All Time Series: Representing and Training with  Time-Dependent Heterogeneous Tabular Data</b></summary>
  <p><b>编号</b>：[104]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06375</p>
  <p><b>作者</b>：Simone Luetto,  Fabrizio Garuti,  Enver Sangineto,  Lorenzo Forni,  Rita Cucchiara</p>
  <p><b>备注</b>：9 pages, 2 figures, 7 tables</p>
  <p><b>关键词</b>：applying Deep Learning, Deep Learning techniques, recent growing interest, Deep Learning, applying Deep</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>There is a recent growing interest in applying Deep Learning techniques to
tabular data, in order to replicate the success of other Artificial
Intelligence areas in this structured domain. Specifically interesting is the
case in which tabular data have a time dependence, such as, for instance
financial transactions. However, the heterogeneity of the tabular values, in
which categorical elements are mixed with numerical items, makes this
adaptation difficult. In this paper we propose a Transformer architecture to
represent heterogeneous time-dependent tabular data, in which numerical
features are represented using a set of frequency functions and the whole
network is uniformly trained with a unique loss function.</p>
  </details>
</details>
<details>
  <summary>26. <b>标题：SubTuning: Efficient Finetuning for Multi-Task Learning</b></summary>
  <p><b>编号</b>：[117]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06354</p>
  <p><b>作者</b>：Gal Kaplun,  Andrey Gurevich,  Tal Swisa,  Mazor David,  Shai Shalev-Shwartz,  Eran Malach</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：training neural networks, resulting in fast, standard approach, fast convergence, convergence and improved</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Finetuning a pretrained model has become a standard approach for training
neural networks on novel tasks, resulting in fast convergence and improved
performance. In this work, we study an alternative finetuning method, where
instead of finetuning all the weights of the network, we only train a carefully
chosen subset of layers, keeping the rest of the weights frozen at their
initial (pretrained) values. We demonstrate that \emph{subset finetuning} (or
SubTuning) often achieves accuracy comparable to full finetuning of the model,
and even surpasses the performance of full finetuning when training data is
scarce. Therefore, SubTuning allows deploying new tasks at minimal
computational cost, while enjoying the benefits of finetuning the entire model.
This yields a simple and effective method for multi-task learning, where
different tasks do not interfere with one another, and yet share most of the
resources at inference time. We demonstrate the efficiency of SubTuning across
multiple tasks, using different network architectures and pretraining methods.</p>
  </details>
</details>
<details>
  <summary>27. <b>标题：Text2shape Deep Retrieval Model: Generating Initial Cases for Mechanical  Part Redesign under the Context of Case-Based Reasoning</b></summary>
  <p><b>编号</b>：[124]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06341</p>
  <p><b>作者</b>：Tianshuo Zang,  Maolin Yang,  Wentao Yong,  Pingyu Jiang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：historical case base, structural features, target mechanical parts, mechanical part redesign, key structural features</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Retrieving the similar solutions from the historical case base for new design
requirements is the first step in mechanical part redesign under the context of
case-based reasoning. However, the manual retrieving method has the problem of
low efficiency when the case base is large. Additionally, it is difficult for
simple reasoning algorithms (e.g., rule-based reasoning, decision tree) to
cover all the features in complicated design solutions. In this regard, a
text2shape deep retrieval model is established in order to support text
description-based mechanical part shapes retrieval, where the texts are for
describing the structural features of the target mechanical parts. More
specifically, feature engineering is applied to identify the key structural
features of the target mechanical parts. Based on the identified key structural
features, a training set of 1000 samples was constructed, where each sample
consisted of a paragraph of text description of a group of structural features
and the corresponding 3D shape of the structural features. RNN and 3D CNN
algorithms were customized to build the text2shape deep retrieval model.
Orthogonal experiments were used for modeling turning. Eventually, the highest
accuracy of the model was 0.98; therefore, the model can be effective for
retrieving initial cases for mechanical part redesign.</p>
  </details>
</details>
<details>
  <summary>28. <b>标题：Learning from Noisy Crowd Labels with Logics</b></summary>
  <p><b>编号</b>：[125]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06337</p>
  <p><b>作者</b>：Zhijun Chen,  Hailong Sun,  Haoqian He,  Pengpeng Chen</p>
  <p><b>备注</b>：12 pages, 7 figures, accepted by ICDE-2023. arXiv admin note: text overlap with arXiv:1603.06318 by other authors</p>
  <p><b>关键词</b>：noisy crowd labels, deep neural networks, crowd labels, noisy crowd, symbolic logic knowledge</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper explores the integration of symbolic logic knowledge into deep
neural networks for learning from noisy crowd labels. We introduce Logic-guided
Learning from Noisy Crowd Labels (Logic-LNCL), an EM-alike iterative logic
knowledge distillation framework that learns from both noisy labeled data and
logic rules of interest. Unlike traditional EM methods, our framework contains
a ``pseudo-E-step'' that distills from the logic rules a new type of learning
target, which is then used in the ``pseudo-M-step'' for training the
classifier. Extensive evaluations on two real-world datasets for text sentiment
classification and named entity recognition demonstrate that the proposed
framework improves the state-of-the-art and provides a new solution to learning
from noisy crowd labels.</p>
  </details>
</details>
<details>
  <summary>29. <b>标题：Parameter-efficient Modularised Bias Mitigation via AdapterFusion</b></summary>
  <p><b>编号</b>：[130]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06321</p>
  <p><b>作者</b>：Deepak Kumar,  Oleg Lesota,  George Zerveas,  Daniel Cohen,  Carsten Eickhoff,  Markus Schedl,  Navid Rekabsaz</p>
  <p><b>备注</b>：Accepted at EACL 2023</p>
  <p><b>关键词</b>：pre-trained language models, Large pre-trained language, societal biases, pre-trained language, model</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large pre-trained language models contain societal biases and carry along
these biases to downstream tasks. Current in-processing bias mitigation
approaches (like adversarial training) impose debiasing by updating a model's
parameters, effectively transferring the model to a new, irreversible debiased
state. In this work, we propose a novel approach to develop stand-alone
debiasing functionalities separate from the model, which can be integrated into
the model on-demand, while keeping the core model untouched. Drawing from the
concept of AdapterFusion in multi-task learning, we introduce DAM (Debiasing
with Adapter Modules) - a debiasing approach to first encapsulate arbitrary
bias mitigation functionalities into separate adapters, and then add them to
the model on-demand in order to deliver fairness qualities. We conduct a large
set of experiments on three classification tasks with gender, race, and age as
protected attributes. Our results show that DAM improves or maintains the
effectiveness of bias mitigation, avoids catastrophic forgetting in a
multi-attribute scenario, and maintains on-par task performance, while granting
parameter-efficiency and easy switching between the original and debiased
models.</p>
  </details>
</details>
<details>
  <summary>30. <b>标题：Homophily-oriented Heterogeneous Graph Rewiring</b></summary>
  <p><b>编号</b>：[136]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06299</p>
  <p><b>作者</b>：Jiayan Guo,  Lun Du,  Wendong Bi,  Qiang Fu,  Xiaojun Ma,  Xu Chen,  Shi Han,  Dongmei Zhang,  Yan Zhang</p>
  <p><b>备注</b>：Accepted by WWW 2023;</p>
  <p><b>关键词</b>：World Wide Web, Wide Web, World Wide, explosive growth, rapid development</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>With the rapid development of the World Wide Web (WWW), heterogeneous graphs
(HG) have explosive growth. Recently, heterogeneous graph neural network (HGNN)
has shown great potential in learning on HG. Current studies of HGNN mainly
focus on some HGs with strong homophily properties (nodes connected by
meta-path tend to have the same labels), while few discussions are made in
those that are less homophilous. Recently, there have been many works on
homogeneous graphs with heterophily. However, due to heterogeneity, it is
non-trivial to extend their approach to deal with HGs with heterophily. In this
work, based on empirical observations, we propose a meta-path-induced metric to
measure the homophily degree of a HG. We also find that current HGNNs may have
degenerated performance when handling HGs with less homophilous properties.
Thus it is essential to increase the generalization ability of HGNNs on
non-homophilous HGs. To this end, we propose HDHGR, a homophily-oriented deep
heterogeneous graph rewiring approach that modifies the HG structure to
increase the performance of HGNN. We theoretically verify HDHGR. In addition,
experiments on real-world HGs demonstrate the effectiveness of HDHGR, which
brings at most more than 10% relative gain.</p>
  </details>
</details>
<details>
  <summary>31. <b>标题：Unlabeled Imperfect Demonstrations in Adversarial Imitation Learning</b></summary>
  <p><b>编号</b>：[147]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06271</p>
  <p><b>作者</b>：Yunke Wang,  Bo Du,  Chang Xu</p>
  <p><b>备注</b>：AAAI 2023</p>
  <p><b>关键词</b>：expert demonstrations, demonstrations, expert, imperfect expert demonstrations, Adversarial imitation learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Adversarial imitation learning has become a widely used imitation learning
framework. The discriminator is often trained by taking expert demonstrations
and policy trajectories as examples respectively from two categories (positive
vs. negative) and the policy is then expected to produce trajectories that are
indistinguishable from the expert demonstrations. But in the real world, the
collected expert demonstrations are more likely to be imperfect, where only an
unknown fraction of the demonstrations are optimal. Instead of treating
imperfect expert demonstrations as absolutely positive or negative, we
investigate unlabeled imperfect expert demonstrations as they are. A
positive-unlabeled adversarial imitation learning algorithm is developed to
dynamically sample expert demonstrations that can well match the trajectories
from the constantly optimized agent policy. The trajectories of an initial
agent policy could be closer to those non-optimal expert demonstrations, but
within the framework of adversarial imitation learning, agent policy will be
optimized to cheat the discriminator and produce trajectories that are similar
to those optimal expert demonstrations. Theoretical analysis shows that our
method learns from the imperfect demonstrations via a self-paced way.
Experimental results on MuJoCo and RoboSuite platforms demonstrate the
effectiveness of our method from different aspects.</p>
  </details>
</details>
<details>
  <summary>32. <b>标题：A Lifetime Extended Energy Management Strategy for Fuel Cell Hybrid  Electric Vehicles via Self-Learning Fuzzy Reinforcement Learning</b></summary>
  <p><b>编号</b>：[161]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06236</p>
  <p><b>作者</b>：Liang Guo (PECASE, AMU),  Zhongliang Li (FEMTO-ST, UTBM),  Rachid Outbib (PECASE, AMU)</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：fuel cells system, fuel cell hybrid, cell hybrid electric, hybrid electric vehicles, fuel cells</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Modeling difficulty, time-varying model, and uncertain external inputs are
the main challenges for energy management of fuel cell hybrid electric
vehicles. In the paper, a fuzzy reinforcement learning-based energy management
strategy for fuel cell hybrid electric vehicles is proposed to reduce fuel
consumption, maintain the batteries' long-term operation, and extend the
lifetime of the fuel cells system. Fuzzy Q-learning is a model-free
reinforcement learning that can learn itself by interacting with the
environment, so there is no need for modeling the fuel cells system. In
addition, frequent startup of the fuel cells will reduce the remaining useful
life of the fuel cells system. The proposed method suppresses frequent fuel
cells startup by considering the penalty for the times of fuel cell startups in
the reward of reinforcement learning. Moreover, applying fuzzy logic to
approximate the value function in Q-Learning can solve continuous state and
action space problems. Finally, a python-based training and testing platform
verify the effectiveness and self-learning improvement of the proposed method
under conditions of initial state change, model change and driving condition
change.</p>
  </details>
</details>
<details>
  <summary>33. <b>标题：Link Prediction with Attention Applied on Multiple Knowledge Graph  Embedding Models</b></summary>
  <p><b>编号</b>：[165]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06229</p>
  <p><b>作者</b>：Cosimo Gregucci,  Mojtaba Nayyeri,  Daniel Hernández,  Steffen Staab</p>
  <p><b>备注</b>：ACM Web Conference 2023</p>
  <p><b>关键词</b>：Predicting missing links, Predicting missing, fundamental task, task to deal, incompleteness of data</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Predicting missing links between entities in a knowledge graph is a
fundamental task to deal with the incompleteness of data on the Web. Knowledge
graph embeddings map nodes into a vector space to predict new links, scoring
them according to geometric criteria. Relations in the graph may follow
patterns that can be learned, e.g., some relations might be symmetric and
others might be hierarchical. However, the learning capability of different
embedding models varies for each pattern and, so far, no single model can learn
all patterns equally well. In this paper, we combine the query representations
from several models in a unified one to incorporate patterns that are
independently captured by each model. Our combination uses attention to select
the most suitable model to answer each query. The models are also mapped onto a
non-Euclidean manifold, the Poincaré ball, to capture structural patterns,
such as hierarchies, besides relational patterns, such as symmetry. We prove
that our combination provides a higher expressiveness and inference power than
each model on its own. As a result, the combined model can learn relational and
structural patterns. We conduct extensive experimental analysis with various
link prediction benchmarks showing that the combined model outperforms
individual models, including state-of-the-art approaches.</p>
  </details>
</details>
<details>
  <summary>34. <b>标题：A Unified View of Long-Sequence Models towards Million-Scale  Dependencies</b></summary>
  <p><b>编号</b>：[169]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06218</p>
  <p><b>作者</b>：Hongyu Hè,  Marko Kabic</p>
  <p><b>备注</b>：20 pages, 7 figures</p>
  <p><b>关键词</b>：image classification, audio processing, fast training, training and superior, NLP</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Ever since their conception, Transformers have taken over traditional
sequence models in many tasks, such as NLP, image classification, and
video/audio processing, for their fast training and superior performance. Much
of these merits result from positional encoding and multi-head attention.
However, Transformers fall short in learning long-range dependencies mainly due
to the quadratic complexity scaled with context length, in terms of both time
and space. Consequently, over the past five years, a myriad of methods has been
proposed to make Transformers more efficient. In this work, we first take a
step back, study and compare existing solutions to long-sequence modeling in
terms of their pure mathematical formulation. Specifically, we summarize them
using a unified template, given their shared nature of token mixing. Through
benchmarks, we then demonstrate that long context length does yield better
performance, albeit application-dependent, and traditional Transformer models
fall short in taking advantage of long-range dependencies. Next, inspired by
emerging sparse models of huge capacity, we propose a machine learning system
for handling million-scale dependencies. As a proof of concept, we evaluate the
performance of one essential component of this system, namely, the distributed
multi-head attention. We show that our algorithm can scale up attention
computation by almost $40\times$ using four GeForce RTX 4090 GPUs, compared to
vanilla multi-head attention mechanism. We believe this study is an
instrumental step towards modeling million-scale dependencies.</p>
  </details>
</details>
<details>
  <summary>35. <b>标题：Order Matters: Agent-by-agent Policy Optimization</b></summary>
  <p><b>编号</b>：[171]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06205</p>
  <p><b>作者</b>：Xihuai Wang,  Zheng Tian,  Ziyu Wan,  Ying Wen,  Jun Wang,  Weinan Zhang</p>
  <p><b>备注</b>：Accepted by ICLR2023, this https URL</p>
  <p><b>关键词</b>：solving coordination tasks, achieved great success, great success empirically, coordination tasks, achieved great</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>While multi-agent trust region algorithms have achieved great success
empirically in solving coordination tasks, most of them, however, suffer from a
non-stationarity problem since agents update their policies simultaneously. In
contrast, a sequential scheme that updates policies agent-by-agent provides
another perspective and shows strong performance. However, sample inefficiency
and lack of monotonic improvement guarantees for each agent are still the two
significant challenges for the sequential scheme. In this paper, we propose the
\textbf{A}gent-by-\textbf{a}gent \textbf{P}olicy \textbf{O}ptimization (A2PO)
algorithm to improve the sample efficiency and retain the guarantees of
monotonic improvement for each agent during training. We justify the tightness
of the monotonic improvement bound compared with other trust region algorithms.
From the perspective of sequentially updating agents, we further consider the
effect of agent updating order and extend the theory of non-stationarity into
the sequential update scheme. To evaluate A2PO, we conduct a comprehensive
empirical study on four benchmarks: StarCraftII, Multi-agent MuJoCo,
Multi-agent Particle Environment, and Google Research Football full game
scenarios. A2PO consistently outperforms strong baselines.</p>
  </details>
</details>
<details>
  <summary>36. <b>标题：Exploring Navigation Maps for Learning-Based Motion Prediction</b></summary>
  <p><b>编号</b>：[175]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06195</p>
  <p><b>作者</b>：Julian Schmidt,  Julian Jordan,  Franz Gritschneder,  Thomas Monninger,  Klaus Dietmayer</p>
  <p><b>备注</b>：Accepted to the 2023 IEEE International Conference on Robotics and Automation (ICRA 2023)</p>
  <p><b>关键词</b>：safe autonomous driving, surrounding agents' motion, predominant High Definition, navigation maps, learning-based motion prediction</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The prediction of surrounding agents' motion is a key for safe autonomous
driving. In this paper, we explore navigation maps as an alternative to the
predominant High Definition (HD) maps for learning-based motion prediction.
Navigation maps provide topological and geometrical information on road-level,
HD maps additionally have centimeter-accurate lane-level information. As a
result, HD maps are costly and time-consuming to obtain, while navigation maps
with near-global coverage are freely available. We describe an approach to
integrate navigation maps into learning-based motion prediction models. To
exploit locally available HD maps during training, we additionally propose a
model-agnostic method for knowledge distillation. In experiments on the
publicly available Argoverse dataset with navigation maps obtained from
OpenStreetMap, our approach shows a significant improvement over not using a
map at all. Combined with our method for knowledge distillation, we achieve
results that are close to the original HD map-reliant models. Our publicly
available navigation map API for Argoverse enables researchers to develop and
evaluate their own approaches using navigation maps.</p>
  </details>
</details>
<details>
  <summary>37. <b>标题：Enhancing SMT-based Weighted Model Integration by Structure Awareness</b></summary>
  <p><b>编号</b>：[177]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06188</p>
  <p><b>作者</b>：Giuseppe Spallitta,  Gabriele Masina,  Paolo Morettin,  Andrea Passerini,  Roberto Sebastiani</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：artificial intelligence research, intelligence research, long-standing goal, goal of artificial, artificial intelligence</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The development of efficient exact and approximate algorithms for
probabilistic inference is a long-standing goal of artificial intelligence
research. Whereas substantial progress has been made in dealing with purely
discrete or purely continuous domains, adapting the developed solutions to
tackle hybrid domains, characterised by discrete and continuous variables and
their relationships, is highly non-trivial. Weighted Model Integration (WMI)
recently emerged as a unifying formalism for probabilistic inference in hybrid
domains. Despite a considerable amount of recent work, allowing WMI algorithms
to scale with the complexity of the hybrid problem is still a challenge. In
this paper we highlight some substantial limitations of existing
state-of-the-art solutions, and develop an algorithm that combines SMT-based
enumeration, an efficient technique in formal verification, with an effective
encoding of the problem structure. This allows our algorithm to avoid
generating redundant models, resulting in drastic computational savings.
Additionally, we show how SMT-based approaches can seamlessly deal with
different integration techniques, both exact and approximate, significantly
expanding the set of problems that can be tackled by WMI technology. An
extensive experimental evaluation on both synthetic and real-world datasets
confirms the substantial advantage of the proposed solution over existing
alternatives. The application potential of this technology is further showcased
on a prototypical task aimed at verifying the fairness of probabilistic
programs.</p>
  </details>
</details>
<details>
  <summary>38. <b>标题：Identifying Semantically Difficult Samples to Improve Text  Classification</b></summary>
  <p><b>编号</b>：[193]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06155</p>
  <p><b>作者</b>：Shashank Mujumdar,  Stuti Mehta,  Hima Patel,  Suman Mitra</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：text classification task, downstream text classification, addressing difficult samples, text classification, investigate the effect</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we investigate the effect of addressing difficult samples from
a given text dataset on the downstream text classification task. We define
difficult samples as being non-obvious cases for text classification by
analysing them in the semantic embedding space; specifically - (i) semantically
similar samples that belong to different classes and (ii) semantically
dissimilar samples that belong to the same class. We propose a penalty function
to measure the overall difficulty score of every sample in the dataset. We
conduct exhaustive experiments on 13 standard datasets to show a consistent
improvement of up to 9% and discuss qualitative results to show effectiveness
of our approach in identifying difficult samples for a text classification
model.</p>
  </details>
</details>
<details>
  <summary>39. <b>标题：RFC-Net: Learning High Resolution Global Features for Medical Image  Segmentation on a Computational Budget</b></summary>
  <p><b>编号</b>：[201]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06134</p>
  <p><b>作者</b>：Sourajit Saha,  Shaswati Saha,  Md Osman Gani,  Tim Oates,  David Chapman</p>
  <p><b>备注</b>：In Proceedings of AAAI Conference on Artificial Intelligence 2023</p>
  <p><b>关键词</b>：Learning High-Resolution representations, Learning High-Resolution, High-Resolution representations, representations is essential, essential for semantic</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Learning High-Resolution representations is essential for semantic
segmentation. Convolutional neural network (CNN)architectures with downstream
and upstream propagation flow are popular for segmentation in medical
diagnosis. However, due to performing spatial downsampling and upsampling in
multiple stages, information loss is inexorable. On the contrary, connecting
layers densely on high spatial resolution is computationally expensive. In this
work, we devise a Loose Dense Connection Strategy to connect neurons in
subsequent layers with reduced parameters. On top of that, using a m-way Tree
structure for feature propagation we propose Receptive Field Chain Network
(RFC-Net) that learns high resolution global features on a compressed
computational space. Our experiments demonstrates that RFC-Net achieves
state-of-the-art performance on Kvasir and CVC-ClinicDB benchmarks for Polyp
segmentation.</p>
  </details>
</details>
<details>
  <summary>40. <b>标题：Can GPT-3 Perform Statutory Reasoning?</b></summary>
  <p><b>编号</b>：[216]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06100</p>
  <p><b>作者</b>：Andrew Blair-Stanek,  Nils Holzenberger,  Benjamin Van Durme</p>
  <p><b>备注</b>：9 pages</p>
  <p><b>关键词</b>：Statutory reasoning, natural language, reasoning with facts, task of reasoning, reasoning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Statutory reasoning is the task of reasoning with facts and statutes, which
are rules written in natural language by a legislature. It is a basic legal
skill. In this paper we explore the capabilities of the most capable GPT-3
model, text-davinci-003, on an established statutory-reasoning dataset called
SARA. We consider a variety of approaches, including dynamic few-shot
prompting, chain-of-thought prompting, and zero-shot prompting. While we
achieve results with GPT-3 that are better than the previous best published
results, we also identify several types of clear errors it makes. In
investigating why these happen, we discover that GPT-3 has imperfect prior
knowledge of the actual U.S. statutes on which SARA is based. More importantly,
GPT-3 performs poorly at answering straightforward questions about simple
synthetic statutes. By also posing the same questions when the synthetic
statutes are written in sentence form, we find that some of GPT-3's poor
performance results from difficulty in parsing the typical structure of
statutes, containing subsections and paragraphs.</p>
  </details>
</details>
<details>
  <summary>41. <b>标题：Boosted ab initio Cryo-EM 3D Reconstruction with ACE-EM</b></summary>
  <p><b>编号</b>：[220]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06091</p>
  <p><b>作者</b>：Lin Yao (1),  Ruihan Xu (2),  Zhifeng Gao (1),  Guolin Ke (1),  Yuhang Wang (1) ((1) DP Technology, Ltd., Beijing, China (2) Peking University, Beijing, China)</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：missing projection angles, projection angles, projection images, missing projection, structure from noisy</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The central problem in cryo-electron microscopy (cryo-EM) is to recover the
3D structure from noisy 2D projection images which requires estimating the
missing projection angles (poses). Recent methods attempted to solve the 3D
reconstruction problem with the autoencoder architecture, which suffers from
the latent vector space sampling problem and frequently produces suboptimal
pose inferences and inferior 3D reconstructions. Here we present an improved
autoencoder architecture called ACE (Asymmetric Complementary autoEncoder),
based on which we designed the ACE-EM method for cryo-EM 3D reconstructions.
Compared to previous methods, ACE-EM reached higher pose space coverage within
the same training time and boosted the reconstruction performance regardless of
the choice of decoders. With this method, the Nyquist resolution (highest
possible resolution) was reached for 3D reconstructions of both simulated and
experimental cryo-EM datasets. Furthermore, ACE-EM is the only amortized
inference method that reached the Nyquist resolution.</p>
  </details>
</details>
<details>
  <summary>42. <b>标题：Universal Agent Mixtures and the Geometry of Intelligence</b></summary>
  <p><b>编号</b>：[225]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06083</p>
  <p><b>作者</b>：Samuel Allen Alexander,  David Quarel,  Len Du,  Marcus Hutter</p>
  <p><b>备注</b>：16 pages, accepted to AISTATS23</p>
  <p><b>关键词</b>：multi-agent Reinforcement Learning, Reinforcement Learning, collective intelligent behaviour, multi-agent Reinforcement, theoretical universal agents</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Inspired by recent progress in multi-agent Reinforcement Learning (RL), in
this work we examine the collective intelligent behaviour of theoretical
universal agents by introducing a weighted mixture operation. Given a weighted
set of agents, their weighted mixture is a new agent whose expected total
reward in any environment is the corresponding weighted average of the original
agents' expected total rewards in that environment. Thus, if RL agent
intelligence is quantified in terms of performance across environments, the
weighted mixture's intelligence is the weighted average of the original agents'
intelligences. This operation enables various interesting new theorems that
shed light on the geometry of RL agent intelligence, namely: results about
symmetries, convex agent-sets, and local extrema. We also show that any RL
agent intelligence measure based on average performance across environments,
subject to certain weak technical conditions, is identical (up to a constant
factor) to performance within a single environment dependent on said
intelligence measure.</p>
  </details>
</details>
<details>
  <summary>43. <b>标题：GAIN: Enhancing Byzantine Robustness in Federated Learning with Gradient  Decomposition</b></summary>
  <p><b>编号</b>：[228]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06079</p>
  <p><b>作者</b>：Yuchen Liu,  Chen Chen,  Lingjuan Lyu,  Fangzhao Wu,  Sai Wu,  Gang Chen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：privacy-aware learning framework, jointly train models, Federated learning, private data, framework by enabling</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Federated learning provides a privacy-aware learning framework by enabling
participants to jointly train models without exposing their private data.
However, federated learning has exhibited vulnerabilities to Byzantine attacks,
where the adversary aims to destroy the convergence and performance of the
global model. Meanwhile, we observe that most existing robust AGgregation Rules
(AGRs) fail to stop the aggregated gradient deviating from the optimal gradient
(the average of honest gradients) in the non-IID setting. We attribute the
reason of the failure of these AGRs to two newly proposed concepts:
identification failure and integrity failure. The identification failure mainly
comes from the exacerbated curse of dimensionality in the non-IID setting. The
integrity failure is a combined result of conservative filtering strategy and
gradient heterogeneity. In order to address both failures, we propose GAIN, a
gradient decomposition scheme that can help adapt existing robust algorithms to
heterogeneous datasets. We also provide convergence analysis for integrating
existing robust AGRs into GAIN. Experiments on various real-world datasets
verify the efficacy of our proposed GAIN.</p>
  </details>
</details>
<details>
  <summary>44. <b>标题：Actional Atomic-Concept Learning for Demystifying Vision-Language  Navigation</b></summary>
  <p><b>编号</b>：[230]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06072</p>
  <p><b>作者</b>：Bingqian Lin,  Yi Zhu,  Xiaodan Liang,  Liang Lin,  Jianzhuang Liu</p>
  <p><b>备注</b>：Accepted by AAAI 2023</p>
  <p><b>关键词</b>：align complex visual, complex visual observations, actional atomic concepts, actional atomic, goal position</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Vision-Language Navigation (VLN) is a challenging task which requires an
agent to align complex visual observations to language instructions to reach
the goal position. Most existing VLN agents directly learn to align the raw
directional features and visual features trained using one-hot labels to
linguistic instruction features. However, the big semantic gap among these
multi-modal inputs makes the alignment difficult and therefore limits the
navigation performance. In this paper, we propose Actional Atomic-Concept
Learning (AACL), which maps visual observations to actional atomic concepts for
facilitating the alignment. Specifically, an actional atomic concept is a
natural language phrase containing an atomic action and an object, e.g., ``go
up stairs''. These actional atomic concepts, which serve as the bridge between
observations and instructions, can effectively mitigate the semantic gap and
simplify the alignment. AACL contains three core components: 1) a concept
mapping module to map the observations to the actional atomic concept
representations through the VLN environment and the recently proposed
Contrastive Language-Image Pretraining (CLIP) model, 2) a concept refining
adapter to encourage more instruction-oriented object concept extraction by
re-ranking the predicted object concepts by CLIP, and 3) an observation
co-embedding module which utilizes concept representations to regularize the
observation representations. Our AACL establishes new state-of-the-art results
on both fine-grained (R2R) and high-level (REVERIE and R2R-Last) VLN
benchmarks. Moreover, the visualization shows that AACL significantly improves
the interpretability in action decision.</p>
  </details>
</details>
<details>
  <summary>45. <b>标题：Threatening Patch Attacks on Object Detection in Optical Remote Sensing  Images</b></summary>
  <p><b>编号</b>：[236]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06060</p>
  <p><b>作者</b>：Xuxiang Sun,  Gong Cheng,  Lei Pei,  Hongda Li,  Junwei Han</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Advanced Patch Attacks, deep neural networks, great safety vulnerability, Patch Attacks, neural networks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Advanced Patch Attacks (PAs) on object detection in natural images have
pointed out the great safety vulnerability in methods based on deep neural
networks. However, little attention has been paid to this topic in Optical
Remote Sensing Images (O-RSIs). To this end, we focus on this research, i.e.,
PAs on object detection in O-RSIs, and propose a more Threatening PA without
the scarification of the visual quality, dubbed TPA. Specifically, to address
the problem of inconsistency between local and global landscapes in existing
patch selection schemes, we propose leveraging the First-Order Difference (FOD)
of the objective function before and after masking to select the sub-patches to
be attacked. Further, considering the problem of gradient inundation when
applying existing coordinate-based loss to PAs directly, we design an IoU-based
objective function specific for PAs, dubbed Bounding box Drifting Loss (BDL),
which pushes the detected bounding boxes far from the initial ones until there
are no intersections between them. Finally, on two widely used benchmarks,
i.e., DIOR and DOTA, comprehensive evaluations of our TPA with four typical
detectors (Faster R-CNN, FCOS, RetinaNet, and YOLO-v4) witness its remarkable
effectiveness. To the best of our knowledge, this is the first attempt to study
the PAs on object detection in O-RSIs, and we hope this work can get our
readers interested in studying this topic.</p>
  </details>
</details>
<details>
  <summary>46. <b>标题：Computation Offloading for Uncertain Marine Tasks by Cooperation of UAVs  and Vessels</b></summary>
  <p><b>编号</b>：[239]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06055</p>
  <p><b>作者</b>：Jiahao You,  Ziye Jia,  Chao Dong,  Lijun He,  Yilu Cao,  Qihui Wu</p>
  <p><b>备注</b>：6 pages, 6 figures, conference</p>
  <p><b>关键词</b>：continuous increment, limited maritime network, maritime network resources, maritime applications, maritime task offloading</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>With the continuous increment of maritime applications, the development of
marine networks for data offloading becomes necessary. However, the limited
maritime network resources are very difficult to satisfy real-time demands.
Besides, how to effectively handle multiple compute-intensive tasks becomes
another intractable issue. Hence, in this paper, we focus on the decision of
maritime task offloading by the cooperation of unmanned aerial vehicles (UAVs)
and vessels. Specifically, we first propose a cooperative offloading framework,
including the demands from marine Internet of Things (MIoTs) devices and
resource providers from UAVs and vessels. Due to the limited energy and
computation ability of UAVs, it is necessary to help better apply the vessels
to computation offloading. Then, we formulate the studied problem into a Markov
decision process, aiming to minimize the total execution time and energy cost.
Then, we leverage Lyapunov optimization to convert the long-term constraints of
the total execution time and energy cost into their short-term constraints,
further yielding a set of per-time-slot optimization problems. Furthermore, we
propose a Q-learning based approach to solve the short-term problem
efficiently. Finally, simulation results are conducted to verify the
correctness and effectiveness of the proposed algorithm.</p>
  </details>
</details>
<details>
  <summary>47. <b>标题：End-to-End Deep Learning Framework for Real-Time Inertial Attitude  Estimation using 6DoF IMU</b></summary>
  <p><b>编号</b>：[246]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06037</p>
  <p><b>作者</b>：Arman Asgharpoor Golroudbari,  Mohammad Hossein Sabour</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Inertial Measurement Units, Measurement Units, medical sciences, engineering to medical, IMU measurements</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Inertial Measurement Units (IMU) are commonly used in inertial attitude
estimation from engineering to medical sciences. There may be disturbances and
high dynamics in the environment of these applications. Also, their motion
characteristics and patterns also may differ. Many conventional filters have
been proposed to tackle the inertial attitude estimation problem based on IMU
measurements. There is no generalization over motion and environmental
characteristics in these filters. As a result, the presented conventional
filters will face various motion characteristics and patterns, which will limit
filter performance and need to optimize the filter parameters for each
situation. In this paper, two end-to-end deep-learning models are proposed to
solve the problem of real-time attitude estimation by using inertial sensor
measurements, which are generalized to motion patterns, sampling rates, and
environmental disturbances. The proposed models incorporate accelerometer and
gyroscope readings as inputs, which are collected from a combination of seven
public datasets. The models consist of convolutional neural network (CNN)
layers combined with Bi-Directional Long-Short Term Memory (LSTM) followed by a
Fully Forward Neural Network (FFNN) to estimate the quaternion. To evaluate the
validity and reliability, we have performed an extensive and comprehensive
evaluation over seven publicly available datasets, which consist of more than
120 hours and 200 kilometers of IMU measurements. The results show that the
proposed method outperforms the state-of-the-art methods in terms of accuracy
and robustness. Furthermore, it demonstrates that this model generalizes better
than other methods over various motion characteristics and sensor sampling
rates.</p>
  </details>
</details>
<details>
  <summary>48. <b>标题：ASR Bundestag: A Large-Scale political debate dataset in German</b></summary>
  <p><b>编号</b>：[258]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06008</p>
  <p><b>作者</b>：Johannes Wirth,  René Peinl</p>
  <p><b>备注</b>：13 pages, 2 tables, 4 figures</p>
  <p><b>关键词</b>：present ASR Bundestag, ASR Bundestag, automatic speech recognition, present ASR, automatic speech</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present ASR Bundestag, a dataset for automatic speech recognition in
German, consisting of 610 hours of aligned audio-transcript pairs for
supervised training as well as 1,038 hours of unlabeled audio snippets for
self-supervised learning, based on raw audio data and transcriptions from
plenary sessions and committee meetings of the German parliament. In addition,
we discuss utilized approaches for the automated creation of speech datasets
and assess the quality of the resulting dataset based on evaluations and
finetuning of a pre-trained state of the art model. We make the dataset
publicly available, including all subsets.</p>
  </details>
</details>
<details>
  <summary>49. <b>标题：Exploiting Graph Structured Cross-Domain Representation for Multi-Domain  Recommendation</b></summary>
  <p><b>编号</b>：[267]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05990</p>
  <p><b>作者</b>：Alejandro Ariza-Casabona,  Bartlomiej Twardowski,  Tri Kurniawan Wijaya</p>
  <p><b>备注</b>：Accepted at the 45th European Conference on Information Retrieval (ECIR'23), full paper track</p>
  <p><b>关键词</b>：recommender systems benefit, cross-domain representation learning, systems benefit, benefit from cross-domain, learning and positive</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Multi-domain recommender systems benefit from cross-domain representation
learning and positive knowledge transfer. Both can be achieved by introducing a
specific modeling of input data (i.e. disjoint history) or trying dedicated
training regimes. At the same time, treating domains as separate input sources
becomes a limitation as it does not capture the interplay that naturally exists
between domains. In this work, we efficiently learn multi-domain representation
of sequential users' interactions using graph neural networks. We use temporal
intra- and inter-domain interactions as contextual information for our method
called MAGRec (short for Multi-domAin Graph-based Recommender). To better
capture all relations in a multi-domain setting, we learn two graph-based
sequential representations simultaneously: domain-guided for recent user
interest, and general for long-term interest. This approach helps to mitigate
the negative knowledge transfer problem from multiple domains and improve
overall representation. We perform experiments on publicly available datasets
in different scenarios where MAGRec consistently outperforms state-of-the-art
methods. Furthermore, we provide an ablation study and discuss further
extensions of our method.</p>
  </details>
</details>
<details>
  <summary>50. <b>标题：MarioGPT: Open-Ended Text2Level Generation through Large Language Models</b></summary>
  <p><b>编号</b>：[271]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05981</p>
  <p><b>作者</b>：Shyam Sudhakaran,  Miguel González-Duque,  Claire Glanois,  Matthias Freiberger,  Elias Najarro,  Sebastian Risi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：PCG, Content, Procedural Content Generation, generate, Large Language Models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Procedural Content Generation (PCG) algorithms provide a technique to
generate complex and diverse environments in an automated way. However, while
generating content with PCG methods is often straightforward, generating
meaningful content that reflects specific intentions and constraints remains
challenging. Furthermore, many PCG algorithms lack the ability to generate
content in an open-ended manner. Recently, Large Language Models (LLMs) have
shown to be incredibly effective in many diverse domains. These trained LLMs
can be fine-tuned, re-using information and accelerating training for new
tasks. In this work, we introduce MarioGPT, a fine-tuned GPT2 model trained to
generate tile-based game levels, in our case Super Mario Bros levels. We show
that MarioGPT can not only generate diverse levels, but can be text-prompted
for controllable level generation, addressing one of the key challenges of
current PCG techniques. As far as we know, MarioGPT is the first text-to-level
model. We also combine MarioGPT with novelty search, enabling it to generate
diverse levels with varying play-style dynamics (i.e. player paths). This
combination allows for the open-ended generation of an increasingly diverse
range of content.</p>
  </details>
</details>
<details>
  <summary>51. <b>标题：Rapid Development of Compositional AI</b></summary>
  <p><b>编号</b>：[289]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05941</p>
  <p><b>作者</b>：Lee Martie,  Jessie Rosenberg,  Veronique Demers,  Gaoyuan Zhang,  Onkar Bhardwaj,  John Henning,  Aditya Prasad,  Matt Stallone,  Ja Young Lee,  Lucy Yip,  Damilola Adesina,  Elahe Paikari,  Oscar Resendiz,  Sarah Shaw,  David Cox</p>
  <p><b>备注</b>：Accepted to ICSE 2023, NIER track</p>
  <p><b>关键词</b>：artificial intelligence components, combine multiple artificial, multiple artificial intelligence, larger problem, hoc style</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Compositional AI systems, which combine multiple artificial intelligence
components together with other application components to solve a larger
problem, have no known pattern of development and are often approached in a
bespoke and ad hoc style. This makes development slower and harder to reuse for
future applications. To support the full rapid development cycle of
compositional AI applications, we have developed a novel framework called
(Bee)* (written as a regular expression and pronounced as "beestar"). We
illustrate how (Bee)* supports building integrated, scalable, and interactive
compositional AI applications with a simplified developer experience.</p>
  </details>
</details>
<details>
  <summary>52. <b>标题：SemanticAC: Semantics-Assisted Framework for Audio Classification</b></summary>
  <p><b>编号</b>：[290]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05940</p>
  <p><b>作者</b>：Yicheng Xiao,  Yue Ma,  Shuyan Li,  Hantao Zhou,  Ran Liao,  Xiu Li</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：propose SemanticAC, semantics-assisted framework, Audio Classification, Audio, semantic</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we propose SemanticAC, a semantics-assisted framework for
Audio Classification to better leverage the semantic information. Unlike
conventional audio classification methods that treat class labels as discrete
vectors, we employ a language model to extract abundant semantics from labels
and optimize the semantic consistency between audio signals and their labels.
We verify that simple textual information from labels and advanced pretraining
models enable more abundant semantic supervision for better performance.
Specifically, we design a text encoder to capture the semantic information from
the text extension of labels. Then we map the audio signals to align with the
semantics of corresponding class labels via an audio encoder and a similarity
calculation module so as to enforce the semantic consistency. Extensive
experiments on two audio datasets, ESC-50 and US8K demonstrate that our
proposed method consistently outperforms the compared audio classification
methods.</p>
  </details>
</details>
<details>
  <summary>53. <b>标题：Transfer Learning for Bayesian Optimization: A Survey</b></summary>
  <p><b>编号</b>：[296]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05927</p>
  <p><b>作者</b>：Tianyi Bai,  Yang Li,  Yu Shen,  Xinyi Zhang,  Wentao Zhang,  Bin Cui</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：including parameter tuning, including parameter, parameter tuning, Bayesian optimization, optimization</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>A wide spectrum of design and decision problems, including parameter tuning,
A/B testing and drug design, intrinsically are instances of black-box
optimization. Bayesian optimization (BO) is a powerful tool that models and
optimizes such expensive "black-box" functions. However, at the beginning of
optimization, vanilla Bayesian optimization methods often suffer from slow
convergence issue due to inaccurate modeling based on few trials. To address
this issue, researchers in the BO community propose to incorporate the spirit
of transfer learning to accelerate optimization process, which could borrow
strength from the past tasks (source tasks) to accelerate the current
optimization problem (target task). This survey paper first summarizes transfer
learning methods for Bayesian optimization from four perspectives: initial
points design, search space design, surrogate model, and acquisition function.
Then it highlights its methodological aspects and technical details for each
approach. Finally, it showcases a wide range of applications and proposes
promising future directions.</p>
  </details>
</details>
<details>
  <summary>54. <b>标题：LipLearner: Customizable Silent Speech Interactions on Mobile Devices</b></summary>
  <p><b>编号</b>：[305]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05907</p>
  <p><b>作者</b>：Zixiong Su,  Shitao Fang,  Jun Rekimoto</p>
  <p><b>备注</b>：21 pages, 14 figures, 4 tables</p>
  <p><b>关键词</b>：enables private communications, natural language, promising technology, technology that enables, enables private</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Silent speech interface is a promising technology that enables private
communications in natural language. However, previous approaches only support a
small and inflexible vocabulary, which leads to limited expressiveness. We
leverage contrastive learning to learn efficient lipreading representations,
enabling few-shot command customization with minimal user effort. Our model
exhibits high robustness to different lighting, posture, and gesture conditions
on an in-the-wild dataset. For 25-command classification, an F1-score of 0.8947
is achievable only using one shot, and its performance can be further boosted
by adaptively learning from more data. This generalizability allowed us to
develop a mobile silent speech interface empowered with on-device fine-tuning
and visual keyword spotting. A user study demonstrated that with LipLearner,
users could define their own commands with high reliability guaranteed by an
online incremental learning scheme. Subjective feedback indicated that our
system provides essential functionalities for customizable silent speech
interactions with high usability and learnability.</p>
  </details>
</details>
<details>
  <summary>55. <b>标题：On Testing and Comparing Fair classifiers under Data Bias</b></summary>
  <p><b>编号</b>：[306]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05906</p>
  <p><b>作者</b>：Mohit Sharma,  Amit Deshpande,  Rajiv Ratn Shah</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：fair classifiers, data, training data, Blum, Stangl</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we consider a theoretical model for injecting data bias,
namely, under-representation and label bias (Blum & Stangl, 2019). We
theoretically and empirically study its effect on the accuracy and fairness of
fair classifiers. Theoretically, we prove that the Bayes optimal group-aware
fair classifier on the original data distribution can be recovered by simply
minimizing a carefully chosen reweighed loss on the bias-injected distribution.
Through extensive experiments on both synthetic and real-world datasets (e.g.,
Adult, German Credit, Bank Marketing, COMPAS), we empirically audit pre-, in-,
and post-processing fair classifiers from standard fairness toolkits for their
fairness and accuracy by injecting varying amounts of under-representation and
label bias in their training data (but not the test data). Our main
observations are: (1) The fairness and accuracy of many standard fair
classifiers degrade severely as the bias injected in their training data
increases, (2) A simple logistic regression model trained on the right data can
often outperform, in both accuracy and fairness, most fair classifiers trained
on biased training data, and (3) A few, simple fairness techniques (e.g.,
reweighing, exponentiated gradients) seem to offer stable accuracy and fairness
guarantees even when their training data is injected with under-representation
and label bias. Our experiments also show how to integrate a measure of data
bias risk in the existing fairness dashboards for real-world deployments</p>
  </details>
</details>
<details>
  <summary>56. <b>标题：Single Motion Diffusion</b></summary>
  <p><b>编号</b>：[307]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05905</p>
  <p><b>作者</b>：Sigal Raab,  Inbal Leibovitch,  Guy Tevet,  Moab Arar,  Amit H. Bermano,  Daniel Cohen-Or</p>
  <p><b>备注</b>：Video: this https URL, Project page: this https URL, Code: this https URL</p>
  <p><b>关键词</b>：computer graphics professionals, Synthesizing realistic animations, Synthesizing realistic, graphics professionals, goal for artists</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Synthesizing realistic animations of humans, animals, and even imaginary
creatures, has long been a goal for artists and computer graphics
professionals. Compared to the imaging domain, which is rich with large
available datasets, the number of data instances for the motion domain is
limited, particularly for the animation of animals and exotic creatures (e.g.,
dragons), which have unique skeletons and motion patterns. In this work, we
present a Single Motion Diffusion Model, dubbed SinMDM, a model designed to
learn the internal motifs of a single motion sequence with arbitrary topology
and synthesize motions of arbitrary length that are faithful to them. We
harness the power of diffusion models and present a denoising network designed
specifically for the task of learning from a single input motion. Our
transformer-based architecture avoids overfitting by using local attention
layers that narrow the receptive field, and encourages motion diversity by
using relative positional embedding. SinMDM can be applied in a variety of
contexts, including spatial and temporal in-betweening, motion expansion, style
transfer, and crowd animation. Our results show that SinMDM outperforms
existing methods both in quality and time-space efficiency. Moreover, while
current approaches require additional training for different applications, our
work facilitates these applications at inference time. Our code and trained
models are available at this https URL.</p>
  </details>
</details>
<details>
  <summary>57. <b>标题：TextDefense: Adversarial Text Detection based on Word Importance Entropy</b></summary>
  <p><b>编号</b>：[312]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05892</p>
  <p><b>作者</b>：Lujia Shen,  Xuhong Zhang,  Shouling Ji,  Yuwen Pu,  Chunpeng Ge,  Xing Yang,  Yanghe Feng</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：natural language processing, natural language, language processing, target model, NLP</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Currently, natural language processing (NLP) models are wildly used in
various scenarios. However, NLP models, like all deep models, are vulnerable to
adversarially generated text. Numerous works have been working on mitigating
the vulnerability from adversarial attacks. Nevertheless, there is no
comprehensive defense in existing works where each work targets a specific
attack category or suffers from the limitation of computation overhead,
irresistible to adaptive attack, etc.
In this paper, we exhaustively investigate the adversarial attack algorithms
in NLP, and our empirical studies have discovered that the attack algorithms
mainly disrupt the importance distribution of words in a text. A well-trained
model can distinguish subtle importance distribution differences between clean
and adversarial texts. Based on this intuition, we propose TextDefense, a new
adversarial example detection framework that utilizes the target model's
capability to defend against adversarial attacks while requiring no prior
knowledge. TextDefense differs from previous approaches, where it utilizes the
target model for detection and thus is attack type agnostic. Our extensive
experiments show that TextDefense can be applied to different architectures,
datasets, and attack methods and outperforms existing methods. We also discover
that the leading factor influencing the performance of TextDefense is the
target model's generalizability. By analyzing the property of the target model
and the property of the adversarial example, we provide our insights into the
adversarial attacks in NLP and the principles of our defense method.</p>
  </details>
</details>
<details>
  <summary>58. <b>标题：USER: Unsupervised Structural Entropy-based Robust Graph Neural Network</b></summary>
  <p><b>编号</b>：[314]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05889</p>
  <p><b>作者</b>：Yifei Wang,  Yupan Wang,  Zeyu Zhang,  Song Yang,  Kaiqi Zhao,  Jiamou Liu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：input graph data, self-supervised graph neural, graph neural networks, vulnerable to inherent, data which greatly</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Unsupervised/self-supervised graph neural networks (GNN) are vulnerable to
inherent randomness in the input graph data which greatly affects the
performance of the model in downstream tasks. In this paper, we alleviate the
interference of graph randomness and learn appropriate representations of nodes
without label information. To this end, we propose USER, an unsupervised robust
version of graph neural networks that is based on structural entropy. We
analyze the property of intrinsic connectivity and define intrinsic
connectivity graph. We also identify the rank of the adjacency matrix as a
crucial factor in revealing a graph that provides the same embeddings as the
intrinsic connectivity graph. We then introduce structural entropy in the
objective function to capture such a graph. Extensive experiments conducted on
clustering and link prediction tasks under random-noises and meta-attack over
three datasets show USER outperforms benchmarks and is robust to heavier
randomness.</p>
  </details>
</details>
<details>
  <summary>59. <b>标题：Position Matters! Empirical Study of Order Effect in Knowledge-grounded  Dialogue</b></summary>
  <p><b>编号</b>：[315]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05888</p>
  <p><b>作者</b>：Hsuan Su,  Shachi H Kumar,  Sahisnu Mazumder,  Wenda Chen,  Ramesh Manuvinakurike,  Eda Okur,  Saurav Sahay,  Lama Nachman,  Shang-Tse Chen,  Hung-yi Lee</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：large pretrained language, pretrained language models, power of large, large pretrained, pretrained language</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>With the power of large pretrained language models, various research works
have integrated knowledge into dialogue systems. The traditional techniques
treat knowledge as part of the input sequence for the dialogue system,
prepending a set of knowledge statements in front of dialogue history. However,
such a mechanism forces knowledge sets to be concatenated in an ordered manner,
making models implicitly pay imbalanced attention to the sets during training.
In this paper, we first investigate how the order of the knowledge set can
influence autoregressive dialogue systems' responses. We conduct experiments on
two commonly used dialogue datasets with two types of transformer-based models
and find that models view the input knowledge unequally. To this end, we
propose a simple and novel technique to alleviate the order effect by modifying
the position embeddings of knowledge input in these models. With the proposed
position embedding method, the experimental results show that each knowledge
statement is uniformly considered to generate responses.</p>
  </details>
</details>
<details>
  <summary>60. <b>标题："Why is this misleading?": Detecting News Headline Hallucinations with  Explanations</b></summary>
  <p><b>编号</b>：[326]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05852</p>
  <p><b>作者</b>：Jiaming Shen,  Jialu Liu,  Dan Finnie,  Negar Rahmati,  Michael Bendersky,  Marc Najork</p>
  <p><b>备注</b>：WWW 2023, 12 pages</p>
  <p><b>关键词</b>：generation enables users, Automatic headline generation, headline generation enables, natural language processing, enables users</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Automatic headline generation enables users to comprehend ongoing news events
promptly and has recently become an important task in web mining and natural
language processing. With the growing need for news headline generation, we
argue that the hallucination issue, namely the generated headlines being not
supported by the original news stories, is a critical challenge for the
deployment of this feature in web-scale systems Meanwhile, due to the
infrequency of hallucination cases and the requirement of careful reading for
raters to reach the correct consensus, it is difficult to acquire a large
dataset for training a model to detect such hallucinations through human
curation. In this work, we present a new framework named ExHalder to address
this challenge for headline hallucination detection. ExHalder adapts the
knowledge from public natural language inference datasets into the news domain
and learns to generate natural language sentences to explain the hallucination
detection results. To evaluate the model performance, we carefully collect a
dataset with more than six thousand labeled <article, headline> pairs.
Extensive experiments on this dataset and another six public ones demonstrate
that ExHalder can identify hallucinated headlines accurately and justifies its
predictions with human-readable natural language explanations.</article,></p>
  </details>
</details>
<details>
  <summary>61. <b>标题：A Human-Centered Review of Algorithms in Decision-Making in Higher  Education</b></summary>
  <p><b>编号</b>：[331]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05839</p>
  <p><b>作者</b>：Kelly McConvey,  Shion Guha,  Anastasia Kuzminykh</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：raising ethical challenges, decision-making in higher, higher education, steadily growing, promising cost-savings</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The use of algorithms for decision-making in higher education is steadily
growing, promising cost-savings to institutions and personalized service for
students but also raising ethical challenges around surveillance, fairness, and
interpretation of data. To address the lack of systematic understanding of how
these algorithms are currently designed, we reviewed an extensive corpus of
papers proposing algorithms for decision-making in higher education. We
categorized them based on input data, computational method, and target outcome,
and then investigated the interrelations of these factors with the application
of human-centered lenses: theoretical, participatory, or speculative design. We
found that the models are trending towards deep learning, and increased use of
student personal data and protected attributes, with the target scope expanding
towards automated decisions. However, despite the associated decrease in
interpretability and explainability, current development predominantly fails to
incorporate human-centered lenses. We discuss the challenges with these trends
and advocate for a human-centered approach.</p>
  </details>
</details>
<details>
  <summary>62. <b>标题：Maneuver Decision-Making For Autonomous Air Combat Through Curriculum  Learning And Reinforcement Learning With Sparse Rewards</b></summary>
  <p><b>编号</b>：[332]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05838</p>
  <p><b>作者</b>：Yu-Jie Wei,  Hong-Peng Zhang,  Chang-Qiang Huang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：combat maneuver decision-making, air combat maneuver, Reinforcement learning, air combat, maneuver decision-making</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Reinforcement learning is an effective way to solve the decision-making
problems. It is a meaningful and valuable direction to investigate autonomous
air combat maneuver decision-making method based on reinforcement learning.
However, when using reinforcement learning to solve the decision-making
problems with sparse rewards, such as air combat maneuver decision-making, it
costs too much time for training and the performance of the trained agent may
not be satisfactory. In order to solve these problems, the method based on
curriculum learning is proposed. First, three curricula of air combat maneuver
decision-making are designed: angle curriculum, distance curriculum and hybrid
curriculum. These courses are used to train air combat agents respectively, and
compared with the original method without any curriculum. The training results
show that angle curriculum can increase the speed and stability of training,
and improve the performance of the agent; distance curriculum can increase the
speed and stability of agent training; hybrid curriculum has a negative impact
on training, because it makes the agent get stuck at local optimum. The
simulation results show that after training, the agent can handle the
situations where targets come from different directions, and the maneuver
decision results are consistent with the characteristics of missile.</p>
  </details>
</details>
<details>
  <summary>63. <b>标题：Level Generation Through Large Language Models</b></summary>
  <p><b>编号</b>：[343]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05817</p>
  <p><b>作者</b>：Graham Todd,  Sam Earle,  Muhammad Umair Nasir,  Michael Cerny Green,  Julian Togelius</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Large Language Models, Large Language, natural language, Language Models, powerful tools</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large Language Models (LLMs) are powerful tools, capable of leveraging their
training on natural language to write stories, generate code, and answer
questions. But can they generate functional video game levels? Game levels,
with their complex functional constraints and spatial relationships in more
than one dimension, are very different from the kinds of data an LLM typically
sees during training. Datasets of game levels are also hard to come by,
potentially taxing the abilities of these data-hungry models. We investigate
the use of LLMs to generate levels for the game Sokoban, finding that LLMs are
indeed capable of doing so, and that their performance scales dramatically with
dataset size. We also perform preliminary experiments on controlling LLM level
generators and discuss promising areas for future work.</p>
  </details>
</details>
<details>
  <summary>64. <b>标题：TPE-Net: Track Point Extraction and Association Network for Rail Path  Proposal Generation</b></summary>
  <p><b>编号</b>：[349]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05803</p>
  <p><b>作者</b>：Jungwon Kang,  Mohammadjavad Ghorbanalivakili,  Gunho Sohn,  David Beach,  Veronica Marin</p>
  <p><b>备注</b>：7 pages, 6 figures, and 1 table Jungwon Kang and Mohammadjavad Ghorbanalivakili have equal contribution</p>
  <p><b>关键词</b>：minimizing collision risks, third-party objects, rail, essential feature, minimizing collision</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>One essential feature of an autonomous train is minimizing collision risks
with third-party objects. To estimate the risk, the control system must
identify topological information of all the rail routes ahead on which the
train can possibly move, especially within merging or diverging rails. This
way, the train can figure out the status of potential obstacles with respect to
its route and hence, make a timely decision. Numerous studies have successfully
extracted all rail tracks as a whole within forward-looking images without
considering element instances. Still, some image-based methods have employed
hard-coded prior knowledge of railway geometry on 3D data to associate
left-right rails and generate rail route instances. However, we propose a rail
path extraction pipeline in which left-right rail pixels of each rail route
instance are extracted and associated through a fully convolutional
encoder-decoder architecture called TPE-Net. Two different regression branches
for TPE-Net are proposed to regress the locations of center points of each rail
route, along with their corresponding left-right pixels. Extracted rail pixels
are then spatially clustered to generate topological information of all the
possible train routes (ego-paths), discarding non-ego-path ones. Experimental
results on a challenging, publicly released benchmark show true-positive-pixel
level average precision and recall of 0.9207 and 0.8721, respectively, at about
12 frames per second. Even though our evaluation results are not higher than
the SOTA, the proposed regression pipeline performs remarkably in extracting
the correspondences by looking once at the image. It generates strong rail
route hypotheses without reliance on camera parameters, 3D data, and
geometrical constraints.</p>
  </details>
</details>
<details>
  <summary>65. <b>标题：Mutation-Based Adversarial Attacks on Neural Text Detectors</b></summary>
  <p><b>编号</b>：[351]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05794</p>
  <p><b>作者</b>：Gongbo Liang,  Jesus Guerrero,  Izzat Alsmadi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Neural text detectors, text detectors aim, distinguish neural, aim to decide, detectors aim</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Neural text detectors aim to decide the characteristics that distinguish
neural (machine-generated) from human texts. To challenge such detectors,
adversarial attacks can alter the statistical characteristics of the generated
text, making the detection task more and more difficult. Inspired by the
advances of mutation analysis in software development and testing, in this
paper, we propose character- and word-based mutation operators for generating
adversarial samples to attack state-of-the-art natural text detectors. This
falls under white-box adversarial attacks. In such attacks, attackers have
access to the original text and create mutation instances based on this
original text. The ultimate goal is to confuse machine learning models and
classifiers and decrease their prediction accuracy.</p>
  </details>
</details>
<details>
  <summary>66. <b>标题：Distributional GFlowNets with Quantile Flows</b></summary>
  <p><b>编号</b>：[352]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05793</p>
  <p><b>作者</b>：Dinghuai Zhang,  Ling Pan,  Ricky T. Q. Chen,  Aaron Courville,  Yoshua Bengio</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Generative Flow Networks, generating complex combinatorial, complex combinatorial structure, Flow Networks, decision-making steps</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Generative Flow Networks (GFlowNets) are a new family of probabilistic
samplers where an agent learns a stochastic policy for generating complex
combinatorial structure through a series of decision-making steps. Despite
being inspired from reinforcement learning, the current GFlowNet framework is
relatively limited in its applicability and cannot handle stochasticity in the
reward function. In this work, we adopt a distributional paradigm for
GFlowNets, turning each flow function into a distribution, thus providing more
informative learning signals during training. By parameterizing each edge flow
through their quantile functions, our proposed \textit{quantile matching}
GFlowNet learning algorithm is able to learn a risk-sensitive policy, an
essential component for handling scenarios with risk uncertainty. Moreover, we
find that the distributional approach can achieve substantial improvement on
existing benchmarks compared to prior methods due to our enhanced training
algorithm, even in settings with deterministic rewards.</p>
  </details>
</details>
<details>
  <summary>67. <b>标题：How to prepare your task head for finetuning</b></summary>
  <p><b>编号</b>：[357]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05779</p>
  <p><b>作者</b>：Yi Ren,  Shangmin Guo,  Wonho Bae,  Danica J. Sutherland</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：transferring information, task head, pretrained network, task head plays, downstream task</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In deep learning, transferring information from a pretrained network to a
downstream task by finetuning has many benefits. The choice of task head plays
an important role in fine-tuning, as the pretrained and downstream tasks are
usually different. Although there exist many different designs for finetuning,
a full understanding of when and why these algorithms work has been elusive. We
analyze how the choice of task head controls feature adaptation and hence
influences the downstream performance. By decomposing the learning dynamics of
adaptation, we find that the key aspect is the training accuracy and loss at
the beginning of finetuning, which determines the "energy" available for the
feature's adaptation. We identify a significant trend in the effect of changes
in this initial energy on the resulting features after fine-tuning.
Specifically, as the energy increases, the Euclidean and cosine distances
between the resulting and original features increase, while their dot products
(and the resulting features' norm) first increase and then decrease. Inspired
by this, we give several practical principles that lead to better downstream
performance. We analytically prove this trend in an overparamterized linear
setting and verify its applicability to different experimental settings.</p>
  </details>
</details>
<details>
  <summary>68. <b>标题：Interpretable Deep Learning for Forecasting Online Advertising Costs:  Insights from the Competitive Bidding Landscape</b></summary>
  <p><b>编号</b>：[363]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05762</p>
  <p><b>作者</b>：Fynn Oldenburg,  Qiwei Han,  Maximilian Kaiser</p>
  <p><b>备注</b>：Acceptd at AAAI 2023 Web for Advertising Workshop, 12 pages, 8 figures, 4 tables</p>
  <p><b>关键词</b>：marketing campaign returns, optimize marketing campaign, making budget plans, advertisers increasingly shift, campaign returns</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>As advertisers increasingly shift their budgets toward digital advertising,
forecasting advertising costs is essential for making budget plans to optimize
marketing campaign returns. In this paper, we perform a comprehensive study
using a variety of time-series forecasting methods to predict daily average
cost-per-click (CPC) in the online advertising market. We show that forecasting
advertising costs would benefit from multivariate models using covariates from
competitors' CPC development identified through time-series clustering. We
further interpret the results by analyzing feature importance and temporal
attention. Finally, we show that our approach has several advantages over
models that individual advertisers might build based solely on their collected
data.</p>
  </details>
</details>
<details>
  <summary>69. <b>标题：Multispectral Self-Supervised Learning with Viewmaker Networks</b></summary>
  <p><b>编号</b>：[365]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05757</p>
  <p><b>作者</b>：Jasmine Bayrooti,  Noah Goodman,  Alex Tamkin</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：identify similar, data points, training models, models to identify, Contrastive learning</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Contrastive learning methods have been applied to a range of domains and
modalities by training models to identify similar ``views'' of data points.
However, specialized scientific modalities pose a challenge for this paradigm,
as identifying good views for each scientific instrument is complex and
time-intensive. In this paper, we focus on applying contrastive learning
approaches to a variety of remote sensing datasets. We show that Viewmaker
networks, a recently proposed method for generating views, are promising for
producing views in this setting without requiring extensive domain knowledge
and trial and error. We apply Viewmaker to four multispectral imaging problems,
each with a different format, finding that Viewmaker can outperform cropping-
and reflection-based methods for contrastive learning in every case when
evaluated on downstream classification tasks. This provides additional evidence
that domain-agnostic methods can empower contrastive learning to scale to
real-world scientific domains. Open source code can be found at
this https URL.</p>
  </details>
</details>
<details>
  <summary>70. <b>标题：Informing clinical assessment by contextualizing post-hoc explanations  of risk prediction models in type-2 diabetes</b></summary>
  <p><b>编号</b>：[368]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05752</p>
  <p><b>作者</b>：Shruthi Chari,  Prasant Acharya,  Daniel M. Gruen,  Olivia Zhang,  Elif K. Eyigoz,  Mohamed Ghalwash,  Oshani Seneviratne,  Fernando Suarez Saiz,  Pablo Meyer,  Prithwish Chakraborty,  Deborah L. McGuinness</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Artificial Intelligence, practitioner connect system, connect system inferences, connect system, greater trust</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Medical experts may use Artificial Intelligence (AI) systems with greater
trust if these are supported by contextual explanations that let the
practitioner connect system inferences to their context of use. However, their
importance in improving model usage and understanding has not been extensively
studied. Hence, we consider a comorbidity risk prediction scenario and focus on
contexts regarding the patients clinical state, AI predictions about their risk
of complications, and algorithmic explanations supporting the predictions. We
explore how relevant information for such dimensions can be extracted from
Medical guidelines to answer typical questions from clinical practitioners. We
identify this as a question answering (QA) task and employ several
state-of-the-art LLMs to present contexts around risk prediction model
inferences and evaluate their acceptability. Finally, we study the benefits of
contextual explanations by building an end-to-end AI pipeline including data
cohorting, AI risk modeling, post-hoc model explanations, and prototyped a
visual dashboard to present the combined insights from different context
dimensions and data sources, while predicting and identifying the drivers of
risk of Chronic Kidney Disease - a common type-2 diabetes comorbidity. All of
these steps were performed in engagement with medical experts, including a
final evaluation of the dashboard results by an expert medical panel. We show
that LLMs, in particular BERT and SciBERT, can be readily deployed to extract
some relevant explanations to support clinical usage. To understand the
value-add of the contextual explanations, the expert panel evaluated these
regarding actionable insights in the relevant clinical setting. Overall, our
paper is one of the first end-to-end analyses identifying the feasibility and
benefits of contextual explanations in a real-world clinical use case.</p>
  </details>
</details>
<details>
  <summary>71. <b>标题：Is Distance Matrix Enough for Geometric Deep Learning?</b></summary>
  <p><b>编号</b>：[372]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05743</p>
  <p><b>作者</b>：Zian Li,  Xiyuan Wang,  Yinan Huang,  Muhan Zhang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：molecular dynamics simulation, Message Passing Neural, Graph Neural Networks, dynamics simulation, distance matrix</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Graph Neural Networks (GNNs) are often used for tasks involving the geometry
of a given graph, such as molecular dynamics simulation. While the distance
matrix of a graph contains the complete geometric structure information,
whether GNNs can learn this geometry solely from the distance matrix has yet to
be studied. In this work, we first demonstrate that Message Passing Neural
Networks (MPNNs) are insufficient for learning the geometry of a graph from its
distance matrix by constructing families of geometric graphs which cannot be
distinguished by MPNNs. We then propose $k$-DisGNNs, which can effectively
exploit the rich geometry contained in the distance matrix. We demonstrate the
high expressive power of our models and prove that some existing well-designed
geometric models can be unified by $k$-DisGNNs as special cases. Most
importantly, we establish a connection between geometric deep learning and
traditional graph representation learning, showing that those highly expressive
GNN models originally designed for graph structure learning can also be applied
to geometric deep learning problems with impressive performance, and that
existing complex, equivariant models are not the only solution. Experimental
results verify our theory.</p>
  </details>
</details>
<details>
  <summary>72. <b>标题：UGAE: A Novel Approach to Non-exponential Discounting</b></summary>
  <p><b>编号</b>：[374]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05740</p>
  <p><b>作者</b>：Ariel Kwiatkowski,  Vicky Kalogeiton,  Julien Pettré,  Marie-Paule Cani</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Reinforcement Learning determines, Reinforcement Learning, mechanism in Reinforcement, Learning determines, discounting</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The discounting mechanism in Reinforcement Learning determines the relative
importance of future and present rewards. While exponential discounting is
widely used in practice, non-exponential discounting methods that align with
human behavior are often desirable for creating human-like agents. However,
non-exponential discounting methods cannot be directly applied in modern
on-policy actor-critic algorithms. To address this issue, we propose Universal
Generalized Advantage Estimation (UGAE), which allows for the computation of
GAE advantage values with arbitrary discounting. Additionally, we introduce
Beta-weighted discounting, a continuous interpolation between exponential and
hyperbolic discounting, to increase flexibility in choosing a discounting
method. To showcase the utility of UGAE, we provide an analysis of the
properties of various discounting methods. We also show experimentally that
agents with non-exponential discounting trained via UGAE outperform variants
trained with Monte Carlo advantage estimation. Through analysis of various
discounting methods and experiments, we demonstrate the superior performance of
UGAE with Beta-weighted discounting over the Monte Carlo baseline on standard
RL benchmarks. UGAE is simple and easily integrated into any advantage-based
algorithm as a replacement for the standard recursive GAE.</p>
  </details>
</details>
<details>
  <summary>73. <b>标题：A Brief Report on LawGPT 1.0: A Virtual Legal Assistant Based on GPT-3</b></summary>
  <p><b>编号</b>：[382]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05729</p>
  <p><b>作者</b>：Ha-Thanh Nguyen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：virtual legal assistant, legal assistant built, assistant built, legal, language model</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>LawGPT 1.0 is a virtual legal assistant built on the state-of-the-art
language model GPT-3, fine-tuned for the legal domain. The system is designed
to provide legal assistance to users in a conversational manner, helping them
with tasks such as answering legal questions, generating legal documents, and
providing legal advice. In this paper, we provide a brief overview of LawGPT
1.0, its architecture, and its performance on a set of legal benchmark tasks.
Please note that the detailed information about the model is protected by a
non-disclosure agreement (NDA) and cannot be disclosed in this report.</p>
  </details>
</details>
<details>
  <summary>74. <b>标题：Learning by Applying: A General Framework for Mathematical Reasoning via  Enhancing Explicit Knowledge Learning</b></summary>
  <p><b>编号</b>：[390]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05717</p>
  <p><b>作者</b>：Jiayu Liu,  Zhenya Huang,  Chengxiang Zhai,  Qi Liu</p>
  <p><b>备注</b>：Accepted by AAAI 2023</p>
  <p><b>关键词</b>：general artificial intelligence, knowledge, master mathematical logic, artificial intelligence, requires machines</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Mathematical reasoning is one of the crucial abilities of general artificial
intelligence, which requires machines to master mathematical logic and
knowledge from solving problems. However, existing approaches are not
transparent (thus not interpretable) in terms of what knowledge has been
learned and applied in the reasoning process. In this paper, we propose a
general Learning by Applying (LeAp) framework to enhance existing models
(backbones) in a principled way by explicit knowledge learning. In LeAp, we
perform knowledge learning in a novel problem-knowledge-expression paradigm,
with a Knowledge Encoder to acquire knowledge from problem data and a Knowledge
Decoder to apply knowledge for expression reasoning. The learned mathematical
knowledge, including word-word relations and word-operator relations, forms an
explicit knowledge graph, which bridges the knowledge "learning" and "applying"
organically. Moreover, for problem solving, we design a semantics-enhanced
module and a reasoning-enhanced module that apply knowledge to improve the
problem comprehension and symbol reasoning abilities of any backbone,
respectively. We theoretically prove the superiority of LeAp's autonomous
learning mechanism. Experiments on three real-world datasets show that LeAp
improves all backbones' performances, learns accurate knowledge, and achieves a
more interpretable reasoning process.</p>
  </details>
</details>
<details>
  <summary>75. <b>标题：HateProof: Are Hateful Meme Detection Systems really Robust?</b></summary>
  <p><b>编号</b>：[395]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05703</p>
  <p><b>作者</b>：Piush Aggarwal,  Pranit Chawla,  Mithun Das,  Punyajoy Saha,  Binny Mathew,  Torsten Zesch,  Animesh Mukherjee</p>
  <p><b>备注</b>：Accepted at TheWebConf'2023 (WWW'2023)</p>
  <p><b>关键词</b>：Exploiting social media, Exploiting social, social media, media to spread, spread hate</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Exploiting social media to spread hate has tremendously increased over the
years. Lately, multi-modal hateful content such as memes has drawn relatively
more traction than uni-modal content. Moreover, the availability of implicit
content payloads makes them fairly challenging to be detected by existing
hateful meme detection systems. In this paper, we present a use case study to
analyze such systems' vulnerabilities against external adversarial attacks. We
find that even very simple perturbations in uni-modal and multi-modal settings
performed by humans with little knowledge about the model can make the existing
detection models highly vulnerable. Empirically, we find a noticeable
performance drop of as high as 10% in the macro-F1 score for certain attacks.
As a remedy, we attempt to boost the model's robustness using contrastive
learning as well as an adversarial training-based method - VILLA. Using an
ensemble of the above two approaches, in two of our high resolution datasets,
we are able to (re)gain back the performance to a large extent for certain
attacks. We believe that ours is a first step toward addressing this crucial
problem in an adversarial setting and would inspire more such investigations in
the future.</p>
  </details>
</details>
<details>
  <summary>76. <b>标题：Compositional Exemplars for In-context Learning</b></summary>
  <p><b>编号</b>：[397]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05698</p>
  <p><b>作者</b>：Jiacheng Ye,  Zhiyong Wu,  Jiangtao Feng,  Tao Yu,  Lingpeng Kong</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：shown impressive In-Context, Large pretrained language, Large pretrained, shown impressive, pretrained language models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Large pretrained language models (LMs) have shown impressive In-Context
Learning (ICL) ability, where the model learns to do an unseen task via a
prompt consisting of input-output examples as the demonstration, without any
parameter updates. The performance of ICL is highly dominated by the quality of
the selected in-context examples. However, previous selection methods are
mostly based on simple heuristics, leading to sub-optimal performance. In this
work, we formulate in-context example selection as a subset selection problem.
We propose CEIL(Compositional Exemplars for In-context Learning), which is
instantiated by Determinantal Point Processes (DPPs) to model the interaction
between the given input and in-context examples, and optimized through a
carefully-designed contrastive learning objective to obtain preference from
LMs. We validate CEIL on 12 classification and generation datasets from 7
distinct NLP tasks, including sentiment analysis, paraphrase detection, natural
language inference, commonsense reasoning, open-domain question answering, code
generation, and semantic parsing. Extensive experiments demonstrate not only
the state-of-the-art performance but also the transferability and
compositionality of CEIL, shedding new light on effective and efficient
in-context learning. Our code is released at
this https URL.</p>
  </details>
</details>
<details>
  <summary>77. <b>标题：CatAlyst: Domain-Extensible Intervention for Preventing Task  Procrastination Using Large Generative Models</b></summary>
  <p><b>编号</b>：[404]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05678</p>
  <p><b>作者</b>：Riku Arakawa,  Hiromu Yakura,  Masataka Goto</p>
  <p><b>备注</b>：Conditionally accepted by ACM CHI Conference on Human Factors in Computing Systems (CHI '23)</p>
  <p><b>关键词</b>：progress by influencing, directly contributing, task outputs, task engagement, workers' progress</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>CatAlyst uses generative models to help workers' progress by influencing
their task engagement instead of directly contributing to their task outputs.
It prompts distracted workers to resume their tasks by generating a
continuation of their work and presenting it as an intervention that is more
context-aware than conventional (predetermined) feedback. The prompt can
function by drawing their interest and lowering the hurdle for resumption even
when the generated continuation is insufficient to substitute their work, while
recent human-AI collaboration research aiming at work substitution depends on a
stable high accuracy. This frees CatAlyst from domain-specific model-tuning and
makes it applicable to various tasks. Our studies involving writing and
slide-editing tasks demonstrated CatAlyst's effectiveness in helping workers
swiftly resume tasks with a lowered cognitive load. The results suggest a new
form of human-AI collaboration where large generative models publicly available
but imperfect for each individual domain can contribute to workers' digital
well-being.</p>
  </details>
</details>
<details>
  <summary>78. <b>标题：Counter-GAP: Counterfactual Bias Evaluation through Gendered Ambiguous  Pronouns</b></summary>
  <p><b>编号</b>：[406]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05674</p>
  <p><b>作者</b>：Zhongbin Xie,  Vid Kocijan,  Thomas Lukasiewicz,  Oana-Maria Camburu</p>
  <p><b>备注</b>：Long Paper at EACL 2023</p>
  <p><b>关键词</b>：detecting biased behavior, Bias-measuring datasets play, play a critical, critical role, role in detecting</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Bias-measuring datasets play a critical role in detecting biased behavior of
language models and in evaluating progress of bias mitigation methods. In this
work, we focus on evaluating gender bias through coreference resolution, where
previous datasets are either hand-crafted or fail to reliably measure an
explicitly defined bias. To overcome these shortcomings, we propose a novel
method to collect diverse, natural, and minimally distant text pairs via
counterfactual generation, and construct Counter-GAP, an annotated dataset
consisting of 4008 instances grouped into 1002 quadruples. We further identify
a bias cancellation problem in previous group-level metrics on Counter-GAP, and
propose to use the difference between inconsistency across genders and within
genders to measure bias at a quadruple level. Our results show that four
pre-trained language models are significantly more inconsistent across
different gender groups than within each group, and that a name-based
counterfactual data augmentation method is more effective to mitigate such bias
than an anonymization-based method.</p>
  </details>
</details>
<details>
  <summary>79. <b>标题：Jaccard Metric Losses: Optimizing the Jaccard Index with Soft Labels</b></summary>
  <p><b>编号</b>：[409]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05666</p>
  <p><b>作者</b>：Zifu Wang,  Matthew B. Blaschko</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：soft Jaccard loss, Jaccard index, Jaccard index measure, Jaccard, soft Jaccard</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>IoU losses are surrogates that directly optimize the Jaccard index. In
semantic segmentation, IoU losses are shown to perform better with respect to
the Jaccard index measure than pixel-wise losses such as the cross-entropy
loss. The most notable IoU losses are the soft Jaccard loss and the
Lovasz-Softmax loss. However, these losses are incompatible with soft labels
which are ubiquitous in machine learning. In this paper, we propose Jaccard
metric losses (JMLs), which are variants of the soft Jaccard loss, and are
compatible with soft labels. With JMLs, we study two of the most popular use
cases of soft labels: label smoothing and knowledge distillation. With a
variety of architectures, our experiments show significant improvements over
the cross-entropy loss on three semantic segmentation datasets (Cityscapes,
PASCAL VOC and DeepGlobe Land), and our simple approach outperforms
state-of-the-art knowledge distillation methods by a large margin. Our source
code is available at:
\href{this https URL}{this https URL}.</p>
  </details>
</details>
<details>
  <summary>80. <b>标题：The Impact of Expertise in the Loop for Exploring Machine Rationality</b></summary>
  <p><b>编号</b>：[410]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05665</p>
  <p><b>作者</b>：Changkun Ou,  Sven Mayer,  Andreas Butz</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：optimization utilizes human, utilizes human expertise, guide machine optimizers, machine optimizers iteratively, solution space</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Human-in-the-loop optimization utilizes human expertise to guide machine
optimizers iteratively and search for an optimal solution in a solution space.
While prior empirical studies mainly investigated novices, we analyzed the
impact of the levels of expertise on the outcome quality and corresponding
subjective satisfaction. We conducted a study (N=60) in text, photo, and 3D
mesh optimization contexts. We found that novices can achieve an expert level
of quality performance, but participants with higher expertise led to more
optimization iteration with more explicit preference while keeping satisfaction
low. In contrast, novices were more easily satisfied and terminated faster.
Therefore, we identified that experts seek more diverse outcomes while the
machine reaches optimal results, and the observed behavior can be used as a
performance indicator for human-in-the-loop system designers to improve
underlying models. We inform future research to be cautious about the impact of
user expertise when designing human-in-the-loop systems.</p>
  </details>
</details>
<details>
  <summary>81. <b>标题：DocILE Benchmark for Document Information Localization and Extraction</b></summary>
  <p><b>编号</b>：[413]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05658</p>
  <p><b>作者</b>：Štěpán Šimsa,  Milan Šulc,  Michal Uřičář,  Yash Patel,  Ahmed Hamdi,  Matěj Kocián,  Matyáš Skalický,  Jiří Matas,  Antoine Doucet,  Mickaël Coustaty,  Dimosthenis Karatzas</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Key Information Localization, Line Item Recognition, Information Localization, Line Item, Key Information</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This paper introduces the DocILE benchmark with the largest dataset of
business documents for the tasks of Key Information Localization and Extraction
and Line Item Recognition. It contains 6.7k annotated business documents, 100k
synthetically generated documents, and nearly~1M unlabeled documents for
unsupervised pre-training. The dataset has been built with knowledge of domain-
and task-specific aspects, resulting in the following key features: (i)
annotations in 55 classes, which surpasses the granularity of previously
published key information extraction datasets by a large margin; (ii) Line Item
Recognition represents a highly practical information extraction task, where
key information has to be assigned to items in a table; (iii) documents come
from numerous layouts and the test set includes zero- and few-shot cases as
well as layouts commonly seen in the training set. The benchmark comes with
several baselines, including RoBERTa, LayoutLMv3 and DETR-based Table
Transformer. These baseline models were applied to both tasks of the DocILE
benchmark, with results shared in this paper, offering a quick starting point
for future work. The dataset and baselines are available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>82. <b>标题：Meta-Learning Based Knowledge Extrapolation for Temporal Knowledge Graph</b></summary>
  <p><b>编号</b>：[418]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05640</p>
  <p><b>作者</b>：Zhongwu Chen,  Chengjin Xu,  Fenglong Su,  Zhen Huang,  You Dou</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Knowledge Graph, Knowledge Graph Extrapolation, temporal knowledge graph, completion via learning, surge of interest</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In the last few years, the solution to Knowledge Graph (KG) completion via
learning embeddings of entities and relations has attracted a surge of
interest. Temporal KGs(TKGs) extend traditional Knowledge Graphs (KGs) by
associating static triples with timestamps forming quadruples. Different from
KGs and TKGs in the transductive setting, constantly emerging entities and
relations in incomplete TKGs create demand to predict missing facts with unseen
components, which is the extrapolation setting. Traditional temporal knowledge
graph embedding (TKGE) methods are limited in the extrapolation setting since
they are trained within a fixed set of components. In this paper, we propose a
Meta-Learning based Temporal Knowledge Graph Extrapolation (MTKGE) model, which
is trained on link prediction tasks sampled from the existing TKGs and tested
in the emerging TKGs with unseen entities and relations. Specifically, we
meta-train a GNN framework that captures relative position patterns and
temporal sequence patterns between relations. The learned embeddings of
patterns can be transferred to embed unseen components. Experimental results on
two different TKG extrapolation datasets show that MTKGE consistently
outperforms both the existing state-of-the-art models for knowledge graph
extrapolation and specifically adapted KGE and TKGE baselines.</p>
  </details>
</details>
<details>
  <summary>83. <b>标题：Operation-level Progressive Differentiable Architecture Search</b></summary>
  <p><b>编号</b>：[421]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05632</p>
  <p><b>作者</b>：Xunyu Zhu,  Jian Li,  Yong Liu,  Weiping Wang</p>
  <p><b>备注</b>：To appear in ICDM 2021</p>
  <p><b>关键词</b>：Neural Architecture Search, low compute cost, Differentiable Neural Architecture, high search efficiency, Neural Architecture</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Differentiable Neural Architecture Search (DARTS) is becoming more and more
popular among Neural Architecture Search (NAS) methods because of its high
search efficiency and low compute cost. However, the stability of DARTS is very
inferior, especially skip connections aggregation that leads to performance
collapse. Though existing methods leverage Hessian eigenvalues to alleviate
skip connections aggregation, they make DARTS unable to explore architectures
with better performance. In the paper, we propose operation-level progressive
differentiable neural architecture search (OPP-DARTS) to avoid skip connections
aggregation and explore better architectures simultaneously. We first divide
the search process into several stages during the search phase and increase
candidate operations into the search space progressively at the beginning of
each stage. It can effectively alleviate the unfair competition between
operations during the search phase of DARTS by offsetting the inherent unfair
advantage of the skip connection over other operations. Besides, to keep the
competition between operations relatively fair and select the operation from
the candidate operations set that makes training loss of the supernet largest.
The experiment results indicate that our method is effective and efficient. Our
method's performance on CIFAR-10 is superior to the architecture found by
standard DARTS, and the transferability of our method also surpasses standard
DARTS. We further demonstrate the robustness of our method on three simple
search spaces, i.e., S2, S3, S4, and the results show us that our method is
more robust than standard DARTS. Our code is available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>84. <b>标题：A Survey on Spectral Graph Neural Networks</b></summary>
  <p><b>编号</b>：[422]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05631</p>
  <p><b>作者</b>：Deyu Bo,  Xiao Wang,  Yang Liu,  Yuan Fang,  Yawen Li,  Chuan Shi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：attracted considerable attention, spectral GNNs, Graph neural networks, GNNs, spectral</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Graph neural networks (GNNs) have attracted considerable attention from the
research community. It is well established that GNNs are usually roughly
divided into spatial and spectral methods. Despite that spectral GNNs play an
important role in both graph signal processing and graph representation
learning, existing studies are biased toward spatial approaches, and there is
no comprehensive review on spectral GNNs so far. In this paper, we summarize
the recent development of spectral GNNs, including model, theory, and
application. Specifically, we first discuss the connection between spatial GNNs
and spectral GNNs, which shows that spectral GNNs can capture global
information and have better expressiveness and interpretability. Next, we
categorize existing spectral GNNs according to the spectrum information they
use, \ie, eigenvalues or eigenvectors. In addition, we review major theoretical
results and applications of spectral GNNs, followed by a quantitative
experiment to benchmark some popular spectral GNNs. Finally, we conclude the
paper with some future directions.</p>
  </details>
</details>
<details>
  <summary>85. <b>标题：Improving Differentiable Architecture Search via Self-Distillation</b></summary>
  <p><b>编号</b>：[424]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05629</p>
  <p><b>作者</b>：Xunyu Zhu,  Jian Li,  Yong Liu,  Weiping Wang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Architecture Search, Differentiable Architecture Search, Neural Architecture Search, Architecture, optimal architecture</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Differentiable Architecture Search (DARTS) is a simple yet efficient Neural
Architecture Search (NAS) method. During the search stage, DARTS trains a
supernet by jointly optimizing architecture parameters and network parameters.
During the evaluation stage, DARTS derives the optimal architecture based on
architecture parameters. However, the loss landscape of the supernet is not
smooth, and it results in a performance gap between the supernet and the
optimal architecture. In the paper, we propose Self-Distillation Differentiable
Neural Architecture Search (SD-DARTS) by utilizing self-distillation to
transfer knowledge of the supernet in previous steps to guide the training of
the supernet in the current steps. SD-DARTS can minimize the loss difference
for the two consecutive iterations so that minimize the sharpness of the
supernet's loss to bridge the performance gap between the supernet and the
optimal architecture. Furthermore, we propose voted teachers, which select
multiple previous supernets as teachers and vote teacher output probabilities
as the final teacher prediction. The knowledge of several teachers is more
abundant than a single teacher, thus, voted teachers can be more suitable to
lead the training of the supernet. Experimental results on real datasets
illustrate the advantages of our novel self-distillation-based NAS method
compared to state-of-the-art alternatives.</p>
  </details>
</details>
<details>
  <summary>86. <b>标题：A novel approach to generate datasets with XAI ground truth to evaluate  image models</b></summary>
  <p><b>编号</b>：[426]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05624</p>
  <p><b>作者</b>：Miquel Miró-Nicolau,  Antoni Jaume-i-Capó,  Gabriel Moyà-Alcover</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：models work internally, eXplainable artificial intelligence, artificial intelligence, work internally, increased usage</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>With the increased usage of artificial intelligence (AI), it is imperative to
understand how these models work internally. These needs have led to the
development of a new field called eXplainable artificial intelligence (XAI).
This field consists of on a set of techniques that allows us to theoretically
determine the cause of the AI decisions. One unsolved question about XAI is how
to measure the quality of explanations. In this study, we propose a new method
to generate datasets with ground truth (GT). These datasets allow us to measure
how faithful is a method without ad hoc solutions. We conducted a set of
experiments that compared our GT with real model explanations and obtained
excellent results confirming that our proposed method is correct.</p>
  </details>
</details>
<details>
  <summary>87. <b>标题：Evaluating the Robustness of Discrete Prompts</b></summary>
  <p><b>编号</b>：[430]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05619</p>
  <p><b>作者</b>：Yoichi Ishibashi,  Danushka Bollegala,  Katsuhito Sudoh,  Satoshi Nakamura</p>
  <p><b>备注</b>：Accepted at EACL 2023</p>
  <p><b>关键词</b>：Pre-trained Language Models, fine-tuning Pre-trained Language, diverse NLP tasks, fine-tuning Pre-trained, Models for diverse</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Discrete prompts have been used for fine-tuning Pre-trained Language Models
for diverse NLP tasks. In particular, automatic methods that generate discrete
prompts from a small set of training instances have reported superior
performance. However, a closer look at the learnt prompts reveals that they
contain noisy and counter-intuitive lexical constructs that would not be
encountered in manually-written prompts. This raises an important yet
understudied question regarding the robustness of automatically learnt discrete
prompts when used in downstream tasks. To address this question, we conduct a
systematic study of the robustness of discrete prompts by applying carefully
designed perturbations into an application using AutoPrompt and then measure
their performance in two Natural Language Inference (NLI) datasets. Our
experimental results show that although the discrete prompt-based method
remains relatively robust against perturbations to NLI inputs, they are highly
sensitive to other types of perturbations such as shuffling and deletion of
prompt tokens. Moreover, they generalize poorly across different NLI datasets.
We hope our findings will inspire future work on robust discrete prompt
learning.</p>
  </details>
</details>
<details>
  <summary>88. <b>标题：Anatomical Invariance Modeling and Semantic Alignment for  Self-supervised Learning in 3D Medical Image Segmentation</b></summary>
  <p><b>编号</b>：[433]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05615</p>
  <p><b>作者</b>：Yankai Jiang,  Mingze Sun,  Heng Guo,  Ke Yan,  Le Lu,  Minfeng Xu</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：recently achieved promising, achieved promising performance, recently achieved, achieved promising, image segmentation tasks</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Self-supervised learning (SSL) has recently achieved promising performance
for 3D medical image segmentation tasks. Most current methods follow existing
SSL paradigm originally designed for photographic or natural images, which
cannot explicitly and thoroughly exploit the intrinsic similar anatomical
structures across varying medical images. This may in fact degrade the quality
of learned deep representations by maximizing the similarity among features
containing spatial misalignment information and different anatomical semantics.
In this work, we propose a new self-supervised learning framework, namely
Alice, that explicitly fulfills Anatomical invariance modeling and semantic
alignment via elaborately combining discriminative and generative objectives.
Alice introduces a new contrastive learning strategy which encourages the
similarity between views that are diversely mined but with consistent
high-level semantics, in order to learn invariant anatomical features.
Moreover, we design a conditional anatomical feature alignment module to
complement corrupted embeddings with globally matched semantics and inter-patch
topology information, conditioned by the distribution of local image content,
which permits to create better contrastive pairs. Our extensive quantitative
experiments on two public 3D medical image segmentation benchmarks of FLARE
2022 and BTCV demonstrate and validate the performance superiority of Alice,
surpassing the previous best SSL counterpart methods by 2.11% and 1.77% in Dice
coefficients, respectively.</p>
  </details>
</details>
<details>
  <summary>89. <b>标题：Cross-domain Random Pre-training with Prototypes for Reinforcement  Learning</b></summary>
  <p><b>编号</b>：[434]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05614</p>
  <p><b>作者</b>：Xin Liu,  Yaran Chen,  Haoran Li,  Boyu Li,  Dongbin Zhao</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：shows great potential, pre-training shows great, shows great, great potential, cross-domain</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Task-agnostic cross-domain pre-training shows great potential in image-based
Reinforcement Learning (RL) but poses a big challenge. In this paper, we
propose CRPTpro, a Cross-domain self-supervised Random Pre-Training framework
with prototypes for image-based RL. CRPTpro employs cross-domain random policy
to easily and quickly sample diverse data from multiple domains, to improve
pre-training efficiency. Moreover, prototypical representation learning with a
novel intrinsic loss is proposed to pre-train an effective and generic encoder
across different domains. Without finetuning, the cross-domain encoder can be
implemented for challenging downstream visual-control RL tasks defined in
different domains efficiently. Compared with prior arts like APT and Proto-RL,
CRPTpro achieves better performance on cross-domain downstream RL tasks without
extra training on exploration agents for expert data collection, greatly
reducing the burden of pre-training. Experiments on DeepMind Control suite
(DMControl) demonstrate that CRPTpro outperforms APT significantly on 11/12
cross-domain RL tasks with only 39% pre-training hours, becoming a
state-of-the-art cross-domain pre-training method in both policy learning
performance and pre-training efficiency. The complete code will be released at
this https URL.</p>
  </details>
</details>
<details>
  <summary>90. <b>标题：Emotion Detection From Social Media Posts</b></summary>
  <p><b>编号</b>：[436]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05610</p>
  <p><b>作者</b>：Md Mahbubur Rahman,  Shaila Shova</p>
  <p><b>备注</b>：Course Project</p>
  <p><b>关键词</b>：expressing personal views, personal views, political proposals, social media, Support Vector Machines</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Over the last few years, social media has evolved into a medium for
expressing personal views, emotions, and even business and political proposals,
recommendations, and advertisements. We address the topic of identifying
emotions from text data obtained from social media posts like Twitter in this
research. We have deployed different traditional machine learning techniques
such as Support Vector Machines (SVM), Naive Bayes, Decision Trees, and Random
Forest, as well as deep neural network models such as LSTM, CNN, GRU, BiLSTM,
BiGRU to classify these tweets into four emotion categories (Fear, Anger, Joy,
and Sadness). Furthermore, we have constructed a BiLSTM and BiGRU ensemble
model. The evaluation result shows that the deep neural network models(BiGRU,
to be specific) produce the most promising results compared to traditional
machine learning models, with an 87.53 % accuracy rate. The ensemble model
performs even better (87.66 %), albeit the difference is not significant. This
result will aid in the development of a decision-making tool that visualizes
emotional fluctuations.</p>
  </details>
</details>
<details>
  <summary>91. <b>标题：Predicting Participants' Performance in Programming Contests using Deep  Learning Techniques</b></summary>
  <p><b>编号</b>：[440]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05602</p>
  <p><b>作者</b>：Md Mahbubur Rahman,  Badhan Chandra Das,  Al Amin Biswas,  Md. Musfique Anwar</p>
  <p><b>备注</b>：Camera Ready Version</p>
  <p><b>关键词</b>：recent days, increasing day, number of technology, technology enthusiasts, enthusiasts is increasing</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In recent days, the number of technology enthusiasts is increasing day by day
with the prevalence of technological products and easy access to the internet.
Similarly, the amount of people working behind this rapid development is rising
tremendously. Computer programmers consist of a large portion of those
tech-savvy people. Codeforces, an online programming and contest hosting
platform used by many competitive programmers worldwide. It is regarded as one
of the most standardized platforms for practicing programming problems and
participate in programming contests. In this research, we propose a framework
that predicts the performance of any particular contestant in the upcoming
competitions as well as predicts the rating after that contest based on their
practice and the performance of their previous contests.</p>
  </details>
</details>
<details>
  <summary>92. <b>标题：MatKB: Semantic Search for Polycrystalline Materials Synthesis  Procedures</b></summary>
  <p><b>编号</b>：[443]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05597</p>
  <p><b>作者</b>：Xianjun Yang,  Stephen Wilson,  Linda Petzold</p>
  <p><b>备注</b>：Work in Progress</p>
  <p><b>关键词</b>：Natural Language Processing, Language Processing, Natural Language, retrieval using Natural, extraction and retrieval</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we present a novel approach to knowledge extraction and
retrieval using Natural Language Processing (NLP) techniques for material
science. Our goal is to automatically mine structured knowledge from millions
of research articles in the field of polycrystalline materials and make it
easily accessible to the broader community. The proposed method leverages NLP
techniques such as entity recognition and document classification to extract
relevant information and build an extensive knowledge base, from a collection
of 9.5 Million publications. The resulting knowledge base is integrated into a
search engine, which enables users to search for information about specific
materials, properties, and experiments with greater precision than traditional
search engines like Google. We hope our results can enable material scientists
quickly locate desired experimental procedures, compare their differences, and
even inspire them to design new experiments. Our website will be available at
Github \footnote{this https URL} soon.</p>
  </details>
</details>
<details>
  <summary>93. <b>标题：A large parametrized space of meta-reinforcement learning tasks</b></summary>
  <p><b>编号</b>：[447]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05583</p>
  <p><b>作者</b>：Thomas Miconi</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：tasks, arbitrary stimuli, meta-RL tasks, describe a parametrized, meta-RL</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We describe a parametrized space for simple meta-reinforcement-learning
(meta-RL) tasks with arbitrary stimuli. The parametrization allows us to
randomly generate an arbitrary number of novel simple meta-learning tasks. The
space of meta-RL tasks covered by this parametrization includes many well-known
meta-RL tasks, such as bandit tasks, the Harlow task, T-mazes, the Daw two-step
task and others. Simple extensions allow it to capture tasks based on
two-dimensional topological spaces, such as find-the-spot or key-door tasks. We
describe a number of randomly generated meta-RL tasks and discuss potential
issues arising from random generation.</p>
  </details>
</details>
<details>
  <summary>94. <b>标题：Characterizing Attribution and Fluency Tradeoffs for Retrieval-Augmented  Large Language Models</b></summary>
  <p><b>编号</b>：[448]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05578</p>
  <p><b>作者</b>：Renat Aksitov,  Chung-Ching Chang,  David Reitter,  Siamak Shakeri,  Yunhsuan Sung</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：prevent semantic hallucinations, generative Large Language, recent progress, difficult to prevent, prevent semantic</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Despite recent progress, it has been difficult to prevent semantic
hallucinations in generative Large Language Models. One common solution to this
is augmenting LLMs with a retrieval system and making sure that the generated
output is attributable to the retrieved information. Given this new added
constraint, it is plausible to expect that the overall quality of the output
will be affected, for example, in terms of fluency. Can scaling language models
help?
Here we examine the relationship between fluency and attribution in LLMs
prompted with retrieved evidence in knowledge-heavy dialog settings. Our
experiments were implemented with a set of auto-metrics that are aligned with
human preferences. They were used to evaluate a large set of generations,
produced under varying parameters of LLMs and supplied context.
We show that larger models tend to do much better in both fluency and
attribution, and that (naively) using top-k retrieval versus top-1 retrieval
improves attribution but hurts fluency. We next propose a recipe that could
allow smaller models to both close the gap with larger models and preserve the
benefits of top-k retrieval while avoiding its drawbacks.</p>
  </details>
</details>
<details>
  <summary>95. <b>标题：Sketch Less Face Image Retrieval: A New Challenge</b></summary>
  <p><b>编号</b>：[449]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05576</p>
  <p><b>作者</b>：Dawei Dai,  Yutang Li,  Liang Wang,  Shiyu Fu,  Shuyin Xia,  Guoyin Wang</p>
  <p><b>备注</b>：5 pages, 6 figs</p>
  <p><b>关键词</b>：specific scenarios, identify a person, sketch, face sketch, target face photo</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In some specific scenarios, face sketch was used to identify a person.
However, drawing a complete face sketch often needs skills and takes time,
which hinder its widespread applicability in the practice. In this study, we
proposed a new task named sketch less face image retrieval (SLFIR), in which
the retrieval was carried out at each stroke and aim to retrieve the target
face photo using a partial sketch with as few strokes as possible (see Fig.1).
Firstly, we developed a method to generate the data of sketch with drawing
process, and opened such dataset; Secondly, we proposed a two-stage method as
the baseline for SLFIR that (1) A triplet network, was first adopt to learn the
joint embedding space shared between the complete sketch and its target face
photo; (2) Regarding the sketch drawing episode as a sequence, we designed a
LSTM module to optimize the representation of the incomplete face sketch.
Experiments indicate that the new framework can finish the retrieval using a
partial or pool drawing sketch.</p>
  </details>
</details>
<details>
  <summary>96. <b>标题：PDSum: Prototype-driven Continuous Summarization of Evolving  Multi-document Sets Stream</b></summary>
  <p><b>编号</b>：[461]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05550</p>
  <p><b>作者</b>：Susik Yoon,  Hou Pong Chan,  Jiawei Han</p>
  <p><b>备注</b>：Accepted by WWW'23</p>
  <p><b>关键词</b>：evolving multi-document sets, multi-document set, predefined multi-document set, multi-document, long studied</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Summarizing text-rich documents has been long studied in the literature, but
most of the existing efforts have been made to summarize a static and
predefined multi-document set. With the rapid development of online platforms
for generating and distributing text-rich documents, there arises an urgent
need for continuously summarizing dynamically evolving multi-document sets
where the composition of documents and sets is changing over time. This is
especially challenging as the summarization should be not only effective in
incorporating relevant, novel, and distinctive information from each concurrent
multi-document set, but also efficient in serving online applications. In this
work, we propose a new summarization problem, Evolving Multi-Document sets
stream Summarization (EMDS), and introduce a novel unsupervised algorithm PDSum
with the idea of prototype-driven continuous summarization. PDSum builds a
lightweight prototype of each multi-document set and exploits it to adapt to
new documents while preserving accumulated knowledge from previous documents.
To update new summaries, the most representative sentences for each
multi-document set are extracted by measuring their similarities to the
prototypes. A thorough evaluation with real multi-document sets streams
demonstrates that PDSum outperforms state-of-the-art unsupervised
multi-document summarization algorithms in EMDS in terms of relevance, novelty,
and distinctiveness and is also robust to various evaluation settings.</p>
  </details>
</details>
<details>
  <summary>97. <b>标题：Adding Conditional Control to Text-to-Image Diffusion Models</b></summary>
  <p><b>编号</b>：[464]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05543</p>
  <p><b>作者</b>：Lvmin Zhang,  Maneesh Agrawala</p>
  <p><b>备注</b>：33 pages</p>
  <p><b>关键词</b>：neural network structure, support additional input, network structure, present a neural, neural network</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>We present a neural network structure, ControlNet, to control pretrained
large diffusion models to support additional input conditions. The ControlNet
learns task-specific conditions in an end-to-end way, and the learning is
robust even when the training dataset is small (< 50k). Moreover, training a
ControlNet is as fast as fine-tuning a diffusion model, and the model can be
trained on a personal devices. Alternatively, if powerful computation clusters
are available, the model can scale to large amounts (millions to billions) of
data. We report that large diffusion models like Stable Diffusion can be
augmented with ControlNets to enable conditional inputs like edge maps,
segmentation maps, keypoints, etc. This may enrich the methods to control large
diffusion models and further facilitate related applications.</p>
  </details>
</details>
<details>
  <summary>98. <b>标题：Robust Knowledge Transfer in Tiered Reinforcement Learning</b></summary>
  <p><b>编号</b>：[468]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05534</p>
  <p><b>作者</b>：Jiawei Huang,  Niao He</p>
  <p><b>备注</b>：56 Pages</p>
  <p><b>关键词</b>：Tiered Reinforcement Learning, Tiered Reinforcement, Reinforcement Learning setting, parallel transfer learning, transfer learning framework</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we study the Tiered Reinforcement Learning setting, a parallel
transfer learning framework, where the goal is to transfer knowledge from the
low-tier (source) task to the high-tier (target) task to reduce the exploration
risk of the latter while solving the two tasks in parallel. Unlike previous
work, we do not assume the low-tier and high-tier tasks share the same dynamics
or reward functions, and focus on robust knowledge transfer without prior
knowledge on the task similarity. We identify a natural and necessary condition
called the "Optimal Value Dominance" for our objective. Under this condition,
we propose novel online learning algorithms such that, for the high-tier task,
it can achieve constant regret on partial states depending on the task
similarity and retain near-optimal regret when the two tasks are dissimilar,
while for the low-tier task, it can keep near-optimal without making sacrifice.
Moreover, we further study the setting with multiple low-tier tasks, and
propose a novel transfer source selection mechanism, which can ensemble the
information from all low-tier tasks and allow provable benefits on a much
larger state-action space.</p>
  </details>
</details>
<details>
  <summary>99. <b>标题：Learning cooperative behaviours in adversarial multi-agent systems</b></summary>
  <p><b>编号</b>：[470]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05528</p>
  <p><b>作者</b>：Ni Wang,  Gautham P. Das,  Alan G. Millard</p>
  <p><b>备注</b>：23rd Annual Conference, Towards Autonomous Robotic Systems 2022</p>
  <p><b>关键词</b>：multi-agent platform called, virtual multi-agent platform, existing virtual multi-agent, platform called RoboSumo, continuous action spaces</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This work extends an existing virtual multi-agent platform called RoboSumo to
create TripleSumo -- a platform for investigating multi-agent cooperative
behaviors in continuous action spaces, with physical contact in an adversarial
environment. In this paper we investigate a scenario in which two agents,
namely `Bug' and `Ant', must team up and push another agent `Spider' out of the
arena. To tackle this goal, the newly added agent `Bug' is trained during an
ongoing match between `Ant' and `Spider'. `Bug' must develop awareness of the
other agents' actions, infer the strategy of both sides, and eventually learn
an action policy to cooperate. The reinforcement learning algorithm Deep
Deterministic Policy Gradient (DDPG) is implemented with a hybrid reward
structure combining dense and sparse rewards. The cooperative behavior is
quantitatively evaluated by the mean probability of winning the match and mean
number of steps needed to win.</p>
  </details>
</details>
<details>
  <summary>100. <b>标题：Awareness requirement and performance management for adaptive systems: a  survey</b></summary>
  <p><b>编号</b>：[476]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05518</p>
  <p><b>作者</b>：Tarik A. Rashid,  Bryar A. Hassan,  Abeer Alsadoon,  Shko Qader,  S. Vimal,  Amit Chhabra,  Zaher Mundher Yaseen</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：assess and modify, modify its behavior, performing as intended, improved functionality, functionality or performance</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Self-adaptive software can assess and modify its behavior when the assessment
indicates that the program is not performing as intended or when improved
functionality or performance is available. Since the mid-1960s, the subject of
system adaptivity has been extensively researched, and during the last decade,
many application areas and technologies involving self-adaptation have gained
prominence. All of these efforts have in common the introduction of
self-adaptability through software. Thus, it is essential to investigate
systematic software engineering methods to create self-adaptive systems that
may be used across different domains. The primary objective of this research is
to summarize current advances in awareness requirements for adaptive strategies
based on an examination of state-of-the-art methods described in the
literature. This paper presents a review of self-adaptive systems in the
context of requirement awareness and summarizes the most common methodologies
applied. At first glance, it gives a review of the previous surveys and works
about self-adaptive systems. Afterward, it classifies the current self-adaptive
systems based on six criteria. Then, it presents and evaluates the most common
self-adaptive approaches. Lastly, an evaluation among the self-adaptive models
is conducted based on four concepts (requirements description, monitoring,
relationship, dependency/impact, and tools).</p>
  </details>
</details>
<details>
  <summary>101. <b>标题：Building Intelligence in the Mechanical Domain -- Harvesting the  Reservoir Computing Power in Origami to Achieve Information Perception Tasks</b></summary>
  <p><b>编号</b>：[477]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05517</p>
  <p><b>作者</b>：Jun Wang,  Suyi Li</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：reservoir computing framework, physical reservoir computing, experimentally examine, examine the cognitive, cognitive capability</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this paper, we experimentally examine the cognitive capability of a
simple, paper-based Miura-ori -- using the physical reservoir computing
framework -- to achieve different information perception tasks. The body
dynamics of Miura-ori (aka. its vertices displacements), which is excited by a
simple harmonic base excitation, can be exploited as the reservoir computing
resource. By recording these dynamics with a high-resolution camera and image
processing program and then using linear regression for training, we show that
the origami reservoir has sufficient computing capacity to estimate the weight
and position of a payload. It can also recognize the input frequency and
magnitude patterns. Furthermore, multitasking is achievable by simultaneously
applying two targeted functions to the same reservoir state matrix. Therefore,
we demonstrate that Miura-ori can assess the dynamic interactions between its
body and ambient environment to extract meaningful information -- an
intelligent behavior in the mechanical domain. Given that Miura-ori has been
widely used to construct deployable structures, lightweight materials, and
compliant robots, enabling such information perception tasks can add a new
dimension to the functionality of such a versatile structure.</p>
  </details>
</details>
<details>
  <summary>102. <b>标题：FairPy: A Toolkit for Evaluation of Social Biases and their Mitigation  in Large Language Models</b></summary>
  <p><b>编号</b>：[480]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05508</p>
  <p><b>作者</b>：Hrishikesh Viswanath,  Tianyi Zhang</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：social groups based, Studies have shown, social groups, groups based, pretrained language models</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Studies have shown that large pretrained language models exhibit biases
against social groups based on race, gender etc, which they inherit from the
datasets they are trained on. Various researchers have proposed mathematical
tools for quantifying and identifying these biases. There have been methods
proposed to mitigate such biases. In this paper, we present a comprehensive
quantitative evaluation of different kinds of biases such as race, gender,
ethnicity, age etc. exhibited by popular pretrained language models such as
BERT, GPT-2 etc. and also present a toolkit that provides plug-and-play
interfaces to connect mathematical tools to identify biases with large
pretrained language models such as BERT, GPT-2 etc. and also present users with
the opportunity to test custom models against these metrics. The toolkit also
allows users to debias existing and custom models using the debiasing
techniques proposed so far. The toolkit is available at
this https URL.</p>
  </details>
</details>
<details>
  <summary>103. <b>标题：Long-Context Language Decision Transformers and Exponential Tilt for  Interactive Text Environments</b></summary>
  <p><b>编号</b>：[481]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05507</p>
  <p><b>作者</b>：Nicolas Gontier,  Pau Rodriguez,  Issam Laradji,  David Vazquez,  Christopher Pal</p>
  <p><b>备注</b>：12 pages, 5 figures, 3 tables</p>
  <p><b>关键词</b>：execute compositional actions, Text-based game environments, execute compositional, compositional actions, learn from sparse</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Text-based game environments are challenging because agents must deal with
long sequences of text, execute compositional actions using text and learn from
sparse rewards. We address these challenges by proposing Long-Context Language
Decision Transformers (LLDTs), a framework that is based on long transformer
language models and decision transformers (DTs). LLDTs extend DTs with 3
components: (1) exponential tilt to guide the agent towards high obtainable
goals, (2) novel goal conditioning methods yielding significantly better
results than the traditional return-to-go (sum of all future rewards), and (3)
a model of future observations. Our ablation results show that predicting
future observations improves agent performance. To the best of our knowledge,
LLDTs are the first to address offline RL with DTs on these challenging games.
Our experiments show that LLDTs achieve the highest scores among many different
types of agents on some of the most challenging Jericho games, such as
Enchanter.</p>
  </details>
</details>
<details>
  <summary>104. <b>标题：MaskSketch: Unpaired Structure-guided Masked Image Generation</b></summary>
  <p><b>编号</b>：[485]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05496</p>
  <p><b>作者</b>：Dina Bashkirova,  Jose Lezama,  Kihyuk Sohn,  Kate Saenko,  Irfan Essa</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Recent conditional image, generation methods produce, Recent conditional, remarkable diversity, conditional image generation</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Recent conditional image generation methods produce images of remarkable
diversity, fidelity and realism. However, the majority of these methods allow
conditioning only on labels or text prompts, which limits their level of
control over the generation result. In this paper, we introduce MaskSketch, an
image generation method that allows spatial conditioning of the generation
result using a guiding sketch as an extra conditioning signal during sampling.
MaskSketch utilizes a pre-trained masked generative transformer, requiring no
model training or paired supervision, and works with input sketches of
different levels of abstraction. We show that intermediate self-attention maps
of a masked generative transformer encode important structural information of
the input image, such as scene layout and object shape, and we propose a novel
sampling method based on this observation to enable structure-guided
generation. Our results show that MaskSketch achieves high image realism and
fidelity to the guiding structure. Evaluated on standard benchmark datasets,
MaskSketch outperforms state-of-the-art methods for sketch-to-image
translation, as well as unpaired image-to-image translation approaches.</p>
  </details>
</details>
<details>
  <summary>105. <b>标题：Element-Wise Attention Layers: an option for optimization</b></summary>
  <p><b>编号</b>：[488]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05488</p>
  <p><b>作者</b>：Giovanni Araujo Bacochina,  Rodrigo Clemente Thom de Souza</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Deep Learning Field, Attention Layers, Transformer-based models, recent years, key element</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>The use of Attention Layers has become a trend since the popularization of
the Transformer-based models, being the key element for many state-of-the-art
models that have been developed through recent years. However, one of the
biggest obstacles in implementing these architectures - as well as many others
in Deep Learning Field - is the enormous amount of optimizing parameters they
possess, which make its use conditioned on the availability of robust hardware.
In this paper, it's proposed a new method of attention mechanism that adapts
the Dot-Product Attention, which uses matrices multiplications, to become
element-wise through the use of arrays multiplications. To test the
effectiveness of such approach, two models (one with a VGG-like architecture
and one with the proposed method) have been trained in a classification task
using Fashion MNIST and CIFAR10 datasets. Each model has been trained for 10
epochs in a single Tesla T4 GPU from Google Colaboratory. The results show that
this mechanism allows for an accuracy of 92% of the VGG-like counterpart in
Fashion MNIST dataset, while reducing the number of parameters in 97%. For
CIFAR10, the accuracy is still equivalent to 60% of the VGG-like counterpart
while using 50% less parameters.</p>
  </details>
</details>
<details>
  <summary>106. <b>标题：Heckerthoughts</b></summary>
  <p><b>编号</b>：[494]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05449</p>
  <p><b>作者</b>：David Heckerman</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：Eric Horvitz, Greg Cooper, Eric, Horvitz, Greg</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In 1987, Eric Horvitz, Greg Cooper, and I visited I.J. Good at his
university. We wanted to see him was not because he worked with Alan Turing to
help win WWII by decoding encrypted messages from the Germans, although that
certainly intrigued us. Rather, we wanted to see him because we had just
finished reading his book "Good Thinking," which summarized his life's work in
Probability and its Applications. We were graduate students at Stanford working
in AI, and amazed that his thinking was so similar to ours, having worked
decades before us and coming from such a seemingly different perspective not
involving AI. This story is a fitting introduction this manuscript. Now having
years to look back on my work, to boil it down to its essence, and to better
appreciate its significance (if any) in the evolution of AI and ML, I realized
it was time to put my work in perspective, providing a roadmap to any who would
like to explore it. After I had this realization, it occurred to me that this
is what I.J. Good did in his book. This manuscript is for those who want to
understand basic concepts central to ML and AI and to learn about early
applications of these concepts. Ironically, after I finished writing this
manuscript, I realized that a lot of the concepts that I included are missing
in modern courses on ML. I hope this work will help to make up for these
omissions. The presentation gets somewhat technical in parts, but I've tried to
keep the math to the bare minimum. In addition to the technical presentations,
I include stories about how the ideas came to be and the effects they have had.
When I was a student in physics, I was given dry texts to read. In class,
however, several of my physics professors would tell stories around the work.
Those stories fascinated me and really made the theory stick. So here, I do my
best to present both the ideas and the stories behind them.</p>
  </details>
</details>
<details>
  <summary>107. <b>标题：The Construction of Reality in an AI: A Review</b></summary>
  <p><b>编号</b>：[495]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05448</p>
  <p><b>作者</b>：Jeffrey W. Johnston</p>
  <p><b>备注</b>：34 pages text, 37 pages references</p>
  <p><b>关键词</b>：surveyed by Frank, inspired by Jean, Jean Piaget, Gary Drescher seeks, constructivism as inspired</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>AI constructivism as inspired by Jean Piaget, described and surveyed by Frank
Guerin, and representatively implemented by Gary Drescher seeks to create
algorithms and knowledge structures that enable agents to acquire, maintain,
and apply a deep understanding of the environment through sensorimotor
interactions. This paper aims to increase awareness of constructivist AI
implementations to encourage greater progress toward enabling lifelong learning
by machines. It builds on Guerin's 2008 "Learning Like a Baby: A Survey of AI
approaches." After briefly recapitulating that survey, it summarizes subsequent
progress by the Guerin referents, numerous works not covered by Guerin (or
found in other surveys), and relevant efforts in related areas. The focus is on
knowledge representations and learning algorithms that have been used in
practice viewed through lenses of Piaget's schemas, adaptation processes, and
staged development. The paper concludes with a preview of a simple framework
for constructive AI being developed by the author that parses concepts from
sensory input and stores them in a semantic memory network linked to episodic
data. Extensive references are provided.</p>
  </details>
</details>
<details>
  <summary>108. <b>标题：Robust Scheduling with GFlowNets</b></summary>
  <p><b>编号</b>：[497]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.05446</p>
  <p><b>作者</b>：David W. Zhang,  Corrado Rainone,  Markus Peschl,  Roberto Bondesan</p>
  <p><b>备注</b>：An earlier version appeared at the NeurIPS 2022 workshop ML4Systems</p>
  <p><b>关键词</b>：classical NP-hard problem, classical NP-hard, schedule operations, target hardware, NP-hard problem</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Finding the best way to schedule operations in a computation graph is a
classical NP-hard problem which is central to compiler optimization. However,
evaluating the goodness of a schedule on the target hardware can be very
time-consuming. Traditional approaches as well as previous machine learning
ones typically optimize proxy metrics, which are fast to evaluate but can lead
to bad schedules when tested on the target hardware. In this work, we propose a
new approach to scheduling by sampling proportionally to the proxy metric using
a novel GFlowNet method. We introduce a technique to control the trade-off
between diversity and goodness of the proposed schedules at inference time and
demonstrate empirically that the pure optimization baselines can lead to subpar
performance with respect to our approach when tested on a target model.
Furthermore, we show that conditioning the GFlowNet on the computation graph
enables generalization to unseen scheduling problems for both synthetic and
real-world compiler datasets.</p>
  </details>
</details>
<details>
  <summary>109. <b>标题：AV-data2vec: Self-supervised Learning of Audio-Visual Speech  Representations with Contextualized Target Representations</b></summary>
  <p><b>编号</b>：[510]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06419</p>
  <p><b>作者</b>：Jiachen Lian,  Alexei Baevski,  Wei-Ning Hsu,  Michael Auli</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：shown great potential, labeled data required, build good systems, Self-supervision has shown, good systems</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Self-supervision has shown great potential for audio-visual speech
recognition by vastly reducing the amount of labeled data required to build
good systems. However, existing methods are either not entirely end-to-end or
do not train joint representations of both modalities. In this paper, we
introduce AV-data2vec which addresses these challenges and builds audio-visual
representations based on predicting contextualized representations which has
been successful in the uni-modal case. The model uses a shared transformer
encoder for both audio and video and can combine both modalities to improve
speech recognition. Results on LRS3 show that AV-data2vec consistently
outperforms existing methods under most settings.</p>
  </details>
</details>
<details>
  <summary>110. <b>标题：Sources of Richness and Ineffability for Phenomenally Conscious States</b></summary>
  <p><b>编号</b>：[513]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06403</p>
  <p><b>作者</b>：Xu Ji,  Eric Elmoznino,  George Deane,  Axel Constant,  Guillaume Dumas,  Guillaume Lajoie,  Jonathan Simon,  Yoshua Bengio</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：full of detail, ineffable or hard, conscious experience, ineffability, conscious experience corresponds</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>Conscious states (states that there is something it is like to be in) seem
both rich or full of detail, and ineffable or hard to fully describe or recall.
The problem of ineffability, in particular, is a longstanding issue in
philosophy that partly motivates the explanatory gap: the belief that
consciousness cannot be reduced to underlying physical processes. Here, we
provide an information theoretic dynamical systems perspective on the richness
and ineffability of consciousness. In our framework, the richness of conscious
experience corresponds to the amount of information in a conscious state and
ineffability corresponds to the amount of information lost at different stages
of processing. We describe how attractor dynamics in working memory would
induce impoverished recollections of our original experiences, how the discrete
symbolic nature of language is insufficient for describing the rich and
high-dimensional structure of experiences, and how similarity in the cognitive
function of two individuals relates to improved communicability of their
experiences to each other. While our model may not settle all questions
relating to the explanatory gap, it makes progress toward a fully physicalist
explanation of the richness and ineffability of conscious experience: two
important aspects that seem to be part of what makes qualitative character so
puzzling.</p>
  </details>
</details>
<details>
  <summary>111. <b>标题：Incorporating Expert Opinion on Observable Quantities into Statistical  Models -- A General Framework</b></summary>
  <p><b>编号</b>：[514]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06391</p>
  <p><b>作者</b>：Philip Cooney,  Arthur White</p>
  <p><b>备注</b>：</p>
  <p><b>关键词</b>：expert opinion, incorporate expert opinion, observable quantities, opinion, expert</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>This article describes an approach to incorporate expert opinion on
observable quantities through the use of a loss function which updates a prior
belief as opposed to specifying parameters on the priors. Eliciting information
on observable quantities allows experts to provide meaningful information on a
quantity familiar to them, in contrast to elicitation on model parameters,
which may be subject to interactions with other parameters or non-linear
transformations before obtaining an observable quantity. The approach to
incorporating expert opinion described in this paper is distinctive in that we
do not specify a prior to match an expert's opinion on observed quantity,
rather we obtain a posterior by updating the model parameters through a loss
function. This loss function contains the observable quantity, expressed a
function of the parameters, and is related to the expert's opinion which is
typically operationalized as a statistical distribution. Parameters which
generate observable quantities which are further from the expert's opinion
incur a higher loss, allowing for the model parameters to be estimated based on
their fidelity to both the data and expert opinion, with the relative strength
determined by the number of observations and precision of the elicited belief.
Including expert opinion in this fashion allows for a flexible specification of
the opinion and in many situations is straightforward to implement with
commonly used probabilistic programming software. We highlight this using three
worked examples of varying model complexity including survival models, a
multivariate normal distribution and a regression problem.</p>
  </details>
</details>
<details>
  <summary>112. <b>标题：Variational Bayesian Neural Networks via Resolution of Singularities</b></summary>
  <p><b>编号</b>：[533]</p>
  <p><b>链接</b>：https://arxiv.org/abs/2302.06035</p>
  <p><b>作者</b>：Susan Wei,  Edmund Lau</p>
  <p><b>备注</b>：32 pages, 13 figures</p>
  <p><b>关键词</b>：singular learning theory, learning theory, theory and practice, variational, variational inference</p>
  <details>
    <summary><b>点击查看摘要</b></summary>
    <p>In this work, we advocate for the importance of singular learning theory
(SLT) as it pertains to the theory and practice of variational inference in
Bayesian neural networks (BNNs). To begin, using SLT, we lay to rest some of
the confusion surrounding discrepancies between downstream predictive
performance measured via e.g., the test log predictive density, and the
variational objective. Next, we use the SLT-corrected asymptotic form for
singular posterior distributions to inform the design of the variational family
itself. Specifically, we build upon the idealized variational family introduced
in \citet{bhattacharya_evidence_2020} which is theoretically appealing but
practically intractable. Our proposal takes shape as a normalizing flow where
the base distribution is a carefully-initialized generalized gamma. We conduct
experiments comparing this to the canonical Gaussian base distribution and show
improvements in terms of variational free energy and variational generalization
error.</p>
  </details>
</details>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">徐耀彬</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://louishsu.xyz/2023/02/15/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html">http://louishsu.xyz/2023/02/15/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://louishsu.xyz" target="_blank">LOUIS' BLOG</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"></div><div class="post_share"><div class="social-share" data-image="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="next-post pull-full"><a href="/2022/11/26/%E5%8D%87%E7%BA%A7%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E5%85%A8%E6%94%BB%E7%95%A5.html"><img class="next-cover" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">升级深度学习开发环境全攻略</div></div></a></div></nav><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="twikoo-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="card-info-avatar is-center"><img class="avatar-img" src="/img/touxiang.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/><div class="author-info__name">徐耀彬</div><div class="author-info__description">专注于自然语言处理前沿技术与应用价值！</div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">13</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">标签</div><div class="length-num">4</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">分类</div><div class="length-num">7</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/isLouisHsu"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/isLouisHsu" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:is.louishsu@foxmail.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>公告</span></div><div class="announcement_content">记录和分享一些学习和开源内容，若有问题可通过邮箱is.louishsu@foxmail.com联系，欢迎交流！！</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">1.</span> <span class="toc-text">统计</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">2.</span> <span class="toc-text">计算机视觉</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">3.</span> <span class="toc-text">自然语言处理</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">4.</span> <span class="toc-text">机器学习</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">5.</span> <span class="toc-text">人工智能</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2023/02/15/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html" title="Arxiv每日速递(2023-02-15)"><img src="https://cdn.jsdelivr.net/gh/isLouisHsu/resource@master/blog_resource/_posts/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92/wc.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Arxiv每日速递(2023-02-15)"/></a><div class="content"><a class="title" href="/2023/02/15/Arxiv%E6%AF%8F%E6%97%A5%E9%80%9F%E9%80%92.html" title="Arxiv每日速递(2023-02-15)">Arxiv每日速递(2023-02-15)</a><time datetime="2023-02-15T00:44:26.223Z" title="发表于 2023-02-15 08:44:26">2023-02-15</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/11/26/%E5%8D%87%E7%BA%A7%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E5%85%A8%E6%94%BB%E7%95%A5.html" title="升级深度学习开发环境全攻略"><img src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="升级深度学习开发环境全攻略"/></a><div class="content"><a class="title" href="/2022/11/26/%E5%8D%87%E7%BA%A7%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E5%85%A8%E6%94%BB%E7%95%A5.html" title="升级深度学习开发环境全攻略">升级深度学习开发环境全攻略</a><time datetime="2022-11-26T15:29:06.000Z" title="发表于 2022-11-26 23:29:06">2022-11-26</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/11/17/2022%E5%85%A8%E7%90%83%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%8A%80%E6%9C%AF%E5%88%9B%E6%96%B0%E5%A4%A7%E8%B5%9B(GAIIC2022)%EF%BC%9A%E5%95%86%E5%93%81%E6%A0%87%E9%A2%98%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB(%E4%BA%8C%E7%AD%89%E5%A5%96).html" title="2022全球人工智能技术创新大赛(GAIIC2022)：商品标题实体识别(二等奖)"><img src="https://cdn.kesci.com/upload/image/r7j60un866.png?imageView2/2/w/2500/h/2500" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="2022全球人工智能技术创新大赛(GAIIC2022)：商品标题实体识别(二等奖)"/></a><div class="content"><a class="title" href="/2022/11/17/2022%E5%85%A8%E7%90%83%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%8A%80%E6%9C%AF%E5%88%9B%E6%96%B0%E5%A4%A7%E8%B5%9B(GAIIC2022)%EF%BC%9A%E5%95%86%E5%93%81%E6%A0%87%E9%A2%98%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB(%E4%BA%8C%E7%AD%89%E5%A5%96).html" title="2022全球人工智能技术创新大赛(GAIIC2022)：商品标题实体识别(二等奖)">2022全球人工智能技术创新大赛(GAIIC2022)：商品标题实体识别(二等奖)</a><time datetime="2022-11-17T14:29:06.000Z" title="发表于 2022-11-17 22:29:06">2022-11-17</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/10/22/%E4%B8%AD%E5%9B%BD%E6%B3%95%E5%BE%8B%E6%99%BA%E8%83%BD%E6%8A%80%E6%9C%AF%E8%AF%84%E6%B5%8B(CAIL2021)%EF%BC%9A%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96(Rank2).html" title="中国法律智能技术评测(CAIL2021)：信息抽取(Rank2)"><img src="http://cail.cipsc.org.cn/img/index_mainpic.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="中国法律智能技术评测(CAIL2021)：信息抽取(Rank2)"/></a><div class="content"><a class="title" href="/2021/10/22/%E4%B8%AD%E5%9B%BD%E6%B3%95%E5%BE%8B%E6%99%BA%E8%83%BD%E6%8A%80%E6%9C%AF%E8%AF%84%E6%B5%8B(CAIL2021)%EF%BC%9A%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96(Rank2).html" title="中国法律智能技术评测(CAIL2021)：信息抽取(Rank2)">中国法律智能技术评测(CAIL2021)：信息抽取(Rank2)</a><time datetime="2021-10-22T14:29:06.000Z" title="发表于 2021-10-22 22:29:06">2021-10-22</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/05/19/%E5%85%A8%E7%90%83%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%8A%80%E6%9C%AF%E5%88%9B%E6%96%B0%E5%A4%A7%E8%B5%9B%E3%80%90%E8%B5%9B%E9%81%93%E4%B8%80%E3%80%91%EF%BC%9A%E5%8C%BB%E5%AD%A6%E5%BD%B1%E5%83%8F%E6%8A%A5%E5%91%8A%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B(%E4%B8%89%E7%AD%89%E5%A5%96).html" title="全球人工智能技术创新大赛【赛道一】：医学影像报告异常检测(三等奖)"><img src="https://tianchi-public.oss-cn-hangzhou.aliyuncs.com/public/files/forum/161037709574435991610377095138.jpeg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="全球人工智能技术创新大赛【赛道一】：医学影像报告异常检测(三等奖)"/></a><div class="content"><a class="title" href="/2021/05/19/%E5%85%A8%E7%90%83%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%8A%80%E6%9C%AF%E5%88%9B%E6%96%B0%E5%A4%A7%E8%B5%9B%E3%80%90%E8%B5%9B%E9%81%93%E4%B8%80%E3%80%91%EF%BC%9A%E5%8C%BB%E5%AD%A6%E5%BD%B1%E5%83%8F%E6%8A%A5%E5%91%8A%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B(%E4%B8%89%E7%AD%89%E5%A5%96).html" title="全球人工智能技术创新大赛【赛道一】：医学影像报告异常检测(三等奖)">全球人工智能技术创新大赛【赛道一】：医学影像报告异常检测(三等奖)</a><time datetime="2021-05-19T09:57:06.000Z" title="发表于 2021-05-19 17:57:06">2021-05-19</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2023 By 徐耀彬</div><div class="footer_custom_text"><p><a style="margin-inline:5px"target="_blank"href="https://hexo.io/"><img src="https://img.shields.io/badge/Frame-Hexo-blue?style=flat&logo=hexo"title="博客框架为Hexo"alt="img"></a><a style="margin-inline:5px"target="_blank"href="https://butterfly.js.org/"><img src="https://img.shields.io/badge/Theme-Butterfly-6513df?style=flat&logo=bitdefender"title="主题采用butterfly"alt="img"></a><a style="margin-inline:5px"target="_blank"href="https://www.jsdelivr.com/"><img src="https://img.shields.io/badge/CDN-jsDelivr-orange?style=flat&logo=jsDelivr"title="本站使用JsDelivr为静态资源提供CDN加速"alt="img"></a><a style="margin-inline:5px"target="_blank"href="https://github.com/"><img src="https://img.shields.io/badge/Source-Github-d021d6?style=flat&logo=GitHub"title="本站项目由Gtihub托管"alt="img"></a><a style="margin-inline:5px"target="_blank"href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img src="https://img.shields.io/badge/Copyright-BY--NC--SA%204.0-d42328?style=flat&logo=Claris"alt="img"title="本站采用知识共享署名-非商业性使用-相同方式共享4.0国际许可协议进行许可"></a></br></p></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="font-plus" type="button" title="放大字体"><i class="fas fa-plus"></i></button><button id="font-minus" type="button" title="缩小字体"><i class="fas fa-minus"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div></div><hr/><div id="local-search-results"></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.css"><script>(() => {
  document.querySelectorAll('#article-container span.katex-display').forEach(item => {
    btf.wrap(item, 'div', '', 'katex-wrap')
  })
})()</script><script>(()=>{
  const $countDom = document.getElementById('twikoo-count')
  const init = () => {
    let initData = {
      el: '#twikoo-wrap',
      envId: 'blog-',
      region: ''
    }

    if (false) {
      const otherData = false
      initData = Object.assign(initData, otherData)
    }
    
    twikoo.init(initData)
  }

  const getCount = () => {
    twikoo.getCommentsCount({
      envId: 'blog-',
      region: '',
      urls: [window.location.pathname],
      includeReply: false
    }).then(function (res) {
      $countDom.innerText = res[0].count
    }).catch(function (err) {
      console.error(err);
    });
  }

  const loadTwikoo = (bool = false) => {
    if (typeof twikoo === 'object') {
      init()
      bool && $countDom && setTimeout(getCount,0)
    } else {
      getScript('https://cdn.jsdelivr.net/npm/twikoo/dist/twikoo.all.min.js').then(()=> {
        init()
        bool && $countDom && setTimeout(getCount,0)
      })
    }
  }

  if ('Twikoo' === 'Twikoo' || !false) {
    if (false) btf.loadComment(document.getElementById('twikoo-wrap'), loadTwikoo)
    else loadTwikoo(true)
  } else {
    window.loadOtherComment = () => {
      loadTwikoo()
    }
  }
})()</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><!-- hexo injector body_end start --> <script data-pjax>if(document.getElementById('recent-posts') && (location.pathname ==='/'|| '/' ==='all')){
    var parent = document.getElementById('recent-posts');
    var child = '<div class="recent-post-item" style="width:100%;height: auto"><div id="catalog_magnet"><div class="magnet_item"><a class="magnet_link" href="http://louishsu.xyz/categories/机器学习/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🐱 机器学习 (1)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://louishsu.xyz/categories/自然语言处理/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">📚 自然语言处理 (1)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://louishsu.xyz/categories/竞赛相关/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🎮 竞赛相关 (3)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://louishsu.xyz/categories/阅读笔记/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🎮 阅读笔记 (1)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><a class="magnet_link_more"  href="http://louishsu.xyz/categories" style="flex:1;text-align: center;margin-bottom: 10px;">查看更多...</a></div></div>';
    console.log('已挂载magnet')
    parent.insertAdjacentHTML("afterbegin",child)}
     </script><style>#catalog_magnet{flex-wrap: wrap;display: flex;width:100%;justify-content:space-between;padding: 10px 10px 0 10px;align-content: flex-start;}.magnet_item{flex-basis: calc(50% - 5px);background: #f2f2f2;margin-bottom: 10px;border-radius: 8px;transition: all 0.2s ease-in-out;}.magnet_item:hover{background: #b30070}.magnet_link_more{color:#555}.magnet_link{color:black}.magnet_link:hover{color:white}@media screen and (max-width: 600px) {.magnet_item {flex-basis: 100%;}}.magnet_link_context{display:flex;padding: 10px;font-size:16px;transition: all 0.2s ease-in-out;}.magnet_link_context:hover{padding: 10px 20px;}</style>
    <style></style>
  <script data-pjax src="https://cdn.jsdelivr.net/gh/Zfour/hexo-github-calendar@1.21/hexo_githubcalendar.js"></script>
  <script data-pjax>
        function GithubCalendarConfig(){
            var git_githubapiurl ="https://python-github-calendar-api.vercel.app/api?isLouisHsu";
            var git_color =['#ebedf0', '#fdcdec', '#fc9bd9', '#fa6ac5', '#f838b2', '#f5089f', '#c4067e', '#92055e', '#540336', '#48022f', '#30021f'];
            var git_user ="isLouisHsu";
            var parent_div_git = document.getElementById('recent-posts');
            var git_div_html = '<div class="recent-post-item" style="width:100%;height:auto;padding:10px;"><div id="github_loading" style="width:10%;height:100%;margin:0 auto;display: block"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"  viewBox="0 0 50 50" style="enable-background:new 0 0 50 50" xml:space="preserve"><path fill="#d0d0d0" d="M25.251,6.461c-10.318,0-18.683,8.365-18.683,18.683h4.068c0-8.071,6.543-14.615,14.615-14.615V6.461z" transform="rotate(275.098 25 25)"><animateTransform attributeType="xml" attributeName="transform" type="rotate" from="0 25 25" to="360 25 25" dur="0.6s" repeatCount="indefinite"></animateTransform></path></svg></div><div id="github_container"></div></div>';
            if(parent_div_git && location.pathname =='/'){
                console.log('已挂载github calendar')
                // parent_div_git.innerHTML=git_div_html+parent_div_git.innerHTML // 无报错，但不影响使用(支持pjax跳转)
                parent_div_git.insertAdjacentHTML("afterbegin",git_div_html) // 有报错，但不影响使用(支持pjax跳转)
            };
            GithubCalendar(git_githubapiurl,git_color,git_user)
        }
        if(document.getElementById('recent-posts')){
            GithubCalendarConfig()
        }
    </script>
    <style>#github_container{min-height:280px}@media screen and (max-width:650px) {#github_container{background-image:;min-height:0px}}</style>
    <style></style><script data-pjax>function electric_clock_injector_config(){
                var parent_div_git = document.getElementsByClassName('sticky_layout')[0];
                var item_html = '<div class="card-widget card-clock"><div class="card-glass"><div class="card-background"><div class="card-content"><div id="hexo_electric_clock"><img id="card-clock-loading" src="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-clock/clock/images/weather/loading.gif" style="height: 120px; width: 100%;" data-ll-status="loading" class="entered loading"></div></div></div></div></div>';
                console.log('已挂载electric_clock')
                // parent_div_git.innerHTML=item_html+parent_div_git.innerHTML // 无报错，但不影响使用(支持pjax跳转)
                parent_div_git.insertAdjacentHTML("afterbegin",item_html) // 有报错，但不影响使用(支持pjax跳转)
            }if( document.getElementsByClassName('sticky_layout')[0] && (location.pathname ==='all'|| 'all' ==='all')){

            electric_clock_injector_config()
        } </script><script src="https://pv.sohu.com/cityjson?ie=utf-8"></script><script data-pjax  src="https://cdn.jsdelivr.net/gh/Zfour/hexo-electric-clock@1.0.6/clock.js"></script><!-- hexo injector body_end end --><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"model":{"jsonPath":"/live2dw/assets/hijiki.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":false},"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body></html>